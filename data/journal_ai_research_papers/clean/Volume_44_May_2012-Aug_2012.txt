Journal of Artificial Intelligence Research 44 (2012) 587-632

Submitted 03/12; published 07/12

SAP Speaks PDDL: Exploiting a Software-Engineering
Model for Planning in Business Process Management
Jorg Hoffmann

hoffmann@cs.uni-saarland.de

Saarland University, Saarbrucken, Germany

Ingo Weber

ingo.weber@nicta.com.au

NICTA, Sydney, Australia

Frank Michael Kraft

frank.michael.kraft@bpmnforum.net

bpmnforum.net, Germany

Abstract
Planning is concerned with the automated solution of action sequencing problems described in declarative languages giving the action preconditions and effects. One important
application area for such technology is the creation of new processes in Business Process
Management (BPM), which is essential in an ever more dynamic business environment. A
major obstacle for the application of Planning in this area lies in the modeling. Obtaining a suitable model to plan with  ideally a description in PDDL, the most commonly
used planning language  is often prohibitively complicated and/or costly. Our core observation in this work is that this problem can be ameliorated by leveraging synergies with
model-based software development. Our application at SAP, one of the leading vendors of
enterprise software, demonstrates that even one-to-one model re-use is possible.
The model in question is called Status and Action Management (SAM). It describes
the behavior of Business Objects (BO), i.e., large-scale data structures, at a level of abstraction corresponding to the language of business experts. SAM covers more than 400
kinds of BOs, each of which is described in terms of a set of status variables and how their
values are required for, and affected by, processing steps (actions) that are atomic from a
business perspective. SAM was developed by SAP as part of a major model-based software
engineering effort. We show herein that one can use this same model for planning, thus
obtaining a BPM planning application that incurs no modeling overhead at all.
We compile SAM into a variant of PDDL, and adapt an off-the-shelf planner to solve
this kind of problem. Thanks to the resulting technology, business experts may create
new processes simply by specifying the desired behavior in terms of status variable value
changes: effectively, by describing the process in their own language.

1. Introduction
Business processes are workflows controlling the flow of activities within and between enterprises (Aalst, 1997). Business process management (BPM) is concerned, amongst other
things, with the maintenance of these processes. To minimize time-to-market in an ever
more dynamic business environment, it is essential to be able to quickly create new processes. Doing so involves selecting and arranging suitable IT transactions from huge inc
2012
AI Access Foundation. All rights reserved.

fiHoffmann, Weber & Kraft

frastructures. That is a very difficult and costly task. Our application supports this task
within the software framework of SAP1 , one of the leading vendors of enterprise software.
A well-known idea in this context, discussed for example by Jonathan, Moore, Stader,
Macintosh, and Chung (1999), Biundo, Aylett, Beetz, Borrajo, Cesta, Grant, McCluskey,
Milani, and Verfaillie (2003), and Rodriguez-Moreno, Borrajo, Cesta, and Oddi (2007),
is to use technology from the field of planning. This is a long-standing sub-area of AI,
that allows the user to describe the problem to be solved in a declarative language. In
a nutshell, planning problems come in the form of an initial state, a goal, and a set of
actions, all formulated relative to a set of (typically Boolean or at least finite-domain) state
variables. A solution (or plan) is a schedule of actions transforming the initial state into
a state that satisfies the goal. The planning technology solves (in principle) any problem
described in that language. By far the most wide-spread planning language is the planning
domain definition language (PDDL) (McDermott, Ghallab, Howe, Knoblock, Ram, Veloso,
Weld, & Wilkins, 1998).2
The idea in the BPM context is to annotate each IT transaction with a planning-like
description formalizing it as an action. This enables planning systems to compose (parts
or approximations of) the desired processes fully automatically, i.e., based on minimal user
input specifying from where the process will start (initial state), and what it should achieve
(goal). Very closely related ideas have been explored under the name semantic web service
composition in the context of the Semantic Web community (e.g., Narayanan & McIlraith,
2002; Agarwal, Chafle, Dasgupta, Karnik, Kumar, Mittal, & Srivastava, 2005; Sirin, Parsia,
& Hendler, 2006; Meyer & Weske, 2006).
Runtime performance is important in such an application. Typically, the user  a business expert wishing to create a new process  will be waiting online for the planning outcome.
However the most mission-critical question, discussed for example by Kambhampati (2007)
and Rodriguez-Moreno et al. (2007), is: How to get the planning model? To be useful, the
model needs to capture the relevant properties of a huge IT infrastructure, at a level of
abstraction that is high-level enough to be usable for business experts, and at the same
time precise enough to be relevant at IT level. Designing such a model is so costly that one
will need good arguments indeed to persuade a manager to embark on that endeavor.
In the present work, we demonstrate that this problem can be ameliorated by leveraging
synergies with model-based software development, thus reducing the additional modeling
overhead caused by planning. In fact, we show that one can  at least in our particular
application  re-use exactly, one-to-one, models that were built for the purpose of software
engineering, and thus reduce the modeling overhead to zero.
It has previously been noted, for example by Turner and McCluskey (1994) and Kitchin,
McCluskey, and West (2005), that planning languages have commonalities with software
specification languages such as B (Schneider, 2001) and OCL (Object Management Group,
2006). Now, typically such specification languages are mathematically oriented to describe
1. http://www.sap.com
2. There are many variants of planning, and of PDDL. All share concepts similar to the short description we
just stated. However, that description corresponds best to classical planning, where (amongst other
things) there is no uncertainty about the action effects. We will discuss some details in Section 2.1.
Throughout the paper, unless we refer to one of the particular planning formalisms defined in here, we
use the term planning in a general sense not targeting any particular variant.

588

fiSAP Speaks PDDL

low-level properties of programs. This stands in contrast with the more abstract models
needed to work with business experts. But that is not always so.
As part of a major effort developing a flexible service-oriented (Krafzig, Banke, & Slama,
2005; Bell, 2008) IT infrastructure, called SAP Business ByDesign, SAP has developed a
model called Status and Action Management (SAM). SAM describes how status variables
of Business Objects (BO) change their values when actions  IT transactions affecting
the BOs  are executed. BOs in full detail are vastly complex, containing 1000s of data
fields and numerous technical-level transactions. SAM captures the more abstract business
perspective, in terms of a smaller number of user-level actions (like submit or reject),
whose behavior is described using preconditions and effects on high-level status properties
(like submitted or rejected). In this way, SAM corresponds to the language of business users, and is in very close correspondence with common planning languages. SAM is
extensive, covering 404 kinds of BOs with 2418 transactions. The model creation in itself
constitutes a work effort spanning several years, involving, amongst other things, dedicated
modeling environments and educational training for modelers.
SAM was originally designed for the purpose of model-driven software development,
to facilitate the design of the Business ByDesign infrastructure, and changes thereunto
during its initial development and afterwards. Business ByDesign covers the needs of a
great breadth of different SAP customer businesses, and is flexibly configurable for these
customers. That configuration involves, amongst other things, the design of customerspecific processes, appropriately combining the functionalities provided. Describing the
properties of individual processing steps, rather than supplying each BO with a standard lifecycle workflow, SAM is well-suited to support this flexibility. However, the business users
designing the processes are typically not familiar with the details of the infrastructure. Using
SAM for planning, we obtain technology that alleviates this problem. As its output, our
technology delivers a first version of the desired process, with the relevant IT transactions
and a suitable control-flow. As its input, the technology requires business users only to
specify the desired status changes  in their own language.
The intended meaning of SAM is, to a large extent, the same as in common planning
frameworks. There are some subtleties in the treatment of non-deterministic actions. One
problem is that many of the non-deterministic actions modeled in SAM have bad outcomes
that preclude successful processing of the respective business object (example: BO data
inconsistent). That problem is aggravated by the fact that, in SAMs non-determinism,
repeated executions of the same action are not independent (example: check BO consistency). We discuss this in detail, and derive a suitable planning formalism. We compile
SAM into PDDL, thus creating as a side-effect of our work a new planning benchmark. An
anonymized PDDL version of SAM is publicly available.
On the algorithmic side, we show that minimal changes to an off-the-shelf planner suffice
to obtain good empirical performance. We adapt the well-known deterministic planning
system FF (Hoffmann & Nebel, 2001) to perform a suitable variant of AO* (Nilsson, 1969,
1971). We run its heuristic function on non-deterministic actions simply by acting as if
we could choose the outcome, i.e., by applying the all-outcomes determinization (Yoon,
Fern, & Givan, 2007). We run large-scale experiments with this modified FF, on the full
SAM model as used in SAP. We show that runtime performance is satisfactory in the vast
majority of cases; we point out the remaining challenges.
589

fiHoffmann, Weber & Kraft

We have also integrated our planning technology into two BPM process modeling environments, making the planning functionality conveniently accessible for non-IT users.
Processes (and plans) in these environments are displayed in a human-readable format.
Users can specify status variable values, for example the planning goal, in simple intuitive
drop-down menus. One of the environments is integrated as a research extension into the
commercial SAP NetWeaver platform. Having said that, our technology is not yet part of
an actual SAP product; we will discuss this in Section 7.
The treatment of non-deterministic actions, in our formalism and algorithms, is specific
to our application context. This notwithstanding, it is plausible that these techniques
could be useful also in other applications dealing with such actions. From a more general
perspective, the contribution of our work is (A) pointing out that it is possible to leverage
software-engineering models for planning, and (B) demonstrating that such an application
can be realized at one of the major players in the BPM industry, thus providing a largescale case study. The principle underlying SAM  modeling software artifacts at a level of
abstraction corresponding to business users  is not limited to SAP. Thus our work may
inspire similar approaches in related contexts.
We next give a brief background on planning and BPM. We then discuss the SAM model
in Section 3, explaining its structure, its context at SAP, and the added value of using it
for planning. We design our planning formalization in Section 4, explain our planning
algorithms in Section 5, and evaluate these experimentally in Section 6. Section 7 describes
our prototypes at SAP. Section 8 discusses related work, and Section 9 concludes.

2. Background
We introduce the basic concepts relevant to our work. We start with planning, then overview
business process management (BPM) and its connection to planning.
2.1 Planning
There are many variants of planning (for an overview, see Traverso, Ghallab, & Nau, 2005).
To handle SAM, we build on a wide-spread classical planning framework, planning with
finite-domain variables (e.g., Backstrom & Nebel, 1995; Helmert, 2006, 2009). We will extend that framework with a particular kind of non-deterministic actions, whose semantics
relates to notions from planning under uncertainty that we outline below.
Definition 1 (Planning Task) A finite-domain planning task is a tuple (X, A, I, G). X
is a set of variables; each x  X is associated with a finite domain dom(x). A is a set of
actions, where each a  A takes the form (pre a , eff a ) with pre a (the precondition) and eff a
(the effect) each being a partial variable assignment. I is a variable assignment representing
the initial state, and G is a partial variable assignment representing the goal.
A fact is a statement x = c where x  X and c  dom(x). We identify partial variable
assignments with conjunctions (sets, sometimes) of facts in the obvious way. A state s is a
complete variable assignment. An action a is applicable in s iff s |= pre a . If f is a partial
variable assignment, then s  f is the variable assignment that coincides with f on each
variable where f is defined, and that coincides with s on the variables where f is undefined.

590

fiSAP Speaks PDDL

Definition 2 (Plan) Let (X, A, I, G) be a finite-domain planning task. Let s be a state,
and let T be a sequence of actions from A. We say that T is a solution for s iff either:
(i) T is empty and s |= G; or
(ii) T = hai  T 0 , s |= pre a , and T 0 is a solution for s  eff a .
If T is a solution for I, then T is called a plan.
One can, of course, define plans for finite-domain planning tasks in a simpler way; the
present formulation makes it easier to extend the definition later on. We remark that,
despite the simplicity of this formalism, it is PSPACE-complete to decide whether or not
a plan exists (this follows directly from the results in Bylander, 1994).
Unlike in classical planning, there exist disjunctive effects in SAM, i.e., actions that
have more than one possible outcome. This type of situation is dealt with in planning under
uncertainty. To model SAMs disjunctive effects appropriately, we will need a mixture of
what is known as non-deterministic actions (e.g., Smith & Weld, 1999) and what is known
as observation actions (e.g., Weld, Anderson, & Smith, 1998).
Non-deterministic actions a are like usual actions except that, in place of a single effect
eff a , they have a set Ea of such effects, referred to as their possible outcomes. Whenever
we apply a at plan execution time, any one of the outcomes in Ea will occur; separate
applications of a are independent. For example, a might throw a dice. At plan generation
time, we do not know which outcome will occur, so we must cater for all cases. The most
straightforward framework for doing so is conformant planning (e.g., Smith & Weld, 1999),
where the plan is still a sequence of actions, and is required to achieve the goal no matter
what outcomes occur during execution. Note that this does not exploit observability, i.e.,
the plan does not make case distinctions based on what outcomes actually do occur. To
handle SAM, we will include such case distinctions, along the lines of what is known as
contingent planning (e.g., Weld et al., 1998). In that framework, case distinctions are made
by explicit observation actions in the plan. Typically, an observation action a observes the
 previously unknown  value of a particular state variable x at plan execution time (for
example, the value of a dice after throwing it). The plan branches on all possible values of
x, i.e., a has one successor for each value in dom(x). Thus the plan is now a tree of actions,
and the requirement is that the goal is fulfilled in every leaf of that tree.
The most wide-spread input language for planning systems today is the Planning Domain Definition Language (PDDL), as used in the international planning competitions
(IPC) (McDermott et al., 1998; Bacchus, 2000; Fox & Long, 2003; Hoffmann & Edelkamp,
2005; Younes, Littman, Weissman, & Asmuth, 2005; Gerevini, Haslum, Long, Saetti, &
Dimopoulos, 2009). We do not get into the details of this language, since for our purposes
here PDDL is merely a particular syntax for implementing our formalisms. More important
for us, regarding the usability of our PDDL encoding of SAM, is the fact that PDDL has a
lot of variants, with varying degrees of support by existing planning systems. Our PDDL
syntax for SAM is in the PDDL variant used in the non-deterministic tracks of the IPC,
i.e., the tracks dealing with non-probabilistic planning under uncertainty (Bonet & Givan,
2006; Bryce & Buffet, 2008). Specifically, we use only the most basic PDDL constructs (often referred to as STRIPS), except in action preconditions where we use quantifier-free
formulas (Pednault, 1989; Bacchus, 2000). This PDDL subset is supported by most existing
591

fiHoffmann, Weber & Kraft

planners, in particular all those based on FF (Hoffmann & Nebel, 2001) or Fast Downward
(Helmert, 2006). The limiting factor for planner support are the non-deterministic actions,
for which we use the most common syntax, namely the (oneof eff 1 . . . eff n ) construct from
the non-deterministic IPC. Non-deterministic actions are supported by only few planners.
Further, the semantics we will give to plans using these actions, as fits our application based
on SAM, is non-standard and not supported by existing planners. This notwithstanding,
several existing approaches are closely related (cf. Section 8), and, as we show herein, at
least one planner  Contingent-FF (Hoffmann & Brafman, 2005)  can be adapted quite
easily and successfully to deal with the new semantics.
2.2 Business Process Management
According to the commonly used definition (e.g., Weske, 2007), a business process consists
of a set of activities that are performed in coordination in an organizational and technical
environment. These activities jointly realize a business goal. In other words, business
processes are how enterprises do business. Business process models serve as an abstraction
of the way enterprises do business. For example, a business process model may specify
which steps are taken, by various entities across an enterprise, to send out a customer quote
answering a request for quotation. The atomic steps in such a process model may be both,
manual steps performed by employees, or automatic steps executed on the IT infrastructure.
We will refer to process models simply as processes.
An explicit model of processes allows all sorts of support and automation, addressed
in the area of business process management (BPM). Herein, we are mostly concerned with
process creation and adaptation. That is done in BPM modeling environments. Importantly,
the users of these environments will typically not be IT experts, but business experts  the
people familiar with, and taking decisions for, the business. The dominant paradigm for
representing business processes are workflows, also called control-flows, often formalized
as Petri nets (e.g., Aalst, 1997). Such a control-flow defines an order of execution for
the process steps, within certain degrees of flexibility implied, for example, by parallelism.
For business experts, the control-flow is displayed in a human-readable format, typically a
flow diagram. Our application at SAP uses Business Process Modeling Notation (Object
Management Group, 2008), short BPMN, which we will illustrate in Section 7.
An alternative paradigm for representing business processes, which relates to the SAM
model we consider herein, are constraint-based representations (e.g., Wainer & de Lima
Bezerra, 2003; van der Aalst & Pesic, 2006; Pesic, Schonenberg, Sidorova, & van der Aalst,
2007). These model processes implicitly through their desired properties, rather than explicitly through concrete workflows. This kind of representation is more flexible, in that,
by modifying the model, we can modify the entire process space. For example, we might
add a new constraint archive customer quotes only if all follow-ups have been created.
Such a representation is also more explicit about the reasons for process design, supporting
human understanding. The downside is that, for actual automated process execution, a
concrete control-flow design is required. One way of viewing our planning technology is
that it provides the service of generating such control-flow designs for SAM.
Processes are executed on IT infrastructures, like the one provided by SAP. Such execution coordinates the individual processing steps, prompting human users as appropriate,
and performing all the necessary data updating on IT level. This is realized in dedicated
592

fiSAP Speaks PDDL

process execution engines (Dumas, ter Hofstede, & van der Aalst, 2005). Clearly, the execution poses high demands on the structure of the workflow. The most basic requirement is
that the atomic process steps correspond to actual steps known to the IT infrastructure.3
The requirements on business processes, such as legal and financial regulations, are
subject to frequent updates. The people responsible for adapting the processes  business
experts  are not familiar with the IT infrastructure, and may come up with processes
whose atomic steps are nowhere near what can be implemented easily, partially overlap
with whole sets of existing functions, and/or require the implementation of new functions
although existing functions could have been arranged to do the job. Thus there is a need
for intensive communication between business experts and IT experts, incurring significant
costs for human labor and increased time-to-market.
How can planning come to the rescue? As indicated, the basic (and well-known) idea
is to use a planning tool for composing (an approximation of) the process automatically,
helping the business expert to come up with a process close to the IT infrastructure. The
main novelty in our work is that we leverage a pre-existing model, SAM, getting us around
one of the most critical issues in the area: the overhead for creating the planner input.

3. SAM
We explain the structure of the SAM language, and give a running example. We outline
the background of SAM at SAP, and explain the added value of using SAM for planning.
3.1 SAM Structure and Example
Status and Action Management (SAM) models belong to business objects (BOs). Each BO
is associated with a set of finite-domain status variables, and with a set of actions. Each
status variable highlights one value that the variable will take when a new instance of the
BO is created. Each action is described with a textual label (its name), a precondition, and
an effect. The precondition and effect are propositional formulas over the variable values.
Definition 3 (SAM BO) A SAM business object o is a triple (X(o), A(o), I(o)). X(o) is
a set of status variables; each x  X(o) is associated with a finite domain dom(x). A(o) is
a set of actions, where each a(o)  A(o) takes the form (pre a(o) , eff a(o) ); pre a(o) (the precondition) is a propositional formula over the atoms {x = c | x  X(o), c  dom(x)}; eff a(o)
(the effect) is a negation-free propositional formula over these same atoms, in disjunctive
normal form (DNF). I(o) is a variable assignment representing os initial state.
This structure is in obvious correspondence with that of Definition 1. The only differences are that there is no goal, and that the preconditions and effects are more complex.
In our planning application, the goal is set by the user creating a new process. We discuss
in Section 4 how to extend Definitions 1 and 2 to handle SAM preconditions and effects.
Note that there are no cross-BO constraints in SAM  each BO o refers only to values
of its own variables. This is a shortcoming of the current version of SAM: in reality, BOs
do interact. We will get back to this further below.
3. Another important requirement is an appropriate data-flow (van der Aalst, 2003; Dumas et al., 2005),
e.g., sending a manager the documents required to decide whether or not to accept a customer quote.
Since, in our case, the data is encapsulated into business objects, this is not a major issue for us.

593

fiHoffmann, Weber & Kraft

Action name
Check CQ Completeness

precondition
CQ.archiving:notArchived

Check CQ Consistency

CQ.archiving:notArchived

Check CQ Approval Status

CQ.archiving:notArchived AND
CQ.approval:notChecked AND
CQ.completeness:complete AND
CQ.consistency:consistent
CQ.archiving:notArchived AND
CQ.approval:necessary
CQ.archiving:notArchived AND
(CQ.approval:notNecessary OR
CQ.approval:granted)
CQ.archiving:notArchived AND
CQ.submission:submitted
CQ.archiving:notArchived AND
CQ.acceptance:accepted
CQ.archiving:notArchived

Decide CQ Approval
Submit CQ

Mark CQ as Accepted
Create Follow-Up for CQ
Archive CQ

effect
CQ.completeness:complete OR
CQ.completeness:notComplete
CQ.consistency:consistent OR
CQ.consistency:notConsistent
CQ.approval:necessary OR
CQ.approval:notNecessary

CQ.approval:granted OR
CQ.approval:notGranted
CQ.submission:submitted

CQ.acceptance:accepted
CQ.followUp:documentCreated
CQ.archiving:archived

Figure 1: Our SAM-like running example, modeling the behavior of customer quotes CQ.
For illustration, Figure 1 gives a SAM-like model for a BO called customer quote (CQ),
that will be our running example. For confidentiality reasons, the shown object and model
are artificial, i.e., they are not contained in SAM as used at SAP. By CQ.x:c we denote
the proposition x = c, in the object CQ. The initial state I(CQ) is:
 CQ.archiving:notArchived,
 CQ.completeness:notComplete,
 CQ.consistency:notConsistent,
 CQ.approval:notChecked,
 CQ.submission:notSubmitted,
 CQ.acceptance:notAccepted,
 CQ.followUp:documentNotCreated.
When using this example below, where relevant we will assume that the goal entered by the
user is CQ.followUp:documentCreated AND CQ.archiving:archived.
The reader should keep in mind that this is merely an illustrative example, which necessarily is simple. In particular, the intended life-cycle workflow is rather obvious, given the
action descriptions in Figure 1. This is very much not the case in general. The Business
Objects modeled in SAM have up to 15 status variables, yielding up to 12 million possible
states (combinations of variable values) even for a single BO. In other words, SAM is a
flexible model  after all, that was its main design purpose  and describes a large number of combination possibilities in a compact way. Furthermore, in two of the application
scenarios for planning ((A) and (C) in Section 3.3 below), we are actually looking not for
entire life-cycles but for process fragments that may begin or end at any BO status values.
594

fiSAP Speaks PDDL

3.2 SAM@SAP
SAM was created by SAP as part of the development of the IT infrastructure supporting
SAP Business ByDesign. That infrastructure constitutes a fully-fledged SAP application.
Its key advantage over traditional SAP applications is a higher degree of flexibility, facilitating the use of SAP software as-a-service. Individual system functions are encapsulated
as software services, using the service-oriented architectures paradigm (Krafzig et al., 2005;
Bell, 2008). The software services may be accessed from standard architectures like BPM
process execution engines, thus enabling their flexible combination with other services. To
further support flexibility, the Business ByDesign IT infrastructure is model-driven. IT artifacts at various system levels are described declaratively using SAP-proprietary modeling
formats. Business objects are one such IT artifact, and SAM is one such format.
The original purpose of SAM was to facilitate the design, and the management of
changes, during the development of the Business ByDesign infrastructure (a formidably
huge enterprise). Of course, SAM also serves the implementation of changes to the infrastructure later on, should changes be required. New developments are first implemented and
tested on the model level. Then parts of the program code are automatically generated from
the model. Straightforward code skeletons contain the status variables, as well as function
headers for the available actions (similar to what Eclipse does for Java class definitions). In
addition, the skeletons are filled with code fragments performing the precondition checks
and updates on status variables. Changes pertaining to the status variable level can thus
be implemented in SAM models, and automatically propagated into the code. In this sense,
the original semantics of SAM is as follows:
(I) When a BO o is newly created, the values of the status variables are set to I(o).
(II) BO actions a(o) whose precondition pre a(o) is not fulfilled are either disallowed, or
raise an exception when executed; which one is true depends on the part of the
architecture attempting to execute the action.
(III) Upon execution of an action a, the status variables change their values as prescribed
by one of the disjuncts in the effect DNF eff a(o) . The only aspect controlled outside
SAM is which disjunct is chosen: that choice is made based on BO data content not
reflected in SAM.
The intention behind SAM is to formulate complex business-level dependencies between
individual processing steps, using simple modeling constructs that facilitate easy modification. The formulation in terms of preconditions and effects relative to high-level status
variable values was adopted as a natural means to meet these requirements. Of course, this
design also took some inspiration from traditional software modeling paradigms (Schneider,
2001; Object Management Group, 2006).
Leveraging SAM for planning is a great opportunity because of the effort it takes to build
such a model. SAM was developed continuously along with Business ByDesign, across a
time span of more than 5 years. Throughout this time, around 200 people were involved (as
a part-time occupation) in the development. SAP implemented a dedicated graphical user
interface for this development. There are design patterns for typical cases, there are naming conventions, there is a fully-fledged governance process, and there even is educational
training for the developers. A council of senior SAP architects supervises the development.
595

fiHoffmann, Weber & Kraft

3.3 Applications of SAM-Based Planning
The Business ByDesign infrastructure is designed to be very general and adaptable, covering
the needs of a great breadth of different SAP customers business domains. To adapt the
infrastructure to their practice, SAP customers may choose to create their own processes
as compositions of the functionalities provided (as Web services), in a way tailored to their
needs. Indeed, a second motivation behind SAM, beside its role for software development,
was to facilitate such flexibility, by describing the possible process space in a declarative
manner, rather than imposing standard workflows as is a common methodology in other
contexts such as artefact-centric business process modeling (e.g., Cohn & Hull, 2009). SAM
shares this motivation with constraint-based process representation languages. It also shares
their downside, in that the actual workflows still need to be created. In this context, there
are at least three application scenarios for planning based on SAM:
(A) Development based on SAM. During model-driven development based on SAM,
planning enables developers to examine how their changes affect the process space.
This greatly facilitates experimentation and testing. For example, planning can be
used for debugging, testing whether or not the goal can still be reached, or whether
the changes opened any unintended possibilities, like, reaching an undesired state of
the BO (e.g., CQ.consistency:notConsistent AND CQ.acceptance:accepted). More
than such reachability testing (essentially a model checking task), planning serves to
generate entire processes, which as we shall see take the form of BPMN process models
with parallelism and conditional splits. Developers can examine the space of processes
generated in this way, determining for different combinations of start/end conditions
how these can be connected. Note that the generality offered by the planning approach
is an absolute requirement here  the process generation tool must be at least as general
as SAM, handling propositional formula preconditions and effects.
(B) Designing extended/customized processes. Individual SAP customers have individual requirements on their processes, and thus may use the same BOs in different
ways. For example, even if the end state of customer quotes (which in practice are
much more complex than our illustrative example) always involved being archived,
different businesses may differ on the side conditions: one organization only archives
POs if all follow-ups have been created; another archives only POs that were successful; a third organization archives POs immediately and automatically after getting
a response; a fourth only based on an explicit user-request. Part of the motivation
behind SAM is to provide such flexibility. Planning based on SAM can be used to
automatically generate a first version of the desired process.4
(C) Process redesign. Sometimes the best option is to design a new process from scratch.
If the business experts doing so are not aware the underlying IT infrastructure, then
this incurs huge costs at process implementation time. SAM opens the possibility
for business experts to explain the individual steps in the new process in terms of
status variable value changes, i.e., in terms of a start/end state corresponding to what
the business user considers to be an atomic processing step. Planning then shows
if and how these status changes can be implemented using existing transactions. In
4. The alternative  equipping each BO with a standard life-cycle or a set thereof  would come at the
prize of a flexibility loss for complex BOs, and is not the choice made by SAP.

596

fiSAP Speaks PDDL

particular, the planner can be called for some business object X (e.g., a sales order)
from within a process being created for some other object Y (e.g., a customer quote).
Hence, despite the mentioned absence of cross-BO constraints in the current version
of SAM, planning can help to create non-trivial processes spanning several BOs.
All these use cases are supported by our prototype at SAP; we will illustrate its use for (C),
in a cross-BO situation as mentioned, in Section 7.3.
An obvious requirement for the planner to be useful is instantaneous response. Typically
a user will be sitting at the computer and waiting for the planner to answer. Further, all
functionality must be accessible conveniently. In particular, each time a user wants to call
the planner, she needs to provide the planning goal (and possibly the initial state). It is
essential that this can be done in a simple and intuitive manner, without in-depth expertise
in IT or about the BO the question. Thus we limit ourselves to conjunctive goals in the
sense of I want these status variables to have these values at the end of the process, like
the goal CQ.followUp:documentCreated AND CQ.archiving:archived in our illustrative
example. In our prototype, such goals are specified using simple drop-down menus.
SAM was not originally intended to do planning, and is of course not perfect for that
purpose. We will discuss the main limitations in Section 9, but we need to briefly touch
on two points here already. The absence of cross-BO constraints in the current version
of SAM has implications for planner setup and performance, and will play a role in our
experiments.5 Another issue is plan quality. The duration/cost of the actions may differ
vastly, but SAM does not contain any information about this: it is not relevant to SAMs
original purpose, software engineering. We will not address plan quality measures herein.
Our planning algorithm of course attempts to find small plans. But it gives no quality
guarantee in that regard, and the practical value of such a guarantee would be doubtful.

4. Planning Formalization
We design the syntax and semantics of a suitable planning formalism capturing SAM, and
we illustrate that formalism using our running example.
4.1 SAM Planning Tasks: Syntax
Given the close correspondence of SAM business objects (Definition 3) with finite-domain
planning tasks (Definition 1), it is straightforward to extend the latter to capture the former.
Definition 4 (SAM Planning Task) A SAM planning task is a tuple (X, A, I, G) whose
elements are the same as in finite-domain planning tasks, except for the action set A. Each
a  A takes the form (pre a , Ea ) with pre a being a propositional formula over the atoms
{x = c | x  X, c  dom(x)}, and Ea being a set of partial variable assignments. The
members eff a  Ea are the outcomes of a.
As discussed above, we keep the goal as simple as possible. For the effects, in place of
the negation-free propositional DNF formulas of Definition 3, we now have sets Ea of outcomes. The action preconditions are as in Definition 3. This generalizes the partial variable
5. As we shall discuss in Section 9, BO interactions do exist. An according extension of SAM is planned,
which could in principle be tackled using the exact same planning technology as presented herein.

597

fiHoffmann, Weber & Kraft

assignments from Definition 1  which are equivalent to negation-free conjunctions over the
atoms {x = c | x  X, c  dom(x)}  to arbitrary propositional formulas over these atoms.
That generalization poses no issue for defining the plan semantics; at implementation level,
most current planning systems compile such preconditions into negation-free conjunctions,
using the methods originally proposed by Gazen and Knoblock (1997).
To obtain a SAM planning task (X, A, I, G), when given as input a SAM business object
o = (X(o), A(o), I(o)) along with a goal conjunction G(o), we first set X := X(o), I := I(o),
and G := G(o). For each a(o)  A(o) we include one a into A, where pre a := pre a(o) . As
for eff a(o) , we create one partial variable assignment eff a for each disjunct in that DNF
formula, and we define the possible outcomes Ea as the set of all these eff a .
By convention, we denote with Ad := {a  A | |Ea | = 1} and And := {a  A | |Ea | > 1}
the sets of deterministic and non-deterministic actions of a SAM planning task, respectively.
If a  Ad , then by eff a we denote the single outcome of a.
4.2 SAM Planning Tasks: Semantics
SAM action preconditions pre a(o) are in direct correspondence with usual planning preconditions, cf. point (II) in Section 3.2. By contrast, SAMs disjunctive effects eff a(o) require
to create a mix of two different kinds of planning actions  non-deterministic actions and
observation actions  from the literature. To understand this, reconsider the role of SAM
action effects eff a(o) in their original environment, i.e., point (III) in Section 3.2. Any one
of the disjuncts will occur, and at plan generation time we do not know which one. At plan
execution time, the SAP system executing the action will observe the relevant data content,
and will decide which branch to take. In the example from Figure 1, Check CQ Completeness will answer CQ.completeness:complete if the BO data is complete, and will answer
CQ.completeness:notComplete otherwise. Of course, the SAP system keeps track of which
outcomes occured. In other words, (a) SAMs disjunctive effects correspond to observation
actions, that (b) internally observe environment data not modeled at the planning level.
Due to (a), it makes perfect sense to handle such actions by introducing case distinctions
at plan generation time, one for each outcome. Due to (b), there is no direct link of the
observation to a reduction of uncertainty at planning level. During execution, the values
of the observed variables are known prior to the observation already, and change as a
result of applying that action. For example, CQ.completeness.notComplete is considered
to be true prior to the first application of Check CQ Completeness, and may be changed
to CQ.completeness.complete by that action. In that respect, and in that the outcome
set (an arbitrary DNF) is more general than the domain of a particular variable, SAMs
disjunctive effects are more similar to the common notions of non-deterministic actions.
For simplicity, we will henceforth refer to SAMs disjunctive-effects actions as nondeterministic actions. Another important point regarding these actions is that data content
is not allowed to change while the process is running; the data is filled in directly upon creation of the BO. Thus the outcome of a non-deterministic action will be the same throughout
the plan execution, and it makes no sense to execute such an action more than once in a
plan. For example, there is no point in repeatedly applying Check CQ Completeness.
A final issue is to decide what a plan actually is. Cimatti, Pistore, Roveri, and Traverso
(2003) describe the three most common concepts, in the presence of non-deterministic ac598

fiSAP Speaks PDDL

tions: strong plans, strong cyclic plans, and weak plans. We will discuss the latter two
below; the most desirable property is the first one. A strong plan guarantees to reach the
goal no matter which action outcomes occur. We now define this formally, for our setting.
An action tree over A is a tree whose nodes are actions from A, and whose edges are
labeled with partial variable assignments. Each action a in the tree has exactly |Ea | outgoing
edges, one for (and labeled with) each eff a  Ea . In the following definitions, And
av refers
to the subset of non-deterministic actions that have not yet been used, and are thus still
available, at any given state during plan execution. Recall that seff a , defined in Section 2,
over-writes s with those variable values defined in eff a , and leaves s unchanged elsewhere.
Definition 5 (Strong SAM Plan) Let (X, A, I, G) be a SAM planning task with A =
nd
Ad  And . Let s be a state, let And
av  A , and let T be an action tree over A  {STOP }.
We say that T is a strong SAM solution for (s, And
av ) iff either:
(i) T consists of the single node STOP , and s |= G; or
(ii) the root of T is a  Ad , s |= pre a , and the sub-tree of T rooted at as child is a strong
SAM solution for (s  eff a , And
av ); or
nd
(iii) the root of T is a  Aav , s |= pre a , and, for each of as children reached via an edge
labeled with eff a  Ea , the sub-tree of T rooted at that child is a strong SAM solution
for (s  eff a , And
av \ {a}).
If T is a strong solution for (I, And ), then T is called a strong SAM plan.
Compare this to Definition 2. Item (i) of the present definition is essentially the same,
saying that there is nothing to do if the goal is already true. In difference to Definition 2,
we then distinguish deterministic actions (ii) and non-deterministic ones (iii). In the former
case, a has a single child and we require the remainder of the tree to solve that child,
similarly as in Definition 2. In the latter case, a has several children all of which need to be
solved by the respective sub-tree. This corresponds to the desired case distinction observing
action outcomes at plan execution time.
Note that, throughout the plan, there is no uncertainty about the current variable values.
Note also that we solve, not a state, but a pair consisting of a state and a subset of nondeterministic actions. This reflects the fact that whether or not an action tree solves a state
depends not only on the state itself, but also on which non-deterministic actions are still
available. The maintenance of the set And
av ensures that we allow each non-deterministic
action only once, on each path through T (but the action may occur several times on
separate paths). Thus any one execution of the plan applies the action at most once.
The problem with Definition 5 is that strong plans typically do not exist. To illustrate this, consider Figure 2, showing a weak SAM plan, a notion we will now formally
define, for our running example from Figure 1. Recall that the goal is assumed to be
CQ.followUp:documentCreated AND CQ.archiving:archived. If either of Check CQ
Completeness or Check CQ Consistency, as shown at the top of Figure 2, result in a
negative outcome (CQ.completeness:notComplete or CQ.completeness:notConsistent),
then the goal becomes unreachable. Thus a strong plan does not exist for this SAM planning task. That phenomenon is not limited to this illustrative example. In our experiments,
almost 75% of a very large sample of SAM planning tasks did not have a strong plan.
To address this, one can define more complicated goals, or a weaker notion of plans. For
the former option, one could use goals specifying alternatives, preferences, and/or temporal
599

fiHoffmann, Weber & Kraft

Check CQ Completeness
Y
N
Check CQ Consistency
Y
N
Check CQ Approval Status
notNec

Nec
Decide CQ Approval
granted

Submit CQ

notGranted

Mark CQ as Accepted
Submit CQ
Create FollowUp for CQ
Mark CQ as Accepted
Archive CQ
Create FollowUp for CQ
Archive CQ

Figure 2: A weak SAM plan for the running example from Figure 1. STOP actions not
shown, FAIL actions marked by (red) crosses.
plan properties (e.g., Pistore & Traverso, 2001; Dal Lago, Pistore, & Traverso, 2002; Shaparau, Pistore, & Traverso, 2006; Gerevini et al., 2009). However, goals will be specified
online by business users and it is absolutely essential for this to be as simple as possible.
We hence decided to go for the second option.6
The weak plans of Cimatti et al. (2003) are too liberal for our purposes. They guarantee
only that at least one possible execution of the plan reaches the goal, posing no requirements on all the other executions. For example, in Figure 2, this would mean to allow
the plan to handle only the left-hand side outcome of Check CQ Approval Status, i.e.,
CQ.approval:notNecessary, and to do nothing at all about (attach the empty tree at) its
other outcome, CQ.approval:necessary.
So what about strong cyclic plans? There, the plan may have cycles, provided every
plan state can, in principle, reach the goal. This allows to wait for a desired outcome, like
a cycle around a dice throw, waiting to obtain a 6. Alas, repetitions of non-deterministic
SAM actions will always produce the same outcome. It is futile to insert a cycle at the
top of Figure 2, waiting for the desired outcome of Check CQ Completeness. While it is
plausible to prompt a user to edit the BO content and then repeat the check (placeholders for
such cycles could be inserted as a planning post-process), this is not a suitable exception
handling in general. Exception handling depends on the business context, and typically
depends on the actual customer using the SAP system. This is impossible to reflect in a
model maintained centrally by SAP.
In conclusion, from the perspective of SAM-based planning there is not much one can
do other than to highlight the bad outcomes to the user, so that the exception handling can
6. Some works on more complex goals can be employed to define alternative notions of weak plans (by
using trivial fall-back goals). We will discuss this in some detail in Section 8.

600

fiSAP Speaks PDDL

be inserted manually afterwards. Of course, a non-deterministic action should have at least
one successful outcome, or else it would be completely displaced in a process. Further, it is
essential to highlight outcomes as bad only if they really are bad, i.e., to not mark as
failed any outcomes that could actually be solved. Our definition reflects all this:
Definition 6 (Weak SAM Plan) Let (X, A, I, G) be a SAM planning task with A = Ad 
nd
And . Let s be a state, let And
av  A , and let T be an action tree over A  {STOP , FAIL}.
We say that T is a weak SAM solution for (s, And
av ) iff either:
(i) T consists of the single node STOP , and s |= G; or
(ii) the root of T is a  Ad , s |= pre a , and the sub-tree of T rooted at as child is a weak
SAM solution for (s  eff a , And
av ); or
nd
(iii) the root of T is a  Aav , s |= pre a , and, for each of as children reached via an edge
labeled with eff a  Ea , we have that either: (a) the sub-tree of T rooted at that child
is a weak SAM solution for (s  eff a , And
av \ {a}); or (b) the sub-tree of T rooted at
that child consists of the single node FAIL, and there exists no action tree T 0 that is
a weak SAM solution for (s  eff a , And
av \ {a}); where (a) is the case for at least one
of as children.
If T is a weak solution for (I, And ), then T is called a weak SAM plan.
Compared to Definition 5, the only difference lies in item (iii), which no longer requires
every child to be solved. Instead, the arrangement of options (a) and (b) means that
failed nodes  leaves in the tree that stop the plan without success  are tolerated, as
long as at least one child is solved, and every failed node is actually unsolvable. This is
in obvious correspondence with our discussion above. In Figure 2, the failed nodes, i.e.,
the sub-trees consisting only of the special FAIL action, are crossed out (in red). Note
the difference to Cimatti et al.s (2003) definition of weak plans discussed above: we
are not allowed to cross out the right-hand side outcome of Check CQ Approval Status,
i.e.,CQ.approval:necessary, because that outcome is solvable.
We remark that allowing non-deterministic actions only once (or, more generally, having
an upper bound on repetition of non-deterministic actions) is required for Definition 6 to
make sense. In item (iii), the definition recurses on itself when stating that some children
may be unsolvable. While such recursion occurs also at other points in Definitions 5 and 6,
at those points the action tree T considered is reduced by at least one node. For unsolvable
children of non-deterministic actions in Definition 6 (iii) (b), such a reduction is not given 
the quantification is over any action tree T 0 that may be suitable to solve the child. What
makes the recursion sound, instead, is that the set of available non-deterministic actions is
diminished by one. Without this, the notion of weak SAM plan would be ill-defined: the
recursion step may result in the same planning task over again, allowing the construction
of planning tasks that are considered solvable if they are unsolvable.7
7. Concretely, say we obtain Definition 6 from Definition 6 by considering states s only, removing the
handling of And
av . Consider the example with one variable x whose possible values are A and B, with
initial state I : x = A, with goal G : x = B, and with a single action a with two possible outcomes, x = A
or x = B. Say T consists only of a. Then the bad outcome of a, i.e., the state x = A, is identical to the
original initial state I. If I is unsolvable according to Definition 6, then this outcome of a qualifies for
Definition 6 (iii) (b), and thus the overall task  the same state I  is considered to be solvable. By
contrast, using Definition 6 as above, the plan must solve the state/available-non-deterministic-actions
pair (x = A, {a}), and the bad outcome of a is the different pair (x = A, ). That pair is unsolvable, and
hence a is a weak plan.

601

fiHoffmann, Weber & Kraft

The following observation holds simply because Definition 5 captures a special case of
Definition 6:
Proposition 1 (Weak SAM Plans Generalize Strong SAM Plans) Let (X, A, I, G)
nd
be a SAM planning task with A = Ad  And . Let s be a state, let And
av  A , and let T be
an action tree over A  {STOP }. If T is a strong SAM solution for (s, And
av ), then T is a
weak SAM solution for (s, And
).
av
In other words, any strong SAM plan is also a weak SAM plan, and hence in particular
any SAM planning task that is solvable under the strong semantics is also solvable under
the weak semantics. The inverse is obviously not true. A counter-example is our running
example in Figure 2.
We remark that, trivially, deciding whether a plan exists is hard for both, Definition 5
and Definition 6. The special case where all actions are deterministic is a generalization of
Definition 2, where as mentioned that problem is PSPACE-complete.
4.3 SAM Planning Tasks: Running Example
For illustration, we encode our running example, Figure 1, into a SAM planning task
(X, A, I, G). We set X := {Arch, Compl , Cons, Appr , Subm, Acc, FoUp}, abbreviating the status variable names mentioned in Figure 1. For example, Arch stands for the
variable CQ.archiving. The domain of each of Arch, Compl , Cons, Subm, Acc, and FoUp
is {true, false}. This serves to abbreviate the various names used for the respective variable
values in Figure 1. The domain of Appr is {notChecked , nec, notNec, granted , notGranted }.
In what follows, for brevity we write facts, i.e., variable/value pairs, involving true/false
valued variables like literals. For example, we write FoUp instead of (FoUp, no).
The initial state of the SAM BO, and thus the SAM planning task, is:
 I = {Arch, Compl , Cons, (Appr , notChecked ), Subm, Acc, FoUp}
The goal is CQ.followUp:documentCreated AND CQ.archiving:archived:
 G = {FoUp, Arch}
The deterministic actions Ad are:
 Mark CQ as Accepted: (Arch  Subm, {Acc})
 Create Follow-Up for CQ: (Arch  Acc, {FoUp})
 Archive CQ: (Arch, {Arch})
 Submit CQ: (Arch  ((Appr , notNec)  (Appr , granted )), {Subm})
Note here that action effects are sets of partial variable assignments, i.e., sets of sets of facts.
For the deterministic actions, there is just one partial variable assignment so we omit the
second pair of set parentheses to avoid notational clutter. Note also that we do not have
delete effects. The effects assign new values to the affected variables, implicitly removing
their old values, cf. the meaning of s  eff a as defined in Section 2.
The non-deterministic actions And are:
 Check CQ Completeness: (Arch, {{Compl }, {Compl }})
 Check CQ Consistency: (Arch, {{Cons}, {Cons}})
602

fiSAP Speaks PDDL

 Check CQ Approval Status:
(Arch  (Appr , notChecked )  Compl  Cons, {{(Appr , nec)}, {(Appr , notNec)}})
 Decide CQ Approval:
(Arch  (Appr , nec), {{(Appr , granted )}, {(Appr , notGranted )}})
Figure 2 shows a weak SAM plan for this example. For presentation to the user, a simple
post-process (outlined in Section 7.1) transforms such plans into BPMN workflows.

5. Planning Algorithms
We design an adaptation of FF (Hoffmann & Nebel, 2001), using a variant of the AO* forward search from Contingent-FF (Hoffmann & Brafman, 2005), as well as a nave extension
of FFs heuristic function. We assume that the reader is familiar with heuristic search in
general, and we refer to the literature (e.g., Pearl, 1984) for that background.
5.1 Search
For strong SAM planning  Definition 5  we use AO* tree search (Nilsson, 1969, 1971).
For weak SAM planning  Definition 6  we use a variant of that search that we refer to as
SAM-AO*. We focus in what follows mainly on SAM-AO*, since AO* is well-known and
will become clear as a side effect of the discussion.
Search is forward in an AND-OR tree whose nodes are states (OR nodes) and actions
(AND nodes). The ORed children of states are the applicable actions, the ANDed children
of actions are the alternative outcomes (for deterministic actions, there is a single child so
the AND node trivializes). Like in AO*, we propagate node solved and node failed
markers. The mechanics for this are the usual ones in the case of OR nodes, i.e., the marker
of the node is the disjunction of its childrens markers. For AND nodes, SAM-AO* differs
from the usual conjunctive interpretation, implementing the weak SAM planning semantics
of Definition 6: amongst other things, an AND node is failed only if all its children are
failed. Figure 3 provides an overview of SAM-AO*, highlighting the differences to AO*.
Figure 4 illustrates the algorithm on a simplification of our running example.
One feature of the algorithm that is immediately apparent is the book-keeping which
non-deterministic actions are still available. Recall here that, in line with Definitions 5
and 6, we allow each non-deterministic action at most once in any execution of a plan. For
the search algorithm  both in strong planning (AO*) and in weak planning (SAM-AO*) 
this means that OR nodes contain not only a state s, but a pair (s, And
av ) giving the state as
nd
well as the subset of A that has not been used up to this node. We will refer to such pairs
as search states from now on. The book-keeping of the sets And
av is straightforward. For the
initial state, all non-deterministic actions are still available. Whenever a non-deterministic
action a is applied, for its outcome states, a is no longer available. For illustration, consider
how the action sets are reduced in Figure 4 (BD).
The heuristic function h, that we assume as a given here, takes as arguments the search
state, i.e., both the state and the available non-deterministic actions. This is because action
availability affects goal distance and hence the heuristic estimates. By h(s) = 0 the heuristic
indicates goal states, and by h(s) =  it may indicate that the state is unsolvable. The
algorithm trusts the heuristic, i.e., it assumes that h only returns these values if the state
603

fiHoffmann, Weber & Kraft

procedure SAM-AO*
input SAM planning task (X, A, I, G) with A = Ad  And , heuristic function h
output A weak plan for (X, A, I, G), or unsolvable
initialize T to consist only of NI ; content(NI ) := (I, And )
status(NI ) :=solved if h(I, And ) = 0, failed if h(I, And ) = , unknown else
while status(NI ) =unknown do
Ns := select-open-node(T ); (s, And
av ) := content(Ns )
for all a  Ad  And
av with s |= pre a do
if a  Ad and is-direct-duplicate(Ns , s  eff a , And
av ) then skip a endif
insert Na as child of Ns into T ; content(Na ) := a
0
nd
d
nd 0
nd
And
av := Aav if a  A , else Aav := Aav \ {a}
for all eff a  Ea do
s0 := s  eff a
0
insert Ns0 as child of Na into T ; content(Ns0 ) := (s0 , And
av )
0
0
0
nd
status(Ns0 ) := solved if h(s0 , And
av ) = 0, failed if h(s , Aav ) = , unknown else
endfor
status(Na ) := SAM-aggregate({status(N 0 ) | N 0 is child of Na in T })
endfor
status(Ns ) := OR-aggregate({status(N 0 ) | N 0 is child of Ns in T })
propagate-status-updates-to-I (Ns )
endwhile
if status(NI ) =failed then return unsolvable endif
return an action tree corresponding to a subtree T 0 of T s.t. NI  T 0 and:
for all inner nodes Ns  T 0 : status(Ns ) = solved and Ns has exactly one child Na in T 0 ;
for all nodes Na  T 0 : all children Ns0 of Na in T are contained in T 0
is-direct-duplicate(N, s0 , And
av ) :=

SAM-aggregate(M ) :=


solved






true  predecessor N0 of N s.t. content(N0 ) = (s0 , And
av )
false else
m  M : m = solved, and
m  M : (m = solved or m = failed)
m  M : m = failed
else

failed



unknown

m  M : m = solved
 solved
failed
m  M : m = failed
OR-aggregate(M ) :=

unknown else

Figure 3: Pseudo-code of SAM-AO*, highlighting the differences to AO*.
s is indeed a goal state/unsolvable. Detecting unsolvable states is within the capabilities of
FFs heuristic, and is of paramount importance for planning with SAM models. Its behavior
is like that of the heuristic in Figure 4 (BD), which immediately marks all unsolvable nodes
as being such. We get back to this in Section 5.2.2 below.
The overall structure of SAM-AO* is the same as that of AO*. Starting with the initial
search state (compare Figure 4 (A)), we iteratively use select-open-node to select an OR node
Ns in the tree that has not yet been expanded and whose status is unknown; the selection
criterion is based on the nodes f -value, as explained below. We expand the selected node
with the applicable actions (in Figure 4 (B), we omit Check CQ Consistency to save
space), and we insert one new node for each possible outcome of these actions (Comp vs.
604

fiSAP Speaks PDDL

A

B

Comp, Cons; CheckComp, CheckCons
unknown; h=2

Comp, Cons; CheckComp, CheckCons
unknown; h=2

Check CQ Completeness unknown

Comp, Cons; CheckCons
unknown; h=1

C

D

Comp, Cons; CheckComp, CheckCons
unknown; h=2

Check CQ Completeness unknown

Comp, Cons; CheckCons
solved; h=1

Comp, Cons; CheckComp, CheckCons
solved; h=2

Check CQ Completeness solved

Comp, Cons; CheckCons
failed; h=infty

Comp, Cons; CheckCons
solved; h=1

Check CQ Consistency solved

Comp, Cons; (none)
solved; h=0

Comp, Cons; CheckCons
failed; h=infty

Comp, Cons; CheckCons
failed: h=infty

Check CQ Consistency solved

Comp, Cons; (none)
failed; h=infty

Comp, Cons; (none)
solved; h=0

Comp, Cons; (none)
failed: h=infty

Figure 4: Phases of SAM-AO* in a simplifaction of the running example (Figure 1), with
only the two variables CQ.completeness and CQ.consistency, and only the
two actions Check CQ Completeness and Check CQ Consistency. The goal,
using the abbrevations here, is Comp, Cons. For search states (s, And
av ), on the
left-hand side of the semicolon we show the state s, and on the right-hand side
we show the set And
av of available non-deterministic actions.
-Comp in Figure 4 (B)); we will discuss the is-direct-duplicate function below. Each new
node, i.e., the corresponding search state, is evaluated with the heuristic function. Once all
outcomes of an action a were inserted, the status of a is updated. Once all actions applicable
to the current node Ns are inserted, the status of Ns is updated. The latter update, reflected
in the OR-aggregate equation in Figure 3, is exactly as in AO*. A key difference to AO* lies
in the former update, reflected in the SAM-aggregate equation. That equation is in obvious
correspondence with Definition 6. In Figure 4 (B), neither of these updates yields any new
information, because the status of one of the action outcomes, Comp, Cons; CheckCons,
is unknown. That changes in Figure 4 (C), where the status of both outcomes becomes
definite (solved/failed), and the updates propagate this information to the action a and the
search state node Ns it was applied to.
After the status of Ns and a has been set, propagate-status-updates-to-I (Ns ) performs a
backward iteration starting at Ns , updating each action and search state along the way to
I using the same two functions, OR-aggregate and SAM-aggregate. This is necessary since
the status of Ns may have changed, and that may affect the status of any predecessors.
This happens, for example, in Figure 4 (D) where the status of the first node and action
now change from unknown to solved . The algorithm terminates when the initial node
605

fiHoffmann, Weber & Kraft

(the search tree root) is solved or failed. In the former case, a solved sub-tree is returned.
That happens in Figure 4 (D), and the sub-tree returned is equivalent to the start (top two
actions) of our example plan in Figure 2.
In addition to status markers, SAM-AO* also annotates search states with their f values, as well as the current best action. This is not shown in Figure 3 since it is (almost)
identical to what is done in AO*. The f -value of a search state node is the minimum of
those of its children, plus 1 accounting for the cost of applying an action; a minimizing child
is the best action. The f -value of an action node is the maximum of its children, except 
and herein lies the only difference to AO*  that we do not set the action value to  unless
all its children are marked as failed. The select-open-node procedure starts in NI and keeps
choosing best actions until it arrives at a non-expanded state, which is selected as Ns .
The is-direct-duplicate function in Figure 3 disallows the generation of search states that
are identical to one of their predecessors in the tree. We refer to this as direct duplicate
pruning. Note that the method prunes duplicates only within deterministic parts of the
search tree. If a predecessor node N0 as in Figure 3 is found, then all actions between
N0 and N are deterministic, because otherwise content(N0 ) would contain strictly more
non-deterministic actions than N . Obviously, direct duplicate pruning preserves soundness
and completeness of the search algorithm. We have:

Proposition 2 (SAM-AO* is Complete and Sound) Let (X, A, I, G) be a SAM planning task, and let h be a heuristic function. SAM-AO* terminates when run on the task with
h. Provided h(s) = 0 iff s is a goal state, and h(s) =  only if s is unsolvable, SAM-AO*
terminates with success iff there exists a weak SAM plan for the task, and the action tree
returned in that case is such a plan.
This follows from the known results about AO*, by definition, and by two simple observations. First, eventually, on any tree path no non-deterministic actions will be available
anymore. Second, direct duplicate pruning allows only finitely many nodes in a SAM planning task without non-deterministic actions.
The reader might wonder whether stronger duplicate pruning methods could be defined, across the non-deterministic actions in the tree. A nave approach, asking only
whether a predecessor of N contains the same state  and ignoring the sets of available
non-deterministic actions  does not work for SAM-AO*. It renders that algorithm unsound. This is because such a pruning method may mark solvable search states as failed,
and failed nodes can be part of the solution in a weak plan. For illustration, consider the
simple example where we have a variable x with values A, B, C, the initial state A, the goal
C, and three actions: a1 has precondition A and the two possible outcomes B and C; a2
has precondition B and outcome A; a3 has precondition A and outcome C. Say the search
has chosen to apply a1 first. Consider a1 s unfavorable outcome B. At this point, in order
to obtain a plan, we must apply a2 , a3 to achieve the goal C. However, the outcome state
s : x = A of a2 is the same as the initial state. Hence s is pruned, hence a1 s outcome B
is marked as failed, hence the algorithm wrongly concludes that a1 s outcomes qualify for
Definition 6 (iii), and that a1 on its own is a plan.
606

fiSAP Speaks PDDL

5.2 Heuristic Function
To compute goal distance estimates, we use all-outcomes-determinization as known in
probabilistic planning (Yoon et al., 2007) to get rid of non-deterministic actions, then run
the FF heuristic (Hoffmann & Nebel, 2001) off-the-shelf. For the sake of self-containedness,
we next explain this in some detail. The reader familiar with FF may skip to Section 5.2.2.
5.2.1 Relaxed Planning Graphs
FFs heuristic function is one out of a range of general-purpose planning heuristics based on
a relaxation widely known as ignoring delete lists (McDermott, 1999; Bonet & Geffner,
2001). Heuristics of this kind have emerged in the late 90s and are still highly successful.
In what follows, we assume that action preconditions and the goal are conjunctions of
positive atoms, and are thus equivalent to sets of facts. For more general formulas, such as
the preconditions in SAM planning tasks, one can apply known transformations (Gazen &
Knoblock, 1997) to achieve this.
The name delete lists comes from a Boolean-variable representation of planning tasks.
Translated to our context, the relaxation means that variables accumulate, rather than
change, their values. For illustration, say we have CQ.archiving:notArchived in our running example, and we apply the action Archive CQ whose effect is CQ.archiving:archived.
Then, in the relaxation, the resulting state will be CQ.archiving:notArchived, CQ.archiving:
archived, containing both the old and the new value of the variable CQ.archiving. Thus
the other actions of this BO, that all require the customer quote to not be archived yet,
remain applicable, and in difference to the plan from Figure 2, a relaxed plan can archive
the CQ right at the start and then proceed to the rest of the processing.
Viewing variable assignments as sets of facts, relaxed action application is equivalent to
taking the set union of the current state with the action effect. This yields a strictly
larger set of facts than the real application of the action (CQ.archiving:notArchived,
CQ.archiving:archived instead of CQ.archiving:archived). Satisfaction of preconditions
and the goal is then tested by asking for inclusion in that set. Bylander (1994) proved
that, within the relaxation, plan existence can be decided in polynomial time. He also
proved, however, that optimal relaxed planning, i.e., finding the length of a shortest possible relaxed plan, is still NP-hard. Therefore, the heuristics used by practical planners
approximate that length. Specifically, the FF heuristic we build on herein computes some
not necessarily optimal relaxed plan. The algorithm doing so consists of two phases. First,
it builds a relaxed planning graph (RPG) to approximate forward reachability. Then it
extracts a relaxed plan from the RPG.
Figure 5 shows how an RPG is computed in our planner. The algorithm gets the state
s as well as the remaining non-deterministic actions, And
av . It then determinizes the latter
actions, inserting each of their possible outcomes as an individual new deterministic action
into the new action set A0 . The following loop is a simple fixed point operation over sets of
facts. The initial set F0 is equal to the state s whose goal distance shall be estimated. Each
loop iteration then increments Ft with the effects of all actions whose preconditions have
been reached. In case all goals are reached, the algorithm stops with success and returns
the iteration index t. If a fixed point occurs before that happens, the algorithm returns .
607

fiHoffmann, Weber & Kraft

procedure RPG
input SAM planning task (X, A, I, G) with A = Ad  And ,
state s, available non-deterministic actions And
av
output Number of relaxed parallel steps needed to reach the goal, or 
A0 := Ad  {(pre a , {eff a }) | a  And
av , eff a  Ea }
F0 := s, t := 0
while G 6 Ft do
A0t := {a  A0S| pre a  Ft }
Ft+1 := Ft  aA0 eff a
t
if Ft+1 = Ft then return  endif
t := t + 1
endwhile
return t

Figure 5: Pseudo-code for building a relaxed planning graph (RPG).
If the RPG returns t < , the heuristic function algorithm enters its second phase,
relaxed plan extraction. This is a straightforward backchaining procedure selecting supporting actions for the goals, and then iteratively for the supporting actions preconditions.
The backchaining makes sure to select only feasible supporters by exploiting the reachability
information encoded in the sets Ft . Note here that t itself is not a good heuristic estimator
because it counts parallel action applications  we could make transactions on 1000 BOs in
parallel and still count this as a single step.
Consider our simplified example from Figure 4. For the root node Comp, Cons; CheckComp, CheckCons, the relaxed plan returned will be hCheck CQ Completeness+ , Check
CQ Consistency+ i, where the superscript + indicates that these are actions from the
determinized set A0 in Figure 5, choosing the positive outcome of each of these actions.
The heuristic value returned is 2, as in Figure 4. Indeed, all the heuristic values from
Figure 4 are as would be returned by FFs heuristic. In particular, if -Comp, i.e.,
CQ.completeness:notComplete, holds in a state, but the action Check CQ Completeness is no longer available, then the heuristic value returned is  because no action in
A0 can achieve the goal Comp, and thus the RPG fixed point does not contain the goal.
Similarly if -Cons holds in a state but Check CQ Consistency is no longer available.
5.2.2 Detecting Failed Nodes
It follows directly from, e.g., the results of Hoffmann and Nebel (2001), that the RPG stops
with success iff there exists a relaxed plan for the task (X, A0 , s, G). From this, we easily
get the following result which is relevant for us:
Proposition 3 (RPG Dead-End Detection in SAM is Sound) Let (X, A, I, G) be a
nd be a set of
SAM planning task with A = Ad  And . Let s be a state, and let And
av  A
non-deterministic actions. If the RPG run on these inputs returns , then there exists no
weak SAM solution for (s, And
av ).
To see this, note that the action set A0 of Figure 5 is, from the perspective of plan
0
existence, an over-approximation of the actual action set Ad  And
av we got available. A
allows us to choose, for any non-deterministic action, the outcome that we want. Thus,
0
from a plan using Ad  And
av we can trivially construct a plan using A . So if no plan using
608

fiSAP Speaks PDDL

A0 exists then neither does a plan using Ad  And
av . From here it suffices to see that nonexistence of a relaxed plan (based on A0 ) implies non-existence of a real plan (based on A0 ).
That is obvious, concluding the argument.
It is of course a very strong simplification to act as if one could choose the outcomes of
non-deterministic actions. Part of our motivation for doing so is to demonstrate that it is not
necessary, at least in this application context, to dramatically enhance off-the-shelf planning
techniques. The simplistic approach just presented suffices to obtain good performance.
This is particularly true regarding the ability to detect dead-ends. We experimented with a
total of 548987 planning instances based on SAM. Of these (within limited time/memory)
we found a weak plan for 441884 instances. Around half of the actions in these plans are
non-deterministic, and these typically yield failed nodes in the plan. For every one of these
failed nodes, in every one of the 441884 solved instances, the RPG returned .
5.2.3 Helpful Actions Pruning
We also adopt FFs helpful actions pruning. Aside from the goal distance estimate, the
relaxed plan can be used to determine a most promising subset H(s)  the helpful actions
 of the actions applicable to the evaluated state s. Essentially, H(s) consists of the actions
that are applicable to s and that are contained in the relaxed plan computed as described
above in Section 5.2.1.8 This action subset is used as a pruning method simply by restricting,
during search, the expansion of state s to consider only the actions H(s). This kind of
heuristic action pruning is of paramount importance for planner performance (Hoffmann &
Nebel, 2001; Richter & Helmert, 2009).
In the SAM setting, one important aspect of FFs helpful actions pruning is that it is
accurate enough to distinguish relevant BOs from irrelevant ones. That is to say, if a BO
is not mentioned in the goal, then no action pertaining to it will ever be considered to be
helpful. This is simply because, as pointed out previously, SAM currently does not model
cross-BO interactions. So if a BO Y is not in the goal then relaxed plan extraction will
never create any sub-goals pertaining to Y .
The obvious  and well-known  caveat of helpful actions pruning is that it does not
preserve completeness. H(s) may not contain any of the actions that actually start a plan
from s. If that happens, then search may stop unsuccessfully even though a plan exists.
This pertains to classical planning just as it pertains to AO* and SAM-AO* as used herein.
Importantly, helpful actions pruning in SAM-AO*, i.e., for weak SAM planning as per
Definition 6, has another more subtle caveat: it does not preserve soundness. Consider
again the example where we have a variable x with values A, B, C, the initial state is A, the
goal is C, and we have three actions of which action a1 has precondition A and two possible
outcomes B and C, a2 has precondition B and outcome A, and a3 has precondition A
and outcome C. Say the search has applied a1 . Say that Ns := (s, And
av ) is the node
corresponding to a1 s unfavorable outcome B. The only way to complete a1 into a plan is
to attach a2 , a3 to Ns . Presume that helpful actions pruning, at the node Ns , removes a2 .
Then Ns is marked as failed, and we wrongly conclude that a1 on its own is a plan.
8. FFs definition of H(s) is a little more complicated, adding also some actions that were not selected for
the relaxed plan but achieve a relevant sub-goal. We omit this for brevity. Recent variants of helpful
actions pruning, for different heuristic functions like the causal graph heuristic (Helmert, 2006), do not
make such additions, selecting H(s) based on membership in abstract solutions only.

609

fiHoffmann, Weber & Kraft

Using helpful actions pruning, one may incorrectly mark a node Ns as failed. If such Ns
is a leaf in a weak plan T , marked as failed even though it is solvable by action tree T 0 , then
T is not a valid plan. This can be fixed, in a plan-correction post-process, by attaching T 0 to
Ns , where T 0 is found by running SAM-AO* without helpful actions pruning on Ns . We did
not implement such a post-process because, according to our experiments, it is unnecessary
in practice: as discussed at the end of the previous sub-section, all failed nodes Ns in our
441884 weak plans have heuristic value , and are thus proved to be, indeed, unsolvable.

6. Experiments
We will describe our prototype at SAP in the next section. In what follows, we evaluate our
planning techniques in detail from a scientific point of view. Our experiments are aimed at
understanding three issues:
(1) What is the applicability of strong respectively weak planning in SAM?
(2) Is the runtime performance of our planner sufficient for the envisioned application?
(3) How interesting is SAM as a planning benchmark?
We first explain the experiments setup. We then describe our experiments with FF for
strong plans, and with FF for weak plans; we summarize our findings with blind search.
While these experiments consider instances pertaining to a single BO, we finally examine
what happens when scaling the number of relevant BOs.
6.1 Experiments Setup
All experiments were run on a 1.8 GHz CPU, with a 10 minute time and 0.5 GB memory
cut-off. Our planner is implemented in C as a modification of FF-v2.3. The source code, the
problem generator used in our experiments, and the anonymized PDDL encoding of SAM are
available for download at http://www.loria.fr/~hoffmanj/SAP-PDDL.zip. Our SAMAO* implementation is modifed from the AO* implementation in Contingent-FF (Hoffmann
& Brafman, 2005). Like that planner, we weight heuristic values by a factor of 5 (we did
not play with this parameter).
We focus on the case where the initial state is set as specified in SAM. Thus a SAM
planning instance in what follows is identified by its goal: a subset of variable values. The
number of such instances is finite, but enormous; just for choosing the subset of variables to
be constrained we have 21110 options. In what follows, we mostly consider goals all of whose
variables belong to a single BO. This is sensible because, as previously stated, SAM currently
does not reflect interactions across BOs. We made an instance generator that allows to
create instance subsets characterized by the number |G| of variables constrained in the goal
(this parameter is relevant for business users, and as we shall see it also heavily influences
planner performance). For given |G|, the generator enumerates all possible variable tuples,
and allows to randomly sample for each of them a given number S of value tuples. The
maximum number of variables of any BO, in the current version of SAM, is 15. We created
all possible instances for |G| = 1, 2, 3, 13, 14, 15 where the number of instances is up to
around 50000. For all other values of |G|, we chose a value for S so that we got around
50000 instances each. The total number of instances we generated is 548987.
610

fiSAP Speaks PDDL

Since SAM currently does not model cross-BO interactions, for a single-BO goal we
can in principle supply to the planner only those actions pertaining to that BO. We will
henceforth refer to this option as using the BO-relevant actions. Contrasting with this, the
full actions option supplies to the planner all actions (no matter which BO they pertain
to). We will use the BO-relevant actions in some experiments where we wish to enable the
planner to prove the planning task to be unsolvable  with the full actions, this is always
impossible because the reachable state space is much too vast. In our baseline, however, we
use the full actions. The motivation for this is that helpful actions pruning will detect the
irrelevant actions anyway (cf. Section 5.2), and in the long term, it is likely that SAM will
model cross-BO interactions.
6.2 Strong SAM Plans
In our first experiment, we evaluate the performance of strong planning on SAM, i.e, we
run FF in a standard AO* tree search forcing all children of AND nodes to be solved. We
identify two parameters relevant to the performance of FF: the kind of BO considered, and
|G|. Figure 6 shows how coverage and state evaluations (number of calls to the heuristic
function) depend on these parameters.
Consider first Figure 6 (a). The x-axis ranges over BOs, i.e., each data point corresponds
to one kind of BO.9 The ordering of BOs is by decreasing percentage of solved instances. For
each BO, the y-axis shows the percentage of solved, unsolved, and failed instances within
that BO. The overall message is mixed. On the one hand, coverage is perfect for 194 of
the 371 BOs, so for more than half of the BOs all the tested instances have a strong plan
which is found by FF. On the other hand, for the other 177 BOs, coverage is rather bad.
For 51 of the BOs, not a single instance is solved. On the 126 BOs in between, coverage
declines steeply. Importantly, when counting unsolved cases in total (across BOs), it turns
out that 88.83% of the instances are unsolved. In other words, for almost 90% of the
tested cases FFs search space does not contain a strong SAM plan. Of course,
this percentage pertains to the particular distribution of test cases that we used. Still this
result indicates that the applicability of strong planning in SAM is quite limited.
Another interesting aspect of Figure 6 (a) is that failed cases are rare: they constitute
only 0.8% of the total instance set. That is, due to helpful actions pruning, FFs search
spaces are typically small enough to be exhausted within the given time and memory.
Consider now Figure 6 (b), which shows coverage on the y-axis over |G| on the x-axis.
Again, the message is mixed. On the one hand, with a single goal (|G| = 1), 58.85% of
the instances are solved with a strong plan. On the other hand, the number of solved cases
declines monotonically, and quite steeply, over growing |G|. With 2 goals we are at 36.95%,
with 4 goals at 29.03%, with 5 goals at 23.86%. For |G|  10, the number of solved cases
is less than 5%, and for |G|  13, the number is less than 1%.
One may wonder at this point whether it is FFs helpful actions pruning that is responsible for the frequent non-existence of strong plans. The answer is no. In a second
experiment with strong planning, we ran FF without helpful actions, giving as input only
9. Note that we do not include all 404 BOs. Precisely, we consider 371 of them. The remaining 33 BOs
are not interesting for planning: all variable values not true in the initial state are unreachable because
these values are set by procedures not encoded in SAM.

611

fi100

100

90

90

80

80

70

70

60

Coverage

Coverage

Hoffmann, Weber & Kraft

SOLVED
UNSOLVED
FAILED

50
40

60

40

30

30

20

20

10

10

0

SOLVED
UNSOLVED
FAILED

50

0
0

50

100

150

200
BO

250

300

350

1

2

3

4

5

6

7

100000

10000

10000

1000

UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

100

9

10 11 12 13 14 15

(b)

100000

Number of evaluated states

Number of evaluated states

(a)

8
|G|

10

1

UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

1000

100

10

1
0

50

100

150

200
BO

250

300

350

1

2

3

(c)

4

5

6

7

8
|G|

9

10 11 12 13 14 15

(d)

Figure 6: Strong planning with FF on full action sets. Coverage (a,b) and state
evaluations (c,d) data, plotted over individual kinds of BOs (a,c) and |G| (b,d).
SOLVED: plan found. UNSOLVED: search space (with helpful actions pruning) exhausted. FAILED: out of time or memory. Ordering of BOs in (c) is by
increasing y-value for each curve individually.
the BO-relevant actions in order to enable proofs of unsolvability. The result is very clear:
the number of solved cases hardly changes at all. The total percentage of solved cases in
the previous experiment is 10.38%, the total percentage in the new experiment is 10.36%.
This low success rate is due to unsolvability, not to prohibitively large search spaces. In
total, 74.1% of the instances are proved unsolvable; FF fails only on 15.54%.
Given the above, the applicability of strong planning in SAM appears limited unless we
can restrict attention to BOs with few variables and/or to single-goal planning tasks. From
a more general perspective, the best option appears to be to:
(I) Try to find a strong SAM plan (using FF with AO*).
(II) If (I) fails, try to find a weak SAM plan (using FF with SAM-AO*).
In this setting, it is relevant how long we will have to wait for the answer to (I). Figures 6
(c) and (d) provide data for this. We consider the instances where FF terminated regularly
(plan found or helpful actions search space exhausted), and we consider performance in
terms of the number of evaluated states, i.e., the number of calls to the heuristic function.
612

fiSAP Speaks PDDL

The ordering of BOs in Figure 6 (c) is by increasing y-value for each curve individually;
otherwise the plot would be unreadable. The most striking observation is that, for 351 of
the 371 BOs, the maximum number of state evaluations is below 100. For solved instances,
this even holds for 369 BOs, i.e., for all but 2 of the BOs. The maximum number of state
evaluations done in order to find a plan is 521, taking 0.22 seconds total runtime. The mean
behavior is even more good-natured, peaking at 9.85 state evaluations. Waiting for a no
can be more time consuming, with a peak at 42954 evaluations respectively 110.87 seconds.
However, since all the yes answers are given very quickly, for practical use in an online
business process modeling environment it seems feasible to simply give the strong planning
one second (or less), and switch to weak planning in case that was not successful.
Consider Figure 6 (d). Like in (c), we can observe the very low number of state evaluations required for the solved cases. Somewhat surprisingly, there is no conclusive behavior
over |G|. The reasons are not entirely clear to us. The UNSOLVED MAX curve is flat at
the top because larger search spaces lead to failure. The discontinuities around |G| = 12 are
presumably due to BO structure. Few BOs have more than 12 variables, so the variance in
the data is higher in this region. For the sharp drops in UNSOLVED MAX and SOLVED
MAX, an additional factor is that there are very few strong plans for such large goals (cf.
Figure 6 (b)): those strong plans that do exist are found easily; disproving existence of a
strong plan can be easier for larger goals, since this increases the chance that the relaxed
plan will identify at least one unsolvable goal.
Summing up our findings regarding the issue (1) [applicability of strong vs. weak planning in SAM] we wish to understand in these experiments, SAM does not admit many
strong plans, but those instances that do have them tend to be solved easily by FF.
6.3 Weak SAM Plans
We will now see that weak SAM planning can solve 8 times as many instances as
strong SAM planning  namely around 80% of our test cases. Precisely, of the 548987
instances, 441884 are solved; all but 43 of these are solved by the default configuration of
our planner. The average percentage of non-deterministic actions, across all weak plans, is
48.29%; the maximum percentage is 91.67%. Figure 7 shows our results, giving the same
four kinds of plots as previously shown for strong planning in Figure 6.
Consider first Figure 7 (a). We see that, now, coverage is perfect in 274 of the 371 kinds
of BOs, as opposed to the 194 BOs of which that is true for strong planning. The latter
BOs are a subset of the former: wherever strong planning has perfect coverage the same is
true of weak planning. Whereas strong planning has 0 coverage  no instance solved at all
 for 51 BOs, we have no such cases here. The minimum coverage is 18.07%, and coverage
is below 50% only for 9 BOs. In total, while strong planning solves only 10.38% of the test
cases, we now solve 80.48%. That said, we still have 17.12% unsolved cases and 2.4% failed
cases, and this gets much worse for some BOs. Per individual BO, the fraction of unsolved
instances peaks at 81.92%, and the fraction of failed instances peaks at 14.98%.
Consider now Figure 7 (b). |G| = 1 is handled perfectly  100% coverage as opposed
to 58.85% for strong planning  but this is followed by a fairly steady decline as |G| grows.
An explanation for the discontinuity at |G| = 3, 4 could be that for |G| = 3 our experiment
613

fi100

100

90

90

80

80

70

70

60

Coverage

Coverage

Hoffmann, Weber & Kraft

SOLVED
UNSOLVED
FAILED

50
40

60

40

30

30

20

20

10

10

0

SOLVED
UNSOLVED
FAILED

50

0
0

50

100

150

200
BO

250

300

350

1

2

3

4

5

6

7

1e+06

100000

100000

10000
UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

1000

9

10 11 12 13 14 15

(b)

1e+06

Number of evaluated states

Number of evaluated states

(a)

8
|G|

100

10

UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

10000

1000

100

10

1

1
0

50

100

150

200
BO

250

300

350

1

(c)

2

3

4

5

6

7

8
|G|

9

10 11 12 13 14 15

(d)

Figure 7: Weak planning with FF on full action sets. Coverage (a,b) and state evaluations (c,d) data, plotted over individual kinds of BOs (a,c) and |G| (b,d).
SOLVED: plan found. UNSOLVED: search space (with helpful actions pruning) exhausted. FAILED: out of time or memory. Ordering of BOs in (c) is by
increasing y-value for each curve individually.
is exhaustive while for |G| = 4 we only sample. As above, the higher variance for large |G|
can be explained by the much smaller number of BOs in this region.
Figures 7 (c) and (d) provide a deeper look into performance on those instances where
FF terminated regularly (plan found or helpful actions search space exhausted). Like in
Figure 6 (c), the ordering of BOs in Figure 7 (c) is by increasing y-value for each curve
individually. The number of state evaluations is typically low. The phenomenon is not quite
as extreme as shown for strong planning in Figure 6 (c). This is likely because the more
generous definition of plans makes it more difficult for FF to prove AND nodes unsolvable,
and hence to prune large parts of the search space. In detail, for 350 of the 371 BOs, the
maximum number of state evaluations is below 100; for solved instances, this holds for 364
BOs (the corresponding numbers for strong planning are 351 and 369). The maximum
number of state evaluations done in order to find a plan is 54386, taking 27.41 seconds total
runtime (521 and 0.22 for strong planning). From the SOLVED MEAN curve we see that
this maximal case is very exceptional  the mean number of state evaluations per BO peaks
614

fiSAP Speaks PDDL

at 47.78. Comparing this to the UNSOLVED MEAN curve, we see that a large number
of search nodes is, as one would expect, much more typical for unsolved instances.
In Figure 7 (d), we see that the overall behavior of state evaluations over |G| largely
mirrors that of coverage, including the discontinuity at |G| = 3, 4. The most notable
exception is the fairly consistent decline of SOLVED MAX for |G| > 3. It is unclear to
us what the reason for that is.
What is the conclusion regarding the issues (2) [planner performance] and (3) [benchmark challenge] we wish to understand? For issue (2), our results look fairly positive. In
particular, consider only the solved instances (weak plan found). As explained above, the
number of state evaluations is largely well-behaved. In addition, the heuristic function is
quite fast. As stated, the maximum runtime is 27.41 seconds. The second largest runtime
is 2.6 seconds, and the third largest runtime is 1.69 seconds; all other plans are found in
less than 0.3 seconds. So a practical approach could be to simply apply a small cut off, like
0.5 seconds, or perhaps a minute if time is not as critical. This yields a quick step (II) as a
follow-up of the similarly quick step (I) determined above for strong planning.
What this strategy leaves us with are, in total, 17.12% unsolved instances and 2.4%
failed ones. Are those an important benchmark challenge for future research? Answering
this question first of all entails finding out whether we can solve these instances when not
using helpful actions pruning, and if not, whether they are solvable at all.
We ran FF without helpful actions pruning on the unsolved and failed instances of
Figure 7, slightly more than 100000 instances in total. We enabled unsolvability proofs
by giving as input only the BO-relevant actions, and we facilitated larger search spaces by
increasing the time/memory cut-offs from 10 minutes and 0.5 GB to 30 minutes and 1.5 GB
respectively. All failed instances are still failed in this new configuration. Of the previously
unsolved instances, 47.43% are failed, and 52.52% are proved unsolvable.10 Only 0.05% 
43 instances  are now solved (the largest plan contains 140 actions). The influence of |G|
and the kind of BO is similar to what we have seen. The number of state evaluations is
vastly higher than before, with a mean and max of 10996.72 respectively 289484 for solved
instances. But the heuristic is extremely fast with only the BO-relevant actions, and hence
finding a plan takes a mean runtime of only 0.12 seconds. The max, second max, and third
max runtimes are 2.94 seconds, 0.7 seconds, and 0.53 seconds respectively; all other plans
are found in less than 0.15 seconds. Thus, with the above, all but 6 of the 441884 weak
plans in this experiment are found in less than 0.5 seconds.
All in all, changing the planner configuration achieves some progress on the instances
not solved by the default configuration, and it appears that many of them are unsolvable
anyway. But certainly they are a challenge for further research.
6.4 Blind Search
To explore to what extent heuristic techniques are actually required to successfully deal with
this domain  and thus to what extent the domain constitutes an interesting benchmark
10. Unsolvability of certain goal value combinations, i.e., partial assignments to a BOs variables, occurs
naturally since these variables are not independent. For example, some of the unsolvable instances
required a BO to simultaneously satisfy BO.approval:In Approval and BO.release:Released. In our
running example, this kind of situation arises, e.g., when requiring CQ.approval:notChecked together
with CQ.acceptance:accepted.

615

fiHoffmann, Weber & Kraft

for such techniques  we ran an experiment with blind search. We used AO* with a trivial
heuristic that returns 1 on non-goal states and 0 on goal states. Since weak planning is
much more applicable than strong planning in SAM, we used the weak planning semantics.
We provided as input only the BO-relevant actions  otherwise, blind forward search is
trivially hopeless due to the enormous branching factor.
For the sake of conciseness, we do not discuss the results in detail here. In summary,
blind search is quite hopeless. It runs out of time or memory on 79.36% of our test instances.
It solves 19.04% of them  as opposed to the 80.48% solved based on FF. Interestingly, due
to FFs ability to detect dead-ends via relaxed planning graphs, blind search is worse than
heuristic search even at proving unsolvability: in total, this happens in 5.99% of the cases
using FF, and in 1.60% of the cases using blind search.
That said, for BOs that have only few status variables and/or status values, and for
goals of size 1 or 2, blind search fares well, if not as well as heuristic search. The interesting
benchmarks lie outside this region  which is the case for more than 90% of our test instances.
6.5 Scaling Across BOs
FF does not scale gracefully to planning tasks with several BOs. We selected, for each BO,
one solved instance m(BO) with maximum number of state evaluations. Since that will
be of interest, we include here all 404 BOs, i.e., also those 33 BOs all of whose planning
goals are trivial (either unsolvable or true in the BOs initial state already); m(BO) is 1 for
these BOs. We generated 404 planning tasks COMk , for 1  k  404, combining the goals
m(BO) for all BOs up to number k, in an arbitrary ordering of the BOs. We compared
the data thus obtained against data we refer to as ACCk , obtained by summing up the
state evaluations when running FF in turn on each of the individual goals m(BO). This
comparison is valid since the BOs are mutually independent, and a plan for COMk can be
obtained as the union of the plans for the individual goals. Figure 8 shows the data.
60000
COMBINED
ACCUMULATED-INDIVIDUAL
Number of evaluated states

50000

40000

30000

20000

10000

0
1

100

200
Number of BOs

300

400

Figure 8: Weak planning with FF when scaling the number of relevant BOs.
State evaluations plotted over the number of BOs for which a goal is specified.
COMBINED means that FF is run on the conjunction of all these goals (COMk
in the text). ACCUMULATED-INDIVIDUAL gives the sum of the data when
running FF individually on each single goal (ACCk in the text).
616

fiSAP Speaks PDDL

As Figure 8 shows quite clearly, FF does not scale gracefully to planning tasks with
several BOs.11 The largest instance solved is k = 103, with 38665 evaluations. The sum of
state evaluations when solving the 103 sub-tasks individually is 529. A possible explanation
is that, adding more goals for additional BOs, more actions are helpful. The increased
number of nodes may multiply over the search depth. Interestingly, the disproportionate
search increase occurs even when the new goal added is trivial. For example, ACC98 has just
1 more state evaluation than ACC97 , while for COM98 and COM97 that difference amounts
to 251 state evaluations. On the other hand, for up to k  14 BOs, ACCk is still below
1000; the difficulties arise only when k becomes quite large.

7. Application Prototypes at SAP
We have integrated our technology into two BPM modeling environments. We next briefly
explain how we transform the planner output into a BPM format. We then outline the
positioning of our prototypes at SAP, and illustrate the business user view of our technology.
We close with a few words on how the prototypes have been evaluated SAP-internally.
7.1 Transforming Plans to Business Processes
Business users expect to get a process model in a human-readable BPM workflow format.
We use BPMN (Object Management Group, 2008). The BPMN process model corresponding to Figure 2 is depicted in Figure 9. This process model makes use of alternative (x)
and parallel (+) execution, unifies redundant sub-trees (Submit CQ . . . Archive CQ),
removes failed outcomes, and highlights in red those nodes that may have such outcomes.
These changes are obtained using the following simple post-process to planning.
Approval:
Necessary

Approval:
not
Necessary

Check CQ
Completeness

Check CQ
Consistency

Decide CQ
Approval

Submit CQ

Mark CQ as
Accepted
Check CQ
Approval
Status

Create FollowUp for CQ

Archive CQ

Figure 9: Final BPM process created for the running example.
11. The vertical part of the plot for ACCk is because, as we noticed before, the globally maximal number
of state evaluations, 54386 for BO 347, is an extreme outlier.

617

fiHoffmann, Weber & Kraft

First, we remove each failed node together with the edge leading to it. In our running example, Figure 2, this concerns the N branches of Check CQ Completeness and
Check CQ Consistency, and the notGranted branch of Decide CQ Approval. Next,
we separate property checking from directing the control flow. We do this for each node
that has more than 1 child. We replace each such node with a process step bearing the same
name, followed by an XOR split (BPMN control nodes giving a choice to execution). In the
example, this concerns Check CQ Approval Status. We then re-unite XOR branches using
XOR joins (BPMN control nodes leading alternative executions back together), avoiding
redundancies in the process by finding pairs of nodes that root identical sub-trees. In Figure 2, this pertains to the two occurrences of Submit CQ. We introduce a new XOR join
node taking the incoming edges of the found node pair. We attach one copy of the common
sub-tree below that XOR join. We insert a BPMN start node, join all leaves via a new XOR
join, and attach a BPMN end node as the new (only) leaf of the plan. Finally, we introduce
parallelism by finding non-interacting sub-sequences of actions in between the XOR splits
and joins that were introduced previously. (This is a heuristic notion of parallelism, that
does not guarantee to detect all possible parallelizations in the process.)
7.2 Positioning of our Prototypes at SAP
As part of the effort to transfer our research results to the SAP product development
organization, we integrated our planning approach into two BPM prototypes.
The first one, called Maestro for BPMN (Born, Hoffmann, Kaczmarek, Kowalkiewicz,
Markovic, Scicluna, Weber, & Zhou, 2008, 2009), is a BPMN process modeling tool developed by SAP Research primarily for the purpose of research and early prototyping. We
focus in what follows on our other prototype, which is implemented in the context of the
commercial SAP NetWeaver platform (SAP, 2010). NetWeaver is one of the most prominent software platforms at SAP, and is the central platform for SAPs service-oriented
architecture. It encompasses all the functionalities required to run an SAP application.
Our prototype is implemented as a research extension of SAP NetWeaver BPM.
SAP NetWeaver BPM consists of different parts for process modeling and execution.
Our planning functionality is integrated into the SAP NetWeaver BPM Process Composer,
NetWeavers BPM modeling environment targeted at the creation of new processes. The
process modeling is done in BPMN notation; that notation is given an execution semantics
by NetWeaver BPMs process execution engine.
7.3 Demonstration of our NetWeaver BPM Prototype
We briefly illustrate what using our planning functionality will look like to business users.
We consider application scenario (C) as described in Section 3.3, where the business user
redesigns a new process from scratch. For application scenarios (A) and (B) from Section 3.3
 using planning during SAM-based development, respectively generating a process template
at the beginning of the modeling activity  the same interface can be used.
In designing a new process, the user chooses the atomic process steps according to
his/her intuition. At IT level, this is no more than drawing a box and inserting a descriptive
text. To align this intuitive design with the actual IT infrastructure the process should run
on, our planner allows to check how the atomic steps can be implemented based on existing
618

fiSAP Speaks PDDL

Figure 10: Screenshot of our BPM modeling environment, showing how business users specify planning goals.

transactions. Say the user has designed the process model shown in Figure 10. Amongst
others, the process contains a step Release Purchase Order, whose intention is to order
the purchase of a special part required to satisfy the customer demand, after the customer
quote has been accepted. The user now wishes to inflate Release Purchase Order to an
actual IT-level process fragment having the intended meaning. A double click on the step
opens the shown interface for entering the planning initial state and goal, i.e., the desired
status variable value changes, associated to this step. The status variable values are chosen
via drop-down menus, selecting initial conditions on the left-hand side and goals on
the right-hand side. In the present case, the goal is PO.Status:Ordered, and the initial
condition is PO.Status:Created because the purchase order (PO) was already created
beforehand and shall now be released.
Once the status variable values are entered, the user clicks on Call composer. This
invokes the planner, using the specified initial condition/goal to define the SAM planning
619

fiHoffmann, Weber & Kraft

Timeout

Notification:
Quote
rejected

Notification:
Quote
accepted

Timeout

Notification:
Quote
rejected

Notification:
Quote
accepted

Process
Purchase Order
Data

Mark Customer
Quote as
Rejected

Create Sales
Order from
Quote and
archive Quote

Release
Purchase
Order

Cancel Purchase
Order (2)

Mark Customer
Quote as
Rejected

Create Sales
Order from
Quote and
archive Quote

Check Purchase
Order Data

Check Purchase
Order Approval
Status

Cancel Purchase
Order (2)
Trigger Followup SO processing

PO Approval Necessary

PO Approval
Not Necessary

Decide Purchase
Order Approval

End

Place Purchase
Order

Trigger Followup SO processing

End

Figure 11: The BPMN process snippet from the screenshot in Figure 10, before (left) and
after (right) calling the planner. The affected steps are highlighted in bold;
actions with failed outcomes are highlighted in red as before.
task.12 The returned plan is transformed to BPMN, and is inserted into the process model in
place of the atomic step that the user had been working on; see the illustration in Figure 11.
In the shown case, the plan is a process snippet containing five atomic transactions with
one XOR split and two possibly failed outcomes, showing that releasing the PO entails to
first process its data, then check this data, and then invoke an approval process similar to
that of our illustrative example;13 finally, the PO is being ordered.
Note here that, while cross-BO interactions are not part of the SAM model, the planner
helps to create a process that spans multiple BOs, and that indeed ties together functionality
that cuts across departmental boundaries. The process snippet shown in Figure 10 invokes
the purchase of goods from a supplier as soon as a customer accepts a quote. This is relevant
for companies that sell highly customized goods (e.g., special-purpose ships), and who in
12. In the current implementation of the prototype, if the value of a variable x is not specified in the initial
condition given by the user, then the planner does not make use of x, i.e., all preconditions on x
are assumed to be false until x is set by an action effect. One could of course easily make this more
comfortable, by assuming SAMs initial values as a default, and by propagating the effects of earlier
SAM transactions (on the same BO) along the process structure. First investigations into the latter
have been performed (May & Weber, 2008).
13. Indeed, approval is one of the design patterns that SAP applied throughout SAM. The actual pattern is
more complicated than our illustrative version here.

620

fiSAP Speaks PDDL

turn must procure customized parts from their suppliers (e.g., ship engines). Such processing
requires to combine services from BOs belonging to Customer Relationship Management
(CRM) and Supplier Relationship Management (SRM), and hence from the two opposite
ends of the system (and company). The designer of the process will typically be intimately
familiar with only one of these two, making it especially helpful to be able to call the planner
to obtain information about the other one.
7.4 Evaluation of our Prototype at SAP
Our prototype was part of a research transfer project with the NetWeaver BPM group,
and shaped during several feedback rounds with developers and architects. The evaluation
within SAP consisted mainly of prototype demonstrations at various SAP events. For
example, an early version of the tool was demonstrated at the 2008 global meeting of SAP
Research BPM and SI (SI stands for Semantic Integration), which included participants
from SAP partners and development. The demonstrations received positive feedback from
SAP software architects. The perception was that this functionality would significantly
strengthen the link between SAP BPM and the underlying software infrastructure, making
it much easier to access the services provided in an effective manner. Most critical comments
were focused on some choices in the user interface design, such as non-logicians will not
understand the meaning of the NOT symbol, or the list of several hundred BOs is too
long for a drop-down box.
We do not have customer evaluation data, and it is not foreseeable when we (or anyone
else) will be able to obtain such data. When our first prototype became available, a partner
organization committed to perform a pilot customer evaluation. That commitment was
retracted in the context of the 2008/2009 financial crisis. Anyway, real customer evaluation
data may be impossible to come by, let alone publish, due to privacy reasons.
There are also some issues arising from the positioning of our prototype inside the SAP
software architecture. The NetWeaver process execution engine currently does not connect
to the actual IT services that implement SAMs actions. While SAM is in productive
use within Business ByDesign, NetWeaver BPM is built on a different technology stack. A
connection could in principle be established relatively easily  after all, service-orientation
is intended to do exactly this sort of thing  however this connection has not as yet been on
SAPs agenda, and it involves some SAP-internal political issues. The fact that the main
drivers of the presented technology  the authors of this paper  have left the company in
the meantime does of course not help to remedy this problem.

8. Related Work
The basic idea explored in this paper  using planning systems to help business experts to
come up with processes close to the IT infrastructure  has been around for quite a long
time. For example, it was mentioned more than a decade ago by Jonathan et al. (1999). It
is also discussed in the 2003 roadmap of the PLANET Network of Excellence in AI Planning
(Biundo et al., 2003). More recently, Rodriguez-Moreno et al. (2007) implemented the idea
in the SHAMASH system. SHAMASH is a knowledge-based BPM tool targeted at helping
with the engineering and optimization of process models (Aler, Borrajo, Camacho, & SierraAlonso, 2002). The tool includes, amongst other things, user-friendly interfaces allowing
621

fiHoffmann, Weber & Kraft

users to conveniently annotate processes with rich context information, in particular in
the form of rules which roughly correspond to planning actions. These rules (and other
information) then form the basis for translation into PDDL, and planning for creation of
new process models.
The largest body of related work was performed during the last decade under a different
name, semantic web service composition (SWSC), in the context of the Semantic Web
Community (e.g., Ponnekanti & Fox, 2002; Narayanan & McIlraith, 2002; Srivastava, 2002;
Constantinescu, Faltings, & Binder, 2004; Agarwal et al., 2005; Sirin, Parsia, Wu, Hendler,
& Nau, 2004; Sirin et al., 2006; Meyer & Weske, 2006; Liu, Ranganathan, & Riabov, 2007).
In a nutshell, the idea in SWSC is (1) to annotate web services with some declarative
abstract explanation of their functionality, and (2) to exploit these semantic annotations
to automatically combine web services for achieving a more complex functionality. While
SWSC terminology differs from what we use in this paper, the idea is basically the same
(although most SWSC works do not address BPM specifically).
The key distinguishing feature of the present work is our approach to obtaining the
planning input (the semantic annotations). Ours is the first attempt to address the
planning/SWSC problem based on SAM, and more generally based on any pre-existing
model at all. Since modeling is costly (Kambhampati, 2007; Rodriguez-Moreno et al.,
2007), this shift of focus gets us around one of the major open problems in the area. The
modeling interfaces in SHAMASH (Rodriguez-Moreno et al., 2007), and some related works
attempting to support model creation (Gonzalez-Ferrer, Fernandez-Olivares, & Castillo,
2009; Cresswell, McCluskey, & West, 2009, 2010), address the same problem, but in very
different ways and to a less radical extent. Whereas these works attempt to ease the
modeling overhead, our re-use of SAM actually removes that overhead completely.
Having said that, of course there are relations between SAM planning and previous work,
at the technical level. In particular, the planning and SWSC literature contains a multitude
of works dealing with actions that, like SAMs disjunctive effect actions, have more than one
possible outcome. Our semantics for such actions, as detailed already in Section 4.2, is a
straightforward mixture of two wide-spread notions in planning: observation actions, where
one out of a list of possible observations is distinguished, and non-deterministic actions,
where one out of a list of possible effects occurs (e.g., Weld et al., 1998; Smith & Weld,
1999; Bonet & Geffner, 2000; Cimatti et al., 2003; Bryce & Kambhampari, 2004; Hoffmann
& Brafman, 2005; Bonet & Givan, 2006; Bryce, Kambhampati, & Smith, 2006; Bryce &
Buffet, 2008; Palacios & Geffner, 2009).
A prominent line of research in web service composition, known as the Roman model
(e.g., Berardi, Calvanese, De Giacomo, Lenzerini, & Mecella, 2003, 2005; De Giacomo &
Sardina, 2007; Sardina, Patrizi, & De Giacomo, 2008; Calvanese, De Giacomo, Lenzerini,
Mecella, & Patrizi, 2008), also deals with a notion of non-determinism in the component
web services, however the framework is very different from ours. The web services in the
Roman model are stateful. That is, each service has a set of possible own/internal states,
and the service provides a set of operations to the outside world, which are responsible for
transitions in the services internal state. The composition task is to create a scheduler (a
function choosing one service for each operation demanded) interacting with the component
services in a way such that they implement a desired goal transition system. Similarly, the
web service composition techniques developed by Marco Pistore and his co-workers (e.g.,
622

fiSAP Speaks PDDL

Pistore, Marconi, Bertoli, & Traverso, 2005; Bertoli, Pistore, & Traverso, 2006, 2010) deal
with this form of non-determinism in stateful component services formalized as transition
systems. In their work, the composition task is to create a controller transition system such
that the overall (controlled) behavior satisfies a planning-like goal (expressed in the EAGLE
language, cf. below). In that latter aspect  attempting to satisfy a planning goal  their
framework is slightly closer to ours than the Roman model.
The main distinguishing feature of our formalism is its notion of weak SAM plans,
allowing failed action outcomes but only if they are proved unsolvable, and only if at least
one outcome of each action is successful. Some other works have also proposed notions
of plans that do not guarantee to achieve the goal in all cases, and some notions of more
complex goals can be used to achieve similar effects. We now briefly discuss the notions
closest to our own approach.
The notions of weak and strong plans, as discussed in Section 4.2, were first introduced by
Cimatti, Giunchiglia, Giunchiglia, and Traverso (1997) and Cimatti, Roveri, and Traverso
(1998b), respectively. Strong cyclic plans were first introduced by Cimatti, Roveri, and
Traverso (1998a). That notion is orthogonal to weak SAM plans in that neither implies the
other. For example, if a bad action outcome invalidates, as a side effect, the preconditions
of all actions in the task, then that action may form part of a weak SAM plan, but never
of a strong cyclic plan. Vice versa, strong cyclic plans have a more general structure, in
particular allowing non-deterministic actions to appear more than once in an execution.
Pistore and Traverso (2001) generalize weak, strong, and strong cyclic plans by handling
goals taking the form of CTL formulas. However, as pointed out by Dal Lago et al. (2002),
such goals are unable to express that the plan should try to achieve the goal, and give up
only if that is not possible. Dal Lago et al. design the goal language EAGLE which addresses
(amongst others) this shortcoming. EAGLE features a variety of goal operators that can
be flexibly combined to form goal expressions. One such expression is TryReach G1 Fail
G2 , where G1 and G2 are alternative goals. The intuition is that the plan should try to
achieve G1 , and resort to G2 if reaching G1 has become impossible. More precisely, a plan
T for such an EAGLE goal is optimal if, for every state s it traverses: (1) T is a strong plan
for G1  G2 ; (2) if there exists a strong plan for G1 from s, then T is such a strong plan;
and (3) if there exists a weak plan for G1 from s, then T is such a weak plan. Applying this
to our context, say we restrict plans to execute each non-deterministic action at most once.
It is easy to see that, within this space of plans, every weak SAM plan is optimal for the
EAGLE goal TryReach G Fail TRUE: weak SAM plans mark s as failed only if reaching
G from s is impossible. However, not every action tree T that is optimal for TryReach G
Fail TRUE is a weak SAM plan. That is because (2) and (3) do not force every action
to have at least one solved outcome. In tasks for which no weak SAM plan exists, any
action tree (e.g., the empty tree) is optimal for TryReach G Fail TRUE. In tasks with a
weak SAM plan, TryReach G Fail TRUE forces each solvable action outcome to provide
a solution, but imposes no constraints below failed outcomes (which may thus be continued
by arbitrarily complex sub-plans).
Shaparau et al. (2006) define a framework that has a similar effect in our context. They
consider contingent planning in the presence of a linear preference order over alternative
goals. Action trees T are plans if they achieve at least one goal in every leaf, i.e., they are
strong plans for the disjunction of the goals. Plan T is at least as good as plan T 0 if, in every
623

fiHoffmann, Weber & Kraft

state common to both, the best possible outcome achievable using T is at least as good as
that achievable using T 0 . T is optimal if it is at least as good as all other plans. Given
this, like for the EAGLE goal TryReach G Fail TRUE discussed above, every weak SAM
plan is optimal for the goal preference G, TRUE, but the inverse is not true because, in
unsolvable tasks and below unsolvable outcomes in solvable tasks, G, TRUE permits the
plan to do anything.
Mediratta and Srivastava (2006) define a framework also based on contingent planning,
but where the user provides as additional input a number K. Then, (1) a plan is any tree
T with  K leaves achieving the goal; and (2) if such T does not exist, then a plan is any
tree whose number of such leaves is maximal. Due to (1), failed nodes are not necessarily
unsolvable (the plan may simply stop once it reached K). Due to (2), even a task where
the goal cannot be reached at all, i.e., no matter what the action outcomes are we cannot
achieve the goal, has a plan. In addition, in our application context there is no sensible
way, for the human modeler, to choose a meaningful value for K.
Summing up, related notions of weak plans exist, but none captures exactly what we
want in SAM. On the algorithmic side, all the works listed here use symbolic search (based
on BDDs), and are thus quite different from our explicit-state SAM-AO* search. The single
exception is the planner described by Mediratta and Srivastava (2006), which is based on a
variant of A*, but for a different plan semantics as described.
Research has been performed also into alternative methods, not based on planning, for
automatically generating processes. For example, Kuster, Ryndina, and Gall (2007) describe
a method computing the synchronized product of the life-cycles of a set of business objects,
and generating a process corresponding to that product. That process serves as the basis for
customer-specific modifications. Clearly, that motivation relates to ours; but the intended
meaning of the output (the generated process), and the input assumed for its generation,
are quite different. As for the input, Kuster et al.s life-cycles are state machines describing
all possible behaviors of the object, which in our formulation here corresponds to the space
of all reachable states. That space can be generated based on SAM, but it can be huge even
for single BOs, not to mention their product (cf. our results for blind search and scaling
across BOs, Sections 6.4 and 6.5). Heuristic search gets us around the need to enumerate
all these states. As for the output, Kuster et al.s generated processes guarantee not only to
comply with the BO behaviors (which ours do as well), but also to cover them, essentially
representing all that could be done. This is very different from the plans we generate,
whose intention is to show specifically how to move between particular start and end states.
Altogether, the methods are complementary. Planning has computational advantages if the
involved objects have many possible states, as is often the case in SAM.

9. Conclusion
We have pointed out that SAP has built a large-scale model of software behavior, SAM,
whose abstraction level and formalization are intimately related to planning models in languages such as PDDL. We have shown how to base a promising BPM application of planning
on this fact. Getting the planner input for free, we avoid one of the most important obstacles
for making this kind of planning application successful in practice. Our solution is specific
to our particular context in its treatment of non-deterministic actions and failed outcomes,
624

fiSAP Speaks PDDL

but such phenomena are quite common in both planning and web service composition, and
our novel approach to dealing with them might turn out to be relevant more generally.
The main open issue is to obtain concrete data evaluating the business value of our
application. Some other points are:
 Our modification of FF successfully handles many SAM instances, finding plans within
runtimes small enough to apply realistic online-setting cut-offs. About 15% of the
instances we encountered still present challenges. These instances could serve as an
interesting benchmark for approaches dealing with failed outcomes in ways related to
what we do here (cf. Section 8).
 The current SAM model does not reflect dependencies across BOs. Such dependencies
do, however, exist in various forms. For example, some BOs form part of the data
contained in another kind of BO, some actions on one kind of BO create a new
instance of another kind of BO, and some actions must be taken by several BOs
together. There is an ongoing activity at SAP Research, aiming at enriching SAM to
reflect some of these interactions, with the purpose of more informed model checking.
All the interactions can easily be modeled in terms of well-known planning constructs
(object creation, and preconditions/effects spanning variables from several BOs), so
we expect that this extended model will enable us to generate more accurate plans. As
the results from Section 6.5 indicate, additional planning techniques may be required
to improve performance in case the number of interacting BOs becomes large. But
for smaller numbers (up to around a dozen BOs) the performance of our current tool
should still be reasonable.
 SAM currently provides no basis for automatically creating a number of additional
process aspects. An important aspect is exception handling, for which at the moment
we can only highlight the places (failed nodes) where it needs to be inserted. Another
issue is data-flow. This is mostly easy since the application data is already prepackaged in the relevant BOs, but there are some cases, like security tokens, not
covered by this. An open line of research is to determine how these aspects could be
modeled, in a way that can be exploited by corresponding planning algorithms.
 It may also be interesting to look into methods presenting the user with a set of
alternative processes. For discerning between relevant alternatives, such methods
require extensions to SAM, like action duration, action cost, or plan preferences.
From a more general perspective, the key contribution of our work is demonstrating the
potential synergy between model-based software engineering and planning-based process
generation. Re-using some (or even all) of the required models, the human labor required
to realize the planning is dramatically reduced. SAMs methodology  business-level descriptions of individual activities within a software architecture  is not specific to SAP.
Thus, exploiting this synergy is a novel approach that may turn out fruitful far beyond the
particular application described herein.

Acknowledgments
We thank the anonymous JAIR reviewers, whose comments helped a lot in improving the
paper.
625

fiHoffmann, Weber & Kraft

Most of this work was performed while all authors were employed by SAP. Part of this
work was performed while Jorg Hoffmann was employed by INRIA (Nancy, France), and
while Ingo Weber was employed by The University of New South Wales (Sydney, Australia).
NICTA is funded by the Australian Government as represented by the Department of
Broadband, Communications and the Digital Economy and the Australian Research Council
through the ICT Centre of Excellence program.

References
Aalst, W. (1997). Verification of Workflow Nets. In Application and Theory of Petri Nets
1997.
Agarwal, V., Chafle, G., Dasgupta, K., Karnik, N., Kumar, A., Mittal, S., & Srivastava, B.
(2005). Synthy: A system for end to end composition of web services. Journal of Web
Semantics, 3 (4).
Aler, R., Borrajo, D., Camacho, D., & Sierra-Alonso, A. (2002). A knowledge-based approach for business process reengineering: SHAMASH. Knowledge Based Systems,
15 (8), 473483.
Bacchus, F. (2000). Subset of PDDL for the AIPS2000 Planning Competition. The AIPS-00
Planning Competition Comitee.
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Bell, M. (2008). Service-Oriented Modeling: Service Analysis, Design, and Architecture.
Wiley & Sons.
Berardi, D., Calvanese, D., De Giacomo, G., Lenzerini, M., & Mecella, M. (2003). Automatic composition of e-services that export their behavior. In Orlowska, M. E.,
Weerawarana, S., Papazoglou, M. P., & Yang, J. (Eds.), Proceedings of the 1st International Conference on Service-Oriented Computing (ICSOC03), Vol. 2910 of Lecture
Notes in Computer Science, pp. 4358. Springer.
Berardi, D., Calvanese, D., De Giacomo, G., Lenzerini, M., & Mecella, M. (2005). Automatic service composition based on behavioral descriptions. International Journal of
Cooperative Information Systems, 14 (4), 333376.
Bertoli, P., Pistore, M., & Traverso, P. (2006). Automated web service composition by
on-the-fly belief space search. In Long, D., & Smith, S. (Eds.), Proceedings of the
16th International Conference on Automated Planning and Scheduling (ICAPS-06),
Ambleside, UK. AAAI.
Bertoli, P., Pistore, M., & Traverso, P. (2010). Automated composition of web services via
planning in asynchronous domains. Artificial Intelligence, 174 (3-4), 316361.
Biundo, S., Aylett, R., Beetz, M., Borrajo, D., Cesta, A., Grant, T., McCluskey, L., Milani,
A., & Verfaillie, G. (2003). PLANET Technological Roadmap on AI Planning and
Scheduling. http://planet.dfki.de/service/Resources/Roadmap/Roadmap2.pdf.
Bonet, B., & Geffner, H. (2000). Planning with incomplete information as heuristic search in
belief space. In Chien, S., Kambhampati, R., & Knoblock, C. (Eds.), Proceedings of the
626

fiSAP Speaks PDDL

5th International Conference on Artificial Intelligence Planning Systems (AIPS-00),
pp. 5261, Breckenridge, CO. AAAI Press, Menlo Park.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bonet, B., & Givan, B. (2006). 5th international planning competition: Non-deterministic
track  call for participation. In Proceedings of the 5th International Planning Competition (IPC06).
Born, M., Hoffmann, J., Kaczmarek, T., Kowalkiewicz, M., Markovic, I., Scicluna, J., Weber,
I., & Zhou, X. (2008). Semantic annotation and composition of business processes with
Maestro. In Demonstrations at ESWC08: 5th European Semantic Web Conference,
pp. 772776, Tenerife, Spain.
Born, M., Hoffmann, J., Kaczmarek, T., Kowalkiewicz, M., Markovic, I., Scicluna, J., Weber, I., & Zhou, X. (2009). Supporting execution-level business process modeling
with semantic technologies. In Demonstrations at DASFAA09: Database Systems for
Advanced Applications, pp. 759763, Brisbane, Australia.
Bryce, D., & Buffet, O. (2008). 6th international planning competition: Uncertainty part.
In Proceedings of the 6th International Planning Competition (IPC08).
Bryce, D., & Kambhampari, S. (2004). Heuristic guidance measures for conformant planning. In Koenig, S., Zilberstein, S., & Koehler, J. (Eds.), Proceedings of the 14th
International Conference on Automated Planning and Scheduling (ICAPS-04), pp.
365374, Whistler, Canada. AAAI.
Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics for belief
space search. Journal of Artificial Intelligence Research, 26, 3599.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69 (12), 165204.
Calvanese, D., De Giacomo, G., Lenzerini, M., Mecella, M., & Patrizi, F. (2008). Automatic
service composition and synthesis: the roman model. IEEE Data Engineering Bulletin,
31 (3), 1822.
Cimatti, A., Giunchiglia, F., Giunchiglia, E., & Traverso, P. (1997). Planning via model
checking: A decision procedure for ar. In Steel, S., & Alami, R. (Eds.), Recent Advances
in AI Planning. 4th European Conference on Planning (ECP97), Vol. 1348 of Lecture
Notes in Artificial Intelligence, pp. 130142, Toulouse, France. Springer-Verlag.
Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2003). Weak, strong, and strong cyclic
planning via symbolic model checking. Artificial Intelligence, 147 (1-2), 3584.
Cimatti, A., Roveri, M., & Traverso, P. (1998a). Automatic obdd-based generation of
universal plans in non-deterministic domains. In Mostow, J., & Rich, C. (Eds.),
Proceedings of the 15th National Conference of the American Association for Artificial
Intelligence (AAAI-98), pp. 875881, Madison, WI, USA. MIT Press.
Cimatti, A., Roveri, M., & Traverso, P. (1998b). Strong planning in non-deterministic domains via model checking. In Simmons, R., Veloso, M., & Smith, S. (Eds.), Proceedings of the 4th International Conference on Artificial Intelligence Planning Systems
(AIPS-98), pp. 3643, Pittsburgh, PA. AAAI Press, Menlo Park.
627

fiHoffmann, Weber & Kraft

Cohn, D., & Hull, R. (2009). Business artifacts: A data-centric approach to modeling
business operations and processes. IEEE Data Engineering Bulletin, 39.
Constantinescu, I., Faltings, B., & Binder, W. (2004). Large scale, type-compatible service
composition. In Jain, H., & Liu, L. (Eds.), Proceedings of the 2nd International
Conference on Web Services (ICWS-04), pp. 506513, San Diego, California, USA.
IEEE Computer Society.
Cresswell, S., McCluskey, T., & West, M. (2010). Acquiring planning domains models using
LOCM. The Knowledge Engineering Review.
Cresswell, S., McCluskey, T. L., & West, M. M. (2009). Acquisition of object-centred domain
models from planning examples. In Gerevini, A., Howe, A. E., Cesta, A., & Refanidis,
I. (Eds.), Proceedings of the 19th International Conference on Automated Planning
and Scheduling (ICAPS-09), Sydney, Australia. AAAI.
Dal Lago, U., Pistore, M., & Traverso, P. (2002). Planning with a language for extended
goals. In Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings of the 18th National
Conference of the American Association for Artificial Intelligence (AAAI-02), pp.
447454, Edmonton, AL, USA. MIT Press.
De Giacomo, G., & Sardina, S. (2007). Automatic synthesis of new behaviors from a library
of available behaviors. In Veloso, M. (Ed.), Proceedings of the 20th International Joint
Conference on Artificial Intelligence (IJCAI-07), pp. 18661871, Hyderabad, India.
Morgan Kaufmann.
Dumas, M., ter Hofstede, A., & van der Aalst, W. (Eds.). (2005). Process Aware Information Systems: Bridging People and Software Through Process Technology. Wiley
Publishing.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning domains. Journal of Artificial Intelligence Research, 20, 61124.
Gazen, B. C., & Knoblock, C. (1997). Combining the expressiveness of UCPOP with
the efficiency of Graphplan. In Steel, S., & Alami, R. (Eds.), Recent Advances in
AI Planning. 4th European Conference on Planning (ECP97), Vol. 1348 of Lecture
Notes in Artificial Intelligence, pp. 221233, Toulouse, France. Springer-Verlag.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministic
planning in the fifth international planning competition: PDDL3 and experimental
evaluation of the planners. Artificial Intelligence, 173 (5-6), 619668.
Gonzalez-Ferrer, A., Fernandez-Olivares, J., & Castillo, L. (2009). JABBAH: a Java application framework for the translation between business process models and HTN.
In Proceedings of the 3rd International Competition on Knowledge Engineering for
Planning and Scheduling, Thessaloniki, Greece.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence
Research, 26, 191246.
Helmert, M. (2009). Concise finite-domain representations for pddl planning tasks. Artificial
Intelligence, 173 (5-6), 503535.
628

fiSAP Speaks PDDL

Hoffmann, J., & Brafman, R. (2005). Contingent planning via heuristic forward search with
implicit belief states. In Biundo, S., Myers, K., & Rajan, K. (Eds.), Proceedings of the
15th International Conference on Automated Planning and Scheduling (ICAPS-05),
pp. 7180, Monterey, CA, USA. AAAI.
Hoffmann, J., & Edelkamp, S. (2005). The deterministic part of IPC-4: An overview. Journal
of Artificial Intelligence Research, 24, 519579.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence Research, 14, 253302.
Jonathan, P. J., Moore, J., Stader, J., Macintosh, A., & Chung, P. (1999). Exploiting ai
technologies to realise adaptive workflow systems. In Proceedings ot the AAAI99
Workshop on Agent-Based Systems in the Business Context.
Kambhampati, S. (2007). Model-lite planning for the web age masses: The challenges of
planning with incomplete and evolving domain models. In Howe, A., & Holte, R. C.
(Eds.), Proceedings of the 22nd National Conference of the American Association for
Artificial Intelligence (AAAI-07), Vancouver, BC, Canada. MIT Press.
Kitchin, D. E., McCluskey, T. L., & West, M. M. (2005). B vs ocl: Comparing specification languages for planning domains. In Proceedings of the ICAPS05 Workshop on
Verification and Validation of Model-Based Planning and Scheduling Systems.
Krafzig, D., Banke, K., & Slama, D. (2005). Enterprise SOA: Service-Oriented Architecture
Best Practices. Prentice Hall.
Kuster, J. M., Ryndina, K., & Gall, H. (2007). Generation of business process models
for object life cycle compliance. In Alonso, G., Dadam, P., & Rosemann, M. (Eds.),
Proceedings of the 5th International Conference on Business Process Management
(BPM07), Vol. 4714 of Lecture Notes in Computer Science, pp. 165181. Springer.
Liu, Z., Ranganathan, A., & Riabov, A. (2007). A planning approach for message-oriented
semantic web service composition. In Howe, A., & Holte, R. C. (Eds.), Proceedings of
the 22nd National Conference of the American Association for Artificial Intelligence
(AAAI-07), Vancouver, BC, Canada. MIT Press.
May, N., & Weber, I. (2008). Information gathering for semantic service discovery and
composition in business process modeling. In CIAO!08: Workshop on Cooperation &
Interoperability - Architecture & Ontology at CAiSE08, Vol. LNBIP 10, pp. 4660,
Montpellier, France.
McDermott, D., Ghallab, M., Howe, A., Knoblock, C., Ram, A., Veloso, M., Weld, D., &
Wilkins, D. (1998). PDDL  the planning domain definition language. Tech. rep.
CVC TR-98-003, Yale Center for Computational Vision and Control.
McDermott, D. V. (1999). Using regression-match graphs to control search in planning.
Artificial Intelligence, 109 (1-2), 111159.
Mediratta, A., & Srivastava, B. (2006). Applying planning in composition of web services
with a user-driven contingent planner. IBM Research Report RI 06002.
Meyer, H., & Weske, M. (2006). Automated service composition using heuristic search. In
Dustdar, S., Fiadeiro, J. L., & Sheth, A. P. (Eds.), Proceedings of the 4th International
629

fiHoffmann, Weber & Kraft

Conference on Business Process Management (BPM06), Vol. 4102 of Lecture Notes
in Computer Science, pp. 8196. Springer.
Narayanan, S., & McIlraith, S. (2002). Simulation, verification and automated composition
of web services. In Iyengar, A., & Roure, D. D. (Eds.), Proceedings of the 11th International World Wide Web Conference (WWW-02), Honolulu, Hawaii, USA. ACM.
Nilsson, N. J. (1969). Searching problem-solving and game-playing trees for minimal cost
solutions. In Information Processing 68 Vol. 2, pp. 15561562, Amsterdam, Netherlands.
Nilsson, N. J. (1971). Problem Solving Methods in Artificial Intelligence. McGraw-Hill.
Object Management Group (2006). Object Constraint Language Specification, Version 2.
http://www.omg.org/technology/documents/formal/ocl.htm.
Object Management Group (2008).
http://www.bpmn.org/.

Business Process Modeling Notation, V1.1.

Palacios, H., & Geffner, H. (2009). Compiling uncertainty away in conformant planning
problems with bounded width. Journal of Artificial Intelligence Research, 35, 623
675.
Pearl, J. (1984). Heuristics. Morgan Kaufmann.
Pednault, E. P. (1989). ADL: Exploring the middle ground between STRIPS and the situation calculus. In Brachman, R., Levesque, H. J., & Reiter, R. (Eds.), Principles of
Knowledge Representation and Reasoning: Proceedings of the 1st International Conference (KR-89), pp. 324331, Toronto, ON. Morgan Kaufmann.
Pesic, M., Schonenberg, M. H., Sidorova, N., & van der Aalst, W. M. P. (2007). Constraintbased workflow models: Change made easy. In Meersman, R., & Tari, Z. (Eds.), OTM
Conferences (1), Vol. 4803 of Lecture Notes in Computer Science, pp. 7794. Springer.
Pistore, M., Marconi, A., Bertoli, P., & Traverso, P. (2005). Automated composition of web
services by planning at the knowledge level. In Kaelbling, L. (Ed.), Proceedings of the
19th International Joint Conference on Artificial Intelligence (IJCAI-05), Edinburgh,
Scotland. Morgan Kaufmann.
Pistore, M., & Traverso, P. (2001). Planning as model checking for extended goals in nondeterministic domains. In Nebel, B. (Ed.), Proceedings of the 17th International Joint
Conference on Artificial Intelligence (IJCAI-01), pp. 479486, Seattle, Washington,
USA. Morgan Kaufmann.
Ponnekanti, S., & Fox, A. (2002). SWORD: A developer toolkit for web services composition.
In Iyengar, A., & Roure, D. D. (Eds.), Proceedings of the 11th International World
Wide Web Conference (WWW-02), Honolulu, Hawaii, USA. ACM.
Richter, S., & Helmert, M. (2009). Preferred operators and deferred evaluation in satisficing
planning. In Gerevini, A., Howe, A. E., Cesta, A., & Refanidis, I. (Eds.), Proceedings
of the 19th International Conference on Automated Planning and Scheduling (ICAPS09), Sydney, Australia. AAAI.
Rodriguez-Moreno, M. D., Borrajo, D., Cesta, A., & Oddi, A. (2007). Integrating planning
and scheduling in workflow domains. Expert Systems Applications, 33 (2), 389406.
630

fiSAP Speaks PDDL

SAP (2010). SAP NetWeaver.. http://www.sap.com/platform/netweaver/index.epx.
Sardina, S., Patrizi, F., & De Giacomo, G. (2008). Behavior composition in the presence
of failure. In Brewka, G., & Lang, J. (Eds.), Proceedings of the 11th International
Conference on Principles of Knowledge Representation and Reasoning (KR08), pp.
640650. AAAI Press.
Schneider, S. (2001). The B-Method: An Introduction. Palgrave.
Shaparau, D., Pistore, M., & Traverso, P. (2006). Contingent planning with goal preferences.
In Gil, Y., & Mooney, R. J. (Eds.), Proceedings of the 21st National Conference of the
American Association for Artificial Intelligence (AAAI-06), Boston, Massachusetts,
USA. MIT Press.
Sirin, E., Parsia, B., Wu, D., Hendler, J., & Nau, D. (2004). HTN planning for web service
composition using SHOP2. Journal of Web Semantics, 1 (4).
Sirin, E., Parsia, B., & Hendler, J. (2006). Template-based composition of semantic web
services. In AAAI Fall Symposium on Agents and Search.
Smith, D. E., & Weld, D. S. (1999). Temporal planning with mutual exclusion reasoning. In
Dean, T. (Ed.), Proceedings of the 16th International Joint Conference on Artificial
Intelligence (IJCAI-99), pp. 326337, Stockholm, Sweden. Morgan Kaufmann.
Srivastava, B. (2002). Automatic web services composition using planning. In Knowledge
Based Computer Systems (KBCS-02), pp. 467477.
Traverso, P., Ghallab, M., & Nau, D. (Eds.). (2005). Automated Planning: Theory and
Practice. Morgan Kaufmann.
Turner, J., & McCluskey, T. L. (1994). The Construction of Formal Specifications: an
Introduction to the Model-Based and Algebraic Approaches. McGraw Hill Software
Engineering series.
van der Aalst, W. (2003). Business process management demystified: A tutorial on models,
systems and standards for workflow management. In Lectures on Concurrency and
Petri Nets in ACPN04: Advanced Courses in Petri Nets, pp. 165.
van der Aalst, W. M. P., & Pesic, M. (2006). Decserflow: Towards a truly declarative service
flow language. In Bravetti, M., Nunez, M., & Zavattaro, G. (Eds.), WS-FM, Vol. 4184
of Lecture Notes in Computer Science, pp. 123. Springer.
Wainer, J., & de Lima Bezerra, F. (2003). Groupware: Design, Implementation, and Use,
Vol. 2806 of LNCS, chap. Constraint-based flexible workflows, pp. 151158. SpringerVerlag.
Weld, D. S., Anderson, C. R., & Smith, D. E. (1998). Extending graphplan to handle
uncertainty & sensing actions. In Mostow, J., & Rich, C. (Eds.), Proceedings of
the 15th National Conference of the American Association for Artificial Intelligence
(AAAI-98), pp. 897904, Madison, WI, USA. MIT Press.
Weske, M. (2007). Business Process Management: Concepts, Languages, Architectures.
Springer-Verlag.
631

fiHoffmann, Weber & Kraft

Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: A baseline for probabilistic planning.
In Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings of the 17th International
Conference on Automated Planning and Scheduling (ICAPS-07), Providence, Rhode
Island, USA. AAAI.
Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). The first probabilistic track
of the international planning competition. Journal of Artificial Intelligence Research,
24, 851887.

632

fiJournal of Artificial Intelligence Research 44 (2012) 223-273

Submitted 11/11; published 05/12

Modeling Social Causality and Responsibility Judgment
in Multi-Agent Interactions
Wenji Mao

WENJI.MAO@IA.AC.CN

State Key laboratory of Management and Control for Complex Systems
Institute of Automation, Chinese Academy of Sciences
No.95 Zhongguancun East Road, Beijing 100190, China

Jonathan Gratch

GRATCH@ICT.USC.EDU

Institute for Creative Technologies, University of Southern California
12015 Waterfront Drive, Playa Vista, CA 90094, U.S.A.

Abstract
Social causality is the inference an entity makes about the social behavior of other entities and self.
Besides physical cause and effect, social causality involves reasoning about epistemic states of
agents and coercive circumstances. Based on such inference, responsibility judgment is the
process whereby one singles out individuals to assign responsibility, credit or blame for multiagent activities. Social causality and responsibility judgment are a key aspect of social
intelligence, and a model for them facilitates the design and development of a variety of multiagent interactive systems. Based on psychological attribution theory, this paper presents a
domain-independent computational model to automate social inference and judgment process
according to an agents causal knowledge and observations of interaction. We conduct
experimental studies to empirically validate the computational model. The experimental results
show that our model predicts human judgments of social attributions and makes inferences
consistent with what most people do in their judgments. Therefore, the proposed model can be
generically incorporated into an intelligent system to augment its social and cognitive
functionality.

1. Introduction
Recent years have seen an explosion of research at the intersection of computing and human
social behavior. Topics such as human-centered (Jaimes, Sebe, & Gatica-Perez, 2006), social
(Wang, Zeng, Carley, & Mao, 2007) and affective computing (Picard, 1997, 2010) emphasize
the role of computers as partners or facilitators of human social activity, and highlight the
challenge of computationally understanding and participating in human social interactions.
Traditional artificial intelligence, with its emphasis on individual problem solving and
reasoning of rational behavior, is not obviously suitable for the social, emotional, and humanlike characteristics of social interaction. In this paper, we demonstrate how AI reasoning
methods can be applied to understanding, modeling and predicting human social judgments,
with applications in human-centric social interaction.
The specific challenge we focus on in this paper is reasoning about social causality. Social
causality refers to the inference an entity makes about the social behavior of other entities and
self. Such inference differs dramatically from how traditional artificial intelligence methods
(e.g., planning) reason about physical reality. Besides physical cause and effect, social

 2012 AI Access Foundation. All rights reserved.

fiMAO & GRATCH
causality includes reasoning about mental states (e.g., did the actor intend to cause the
outcome? could she foresee the outcome?) and social power (e.g., did the actor have the
freedom to act or was she coerced by circumstances or other individuals?). Responsibility
judgment is the process whereby one forms judgment results about responsibility, credit or
blame based on the inference of social causality. Social causality and responsibility judgment
underlie how we act on and make sense of the social world around us: they lead to emotional
expressions of praise or rage; they justify public applause or prison terms. In short, they lie at
the heart of social intelligence.
With the advance of multi-agent interactive systems, adaptive user interfaces and
applications that socially interact with people, it is increasingly important to model and reason
about this human-centric form of social intelligence. Social causal reasoning facilitates multiagent planning by augmenting classical planners with the ability to reason about which entities
have the power to effect changes. It facilitates adaptive learning by appraising praiseworthy or
blameworthy behavior, and reinforcing the praiseworthy. In modeling the communicative and
social behavior of human-like agents, responsibility judgment helps inform models of social
emotions by characterizing which situations evoke anger, guilt or praise (Gratch, Mao, &
Marsella, 2006). As people are usually adept at taking credit and deflecting blame in social
dialogue (e.g., negotiation), the information helps guide natural language conversation strategies
(Martinovski, Mao, Gratch, & Marsella, 2005).
Social causal inference helps reason about the social and cognitive states of an entity, and
responsibility judgment helps form the assessment of the observed social behavior of an entity
(either a human user, a computer program or an agent). They thus can facilitate various forms of
interactions including human-computer, human-agent and agent-agent interactions. They can also
facilitate human-human interaction by identifying the underlying cognitive process and principles
of human judgments. In a multi-agent environment, social causality and responsibility judgment
help share responsibility in multi-agent organization (Jennings, 1992), evaluate social power and
dependence (Castelfranchi, 1990; Sichman, Conte, Demazeau, & Castelfranchi, 1994), automate
after-action review for group training (Gratch & Mao, 2003; Johnson & Gonzalez, 2008), and
support social simulation of agent society.
Our primary goal is to develop a faithful computational framework for human-like
intelligent agents so as to drive realistic behavior modeling and generation (Swartout et al.,
2006). Psychological and philosophical studies agree on the broad features people use in their
everyday behavioral judgment. Our work is particularly influenced by attribution theory, a
body of research in social psychology exploring folk explanation of behavior. Based on
psychological attribution theory, we have developed a general computational framework for
inferring social causality and forming responsibility judgment according to an agents causal
knowledge and observations of communication and task execution, and empirically validated
our approach using human data.
The rest of this paper is organized as follows. In Section 2, we review previous computational
work on social causality, responsibility and blame/credit. In Section 3, we introduce two
influential attributional models of behavioral judgment, Weiners (1995) model for responsibility
judgment and Shavers (1985) model for blame attribution. Based on these attributional models,
Section 4 presents our computational framework for social causality and responsibility judgment.
224

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
We provide the computational representation, inferences and algorithm in our proposed model,
and illustrate our approach using an example from our system development. Then in Section 5,
we report our empirical studies on model validation. Section 6 further discusses some research
issues. The paper concludes in Section 7.

2. Related Work
Since the rise of cognitive science (Newell & Simon, 1972), computational methods and
metaphors have been applied to modeling and understanding human behavior. Several lines of
research have addressed aspects of social cognition, including natural language dialogue (Cassell,
Sullivan, Prevost, & Churchill, 2000; Ferguson & Allen, 2007), collaborative problem solving
(Rich, Sidner, & Lesh, 2001; Schurr, Marecki, Tambe, & Scerri, 2005), modeling emotions
(Marinier & Laird, 2004; Gratch, Marsella, & Petta, 2009), simulating human negotiation
processes (Kraus, Hoz-Weiss, Wilkenfeld, 2008; Martinovski & Mao, 2009), and understanding
human social networks (Golbeck & Hendler, 2006; Wang et al., 2010). When modeling human
social behavior, it is useful to distinguish between normative, descriptive and legal perspectives.
Normative models attempt to prescribe how people should assign responsibility and blame/credit.
Descriptive models characterize what people do in practice, which may differ considerably from
normative prescriptions. Legal models refer to the formalized processes society uses for
responsibility assignment, which can be seen as the amalgam of normative and practical
considerations. Before presenting our descriptive model of social causality and responsibility
judgment, we motivate this work by examining each of these perspectives.
2.1 Normative Models
Normative (or prescriptive) models typically put forward a set of rational principles that should
universally guide decision-making. For example, Bayesian decision theory is proposed as the
optimal method for deciding between alternative courses of actions. Game theory is proposed as
the ideal method for arriving at certain social decisions, such as whether or not to cooperate with
another, possibly deceptive, party. While game theoretic approaches model group decision
making itself in a rational way, social causality and responsibility judgment model the reasoning
and assessment of social causes and consequences resulting from such decision making. For the
judgment of causality, responsibility and blame/credit, research on normative models largely
resides on moral philosophy where the aim is to identify rational principles to govern the
assignment of social credit and blame. For example, Kant (1998) argued that, unlike what is often
observed in practice, it would be rational to assign the same standards of responsibility regardless
of the valence (i.e., praiseworthy or blameworthy) or severity of a social act. Within computer
science and artificial intelligence, we are unaware of any other complete models based on the
normative principles, with the exception of the computational model proposed by Chockler and
Halpern (2004).
2.2 Legal Models
Legal models attempt to formalize responsibility judgment and inferences realized within judicial
systems, typically with the aim of automating or verifying human legal judgments. This is a
fertile research field at the intersection of artificial intelligence and law. The field has
225

fiMAO & GRATCH
continuously been progressing since the development of early legal systems such as TAXMAN
& TAXMAN- (McCarty & Sridharan, 1981; McCarty, 1995), HYPO (Rissland & Ashley,
1987), CABARET (Rissland & Skalak, 1991) and CATO (Aleven & Ashley, 1995). There are
similarities in the judgments of normative and legal responsibility, and some researchers have
suggested using legal model as a direct analogue for normative model of responsibility judgment
(e.g., Fincham & Jaspars, 1980). However, there are fundamental differences between these two
kinds of responsibility judgment. Legal judgment largely depends on specific circumstances.
That is why most legal reasoning systems are case-based, whereas evaluating moral
responsibility identifies general theories that fall within the broad studies of cognitive
functionalism1 (e.g., clarifying the roles of cause, belief and intention in explaining behavior).
In addition to case-based legal reasoning systems, researchers have proposed logic-based
approaches that focus on general reasoning mechanism, typically defeasible inference using nonmonotonic reasoning and defeasible argumentation (e.g., Hage, 1997; Prakken, 1997). The main
efforts in logic-based legal systems are on the representation of complex legal rules (e.g.,
contradictory, nonmonotonic and priority rules), inference with rules and exceptions, and
handling conflict rules (Prakken & Sartor, 2002). McCarty (1997) argued whether in real cases, a
judge would apply formal theory to evaluate complex rules, and thereby arrive at correct results.
He called for a more intuitive version of legal rules, which would be simple and clear.
Furthermore, we argue that a laymans judgment of behavior in everyday situations is not quite
the same as that made in the court. Not only does it occur in richer forms of social interaction,
but it follows different set of rules.
2.3 Descriptive Models
Descriptive models attempt to characterize how people form social judgments in practice, which
can differ from both the presumed normative principles and legal judgments. For example, in
contrast to Kants prescription to adopt uniform principles, people use different criteria when
assigning blame versus credit and often form different judgments depending on the severity of an
outcome. Descriptive models also differ in their criteria for validation. Whereas normative
models are judged by their consistency with universal principles such as fairness and legal
models are judged by their consistency with past legal decisions, descriptive models are assessed
by their agreement with the judgments people form in their day-to-day lives. In this sense,
descriptive models are most relevant to the field of human-centered or social computing, where
the goal is to adapt computation to human norms of practice, rather than forcing humans to adapt
to prescriptive norms of behavior. Research on descriptive models largely resides on social
psychology (Heider, 1958; Shaver, 1985; Weiner 1995, 2001, 2006) and there is little work
within artificial intelligence on attributing responsibility and blame/credit in a human-like
fashion.
2.4 Computational Approaches
In AI and causality research, computational approaches were developed to address the problem
by extending causal models (Halpern & Pearl, 2001; Chockler & Halpern, 2004). Halpern and
Pearl (2001) presented a definition of actual cause within the framework of structural causal
1

The doctrine that views theories of behavior as complex mental states, introduced and individualized by the functions
or the roles they play in producing the behavior to be explained.
226

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
models. As their approach can extract more complex causal relationships from simple ones, their
model is capable of inferring indirect causal factors including social cause. A causal model (or a
structural model) is a system of equations over a set of random variables. There are two finite
sets of variables: exogenous (U) and endogenous (V). The values of exogenous variables are
determined by factors outside the model, thus they have no corresponding equations. Each
endogenous variable has exactly one causal equation (or structural equation) that determines
their value. A causal model can be expressed as a causal diagram, with nodes corresponding to
the variables, and edges from the parents of each endogenous variable (indicated by the causal
equations) to the endogenous variable. Take the two-man firing squad example (Pearl, 1999):
There is a two-man firing squad; on their captains order, both riflemen shoot simultaneously
and accurately, and the prisoner dies.
Figure 1 illustrates the causal model for the firing squad example, where U={Uc} and V={C,
R1, R2, D}. A vector of values for the exogenous variables in U (called a context) in the causal
model represents a specific situation (i.e., a causal world). For instance, if we assume Uc=1 (i.e.,
the captains order is true) in the causal model below, then the resulting causal world describes
the two-man firing squad story above. Causal inference is based on counterfactual dependence
under some contingency. Roughly speaking, B is counterfactually dependent on A if, had A not
happened then B would not have happened. For example, in the above firing squad scenario,
given the context that the captain orders, under the contingency that rifleman-2 did not shoot, the
prisoners death is counterfactually dependent on rifleman-1s shooting. So rifleman-1s shooting
(R1=1) is an actual cause of the death. Similarly, rifleman-2s shooting (R2=1) is an actual cause
of the death. Besides the two riflemen who physically cause the death, Halpern & Pearls model
can find the captains order (C=1) as an actual cause for the death as well.
Context (Uc)

Causal equations:
Commander orders (C)

Uc = C
C = R1

Rifleman-1
shoots (R1)

Rifleman-2
shoots (R2)

C = R2
R1  R2 = D

Prisoners death (D)

Figure 1: Causal Model for the Firing-Squad Example
Chockler and Halpern (2004) further extended this notion of causality, to account for degree
of responsibility. They provide a definition of degree of responsibility based on the consideration
of contingencies. Given a causal model M, a variable XV and a context , the degree of
responsibility of a formula X=x for an outcome  is measured by the minimal number of changes
k that have to be made in  in order to make  counterfactually depend on X=x. If X=x is not an
actual cause of , then the degree of responsibility of X=x for  is 0; Otherwise the degree of
responsibility of X=x for  is 1/(k+1). If  counterfactually depends on X=x, then the degree of
responsibility of X=x for  is 1. For example, if a person wins an election 11-0, then each voter

227

fiMAO & GRATCH
who votes for her is a cause for the victory, and the degree of responsibility of each voter for the
victory is 1/6. However, in a 6-5 victory, the degree of responsibility of each voter is 1.
Based on this notion of responsibility, Chockler and Halpern (2004) then defined the degree
of blame, using the expected degree of responsibility weighed by the epistemic state of an agent.
An agents epistemic state is represented as a pair (K, Pr), where K is a situation with the form
(M, ) and Pr is a probability distribution over K. The degree of blame of X=x for  relative to an
agents epistemic state (K, Pr) is computed as the sum of multiplying the expected degree of
responsibility of X=x for  in each possible situation in (MXx, ) and the agents epistemic state
of the probability of the situation. To illustrate this, they provide the ten-man firing squad
example:
There is a firing squad consisting of ten excellent marksmen. Only one of them has live bullets
in his rifle; the rest have blanks. The marksmen do not know which of them has the live
bullets. The marksmen shoot at the prisoner and he dies.
Suppose that an agent knows that exactly one marksman has live bullets in his rifle, and that
all the marksmen will shoot. Then the agent considers 10 possible situations, depending on who
has the bullets. Let {p1, , p10} be the probability distribution over these situations, where pi is
the agents prior probability that marksman-i has live bullets. Thus, according to the agents
epistemic state, the expected degree of responsibility of marksman-1s shot for the death is 1
under the situation when he has the bullets (and 0 under other situations), and the degree of
blame of marksman-1s shot for the death is p1.
Grounded on the philosophical principle (i.e., counterfactual reasoning), Chockler &
Halperns extended definition of responsibility accounts better for multiple causes and the
extent to which each cause contributes to the occurrence of a specific outcome. Another
advantage of their model is that their definition of degree of blame takes an agents epistemic
state into consideration. However, they only consider one epistemic variable, that is, an
agents knowledge prior to action performance. Important concepts in moral responsibility,
such as intention and freedom of choice are excluded from their definition. As a result, their
model uses one epistemic state as the only determinant for blame assignment, which is
inconsistent with psychological theories.
As Chockler & Halperns (2004) model is the extension of counterfactual reasoning within
the structural-model framework, and structural-model approach represents all the events as
random variables and causal information as equations over the random variables, there are
several other limitations in their model. For instance, causal equations do not have direct
correspondence in computational systems, so it is hard to obtain them for practical
applications. As communicative events are also represented as random variables in their model
(which are propositional), it is difficult to construct equations for communicative acts and
infer intermediate beliefs (e.g., beliefs about desires, intentions, etc) that are important for
social causal reasoning.

3. Attribution Theory for Behavioral Judgment
Most contemporary psychological studies of social causality and responsibility judgment draw on
attribution theory (Heider, 1958). In over 50 years of research, attribution theory has progressed
228

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
significantly and became a core area of social psychology (Malle, 2001; Weiner, 2006).
Attribution research views that social perceivers make sense of the world by attributing behavior
and events to their underlying causes. Attribution therefore refers to the process of ascribing a
cause to an event or explaining the event, as well as the inferences or judgments made. Two
influential attributional models for social causality, responsibility and blame (or credit) are those
proposed by Shaver (1985) and Weiner (1995), which identify the underlying key factors (i.e.,
attribution variables) people use in behavioral judgment. Below we summarize their theories (we
adopt the terminology of Shavers model in this paper).
The assessments of physical causality and coercion identify the responsible party. Physical
causality refers to the connection between events and the outcomes they produce, which
includes personal causality (i.e., human agency) and impersonal causality (i.e., environmental
factors). Only when human agency is involved, does an event become relevant to the
investigation of responsibility and blame/credit. In the absence of coercion, the actor whose
action directly produces the outcome is regarded as responsible. However, in the presence of
coercion (as when some external force, such as a more powerful individual or a socially
sanctioned authority, limits an agents freedom of choice), some or all of the responsibility
may be deflected to the coercive force. For example, in the two-man firing squad example, if
the captains order does limit the riflemens freedom to avoid the prisoners death, the captain
should take some or all of the responsibility, depending on the degree of coercion.
Intention and foreseeability determine the degree of responsibility. Intention is generally
conceived as the commitment to work towards a certain act or outcome. Most theories view
intention as the major determinant of the degree of responsibility. Foreseeability refers to an
agents foreknowledge about actions and their effects. For example, although the riflemen
foresaw that shooting a gun leads to the prisoners death, they may not intend shooting and
killing the prisoner. However, if an agent intends an action to achieve a certain outcome, then
the agent must have the foreknowledge that the action brings about the outcome. The higher
the degree of intention, the greater the responsibility assigned. If the riflemen have no
intention of killing the prisoner, for instance, they should be assigned much less responsibility
than in the case when they really intend so.
Weiner (2001) distinguished between act intentionality and outcome intent. An agent may
intentionally perform an action, but may not intend all the action effects. For example, the
riflemen may intentionally shoot the enemy, but may not intend the side effect of exposing
themselves to the enemy force. It is outcome intention (i.e., intended action effect), rather than
act intention (i.e., intended action) that are key in responsibility and behavioral judgment.
Similar difference exists in outcome coercion (i.e., coerced action effect) and act coercion (i.e.,
coerced action). Furthermore, an agents intentional action and action effect may fail.
However, as long as it manifests intentions, a failed attempt can be blamed or credited almost
the same as a successful one (Zimmerman, 1988).
The result of the judgment process is the assignment of certain blame or credit to the
responsible party. Shavers model of blame assignment follows a strict sequential process. In
his model, first one assesses physical causality. If human agency is involved, the judgment
process proceeds by assessing other key variables. Finally, the perceiver takes possible
mitigating factors (i.e., justifications or excuses) into consideration and assigns proper blame
229

fiMAO & GRATCH
to the responsible agent (mitigating factors are not modeled yet in our work). Weiners model
is similar, but it is more relaxed in that the sequential processing in Shavers model is not
presumed (we follow the implications of Weiners model and relax the strict sequential feature
in Shavers model). The intensity of blame or credit is determined by the severity or positivity
of the outcome as well as the degree of responsibility. The latter is based on the assessed
values of attribution variables.

4. Proposed Computational Model
Attribution theory identifies the general process and key variables people use in judging social
behavior. However, this process and the variables are not directly applicable to computational
systems, as they are described at an abstract conceptual level that is insufficiently precise from a
computational perspective. On the other hand, current intelligent systems are increasingly
sophisticated, usually involving natural language communication, multi-agent interactions, goaldirected reasoning to generate and execute plans, and methods to explicitly model beliefs, desires
and intentions of agents (Pollack, 1990; Grosz & Kraus, 1996; Gratch et al., 2006; Ferguson &
Allen, 2007; Swartout et al., 2010).
To bridge the gap between conceptual descriptions of the theory and actual components in
current intelligent systems, we need to develop the computational mechanisms that automatically
convert the implications of the conceptual descriptions into a functionally workable model in use
for intelligent systems. The computational model functions as the inferential mechanism to
derive the conceptual variables in the theory from information and context available in practical
systems. Ideally, the computational model should be based on the data structures and
representations that are typically used in practical systems, and rely as little as possible on
additional structural or representational features.
In constructing our computational model, we follow the basic dimensions in Shavers model
but relax its strict sequential feature. We follow the implications of Weiners model, considering
both the actions of agents and the outcomes they produce. We adopt plan representation used by
most intelligent systems, especially in agent-based systems. This representation provides a
concise description of the causal relationship between events and states. It also provides a clear
structure for exploring alternative courses of actions, recognizing intentions, and assessing
coercive situations and plan interventions.
We take advantage of artificial intelligence modeling and reasoning techniques, in particular,
the Belief-Desire-Intention model (Bratman, 1987; Georgeff & Lansky, 1987) and commonsense
reasoning (Gordon & Hobbs, 2004; Mueller, 2006). The BDI concepts help us map sometimes
vague psychological terms into widely accepted concepts in AI and agent research, and research
in commonsense reasoning informs the design of the inferential mechanism that generally
operates on these conceptual representations. We use logic as a formal representation tool,
focusing on the design of a small number of inference rules to capture the intuitions in peoples
judgments of social behavior2.
2

Note that our focus here is not the definition of a logical language, but rather, we aim at identifying the commonsense
intuitions in peoples behavioral judgment so as to come up with the computational modeling of social causality and
responsibility attribution.
230

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS

Observations

Sources

Plan Execution

Causal
Knowledge

Module

Task
Execution

Inferences
Action
Sequence

Causal
Inference

Dialog Module

Social
Information

Inference
Rules

Communication

Speech Act
Sequence

Dialog
Inference

Beliefs

Algorithm

Results

Attribution
Values

Judgment
Process

Responsibility
Blame/Credit

Figure 2: Overview of the Computational Model
We have developed a computational model that can automatically derive judgments
underlying responsibility and blame attribution from knowledge and observations about social
acts. Figure 2 illustrates an overview of the computational model. Two sources of information
contribute to the inference process. One source is the actions performed by the agents involved in
the social situation (including physical acts and communicative acts). The other is the general
causal knowledge about actions and states of the world (i.e., causal knowledge), social roles and
power relationship of agents (i.e., social information). Causal inference derives beliefs from
causal evidence. Dialog inference derives beliefs from communicative evidence. Both
inferences make use of commonsense rules and generate beliefs of attribution variables. These
beliefs serve as inputs for the judgment process, which is described as an algorithm. Finally,
the algorithm forms an overall judgment and assigns proper credit or blame to the responsible
agents.
4.1 Representations
Our computational representation is based on the plan descriptions that are widely applied to the
applications and architecture design of intelligent systems (e.g., Georgeff & Lansky, 1987;
Veloso et al., 1995; Fischer, Mueller, & Pischel, 1996; Rao, 1996; dInverno, Kinny, Luck, &
Wooldridge, 1997; Huber, 1999; Gil, Deelman, Blythe, Kesselman, & Tangmurarunkit, 2004;
Marsella & Gratch, 2009). More specifically, we adopt the classical STRIPS operators (Fikes &
Nilsson, 1971) with the hierarchical plan representation (Erol, Hendler, & Nau, 1994; Nau, Cao,
Lotem, & Muoz-Avila, 1999).
4.1.1 C AUS AL K NOWLE DGE
In our approach, causal knowledge is encoded via a hierarchical plan representation. An action
has a set of propositional preconditions and effects (including conditional effects). Actions can be
either primitive (i.e., directly executable by agents) or abstract. An abstract action may be
decomposed in multiple ways and each decomposition is one choice of executing the action.
Different choices of action execution are alternatives each other. If an abstract action can be
decomposed in multiple ways, it is a decision node (i.e., or node) and an agent must decide
231

fiMAO & GRATCH
amongst the alternatives. Otherwise, if an abstract action can only be decomposed in one way, it
is a non-decision node (i.e., and node) and execution of the action is realized via executing all its
subactions.
A plan is a set of actions to achieve certain intended goal(s). As a plan may contain abstract
actions (i.e., an abstract plan), decomposing the abstract actions into primitive ones in an abstract
plan results in a set of primitive plans (i.e., plans composed of only primitive actions), which are
directly executable by agents. Consequences or outcomes (we use them as exchangeable) are
those desirable or undesirable action effects (i.e., effects having positive or negative significance
to an agent). The desirability of action effects is represented by utility values (Blythe, 1999). To
represent the hierarchical organizational structure of social agents, each action in a plan is
associated with a performer (i.e., the agent capable of performing the action) and an agent who
has authority over its execution. This is used to model the power relationships of agents.
Troop-at-aa

Support Unit 1-6
Performer: lieutenant
Authority: lieutenant

OR
Troop-at-aa



Troop-at-aa

Send One Squad

Send Two Squads

Performer: sergeant
Authority: lieutenant

Performer: sergeant
Authority: lieutenant

AND

AND

One-sqd-at-aa

Remaining-at-aa

Two-sqds-at-aa


Remaining-at-aa

One Squad Forward

Remaining Forward

Two Squads Forward

Remaining Forward

Performer: squad leader
Authority: sergeant

Performer: squad leader
Authority: sergeant

Performer: squad leader
Authority: sergeant

Performer: squad leader
Authority: sergeant

1-6 Supported Unit Fractured

Not Fractured



Route Secured

1-6 Supported



Figure 3: Partial Plan Representation for an Agent Team
Figure 3 illustrates an example of plan representation from a team training system we
developed (we shall discuss more on this example in Section 4.4). In the example, a lieutenant, a
sergeant and squad leaders work as a team in fulfilling the task of supporting a sister unit (i.e.,
unit 1-6). The lieutenant is the leader of the troop. Two alternative ways are available to support
unit 1-6, either sending one squad or sending two squads. Each alternative can be performed by
the sergeant if authorized. The alternatives can be further decomposed into subsequent primitive
actions that are directly executable by the squad leaders. Action execution brings about certain
effects, for example, two squads forward (meaning that two of the four squads in the troop leave
the scene) fractures the unit (meaning that the troop forces are split and weakened), which is
undesirable to the troop. (Unit) 1-6 supported (meaning that the sister unit is reinforced by the
departing squads) is a desirable team goal.
4.1.2 C OM M UNIC ATIVE E VE NTS
Communication between agents is a rich source of information for inferring social causality.
We represent communicative events as a sequence of speech acts (Austin, 1962; Searle, 1969).
For our purpose, we consider the speech acts commonly used in agent communication, and
especially those that help infer dialogue agents desires, intentions, foreknowledge and choices
in acting. We thus focus on the acts inform, request, order, accept, reject and counter-propose.
232

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
4.1.3 A TTR IB UTION V AR IAB LE S
Attributional models employ a set of key variables to determine social cause and responsibility.
Causality refers to the relationship between cause and effect. For the investigation of
responsibility attribution, the involvement of human agency is required (Weiner, 1995; Shaver,
1985). In our approach, we encode causal knowledge about actions (i.e., human agency) and
the effects they produce via plan representation.
We consider both act intentionality and outcome intent of agents. Act intention is
represented using intend and do, outcome intention using intend and achieve, and the
connection between act and outcome intentions using intend and by. We use know and bring
about to represent foreseeability. Two concepts are important in modeling coercion 3 . One
concept is social obligation. The other is (un)willingness. For example, if some authorizing
agent commands another agent to perform a certain action, then the latter agent has the
obligation to do so. But if the latter agent is actually willing to, this is a voluntary act rather
than a coercive one. We use coerce and do to represent act coercion and coerce and achieve
for outcome coercion.
4.1.4 N OTATIONS
Now we provide the symbolic expressions of the notations used in our model 4.
Predicates
Let x and y be different agents, A and B be actions, e be an action effect, p and q be propositions,
E be an effect set and t be a time. We adopt the following predicates in the model:
P1.
P2.
P3.
P4.
P5.
P6.
P7.
P8.
P9.
P10.
P11.
P12.
P13.
P14.
P15.
P16.

primitive(A): A is a primitive action.
and-node(A): action A is a non-decision node in plan structure.
or-node(A): action A is a decision node in plan structure.
alternative(A, B): actions A and B are alternatives of performing a higher-level action.
do(x, A): agent x performs an action A.
achieve(x, e): agent x achieves an effect e.
bring-about(A, e): action A brings about an effect e.
by(A, e): by acting A to achieve an effect e.
execute(x, A, t): agent x executes an action A at time t.
occur(e, t): effect e occurs at time t.
inform(x, y, p, t): agent x informs agent y that p at time t.
request(x, y, p, t): agent x requests agent y that p at time t.
order(x, y, p, t): agent x orders agent y that p at time t.
accept(x, p, t): agent x accepts that p at time t.
reject(x, p, t): agent x rejects that p at time t.
counter-propose(x, p, q, y, t): agent x counters that p and proposes that q to agent y at
time t.
P17. cause(x, e, t): agent x causes an effect e at time t.
3

4

Coercion sometimes means physical coercion, such as pushing someones hand to pull the trigger of a gun. Here we
mean psychological coercion, which emphasizes its impact on the psychological states of agents.
Although we represent these notations in first-order predicate calculus, we treat them as semi-formal notations in our
model and do not conduct theorem-proving type of inference with them in strict logical sense.
233

fiMAO & GRATCH
P18.
P19.
P20.
P21.
P22.
P23.
P24.
P25.

assist-cause(x, y, e, t): agent x assists agent y in achieving an effect e at time t.
know(x, p, t): agent x knows that p at time t.
want(x, p, t): agent x wants that p at time t.
obligation(x, p, y, t): agent x has the obligation that p created by agent y at time t.
intend(x, p, t): agent x intends that p at time t.
coerce(x, y, p, t): agent x coerces agent y that p at time t.
superior(x, y): agent x is a superior of agent y.
enable(x, E, t): agent x makes an effect set E true at time t (enable(x, E, t) means that agent
x disables effect set E by making at least one effect in E false at time t).
P26. can-enable(x, E, t): agent x is capable of making an effect set E true at time t (can-enable(x,
E, t) means that agent x can disable effect set E by making at least one effect in E false at
time t).
P27. true(E, t): effect set E is true at time t (this means that every effect in E is true at time t, and
true(E, t) means at least one effect in E is false at time t).
Predicates P1P10 denote the features related to plan structure and action execution. Predicates
P11P16 represent communicative acts. These predicates are used to express task knowledge and
observations of action execution and agent communication. Predicates P17P23 describe the
epistemic variables (including attributions) used for inferring intermediate beliefs. Predicates
P24P26 represent the power relationship and capabilities of agents.
Functions
Let A be an action, e be an action effect and DT be the domain theory5. We adopt the following
functions in the model:
F1.
F2.
F3.
F4.
F5.
F6.
F7.
F8.
F9.
F10.
F11.
F12.
F13.
F14.
F15.

5

subaction(A): subaction set of an abstract action A.
choice(A): choice set for performing an abstract action A.
precondition(A): precondition set of an action A.
effect(A): (definite) effect set of an action A.
conditional-effect(A): conditional effect set of an action A.
antecedent(e): antecedent set of a conditional effect e.
consequent(e): consequent of a conditional effect e.
indefinite-effect(A): indefinite effect set of an action A.
relevant-action(e, DT): relevant action set to achieve an effect e based on the domain
theory DT.
relevant-effect(e, DT): relevant effect set to achieve an effect e based on the domain theory
DT.
side-effect(e, DT): side effect set to achieve an effect e based on the domain theory DT.
performer(A): performing agent(s) of an action A.
authority(A): authorizing agent(s) of an action A.
primary-responsible(e): primary responsible agent(s) for an effect e.
secondary-responsible(e): secondary responsible agent(s) for an effect e.

Domain theory is a general term used in planning and plan-based systems, specifying the actions performed in a
domain and state affairs (typically described as preconditions and effects) that are causally linked to the actions.
Domain theory is the general knowledge of the domain represented using a given plan representation.
234

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
Among these functions, F1F7 denote the generic features in (hierarchical) plan representation.
Functions F8F11 describe indefinite effect set, relevant action/effect and side effect, and functions
F12F15 represent the agents involved.
4.2 Reasoning about So cial Causality
Social causality and responsibility judgment involve evaluating outcomes of events with
personal significance to an agent. This evaluation is always from a perceiving agents
subjective perspective. The perceiver uses her knowledge about the observed agents and
observation of behavior to infer beliefs of social attributions. We show how automatic
methods of causal and dialogue reasoning can provide such a mechanism.
4.2.1 D IALOGUE I NFE R E NC E
Conversation between agents is a rich source of information for deriving attribution values.
Early attribution theorists (Kidd & Amabile, 1981; Hilton, 1990) have pointed out the importance
of language communication in attributing behavior. Within AI research community, there has
been much related work on intentions in agent communication (Cohen & Levesque, 1990; Smith
& Cohen, 1996), plan inference (Allen & Perrault, 1980; Litman & Allen, 1990), discourse
structure (Grosz & Sidner, 1986; Lochbaum, Grosz, & Sidner, 2000) and speech act theory
(Perrault, 1990). Although some previous research have partially addressed the issue of inferring
intentions under different formalism, our focus here is on identifying the generic commonsense
reasoning rules of attribution variables as well as their interrelations from social
communication.
Natural language communication can be seen as a collaborative activity between
conversational agents. Successful communication requires the participants to follow the basic
conversation principles (Grice, 1975) and reach some degree of common ground (Clark &
Schaefer, 1987). Thus we assume communication between agents is grounded (Traum, 1994),
and conversation conforms to Grices maxims of Quality6 and Relevance7. In a conversational
dialogue, the participating agents exchange information alternatively. A perceiving agent (who
can be one of the participating agents or another agent) forms and updates beliefs according to
the observed speech acts and previous beliefs.
We design commonsense rules that allow a perceiving agent to derive beliefs about the
epistemic states of the observed agents. We also take social information (i.e., social roles and
relationship) into consideration. For example, an order can be successfully issued only to
subordinates, but a request can be made of any agent; and same request performed by agents
with different social status may lead to different belief derivations.
Hobbs (1985) proposed a first-order logic notation, using eventuality8 to reify events and
conditions. To avoid expressing higher-order properties in first-order logic, our formalism has
adopted this notation; but for simplification and ease of illustration, we still keep the higher6
7
8

The quality maxim states that one ought to provide true information in conversation.
The relevance maxim states that ones contribution to conversation ought to be pertinent in context.
Eventuality is an extra argument used in each predication referring to the condition that exists when that predication
is true. For every predicate P(x), P is true of x if and only if there is an eventuality or possible situation e of P being
true of x (called P) and e really exists, i.e. (x)P(x)(e)P(e,x)Exist(e). The work of Hobbs (1985) provided
further explanation on the ontological assumptions of the notation.
235

fiMAO & GRATCH
order expressions in this paper (note that they are actually handled using Hobbs notation in
our approach). Also, to simplify logical forms, universal quantifiers are omitted in the rules,
and we substitute A and e for do(x, A) and achieve(x, e) respectively, when causing no
confusion.
If at time t1, a speaker (s) informs (or tells) a hearer (h) the content p, then after t1, it can be
inferred that the speaker knows that proposition p as long as there is no intervening
contradictory belief (Rule D1). As conversations between agents are grounded, it can be
inferred that the hearer also knows that p (Rule D2). To further simplify the expressions of rules,
we introduce a predicate etc9 which stands for the absence of contradictory situations.
Rule D1 [inform]:
inform(s, h, p, t1)  t1<t2  etc1  know(s, p, t2)
Rule D2 [inform-grounded]:
inform(s, h, p, t1)  t1<t2  etc2  know(h, p, t2)
A request shows what the speaker wants (Rule D3). An order (or command) shows what the
speaker intends (Rule D5). An order can only be successfully issued by someone higher in
social status. If requested or ordered by a superior, it creates a social obligation for the hearer
to perform the content of the act (Rules D4 & D6).
Rule D3 [request]:
request(s, h, p, t1)  t1<t2  etc3  want(s, p, t2)
Rule D4 [superior-request]:
request(s, h, p, t1)  superior(s, h)  t1<t2  etc4  obligation(h, p, s, t2)
Rule D5 [order]:
order(s, h, p, t1)  t1<t2  etc5  intend(s, p, t2)
Rule D6 [order]:
order(s, h, p, t1)  t1<t2  etc6  obligation(h, p, s, t2)
The hearer may accept, reject or counter-propose an order (or request). Various inferences
can be made depending on the response of the hearer and the social relationship between the
speaker and the hearer. For instance, if the hearer accepts, and there is no obligation
beforehand or the hearer is willing to (i.e., wants), it can be inferred that the hearer intends
(Rules D7 & D8).
Rule D7 [accept]:
obligation(h, p, s, t1)  accept(h, p, t2)  t1<t2<t3  etc7  intend(h, p, t3)
Rule D8 [willing-accept]:
want(h, p, t1)  accept(h, p, t2)  t1<t2<t3  etc8  intend(h, p, t3)
If there is no clear evidence of an agents willingness, yet the agent accepts the obl igation,
there is evidence of coercion (Rule D9). In another case, if an agent is obviously unwilling to
(i.e., unintended) but accepts the obligation, there is clear evidence of coercion (Rule D10).
Rule D9 [accept-obligation]:

9

This is similar to the notation used in the work of Hobbs, Stickel, Appelt, and Martin (1993). It essentially means that
there is no contradictory belief in between.
236

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
(t1)(t1<t3  intend(h, p, t1))  obligation(h, p, s, t2)  accept(h, p, t3)  t2<t3<t4  etc9
 coerce(s, h, p, t4)
Rule D10 [unwilling-accept-obligation]:
intend(h, p, t1)  obligation(h, p, s, t2)  accept(h, p, t3)  t1<t3  t2<t3<t4  etc10 
coerce(s, h, p, t4)
If the hearer rejects, infer that the hearer does not intend (Rule D11). If the hearer counters A
and proposes B instead, both the speaker and the hearer are believed to know that A and B are
alternatives (Rules D12 & D13). It also implies what the hearer wants and does not intend (Rules
D14 & D15).
Rule D11 [reject]:
reject(h, p, t1)  t1<t2  etc11  intend(h, p, t2)
Rule D12 [counter-propose]:
counter-propose(h, A, B, s, t1)  t1<t2  etc12  know(h, alternative(A, B), t2)
Rule D13 [counter-propose-grounded]:
counter-propose(h, A, B, s, t1)  t1<t2  etc13  know(s, alternative(A, B), t2)
Rule D14 [counter-propose]:
counter-propose(h, p, q, s, t1)  t1<t2  etc14  intend(h, p, t2)
Rule D15 [counter-propose]:
counter-propose(h, p, q, s, t1)  t1<t2  etc15  want(h, q, t2)
If the speaker has known the alternatives and still requests (or orders) one of them, infer that
the speaker wants (or intends) the chosen action and does not intend the alternative (Rules D16 &
D17). (Here z can be s or h.)
Rule D16 [know-alternative-request]:
know(s, alternative(A, B), t1)  request(s, h, do(z, A), t2)  t1<t2<t3  etc16  intend(s, do(z,
B), t3)
Rule D17 [know-alternative-order]:
know(s, alternative(A, B), t1)  order(s, h, A, t2)  t1<t2<t3  etc17  intend(s, do(h, B), t3)
4.2.2 C AUS AL I NFE R E NC E
Plan representation gives further information for inferring agency, intention and coercion, in
both direct and indirect cases. Causal inference is a plan-based evaluation based on the causal
information provided by plan representation.
Agency. In a plan execution environment where multiple agents inhabit, agents plans can
interact in various ways. The preconditions of an agents action may be established by the
activities of other agents, and thus these other agents indirectly help cause the outcome. Given
the domain theory DT, observed executed actions and an outcome e, the performer of an action A
that directly causes e is the causal agent (Rule C1). Other performers of relevant actions to
achieve e have indirect agency (Rule C2). In the absence of coercion, causal agent is deemed
responsible for e, while other agents assist causing e should share responsibility with this causal
agent. (The computation of relevant actions and effects to achieve e is given in Appendix A.)
Rule C1 [cause-action-effect]:
execute(x, A, t1)  eeffect(A)  occur(e, t2)  t1<t2<t3  etc18  cause(x, e, t3)
237

fiMAO & GRATCH
Rule C2 [cause-relevant-effect]:
cause(y, e, t1)  erelevant-effect(e, DT)  cause(x, e, t2)  t1<t2<t3  etc19  assistcause(y, x, e, t3)
Intention. Attribution of intention is essential to peoples explanations of behavior (Heider, 1958;
Malle & Knobe, 1997). As we have discussed in Section 4.2.1, intentions can be inferred from
evidence in natural language conversation. Causal inference helps infer outcome intention from
evidence of act intention. For example, if an agent intends an action A voluntarily, the agent must
intend at least one action effect of A (Rule C3).
Rule C3 [intend-action]:
intend(x, do(z, A), t1)  (y)coerce(y, x, A, t1)  t1<t2  etc20  e(eeffect(A)  intend(x,
e, t2))
In more general cases, when an action has multiple effects, in order to identify whether a
specific outcome is intended or not, a perceiver may examine action alternatives the agent
intends and does not intend, and compare the effects of intended and unintended alternatives.
If an agent intends an action A voluntarily and does not intend its alternative B, we can infer
that the agent either intends (at least) one action effect that only occurs in A or does not intend
(at least) one effect that only occurs in B, or both. If the effect set of A is a subset of that of B,
or if the effect set of B is a subset of that of A, they can be further simplified (Rules C4 & C5).
Rule C4 [intend-one-alternative]:
intend(x, do(z, A), t1)  intend(x, do(z, B), t1)  (y)coerce(y, x, A, t1)  alternative(A, B) 
effect(A)effect(B)  t1<t2  etc21  e(eeffect(A)  eeffect(B)  intend(x, e, t2))
Rule C5 [intend-one-alternative]:
intend(x, do(z, A), t1)  intend(x, do(z, B), t1)  (y)coerce(y, x, A, t1)  alternative(A, B) 
effect(B)effect(A)  t1<t2  etc22  e(eeffect(A)  eeffect(B)  intend(x, e, t2))
If there is no clear belief of intention derived from causal and dialogue inferences, we can
employ intention recognition as a general approach to detecting intentions. Given the observed
executed actions of agent(s) and a plan library, if the observed action sequence matches the
actions in a primitive plan, then we can certainly infer that the primitive plan is pursued by the
agent(s). In most situations, however, the observed action sequence can only partially match a
specific plan. To find a hypothesized plan that best explains the observed actions, most intention
recognition algorithms use probabilistic models for the inference. We have developed a general
intention recognition algorithm based on probabilistic plan inference (Mao, Gratch, & Li, in
press). Our algorithm recursively uses causal information in the plan representation to
compute the best candidate plan. Here we provide the criteria for determining intended actions
and effects.
If an agent intends a certain plan to achieve the goal of the plan, then the agent should
intend those actions and effects that are relevant to achieving the goal in the plan context
(Rules C6 & C7). The goal itself should be intended by definition. Other side effects are not
intended by the agent (Rule C8). (The computation of relevant actions and effects as well as
side effects in the plan context is given in Appendix A.)
Rule C6 [intend-plan]:
intend(x, by(plan, goal), t1)  Arelevant-action(goal, plan)  t1<t2  etc23  intend(x, A, t2)
238

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
Rule C7 [intend-plan]:
intend(x, by(plan, goal), t1)  erelevant-effect(goal, plan)  t1<t2  etc24  intend(x, e, t2)
Rule C8 [intend-plan]:
intend(x, by(plan, goal), t1)  eside-effect(goal, plan)  t1<t2  etc25  intend(x, e, t2)
Foreknowledge. As foreknowledge belongs to an agents epistemic state, it is mainly derived
from dialogue inference. Speech act such as inform or tell, gives the evidence that the
conversants know the content of the act. Intention recognition also helps infer an agents
foreknowledge, as intention entails foreknowledge: if an agent intends an action A to achieve an
effect e of A, then the agent must know that A brings about e (Rule C9).
Rule C9 [intent-foreknowledge-relation]:
intend(x, by(A, e), t1)  t1<t2  etc26  know(x, bring-about(A, e), t2)
In addition, an agent should know what her action would bring about, if the action and its
effects are general knowledge in the plan representation and the perceiver does not have
contradictory belief of the specific knowledge the involved agents have (Rules C10 & C11).
Rule C10 [foreknowledge-performer]:
eeffect(A)  etc27  know(performer(A), bring-about(A, e), t1)
Rule C11 [foreknowledge-authority]:
eeffect(A)  etc28  know(authority(A), bring-about(A, e), t1)
Coercion. A causal agent could be absolved of responsibility if she was coerced to cause some
outcome by other forces. But just applying coercive force does not mean outcome coercion
actually occurs. What really matters is whether this force truly constrains the causal agents
freedom to avoid the outcome. Causal inference helps infer outcome coercion from evidence
of act coercion.
If an agent is coerced to execute a primitive action, the agent is also coerced to achieve all
the action effects (Rule C12). If being coerced to execute an abstract action and the action has
only one decomposition (i.e., non-decision node), then the agent is also coerced to execute the
subsequent actions and achieve all the subaction effects (Rules C13 & C14).
Rule C12 [coerce-primitive]:
coerce(y, x, A, t1)  primitive(A)  eeffect(A)  t1<t2  etc29  coerce(y, x, e, t2)
Rule C13 [coerce-non-decision-node]:
coerce(y, x, A, t1)  and-node(A)  Bsubaction(A)  t1<t2  etc30  coerce(y, x, B, t2)
Rule C14 [coerce-non-decision-node]:
coerce(y, x, A, t1)  and-node(A)  eeffect(A)  t1<t2  etc31  coerce(y, x, e, t2)
If the coerced action has multiple decompositions (i.e., decision node), then the subsequent
actions are not coerced (Rule 15). Since the agent has options, only the effects that appear in
all alternatives are unavoidable (i.e., definite), and thus these effects are coerced (Rule 16);
Other effects that only appear in some (but not all) alternatives are avoidable (i.e., indefinite),
so they are not coerced (Rule 17). (The computation of definite and indefinite effects is given
in Appendix B.)
Rule C15 [coerce-decision-node]:
coerce(y, x, A, t1)  or-node(A)  Bchoice(A)  t1<t2  etc32  coerce(y, x, B, t2)
239

fiMAO & GRATCH
Rule C16 [coerce-decision-node]:
coerce(y, x, A, t1)  or-node(A)  eeffect(A)  t1<t2  etc33  coerce(y, x, e, t2)
Rule C17 [coerce-decision-node]:
coerce(y, x, A, t1)  or-node(A)  eindefinite-effect(A)  t1<t2  etc34  coerce(y, x, e,
t2)
Given a conditional effect is coerced, if its antecedents are initially true, its consequent is also
coerced (Rule C18). Otherwise, if its antecedents are false initially, then the consequent is not
coerced (Rule C19). If the antecedents are established by self (i.e., the performer), then the
consequent is not coerced, as she could choose to do otherwise (Rule C20). If some other agent(s)
establish the antecedents, then these other agents assist coercing the consequent (Rule C21).
An agent can be indirectly coerced (e.g., by enabling/disabling action preconditions, or
blocking other action alternatives). If among the choices of the coerced action, there is only one
executable alternative available or the coerced agent can enable only one alternative (i.e., by
making action preconditions true), then the agent is coerced to execute the only alternative (Rules
C22 & C23). If the only available alternative is enabled by some other agent(s), then these other
agents assist coercing the only alternative (Rule C24). If some other agent(s) block other action
alternatives (by disabling action preconditions), then the only alternative left is coerced and these
blocking agents are also coercers (Rule C25).
Coercion entails intention. Handing over ones wallet under the threat of your money or your
life may well be seen as intentional: one decides to do so, albeit unwillingly, with the goal of
saving life.
Rule C26 [coerce-intend-relation]:
coerce(y, x, p, t1)  t1<t2  etc43  intend(x, p, t2)
The complete inference rules are given in Appendix C.
4.3 Attribution Algorithm
The beliefs derived from dialogue and causal inferences are used in the attribution process to
form an overall judgment. Different perceivers may have different observations, different
knowledge and preferences, thus they may form different beliefs and judge the same situation
differently. Despite individual differences, the posited attribution process is general, and
applies uniformly to different perceivers. If an action performed by an agent brings about a
positive or negative effect, and the agent is not coerced to achieve the action effect, then the
performer of the action is the primary responsible agent. Other agents who indirectly assist the
performer are the secondary responsible agents. In the presence of external coercion, the
primary responsible agent is redirected to the coercer (Note that coercion may occur in more
than one level of action hierarchy, and so the process may need to trace several levels up to
find the ultimate source of responsibility). Other agents who indirectly assist the coercer are
the secondary responsible agents. They should share responsibility with the primary
responsible agent.
We have developed an algorithm to find the responsible agent(s) for a specific outcome
(consequence e). First, based on the speech act (SA) sequence, the algorithm infers from
dialogue evidence (Step 1). Then it applies causal inference rules (Step 2). For each executed
240

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
action that potentially leads to the consequence, if the action does cause the outcome occurrence
or the performer of the action intends to bring the outcome about (i.e. failed attempt) (Step 3.1),
then assign the performer to the primary responsible agent. Other agents who assist the
performer (by enabling action preconditions) are secondary responsible agents (Step 3.2). To
trace the coercing agent(s), the evaluation process starts from the primitive action (Step 3.3),
and works up the action hierarchy (Step 3.4). During each pass through the main loop, if there
is evidence of outcome coercion (Step 3.4.2), the authority is deemed responsible (Step 3.4.3).
If current action is not the root node in action hierarchy and outcome coercion is true, the
algorithm assigns the parent node to current action (Step 3.4.4) and evaluates the next level up.
If the outcome is intended by the responsible agent (Step 3.5), the degree of responsibility is high
(Step 3.6). If the outcome is not intended (Step 3.7), then the degree assigned is low (Step 3.8).
Otherwise, assign medium degree of responsibility (Step 3.9). At last, the algorithm returns the
primary and secondary responsible agents as well as the degrees of responsibility (Step 4).
Attribution Algorithm (SA sequence S, domain theory DT, consequence e, observations):
1. Based on the speech act sequence S, apply dialog inference rules
2. Based on DT in the plan representation, apply causal inference rules
3. FOR each executed action A in observations
3.1
IF cause(performer(A), e) OR intend(performer(A), by(A, e)) THEN
3.2
primary-responsible(e) = performer(A)
secondary-responsible(e) = performer(relevant-action(e, DT))
3.3
P=A
3.4
DO
3.4.1
B=P
3.4.2
IF coerce(authority(B), performer(B), e) THEN
3.4.3
primary-responsible(e) = authority(B)
3.4.4
P = parent of node B in DT
END-IF
WHILE B  root of action hierarchy AND coerce(authority(B), performer(B), e)
3.5
IF intend(primary-responsible(e), e) THEN
3.6
Assign high degree of responsibility
3.7
ELSE IF intend(primary-responsible(e), e) THEN
3.8
Assign low degree of responsibility
3.9
ELSE assign medium degree of responsibility
END-IF
END-FOR
4. RETURN primary-responsible(e)  secondary-responsible(e); Degrees of responsibility
We adopted the categorical model of responsibility assignment. If the outcome is intended
by the responsible agent, the degree of responsibility is high (Recall that as long as it manifests
intentions, a failed attempt can be blamed or credited almost the same as a successful one). If the
outcome is not intended by the responsible agent, then the degree of responsibility is low.
Otherwise, if there is no clear evidence of outcome intention, assign medium degree of
responsibility. The intensity of credit or blame is computed by multiplying the degree of
responsibility and the utility of the outcome. Events may lead to more than one
desirable/undesirable outcomes. For evaluating multiple outcomes, we apply the algorithm the
241

fiMAO & GRATCH
same way, focusing on one outcome each time during its execution. Finally, to form an overall
judgment, the results are aggregated and grouped by the responsible agents.
4.4 Illustrative Example
We use an example from the Mission Rehearsal Exercise (MRE) leadership training system
(Swartout et al., 2006) to illustrate how the model works. In the MRE system, a human trainee
can practice decision making skills through interactions with virtual autonomous agents. To
train students in high-stake social situations, these virtual agents not only have figures that
resemble humans, they should also make sense of the perceived social events and exhibit
human-like social reasoning ability. The training scenario opens with a lieutenant (played by
the student), who lead a troop of soldiers to fulfill a peacekeeping mission. On his way to
reinforce another unit, one of the troops vehicles has seriously injured a civilian boy. The
boys mother and a medic are in the accident area, and a crowd is gathering around. The
student is faced with the dilemma of whether to continue his mission or to render aid to the
boy. Many decisions are possible, and each decision he makes will lead to different outcomes
as the scenario unfolds. Here the important question for our work is that when some good or
bad outcomes occur, how to ensure the agents make reasonable judgments and react like
people in such social situations.
In one training exercise, for example, the student (i.e. lieutenant) decided to split his forces.
He ordered his sergeant (acted by an autonomous agent) to send half of his squads to assist
another unit. The sergeant informed of the bad consequence and tried to negotiate for a better
alternative. However, the student persisted with his decision, and finally, the sergeant ordered
the squad leader (Lopez) to perform the act. Three social actors are involved in this example.
The lieutenant acts as an authority over the sergeant. The squad leader acts as a subordinate of
the sergeant. The following dialogue is extracted from an actual run of the system. Below we
illustrate how to attribute responsibility and blame based on the causal knowledge and
observations of agents.
Student:
Sergeant:
Student:
Sergeant:
Lopez:

Sergeant, send two squads forward. (Line 1)
That is a bad idea, sir. We shouldnt split our forces. (Line 2) Instead we
should send one squad to recon forward. (Line 3)
Send two squads forward. (Line 4)
Against my recommendation, sir. (Line 5) Lopez! Send first and fourth squads
to Eagle 1-6s location. (Line 6)
Yes, sir. Squads! Mount up! (Line 7)

Within the MRE system, conversations between agents are represented as speech acts and a
dialogue history is stored. Details on how this negotiation dialogue is automatically generated
and how natural language is mapped into speech acts can be found in the work of Traum and his
colleagues (2003, 2008). The dialogue above corresponds to the following speech acts, ordered
by the time the speakers addressed them. (The symbols lt, sgt and sld stand for the lieutenant,
the sergeant and the squad leader, respectively. t1<t2<<t7.)
Act 1:
Act 2:
Act 3:

order(lt, sgt, do(sgt, send-two-sqds), t1)
(Line 1)
inform(sgt, lt, bring-about(send-two-sqds, unit-fractured), t2)
(Line 2)
counter-propose(sgt, do(sgt, send-two-sqds), do(sgt, send-one-sqd), lt, t3) (Line 3)
242

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS

Act 4:
Act 5:
Act 6:
Act 7:

order(lt, sgt, do(sgt, send-two-sqds), t4)
accept(sgt, do(sgt, send-two-sqds), t5)
order(sgt, sld, do(sld, two-sqds-fwd), t6)
accept(sld, do(sld, two-sqds-fwd), t7)

(Line
(Line
(Line
(Line

4)
5)
6)
7)

Figure 3 illustrates the causal knowledge of the troop underlying the example. Take the
sergeants perspective as an example. The sergeant has access to the partial plan knowledge of
the troop, and perceives the conversation between the actors and task execution. He observed a
physical action two-squads-forward executed by the squad leader and the occurrence of action
effects. Two effects are salient to the sergeant, (unit) 1-6 supported and unit fractured.
Supporting unit 1-6 is a desirable team goal. Assume unit fractured is undesirable to the
sergeant and so he assigns negative utility to it. This consequence serves as input of the
algorithm.
Step 1. Based on sequence 1-7 in the dialogue history, the sergeant can derive a number of
beliefs by inferring the observed speech acts (Here t1<t1<t2<t2<<t7<t7):
Belief 1:
Belief 2:
Belief 3:
Belief 4:
Belief 5:
Belief 6:
Belief 7:
Belief 8:
Belief 9:
Belief 10:
Belief 11:
Belief 12:
Belief 13:

intend(lt, do(sgt, send-two-sqds), t1)
(Act 1, Rule D5)
obligation(sgt, do(sgt, send-two-sqds), lt, t1)
(Act 1, Rule D6)
know(sgt, bring-about(send-two-sqds, unit-fractured), t2)
(Act 2, Rule D1)
know(lt, bring-about(send-two-sqds, unit-fractured), t2)
(Act 2, Rule D2)
know(sgt, alternative(send-two-sqds, send-one-sqd), t3)
(Act 3, Rule D12)
know(lt, alternative(send-two-sqds, send-one-sqd), t3)
(Act 3, Rule D13)
intend(sgt, do(sgt, send-two-sqds), t3)
(Act 3, Rule D14)
want(sgt, do(sgt, send-one-sqd), t3)
(Act 3, Rule D15)
intend(lt, do(sgt, send-one-sqd), t4)
(Act 4, Belief 6, Rule D17)
coerce(lt, sgt, do(sgt, send-two-sqds), t5)
(Act 5, Beliefs 2&7, Rule D10)
intend(sgt, do(sld, two-sqds-fwd), t6)
(Act 6, Rule D5)
obligation(sld, do(sld, two-sqds-fwd), sgt, t6)
(Act 6, Rule D6)
coerce(sgt, sld, do(sld, two-sqds-fwd), t7)
(Act 7, Belief 12, Rule D9)

Step 2. Based on the observations of task execution and the beliefs obtained in Step 1, causal
inference further derives the following beliefs of the sergeant (Here t0 is the initial time,
t0<t0<t1):
Belief 14:
Belief 15:
Belief 16:
Belief 17:
Belief 18:
Belief 19:
Belief 20:
Belief 21:

know(sld, bring-about(two-sqds-fwd, unit-fractured), t0)
(Rule C10)
know(sgt, bring-about(two-sqds-fwd, unit-fractured), t0)
(Rule C11)
intend(lt, unit-fractured, t4)
(Beliefs 1&9, Rule C5)
coerce(lt, sgt, do(sgt, two-sqds-fwd), t5)
(Belief 10, Rule C13)
coerce(lt, sgt, do(sgt, remaining-fwd), t5)
(Belief 10, Rule C13)
coerce(lt, sgt, 1-6-supported, t5)
(Belief 10, Rule C14)
coerce(lt, sgt, unit-fractured, t5)
(Belief 10, Rule C14)
coerce(sgt, sld, unit-fractured, t7)
(Belief 13, Rule C12)

Step 3. Steps 3.13.2: As action two-squads-forward directly causes the evaluated outcome unitfractured, and the action is performed by the squad leader, initially, assign the squad leader to
the responsible agent.

243

fiMAO & GRATCH
Step 3.4: Loop 1: The algorithm starts from the primitive action two-squads-forward. The
sergeant believes that he coerced the squad leader to fracture the unit (Belief 21). The sergeant
also believes that both he and the squad leader should have foreseen the outcome unit-fractured
(Beliefs 14&15). As outcome coercion is true, the sergeant is assigned to the responsible agent.
Since outcome coercion is true and current node is not the root of the action hierarchy, the
algorithm enters next loop.
Loop 2: The action is send-two-squads, performed by the sergeant. The sergeant believes that
the lieutenant coerced him to fracture the unit (Belief 20). The sergeant also believes that the
lieutenant intended unit-fractured (Belief 16). As outcome coercion is true, the lieutenant is
assigned to the responsible agent. Since outcome coercion is true and current node is not the root
of the action hierarchy, the algorithm enters next loop.
Loop 3: The action is support-unit-1-6, performed by the lieutenant. There is no relevant
dialogue act in history, nor is there clear evidence of coercion. As current node is already the
root of the action hierarchy, the algorithm exits the loop.
Steps 3.53.9: As the sergeant believes that the lieutenant intended unit-fractured, the
lieutenant is assigned high degree of responsibility for the outcome.

5. Evaluation
To evaluate our computational framework, we need to assess the consistency between model
predictions and human judgments of social cause, responsibility and blame/credit. In particular,
we need to evaluate the consistency of the models inferential mechanism underlying human
attributions of responsibility and blame/credit  that is, whether our model uses the same sources
of evidence and draws the same intermediate conclusions as people do. Thus, we design an
experiment to test how our model performs in predicting the beliefs of intermediate variables
(including attribution variables and other epistemic variables in the model) and evidence used
for the inference process. We claim that our model predicts human judgments of social
attributions and makes inferences consistent with what most people do in their judgments. As the
alternative computational approaches are incapable of inferring the beliefs of intermediate
variables, we directly compare the predictions of our model with human data.
5.1 Method
Participants and Procedure
The study consisted of 48 subjects that were either computer science graduate students or staff
at the University of Southern California. Their ages range from 20 to 35, and 30 of the subjects
were male. Among them, 12 subjects each completed four scenarios of the survey. Other
subjects each completed two scenarios. The survey was composed of four small scenarios
where the order of the scenarios was randomized across subjects. Each scenario was followed
by a questionnaire, asking questions about the assessments of internal variables including the
characters foreknowledge, desire, intentions, obligation and perceived coercions. In
answering each question, the subjects were asked to mark the (multiple) lines in the scenario
according to which they draw the answer. At the end of each questionnaire, there is a question
asking the subjects to score how much blame the characters deserve in the scenario.
244

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
Materials
As a starting point, we adopt the company program scenario first used in (Knobe, 2003a).
This scenario has received much attention in recent folk psychology and experimental
philosophy research (Jones, 2009). We design three variants of the company program scenario
and the questionnaires following each scenario. The original scenario (Scenario 2), its variants
(Scenarios 1, 3 and 4) and the complete questionnaires are given in Appendix D. For the
convenience of assessing inference rules, descriptions of each scenario are organized into
separate labeled lines of evidence (e.g., E1-E6).
Scenario 2:
E1
E2
E3
E4
E5
E6

The chairman of Beta Corporation is discussing a new program with the vice president of
the corporation.
The vice president says, The new program will help us increase profits,
but according to our investigation report, it will also harm the environment.
The chairman answers, I only want to make as much profit as I can. Start the new
program!
The vice president says, Ok, and executes the new program.
The environment is harmed by the new program.

Figure 4: Company Program Scenario 2
Experimental Design
As our model embodies the theoretical view that people will judge social cause and
responsibility differently based on their perception of the key variables such as intention,
foreknowledge and coercion, a good experimental design is to see how the model performs
when evidence for such judgments is systematically varied. To this end, we take the
description of a single social situation and systematically vary it, using the inference rules of
our model as a guide. For example, if our model suggests that particular evidence supports the
inference of coercion, then an obvious variation would be to add a line to the scenario
encoding such evidence. By exploring the space of inference rules and generating the
scenarios accordingly, we were able to incorporate information needed for different inference
paths and to predict judgment results in a systematic way.
Based on the computational framework introduced in Section 4, the specific information
utilized in the inference process includes those causal knowledge, goal identification, and
observations of speech acts, physical actions and the occurrence of action effects. We encode
the information into each line of the scenarios. The encoded information serves as the models
inputs and provides evidence for the specific inference. For example, in Scenario 1, the
following information is encoded (vp and chm refer to the vice president and the chairman,
respectively):
E1:
E2:
E3:
E4:
E5:
E6:

request(vp, chm, do(vp, new-program), t1)
(speech act)
inform(vp, chm, bring-about(new-program, profit-increase), t2)
(causal knowledge)
inform(vp, chm, bring-about(new-program, env-harm), t2)
(causal knowledge)
accept(chm, do(vp, new-program), t3)
(speech act)
execute(vp, new-program, t4)
(action execution)
occur(env-harm, t5)
(outcome occurrence)
245

fiMAO & GRATCH
We design questions to test beliefs about different variables. Each question corresponds to
the firing of an inference rule. We select to assess most groups of dialogue and causal
inference rules (D1-D17 and C1-C17). Some rules are tested in the virtual training system in
Section 4.4. For dialogue inference, we design questions to test speech acts inform,
request, order, accept, accept-obligation and counter-propose. Know-alternative
is tested in the virtual training scenario. For causal inference, we design questions to test
intend-action, intend-plan, intent-foreknowledge-relation, coerce-primitive and
coerce-decision-node. Intend-one-alternative, foreknowledge and coerce-nondecision-node are tested in the virtual training scenario.
In Scenario 1, we manipulate evidence related to agents foreknowledge of the outcome
(i.e., no foreknowledge). We design questions to test the inference rules for foreseeability
(Question 4, Rule D1), relation of intent and foreknowledge (Question 5, Rule C9), connection
of act and outcome intentions (Question 3, Rule C3), etc. Scenario 2 gives clear evidence of
foreknowledge. The authoritys goal is also stated. Correspondingly, questions are designed to
test rules for intentional action/effect and side effect (Questions 3-4, Rules C7&C8), having
foreknowledge (Question 1, Rule D2), and speech acts. In Scenario 3, we manipulate the
degree of perceived coercion and unwillingness by introducing an alternative course of action
that will not harm the environment and which the vice president prefers. Specifically, we add
one line between E3 and E4 (and all the other lines remain the same as those in Scenario 2).
Questions are designed to test the agents willingness (Question 2, Rules D14&D15) and
perceived coercion (Questions 3-4, Rules D10&C12). In Scenario 4, we manipulate the
characters freedom of choice. We introduce an alternative, but the preference of the vice
president is based on a feature unrelated to the environment and the vice president is allowed
to choose from the options. We design three questions to test other important rules for
coercion (Rules C15-C17).
Model Predictions
For each question in the questionnaire, the models prediction of belief and belief derivation
are given in Appendix E.
5.2 Results
Here we provide the experimental results on assessing inferred beliefs and inference rules.
Question 1

Question 2

Question 3

Question 4

Question 5

Yes

No

Yes

No

Yes

No

Yes

No

Yes

No

0

27

3

29

1

2

28

0





0

30

0

30

0

10

20

22





9

2

28

29

1

21

9

5

25

5

25

Scenario
1

Model



People

30

Scenario
2

Model



People

30

Scenario
3

Model



People

21

Scenario
4

Model



People

21














9

Question 6
Chair

VP

30

3.00

3.73

8

5.63






N/A


5.63

3.23

4.13

5.20




N/A

N/A

Table 1: Model Predictions and Subject Responses for Company Program Scenarios
246

3.77

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
5.2.1 A S S E S S ING I NFE R R E D B E LIE FS
Table 1 summarizes the experimental results. Results for questions 1 to 5 indicate the total
number of subjects that gave a particular answer. For example, for Scenario 1, all thirty
subjects reported that the vice president wanted to start the new program. Question 6 refers to
the amounts of blame attributed to the chairman and the vice president on a scale of 1 (little) to
6 (lots), and the table lists the subjects average reported values. The models predictions are
checked with  in the table. The data show that for most questions, people agree with each
other quite well. But certain disagreements exist on some of the questions.
As our purpose is to assess the models general agreement with people, we measure the
agreement between the model and each subject using the Kappa statistic. The Kappa
coefficient is the de facto standard to evaluate the agreement between raters, which factors out
expected agreement due to chance (Carletta, 1996). The K coefficient is computed as:
K

P( A)  P( E )
1  P( E )

P(A) is the propositional agreement among raters. P(E) is the expected agreement, that is,
the probability that the raters agree by chance. Di Eugenio and Glass (2004) argued that the
computation of K coefficient is sensitive to the skewed distribution of categories (i.e.,
prevalence). In our treatment, we account for prevalence and construct contingency tables for
the calculation, and average the results of Kappa agreement of the models predictions with
each subjects answers. The average Kappa agreement between the model and subjects is
0.732. Based on the scales given by Rietveld and van Hout (1993), 0.6<K<0.8 indicates
substantial agreement. The empirical results show good consistency between the models
generation of intermediate beliefs and human data.
5.2.2 A S S E S S ING I NFE R E NC E R ULE S
In our model, every belief is derived by a specific inference rule, so the answer to a question in
the questionnaires corresponds to the firing of one rule (with the exception of three questions
in the questionnaires designed to test two rules each). As the condition side of each rule is
composed of a set of evidence, to assess the accuracies of the inference rules, we compare the
conditions of each rule with the evidence people use in forming each answer. Accuracy of
each rule is measured using standard confusion matrix (Kohavi & Provost, 1998). For every
subjects evidence choice in each question, we build a confusion matrix to compute the
number of true positive TP (i.e., evidence both the rule and the subject use), true negative TN
(i.e., evidence both the rule and the subject ignore), false positive (i.e., evidence the rule
incorrectly uses), and false negative (i.e., evidence the rule incorrectly ignores).
For each question Qi, the correct selection of evidence by the corresponding rule with
respect to subjects is measured by accuracy (AC), where Ns is the total number of subjects and
Ne is the total number of evidence for Qi.
 (TP( j, Qi)  TN ( j, Qi ))

 AC ( j, Qi )

AC (Qi ) 

jSubjects

Ns



jSubjects

247

Ns  Ne

fiMAO & GRATCH
Table 2 lists the accuracies of the tested rules. The average accuracy of these rules is 0.85.
The empirical results show that the evidence the model uses for inference is consistent with
human data. Thus the first experimental study generally supports our first claim of evaluation:
our model predicts human judgments of social attributions and makes inferences consistent
with what most people do in their judgments.

Scenario 1

Scenario 2

Scenario 3

Scenario 4

Question

Inference Rule

Average Accuracy

1

D3 [Request]

0.76

2

D7 [Accept]

0.96

3

C3 [Intend-Action]

0.85

4

D1 [Inform]

0.94

5

C9 [Intent-Foreknowledge-Relation]

0.91

1

D2 [Inform-Grounded]

0.92

2

D5 [Order]

0.96

3

C7 [Intend-Plan]

0.86

4

C8 [Intend-Plan]

0.70

5

D6 & D9 [Order; Accept-Obligation]

0.84

1

D13 [Counter-Propose-Grounded]

0.94

2

D14 & D15 [Counter-Propose]

0.88

3

D6 & D10 [Order; Unwilling-Accept-Obligation]

0.80

4

C12 [Coerce-Primitive]

0.74

1

C16 [Coerce-Decision-Node]

0.71

2

C15 [Coerce-Decision-Node]

0.84

3

C17 [Coerce-Decision-Node]

0.75

Table 2: Accuracies of Evidence Used by the Inference Rules
5.3 Discussion
Although the experimental results show fairly good consistency between our models predictions
and human data with respect to the inferred beliefs and inference rules, the results above also
reveal several disagreements among the subjects and the accuracies of the evidence used by
several inference rules are relatively lower. Now we briefly discuss the experimental findings
from our first study.
In Scenario 1, the questionnaire specifically queries the perceived desire, foreknowledge and
intentions of the characters. The accuracy of the rule tested in Question 1 is lower than the others
because, in addition to evidence E1, many people chose E2 as well. Post-experiment interviews
with the subjects uncovered that many subjects had assumed that making profits should be
desirable to the vice president (because of his role), and therefore, she should want to start the
new program to increase profits (which is supported by E2).
Scenarios 2 and 3 manipulate the degree of perceived coercion and willingness of the coerced
agent. In Question 4 of Scenario 2, one-third of the subjects think it the chairmans intention to
harm the environment. Whether a side effect is intentional or not is controversial in philosophy, and
other empirical studies show similar results as ours (Nadelhoffer, 2006). Also in Question 5 of
Scenario 2, some subjects think the vice president is not coerced to start the new program by the
chairman, as the evidence is weaker than that in Scenario 3. Half of them referred to evidence E5,
248

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
indicating that they expect the vice president to negotiate with the chairman rather than directly
accept the order.
In the first question of Scenario 3, some subjects think the chairman does not know the
alternative program, though the vice president clearly states this in the scenario. Most of these
subjects (80%) referred to evidence E5, showing that they looked for grounding information. As our
model infers grounded information from conversation, we should have considered this in the
scenario design. In Question 4 of Scenario 3, some subjects seemed reluctant to infer outcome
coercion from evidence of act coercion. Nonetheless, they still assigned high degree of blame to the
chairman.
In Scenario 4, the vice president has some freedom of choice. In Question 1, some subjects think
that the vice president is not coerced to increase profits, for the same reason mentioned earlier. They
think it the vice presidents job to increase profits, so she must be willing to do so. The accuracies
of the inference rules for Question 1 and Question 3 are relatively low. In our model, the evidence
needed for the inference is E3, E4 and E5. Many subjects ignore knowledge E3 and this lowers the
accuracies of the two rules (similar reason for the low accuracies of the rules used in Question 4 of
Scenarios 2&3).
Comparing the blame assignments in Scenarios 2 and 3, it shows that on the one hand, the higher
the degree of coercion, the less blame is assigned to the actor  a result consistent with
psychological findings. On the other hand, even when perceived coercion is not strong, people still
assign high degree of blame to the coercer, as in Scenario 2. In Scenario 4, people assigned more
blame to the vice president, as she could have done otherwise. This result is consistent with
psychological findings (Shaver, 1985). However, people still assigned considerable blame to the
chairman, though it was the vice presidents choice to harm the environment.
5.4 Additional Experiment
In this section, we design an additional experiment to compare the overall judgment results by
our model and the alternative models with human data. In Section 2, we have introduced
Chockler and Halperns (2004) model (abbreviated to C&H model) for responsibility and blame
judgments. In addition to the C&H model, we also compare our model with two simple models.
A simple cause model always assigns responsibility and blame to the actor whose action directly
produces the outcome. This is the approach used by most current intelligent systems. Instead of
picking up the actor, a slightly more sophisticated model captures the intuition that hierarchical
structure is a universal characteristic of human society and organizations and social power
always flows from the top in the organizational structure. A simple authority model can choose
the highest authority as the responsible and blameworthy agent. Below we report our experiment
with human data on the overall judgments and compare our models predictions with the results
by simple cause model, simple authority model and the C&H model.
5.4.1 M E THOD
Participants and Procedure
Twenty-seven subjects participated in the experiment. They were either staffs or graduate
students at the University of Southern California, with ages ranging from 20 to 45, and 14 of the
subjects were female. The subjects were presented with four similar scenarios. Each scenario was
249

fiMAO & GRATCH
followed by a questionnaire, asking questions about the assessments of physical cause,
responsibility, blame and perceived coercion of the characters. The order of the scenarios was
randomly assigned.
Materials
We took as a starting point the firing squad scenario typically used in causality research. For
the convenience of comparing with the related work, we used the original firing squad scenario
in the work of Chockler & Halpern (2004) (Scenario 1), and designed its variants (Scenarios 2, 3
and 4). Each scenario is followed by a questionnaire. The questions in the questionnaires are the
same across scenarios. The original scenario, its variants and the wording of the questions are
given in Appendix F.
Experimental Design
We designed the variants of Scenario 1 to systematically vary the perception of the key variables
such as intention and coercion. In each variant, we manipulate evidence of perceived coercion
and intentions of agents. Scenario 2 extends the example by including an authority - the
commander, who orders the squad to shoot. Scenario 3 further extends the example by presenting
a negotiation dialogue between the commander and the marksmen. The marksmen first reject the
commanders order. The commander insists and orders again. Finally the marksmen accept the
order and shoot at the prisoner. In Scenario 4, the commander still orders, but each marksman has
freedom to choose either using blanks or live bullets before shooting.
Model Predictions
Each alternative approach represents a typical way of handling social causality, responsibility
and blame judgment. Below we give the predictions of our model (abbreviated to M&G model)
and alternative models.
Simple cause model: The simple cause model uses physical causality as a substitute for social
causality. So for each scenario, it predicts the marksman (or marksmen) with bullets as the
responsible and blameworthy agent.
Simple authority model: The simple authority model judges social cause and responsibility
from the top in power hierarchy, and regards the highest authority as being responsible. It assigns
responsibility and blame to the commander in Scenarios 2 to 4.
C&H model: As each marksman is a real cause for the outcome, the C&H model predicts all
marksmen share responsibility and blame in Scenario 1. For the similar reason, in Scenarios 2
and 3, the C&H model predicts both the commander and all marksmen are responsible and
blameworthy. The models prediction of Scenario 4 depends on the context (We shall discuss
more on this later).
M&G model: In Scenario 1, our model predicts the same result as that in the C&H model, but
judges the commander as the sole responsible and blameworthy agent in Scenarios 2 and 3. In
the last scenario, our model assigns responsibility and blame to the marksmen with bullets.
5.4.2 R E S ULTS
In answering the questions, the subjects choose the responsible and blameworthy agents from six
categories. They are marksmen with bullets, all marksmen, commander, commander and
250

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
marksmen with bullets, commander and all marksmen, and none of the above (see Appendix E).
Figure 5 shows the proportion of subjects that attribute blame and responsibility to different
categories of agents, and the corresponding confidence intervals (=0.05) (Rice, 1994). For
example, in scenario 1, three subjects blame the marksman with live bullets in his rifle, 19 blame
all the marksmen and the rest do not blame any of them. The analysis of the sample data and their
confidence intervals show that a small percentage of the population will blame the marksman
with live bullets, a significant majority will blame all the marksmen, and a small percentage
wont blame any, with 0.95 confidence.
Responsibility
Responsibility
100 90

-

80

-

70

-

60

-

50

-

40

-

30

-

20

-

10

-

with bullets

all marksmen

100 -

Blame

90

-

Confidence interval

80

-

70

-

60

-

50

-

40

-

30

-

20

-

10

-

Blame
Confidence interval

commander

none

with bullets
& commander

Scenario 1

all marksmen
& commander

Scenario 2
Responsibility

100 -

Responsibility

Blame

100 -

Blame

Confidence interval

90 -

Confidence interval

90

-

80

-

80 -

70

-

70 -

60

-

60 -

50

-

50 -

40

-

40 -

30

-

30 -

20

-

20 -

10

-

10 -

commander

with bullets
& commander

all marksmen
& commander

with bullets

all marksmen

commander

with bullets
& commander

all marksmen
& commander

Scenario 4

Scenario 3

Figure 5: Proportion of Population Agreement on Responsibility/Blame in Scenarios

Blame

Simple Cause
Model

Simple Authority
Model

Results

Match

Results

Match

Scenario
1

with bullets

no

N/A

no

Scenario
2

with bullets

no

commander

yes

Scenario
3

with bullets

no

commander

yes

Scenario
4

with bullets

yes
(partial)

commander

no

Match

Results

Match

Human
Majority
Agreement

yes

all
marksmen

yes

all marksmen

no

commander

yes

commander

no

commander

yes

commander



with bullets

yes
(partial)

with bullets/
with bullets &
commander

C&H Model
Results
all
marksmen
commander
& all
marksmen
commander
& all
marksmen
context
dependent

M&G Model

Table 3: Comparison of Results by Different Models with Human Data
Table 3 summarizes the results of blame assignment generated by different models, and
compares these results with the dominant proportion (i.e., majority) of human agreement. (In
Scenario 4, however, the dominant proportion overlaps with another category; in this case, if a
251

fiMAO & GRATCH
models prediction falls into the majority category, we regard it as a partial match). The simple
cause model partially matches the human agreement in Scenario 4, but is inconsistent with the
data in Scenarios 1 to 3. The simple authority model matches the human data in Scenarios 2 and
3, but is inconsistent with the data in other scenarios. In general, simple models use invariant
approaches to the judgment problem. Therefore, they are insensitive to the changing social
situations specified in each scenario. The C&H model matches human judgments in Scenario 1.
In the remaining scenarios, the results show that their blame model does not match human data
very well. These empirical findings show that our model approximates human judgments of
responsibility and blame/credit and performs better than other computational approaches.
5.4.3 C OM P AR IS ON

AND

D IS C US S ION

We briefly discuss how our model appraises each scenario and compare our approach with the
C&H model.
Scenario 1. Actions and plans are explicitly represented in our approach. In Scenario 1, each
marksman performs a primitive action, shooting. The action has a conditional effect, with the
antecedent live bullets and the consequent death. All marksmens shooting actions constitute a
team plan squad firing, with the definite (goal) outcome death (Figure 6). The shooting actions
are observed executed, and the outcome death occurs. As all the observed primitive actions of the
marksmen match the team plan, we can certainly infer that the plan is pursued by the squad10 (i.e.,
certain case of intention recognition). The marksmen are believed to intend the actions in the
plan and the plan outcome (i.e. death).
Squad Firing
Performer: squad
Authority: none
AND

Shooting

Shooting

Performer: marksman-1
Authority: none

Performer: marksman-2
Authority: none

Live Bullets

Death

Live Bullets

Death



Shooting
Performer: marksman-10
Authority: none
Live Bullets

Death

Figure 6: Team Plan for the Squad in Scenario 1
The marksman with the bullets is the sole causal agent for the death. This marksman intends
the outcome, and thus deserves high degree of responsibility and blame. As other marksmen with
blanks also intend the actions and the outcome, and shooting actions are observed executed but
the antecedent of the conditional effect is false, their failed attempt can be detected. Therefore,
other marksmen are also blameworthy for their attempt (recall that an unsuccessful attempt can
be blamed or credited almost the same as a successful one, in Section 3).
The C&H model judges responsibility according to the actual cause of the event. As the
marksman with the bullets is the only cause of the death, this marksman has degree of
responsibility 1 for the death and others have degree of responsibility 0. This result is
10

Note that our intention recognition method is generally applied to a plan library and sequences of actions. This
example is oversimplified.
252

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
inconsistent with human data. In determining blame, the C&H model draws the same conclusion
as ours, but their approach is different. They consider each marksmans epistemic state before
action performance (corresponding to foreknowledge). There are 10 situations possible,
depending on who has the bullets. Each marksman is responsible for one situation (in which this
marksman has bullets), with degree of responsibility 1. Given that each situation is equally likely
to happen (i.e., with possibility 1/10), each marksman has degree of blame 1/10.
As there is no notion of intention in their model, the C&H model uses foreknowledge as the
only determinant for blame assignment. This is fine when there is no evidence of foreknowledge,
as no foreknowledge entails no intention (Rule C9). When there is evidence of foreknowledge,
however, the blame assigned is high, even if there is no intention manifested in the case. For
example, in a context different from this example, if a marksman fires the gun by mistake,
without any intention of causing or attempting the death, in the C&H model, this marksman will
be blamed just the same as those who truly have such intention.
Scenarios 2&3. In our model, we take different forms of social interactions into account. The
inference process reasons about beliefs from both causal and dialogue evidence. Figure 7
illustrates the team plan of the squad in Scenarios 2 and 3, where a commander acts as an
authority of the squad.
Squad Firing
Performer: squad
Authority: commander
AND

Shooting

Shooting

Performer: marksman-1
Authority: commander

Performer: marksman-2
Authority: commander

Live Bullets

Death

Live Bullets

Death



Shooting
Performer: marksman-10
Authority: commander
Live Bullets

Death

Figure 7: Team Plan for the Squad in Scenarios 2 and 3
The intermediate beliefs inferred from Scenario 2 are given below. (The symbols cmd, sqd
and mkn stand for the commander, the squad and the marksman with bullets, respectively.
t1<t1<t2<t2.)
(1)
(2)
(3)
(4)
(5)
(6)
(7)

intend(cmd, do(sqd, squad-firing), t1)
obligation(sqd, do(sqd, squad-firing), t1)
intend(cmd, death, t1)
coerce(cmd, sqd, squad-firing, t2)
coerce(cmd, sqd, shooting, t2)
coerce(cmd, sqd, death, t2)
coerce(cmd, mkn, death, t2)

(Act order, Rule D5)
(Act order, Rule D6)
(Belief 1, Rule C3)
(Act accept & Belief 2, Rule D9)
(Belief 4, Rule C13)
(Belief 4, Rule C14)
(Belief 5, Rules C14 & C18)

So in Scenario 2, the marksman causes the death due to coercion. The commander is
responsible for the death. As the commander intends the outcome (Belief 3) and the severity of
the outcome death is high, the commander is assigned high degree of responsibility and blamed
with high intensity.
253

fiMAO & GRATCH
Scenario 3 includes a sequence of negotiation acts. The derived beliefs thus change to the
following (t4<t4):
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)

intend(cmd, do(sqd, squad-firing), t1)
obligation(sqd, do(sqd, squad-firing), t1)
intend(cmd, death, t1)
intend(sqd, do(sqd, squad-firing), t2)
coerce(cmd, sqd, squad-firing, t4)
coerce(cmd, sqd, shooting, t4)
coerce(cmd, sqd, death, t4)
coerce(cmd, mkn, death, t4)

(Act order, Rule D5)
(Act order, Rule D6)
(Belief 1, Rule C3)
(Act reject, Rule D11)
(Act accept & Beliefs 2&4, Rule D10)
(Belief 5, Rule C13)
(Belief 5, Rule C14)
(Belief 6, Rules C14 & C18)

Clearly the marksmen do not intend firing (Belief 4). Scenario 3 shows evidence of strong
coercion. This is also reflected in the data. A greater proportion of subjects regard the
commander as responsible and blameworthy in Scenario 3 than in Scenario 2.
Assume marksman-1 is the one with the live bullets. Using the C&H approach, the outcome is
counterfactually dependent on marksman-1s shooting, so marksman-1s shooting is an actual
cause of the death. Similarly, the commanders order is also an actual cause of the death. Based
on the responsibility definition in the C&H model, both the commander and marksman-1 are
responsible for the death, and each has degree of responsibility 111. In assigning blame, there are
ten situations altogether, and in each situation, the commander has expected responsibility 1, so
the commander is to blame with degree 1. The marksmen each have degree of blame 1/10. Thus
the C&H model appraises that the commander and all marksmen are blameworthy for the
outcome.
The C&H model represents all the relevant events in the scenarios as random variables. Thus,
if we want to model the communicative acts in Scenarios 2 and 3 using their approach, each act
must be represented as a separate variable in their model (or a number of speech acts can be
clumped together and represented as one variable). As conversational dialogue involves flexible
contents and orders of the acts, it is difficult to come up with structural equations and represent
the relationships between the variables. If we ignore some of the communicative acts in between,
intermediate beliefs conveyed by them will be lost.
Scenario 4. Unlike the previous scenarios, in Scenario 4, the bullets are not initially set before
the scenario starts. The marksmen can choose to use either bullets or blanks before shooting.
Firing is still the joint action of the squad, but there is no team plan or common goal for the
squad. As the commander orders the joint action, shooting actions and conditional effects are
coerced. However, as the antecedents are enabled by a self agent (i.e., the marksmen with bullets),
the consequent death is not coerced. The inferred beliefs are as follows.
(1)
(2)
(3)
(4)
11

intend(cmd, do(sqd, squad-firing), t1)
obligation(sqd, do(sqd, squad-firing), t1)
coerce(cmd, sqd, squad-firing, t3)
coerce(cmd, sqd, shooting, t3)

(Act order, Rule D5)
(Act order, Rule D6)
(Act accept & Belief 2, Rule D9)
(Belief 3, Rule C13)

Halpern and Pearl (2005) provide a refined definition of causality, where only the contingencies with allowable
settings are considered. Under this refined definition, the commander is the only responsible agent for the death. But
the results of blame assignment remain the same in each scenario.
254

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
(5) coerce(cmd, mkn, death, t3)

(Belief 4, Rules C14 & C20)

In this case, the commander is not responsible for the outcome, but rather, the marksmen who
choose to use bullets and cause the death are responsible and blameworthy. Figure 5 shows that
in Scenario 4, peoples judgments somehow diffuse. There is an overlap between blaming the
marksmen with bullets and blaming both the commander and the marksmen with bullets.
Nonetheless, the category our model predicts is clearly better than the other three.
The C&H model requires all the structural equations to be deterministic. In essence, their
model could not handle alternative courses of action, which inherently have nondeterministic
properties. One remedy for this is to push the nondeterminism into the setting of the context (see
Section 2 for the explanation of context). For example, in Scenario 4, they could build a causal
model to let the context determine whether the bullets are live or blank for each marksman, and
then have a probability distribution over contexts. After that, they can compute the probability of
an actual cause. However, since these contexts are treated as background variables whose values
are assigned by the modeler, their approach could not construct the internal reasoning process to
automate the inference for alternative courses of actions.

6. General Discussion
Based on the well-founded psychological attribution theory, we have built a general
computational model for social causality and responsibility judgment. Our model takes
different forms of social interaction into account and considers both the actions of agents and the
outcomes they produce. We make use of commonsense reasoning to infer beliefs from dialogue
communication and task execution. Our model is based on the general representation commonly
used in intelligent systems. Causal inference is a plan-based evaluation over this representation.
Both the inferences of social attributions and the overall judgments by our model have shown
strong empirical support with respect to human data and in comparison with the alternative
approaches.
Although the examples in this paper have focused on negative consequences and blame
judgment, our model is capable of both credit and blame judgments. Currently we use a uniform
model for these two types of judgments. However, several researchers made a distinction
between them. DArcy (1963) pointed out that the criteria for judging benefit (i.e., credit
assignment) are stricter than those for judging harm (i.e., blame assignment). The empirical
findings in the work of Knobe (2003b) also show credit and blame asymmetry in peoples
judgments of behavior. These findings suggest us to consider using an asymmetry model for
credit and blame assignments in our future extension.
Subjects tended to assign shared blame to the individuals involved. In the firing squad scenario 1,
for example, a portion of the subjects mentioned that they think the marksmen actually make group
decisions together, and so they should be collectively responsible for the outcome. Sometimes this
is true even when the individual is not causally connected to the creditworthy or blameworthy event
(e.g., the chairman is blamed in the company program scenario 1). Some researchers work is
relevant to this. Norman and Reed (2010) provided a logic formalism to account for delegation and
responsibility. Our models representational and inferential mechanism has the potential to
incorporate these extensions.
255

fiMAO & GRATCH
Although attribution theory emphasizes subjective interpretation of events, it is a general theory
of laymans judgment of behavior. We start from the general principles identified by attribution
theory. However, it is also well known that responsibility judgment is influenced by the perceivers
emotional states, interpersonal goals such as impression management (Mele, 2001), and
dispositional differences such as personality. People are notoriously biased when describing their
involvement in creditworthy or blameworthy events (Bradley, 1978). These biases reveal subjective
needs and motivational influence of the perceiver on responsibility judgment. Related work carried
out in our lab has explored the influence of individual difference in the explanation of social
events by modeling different explanatory styles according to agents personalities (Oh, Gratch,
& Woo, 2007).
In this paper, we have focused on the computational modeling of social causality and
responsibility judgment in the context of multi-agent interactions. We produce the first general
computational framework for social causality and responsibility judgment based on
psychological attribution theory. One major contribution of our work is the identification of
commonsense knowledge about the derivation of attributions from inter-agent communication
and task execution. Another contribution of our work is the empirical validation of the model
using human data. By producing the model, we also propose the computational account of
coercion and design the algorithm to describe the attribution process and responsibility judgment.
Because of the interdisciplinary nature of this work, it also takes a first step toward cognitive
modeling of human social intelligence and helps advance our understanding of the process and
principles of human social inference.
For practical applications of this work, we have taken a semi-formal approach and
implemented our model mainly as a production system. Previously, there have been several
versions of implementations and improvements regarding this work. The model was first
implemented within Soar architecture in the context of virtual training environment described
earlier. As in the virtual training system, the model was closely coupled with other system
components using the blackboard representation, and belief update was handled using Soars
JTMS mechanism. We then moved to general-purpose programming language and implemented
the inference engine in Java. The inference engine includes three parts: dialogue reasoner,
intention recognizer and causal reasoner. We implemented dialogue inference rules and most of
the causal inference rules in the model (Rules C22-C25 were not implemented). Intention
recognizer was implemented separately. Our experimental studies were based on the Java
inference engine.
Other implementation and improvement efforts include the extension of the basic model in
interactive environment by exploring different explanatory styles (Oh et al., 2007) and the
improvement of the basic model by adding a model of negligence (Melissen, 2008). Tomai (2009)
took the same attribution variables as ours and extended the basic model using qualitative
process theory. His work translates attribution theorys implications of blame assignment into six
views which impose ordinal constraints on blame assignment.

7. Conclusion
The social nature of computing is pervasive in every aspect of software research and
development. With the advance of computer and communication technologies, social computing
256

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
and intelligent system design will move toward emphasizing social intelligence (Wang et al.,
2007). In this paper, we model a key aspect of social intelligence, by formalizing the underlying
social reasoning process in peoples behavioral judgment. We show how AI knowledge
representation and reasoning methods can be utilized to automate social inference and judgment
process. We also conduct human experiments to empirically validate our proposed model. The
experimental results show that our models predictions of the beliefs about intermediate variables,
inferential mechanism and judgment results are consistent with peoples responses. Therefore,
our proposed model can be generally applied to the modeling of human-like social inference and
behavioral judgment for intelligent entities.

Acknowledgments
We thank Jerry Hobbs, Paul Rosenbloom, Andrew Gordon, David Traum, Stephen Read,
Joseph Halpern, Bernard Weiner and Joshua Knobe for the valuable discussions. This work
was sponsored by the U.S. Army Research, Development, and Engineering Command
(RDECOM), and the content does not necessarily reflect the position or the policy of the
Government, and no official endorsement should be inferred. The work was supported in part
by NNSFC grants #61175040, #71025001, #60921061, #70890084 and #91024030.

Appendix A. Computing Relevant Actions and Effects
Given the domain theory DT, an executed action set and a specific outcome e, the relevant
actions to achieve e contain the following actions:


The action A that causes e is relevant.



The actions that enable a precondition of a relevant action to achieve e are relevant.



If e is enabled by the consequent of a conditional effect of A, the actions that establish an
antecedent of the conditional effect are relevant.



If a precondition of a relevant action is enabled by the consequent of a conditional effect,
the actions that establish an antecedent of the conditional effect are also relevant.

The preconditions of these relevant actions comprise the relevant effects to achieve e. Except
for e, other effects of relevant actions are side effects.
If domain theory DT is confined to those actions, preconditions and effects in a specific plan
(i.e., within the plan context), relevant actions and effects to achieve the goal of the plan can be
derived based on the same computation as given above.

Appendix B. Computing Definite and Indefinite Effects
Let A be an action. If A is an abstract action and has only one decomposition, let ai be a subaction
of A. If A is an abstract action and has multiple decompositions, let ai be a choice of A. The
definite effect set of A is denoted as effect(A), and the indefinite effect set of A is denoted as
indefinite-effect(A).

257

fiMAO & GRATCH
The definite effect set effect(A) is composed of those action effects, which occur in each way
of decomposing A into primitive actions. It is computed recursively as follows:
 If A is a primitive action, effect(A) consists of all its action effects.
effect ( ai )
 If A is an abstract action and has only one decomposition, effect ( A) 
a
isubaction ( A )
effect ( ai )
 If A is an abstract action and has multiple decompositions, effect ( A) 




aichoice ( A)

The indefinite effect set indefinite-effect(A) is composed of those action effects that only
occur in some (but not all) ways of decomposing A into primitive actions. It is computed
recursively as follows:
 If A is a primitive action, indefinite-effect(A) = .
 If A is an abstract action and has only one decomposition,



indefinite  effect ( A) 

indefinite  effect (ai )

aisubaction ( A)

 If A is an abstract action and has multiple decompositions,
indefinite  effect ( A) 



(effect (ai )  indefinite  effect (ai )) 

aichoice ( A)



effect (ai )

aichoice ( A)

Appendix C. Inference Rules
For simplification, all universal quantifies are omitted. Variables x, y and z are different agents.
Let s and h be a speaker and a hearer, p and q be propositions, and t, t1, , t4 be time stamps.
Let A, B and C be actions. Variable e is a state, denoting an action precondition, an effect, an
antecedent or a consequent of a conditional effect. All the rules are from a perceiving agents
perspective.
Dialogue Inference Rules
D1 [inform]:
inform(s, h, p, t1)  t1<t2  etc1  know(s, p, t2)
D2 [inform-grounded]:
inform(s, h, p, t1)  t1<t2  etc2  know(h, p, t2)
D3 [request]:
request(s, h, p, t1)  t1<t2  etc3  want(s, p, t2)
D4 [superior-request]:
request(s, h, p, t1)  superior(s, h)  t1<t2  etc4  obligation(h, p, s, t2)
D5 [order]:
order(s, h, p, t1)  t1<t2  etc5  intend(s, p, t2)
D6 [order]:
order(s, h, p, t1)  t1<t2  etc6  obligation(h, p, s, t2)
D7 [accept]:
258

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
obligation(h, p, s, t1)  accept(h, p, t2)  t1<t2<t3  etc7  intend(h, p, t3)
D8 [willing-accept]:
want(h, p, t1)  accept(h, p, t2)  t1<t2<t3  etc8  intend(h, p, t3)
D9 [accept-obligation]:
(t1)(t1<t3  intend(h, p, t1))  obligation(h, p, s, t2)  accept(h, p, t3)  t2<t3<t4  etc9 
coerce(s, h, p, t4)
D10 [unwilling-accept-obligation]:
intend(h, p, t1)  obligation(h, p, s, t2)  accept(h, p, t3)  t1<t3  t2<t3<t4  etc10  coerce(s,
h, p, t4)
D11 [reject]:
reject(h, p, t1)  t1<t2  etc11  intend(h, p, t2)
D12 [counter-propose]:
counter-propose(h, A, B, s, t1)  t1<t2  etc12  know(h, alternative(A, B), t2)
D13 [counter-propose-grounded]:
counter-propose(h, A, B, s, t1)  t1<t2  etc13  know(s, alternative(A, B), t2)
D14 [counter-propose]:
counter-propose(h, p, q, s, t1)  t1<t2  etc14  intend(h, p, t2)
D15 [counter-propose]:
counter-propose(h, p, q, s, t1)  t1<t2  etc15  want(h, q, t2)
D16 [know-alternative-request]:
know(s, alternative(A, B), t1)  request(s, h, do(z, A), t2)  t1<t2<t3  etc16  intend(s, do(z, B),
t3)
D17 [know-alternative-order]:
know(s, alternative(A, B), t1)  order(s, h, A, t2)  t1<t2<t3  etc17  intend(s, do(h, B), t3)
Causal Inference Rules
C1 [cause-action-effect]:
execute(x, A, t1)  eeffect(A)  occur(e, t2)  t1<t2<t3  etc18  cause(x, e, t3)
C2 [cause-relevant-effect]:
cause(y, e, t1)  erelevant-effect(e, DT)  cause(x, e, t2)  t1<t2<t3  etc19  assist-cause(y,
x, e, t3)
C3 [intend-action]:
intend(x, do(z, A), t1)  (y)coerce(y, x, A, t1)  t1<t2  etc20  e(eeffect(A)  intend(x, e,
t2))
C4 [intend-one-alternative]:
intend(x, do(z, A), t1)  intend(x, do(z, B), t1)  (y)coerce(y, x, A, t1)  alternative(A, B) 
effect(A)effect(B)  t1<t2  etc21  e(eeffect(A)  eeffect(B)  intend(x, e, t2))
C5 [intend-one-alternative]:
259

fiMAO & GRATCH
intend(x, do(z, A), t1)  intend(x, do(z, B), t1)  (y)coerce(y, x, A, t1)  alternative(A, B) 
effect(B)effect(A)  t1<t2  etc22  e(eeffect(A)  eeffect(B)  intend(x, e, t2))
C6 [intend-plan]:
intend(x, by(plan, goal), t1)  Arelevant-action(goal, plan)  t1<t2  etc23  intend(x, A, t2)
C7 [intend-plan]:
intend(x, by(plan, goal), t1)  erelevant-effect(goal, plan)  t1<t2  etc24  intend(x, e, t2)
C8 [intend-plan]:
intend(x, by(plan, goal), t1)  eside-effect(goal, plan)  t1<t2  etc25  intend(x, e, t2)
C9 [intent-foreknowledge-relation]:
intend(x, by(A, e), t1)  t1<t2  etc26  know(x, bring-about(A, e), t2)
C10 [foreknowledge-performer]:
eeffect(A)  etc27  know(performer(A), bring-about(A, e), t)
C11 [foreknowledge-authority]:
eeffect(A)  etc28  know(authority(A), bring-about(A, e), t)
C12 [coerce-primitive]:
coerce(y, x, A, t1)  primitive(A)  eeffect(A)  t1<t2  etc29  coerce(y, x, e, t2)
C13 [coerce-non-decision-node]:
coerce(y, x, A, t1)  and-node(A)  Bsubaction(A)  t1<t2  etc30  coerce(y, x, B, t2)
C14 [coerce-non-decision-node]:
coerce(y, x, A, t1)  and-node(A)  eeffect(A)  t1<t2  etc31  coerce(y, x, e, t2)
C15 [coerce-decision-node]:
coerce(y, x, A, t1)  or-node(A)  Bchoice(A)  t1<t2  etc32  coerce(y, x, B, t2)
C16 [coerce-decision-node]:
coerce(y, x, A, t1)  or-node(A)  eeffect(A)  t1<t2  etc33  coerce(y, x, e, t2)
C17 [coerce-decision-node]:
coerce(y, x, A, t1)  or-node(A)  eindefinite-effect(A)  t1<t2  etc34  coerce(y, x, e, t2)
C18 [coerce-conditional-effect-initial-antecedent-true]:
econditional-effect(A)  true(antecedent(e), t1)  coerce(y, x, e, t2)  t1<t2<t3  etc35 
coerce(y, x, consequent(e), t3)
C19 [coerce-conditional-effect-initial-antecedent-false]:
econditional-effect(A)  true(antecedent(e), t1)  coerce(y, x, e, t2)  t1<t2<t3  etc36 
coerce(y, x, consequent(e), t3)
C20 [coerce-conditional-effect-self-establish-antecedent]:
econditional-effect(A)  coerce(y, x, e, t1)  enable(x, antecedent(e), t2)  t1<t2<t3  etc37 
coerce(y, x, consequent(e), t3)
C21 [coerce-conditional-effect-other-establish-antecedent]:
econditional-effect(A)  coerce(y, x, e, t1)  enable(z, antecedent(e), t2)  can-enable(x,
antecedent(e), t2)  t1<t2<t3  etc38  coerce(yz, x, consequent(e), t3)
260

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
C22 [coerce-decision-node-initial-one-alternative]:
Achoice(C)  true(precondition(A), t1)  (Bchoice(C)BA  true(precondition(B), t1)
can-enable(x, precondition(B), t1))  coerce(y, x, C, t2)  t1<t2<t3  etc39  coerce(y, x, A, t3)
C23 [coerce-decision-node-self-enable-alternative]:
coerce(y, x, C, t1)  Achoice(C)  enable(x, precondition(A), t2)  (Bchoice(C)BA 
true(precondition(B), t2)can-enable(x, precondition(B), t2))  t1<t2<t3  etc40  coerce(y, x,
A, t3)
C24 [coerce-decision-node-other-enable-alternative]:
coerce(y, x, C, t1)  Achoice(C)  enable(z, precondition(A), t2)  (Bchoice(C)BA 
true(precondition(B), t2)can-enable(x, precondition(B), t2))  t1<t2<t3  etc41  coerce(yz,
x, A, t3)
C25 [coerce-decision-node-disable-other-alternative]:
coerce(y, x, C, t1)  Achoice(C)  true(precondition(A), t2)  (Bchoice(C)BA  enable(z,
precondition(B), t3)can-enable(x, precondition(B), t3))  t1<t3<t4  t2<t4  etc42 
coerce(yz, x, A, t4)
C26 [coerce-intend-relation]:
coerce(y, x, p, t1)  t1<t2  etc43  intend(x, p, t2)

Appendix D. Company Program Scenarios
Scenario 1:
E1
E2
E3
E4
E5
E6

The vice president of Beta Corporation goes to the chairman of the board and requests,
Can we start a new program?
The vice president continues, The new program will help us increase profits,
and according to our investigation report, it has no harm to the environment.
The chairman answers, Very well.
The vice president executes the new program.
However, the environment is harmed by the new program.

Questions:
1. Does the vice president want to start the new program?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

E4

E5

E6

2. Does the chairman intend to start the new program?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4
High

Based on which information (circle all that apply)?

E1

261

fiMAO & GRATCH
3. Is it the chairmans intention to increase profits?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

4. Does the vice president know that the new program will harm the environment?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

5. Is it the vice presidents intention to harm the environment by starting the new program?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

6. How much would you blame the individuals for harming the environment?
Blame the chairman:
Blame the vice president: 1

1
2

2
3

3
4

4
5

5
6

Little

6
Lots

Scenario 2:
E1
E2
E3
E4
E5
E6

The chairman of Beta Corporation is discussing a new program with the vice president of
the corporation.
The vice president says, The new program will help us increase profits,
but according to our investigation report, it will also harm the environment.
The chairman answers, I only want to make as much profit as I can. Start the new
program!
The vice president says, Ok, and executes the new program.
The environment is harmed by the new program.

Questions:
1. Does the chairman know that the new program will harm the environment?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

E4

E5

E6

2. Does the chairman intend to start the new program?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4
High

Based on which information (circle all that apply)?

E1

3. Is it the chairmans intention to increase profits?
262

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS

Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

E4

E5

E6

4. Is it the chairmans intention to harm the environment?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

5. Is the vice president coerced to start the new program (i.e. by the obligation of obeying the
chairman)?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

6. How much would you blame the individuals for harming the environment?
Blame the chairman:
Blame the vice president: 1

1
2

2
3

3
4

4
5

5
6

6

Little

Lots

Scenario 3:
E1
E2
E3
E4
E5
E6
E7

The chairman of Beta Corporation is discussing a new program with the vice president of
the corporation.
The vice president says, The new program will help us increase profits,
but according to our investigation report, it will also harm the environment.
Instead, we should run an alternative program, that will gain us fewer profits than this
new program, but it has no harm to the environment.
The chairman answers, I only want to make as much profit as I can. Start the new
program!
The vice president says, Ok, and executes the new program.
The environment is harmed by the new program.

Questions:
1. Does the chairman know the alternative of the new program?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

High

Based on which information (circle all that apply)?

E1

E2

E3

E4

E5

E6

E7

E5

E6

E7

2. Which program is the vice president willing to start?
Your answer:
Your confidence:

1

New program
2
3

Low

Based on which information (circle all that apply)?

Alternative program
4
5
6
High

E1
263

E2

E3

E4

fiMAO & GRATCH
3. Is the vice president coerced to start the new program?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

High

Based on which information (circle all that apply)?

E1

E2

E3

E4

E5

E6

E7

E4

E5

E6

E7

4. Is the vice president coerced to harm the environment?
Your answer:
Your confidence:

1

Yes
2

3

Low

No
4

5

6

High

Based on which information (circle all that apply)?

E1

E2

E3

5. How much would you blame the individuals for harming the environment?
Blame the chairman:
Blame the vice president: 1

1
2

2
3

3
4

4
5

5
6

Little

6
Lots

Scenario 4:
E1
E2
E3
E4
E5
E6

The chairman of Beta Corporation is discussing a new program with the vice president of
the corporation.
The vice president says, There are two ways to run this new program, a simple way and a
complex way.
Both will equally help us increase profits, but according to our investigation report, the
simple way will also harm the environment.
The chairman answers, I only want to make as much profit as I can. Start the new
program either way!
The vice president says, Ok, and chooses the simple way to execute the new program.
The environment is harmed.

Questions:
1. Is the vice president coerced by the chairman to increase profits?
Your answer:
Your confidence:

Yes
1

2

No
3

Low

4

5

6

E2

E3

High

Based on which information (circle all that apply)?

E1

E4

E5

E6

E5

E6

E5

E6

2. Is the vice president coerced by the chairman to choose the simple way?
Your answer:
Your confidence:

Yes
1

2

No
3

Low

4

5

6

High

Based on which information (circle all that apply)?

E1

E2

E3

E4

3. Is the vice president coerced by the chairman to harm the environment?
Your answer:
Your confidence:

Yes
1

2

No
3

Low

Based on which information (circle all that apply)?

4

5

6

E2

E3

High

E1
264

E4

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
4. How much would you blame the individuals for harming the environment?
Blame the chairman:
Blame the vice president: 1

1
2

2
3

3
4

4
5

5
6

Little

6
Lots

Appendix E. Belief Derivation of Company Program Scenarios
The symbols chm and vp refer to the chairman and the vice president, respectively. Time stamps
t1<t1<t2<t2<<t4<t5. The severity of the outcome environmental harm is set to medium.
Scenario 1
Information Encoding:
E1
E2
E3
E4
E5
E6

request(vp, chm, do(vp, new-program), t1)
inform(vp, chm, bring-about(new-program, profit-increase), t2)
inform(vp, chm, bring-about(new-program, env-harm), t2)
accept(chm, do(vp, new-program), t3)
execute(vp, new-program, t4)
env-harmeffect(new-program); occur(env-harm, t5)

Question 1 (Rule D3 [request]):
request(vp, chm, do(vp, new-program), t1)
 want(vp, do(vp, new-program), t1)
Question 2 (Rule D7 [accept]):
accept(chm, do(vp, new-program), t3)
 intend(chm, do(vp, new-program), t3)
Question 3 (Rule C3 [intend-action]):
intend(chm, do(vp, new-program), t3)  coerce(vp, chm, new-program, t3)
 profit-increaseeffect(new-program)  intend(chm, profit-increase, t3)
Question 4 (Rule D1 [inform]):
inform(vp, chm, bring-about(new-program, env-harm), t2)
 know(vp, bring-about(new-program, env-harm), t2)
 know(vp, bring-about(new-program, env-harm), t2)
Question 5 (Rule C9 [intent-foreknowledge-relation]):
know(vp, bring-about(new-program, env-harm), t2)
 intend(vp, by(new-program, env-harm), t2)
Question 6 (Attribution Algorithm):
Primary-responsible agent: vp
Degree of responsibility/Intensity of blame: low
Scenario 2
Information Encoding:
E2

inform(vp, chm, bring-about(new-program, profit-increase), t1)
265

fiMAO & GRATCH
E3
E4
E5
E6

inform(vp, chm, bring-about( new-program, env-harm), t1)
goal(chm, profit-increase); order(chm, vp, do(vp, new-program), t2)
accept(vp, do(vp, new-program), t3); execute(vp, new-program, t3)
occur(env-harm, t4)

Question 1 (Rule D2 [inform-grounded]):
inform(vp, chm, bring-about( new-program, env-harm), t1)
 know(chm, bring-about( new-program, env-harm), t1)
Question 2 (Rule D5 [order]):
order(chm, vp, do(vp, new-program), t2)
 intend(chm, do(vp, new-program), t2)
Question 3 (Rule C7 [intend-plan]):
intend(chm, by(new-program, profit-increase), t2)  profit-increaserelevant-effect(profitincrease, new-program)
 intend(chm, profit-increase, t2)
Question 4 (Rule C8 [intend-plan]):
intend(chm, by(new-program, profit-increase), t2)  env-harmside-effect(profit-increase,
new-program)
 intend(chm, env-harm, t2)
Question 5 (Rules D6 [order] & D9 [accept-obligation]):
order(chm, vp, do(vp, new-program), t2)
 obligation(vp, do(vp, new-program), chm, t2)
obligation(vp, do(vp, new-program), chm, t2)  accept(vp, do(vp, new-program), t3)
 coerce(chm, vp, do(vp, new-program), t3)
Question 6 (Attribution Algorithm):
Primary-responsible agent: chm
Degree of responsibility/Intensity of blame: low
Scenario 3
Information Encoding:
E2
E3
E4
E5
E6
E7

inform(vp, chm, bring-about(new-program, profit-increase), t1)
inform(vp, chm, bring-about( new-program, env-harm), t1)
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
goal(chm, profit-increase); order(chm, vp, do(vp, new-program), t2)
accept(vp, do(vp, new-program), t3); execute(vp, new-program, t3)
occur(env-harm, t4)

Question 1 (Rule D13 [counter-propose-grounded]):
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
 know(chm, alternative(new-program, alternative-program), t1)
Question 2 (Rules D14 & D15 [counter-propose]):
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
 intend(vp, do(vp, new-program), t1)
266

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
 want(vp, do(vp, alternative-program), t1)
Question 3 (Rules D6 [order] & D10 [unwilling-accept-obligation]):
order(chm, vp, do(vp, new-program), t2)
 obligation(vp, do(vp, new-program), chm, t2)
intend(vp, do(vp, new-program), t1)  obligation(vp, do(vp, new-program), chm, t2) 
accept(vp, do(vp, new-program), t3)
 coerce(chm, vp, do(vp, new-program), t3)
Question 4 (Rule C12 [coerce-primitive]):
coerce(chm, vp, do(vp, new-program), t3)  primitive(new-program)  env-harmeffect(newprogram)
 coerce(chm, vp, env-harm, t3)
Question 5 (Attribution Algorithm):
Primary-responsible agent: chm
Degree of responsibility/Intensity of blame: low
Scenario 4
Information Encoding:
E2

E3

E4
E5

E6

inform(vp, chm, or-node(new-program), t1)
inform(vp, chm, simple-waychoice(new-program), t1)
inform(vp, chm, complex-waychoice(new-program,), t1)
inform(vp, chm, bring-about(simple-way, profit-increase), t1)
inform(vp, chm, bring-about(complex-way, profit-increase), t1)
inform(vp, chm, bring-about(simple-way, env-harm), t1)
goal(chm, profit-increase); order(chm, vp, do(vp, new-program), t2)
accept(vp, do(vp, new-program), t3); intend(vp, simple-way, t3); intend(vp, complex-way,
t3);
execute(vp, simple-way, t4)
occur(env-harm, t5)

Question 1 (Rule C16 [coerce-decision-node]):
order(chm, vp, do(vp, new-program), t2)
 obligation(vp, do(vp, new-program), chm, t2)
obligation(vp, do(vp, new-program), chm, t2)  accept(vp, do(vp, new-program), t3)
 coerce(chm, vp, do(vp, new-program), t3)
coerce(chm, vp, do(vp, new-program), t3)  or-node(new-program)  profit-increaseeffect(newprogram)
 coerce(chm, vp, profit-increase, t3)
Question 2 (Rule C15 [coerce-decision-node]):
coerce(chm, vp, do(vp, new-program), t3)  or-node(new-program)  simple-waychoice(newprogram)
 coerce(chm, vp, simple-way, t3)
Question 3 (Rule C17 [coerce-decision-node]):
267

fiMAO & GRATCH
coerce(chm, vp, do(vp, new-program), t3)  or-node(new-program)  env-harmindefiniteeffect(new-program)
 coerce(chm, vp, env-harm, t3)
Question 4 (Attribution Algorithm):
Primary-responsible agent: vp
Degree of responsibility/Intensity of blame: high

Appendix F. Firing Squad Scenarios
Scenario 1
Suppose that there is a firing squad consisting of ten excellent marksmen. Only one of them has
live bullets in his rifle; the rest have blanks. The marksmen do not know which of them has the
live bullets. The marksmen shoot at the prisoner and he dies.
Scenario 2
Suppose that there is a firing squad consisting of a commanding officer and ten excellent
marksmen that generally abide by their leaders commands. Only one of them has live bullets in
his rifle; the rest have blanks. The commanding officer and the marksmen do not know which
marksman has the live bullets. The commander orders the marksmen to shoot the prisoner. The
marksmen shoot at the prisoner and he dies.
Scenario 3
Suppose that there is a firing squad consisting of a commanding officer and ten excellent
marksmen that generally abide by their leaders commands. Only one of them has live bullets in
his rifle; the rest have blanks. The commanding officer and the marksmen do not know which
marksman has the live bullets. The commander orders the marksmen to shoot the prisoner. The
marksmen refuse the order. The commander insists that the marksmen shoot the prisoner. The
marksmen shoot at the prisoner and he dies.
Scenario 4
Suppose that there is a firing squad consisting of a commanding officer and ten excellent
marksmen that generally abide by their leaders commands. The commanding officer orders the
marksman to shoot the prisoner, and each marksman can choose to use either blanks or live
bullets. The commander and the marksmen do not know whether other marksmen have live
bullets. By tradition, if the prisoner lives (i.e., everyone chooses blanks), he is set free. The
marksmen shoot at the prisoner and he dies.
Questions (in Scenario 1, Questions 1-3 only contain selections a and b):
1.

Who physically caused the death?
a) the marksmen who had live bullets in their rifles
b) all the marksmen in the firing squad
c) the commanding officer
d) a) and c)
268

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
e)
f)

everybody
none of the above

2.

Who would you think is responsible for the death?
a) the marksmen who had live bullets in their rifles
b) all the marksmen in the firing squad
c) the commanding officer
d) a) and c)
e) everybody
f) none of the above

3.

Who deserves blame for the death?
a) the marksmen who had live bullets in their rifles
b) all the marksmen in the firing squad
c) the commanding officer
d) a) and c)
e) everybody
f) none of the above

4.

In making your judgment, do you feel the marksmen were coerced?
a) there was strong coercion
b) there was weak coercion
c) there was no coercion

References
Aleven, V., & Ashley, K. D. (1995). Doing Things with Factors. Proceedings of the Fifth International
Conference on Artificial Intelligence and Law.
Allen, J. F., & Perrault, C. R. (1980). Analyzing Intention in Utterances. Artificial Intelligence, 15(3):143178.
Austin, J. (1962). How to Do Things with Words. Harvard University Press.
Blythe, J. (1999). Decision-Theoretic Planning. AI Magazine, 20(2):37-54.
Bradley, G. W. (1978). Self-Serving Biases in the Attribution Process: A Reexamination of the Fact or
Fiction Question. Journal of Personality and Social Psychology, 36(1):56-71.
Bratman, M. E. (1987). Intention, Plans, and Practical Reason. Harvard University Press.
Carletta, J. (1996). Assessing Agreement on Classification Tasks: the Kappa Statistic. Computational
Intelligence, 22(2):249-254.
Cassell, J., Sullivan, J., Prevost, S., & Churchill, E. (Eds.) (2000). Embodied Conversational Agents.
Cambridge University Press.
Castelfranchi, C. (1990). Social Power. Proceedings of the First European Workshop on Modeling
Autonomous Agents in a Multi-Agent World.
Chockler, H., & Halpern, J. Y. (2004). Responsibility and Blame: A Structural-Model Approach. Journal of
Artificial Intelligence Research, 22:93-115.
Clark, H. H., & Schaefer, E. F. (1987). Collaborating on Contributions to Conversation. Language and
Cognitive Processes, 2:1-23,.

269

fiMAO & GRATCH
Cohen, P. R., & Levesque, H. J. (1990). Intention is Choice with Commitment. Artificial Intelligence, 42(23):213-261.
DArcy, E. (1963). Human Acts: An Essay in Their Moral Evaluation. Oxford: Clarendon.
Di Eugenio, B., & Glass, M. (2004). The Kappa Statistic: A second Look. Computational Linguistics,
30(1):95-101.
dInverno, M., Kinny, D., Luck, M., & Wooldridge, M. (1997). A Formal Specification of dMARS. In: M.
P. Singh, A. Rao and M. J. Wooldridge (Eds.). Intelligent Agents IV, pp. 155-176. Springer-Verlag.
Erol, K., Hendler, J., & Nau, D. S. (1994). UMCP: A Sound and Complete Procedure for Hierarchical
Task-Network Planning. Proceedings of the Second International Conference on Artificial Intelligence
Planning Systems.
Ferguson, G., & Allen, J. (2007). Mixed-Initiative Dialogue Systems for Collaborative Problem-Solving. AI
Magazine, 28(2):23-32.
Fikes, R.E., & Nilsson, N. J. (1971). STRIPS: A New Approach to the Application of Theorem Proving to
Problem Solving. Artificial Intelligence, 2(3-4).
Fincham, F. D., & Jaspars, J. M. (1980). Attribution of Responsibility: From Man the Scientist to Man as
Lawyer. In: L. Berkowitz (Ed.). Advances in Experimental Social Psychology (Vol. 13), pp. 81-138.
Academic Press.
Fischer, K., Mueller, J. P., & Pischel, M. (1996). A Pragmatic BDI Architecture. In: M. Wooldridge, J. P.
Mueller and M. Tambe (Eds.). Intelligent Agents II, pp. 203-218. Springer-Verlag.
Georgeff, M. P., & Lansky, A. L. (1987). Reactive Reasoning and Planning. Proceedings of the Sixth
National Conference on Artificial Intelligence.
Gil, Y., Deelman, E., Blythe, J., Kesselman, C., & Tangmurarunkit, H. (2004). Artificial Intelligence and
Grids: Workflow Planning and Beyond. IEEE Intelligent Systems, 19(1):26-33.
Golbeck, J., & Hendler, J. (2006). Inferring Binary Trust Relationships in Web-Based Social Networks,
ACM Transactions on Internet Technology, 6(4):497-529.
Gordon, A., & Hobbs, J. R. (2004). Formalizations of Commonsense Psychology. AI Magazine, 25(4):4962.
Gratch, J., & Mao, W. (2003). Automating After Action Review: Attributing Blame or Credit in Team
Training. Proceedings of the Twelfth Conference on Behavior Representation in Modeling and
Simulation.
Gratch, J., Mao, W., & Marsella, S. (2006). Modeling Social Emotions and Social Attributions. In: R. Sun
(Ed.). Cognition and Multi-Agent Interaction, pp. 219-251. Cambridge University Press.
Gratch, J., Marsella, S., & Petta, P. (2009). Modeling the Antecedents and Consequences of Emotion.
Journal of Cognitive Systems Research, 10(1):1-5.
Grice, H. P. (1975). Logic and Conversation. In: P. Cole and J. Morgan (Eds.). Syntax and Semantics: Vol
3, Speech Acts. Academic Press.
Grosz, B., & Kraus, S. (1996). Collaborative Plans for Complex Group Action. Artificial Intelligence,
86(2):269-357.
Grosz, B. J., & Sidner, C. L. (1986). Attention, Intentions, and the Structure of Discourse. Computational
Linguistics, 12(3):175-204.
Hage, J. C. (1997). Reasoning with Rules: An Essay on Legal Reasoning and Its Underlying logic. Kluwer
Academic Publishers.
Halpern, J. Y., & Pearl, J. (2001). Causes and Explanations: A Structural-Model Approach. Part : Causes.
Proceedings of the Seventeenth Conference in Uncertainty in Artificial Intelligence.
Halpern, J. Y., & Pearl, J. (2005). Causes and Explanations: A Structural-Model Approach. Part : Causes.
British Journal for Philosophy of Science, 56(4):843-887.
270

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
Heider, F. (1958). The Psychology of Interpersonal Relations. John Wiley & Sons Inc.
Hilton, D. J. (1990). Conversational Processes and Causal Explanation. Psychological Bulletin, 107:65-81.
Hobbs, J. R. (1985). Ontological Promiscuity. Proceedings of the Twenty-Third Annual Meeting of the
Association for Computational Linguistics.
Hobbs, J. R., Stickel, M., Appelt, D., & Martin, P. (1993). Interpretation as Abduction. Artificial
Intelligence, 63(1-2):69-142.
Huber, M. J. (1999). JAM: A BDI-Theoretic Mobile Agent Architecture. Proceedings of the Third
International Conference on Autonomous Agents.
Jaimes, A., Sebe, N., & Gatica-Perez, D. (2006). Human-Centered Computing: A Multimedia Perspective.
Proceedings of the Fourteenth Annual ACM International Conference on Multimedia.
Jennings, N. R. (1992). On Being Responsible. In: E. Werner and Y. Demazeau (Eds.). Decentralized A.I.,
pp. 93-102. North Holland Publishers.
Johnson, C., & Gonzalez, A. J. (2008). Automated After Action Review: State-of-the-Art Review and
Trends. The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology.
5(2):108-121.
Jones, D. (2009). The Good, the Bad and the Intentional. The Psychologist, 22(8):666-669, August.
Kant, I. (1998). Groundwork of the metaphysics of morals. Cambridge University Press.
Kidd, R. F., & Amabile, T. M. (1981). Causal Explanations in Social Interaction: Some Dialogues on
Dialogue. In: J. H. Harvey, W. J. Ickes and R. F. Kidd (Eds.). New Directions in Attribution Research
(Vol. 3), pp. 307-328. Lawrence Erlbaum Associates.
Knobe, J. (2003a). Intentional Action and Side-Effects in Ordinary Language. Analysis, 63:190-193.
Knobe, J. (2003b). Intentional Action in Folk Psychology: An Experimental Investigation. Philosophical
Psychology, 16:309-324.
Kohavi, R., & Provost, F. (1998). Glossary of Terms. Machine Learning, 30(2/3):271-274.
Kraus, S., Hoz-Weiss, P., & Wilkenfeld, J. (2008), Resolving Crises through Automated Bilateral
Negotiations. Artificial Intelligence, 172(1).
Litman, D. J., & Allen, J. F. (1990). Discourse Processing and Commonsense Plans. In: P. R. Cohen, J.
Morgan and M. E. Pollack (Eds.), Intentions in Communication, pp.365-388. The MIT Press.
Lochbaum, K. E., Grosz, B. J., & Sidner, C. L. (2000). Discourse Structure and Intention Recognition. In: R.
Dale, H. Moisl and H. Somers (Eds.), Handbook of Natural Language Processing, pp.123-146.
Malle, B. F. (2001). Attribution processes. In N. J. Smelser and P. B. Baltes (Eds.), International
encyclopedia of the social and behavioral sciences Vol. 14, pp. 913-917. Elsevier.
Malle, B. F., & Knobe, J. (1997). The Folk Concept of Intentionality. Journal of Experimental Social
Psychology, 33:101-121.
Mao, W., Gratch, J., & Li, X. (in press). Probabilistic Plan Inference for Group Behavior Prediction. IEEE
Intelligent Systems.
Marinier, R. P., & Laird, J.E. (2004). Towards a Comprehensive Computational Model of Emotions and
Feelings. Proceedings of the Sixth International Conference on Cognitive Modeling.
Marsella, S., & Gratch, J. (2009). EMA: A Process Model of Appraisal Dynamics. Journal of Cognitive
Systems Research, 10(1): 70-90.
Martinovski, B., & Mao, W. (2009). Emotion as an Argumentation Engine: Modeling the Role of Emotion
in Negotiation. Group Decision and Negotiation, 18(3):235-259.
Martinovski, B., Mao, W., Gratch, J., & Marsella, S. (2005). Mitigation Theory: An Integrated Approach.
Proceedings of the Twenty-Seventh Annual Conference of the Cognitive Science Society.

271

fiMAO & GRATCH
McCarty, L. T., & Sridharan, N. S. (1981). The Representation of an Evolving System of Legal Concepts: .
Prototypes and Deformations. Proceedings of the Seventh International Joint Conference on Artificial
Intelligence.
McCarty, L. T. (1995). An Implementation of Eisner v. Macomber. Proceedings of the Fifth International
Conference on Artificial Intelligence and Law.
McCarty, L. T. (1997). Some Arguments about Legal Arguments. Proceedings of the Sixth International
Conference on Artificial Intelligence and Law.
Mele, A. R. (2001). Self-Deception Unmasked. Princeton University Press.
Melissen, A. (2008). Exploring Neglected Avenues in the Modeling of Attribution Theory. Master Thesis,
Department of Human Media Interaction, University of Twente.
Mueller, E. (2006). Commonsense Reasoning. Morgan Kaufmann Publishers.
Nadelhoffer, T. (2006). On Trying to Save the Simple View. Mind & Language, 21(5):565-586, November.
Nau, D. S., Cao, Y., Lotem, A., & Muoz-Avila, H. (1999). SHOP: Simple Hierarchical Ordered Planner.
Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence.
Newell, A., & Simon, H. A. (1972). Human Problem Solving. Prentice-Hall.
Norman, T. J., & Reed, C. (2010). A Logic of Delegation and Responsibility. Artificial Intelligence,
174(1):51-71.
Oh, S., Gratch, J., & Woo, W. (2007). Explanatory Styles for Socially Interactive Agents. Proceedings of
the Second International Conference on Affective Computing and Intelligent Interaction.
Pearl, J. (1999). Reasoning with Cause and Effect. Proceedings of the Sixteenth International Joint
Conference on Artificial Intelligence.
Perrault, C. R. (1990). An Application of Default Logic to Speech Act Theory. In: P. R. Cohen, J. Morgan
and M. E. Pollack (Eds.), Intentions in Communication, pp.161-186. The MIT Press.
Picard, R. W. (1997). Affective Computing. The MIT Press.
Picard, R. W. (2010). Affective Computing: From Laughter to IEEE. IEEE Transactions on Affective
Computing, 1(1):11-17, January-June.
Pollack, M. E. (1990). Plans as Complex Mental Attitudes. In: P. R. Cohen, J. Morgan and M. E. Pollack
(Eds.), Intentions in Communication, pp.77-103. The MIT Press.
Prakken, H. (1997). Logic Tools for Modeling Legal Argument: A Study of Defeasible Argumentation in
Law. Kluwer Academic Publishers.
Prakken, H., & Sartor, G. (2002). The Role of Logic in Computational Models of Legal Argument. In:
A.Kakas and F. Sadri (eds.). Computational Logic: Logic Programming and Beyond, Essays in Honor
of Robert A. Kowalski, Part II, pp. 342-380. Springer-Verlag.
Rao, A. S. (1996). AgentSpeak(L): BDI Agents Speak out in a Logical Computable Language. In: W. Van
de Velde and J. W. Perram (Eds.). Agents Breaking Away: Proceedings of the Seventh European
Workshop on Modeling Autonomous Agents in Multi-Agent World, pp. 42-55. Springer-Verlag.
Rice J. A. (1994). Mathematical Statistics and Data Analysis (Second Edition). Duxbury Press.
Rich, C., Sidner, C. L., & Lesh, N. (2001). COLLAGEN: Applying Collaborative Discourse Theory to
Human-Computer Interaction. AI Magazine, 22(4):15-26.
Rietveld, T., & van Hout. R. (1993). Statistical Techniques for the Study of Language and Language
Behavior. Mouton de Gruyter.
Rissland, E. L., & Ashley, K. D. (1987). A Case-Based System for Trade Secrets Law. Proceedings of the
First International Conference on Artificial Intelligence and Law.
Rissland, E. L., & Skalak, D. B. (1991). CABARET: Statutory Interpretation in a Hybrid Architecture.
International Journal of Man-Machine Studies, 34:839-887.
272

fiMODELING SOCIAL CAUSALITY AND RESPONSIBILITY JUDGMENT IN MULTI-AGENT INTERACTIONS
Schurr, N., Marecki, J., Tambe, M., & Scerri, P. (2005). Towards Flexible Coordination of Human-Agent
Teams. Multiagent and Grid Systems, 1(1):3-16.
Searle, J. R. (1969). Speech Acts: An Essay in the Philosophy of Language. Cambridge University Press.
Shaver, K. G. (1985). The Attribution Theory of Blame: Causality, Responsibility and Blameworthiness.
Springer-Verlag.
Sichman, J. S., Conte, R., Demazeau, Y., & Castelfranchi, C. (1994). A Social Reasoning Mechanism
Based on Dependence Networks. Proceedings of the Eleventh European Conference on AI.
Smith, I. A., & Cohen, P. R. (1996). Toward a Semantics for Agent Communications Language Based on
Speech-Acts. Proceedings of the Thirteenth National Conference on Artificial Intelligence.
Swartout, W., Gratch, J., Hill, R., Hovy, E., Marsella, S., Rickel, J., & Traum, D. (2006). Toward Virtual
Humans. AI Magazine, 27(2):96-108.
Swartout, W., Traum, D., Artstein, R., Noren, D., Debevec, P., Bronnenkant, K., Williams, J., Leuski, A.,
Narayanan, S., Piepol, D., Lane, C., Morie, J., Aggarwal, P., Liewer, M., Chiang, J., Gerten, J., Chu, S.,
& White, K. (2010). Ada and Grace: Toward Realistic and Engaging Virtual Museum Guides.
Proceedings of the Tenth International Conference on Intelligent Virtual Agents.
Tomai, E. (2009). A Pragmatic Approach to Computational Narrative Understanding. Ph.D. Thesis,
Electrical Engineering and Computer Science Department, Northwestern University.
Traum, D. (1994). A Computational Theory of Grounding in Natural Language Conversation. Ph.D. Thesis,
Computer Science Department, University of Rochester.
Traum, D., Gratch, J., Marsella, S., Lee, J., & Hartholt, A. (2008). Multi-party, Multi-issue, Multi-strategy
Negotiation for Multi-modal Virtual Agents. Proceedings of the Eighth International Conference on
Intelligent Virtual Agents.
Traum, D., Rickel, J., Gratch, J., & Marsella, S. (2003). Negotiation over Tasks in Hybrid Human-Agent
Teams for Simulation-Based Training. Proceedings of the Second International Joint Conference on
Autonomous Agents and Multiagent Systems.
Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating Planning and
Learning: the Prodigy Architecture. Journal of Theoretical and Experimental Artificial Intelligence,
7(1):81-120.
Wang, F., Zeng, D., Carley, K., & Mao, W. (2007). Social Computing: From Social Informatics to Social
Intelligence. IEEE Intelligent Systems, 22(2):79-83.
Wang, F., Zeng, D., Hendler, J. A., Zhang Q., Feng, Z., Gao, Y., Wang, H., & Lai, G. (2010). A Study of
the Human Flesh Search Engine: Crowd-Powered Expansion of Online Knowledge. Computer,
43(8):45-53.
Weiner, B. (1995). The Judgment of Responsibility: A Foundation for a Theory of Social Conduct. The
Guilford Press.
Weiner, B. (2001). Responsibility for Social Transgressions: An Attributional Analysis. In: B. F. Malle, L. J.
Moses and D. A. Baldwin (Eds.), Intentions and Intentionality: Foundations of Social Cognition, pp.
331-344. The MIT Press.
Weiner, B. (2006). Social Motivation, Justice and the Moral Emotions: An Attributional Approach.
Lawrence Erlbaum Associates.
Zimmerman, M. J. (1988). An Essay on Moral Responsibility. Rowman & Littlefield.

273

fiJournal of Artificial Intelligence Research 44 (2012) 455-490

Submitted 1/12; published 7/12

Tractable Triangles and Cross-Free Convexity
in Discrete Optimisation
Martin C. Cooper

cooper@irit.fr

IRIT, University of Toulouse III
Toulouse, France

Stanislav Zivny

standa.zivny@cs.ox.ac.uk

Department of Computer Science, University of Oxford
Oxford, UK

Abstract
The minimisation problem of a sum of unary and pairwise functions of discrete variables
is a general NP-hard problem with wide applications such as computing MAP configurations
in Markov Random Fields (MRF), minimising Gibbs energy, or solving binary Valued
Constraint Satisfaction Problems (VCSPs).
We study the computational complexity of classes of discrete optimisation problems
given by allowing only certain types of costs in every triangle of variable-value assignments
to three distinct variables. We show that for several computational problems, the only nontrivial tractable classes are the well known maximum matching problem and the recently
discovered joint-winner property. Our results, apart from giving complete classifications in
the studied cases, provide guidance in the search for hybrid tractable classes; that is, classes
of problems that are not captured by restrictions on the functions (such as submodularity)
or the structure of the problem graph (such as bounded treewidth).
Furthermore, we introduce a class of problems with convex cardinality functions on
cross-free sets of assignments. We prove that while imposing only one of the two conditions
renders the problem NP-hard, the conjunction of the two gives rise to a novel tractable class
satisfying the cross-free convexity property, which generalises the joint-winner property to
problems of unbounded arity.

1. Introduction
The topic of this paper is the following optimisation problem: given a set of discrete variables
and a set of functions, each depending on a subset of the variables, minimise the sum
of the functions over all variables. This fundamental research problem has been studied
within several different contexts of computer science and artificial intelligence under different
names: Min-Sum Problems (Werner, 2007), MAP inference in Markov Random Fields
(MRF) and Conditional Random Fields (CRF) (Lauritzen, 1996; Wainwright & Jordan,
2008), Gibbs energy minimisation (Geman & Geman, 1984), Valued Constraint Satisfaction
Problems (Dechter, 2003), or (for two-state variables) pseudo-Boolean optimisation (Boros
& Hammer, 2002).
We use the terminology of Valued Constraint Satisfaction Problems (VCSPs) (Schiex,
Fargier, & Verfaillie, 1995; Dechter, 2003). We start with a special case of VCSPs that deals
only with the feasibility (rather than optimisation) problem.
c
2012
AI Access Foundation. All rights reserved.

fiCooper & Zivny

A Constraint Satisfaction Problem (CSP) instance consists of a collection of variables
which must be assigned values subject to specified constraints (Montanari, 1974). Each
CSP instance has an underlying undirected graph, known as its constraint graph (or structure), whose vertices are the variables of the instance, and two vertices are adjacent if
corresponding variables are related by some constraint.
An important line of research on CSPs is to identify all tractable cases which are recognisable in polynomial time. Most of this work has been focused on one of the two general
approaches: either identifying forms of constraint which are sufficiently restrictive to ensure
tractability no matter how they are combined (Bulatov, Krokhin, & Jeavons, 2005; Feder &
Vardi, 1998), or else identifying structural properties of constraint networks which ensure
tractability no matter what forms of constraint are imposed (Dechter & Pearl, 1988).
The first approach has led to identifying certain algebraic closure operations known as
polymorphisms (Jeavons, 1998) which are necessary for a set of constraint types to ensure
tractability. A set of constraint types with this property is called a tractable constraint
language. The second approach has been used to characterise all tractable cases of boundedarity CSPs (such as binary CSPs) (Dalmau, Kolaitis, & Vardi, 2002; Grohe, 2007) and
unbounded-arity CSPs (Marx, 2010).
In practice, constraint satisfaction problems usually do not possess a sufficiently restricted structure or use a sufficiently restricted constraint language to fall into any of
these tractable classes. Nevertheless, they may still have properties which ensure they
can be solved efficiently, but these properties concern both the structure and the form of
the constraints. Such properties have sometimes been called hybrid reasons for tractability (Dechter, 2003; Cohen, 2003; Cohen & Jeavons, 2006; Cooper, Jeavons, & Salamon,
2010; Cohen, Cooper, Green, & Marx, 2011).
CSPs capture only the feasibility aspects of a given problem. Since many computational
problems involve seeking a solution that optimises certain criteria, as well as satisfying certain restrictions, various general frameworks for optimisation problems have been studied
such as linear programming, mixed integer programming and others (Hooker, 2007). One
possibility is to extend CSPs to so-called soft constraint satisfaction problems, which allow
measures of desirability to be associated with different assignments to the variables (Dechter,
2003; Meseguer, Rossi, & Schiex, 2006). In an instance of a soft CSP, every constraint
is associated with a function (rather than a relation as in standard CSPs) which represents preferences among different partial assignments, and the goal is to find the best
assignment. Several very general soft CSP frameworks have been proposed in the literature (Schiex, Fargier, & Verfaillie, 1995; Bistarelli, Montanari, & Rossi, 1997). In this paper
we focus on one of the very general frameworks, the valued constraint satisfaction problem (VCSP) (Schiex, Fargier, & Verfaillie, 1995). VCSPs are powerful enough to include
many interesting optimisation problems (Rossi, van Beek, & Walsh, 2006; Cohen, Cooper,
Jeavons, & Krokhin, 2006) and, as pointed out at the beginning of this introduction, are
equivalent to other well studied optimisation problems studied in computer vision and other
fields of computer science and artificial intelligence.
An important line of research on VCSPs is to identify tractable cases which are recognisable in polynomial time. It is well known that structural reasons for tractability generalise
to the VCSP (Bertele & Brioshi, 1972; Dechter, 2003). In the case of language restrictions, only a few conditions are known to guarantee tractability of a given set of valued
456

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

constraints (Cohen, Cooper, Jeavons, & Krokhin, 2006; Cohen, Cooper, & Jeavons, 2008;
Jonsson, Kuivinen, & Thapper, 2011; Kolmogorov, 2011; Kolmogorov & Zivny, 2012).
1.1 Contributions
This paper is the full version of results described in two conference papers (Cooper & Zivny,
2011a, 2011c).
1.1.1 Binary VCSPs
In the first part of the paper, we study hybrid tractability of binary VCSPs (i.e. optimisation
problems involving functions of at most two arguments) for various sets of possible costs
that correspond to CSPs, CSPs with soft unary constraints, Max-CSPs, finite-valued VCSPs
and general-valued VCSPs.
We focus on classes of instances defined by allowed combinations of binary costs in every
assignment to 3 different variables (called a triangle). Our motivation for this investigation
is that one such restriction, the so-called joint-winner property has recently been shown to
define a tractable class (Cooper & Zivny, 2011b). For finite sets of possible costs (corresponding to CSPs and Max-CSPs), there are only finitely many possibilities. For example,
in Max-CSPs there are only four possible multi-sets of costs, namely {0, 0, 0}, {0, 0, 1},
{0, 1, 1} and {1, 1, 1}. However, for infinite sets of possible costs (corresponding to finitevalued CSPs and general-valued VCSPs) there are infinitely many combinations. Obviously,
we cannot consider them all, and hence we consider an equivalence relation based on the
total order on the valuation structure. For example, we consider the four equivalence classes
of multi-sets {, , } given by  =  = ,  =  < ,  =  > ,  <  < .
For all sets of possible costs  we consider, we prove a dichotomy theorem, thus identifying all tractable cases with respect to the equivalence relation on the combinations of
costs. It turns out that there are only two non-trivial tractable cases: the well-known
maximum matching problem (Edmonds, 1965b), and the recently discovered joint-winner
property (Cooper & Zivny, 2011b).
1.1.2 Non-binary VCSPs
In the second part of the paper, we introduce the cross-free convexity property (CFC), and
show that it gives rise to a novel tractable class of VCSPs. Informally speaking, the CFC
property is a conjunction of convex cost functions applied to a structured set of sets of
variable-value assignments. The CFC property generalises our recent results on VCSPs
satisfying the non-overlapping convexity property (Cooper & Zivny, 2011b) by dropping
the assumption that the input functions are non-decreasing and allowing the assignmentsets to be not only hierarchically nested (laminar) but also cross-free. (All terms will be
defined formally in Section 4.) Not only do we generalise the tractable class from the work
of Cooper & Zivny (2011b), but our algorithm also has better running time compared to
the algorithm of Cooper & Zivny (2011b). Moreover, we show that relaxing either one of
the cross-free or convexity assumptions leads to an NP-hard class.
A VCSP instance may be such that some subset of its constraints are cross-free convex.
Since our network is projection-safe (Lee & Leung, 2009), we can use it to establish soft
global arc consistency on this subset of constraints viewed as a single global constraint.
457

fiCooper & Zivny

We also show that, over Boolean domains, it is possible to determine in polynomial time
whether there exists some subset of the constraints such that the VCSP instance satisfies the
cross-free convexity property after renaming the variables in these constraints. To explore
this area even further, we study restrictions on overlaps of constraint scopes, and identify
another tractable class which is incomparable with the cross-free convexity property.
1.2 Organisation of the Paper
The rest of this paper is organised as follows. We start, in Section 2, by defining valuation
structures, valued constraint satisfaction problems, and basics of flow networks. Section 3
is devoted to the classification of binary VCSPs defined by triangles: In Section 3.1, we
present our results on CSPs, followed up with results on CSPs with soft unary constraints
in Section 3.2. In Section 3.3, we present our results on Max-CSPs, followed by the results
on finite-valued and general-valued VCSPs in Section 3.4 and in Section 3.5 respectively.
Section 4 is devoted to our results on non-binary VCSPs: In Section 4.1, we present an
algorithm for VCSPs satisfying the cross-free convexity property and analyze its running
time. Section 4.4 shows that neither cross-freeness nor convexity on its own is enough to
guarantee tractability. In Section 4.5, we extend the class of cross-free convex VCSPs over
Boolean domains using the notion of renamability. Section 4.6 explores a related notion
over sets of variables rather than sets of variable-value assignments. Finally, we conclude
in Section 5.

2. Preliminaries
In this section, we define valuation structures, valued constraint satisfaction problems, and
present the basics of flow networks.
2.1 Valuation Structures
A valuation structure, , is a totally ordered set, with a minimum and a maximum element
(denoted 0 and ), together with a commutative, associative binary aggregation operator
(denoted ), such that for all , ,   ,   0 = , and        whenever   .
Members of  are called costs.
We shall denote by Q+ the set of all non-negative rational numbers. We define Q+ =
Q+  {}. We consider the following subsets of the valuation structure Q+ : {0, }, {0, 1},
Q+ and Q+ , where in all cases the aggregation operation is the standard addition operation
on rationals +. Moreover, for all a  Q+ , we define a +  =  + a = .
2.2 Valued Constraint Satisfaction Problems
An instance of the Valued Constraint Satisfaction Problem (VCSP) (Schiex, Fargier, &
Verfaillie, 1995) is given by n variables v1 , . . . , vn over finite domains D1 , . . . , Dn of values
and a set of constraints C. Each constraint from C is a pair hs, gi, where s is a list of
variables s = hvi1 , . . . , vim i called the constraint scope, and g is an m-ary cost function
g : Di1  . . .  Dim  . Any assignment of values from the domains to all the variables is
called a solution. The goal is to find an optimal solution; that is, a solution which minimises
the total cost given by the aggregation of the costs for its restrictions onto each constraint
458

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

scope:
M

min

v1 D1 ,...,vn Dn

g(vi1 , . . . , vim ) .

hhvi1 ,...,vim i,giC

Depending on the set  of costs which may occur in instances, we get special cases of
the VCSP:  = {0, } corresponds to the Constraint Satisfaction Problem (CSP), {0, 1}
corresponds to the Maximum Constraint Satisfaction Problem (Max-CSP), Q+ corresponds
to the finite-valued VCSP, and finally Q+ corresponds to the general-valued VCSP.
If all the domains of all the variables are the same, we denote this common domain by
D. A CSP instance is called satisfiable if the cost of an optimal solution is zero (i.e. all
constraints are satisfied).
Cost functions with range {0, } are called crisp. Cost functions which are not crisp
are called soft.
2.3 Binary Valued Constraint Satisfaction Problems
In Section 3 we will be interested in the special case of the VCSP when the bound on the
arity of all constraints is 2; these are known as binary VCSPs. Without loss of generality, we
can assume that any binary VCSP
instance contains constraints of all possible scopes; that

n
is, n unary constraints and 2 binary constraints. We denote the cost function associated
with the unary constraint with the scope hvi i by ci and the cost function associated with the
binary constraint with the scope hvi , vj i by cij . The absence of any constraint on variable
vi (or between variables vi , vj ) is modelled by a cost function ci (or cij , respectively) which
is uniformly zero. Using this notation, the goal is to find a solution which minimises the
total cost given by:
n
M
M
ci (vi ) 
cij (vi , vj ) .
i=1

1i<jn

Remark 2.1. We remark on terminological differences. VCSPs are studied under different
names such as Min-Sum, Gibbs energy minimisation, or Markov Random Fields; domain
values are sometimes called labels, whereas binary instances are called pairwise instances,
m-ary cost functions are called m-cliques, and solutions are called labellings.
2.4 Network Flows
Here we review some basics on flows in graphs. We refer the reader to standard textbooks (Ahuja, Magnanti, & Orlin, 2005; Schrijver, 2003) for more details. We present only
the notions and results needed for our purposes. In particular, we deal with integral flows
only. We denote by N the set of positive integers with zero. Let G = (V, A) be a directed
graph with vertex set V and arc set A. For each arc a  A there is a demand/capacity function [d(a), c(a)] and a weight (or cost) function w(a), where d(a), c(a)  N and w(a)  Q.
Let s, t  V . A function f : A  N is called an s  t flow (or just a flow) if for all
v  V \ {s, t},
X
a=(u,v)A

f (a) =

X

f (a)

a=(v,u)A

459

(flow conservation).

fiCooper & Zivny

We say that a flow is P
feasible if d(a)  fP
(a)  c(a) for each a  A. We define the value
of
flow
f
as
val(f
)
=
f
(a)

a=(s,v)A
a=(v,s)A f (a). We define the cost of flow f as
P
aA w(a)f (a). A minimum-cost flow is a feasible flow with minimum cost.
Algorithms for finding the minimum-cost flow of a given value are well known (Ahuja,
Magnanti, & Orlin, 2005; Schrijver, 2003). We consider a generalisation of the minimumcost flow problem. For each arc a  A there is a convex weight function wa which associates
a cost wa (f (a)) to the flow f (a) along arc a. In particular, we consider the model in which
the weight functions wa (a  A) are convex piecewise linear and given by the breakpoints
(which covers
P the case of convex functions over the integers). The cost of flow f is now
defined as aA wa (f (a)). The corresponding problem of finding a minimum-cost integral
flow is known as the minimum convex cost flow problem. In a network with n vertices and
m edges with capacities at most U , the minimum convex cost flow problem can be solved
in time O((m log U )SP (n, m)), where SP (n, m) is the time to compute a shortest directed
path in a network with n vertices and m edges (Minoux, 1984, 1986; Ahuja, Magnanti, &
Orlin, 2005).

3. Complexity Classification of Binary VCSPs Defined by Triangles
In a VCSP instance, we use the word triangle for any set of assignments {hvi , ai, hvj , bi, hvk , ci},
where vi , vj , vk are distinct variables and a  Di , b  Dj , c  Dk are domain values. The
multi-set of costs in such a triangle is {cij (a, b), cik (a, c), cjk (b, c)}. A triple of costs will
always refer to a multi-set of binary costs in a triangle.
A triangle {hvi , ai, hvj , bi, hvk , ci}, where a  Di , b  Dj , c  Dk , satisfies the jointwinner property (JWP) if either all three cij (a, b), cik (a, c), cjk (b, c) are the same, or two
of them are equal and the third one is bigger. A VCSP instance satisfies the joint-winner
property if every triangle satisfies the joint-winner property.
Theorem 3.1. (Cooper & Zivny, 2011b) The class of VCSP instances satisfying JWP is
tractable.
In our previous work (Cooper & Zivny, 2011b), we also showed that the class defined by
the joint-winner property is maximal  allowing a single extra triple of costs that violates
the joint-winner property renders the class NP-hard.
Theorem 3.2. (Cooper & Zivny, 2011b) Let  <   , where   Q+ and ,   Q+ ,
be a multi-set of costs that do not satisfy the joint-winner property. The class of instances
where the costs in each triangle either satisfy the joint-winner property or are {, , } is
NP-hard, even for Boolean Max-CSPs, CSPs over size-3 domains or Boolean finite-valued
VCSPs.
In this section we consider a much broader question, whether allowing any fixed set S
of triples of costs in triangles, where S does not necessarily include all triples allowed by
the JWP, defines a tractable class of VCSP instances.
In the case of CSP, there are only four possible multi-sets of costs ({0, 0, 0}, {0, 0, },
{0, , }, {, , }) and it is possible to study all 16 subsets S of this set. But, given
an infinite set of possible costs, such as Q+ or Q+ , there is an infinite number of sets S of
triples of costs. Obviously, we cannot consider all such sets. Therefore, we only consider
460

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

cases defined by the total order < on , corresponding to a partition of the set of all possible
triples of costs into a small number of types of triples.
Let D denote the set of all possible cost types under consideration. Let  be a fixed
set of allowed costs. For any S  D, we denote by A (S) (A for allowed) the set of binary
VCSP instances whose costs lie in  and where the triples of costs in all triangles belong
to S.
Our goal is to classify the complexity of A (S) for every S  D. The problem A (S)
is considered tractable if there is a polynomial-time algorithm to solve it and intractable if
it is NP-hard.
Proposition 3.3. Let  be an arbitrary set of costs and S a set of cost types.
1. If A (S) is tractable and S 0  S, then A (S 0 ) is tractable.
2. If A (S) is intractable and S 0  S, then A (S 0 ) is intractable.
Remark 3.4. We implicitly allow all unary cost functions. In fact, all our tractability
results work with unary cost functions, and our NP-hardness results do not require any
unary cost functions.
Remark 3.5. We consider problems with unbounded domains; that is, the domain sizes
are part of the input. However, all our NP-hardness results are obtained for problems with
a fixed domain size.1 In the case of CSPs, we need domains of size 3 to prove NP-hardness,
and in all other cases domains of size 2 are sufficient to prove NP-hardness. Since binary
CSPs are known to be tractable on Boolean domains, and any VCSP is trivially tractable
over domains of size 1, all our NP-hardness results are tight.
3.1 CSP
In this section, we will focus on the set of possible costs  = {0, }; that is, Constraint
Satisfaction Problems (CSPs). We consider the four following types of triples of costs:
Symbol
<
>
0


Costs
{0, 0, }
{0, , }
{0, 0, 0}
{, , }

The set of possible cost types is thus D = {<, >, 0, }. Indeed, these four cost types
correspond precisely to the four possible multi-sets of costs: {0, 0, 0}, {0, 0, }, {0, , }
and {, , }. The dichotomy presented in this section therefore represents a complete
characterisation of the complexity of CSPs defined by placing restrictions on triples of costs
in triangles.
As A{0,} (D) allows all binary CSPs, A{0,} (D) is intractable (Papadimitriou, 1994)
unless the domain is of size at most 2, in which case it is equivalent to 2-SAT, which is a
well-known tractable class (Schaefer, 1978).
1. In other words, the considered problems are not fixed-parameter tractable (Downey & Fellows, 1999) in
the domain size.

461

fiCooper & Zivny

<, >, 0, 

<, >

<, >, 0

<, >, 

<, 0, 

>, 0, 

<, 0

<, 

>, 0

>, 

<

>

0



0, 



Figure 1: Complexity of CSPs A{0,} (S), S  {<, >, 0, }.
Proposition 3.6. A{0,} (D) is intractable unless |D|  2.
The joint-winner property for CSPs gives
Corollary 3.7 (of Theorem 3.1). A{0,} ({<, 0, }) is tractable.
Proposition 3.8. A{0,} ({>, 0, }) is tractable.
Proof. Since < is forbidden, if two binary costs in a triangle are zero then the third binary
cost must also be zero. In other words, if the assignment hv1 , a1 i is consistent with hvi , ai i
for each i  {2, . . . , n}, then for all i, j  {1, . . . , n} such that i 6= j, hvi , ai i is consistent with
hvj , aj i. Thus Singleton Arc Consistency, which is a procedure enforcing Arc Consistency for
every variable-value pair (Rossi, van Beek, & Walsh, 2006), solves A{0,} ({>, 0, }).
Proposition 3.9. A{0,} ({<, >, }) is tractable.
Proof. This class is trivial: instances with at least three variables have no solution of finite
cost, since the triple of costs {0, 0, 0} is not allowed.
Proposition 3.10. A{0,} ({<, >, 0}) is intractable unless |D|  2.
Proof. It is straightforward to encode the 3-Colouring problem as a binary CSP. The result
then follows from the fact that 3-Colouring is NP-hard for triangle-free graphs (i.e. graphs
that do not contain K3 , the complete graph on 3 vertices, as a subgraph), which can be
derived from two results from the work of Lovasz (1973). (Indeed, 3-Colouring is NP-hard
even for triangle-free graphs of degree at most 4; see Maffray & Preissmann, 1996.) The
triple of costs {, , } cannot occur in the CSP encoding of the colouring of a trianglefree graph.
462

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

Results from this section, together with Proposition 3.3, complete the complexity classification, as depicted in Figure 1: white nodes represent tractable cases and shaded nodes
represent intractable cases.
Theorem 3.11. For |D|  3, a class of binary CSP instances defined as A{0,} (S), where
S  {<, >, 0, }, is intractable if and only if {<, >, 0}  S.
3.2 CSP with Soft Unary Constraints
A simple way to convert classical CSPs into an optimisation problem is to allow soft unary
constraints. This framework includes well-studied problems such as Max-Ones over Boolean
domains (Creignou, Khanna, & Sudan, 2001; Khanna, Sudan, Trevisan, & Williamson,
2001) and non-Boolean domains (Jonsson, Kuivinen, & Nordh, 2008), Max-Solution (Jonsson & Nordh, 2008), or Min-Cost-Hom (Takhanov, 2010).
It turns out that the dichotomy given in Theorem 3.11 remains valid even if soft unary
constraints are allowed. In this case, the intractable cases are now intractable even for
domains of size 2.
Q+
We use the notation A{0,}
(S) to represent the set of VCSP instances with binary
costs from {0, }, unary costs from Q+ and whose triples of costs in triangles belong to
S. In other words, we now consider VCSPs with crisp binary constraints and soft unary
constraints.
Q

+
Theorem 3.12. For |D|  2, a class of binary CSP instances defined as A{0,}
(S), where
S  {<, >, 0, }, is intractable if and only if {<, >, 0}  S.

Proof. For the tractability part of the theorem, it suffices to show tractability when S is
{<, >, }, {<, 0, } or {>, 0, }, the three maximal tractable sets in the case of CSP
shown in Figure 1.
Q

+
The tractability of A{0,}
({<, 0, }) is again a corollary of Theorem 3.1 since the jointwinner property allows any unary soft constraints.

Q

+
To solve A{0,}
({>, 0, }) in polynomial time, we establish Singleton Arc Consistency
in the CSP instance corresponding to the binary constraints and then loop over all assignments to the first variable. For each assignment a1 to variable v1 , we can determine the
optimal global assignment which is an extension of hv1 , a1 i by simply choosing the assignment ai for each variable vi with the least unary cost ci (ai ) among those assignments hvi , ai i
that are consistent with hv1 , a1 i.

Q

+
As in the proof of Proposition 3.9, any instance of A{0,}
({<, >, }) is tractable, since
instances with at least three variables have no solution of finite cost.
Sets S which are intractable for CSPs clearly remain intractable when soft unary constraints are allowed. However, we want to prove intractability even in the Boolean case;
that is, when |D| = 2.

Q

Q

+
+
({<, >, 0}) (and hence, by Proposition 3.3, of A{0,}
({<, >
The intractability of A{0,}
, 0, })) follows from the fact that the Independent Set problem (Garey & Johnson, 1979)
is intractable even on triangle free graphs. This follows from the standard trick (Poljak,
1974) of replacing every edge by P4 , the path on 4 vertices (this operation is also known

463

fiCooper & Zivny

as 2-subdivision). In particular, a graph G with m edges has an independent set of size k
if and only if the 2-subdivision of G, denoted by G0 , has an independent set of size k + m.
Note that G0 is triangle-free. Any instance G0 of the Independent Set problem on triangleQ

+
free graphs can be encoded as an instance of A{0,}
({<, >, 0}) over the {0, 1} domain in
the straightforward way: variables correspond to vertices; edge {i, j} yields cost function
cij (1, 1) =  and cij (x, y) = 0 for (x, y) 6= (1, 1); ci (0) = 1 and ci (1) = 0 for every i. Since

Q

+
G0 is triangle-free, the constructed instance belongs to A{0,}
({<, >, 0}).

3.3 Max-CSP
In this section, we will focus on the set of possible costs  = {0, 1}. It is well known that
the VCSP with costs in {0, 1} is polynomial-time equivalent to unweighted Max-CSP (no
repetition of constraints allowed) (Rossi, van Beek, & Walsh, 2006). The four types of
triples of costs we consider are:
Symbol
<
>
0
1

Costs
{0, 0, 1}
{0, 1, 1}
{0, 0, 0}
{1, 1, 1}

The set of possible cost types is then D = {<, >, 0, 1}. Again, these four costs types
correspond precisely to the four possible multi-sets of costs: {0, 0, 0}, {0, 0, 1}, {0, 1, 1},
and {1, 1, 1}. As for the CSP, our dichotomy result for Max-CSP represents a complete
characterisation of the complexity of classes of instances defined by placing restrictions on
triples of costs in triangles.
<, >, 0, 1

<, >

<, >, 0

<, >, 1

<, 0, 1

>, 0, 1

<, 0

<, 1

>, 0

>, 1

<

>

0

1

0, 1



Figure 2: Complexity of Max-CSPs A{0,1} (S), S  {<, >, 0, 1}.
As A{0,1} (D) allows all binary Max-CSPs, A{0,1} (D) is intractable (Garey & Johnson,
1979; Papadimitriou, 1994) unless the domain is of size 1.
464

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

Proposition 3.13. A{0,1} (D) is intractable unless |D|  1.
The joint-winner property (Cooper & Zivny, 2011b) for Max-CSPs gives
Corollary 3.14 (of Theorem 3.1). A{0,1} ({<, 0, 1}) is tractable.
Proposition 3.15. A{0,1} ({<, >}) is tractable.
Proof. We show that A{0,1} ({<, >}) contains instances on at most 5 variables, thus showing
that A{0,1} ({<, >}) is trivially tractable. Consider an instance of A{0,1} ({<, >}) on 6 or
more variables. Choose 6 arbitrary variables v1 , . . . , v6 and 6 domain values di  Dvi ,
1  i  6. Every cost is either 0 or 1. It is well known (Goodman, 1959) and not difficult to
show2 that for every 2-colouring of edges of K6 (the complete graph on 6 vertices) there is a
monochromatic triangle. Therefore, there is a triangle with costs either {0, 0, 0} or {1, 1, 1}.
But this is a contradiction with the fact that only cost types < (i.e. {0, 0, 1}) and > (i.e.
{1, 1, 0}) are allowed.
Remark 3.16. Both A ({>}) and A ({<, >}) are tractable over any finite set of costs 
due to a similar Ramsey type of argument: given  = {0, 1, . . . , K  1}, there is nK  N
such that for every complete graph G on n vertices, where n  nK , and every colouring of
the edges of G with K colours, there is a monochromatic triangle in G. Hence there are
only finitely many instances, which can be stored in a look-up table. However, once the set
of costs is infinite (e.g. Q+ ), both classes become intractable, as shown in the next section.
Proposition 3.17. A{0,1} ({>, 0, 1}) is intractable unless |D|  1.
Proof. Given an instance of the Max-2SAT problem, we show how to reduce it to a {0, 1}valued VCSP instance from A{0,1} ({>, 0, 1}). The result then follows from the well-known
fact that Max-2SAT is NP-hard (Garey & Johnson, 1979; Papadimitriou, 1994). Recall
that an instance of Max-2SAT is given by a set of m clauses of length 2 over n variables
x1 , . . . , xn and the goal is to find an assignment that maximises the number of clauses that
have at least one true literal.
In order to simplify notation, rather than constructing a VCSP instance from A{0,1} ({>
, 0, 1}) with the goal to minimise the total cost, we construct an instance from A{0,1} ({<
, 0, 1}) with the goal to maximise the total cost. This implies that the allowed sets of costs
in triangles are {0, 0, 1}, {0, 0, 0}, and {1, 1, 1}. Clearly, these two problems are polynomialtime equivalent.
For each variable xi , we create a large number M of copies xji of xi with domain {0, 1},
1  i  n and 1  j  M . For each variable xi , the new copies of xi are pairwise joined by an
equality-encouraging cost function h, where h(x, y) = 1 if x = y and h(x, y) = 0 otherwise.
By choosing M very large, we can assume from now on that all copies of xi will be assigned
the same value in all optimal solutions. We can effectively ignore the contribution of these
2. Take an arbitrary vertex v in K6 where every edge is coloured either blue or red. By the pigeonhole
principle, v is incident to at least 3 blue or at least 3 red edges. Without loss of generality, we consider
the former case. Let v1 , v2 and v3 be the three vertices incident to three blue edges incident to v. If an
any of the edges {v1 , v2 }, {v1 , v3 }, {v2 , v3 } is blue, we have a blue triangle. If all three edges are red, we
have a red triangle.

465

fiCooper & Zivny


cost functions, which is K = n M
2 , to the total cost. It is straightforward to check that all
triangles involving the new copies of the variables have the allowed costs.
For each clause (l1  l2 ), where l1 and l2 are literals, we create a variable zi with domain
{l1 , l2 }, 1  i  m. For each literal l in the domain of zk : if l is a positive literal l = xi , we
introduce cost function g between zk and each copy xji of xi , where g(l, 1) = 1 and g(., .) = 0
otherwise; if l is a negative literal l = xi , we introduce cost function g 0 between zk and
each copy xji of xi , where g 0 (l, 0) = 1 and g 0 (., .) = 0 otherwise.
To make sure that the only sets of costs in all triangles are {0, 0, 1}, {0, 0, 0}, and
{1, 1, 1}, we also add cost functions f between the different clause variables zk and zk0
involving the same literal l, where f (l, l) = 1 and f (., .) = 0 otherwise. The contribution of
all the cost functions between zk and zk0 , 1  k 6= k 0  m, is less than M and hence of no
importance for M very large.
Answering the question of whether the resulting VCSP instance has a solution with a
cost  K + pM is equivalent to determining whether the original Max-2SAT instance has a
solution satisfying at least p clauses. This is because each clause variable zk can only add
a score  M if we assign value l to zk for some literal l which is assigned true.
Proposition 3.18. Both A{0,1} ({<, >, 0}) and A{0,1} ({<, >, 1}) are intractable unless |D| 
1.
Proof. We present a reduction from Max-Cut, a well-known NP-hard problem (Garey &
Johnson, 1979), which is NP-hard even on triangle-free graphs (Lewis & Yannakakis, 1980).
An instance of Max-Cut can easily be modelled as a Boolean {0, 1}-valued VCSP instance:
every vertex of the graph is represented by a variable with the Boolean domain {0, 1}, and
every edge yields cost function f , where f (x, y) = 1 if x = y and f (x, y) = 0 if x 6= y.
Observe that since the original graph is triangle-free, there cannot be a triangle with costs
{1, 1, 1}. Therefore, the constructed instance belongs to A{0,1} ({<, >, 0}).
For the A{0,1} ({<, >, 1}) case, instead of minimising the total cost, we maximise the total
cost for instances from A{0,1} ({<, >, 0}). Again, we model an instance of the Max-Cut
problem using Boolean variables, and every edge yields a cost function g, where g(x, y) = 0
if x = y and g(x, y) = 1 if x 6= y (where in this case the aim is to maximise the total cost).
The constructed instance belongs to A{0,1} ({<, >, 0}). (In fact, in this case we do not need
the original graph to be triangle-free.)
Proposition 3.19. A{0,1} ({>, 0}) is tractable.
Proof. Let I be an instance from A{0,1} ({>, 0}). The algorithm loops through all possible
assignments {hv1 , a1 i, hv2 , a2 i} to the first two variables. Suppose that c12 (a1 , a2 ) = 1 (the
case c12 (a1 , a2 ) = 0 is similar). Observe that the possible variable-value assignments to other
variables {hvi , bi | 3  i  n, b  Di } can be uniquely split in two sets L and R such that: (1)
for every hvi , bi  L, c1i (a1 , b) = 1 and c2i (a2 , b) = 0; for every hvi , bi, hvj , ci  L, cij (b, c) =
0; (2) for every hvi , bi  R, c1i (a1 , b) = 0 and c2i (a2 , b) = 1; for every hvi , bi, hvj , ci  R,
cij (b, c) = 0; (3) for every hvi , bi  L and hvj , ci  R, cij (b, c) = 1. Ignoring unary cost
functions for a moment, to find an optimal assignment to the remaining n  2 variables, one
has to decide how many variables vi , 3  i  n, will be assigned a value b  Di such that
hvi , bi  L. The cost of a global assignment involving k variable-value assignments from L
is 1 + k + (n  2  k) + k(n  2  k) = n  1 + k(n  2  k). For some variables vi it could
466

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

happen that hvi , bi  L for all b  Di or hvi , ci  R for all c  Di . If this is the case, then
we choose an arbitrary value b for xi with minimum unary cost ci (b). This is an optimal
choice whatever the assignments to the variables xj (j  {3, . . . , i  1, i + 1, . . . , n}).
Assuming that all such variables have been eliminated and now taking into account
unary cost functions, the function to minimise is given by the objective function (in which
we drop the constant term n  1):
X
X
X
X
(
xi )(n  2 
xi ) +
wiL xi +
wiR (1  xi )
(each sum being over i  {3, . . . , n}), where xi  {0, 1} indicates whether vi is assigned a
R
value from R or L, wiL = min{ci (b) : b  Di hvi , bi  L}, and similarly
PwiL = min{c
P Ri (c) : c 
Di hvi , ci  R}. The objective
function
is
thus
equal
to
k(n2k)+
w
x
+
wi (1xi ),
i
i
P
where, as above, k =
xi is the number of assignments from L. This objective function
is minimised either when k = 0 or when k = n  2. This followsPfrom theP
fact that the
contribution of unary cost functions to the objective function is
wiL xi + wiR (1  xi )
which is at most n  2 (since in Max-CSP all unary costs belong to {0, 1}). This is no
greater than the value of the quadratic term k(n  2  k) for all values of k in {1, . . . , n  3},
i.e. not equal to 0 or n  2.
The optimal assignment which involves k = 0 (respectively k = n  2) assignments from
L is obtained by simply choosing each value ai (for i > 2) with minimum unary cost among
all assignments hvi , ai i  R (respectively L).
In the case that c12 (a1 , a2 ) = 0, a similar argument shows that the quadratic term in
the objective function is now 2(n  2  k) + k(n  2  k) = (k + 2)(n  2  k). This is always
minimised by setting k = n  2 and again the sum of the unary costs is no greater than the
value of the quadratic term for other values of k 6= n  2. The optimal assignment which
involves all k = n  2 assignments from L is obtained by simply choosing each value ai (for
i > 2) with minimum unary cost among all assignments hvi , ai i  L.
Proposition 3.20. A{0,1} ({>, 1}) is tractable.
Proof. Let I be an instance from A{0,1} ({>, 1}) without any unary constraints; i.e. all
constraints are binary. Observe that every variable-value assignment hvi , ai, where a  Di ,
is included in zero-cost assignment-pairs involving at most one other variable; i.e. there
is at most one variable vj , such that cij (a, b) = 0 for some b  Dj . In order to minimise
the total cost, we have to maximise the number of zero-cost assignment-pairs. In a global
assignment, no two zero-cost assignment-pairs can involve the same variable, which means
that this can be achieved by a reduction to the maximum matching problem, a problem
solvable in polynomial time (Edmonds, 1965b). We build a graph with vertices given by
the variables of I, and there is an edge {vi , vj } if and only if there is a  Di and b  Dj
such that cij (a, b) = 0.
To complete the proof, we show that unary constraints do not make the problem more
difficult to solve; it suffices to perform a preprocessing step before the reduction to maximum
matching. Let vi be an arbitrary variable of I. If ci (a) = 1 for all a  Di , then we can
effectively ignore the unary cost function ci since it simply adds a cost of 1 to any solution.
Otherwise, we show that all a  Di such that ci (a) = 1 can be ignored. Take an arbitrary
assignment s to all variables such that s(vi ) = a, where ci (a) = 1. Now take any b  Di
467

fiCooper & Zivny

such that ci (b) = 0. We claim that assignment s0 defined by s0 (vi ) = b and s0 (vj ) = s(vj )
for every j 6= i does not increase the total cost compared with s. Since the assignment
hvi , ai can occur in at most one zero-cost assignment-pair, there are two cases to consider:
(1) if there is no hvj , ci with s(vj ) = c such that cij (a, c) = 0, then the claim holds since
ci (a) = 1 and ci (b) = 0, so the overall cost can only decrease if we replace a by b; (2) if there
is exactly one j 6= i such that cij (a, c) = 0 and s(vj ) = c, then again the cost of s0 cannot
increase because the possible increase of cost by 1 in assigning b to vi is compensated by the
unary cost function ci . Therefore, before using the reduction to maximum matching, we can
remove all a  Di such that ci (a) = 1 and keep only those a  Di such that ci (a) = 0.
Remark 3.21. In the proof of Proposition 3.20, we have shown that any instance from
A{0,1} ({>, 1}) can be reduced to an instance of maximum matching in graphs (Edmonds,
1965b). We remark that conversely, given a graph G, the maximum matching problem in
0 from A
G can be modelled as a VCSP instance IG
{0,1} ({>, 1}).
We order the vertices of G arbitrarily and call them 1, 2, . . . , n. The instance IG will have
n variables v1 , . . . , vn , one for each vertex of G. Let {n1 , . . . , nm } be the neighbours of vertex
i in G, where m is the degree of vertex i in G; that is, {j | {i, j}  E(G)} = {n1 , . . . , nm }.
We define Di = {0, n1 , . . . , nm }.
Any edge {i, j}  E(G), where i < j, yields cij (j, i) = 1, and all remaining costs are 0.
It follows from the definition of IG that (i) solutions to IG of maximum cost correspond to
maximum matchings in G; and (ii) IG  A{0,1} ({<, 0}). By swapping the costs 0 and 1, we
0 from A
get an instance IG
{0,1} ({>, 1}), whose solutions correspond to matchings in G and
solutions of minimum cost correspond to maximum matchings in G.
Results from this section, together with Proposition 3.3, complete the complexity classification, as depicted in Figure 2: white nodes represent tractable cases and shaded nodes
represent intractable cases.
Theorem 3.22. For |D|  2, a class of binary unweighted Max-CSP instances defined
as A{0,1} (S), where S  {<, >, 0, 1}, is intractable if and only if either {<, >, 0}  S,
{<, >, 1}  S, or {>, 0, 1}  S.
3.4 Finite-Valued VCSP
In this section, we will focus on finite-valued VCSPs. In other words, we consider the set
of possible costs  = Q+ . Since there are an infinite number of triples of costs, we consider
types of triples defined by the total order on . We study three different ways of partitioning
the set of all triples of costs into distinct types.
3.4.1 Classification with respect to Order
The set of possible cost types is D = {4, <, >, =}, where these four types are defined in
the following table:
Symbol
4
<
>
=

Costs
{, , }
{, , }
{, , }
{, , }

Remark
, ,   ,  6=  6=  6= 
,   ,  < 
,   ,  > 

468

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

4, <, >, =

4, <

4, <, >

4, <, =

4, >, =

<, >, =

4, >

4, =

<, >

<, =

4

<

>

=

>, =



Figure 3: Complexity of finite-valued VCSPs AQ+ (S), S  {4, <, >, =}.
As AQ+ (D) allows all finite-valued VCSPs, it is intractable even over a Boolean domain (Cohen, Cooper, Jeavons, & Krokhin, 2006) as it includes the Max-SAT problem
for the exclusive or predicate (Papadimitriou & Yannakakis, 1991; Creignou, Khanna, &
Sudan, 2001).
Proposition 3.23. AQ+ (D) is intractable unless |D|  1.
The joint-winner property (Cooper & Zivny, 2011b) for finite-valued VCSPs gives
Corollary 3.24 (of Theorem 3.1). AQ+ ({<, =}) is tractable.
Proposition 3.25. AQ+ ({4}) is intractable unless |D|  1.
Proof. We show a reduction from Max-Cut, a well-known NP-hard problem (Garey &
Johnson, 1979). An instance of Max-Cut can be easily modelled as a Boolean finite-valued
VCSP instance: every vertex of the graph is represented by a variable with the Boolean
domain {0, 1}, and every edge yields cost function f , where f (x, y) = 1 if x = y and f (x, y) =
0 if x 6= y. However, the constructed instance does not belong to AQ+ ({4}). Nevertheless,
we can amend the VCSP instance by infinitesimal perturbations: all occurrences of the cost
0 are replaced by different numbers that are very close to 0, and all occurrences of the cost
1 are replaced by different numbers very close to 1. Now since all the costs are different,
clearly the instance belongs to AQ+ ({4}).
Proposition 3.26. AQ+ ({>}) is intractable unless |D|  1.
Proof. We prove this by a perturbation of the construction in the proof of Proposition 3.17,
which shows intractability of AQ+ ({>, =}). In order to simplify the proof, similarly to the
proof of Proposition 3.17, we prove that maximising the total cost in the class AQ+ ({<})
is NP-hard.
In the construction in the proof of Proposition 3.17 we add i to each binary cost cij (a, b),
where i < j, if cij (a, b) was equal to 1. We assume that  is very small (n < 1). This simply
469

fiCooper & Zivny

ensures that each triple of costs {1, 1, 1} in a triangle of assignments is now perturbed to
become {1 + i, 1 + i, 1 + j}.
In the reduction from Max-2SAT, for each literal l, let Cl be the set of all variablevalue assignments corresponding to l (in both the xji and the zk variables). Recall that all
binary costs for pairs of the assignments within Cl were 1 and all binary costs for pairs of
the assignments from distinct Cl , Cl0 were all 0 in the VCSP encoding of the Max-2SAT
instance. We place an arbitrary ordering on the literals l1 < l2 <    < lr . We then add
i to each binary cost between two variable-value assignments whenever these assignments
correspond to literals li , lj with i < j. This simply ensures that each triple of costs {0, 0, 0}
in a triangle of assignments is now perturbed to become {0 + i, 0 + i, 0 + j}.
The resulting VCSP instance is in AQ+ ({>}) and correctly codes the original Max-2SAT
instance for sufficiently small .
Results from this section, together with Proposition 3.3, complete the complexity classification, as depicted in Figure 3: white nodes represent tractable cases and shaded nodes
represent intractable cases.
Theorem 3.27. For |D|  2, a class of binary finite-valued VCSP instances defined as
AQ+ (S), where S  {4, <, >, =}, is tractable if and only if S  {<, =}.
3.4.2 Classification with respect to Minimum Cost
The tractable classes A{0,1} ({>, 1}), A{0,1} ({>, 0}) and A{0,1} ({<, >}) appear in Figure 2,
but do not appear as subclasses of the tractable classes AQ+ (S) identified in Figure 3. This
is due to the fact that for the infinite set of possible costs  = Q+ , Figure 3 covers only
a subset of the infinite number of possible restrictions on triples of costs in triangles. We
now consider triples of costs which allow us to find generalisations of these three tractable
classes to finite-valued VCSPs, by considering restrictions depending on the relationship of
costs with the minimum or maximum binary cost in an instance.
We start with the minimum cost. Without loss of generality we can assume that the
minimum binary cost of an instance is 0. We consider the following types of triples of costs:
Symbol
40
<0
>0
0

Costs
{, , 0}
{0, 0, }
{, , 0}
{0, 0, 0}

Remark
,   ,  >  > 0
  ,  > 0
  ,  > 0

For simplicity of presentation, we do not consider the remaining type of triples of costs,
namely {, , } such that , ,  > 0. Since it is possible to transform any VCSP instance
into an equivalent instance with non-zero costs by adding a constant  > 0 to all binary
costs, it is clear that allowing all such triples of costs would render the VCSP intractable.
The complexity of combinations of costs from {40 , <0 , >0 , 0} are shown in Figure 4:
white nodes represent tractable cases and shaded nodes represent intractable cases.
Proposition 3.28. AQ+ ({>0 , 0}) is tractable.
470

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

40 , <0 , >0 , 0

40 , <0

40 , <0 , >0

40 , <0 , 0

40 , >0 , 0

<0 , >0 , 0

40 , >0

40 , 0

<0 , >0

<0 , 0

40

<0

>0

0

>0 , 0



Figure 4: Complexity of finite-valued VCSPs AQ+ (S), S  {40 , <0 , >0 , 0}.
Proof. Observe that either all non-zero binary costs involve the same variable vk (i.e. cij = 0
for all i, j 6= k) or there is only one distinct cost  > 0 in the instance. (Otherwise, if there
are two distinct  6=  non-zero costs ,  > 0 in the instance such that cij (a, b) =  and
ckl (c, d) =  for distinct i, j, k, l, then it is easy to verify that it is not possible to assign
costs to cik (a, c), cil (a, d), cjk (b, c), cjl (b, d) so that all triangles have cost types >0 or 0.)
This implies that AQ+ ({>0 , 0}) is equivalent to A{0,1} ({>, 0}) after the instantiation of at
most one variable.
Corollary 3.29 (of Theorem 3.1). AQ+ ({<0 , 0}) is tractable.
Proposition 3.30. AQ+ ({40 , <0 , >0 }) is tractable.
Proof. Analogously to the Ramsey type argument in the proof of Proposition 3.15, any
instance on more than 5 variables must contain either a triangle of zero costs or a triangle
of three non-zero costs and hence cannot belong to AQ+ ({40 , <0 , >0 }).
Proposition 3.31. AQ+ ({<0 , >0 , 0}) is intractable unless |D|  1.
Proof. By reduction from Max-Cut on triangle-free graphs as in the proof of Proposition 3.18
Proposition 3.32. AQ+ ({40 , 0}) is intractable unless |D|  1.
Proof. It has been shown that the VCSP remains intractable on bipartite graphs and
Boolean domains (Cooper & Zivny, 2011b). Let I be such an instance with a partition
V1 ,V2 of the variables. Insignificantly small but distinct costs can be added to all binary
costs in I between variables i  V1 and j  V2 to ensure that all triangles are of type 40 or
0.
471

fiCooper & Zivny

Theorem 3.33. For |D|  2, a class of binary finite-valued VCSP instances defined as
AQ+ (S), where S  {40 , <0 , >0 , 0}, is tractable if and only if S  {<0 , 0}, S  {>0 , 0} or
S  {40 , <0 , >0 }.
3.4.3 Classification with respect to Maximum Cost
Let M  Q+ be any cost and consider the following types of triples of costs:
Symbol
4M
<M
>M
M

Costs
{, , M }
{, , M }
{, M, M }
{M, M, M }

Remark
,   ,  <  < M
  ,  < M
  ,  < M

Again, we do not consider the remaining type of triples of costs, namely {, , } such
that , ,  < M , since allowing such triples of costs renders the VCSP intractable. If
{4M , <M , >M , M } are the only allowed combinations of triples of costs, then M is clearly
the maximum binary cost in the instance.
4M , <M , >M , M

4M , <M , >M

4M , <M

4M , <M , M

4M , >M , M

<M , >M , M

4M , >M

4M , M

<M , >M

<M , M

4M

<M

>M

M

>M , M



Figure 5: Complexity of finite-valued VCSPs AQ+ (S), S  {4M , <M , >M , M }.
The complexity of combinations of costs from {4M , <M , >M , M } are depicted in Figure 5: white nodes represent tractable cases and shaded nodes represent intractable cases.
The most interesting case is AQ+ ({>M , M }), which turns out to be tractable by a
reduction to maximum weighted matching and hence is a proper generalization of class
A{0,1} ({>, 1}).
Proposition 3.34. AQ+ ({>M , M }) is tractable.
Proof. The proof is similar to the proof of Proposition 3.20. Consider an instance I in
AQ+ ({>M , M }), and let
ij = min{ci (u) + cij (u, v) + cj (v) | u  Di , v  Dj }
472

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

with the minimum being attained when u = aji and v = aij . We can assume, without
loss of generality, that the unary cost functions satisfy i, di  Di such that ci (di ) = 0
(by subtracting, if necessary, min ci (u) from the unary cost function ci ). This implies that
ij  cij (di , dj )  M .
Suppose that (bi , bj ) 6= (aji , aij ) and cij (bi , bj ) < M . Then we can replace (bi , bj ) by
(aji , aij ) in any solution to produce a solution of no greater cost: this is because all other
binary costs involving bi or bj are necessarily maximal (i.e. equal to M ). Therefore, setting
cij (bi , bj ) = M does not change the cost of an optimal solution to the instance I. It follows
that we can assume that there is at most one non-maximal binary cost cij (aji , aij ) in each
binary cost function cij .
Consider the weighted complete graph G with vertices 1, . . . , n and edge weights M ij .
Let MG be a maximum weighted matching of G. Define a solution x = hx1 , . . . , xn i to I by
 j
ai if {i, j}  MG
xi =
.
di otherwise
This solution is well-defined since MG is a matching. The weight of MG is
 
X
n
(M  ij ) =
M  cost(x).
2
{i,j}MG

On the other hand, consider any solution y to I. Let
E(y) = {{i, j} | yi = aji  yj = aij  ij < M }.
E(y) is a matching of G of weight
X

 
n
(M  ij ) 
M  cost(y).
2

{i,j}E(y)

Since MG is a maximum weighted matching, we can deduce that cost(y)  cost(x). Hence
x is an optimal solution.
Tractability follows from the tractability of the maximum weighted matching problem (Edmonds, 1965a).
Remark 3.35. We have seen in the proof of Proposition 3.34 that AQ+ ({>M , M }) is
tractable via a reduction to the maximum weighted matching problem (Edmonds, 1965a).
Similarly to Remark 3.21, it is easy to show that, conversely, any instance of the maximum weighted matching problem can be modelled as a VCSP instance from AQ+ ({>M , M }).
Corollary 3.36 (of Theorem 3.1). AQ+ ({<M , M }) is tractable.
Proposition 3.37. AQ+ ({4M , <M , >M }) is tractable.
Proof. Analogously to the proof of Proposition 3.30, instances contain at most 5 variables.
Proposition 3.38. AQ+ ({<M , >M , M }) is intractable unless |D|  1.
473

fiCooper & Zivny

Proof. By reduction from Max-Cut as in the proof of Proposition 3.18
Proposition 3.39. AQ+ ({4M , M }) is intractable unless |D|  1.
Proof. We will show intractability by reduction from VCSP on bipartite graphs and with
Boolean domains which is known to be NP-hard (Cooper & Zivny, 2011b). It suffices to
replace all zero costs by M in the reduction from VCSP on bipartite graphs given in the
proof of Proposition 3.32 to produce an equivalent instance in AQ+ ({4M , M }).
Theorem 3.40. For |D|  2, a class of binary finite-valued VCSP instances defined as
AQ+ (S), where S  {4M , <M , >M , M }, is tractable if and only if S  {<M , M } or S 
{>M , M } or S  {4M , <M , >M }.
3.5 General-Valued VCSP
In this section, we focus on general-valued VCSPs. In other words, we consider the complete
valuation structure Q+ as the set of possible costs . In fact, the complexity classifications
coincide with the classifications for finite-valued VCSPs obtained in Section 3.4.
Theorem 3.27 applies to  = Q+ as well. Indeed, the hard cases remain intractable when
we allow more triangles (involving infinite costs), and the only tractable case, AQ+ ({<, =}),
remains tractable: AQ+ ({<, =}) is tractable by Theorem 3.1.
Theorem 3.41. For |D|  2, a class of binary general-valued VCSP instances defined as
AQ+ (S), where S  {4, <, >, =}, is tractable if and only if S  {<, =}.
Similarly with Theorem 3.33. Indeed, intractable cases remain intractable, and tractable
cases remain tractable.
Theorem 3.42. For |D|  2, a class of binary general-valued VCSP instances defined as
AQ+ (S), where S  {40 , <0 , >0 , 0}, is tractable if and only if S  {<0 , 0}, S  {>0 , 0} or
S  {40 , <0 , >0 }.
Similarly with Theorem 3.40. Indeed, intractable cases remain intractable, and tractable
cases remain tractable. (The class AQ+ ({>M , M }) becomes trivially tractable if M = 
as there is no solution of finite cost in instances with more than two variables.)
Theorem 3.43. For |D|  2, a class of binary general-valued VCSP instances defined
as AQ+ (S), where S  {4M , <M , >M , M }, is tractable if and only if S  {<M , M } or
S  {>M , M } or S  {4M , <M , >M }.

4. Cross-Free and Convex VCSPs
In Section 3, we studied the computational complexity of several classes of binary VCSPs.
In all considered cases, the joint-winner property (JWP) was either the only one or one of
only a few tractable cases.
In this section, we will generalise JWP to the cross-free convexity property (CFC). This
property defines a novel tractable class for which we describe an efficient algorithm. In
Section 4.4, we show that the neither of the two conditions in the definition of the CFC
474

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

property can be dropped without rendering the problem NP-hard. Moreover, in Section 4.5,
we present an extension of the CFC over Boolean domains. Section 4.6 is devoted to a related
idea of overlaps studied previously only for SAT and Max-SAT.
4.1 Definition and Examples of Cross-Free and Convex VCSPs
A function g : {0, . . . , s}  Q+ is called convex on the interval [l, u] if g is finite-valued on
the interval [l, u] and the derivative of g is non-decreasing on [l, u], i.e. g(m+2)g(m+1) 
g(m + 1)  g(m) for all m = l, . . . , u  2. For brevity, we will often say that g is convex if it
is convex on some interval [l, u]  [0, s] and infinite elsewhere (i.e. on [0, l  1]  [u + 1, s]).
Two sets A1 , A2  A are said to be nested if they are either disjoint or one is a subset
of the other (i.e. A1  A2 = , A1  A2 or A2  A1 ). If A1 and A2 are not nested, then we
say that they overlap. We say that A1 and A2 incompletely overlap if A1 and A2 overlap
and A1  A2 6= A.
Sets A1 , . . . , Ar are called laminar (Schrijver, 2003) (or hierarchically nested ; see Cooper
& Zivny, 2011a) if for any 1  i, j  r, Ai and Aj are nested. Sets A1 , . . . , Ar  A are
called cross-free if for every 1  i, j  r, either Ai  Aj , or Ai  Aj , or Ai  Aj = , or
Ai Aj = A (Schrijver, 2003). It is clear that if sets A1 , . . . , Ar are laminar, then A1 , . . . , Ar
are also cross-free.
For notational convenience, we interpret a solution x (i.e. an assignment to the variables
v1 , . . . , vn ) to a VCSP instance as the set of hvariable,valuei assignments {hvi , xi i | xi 
Di  i = 1, . . . , n}.
If Ai is a set of hvariable,valuei assignments of a VCSP instance P and x a solution to
P, then we use the notation |x  Ai | to represent the number of hvariable,valuei assignments
in the solution x which lie in Ai .
Definition 4.1 (Laminar/Cross-free convexity). Let P be a VCSP instance. Let A1 , . . . , Ar
be laminar (cross-free) sets of hvariable,valuei assignments of P. Let si be the number
of distinct variables occurring in the set of hvariable,valuei assignments Ai . Instance P
satisfies the laminar-free (cross-free) convexity property if the objective function of P is
g(x) = g1 (|x  A1 |) + . . . + gr (|x  Ar |) where each gi : [0, si ]  Q+ (i = 1, . . . , r) is convex
on an interval [li , ui ]  [0, si ] and gi (z) =  for z  [0, li  1]  [ui + 1, si ].
We remark that the functions gi in Definition 4.1 are not the cost functions associated
with the constraints.
It follows from the definition that the laminar convexity property implies the cross-free
convexity property.
Remark 4.2. Observe that the addition of any unary cost function cannot destroy the laminar or cross-free convexity property. This is because for each hvariable,valuei assignment
hvj , ai we can add the singleton Ai = {hvj , ai} which is necessarily either disjoint from or a
subset of any other set Ak (and furthermore the corresponding function gi : {0, 1}  Q+ is
trivially convex).
We now give a very special case of the cross-free convexity property, where all sets are
disjoint and thus trivially cross-free.
475

fiCooper & Zivny

Example 4.3 (Value-based soft GCC). The Global Cardinality Constraint (GCC),
introduced by Regin (1996), is a generalisation of the AllDifferent constraint (Regin,
1994). Given a set of n variables, the GCC specifies for each domain value d a lower
bound ld and an upper bound ud on the number of variables that are assigned value d. The
AllDifferent constraint is the special case of GCC with ld = 0 and ud = 1 for every d.
Soft versions of the GCC have been considered by van Hoeve, Pesant, & Rousseau (2006).
The value-based soft GCC minimises the number of values below or above the given
bound. We show that the value-based soft GCC satisfies the cross-free convexity property.
For every domain value d  D, let Ad = {hvi , di : i = 1, . . . , n}. Clearly, A1 , . . . , As are
disjoint, where s = |D|. For every d, let


ld  m if m < ld
gd (m) =
0
if ld  m  ud


m  ud if m > ud
It follows readily from the definition of gd that the sequence gd (m + 1)  gd (m), for m =
0, . . . , n  1, is the sequence 1, . . . , 1, 0, . . . , 0, 1, . . . , 1. Therefore, for every d, gd has a
non-decreasing derivative and hence is convex.
Example 4.4 (Nested value-based soft GCC). Being able to nest GCC constraints is useful
in many staff assignment problems where there is a hierarchy (e.g. senior manager-managerpersonnel, foreman-worker, or senior nurse-nurse) (Zanarini & Pesant, 2007). We might
want to impose soft global cardinality constraints such as each day we prefer that there
are between 10 and 15 people at work, of which at least 5 are managers among whom
there is exactly 1 senior manger, with convex penalties as described in Example 4.3 if these
constraints do not hold.
Suppose that the constraints of a VCSP instance consist of soft GCC constraints on
pairwise nested sets of variables S1 , . . . , St . Let Aid = {hx, di : x  Si }. Clearly, the
sets of assignments Aid are cross-free and, as shown in Example 4.3, the cost functions
corresponding to each soft GCC constraint are convex.
The main result of this section is the following theorem:
Theorem 4.5. Any VCSP instance P satisfying the cross-free convexity property can be
solved in polynomial time.
Firstly, we present an algorithm to solve VCSPs satisfying the laminar convexity property, followed by a reduction from the cross-free case to the laminar case. Secondly, we give
a proof of polynomial-time complexity of this algorithm.
4.2 Algorithm for Laminar Convex VCSPs
We call the sets Ai (i = 1, . . . , r) assignment-sets. We assume that the assignment-sets
Ai are distinct, since if Ai = Aj then these two sets can be merged by replacing the two
functions gi ,gj by their sum (which is necessarily also convex). Without loss of generality, we
can assume that the assignment-set consisting of all variable-value assignments is present,
and the corresponding function is the constant zero function. (If the corresponding function
476

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

gi is not the constant zero function, then we just add the constant term gi (n) to the objective
function.) This will be useful in the construction described below. We say that assignmentset Ak is the father of assignment-set Ai if it is the minimal assignment-set which properly
contains Ai , i.e. Ai  Ak and @Aj such that Ai  Aj  Ak . It follows from the definition
of laminarity that Ak is unique and hence that the father relation defines a tree. Moreover,
again from the definition of laminarity, for every variable vi of P and every a  Di , there is
a unique minimal assignment-set containing hvi , ai.
We construct a directed graph GP whose minimum-cost integral flows of value n are in
one-to-one correspondence with the solutions to P. GP has the following nodes:
1. the source node s;
2. a variable node vi (i = 1, . . . , n) for each variable of P;
3. an assignment node hvi , di (d  Di , i = 1, . . . , n) for each possible variable-value
assignment in P;
4. an assignment-set node Ai (i = 1, . . . , r) for each assignment-set in P;
5. the sink node t, which we identify with the assignment-set consisting of all variablevalue assignments.
GP has the following arcs:
1. a = (s, vi ) for each variable vi of P; the demand and capacity are given by d(a) =
c(a) = 1 (this forces a flow of exactly 1 through each variable node vi ); the weight
function is given by w(a) = 0;
2. a = (vi , hvi , di) for all variables vi and for each d  Di ; d(a) = 0; c(a) = 1; w(a) = 0;
3. a = (hvi , di, Aj ) for all variables vi and for each d  Di , where Aj is the minimal
assignment-set containing hvi , di; d(a) = 0; c(a) = 1; w(a) = 0;
4. for each assignment-set Ai with father Aj , there is an arc a from Ai to Aj with weight
function gi , demand d(a) = li and capacity c(a) = ui .
Clearly, GP can be constructed from P in polynomial time. We now prove that
minimum-cost flows f of value n in GP are in one-to-one correspondence with solutions
to P and, furthermore, that the cost of f is equal to the cost in P of the corresponding
solution.
All feasible flows have value n since all n arcs (s, vi ) leaving the source have both
demand and capacity equal to 1. Flows in GP necessarily correspond to the assignment
of a unique value xi to each variable vi since the flow of 1 through node vi must traverse
a node hvi , xi i for some unique xi  Di . It remains to show that for every assignment
x = {hv1 , x1 i, . . . , hvn , xn i} which is feasible (i.e. whose cost in P is finite), there is a
corresponding minimum-cost feasible flow f in GP of cost g(x) = g1 (|x  A1 |) + . . . + gr (|x 
Ar |).
For each arc a that is incoming to or outgoing from hvi , di in GP , let f (a) = 1 if
d = xi and 0 otherwise. By construction, each assignment-set node Ai in GP has exactly
477

fiCooper & Zivny

one outgoing arc to its father assignment-set. The flow fa in arc a from Ai to its father
assignment-set Aj is uniquely determined by the assignment of values to variables in the
solution x. Trivially, this is therefore
P a minimum-cost flow corresponding to the assignment
x. The cost of flow f is clearly i gi (|x  Ai |) which corresponds precisely to the cost of
the assignment x.
Having proved the correspondence between the cost of solutions to P and the cost of
minimum-cost flows, it follows that the algorithm, which for given P constructs GP and
finds a minimum-cost flow, is correct.
Example 4.6. Let P be a VCSP instance with 4 variables v1 , v2 , v3 , v4 , D1 = D2 = D3 =
D4 = {0, 1}, and the assignment-sets Ai , 1  i  8 given in Figure 6. The cost functions
gi , 1  i  8 are arbitrary convex functions.
The network GP corresponding to instance P is shown in Figure 7: demands and capacities are in square brackets for the corresponding layer of the graph, and weights of
arcs without numbers are 0. The only non-zero weight functions are on arcs between
assignment-sets; those arcs have the corresponding cost functions gi , 1  i  7. Set
A8 is identified with the sink t. Minimum-cost feasible flows in GP correspond to assignments to P modulo the addition of the constant g8 (4) (since there are 4 variables
and A8 consists of all variable-value assignments). The bold red edges represent flow
f corresponding to the assignment v1 = v2 = 1 and v3 = v4 = 0 with the total cost
g1 (1) + g2 (0) + g3 (2) + g4 (1) + g5 (0) + g6 (1) + g7 (3). Finding a minimum-cost flow in GP is
equivalent to finding an optimal solution to P.
4.3 From Laminar VCSPs to Cross-Free VCSPs
An alternative way of expressing the definition of cross-freeness is that for every 1  i, j  r,
one of Ai  (A \ Aj ), (A \ Ai )  Aj , Ai  Aj , (A \ Ai )  (A \ Aj ) is empty. It follows directly
that if A1 , . . . , Ar are cross-free then so are A1 , . . . , Ar , (A \ Ai ) for any 1  i  r.
We now show how to reduce any VCSP instance with the cross-free convexity property
to an instance satisfying the laminar convexity property.
First we show that without loss of generality, we can assume that every Ai satisfies
|Ai |  b|A|/2c, 1  i  r. Let Ai be arbitrary such that |Ai | > b|A|/2c. As pointed
out above, without loss of generality there is Aj , 1  j  r, such that Aj = A \ Ai . (If
there is no such Aj among A1 , . . . , Ar , we can add Aj with the corresponding convex cost
function being the constant zero cost function. This would only double the number of
assignment-sets.)
Let hi be defined by hi (y) = gi (n  y) and let gj0 = gj + hi . Clearly gj0 is convex, and
furthermore
gj0 (|Aj  x|) = gj (|Aj  x|) + hi (|Aj  x|)
= gj (|Aj  x|) + gi (n  |Aj  x|)
= gj (|Aj  x|) + gi (|A  x|  |Aj  x|)
= gj (|Aj  x|) + gi (|Ai  x|).
So we can eliminate the set Ai and its cost function gi by replacing gi , gj by a single cost
function gj0 .
478

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

A8

A1
A6

A2

hv1 , 0i hv3 , 0i

hv3 , 1i hv2 , 0i

A5
hv4 , 1i

A7
A3

A4

hv2 , 1i hv4 , 0i

hv1 , 1i

Figure 6: Laminar sets of assignments from instance P of Example 4.6.

[1, 1]

[0, 1]

[0, 1]

[li , ui ]

[li , ui ]

hv1 , 0i

hv1 , 1i

A1
v1

hv2 , 0i

v2

hv2 , 1i

g1
A2
g2

s

A3
v3

hv3 , 0i

v4

hv3 , 1i

A4
A5

A6

g6

A7

g7

g3

t

g4
g5

hv4 , 0i

hv4 , 1i

Figure 7: Network GP corresponding to the VCSP P of Example 4.6.

479

fiCooper & Zivny

Since all sets are at most half of the size of A, if Ai  Aj = A for some 1  i, j  r, then
necessarily Aj = A \ Ai . However, in this case, using the same argument as above, for each
such pair of complementary sets Ai and Aj , we can eliminate Ai and its cost function gi by
replacing gi , gj by a single cost function gj0 . Consequently, the resulting sets A1 , . . . , Ar are
laminar.
Complexity Let P be a VCSP instance with n variables, each with a domain of size
at most d, and r laminar assignment-sets Ai . The maximum number of distinct nonoverlapping sets Ai is 2nd  1 since the sets of assignments Ai form a tree with at most nd
leaves (corresponding to single hvariable,valuei assignments) and in which all non-leaf nodes
have at least two sons. Thus r = O(nd). The network GP has n0 = O(n + nd + r) = O(nd)
vertices and arcs. GP can be built in O((nd)2 ) time in a top-down manner, by adding
assignment-sets in inverse order of size (which ensures that an assignment-set is always
inserted after its father) and using a table T [hv, ai]=smallest assignment-set (in the tree
being built) containing hv, ai.
In a network with n0 vertices and m0 arcs with capacities at most U , the minimum convex
cost flow problem can be solved in time O((m0 log U )SP (n0 , m0 )), where SP (n0 , m0 ) is the
time to compute a shortest directed path in a network with n0 vertices and m0 edges (Ahuja,
Magnanti, & Orlin, 2005). Using Fibonacci heaps (Fredman & Tarjan, 1987), SP (n0 , m0 ) =
O(m0 + n0 log n0 ) = O(nd log(nd)), since the number of vertices n0 and arcs m0 are both
O(nd). The maximum capacity U in the network GP is at most n. Hence an optimal
solution to a cross-free convex VCSP can be determined in O((nd log n)(nd log(nd))) =
O((nd)2 (log n)(log n + log d)) time.
Remark 4.7. In our previous work (Cooper & Zivny, 2011b), we proved a special case
of Theorem 4.5 where all functions gi , 1  i  r, are non-decreasing and assignment sets
are laminar. (Previously, the laminar convexity property for non-decreasing functions gi ,
1  i  r, was called the non-overlapping convexity property; also, assignment-sets were
called assignment-cliques; see Cooper & Zivny, 2011b.)
The presented algorithm is similar to the algorithm of Cooper & Zivny (2011b) based
on finding a minimum-cost flow in a network. The main difference is that we require only
a single arc between any pair of nodes and the corresponding cost function gi is now an
arbitrary convex function (which is not necessarily non-decreasing). The running time of
our algorithm is thus better than the running time of the algorithm from our previous
work (Cooper & Zivny, 2011b), which is O(n3 d2 ). The improvement is mostly due to the
fact that the new construction involves only O(nd) arcs as opposed to O((nd)2 ) arcs in the
previous work (Cooper & Zivny, 2011b). Moreover, our algorithm solves a strictly bigger
class of problems compared to the previous result (Cooper & Zivny, 2011b). Overall, we
solve more and faster!
Remark 4.8. We remark that since our construction is projection-safe (Lee & Leung,
2009), it can be used for Soft Global Arc Consistency for cross-free convex constraints.
Remark
4.9. For a VCSP instance P with the objective function of the form g(x) =
Pr
i=1 gi (|xAi |), it follows from the definitions that we can test in polynomial time whether
or not P satisfies the cross-free convexity property; that is, whether gi are convex and Ai are
480

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

cross-free, for 1  i  r. In fact, the described algorithm requires that the assignment-sets
Ai and the functions gi be given explicitly.
In the conference version of this work (Cooper & Zivny, 2011a), we mentioned the
recognition problem as an open problem. In fact, this problem is easily shown intractable.
Given an arbitrary VCSP instance P, there always exists a cross-free convex instance P 0
whose optimal solution coincides with a fixed optimal solution to P. Therefore, finding P 0
is impossible in polynomial time unless P=NP as otherwise an arbitrary VCSP instance P
could be solved in polynomial time using Theorem 4.5.
4.4 Maximality of Cross-Free Convexity
This section shows that relaxing either convexity or cross-freeness (in fact, laminarity) in
Definition 4.1 leads to intractability.
Theorem 4.10. The class of VCSP instances whose objective function is of the form g(x) =
g1 (|x  A1 |) + . . . + gr (|x  Ar |) where the functions gi are convex, but the sets of assignments
Ai may overlap, is NP-hard, even if |Ai |  2 for all i  {1, . . . , r} and all variables are
Boolean.
Proof. It suffices to demonstrate a polynomial-time reduction from the well-known NP-hard
problem Max-2SAT (Garey & Johnson, 1979). Any Max-2SAT clause l1  l2 (where l1 , l2
are literals) is equivalent to the convex cost function g(|x  {l1 , l2 }|) where g(0) = 1 and
g(1) = g(2) = 0. It is therefore possible to code any instance of Max-2SAT using convex
cost functions (on possibly overlapping sets of assignments).
Theorem 4.11. The class of VCSP instances whose objective function is of the form g(x) =
g1 (|x  A1 |) + . . . + gr (|x  Ar |) where the sets of assignments Ai are laminar, but the
functions gi are not necessarily convex, is NP-hard even if |Ai |  3 for all i  {1, . . . , r}
and all variables are Boolean.
Proof. We give a polynomial-time reduction from the well-known NP-complete problem
3SAT (Garey & Johnson, 1979). Let I3SAT be an instance of 3SAT with m clauses.
The constraint AllEqual(l1 , l2 , l3 ) (where l1 , l2 , l3 are literals) is equivalent to the (nonconvex) cost function g(|x  {l1 , l2 , l3 }|) where g(0) = g(3) = 0 and g(1) = g(2) = .
For each variable v in I3SAT , we use the following gadget Gv based on non-overlapping
AllEqual constraints to produce multiple copies v1 , . . . , vm of the variable v and multiple
copies w1 , . . . , wm of its negation v: Gv consists of the constraints AllEqual(ui , vi , yi )
(i  {1, . . . , m}), AllEqual(yi , wi , ui+1 ) (i  {1, . . . , m  1}), and AllEqual(ym , wm , u1 ),
where the variables ui , yi occur only in the gadget Gv . It is easy to verify that Gv imposes
v1 = . . . = vm = w1 = . . . = wm . Furthermore, the variables vi , wi occur only negatively in
Gv . We now replace the ith clause of I3SAT by a clause in which each positive variable v
is replaced by its ith copy vi and each negative variable v is replaced by the ith copy wi of
v. This produces a laminar VCSP instance which is equivalent to I3SAT (but whose cost
functions are not all convex).
Note that the NP-hardness reduction in the proof of Theorem 4.11 requires assignmentsets of size up to 3. This leaves open the complexity of laminar (and cross-free) non-convex
VCSPs where all assignment-sets are of size at most 2.
481

fiCooper & Zivny

The following result shows that the complexity of cross-free non-convex VCSPs with
assignment-sets of size 2 and domains of size d is polynomial-time equivalent to cross-free
non-convex VCSPs with assignment-sets of size 2 and domains of size at most 3.
Proposition 4.12. Cross-free VCSPs with assignment-sets of size at most 2 and domains
of size d > 3 are polynomial-time equivalent to cross-free VCSPs with assignment-sets of
size at most 2 and domains of size at most 3.
Proof. First we observe that for VCSPs with assignment-sets of size at most 2, laminarity
and cross-freeness are almost identical. The extra condition in the definition of cross-freeness
(for A1 , A2  A, A1  A2 6=   A1  A2 = A) is irrelevant for instances with more than
3 variable-value assignments. Hence we only need to prove the equivalence for laminar
VCSPs.
Let v` be such that D` = {a1 , . . . , ak }, where k > 3. We replace v` by k variables
v`,1 , . . . , v`,k with respective domains D`,1 = {1, a1 }, D`,i = {0, 1, ai } for i = 2, . . . , k  1,
and D`,k = {0, ak }. (Here we assume, without loss of generality, that 0 and 1 are different
from ai , i = 1, . . . , k.) Moreover, we introduce k1 new assignment-sets {hv`,i , 1i, hv`,i+1 , 0i}
for i = 1, . . . , k  1 with the associated convex function g defined as g(1) = 0 and g(0) =
g(2) = . Finally, in any assignment-set involving the variable-value assignment hv` , ai i
(for some i  {1, . . . , k}), this assignment is replaced by hv`,i , ai i.
The function g applied to the assignment-sets {hv`,i , 1i, hv`,i+1 , 0i} ensures that the only
possible finite-cost assignments to variables v`,1 , . . . , v`,k are of the form 1, . . . , 1, ai , 0, . . . , 0.
Since exactly one of the variables v`,1 , . . . , v`,k is assigned a value from D` , there is a one-toone correspondence between optimal solutions to the transformed instance and the original
instance.
The tractability of cross-free non-convex VCSPs with assignment-sets of size 2 over
domains of size 3 (or larger, by Proposition 4.12) is left as an open problem.
The case of cross-free assignment-sets of size at most 2 over Boolean domains is shown
tractable in Theorem 4.21 in Section 4.6.
4.5 Renamable Boolean Cross-Free Convex VCSPs
In this section we extend the class of cross-free convex VCSPs to allow renaming of certain
variables in the case of Boolean domains. In this section we will consider only Boolean
VCSPs.
We begin by illustrating the notion of renaming by means of an example. First, we
require some notation. Cost function AtMostr (A) returns 0 if x contains at most r assignments from the set of assignments A, and AtMostr (A) returns 1 otherwise. Similarly,
cost function AtLeastr (A) returns 0 if x contains at least r assignments from the set of
assignments A, and AtLeastr (A) returns 1 otherwise. Note that cost functions AtLeast1
and AtMostr , where r = |A|  1, are both convex on [0, |A|].
Example 4.13. Let P be a Max-SAT instance given in CNF form by the following clauses:
(a  b  c),

(c  d),

(c  d  e),
482

(a  e).

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

Clearly, a clause with literals A can be written as AtLeast1 (A) in the VCSP encoding of
this instance. Notice that, in this example, the first two clauses are overlapping. However,
we can replace the second clause by the equivalent constraint AtMost1 ({c, d}). This
gives us an equivalent problem with the following constraints:
(a  b  c),

AtMost1 ({c, d}),

(c  d  e),

(a  e).

Now P is expressed as an instance satisfying the cross-free convexity property on the crossfree sets of assignments {a, b, c}, {c, d}, {c, d, e}, {a, e}.
Example 4.13 leads to the following definitions:
Definition 4.14. Given a valued constraint in the form of the cost function g(|x  A|),
where A is a set of Boolean assignments (i.e. literals) of size m, we define the renaming of
this valued constraint, on the set of Boolean assignments A = {` | `  A}, as the valued
constraint g 0 (|x  A|) = g(m  |x  A|) = g(|x  A|).
The function g 0 (z) = g(m  z) is clearly convex if and only if g is convex.
Definition 4.15. A Boolean VCSP instance P with the objective function g1 (|x  A1 |) +
. . . + gr (|x  Ar |) is renamable cross-free convex if there is a subset of the constraints of P
whose renaming results in an equivalent VCSP instance P 0 which is cross-free convex.
Theorem 4.16. The class of renamable cross-free convex VCSPs is recognisable and solvable in polynomial time.
Proof. We show that recognition is polynomial-time by a simple reduction to 2-SAT, a
well-known problem solvable in polynomial time (Garey & Johnson, 1979). Let P be a
Boolean VCSP instance with r constraints such that the ith constraint (i = 1, . . . , r) is
gi (|x  Ai |) for a convex function gi . For each constraint in P, there is a Boolean variable
reni indicating whether or not the ith constraint is renamed. For each pair of distinct
i, j  {1, . . . , r}, we add clauses of length 2 as follows:
1. if Ai and Aj incompletely overlap then add constraint reni  renj (since we must
rename just one of the two constraints);
2. if Ai and Aj incompletely overlap then add constraint reni  renj (to avoid introducing an overlap by a renaming).
It is easy to see that solutions to the constructed 2-SAT instance correspond to valid
renamings of P which give rise to an equivalent VCSP instance satisfying the cross-free
convexity property. Tractability of solving the resulting renamed instance follows directly
from Theorem 4.5.
4.6 Knuth-Nested VCSPs
In order to relate our work to previous work, in this section we present a different class
of tractable VCSPs which considers sets of variables (rather than sets of assignments) and
allows overlaps of size 1. We show that a known tractable class can be extended from
Max-SAT to VCSPs. We then apply this result to show that in a very special case the
assumption of convexity in cross-free convex VCSPs can be dropped.
483

fiCooper & Zivny

Definition 4.17. Given a VCSP instance P with variables V = {v1 , . . . , vn } and constraints
with scopes C = {C1 , . . . , Cm }, we define the incidence graph of P as IP = (V (IP ), E(IP )),
where V (IP ) = V  C and E(IP ) = {{vi , Cj } | vi  Cj }.
Definition 4.18. A VCSP instance P is called Knuth-nested if the variables of P can
be linearly ordered v1 , . . . , vn such that IP together with the edges {{vi , vi+1 } | 1  i 
n}  {vn , v1 } allows a planar drawing so that the circle v1 , . . . , vn , v1 bounds the outer face.
P is called Knuth-co-nested if the constraint scopes of P can be linearly ordered C1 , . . . , Cm
such that IP together with the edges {{Ci , Ci+1 } | 1  i  m}  {Cm , C1 } allows a planar
drawing so that the circle C1 , . . . , Cm , C1 bounds the outer face.
Knuth described a linear-time algorithm for solving Knuth-nested SAT instances (Knuth,
1990). Kratochvl and Krivanek generalised Knuths result and provided a linear-time algorithm for recognising and solving Knuth-nested and Knuth-co-nested SAT/Max-SAT
instances (Kratochvl & Krivanek, 1993). Henderson in his Masters thesis showed several
different proofs of these results, including a proof that Knuth-nested and Knuth-co-nested
SAT/Max-SAT instances have treewidth at most three (Biedl & Henderson, 2004; Henderson, 2005), and hence are solvable in polynomial time via a standard dynamic programming
approach.
Theorem 4.19. The class of Knuth-nested and Knuth-co-nested VCSP instances with constraints of bounded arity is recognisable and solvable in polynomial time.
Proof. Recognition can be reduced, via a simple reduction from the work of Kratochvl and
Krivanek (1993), to the planarity testing problem (Hopcroft & Tarjan, 1974).
Following Hendersons argument (2005, p. 21), it is easy to show that if P is Knuthnested or Knuth-co-nested, then the incidence graph IP of P has treewidth at most 3. A
VCSP with domains of size at most d, constraints of arity at most k and incidence graph
IP is clearly equivalent to a binary VCSP with constraint graph IP in which domains are
of size at most dk . The result then follows from the fact that any VCSP instance with a
constraint graph of bounded treewidth is solvable in polynomial time (Bertele & Brioshi,
1972).
Note that the class of Knuth-nested (Knuth-co-nested) VCSP instances (in fact, even
SAT instances) cannot be generalised as it follows from the work of Lichtenstein (1982) that
the satisfiability of the conjunction of two Knuth-nested formulas is NP-complete.
We now show that the class of Knuth-nested/Knuth-co-nested instances from this section
is incomparable with the class of cross-free convex instances defined in Section 4.1 even in
the special case of Boolean formulas. Moreover, we also show that the class of Knuthnested/Knuth-co-nested instances is incomparable with the class of renamable Boolean
cross-free convex instances defined in Section 4.5.
Example 4.20. The SAT instance I = (x  y)  (y  z)  (y  w) is Knuth-nested and
Knuth-co-nested, but neither cross-free nor renamable cross-free.
The following SAT instance is neither Knuth-nested nor Knuth-co-nested, but is crossfree (in fact laminar): (x  y  z)  (x  u  v)  (y  u  w)  (z  v  w).
484

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

We now turn our attention to cross-free VCSPs with possibly non-convex cost functions
and assignment-sets of size at most 2. We show that the tractability of Boolean VCSP
instances, i.e. instances over 2-element domains, follows from Theorem 4.19. Recall that the
case of convex cost functions is tractable from Theorem 4.5, but that, from Theorem 4.11,
the case of non-convex cost functions is intractable for assignments sets of size 3.
Theorem 4.21. Any cross-free Boolean VCSP instance with assignment-sets of size at
most 2 is solvable in polynomial time.
Proof. As mentioned in the proof of Proposition 4.12, first observe that for VCSPs with
assignment-sets of size 2 (or any fixed size for that matter) laminarity and cross-freeness
are almost identical. The extra condition in the definition of cross-freenes (for A1 , A2  A,
A1  A2 6=   A1  A2 = A) is irrelevant for instances with more than 3 variable-value
assignments. Hence we only need to prove tractability for laminar Boolean VCSPs with
assignment-sets of size at most 2.
We show that any Boolean VCSP with laminar assignment-sets of size at most 2 is
Knuth-nested. Tractability then follows from Theorem 4.19.
Take an arbitrary variable, for instance v1 . We will show that there is an order < of
variables satisfying the requirements of the Knuth-nested property. Since |D1 | = 2, there
are at most two assignment-sets, say Ai and Aj , containing (different) assignments to v1 .
Now since all assignment-sets are of size at most two, there is at most one more assignment
in Ai , say an assignment to variable vk . We define v1 < vk . Similarly, there is at most one
more assignment in Aj , say an assignment to variable vl , and we define vl < v1 . Continuing
the same reasoning for variables vl and vk , we can get another variable smaller (in the order
< we are building) than vl and another variable bigger than vk . This has to stop eventually:
either there are no more variables, or some assignment-set is of size 1, or some variable has
domain of size 1, or the last considered assignment-set contains assignments to the smallest
and the biggest variables (in the order <). It is easy to observe that in all cases we have a
planar drawing as required in Definition 4.18. If there are some variables left, we continue
in the same way.
Next we show that cross-free VCSPs over 3-element domains with assignments sets of
size at most 2 may be neither Knuth-nested nor Knuth-co-nested.
Example 4.22. Take four variables x, y, z, w with the domain {0, 1, 2}, and sets A1 =
{hx, 0i, hy, 0i}, A2 = {hy, 1i, hz, 0i}, A3 = {hx, 1i, hz, 1i}, A4 = {hy, 2i, hw, 0i}. This instance
is cross-free (in fact laminar), but is neither Knuth-nested nor Knuth-co-nested.

5. Conclusions
We have studied hybrid reasons for tractability for optimisation problems that can be cast as
Valued Constraint Satisfaction Problems (VCSPs), or equivalently Markov Random Fields
(MRFs) or Min-Sum problems. These are reasons for tractability that do not follow from
the restriction on the functions (such as submodularity) or from the restriction on the
structure of the instance (such as bounded treewidth).
Firstly, we have studied binary VCSPs (also known as pairwise MRFs). In the CSP
and Max-CSP case, we have obtained a complete dichotomy concerning the tractability
485

fiCooper & Zivny

of problems defined by placing restrictions on the possible combinations of binary costs
in triangles of variable-value assignments. In the case of finite-valued and general-valued
VCSP, we have obtained complete dichotomies with respect to equivalence classes which
naturally follow from the total order on the valuation structure. We have shown that the
joint-winner property and maximum (weighted) matching are the only non-trivial tractable
classes.
Secondly, we have studied non-binary VCSPs. We have presented a novel class of optimisation problems that can be solved efficiently using flow techniques. The new class
is defined as problems with convex functions over a cross-free family of variable-value assignments. We have shown that neither of the two conditions on its own is sufficient for
tractability. Moreover, over Boolean domains, we have managed to extend the new class
using the idea of renamability.
We have left open one special case, namely the tractability of cross-free non-convex
VCSPs with assignment-sets of size at most 2 and domains of size at most 3. (Assignmentsets of size 3 make the problem intractable even for Boolean domains, and assignment-sets
of size 2 over Boolean domains have been shown tractable.)

Acknowledgments
Martin Cooper is supported by ANR Projects ANR-10-BLAN 0210 and 0214. Stanislav
Zivny is supported by a Junior Research Fellowship at University College, Oxford.

References
Ahuja, R., Magnanti, T., & Orlin, J. (2005). Network Flows: Theory, Algorithms, and
Applications. Prentice Hall/Pearson.
Bertele, U., & Brioshi, F. (1972). Nonserial dynamic programming. Academic Press.
Biedl, T., & Henderson, P. (2004). Nested SAT Graphs have Treewidth Three. Tech. rep.
CS-2004-70, University of Waterloo.
Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based Constraint Satisfaction
and Optimisation. Journal of the ACM, 44 (2), 201236.
Boros, E., & Hammer, P. L. (2002). Pseudo-Boolean optimization. Discrete Applied Mathematics, 123 (1-3), 155225.
Bulatov, A., Krokhin, A., & Jeavons, P. (2005). Classifying the Complexity of Constraints
using Finite Algebras. SIAM Journal on Computing, 34 (3), 720742.
Cohen, D., & Jeavons, P. (2006). The complexity of constraint languages. In Rossi, F., van
Beek, P., & Walsh, T. (Eds.), The Handbook of Constraint Programming. Elsevier.
Cohen, D. A. (2003). A New Class of Binary CSPs for which Arc-Constistency Is a Decision
Procedure. In Proceedings of the 9th International Conference on Principles and
Practice of Constraint Programming (CP03), Vol. 2833 of Lecture Notes in Computer
Science, pp. 807811. Springer.
Cohen, D. A., Cooper, M. C., Green, M., & Marx, D. (2011). On guaranteeing polynomiallybounded search tree size. In Proceedings of the 17th International Conference on
486

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

Principles and Practice of Constraint Programming (CP11), Vol. 6876 of Lecture
Notes in Computer Science, pp. 160171. Springer.
Cohen, D. A., Cooper, M. C., & Jeavons, P. G. (2008). Generalising submodularity and Horn
clauses: Tractable optimization problems defined by tournament pair multimorphisms.
Theoretical Computer Science, 401 (1-3), 3651.
Cohen, D. A., Cooper, M. C., Jeavons, P. G., & Krokhin, A. A. (2006). The Complexity of
Soft Constraint Satisfaction. Artificial Intelligence, 170 (11), 9831016.
Cooper, M. C., Jeavons, P. G., & Salamon, A. Z. (2010). Generalizing constraint satisfaction
on trees: Hybrid tractability and variable elimination. Artificial Intelligence, 174 (9
10), 570584.
Cooper, M. C., & Zivny, S. (2011a). Hierarchically nested convex VCSP. In Proceedings
of the 17th International Conference on Principles and Practice of Constraint Programming (CP11), Vol. 6876 of Lecture Notes in Computer Science, pp. 187194.
Springer.
Cooper, M. C., & Zivny, S. (2011b). Hybrid tractability of valued constraint problems.
Artificial Intelligence, 175 (9-10), 15551569.
Cooper, M. C., & Zivny, S. (2011c). Tractable triangles. In Proceedings of the 17th International Conference on Principles and Practice of Constraint Programming (CP11),
Vol. 6876 of Lecture Notes in Computer Science, pp. 195209. Springer.
Creignou, N., Khanna, S., & Sudan, M. (2001). Complexity Classification of Boolean Constraint Satisfaction Problems, Vol. 7 of SIAM Monographs on Discrete Mathematics
and Applications. SIAM.
Dalmau, V., Kolaitis, P. G., & Vardi, M. Y. (2002). Constraint Satisfaction, Bounded
Treewidth, and Finite-Variable Logics. In Proceedings of the 8th International Conference on Principles and Practice of Constraint Programming (CP02), Vol. 2470 of
Lecture Notes in Computer Science, pp. 310326. Springer.
Dechter, R., & Pearl, J. (1988). Network-based Heuristics for Constraint Satisfaction Problems. Artificial Intelligence, 34 (1), 138.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Downey, R., & Fellows, M. (1999). Parametrized Complexity. Springer.
Edmonds, J. (1965a). Maximum Matching and a Polyhedron with 0, 1 Vertices. Journal of
Research National Bureau of Standards, 69 B, 125130.
Edmonds, J. (1965b). Paths, trees, and flowers. Canadian Journal of Mathematics, 17,
449467.
Feder, T., & Vardi, M. Y. (1998). The Computational Structure of Monotone Monadic
SNP and Constraint Satisfaction: A Study through Datalog and Group Theory. SIAM
Journal on Computing, 28 (1), 57104.
Fredman, M. L., & Tarjan, R. E. (1987). Fibonacci heaps and their uses in improved network
optimization algorithms. Journal of the ACM, 34 (3), 596615.
487

fiCooper & Zivny

Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory
of NP-Completeness. W.H. Freeman.
Geman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the
bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 6 (6), 7210741.
Goodman, A. W. (1959). On Sets of Acquaintances and Strangers at any Party. The
American Mathematical Monthly, 66 (9), 778783.
Grohe, M. (2007). The complexity of homomorphism and constraint satisfaction problems
seen from the other side. Journal of the ACM, 54 (1), 124.
Henderson, P. (2005). Planar Graphs and Partial k-Trees. Masters thesis, University of
Waterloo.
Hooker, J. (2007). Integrated Method for Optimization. Springer.
Hopcroft, J. E., & Tarjan, R. E. (1974). Efficient planarity testing. Journal of the ACM,
21 (4), 549568.
Jeavons, P. G. (1998). On the Algebraic Structure of Combinatorial Problems. Theoretical
Computer Science, 200 (1-2), 185204.
Jonsson, P., Kuivinen, F., & Nordh, G. (2008). MAX ONES Generalized to Larger Domains.
SIAM Journal on Computing, 38 (1), 329365.
Jonsson, P., Kuivinen, F., & Thapper, J. (2011). Min CSP on Four Elements: Moving
Beyond Submodularity. In Proceedings of the 17th International Conference on Principles and Practice of Constraint Programming (CP11), Vol. 6876 of Lecture Notes
in Computer Science, pp. 438453. Springer.
Jonsson, P., & Nordh, G. (2008). Introduction to the maximum solution Problem. In
Complexity of Constraints, Vol. 5250 of Lecture Notes in Computer Science, pp. 255
282. Springer.
Khanna, S., Sudan, M., Trevisan, L., & Williamson, D. (2001). The approximability of
constraint satisfaction problems. SIAM Journal on Computing, 30 (6), 18631920.
Knuth, D. E. (1990). Nested satisfiability. Acta Informatica, 28 (1), 16.
Kolmogorov, V. (2011). Submodularity on a tree: Unifying l] -convex and bisubmodular
functions. In Proceedings of the 36th International Symposium on Mathematical Foundations of Computer Science (MFCS11), Vol. 6907 of Lecture Notes in Computer
Science, pp. 400411. Springer.
Kolmogorov, V., & Zivny, S. (2012). The complexity of conservative valued CSPs. In
Proceedings of the 23rd Annual ACM-SIAM Symposium on Discrete Algorithms
(SODA12), pp. 750759. SIAM. Full version available on arXiv:1110.2809.
Kratochvl, J., & Krivanek, M. (1993). Satisfiability of co-nsted formulas. Acta Informatica,
30 (4), 397403.
Lauritzen, S. L. (1996). Graphical Models. Oxford University Press.
488

fiTractable Triangles and Cross-Free Convexity in Discrete Optimisation

Lee, J. H.-M., & Leung, K. L. (2009). Towards efficient consistency enforcement for global
constraints in weighted constraint satisfaction. In Proceedings of the 21st International
Joint Conference on Artificial Intelligence (IJCAI09), pp. 559565.
Lewis, J. M., & Yannakakis, M. (1980). The node-deletion problem for hereditary properties
is NP-complete. Journal of Computer System Sciences, 20 (2), 219230.
Lichtenstein, D. (1982). Planar formulae and their uses. SIAM Journal on Computing,
11 (2), 329343.
Lovasz, L. (1973). Coverings and colorings of hypergraphs. In Proceedings of the 4th
Southeastern Conference on Combinatorics, Graph Theory and Computing, pp. 312.
Maffray, F., & Preissmann, M. (1996). On the NP-completeness of the k-colorability problem
for triangle-free graphs. Discrete Mathematics, 162 (1-3), 313317.
Marx, D. (2010). Tractable hypergraph properties for constraint satisfaction and conjunctive queries. In Proceedings of the 42nd ACM Symposium on Theory of Computing
(STOC10), pp. 735744.
Meseguer, P., Rossi, F., & Schiex, T. (2006). Soft constraints. In Rossi, F., van Beek, P.,
& Walsh, T. (Eds.), The Handbook of Constraint Programming. Elsevier.
Minoux, M. (1984). A polynomial algorithm for minimum quadratic cost flow problems.
European Journal of Operational Research, 18, 377387.
Minoux, M. (1986). Solving integer minimum cost flows with separable convex cost objective
polynomially. Mathematic Programming Studies, 26, 237239.
Montanari, U. (1974). Networks of Constraints: Fundamental properties and applications
to picture processing. Information Sciences, 7, 95132.
Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.
Papadimitriou, C. H., & Yannakakis, M. (1991). Optimization, Approximation, and Complexity Classes. Journal of Computer and System Sciences, 43 (3), 425440.
Poljak, S. (1974). A note on stable sets and colorings of graphs. Commentationes Mathematicae Universitatis Carolinae, 15 (2), 307309.
Regin, J.-C. (1994). A filtering algorithm for constraints of difference in CSPs. In Proceedings
of the 12th National Conference on AI (AAAI94), Vol. 1, pp. 362367.
Regin, J.-C. (1996). Generalized Arc Consistency for Global Cardinality Constraint. In
Proceedings of the 13th National Conference on AI (AAAI96), Vol. 1, pp. 209215.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). The Handbook of Constraint Programming. Elsevier.
Schaefer, T. J. (1978). The Complexity of Satisfiability Problems. In Proceedings of the 10th
Annual ACM Symposium on Theory of Computing (STOC78), pp. 216226. ACM.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued Constraint Satisfaction Problems:
Hard and Easy Problems. In Proceedings of the 14th International Joint Conference
on Artificial Intelligence (IJCAI95), pp. 631637.
Schrijver, A. (2003). Combinatorial Optimization: Polyhedra and Efficiency, Vol. 24 of
Algorithms and Combinatorics. Springer.
489

fiCooper & Zivny

Takhanov, R. (2010). A Dichotomy Theorem for the General Minimum Cost Homomorphism Problem. In Proceedings of the 27th International Symposium on Theoretical
Aspects of Computer Science (STACS10), pp. 657668.
van Hoeve, W. J., Pesant, G., & Rousseau, L.-M. (2006). On global warming: Flow-based
soft global constraints. Journal of Heuristics, 12 (4-5), 347373.
Wainwright, M. J., & Jordan, M. I. (2008). Graphical models, exponential families, and
variational inference. Foundations and Trends in Machine Learning, 1 (1-2), 1305.
Werner, T. (2007). A Linear Programming Approach to Max-Sum Problem: A Review.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (7), 11651179.
Zanarini, A., & Pesant, G. (2007). Generalizations of the global cardinality constraint for hierarchical resources. In Proceedings of the 4th International Conference on Integration
of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems (CPAIOR07), Vol. 4510 of Lecture Notes in Computer Science, pp.
361375. Springer.

490

fiJournal of Artificial Intelligence Research 44 (2012) 633-708

Submitted 11/11; published 08/12

The Logical Difference for the
Lightweight Description Logic EL
Boris Konev
Michel Ludwig

konev@liverpool.ac.uk
michel.ludwig@liverpool.ac.uk

Department of Computer Science
University of Liverpool, UK

Dirk Walther

dirk.walther@upm.es

Departamento Inteligencia Artificial, Facultad de Informatica
Universidad Politecnica de Madrid, Spain

Frank Wolter

wolter@liverpool.ac.uk

Department of Computer Science
University of Liverpool, UK

Abstract
We study a logic-based approach to versioning of ontologies. Under this view, ontologies
provide answers to queries about some vocabulary of interest. The difference between
two versions of an ontology is given by the set of queries that receive different answers.
We investigate this approach for terminologies given in the description logic EL extended
with role inclusions and domain and range restrictions for three distinct types of queries:
subsumption, instance, and conjunctive queries. In all three cases, we present polynomialtime algorithms that decide whether two terminologies give the same answers to queries
over a given vocabulary and compute a succinct representation of the difference if it is nonempty. We present an implementation, CEX2, of the developed algorithms for subsumption
and instance queries and apply it to distinct versions of Snomed CT and the NCI ontology.

1. Introduction
Terminologies are lightweight ontologies that are used to provide a common vocabulary
for a domain of interest together with descriptions of the meaning of terms built from the
vocabulary and relationships between them. They are being used in areas such as medical
informatics, bio-informatics, and the semantic web to capture domain semantics and promote interoperability. Terminologies are often large and complex. For example, the widely
used medical terminology Snomed CT (Systematized Nomenclature of Medicine Clinical
Terms) contains more than 300 000 term definitions (IHTSDO, 2008). Another example is
the National Cancer Institute ontology (NCI) consisting of more than 60 000 axioms (Golbeck, Fragaso, Hartel, Hendler, Oberhaler, & Parsia, 2003). Engineering, maintaining, and
using such terminologies is a complex and laborious task, which is practically unfeasible
without appropriate tool support. In this article, we focus on a principled logic-based
approach to support for terminology versioning.
Dealing with multiple versions of the same information unit is nothing new in computing, and version control is a well established computer technology. Although modern version
control systems provide a range of operations including support for collaborative development, branching, merging, etc., these operations extend and rely on the basic operations of
c
2012
AI Access Foundation. All rights reserved.

fiKonev, Ludwig, Walther, & Wolter

detecting and representing the differences between versions. In this paper, we focus on this
basic problem of versioning.
The need for versioning support is recognised by the ontology research community and
ontology users, and a large number of approaches and tools have been developed. In our
review of currently existing support for ontology versioning, we distinguish three approaches
and describe them according to the difference between ontologies they compute:
1. versioning based on syntactic difference (syntactic diff);
2. versioning based on structural difference (structural diff);
3. versioning based on logical difference (logical diff).
The syntactic diff underlies most existing version control systems used in software development (Conradi & Westfechtel, 1998) (such as, for example, RCS, CVS, SCCS). It works
with text files and represents the difference between versions as blocks of text present in one
version but not another, ignoring any meta-information about the document. As observed
already in the work of Noy and Musen (2002), ontology versioning cannot rely on a purely
syntactic diff operation since many syntactic differences (e.g., the order of ontology axioms)
do not affect the semantics of ontologies. Therefore, ontology versioning based on syntactic
difference is essentially limited to comparing rather informal change logs (Oliver, Shahar,
Shortliffe, & Musen, 1999).
The structural diff extends the syntactic diff by taking into account information about
the structure of ontologies. It has been suggested for dealing with structured and hierarchical documents such as UML diagrams, database schemas, or XML documents (see, e.g.,
Ohst, Welle, & Kelter, 2003, and references within). For ontologies, the main characteristic
of the structural diff is that it regards them as structured objects, such as an is-a taxonomy (Noy & Musen, 2002), a set of RDF triplets (Klein, Fensel, Kiryakov, & Ognyanov,
2002) or a set of class defining axioms (Redmond, Smith, Drummond, & Tudorache, 2008;
Jimenez-Ruiz, Cuenca Grau, Horrocks, & Llavori, 2011). Changes to ontologies are mostly
described in terms of structural operations, for example, adding or deleting a class, extending a class, renaming slots, moving a class from one place in the hierarchy to another,
adding or deleting an axiom, class renaming, etc.; sometimes basic logical properties of
ontologies, e.g., the equivalence of different structural forms of concepts, are also taken into
account (Palma, Haase, Corcho, & Gomez-Perez, 2009; Jimenez-Ruiz et al., 2011). Ontology versioning based on structural diff of some form is available in most current ontology
editors and ontology management systems either natively or through plugins (Noy & Musen,
2002; Klein et al., 2002; Jimenez-Ruiz et al., 2011).
Though very helpful, the structural diff still has the deficiency of having no unambiguous semantic foundation and being syntax dependent. Moreover, it is tailored towards
applications of ontologies which are based on the induced concept hierarchy (or some mild
extension of it), but does not capture modern applications such as ontology based data access (OBDA) (Poggi, Lembo, Calvanese, Giacomo, Lenzerini, & Rosati, 2008; Lutz, Toman,
& Wolter, 2009) in which ontologies are used to provide a user-oriented view of the data
634

fiThe Logical Difference for the Lightweight Description Logic EL

and make it accessible via queries formulated solely in the language of the ontology without
any knowledge of the actual structure of the data.1
The logical diff has only been recently introduced (Konev, Walther, & Wolter, 2008;
Kontchakov, Wolter, & Zakharyaschev, 2010) and completely abstracts from the representation of the ontology. Here, an ontology is regarded as a set of axioms formulated in a logical
language with a formal and unambiguous semantics. Under this view, ontologies provide
answers to queries about some vocabulary of interest. Typical queries include subsumption
queries between concepts and, if the ontology is used to access instance data, instance and
conjunctive queries. The logical diff is motivated by this view. If two versions of an ontology
give the same answers to a class of queries relevant to an application domain, they may be
deemed to have no difference regardless of their syntactic or structural form; and queries
producing different answers from the versions may be considered as a characterisation of
the difference itself. In this way one can, for example, define exactly the differences visible
when querying instance data or exactly the differences expressed by subsumptions between
concepts.
To make this approach work in practice, at least two problems have to be addressed:
 For most ontology languages and classes of queries the computational complexity of
even detecting if two ontology versions differ over a certain vocabulary is at least
one exponential harder than ontology classification and is sometimes undecidable;
and even if the computational complexity does not increase, searching for differences
between ontologies within a certain vocabulary requires techniques that are very different from those used for standard reasoning (Lutz, Walther, & Wolter, 2007; Lutz
& Wolter, 2010; Cuenca Grau, Horrocks, Kazakov, & Sattler, 2008).
 If the set of queries producing different answers from the two versions is not empty,
it is typically infinite and, therefore, cannot be presented to the user as such. Thus,
techniques to succinctly characterise its elements and present them to the user are
required.
The aim of this paper is to provide first steps toward solutions to these problems for
terminologies (aka classical TBoxes) given in the description logic ELHr that extends the
description logic EL underlying the OWL 2 EL profile with role inclusions and domain and
range restrictions (Baader, Brandt, & Lutz, 2008). Our main contributions are as follows:
1. It has been argued that syntax-dependence should be regarded as an advantage rather than a deficiency
in the context of versioning (Goncalves, Parsia, & Sattler, 2011; Jimenez-Ruiz et al., 2011). For example, Jimenez-Ruiz et al. argue that logical equivalence between ontologies can be too permissive: even if
O  O0  the strongest assumption from a semantic point of view  conflicts may still exist. This might
result from the presence of incompatible annotations (statements that act as comments and do not carry
logical meaning), or a mismatch in modelling styles; for example, O may be written in a simple language
such as the OWL 2 EL profile and contain  = (A v B u C), while O0 may contain  = (B t C v A).
Even though   , the explicit use of negation and disjunction means that O0 is outside the EL profile.
We agree with Jimenez-Ruiz et al. and Goncalves et al. that there are various applications in which a
structural rather than logical difference is appropriate. Even a syntactic diff has applications in ontology
versioning. In practice, we see logic-based approaches as complementary to structural approaches. An
interesting analysis of NCI versions taking into account both structural and logical differences is given
in the work of Goncalves et al.

635

fiKonev, Ludwig, Walther, & Wolter

 for subsumption, instance, and conjunctive queries, we present polynomial-time algorithms
that decide whether two ELHr -terminologies give different answers to some query from the
respective class of queries over a given signature of concept and role names (note that we
use the terms signature and vocabulary synonymously).
 Besides of a polynomial-time decision procedure detecting differences, we also develop a
succinct presentation of the (typically infinite) difference. This presentation can be computed in polynomial time as well.
 We present two different types of polynomial-time algorithms for deciding the existence
of logical differences between terminologies and for computing a succinct representation
of it: the first type of algorithms is conceptually more transparent as it keeps the two
input terminologies separate and reduces (a substantial part of) the difference problem to
an instance checking problem for an ABox. Such algorithms are, however, not sufficiently
efficient on very large inputs. For example, substantial performance problems occur when
computing the differences between versions of Snomed CT on their joint signature since
the constructed ABox is typically of quadratic size in the input terminologies. The second
variant of algorithms, which is based on dynamic programming, is more efficient in practice.
It is developed in detail for acyclic ELHr -terminologies.
 We present an implementation, CEX2, that is based on the second type of algorithms and
computes a succinct representation of the difference between acyclic ELHr -terminologies
for the concept and instance query case. In addition, a prototype implementation of the
ABox-based algorithm is used to estimate its efficiency.
 As an important tool in our investigation, we present description logics, ELran and
ELran,u,u , that capture as subsumption differences the instance and query difference between ELHr -terminologies. This result is presented for general ELHr -TBoxes and can,
therefore, be exploited in future work on versioning for general ELHr -TBoxes.
 We present experiments using CEX2 that illustrate the efficiency of the algorithms and
potential applications to terminologies such as Snomed CT and NCI. A plugin for Protege
is discussed. CEX2 extends the functionality of the first version of CEX (Konev, Walther, &
Wolter, 2008) and of the OwlDiff plugin (Kremen, Smd, & Kouba, 2011), which implements
the algorithms developed by Konev, Walther, and Wolter. Based on Snomed CT, we also
investigate the performance of the ABox-based algorithms in practice.
This paper is based on, and extends the work of Konev, Walther, and Wolter (2008).
To improve readability, a number of proofs have been deferred to an appendix.

2. Preliminaries
Let NC , NR , and NI be countably infinite and mutually disjoint sets of concept names, role
names, and individual names. EL-concepts C are built according to the rule
C :=

A

|

>

| C uD

|

r.C,

where A  NC , r  NR , and C, D range over EL-concepts. The set of ELHr -inclusions
consists of
 concept inclusions C v D, ran(r) v D and ran(r) u C v D,
636

fiThe Logical Difference for the Lightweight Description Logic EL

 concept equations C  D, and
 role inclusions r v s,
where C and D are EL-concepts and r, s  NR . An ELHr -TBox T is a finite set of ELHr inclusions. Inclusions of the form ran(r) v D and ran(r)uC v D are also referred to as range
restrictions, and inclusions of the form r.> v D are referred to as domain restrictions.
An ELHr -TBox is called an ELHr -terminology if all its concept inclusions and equations
are of the form
 A v C and A  C,
 ran(r) v C, and
 r.> v C,
where A  NC and r  NR , C is an EL-concept such that C 6= >, C 6= > u >, etc., and no
concept name occurs more than once on the left-hand side. Note that, in concept inclusions
of the form r.> v C, the concept r.> is often denoted dom(r). A terminology is acyclic
(or unfoldable) if the process of exhaustively substituting definitions in place of the defined
concept names terminates. For example, if a terminology contains a concept inclusion
Mother v hasMother.Mother
it is not acyclic. Formally, consider the relation T between concept names by setting
A T B if there exists an ELHr -inclusion of the form A  C or A v C in T such that B
occurs in C. A terminology T is acyclic if the transitive closure +
T of T is irreflexive.
In description logic, instance data are represented by ABox assertions of the form >(a),
A(a) and r(a, b), where a, b  NI , A  NC , and r  NR . An ABox A is a non-empty finite
set of ABox-assertions. A is said to be a singleton ABox if it contains exactly one ABox
assertion. By obj(A) we denote the set of individual names in A. A knowledge base K (KB)
is a pair (T , A) consisting of a TBox T and an ABox A. Assertions of the form C(a) and
r(a, b), where a, b  NI , C an EL-concept, and r  NR , are called instance assertions. Note
that instance assertions of the form C(a) with C not a concept name nor C = > do not
occur in ABoxes.
The semantics of ELHr is given by interpretations I = (I , I ), where the domain I
is a non-empty set, and I is a function mapping each concept name A to a subset AI of
I , each role name r to a binary relation rI  I  I , and each individual name a to an
element aI  I . The extension C I of a concept C is defined by induction as follows:
>I
(C u D)I
(r.C)I
ran(r)I

:=
:=
:=
:=

I
C I  DI
{d  I | e  C I : (d, e)  rI }
{d  I | e : (e, d)  rI }

I satisfies
 a concept inclusion C v D, in symbols I |= C v D, if C I  DI ;
637

fiKonev, Ludwig, Walther, & Wolter

 a concept equation C  D, in symbols I |= C  D, if C I = DI ;
 a role inclusion r v s, in symbols I |= r v s, if rI  sI ;
 an assertion C(a), in symbols I |= C(a), if aI  C I ,
 an assertion r(a, b), in symbols I |= r(a, b), if (aI , bI )  rI .
We say that an interpretation I is a model of a TBox T (ABox A) if I |=  for all   T
(  A). An ELHr -inclusion  follows from a TBox T if every model of T is a model of
, in symbols T |= . |=  is used to denote that  follows from the empty TBox and we
sometimes write r vT s for T |= r v s. An instance assertion  follows from a KB (T , A)
if every individual name that occurs in  also occurs in obj(A) and every model of (T , A) is
a model of , in symbols (T , A) |= . The most important ways of querying ELHr -TBoxes
and KBs are
 subsumption: check whether T |= , for an ELHr -inclusion  and TBox T ,
 instance checking: check whether (T , A) |= , for an instance assertion  and KB
(T , A), and
 conjunctive query answering.
To define the latter, call a first-order formula q(~x) a conjunctive query if it is of the form
~y (~x, ~y ), where  is a conjunction of expressions A(t), A  NC , and r(t1 , t2 ), r  NR , with
t, t1 , t2 drawn from NI and the sequences of variables ~x and ~y . Let ~x = x1 , . . . , xk . Let I be
an interpretation and  be a mapping from ~x  ~y into I . Set (a) = aI for all a  obj(A).
We say that a vector ~a = a1 , . . . , ak is a -match of q(~x) and I if  satisfies the following
conditions:
 (t)  AI for every conjunct A(t) of ;
 ((t1 ), (t2 ))  rI for every conjunct r(t1 , t2 ) of ;
 (xi ) = aIi for 1  i  k.
We set I |= q[~a] if, and only if, there exists a  such that ~a is a -match of q(~x) and I. Let
(T , A) be a KB. Then a sequence ~a of members of obj(A) is a certain answer to q(~x) of a
KB (T , A), in symbols (T , A) |= q(~a), if I |= q[~a], for every model I of (T , A).
All three types of querying ELHr -TBoxes have been studied extensively. The complexity
of subsumption and instance checking is in PTime (Baader et al., 2008). The combined
complexity of answering Boolean conjunctive queries (i.e., deciding whether (T , A) |= q for
a conjunctive query q without free variables) is coNP-complete (Rosati, 2007) and its data
complexity is in PTime (Rosati, 2007). Information on reasoners for subsumption checking
for ELHr can be found in the work of Delaitre and Kazakov (2009), Kazakov, Krotzsch,
and Simancik (2011), and Mendez and Suntisrivaraporn (2009). Lutz et al. (2009) present
an approach to efficient conjunctive query answering for ELHr .
638

fiThe Logical Difference for the Lightweight Description Logic EL

2.1 Normal Form
It is often convenient to consider normalised ELHr -terminologies. Let T be an ELHr terminology and A a concept name. Call A
 primitive in T if A  NC \ ({A  NC | A  C  T }  {A  NC | A v C  T });
 pseudo-primitive in T if A  NC \ {A  NC | A  C  T }.
Note that concept names that do not occur in T are primitive and pseudo-primitive in T .
Call a concept name A non-conjunctive in T if it is pseudo-primitive in T or there exists
a concept of the form r.C such that A  r.C  T . Otherwise, A is called conjunctive
in T . Thus, A is conjunctive in T if, and only if, there exists a concept name B such that
A  B  T or there exist C1 , . . . , Cn , n  2, such that A  C1 u    u Cn  T . Let X be a
finite set d
of concepts. We say that a concept F is a conjunction of concepts in X if F is of
the form DX D. Any D  X is then called a conjunct of F and, if D is a concept name,
then it is called an atomic conjunct of F . We sometimes write D  F instead of D  X.
An ELHr -terminology T is normalised if it consists of ELHr -inclusions of the following
form:
 A  r.B, or A  F , where A, B are concept names and F is a non-empty conjunction
of concept names such that every conjunct B 0 of F is non-conjunctive in T ;
 E v r.B, E v r.>, or E v F , where B is a concept name, E is either a concept
name, or is of the form s.>, or ran(s), and F is a non-empty conjunction of concept
names such that every conjunct B 0 of F is non-conjunctive in T .
As the following lemma shows, any ELHr -terminology can be normalised yielding a
model conservative extension of the original terminology.
Lemma 1. For every ELHr -terminology T , one can construct in polynomial time a normalised terminology T 0 of polynomial size in |T | such that sig(T )  sig(T 0 ), T 0 |= T , and
for every model I of T there exists a model J of T 0 such that I = J and X I = X J for
every X  sig(T ). Moreover, T 0 is acyclic if T is acyclic.
Normalised terminologies in the sense defined above are a minor modification of normalised terminologies as defined by Baader (2003). The straightforward extension of the
proof given by Baader is provided in the appendix.
2.2 Canonical Model
We define a canonical model, IK , for ELHr -knowledge bases K. IK can be constructed in
polynomial time and gives the same answers to instance queries as K; i.e., IK |=  if, and
only if, K |= , for any instance assertion . The construction is similar to the canonical
model introduced by Lutz et al. (2009).
Let sub(T ) denote the set of all subconcepts of concepts used in T , rol(T ) the set of all
role names occurring in T . Take fresh individual names xran(r),D for every r  rol(T ) and
D  sub(T ) and set
NIaux := {xran(r),D | r  rol(T ) and D  sub(T )}.
639

fiKonev, Ludwig, Walther, & Wolter

Now define the generating interpretation WK of a KB K = (T , A) as follows:
W K
AW K
r WK

aWK

:= obj(A)  NIaux ;
:= {a  obj(A) | K |= A(a)}  {xran(r),D  NIaux | T |= ran(r) u D v A};
:= {(a, b)  obj(A)  obj(A) | s(a, b)  A and T |= s v r} 
{(a, xran(s),D )  obj(A)  NIaux | K |= s.D(a) and T |= s v r} 
{(xran(s),D , xran(s0 ),D0 )  NIaux  NIaux | T |= ran(s) u D v s0 .D0 , T |= s0 v r};
:= a, for all a  obj(A).

A path in WK is a finite sequence d0 r1 d1    rn dn , n  0, where d0  obj(A) and, for all i < n,
WK
(di , di+1 )  ri+1
. We use paths(WK ) to denote the set of all paths in WK . If p  paths(WK ),
then tail(p) denotes the last element dn in p.
The canonical model IK of a knowledge base K is the restriction of WK to all domain
elements d such that there is a path in WK with tail d. The following result summarises
the main properties of IK .
Theorem 2. Let K = (T , A) be an ELHr -KB. Then
1. IK is a model of K;
2. IK can be computed in polynomial time in the size of K;
3. for all xran(s),D  IK and all a  obj(A), if C is an EL-concept or C = ran(r), then
 K |= C(a) if, and only if, aIK  C IK .
 T |= ran(s) u D v C if, and only if, xran(s),D  C IK .
The proof of Theorem 2 is given in the appendix. It follows from Point 3 that IK gives
the same answers to instance queries as K itself.

3. Logical Difference
In this section, we introduce three notions of logical difference between TBoxes and the
derived notion of -inseparability. Intuitively, the logical difference between two TBoxes T1
and T2 should be the set of all relevant formulas  such that T1 |=  and T2 6|=  or vice
versa. Of course, which formulas  are relevant depends on the application domain. In many
applications only subsumptions between concepts are relevant, but if TBoxes are employed
to access instance data, then answers to instance or even conjunctive queries can be relevant
as well. In addition, in applications of large-scale terminologies such as Snomed CT and
NCI typically only a very small subset of the vocabulary of the terminology is relevant.
Thus, a meaningful notion of logical difference should take into account only those formulas
that are given in a certain signature of interest, where a signature  is a subset of NC  NR .
Given a concept, role, concept inclusion, TBox, ABox, or query E, we denote by sig(E)
the signature of E, that is, the set of concept and role names occurring in it. We call E a
-concept, -concept inclusion, -TBox, -ABox, or -query, respectively, if sig(E)  .
Similarly, an EL -concept C is an EL-concept such that sig(C)   and an ELHr -inclusion
 is an ELHr -inclusion such that sig()  .
The first notion of logical difference we introduce corresponds to applications in which
only subsumptions are relevant.
640

fiThe Logical Difference for the Lightweight Description Logic EL

Definition 3 (-concept difference). The -concept difference between ELHr -TBoxes T1
and T2 is the set cDiff  (T1 , T2 ) of all ELHr -inclusions  such that T1 |=  and T2 6|= .
We say that T1 and T2 are -concept inseparable, in symbols T1 C
 T2 , if cDiff  (T1 , T2 ) =
cDiff  (T2 , T1 ) = .
-concept inseparability between T1 and T2 means that T1 can be replaced by T2 in
any application that is only concerned with ELHr -inclusions.2 As the following example
shows, however, -concept inseparable terminologies can give different answers for the same
instance query and data.
Example 4. Let T1 = {ran(r) v A1 , ran(s) v A2 , B  A1 u A2 }, T2 = ,  = {r, s, B}.
One can show that T1 and T2 are -concept inseparable. However, for the -ABox A =
{r(a, c), s(b, c)} we have (T1 , A) |= B(c) but (T2 , A) 6|= B(c).
To take into account the differences between TBoxes that are relevant if TBoxes are
used to access instance data, we consider the -instance difference.
Definition 5 (-instance difference). The -instance difference between TBoxes T1 and T2
is the set iDiff  (T1 , T2 ) of pairs of the form (A, ), where A is a -ABox and  a -instance
assertion such that (T1 , A) |=  and (T2 , A) 6|= . We say that T1 and T2 are -instance
inseparable, in symbols T1 i T2 , if iDiff  (T1 , T2 ) = iDiff  (T2 , T1 ) = .
In contrast to ELHr , it has been shown by Lutz and Wolter (2010) that for EL-TBoxes
there is no difference between -concept inseparability and -instance inseparability. In
this paper we extend this result to ELHr -TBoxes without range restrictions (the proof is
given after Corollary 37):
Theorem 6. Let T1 and T2 be ELHr -TBoxes without range restrictions and  a signature.
i
Then T1 C
 T2 if, and only if, T1  T2 .
Sometimes, instance queries are not sufficiently expressive, and conjunctive queries are
employed. In that case, the following notion of difference is appropriate.
Definition 7 (-query-difference). The -query difference between TBoxes T1 and T2 is
the set qDiff  (T1 , T2 ) of pairs of the form (A, q(~a)), where A is a -ABox, q(~x) a conjunctive query, and ~a a tuple of individual names in A such that (T1 , A) |= q(~a) and
(T2 , A) 6|= q(~a). We say that T1 and T2 are -query inseparable, in symbols T1 q T , if
qDiff  (T1 , T2 ) = qDiff  (T2 , T1 ) = .
As observed by Lutz and Wolter (2010) already, even for EL -instance inseparability
does not imply -query inseparability. The following is a simple example.
Example 8. Let T1 = {A v r.B}, T2 = ,  = {A, B}. Then T1 and T2 are -instance
inseparable, but they are not -query inseparable. Consider the -ABox A = {A(a)} and
the -query q = x.B(x). Then (T1 , A) |= q but (T2 , A) 6|= q.
2. We refer the reader to the conclusion of this paper for a brief discussion of this claim.

641

fiKonev, Ludwig, Walther, & Wolter

It is shown by Lutz and Wolter (2010) that Example 8 is essentially the only situation
in which there is a difference between -instance inseparability and -query inseparability
in EL: the two notions become equivalent for EL if the universal role is admitted in instance
queries (e.g., in Example 8, the conjunctive query x.B(x) corresponds to the instance query
u.B(a) for the universal role u). In contrast, for ELHr there are more subtle differences
between the instance and the query case.
Example 9. Let T1 = {A v s.>, s v r1 , s v r2 }, T2 = {A v r1 .> u r2 .>},  =
{A, r1 , r2 }. Then T1 and T2 are -concept and -instance inseparable, but they are not
-query inseparable. To show the latter, let A = {A(a)} and let q = x(r1 (a, x)  r2 (a, x)).
Then (T1 , A) |= q but (T2 , A) 6|= q.
We have seen that -concept inseparability does not imply -instance inseparability
and that -instance inseparability does not imply -query inseparability. The converse
implications, however, hold:
Lemma 10. For all ELHr -TBoxes T1 and T2 and all signatures :
T1 q T2



T1 i T2



T1 C
 T2 .

Proof. The first implication follows from the observation that every instance query can be
regarded as a conjunctive query. For the second implication, note first that if s v r 
cDiff  (T1 , T2 ), then ({s(a, b)}, r(a, b))  iDiff  (T1 , T2 ). Now let C v D  cDiff  (T1 , T2 ).
One can construct a -ABox AC with individual a such that for all EL-concepts D0 :
(T , AC ) |= D0 (a) if, and only if, T |= C v D0 (cf. Lemma 36). Thus (AC , D(a)) 
iDiff  (T1 , T2 ).
Having introduced three notions of difference between ELHr -TBoxes, we now investigate two problems: (i) how to detect whether there is any difference between two ELHr terminologies and, if so, (ii) how to represent the differences.
In what follows we assume that the fresh symbols used in the normalised form of terminologies do not occur in the signature  for which we compute the difference between
terminologies. Then we obtain the following lemma as a direct corollary of Lemma 1.
Lemma 11. For any ELHr -terminologies T1 , T2 and their normalised forms T10 , T20 as
defined in Lemma 1, we have that the following hold:
 cDiff  (T1 , T2 ) = cDiff  (T10 , T20 );
 iDiff  (T1 , T2 ) = iDiff  (T10 , T20 );
 qDiff  (T1 , T2 ) = qDiff  (T10 , T20 ).
From now on, unless stated otherwise, we consider normalised terminologies only.
642

fiThe Logical Difference for the Lightweight Description Logic EL

4. The Case of EL-Terminologies
Before investigating the logical difference for ELHr -terminologies, we illustrate the main
ideas behind the proofs by considering the -concept difference for EL-terminologies. An
EL-terminology is an ELHr -terminology consisting of EL-inclusions only, that is, concept
inclusions of the form A v C and concept equations of the form A  C. We start with the
observation that even for acyclic EL-terminologies there are T1 and T2 in which cDiff  (T1 , T2 )
contains inclusions of at least exponential size only. Thus, when searching for witness
inclusions in cDiff  (T1 , T2 ), one has to deal with the case in which all witness inclusions
have at least exponential size.
Example 12. Consider
T1 = {A0 v B0 , A1  Bn }  {Bi+1  r.Bi u s.Bi | 0  i < n}
T2 = {A1 v F0 }  {Fi v r.Fi+1 u s.Fi+1 | 0  i < n}
and  = {A0 , A1 , r, s}. Then a concept inclusion in cDiff  (T1 , T2 ) of minimal size is given
by Cn v A1 , where
C0 = A0 and Ci+1 = r.Ci u s.Ci , for i  0.
Clearly, Cn is of exponential size. Note, however, that if we use structure sharing and define
the size of Cn as the number of its subconcepts, then Cn is only of polynomial size.
We now derive basic properties of EL-terminologies using a sequent calculus.
4.1 Proof System for EL
We derive basic properties of EL from the Gentzen-style sequent calculus presented by Hofmann (2005); see Figure 1. The calculus operates on sequents of the form C v D, where
C, D are EL-concepts; here the symbol v is treated as a syntactic separator. A derivation
(or, equivalently, a proof ) of a sequent C v D is a finite rooted tree whose nodes are labelled
with sequents, whose root is labelled with C v D, whose leaves are labelled with axioms
(instances of Ax or AxTop) and whose internal nodes are labelled with the result of an
application of one of the inference rules to the labels of their children. The length of a
derivation is the number of rule applications in the derivation.
Example 13. Let T = {A  B1 uB2 , F v B1 }. A derivation D of the sequent r.(F uB2 ) v
r.A is shown below. The root of the derivation D is labelled with r.(F u B2 ) v r.A and
the two leaves with B1 v B1 and B2 v B2 , respectively.
(Ax)

B1 v B1
(PDefL)
(Ax)
F v B1
B2 v B2
(AndL1)
(AndL2)
F u B2 v B1
F u B2 v B2
(AndR)
F u B2 v B1 u B2
(DefR)
F u B2 v A
(Ex)
r.(F u B2 ) v r.A
643

fiKonev, Ludwig, Walther, & Wolter

CvC

(Ax)

Cv>

(AxTop)

CvE
(AndL1)
C uD vE

CvE CvD
(AndR)
C vDuE
CA v D
(DefL)
AvD

CvD
(Ex)
r.C v r.D

D v CA
(DefR)
DvA

CA v D
(PDefL)
AvD

DvE
(AndL2)
C uD vE

where A  CA  T

where A v CA  T

Figure 1: Gentzen-style proof system for EL-terminologies.
Notice that the basic calculus of Hofmann (2005) considers EL without the constant >
and for terminologies without concept inclusions. To take care of >, we have added the
rule (AxTop), and (PDefL) is the rule representing inclusions of the form A v C. Cutelimination, completeness, and correctness can now be shown in a straightforward extension
of the proof given by Hofmann.
For a terminology T and concepts C, D, we write T ` C v D if, and only if, there exists
a proof of C v D in the calculus of Figure 1.
Theorem 14 (Hofmann). For all EL-terminologies T and concepts C, D, it holds that
T |= C v D if, and only if, T ` C v D.
We apply this calculus to derive a description of the syntactic form of concepts C such
that T |= C v D, where D is non-conjunctive in T .
Lemma 15. Let T be a normalised EL-terminology, r a role name, A a concept name and
D an EL-concept.
1. Assume
T |=

l

Ai u

1in

l

rj .Cj v A,

1jm

where A is pseudo-primitive in T , Ai are concept names for 1  i  n, Cj are ELconcepts for 1  j  m, and m, n  0. Then there exists Ai , 1  i  n, such that
T |= Ai v A.
2. Assume now
T |=

l
1in

l

Ai u

rj .Cj v r.D,

1jm

where Ai are concept names for 1  i  n, Cj are EL-concepts for 1  j  m, and
m, n  0. Then
 there exists Ai , 1  i  n, such that T |= Ai v r.D or
 there exists rj , 1  j  m, such that rj = r and T |= Cj v D.
644

fiThe Logical Difference for the Lightweight Description Logic EL

d
d
Proof. We use Theorem 14. First, we prove Point 1. Let C = 1in Ai u 1jm rj .Cj
and assume T |= C v A, where A is pseudo-primitive in T . Let D be a proof of C v A.
Note that, since A is pseudo-primitive in T (and a concept name), by inspecting the form
of the conclusions of the inference rules, one can see that the root of the derivation D can
only have been derived by either Ax, AndL1, AndL2, DefL, or PDefL. We now show
that there exists Ai , 1  i  n, such that T |= Ai v A by induction on n + m, i.e. the
number of conjuncts in C. It is easy to see that n + m  1 as T 6|= > v A by definition of
terminologies T .
The base case of n + m = 1 is trivial: the root of D can only have been derived by one
of Ax, DefL, or PDefL; so, we can conclude that C = A1 ; i.e. n = 1, m = 0, and we set
Ai = A1 .
Assume n + m > 1. Then the root of D can only have been derived by either AndL1
or AndL2. In both cases, the premise used in the application of either inference rule is
a sequent C 0 v A such that either C = C 0 u D or C = D u C 0 for an EL-concept D.
Thus, C 0 contains less conjuncts than C (but still at least one). We can also conclude that
T |= C 0 v A holds by Theorem 14. By applying the induction hypothesis, there hence
exists a concept name Ai which is a conjunct of C 0 such that T |= Ai v A. Finally, we still
note that Ai is also a conjunct of C.
d
d
We now prove Point 2. Let C = 1in Ai u 1jm rj .Cj and assume T |= C v r.D.
Let D be a proof of C v r.D. Note that due to the form of the right-hand side of the sequent
C v r.D, the rule used to derive the root of D can only have been one of Ax, AndL1,
AndL2, DefL, PDefL, or Ex. We now prove that either there exists Ai , 1  i  n, such
that T |= Ai v r.D, or there exists rj , 1  j  m, with rj = r and T |= Cj v D by
induction on n + m again. Similarly to above, we have n + m  1.
If n + m = 1, the rule used to derive the root of D can only have been one of Ax, DefL,
PDefL, or Ex. We have two subcases:
 the root of D was derived with DefL or PDefL: then n = 1, m = 0 and C = A1 ; i.e.
T |= Ai v r.D for Ai = A1 .
 the root of D was derived with Ax or Ex: then n = 0, m = 1, C = r1 .C1 , and
r1 = r. If C1 = D, then obviously T |= C1 v D holds. Otherwise, the rule Ex was
used to derive the root of D and T ` C1 v D holds, which implies that T |= C1 v D.
Thus, in any case, rj = r and T |= Cj v D holds for j = 1.
The case n+m > 1 can be proved by induction analogously to the proof of Point 1 above.
We apply Lemma 15 to elements of cDiff  (T1 , T2 ).
Theorem 16 (Primitive witness for EL). Let T1 and T2 be EL-terminologies and  a
signature. If   cDiff  (T1 , T2 ), then either C v A or A v D is a member of cDiff  (T1 , T2 ),
where A  sig() is a concept name and C, D are EL-concepts occurring in .
Proof. Let  = C v D  cDiff  (T1 , T2 ). The proof is by induction on the construction of
D. We have D 6= > as T2 |= C v >. If D = D1 u D2 , then one of C v Di , i = 1, 2, is in
cDiff  (T1 , T2 ) and we can apply the induction hypothesis. If D = r.D1 then, by Lemma 15,
645

fiKonev, Ludwig, Walther, & Wolter

either (i) there exists a conjunct A of C, A a concept name, such that T1 |= A v D, or (ii)
there exists a conjunct r.C1 of C with T1 |= C1 v D1 .
In case (i) it follows that T2 6|= A v D as otherwise T2 |= C v D and C v D 6
cDiff  (T1 , T2 ) due to |= C v A. Hence, A v D  cDiff  (T1 , T2 ).
Finally, for case (ii) we obtain T2 6|= C1 v D1 as otherwise |= C v r.C1 , T2 |= r.C1 v D
and C v D 6 cDiff  (T1 , T2 ) again. Thus, C1 v D1  cDiff  (T1 , T2 ) and we can apply the
induction hypothesis.
By Theorem 16, every inclusion C v D in the -concept difference of T1 and T2 contains a basic witness inclusion that has a concept name either on the right-hand side or
the left-hand side. We define
 the set of left-hand -concept difference witnesses, cWtnlhs
 (T1 , T2 ), as the set of all
A    NC such that there exists a concept D with A v D  cDiff  (T1 , T2 ) and
 the set of right-hand -concept difference witnesses, cWtnrhs
 (T1 , T2 ), as the set of all
A    NC such that there exists a concept C with C v A  cDiff  (T1 , T2 ).
rhs
We regard the concept names in cWtnlhs
 (T1 , T2 ) and cWtn (T1 , T2 ) as a succinct and, in a
certain sense, complete representation of the -concept difference between T1 and T2 and
define the set of all -concept difference witnesses as
rhs
cWtn (T1 , T2 ) = (cWtnlhs
 (T1 , T2 ), cWtn (T1 , T2 )).

In what follows, we first present a polytime algorithm computing cWtnrhs
 (T1 , T2 ). A polytime algorithm computing cWtnlhs
(T
,
T
)
has
already
been
given
by
Lutz
and Wolter (2010)
1 2

(for EL-TBoxes). We briefly present it since an extension will be developed when we consider ELHr -terminologies. Both algorithms together decide -concept inseparability since,
by Theorem 16, T1 and T2 are -concept inseparable if, and only if, cWtn (T1 , T2 ) =
cWtn (T2 , T1 ) = (, ).
4.2 Computing cWtnrhs
 (T1 , T2 )
Let A   and assume we want to decide whether A  cWtnrhs
 (T1 , T2 ). Thus, we want to
decide whether there exists a -concept C such that T1 |= C v A and T2 6|= C v A. Our
general strategy is as follows. Let
noimplyT2 , (A) = {C | T2 6|= C v A, C an EL -concept}.
We aim at an algorithm that checks whether noimplyT2 , (A) contains some C with T1 |=
C v A. For two sets C and D of concepts we call C a cover of D if C  D and for all
D  D there exists a C  C such that |= C v D. Thus, C  noimplyT2 , (A) is a cover
of noimplyT2 , (A) if for all D  noimplyT2 , (A) there exists a C  C such that |= C v D.
Note that if C is a cover of noimplyT2 , (A), then there exists some -concept C such that
C v A  cDiff  (T1 , T2 ) if, and only if, there exists some C  C such that T1 |= C v A.
Thus we have reduced the original problem to the construction of an appropriate cover C
and deciding the subsumption problem T1 |= C v A, for C  C. Unfortunately, in general,
no finite cover exists. The following example illustrates the situation.
646

fiThe Logical Difference for the Lightweight Description Logic EL

Example 17. (1) Let  = {A, B, r} and T2 = . Then noimplyT2 , (A) contains all concepts that do not have A as an atomic conjunct. Clearly, noimplyT2 , (A) contains no
finite cover.
(2) Let 0 = {A, B, r} and T20 = {A  r.A}. Then noimplyT20 ,0 (A) contains all
0 \ {A}-concepts and contains no finite cover.
(3) Let 00 = {A, B1 , B2 } and T200 = {A  B1 u B2 }. Then {B1 , B2 } is a cover of
noimplyT200 ,00 (A).
As a consequence, instead of directly constructing a cover of noimplyT2 , (A), we first
construct transparent and small covers of
noimplyT2 , (A)  {C | depth(C)  n},
for all n  0, where depth(C) is the role-depth of C; i.e., the number of nestings of existential
restrictions in C.3 Those covers are denoted noimplynT2 , (A), n  0, and are singleton
sets if A is non-conjunctive in T2 and finite sets containing at most k concepts if A 
B1 u  uBk  T2 . Based on this sequence, we present two distinct algorithms for computing
cWtnrhs
 (T1 , T2 ):
1. we encode the infinite sequence noimplynT2 , (A), n  0, into a polynomial-size ABox
AT2 , . In this way we obtain a reduction of the original problem to an instance
checking problem for the knowledge base (T1 , AT2 , ). In a certain sense, the ABox
AT2 , encodes a (in general infinite) cover of noimplyT2 , (A).
2. we employ the terminology T1 in a dynamic programming approach to decide which
concepts in noimplynT2 , (A) are relevant for deciding whether A  cWtnrhs
 (T1 , T2 ).
Although less transparent, for large terminologies the latter approach is considerably
more efficient. We develop it for acyclic terminologies.
For an EL-terminology T , a concept name A and a signature , set
pre
T (A) = {B   | T |= B v A}.
The finite covers noimplynT2 , (A), n  0, are defined in Figure 2. For n = 0, the
set noimplynT2 , (A) consists of concepts without role names. We distinguish between conjunctive and non-conjunctive A. Note that if A is non-conjunctive, then noimplynT2 , (A)
is a singleton set. Example 17 (3) shows that this is not always the case for conjunctive A. For n + 1, we distinguish between pseudo-primitive concept names, conjunctive
concept names, and those that have a definition of the form A  r.C. Again, for nonn
conjunctive A, noimplyn+1
T2 , (A) is a singleton set. Note that the concepts all are covers of
{C | depth(C)  n, C an EL -concept}, for all n  0. We illustrate the definitions using
the EL-terminologies from Example 17.
Example 18. (1) Let  = {A, B, r} and T2 = . Then A and B are non-conjunctive in T2
and noimply0T2 , (A) = {B} and noimply0T2 , (B) = {A}. A and B are also pseudo-primitive
in T2 , and so noimply1T2 , (A) = {B u r.(A u B)} and noimply1T2 , (B) = {A u r.(A u B)}.
3. More precisely depth(A) = 0, depth(C1 u C2 ) = max{depth(C1 ), depth(C2 )}, and depth(r.D) =
depth(D) + 1.

647

fiKonev, Ludwig, Walther, & Wolter

Set, inductively,
all0 =

l

A0

l

and alln+1
=


A0 

A0 u

A0 

l

s.alln .

s

Define noimply0T2 , (A) as follows:
 if A is non-conjunctive in T2 , then
l

noimply0T2 , (A) = {

A0 };

A0 \pre
T (A)
2

 if A is conjunctive and A  F  T2 , then
[

noimply0T2 , (A) =

noimply0T2 , (B);

BF

and define, inductively, noimplyn+1
T2 , (A) by
 if A is pseudo-primitive in T2 , then
l

noimplyn+1
T2 , (A) = {

A0 u

A0 (\pre
T (A))

l

s.alln }.

s

2

 If A is conjunctive and A  F  T2 , then
noimplyn+1
T2 , (A) =

[

noimplyn+1
T2 , (B).

BF

 If A  r.B  T2 , then
n+1
noimplyn+1
T2 , (A) = {C,T2 }, where
n+1
=(
C,T
2

l

A0 u

A0 (\pre
T2 (A))

l

l

s.alln u

r.E).

r
Enoimplyn
T

r6=s

2 ,

(B)

Figure 2: Definition of noimplynT2 , (A)

(2) Let 0 = {A, B, r} and T20 = {A  r.A}. Then A and B are non-conjunctive in T20
and noimply0T 0 ,0 (A) = {B} and noimply0T 0 ,0 (B) = {A}. B is pseudo-primitive in T20 and so
2

2

noimply1T2 , (B) = {A u r.(A u B)}. A  r.A  T20 and so noimplyT20 ,0 (A) = {B u r.B}.
T200

(3) Let 00 = {A, B1 , B2 } and T200 = {A  B1 u B2 }. B1 and B2 are non-conjunctive in
and so noimply0T 00 ,00 (B1 ) = {B2 } and noimply0T 00 ,00 (B2 ) = {B1 }. A is conjunctive in T200
2

2

648

fiThe Logical Difference for the Lightweight Description Logic EL

and, by definition, noimply0T 00 ,00 (A) = {B1 , B2 }. Since  does not contain any role names,
2

we have noimply0T 00 ,00 (X) = noimplynT 00 ,00 (X), for all X  {A, B1 , B2 } and n > 0.
2

2

The following lemma shows the correctness of the definition of noimplynT2 , (A).
Lemma 19. Let T2 be a normalised EL-terminology,  be a signature, and A  NC . Then
noimplynT2 , (A) is a cover of noimplyT2 , (A)  {C | depth(C)  n}. Namely, for all n  0,
C1. T2 6|= C v A, for all C  noimplynT2 , (A).
C2. For all EL -concepts D with n = depth(D), if T2 6|= D v A, then |= C v D for some
C  noimplynT2 , (A).
S
In particular, n0 noimplynT2 , (A) is a cover of noimplyT2 , (A).
Proof.d C1. Assume first that A is pseudo-primitive in T2 . Then noimplynT2 , (A) consists of
C = A0 (\pre (A)) A0 u F , where F is a (possibly empty) conjunction of concepts of the
T2

form s.Fi . By Lemma 15, T2 6|= C v A because the only atomic conjuncts of C are in
 \ pre
T2 (A).
We now prove C1 for concept names A which are not pseudo-primitive
in T2 . The proof
d
is by induction on n. For n = 0 and A  r.B  T2 , assume T2 |= A0 (\pre (A)) A0 v A.
T2

As A  r.B  T2 , we have by Lemma 15 that there must exist A0   \ pre
T2 (A) with
0

T2 |= A v A. But this contradicts the definition of the
S set preT2 (A)). For n = 0 and A
conjunctive with A  F  T2 , let C  noimplynT2 , (A) = BF noimplynT2 , (B). There hence
exists an atomic conjunct B of F such that C  noimplynT2 , (B). As T2 is normalised, B is
non-conjunctive, i.e. property C1 has already been proved above for B. Thus, T2 6|= C v B,
which implies that T2 6|= C v A as otherwise T2 |= C v B would hold.
For the induction step, assume C1 has been proved for n  0.
be the only element of noimplyn+1
Let A  r.B  T2 and let CTn+1
T2 , (A). Assume
2 ,
n+1
T2 |= CT2 , v A. By Lemma 15 there are two possibilities:
d
 T2 |= A0 (\pre (A)) A0 v r.B. Similarly to above, the claim follows from Lemma 15
T2

and the fact that A  r.B  T2 .
 r   and there exists E  noimplynT2 , (B) such that T2 |= E v B. This is excluded
by the induction hypothesis.
We have derived a contradiction. The case A  F  T2 , A conjunctive in T2 , is considered
analogously to the case n = 0.
C2. Let n = 0 and assume first that A is non-conjunctive. Let D be a -concept
with depth(D)d = 0 and T2 6|= D v A. Then all conjuncts of D are in  \ pre
T2 (A) and
we obtain |= A0 \pre (A) A0 v D. Now assume A is conjunctive in T2 and A  F  T2 .
T2

Let D be a -concept with depth(D) = 0 and T2 6|= D v A. Then T2 6|= D v B, for some
conjunct B of F . By induction, |= C v D for the (unique as B must be non-conjunctive)
C  noimply0T2 , (B), and therefore |= C v D for some C  noimply0T2 , (A).
For the induction step, assume that C2 has been shown for n. Let D be a -concept
with T2 6|= D v A and depth(D) = n + 1.
649

fiKonev, Ludwig, Walther, & Wolter

(a) Let A be pseudo-primitive in T2 . Then the atomicdconjuncts of D aredincluded in
n
0
 \ pre
A0 \pre (A) A u s s.all .
T2 (A). Now |= C v D follows immediately for C =
T2

(b) Let A  r.B  T2 . Let CTn+1
be the only element of noimplyn+1
T2 , (A) and assume
2 ,
D=

l

l

Eu

EQ0
n+1
Then Q0   \ pre
T2 (A). Hence, |= CT2 , v
We distinguish two cases:

s.D0 .

(s,D0 )Q1

d

EQ0

E. Now consider a conjunct s.D0 of D.

 if s 6= r, then |= CTn+1
v s.D0 , as required.
2 ,
 if s = r, then s   and it is sufficient to show that there exists E  noimplynT2 , (B)
such that |= E v D0 . Suppose there does not exist such an E. Then, by (the
contraposition of) the induction hypothesis, T2 |= D0 v B. But this contradicts
T2 6|= D v A (as A  r.B  T2 ).
(c) A is conjunctive in T2 and A  F  T2 . This case is analogous to the case in which
A is conjunctive in T2 and n = 0.
Corollary 20. For all normalised EL-terminologies T1 and T2 and all A  NC the following
conditions are equivalent:
 there exists an EL -concept C such that T1 |= C v A and T2 6|= C v A;
 there exists n  0 and C  noimplynT2 , (A) such that T1 |= C v A.
Observe that a direct application of Corollary 20 does not yield a procedure for comn
puting cWtnrhs
 (T1 , T2 ) as it gives no bound on n for the set noimplyT2 , (A). At this point
we present two ways of avoiding this problem (as well as the problem that concepts in
noimplynT2 , (A) can be of exponential size). Firstly, instead of working with covers we construct an ABox encoding covers. In contrast to concepts, ABoxes admit the encoding of
structure sharing d
and cycles and so, intuitively, admit the polynomial reconstruction of the
infinite concept n0,Cnoimplyn (A) C.
T2 ,
The ABox AT2 , is constructed in Figure 3, where for a normalised EL-terminology T
and a concept name A  sig(T ), we set

{A}, A is non-conjunctive in T
non-conjT (A) =
{B1 , . . . , Bn }, A  B1 u    u Bn  T
Note that the construction of AT2 , is very similar to the construction of noimplynT2 , (A).
The assertions for the individual  play the role of the concepts alln , n  0, and the
assertions for the individuals A play the role of the sets noimplynT2 , (A), n  0. In fact, one
can readily show that AT2 , |= C(A ) for any C  noimplynT2 , (A) and A non-conjunctive in
T2 and, conversely, (a more involved proof) shows that whenever AT2 , |= D(A ) for some
EL-concept D, then there exist n  0 and C  noimplynT2 , (A) such that |= C v D. We
illustrate the construction of AT2 , using the EL-terminologies from Example 17.
650

fiThe Logical Difference for the Lightweight Description Logic EL

Let
{A | A  sig(T2 )   and non-conjunctive in T2 }  { }  NI .
be a set of individual names. For A non-conjunctive in T2 , define sets AT2 , (A) of assertions
as follows
 if A is pseudo-primitive in T2 , then
AT2 , (A) = {A0 (A ) | A0   \ pre
T2 (A)}  {r(A ,  ) | r  },
 if A  r.B  T2 , then
AT2 , (A) ={A0 (A ) | A0   \ pre
T2 (A)}
 {s(A ,  ) | r 6= s  }
 {r(A , B 0 ) | B 0  non-conjT2 (B), if r  }
Let
[

AT2 , = { A0 ( ) | A0   }  { r( ,  ) | r   } 

AT2 , (A)

Asig(T2 )
A is non-conjunctive in T2

Figure 3: Construction of AT2 , .
Example 21. (1) Let  = {A, B, r} and T2 = . Then
AT2 , = {A(B ), B(A ), r(A ,  ), r(B ,  )}  A ,
where A = {A( ), B( ), r( ,  )}.
(2) Let 0 = {A, B, r} and T20 = {A  r.A}. Then
AT20 ,0 = {A(B ), B(A ), r(A , A ), r(B , 0 )}  A0 ,
where A0 = {A(0 ), B(0 ), r(0 , 0 )}.
(3) Let 00 = {A, B1 , B2 } and T200 = {A  B1 u B2 }. Then
AT200 ,00 = {B1 (B2 ), B2 (B1 )}  A00 ,
where A00 = {A(00 ), B1 (00 ), B2 (00 )}.
We now obtain the following characterisation of cWtnrhs
 (T1 , T2 ).
Theorem 22. Let T1 and T2 be normalised EL-terminologies and  a signature. Then the
following conditions are equivalent for any A  :
 A  cWtnrhs
 (T1 , T2 );
 there exist n  0 and C  noimplynT2 , (A) such that T1 |= C v A;
651

fiKonev, Ludwig, Walther, & Wolter

 (T1 , AT2 , ) |= A(B ) for some B  non-conjT2 (A).
The equivalence of Points 1 and 2 follows from Corollary 20. We do not give a detailed
proof of the equivalence of Points 2 and 3 as this follows from the more general results for
ELHr -terminologies we present below.
Example 23. For a normalised form of the terminologies from Example 12,
0
00
T1 = {A0 v B0 , A1  Bn }  {Bi+1  Bi+1
u Bi+1
| 0  i < n}
0
00
 {Bi+1  r.Bi | 0  i < n}  {Bi+1  s.Bi | 0  i < n}

T2 = {A1 v F0 }  {Fi  Fi0 u Fi00 | 0  i < n}
 {Fi0 v r.Fi+1 | 0  i < n}  {Fi00 v s.Fi+1 | 0  i < n},
and  = {A0 , A1 , r, s}, the ABox AT2 , can be graphically represented as
r, s
r, s

r, s
r, s

F 00
A0 ,A1

r, s
r, s


A0 ,A1


F 00

F 0

A0 ,A1

A0 ,A1

1

r, s

n

F 00

r, s
A0
A1

n

1

r, s

A1
A0

F 0

A0 ,A1

0

A0
F 0

0

A0

It should be clear that (T1 , AT2 , ) |= A1 (A1 ). In fact, (T1 , A) |= A1 (A1 ) holds already for
the restriction A of AT2 , to the individuals {A1 ,  }.
Theorem 24. For EL-terminologies T1 and T2 and a signature , the set cWtnrhs
 (T1 , T2 )
can be computed in polynomial time.
Proof. It suffices to give a polynomial time algorithm that decides for every A   whether
A  cWtnrhs
 (T1 , T2 ). First, the ABox AT2 , can be computed in polynomial time and is
of quadratic size in T2 . By Theorem 22, A  cWtnrhs
 (T1 , T2 ) iff (T1 , AT2 , ) |= A(B ) for
some B  non-conjT2 (A), and the latter condition can be checked in polynomial time since
instance checking is in polynomial time for EL-TBoxes.
Regarding the efficiency of this approach, observe that for typical terminologies and large
, the ABox AT2 , is indeed of quadratic size in T2 since  \ pre
T2 (A) will typically contain
most of the concept names in . Thus, for very large terminologies and  a straightforward
implementation of this rather elegant algorithm does not work efficiently as one would have
to store an ABox of quadratic size and do instance checking for it. We refer the reader to
Table 3 and its discussion where a prototype implementation of this approach is applied to
modules of Snomed CT.
We now describe our second approach for computing cWtnrhs
 (T1 , T2 ), which only works
for acyclic EL-terminologies. Recall that A  cWtnrhs
(T
,
T
1 2 ) if, and only if, there ex
ists an EL -concept C such that T2 6|= C v A and T1 |= C v A. Thus, we have
A 6 cWtnrhs
 (T1 , T2 ) if, and only if, for every EL -concept C with C  noimplyT2 , (A)
652

fiThe Logical Difference for the Lightweight Description Logic EL

procedure NotWitness(E)
if E is pseudo-primitive
 in T1 then
	

NotWitness(E) := A   | pre
T1 (E)  preT2 (A)
end if
if (E  E1 u    u Ek S
 T1 ) then
NotWitness(E) := ki=1 NotWitness(Ei )
end if
if E  r.E 0  T1 then
0 ) then
if r 
/  or All  NotWitness(E

	

NotWitness(E) := A   | pre
T1 (E)  preT2 (A)
else

fi

fi A  r.A0  T2


fi
NotWitness(E) := A   fifi non-conjT2 (A0 )  NotWitness(E 0 )


fi pre (E)  pre (A)
T1
T2
end if
end if
end procedure
Figure 4: Computation of NotWitness(E).
it holds that C  noimplyT1 , (A). Our approach is now based on computing a not witness
relation NW  ((sig(T1 )  )  NC )  ((sig(T2 )  )  NC ), which is defined as follows:
(E, A)  NW

if, and only if,

() noimplyT2 , (A)  noimplyT1 , (E)

Observe that A  cWtnrhs
 (T1 , T2 ) if, and only if, (A, A) 6 NW; hence, to compute the
set cWtnrhs
(T
,
T
)
it
is
sufficient
to compute the relation NW. In practice, it is crucial to
1 2

compute the relation NW rather than its complement: in typical terminologies most concept
names are unrelated in the sense that they do not subsume each other. Thus, the relation
NW is much smaller than its complement (which contains, among others, all pairs (E, A)
that do not subsume each other in T1 and T2 ).
To determine the pairs (E, A)  NW, we aim at computing for every concept name
E  sig(T1 )   the set of concept names A  sig(T2 )   for which the property () holds.
This set will be called NotWitness(E) and is computed in Figure 4, with the following
modifications: (1) we only consider those A  sig(T2 )   which are non-conjunctive in T2
and take conjunctive concept names into account later. (2) We consider a fresh concept
name All not occurring in   sig(T1 )  sig(T2 )  informally standing for all possible concepts.
Thus, the procedure, NotWitness(E) given in Figure 4 recursively associates with every
E  sig(T1 )   a subset of the set
 = {All}  { A | A  (sig(T2 )  ), A is non-conjunctive in T2 }
and NW is a relation over
((sig(T1 )  )  NC )  (((sig(T2 )  )  NC )  {All}).
653

fiKonev, Ludwig, Walther, & Wolter

Note that unlike in the approach for computing cWtnrhs
 (T1 , T2 ) that was presented previously, the approach described here does not handle the two terminologies separately. In
the previous approach the ABox AT2 , could be precomputed for T2 and then be re-used to
compare T2 against any other terminology T1 , whereas here both terminologies are analysed
simultaneously. We now prove the correctness of the procedure NotWitness(E).
Lemma 25. For any normalised acyclic EL-terminologies T1 and T2 , any signature , any
E  sig(T1 )   and any A   the following holds: A  NotWitness(E) if, and only if,
(E, A)  NW.
Proof. We prove that for any E  sig(T1 )   and any A   the following two conditions
are equivalent:
 A  NotWitness(E);
 for all n  0 and all C  noimplynT2 , (A): T1 6|= C v E.
S
This is sufficient since n0 noimplynT2 , (A) is a cover of noimplyT2 , (A) (Lemma 19).
For E 6 sig(T1 ) the claim is trivial. For E  sig(T1 ) the proof is by induction relative
to the relation T1  sig(T1 )  sig(T1 ) (whose definition can be found on page 637). Note
that since the considered terminologies are acyclic and sig(T1 ) is finite, the relation T1 is
well-founded.
We distinguish between the possible definitions of E in T1 . Suppose E is pseudoprimitive in T1 . For A  , it follows from the definition of noimplynT2 , (A) and from
Lemma 15 that there exist n  0 and C  noimplynT2 , (A) such that T1 |= C v E if, and

only if, T1 |= B v E for some B  ( \ pre
T2 (A)). Note that for all B  ( \ preT2 (A)),
T1 6|= B v E holds if, and only if, for every B  , T1 |= B v E implies that B  pre
T2 (A).
n

Thus, for every n and C  noimplyT2 , (A), T1 6|= C v E if, and only if, preT1 (E)  pre
T2 (A)
if, and only if, A  NotWitness(E).
Assume that E  E1 u    u Ek  T1 . Then, for any concept C, T1 6|= C v E if, and
only if, T1 6|= C v Ei for some 1  i  k. Hence, by applying the induction hypothesis we
obtain for every n and C  noimplynT2 , (A), T1 6|= C v E if, and only if, A  NotWitness(Ei )
for some 1  i  k, if, and only if, A  NotWitness(E).
Finally, assume that E  r.E 0  T1 . Notice that, since All 
/ (  sig(T1 )  sig(T2 )) (in

particular, All is pseudo-primitive in T2 ), we have preT2 (All) = . Thus, by definition for
every n  0, noimplynT2 , (All) = {alln }. By applying the induction hypothesis we can assume
that the lemma holds for E 0 , which implies that All 
/ NotWitness(E 0 ) if, and only if, for
some n  0, T1 |= alln v E 0 . We now distinguish between the following cases, analogously
to the case distinction in procedure NotWitness(E) (see Figure 4).
If r 
/ , for any -concept of the form s.G, where s  NR  , we have r 6= s and
T1 6|= s.G v r.E 0 . Similarly, if All  NotWitness(E 0 ), it holds for every n  0 that
T1 6|= alln v E 0 . Hence, for any -concept of the form s.G, we obtain T1 6|= s.G v r.E 0
as otherwise T1 |= alln v E 0 would hold for n = depth(s.G) (where depth(s.G) is the
role-depth of s.G). So, by Lemma 15, these two cases are analogous to the case of E being
pseudo-primitive considered above.
Assume now that r   and All 
/ NotWitness(E 0 ), that is, for some n0  0 we have
n0
0
T1 |= all v E .
654

fiThe Logical Difference for the Lightweight Description Logic EL

First, we observe that if A does not have a definition of the form A  r.A0 in T2 , then for
+1
the unique C  noimplynT20,
(A) we have T1 |= C v E as r.alln0 is a conjunct of C (and as A
is non-conjunctive in T2 by definition of the set ). If A has a definition of the form A  r.A0
in T2 , for any n  0 and C  noimplynT2 , (A), we have by Lemma 15 that T1 6|= C v E
n1

0
0
if, and only if, pre
T1 (E)  preT2 (A), and, if n > 0, for every C  noimplyT2 , (A ) we have
0
0
T1 6|= C v A .
We can conclude that in case r   and All 
/ NotWitness(E 0 ), for any A  , any
n
n  0, and any C  noimplyT2 , (A), we have T1 6|= C v E, if, and only if, A  r.A0 
m
0

0
T2 , pre
T1 (E)  preT2 (A) and for any m  0 and any C  noimplyT2 , (A ) we have
m
0
0
T
(A0 ) =
S1 6|= C v E . Noticem further that, by definition for any m  0,0 noimplyT2 ,
m
0
Bnon-conjT (A0 ) noimplyT2 , (B). Thus, for any m  0 and any C  noimplyT2 , (A ),
2

T1 6|= C 0 v E 0 holds if, and only if, for any m  0, any B  non-conjT2 (A0 ) and any
0
0
0
C 0  noimplym
T2 , (B), T1 6|= C v E , if, and only if, for any B  non-conjT2 (A ), B 
0
NotWitness(E ) holds by applying the induction hypothesis.
Thus, T1 6|= C v E, for any n  0 and C  noimplynT2 , (A), if, and only if, A 
NotWitness(E).
Corollary 26. Let T1 and T2 be normalised acyclic EL-terminologies and  a signature.
Then cWtnrhs
 (T1 , T2 ) = { A  sig(T1 )   |  B  non-conjT2 (A) with B 6 NotWitness(A) }.
Proof. First, we observe that if A  cWtnrhs
 (T1 , T2 ), A  sig(T1 ) must hold as otherwise
for any -concept C we have T1 |= C v A if, and only if, |= C v A, and thus A 6
cWtnrhs
 (T1 , T2 ). Now, for all A  NC we have:
A  cWtnrhs
 (T1 , T2 )

iff

iff

iff
iff

A  sig(T1 )   (by our observation) and, by definition,
there exists a -concept C with T2 6|= C v A and T1 |=
CvA
A  sig(T1 )   and there exists B  non-conjT2 (A) and
a -concept C with T2 6|= C v B and T1 |= C v A (as
otherwise T2 |= C v A would hold)
A  sig(T1 )   and there exists B  non-conjT2 (A) with
(A, B) 6 NW (by definition of the relation NW)
A  sig(T1 )   and there exists B  non-conjT2 (A) with
B 6 NotWitness(A), by Lemma 25.

For acyclic terminologies, we now obtain an alternative proof of Theorem 24.
Theorem 27. For acyclic EL-terminologies T1 and T2 and a signature , cWtnrhs
 (T1 , T2 )
can be computed in polynomial time using the procedure NotWitness(E).
Proof. To compute the set cWtnrhs
 (T1 , T2 ), it is sufficient by Corollary 26 to compute the
sets NotWitness(E) for every E  sig(T1 ). Assuming that T1 and T2 are classified and the
result of classification is cached, NotWitness(E) can be computed for all E  sig(T1 ), in the
worst case, in time O((|T1 | + |T2 |)3 ).
Example 28. For the acyclic terminologies T1 , T2 and the signature  from Example 23,
NotWitness(A0 ) = {A0 },
655

NotWitness(B0 ) = {A0 }

fiKonev, Ludwig, Walther, & Wolter

and for all other concept names X  sig(T1 ), NotWitness(X) = . In particular A1 
/
NotWitness(A1 ), so we conclude that A1 is a concept difference witness.
4.3 Computing cWtnlhs
 (T1 , T2 )
Recall that the set of left-hand -concept difference witnesses, cWtnlhs
 (T1 , T2 ), is the set
of all A    NC such that there exists a concept C with A v C  cDiff  (T1 , T2 ). The
tractability of computing cWtnlhs
 (T1 , T2 ) for EL has been proved by Lutz and Wolter (2010)
for arbitrary EL-TBoxes by reduction to simulation checking. Here we formulate the main
steps again because we employ the same technique when dealing with the logical difference
for ELHr -terminologies.
For any two interpretations I1 and I2 we say that a relation S between I1 and I2 is a
-simulation if, and only if, the following conditions hold:
 if (d, e)  S and d  AI1 with A  , then e  AI2 ;
 if (d, e)  S and (d, d0 )  rI1 with r  , then there exists e0 with (d0 , e0 )  S and
(e, e0 )  rI2 .
For d  I1 and e  I2 we write (I1 , d)  (I2 , e) if there exists a -simulation relation S between I1 and I2 such that (d, e)  S. It can be checked in polynomial time
whether (I1 , d)  (I2 , e) and various polynomial-time algorithms checking the existence of
simulations have been developed (Clarke & Schlingloff, 2001; Crafa, Ranzato, & Tapparo,
2011; van Glabbeek & Ploeger, 2008). Simulations characterise the expressive power of
EL-concepts in the following sense.
Lemma 29 (Lutz & Wolter, 2010). Let I1 and I2 be interpretations,  a signature, d  I1 ,
and e  I2 . Then
(I1 , d)  (I2 , e)



for all EL -concepts C: d  C I1  e  C I2 .

It follows that for any A  , we have
A  cWtnlhs
 (T1 , T2 )



(IK1 , a) 6 (IK2 , a)

where Ki = (Ti , A) for A = {A(a)} and IKi is the canonical model for Ki , i = 1, 2.
To see this, recall that by Theorem 2 for every EL-concept C, a  C IKi if, and only if,
(Ti , A) |= C(a). The latter condition is equivalent to Ti |= A v C. We have, therefore,
proved:
Theorem 30 (Lutz & Wolter, 2010). For EL-TBoxes T1 and T2 and signatures , the set
cWtnlhs
 (T1 , T2 ) can be computed in polynomial time.
The following example illustrates the use of simulations between canonical models to
determine cWtnlhs
 (T1 , T2 ).
Example 31. Let  = {A, r, B1 , B2 } and
T1 = {A v r.F0 , F0 v F1 u F2 , F1 v r.B1 , F2 v r.B2 },
T2 = {A v G1 u G2 , G1 v r.G01 , G2 v r.G02 , G01 v r.B1 , G02 v r.B2 }
656

fiThe Logical Difference for the Lightweight Description Logic EL

To check whether A  cWtnlhs
 (T1 , T2 ) consider the KBs K1 = (T1 , {A(a)}) and K2 =
(T2 , {A(a)}). Then A  cWtnlhs
 (T1 , T2 ) iff (IK1 , a) 6 (IK2 , a), for the canonical models
IK1 and IK2 of K1 and K2 , respectively. Illustrations of the canonical models IK1 and IK2
are shown below.
xran(r),B1
B1

xran(r),B2
B2

r

xran(r),B1
B1

r

r

r

A

r

xran(r),G01

xran(r),F0

IK 1

xran(r),B2
B2
xran(r),G02

r

r

A

a

a

IK2

But (IK1 , a) 6 (IK2 , a) because the point xran(r),F0 is neither -simulated by xran(r),G01 nor
-simulated by xran(r),G02 . A concept inclusion in cDiff  (T1 , T2 ) with A on the left-hand side
is given by A v r.((r.B1 ) u (r.B2 )).

5. ELHr -Instance Difference
Our polynomial-time algorithms for inseparability and logical difference in ELHr are based
on extensions of the ideas used in Section 4 for EL. There is, however, one important
difference: we introduce new logics, ELran and ELran,u,u , for which the concept difference
captures exactly the instance and, respectively, query difference in ELHr . To prove an analogue of Theorem 16 for those languages and, thereby, for the instance and query difference
for ELHr , we introduce a sequent calculus which characterises all ELran -consequences of
ELHr -terminologies. We start our investigation with the instance difference case since it is
more transparent than the concept difference case (recall that for EL there is no difference
between the instance and the concept difference).
5.1 ELran -Concept Difference
Recall Example 4 showing that ELHr -concept inseparability does not imply -instance
inseparability:
T1 = {ran(r) v A1 , ran(s) v A2 , B  A1 u A2 },

T2 = ,

 = {r, s, B}.

Notice that for the ABox A = {r(a, c), s(b, c)}, exhibiting the instance difference between
T1 and T2 , c is in the range of both r and s. This example suggests that if ran(r) and ran(s)
could be used in complex concepts, this kind of difference can be made visible for a concept
language.
Definition 32 (ELran ). C ran -concepts are constructed using the following syntax rule
C :=

A

|

ran(r)

|

C uD

|

r.C,

where A  NC , C, D range over C ran -concepts and r  NR . The set of ELran -inclusions
consists of all concept inclusions C v D and role inclusions r v s, where C is a C ran concept, D an EL-concept, and r, s  NR .
657

fiKonev, Ludwig, Walther, & Wolter

Clearly, every ELHr -inclusion is an ELran -inclusion. Additionally, in ELran -inclusions
the concept ran(r) can occur everywhere in concepts on the left-hand side of inclusions.
This gives us additional concept inclusions for the -concept difference.
Example 33. For T1 and T2 from Example 4, we have T1 |= ran(r) u ran(s) v B, but
T2 6|= ran(r) u ran(s) v B. Thus, using the C ran -concept ran(r) u ran(s) we can simulate
the ABox {r(a, c), s(b, c)} from Example 4 and make the -difference that could not be
observed in ELHr visible in ELran .
We now show that Example 33 can be generalised to arbitrary TBoxes. To this end, we
consider the following straightforward generalisation of the -concept difference to differences over ELran .
ran
r
Definition 34 (ELran
 -difference). The EL -difference between ELH -TBoxes T1 and T2
ran
is the set cDiff ran
 (T1 , T2 ) of all EL -inclusions  such that T1 |=  and T2 6|= .

To prove the equivalence between -instance difference in ELHr and -concept differran of
ence in ELran , we first associate with every ABox A and individual a in A a set CA,a
ran
C -concepts. Assume A is given. Let, inductively, for a  obj(A):
l
l
0,ran
=(
CA,a
A) u (
ran(r));
A(a)A

and
n+1,ran
=(
CA,a

l

A(a)A

A) u (

r(b,a)A

l

ran(r)) u (

r(b,a)A

l

n,ran
),
r.CA,b

r(a,b)A

and set
n,ran
ran
| n  0}
CA,a
= {CA,a
n,ran
(a) fordall n > 0. Moreover, the lemma below shows d
that, intuObserve that A |= CA,a
ran is the most specific concept with A |=
ran (a).
itively, the infinite conjunction CA,a
CA,a
Conversely, we associate an ABox with a C ran -concept. The construction is straightforward; however, some care has to be taken since we do not introduce structure sharing
but associate distinct individual names with distinct occurrences of subconcepts. Given a
C ran -concept C, we first define a path in C as a finite sequence C0  r1  C1      rn  Cn ,
where C0 = C, n  0, and ri+1 .Ci+1 is a conjunct of Ci , for 0  i < n. We use paths(C)
to denote the set of all paths in C. If p  paths(C), then tail(p) denotes the last element
Cn in p.
Now, let aran and ap for p  paths(C) be individual names and set inductively:

AC = { s(ap , aq ) | p, q  paths(C); q = p  s  C 0 , for some C 0 }
 { A(ap ) | A is a conjunct of tail(p), p  paths(C) }
 { >(ap ) | > is a conjunct of tail(p), p  paths(C) }
 { r(aran , ap ) | ran(r) is a conjunct of tail(p), p  paths(C) }
Example 35. Let C = (r.(A u ran(v))) u (s.((t.(A u ran(v))) u (t.(B u ran(s))))) be a
C ran -concept. Then AC can be represented graphically as follows.
658

fiThe Logical Difference for the Lightweight Description Logic EL

s

A
v

B

t

t

A
r

v

aran

s

aC

We only indicate aC and aran ; other individuals are identified by paths in C. Note that
different occurrences of A u ran(v) in C correspond to different individuals in AC .
Lemma 36. Let T be an ELHr -TBox, A be an ABox, C0 and D0 be C ran -concepts, and let
a0  obj(A). Then
n,ran
 (T , A) |= D0 (a0 ) if, and only if, there exists n  0 such that T |= CA,a
v D0 ;
0

 T |= C0 v D0 if, and only if, (T , AC0 ) |= D0 (aC0 ).
Below, we will employ this lemma to transfer an analogue of Theorem 16 for ELran to
ELHr -instance differences. For now, we only note the following consequence:
Corollary 37. For any two ELHr -TBoxes T1 and T2 , cDiff ran
 (T1 , T2 ) =  if, and only if,
iDiff  (T1 , T2 ) = .
n,ran
Proof. If (A, D0 (a0 ))  iDiff  (T1 , T2 ), then there exists an n  0 such that CA,a
v
0
ran
D0  cDiff ran
(T
,
T
).
Conversely,
if
C
v
D

cDiff
(T
,
T
),
then
(A
,
D
(a
))

1
2
0
0
1
2
0
C
C


0
0
iDiff  (T1 , T2 ).

Note that Theorem 6 follows from Corollary 37 since for any ELHr -TBox T without
range restrictions T |= C v D if, and only if, T |= C 0 v D, where C 0 is obtained from C
by replacing any concept of the form ran(r) in C by >.
5.2 Proof System for ELHr
The Gentzen-style proof system for ELHr consists of the rules given in Figures 1 and 5.
Cut elimination, correctness, and completeness of the proof system can be shown similarly
to the corresponding proofs given by Hofmann (2005).
Theorem 38. For all ELHr -terminologies T and C ran -concepts C and D, it holds that
T |= C v D if, and only if, T ` C v D.
We now generalise Lemma 15 to ELHr -terminologies.
Lemma 39. Let T be an ELHr -terminology, A a concept name and r.D an EL-concept.
Assume
l
l
l
T |=
ran(si ) u
Aj u
rk .Ck v r.D,
1il

1jn

1km

where Ck , 1  k  m, are C ran -concepts and l, m, n  0. Then at least one of the following
conditions holds:
659

fiKonev, Ludwig, Walther, & Wolter

r.(C u ran(r)) v D
(ExRan)
r.C v D
BvD
(Dom)
r.C v D
where r.> v B  T
AvD
(Ran)
ran(r) v D
s.C v D
(Sub)
r.C v D

where ran(r) v A  T

ran(s) v D
(RanSub)
ran(r) v D

where r v s  T

Figure 5: Additional rules for ELHr -terminologies.
(e1) there exists rk , 1  k  m, such that T |= rk v r and T |= Ck u ran(rk ) v D;
(e2) there exists Aj , 1  j  n, such that T |= Aj v r.D;
(e3) there exists rk , 1  k  m, such that T |= rk .> v r.D;
(e4) there exists si , 1  i  l, such that T |= ran(si ) v r.D.
Now assume that A is pseudo-primitive and
l
l
T |=
ran(si ) u
Aj u
1il

1jn

l

rk .Ck v A,

1km

where Ck , 1  k  m, are C ran -concepts and l, m, n  0. Then at least one of the following
conditions holds:
(a1) there exists Aj , 1  j  n such that T |= Aj v A;
(a2) there exists rk , 1  k  m such that T |= rk .> v A;
(a3) there exists si , 1  i  l such that T |= ran(si ) v A.
Proof. We prove the first part of the lemma, the second part can then be proved analogously.
d
d
d
Let C = 1il ran(si ) u 1jn Aj u 1km rk .Ck and assume that T |= C v r.D
holds. Then, we have T ` C v r.D by Theorem 38, which implies that there exists a
derivation D of the sequent C v r.D. The proof now proceeds by induction on the depth
of D, i.e. the maximal length of any path from the root to one of the leaves of D.
Notice that if l + n + m  2, the root of D can only have been derived by AndL1 or
AndL2. The lemma follows then from the induction hypothesis.
Otherwise, we have l + n + m = 1. Note that l + m + n = 0 is not possible since
T 6|= > v r.D by definition of the terminology T . If C = A1 or C = ran(s1 ), then (e2) or
(e4), respectively, hold already. It remains to consider the case where C = r1 .C1 . Then,
the rule used to derive the root of D can only have been one of Ax, Ex, ExRan, Dom or
Sub. We consider those cases one by one:
660

fiThe Logical Difference for the Lightweight Description Logic EL

 the root of D was derived with Ax: then by considering the form of the inference rule,
r1 = r and C1 = D. Hence T |= r1 v r and T |= C1 u ran(r1 ) v D, which implies
that (e1) holds.
 the root of D was derived with Ex: then r1 = r and T ` C1 v D. Hence, T |= r1 v r
and T |= C1 v D holds by Theorem 38. Thus, T |= C1 u ran(r1 ) v D and we can
infer that (e1) holds again.
 the root of D was derived with Dom: we have T ` B v r.D and r1 .> v B  T .
Then by Theorem 38, T |= B v r.D and hence, T |= r1 .> v r.D, that is, (e3)
holds.
 the root of D was derived with ExRan: we obtain T ` r1 .(C1 u ran(r1 )) v r.D.
Since the sequent r1 .(C1 u ran(r1 )) v r.D has a derivation that is of shorter length
than D, we can apply the induction hypothesis. Hence, either T |= r1 .> v r.D,
that is, (e3) holds, or T |= r1 v r and T |= (C1 u ran(r1 )) u ran(r1 ) v D. Hence (e1)
holds as |= C1 u ran(r1 ) v (C1 u ran(r1 )) u ran(r1 ).
 the root of D was derived with Sub: we obtain T ` s.C1 v r.D and r1 v s  T .
By the induction hypothesis, either T |= s.> v r.D, or T |= s v r and T |=
C1 u ran(s) v D. It can be seen that T |= r1 .> v r.D, or T |= r1 v r and
T |= C1 u ran(r1 ) v D, respectively. Hence (e3) or (e1) holds.

We now prove an extension of Theorem 16 to ELran -consequences of ELHr -terminologies.
We give a rather detailed description of the simple witness inclusions contained in members
of cDiff ran
 (T1 , T2 ) since we are going to use this result again when analysing the concept
difference in ELHr .
Theorem 40 (Primitive witness for ELran -differences). Let T1 and T2 be ELHr -terminologies
and  a signature. If   cDiff ran
 (T1 , T2 ), then either there exist {r, s}  sig() with
ran
r v s  cDiff  (T1 , T2 ) or  is of the form C v D, and one of
1. C 0 v A or ran(r) u C 0 v A,
2. A v D0 , r.> v D0 or ran(r) v D0
0
is a member of cDiff ran
 (T1 , T2 ), where r  sig(), A  sig() is a concept name, C is a
subconcept of C and D0 is a subconcept of D.
ran -concept and D an EL-concept. We
Proof. Let C v D  cDiff ran
 (T1 , T2 ), where C is a C
prove the theorem by induction on the structure of D.
Notice that D 6= > as T2 |= C v >. If D is a concept name, then an inclusion from
Point 1 exists. If D = D1 u D2 , then one of C v Di , i = 1, 2, is in cDiff ran
 (T1 , T2 ).
We can apply the induction hypothesis anddwe can infer that
an
inclusion
from
Point 1
d
d
or Point 2 exists. If D = r.D1 , let C = 1il ran(si ) u 1jn Aj u 1km rk .Ck .
Then, by Lemma 39, one of (e1)(e4) holds. Cases (e2)(e4) directly entail that an
inclusion from Point 1 or Point 2 exists. In case of (e1), either rk v r  cDiff ran
 (T1 , T2 )

661

fiKonev, Ludwig, Walther, & Wolter

or T1 |= Ck u ran(rk ) v D1 but T2 6|= Ck u ran(rk ) v D1 (as otherwise T2 |= C v D would
hold). Now we can apply the induction hypothesis to D1 and conclude that an inclusion
from Point 1 or Point 2 exists.
5.3 Instance Difference Witnesses
Similarly to Theorem 16 for the concept difference between EL-terminologies and derived from its extension, Theorem 40, for ELran , we show that every member (A, ) of
iDiff  (T1 , T2 ) gives rise to a basic witness in which either the ABox or the instance query
are atomic. To keep the formulation succinct we give an abstract description of the relationship between (A, )  iDiff  (T1 , T2 ) and its witness using only the signature of (A, ).
The interested reader will have no problem to derive a stronger relationship between (A, )
and its witness from the proof.
Theorem 41 (Primitive witness for ELHr -instance differences). Let T1 and T2 be ELHr terminologies and  a signature. If   iDiff  (T1 , T2 ), then at least one of the following
conditions holds:
1. ({r(a, b)}, s(a, b))  iDiff  (T1 , T2 ), for some r, s  sig();
2. (A, A(b))  iDiff  (T1 , T2 ), for some concept name A  sig(), individual b, and
ABox A with sig(A)  sig().
3. (A, D(b))  iDiff  (T1 , T2 ), for some singleton ABox A, individual b in A, and ELconcept D such that sig(A), sig(D)  sig();
Proof. Let (A, )  iDiff  (T1 , T2 ). We distinguish the following cases.
(a) If  = s(a, b), then (T1 , A) |= s(a, b) if, and only if, for some r(a, b)  A we have T1 |=
r v s. As (T2 , A) 6|= s(a, b) we obtain T2 6|= r v s. Thus, ({r(a, b)}, s(a, b))  iDiff  (T1 , T2 )
and Point 1 holds.
(b) Assume  = D(b) for some EL-concept D. By Lemma 36, for some n  0 we have
n,ran
n,ran
v D. By Theorem 40, one of (i) r v s, (ii) A v D0 , (iii)
v D and T2 6|= CA,b
T1 |= CA,b
r.> v D0 , (iv) ran(r) v D0 , (v) C v A, or (vi) ran(r)uC v A is a member of cDiff ran
 (T1 , T2 ),
n,ran
and D0 is a
where r  sig(), A  sig() is a concept name, C is a subconcept of CA,b
subconcept of D. If (i) r v s  cDiff ran
 (T1 , T2 ), then ({r(a, b)}, s(a, b))  iDiff  (T1 , T2 ) and
Point 1 holds.
Now let F v G denote the member of cDiff ran
 (T1 , T2 ) in the cases (ii)-(vi) above. Conran
sider the ABox AF associated with the C -concept F in Point 2 of Lemma 36. Then
sig(AF )  sig() and (AF , G(aF ))  iDiff  (T1 , T2 ).
In case (ii), we obtain that F = A is a concept name. Hence AF = {A(aF )} and Point 3
holds. For case (iii), we obtain AF = {r(aF , a> ), >(a> )} and Point 3 of the lemma applies
again (after removing >(a> ) from AF ). Similarly, if (iv), then AF = {r(aran , aF )}, and
Point 3 of the lemma holds. Finally, for the cases (v) and (vi), G  sig() is a concept
name. Hence Point 2 of the lemma applies.
Theorem 41 justifies the following finite representation of the -instance difference between ELHr -terminologies. It corresponds exactly to the three distinct points of the theorem. Assume T1 and T2 are given. Let
662

fiThe Logical Difference for the Lightweight Description Logic EL

 the set of role -instance difference witnesses, iWtnR
 (T1 , T2 ), consist of all r v s such
that T1 |= r v s and T2 6|= r v s;
 the set of right-hand -instance difference witnesses, iWtnrhs
 (T1 , T2 ), consist of all
A   such that there exists A with (A, A(a))  iDiff  (T1 , T2 );
 the set of left-hand -instance difference witnesses, iWtnlhs
 (T1 , T2 ), consist of all A  
such that there exists C(a) with ({A(a)}, C(a))  iDiff  (T1 , T2 ) and all r   such
that there exists C(c) with c = a or c = b such that ({r(a, b)}, C(c))  iDiff  (T1 , T2 ).
The set of all -instance difference witnesses is defined as
rhs
lhs
iWtn (T1 , T2 ) = (iWtnR
 (T1 , T2 ), iWtn (T1 , T2 ), iWtn (T1 , T2 )).

By Theorem 41, observe that iWtn (T1 , T2 ) = (, , ) if, and only if, iDiff  (T1 , T2 ) = . The
set iWtnR
 (T1 , T2 ) can be easily computed in polynomial time and will not be analysed further
in this paper. Thus, our aim now is to present polynomial-time algorithms computing
lhs
iWtnrhs
 (T1 , T2 ) and iWtn (T1 , T2 ).
5.4 Computing iWtnrhs
 (T1 , T2 )
We compute iWtnrhs
 (T1 , T2 ) in two different ways: first, we present the more transparent
ABox approach that works for arbitrary ELHr -terminologies, and second we present the
more efficient dynamic programming approach that works for acyclic ELHr -terminologies
only. Both approaches have been introduced in Section 4.2 for EL-terminologies. We start
with the ABox approach and exhibit a -ABox AT2 , depending on T2 and  only such that
for non-conjunctive A   there exists an ABox A such that (A, A(d))  iDiff  (T1 , T2 ) if,
and only if, (T1 , AT2 , ) |= A(A ) for a certain individual name A . The case of conjunctive
A is reduced to this condition for its defining concept names.
To deal with ELHr -terminologies rather than with EL-terminologies we have to extend
the structure of AT2 , significantly. To describe the model-theoretic properties of AT2 , , we
require the notion of a -range simulation. They capture model-theoretically the expressive
power of C ran -concepts (the concepts that have been used to describe the -instance difference in terms of subsumption, cf. Lemma 36). For any two ABoxes A1 , A2 with designated
individual names a1 and a2 , we say that a relation S between obj(A1 ) and obj(A2 ) is a
-simulation if, and only if,
(S1) (a1 , a2 )  S;
(S2) for all A  : if (a, b)  S and A(a)  A1 , then A(b)  A2 ;
(S3) for all r  : if (a, b)  S and r(a, a0 )  A1 , then there exists b0 with (a0 , b0 )  S and
r(b, b0 )  A2 .
We say that S is a -range simulation if, in addition,
(RS) for all r  : if (a, b)  S and there exists c such that r(c, a)  A1 , then there exists
c0 with r(c0 , b)  A2 .
In what follows we write
663

fiKonev, Ludwig, Walther, & Wolter

 (A1 , a1 )  (A2 , a2 ) if there exists a -simulation between (A1 , a1 ) and (A2 , a2 ); and
 (A1 , a1 ) ran
(A2 , a2 ) if there exists a -range simulation between (A1 , a1 ) and

(A2 , a2 ).
The following lemma shows that range simulations characterise C ran -concepts.
Lemma 42. Let A1 and A2 be -ABoxes with designated individual names a1 and a2 . If
ran -concepts
(A1 , a1 ) ran
 (A2 , a2 ), then (T , A1 ) |= C(a1 ) implies (T , A2 ) |= C(a2 ) for all C
C.
Proof. We apply Lemma 36. Let S be a -range simulation between A1 and A2 with
(a1 , a2 )  S. One can prove by induction on n that for all n  0, for all a  obj(A1 ) and
for all b  obj(A2 ),
n,ran
(b).
() If (a, b)  S, then A2 |= CA
1 ,a
ran Now assume that (A1 , a1 ) ran
 (A2 , a2 ) and that (T , A1 ) |= C(a1 ) holds for a C
n,ran
concept C. Then, by Lemma 36, there exists n  0 such that T |= CA1 ,a1 v C. Moreover,
n,ran
as (A1 , a1 ) ran
 (A2 , a2 ), we have by () that A2 |= CA1 ,a1 (a2 ), which then implies that
(T , A2 ) |= C(a2 ), as required.

The construction of AT , is now given in Figure 6, where T is a normalised ELHr terminology and  a signature. We advise the reader to recall the definition of AT , given
in Figure 3 for EL-terminologies T and then consider the additional ingredients required
for ELHr -terminologies. We remind the reader of the definition of non-conjT (A) from
Section 4.2:

{A}, A is non-conjunctive in T
non-conjT (A) =
{B1 , . . . , Bn }, A  B1 u    u Bn  T
In Figure 6, we also use the following sets, for A  NC and r  NR :
 preC
T (A) = { B    NC | T |= B v A },
 preDom
T (A) = { r    NR | T |= r.> v A },
 preRan
T (A) = { r    NR | T |= ran(r) v A },
 preRole
T (r) = { s    NR | T |= s v r }.
The following example illustrates the definition of AT , .
Example 43. For T1 = {ran(r) v A1 , ran(s) v A2 , B  A1 u A2 }, T2 = , and  = {r, s, B}
defined as in Example 4, we have
AT2 , = {B( ), r( ,  ), s( ,  ), r(B ,  ), s(B ,  ), r( , B ), s( , B )}.
It holds that (T1 , AT2 , ) |= B(B ) and (T2 , AT2 , ) 6|= B(B ).

664

fiThe Logical Difference for the Lightweight Description Logic EL

Let
{A | A  sig(T )   and non-conjunctive in T }  { }  NI .
be a set of individual names. For A non-conjunctive in T , define sets AT , (A) of assertions
as follows
 if A is pseudo-primitive in T , then
AT , (A) = { A0 (A ) | A0   \ preC
T (A) }
 { r(A ,  ) | r   \ preDom
T (A) }
 { r( , A ) | r   \ preRan
T (A) },
 if A  r.B  T , then for s  NR let


0
A = { (s, B 0 ) | B 0  non-conjT (B), s  preRole
T (r) \ (preDomT (A)  preRanT (B )) }

and set
AT , (A) = { A0 (A ) | A0   \ preC
T (A) }
 { s( , A ) | s   \ preRan
T (A) }

 { s(A ,  ) | s   \ (preRole
T (r)  preDomT (A)) }

 { s(A , ) | (s, )  A }.
Let
AT , = { A0 ( ) | A0   }  { r( ,  ) | r   } 

[

AT , (A)

Asig(T )
A is non-conjunctive in T

Figure 6: Construction of AT , for ELHr -terminologies.
Lemma 44. For every normalised ELHr -terminology T and signature  the following
conditions are equivalent for all -ABoxes A, A  sig(T )   non-conjunctive in T , and
all a  obj(A):
1. (T , A) 6|= A(a);
2. A  obj(AT , ) and (A, a) ran
 (AT , , A ).
Lemma 44 is proved in the appendix.
Lemma 45. Let T1 and T2 be normalised ELHr -terminologies,  a signature and A  .
Let AT2 , be the ABox constructed in Figure 6. Then the following conditions are equivalent:
 there exists a -ABox A such that (T1 , A) |= A(a) and (T2 , A) 6|= A(a);
 (T1 , AT2 , ) |= A(B ) for some B  non-conjT2 (A).
665

fiKonev, Ludwig, Walther, & Wolter

Proof. Assume there exists a -ABox A and a  obj(A) with (T1 , A) |= A(a) and (T2 , A) 6|=
A(a). Then, as (T2 , A) 6|= A(a), for some B  non-conjT2 (A), (T2 , A) 6|= B(a). Hence,
by Lemma 44, (A, a) ran
 (AT2 , , B ). But then, by Lemma 42, (T1 , AT2 , ) |= A(B ), as
required.
Conversely, suppose that (T1 , AT2 , ) |= A(B ) for some B  non-conjT2 (A) with B 
obj(AT2 , ). Notice that, by Lemma 44, (T2 , AT2 , ) 6|= B(B ). Hence (T2 , AT2 , ) 6|= A(B )
and so AT2 , and B witness Point 1.
Theorem 46. Let T1 and T2 be normalised ELHr -terminologies and  a signature. Then
iWtnrhs
 (T1 , T2 ) can be computed in polynomial time.
Proof. By Lemma 45, A  iWtnrhs
 (T1 , T2 ) if, and only if, for some B  non-conjT2 (A) we have
(T1 , AT2 , ) |= A(B ). It remains to observe that AT2 , can be constructed in polynomial
time and checking whether (T1 , AT2 , ) |= A(B ) is in polynomial time.
We now briefly describe how the dynamic programming approach for computing the set
r
iWtnrhs
 (T1 , T2 ) for acyclic terminologies is extended from EL to ELH . The extension of
the NotWitness(E) algorithm from Figure 4 to ELHr is given in Figure 7. As in Figure 4,
the procedure NotWitness(E) recursively associates with every E  sig(T1 )   a subset of
 = {All}  { A | A  (sig(T2 )  ), A is non-conjunctive in T2 }.
The conditions for A  NotWitness(E) become more complex since now one has to take into

account the sets preRan
T (E) and preDomT (E). To prove the correctness of the NotWitness
algorithm, we observe the following consequence of Lemma 36.
Corollary 47. Let T1 and T2 be normalised acyclic ELHr -terminologies and  a signature.
ran -concept C such that C v A  cDiff ran (T , T ) }.
Then iWtnrhs
1 2
 (T1 , T2 ) = { A   |  C

Proof. First, let A  iWtnrhs
 (T1 , T2 ). Then there exists a -ABox A such that (T1 , A) |=
A(a) and (T2 , A) 6|= A(a). Hence, by Point 1 of Lemma 36 there exists n  0 such that
n,ran
n,ran
ran -concept. Conversely, assume A  
CA,a
v A  cDiff ran
 (T1 , T2 ). Note that CA,a is a C
such that there exists a C ran -concept C with C v A  cDiff ran
 (T1 , T2 ). Then by Point 2 of
Lemma 36, (AC , A(aC ))  iDiff  (T1 , T2 ), i.e. A  iWtnrhs
(T
,
T2 ).
1

We now formulate the correctness of the NotWitness algorithm in the same way as in
Corollary 26.
Theorem 48. Let T1 and T2 be normalised acyclic ELHr -terminologies and  a signature.
Then iWtnrhs
 (T1 , T2 ) = { A  sig(T1 )   |  B  non-conjT2 (A) with B 6 NotWitness(A) }.
The proof is an extension of the proofs of Lemma 25 and Corollary 26. Namely, one can
show that for all A  sig(T1 )   and all B  sig(T2 )   such that B is non-conjunctive
in T2 the following conditions are equivalent:
 B  NotWitness(A);
ran -concepts C: T 6|= C v B implies T 6|= C v A.
 for all C
2
1

Using Corollary 47, we thus obtain for every A  : A  iWtnrhs
 (T1 , T2 ) if, and only if,
ran
there exists a C -concept C with T2 6|= C v A and T1 |= C v A if, and only if, there exists
B  non-conjT2 (A) with B 6 NotWitness(A).
666

fiThe Logical Difference for the Lightweight Description Logic EL

procedure AuxPP (E)


if preC
T1 (E) =  and preRanT1 (E) =  and preDomT1 (E) =  then
return {All}
else

Auxconcept := { A   | preC
T1 (E)  preCT2 (A) }

Auxran := { A   | preRanT1 (E)  preRan
T2 (A) }

Auxdom := { A   | preDomT1 (E)  preDom
T2 (A) }
return Auxconcept  Auxran  Auxdom
end if
end procedure
procedure NotWitness(E)
if E is pseudo-primitive in T1 then
NotWitness(E) := AuxPP (E)
else if E  E1 u    uSEk  T1 then
k
NotWitness(E) := i=1 NotWitness(Ei )
else if E  r.E 0  T1 then
0
if preRole
T1 (r) =  or All  NotWitness(E ) then
NotWitness(E) := AuxPP (E)
else
fi


fi A is pseudo-primitive in T , and
fi
Auxrole,prim := A   fi

preRole
T1 (r)  preDomT2 (A)
fi

fi A  t.B  T2 ,

fi


fi





fi preRoleT1 (r)  preRoleT2 (t)  preDomT2 (A), and


fi




fi for all s  preRoleT (r)  preRoleT (t) with
1
2
Auxrole,exist := A   fifi

0

s

/
preDom
(A)
and
B

non-conj
fi

T2 (B) with
T2

fi


0
00

fi

s

6
preRan
(B
),
there
exists
E

non-conjT1 (E 0 )
T2

fi


00
0
00
fi
with B  NotWitness(E ) and s 6 preRan
T1 (E )
NotWitness(E) := (Auxrole,prim  Auxrole,exist )  AuxPP (E)
end if
end if
end procedure





















Figure 7: Computation of NotWitness(E) for ELHr .
5.5 Tractability of iWtnlhs
 (T1 , T2 )
We prove the tractability of iWtnlhs
 (T1 , T2 ) by the same reduction to simulation checking as
in the case of EL-terminologies (Theorem 30).
Theorem 49. Let T1 and T2 be ELHr -TBoxes and let  be a signature. Then the set
iWtnlhs
 (T1 , T2 ) can be computed in polynomial time.
Proof. For any concept name A   we have
A  iWtnlhs
 (T1 , T2 )


667

(IK1 , a) 6 (IK2 , a)

fiKonev, Ludwig, Walther, & Wolter

where Ki = (Ti , A) for A = {A(a)} and IKi is the canonical model for Ki , i = 1, 2. Indeed,
({A(a)}, C(a))  iDiff  (T1 , T2 ), for some EL -concept C, if, and only if, by Theorem 2, a 
C IK1 and a 
/ C IK2 . But this condition is, by Lemma 29, equivalent to (IK1 , a) 6 (IK2 , a).
The latter condition can be checked in polynomial time.
Similarly, for any role name r   we have
r  iWtnlhs
 (T1 , T2 )



(IK1 , a) 6 (IK2 , a) or (IK1 , b) 6 (IK2 , b)

where Ki = (Ti , A), A = {r(a, b)}, and IKi is the canonical model for Ki , i = 1, 2. Again,
the latter condition can be checked in polynomial time.

6. ELHr -Concept Difference
In this section we present polynomial-time algorithms deciding -concept inseparability and
computing a succinct representation of the concept difference between ELHr -terminologies.
The algorithms are essentially by reduction to the instance difference case.
We start by introducing the succinct representation of the -concept difference. Let
T1 and T2 be ELHr -terminologies. Since cDiff  (T1 , T2 )  cDiff ran
 (T1 , T2 ), it follows from
Theorem 40 for C v D  cDiff  (T1 , T2 ) that there exists an inclusion of at least one of the
following forms
(i) C 0 v A,
(ii) ran(r) u C 0 v A,
(iii) A v D0 ,
(iv) r.> v D0 , or
(v) ran(r) v D0
in cDiff  (T1 , T2 ), where r  sig(), A  sig() is a concept name, C 0 is a subconcept of C
and D0 is a subconcept of D. Notice in particular for case (ii) that C 0 is an EL-concept.
Hence, just as in the case of the -instance difference, we obtain the following representation
of the -concept difference. Assume T1 and T2 are given. Let
 the set of role inclusion -concept difference witnesses, cWtnR
 (T1 , T2 ), consist of all
r v s such that T1 |= r v s and T2 6|= r v s;
 the set of right-hand -concept difference witnesses, cWtnrhs
 (T1 , T2 ), consist of all
A   such that there exists an EL-concept C with either C v A  cDiff  (T1 , T2 ) or
there additionally exists a role name r   such that ran(r) u C v A  cDiff  (T1 , T2 ).
 the set of left-hand -concept difference witnesses, cWtnlhs
 (T1 , T2 ), consist of all A  
such that there exists an EL-concept C with A v C  cDiff  (T1 , T2 ), and of all
role names r   such that there exists an EL-concept C with either r.> v C 
cDiff  (T1 , T2 ) or ran(r) v C  cDiff  (T1 , T2 ).
The set of all -concept difference witnesses is defined as
rhs
lhs
cWtn (T1 , T2 ) = (cWtnR
 (T1 , T2 ), cWtn (T1 , T2 ), cWtn (T1 , T2 )).

668

fiThe Logical Difference for the Lightweight Description Logic EL

Observe that cWtn (T1 , T2 ) = (, , ) if, and only if, cDiff  (T1 , T2 ) = . We also obtain
lhs
that the sets cWtnR
 (T1 , T2 ) and cWtn (T1 , T2 ) coincide with the corresponding witness sets
for the instance difference, which allows us to re-use some results that we have developed
for detecting instance differences.
Lemma 50. Let T1 and T2 be normalised ELHr -terminologies and  a signature. Then the
following holds:
R
1. cWtnR
 (T1 , T2 ) = iWtn (T1 , T2 ),
lhs
2. cWtnlhs
 (T1 , T2 ) = iWtn (T1 , T2 )
rhs
3. cWtnrhs
 (T1 , T2 )  iWtn (T1 , T2 )
lhs
Proof. Point 1 follows directly from the definition. Proving cWtnlhs
 (T1 , T2 )  iWtn (T1 , T2 )
rhs
and cWtnrhs
 (T1 , T2 )  iWtn (T1 , T2 ) is similar to Lemma 10. Finally, to prove that
lhs
lhs
iWtn (T1 , T2 )  cWtn (T1 , T2 ), assume that A  iWtnlhs
 (T1 , T2 ). Then there exists an ELconcept D(a) with ({A(a)}, D(a))  iDiff  (T1 , T2 ). But then T1 |= A v D and T2 6|= A v D
lhs
and, therefore, A  cWtnlhs
 (T1 , T2 ). The argument for r  iWtn (T1 , T2 ) is similar.

We have presented polynomial-time algorithms which can compute iWtnlhs
 (T1 , T2 ) and
rhs
iWtnR
(T
,
T
).
Thus,
it
remains
to
analyse
cWtn
(T
,
T
).
1
2
1
2


6.1 Tractability of cWtnrhs
 (T1 , T2 )
We prove tractability of cWtnrhs
 (T1 , T2 ) by modifying the ABox AT2 , that has been introrhs
duced to prove tractability of iWtnrhs
 (T1 , T2 ). Recall that A  iWtn (T1 , T2 ) iff (T1 , AT2 , ) |=
A(B ) for some B  non-conjT2 (A) (cf. Lemma 45). Not all A satisfying this condition are in
cWtnrhs
 (T1 , T2 ) since the ABox AT2 , cannot always be captured by a set of EL-concepts
(cf. Example 4). Our modification of AT2 , is motivated by the observation that if an ABox
A does not contain any individual in the range of two distinct role names, then EL-concepts
rather than C ran -concepts are sufficient to capture the consequences of the ABox. Thus, we
are going to modify AT2 , in a minimal way so that the resulting ABox does not contain
any individual name in the range of two distinct role names.
Definition 51. An ABox A is role-splitting if there is no pair of assertions r(a, c), s(b, c) 
A, for individual names a, b, c and distinct role names r, s.
The following lemma states the main property of role-splitting ABoxes.
Lemma 52. Let T1 and T2 be normalised ELHr -terminologies,  a signature with A  
and let A be a role-splitting -ABox such that (T1 , A) |= A(a) and (T2 , A) 6|= A(a). Then
A  cWtnrhs
 (T1 , T2 ).
n,ran
n,ran
Proof. By Lemma 36, there exists n  0 such that T1 |= CA,a
v A and T2 6|= CA,a
v A.
Assume first that there does not exist b  obj(A) and r   such that r(b, a)  A. Then,
n,ran
by definition and since A is role-splitting, ran(r) only occurs in CA,a
in the direct scope
n,ran
of the existential restriction r. Hence CA,a is equivalent to an EL -concept, and we
are done. Now assume there exists r(b, a)  A. Then, again since A is role-splitting,
n,ran
CA,a
is equivalent to a concept ran(r) u C, where C is an EL -concept. In this case
T1 |= ran(r) u C v A and T2 6|= ran(r) u C v A, as required.

669

fiKonev, Ludwig, Walther, & Wolter

For a -ABox A such that sig(A)  NR 6= , we define its role-splitting unfolding A
with individuals { ar | a  obj(A), r  sig(A)  NR } by setting
A = { A(ar ) | A(a)  A, r  sig(A)  NR }  { r(as , br ) | r(a, b)  A, s  sig(A)  NR }.
Example 53. Consider T1 = {ran(r) v A1 , ran(s) v A2 , B  A1 u A2 }, T2 = ,  =
{r, s, B} and A = {r(a, c), s(b, c)} from Example 4. We have (T1 , A) |= B(c) but (T2 , A) 6|=
B(c). Notice that the role-splitting unfolding A = {r(ar , cr ), r(as , cr ), s(br , cs ), s(bs , cs )}
does not contain any individual in the range of more than one role
c

A

cr

A

cs
r

r

s

r

a

b

ar

s
s

br

as

bs

and (T1 , A ) 6|= B(cr ), (T1 , A ) 6|= B(cs ).
We apply the role-splitting unfolding to the ABox AT , from Figure 6. The following
result is the concept version of Lemma 44 and is proved in the appendix by a reduction to
Lemma 44. The ABox AC corresponding to an EL-concept C has been introduced before
Lemma 36. For simplicity, we consider signatures  containing at least one role name.
Lemma 54. For every normalised ELHr -terminology T , signature  such that   NR 6= ,
concept name A that is non-conjunctive in T , role name r  , and EL -concepts C the
following conditions are equivalent for D = C and D = ran(r) u C:
 T 6|= D v A;

 for some r    NR , (A )r  obj(AT , ) and (AD , aD ) ran
 (AT , , (A )r ).

The following lemma can now be proved similarly to Lemma 45, using Lemma 54 instead
of Lemma 44.
Lemma 55. Let T1 and T2 be normalised ELHr -terminologies,  a signature with A  
such that   NR 6= . Then the following conditions are equivalent:
 A  cWtnrhs
 (T1 , T2 );
 there exists r   such that (T1 , AT2 , ) |= A((B )r ) for some B  non-conjT2 (A).
Proof. Assume that A  cWtnrhs
 (T1 , T2 ). Then, there either exists an EL -concept C
with T1 |= C v A and T2 6|= C v A, or there additionally exists r   such that T1 |=
ran(r) u C v A and T2 6|= ran(r) u C v A. Hence, for D = C and D = ran(r) u C,
respectively, T2 6|= D v B, for some B  non-conjT2 (A), and by Lemma 54, there exists

r   with (A )r  obj(AT , ) and (AD , aD ) ran
 (AT2 , , (B )r ). But then, by Lemma 42
(T1 , AT2 , ) |= A((B )r ) as (T1 , AD ) |= A(aD ) holds by Lemma 36.
For the converse direction, it is easy to see that (B )r  obj(AT2 , ), B  obj(AT2 , ), and

(AT2 , , (B )r ) ran
 (AT2 , , B ), which implies that (T2 , AT2 , ) 6|= A((B )r ) by Lemma 44.
Consequently, we obtain A  cWtnrhs
 (T1 , T2 ) by applying Lemma 52 and by using the fact
that the ABox AT2 , is role-splitting.
670

fiThe Logical Difference for the Lightweight Description Logic EL

Finally, we obtain the tractability result.
Theorem 56. Let T1 and T2 be ELHr -terminologies and  a signature. Then the set
cWtnrhs
 (T1 , T2 ) can be computed in polynomial time.
rhs
Proof. If   NR = , then cWtnrhs
 (T1 , T2 ) = iWtn (T1 , T2 ), which can be computed in
polynomial time by Theorem 46.
Otherwise   NR 6=  and the result follows from Lemma 55 and the fact that AT2 ,
can be constructed in polynomial time in the size of T2 .

7. ELHr -Query Difference
To investigate the query difference between ELHr -terminologies, we introduce the language
ELran,u,u that extends ELran with the universal role and intersections of roles. We show
that concept differences in ELran,u,u correspond to query differences in ELHr . For ELran,u,u
we can prove an analogue of Theorem 40, which states that any inclusion in the concept
difference contains an inclusion in which either the left-hand side or the right-hand side
is atomic. Using the correspondence between concept difference in ELran,u,u and query
difference in ELHr we then obtain a meaningful definition of a succinct representation of
the query difference qDiff  (T1 , T2 ). Finally, we provide polynomial-time algorithms deciding
-query inseparability and computing the succinct representation of the query difference.
7.1 ELran,u,u -Concept Difference
We start this section by defining the language ELran,u,u .
Definition 57 (ELran,u,u ). Let u (the universal role) be a fresh logical symbol. C u,u concepts are constructed using the following syntax rule
C :=

A

|

C uD

|

R.C

|

u.C,

where A  NC , C, D range over C u,u -concepts and R = r1 u    u rn with r1 , . . . , rn  NR for
some n  1. The set of ELran,u,u -inclusions consists of concept inclusions C v D and role
inclusions r v s, where C is a C ran -concept, D a C u,u -concept, and r, s  NR .
The semantics of the additional constructors is straightforward by setting, for any interpretation I,
 (r1 u    u rn )I = rI1      rnI ;
 uI = I  I .
Note that we regard the universal role u as a logical symbol; i.e., u 6 NR and sig(u.C) =
sig(C) for any concept C. Assuming that u is a logical symbol reflects the fact that its firstorder translation uses no non-logical symbols. For example, the signature of the first-order
translation x.A(x) of u.A does not contain any non-logical symbols with the exception
of A itself.
It will be convenient to decompose C u,u -concepts. The set of C u -concepts is defined as
the set of all C u,u -concepts without the universal role. Every C u,u -concept C is equivalent
671

fiKonev, Ludwig, Walther, & Wolter

to a concept of the form D0 u u.D1 u    u u.Dk , where D0 , . . . , Dk are C u -concepts. To
see this, observe that any concept C with a subconcept u.D is equivalent to u.D u C 0 ,
where C 0 is obtained from C by replacing all occurrences of u.D by >. For example,
A u r.(B u u.E) is equivalent to the concept u.E u A u r.(B u >).
u,u
u ) the set of all C u,u (C u ) concepts whose signature
In the following we denote by C
(C
is contained in .
Clearly, every ELran -inclusion is an ELran,u,u -inclusion. In addition, role conjunctions
and the universal role in ELran,u,u -inclusions can be used to capture differences between
ELHr -TBoxes that cannot be captured by ELHr -inclusions.
Example 58. We first reconsider Example 8. Recall that
T1 = ,

T2 = {A v r.B},

 = {A, B}.

Then T2 |= A v u.B but T1 6|= A v u.B and, as the universal role is regarded as a
logical symbol, sig(A v u.B)  . Thus, by employing the universal role ELran,u,u we can
simulate the query difference ({A(a)}, x.B(x)) using the subsumption A v u.B.
Second, we reconsider Example 9. Recall that
T1 = {A v s.>, s v r1 , s v r2 },

T2 = {A v r1 .> u r2 .>},

 = {A, r1 , r2 }.

Then T1 |= A v (r1 u r2 ).> and T2 6|= A v (r1 u r2 ).>. Thus, we can simulate the query
difference ({A(a)}, x.(r1 (a, x)  r2 (a, x))) using the subsumption A v (r1 u r2 ).>.
We introduce the appropriate notion of -concept difference for ELran,u,u .
ran,u,u
Definition 59 (EL
-difference). The ELran,u,u
-difference between ELHr -TBoxes T1

ran,u,u
ran,u,u
-inclusions  such that T1 |=  and
(T1 , T2 ) of all EL
and T2 is the set cDiff 
T2 6|= .

We now extend Lemma 39 for concepts that use the universal role or conjunctions of
roles.
Lemma 60. Let T be an ELHr -terminology and R.D a C u -concept with R = t1 u    u tq
a conjunction of role names. Assume
l
l
l
T |=
ran(si ) u
Aj u
rk .Ck v R.D,
1il

1jn

1km

where Ck , 1  k  m, are C ran -concepts and l, m, n  0. Then at least one of the following
conditions holds:
(e1u ) there exists rk , 1  k  m, such that rk vT t1 ,. . . , rk vT tq , and T |= Ck uran(rk ) v
D;
(e2u ) there exists Aj , 1  j  n, such that T |= Aj v R.D;
(e3u ) there exists rk , 1  k  m, such that T |= rk .> v R.D;
(e4u ) there exists si , 1  i  l, such that T |= ran(si ) v R.D.
672

fiThe Logical Difference for the Lightweight Description Logic EL

If u is the universal role and T |= C v u.D, where C is a C ran -concept and D is a
C u -concept, then at least one of the following holds:
(e1u ) there exists a subconcept r.C 0 of C such that T |= C 0 u ran(r)v D;
(e2u ) there exists a concept name A in C such that T |= A v u.D;
(e3u ) there exists a role name r in C such that T |= r.> v u.D;
(e4u ) there exists a role name r in C such that T |= ran(r) v u.D;
(e5u ) T |= C v D;
(e6u ) there exists a subconcept (ran(r) u C 0 ) of C such that T |= r.C 0 v D.
Theorem 61 (Primitive witnesses for ELran,u,u ). Let T1 and T2 be ELHr -terminologies
ran,u,u
and  a signature. If   cDiff 
(T1 , T2 ), then either there exist {r, s}  sig() with
ran,u,u
r v s  cDiff 
(T1 , T2 ) or  is of the form C v D, and one of
1. C 0 v A
2. A v D0 , r.> v D0 or ran(r) v D0
is a member of cDiff ran,u,u
(T1 , T2 ), where A  sig() is a concept name, r  sig() is a role

0
ran
name, C is a C -concept, D0 is a C u,u -concept, and sig(C 0 ), sig(D0 )  sig().
Proof. Let C v D  cDiff ran,u,u
(T1 , T2 ), where C is a C ran -concept and D a C u,u -concept.

We prove the result by induction on the structure of D. The proof is verydsimilar to the
proof of Theorem
d
d 40 and so we consider the case D = u.D1 only. Let C = 1il ran(si ) u
1jn Aj u 1km rk .Ck . Then, by Lemma 60, one of (e1u )(e6u ) holds.
Cases (e2u )(e4u ) directly entail the existence of an inclusion from Point 2 of the
theorem. In case (e1u ) there exists a subconcept r.C 0 of C such that T1 |= C 0 uran(r) v D1 .
We have that T2 6|= C 0 u ran(r) v D1 as otherwise we have T2 |= r.C 0 v r.D1 , i.e.
(T1 , T2 ). We can apply the
T2 |= C v D would hold. Thus, C 0 u ran(r) v D1  cDiff ran,u,u

induction hypothesis to D1 and infer that an inclusion from Point 1 or Point 2 exists.
(T1 , T2 ) as otherwise T2 |= C v
Similarly, for case (e5u ), we have C v D1  cDiff ran,u,u

D1 , i.e. T2 |= C v D due to D = u.D1 . By applying the induction hypothesis to D1 , we
obtain that an inclusion from Point 1 or Point 2 exists.
Finally, in case (e6u ) there exists a subconcept ran(r) u C 0 of C such that T1 |= r.C 0 v
D1 . Observe first that for every model I of T2 and for every d  C I , there exists d0 
(ran(r) u C 0 )I , which implies that there exists d00  (r.C 0 )I . If we now assume that
T2 |= r.C 0 v D1 , it would follow that for every model I of T2 and for every d  C I ,
there exists d00  D1I , i.e. T2 |= C v u.D1 would hold. We can infer that r.C 0 v D1 
ran,u,u
cDiff 
(T1 , T2 ) and by applying the induction hypothesis to D1 , we conclude that an
inclusion from Point 1 or Point 2 exists.
7.2 Query Difference Witnesses
We start by connecting concept differences in ELran,u,u with query differences between
ELHr -terminologies. The direction from query differences in ELHr to concept differences
in ELran,u,u is straightforward: observe that every assertion C(a) with C a C u,u -concept can
673

fiKonev, Ludwig, Walther, & Wolter

be regarded as a Boolean conjunctive query qC,a . For example, the assertion (u.Aur.B)(a)
is equivalent to the conjunctive query xy.(A(x)r(a, y)B(y)) (details of the translation
are provided in the appendix). We obtain (where AC is the ABox defined before Lemma 36):
Lemma 62. For any two ELHr -TBoxes T1 and T2 and signature , we have C v D 
cDiff ran,u,u
(T1 , T2 ) if, and only if, (AC , qD,aC )  qDiff  (T1 , T2 ).

In what follows we will not distinguish between an assertion C(a) with C a C u,u -concept
and the conjunctive query qC,a . It follows from Lemma 62 that if qDiff  (T1 , T2 ) = , then
cDiff ran,u,u
(T1 , T2 ) = .

We come to the (considerably more involved) direction from query differences to concept
differences in ELran,u,u . The following lemma provides a rather abstract description of how
inclusions in qDiff  (T1 , T2 ) are reflected by members of cDiff ran,u,u
(T1 , T2 ) by stating that

they are given in the same signature.
Lemma 63. For any two ELHr -TBoxes T1 and T2 and signature , if   qDiff  (T1 , T2 ),
(T1 , T2 ) with sig(0 )  sig().
then there exists 0  cDiff ran,u,u

The interested reader can extract a more detailed description from the proof given in the
appendix. The proof of Lemma 63 given in the appendix is model-theoretic and employs
the close relationship between conjunctive query entailment and homomorphisms (Chandra
& Merlin, 1977). The intuition behind the result, however, is rather straightforward: if
(T , A) |= q[~a] for a conjunctive query q(~x) = ~y (~x, ~y ) and ELHr -TBox T , then for every
model I of (T , A) there is a mapping  from the variables ~x and ~y into I such that ~a is a
-match of q(~x) and I. (T , A) has models that are essentially forest-shaped: they consist
of tree-shaped models attached to the ABox individuals in A (cf. Lutz et al., 2009). In
such forest-shaped models, the individuals from ~y that are not mapped to individuals in
A are mapped to the trees attached to the ABox individuals. Such a mapping, however,
exists already for a conjunctive query q 0 such that q is a homomorphic image of q 0 and q 0 is
essentially forest-shaped: the individuals not mapped to ABox individuals form trees that
are attached to the core of q 0 that is mapped to the ABox individuals. In other words, we
obtain q 0 by partitioning q into a core and into subsets that correspond to C u,u -concepts!
Now, if there exists a -ABox A and a conjunctive -query q(~a) such that (T2 , A) |= q[~a]
and (T1 , A) 6|= q[~a], then we find such a conjunctive -query q 0 with the same behaviour as
q that is essentially forest-shaped. From (A, q 0 ) one can then obtain the required ELran,u,u inclusion C v D, where D captures some subtree of the query q 0 (a C u,u -concept) and C
(a C ran -concept) the ABox A. The intuition for the last step is exactly the same as for
Lemma 36.
We note that the result holds for general TBoxes and not only terminologies. From
Lemma 63 and Theorem 61, we directly obtain the following description of primitive witnesses for query differences.
Theorem 64 (Primitive witness for ELHr -query differences). Let T1 and T2 be ELHr terminologies and  a signature. If   qDiff  (T1 , T2 ), then at least one of the following
conditions holds (for some individual names a, b):
1. ({r(a, b)}, s(a, b))  qDiff  (T1 , T2 ), for some r, s  sig();
674

fiThe Logical Difference for the Lightweight Description Logic EL

2. (A, A(b))  qDiff  (T1 , T2 ), for some concept name A  sig() and ABox A with
sig(A)  sig();
3. (A, D(b))  qDiff  (T1 , T2 ), for some singleton ABox A and C u,u -concept D such that
sig(A), sig(D)  sig().
Observe that Theorem 64 coincides with Theorem 41 with the exception that in Point 3
the concept D can now be a C u,u -concept. We can, therefore, define the following finite
representation of the -query difference. Assume T1 and T2 are given. Define the set
 qWtnR
 (T1 , T2 ) of role -query difference witnesses as the set of role -instance differR
ence witnesses; i.e., qWtnR
 (T1 , T2 ) = iWtn (T1 , T2 );
 qWtnrhs
 (T1 , T2 ) of right-hand -query difference witnesses as the set of right-hand
rhs
-instance difference witnesses; i.e., qWtnrhs
 (T1 , T2 ) = iWtn (T1 , T2 );
 qWtnlhs
 (T1 , T2 ) of left-hand -instance difference witnesses as the set of all A   such
that there exists a C u,u -concept C with ({A(a)}, C(a))  qDiff lhs
 (T1 , T2 ) and all r  
u,u
such that there exists a C -concept C such that ({r(a, b)}, C(c))  qDiff  (T1 , T2 ) for
c = a or c = b.
The set of all -query difference witnesses is defined as
rhs
lhs
qWtn (T1 , T2 ) = (qWtnR
 (T1 , T2 ), qWtn (T1 , T2 ), qWtn (T1 , T2 )).

By Theorem 64, qWtn (T1 , T2 ) = (, , ) if, and only if, qDiff  (T1 , T2 ) = . Algorithms
rhs
computing qWtnR
 (T1 , T2 ) and qWtn (T1 , T2 ) have been presented in the section on instance
difference. It thus remains to consider qWtnlhs
 (T1 , T2 ).
7.3 Tractability of qWtnlhs
 (T1 , T2 )
u,u -concepts
To prove tractability of qWtnlhs
 (T1 , T2 ) we first capture the expressive power of C
using a stronger form of simulation between interpretations. Let I1 and I2 be interpretations. A -simulation S between I1 and I2 is called a global intersection preserving
-simulation if, in addition,

 for every d  I1 there exists a d0  I2 with (d, d0 )  S;
 if (d, e)  S, d0  I1 , and R = {r   | (d, d0 )  rI1 } =
6 , then there exists e0 with
(e, e0 )  S and (d0 , e0 )  rI2 for all r  R.
We write (I1 , d) 
 (I2 , e) if there exists a global intersection preserving -simulation S
between I1 and I2 such that (d, e)  S.
Lemma 65. Let I1 and I2 be finite interpretations,  a signature, d  I1 , and e  I2 .
Then
u,u
(I1 , d) 

for all C  C
: d  C I1  e  C I2 .
 (I2 , e)
It can be checked in polynomial time whether (I1 , d) 
 (I2 , e).
675

fiKonev, Ludwig, Walther, & Wolter

The proof is a straightforward extension of the proof of Lemma 29 and the polynomialtime algorithm deciding the existence of -simulations.
We observe that Theorem 2 about the properties of the canonical model IK of a KB K
can be extended to C u,u -concepts (in the appendix, the proof is given for C u,u -concepts as
well). Namely, we have for all C u,u -concepts C0 :
 K |= C0 (a) if, and only if, aIK  C0IK .
 T |= C u D v C0 if, and only if, xC,D  C0IK .
It follows that for any concept name A  , we have
A  qWtnlhs
 (T1 , T2 )



(IK1 , a) 6
 (IK2 , a),

where Ki = (Ti , A) and A = {A(a)}, for i = 1, 2. We also have for every role name r  
that

r  qWtnlhs
 (IK1 , a) 6
 (T1 , T2 )
 (IK2 , a) or (IK1 , b) 6 (IK2 , b)
where Ki = (Ti , A) and A = {r(a, b)}, for i = 1, 2. Thus, we obtain the following tractability
result:
Theorem 66. Let T1 and T2 be ELHr -terminologies and  a signature. Then the set
qWtnlhs
 (T1 , T2 ) can be computed in polynomial time.

8. Implementation and Experiments
In this section, we describe an experimental evaluation of the theoretical work developed above. Our experiments employ the CEX2 tool.4 In CEX2, we have implemented
polynomial-time algorithms which, given acyclic ELHr -terminologies T1 and T2 and a signature  as input, compute witnesses for the concept difference cDiff  (T1 , T2 ) and the
instance difference iDiff  (T1 , T2 ).5
CEX2 is written in OCaml and the reasoner CB (Kazakov, 2009) is internally used as
classification engine. In the implementation of CEX2, we have employed the algorithms
developed in this paper. In more detail, for the instance difference case for acyclic ELHr terminologies T1 and T2 ,
 to compute iWtnR
 (T1 , T2 ), CEX2 performs a straightforward comparison of the role
inclusion chains entailed by the terminologies T1 and T2 ;
 to compute iWtnrhs
 (T1 , T2 ), CEX2 uses the NotWitness algorithm in Figure 7 and then
employs Theorem 48;
 to compute iWtnlhs
 (T1 , T2 ), CEX2 checks for the existence of a -simulation between
the canonical models (Theorem 49).
4. Available under an open-source license at http://www.csc.liv.ac.uk/~michel/software/cex2/
5. An extended version of CEX2 computing witnesses for the query difference qDiff  (T1 , T2 ) as well is
presented by (Konev, Ludwig, & Wolter, 2012). In addition, Konev et al. describe experiments comparing
query difference witnesses with concept and instance difference witnesses that are not presented in this
paper.

676

fiThe Logical Difference for the Lightweight Description Logic EL

The output for iWtnlhs
 (T1 , T2 ) is partitioned into three sets:
 the set of left-hand atomic -instance difference witnesses, iWtnlhs,A
(T1 , T2 ), which is

defined as the set of all concept names A   such that there exists an EL-concept C
such that ({A(a)}, C(a)})  iDiff  (T1 , T2 ) (equivalently A v C  cDiff  (T1 , T2 ));
 the set of left-hand domain -instance difference witnesses, iWtnlhs,dom
(T1 , T2 ), which

is defined as the set of all role names r   such that there exists an EL-concept C
with ({r(a, b)}, C(a))  iDiff  (T1 , T2 ) (equivalently, r.> v C  cDiff  (T1 , T2 )); and
 the set of left-hand range -instance difference witnesses, iWtnlhs,ran
(T1 , T2 ), which is

defined as the set of all role names r   such that there exists an EL-concept C with
({r(a, b)}, C(b))  iDiff  (T1 , T2 ) (equivalently, ran(r) v C  cDiff  (T1 , T2 )).
Obviously, it holds that:
lhs,A
iWtnlhs
(T1 , T2 )  iWtnlhs,dom
(T1 , T2 )  iWtnlhs,ran
(T1 , T2 ).
 (T1 , T2 ) = iWtn



For the concept difference case, recall that
R
cWtnR
 (T1 , T2 ) = iWtn (T1 , T2 ),

lhs
cWtnlhs
 (T1 , T2 ) = iWtn (T1 , T2 ),

and so we use the same algorithms as in the instance case. We also set
(T1 , T2 ) = iWtnlhs,X (T1 , T2 )
cWtnlhs,X

rhs
for X  {A, dom, ran}. To compute iWtnrhs
 (T1 , T2 ), CEX2 exploits that cWtn (T1 , T2 ) 
rhs
rhs
iWtn (T1 , T2 ) (Lemma 50) and first computes iWtn (T1 , T2 ) and then checks using a
straightforward variant of the NotWitness algorithm for concept differences whether A 
cWtnrhs
 (T1 , T2 ).
In the following three subsections we describe the experiments that we have conducted.
The experimental settings were as follows. All programs were run on PCs equipped with
an Intel Core 2 Duo E6400 CPU and 3 GiB of main memory. Version 2.0.1 of CEX2 was
used.

8.1 Comparing Different Versions of Snomed CT
We applied CEX2 to compare a January 2009 (SM09a) and a July 2009 (SM09b) version of Snomed CT. SM09a and SM09b contain 310013 and 307693 concept names, respectively. Both versions use the same 62 role names, and they contain role inclusions
but no domain or range restrictions are present. Consequently, one can infer from Corollary 47 that iWtn (SM09b, SM09a) = cWtn (SM09b, SM09a). In what follows we consider
cWtn (SM09b, SM09a) only.
For our experiments we used signatures ranging over so called Snomed CT subsets,
which are employed in the UK for the deployment of Snomed CT in specific areas. We compared SM09a with SM09b on 159 such signatures  by computing cWtn (SM09b, SM09a)
for each of these sets . The considered signatures always contain all of the 62 Snomed
CT role names. The comparisons which resulted in a non-empty difference are reproduced
677

fiKonev, Ludwig, Walther, & Wolter

in Table 2. In none of the cases, differences regarding role inclusions have been detected. In
Table 2, the second column gives the number of concept names in the respective subset ,
and the third and fifth column the number of concept witness differences. Observe that the
number of differences does not correlate with the size of the considered signatures , i.e.
there exist signatures that are somewhat comparable in size, but induce a greatly varying
number of difference witnesses (see e.g. the subsets Diagnosis and Manumat).
In order to determine how many difference witnesses computed by CEX2 can be obtained
from a straightforward comparison of the class hierarchies already, we have also computed
the sets
clsWtnlhs
 (SM09b, SM09a) = { A   |  B   : A v B  cDiff  (SM09b, SM09a) }
and
clsWtnrhs
 (SM09b, SM09a) = { B   |  A   : A v B  cDiff  (SM09b, SM09a) }
for each of the considered comparison signatures . The results that we have obtained are
also depicted in Table 2. One can see that often a great number of differences cannot be
detected by considering the classification difference only.
In the last three columns of Table 2, we give the CPU times required for computing all
concept witnesses:
 first, the times are given when CEX2 is directly applied to the full terminologies
SM09a and SM09b;
 second, the times are given when one first extracts -modules using the module extraction tool MEX (Konev, Lutz, Walther, & Wolter, 2008) from SM09a and, respectively,
SM09b and then applies CEX2 to the extracted -modules. Observe that a -module
extracted by MEX is -query (and, therefore, -concept and -instance) inseparable
from the whole terminology. Thus, the computed concept witnesses are the same.
 finally, the times are given if, in addition to computing concept witnesses from the full
terminologies SM09a and SM09b, CEX2 also computes examples of concept inclusions
in the logical difference that explain the witnesses. We discuss this feature of CEX2
below.
One can observe that extracting MEX modules leads to a significant improvement of the
performance of CEX2. Of course, if the signature is very large (e.g., for Diagnosis and
Finding), the resulting modules are almost as large as Snomed CT itself and the effect
is less significant. Secondly, one can observe that the additional computation of example concept inclusions in the logical difference roughly doubles the times needed for the
comparison.
Finally, to evaluate the practical feasibility of using the ABox approach to compute
the sets iWtnrhs
 (SM09b, SM09a), we have implemented the computation of ABoxes AT ,
together with an ABox reasoning algorithm for checking the second condition of Lemma 45.
We have then tested our implementation on the subsets  of Snomed CT used for evaluating the performance of CEX2. To limit the size of the ABoxes AT , and to speed up
computations, we first computed modules using MEX. The results that we obtained are
678

fiThe Logical Difference for the Lightweight Description Logic EL

shown in Table 3. The size of the -modules computed by MEX, i.e. T1 of SM09b and T2
of SM09a, is shown in columns two and three, respectively. As expected from the definition of AT , , one can observe that the number of concept and role membership assertions
present in the ABoxes AT2 , can grow very large, even for modules and signatures with only
a few thousand concept names.
For 8 of the 41 considered subsets our implementation ran out of available physical
memory (indicated by a time value -) when all possible concept membership consequences
of the ABox were to be computed. Overall, we observed the longest execution time of
over 5 hours for the set Specmatyp. In conclusion, one can see that a straightforward
implementation of the ABox approach is practically useful only for terminologies and
signatures of a few thousand concept names.
8.2 Comparing Different Versions of the NCI Thesaurus
We have also used the CEX2 tool to compare distinct versions of the NCI Thesaurus. Most
distributed releases of the NCI Thesaurus contain language constructs which are not part of
ELHr (such as disjunction and value restriction). To obtain ELHr -terminologies, we have
removed all inclusions that contain a non-ELHr constructor from the original terminologies.
Typically, this affected 5%-8% of the inclusions present in each of the distributed NCI
versions. Most of the ELHr -versions generated in this way contain role inclusions as well
as domain and range restrictions.
Similarly to the work of Goncalves et al. (2011), we have compared 71 consecutive
ELHr -versions of the NCI Thesaurus ranging between the versions 03.10J and 10.02d, with
the exception of 05.03F and 05.04d, which could not be parsed correctly. Version 10.03h
and some later versions of the NCI Thesaurus are not acyclic, and hence, they could not
be handled by the CEX2 tool.
For any two consecutive versions NCIn and NCIn+1 within the considered range, we
computed the sets cWtn (NCIn+1 , NCIn ) and iWtn (NCIn+1 , NCIn ) on signatures  =
sig(NCIn )  sig(NCIn+1 ). An overview of the set sizes for cWtnrhs
 (NCIn+1 , NCIn ) and
lhs,A
cWtn (NCIn+1 , NCIn ) that we obtained can be found in Figure 8. The comparisons are
sorted chronologically along the x-axis according to the release dates of the NCI ontology
versions, whereas the corresponding number of left-hand atomic difference witnesses or
right-hand difference witnesses can be found on the y-axis. One can see the number of righthand difference witnesses remained fairly low throughout the different versions. However,
occasional spikes occurred in the number of left-hand atomic difference witnesses with a
maximum value of 33487 for comparing the versions 05.01d and 05.03d. Moreover, in none
of the comparisons except for those shown in Figure 9 left-hand role domain or left-hand role
range difference witnesses were identified. Overall, no witnesses regarding role inclusions
were detected and we found that for every two considered consecutive versions NCIn and
NCIn+1 on  = sig(NCIn )  sig(NCIn+1 ),
cWtn (NCIn+1 , NCIn ) = iWtn (NCIn+1 , NCIn ).
A running time of 140 seconds and 228 MiB of memory were required on average for
computing witnesses and example inclusions for iDiff  (NCIn+1 , NCIn ). Computing witnesses and example inclusions for cDiff  (NCIn+1 , NCIn ) on average took 157 seconds and
used 228 MiB of memory.
679

fiKonev, Ludwig, Walther, & Wolter

Subset Name 
Admin
Adminproc
Cdacarest
Crcareneur
Crcareresp
Devicetyp
Diagimg
Diagnosis
Drgadrcon
Endosfind
Endosproc
Epcream.6a
Epenema.7a
Epenema.7b
Epeye.4
Epiuds16
Famhist
Finding
Foodadrcon
Ffoodaller
Invest
Labinvest
Labinvmeth
Labisolate
Labmorph
Labspec
Labtopog
Lifestyle
Manumat
Nofoodall
Nonhuman
Pbcl
Pbhllng
Pf
Provadv
Sf
Socpercir
Specmatyp
Treatment
Vmp
Vtm

|  NC |
7684
3198
355
1640
1082
6539
4162
75879
8009
178
73
403
25
6
223
1
416
168383
2378
468
14839
3904
3794
16313
4854
1221
27277
13090
90503
686
1839
5866
1113
79
1052
613
6786
8830
43660
13667
2117

|cWtnrhs
 |
7
0
1
28
72
26
27
7410
131
0
1
0
0
0
0
0
8
11824
11
1
1396
61
103
150
32
3
866
77
2
1
24
633
1
0
2
0
8
10
2419
2
0

|clsWtnrhs
 |
5
0
1
8
18
26
13
881
131
0
1
0
0
0
0
0
5
2497
11
1
534
45
81
150
32
3
220
41
0
1
11
116
0
0
1
0
8
8
1255
0
0

|cWtnlhs,A
|

29
6
1
197
262
22
13
12409
47
13
5
3
3
2
6
1
31
31228
15
9
5549
2520
3380
661
45
18
169
826
22
13
469
1342
27
4
158
3
2
46
9251
22
13

|clsWtnlhs
 |
7
0
1
13
64
22
8
5406
47
0
3
0
0
0
0
0
4
20063
14
9
5441
133
3374
661
45
3
169
148
0
13
131
402
0
0
108
0
2
10
8740
0
0

Time (s)
cWtn - from
full ontologies
358.51
344.60
337.91
399.57
377.36
369.20
444.66
844.26
1419.52
363.23
352.84
337.41
337.42
337.50
337.53
337.26
339.36
1559.23
481.20
379.42
511.12
382.32
367.20
671.36
858.11
360.80
1947.19
445.75
349.73
421.23
678.53
395.27
454.39
337.68
343.78
338.13
366.14
380.19
793.12
342.70
339.14

Time (s)
cWtn - with
module extraction
9.89
8.24
6.76
15.58
12.24
8.01
38.56
486.53
10.17
7.86
7.30
7.39
6.86
6.76
7.20
6.69
8.84
1366.08
7.74
7.03
76.90
12.47
10.70
14.14
8.28
13.38
38.05
32.49
15.36
7.11
12.50
12.18
7.99
7.12
8.19
7.44
8.99
16.10
330.45
12.95
9.45

Time (s)
cWtn
with examples
654.12
642.23
556.41
704.21
680.51
589.81
775.37
2699.89
1708.49
662.67
573.66
631.51
556.31
629.57
1236.84
1233.89
633.94
5017.02
1516.47
677.97
769.93
680.94
1290.83
1005.95
1113.70
1272.51
4463.05
765.10
1224.92
721.74
1907.70
1358.88
761.00
634.26
569.56
629.50
1300.47
685.35
1315.23
1247.18
633.50

Table 2: Subset Comparisons for T1 = SM09b and T2 = SM09a Resulting in a Non-Empty
Difference

680

fiThe Logical Difference for the Lightweight Description Logic EL

Subset Name 
Admin
Adminproc
Cdacarest
Crcareneur
Crcareresp
Devicetyp
Diagimg
Diagnosis
Drgadrcon
Endosfind
Endosproc
Epcream.6a
Epenema.7a
Epenema.7b
Epeye.4
Epiuds16
Famhist
Finding
Foodadrcon
Foodaller
Invest
Labinvest
Labinvmeth
Labisolate
Labmorph
Labspec
Labtopog
Lifestyle
Manumat
Nofoodall
Nonhuman
Pbcl
Pbhllng
Pf
Provadv
Sf
Socpercir
Specmatyp
Treatment
Vmp
Vtm

|  NC |

|sig(T1 )  NC |

|sig(T2 )  NC |

|{ A(a) | A(a)  AT2 , }|
(in thousands)

|{ r(a, b) | r(a, b)  AT2 , }|
(in thousands)

Time (s)

7684
3198
355
1640
1082
6539
4162
75879
8009
178
73
403
25
6
223
1
416
168383
2378
468
14839
3904
3794
16313
4854
1221
27277
13090
90503
686
1839
5866
1113
79
1052
613
6786
8830
43660
13667
2117

6746
3071
322
6484
5273
3617
11007
156588
8323
1487
809
1425
85
13
851
5
3126
323809
2716
636
42071
9308
10132
16281
4575
7106
27118
26233
11605
990
8728
8497
2488
386
3104
1856
6757
12928
111178
11972
7655

6750
3120
323
6375
5206
3619
11074
156441
8361
1534
826
1446
86
15
859
7
3136
324400
2723
644
42559
9302
10147
16313
4558
7064
27142
26473
11649
991
8848
8793
2487
389
3014
1860
6754
12871
111612
12018
7711

66942
12352
148
8568
4361
43743
40817
8636801
70643
210
48
641
4
0
214
0
1003
41381927
6745
326
504618
36048
36738
267268
24538
5566
723594
250140
8851332
727
13698
64174
3083
37
3202
1332
48627
112252
3716810
289683
16540

1081
480
52
651
503
830
1220
14134
1095
148
82
198
19
10
120
8
301
30521
353
87
4224
1147
1203
2033
628
570
3294
2374
12127
132
926
1357
344
59
378
270
889
1580
10578
2629
970

9291.75
1642.41
3.86
3110.07
3689.22
2381.00
12503.63
2097.23
143.87
17.88
315.58
0.32
0.06
60.80
0.05
137.34
277.80
11.57
8632.09
4131.02
7785.59
1275.48
646.59
26.99
10110.25
16410.12
933.00
3.86
518.47
249.26
5819.23
18306.56
2861.37

Table 3: Performance of the ABox Approach for Computing iWtnrhs
 (SM09b, SM09a)

681

fiKonev, Ludwig, Walther, & Wolter

35000
Nr of Right-Hand Witnesses
Nr of Left-Hand Atomic Witnesses
30000

25000

20000

15000

10000

5000

0

lhs,A
Figure 8: Sizes of cWtnrhs
(NCIn+1 , NCIn ) between Consec (NCIn+1 , NCIn ) and cWtn
utive ELHr -versions NCIn and NCIn+1 of the NCI Thesaurus

T1
04.04j
04.11a
05.03d
06.02d
08.10e
08.12d
09.06e

T2
04.03n
04.09a
05.01d
06.01c
08.09d
08.11d
09.05d

|  NC |
34245
35976
38020
45582
66052
68229
70493

|  NR |
76
91
92
113
123
123
123

|cWtnrhs
 |
252
106
138
419
1774
968
1305

|cWtnlhs,A
|

4926
4023
33487
1438
19055
4726
575

|cWtnlhs,dom
|

1
2
92
1
113
114
1

|cWtnlhs,ran
|

1
2
92
1
113
113
1

lhs
Figure 9: Detailed Results for cWtnrhs
 (T1 , T2 ) and cWtn (T1 , T2 ) on Selected Versions of
the NCI Thesaurus using Shared Signatures  = sig(T1 )  sig(T2 )

682

fiThe Logical Difference for the Lightweight Description Logic EL

The peaks in atomic left-hand difference witnesses mostly resulted from changes to a few
very general concepts. As mentioned above already, Goncalves et al. (2011) provide an indepth analysis of NCI versions. A systematic comparison of the methods used by Goncalves
et al. with the logical diff introduced in this paper would be very interesting, but is beyond
the scope of this paper. One interesting observation that can be made is, however, that the
peak of atomic left-hand witnesses that we observed between the versions 05.01d and 05.03d
correlates with the fact that according to Goncalves et al. a large number of non-redundant
axioms were added to version 05.03d. However, a comparable number of non-redundant
axioms were also added to version 04.12g, but no peak in atomic left-hand or right-hand
witnesses was observed in our analysis.
8.3 Scalability Analysis
We demonstrated in the previous sections that CEX2 is capable of finding the logical difference between two unmodified versions of Snomed CT and between distinct versions of the
NCI thesaurus restricted to ELHr . In order to see how CEX2s performance scales, we have
also tested it on randomly generated acyclic terminologies of various sizes. Each randomly
generated terminology contains a certain number of defined- and primitive concept names
and role names. The ratio between concept equations and concept inclusions is fixed, as is
the ratio between existential restrictions and conjunctions. The random terminologies were
generated for a varying number of defined concept names using the parameters of SM09a:
62 role names; the equality-inclusion ratio is 0.525; and the exists-conjunction ratio is 0.304.
For every chosen size, we generated 10 samples consisting of two random terminologies as
described above. We then applied CEX2 to find the logical difference of the two terminologies over their joint signature. Figure 10 shows the average memory consumption of CEX2
over 10 randomly generated terminologies of various sizes. In 10(a) the maximum length
of conjunctions was fixed as two (M=2), and in 10(b) the number of conjuncts in each conjunction is randomly selected between two and M. It can be seen that the performance of
CEX2 crucially depends on the length of conjunctions. In 10(b), the curves break off at the
point where CEX2 runs out of physical memory6 . For instance, in the case of M=22, this
happens for terminologies with more than 7 500 defined concept names. Finally, we note
that the time required by CEX2 to compare two such random terminologies highly varied
across the different samples. The maximum time required by CEX2 was 11 333 seconds.
8.4 Additional User Support for Analysing Differences
So far we have discussed experiments with CEX2 in which one computes the set of concept
and instance difference witnesses between two terminologies. Clearly, such witnesses do not
provide sufficient information for a detailed analysis of the logical difference between two
terminologies. For a more thorough analysis, it is required to consider examples  from
cDiff  (T1 , T2 ) and iDiff  (T1 , T2 ) that show why certain concept names are concept/instance
difference witnesses. Thus, whenever it searches for concept names A such that there
exists a C with C v A  cDiff  (T1 , T2 ), CEX2 can output example concept inclusions
C v A  cDiff  (T1 , T2 ). Similarly, if requested, CEX2 can also compute example inclusions
6. In some cases the classification of the terminologies through CB already requires more than 3 GiB of
memory.

683

fiKonev, Ludwig, Walther, & Wolter

1200

3500

3000

Memory Consumption in MiB

Memory Consumption in MiB

1000

800

600

400

2500

2000

1500

1000

200
500

M=10

M=2

M=22

0

Number of Concept Names

95
00

85
00

75
00

65
00

55
00

45
00

35
00

25
00

15
00

50
0

10
00
0
30
00
0
50
00
0
70
00
0
90
00
0
11
00
00
13
00
00
15
00
00
17
00
0
19 0
00
00
21
00
00
23
00
00
25
00
00
27
00
00
29
00
0
31 0
00
00
33
00
00
35
00
00

0

Number of Concept Names

(a) Short Conjunctions

(b) Long Conjunctions

Figure 10: Memory Consumption of CEX2 on Randomly Generated Terminologies
illustrating left-hand concept differences A v C, r.> v C, or ran(r) v C, and examples for
the instance difference case. We know from Example 12 that even minimal such examples
can be of exponential size in the input terminologies. In practice, however, for Snomed CT
and NCI the additional computation of an example inclusion for every concept/instance
difference witness only doubles the times required for the computation. As described
above already, this can be observed in Table 2, where the computation times with examples
are shown in the last column and the computation times without examples are shown in the
7th column. The examples computed by CEX2 are often of reasonable size. For instance, if
we consider the subset Specimen Material Type (Specmatyp) from Table 2, it holds that
(i) there exist 10 right-hand -concept witnesses, i.e. |cWtnrhs
 (SM09b, SM09a)| = 10;
(SM09b, SM09a),
(ii) the set of left-hand atomic -concept difference witnesses, cWtnlhs,A

contains 46 concept names.
In Point (i) and (ii), the longest concepts C, D for C v A  cDiff  (SM09b, SM09a) and
A v D  cDiff  (SM09b, SM09a) that were computed by CEX2 had twelve concept and role
name occurrences (thus were far smaller than the exponential worst case suggests).
Having computed not only difference witnesses but also example concept inclusions for
witnesses, it is of interest to explain why an example concept inclusion is entailed by one
terminology but not the other. Computing minimal subsets of a terminology that entail an
example concept inclusion is a promising approach to explaining logical differences that is
also known as axiom pinpointing or justification. It is not supported by CEX2, but has been
investigated extensively for various description logics including EL (Schlobach & Cornet,
2003; Baader, Penaloza, & Suntisrivaraporn, 2007; Kalyanpur, Parsia, Horridge, & Sirin,
2007; Horridge, Parsia, & Sattler, 2010; Penaloza & Sertkaya, 2010). To illustrate this
approach, consider again the subset Specimen Material Type (Specmatyp) from Table 2.
CEX2 outputs
VenipunctureForBloodTest  cWtnlhs,A
(SM09b, SM09a).

684

fiThe Logical Difference for the Lightweight Description Logic EL

(1)

LaboratoryTest v LaboratoryProcedure u EvaluationProcedure
BloodTest  LaboratoryTest u  roleGroup. hasSpecimen. BloodSpecimen

(2)

(3) VenipunctureForBloodTest  (roleGroup.hasFocus .BloodTest)
u Venipuncture
u (roleGroup.((procedureSiteDirect.VenousStructure)
u (method.PunctureAction)))

Figure 11: Minimal Axiom Set
It also computes the following concept inclusion (slightly simplified by hand) as a member of cDiff  (SM09b, SM09a):
()

VenipunctureForBloodTest
v roleGroup.hasFocus.EvaluationProcedure

Using axiom pinpointing one can then compute a minimal set of inclusions from SM09b
which entails the concept inclusion above; such a set is shown in Figure 11. Axioms 2 and 3
are in both terminologies, but SM09a contains
LaboratoryTest v LaboratoryProcedure
instead of Axiom 1, which explains this difference between the two terminologies. Note
that concept and role names from  are shaded in grey. It can be seen that the interaction
between -concepts heavily depends on inclusions that are built up mainly from non-concepts; actually none of inclusions required to derive () is a -inclusion.
We finally note that CEX2 is a text-based tool. In order to make it more accessible to
ontology users, a Protege plugin, LogDiffViz7 , was created, which calls CEX2 and visualises
both ontology versions and the differences as a hierarchical structure. LogDiffViz also
provides basic axiom pinpointing. The plugin is distributed as a self-contained Java archive
file (JAR) in which CEX2 is bundled.

9. Related Work
We describe the relationship between the work presented in this paper and existing work on
logical difference and inseparability of ontologies. Related work on versioning and the distinction between syntactical, structural, and logic-based approaches to versioning have been
discussed in the introduction already and will not be presented again here. The problem
of deciding whether two ontologies are -inseparable for some signature  has been investigated for many ontology languages and different notions of inseparability such as concept
inseparability, instance inseparability, conjunctive query inseparability, and model-theoretic
inseparability (i.e., the -reducts of models of the first ontology coincide with the -reducts
of models of the second ontology). Inseparability is also closely related to the notion of conservative extensions since one ontology is a conservative extension of another ontology if
it contains the other ontology as a subset and both are inseparable w.r.t. the signature of
7. Available at http://protegewiki.stanford.edu/wiki/Logical_Difference_Vizualiser_(LogDiffViz)

685

fiKonev, Ludwig, Walther, & Wolter

the smaller ontology. Thus, algorithmic results on deciding conservativity are directly relevant for inseparability as well. The tractability results presented in this paper are in sharp
contrast to most other known results. We start with general EL-TBoxes: for general ELTBoxes deciding inseparability and conservative extensions are ExpTime complete problems
for concept, instance and conjunctive queries. Both problems are undecidable for modeltheoretic inseparability and model-theoretic conservative extensions (Lutz & Wolter, 2010).
(We note, however, that in the model-theoretic case unexpected positive algorithmic results
have been obtained in Konev, Lutz, et al., 2008, for acyclic EL and ALC and their extensions
with inverse roles.) For ALC and its standard extensions without nominals deciding concept
inseparability and conservative extensions is 2ExpTime-complete (Ghilardi, Lutz, & Wolter,
2006; Lutz et al., 2007; Lutz & Wolter, 2011) and for ALCQIO deciding concept inseparability and conservative extensions becomes undecidable (Lutz et al., 2007; Cuenca Grau
et al., 2008). Nothing is known for ALC about the complexity of inseparability for instance
and conjunctive queries. For DL-Lite dialects (Calvanese, Giacomo, Lembo, Lenzerini, &
Rosati, 2006), the complexity of concept, instance, and query inseparability ranges from
PSpace-hard (and in ExpTime) for the description logic underlying the OWL 2 QL standard, NP-complete for DL-Litehorn , and p2 -complete for DL-Litebool (Konev, Kontchakov,
Ludwig, Schneider, Wolter, & Zakharyaschev, 2011; Kontchakov et al., 2010). For DLLitebool model-theoretic inseparability is decidable (Kontchakov et al., 2010) and for DLLitecore concept, instance, and query inseparability are in PTime (Konev et al., 2011). In
contrast to the work presented in this paper, however, no attempt is made to present the
logical difference to the user if two ontology are not inseparable. As mentioned above, in
the work of Konev et al. (2012), CEX2 is extended to the conjunctive query difference case
between acyclic ELHr -terminologies and various experiments based on the NCI thesaurus
are discussed.
The work discussed so far is concerned with the logical difference and inseparability between description logic TBoxes. The difference between description logic concepts has been
investigated, for example, in the work of Teege (1994), and of Brandt, Kusters, and Turhan
(2002) but besides of the interest in some kind of difference the problems considered as well
as the techniques employed are rather different. Inseparability and conservativity between
ontologies given in ontology languages that are more expressive than description logics (including first-order logic) have been considered in the work of Kutz and Mossakowski (2008,
2011). Similar relationships between theories have also been investigated in answer set
programming (Pearce & Valverde, 2004; Eiter, Fink, & Woltran, 2007; Pearce & Valverde,
2012).
Finally, we note that Lemma 15 and the ABox constructed in Figure 3 appear to capture and describe fundamental properties of EL and ELHr -terminologies. Both have been
applied to investigate seemingly unrelated problems such as query containment for ontology
based data access using EL-terminologies (Bienvenu, Lutz, & Wolter, 2012b) and first-order
rewritability of instance queries (Bienvenu, Lutz, & Wolter, 2012a).

10. Conclusion
In this paper, we have presented polytime algorithms that decide concept, instance, and
query-inseparability w.r.t. a signature  for ELHr -terminologies and compute a represen686

fiThe Logical Difference for the Lightweight Description Logic EL

tation of the difference if it is non-empty. Experiments using CEX2 based on SNOMED
CT and NCI show that the outputs given by our algorithm are mostly of reasonable size
and can be analysed by users. Many extensions, applications, and open problems remain
to be explored. Here we mention some of them:
(1) We have motivated the study of -inseparability between terminologies by the problem of comparing different versions of a terminology regarding what they say about a
certain signature. Other potential and promising applications can be found in the area
of decomposing and composing ontologies. For example, when importing an ontology T
into an ontology T 0 (i.e., forming T  T 0 ) it is often important to ensure that T 0 does not
interfere with the signature of T . In other words, T  T 0 should be a conservative extension
of T in the sense that the consequences of T  T 0 in the signature of T should coincide
with the consequences of T itself (Cuenca Grau et al., 2008; Ghilardi et al., 2006; Vescovo,
Parsia, Sattler, & Schneider, 2011). As observed above already, -inseparability generalises conservative extensions and, therefore, our algorithms can be used to check whether
one terminology is a conservative extension of another terminology. Algorithms checking
conservative extensions can also be used to extract modules from ontologies (Cuenca Grau
et al., 2008; Kontchakov, Pulina, Sattler, Schneider, Selmer, Wolter, & Zakharyaschev, 2009;
Konev et al., 2011). It would be of interest to explore applications of our inseparability
testing algorithms to extract modules of terminologies and check conservativity.
(2) Inseparability as defined in this paper does not mean that one terminology can be
replaced by another terminology in every context. In various applications of inseparability
for modularity it is important to ensure that if T1 and T2 are -inseparable, then T1  T
and T2  T are -inseparable as well, for any ontology T . This is called the replacement
property by Konev, Lutz, Walther, and Wolter (2009) and has been exploited and discussed,
for example, in the work of Cuenca Grau et al. (2008) and of Kontchakov et al. (2010). The
notions of inseparability introduced in this paper do not have the replacement property. To
see this, let  = {A, A0 , B, B 0 } and

T1 =

A v r.B
A0  r.B 0




and T2 =

A v r.B
A0 v r.B 0


.

T1 and T2 are -query inseparable (and, therefore, -concept and -instance inseparable),
but T1  T is not even -concept inseparable from T2  T , for T = {B v B 0 }. Indeed,
observe that (T1  T ) |= A v A0 , but (T2  T ) 6|= A v A0 .
It is an important open research problem to determine the complexity of, and to develop
algorithms for strong versions of inseparability with the replacement property for EL and
ELHr -terminologies.
(3) ELHr is a rather weak description logic. It would be of great interest to explore in
how far techniques developed for ELHr can be applied to ontologies which contain additional constructors, but still consist mainly of ELHr -inclusions. It is unlikely that tractable
sound and complete algorithms for interesting extensions exist, but it seems worth exploring algorithms that are sound and incomplete extensions of the algorithms presented in this
paper. Some results in that direction have been presented by Goncalves, Parsia, and Sattler
(2012).
687

fiKonev, Ludwig, Walther, & Wolter

Acknowledgments
This research was supported by EPSRC grant EP/H043594/1. We would like to thank
William Gatens for the development of the LogDiffViz Protege plugin and three anonymous
reviewers for their helpful comments.

Appendix A. Proofs for Section 2
Lemma 1 For every terminology T , one can construct in polynomial time a normalised
terminology T 0 of polynomial size in |T | such that sig(T )  sig(T 0 ), T 0 |= T , and for every
model I of T there exists a model J of T 0 such that I = J and X I = X J for every
X  sig(T ). Moreover, T 0 is acyclic if T is acyclic.
Proof. Given a terminology T , construct a normalised terminology T 0 in five steps as follows:
First, remove all occurrences of > in conjunctions, and replace C in each occurrence of r.C,
where C is not a concept name or >, with a fresh concept name A and add the concept
definition A  C to the terminology. Repeat the last step exhaustively.
Second, replace every ri .Bi in each inclusion with a right-hand side of the form F u
r1 .B1 u    u rm .Bm (m  1), where each Bi is either a concept name or Bi = >, and F
is a conjunction of concept names such that F 6= > or m  2, with a fresh concept name
Bi0 and add the concept definition Bi0  ri .Bi to the terminology.
Third, replace every inclusion of the form A  r.> with two inclusions A v r.> and
r.> v A in the terminology.
Fourth, consider any concept name A such that there are sequences B0 , . . . , Bn1 and
F0 , . . . , Fn , where the Fi are conjunctions of concept names, such that the terminology
contains the concept definitions A  F0 and Bi  Fi+1 , for i < n, where Bi is a conjunct of
Fi and A a conjunct of Fn . Let Fn0 be the conjunction of concept names in Fn except A. Let,
0
recursively, Fi1
be the result of replacing the conjunct Bi1 in Fi1 with the conjunction
0
Fi , for 1  i  n. Replace the concept definition A  F0 in the terminology with the
primitive concept definition A v F00 .
Fifth, for each inclusion A  F , A v F , r.> v F , or ran(r) v F , where F is a
conjunction of concept names, replace every conjunct B in F for which there is a B  F 0
in the terminology, where F 0 is a conjunction of non-conjunctive concept names, with F 0 .
To see that the construction indeed yields a normalised terminology T 0 , observe that
the steps 1, 2, and 3 ensure that each inclusion has one of the following forms: A  r.B,
A  F , E v r.B, E v r.>, or E v F , where B is a concept name, E is either a concept
name, or is of the form s.>, or ran(s), and F is a conjunction of (possibly conjunctive)
concept names. Step 4 breaks cycles in concept definitions and Step 5 takes care that all
conjuncts of the conjunction of concept names F in the right-hand side of each inclusion of
the form A  F , A v F , r.> v F , or ran(r) v F are non-conjunctive concept names. It is
readily verified that T 0 is acyclic if T is acyclic as none of the above steps introduces cycles
in concept definitions.
We now show that T 0 can be obtained in polynomial time and that T 0 is of polynomial
size in |T |. Let n be the number of inclusions in T and c the maximal length of an inclusions
right-hand side in T . Clearly, the steps 1, 2 and 3 each do not increase the number of
inclusions by more than c  n, raising the total number of inclusions to at most 4nc. Steps 4
688

fiThe Logical Difference for the Lightweight Description Logic EL

and 5 do not increase the number of inclusions, but the length of their right-hand sides. The
length of the right-hand side of an inclusion can increase to at most the sum of the lengths
of the right-hand sides of all inclusions, i.e., 4nc2 is an upper bound for each right-hand
side. The upper bound of the running time for each of the steps in the construction is
therefore 16n2 c3 . Hence, the size of T 0 and the running time of the construction are both
in O(n2  c3 ).
Notice that every new concept name occurs on the left-hand side of a unique concept
definition A  C in T 0 . Thus, every model I of T can be expanded to a model J of T 0 by
interpreting the fresh concept names in sig(T 0 ) \ sig(T ) by setting AJ = C I .
Moreover, it is readily checked that T 0 |= T .
We prove an extended version of Theorem 2 according to which not only EL-concepts
and concepts of the form ran(r) are evaluated correctly in the canonical model IK , but
also C u,u -concepts (which are introduced in Definition 57).
Theorem 2[Extended Version] Let K = (T , A) be an ELHr -KB. Then
1. IK is a model of K;
2. IK can be computed in polynomial time in the size of K;
3. for all xC,D  IK and all a  obj(A), if C0 is a C u,u -concept or of the form ran(r),
then
 K |= C0 (a) if, and only if, aIK  C0IK .
 T |= C u D v C0 if, and only if, xC,D  C0IK .
Proof. Point 2 follows from the fact that instance checking in ELHr can be done in polynomial time.
We first prove Point 3 for EL-concepts C0  sub(T ). The proof is by simultaneous
induction on the construction of C0 . The interesting step is for C0 = r.D0 .
We start with the proof of the direction from left to right. Assume first that K |= C0 (a).
Then (a, xran(r),D0 )  rIK . We have T |= (ran(r) u D0 ) v D0 . Thus, by the induction
hypothesis, xran(r),D0  D0IK . But then a  C0IK , as required. Now assume T |= C uD v C0 .
Then (xC,D , xran(r),D0 )  rIK . We have T |= (ran(r) u D0 ) v D0 . By the induction
hypothesis, xran(r),D0  D0IK . But then xC,D  C0IK , as required.
Conversely, assume that aIK  C0IK . There exists d  IK such that (aIK , d)  rIK
and d  D0IK . Assume first that d = b  obj(A). By the induction hypothesis, K |= D0 (b).
There exists s such that s(a, b)  A and s vT r. Thus, K |= C0 (a), as required. Assume
now that d = xran(s),F . Then K |= s.F (a), s vT r and xran(s),F  D0IK . By the induction
hypothesis, T |= ran(s) u F v D0 . Thus, K |= C0 (a), as required.
Now assume xC,D  C0IK . There exists xran(s),F with T |= C u D v s.F , s vT r and
xran(s),F  D0IK . By the induction hypothesis, T |= ran(s) u F v D0 . Thus T |= C u D v
r.D0 , as required.
We now prove Point 3 for concepts of the form C0 = ran(r). Assume K |= (ran(r))(a).
Then there exist b and s with s(b, a)  A and s vT r. But then a  ran(r)IK . Conversely,
689

fiKonev, Ludwig, Walther, & Wolter

assume that a  ran(r)IK . Then, by definition of IK , there exist b and s with s(b, a)  A
and s vT r. Hence K |= (ran(r))(a), as required.
Assume T |= C u D v ran(r). Then we have, for C = ran(s), s vT r. Then xC,D 
ran(r)IK since there is a path in WK with tail xC,D . The converse direction is similar.
It follows from what has been proved so far that IK is a model of (T , A). Thus we have
proved Point 1, and it remains to prove Point 3.
We prove Point 3 for arbitrary C u,u -concepts C0 . The interesting step is for C0 = S.D0 ,
where S = r1 u    u rn .
Assume first that K |= C0 (a). Then a  C0IK since IK is a model of K. Similarly, if
T |= C u D v C0 , then xC,D  C0IK since xC,D  (C u D)IK and IK is a model of T .
Conversely, assume that a  C0IK . There exists d  IK such that (aIK , d)  S IK and
d  D0IK . Assume first that d = b  obj(A). By the induction hypothesis, K |= D0 (b). For
every ri , 1  i  n, there exists si with si (a, b)  A and si vT ri . Thus, K |= C0 (a), as
required.
Assume now that d = xran(s),F . Then K |= s.F (a), s vT ri for 1  i  n and
xran(s),F  D0IK . By the induction hypothesis, T |= ran(s) u F v D0 . Thus, K |= C0 (a), as
required.
Now assume xC,D  C0IK . There exists xran(s),F with T |= C u D v s.F , s vT ri ,
1  i  n, and xran(s),F  D0IK . By the induction hypothesis, T |= ran(s) u F v D0 . Thus
T |= C u D v S.D0 , as required.

Appendix B. Proofs for Section 5
In some proofs, we require models for infinite sets of concepts. We introduce some notation
and a well known result about the existence of minimal models. Let  be a (possibly
infinite) set of C ran -concepts (which are introduced in Definition 32), T an ELHr -TBox, and
D either a C u,u -concept (which are introduced in Definition 57) or a C ran -concept. We write
T   |= D and say that  is included in D w.r.t. T if, for every model I of T and d  I ,
d  DI follows from d  C I for all C  . The following observation follows from the fact
that all C u,u and C ran -concepts are equivalent to Horn formulas (in the sense of Chang and
Keisler, 1990):
Lemma 67. For all ELHr -TBoxes T and sets  of C ran -concepts there exists a model I of
T and d  I such that the following are equivalent, for all C u,u  C ran -concepts D:
 T   |= D;
 d  DI .
We now come to the proof of Lemma 36. For the convenience of the reader we formulate
the result again.
Lemma 36. For every ELHr -TBox T , ABox A, and all C ran -concepts C0 and D0 , and
a0  obj(A):
n,ran
 (T , A) |= D0 (a0 ) if, and only if, there exists n  0 such that T |= CA,a
v D0 ;
0

690

fiThe Logical Difference for the Lightweight Description Logic EL

 T |= C0 v D0 if, and only if, (T , AC0 ) |= D0 (aC0 ).
n,ran
(a0 )
Proof. We prove Point 1. For the direction from right to left observe that A |= CA,a
0
n,ran
for all n  0. Thus, T |= CA,a0 v D0 implies (T , A) |= D0 (a0 ).
ran |= D . Then, using compactness,
Now assume (T , A) |= D0 (a0 ). We show that T CA,a
0
0
n,ran
we find an n  0 such that T |= CA,a0 v D0 , as required.
ran 6|= D . Take, for every a  obj(A), a model I of T with a point
Assume T  CA,a
0
a
0
I
ran |= C. Such
da   a such that for all C ran -concepts C: da  C Ia if, and only if, T  CA,a
models exist by Lemma 67. We may assume that they are mutually disjoint. Take the
following union I of the models Ia :
S
 I = aobj(A) Ia ;
S
 AI = aobj(A) AIa , for A  NC ;
S
 rI = aobj(A) rIa  {(da , db ) | r0 (a, b)  A, r0 vT r}, for r  NR ;

 aI = da , for a  obj(A).
Claim 1. For all C ran -concepts C and all a  obj(A) the following holds for all d  Ia :
d  C Ia iff d  C I .
The proof is by induction on the construction of C. The interesting cases are C = ran(r)
and C = r.D and the direction from right to left.
Let d S
 C I and assume first that C = ran(r). Let d  C I  Ia and (d0 , d)  rI . For
(d0 , d)  aobj(A) rIa , the claim follows from the definition. Otherwise, d = da , d0 = db
n,ran
for every n  0. Hence,
for some b with r0 (b, a)  A and r0 vT r. Thus, ran(r0 )  CA,a
ran
I
a
T  CA,a |= ran(r) and we obtain d  C .
Assume now
r.D and d  C I  Ia . Take d0 with (d, d0 )  rI and d0  DI .
S that C =
0
I
0
For (d, d )  a0 obj(A) r a , d  C Ia follows immediately from the induction hypothesis.
Otherwise, d = da and d0 = db for some b with r0 (a, b)  A and r0 vT r. By the induction
ran |= D. By compactness, there exists a concept E  C ran
hypothesis, d0  DIb . Hence, T CA,b
A,b
n,ran
for every n > 0. But
such that T |= E v D. From r0 (a, b)  A, we obtain r0 .E  CA,a
ran |= r 0 .D and we obtain d  C Ia using r 0 v r. This finishes the proof of
then, T  CA,a
a
T
the claim.
Now, for C v D  T , let d  I with d  C I , i.e. d  Ia for some a  obj(A). By
Claim 1 we have d  C Ia , which implies that d  DIa as C Ia  DIa . We can conclude
that d  DI by applying Claim 1 again. Similarly, one can show that C I = DI for every
C  D  T and rI  sI for every r v s  T . It follows that I is a model of T . By
construction of I, we have (aI , bI )  rI for every r(a, b)  A. Moreover, for A(a)  A with
ran |= A, which implies that d  AIa and aI  AI by our
a  obj(A), it holds that T  CA,a
a
ran 6|= D ,
claim. We can thus infer that I is a model of (T , A) and I 6|= D0 (a0 ) as T  CA,a
0
0
Ia

which implies that da0 6 D0 0 and aI0 6 D0I , by Claim 1. Hence, (T , A) 6|= D0 (a0 ) and we
have derived a contradiction.
The proof of Point 2 is a simple application of the definition.
691

fiKonev, Ludwig, Walther, & Wolter

Now we prove cut elimination, correctness, and completeness of the calculus for ELHr
given in Figures 1 and 5. We start with some basic observations, which can be easily proved
by induction on the length of derivations.
Lemma 68. For any ELHr -terminology T , C ran -concepts C, D and any role names r, s
we have
1. if T ` > v D, then T ` C v D;
2. if T ` C v A and A v CA  T or A  CA  T , then T ` C v CA ;
3. if T ` C v r.D then T ` C v r.(D u ran(r));
4. if T ` C v r.D, and r.> v B  T , then T ` C v B;
5. if T ` C v ran(r) and ran(r) v A  T , then T ` C v A;
6. if T ` C v r.D, and r v s  T , then T ` C v s.D;
7. if T ` C v ran(r) and r v s  T , then T ` C v ran(s).
Lemma 69 (Cut elimination). For any ELHr -terminology T , C ran -concepts C, D, and E,
if T ` C v D and T ` D v E then T ` C v E.
Proof. Let D1 be the derivation of C v D and D2 be the derivation of D v E. Let Li be
the length of Di , i = 1, 2. The proof of the lemma is by induction on the lexicographical
ordering on pairs (L2 , L1 ).
The case when L2 = 0 or L1 = 0, as well as the cases when L2 ends with one of
AndL1, AndL2, AndR, Ex, DefL, DefR or PDefL are virtually the same as in the
proof of Hofmann (2005). Assume D2 ends with Dom, and so its last sequent is of the form
r.D0 v E, and the sequent above it is B v E. By Lemma 68, Item 4, T ` C v r.D0
implies T ` C v B, so by the induction hypothesis, T ` C v E.
The cases when D2 ends with ExRan, Ran, Sub, or RanSub can be dealt with in the
similar way using Lemma 68, Items 3, 57.
Theorem 38. Let T be an ELHr -terminology; C0 and D0 be C ran -concepts. Then T |=
C0 v D0 if, and only if, T ` C0 v D0 .
Proof. It can be easily checked that the proof system rules are sound and so if T ` C0 v D0 ,
then T |= C0 v D0 .
Conversely, assume that T |= C0 v D0 . To prove T ` C0 v D0 we construct an
interpretation I based on the derivability of sequents from T . We show that I is a model
of T . As a consequence we obtain C0I  D0I and conclude that T ` C0 v D0 based on the
properties of I.
The domain I is the set of all well-formed pairs x = hC, RC i, where C is a C ran -concept
and RC is a finite set of role names such that
l
s  NR : if T ` (C u
ran(r)) v ran(s), then s  RC .
rRC

692

fiThe Logical Difference for the Lightweight Description Logic EL

We introduce the following abbreviation. Let
l
Ran(RC ) =
ran(r).
rRC

C ran -concepts C are interpreted as
I(C) = {hD, RD i  I | T ` (D u Ran(RD )) v C},
and r  NR are interpreted as
I(r) = {(hC, RC i , hD, RD i)  I  I | r  RD
and T ` (C u Ran(RC )) v r.(D u Ran(RD ))}.
Note that I(C) is nonempty for every C: consider R0C = {s  NR | T ` C v ran(s)}. As
0
T is finite, R0C is finite.
d Notice that, by Ax and AndR, T ` C v C u Ran(RC ) so, by
Lemma 69, if T ` (C u rR0 ran(r)) v ran(s), for some s, then T ` C v ran(s), so s  R0C .
C


ff


ff
That is, C, R0C is a well-formed pair and, obviously, C, R0C  I(C).
We now show that I(C) = C I for all C ran -concepts C. The proof is by induction on the
construction of C.
1. I(>) = I .
For any well-formed pair hC, RC i, T ` C u Ran(RC ) v > is an axiom.
2. I(C u D) = I(C)  I(D).
Let hC, RC i  I(D1 u D2 ), that is T ` (C u Ran(RC )) v (D1 u D2 ). Since T ` (D1 u D2 ) v
D1 , by Lemma 69, we have T ` (C u Ran(RC )) v D1 , that is, hC, RC i  I(D1 ). Similarly,
hC, RC i  I(D2 ).
Conversely, suppose hC, RC i  I(D1 ) and hC, RC i  I(D2 ) holds, that is, T ` (C u
Ran(RC )) v D1 and T ` (C uRan(RC )) v D2 . By AndR, T ` (C uRan(RC )) v (D1 uD2 ),
that is, hC, RC i  I(D1 u D2 ).
3. I(r.C) = {x  I | y  I(C) : (x, y)  I(r)}.
Suppose for some well-formed pair hD, RD i we have hD, RD i  I(r.C), that is T `
(D u Ran(RD )) v r.C. Then, by Lemma 68, Item 3, T ` (D u Ran(RD )) v r.(C u ran(r)).
Consider RrC = {s  NR | T ` (C u ran(r)) v ran(s)}. Clearly, r  RrC and, similarly
to the argument for R0C above, hC, RrC i is a well-formed pair. By Ax and AndR, T `
Curan(r) v CuRan(RrC ), by Ex, T ` r.(Curan(r)) v r.(CuRan(RrC )) and by Lemma 69,
T ` (D u Ran(RD )) v r.(C u Ran(RrC )). Then, by definition, (hD, RD i , hC, RrC i)  I(r)
and, since T ` (C u Ran(RrC )) v C, we have hC, RrC i  I(C).
Conversely, let (hD1 , RD1 i , hD2 , RD2 i)  I(r) and hD2 , RD2 i  I(C), that is, T ` (D1 u
Ran(RD1 )) v r.(D2 uRan(RD2 )), r  RD2 , and T ` (D2 uRan(RD2 )) v C. By Ex we have
T ` r.(D2 u Ran(RD2 )) v r.C, and, by Lemma 69, we have T ` (D1 u Ran(RD1 )) v r.C,
that is, hD1 , RD1 i  I(r.C).
4. I(ran(r)) = {y  I | x : (x, y)  I(r)}.
First we show that I(ran(r)) = {hC, RC i  I | r  RC }. If r  RC , we have T `
C u Ran(RC ) v ran(r), that is, I(ran(r))  {hC, RC i  I | r  RC }. Suppose hC, RC i 
I(ran(r)), that is, T ` (C u Ran(RC )) v ran(r). Then, since hC, RC i is a well-formed pair,
r  RC , that is, I(ran(r))  {hC, RC i  I | r  RC }.
693

fiKonev, Ludwig, Walther, & Wolter

Suppose now that hC, RC i  I(ran(r)), that is, hC, RC i is such that r  RC . Let D
denote (C u Ran(RC )). By induction on the length of derivations one can see that a sequent
of the form r.D v ran(s) is not derivable for any s  NR . Therefore, hr.D, i is a wellformed pair and (hr.D, i , hC, RC i)  I(r). Conversely, let (hD1 , RD1 i , hD2 , RD2 i)  I(r)
then, in particular, r  RD2 . That is, hD2 , RD2 i  I(ran(r)).
Now we show that I is a model of T . We need to show that all axioms of T are true in
I.
1. I(X)  I(CX ), whenever X  CX  T or X v CX  T .
Let hC, RC i  I(X), that is, T ` (C u Ran(RC )) v X. By Lemma 68, Item 2, T `
(C u Ran(RC )) v CX , that is, hC, RC i  I(CX ).
2. I(CX )  I(X), whenever X  CX  T .
Let hC, RC i  I(CX ), that is, T ` (C u Ran(RC )) v CX . Since by Ax and DefR
T ` CX v X, by Lemma 69, T ` (C u Ran(RC )) v X, that is hC, RC i  I(X).
3. (x, y)  I(r)  y  I(A), whenever ran(r) v A  T .
Let (hC, RC i , hD, RD i)  I(r), that is, T ` (C u Ran(RC )) v r.(D u Ran(RD )) and
r  RD . Since r  RD and, as, by Ax and Ran, T ` ran(r) v A, by AndL1, AndL2 we
have T ` (D u Ran(RD )) v A, that is, hD, RD i  I(A).
4. (x, y)  I(r)  x  I(B), whenever r.> v B  T .
Let (hC, RC i , hD, RD i)  I(r), that is, T ` (C u Ran(RC )) v r.(D u Ran(RD )) and
r  RD . Notice that, by Lemma 68, Item 4, we have T ` (C u Ran(RC )) v B, that is,
hC, RC i  I(B).
5. I(s)  I(r), whenever s v r  T .
Let (hC, RC i , hD, RD i  I(r)), that is T ` (C uRan(RC )) v r.(DuRan(RD )) and r  RD .
By Lemma 68, Item 6, T ` (C u Ran(RC )) v s.(D u Ran(RD )). Since r v s  T , by
Ax and RanSub, T ` ran(r) v ran(s) and T ` (D u Ran(RD )) v ran(s) by AndL1 and
AndL2. Since hD, RD i is well-formed, s  RD . Thus, (hC, RC i , hD, RD i)  I(s)


ff
As T |= C0 v D0 , we have I(C0 )  I(D0 ). Since C0 , R0C0  I(C0 ), we have


ff
C0 , R0C0  I(D0 ), that is T ` (C0 u Ran(R0C0 )) v D0 . As T ` C0 v C0 u Ran(R0C0 ),
we have T ` C0 v D0 by Lemma 69.
Proof of Lemma 44. Let T be a normalised ELHr -terminology and  a signature. Additionally, let A be a -ABox, A  sig(T )   non-conjunctive in T and a  obj(A).
For the direction (1.)  (2.), it is a direct consequence of the construction of AT ,
that for all b  obj(A) and B  sig(T )   non-conjunctive in T if (T , A) 6|= B(b) then
B  obj(AT , ).
Assume that (T , A) 6|= A(a). Then A  obj(AT , ). We now define a -range simulation S by setting,
 for b  obj(A) and for B  sig(T )   non-conjunctive in T with B  obj(AT , ) :
(b, B )  S if, and only if, (T , A) 6|= B(b),
 (b,  )  S for all b  obj(A).
We show that S is indeed a -range simulation with (a, A )  S by verifying that the
conditions (S1)(S3) and (RS) introduced on page 663 hold.
694

fiThe Logical Difference for the Lightweight Description Logic EL

(S1)

As (T , A) 6|= A(a) and A  obj(AT , ), it immediately follows that (a, A )  S.

(S2) Let now (b, )  S and B(b)  A with B  . We have to prove that B()  AT , .
For  = B with B  sig(T )   non-conjunctive in T , we obtain from the definition of S
that (T , A) 6|= B(b). Moreover, it holds that B 6 preC
T (B) as otherwise (T , A) |= B(b).
Thus, by the definition of AT , (B) we have B(B )  AT , . For  =  , it immediately
follows that B( )  AT , by the definition of AT , .
(S3) Now, let (b, )  S and r(b, b0 )  A with r  . We have to prove that there exists
 0  obj(AT , ) with (b0 ,  0 )  S and r(,  0 )  AT , . For  =  , it immediately follows from
the definition of AT , that r( ,  )  AT , and (b0 ,  )  S holds by the definition of S.
For  = B with B  sig(T )   non-conjunctive in T it follows from the definition
of S that (T , A) 6|= B(b). Additionally, we can infer that r 6 preDom
T (B) as otherwise
(T , A) |= (r.>)(b) would imply that (T , A) |= B(b).
Consider cases how B is defined in T . If B is pseudo-primitive in T , we obtain from the
definition of AT , (B) that r(B ,  )  AT , and it holds that (b0 ,  )  S by the definition
of S.
For B  r0 .B 0  T , we have to distinguish between the following two cases. If r 6
 0

0
preRole
T (r ), we obtain r   \ (preRoleT (r )  preDomT (B)) and thus r(B ,  )  AT , by
the definition of AT , and it holds again that (b0 ,  )  S by the definition of S. In the case
 0

0
where r  preRole
T (r ), we have r  preRoleT (r ) \ preDomT (B). Furthermore, as (T , A) 6|=
0
0
B(b) and so (T , A) 6|= (r .B )(b), it is easy to see that there must exist Bi00  non-conjT (B 0 )
00
00 0
with r 6 preRan
T (Bi ) and (T , A) 6|= Bi (b ). Then we have r(B , Bi00 )  AT , by the
0
definition of AT , (B) and (b , Bi00 )  S by the definition of S.
(RS) Let now (b, )  S such that r(c, b)  A for r  . We have to show that there exists
 0 with r( 0 , )  AT , . For  = B with B  sig(T )   non-conjunctive in T , we obtain
again from the definition of S that (T , A) 6|= B(b). Furthermore, we have r 6 preRan
T (B)
as otherwise (T , A) |= B(b). Thus, by the definition of AT , (B) we have r( , B )  AT , .
For  =  , it follows by the definition of AT , that r( ,  )  AT , .
For the converse direction (2.)  (1.), we assume that A  obj(AT , ) and (A, a) ran

(AT , , A ). It is then sufficient to show for all n that
n,ran
T 6|= CA
vA
T , ,A

as this implies that (T , AT , ) 6|= A(A ) by Lemma 36. We then obtain from Lemma 42 that
(T , A) 6|= A(a) holds.
Thus, we now prove by induction on n that for every concept name B  sig(T )  
n,ran
non-conjunctive in T with B  obj(AT , ), we have T 6|= CA
v B.
T , ,B
Let n = 0 and B  sig(T )   non-conjunctive in T with B  obj(AT , ). It then follows
that
l
l
l
0,ran
0
CA
=
B
u
ran(s)
u
ran(s)
T , ,B
B 0 \preC
T (B)

s\preRan
T (B)

695

Ar.BT
Bnon-conjT (B)


spreRole
T (r)\(preDomT (A)preRanT (B))

fiKonev, Ludwig, Walther, & Wolter

0,ran
Hence, one can see that for every subconcept of the form ran(s) that occurs in CA
,
T , ,B

we obtain that s 6 preRan
T (B). As B it non-conjunctive in T , it holds that either B is
pseudo-primitive in T or that B  r0 .B 0  T . Hence, by Lemma 39 we can conclude that
0,ran
T 6|= CA
v B.
T , ,B
For n > 0, let again B  sig(T )   non-conjunctive in T with B  obj(AT , ). We then
distinguish between the following two cases. If B is pseudo-primitive in T , we obtain
n,ran
CA
=
T , ,B

l

l

B0 u

s\preRan
T (B)

B 0 \preC
T (B)

l

ran(s) u

ran(s)

Ar.BT
Bnon-conjT (B)


spreRole
T (r)\(preDomT (A)preRanT (B))

u

l

s.Cs

s\preDom
T (B)
n,ran
v B.
for C ran -concepts Cs . It follows again from Lemma 39 that T 6|= CA
T , ,B
0
0
For B  r .B , we obtain
n,ran
=
CA
T , ,B

l
B 0 \preC
T (B)

u

l

B0 u

s\preRan
T (B)

l

ran(s)

Ar.BT
Bnon-conjT (B)


spreRole
T (r)\(preDomT (A)preRanT (B))

l

s.Cs u


0
s\(preRole
T (r )preDomT (B))

l

ran(s) u

n1,ran
s.CA
T , , 00

B 00 non-conjT (B 0 )
0 )\(preDom (B)preRan (B 00 ))
spreRole
(r
T
T
T

B

for C ran -concepts Cs . It is easy to see that the conditions (e2), (e3) and (e4) of Lemma 39
n,ran
v B to hold, condition (e1) would have to be fulfilled.
do not hold. Thus, for T |= CA
T , ,B
n,ran
n1,ran
with B 00  non-conjT (B 0 )
of CA
We observe that for every subconcept s.CA
T , ,B
T , , 00
B

n1,ran


00
00
0
and s  preRole
T (r ) \ (preDomT (B)  preRanT (B )), we obtain T 6|= CAT , , 00 v B from
B

n1,ran
u ran(s) v B 0 by Lemma 39
the induction hypothesis. Thus, we have T 6|= CA
T , ,B 00
for every such B 00 and s. We can infer that condition (e1) does not hold and, therefore,
n,ran
v B.
T 6|= CA
T , ,B

Appendix C. Proofs for Section 6
Proof of Lemma 54. Let T be a normalised ELHr -terminology and  a signature such
that   NR 6= . Additionally, let A  NC be a concept name that is non-conjunctive
in T , let r   be a role name, and let C be an EL -concept. Finally, let D = C or
D = ran(r) u C.
First observe that we obtain from Lemma 36 that T 6|= D v A holds if, and only if,
(T , AD ) 6|= A(aD ). Additionally, by Lemma 44, we have (T , AD ) 6|= A(aD ) if, and only if,
A  obj(AT , ) and (AD , aD ) ran
 (AT , , A ). Thus, it is sufficient to show the following
equivalence:

ran

(AD , aD ) ran
 (AT , , A )   r   : (A )r  obj(AT , ) and (AD , aD )  (AT , , (A )r )

696

fiThe Logical Difference for the Lightweight Description Logic EL

Next note that the ABox AD is role-splitting as C is an EL-concept and if D = ran(r) u C,
then { s(b, aD )  AD | b  obj(AD ), s  sig(AD ) } = {r(aran , aD )}.
Assume first A  obj(AT , ), (AD , aD ) ran
 (AT , , A ) and let S  obj(AD )obj(AT , )
be the corresponding -range simulation. We define a relation S   obj(AD )  obj(AT , )
by setting for every a  obj(AD ), every   obj(AT , ) and every role name r   such that
r  obj(AT , ):
(a, r )  S 

 (a, )  S and if s(c, a)  AD for some s  sig(AD ) and c  obj(AD ),
then s = r

Note that S  is well-defined as AD is role-splitting.
To show that S  is a -range simulation such that there exists r  sig(A,T ) with (A )r 
obj(AT , ) and (aD , (A )r )  S  , we prove that the conditions (S1)(S3) and condition (RS)
from page 663 hold.
(S1) If there exists s(c, aD )  AD for some s  sig(AD )   and c  obj(AD ), then there
exists  0  obj(AT , ) with s( 0 , A )  AT , as (aD , A )  S and S is a -range simulation,
i.e. s(( 0 )s , (A )s )  AT , and (A )s  obj(AT , ). Hence, (aD , (A )s )  S  .
Otherwise, it is easy to see that there exists r   with (A )r  obj(AT , ) as A 
obj(AT , ) and sig(AT , )  . Thus, as (aD , A )  S, we have (aD , (A )r )  S  .
(S2) Let (a, r )  S  and A(a)  AD for a  obj(AD ),   obj(AT , ), A   and
r  sig(AT , ). It follows from the definition of S  that (a, )  S. Hence, as S is a -range
simulation, we have A()  AT , , which implies that A(r )  AT , by the definition of
AT , .
(S3) Let (a, r )  S  and s(a, a0 )  AD for a, a0  obj(AD ),   obj(AT , ), r  sig(AT , )
and s  . From the definition of S  we obtain (a, )  S. Additionally, as S is a -range
simulation, there exists  0  obj(AT , ) such that (a0 ,  0 )  S and s(,  0 )  AT , . Thus, we
have s(r , s0 )  AT , by the definition of AT , and (a0 , s0 )  S  by the definition of S  as
AD is role-splitting.
(RS) Let (a, r )  S  and s(c, a)  AD for a, c  obj(AD ),   obj(AT , ), r  sig(AT , )
and s  . By the definition of S  , (a, )  S holds and r = s. As S is a -range simulation,
there exists  0  obj(AT , ) with s( 0 , ) = r( 0 , )  AT , . Hence, r(r0 , r )  AT , holds by
the definition of AT , .
For the converse direction, we assume that there exists r   such that (A )r  obj(AT , )



and (AD , aD ) ran
 (AT , , (A )r ) holds. Let S  obj(AD )  obj(AT , ) be the corresponding
-range simulation. We define a relation S  obj(AD )  obj(AT , ) by setting for every
a  obj(AD ) and every   obj(AT , ):
(a, )  S



 r  sig(AT , ) : (a, r )  S  .

It is straightforward to verify that A  obj(AT , ) and that S is a -range simulation with
(aD , A )  S.
697

fiKonev, Ludwig, Walther, & Wolter

Appendix D. Proofs for Section 7
Proof of Lemma 60. We require some preliminary observations. Let AC be the ABox
associated with a C ran -concept C (Lemma 36). Then, for any ELHr -terminology T , C ran concept C and C u,u concept D, we have T |= C v D if, and only if K |= D(aC ), where
K = (T , AC ). By Theorem 2 (extended version),
 T |= C v D if, and only if, IK |= D(aC ), where IK is the canonical model for K.
Note that T |= C v u.D if, and only if, DIK 6=  and that for any d, d0  IK and
R = t1 u    u tn , we have (d, d0 )  RIK if, and only if, there exists a role name s such that
(d, d0 )  sIK and s vT ti , for i = 1, . . . , n. We summarise the consequences we require in
the proof below:
(i) if D is a C u -concept with occurrences Si = ri,1 u . . . u ri,mi of intersections of roles,
1  i  k, then T |= C v D if, and only if, there exist role names si , 1  i  k, such
that si vT ri,j for 1  i  k, 1  j  mi and T |= C v D0 , where D0 is obtained from
D by replacing Si with si .
(ii) If D is a C u -concept, then T |= C v u.D if, and only if, there exists a sequence
r10 , . . . , rn0 such that IK |= (r10 .    rn0 .D)(aran ) or IK |= (r10 .    rn0 .D)(aC ). In
the first case, there exists a subconcept (ran(r) u C 0 ) of C (up to commutativity
and associativity of u) such that T |= r.C 0 v r10 .    rn0 .D. In the second case
T |= C v r10 .    rn0 .D.
d
d
d
Now assume that C = 1il ran(si )u 1jn Aj u 1km rk .Ck and T |= C v R1 .D.
Let R1 , . . . , Rk be all the occurrences of role intersections in R1 .D, where Ri = ri,1 u . . . u
ri,mi , for 1  i  k. By (i), we find role names si , 1  i  k, such that si vT ri,j for
1  i  k, 1  j  mi and T |= C v D0 , where D0 is obtained from D by replacing Ri with
si . By applying Lemma 39 to T |= C v s1 .D0 and by using that t1 vT r1,j , for 1  j  m1
and T |= D0 v D, we obtain that one of the conditions (e1u ), (e2u ), (e3u ), or (e4u ) must
hold.
For the second part of the lemma, we first prove by induction on n  1 for every C ran concept C and for every C u -concept D with T |= C v r1 .    rn .D that at least one of
the following conditions holds
(e1n ) there exists a subconcept r.C 0 of C such that T |= C 0 u ran(r)v D;
(e2n ) there exists a concept name A in C such that T |= A v u.D;
(e3n ) there exists a role name r in C such that T |= r.> v u.D;
(e4n ) there exists a role name r in C such that T |= ran(r) v u.D.
For n = 1, let C be a C ran concept and D be a C u -concept with T |= C v r1 .D. We
then obtain that at least one of the conditions (e1u ), (e2u ), (e3u ), or (e4u ) must hold from
the first part of the lemma, and hence, one of (e1n ), (e2n ), (e3n ), or (e4n ) is satisfied. For
n > 1, let C now be a C ran concept and D be a C u -concept such that T |= C v r1 .    rn .D.
We can apply the first part of the lemma again, and if conditions (e2u ), (e3u ), or (e4u ) are
fulfilled, then we can conclude that conditions (e2n ), (e3n ), or (e4n ) are also satisfied. In the
698

fiThe Logical Difference for the Lightweight Description Logic EL

case where (e1u ) holds, there exists a subconcept r.C 0 of C such that T |= C 0 u ran(r) v
r2 .    rn .D. From the induction hypothesis we obtain that at least one of the conditions
(e1n ), (e2n ), (e3n ), or (e4n ) is fulfilled for T |= C 0 u ran(r) v r2 .    rn .D, and thus also
for T |= C v r1 .    rn .D as r  sig(C) and as every subconcept of C 0 is also a subconcept
of C.
Now, if T |= C v u.D for a C ran -concept C and a C u -concept D, then by (ii) we have
to distinguish between the following two cases:
 There exists a subconcept ran(r) u C 0 of C and a sequence r10 , . . . , rn0 0 such that T |=
r.C 0 v r10 .    rn0 0 .D. For n0 = 0, we have T |= r.C 0 v D and condition (e6u )
holds. For n0  1 we obtain that at least one of the conditions (e1n ), (e2n ), (e3n ), or
(e4n ) is satisfied. If (e1n ) holds, then there exists a subconcept r0 .C 00 of r.C 0 such
that T |= C 00 u ran(r0 ) v D. If r.C 0 = r0 .C 00 , we have T |= C 0 u ran(r) v D. If
(C 0 u ran(r)) occurs at the top-level of the concept C, then T |= C v D holds, and
thus, condition (e5u ). Otherwise, there exists a subconcept s.((C 0 u ran(r)) u E) in
C and (e1u ) is satisfied as T |= C 0 u ran(r) u E u ran(s) v D. If r.C 0 6= r0 .C 00 , r0 .C 00
is a subconcept of C 0 (thus, of C) and so condition (e1u ) holds. Finally, if one of the
conditions (e2n ), (e3n ), or (e4n ) is satisfied, then one of (e2u ), (e3u ), or (e4u ) holds
by (ii).
 There exists a sequence r10 , . . . , rn0 0 with T |= C v r10 .    rn0 0 .D. For n0 = 0 condition
(e5u ) holds. If n0  1, then at least one of the conditions (e1n ), (e2n ), (e3n ), or (e4n )
holds. Then, by (ii), we can conclude that one of the conditions (e1u ), (e2u ), (e3u ),
or (e4u ) is satisfied as well.

We give the translation of C u,u -assertions to conjunctive queries. It is similar to the
construction of an ABox from a C ran -concept given in Section 5.1. First, given a C u -concept
C, we define a path in C as a finite sequence C0  R1  C1 . . . Rn  Cn , where C0 = C, n  0,
and Ri+1 .Ci+1 is a conjunct of Ci , for 1  i < n (Ri are conjunctions of role names). Let
xp for p  paths(C) be pairwise distinct variable names and set
XC = { s(xp , xq ) | p, q  paths(C); q = p  R  C 0 , s conjunct of R }
 { A(xp ) | A is a conjunct of tail(p), p  paths(C) }
Let ~x be the sequence
V of all variables in XC except xC . Then the conjunctive query qC,a is
obtained from ~x. XC  by replacing xC with
Va. Finally,
V for D = D0 uu.D1 u  uu.Dk
we obtain the conjunctive query qD,a from ~x.( 0ik XD ), (we assume that distinct
i
variables are used in every XDi , 0  i  k, and that ~x is a sequence of all variables except
xD0 ) by replacing xD0 with a.
To prove Lemma 63 we require some preparation. Query answering is closely related to
the existence of certain homomorphisms between interpretations. Let  be a signature, O
a set of individual names, and I1 , I2 interpretations. A function f : I1  I2 is called a
(O, )-homomorphism if
 f (aI1 ) = f (aI2 ) for all a  O;
699

fiKonev, Ludwig, Walther, & Wolter

 d  AI1 implies f (d)  AI2 for all A  ;
 (d1 , d2 )  rI1 implies (f (d1 ), f (d2 ))  rI2 for all r  .
It is known (Chandra & Merlin, 1977) that if there exists a (O, )-homomorphism from I1
to I2 and I1 |= q[~a] for a conjunctive -query q using only individual names from O and
~a = a1 , . . . , ak from O, then I2 |= q[~a].
For the proof below we slightly refine the notion of an (O, )-homomorphism by considering partial (O, )-homomorphisms with domains that satisfy certain conditions. Namely,
for every n  0, we will call a partial (O, )-homomorphism a level n homomorphism if its
domain contains all elements reachable by a -role chain of length at most n from either
a named individual or from an element without a -predecessor. We then prove that if
for every ELran,u,u -inclusion C v D with depth(C), depth(D)  n, T1 |= C v D implies
T2 |= C v D, then there exists a such a partial level n homomorphism from a certain model
of (T1 , A) to a certain model of (T2 , A).
We consider such partial homomorphisms on certain interpretations only, which we
introduce first. Let O be a finite set of individual names and I an interpretation. d  I
is called O-named if there exists a  O with d = aI . A model I is called an O-forest if
(F1) for everySd  I which is not O-named, there exists at most one d0  I such that
(d0 , d)  rNR rI ;
S
(F2) there are no infinite sequences d0 , d1 , . . . with (di+1 , di )  rNR rI for all i  0 such
that no di is O-named.
S
(F3) if (d, d0 )  rNR rI and d0 is O-named, then d is O-named.
Let O be a finite set of individual names, n  0, and  a signature. A partial function f
from an O-forest I to a model I 0 is called an (O, n, )-homomorphism if
0

(H1) for all a  O: aI is in the domain of f and f (aI ) = aI ;
0

(H2) for all d, d0 in the domain of f and r  : (d, d0 )  rI implies (f (d), f (d0 ))  rI ;
0

(H3) for all d in the domain of f and A  : d  AI implies f (d)  AI ;
(H4) for all d if there does not exist a chain d1 , . . . , dm = d with (di , di+1 ) 
length m > n of not O-named di , then d is in the domain of f .

S

r r

I

of

Now one can prove the following
Lemma 70. Suppose I is an O-forest, I 0 an interpretation and for every m > 0 there
exists a (O, m, )-homomorphism from I to I 0 . Assume as well that I |= q[~a] with q a
conjunctive -query using only individual names from O and ~a = a1 , . . . , ak from O. Then
I 0 |= q[~a].
Proof. Assume that ~a is a -match of I and q(~x) = ~y .q 0 (~x, ~y ) such that ~a consists of
elements of O. By (F2) and (F3) in the definition of O-forests and (H1) and (H4) in the
definition of partial homomorphisms, there exists m > 0 such that all (v), v from ~x  ~y ,
are in the domain of any (O, m, )-homomorphism f . Take a (O, m, )-homomorphism f .
Then ~a is a  0 -match of q(~x) and I 0 , where  0 (v) = f ((v)), for all v  ~x  ~y .
700

fiThe Logical Difference for the Lightweight Description Logic EL

Finally, we also need a technique for constructing (O, m, )-homomorphisms. Let I be
an interpretation. For each d  I and m > 0, let
u
tIm,,u (d) = {C  C
| depth(C)  m, d  C I },

where, as above, depth(C) is the role-depth of C; i.e., the number of nestings of existential
restrictions in C.
Lemma 71. Let  be a finite signature and let m > 0 Suppose I is an O-forest and I 0 an
interpretation such that
0

0

0

(in0) (aI , bI )  rI implies (aI , bI )  rI , for all a, b  O and r  ;
0

(in1) tIm,,u (aI )  tIm,,u
(aI ), for all a  O;
0
0

(d0 );
(d)  tm,,u
(in2) for all d  I there exists d0  I such that tm,,u
I
I0
Then there exists a (O, m, )-homomorphism g from I to I 0 .
Proof. We construct g by constructing a sequence of functions f0 , . . . , fm , where fi : I  I 0 ,
as follows: the domain dom(f0 ) of f0 consists
of all aI with a  O and all d  I such that
S
0
0
0
there does not exist a d with (d , d)  r rI . For aI with a  O we set f0 (aI ) = aI .
For every remaining d  dom(f0 ) choose a d0 according to (in2) and set f0 (d) = d0 . Observe
that tm,,u
(d)  tIm,,u
(f0 (d)) for all d  dom(f0 ).
0
I
Now suppose that fn has been constructed and
(fn (d)) for all d  dom(fn );
(d)  tmn,,u
(in3) tmn,,u
I
I0
(in4) for n > 0: d  dom(fn ) if, and only if, d is not O-named and there exists a sequence
d0 r1I d1 r2I    rnI dn = d of which at most d0 is O-named such that ri   and d0 
dom(f0 ).
S
To construct fn+1 consider a d  dom(fn ) and a not O-named d0 such that (d, d0 )  r rI .
0
0
I
u
0
The
d domain of fn+1 consists of all such d . Let Rd,d = {r   | (d, d )  r } and Rd,d0 =
( rR 0 r). Then
d,d
l
u
Rd,d
D  tmn,,u
(d)
0.
I
mn1,,u 0
(d )
DtI

By (in3),
u
Rd,d
0.

l

D  tImn,,u
(fn (d))
0

mn1,,u 0
DtI
(d )
0

Thus, we can choose an e with (fn (d), e)  rI for all r  Rd,d0 and tImn1,,u (d0 ) 
tmn1,,u
(e) and set fn+1 (d0 ) = e. This defines fn+1 . Observe further that fn+1 is wellI0
defined by (F1). Observe that fn+1 has the properties (in3) and (in4), by (F3).
S
Now we set g = 0nm fm . It is readily checked that g is as required.
701

fiKonev, Ludwig, Walther, & Wolter

We are now in the position to prove Lemma 63.
Lemma 63 If   qDiff  (T1 , T2 ), then there exists 0  cDiff ran,u,u
(T1 , T2 ) with sig(0 ) 

sig().
Proof. Assume T1 and T2 are given and let (A, q(~a))  qDiff  (T1 , T2 ). Let 0 = sig(A) 
sig(q). Assume that, in contrast to what is to be shown,
T1 |= 

()



T2 |= 

for all ELran,u,u -inclusions  with sig()  0 .
Consider a model I 0 of (T2 , A) with I 0 6|= q[~a]. By Lemma 70, we obtain a contradiction
if there exists an obj(A)-forest I which is a model of (T1 , A) and such that for every n > 0
there exists an (obj(A), n, 0 )-homomorphism fn from I to I 0 .
0
Take, for every a  obj(A) a model Ia0 of T1 with da  Ia such that for all C ran  C u,u concepts C:
0
da  C Ia  T1  tI 0 (a) |= C
where

0

0

I
ran
 C I }.
tI 0 (a) = {C  C
0 | a

Such interpretations Ia0 exist by Lemma 67. We now define the unfolding
Ia of Ia0 . A path
d
in Ia0 is a finite sequence d0 R1 d1 . . . Rn dn , n  0, such that Ri+1 = Ri+1 for a set Ri+1
0
of role names with r  Ri+1 iff (di , di+1 )  rIa , for all i < n. For a path p, tail(p) denotes
the last element of p. Now let Ia consist of all paths in Ia0 and set
0

 AIa = {p  Ia | tail(p)  AIa };
 rIa = {(d, dRd0 )  Ia  Ia | r  R}.
Then Ia is an O-forest for O = . Moreover, for all C u,u -concepts C and all p  Ia :
()

p  C Ia



0

tail(p)  C Ia .

In particular, Ia is still a model of T1 .
Take the following (disjoint) union I of the interpretations Ia :
S
 I = aobj(A) Ia ;
S
 AI = aobj(A) AIa , for A  NC ;
S
 rI = aobj(A) rIa  {(da , db ) | r0 (a, b)  A, r0 vT1 r}, for r  NR ;
 aI = da , for a  obj(A).
We show that I is an obj(A)-forest, a model of (T1 , A) and that there exist (obj(A), n, )homomorphisms from I to I 0 for all n > 0. First observe the following:
Claim 1. For all EL concepts C and d  Ia :
d  C I  d  C Ia
702

fiThe Logical Difference for the Lightweight Description Logic EL

The proof is by induction on the construction of C. The interesting case is C = r.D and
the direction from left to right.
Assume that d  C I  Ia . Take d0 with (d, d0 )  rI
S
and d0  DI . For (d, d0 )  a0 obj(A) rIa0 , d  C Ia follows immediately from the induction
hypothesis. Otherwise, d = da , d0 = db for some b with r0 (a, b)  A and r0 vT1 r. By the
induction hypothesis, d0  DIb . Hence, by (), T1  tI 0 (b) |= D. By compactness, there
exists a concept E  tI 0 (b) such that T1 |= E v D. We obtain r0 .E  tI 0 (a). But then
T1 |= r0 .E v r0 .D and we obtain da  C Ia using r0 vT1 r and ().
Claim 2. I is an obj(A)-forest and a model of (T1 , A).
That I is an obj(A)-forest and a model of A follows from the construction. It remains to
show that I is a model of T1 . For role inclusions r v s  T1 it follows from the construction
that rI  sI . Suppose C1 v C2  T1 . If C1 is an EL-concept, then I |= C1 v C2 follows
from Claim 1 and the condition that the Ia are models of T1 . Now assume that C1 = ran(r)
and let d  ran(r)I . If d 6= da for any a, then d  C2I since the Ia are models of T1 . If d = da ,
there exists r0 (b, a)  A with r0 vT1 r. We have ran(r0 )  tI 0 (a), and so T1  tI 0 (a) |= C2 .
Hence, by (), da  C2Ia , i.e. da  C2I by Claim 1.
Claim 3. For every n > 0 there exists an (obj(A), n, 0 )-homomorphism from I to I 0 .
By Lemma 71, it is sufficient to show conditions (in0), (in1), and (in2). Condition (in0)
follows directly from (). Condition (in1) is proved by induction on the construction of C.
The interesting step is for C = S.D with S = r1 u    u rm . Let a  obj(A) and C 
0
tIn, ,u (aI ). Take d0 with (aI , d0 )  S I and d0  DI . If d0  Ia , then, by (), T1  tI 0 (a) |=
0 ,u
0
(aI ). Now assume
S.D. By () and compactness, T2  tI 0 (a) |= S.D. Hence C  tIn,
0
d0 6 Ia . Then there are r10 , . . . , rk0 and b with d0 = bI such that ri0 (a, b)  A for 1  i  k
0
and for every 1  i  m there exists an 1  j  m with rj0 vT1 ri . We have D  tIn, ,u (bI ).
0

0

,u I
(b ). By (), for every 1  j  m there exists an
By the induction hypothesis D  tn,
I0
0 ,u
0
0
1  j  k with rj vT2 ri . But then C  tIn,
(aI ), as required.
0
d
For (in2), let d  I and C = Dtn,0 ,u (d) D. If d 6= aI for any a  obj(A), then
I

by () there exists b  obj(A) such that T1  tI 0 (b) |= u.C. By compactness and (),
0 ,u
0 ,u
0
(d)  tn,
(d0 ), as required. If
T2  tI 0 (b) |= u.C. Hence, there exists d0  I with tn,
I
I0
0
d = aI for some a  obj(A), then, by (in1) shown above, d0 = aI is as required.
This finishes the proof of Lemma 63.

References
Baader, F., Brandt, S., & Lutz, C. (2008). Pushing the EL envelope further. In Proceedings
of the 6th International Workshop on OWL: Experiences and Directions (OWLED
2009), Vol. 529 of CEUR Workshop Proceedings. CEUR-WS.org.
Baader, F., Penaloza, R., & Suntisrivaraporn, B. (2007). Pinpointing in the description
logic EL+ . In Proceedings of the 30th Annual German Conference on Artificial Intelligence (KI 2007), Vol. 4667 of Lecture Notes in Computer Science, pp. 5267,
Heidelberg/Berlin, Germany. Springer Verlag.
703

fiKonev, Ludwig, Walther, & Wolter

Baader, F. (2003). Terminological cycles in a description logic with existential restrictions.
In Proceedings of the 18th International Joint Conference on Artificial Intelligence
(IJCAI 2003), pp. 325330, San Francisco, CA, USA. Morgan Kaufmann.
Bienvenu, M., Lutz, C., & Wolter, F. (2012a). Deciding FO-rewritability in EL. In Proceedings of the 25th International Workshop on Description Logics (DL 2012).
Bienvenu, M., Lutz, C., & Wolter, F. (2012b). Query containment in description logics revisited. In Proceedings of the 13th International Conference on Principles of Knowledge
Representation and Reasoning (KR 2012).
Brandt, S., Kusters, R., & Turhan, A.-Y. (2002). Approximation and difference in description logics. In Proceedings of the 8th International Conference on Principles and
Knowledge Representation and Reasoning (KR-02), pp. 203214, San Francisco, CA,
USA. Morgan Kaufmann.
Calvanese, D., Giacomo, G. D., Lembo, D., Lenzerini, M., & Rosati, R. (2006). Data
complexity of query answering in description logics. In Proceedings of the Tenth
International Conference on Principles of Knowledge Representation and Reasoning
(KR 2006), pp. 260270.
Chandra, A. K., & Merlin, P. M. (1977). Optimal implementation of conjunctive queries in
relational data bases. In Proceedings of the 9th Annual ACM Symposium on Theory
of Computing (STOC 77), pp. 7790, New York, NY, USA. ACM.
Chang, C. C., & Keisler, H. J. (1990). Model Theory, Vol. 73 of Studies in Logic and the
Foundations of Mathematics. Elsevier, Amsterdam, The Netherlands.
Clarke, E., & Schlingloff, H. (2001). Model checking. In Handbook of Automated Reasoning,
Vol. II, chap. 24, pp. 16351790. Elsevier, Amsterdam, The Netherlands.
Conradi, R., & Westfechtel, B. (1998). Version models for software configuration management. ACM Computing Surveys (CSUR), 30 (2), 232282.
Crafa, S., Ranzato, F., & Tapparo, F. (2011). Saving space in a time efficient simulation
algorithm. Fundamenta Informaticae, 108 (1-2), 2342.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2008). Modular reuse of ontologies: theory and practice. Journal of Artificial Intelligence Research (JAIR), 31,
273318.
Delaitre, V., & Kazakov, Y. (2009). Classifying ELH ontologies in SQL databases. In
Proceedings of the 6th International Workshop on OWL: Experiences and Directions
(OWLED 2009), Vol. 529 of CEUR Workshop Proceedings. CEUR-WS.org.
Eiter, T., Fink, M., & Woltran, S. (2007). Semantical characterizations and complexity of
equivalences in answer set programming. ACM Transactions on Computational Logic,
8 (3).
Ghilardi, S., Lutz, C., & Wolter, F. (2006). Did I damage my ontology? A case for conservative extensions in description logic. In Proceedings of the Tenth International
Conference on Principles of Knowledge Representation and Reasoning (KR 2006),
pp. 187197, Menlo Park, CA, USA. AAAI Press.
704

fiThe Logical Difference for the Lightweight Description Logic EL

Golbeck, J., Fragaso, G., Hartel, F., Hendler, J., Oberhaler, J., & Parsia, B. (2003). The
National Cancer Institutes thesaurus and ontology. Journal of Web Semantics, 1 (1),
7580.
Goncalves, R. S., Parsia, B., & Sattler, U. (2011). Analysing multiple versions of an ontology:
A study of the NCI thesaurus. In Proceedings of the 24th International Workshop
on Description Logics (DL 2011), Vol. 745 of CEUR Workshop Proceedings. CEURWS.org.
Goncalves, R. S., Parsia, B., & Sattler, U. (2012). Concept-based semantic difference in
expressive description logics. In Proceedings of the 25th International Workshop on
Description Logics (DL 2012).
Hofmann, M. (2005). Proof-theoretic approach to description-logic. In Proceedings of the
20th Annual IEEE Symposium on Logic in Computer Science (LICS 2005), pp. 229
237, Washington, DC, USA. IEEE Computer Society.
Horridge, M., Parsia, B., & Sattler, U. (2010). Justification oriented proofs in OWL. In
Proceedings of the 9th International Semantic Web Conference (ISWC 2010), Vol.
6496 of Lecture Notes in Computer Science, pp. 354369, Berlin/Heidelberg, Germany.
Springer-Verlag.
IHTSDO (2008). SNOMED Clinical Terms User Guide. The International Health Terminology Standards Development Organisation (IHTSDO). Available from
http://www.ihtsdo.org/publications/introducing-snomed-ct/.
Jimenez-Ruiz, E., Cuenca Grau, B., Horrocks, I., & Llavori, R. B. (2011). Supporting
concurrent ontology development: Framework, algorithms and tool. Data & Knowledge
Engineering, 70 (1), 146164.
Kalyanpur, A., Parsia, B., Horridge, M., & Sirin, E. (2007). Finding all justifications of
OWL DL entailments. In Proceedings of the 6th International and 2nd Asian Semantic
Web Conference (ISWC07+ASWC07), pp. 267280, Berlin/Heidelberg, Germany.
Springer Verlag.
Kazakov, Y. (2009). Consequence-driven reasoning for Horn SHIQ ontologies. In Proceedings
of the 21st International Conference on Artificial Intelligence (IJCAI 2009), pp. 2040
2045.
Kazakov, Y., Krotzsch, M., & Simancik, F. (2011). Unchain my EL reasoner. In Proceedings of the 24th International Workshop on Description Logics (DL 2011), CEUR
Workshop Proceedings. CEUR-WS.org.
Klein, M. C. A., Fensel, D., Kiryakov, A., & Ognyanov, D. (2002). Ontology versioning and
change detection on the web. In Knowledge Engineering and Knowledge Management:
Ontologies and the Semantic Web, Vol. 2473 of Lecture Notes in Computer Science,
pp. 247259. Springer Verlag, Berlin/Heidelberg, Germany.
Konev, B., Lutz, C., Walther, D., & Wolter, F. (2008). Semantic modularity and module
extraction in description logic. In Proceedings of the 18th European Conference on
Artificial Intelligence (ECAI 2008), Vol. 178 of Frontiers in Artificial Intelligence and
Applications, pp. 5559, Amsterdam, The Netherlands. IOS Press.
705

fiKonev, Ludwig, Walther, & Wolter

Konev, B., Walther, D., & Wolter, F. (2008). The logical difference problem for description
logic terminologies. In Proceedings of the 4th International Joint Conference on Automated Reasoning (IJCAR 2008), Vol. 5195 of Lecture Notes in Computer Science,
pp. 259274, Berlin/Heidelberg, Germany. Springer Verlag.
Konev, B., Kontchakov, R., Ludwig, M., Schneider, T., Wolter, F., & Zakharyaschev, M.
(2011). Conjunctive query inseparability of OWL 2 QL TBoxes. In Proceedings of
the 25th Conference on Artificial Intelligence (AAAI 2011), Menlo Park, CA, USA.
AAAI Press.
Konev, B., Ludwig, M., & Wolter, F. (2012). Logical difference computation with CEX2.5.
In Proceedings of the 6th International Joint Conference on Automated Reasoning
(IJCAR 2012), Lecture Notes in Computer Science, Berlin/Heidelberg, Germany.
Springer.
Konev, B., Lutz, C., Walther, D., & Wolter, F. (2009). Formal properties of modularisation.
In Modular Ontologies, pp. 2566. Springer Verlag, Berlin/Heidelberg, Germany.
Kontchakov, R., Wolter, F., & Zakharyaschev, M. (2010). Logic-based ontology comparison
and module extraction, with an application to DL-Lite. Artificial Intelligence, 174 (15),
10931141.
Kontchakov, R., Pulina, L., Sattler, U., Schneider, T., Selmer, P., Wolter, F., & Zakharyaschev, M. (2009). Minimal module extraction from DL-Lite ontologies using
QBF solvers. In Proceedings of the 21st International Joint Conference on Artificial
Intelligence (IJCAI 2009), pp. 836841, San Francisco, CA, USA. Morgan Kaufmann.
Kutz, O., & Mossakowski, T. (2008). Conservativity in structured ontologies. In Proceedings
of the 18th European Conference on Artificial Intelligence (ECAI 2008), Vol. 178
of Frontiers in Artificial Intelligence and Applications, pp. 8993, Amsterdam, The
Netherlands. IOS Press.
Kutz, O., & Mossakowski, T. (2011). A modular consistency proof for DOLCE. In Proceedings of the 25th Conference on Artificial Intelligence (AAAI 2011), Menlo Park, CA,
USA. AAAI Press.
Kremen, P., Smd, M., & Kouba, Z. (2011). OWLDiff: A practical tool for comparison and
merge of OWL ontologies. In Proceedings of the 10th International Workshop on Web
Semantics, pp. 229233, Los Alamitos, CA, USA. IEEE Computer Society Press.
Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive query answering in the description
logic EL using a relational database system. In Proceedings of the 21st International
Joint Conference on Artificial Intelligence (IJCAI 2009), pp. 20702075, Menlo Park,
CA, USA. AAAI Press.
Lutz, C., Walther, D., & Wolter, F. (2007). Conservative extensions in expressive description logics. In Proceedings of the 20th International Joint Conference on Artificial
Intelligence (IJCAI 2007), pp. 453458, Menlo Park, CA, USA. AAAI Press.
Lutz, C., & Wolter, F. (2010). Deciding inseparability and conservative extensions in the
description logic EL. Journal of Symbolic Computing, 45 (2), 194228.
Lutz, C., & Wolter, F. (2011). Foundations for uniform interpolation and forgetting in expressive description logics. In Proceedings of the 22nd International Joint Conference
706

fiThe Logical Difference for the Lightweight Description Logic EL

on Artificial Intelligence (IJCAI 2011), pp. 989995, Menlo Park, CA, USA. AAAI
Press.
Mendez, J., & Suntisrivaraporn, B. (2009). Reintroducing CEL as an OWL 2 EL reasoner.
In Proceedings of the 22nd International Workshop on Description Logics (DL 2009),
Vol. 477 of CEUR Workshop Proceedings. CEUR-WS.org.
Noy, N. F., & Musen, M. A. (2002). PromptDiff: A fixed-point algorithm for comparing
ontology versions. In Proceedings of the 18th national conference on Artificial intelligence, pp. 744750, Menlo Park, CA, USA. AAAI Press.
Ohst, D., Welle, M., & Kelter, U. (2003). Differences between versions of UML diagrams.
In Proceedings of the 9th European software engineering conference held jointly with
11th ACM SIGSOFT international symposium on Foundations of software engineering
(ESEC03/SIGSOFT FSE03), pp. 227236, New York, NY, USA. ACM.
Oliver, D. E., Shahar, Y., Shortliffe, E. H., & Musen, M. A. (1999). Representation of
change in controlled medical terminologies. Artificial Intelligence in Medicine, 15 (1),
5376.
Palma, R., Haase, P., Corcho, O., & Gomez-Perez, A. (2009). Change representation for
OWL 2 ontologies. In Proceedings of the 6th International Workshop on OWL: Experiences and Directions (OWLED 2009), Vol. 529 of CEUR Workshop Proceedings.
CEUR-WS.org.
Pearce, D., & Valverde, A. (2004). Uniform equivalence for equilibrium logic and logic programs. In Proceedings of the 7th International Conference on Logic Programming and
Nonmonotonic Reasoning (LPNMR 2004), Vol. 2923 of Lecture Notes in Computer
Science, pp. 194206, Berlin/Heidelberg, Germany. Springer.
Pearce, D., & Valverde, A. (2012). Synonymous theories and knowledge representations in
answer set programming. Journal of Computer and System Sciences, 78 (1), 86104.
Penaloza, R., & Sertkaya, B. (2010). On the complexity of axiom pinpointing in the EL
family of description logics. In Proceedings of the 12th International Conference on
Principles of Knowledge Representation and Reasoning (KR 2010), Menlo Park, CA,
USA. AAAI Press.
Poggi, A., Lembo, D., Calvanese, D., Giacomo, G. D., Lenzerini, M., & Rosati, R. (2008).
Linking data to ontologies. Journal of Data Semantics, 10, 133173.
Redmond, T., Smith, M., Drummond, N., & Tudorache, T. (2008). Managing change: An
ontology version control system. In Proceedings of the 5th International Workshop
on OWL: Experiences and Directions (OWLED 2008), Vol. 432 of CEUR Workshop
Proceedings. CEUR-WS.org.
Rosati, R. (2007). On conjunctive query answering in EL. In Proceedings of the 2007
International Workshop on Description Logic (DL 2007), Vol. 250 of CEUR Workshop
Proceedings. CEUR-WS.org.
Schlobach, S., & Cornet, R. (2003). Non-standard reasoning services for the debugging of
description logic terminologies. In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI 2003), pp. 355362, San Francisco, CA, USA.
Morgan Kaufmann.
707

fiKonev, Ludwig, Walther, & Wolter

Teege, G. (1994). Making the difference: A subtraction operation for description logics.
In Proceedings of the 4th International Conference on Principles of Knowledge Representation and Reasoning (KR94), pp. 540550, San Francisco, CA, USA. Morgan
Kaufmann.
van Glabbeek, R. J., & Ploeger, B. (2008). Correcting a space-efficient simulation algorithm.
In Proceedings of the 20th International Conference on Computer Aided Verification
(CAV 2008), Vol. 5123 of Lecture Notes in Computer Science, pp. 517529, Heidelberg/Berlin, Germany. Springer Verlag.
Vescovo, C. D., Parsia, B., Sattler, U., & Schneider, T. (2011). The modular structure of
an ontology: Atomic decomposition. In Proceedings of the 22nd International Joint
Conference on Artificial Intelligence (IJCAI 2011), pp. 22322237, Menlo Park, CA,
USA. AAAI Press.

708

fiJournal of Artificial Intelligence Research 44 (2012) 423-453

Submitted 10/11; published 07/12

Modelling Observation Correlations for Active Exploration and
Robust Object Detection
Javier Velez
Garrett Hemann
Albert S. Huang

VELEZJ AT MIT.EDU
GHEMANN AT ALUM.MIT.EDU
ASHUANG AT MIT.EDU

MIT Computer Science and Artificial Intelligence Laboratory
Cambridge, MA, USA

Ingmar Posner

INGMAR AT ROBOTS.OX.AC.UK

Mobile Robotics Group
Dept. Of Engineering Science, Oxford University
Oxford, UK

Nicholas Roy

NICKROY AT CSAIL.MIT.EDU

MIT Computer Science and Artificial Intelligence Laboratory
Cambridge, MA, USA

Abstract
Today, mobile robots are expected to carry out increasingly complex tasks in multifarious, realworld environments. Often, the tasks require a certain semantic understanding of the workspace.
Consider, for example, spoken instructions from a human collaborator referring to objects of interest; the robot must be able to accurately detect these objects to correctly understand the instructions.
However, existing object detection, while competent, is not perfect. In particular, the performance
of detection algorithms is commonly sensitive to the position of the sensor relative to the objects in
the scene.
This paper presents an online planning algorithm which learns an explicit model of the spatial
dependence of object detection and generates plans which maximize the expected performance of
the detection, and by extension the overall plan performance. Crucially, the learned sensor model
incorporates spatial correlations between measurements, capturing the fact that successive measurements taken at the same or nearby locations are not independent. We show how this sensor
model can be incorporated into an efficient forward search algorithm in the information space of
detected objects, allowing the robot to generate motion plans efficiently. We investigate the performance of our approach by addressing the tasks of door and text detection in indoor environments
and demonstrate significant improvement in detection performance during task execution over alternative methods in simulated and real robot experiments.

1. Introduction
Years of steady progress in mapping and navigation techniques for mobile robots have made it
possible for autonomous agents to construct accurate geometric and topological maps of relatively
complex environments and to robustly navigate within them (e.g., Newman, Sibley, Smith, Cummins, Harrison, Mei, Posner, Shade, Schroeter, Murphy, Churchill, Cole, & Reid, 2009). Lately,
mobile robots have also begun to perform high-level tasks such as the following of natural language
instructions or an interaction with a particular object, requiring a relatively sophisticated interpretation by an agent of its workspace. Some of the recent literature therefore focuses on augmenting
c
2012
AI Access Foundation. All rights reserved.

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a)

(b)

Figure 1: A traditional geometric environment map (a) represented as a simple two dimensional
occupancy grid with regions that are free-space (cyan) and not (red) useful for navigation
and localization, (b) the geometric map augmented with semantic information about the
identity, structure and location of objects in the world allowing for richer interactions
between agent and workspace.

metric maps with higher-order semantic information such as the location and identity of objects in
the workspace (see Fig. 1).
To this end, advances in both vision- and laser-based object detection and recognition have
been leveraged to extract semantic information from raw sensor data (e.g., Posner, Cummins, &
Newman, 2009; Douillard, Fox, & Ramos, 2008; Martinez-Mozos, Stachniss, & Burgard, 2005;
Anguelov, Koller, Parker, & Thrun, 2004). Commonly, the output of such a detection system is
accepted prima facie, possibly with some threshold on the estimated sensor error. A consequence
of directly using the results of an object detector is that the quality of the resulting map strongly
depends on the shortcomings of the object detector. Vision-based object detection, for example, is
oftentimes plagued by significant performance degradation caused by a variety of factors including
a change of aspect compared to that encountered in the training data, changes in illumination and, of
course, occlusion (e.g., Coates & Ng, 2010; Mittal & Davis, 2008). Both aspect and occlusions can
be addressed naturally by a mobile robot: the robot can choose the location of its sensors carefully
before acquiring the data and performing object detection, thereby improving the robustness of the
detection process by specifically counteracting known detector issues. Rather than placing the burden of providing perfect detections on the detector itself, the robot can act to improve its perception.
Rarely, however, is this ability of a mobile robot actually exploited when building a semantic map.
In this paper, we present an online planning algorithm for robot motion that explicitly incorporates a model of the performance of an object detector. We primarily address the problem in the
context of a robot exploring an unknown environment with the goal of building a map accurately
labeled with the location of semantic objects of interest  here, in particular, we consider doors
and textual signs. However, our approach can be applied to any problem where the robot must plan
trajectories that depend on the location of objects and landmarks of interest in an environment. We
show how our planning approach weighs the benefit of increasing its confidence about a potential
semantic entity against the cost of taking a detour to a succession of more suitable vantage point.
Fig. 2 gives a cartoon illustration of the problem, where a robot encounters a possible new object
424

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

(a)

(b)

(c)

Figure 2: A conceptual illustration of (a) the robot at viewpoint x while following the original
trajectory (bold line) towards the goal (red star), (b) the perception field for a particular
object detector centered around an object hypothesis, and (c) an alternative path (bold
dash-dotted line) along a more informative route. Cell shadings indicate the relative value
of observations taken from each cell in terms of mutual information. Lighter values
indicate lower mutual information and therefore desirable vantage points. The challenge
is not only learning how the mutual information varies spatially, but also capturing how
the mutual information at each cell changes with each new measurement.

while executing a path to a goal. Based on the expected information available from possible vantage
points, the robot may decide that the original path provided an accurate model of the object, or it
may choose to modify its path to reduce the possibility of errors in the object model.
We make two primary contributions in this paper. Firstly, we describe a new sensor model
that uses a mixture of Gaussian Processes not only to model the performance of the object detection system as a function of the robots relative position to the detected features but to also learn
online a model of how sensor measurements are spatially correlated. Typical estimation and planning algorithms assume that sensor measurements are conditionally independent of each other given
knowledge of the robots position, but this assumption is clearly incorrect  properties of the environment introduce a strong correlation between sensor measurements. Rather than estimate all
possible hidden variables that capture the full sensor model to preserve conditional independence,
we explicitly model spatial correlation of measurements and use this correlation model to estimate the mutual information between measurements taken at different locations. We then use the
mutual information both to bias the random sampling strategy during trajectory generation and to
evaluate the expected cost of each sampled trajectory. Secondly, we show how to incorporate the
learned sensor model into a forward search process using the Posterior Belief Distribution (PBD)
algorithm (He, Brunskill, & Roy, 2010, 2011) to perform computationally efficient deep trajectory
planning. The PBD approximation allows us to compute the expected costs of sensing trajectories
without explicitly integrating over the possible sensor measurements.
While our work is not the first result in actively controlling a sensor to improve its accuracy,
previous work has largely ignored motion cost and has typically assumed observations are conditionally independent given the sensor position. Inspired by recent progress in forward search for
planning under uncertainty, we demonstrate a system which allows us to efficiently find robust observation plans. This paper builds on our previous work presented at ICAPS 2011 (Velez, Hemann,
Huang, Posner, & Roy, 2011) and provides several substantial extensions. Specifically, we describe
a significantly richer sensor model, extend the approach to an improved planning algorithm and ad425

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

dress an additional object of interest  human-readable text. We demonstrate our overall approach
using a real robot as well as simulation studies.
Our exposition begins with the problem formulation of planning trajectories to improve object
detection in Section 2. In Section 3 we describe the specific sensor model and how to characterize
sensor models using mutual information. Section 4 then gives two different approaches to learning
how the sensor models vary spatially, and how observations are correlated spatially. We describe
our planning algorithm and how the sensor model is incorporated into the system in Section 5. We
follow with a description of the implementation for efficient planning using our sensor models in
Section 6. Section 7 describes the object detectors used for our results. Section 8 shows simulation
results of how our approach improves object detection compared to other approaches and Section 9
shows the performance of our system in real world trials. In Sections 10 and 11 we conclude with a
discussion of related work and future directions.

2. Problem Formulation
Consider a robot following a particular trajectory towards a goal in an environment with objects of
interest at unknown locations, for example, a rescue robot looking for people in a first-responder
scenario. Traditionally, an object detector can be used at waypoints along the trajectory where a
detection is either accepted into the map or rejected based on simple detector thresholds. However,
the lack of introspection of this approach regarding both the confidence of the object detector and
the quality of the data gathered can lead to an unnecessary acceptance of spurious detections. Most
systems simply discard lower confidence detections and have no way to improve the estimate with
further, targeted measurements. In contrast, we would like the robot to modify its motion to both
minimize total travel cost and the cost of errors when deciding whether or not to add newly observed
objects to the map.
Let us represent the robot as a point x  R2  SO(2), where SO(2) denotes the special orthogonal group representing orientation and R2 represents the location in 2D euclidean space. Without
loss of generality, we can express a robot trajectory as a set of waypoints x0:K , with an associated
motion cost cmot (x0:K ) for the sum total travel between waypoints x0 and xk . If the robot has a
prior map of the environment and is planning a path to some pre-specified goal, then computing a
minimum cost path x0:K is a well-understood motion planning problem.
As the robot moves, it receives output from its object detector that gives rise to a belief over
whether a detected object truly exists at the location indicated1 . We can model the presence of the
ith object at some location (ui , vi ) with the random variable yi  {object, no-object}. As the system
runs, the object detector will fire and give rise to objects Yi at given locations which our system
must then reason about and qualify as being either genuine objects or false firings from the object
detector.
Let us define a decision action ai  {accept, reject}, where the detected object is either accepted
into the map (the detection is determined to correspond to a real object) or rejected (the detection is
determined to be spurious). Let us also define a cost dec : {{accept, reject}{object, no-object}} 7
R for a correct or incorrect accept or reject decision. We cannot know the true cost of the decisions
{ai } because we ultimately do not know the true state of objects in the environment. We therefore
1. We assume the robot knows its own location, and has a sufficiently well-calibrated camera to determine the location
of the object in the map. In this work, the uncertainty is whether or not an object of a specific type is present at a
given location (u, v).

426

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

infer a distribution over the state of each object p(y) and generate a plan to minimize the expected
cost E[dec ] of individual decision actions given the distribution over objects.
We formulate the planning problem as choosing a plan , comprised of a sequence of waypoints
and decision actions,  7 {x0:K  a0:Q } for a path of length k and Q hypothesized objects to
minimize the total travel cost along the trajectory and the expected costs of the decision actions at
the end of the trajectory, such that the optimal plan   is given by

  = arg min cmot (x0:K ) + cdet (x0:K , a) ,
(1)
x0:K ,a

where

cdet (x0:K , a) = Ey|x0:K[dec (a, y)],

(2)

where Ey|x0:K [] denotes the expectation with respect to the robots knowledge regarding the object,
y, after having executed path x0:K . The number of hypothesized objects, Q, is the number of possible objects the detector fired on after traversing the entire trajectory and is not known beforehand.
Note that the planning problem of computing   is often formulated as a partially observable
Markov decision process or POMDP (Sondik, 1971; Kaelbling, Littman, & Cassandra, 1998), but
the POMDP representation will grow with combinatorial complexity in the presence of multiple
detections. Furthermore, POMDP solutions assume stationary and Markov model parameters; our
sensor model is non-stationary and explicitly non-Markov because we do not want to represent the
environmental features that are needed to support a non-Markov sensor model. Since our approach
uses a sensor model that adapts with each successive observation, a new POMDP model would
need to be constructed and solved after each observation. Lastly, an explicit POMDP model would
require the plan to take into account all possible observations the robot might encounter as it carries
out the motion trajectory. More precisely, the expected cost of the plan must be computed with respect to all possible observations and objects, rather than just the object distributions. We avoid the
resulting computational complexity by using a forward search algorithm similar to forward search
approximation techniques for solving POMDPs (Ross, Pineau, Paquet, & Chaib-draa, 2008), which
are known to scale well in the presence of complex representations. We also avoid explicitly computing the observation distribution during planning through the use of an approximation technique
known as the Posterior Belief Distribution (PBD) algorithm, adapted to our sensor model.

3. A Sensor Model for Object Detection
In order to compute the expected cost of decision actions, we must estimate the probability of objects existing in the world given the observations we might see while executing the motion plan.
We therefore require a probabilistic model of the object detector that allows us to infer the distribution over the object given measurements, p(y|z). We know that sensor characteristics vary as the
robot moves around the object because of interactions with the environment, hence we make this
relationship explicit by writing the posterior as p(y|z, x) to include the viewpoint x.
Furthermore, a measurement, z, taken from a particular viewpoint x consists of the output
of the object detector, assumed to be a real number indicating the confidence of the detector that
an object exists. The distribution over the range of confidence measurements is dependent on a
particular object detector and is captured by the random variable Z defined over the continuous
range [zmin , zmax ]. At every waypoint x the posterior distribution over Y can be expressed as
p(y|z, x) = R

p(z|y, x)p(y)
,
yY p(z|y, x)p(y)
427

(3)

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a)

(b)

(c)

Figure 3: Different graphical models representing the observation function. (a) A naive Bayes
approximation which assumes every observation z is conditionally independent given
knowledge of the object y. (b) The true model which assumes observations are independent given knowledge of both the environment  and the object y. (c) The model
employed here, in which the correlations are approximated by way of a mixture model in
the input space of waypoints {x  R2  SO(2)} (Equ. 9).

where p(z|y, x) denotes the likelihood, for every possible state of Y , of observing a particular
detector confidence at x. (The expression would seem to require p(y|x), but y is independent of the
waypoint until measurement z is received.)
3.1 The Observation Model
Observations z that are directly produced by a physical device, such as a camera, are often treated
as conditionally independent given the state of the robot (see Fig. 3a). However, the observations
are not independent given knowledge only of the current state, but in fact are independent given
both the state Y and environment  as shown in Fig. 3(b). If one (or both) of these variables are
unknown, then the measurements are no longer first-order Markov but are in fact correlated. This
can be seen more intuitively by noting that if the robot were stationary, aimed at a static scene, we
would not expect the response of the object detector on successive images to be independent. We
anticipate observations from the object detector to be extremely correlated, with the expectation that
no new information would be gained after more than a handful of images.
To correct our observation model we maintain a history of observations. As more waypoints are
visited, knowledge regarding an object can be integrated recursively. Let T K denote a trajectory of
K waypoint-observation pairs obtained in sequence such that T K = {(x1 , z 1 ), (x2 , z 2 ), . . . , (xK , z K )}.
Knowledge gained at each step along the trajectory can be integrated into the posterior distribution
over Y such that

K

T K = (xK , z K )  T K1 ,

(4)

K

(5)

K

K

p(y|z , x , )  p(y|z , x , T
=

K1

),

p(z K |y, xK , T K1 )p(y|T K1 )
,
p(z K |xK , T K1 )

(6)

where z K is the K th observation, which depends not only on the current waypoint but also on the
history of measurements and waypoints T K1 . The denominator in Equ. 6 serves to moderate the
428

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

influence of the measurement likelihood on the posterior based on any correlations existing between
observations taken along the trajectory.
The difficulty with the model in Equ. 6 is that the sensor model p(z K |y, xK , T K1 ) is difficult
to arrive at, depending as it does on the history of measurements. Furthermore, K can be arbitrarily
large, so we need a model that predicts observations given an infinite history of observations. We
will describe this new sensor model in Section 4.
3.2 Perception Fields
Before developing a new sensor model, we first need a way to examine how any sensor model
captures the effect of measurements on our posterior belief of the object y, and we use the reduction
in uncertainty relative to the current belief from the next observation. Given a waypoint xK and the
trajectory T K1 visited thus far, the reduction in uncertainty is captured by the mutual information
between the object state y and the observation Z K received at xK such that
I(Y, Z K ; xK , T K1 ) =
H(Y ; T K1 )  H(Y |Z K ; xK , T K1 ),

(7)

where H(Y ; T K1 ) and H(Y |Z K ; xK , T K1 ) denote the entropy and the conditional entropy, respectively (we drop the xK from the entropy since the distribution of Y is independent of the robot
being at xK without the corresponding observation Z K ). Thus, H(Y ; T K1 ) expresses the certainty of the current belief over whether the object exists given the trajectory thus far, unswayed by
any new measurements. At every time step, this term is constant for every waypoint considered and
is therefore disregarded. The conditional entropy in Equ. 7 can be expanded in terms of the posterior over the state of the hidden variable Y given the previous trajectory T K1 and an additional
measurement taken at xK , p(y|z K , xK , T K1 ) (c.f. Equs. 6 and 9), and the likelihood of z K taking
a particular value conditioned on the trajectory thus far and whether an object viewed from xK is
present or not, p(z K |xK , T K1 ),
H(Y |Z K ; xZK , T K1 ) =



p(z|xK , T K1 )H(Y |z, xK , T K1 ) ,

(8)

z

|z, xK , T K1 ) is computed using the sensor model p(y|z K , xK , T K1 ) given in Equ. 6,

where H(Y
which is a function of our belief over y after traversing waypoint-observation trajectory T K . The
expected reduction in uncertainty given by the conditional entropy values for all waypoints in the
robots workspace form the perception field2 for a particular object hypothesis (see Fig. 2(b)). We
will use the perception field induces by a sensor model in two ways: firstly as a bias in the search
for informative path, and secondly as part of the evaluation of the expected cost of each path.

4. Correlation Models
As described previously, conventional first-order Markov sensor models do not correctly represent
the effect of successive observations that are implicitly correlated by unmodelled environmental
2. The reduction in position uncertainty from robot observations across an environment is sometimes known as the
sensor uncertainty field (Takeda & Latombe, 1992) in active localization. Since our application is object detection,
we use the term perception field to avoid confusion with the localization problem, but the concepts are otherwise
identical.

429

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

variables. The images used by our object detector are not conditionally independent but correlated
through the environment . If the robot position and the scene are stationary, then the probability of
individual pixel values in successive images will be strongly correlated by the shared environmental
representation and robot position, varying only by sensor noise. Subsequently, the object detector
responses will also be strongly correlated. However, correctly representing observations in this way
requires an environmental model sufficient to capture the image generation process, an intractable
computational and modeling burden. Image-based object detectors are not the only detectors which
exhibit a dependence on the environment. Any object detector which utilizes properties of the
environment (geometric or otherwise) to generate detections cannot a priori be treated as producing
conditionally independent observations given only the state of the robot. Correctly representing the
full generative model of object detection which takes into account all environmental properties used
by a detector is frequently an intractable task.
To overcome this difficulty, we approximate the real process of object detection with a simplistic
model of how the images are correlated. We replace the influence of the environment  on correlations between observations with a convex combination of a fully independent model that does
not depend on the history of observations, and a correlated observation model that does depend on
the history of observations. We treat whether a particular observation is correlated to any previous
observation as a random variable. The new posterior belief over the state of the world is computed
as
K
p(z K |y, xK , T K1 ) = p(z K  T K1 )p(zind
|y, xK )
K
+ (1  p(z K  T K1 ))p(zcorr
|y, xK , T K1 ),

(9)

where we have marginalized over whether the observation z K is actually independent from any
previous observation or not. We use the notation A  B to represent event A is independent
of B. Factorizing the likelihood in this way (Equ. 9) will allow us to capture the intuition that
repeated observations from the similar waypoints add little to the robots knowledge about the state
of the world and should be treated as correlated. Observations from further afield, however, become
increasingly independent;  has less of a correlating effect.
In order to have a complete sensor model which uses the factorization in Equ. 9, we need to construct the model for the independent and correlated likelihoods as well as model the probability of a
particular detection being independent of any previous detections. The following sections describe
two different approaches to modeling the likelihood functions and the probability of independent
detections.
4.1 The Static Disc Model
Our first sensor model is called the static disc sensor model, and is very coarse, assuming that
measurements are drawn according to either a learned first-order Markov model or according to the
nearest previous observation.
K |y, xK is approximated using a histogramThe distribution over the independent detections zind
based detector performance on labeled training data. That is, training data is collected by placing
the robot at each waypoint in a grid around a training object facing the object. The robot collects
a series of images at each waypoint, and generates a histogram of object detection confidences for
each waypoint from the collected images, where the histogram gives the probability of a measurement z K from a specific (relative) waypoint xK . In contrast, the correlated detection model assumes
430

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

(a) Perception Field Before Observations

(b) Perception Field After One Observation, Disc Model

Figure 4: Perception field for a possible door using the static disc sensor model. The unknown
object is at the center (blue) looking towards the right. Brighter regions correspond to
waypoints more likely to result in higher confidence posterior beliefs. Observations are
taken with the robot at the denoted location (magenta) and oriented to point the sensor
directly at the object.

that measurements are fully correlated and always equal to the closest (in x) previously seen observation. As described in Equ. 9 we treat the probability of observation independence as a mixing
parameter, disc and express it as a truncated linear function of the Euclidean distance, d, between
two viewpoints. The distribution is normalized with respect to a maximum distance dmax , beyond
which observations are treated as fully independent. Thus,
 d
K
K1
dmax  d < dmax
(10)
p(z 
T
) = disc =
1
 d  dmax
In other words, no information is gained by taking additional measurements at the same waypoint
and the information content of observations increases linearly with distance from previous ones.
With reference to Equ. 6, this model results in the belief update,


K |y, xK )
p(zind
K
p(y|T ) = disc
+ (1disc ) p(y|T K1 ).
(11)
K |xK )
p(zind
431

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Fig. 4 shows two example perception fields for an object detector trained on doors (see Section 7
for the training process). In Fig. 4(a), we see that the highly informative measurements are directly
in front of the door, between 8m and 10m. In Fig. 4(b), we see the change to the perception field
after an observation. The mixture parameter for our static disc model, disc , has a dmax value
empirically chosen to be 3 meters.
4.2 The Dynamic Time-Varying Correlation Model
The static disc model shown in the previous section does not allow for the sensor model to change
according to the data actively seen during a trajectory. Our purpose in introducing a correlation
model is to capture the effect of the environment  on our object detector. An object detectors
response to individual object appearances is captured by the dependence on  (for example, a door
detector may have a different behavior when detecting highly reflective glass doors versus solid oak
doors). However, the static disc model assumes a fixed correlation model and sensor model for
all objects of a particular class, regardless of changes in the detectors response across individual
instances of object from the same class. The previous model also assumes a strong (truncated)
linear relationship between the probability of two observations being correlated and the distance
between two observations. We would like to relax this assumption in order to better model a broad
range of object detectors. Our second sensor model solves both the aforementioned issues with the
static disc model, and also allows for time-varying correlations as more observations are taken of
an object. Both sensor models make use of the factorization in Equ. 9, but differ in the models
K |y, xK ) and p(z K |y, xK , T K1 ) as well as the structure of
used for the detection likelihoods p(zind
corr
p(z K  T K1 ).
What we would like is a mechanism for learning a correlation between the measurements that
can depend on a potentially infinite number of previous measurements, and we use a Gaussian
Process (GP) to model both the independent and correlated sensor models. A Gaussian process is a
collection of random variables, any finite number of which have a joint Gaussian distribution, and is
completely specified by a mean function and a covariance function (Rasmussen & Williams, 2006).
We use GP regression in our likelihood models and always use the zero mean function 0 and the
Squared Exponential (SE) variance function with the following structure:
0 T (scaleI)1 (xx0 )/2

SE(x, x0 ) = sigma  e(xx )

.

(12)

We use the notation SEi (X; ) to mean that kernel SEi is a function of X and is parameterized by
.
4.2.1 I NDEPENDENT AND C ORRELATED L IKELIHOOD M ODELS
In order to model independent observations we use a Gaussian Process, GP ind , with zero mean function and squared-exponential covariance function as described above. The kernel parameters, ind ,
are learned from training data pairs of waypoints x and observations z as described in section 4.2.3.
The GP takes as input a particular waypoint x and predicts the detector output z at that waypoint.
Letting T train be the set of labeled waypoint-observation pairs used in GP ind , the observation model
for independent observation becomes
K
K
zind
|y, xK , T K1 = zind
|y, xK

 GP ind (0, SEind (T train , xK ; ind )).
432

(13)

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

where we see that the model depends solely on the training data to provide a prediction.
Similar to the independent model we use a Gaussian Process, GP corr , with zero mean function and learned SE kernel for the correlated observation model (Equ. 14) trained to model nonindependent observations from the object detector. The kernel parameters, corr , are learned from
training data as described in Section 4.2.3. Let T corr-train be the set of waypoint-observations pairs
used to train GP corr . But, GP corr uses the training data only to learn the kernel parameters and makes
predictions only from the data acquired during current trajectory T K1 so far, which results in the
following correlated observation model:
K
zcorr
|y, xK , T K1  GP corr (0, SEcorr (T K1 , xK ; corr )).

(14)

Unlike our independent model GP which predicts using only training data (Equ. 13), our correlated
model GPs predictions are based solely on data observations taken for the current object rather
K |y, xK , T K1 using
than observation histories from other objects. Predicting the likelihood of zcorr
the GP regression by marginalizing out all but the previous trajectory of observations results in a
normal distribution,
K
2
zcorr
|y, xK , T K1  N (corr,K , corr,K
).

(15)

The choice to model both independent and correlated observations using GPs results in our
overall observation model simplifying to a mixture of two Gaussian distributions,
2
).
z K |y, xK , T K1  N (obs , obs

(16)

4.2.2 M IXTURE PARAMETER AS P ROXY FOR I NDEPENDENCE
The reason to factor our likelihood into an independent model and a correlated model is to capture the intuition that nearby observations are correlated and are therefore less informative, but
we require some baseline model of observations in the remaining robot waypoints. We model the
probability of an observation being independent (p(z K  T K1 ) in Equ. 9) by treating it as a
time-varying spatial mixture parameter . The mixing parameter is chosen to be a function of the
variance of the correlation model estimate,
2

p(z K 
 T K1 ) = p(z K 
 T K1 |xK , T K1 ) = (xK , T K1 ) = 1  ecorr,K .

(17)

Because we are using an SE kernel function for GP corr , we know the variance in the prediction
corr,K is a function of the input space distance and is independent of the actual prediction value
(Rasmussen & Williams, 2006). Note that GP corr is a function of the current trajectory in the
world, T K1 , and the current waypoint xK but is not a function of the training data T corr-train .
The variance in the estimate from GP corr is a function of the distance between the waypoints of
observations taken so far for a particular object, and encodes our intuition that observations from
similar waypoints are correlated. In fact, as the current waypoint approaches any of the previous
K |y, xK , T K1 approaches 0,   1, which means we
observation waypoints, the variance of zcorr
trust our correlated observation model more than our independent model. Similarly, as the distance
between the current waypoint and any previous observation waypoint becomes large,   0 and
we trust our independent observation model almost exclusively. In other words, little information
is gained by taking additional measurements at the same waypoint and the information content of
observations increases with distance from previous ones.
433

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

As shown in Fig. 3(c), we remove  and add a dependency between previous waypoints and
the current observation z K . We use a pair of GPs to model the spatial time-varying properties of
correlations in the observation sequence from an object detector.

(a) Learned perception field for the first
observation.

(b) Learned perception field for the third
observation.

Figure 5: Learned perception field for door detector for the (a) first observation and (b) third observation. In (b), the previous observations (shown in magenta) shift where we expect
informative vantage points to be. In both panels, the unknown object is centered at the
origin facing the right. Brighter regions correspond to waypoints more likely to result in
higher confidence posterior beliefs. Observations are taken with the robot at the denoted
location (magenta) and oriented to point the sensor directly at the object.

4.2.3 T RAINING THE S ENSOR M ODELS
Our dynamic time-varying observation model consist of a mixture of two Gaussians (see Equ. 16),
each of which is modeled using two Gaussian Processes, GP ind and GP corr , for every object hypothesis. Each Gaussian Process maps from locations, x, to the resulting object detection score
z. Every object detector in our system has its own observation model. The independent observation likelihood GPs were trained using all the available training data. Each labeled tuple
(z, x, y = {object, no-object}) was used as if it were an independent sample and fed to the independent GP corresponding to the labeled object state ({object, no-object}). These same training
samples were used to learn the SE kernel for the independent GP models. In this way we learn
the model of detector output likelihood for the cases when an object truly existed or not, assuming independent observations. These two GPs are shared across all objects and is constant for all
measurements.
The correlated observation model GPs have the same learned SE kernel as each other but use
different data. The SE kernel is trained only with data from the same object since we are trying
to learn the model for correlated detections. We split the training data set into subsets which cor434

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

(a) Learned perception field for the first
observation.

(b) Learned perception field for the third
observation.

Figure 6: Learned perception field for text detector for the (a) first observation and (b) third observation. In (b), the previous observations (shown in magenta) shift where we expect
informative vantage points to be. In both panels, the unknown object is centered at the
origin facing the right. Brighter regions correspond to waypoints more likely to result in
higher confidence posterior beliefs. Observations are taken with the robot at the denoted
location (magenta) and oriented to point the sensor directly at the object.

respond to the same objects. The SE kernel parameters are chosen to be the maximal likelihood
parameters for the set of subsets. However, once the kernel parameters have been learned, the correlated model GPs are initially devoid of data. These two correlated model GPs are instantiated on
a per-object basis and are not shared across objects. Samples are added during runtime while the
robot actively observes detector outputs from the world. As such, the correlated model GPs track
the current set of waypoints observed for a particular object, whereas the independent model GPs
track all of the training samples since they are treated as independent.
Using the learned dynamic time-varying sensor model we derived the initial perception field
about a door shown in Fig. 5(a). Fig. 5(b) shows the perception field after several observations
have been taken around the door. Notice that the expected amount of information has significantly
decreased around the observed points but farther waypoints may still yield useful observations.
The initial perception field shows the areas of high expected information gain for an observation
according to the training samples for a particular object detector. Since there are not previous
observations, the initial perception field shows use the learned independent Gaussian Process for a
object detector.
The derived perception field about a text sign is shown in Fig. 6(a). Experimentally, we truncated
the text perception field for waypoints that had an aspect of more than 45 degrees to the object for
435

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

computational efficiency, given that our detector did not fire when viewing signs at more obtuse
angles in the training data. Fig. 6(b) shows the perception field after several observations have
been taken around the object. Notice that our text detector has a significantly different perception
field that our door detector, both in initial shape as well as in response to observations. We see
that the door detector has peaks within the perception field, signifying regions with relatively high
information gain. The text detector, on the other hand, has a very smooth perception field which
drops off mainly as a function of depth.

5. Planning To Perceive
Given the sensor model described in the previous section, we now describe a planning algorithm
that trades off the necessity of gaining additional information about an object hypothesis against the
operational cost of obtaining this information. In particular, when an object is first detected, a new
path to the original goal is planned based on the total cost function which includes both the motion
cost cmot along the path and the value of measurements from waypoints along the path expressed
as a reduction in the expected cost of decision actions. Recall that the cost function consists of two
terms: the motion cost cmot (x0:K ) and the decision cost cdet (x0:K , a), such that the optimal plan
  is given by Equ. 1, which we reproduce here:

  = arg min cmot (x0:K ) + cdet (x0:K , a) ,
x0:K ,a

where

cdet (x0:K , a) = Ey|x0:K[dec (a, y)],

where Ey|x0:K [] denotes the expectation with respect to the robots knowledge regarding the object,
after having executed path x0:K .
5.1 Motion cost
The path cost, cmot (x0:K ), encompasses operational considerations such as power expended and
time taken when moving along a particular trajectory and is typically proportional to the length of
the trajectory.
5.2 Decision Cost
The decision cost, cdet (x0:K , a), not only captures the expected cost of accepting (or rejecting) a
potential object detection, but it also captures the expected yield in information from observations
along path x0:K . The trajectory affects the cost of the decision actions in terms of changing the
expectation, rather than the decision actions themselves, in effect allowing the algorithm to decide
if more observations are needed.
Note that the decision actions can be treated independently of each other and also independently
of the robot motion, which allows us to compute the expected decision costs very efficiently. We
take advantage of this efficiency to move the minimization over decision actions directly inside the
cost function. Abusing notation for cdec , we have
cdet (x0:K ) = arg min cdet (x0:K , a)

(18)

a

= arg min Ey|x0:K[dec (a, y)].
a

436

(19)

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

Next, we can write the plan in terms of x0:K .

  = arg min cmot (x0:K ) + cdet (x0:K ) .

(20)

x0:K

dec (accept, ) and dec (reject, ) are the costs associated with declaring that the object exists or
not, respectively, after measuring z at xK following traversal of waypoint-observation trajectory
T K1 . These costs include the penalties imposed when accepting a true positive detection and
when accepting a false positive detection, respectively, and are chosen by the user of the system to
reflect the value/penalty of decision for a particular domain.
The expectation inside Equ. 19 relies on a model of Y conditioned on the trajectory x0:K ; as
can be seen in Fig. 3(c), Y and x0:K are correlated through z K . During planning, the actual z K that
will be received cannot be known ahead of time, so to evaluate the expectation exactly, it must be
taken with respect to both the object state Y and the received observations, as in
Ey|x0:K [
(a, y)] =

Z dec
K
K1
p(z|x , T
)Ey|z,x0:K1 [dec (a, y)] ,

(21)

z

where p(z|xK , T K1 ) denotes the probability of obtaining a particular detector confidence value
when observing the object from x given a previous trajectory T K1 , and is computed akin to the
posterior in Equ. 6. In Section 6.2 we show how we can efficiently approximate this expectation
over the observation sequence by treating our belief as normally distributed.
The planning process proceeds by searching over sequences of x0:K , evaluating paths by approximating the expectations with respect to both the observation sequences and the object state.
The paths with the lowest decision cost will tend to be those leading to the lowest posterior entropy,
avoiding the large penalty for false positives or negatives.
5.3 Multiple Objects
We formally define a vantage point relative to an object y, vy  RM , as a vector in an M dimensional feature space describing the configuration of the robot relative to the potential object.
We also define a mapping F : R2  SO(2)  Y 7 RM between a robot waypoint x and its corresponding vantage point vy = F (x, y). In principle, a vantage point need not be restricted to spatial
coordinates but may incorporate additional information such as, for example, the degree of occlusion experienced or image contrast (for an appearance based detector). In this work, however, only
the range, r, and aspect, , relative to the object with the robot oriented to directly face the object
are considered such that vy  R  SO(2) (see Fig. 2a). It is important to note that the system must
be able to accurately compute a vantage point; for this paper a stereo camera is used to estimate
the distance and orientation of a potential object. The planning approach described so far can be
extended to planning in an environment with Q object hypotheses by considering a modified cost
function which simply adds the cost for each object. We also augment our dec (a, y)  dec (a, y, i)
to be able to provide different decision costs for different object types (or even different object instances). The augmentation allows us to specify the relative importance of different objects types
in our algorithm. In this work we consider an objects existence to be independent of other objects
hence the individual object perception fields are additive for a particular waypoint x. We also restrict
ourselves to waypoints which correspond to the robot facing a particular hypothesized object.
437

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Given no prior information about object locations, we do not hypothesize how many objects
there are in the world. We initially let Q = 0 and run the object detector during the robot motion.
After each image is processed by the object detector, the system judges whether the detection belongs to an object hypothesis already being considered or not (e.g., using the distance between the
hypothesized object and the detection). If the detector determines that the probability of an object
at some new location is above a threshold and it does not belong to any hypothesis objects, the
number of object hypotheses Q is increased and the robot replans. If the detection is determined to
correspond to a particular object hypothesis, the system updates the belief and replans.
5.4 Multi-Step Planning
A simple approach for planning considers every possible trajectory to the goal and weights each
by the cost of taking the trajectory, choosing the minimum cost trajectory as the plan. This simple
algorithm scales approximately exponentially in the length of the planning horizon T and thus
rapidly becomes intractable as more observations are considered. We adopt a roadmap scheme in
which a fixed number of waypoints are sampled every time a new waypoint is to be added to the
current trajectory. A graph is built between the sampled poses, with straight-line edges between
samples.
The sampling scheme is biased towards waypoints more likely to lead to useful observations
using the perception field (see Section 3.2). Due to the correlations between individual observations
made over a trajectory of waypoints, the perception field changes as new observations are added. In
particular, the correlation model imposed in this work (Equs. 17 and 9 for the dynamic time-varying
model or Equ. 11 for the static disc model) forces
lim

# obs. at xK 

I(Y, Z K ; xK , T K1 )  0,

when considering measurements from waypoints already visited. In other words, the robot will
prefer to observe the putative object from different waypoints over taking repeated measurements
at the same place.
Algorithm R EPLAN O N N EW D ETECTION (Fig. 7) summarizes the planned-waypoints approach
of sampling and evaluating trajectories to balance increased confidence with motion costs. The
algorithm uses the Posterior Belief Distribution framework if able to quickly sample trajectories
with many observations, then selects the best of those as the current plan according to our cost
metric.
Figure 8 details the stages of our algorithm on an example run where a single door is detected
while going towards a goal.

6. Efficient Perception Field Computation
Our planning algorithm needs to calculate the perception field for deep planning horizons (T  1).
The variant of our algorithm which uses our static disc sensor model must evaluate the expected
change in our belief over y for every potential future waypoint, and must carry that belief thought
each level of our search tree over future trajectories xK+1:K+T . However, when using the dynamic
time-varying sensor model we can treat our belief over y as normally distributed. Under the normal
distribution approximation, in the limit of an infinite number of observations, the mean of the normal
distribution will converge to either 0 or 1 (depending on whether the object is present or not), with
438

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

Algorithm R EPLAN O N N EW D ETECTION
Input: an object detection z at vantage point x
// Step 1: Update Our Belief
2: if using static disc sensor model then
3:
dmin = arg min |x  xi |
1:

4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:

disc =

xi T K1
dmin
dM AX
K |y,T K )
disc p(z
p(z K |T K )

Equ 10

+ (1disc ) p(y|T K1 )

p(y) 
else
N (corr,K , corr,K )  PREDICT(GP corr , x)
2
  1  ecorr,K
n  n1 + Kn (zn  W (n1 ))
n  (n1 + Gn bn GTn )1
// Step 2: Sample Trajectories
T  {}
while sampling time remains do
traj  {}
if using static disc sensor model then
y0  y
for i = 1  T do
Pi  COMPUTE - PERCEPTION - FIELD(yi1 )
xi  Pi // sample vantage point
p(yi )  Ez 0 [p(z 0 |xi , T K1 , yi1 )p(yi1 )]
traj  traj  xi
else
00  n
00  n
GP 0corr  GP corr
for i = 1  T do
i1
Pi  COMPUTE - PERCEPTION - FIELD(0i1 , 0i1 , GP corr
)
xi  Pi // sample vantage point
z 0  PREDICT(GP i1
corr , GP ind , xi )
0
GP icorr  UPDATE - SENSOR - MODEL(GP i1
corr , xi , z )
0i  0i1 + Kn (zn 0  W (0i1 ))
0i  (0i1 + Gn bn GTn )1
traj  traj  xi
T  T  traj



35: EXECUTE - TRAJECTORY

Equ 11

Equ 17
Equs 25, 27 and 28

Equ 8

Equs 8 and 32
Equs 9, 13, 14 and 17
Equs 25, 27 and 28

arg min COST(t0 )
t0 T

Figure 7: The waypoint planning algorithm samples trajectories using the perception field, then
chooses the trajectories which balance increasing the robots confidence about an object
with minimizing trajectory costs (Equ. 1).

439

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a) Initially, the robot (blue
triangle) has a goal (red star)
an no detections have fired
yet, so no potential objects
are being reasoned about.

(b) After the detector fires,
the robot starts reasoning
about the potential object.
The system creates an initial
perception field from training
data for the potential object
and plans a path to take more
detections.

(c) After two detections (magenta) the belief is high
enough that the system is confident the door truly exists in
the world and continues on
towards the goal. Shown is
the resulting perception field
after the two taken observations.

Figure 8: A sample run of our system, from an initially empty set of objects being reasoned about
(a), to a door detector firing and causing a new door object hypothesis and perception field
to be created (b). The system then plans and executes a path to the goal which allows it
to take advantageous observations of the hypothesized door. After two observations, the
system continues towards the goal since the belief of whether the door exists or not is
such that the increase in expected reward for further improving the confidence of the
object model is not justified by the additional cost (c). Brighter regions of the perception
fields correspond to waypoints more likely to result in higher confidence posterior beliefs.
Observations are taken with the robot at the denoted location (magenta) and oriented to
point the sensor directly at the object. The belief over whether the door truly exists or not
is denoted by the green bar.

very small variance. Additionally, the expected cost of a decision will depend only on the variance
of the distribution: the smaller the covariance of the normal posterior, the less likely the probability
of a decision error. Finally, the posterior covariance of the normal will depend only on the sensor
model, and not the observation itself. As a result, if we know the sensor model information gain
for each measurement, we can predict the posterior covariance, and hence the expected cost of any
decision action, without knowing the exact observation sequence itself. This approximation of the
binomial measurement function is known as the Posterior Belief Distribution (PBD) algorithm (He
et al., 2011), and can be used to efficiently compute the resulting belief after T time steps. We sketch
the general idea behind PBD below, which we use to compute the expected entropy reduction in our
belief by future observations.
440

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

6.1 The Belief Over y
In reality, an object either exists or does not exists in the world (denoted by Y ). Labeled training
data for the output of an object detector is of the form (z, x, y = {object, no-object}), where we pair
the detector output at a particular waypoint with the knowledge of whether the object exists or not.
In order to use such labeled samples to train our sensor model (a model of the object detector), we
keep track of a belief  over whether the object exists or not. Equs. 22 and 23 show our independent
and correlated observation model likelihood given  using the likelihood given Y . We marginalize
over our belief for both our independent and correlated observations models (Equs. 13 and 14) to
get
K
K
p(zind
|, xK , T K1 ) =   p(zind
|object, xK , T K1 )
K
+ (1  )  p(zind
|no-object, xK , T K1 )

(22)

K
K
p(zcorr
|, xK , T K1 ) =   p(zcorr
|object, xK , T K1 )
K
+ (1  )  p(zcorr
|no-object, xK , T K1 ),

(23)

where each likelihood is itself modeled as a GP similar to Equ. 13 or 14 for the independent or
correlated models respectively.
Noting that we can write the likelihood of z in terms of  using Y (Equs. 22 and 23), we can
similarly rewrite Equ. 9 in terms of likelihoods based on  as
K
p(z K |, xK , T K1 ) = p(z K  T K1 )p(zind
|, xK , T K1 )
K
+ (1  p(z K  T K1 ))p(zcorr
|, xK , T K1 ).

(24)

6.2 Posterior Belief Distribution
The PBD algorithm allows us to estimate the expected information gain from a particular waypoint
without integrating over potential observations z. We begin by framing our problem in the Exponential Family Kalman Filter (efKF) formulation (He et al., 2011) where we treat  as the state we
are trying to estimate, and we have an exponential family observation model,
n = n1  N (n , n )

(25)

zn = exp(zn n  bn (n ) + n (zn )).

(26)

Given a single observation and the canonical link function W mapping from state to observation
parameter , the posterior mean and variance of the belief can be computed as,
n = n1 + Kn (zn  W (n1 ))
n = (n1 + Gn bn GT )1

(27)
(28)

n

Kn = n1 Gn (Gn n1 GTn + bn
zn = n  bn
fi
n fifi
Gn =
n fi

1

 (bn  zn )
.

n =n1

441

1 1

)

(29)
(30)
(31)

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

GP
object
Text GP ind
no-object
Text GP ind
object
Text GP corr
no-object
Text GP corr
object
Door GP ind
no-object
Door GP ind
object
Door GP corr
no-object
Door GP corr

SE kernel 
5.5
16.2
4.2
4.6
0.52
54.3
0.002
9303

SE kernel l
0.15
0.23
0.14
0.09
0.58
0.49
0.17
0.31

Table 1: The learned GP parameters. Note that the kernel scale for the door and text differ for the
correlated observation GPs.

Of particular importance to us is the fact that the posterior covariance has a closed form solution,
is independent from the posterior mean (He et al., 2011), and does not require integrating over all
possible observations Z. We now can compute the posterior covariance after T observations in the
future as
T
X
n+T = (n1 +
Gi bi GTi )1 .
(32)
i=1

Rather than having to marginalize out potential future observations for every future waypoint, we
can compute the variance of our belief after T observations by simply multiplying through the
variance of the observations at each of the future waypoints. Given that our perception field is a
function of the variance in our belief (since the entropy of a normal distribution is a function of the
variance), we can now quickly compute the field for deep observation trajectories. Such efficient
computation allows our planning algorithm to sample potential observation trajectories with many
observations (T  1), thereby increasing the effective search depth of our algorithm and improving
our plans.

7. Objects: Doors and Signs
Our system is in general agnostic to the type of detector employed and even the sensing modality
used. The only constraint is formed by the need to be able to define vantage points (see Section
5.3) to compute a perception field (see Section 3.2). In this work, we chose to test our approach
with two different vision-based object detectors: the first leverages the parts-based object detector
by Felzenszwalb, Mcallester, and Ramanan (2008) trained to find doors; the second detector aims to
spot human-readable text in the world such as commonly found on signs. The use of text-spotting
was inspired by the work of Posner, Corke, and Newman (2010) and the authors kindly provided us
with a C++ software library of the latest incarnation of their text-spotting engine, which provides
detection and parsing facilities for individual words in natural scene images.
The door detector was trained on approximately 1400 positive and 2000 negative examples
from manually labeled images collected from a large range of indoor areas excluding our testing
environment. Performance on images from the testing environment was low due to false positives
triggered by visual structures not present in the training images. The detector could be re-trained to
442

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.31 0.06
0.44 0.07
67.08 2.23
50

G REEDY=0.6
0.60 0.07
0.62 0.07
41.95 0.88
50

P LANNEDdisc
0.75 0.06
0.80 0.06
54.98 3.04
50

RTBSS
0.45 0.06
0.58 0.07
47.57 0.19
50

Table 2: Simulation performance on single door scenario, with standard error values.

improve performance, but the problem recurs when new environments are encountered. These same
examples were also used to train both the sensor models of the door detector.
The text detector was trained exactly as described by Posner et al. (2010). The dynamic timevarying sensor model was determined using approximately 1800 positive and 2000 negative examples from manually labeled images collected from an indoor office environment excluding our
testing environment. We used the text detector only to localize text in the environment, and did not
actually use the contents of the text itself.
For the mixture parameter in our dynamic time-varying sensor model, the scale factor  was
chosen as the maximum likelihood estimator using the training data for each detector in the system.
We learned scaling values door = 6.5 and text = 5.4. Table 1 shows the learned GP parameters
for both the door and text detectors.

8. Simulation Results
We first assessed our planning approach using the learned models in a simulated environment. Our
simulation environment consisted of a robot navigating through an occupancy map, with object
detections triggered according to the learned observation model. We also simulated false positives
by placing non-object perceptual features that probabilistically triggered object detections using the
learned model for false-alarms. The processing delay incurred by the actual object detector was also
simulated (the door detector requires approximately 4.5 seconds to process a spatially decimated
512x384 pixel image while the text detector requires 8 seconds to process a full 1024x768 pixel
image).
8.1 Comparison Algorithms
For the simulation trials we compared our algorithm against two other algorithms. The G REEDY
algorithm selected the best waypoint according to our perception field for each potential object until the belief of each object exceeded a threshold . Second, we compared our algorithm against
the RTBSS online POMDP algorithm (Paquet, Tobin, & Chaib-draa, 2005). The RTBSS algorithm
could not use our full sensor model because of the Markov assumption and only utilized the independent part of the model. One could augment the state space to include the entire history of
detections  and therefore use our full sensor model, however such a large state space would render
the POMDP intractable in practice. We chose a maximum depth equal to that of our algorithm and
modeled the world using a resolution of 2.5 meters for the RTBSS algorithm. We will denote the
algorithm using the static disc sensor model as P LANNEDdisc , and the dynamic time-varying sensor
model as P LANNED.
443

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.64 0.03
0.63 0.02
153.32 4.37
50

G REEDY=0.6
0.54 0.03
0.57 0.03
121.35 1.32
50

P LANNEDdisc
0.53 0.05
0.76 0.03
138.21 7.12
50

RTBSS
0.70 0.03
0.66 0.03
160.74 6.08
50

Table 3: Simulation performance on multiple door scenario, with standard error values.

(a) The small simulation environment used for doors
containing a single object (blue) and two non-object
(black).

(b) The multiple object simulation environment used
for doors containing 4 objects (blue) and 6 nonobjects (black).

Figure 9: The simulation environments for the static disc sensor model of a door detector.
8.2 Static Disc Sensor Model Simulations
First, we tested our P LANNEDdisc algorithm on a small the simulation environment with one door
object shown in Fig. 9(a). Table 2 shows the simulation results for our static disc model of the door
detector. Overall, explicitly planning waypoints resulted in significantly higher performance. The
P LANNEDdisc algorithm performed better than RTBSS in terms of precision and recall, most likely
because our algorithm sampled continuous-space waypoints and the RTBSS algorithm had a fixed
discrete representation, while RTBSS paths were shorter.
We evaluated our P LANNEDdisc algorithm in a larger, more complex scenario containing four
doors and six non-door objects. Fig. 9(b) shows the multiple door simulation environment. Table 3
shows the simulation results for the multi-door scenario. Our P LANNEDdisc algorithm resulted in the
second shortest paths after G REEDY=0.6 but with superior detection performance. P LANNEDdisc
also resulted in significantly shorter paths than RTBSS given the same operating point on the ROC
curve.
8.3 Dynamic Time-Varying Sensor Model Simulations
We tested our P LANNED algorithm on both a small simulation with a single text sign and a more
complex simulation environment with two signs shown in Figs. 10 and 11. Table 4 shows the results
of 20 trials using our text detector sensor model in the single object simulation. For text signs, we
444

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
0.37 0.10
0.47 0.12
35.32 1.08
20

P LANNED
0.24 0.06
0.47 0.12
20.40 0.74
20

RTBSS
0.20 0.06
0.40 0.11
18.43 0.43
20

Table 4: Simulation performance on single sign scenario, with standard error values.

see that our deep trajectory planning does not help very much (compare the G REEDY strategy with
the Planned strategy which had a planning horizon of 5). The information for the text detector
was spread out smoothly (see the perception field Fig. 6(a)) hence the greedy strategy was the best
thing to do. However, our planner took into account cost and so resulted in lower precision-recall
performance but much shorter path length. We also saw that our correlation sensor model allowed
our planned algorithm to perform better than RTBSS. The belief updates predicted by RTBSS were
overconfident hence the RTBSS algorithm resulted in shorter path lengths but worse precision-recall
performance than our planned-waypoints algorithm.

Figure 10: The small simulation environment used for text signs containing a single object (blue)
and a single non-object (black).

Next, we evaluated our P LANNED algorithm in a more complex scenario containing two objects
and two non-objects shown in Fig. 11. Table 5 shows the simulation results for the multiple-object
scenario. The P LANNED algorithm resulted in the best precision-recall performance with short path
length. RTBSS also resulted in short path length, but because of the lack of a correlation model
became overconfident in its belief, performing significantly worse than the planned-waypoints algorithm in terms of precision-recall.
Fig. 11 also shows the density of all trajectories traversed by each algorithm for all simulations
run. Brighter spots denote places where the simulated robot frequented during the simulation runs.
We see that the P LANNED algorithm kept the robot close to the shortest path because of our cost
function, as does RTBSS. However, our P LANNED algorithm decided to spread detections apart
because of the correlation model employed whereas RTBSS over-valued the information gained
from nearby observations. The G REEDY algorithm did not take into account the motion cost for
taking an observation and so we saw a widespread set of trajectories and waypoints being visited
during the simulations.
445

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
0.23 0.06
0.28 0.08
66.72 1.39
20

P LANNED
0.93 0.05
0.72 0.07
33.80 1.00
20

RTBSS
0.54 0.11
0.43 0.09
23.32 0.63
20

Table 5: Simulation performance on multiple signs scenario, with standard error values.

(a) G REEDY Trajectories

(b) P LANNED Trajectories

(c) RTBSS Trajectories

Figure 11: The multiple object simulation environment used for text containing 2 objects (blue) and
2 non-objects (red). Shown are the density of paths taken by the different algorithms
during all simulation trials. The planned approach results in a narrower space of paths
than G REEDY while avoiding nearby (correlated) observations.

8.4 Time Improvements Because of PBD
We ran a comparison between updating our perception field using the PBD algorithm (see Section
6.2) and an update which requires computing the expectation over possible detector outputs. We
created a histogram of potential detector values with either 100 or 10 bins and used these sampled
to compute the expected mutual information gain (the perception field) for each of those detector
output bins. Table 6 shows the results of computing a perception field 100 times. The PBD algorithm
allowed us to efficiently calculate the perception field since we did not have to explicitly iterate over
the possible detector values but could use Equ. 32.
Updating the perception field was the most time-consuming part of our algorithm since it must
be updated when reasoning about future observations during planning. The total run-time was
determined by how many trajectories were sampled using the perception field and the depth of these
future trajectories, both of which could be tuned to a particular scenario and application. In this
paper we let the planning algorithm sample and evaluate trajectories until the same amount of time
as running the object detector on a single image had passed.
446

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

min
avg
max

100 bins for z
4.17s
4.58s
4.97s

10 bins for z
1.17s
1.20s
1.22s

PBD
0.85s
0.85s
0.87s

Table 6: Timing results for computing a perception field using either the PBD algorithm, or explicitly enumerating potential detector values z and computing the expectation over these
values.

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.53 0.14
0.60 0.14
153.86 33.34
10

P LANNEDdisc
0.7 0.15
0.7 0.15
91.68 15.56
10

Table 7: Results of door real-world trials using robot wheelchair, with standard error values.

(a) Trajectory executed on the actual robot wheelchair using planned-waypoints
from S to G where the robot discovers one true door (cyan). Near the goal,
it detects two more possible doors (red dots), detours to inspect them, and (correctly) decides that they are not doors.

(b) Robotic wheelchair
platform

Figure 12: Real world trial of door detector using robotic wheelchair platform

9. Results For Real World Trials
Finally, we validated the results of the P LANNEDdisc and P LANNED algorithms on a robot wheelchair
platform (Fig. 12(b)). Our autonomous wheelchair was equipped with onboard laser range scanners,
primarily used for obstacle sensing and navigation, a Point Grey Bumblebee2 color stereo camera,
and an quad-core laptop as the main processing unit. The stereo camera was used to accurately
determine the vantage point for a particular detection. Both door and textual signs were planar, so
447

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

we fit a plane to the detection bounding box and 3D points from the stereo camera to determine the
orientation of the possible object given a detection.
For both door and text real world trials, the robot started at a particular location and orientation.
The robot was then given the same goal position such that a nominal trajectory would bring it past
one true object (a door or a text sign), and near several fixtures which trigger object detections.
Initially, the system had no object hypothesis and the detector was run continuously as it moved
towards the goal in the shortest path. As the object detector fired, the system started reasoning
about the object hypothesis corresponding to the detections. The robot deviated from the shortest
path to take observations for certain object hypothesis as determined by the cost function. Finally,
the robot reached the goal and the trial ended. The object hypothesis were accepted if the belief
was greater than 0.5. The cost of an incorrect decision was set to be 16 times the cost of a meter in
path length, and the cost for a correct decision was set to be the negative of an incorrect decision.
All trials were capped at 20 minutes and were done in a real office environment without special
accommodations to be as realistic as possible.
Fig. 12(a) shows the location of the door trials. The robot always started at the start location
(marked by S) and was given the same goal location (G). There was a single door which could
be seen from the path from start to the goal. Near the goal there were also a set of windows and light
fixtures which often caused the door detector to fire. Fig. 12(a) illustrates the trajectory executed
during a single trial of the P LANNEDdisc algorithm, and Table 7 summarizes the results of all trials
for doors. G REEDY=0.8 was chosen as a baseline comparison since it was the best performing of
the existing algorithms according to Table 3. Our P LANNEDdisc algorithm resulted in significantly
shorter trajectories while maintaining comparable precision and recall. For doors detected with substantial uncertainty, our algorithm planned more advantageous waypoints to increase its confidence
and ignored far away detections because of high motion cost. It is interesting to see in Fig. 12(a) how
our algorithm deviated to take observations of the false detections near the goal location, ultimately
correctly deciding that those object hypothesis were in fact not doors.
We similarly conducted an experiment using the P LANNED algorithm and G REEDY=0.7 on the
same robotic wheelchair platform with the text detection algorithm. The robot was given a nominal
trajectory which brought it past a single textual sign (a poster with an office number on it placed at
a common location for poster notifications). The trials were run during the daytime hours to allow
for both artificial as well as natural lighting and common environmental changes such as people
walking by the robot. Table 8 summarizes the results of 5 real-world trials with both algorithms.
We see that the G REEDY algorithm outperformed P LANNED in terms of precision (consistent with
our simulation results) but had much longer path lengths. The P LANNED algorithm balanced the
cost of gaining new observations against the travel time and resulted in much shorter trajectories.
The large path-length associated with the greedy algorithm came from two sources: first, the greedy
algorithm did not take path cost into account when deciding the next observation to take, and second
the greedy algorithm kept taking pictures of all object hypothesis until the belief was above a certain
threshold  this included any sporadic object detections caused by lights or temporary environment
noise.
Lastly, we ran a small set of 3 trials using the P LANNED algorithm looking for text signs in a
completely different environment than the previous trial. Here we ran the trials at night with very
few people walking by. Table 9 shows the results. Even in a different environment, the algorithms
behaved similarly, with the G REEDY algorithm outperforming our P LANNED algorithm at the cost
of much longer paths.
448

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
1 0
1 0
102.77 7.21
5

P LANNED
0.70 0.09
0.80 0.09
34.86 5.29
5

Table 8: Results of text real-world trials using robot wheelchair.
Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
1 0
1 0
39.2047  2.76
3

P LANNED
0.33 0.33
1 0
17.5351 4.35
3

Table 9: Results of small text real-world trials in a different location using robot wheelchair.

10. Related Work
The problem of planning motion trajectories for a mobile sensor has been explored by a number
of domains including planning, sensor placement, active vision and robot exploration. The most
general formulation is the partially observable Markov decision process (Sondik, 1971). Exact
solutions to POMDPs are computationally intractable, but recent progress has led to approximate
solvers that can find good policies for many large, real-world problems (Pineau, Gordon, & Thrun,
2006; Smith & Simmons, 2005; Kurniawati, Hsu, & Lee, 2008; Kurniawati, Du, Hsu, & Lee, 2010).
However, the complexity of representing even an approximate POMDP solution has led to forward
search strategies for solving POMDPs (Ross et al., 2008; Prentice & Roy, 2009; He et al., 2010).
Eidenberger and Scharinger (2010) formulate the problem of choosing sensor locations for active
perception as a POMDP very similar in spirit to our formulation. However, they explicitly model the
underlying physics of the object generation, model the uncertainty in the object location rather than
object type, and are also unable to plan more than one step into the future, and therefore the work is
most similar to the G REEDY strategies described in previous sections. Our approach is inspired by
the forward search POMDP algorithms, but incorporates a more complex model that approximates
the correlations between observations.
In contrast to POMDP models of active sensing, the controls community and the sensor placement community have developed information-theoretic models, where the goal is only to minimize a
norm of the posterior belief, such as the entropy. This objective function does not depend on the motion costs of the vehicle, and is sub-modular (Krause & Guestrin, 2007). As a consequence, greedy
strategies that choose the next-most valuable measurement can be shown to be boundedly close
to the optimal, and the challenge is to generate a model that predicts this next-best measurement
(Guestrin, Krause, & Singh, 2005; Krause, Leskovec, Guestrin, VanBriesen, & Faloutsos, 2008).
In terms of image processing and object recognition, Denzler and Brown (2002) and Sommerlade
and Reid (2010) showed that information-theoretic planning could be used to tune camera parameters to improve object recognition performance and applied to multi-camera systems, although their
use of exhaustive search over the camera parameters rapidly becomes unwieldy. Lastly, Sridharan, Wyatt, and Dearden (2008) showed that by formulating an information-theoretic problem as
a decision-theoretic POMDP, true multi-step policies did improve the performance of a computer
449

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

vision system in terms of processing time. However, all of these previous algorithms use models for
sequential decision making where the costs of the actions are independent (or negligible), leading
to a submodular objective function and limited improvement over greedy strategies.
There has been considerable work in view point selection in active vision which we briefly
review here. A few relevant pieces of work include that by Arbel and Ferrie (1999) and more
recently Laporte and Arbel (2006) who use a Bayesian approach to model detections that is related
to ours, but only searches for the next-best viewpoint, rather than computing a full plan. The work
of Deinzer, Denzler, and Niemann (2003) is perhaps most similar to ours in that the viewpoint
selection problem is framed using reinforcement learning, but again the authors neglect costs for
camera movement and identify the absence of costs as a limitation of their work. Similarly, the
system by Mittal and Davis (2008) learns a model of object occlusion and uses simulated annealing
to solve for the optimal plan; the contribution is to learn a predictive model of good viewpoints. The
work by Borotschnig, Paletta, Prantl, and Pinz (2000) uses an appearance-based object detection
system to plan viewpoints that minimize the number of observations required to achieve a certain
recognition rate, but does not account for correlations in the different observations.
The field of object localization and search has seen some recent advancements. The use of
object to object relations seems like a promising direction as shown in the works of Aydemir, Sjoo,
Folkesson, Pronobis, and Jensfelt (2011) and Joho, Senk, and Burgard (2011). Our approach differs
in that the system uses spatial relations between a single object and multiple observations rather than
between different objects. The works by Joho et al. (2011) and Aydemir, Gobelbecker, Pronobis,
Sjoo, and Jensfelt (2011) model the environment and achieve good results, whereas our system
models the correlation between observations in lieu of modeling the full environment. The idea
of attention seems a powerful tool for visual search (Tsotsos, 1992) with systems such as those
due to Meger, Forssen, Lai, Helmer, McCann, Southey, Baumann, Little, and Lowe (2008) and
Andreopoulos, H., Janssen, Hasler, Tsotsos, and Korner (2011) exhibiting excellent results. Rather
than using attention, our system utilizes the mutual information and minimizes the cost of taking
observations. It is useful to note that while our system minimizes a single cost function which
encodes both information and path costs, Ye and Tsotsos (1999) formalized an approach which
both maximizes the probability of localizing an object and minimizes the cost.
In robot exploration, where the goal is to generate robot trajectories that learn the most accurate
and complete map with minimum travel cost, the costs of motion must be incorporated. Bourgault,
Makarenko, Williams, Grocholsky, and Whyte (2002) developed a full exploration planner that
incorporated an explicit trade-off between motion plans and map entropy. Stachniss, Grisetti, and
Burgard (2005) described a planner that minimized total expected cost, but only performed search
over the next-best action. To address the computational challenge, Kollar and Roy (2008) used
reinforcement learning to both learn a model over the expected cost to the next viewpoint in the
exploration, and minimize the total expected cost of a complete trajectory.
The contribution of our work over the existing work is primarily to describe a planning model
that incorporates both action costs and detection errors, and specifically to give an approximate
observation model that captures the dynamic correlations between successive measurements that
still allows forward-search planning to operate, leading to an efficient multi-step search to improve
object detection.
450

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

11. Conclusion and Future Work
Previous work in planned sensing has largely ignored motion costs of planned trajectories and used
simplified sensor models with strong independence assumptions. In this paper, we presented a sensor model that approximates the correlation in observations made from similar vantage points, and
an efficient planning algorithm that balances moving to highly informative vantage points with the
motion cost of taking detours. We did not fully model the effects of the entire environment on a
sensor  an intractable endeavor. Our sensor model simplifies environment interactions by treating
them as correlations between the entire history of sensor readings. We placed an emphasis on spatial
relations to model the correlations between new sensor readings and the history of previous sensor
readings. Because of the properties of Gaussian Processes, our sensor model allows for efficient
deep trajectory sampling utilizing the Posterior Belief Distribution framework. We tested our algorithm with two different object detectors (doors and signs) and found better detector dependent
observation trajectories than comparable strategies.
The system presented here planned deviations from a particular shortest-path trajectory to a
goal in order to detect and localize objects after they had been spotted once. In the future we aim to
incorporate a large scale spatial model of where object are likely to be before we have encountered
them. Next generation systems will also have to deal with novel objects for which there exists no
prior object detector and for whom a detector must be created on the fly. Our goal is to create
an end-to-end online adaptive semantic mapping solution which works for arbitrary objects and
environments.

References
Andreopoulos, A., H., W., Janssen, H., Hasler, S., Tsotsos, J., & Korner, E. (2011). Active 3d object
localization using asimo. IEEE Transactions on Robotics, 27(1), 4764.
Anguelov, D., Koller, D., Parker, E., & Thrun, S. (2004). Detecting and modeling doors with mobile
robots. In Proc. ICRA.
Arbel, T., & Ferrie, F. P. (1999). Viewpoint selection by navigation through entropy maps. In Proc.
ICCV, Kerkyra, Greece.
Aydemir, A., Sjoo, K., Folkesson, J., Pronobis, A., & Jensfelt, P. (2011). Search in the real world:
Active visual object search based on spatial relations. In Proc. ICRA.
Aydemir, A., Gobelbecker, M., Pronobis, A., Sjoo, K., & Jensfelt, P. (2011). Plan-based object
search and exploration using semantic spatial knowledge in the real world. In Proc. ECMR,
Orebro, Sweden.
Borotschnig, H., Paletta, L., Prantl, M., & Pinz, A. (2000). Appearance-based active object recognition. Image and Vision Computing, 18(9), 715727.
Bourgault, F., Makarenko, A. A., Williams, S. B., Grocholsky, B., & Whyte, D. H. F. (2002). Information based adaptive robotic exploration. In Proc. IROS, EPFL, Lausanne.
Coates, A., & Ng, A. Y. (2010). Multi-camera object detection for robotics. In Proc. ICRA.
Deinzer, F., Denzler, J., & Niemann, H. (2003). Viewpoint selection - planning optimal sequences
of views for object recognition. In Proc. ICCV. Springer.
451

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Denzler, J., & Brown, C. M. (2002). Information theoretic sensor data selection for active object
recognition and state estimation. IEEE Trans. Pattern Analysis and Machine Intelligence,
24(2), 145157.
Douillard, B., Fox, D., & Ramos, F. (2008). Laser and vision based outdoor object mapping. In
Proc. RSS.
Eidenberger, R., & Scharinger, J. (2010). Active perception and scene modeling by planning with
probabilistic 6d object poses. In Proc. IROS.
Felzenszwalb, P., Mcallester, D., & Ramanan, D. (2008). A discriminatively trained, multiscale,
deformable part model. In Proc. CVPR.
Guestrin, C., Krause, A., & Singh, A. (2005). Near-optimal sensor placements in Gaussian Processes. In Proc. ICML.
He, R., Brunskill, E., & Roy, N. (2010). PUMA: Planning under uncertainty with macro-actions. In
Proc. AAAI, Atlanta, GA.
He, R., Brunskill, E., & Roy, N. (2011). Efficient planning under uncertainty with macro-actions.
Journal of Artificial Intelligence Research, 40, 523570.
Joho, D., Senk, M., & Burgard, W. (2011). Learning search heuristics for finding objects in structured environments. Robotics and Autonomous Systems, 59(5), 319328.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning and acting in partially observable
stochastic domains. Artificial Intelligence, 101, 99134.
Kollar, T., & Roy, N. (2008). Trajectory optimization using reinforcement learning for map exploration. International Journal of Robotics Research, 27(2), 175197.
Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.
In Proc. AAAI.
Krause, A., Leskovec, J., Guestrin, C., VanBriesen, J., & Faloutsos, C. (2008). Efficient sensor
placement optimization for securing large water distribution networks. Journal of Water Resources Planning and Management, 134, 516.
Kurniawati, H., Du, Y., Hsu, D., & Lee, W. (2010). Motion planning under uncertainty for robotic
tasks with long time horizons. International Journal of Robotics Research, 30(3).
Kurniawati, H., Hsu, D., & Lee, W. (2008). SARSOP: Efficient point-based POMDP planning by
approximating optimally reachable belief spaces. In Proc. RSS.
Laporte, C., & Arbel, T. (2006). Efficient discriminant viewpoint selection for active bayesian
recognition. International Journal of Computer Vision, 68(3), 267287.
Martinez-Mozos, O., Stachniss, C., & Burgard, W. (2005). Supervised Learning of Places from
Range Data using Adaboost. In Proc. ICRA.
Meger, D., Forssen, P., Lai, K., Helmer, S., McCann, S., Southey, T., Baumann, M., Little, J., &
Lowe, D. (2008). Curious george: An attentive semantic robot. Robotics and Autonomous
Systems, 56(6), 503511.
Mittal, A., & Davis, L. (2008). A general method for sensor planning in multi-sensor systems:
Extens ion to random occlusion. International Journal of Computer Vision, 76, 3152.
452

fiM ODELLING O BSERVATION C ORRELATIONS F OR ROBUST O BJECT D ETECTION

Newman, P., Sibley, G., Smith, M., Cummins, M., Harrison, A., Mei, C., Posner, I., Shade, R.,
Schroeter, D., Murphy, L., Churchill, W., Cole, D., & Reid, I. (2009). Navigating, recognising and describing urban spaces with vision and laser. International Journal of Robotics
Research, 28(11-12).
Paquet, S., Tobin, L., & Chaib-draa, B. (2005). Real-time decision making for large POMDPs. In
18th Canadian Conference on Artificial Intelligence.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations for large
POMDPs. Journal of Artificial Intelligence Research, 27, 335380.
Posner, I., Corke, P., & Newman, P. (2010). Using text-spotting to query the world. In Proc. IROS.
Posner, I., Cummins, M., & Newman, P. (2009). A generative framework for fast urban labeling
using spatial and temporal context. Autonomous Robots, 26(2), 153170.
Prentice, S., & Roy, N. (2009). The belief roadmap: Efficient planning in belief space by factoring
the covariance. International Journal of Robotics Research, 8(11-12), 14481465.
Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes for Machine Learning. MIT
Press.
Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms for POMDPs.
Journal of Artificial Intelligence Research, 32(1), 663704.
Smith, T., & Simmons, R. (2005). Point-based POMDP algorithms: Improved analysis and implementation. In Proc. UAI.
Sommerlade, E., & Reid, I. (2010). Probabilistic surveillance with multiple active cameras. In Proc.
ICRA.
Sondik, E. J. (1971). The Optimal Control of Partially Observable Markov Processes. Ph.D. thesis,
Stanford University.
Sridharan, M., Wyatt, J., & Dearden, R. (2008). HiPPo: Hierarchical POMDPs for planning information processing and sensing actions on a robot. In Proc. ICAPS.
Stachniss, C., Grisetti, G., & Burgard, W. (2005). Information gain-based exploration using RaoBlackwellized particle filters. In Proc. RSS, Cambridge, MA, USA.
Takeda, H., & Latombe, J. (1992). Sensory uncertainty field for mobile robot navigation. Proc.
ICRA.
Tsotsos, J. K. (1992). On the relative complexity of active vs. passive visual search. International
Journal of Computer Vision, 7(2), 127141.
Velez, J., Hemann, G., Huang, A., Posner, I., & Roy, N. (2011). Planning to perceive: Exploiting
mobility for robust object detection. In Proc. ICAPS, Freiburg, Germany.
Ye, Y., & Tsotsos, J. (1999). Sensor planning for 3d object search. Computer Vision and Image
Understanding, 73(2), 145168.

453

fiJournal of Artificial Intelligence Research 44 (2012) 335-382

Submitted 03/12; published 06/12

Plan-based Policies for Efficient Multiple Battery Load Management
Maria Fox
Derek Long
Daniele Magazzeni

MARIA . FOX @ KCL . AC . UK
DEREK . LONG @ KCL . AC . UK
DANIELE . MAGAZZENI @ KCL . AC . UK

Department of Informatics
Kings College London
Strand, London WC2R 2LS, UK

Abstract
Efficient use of multiple batteries is a practical problem with wide and growing application.
The problem can be cast as a planning problem under uncertainty. We describe the approach we
have adopted to modelling and solving this problem, seen as a Markov Decision Problem, building
effective policies for battery switching in the face of stochastic load profiles.
Our solution exploits and adapts several existing techniques: planning for deterministic mixed
discrete-continuous problems and Monte Carlo sampling for policy learning. The paper describes
the development of planning techniques to allow solution of the non-linear continuous dynamic
models capturing the battery behaviours. This approach depends on carefully handled discretisation of the temporal dimension. The construction of policies is performed using a classification
approach and this idea offers opportunities for wider exploitation in other problems. The approach
and its generality are described in the paper.
Application of the approach leads to construction of policies that, in simulation, significantly
outperform those that are currently in use and the best published solutions to the battery management problem. We achieve solutions that achieve more than 99% efficiency in simulation compared
with the theoretical limit and do so with far fewer battery switches than existing policies. Behaviour
of physical batteries does not exactly match the simulated models for many reasons, so to confirm
that our theoretical results can lead to real measured improvements in performance we also conduct
and report experiments using a physical test system. These results demonstrate that we can obtain
5%-15% improvement in lifetimes in the case of a two battery system.

1. Introduction
In this paper we describe an application of planning to the important problem of multiple battery
management. The paper is an extended and developed version of work originally presented at the
International Conference on Automated Planning and Scheduling (Fox, Long, & Magazzeni, 2011)
and, in particular, adds physical results to the work described in that paper.
An increasing number of systems depend on batteries for power supply, ranging from small mobile devices to very large high-powered devices such as batteries used for local storage in electrical
substations. In many of these systems there are significant user-benefits, or engineering reasons, to
base the supply on multiple batteries, with load being switched between batteries by a control system. In order to power such systems for the longest time possible, it is necessary to devise switching
strategies that extract the maximum possible lifetime out of the batteries. We show how planning is
used as the basis of a highly efficient switching strategy.
Due to the physical and chemical properties of batteries, it is possible to extract a greater proportion of the energy stored in a single battery of capacity C than of that stored in n batteries each
c
2012
AI Access Foundation. All rights reserved.

fiF OX , L ONG & M AGAZZENI

of capacity C/n, for n > 1. Throughout this paper, when we refer to the efficiency of a switching
strategy in the use of multiple batteries, we are talking about the proportion of the charge we extract
from the batteries to service a load, compared with servicing the same load from a single battery
with capacity equal to the combined collection of batteries and equivalent physical properties. If
this proportion is very high, for example: over 90%, then the switching strategy can be considered
highly efficient.
The key to efficient use of multiple batteries lies in the design of effective policies for the
management of the switching of load between them. We are concerned with the situation in which
the load can be serviced entirely by one of a suite of batteries at a time, so that the charge of that
battery drains while the other batteries charge levels remain static. This problem is distinct from
the problem of managing cells within a single battery, where the objective is usually to keep the
charge in the cells level. Batteries exhibit the phenomenon of recovery, which is a consequence of
the chemical properties of a battery: as charge is drawn from a battery, the stored charge is released
by a chemical reaction, which takes time to replenish the charge. In general, charge will be drawn
from a battery faster than the reaction can replenish it and this can lead to a battery appearing to
become dead when, in fact, it still contains stored charge. Therefore, more efficient use of multiple
batteries can be achieved by exploiting recovery. By allowing the battery to rest, the reaction can
replenish the charge and the battery become functional once again. Thus, efficient use of multiple
batteries involves carefully timing the use and rest periods. Determining this timing can be seen as
a planning problem.
The paper is organised as follows. We begin by presenting the multiple battery usage problem
in detail, and describing the battery model we use.
In Section 4 we describe the approach we have adopted for solving the deterministic version of
the problem, where we assume that we know the load profile to service. We provide a PDDL +
encoding of the problem and we describe a planning technique for dealing with the continuity
involved in the domain. We complete this section by comparing the performance of plan-based
solutions with the best policies currently considered for multiple battery management.
In Section 5 we show how the high quality plans obtained for the deterministic problems can
be used to learn an efficient policy for the general case where the load profiles are not known in
advance. We describe the classification process we have used and we evaluate the performance of
the policy when servicing stochastic load profiles. Related work is then discussed in Section 6.
In Section 7 we present the details of a physical experiment, using 6 Volt lead acid batteries,
which we conducted in order to confirm our simulation results. We describe the experimental setup
and, in the interests of reproducibility, the parameter estimation process we have followed. We then
report our experimental results and discuss their significance.
Section 8 outlines our plans for future work and Section 9 concludes the paper.

2. Motivations
Many electrically powered systems rely on large, heavy batteries to supply adequate levels of power
and current. If the power requirements of these devices can be supplied by multiple lightweight
batteries, coordinated to supply the same load as would typically be supplied by a much larger
battery, this could significantly change the way these devices are used and the range of applications
to which they might be suited.
336

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Examples of powered systems that could benefit from distribution of the battery power include
externally powered electric prosthetics. Prostheses powered by electric motors can be more functional and more attractive than body-powered prosthetics, but they can be heavy and expensive. The
power requirements of a capable prosthetic arm, combining an elbow with a dexterous hand, necessitate a large, and hence heavy, battery. The high torque motors required to drive a prosthetic elbow
require high voltages and current, while modern dexterous hands require significantly more current
than did the traditional single-motor electric hands.
While a primitive prosthetic arm could run both the elbow and the hand on a 1 Amp Hour battery,
dexterous hands require batteries with as much as 2 Amp Hour capacities, and if the hand and the
elbow are to be run off the same battery, then even more current and larger capacities are needed
with a consequent increase in weight and heat. The high power demand requires that either multiple
batteries are carried or batteries are frequently recharged or replaced. The weight of externally
powered prostheses is a common source of dissatisfaction amongst users and the placement of
batteries to minimise the weight effects is an important part of the prosthetic design. If the battery
power can be distributed around the body, with the power requirements being met by carefully
coordinated multiple independent batteries of the same power but much smaller capacity, then the
weight issue can be made less significant to the user, and the heat generated by the batteries can also
be reduced making them more comfortable to wear.
The same benefits can potentially be obtained in any situation where batteries have to be carried in order to power portable electrical devices. Military personnel currently carry about 20kg of
batteries into the field to power their communication equipment, vision and sensing systems and
other electronic devices. Robotic devices are often battery powered and rely on carrying large numbers of batteries to maximise operational lifetime. Electric cars typically carry multiple batteries,
although they must sometimes be used in series to maximise power availability. This creates different constraints on the way they can be used from those we consider in this paper. However, as the
technology develops, opportunities will arise for exploiting partitioned batteries in electric vehicles.
One of the advantages of being able to distribute battery power across multiple independent
batteries is the ability to swap batteries out as they die, requiring a few small battery spares to be
carried instead of one large one. This hot-swapping capability could have an important role to
play in mobile computing devices where, instead of having to recharge the battery every 6 hours or
so, continuous power over a longer period could be achieved by selectively replacing spent cells.
The major motivation for the work we have done is therefore to obtain close-to-optimal battery
performance for high-powered devices, while benefitting from the ability to distribute the weight
and heat production.

3. The Multiple Battery Usage Problem
The multiple battery usage planning problem has been explored by several authors, from an electrical engineering perspective, for example in the work of Benini et al. (2003) and Rao et al. (2003),
and also from a scheduling perspective (Jongerden, Haverkort, Bohnenkamp, & Katoen, 2009) and
an optimisation perspective (Wang & Cassandras, 2011) (in the latter, the simplifying assumption
that load can be shared arbitrarily between batteries is made). Benini et al. construct a very accurate
battery model, parameterising it to capture lithium-ion, cadmium-nickel and lead-acid battery types,
and show how hand constructed policies can achieve efficiency, relative to a single battery, between
70% and 97.5%. To achieve this, the policy is constructed to select a new battery whenever the
337

fiF OX , L ONG & M AGAZZENI

voltage of the battery currently servicing a load drops below a certain threshold. The next battery is
selected according to one of four alternative policies (Benini et al., 2003):
 Vmax : select the battery pack with highest state of charge.
 Vmin : select the battery pack with lowest state of charge.
 Tmax : select the battery pack that has been unused for the longest time.
 Tmin : select the battery that has been unused for the shortest time.
The authors show that Vmax is the best of these policies, tested on up to four batteries. In the general
case of n batteries, the Vmax is referred to as best-of-n.
Jongerden et al. (2009) uses a model checking strategy, based on U PPAAL, to schedule battery
use given a known load profile. The approach is based on the use of a different battery model,
the Kinetic Battery Model, discussed in more detail below. This is a non-linear continuous model
and the authors treat it by discretisation and scheduling to a horizon. This approach allows them
to find highly effective schedules, but it does not scale well because of the need to use a finegrained discretisation of the temporal dimension. It is worth emphasising, since it contrasts with
our approach, that Jongerden et al. work with a fixed size discretisation of time, allowing them to
focus on scheduling the resources (batteries) into the load periods.
In deployed systems, the standard policies are typically static, based on rapid switching between available batteries. In fact, an optimal use of multiple batteries can be achieved theoretically
by switching between them at extremely high frequency, when the behaviour converges on that of a
single battery (Rao et al., 2003). Unfortunately, this theoretical solution is not achievable in practice
because of the losses in the physical process of switching between batteries, as the frequency increases. In fact, switching losses in MOSFETs are approximately linearly dependent on switching
frequency and also on the current being switched (Eberle, 2008). Tmax and Vmax policies applied
at fixed frequencies are the most commonly fielded solutions, but these often achieve less than 80%
efficiency (Benini et al., 2003).
3.1 Objectives
In this paper our objective is to construct policies for multiple battery problems, where load is
modelled probabilistically using known distributions for load size, load duration and load frequency
(or equivalently, the gaps between successive loads). Our primary purpose, in constructing these
policies, is to achieve the longest possible battery lifetime. The best deployed solutions typically
deliver less than 80% efficiency, while the best published solutions deliver less than about 95%
efficiency (our reading suggests that these high values are in simulation rather than in physical
experiments). We show that our approach, based on construction of optimising solutions to Monte
Carlo sampled problem instances and their use in the construction of appropriate policies, produces
robust solutions that deliver better than 99% efficiency in simulation. Furthermore, as a side-effect
of the way in which these solutions are constructed, we achieve this efficiency in lifetime while using
smaller numbers of battery switches than published policies. This beneficial side-effect reduces the
potential switching losses in implementing the policy. We use the Kinetic Battery Model (Manwell
& McGowan, 1993) (KiBaM) as the basis of our construction of optimising solutions and this raises
challenges in the treatment of the non-linear mixed discrete-continuous optimisation problem, as
we discuss below.
338

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

3.2 The Kinetic Battery Model
In the Kinetic Battery Model (Manwell & McGowan, 1993; Jongerden et al., 2009) the battery
charge is distributed over two wells: the available-charge well and the bound-charge well (see Figure 1).



Bound
charge

Available
charge
Charge flow

Load draws
charge

Total charge



Figure 1: Kinetic Battery Model
A fraction c of the total charge is stored in the available-charge well, and a fraction 1  c in the
bound-charge well. The available-charge well supplies electrons directly to the load (i(t)), where
t denotes the time, whereas the bound-charge well supplies electrons only to the available-charge
well. The charge flows from the bound-charge well to the available-charge well through a valve
with fixed conductance, k. Moreover, the rate at which charge flows between the wells depends on
the height difference between the two wells. The heights of the two wells are given by:
h1 =

y1
c

h2 =

y2
1c

where y1 is the the available charge and y2 is the bound charge. When a load is applied to the
battery, the available charge reduces, and the height difference between the two wells grows. When
the load is removed, charge flows from the bound-charge well to the available-charge well until the
heights are equal again. The change in the charge in both wells is given by the following system of
differential equations:
(
dy1
dt = i(t) + k(h2  h1 )
dy2
dt = k(h2  h1 )
with initial conditions y1 (0) = c  C and y2 (0) = (1  c)  C, where C is the total battery capacity.
To describe the discharge process of the battery, as in Jongerden et al. (2009), we adopt coordinates representing the height difference between the two wells,  = h2  h1 , and the total charge in
the battery,  = y1 + y2 . In this new setting y1 = c(  (1  c)).
The change in both wells is then given by the system of differential equations
(
i(t)
d
0
dt = c  k 
d
dt = i(t)
with solutions
339

fiF OX , L ONG & M AGAZZENI

(
k0 t
(t) = ci  1ek0
(t) = C  it
where k 0 = k/(1  c)c, (0) = 0 and (0) = C. The condition for a battery to be empty is
(t) = (1  c)(t).
This model is less sophisticated than that used by Benini et al. (2001), but a comparison of battery models by Jongerden and Haverkort (2009) concludes that the Kinetic Battery Model (KiBaM)
is the best for performance modelling.
3.3 Battery Usage Planning
Although the battery load management can be seen as a scheduling problem, the setting we consider
makes it a planning problem. For a given a load profile to service, if we knew the number of
switching actions between batteries that would be required, but not the times at which these actions
should be performed, then the problem could be managed as a scheduling problem. In our case,
however, the number of switching actions cannot be identified in advance, as each period of load
can be shared arbitrarily between different batteries. Thus, the battery load management becomes
a planning problem. By discretising time to the shortest time over which a battery must be in
use, it is possible to construct a scheduling problem in which the maximum possible number of
battery switches is considered, where some of the switches might not be used. The difficulty in this
approach is that the shortest period of use can be very short compared with the battery lifetime:
in our physical experiments (Section 7), for example, the maximum number of switches would be
over 700, while for larger capacity batteries or smaller loads the number of switches could easily be
several thousand. The scheduling approach used by Jongergen et al. (2009) cannot scale to manage
more than a few tens of intervals.
Furthermore, the KiBaM, which is a deterministic non-linear continuous model of battery performance, lends itself, in principle, to use in an optimisation problem solver that can find the best
battery usage plan, given a load profile. The multiple battery usage problem, in its deterministic
form, is clearly an optimisation problem and Wang and Cassandras (2011) have shown that, under
certain assumptions, it can be tackled analytically (despite being non-linear), using the KiBaM. In
order to do so they assume that load can be split arbitrarily between batteries (which is not easily
achievable in practice). They also assume that the load can be serviced in an arbitrary schedule
within a given timespan, provided that the total charge drawn from the batteries meets a required
workload. This second assumption is not consistent with our own situation, in which load must be
serviced according to demands placed by a user at specific times, without flexibility. Unfortunately,
their analysis cannot be modified to deal with the situation we consider.
It is of interest to speculate on whether a standard Operations Research approach, using some
form of Mixed-Integer Linear Program (MILP) model, might be used to solve the deterministic
multiple battery usage problem. At first glance the answer is trivial: since the model is non-linear, it
is clear that a MILP cannot be used. A more sophisticated approach might be considered, using an
approximation of the exponential recovery curves using piece-wise linear components. However,
because the precise shape of these recovery curves depends on the state of charge of the battery
at the start of the period of recovery (both its available and bound parts), the approximations must
either be built dynamically, or else the model must anticipate all possible states of charge at all
times points, effectively building the entire search space of the states of charge of the battery into
340

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

the model. The former approach cannot be achieved in a standard MILP and we are not aware of any
solving technology that could manage this approach; the latter approach is obviously impractical for
anything but the most trivial of situations.
In most real battery usage problems the load profile is generated by external processes, typically
controlled directly or indirectly by user demands. These demands can often be modelled probabilistically, reflecting typical patterns of use. In our work we assume that the profiles are drawn from
a known distribution. The consequence is that the planning problem ceases to be a deterministic
optimisation problem, but a probabilistic problem in which the plan must be a policy, as discussed
in Section 5.
3.4 Our Approach
We adopt an approach based on a combination of two ideas. Firstly, we sample from the distribution
of loads to arrive at a deterministic problem, which we then solve using the continuous KiBaM as
our battery model. This leads to an interesting continuous non-linear optimisation problem, which
we solve using a discretise-and-validate approach. Currently we are using UPMurphi (Della Penna,
Intrigila, Magazzeni, & Mercorio, 2009) to solve the deterministic instances but, after discretisation,
any metric temporal planner could be used in principle. Secondly, we use a decision tree classifier to
combine the solutions to the sample problem instances and learn a policy for the MDP from which
the problems are drawn. The classification process maps states into actions and produces a policy
in the form of a decision tree.
Our approach is domain-specific in some respects:
 Our discretisation scheme, while based on general principles, is selected for the problem
domain and load distribution.
 We use a search heuristic that, while not restricted to the battery problem alone, is not suited
to all problems.
 The aggregation of solutions into a policy makes use of an entirely general approach, but the
extent to which the approach yields good policies will depend on the nature of the problem
space in which it is applied.
We make use of existing tools as far as is possible, to simplify the construction of our solution.

4. Solving Deterministic Multiple Battery Problems
In this section we consider the multiple battery management problem as an optimisation problem,
when faced with a known and deterministic load profile.
4.1 A PDDL + Battery Model
P DDL + (Fox & Long, 2006) is an extension of the standard planning domain modelling language,
PDDL , to capture continuous processes and events. The dynamics of KiBaM can be captured very
easily in PDDL +. In Figure 2 we show the two processes, consume and recover, that govern
the behaviour of batteries and the event triggered by attempting to load a battery once its available
charge is exhausted. In addition, there is a durative action of variable duration that allows the
planner to use a battery over an interval (see Figure 3). The two processes are active whenever their
341

fiF OX , L ONG & M AGAZZENI

preconditions are satisfied, meaning that they usually execute concurrently. Together, they model
both the draining of charge and the recovery that are described in the differential equation d/dt.
An event is triggered if there is ever a positive load and no active service.
(:process consume
:parameters (?b - battery)
:precondition (switchedOn ?b)
:effect (and (decrease (gamma ?b) (* #t (load)))
(increase (delta ?b) (* #t (/ (load) (cParam ?b)))))
)
(:process recover
:parameters (?b - battery)
:precondition (>= (delta ?b) 0)
:effect (and (decrease (delta ?b) (* #t (* (kprime ?b) (delta ?b)))))
)
(:event batteryDead
:parameters (?b - battery)
:precondition (and (switchedOn ?b)
(<= (gamma ?b) (* (-1 (cParam ?b)) (delta ?b))))
:effect (and (not (switchedOn ?b)) (dead ?b))
)

Figure 2: Part of PDDL + encoding of KiBaM dynamics
(:durative-action use
:parameters (?b - battery)
:duration (>= ?duration 0)
:condition (and (at start (switchedOff ?b))
(over all (switchedOn ?b)))
:effect (and (at start (and (switchedOn ?b) (not (switchedOff ?b))
(increase (services) 1)))
(at end (and (switchedOff ?b) (not (switchedOn ?b))
(decrease (services) 1))))
)

Figure 3: P DDL + durative action for battery use
The load profile to be serviced is encoded in the PDDL + problem through the use of timed initial
literals, which allow expression of exogenous events corresponding, in our case, to changes in the
load value. A fragment of the problem (which also contains the battery specification) is shown in
Figure 4.
The use of PDDL + as our modelling language grants several benefits. Firstly, it allows us to use
VAL (Howey, Long, & Fox, 2004) to validate solutions analytically against the continuous model,
allowing us to confirm that the discretisation we use during construction of solutions does not compromise the correctness of the plan. Secondly, it provides us with a semantics for our model in terms
342

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

(define (problem 2B) (:domain kibam)
(:objects b1 b2 - battery)
(:init
(= (cParam b1) 0.166)
(= (kprime b1) 0.122)
(= (gamma b1) 5.5)
(= (delta b1) 0)
...
(at 0 (= (load) 0.25))
(at 1.00 (= (load) 0.50))
(at 2.00 (= (load) 0.25))
(at 3.00 (= (load) 0.50))
(at 4.00 (= (load) 0.25))
...

Figure 4: Fragment of the PDDL + problem
of a timed hybrid automaton as described by Fox and Long (2006). Finally, we can make use of existing tools that construct and search in spaces defined by PDDL + models, such as UPMurphi (Della
Penna et al., 2009).
In their paper on PDDL +, Fox and Long (2006) propose a semantics based on a mapping to
timed hybrid automata (Alur & Dill, 1994). The semantics of the domain instantiated for two
batteries is given by the three hybrid automata shown in Figure 5, where variables d, g, L and s
refer to PDDL + functions delta, gamma, load and services, respectively. This semantics
is one route by which model-checking systems designed to manage timed hybrid automata can be
adapted to operate directly on the battery problem. The batteries reveal their non-linear behaviour
in the definitions of the expressions governing the rates of change of both d1 and d2 in the pair
of states switchedOnB1 and switchedOffB1 and the equivalent pair for B2. Unfortunately, these
equations are beyond the reach of most current model-checking systems, but by discretising the
ranges of these variables the functions can be managed by UPMurphi.
The variable T is the time-slip variable introduced by Fox and Long (2006) which allows the
correct modelling of PDDL + domains with events in standard hybrid automata. In particular, the
time-slip variable increases at rate 1 whenever the preconditions of the events disaster (positive
load and no battery being used) or notOptimal (a battery being used without any load to service)
are satisfied. Each state in the three hybrid automata has an invariant condition stating that the
time-slip variable must be 0, and this guarantees that the events will be applied as soon as their
preconditions become true, without any action transitions occurring between.
4.2 The Discretise-and-Validate Approach
Our technique is based on a discretise-and-validate approach (see Figure 6), in which the continuous
dynamics of the problem are relaxed into a discretised model, where discrete time steps and corresponding step functions for resource values are used in place of the original continuous dynamics.
This relaxed problem is solved using a forward reachability analysis and then solutions are validated
against the continuous model using the validator, VAL (Howey et al., 2004), which provides analytic
solutions to differential equations involved in the models.
343

fiF OX , L ONG & M AGAZZENI

batteryDeadB1
Inv: T=0
Flow:
d1 = 0 g1 = 0

Jump: g1  (1-c)d1
d1 = d1
g1 = g1
s = s - 1

T= 0 V T = 1
deadB1

useB1stop
Inv: T=0
Flow:
d1 = L/c - kd1
g1 = -L
T= 0 V T = 1
switchedOnB1

Jump: d1 = d1
g1 = g1
s = s - 1

useB1start

T= 0 V T = 1

Inv: T=0
Flow:
L > 0 /\ s = 0
T=1
L = 0 /\ s > 0
T=1
T= 0 V T = 1

switchedOffB1

loadProfile

Inv: T=0
Flow:
d1 = -kd1

Jump: d1 = d1
g1 = g1
s = s + 1
batteryDeadB2
Inv: T=0
Flow:
d2 = 0

g2 = 0

T= 0 V T = 1
deadB2

Jump: g2  (1-c)d2
d2 = d2
g2 = g2
s = s - 1

disaster

notOptimal

Jump: L > 0
s=0

Jump: L = 0
s>0

useB2stop
Inv: T=0
Flow:
d2 = L/c - kd2
g2 = -L
T= 0 V T = 1
switchedOnB2

Jump: d2 = d2
g2 = g2
s = s - 1

Inv: T=0
Flow:

Inv: T=0
Flow:
d2 = -kd2
T= 0 V T = 1

useB2start

T= 0 V T = 1
notSatisfactory
service

switchedOffB2

Jump:

Figure 5: Hybrid automata modelling two kinetic batteries scheduling

Continuous Model

Discretise

Solve

Validate

Figure 6: The Discretise and Validate Approach

The validation process is used to identify whether a finer discretisation is required and guide
remodelling of the relaxed problem. As an example, in our simulation, we first considered a time
discretisation t = 0.1, and obtained the plan shown in Figure 7 (left). However, when we validated
the discrete solution generated by the planner against the continuous model, we found out that the
solution was indeed not valid, as highlighted in the following fragment of the VAL report:

Checking
Updating
Updating
Updating

next happening (time 5.08986)
(gamma b1) (0.502404) by 0.337447 assignment
(delta b1) (0.328362) by 0.550475 assignment
(delta b2) (0.405504) by 0.257052 assignment

EVENT triggered at (time 5.08986)
Triggered event (batterydead b1)
Deleting (switchedon b1)
Adding (dead b1)
Invariant for (use b1) has its condition unsatisfied
between time 5.08986 to 5.1.
344

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

0.0:
3.40:
3.90:
4.00:
4.50:
5.10:
5.30:
5.60:
5.80:
6.10:
6.80:
7.00:
8.30:
8.50:
8.70:

(use b1)
[3.40]
(use b2)
[0.50]
(use b1)
[0.10]
(use b2)
[0.50]
(use b1)
[0.60]
(use b2)
[0.20]
(use b1)
[0.30]
(use b2)
[0.20]
(use b1)
[0.30]
(use b2)
[0.70]
(use b1)
[0.20]
(use b2)
[1.30]
(use b1)
[0.20]
(use b2)
[0.20]
(satisfied)

0.0:
3.40:
3.90:
4.00:
4.50:
5.08:
5.35:
5.43:
6.10:
6.15:
6.55:
6.60:
7.10:
7.15:
8.15:
8.45:
8.65:
8.70:

(use b1) [3.40]
(use b2) [0.50]
(use b1) [0.10]
(use b2) [0.50]
(use b1) [0.58]
(use b2) [0.27]
(use b1) [0.08]
(use b2) [0.57]
(use b1) [0.05]
(use b2) [0.40]
(use b1) [0.05]
(use b2) [0.50]
(use b1) [0.05]
(use b2) [1.00]
(use b1) [0.30]
(use b2) [0.20]
(use b1) [0.05]
(satisfied)

Figure 7: Plans generated using different time discretisations: t = 0.1 (left) and t = 0.01 (right)
The very precise analysis provided by VAL allows us to know the exact value of the charge in
the (simulated) batteries during the execution of the plan. In this example, the charge in battery 1
terminates 0.01014 time units before the time expected with the discretised model. This suggests a
refinement of the discretisation, setting t = 0.01, which eventually produced a valid plan, shown in
Figure 7 (right). As can be seen, the finer discretisation handles very sensitive interactions and the
system switches to battery 2 when charge in battery 1 is almost fully drained (at time point 5.08).
Although Jongerden et al. (2009) also use a discretisation approach, they fix the granularity of
the time-step in advance. In contrast, we use a variable sized discretisation, by allowing a range of
alternative step sizes to be considered during search.
We now introduce the formal statement of the deterministic version of the problem we are
interested in. A hybrid system is a system whose state description involves continuous as well as
discrete variables. We approximate the system by discretising the continuous components of the
state (which we assume to be bounded) and their dynamic behaviours so obtaining a finite number
of states.
Definition 1 (Finite State Temporal System) A Finite State Temporal System (FSTS) S is a 5tuple (S,s0 ,A,D,F ), where: S is a finite set of states, s0  S is the initial state, A is a finite set
of actions, D is a finite set of durations and F : S  A  D  S is the transition function, i.e.
F (s, a, d) = s0 iff the system can reach state s0 from state s via action a having a duration d. For
each state s  S, we also define the set EnAct(s)= {a  A|d  D : F (s, a, d)  S}, as the set of
all the actions enabled at state s.
In an FSTS, each state s  S is assumed to contain a special temporal variable t denoting the time
elapsed in the current path from the initial state to s. In the following we use the notation t(s) for
the value of variable t in state s. For all si , sj  S such that F (si , a, d) = sj , t(sj ) = t(si ) + d.
345

fiF OX , L ONG & M AGAZZENI

Definition 2 (Trajectory) A trajectory in the FSTS S = (S, s0 , A, D, F ) is a sequence  =
s0 a0 d0 s1 a1 d1 s2 a2 d2 . . . sn where, i  0, si  S is a state, ai  A is an action, di  D is a
duration and F (si , ai , di ) = si+1 . If  is a trajectory, we write s (i), a (i) and d (i) to denote the
state si , the action ai and the duration di , respectively. Finally, we denote with || the length of ,
P||1
given by the number of actions in the trajectory, and with  the duration of , i.e.  = i=0 d (i).
In order to define the planning problem for such a system, we assume that a set of goal states
G  S has been specified. Moreover, to have a finite state system, we fix a finite temporal horizon,
T, and we require a plan to reach the goal within time T . In the case of the battery usage planning
problem, this horizon is very important because it represents the target duration for the service
provided by the battery. In fact, a good upper bound can be found for the battery problem, which is
discussed further in section 4.3.
Definition 3 (Planning Problem on FSTS) Let S = (S, s0 , A, D, F ) be an FSTS. Then, a planning
problem (PP) is a triple P = (S, G, T ) where G  S is the set of the goal states and T is the finite
temporal horizon. A solution for P is a trajectory   in S s.t.: |  | = n,    T , s (0) = s0 and
s (n)  G.
The constraints we add to the temporal planning problem are parameterised and can be iteratively relaxed in order to explore successively larger spaces for plans. We use a finite collection
of possible durations for segments of processes (Definition 2). This set can be refined by the addition of smaller durations if successive searches fail to find a solution. Allowing different durations
within the same search enables the planner to construct states that interact with executing processes
at different time points, while stepping quickly along the timeline where there are no interesting
features.
4.3 The Monotonicity Property and Planning
The battery domain has an important property that supports a simple heuristic evaluation function
for states: the charge in the battery monotonically decreases over time and the optimal solution is
the one that gives the longest possible plan. An upper bound on the duration of the solution can
be found using the observation that the optimal duration cannot exceed that of a single battery with
combined capacity equal to the sum of the capacities of the multiple batteries (assuming the same
discharging and flow behaviours). Once we have a horizon, we construct and search our discretised
search space. To make this approach practical, it is essential that we have an informed heuristic
to search the space. For this domain, duration of the plan to the current state plus total remaining
charge is admissible, but completely uninformative, while duration plus total available charge is
highly informative. This is also equivalent to minimising the total bound charge.
This heuristic is suitable for a class of domains: in any domain where there is a monotonically
decreasing resource, and the longest plan is required (such as the satellite domain against a finite
amount of resources), a heuristic that sums plan duration and available resource will be informative.
We then use a variant of the best-first search (Algorithm 1) to efficiently explore the reachable
space. To use variable discretisation efficiently, we break the symmetry in the structure of the search
space that arises from the possible orderings of different length action instances. Redundancy is
eliminated by disallowing the use of long duration actions immediately following shorter duration
versions of the same actions. Long duration actions can only be used if an event or other action has
346

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

intervened since the last short action in the family. We also disallow the repeated consecutive use
of short duration actions beyond the accumulated duration of the next longer duration action. The
longest duration action can be repeated arbitrarily often.
Algorithm 1 Dynamic State Space Search (P)
Input: a planning problem P = ((S, s0 , A, D, F ), G, T )
Output: a valid plan  
1: Q  (s0 , null, 0);
2: H  s0 ;
3: if s0  G then return   ;
4: while Q 6=  do
5:
(sh , ai , dk )  argmax(s,a,d)Q h(s);
6:
for all aj  EnAct(sh ) do
7:
if aj 6= ai then   {dl  D|t(sh ) + dl  T };
8:
else   {dl  D|dl  dk  t(sh ) + dl  T };
9:
for all dl   do
10:
s0  F (sh , aj , dl );
11:
if s0  G then return   ;
12:
if s0 
/ H then
13:
Q  Q  (s0 , aj , dl );
14:
H  H  s0 ;

4.4 Plan Search with Variable Discretisation
We now illustrate the way in which the range of differently sized duration intervals can lead to
significant benefits in the size of the set of visited nodes in the search space, compared with using a
fixed duration increment.
Consider the load profile shown at the top of Figure 8. The planning problem for two batteries
is defined according to definitions 1 and 3, with G = {s  S|t(s) = 2.42}, i.e. the goal is to service
the whole load profile. The temporal horizon T is set to the duration of the profile as well. The
definition of the FSTS is straightforward: the set of actions is A = {useB1, useB2, wait} where
the former actions refer to the battery being used while the latter one is applicable when there is no
active service. The set of durations we use for this example is D = {0.01, 0.4, 0.5, 1.0} (measured
in minutes). In practice, to define the set of durations we start with a minimum value and then
we add exponentially increasing values up to a maximum duration given by the longest interval
between different events (i.e., load variations). In particular, the smallest duration is included in
order to handle very sensitive interactions.
In the initial state s0 there is no load and no active service and both batteries have a limited
initial capacity. In this setting, the plan search with variable discretisation proceeds as follows:
1. No battery is used for a period of 1 minute (when the load is idle). The corresponding transition is shown in Figure 8.
2. After one minute a load is applied and battery 1 is used. This corresponds to transition
< s1 , useB1, 1.0, s2 >. However, for sake of simplicity, let us assume that, due to their
347

fiF OX , L ONG & M AGAZZENI

Figure 8: Example of search using variable discretisation
limited capacity, batteries cannot be used continuously for 1 minute. The transition is thus
not valid and a shorter duration has to be considered.
3. Battery 1 is used for 0.5 minute. Then, since a load is still applied, the second battery is used.
As before, the transition < s2 , useB2, 1.0, s3 > can be considered, but in this case there
would be an active service and no load.
4. Battery 2 is used for 0.5 minute. In the next period no load is applied, then no battery is used.
The transition < s3 , wait, 0.5, s4 > is considered, but it would lead to a positive load and
no active service, so the duration of action wait has to be reduced to 0.4.
5. To service the last load period of 0.02 minute, battery 1 could be used. However, in this
sample instance let us assume that the remaining charge in battery 1 allows it to service only
0.01 minute. So, finally, battery 2 is used until the end of the load profile.
The validity of a transition is dynamically checked during the search since invalid transitions
trigger specific events (e.g. event batteryDead is triggered at step 2 and event disaster is
triggered at step 4) which, in turn, violates the invariant conditions of corresponding actions (a
battery must not die during use). Moreover, with variable discretisation only 6 states have to be
visited in order to reach the goal, while using a uniform discretisation it is necessary to explore at
least 242 states since the finest discretisation of 0.01 must be used in order to correctly handle the
interactions in steps 5 and 6.
A further benefit of the use of differently sized durations in the discretisation is that favouring
longer durations reduces the number of switches in the solutions we generate, leading to solutions
that are better in practical terms than those based on a high frequency switching between batteries,
as is shown in subsequent results.
348

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

4.5 Performance on Deterministic Load Problems
We now present a first set of experimental results to show, in simulation, the performance of our
solver on the deterministic battery usage optimisation problem. We use the same case study proposed by Jongerden et al. (2009), where two types of jobs are considered, a low current job (250
mA) and a high current job (500 mA), according to the following load profiles:
 continuous loads: one load with only low current jobs (CL 250), one with only high current
jobs (CL 500) and one alternating between a low current job and a high current job (CL alt);
 intermittent loads with short idle periods of one minute between the jobs: one with only
low current jobs (ILs 250), one with only high current jobs (ILs 500), and one alternating
between a low current job and a high current job (ILs alt);
 intermittent loads with long idle periods of two minutes between the jobs: one with only low
current jobs (ILl 250) and one with only high current jobs (ILl 500).
As a first step, we used these load profiles to validate our variable-range discretisation KiBaM
model (planning-KiBaM), and to find an appropriate discretisation for the continuous variables
involved in the system dynamics (i.e. variables  and  and process durations). To do this we used
VAL to validate solutions for the discretised model against the continuous model. As in the work by
Jongerden et al. (2009), we considered two battery types, one with capacity 5.5 Amin (B1 ) and one
with capacity 11 Amin (B2 ). These are small batteries, typical of the capacities of those in small
portable devices such as PDAs or mobile phones. Both battery types have the same parameters:
c = 0.166 and k 0 = 0.122min1 . We discretised  and , rounding them to 0.00001, and, for all
the load profiles above and for both battery types, we obtained the same lifetimes computed with
the original KiBaM and validated by Jongerden and Haverkort (2008).
To generate the scheduling plans for multiple batteries, we used the approach described in sections 4.2 and 4.3 and the set of durations D = {0.01, 0.02, 0.05, 0.1, 0.25, 0.5, 1.0}.
An example of PDDL + plan is shown in Figure 9, where each row < ti , ai , di > contains the
time point ti in which action ai (whose duration is di ) is applied.
0.0:
1.20:
1.30:
1.80:
2.40:
2.50:
3.10:
4.60:
4.70:
6.20:

(use
(use
(use
(use
(use
(use
(use
(use
(use
(use

b1)
b1)
b2)
b1)
b1)
b2)
b1)
b1)
b2)
b1)

[1.00]
[0.10]
[0.10]
[0.20]
[0.10]
[0.10]
[1.00]
[0.10]
[0.10]
[0.30]

Figure 9: Fragment of the PDDL+ plan
Figure 10 shows a fragment of the corresponding VAL report. Note that VAL provides analytic
solutions to the differential equations involved in the KiBaM dynamics.
To evaluate the efficiency of our approach, we compared our solutions to those obtained using
the U PPAAL-based approach. The resulting lifetimes are shown in Table 1 where the upper bound
349

fiF OX , L ONG & M AGAZZENI

Figure 10: Fragment of VAL report

column shows the theoretical upper bound given by a best-of-two policy with an extremely highfrequency switching. It can be seen, in the first two rows of this table, that the power that can be
extracted from a battery with a nominal capacity of 5.5 Amin is only 12.16 min  250 mA, which
is 3.04 Amin, when loading continuously at 250 mA, or 4.59  500 mA which is 2.3 Amin when
drawing a continuous load of 500 mA. This gives an indication of the extent to which the limit on
the conversion of bound charge to available charge affects the performance of batteries.
load
profile

Upper bound
lifetime
B1
B2

U PPAAL-KiBaM
lifetime
B1
B2

CL 250
CL 500
CL alt
ILs 250
ILs 500
ILs alt
ILl 250
ILl 500

12.16
4.59
7.03
44.79
10.82
16.95
84.91
21.86

12.04
4.58
6.48
40.80
10.48
16.91
78.96
18.68

46.92
12.16
21.26
132.8
44.79
72.75
216.9
84.91

N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A

Planning-KiBaM
lifetime (visited states)
B1
B2
12.14 (194)
4.59 (116)
7.03 (136 )
44.76 (552)
10.8 (131)
16.92 (159)
84.88 (488)
21.85 (173)

46.91 (691)
12.14 (194)
21.2 (350)
132.7 (1068)
44.76 (552)
72.55 (599)
216.8 (1123)
84.88 (488)

Table 1: System lifetime (in minutes) for all load profiles according to different battery usages
350

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

In all load profiles considered we observe that our approach outperforms the U PPAAL-based
one significantly, providing solutions that achieve more than 99% efficiency compared with the
theoretical limit. The key points described in the preceding parts of this section allow the resulting
search to efficiently prune the state space and quickly find the solutions. In particular, by using
variable discretisation it is possible to consider a much finer discretisation for variables  and 
than is used in the work by Jongerden et al. (2009) and to handle very sensitive interactions. This
is crucial, particularly when the available charge in the batteries is almost exhausted. Jongerden et
al. (2009) describe their plans as optimal, but it is important to note that this is only with respect
to the discretisation that they use; a finer-grained discretisation offers the opportunity for a higher
quality solution to be found at the cost of a much larger state space. Despite the very large state
space our model creates, the solver visits a very small collection of states (as shown in the table).
These problems are all solved in less than a second.
When dealing with larger batteries of type B2 , the state space becomes so large that any exhaustive approach is infeasible. Indeed, in the works by Jongerden et al. (2009, 2008), the authors were
not able to handle this second case. We also found high quality solutions for batteries of type B2 :
an example is shown in Figure 11 compared with the standard best-of-two solution, showing the
huge improvement we can obtain over this policy. Note that the slicing of the load periods occurs
towards the end of the plan, and this is a phenomenon we have observed in all our plans.
We also considered an 8 battery system (an example of its behaviour is shown in Figure 14).
Benini et al. (2003) indicate that the designers of the SMBus (SBS Implementers Forum, 2000)
architecture, which is a communication and control architecture and protocol that has been used
in the development of Smart Batteries, suggest that there might be good reasons not to partition
charge among more than four batteries. In fact, there are examples of systems using more than
four batteries, such as HP 6-cell lithium-ion Smart Battery packs. In practice, partitioning charge
between batteries offers multiple benefits, including the opportunities to use industry standard cells
and to exploit different distributions of weight and possible cooling requirements. The tradeoffs
between these benefits and the potential loss of efficiency arising from the partitioning is complex.
The more batteries that are to be used, the larger is the state space for both planning and policy
learning; constructing a solution to an 8 battery problem is significantly harder than for a 4 battery
problem, so we present these results as evidence that we can scale to larger systems, subsuming the
smaller cases.
The results are reported in Table 2, and show that we can scale effectively to much larger problems. Notice that the number of switches we use to produce the results is very significantly smaller
than the best-of-8 policy giving the theoretical upper bound, however the resulting solutions achieve
more than 99% efficiency. The final column, labelled Plan-based Policy, shows the performance of
the policies we discuss in the next section, applied to these load profiles. These generate slightly
worse performance in switches, but maintain the lifetime performance.
One final observation worth noting is that the structure of the usage profile across the batteries
leads, in the two-battery case, to one battery being discharged sooner than the other. In the 8-battery
case this effect is more pronounced, with several batteries being discharged while others still have
significant charge remaining. This has an interesting consequence: using this policy it becomes
possible to hot-swap batteries, replacing used batteries with new ones, while the system is active.
The fact that one or more batteries still hold charge allows loads to be serviced while the used
batteries are exchanged with charged ones and the policy can adapt to the new states of charge of
351

fiF OX , L ONG & M AGAZZENI

12
total charge battery 1
total charge battery 2
available charge battery 1
available charge battery 2
battery schedule

10

charge (Ahr)

8

6

4

2

0
0

1000

2000

3000
4000
time (0.01 min)

5000

6000

7000

(a) Vmax (based on the feasible frequency switching used in (Jongerden et
al. 2009))
12
total charge battery 1
total charge battery 2
available charge battery 1
available charge battery 2
battery schedule

10

charge (Ahr)

8

6

4

2

0
0

1000

2000

3000

4000

5000

6000

7000

time (0.01 min)

(b) Plan

Figure 11: ILs alt load test with two batteries of type B2
the batteries once the used ones have been replaced. This is in marked contrast to the high-frequency
switching policies, where the batteries all discharge at approximately the same time.

5. From Plans to Policies
Having shown how to generate high quality plans for deterministic multiple battery management
problems, we now turn our attention to the stochastic problem we are really interested in solving.
In general, we cannot know in advance what will be the load profile applied to the batteries, but we
352

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

load
profile
CL 250
CL 500
CL alt
ILs 250
ILs 500
ILs alt
ILl 250
ILl 500

8 batteries B2
lifetime (number of switches)
Upper bound
Plan
Plan-based Policy
310.6 (31072)
134.7 (13472)
192.8 (19280)
660.7 (33076)
308.7 (15476)
424.8 (21280)
1008.9 (33692)
480.9 (16090)

307.6 (485)
133.4 (266)
190.8 (355)
654.1 (495)
305.7 (293)
420.6 (357)
998.8 (471)
476.1 (295)

307.6 (992)
133.4 (571)
190.8 (806)
654.1 (904)
305.7 (513)
420.6 (614)
998.8 (822)
476.1 (597)

Table 2: System lifetime (in minutes) for all load profiles serviced with 8 batteries
assume that a probability distribution characterising typical use of the batteries is available. Such a
probabilistic problem can be cast as a hybrid temporal Markov Decision Process (MDP).
Formally, a MDP is defined as follows:
Definition 4 A Markov Decision Process is a 4-tuple, (S, A, P, R), where S is a set of states, A is
a finite set of actions, P is a probability function where Pa (s, s0 ) = P r(st+1 = s0 |st = s, at = a)
is the probability that action a  A will cause a transition from state s  S to s0  S when applied
at time t, and R is a reward function, where Ra (s, s0 ) is the reward earned for making the transition
from state s to s0 by action a.
The Markov property is that the probability distribution for a transition out of a state is not
affected by the path by which the state was reached. In general, MDPs are defined with finite
state spaces, but a continuous MDP can also be considered, in which the states are embedded in
multidimensional real space. The battery usage problem can be seen as a continuous MDP, where
the states are tuples that define the (continuous) state parameters for each of the batteries and also the
current state of the load and which battery is servicing the load (if the load is non-zero). Actions in
this problem indicate which battery should now service the load, but can also correspond to events
that change the current load. In the battery problem the actions switching between batteries are
deterministic, but the events that cause load changes are probabilistic, representing the uncertainty
about the demands of the user on the powered system. The time between events is also governed by
a stochastic process, but the timing of switching actions is controllable.
More formally, for a problem with n batteries, a state is characterised by the tuple
(sb1 , sa1 , sb2 , sa2 , ..., sbn , san , B, t, L), where sbi is the bound charge in battery i, sai is the available charge in battery i, B is the number of the battery currently servicing load (1  B  n), t is
the time of the state and L is the current load. Out of each state there is a deterministic action, Use
B 0 , which causes a transition to the state (sb1 , sa1 , sb2 , sa2 , ..., sbn , san , B 0 , t, L), in which battery
B 0 is the battery servicing load. There is also a non-deterministic action, wait(T), where T is a time
interval, which causes a transition to a state in which time has advanced to time t0  t + T , the state
of charge of battery B is updated according to the battery model and the load might be different
(according to the probability distribution governing loads). The interpretation of the action is that
353

fiF OX , L ONG & M AGAZZENI

it advances time to the next event, which will be when a battery is depleted of available charge, or
when the load changes, or when T time has passed, whichever is first.
The reward function for the battery problem gives positive reward for each transition, proportional to the advance of variable t. Once the system enters a state in which the currently active
battery has no available charge, it terminates (or, equivalently, enters a special final state on which
all further transitions loop without incrementing t). This reward system means that the optimal
solution will be the one with greatest duration.
A solution to an MDP is a policy:
Definition 5 A policy, , for MDP (S, A, P, R), is a mapping  : S  A, specifying which action
to execute in each state.
For the battery problem, the policy will be a function that determines which battery to use when
load must be serviced, using the current states of charge of the available batteries as the basis for
making the decision.
Considerable research effort has been invested in the problem of finding policies for MDPs, as
discussed in Section 6.
The way we approach this problem is to see the mapping as a classification, where the state of
the batteries is mapped to a class corresponding to the correct choice of battery. We can use the
solutions to the determinised problems as the basis of a classifier construction problem and use an
existing machine learning approach to build a good classifier. The overall approach is sketched in
Figure 12.
Several important observations can be made. Firstly, the successful construction of a classifier
depends on there being exploitable structure in the space defined by the solutions to the determinised
problems. Secondly, the states are described by continuous variables: we discretise these for the
purpose of building the classifier. Thirdly, our solution set will generally not cover the whole space
of reachable states, so it is important that we complete the policy with a sensible default action to
deal with states that the policy fails to handle. In our case, the default action is a best-of-n rule,
which is the best of the published hand-constructed policies for this problem. If the policy suggests
to switch to a battery whose available charge is below a critical threshold, then the policy action is
ignored, and the default action is used. We discuss the impact of this in physical experiments in
Section 7.
Finally, we note that deployment of the constructed policies will require that they can be efficiently implemented in cheap hardware. Simple classifier rule systems can be very effectively
implemented in look-up tables, which are ideal for implementation on Field Programmable Gate
Arrays (FPGAs) or as purpose-built hardware.
5.1 Policy Learning through Classification
To learn a policy through classification, it is first necessary to generate an appropriate training data
set. For our problem, this data set must associate the states of the batteries and the current load
with an appropriate decision (which battery to use to service the load). We construct the training
set by building a sample of profiles from the stochastic description of the expected loads. The
distributions we used to describe amplitude, duration and frequency of loads are shown in Figure 13.
The deterministic solutions to these problems are constructed as described in Section 4. Training
data is then generated from these plans by simulating their execution and recording the battery
354

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Figure 12: Plan-based policy learning: this figure illustrates our approach to policy learning
schematically. The off-line training phase involves construction of a set of planning
problem instances by sampling from the initial state distribution, followed by construction of plans for each instance. These plans are then classified to obtain a state-to-action
mapping in the form of a decision tree which can be used as a policy.

states, load and battery choice at a fixed time increment throughout the plan. For example, if the
increment is 0.01 minutes then the training data generated from a plan will record the battery states
of charge (available and bound), load and currently selected battery (which might or might not have
changed from the previous time increment) at every 0.01 minute interval throughout the plan. In
our experiments we selected the time increment to be the same as the smallest increment used in the
variable discretisation described in Section 4.4, but this is not a requirement of the approach. The
choice of time increment determines the frequency of the decision-cycle for the learned policy. The
time increment also determines how much training data is generated from a single plan, according
to the makespan of the plan. In order to reduce the volume of training data for fine-grained time
increments used with long makespan batteries, it is possible to randomly sample from the set of
state-battery-selection pairs across multiple plans. In our experiments we did not need to do this.
Once the training data is generated, a classifier can be learned using a standard machine learning
approach. W EKA (Hall, Frank, Holmes, Pfahringer, Reutemann, & Witten, 2009) is a machine
learning framework, developed at the University of Waikato, that provides a set of classification and
clustering algorithms for data-mining tasks. W EKA takes as input a training set, comprising a list
of instances sharing a set of attributes. In order to perform the classification on the battery usage
problem data, we consider instances of the following form:
 = (1 , 1 , . . . , N , N , B, L)
355

fiF OX , L ONG & M AGAZZENI

where i and i denote the available charge and total charge of the ith battery, respectively, B is
the currently active battery and L is the current load (this is essentially the state of the MDP but
without the time label, since we want our policy to operate independently of time). In this setting,
the attribute used as the class is the battery B.
The stochastic load profiles have been defined with a distribution of:
 the load amplitude l  [100 . . . 750] mA;
 the load/idle period duration d  [0.1 . . . 5] min;
 the load frequency f  [0.3 . . . 0.7].
The probability distributions are shown in Figure 13.
P(l)

P(d)

P(f)

0.40

0.40

0.35
250

0.5

500

0.5
0.20

0.15
100

750

0.15
0.10
0.05

0.2
0.1

load amplitude l (mA)

0.25

1.0

0.10

0.6

0.4

2.5

0.3

5.0
load/idle period duration d (min)

0.7
load frequency f

Figure 13: Probability distributions for the stochastic load profiles
10
battery schedule
load

load amplitude / battery in use

8

6

4

2

0
0

5000

10000
15000
time (0.01 min)

20000

25000

Figure 14: Plan-based policy for 8 batteries with a stochastic load
This leads to load profiles that are very irregular (see the bottom of Figure 14) and therefore
harder to handle than the very regular profiles considered by Jongerden et al. We generated a
set of stochastic load profiles and for each of them we produced a near-optimal plan using the
deterministic solving described in Section 4. This set of plans has been used as the training set for
the classification process.
356

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Algorithm
DMNBtext
NaiveBayes
NaiveBayesSimple
NaiveBayesUpdateable
Logistic
MultilayerPerceptron
RBFNetwork
SimpleLogistic
SMO
IB1
IBk
AdaBoostM1
AttributeSelectedClassifier
Bagging
Clustering
Regression
CVParameterSelection
Dagging
Decorate
END
EnsembleSelection
Grading
LogitBooost
RandomCommittee
RandomSubSpace
RotationForest
Stacking
Vote
VFI
DecisionTable
DTNB
DecisionStump
J48
J48graft
OneR
LADTree
NBTree
SimpleCart

cross-validation success
18%
37%
36%
36%
44%
51%
43%
44%
44%
99%
99%
27%
98%
98%
26%
98%
19%
44%
99%
99%
99%
19%
47%
99%
99%
99%
19%
19%
23%
90%
90%
27%
99%
99%
56%
45%
99%
99%

model size









26 Mb
26 Mb

29 Mb
18 Mb

9 Mb


31 Mb
15 Mb
70 Mb


12 Mb
21 Mb
22 Mb



6 Mb
6 Mb

2 Mb
13 Mb


114 Mb
86 Mb

Table 3: Performance of classification algorithms tested on 10,000 training examples

357

fiF OX , L ONG & M AGAZZENI

In order to select the most suitable classification algorithm, we applied all the classifiers provided by WEKA to a data set of 10,000 training examples. We first evaluated their performance as
the number of correctly classified instances during the cross-validation. We discarded classifiers
providing less than 70% correctness. We then considered the memory and the time required to use
the classifier. The output of the classification process is a model encoding the resulting decision
tree. In some cases, the generated model requires significant memory to store (more than 500Mb of
RAM memory), or it is too slow to be used. These parameters have also been used to determine the
number of training examples to classify, as the bigger the training set, the better the performance
and the higher the memory and time requirements. Some of the classifiers with their performance
are reported in Table 3.
...
if(b2gamma<=0.297404){
if(b2gamma<=0.296404){
if(b2gamma<=0.288404){
if(b2gamma<=0.286404){
if(b2gamma<=0.277404){
return 1;
}
if(b2gamma>0.277404){
return 2;
}
}
if(b2gamma>0.286404){
return 1;
}
}
if(b2gamma>0.288404){
return 2;
}
}
if(b2gamma>0.296404){
if(b2y1<=-0.043615){
return 1;
}
if(b2y1>-0.043615){
if(b1gamma<=0.164404){
return 1;
}
if(b1gamma>0.164404){
return 2;
}
}
...

Figure 15: Fragment of decision tree
According to these criteria, we selected the J48 classifier, which implements the machine learning algorithm C4.5 (Quinlan, 1993). The output is a decision tree whose leaves represent, in our case
358

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

load
profile
R100
R250
R500
R750

Upper bound
time()
sw()
792.6(15.5)
369.8(1.91)
226.7(2.13)
188.3(0.8)

71383(1379)
28952(853)
14671(512)
11519(463)

Plan-based Policy
time()
sw()
786.2(15.4)
366.7(2.02)
224.6(2.27)
186.4(0.7)

1667(161)
1518(143)
987(122)
302(33)

Table 4: Average system lifetime and number of switches for stochastic load profiles for 8 battery
systems
study, the battery to be used (a fragment of the tree is shown in Figure 15). For the cardinality of the
training set, an empirical evaluation showed that the best result is obtained using 250,000 training
examples (note that this involves considering about 4  106 real values characterising the states and
battery selections in these training examples) since further extending the training set does not make
any significant improvement in the performance but increases memory and time requirements.
5.2 Results from Policies
In order to use the decision tree we embedded the WEKA classes for loading the classification model
into our battery simulation framework. The model for the 8 battery case is represented by a tree with
61 levels and consists of 7645 nodes, each one containing a comparison between one of the state
variables and a threshold. Applying this decision tree to determine which battery to load at each
decision point takes negligible time.
To evaluate the performance of the policy we considered four probability distributions with
different average value for the load amplitude, namely 100, 250, 500, 750 mA. For each distribution
we generated 100 stochastic load profiles and we used the policy to service them. Note that the load
profiles used for evaluating the policy are independent from the ones used for training, although
they are drawn from the same probability distributions.
Table 4 shows the average value and standard deviation for the system lifetime and the number
of switches obtained using the best-of-8 policy at high frequency switching and our policy.
Also in this case, we observe that our policy achieves more than 99% efficiency compared with
the theoretical upper bound given by the best-of-8 policy executed at very high frequency (recall
that this is infeasible in practice). Moreover, the number of switches used by the policy is slightly
greater than in the corresponding deterministic solving, but is one order of magnitude lower than
the corresponding value for the best-of-n policy.

6. Related Work
A variety of approaches have been proposed for solving continuous Markov Decision Processes (Sanner & Boutilier, 2009). Meuleau et al. (2009) propose hybrid AO* search, using a dynamic programming approach to guide heuristic search for problems involving continuous resources
used by stochastic actions. This approach does not handle time-dependent resource consumption,
but it appears that the above MDP could be modelled for solution by this approach. The authors give
empirical data for solution of problems with up to 25,000 states. Our model, with an appropriate
359

fiF OX , L ONG & M AGAZZENI

discretisation, contains more that 1086 states for 8 batteries. Mausam and Weld (2008) describe a
planner for concurrent MDPs, which are MDPs with temporal uncertainty. Again, these problems
are similar to ours, although their planner does not manage continuous time-dependent resources, so
is not directly applicable to our problem. Furthermore, the largest problems they consider contain
4,000,000 states and take more than an hour to solve.
In solving very large MDPs, researchers have identified a variety of techniques that can help
to overcome the prohibitive cost of policy iteration or value iteration, the classical techniques for
solving MDPs. In general, these techniques approximate the solution, often focussing on those parts
of the policy that apply to states that are likely to be visited along the trajectory. Relevant techniques
are discussed in the work of Bertsekas and Tsitsiklis (1996).
Our approach is in the branch of work devoted to the development of plan-based reasoning under
uncertainty. In fact, when explicit modelling of uncertainty is impractical, sampling can provide an
effective alternative.
Hindsight Optimisation (HO) (Chang, Givan, & Chong, 2000; Fern, Yoon, & Givan, 2006)
has become a well-researched technique for learning policies based on plans. A policy always
proposes the best action to do next in any state, and is therefore more or less robust to the uncertainty
encountered in reality. The HO technique works as follows: given an MDP and a state, s, the first
step is to sample, from the MDP, a large number of deterministic instances of the process with
initial state s. The next step is to solve these instances using a deterministic planner over a fixed
horizon. Finally, the estimated value for the state s is computed as the average value obtained from
the deterministic plans. It is then possible to choose, in any state, the move that led to the best
performance on average in the samples.
Although our approach is similar to Hindsight Optimisation, there are significant differences.
First, previous works in this direction have only addressed propositional domains (see, e.g.
the work of Fern, Yoon and Givan (2004, 2006, 2007), or Konigsbuch, Kuter and Infantes, 2010)
while here we are interested in a hybrid discrete-continuous problem, as we deal with the non-linear
continuous and deterministic planning models of the drain and recovery behaviour of batteries, using
sampling to provide the noise encountered in reality. The approach is to sample the deterministic
instances of the problem using simple assumptions about the underlying distributions governing the
physical reality. In many natural situations, Gaussian distributions work well as an approximation
of the uncertainty in the problem. In this work, for example, we show that by sampling many
deterministic discretised cases, and planning solutions to each of them exactly, it is possible to
classify the states of the solution plans into a policy that can robustly manage the load distribution
in both simulated and real battery configurations. The weaknesses of the assumptions made about
the underlying distributions are overcome by introducing default actions (described in Section 5),
which can be applied when the policy finds itself in a state outside the range of applicability of the
policy. Integrating the policy with the default action leads to very competent policies that perform
well across a wide range of physical situations, including situations that are dissimilar to those
encountered during the learning phase.
Another important difference is that rather than averaging over plan states to obtain a policy, in
our approach we use a decision tree classifier to arrange the states according to their information
content (reflected in how well they support a partitioning of the planned actions). This results in a
classification of actions into states, and a policy that proposes the best action to use in any state is
determined online by comparing policy state variables with the real values encountered as the policy
is executed. Although training for policy-learning is expensive in terms of time and computational
360

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

resources, the planning and learning is done offline, and the offline process is not strongly resourcebounded. The classification phase produces a policy in the form of a decision tree, that is compact
and the execution of which takes negligible time and this is a key feature for this application. In fact,
due to the continuity involved in the battery model, and the need for planning to a very long horizon
(up to 60,000 time steps), the resulting state space is huge. This makes any approach based on an
explicit mapping of each state to an action impractical. In particular, it is not possible to compute an
HO-based policy offline and then map each state to the best action according to the policy values.
On the other hand, using HO online (which is viable in many cases) in infeasible in this application,
as the nature of the battery scheduling problem requires a very fast interaction between the policy
and the battery system. Our approach meets both the scalability and fast-response requirements.
Finally, the idea of looking ahead over what if scenarios, and then benefiting from the experience gained, is powerful. In HO it is assumed that, in general, the experience of the deterministic
planner is sufficient to give insights into the best moves possible in a real state encountered during
execution. However, another important aspect that makes our approach different, and that we investigated more deeply in a different context (Fox, Long, & Magazzeni, 2012), is that, in many cases, it
is necessary to distinguish between the plan state and the policy state. For example, while the plan
state might contain a variable representing whether an unreliable valve is open or closed, observable experience records the effects of its unreliability  for example, the effect on flow-rate through
a pipe  over a given time period. A policy-state variable can therefore be constructed to record the
observed flow rate, which is a proxy for whether the valve is open or closed. This approach, which
we call observable-correlate policy learning, is very different from averaging over the plan states
encountered during planning, because policy states capture the actual situation being experienced,
while plan states remain abstracted and distanced from reality. In that work (Fox et al., 2012), we
apply exactly the same policy-learning technique as described here to the problem of learning robust
observable-correlate policies for following the boundary of a surface algal bloom. In this context
we define a collection of policy state variables which correlate plan state variables with observable
experience.

7. Physical Experiments
In this section we report the results obtained from a kitchen table experiment comprising a simple
circuit constructed out of breadboard components and an Arduino Mega board which we used for
sensing and control.1 Using this apparatus we have been able to demonstrate that our simulation
results do translate into reality. As part of our future work, further experiments will be undertaken
in a professional laboratory to continue to explore the benefits and limitations of our approach.
The goal of the experiment is to demonstrate that the plan-based policy method achieves similar
lifetime to that achieved by the best-of-two policy, but with significantly reduced switching. It is
clear from the simulation results that the plan-based policy can achieve close to optimal lifetime with
only a fraction of the switching that best-of-two requires, although the simulation also suggests that
the best-of-two policy should achieve within less than 1% of the theoretical optimal even switching
at a frequency of once every 5 minutes. We therefore expected little opportunity for our learned
policy to improve the lifetime and were therefore hoping to achieve similar lifetime but with a
1. The results and figures presented throughout this section are presented in colour in order to clarify the relationships
between multiple plots. Unfortunately, several figures are difficult to interpret in monochrome and the reader is
recommended to view the figures using an appropriate medium.

361

fiF OX , L ONG & M AGAZZENI

Figure 16: A photograph of the battery apparatus constructed to manage two batteries.

much lower switching frequency. Our results show that the plan-based policy does exhibit much
lower frequency switching. In fact we found that the plan-based policy achieves significantly longer
lifetimes as well.
We begin by describing how we built the circuit that we used for the experiment. We then recall
the KiBaM model, and explain how its parameters were estimated. The plan-based and best-of-two
policies rely on being able to read the state of available charge of the batteries. This is very difficult
to estimate, and the performance of the policies depends absolutely on estimating this quantity
accurately, so we explain how we read state of available charge in our set-up. Finally we present the
results of our experiments and describe our plans for future work.
7.1 The Electronic Apparatus
We constructed an experimental apparatus for a suite of two batteries, shown in Figure 16. We
used Ritar 6 volt lead acid batteries of nominal capacity 1 Amp hour for 20 hours of discharge
(1Ah@20h). We connected each of these batteries in a circuit to an Arduino Mega board.
Part of each circuit was constructed to allow the Arduino to read the voltage on the connected
battery. We want to ensure that the current drawn to measure the voltage is negligible, so high
external resistance, of 3.6k and 7.2k, was used to bridge the Arduino input. Using a voltmeter
we read 6.5-6.7V on a fresh battery, so we consider VEM F = 6.5V. This is too high a voltage
for the Arduino inputs which have a maximum input voltage of 5V. Since, considering the battery
voltage sensing element of the circuit with resistance R, VEM F = iR and VEM F = 6.5V , we
use R = 7.2 + 3.6 = 10.8k in order to divide the voltage and to achieve a negligible current of
0.0006A. A higher resistance might seem preferable to still further reduce the current losses, but the
362

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

3.6

1

1

8

8

3.6

+ 6V
B1 

Volts In (L2 Lo)

Volts In (L2 Hi)

PWM Out S2

Volts In (B2)

Volts In (L1 Lo)

Volts In (L1 Hi)

PWM Out S1

Volts In (B1)

Gnd

Arduino Mega

+ 6V
B2 

7.2

7.2

Figure 17: The battery apparatus for two batteries.

Arduino uses an analog-to-digital converter based on measuring charge on a capacitor over time.
This approach relies on sufficient current flow into the capacitor to get accurate measurements in
short time periods and very high resistance prevents this. In practice, a resistance of  10k is about
the limit at which the Arduino can respond to changes in the inputs within the timing constraints
of our sampling. With these resistances the voltage reading at the Arduino is VEM F  0.0006 
3600 = 4.34V , which is within its operating range.
The current is diverted to a load consisting of a switch and two resistors of 8 and 1. The role of
the switch, which is a MOSFET IRF630 controlled using a pulse width modulated output from the
Arduino, is to ensure a smooth delivery of power to the resistors. The load is 6.5/(9+r +Rs ) where
r is the internal resistance of the battery and Rs is the effective variable switch resistance under pulse
width modulated control. The data sheet for the Ritar 6V battery lists the internal resistance, r, as
50m, while we measured 0.34, a value almost 7 times greater. We believe that the discrepancy
comes from a systematic distortion in the sensed values reported by the Arduino. We consistently
use these readings in all of our experiments and regard the discrepancy as a systematic error. Our
experiments use currents varying between 0.2A and 0.3A, so, when VEM F = 6.5V and i = 0.3A,
Rs is about 12, but is lower when the battery is less charged (and the voltage drops) and higher
when a lower current load is required.
The circuit diagram is shown in Figure 17. It will be noted that the load is duplicated in this
design, which completely separates the parts of the circuit responsible for interacting with each
363

fiF OX , L ONG & M AGAZZENI

battery. In fielded systems the load would be common and diodes used to prevent flow of electricity
between batteries at different charge states.
7.2 Estimating Parameters
In this work we used the Kinetic Battery Model (Manwell & McGowan, 1993) and we followed
the parameter estimation process described by Manwell and McGowan (1994). Following their
description, the extended KiBaM has three parts: a capacity model, a voltage model and a lifetime
model. We use a simple lifetime model (we assume that there is no change in the battery behaviour
due to recharging).
7.2.1 T HE C APACITY M ODEL
The capacity model, which describes how capacity varies as the battery is drained and allowed to
rest, is described by a first order differential system. The quantity
qmax (I)
is the maximum amount of charge, in Amp hours, that we could hope to extract from the battery
if we discharged it continuously, at nominal current I, until drained. The time it takes to drain the
battery at nominal current I is T . T and I are linked by the following equation:
qmax (I) =

1  ek0 T

Ck 0 cT
+ c(k 0 T  1 + ek0 T )

derived from the model described in Section 3.2. The model relies on three constants: C, which is
the maximum capacity of the battery in Amp hours, k, which is the rate per hour of conductance
between the bound well and the available well of the model, and c, which is the ratio of available
k
charge to maximum capacity. In Section 3.2, k 0 is defined to be c(1c)
. It can be seen that qmax (I) =
IT .
These constants are found by fitting a curve to data. We obtained our data by draining batteries
one at a time, from their fully charged state, using different currents in the circuit described in
Section 7.1. An example of the data collected is shown in Figure 18, where the top curve is the
measured voltage of the battery over time, the line at 5.25V is the point at which the battery is
considered dead, the point cloud comprising a thick curve at 208mA is the measured load, and the
thin straight line running through this point cloud is a rolling average of the load. The vertical line
shows where we treated the battery as dead. As shown in Figure 19, there is uncertainty about
exactly where the battery dies.
The values of C, k, c that we calculated are:
C = 1.372Ah
k = 0.1967h1
c = 0.3870
and
k 0 = 0.8290h1
364

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Figure 18: Battery discharge curve: terminal voltage (top curve) and load (bottom curve).

millivolts (top curves) and 0.1 milliamps (bottom curves)

5600

5500

5400

5300

5200

5100

5000

4900

4800
33000

33500

34000

34500

35000
35500
half-seconds

36000

36500

37000

37500

Figure 19: A close up of the point cloud of the voltage curve at the point where the battery is
considered dead.

365

fiF OX , L ONG & M AGAZZENI

0.7
Observed data
Fitted curve
Data Sheet values
0.6

I - Amps

0.5

0.4

0.3

0.2

0.1

0
0

2

4

6

8

10
T - hours

12

14

16

18

20

Figure 20: Data for current and time to drain batteries. The Data Sheet values are shown for comparison.

The fitted curve of T against I, for the fitted C, k, c values, is shown in Figure 20. The square
points are our observed data, while the stars are the data points reported on the Ritar 6V battery
data sheet. We found that the data sheet appears to consistently under-estimate the performance
of the battery. It can be seen that our observed data points are clustered in the 0.17A to 0.3A
region of the curve. We were unable to report points for lower currents, because the pulse width
modulation could not be set to an appropriately low value without dropping the control voltage for
the MOSFET switch below the point at which the switch opens. We could not report points for high
currents without melting the resistors comprising the load on the circuit.
We used the C, k, and c values to construct the initial state of the battery load management
planning problem, and then we learned a policy from plans produced against this model. Therefore,
an accurate estimation of these parameters is very important. The policy will be far less effective
if the wrong capacity model is used. We learned a policy using a time granularity of 0.01h, which
is 36 seconds. In our timing loops for collecting data from the Arduino sensors we use averages
computed over 0.5 seconds: the data points in Figure 19 are shown at this resolution. Thus, we
collect 72 data points from each sensor between decision points at the granularity of our planning
model and, consequently, our learned policy. As can be seen, there is considerable noise in these
values and to reduce this noise we construct a rolling average over the preceding window of 65
points. We selected 65 to avoid the particularly noisy data values generated when there is a switch
between batteries.
366

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

7.2.2 T HE VOLTAGE M ODEL
In order to be able to exploit our plan-based policies it is necessary to be able to evaluate the state of
charge of the batteries at every decision point. It is known to be very difficult to accurately evaluate
state of charge because the behaviour of batteries is noisy, variable and highly non-linear. However,
terminal voltage is recognised as a reasonable proxy for state of charge. We therefore observe the
output voltage of each battery and calculate its state of charge from this reading.
The measured terminal voltage, Eobs , falls off as the battery is drained, producing a typical
knee-shaped curve representing the decrease in voltage over time as the current is drawn, and
illustrating the collapse in voltage once the battery is dead. Manwell and McGowan model this
voltage curve using the equation:
Vobs = VEM F + AX + BX/(D  X)
Q
where X is defined to be qmax
(I) and Q is the total charge consumed to date by the battery.
The parameters A, B and D are found by non-linear curve fitting to data, using voltage against
time for constant current discharges. We used 4 sets of data obtained by draining batteries from
fully charged, one at a time on our battery apparatus, to estimate the curve for the Ritar 6V batteries.
Figure 21 shows an example of a discharge curve. The batteries are effectively dead as soon as the
voltage drops over the knee. This occurs at 5.25V . Figure 21 also shows a voltage model curve (the
solid black line), of the type described above, fitted to the discharge data for a battery. In this case
we have discharged the battery past the critical point where it is considered dead, to show how the
voltage drops dramatically (and the load cannot be maintained reliably). The vertical line shows the
point at which the battery is judged dead and the curve is fitted to the data up to this point. As can
be seen, the curve fits well until after the knee, when the behaviour is no longer governed by the
simple quadratic voltage model.
The parameter values we computed for our batteries are:

A = 0.194mV s1
B = 2.22  103 mV s1
and
D = 1.05h.
A governs the almost linear decay in voltage over the first part of the discharge curve and it is the
easiest parameter to estimate accurately. B and D together determine the shape and initiation of the
dip in the voltage as the battery gets close to its dying threshold. The fit of the values for B and D
is much more sensitive to noise than is the value of A.
7.2.3 E VALUATING THE S TATE OF C HARGE OF THE BATTERY
Using the Arduino Mega board, we collect voltage and current values from the batteries at a frequency of every half a second. For each battery in use, we compute a rolling average over the last
65 voltage readings reported since the battery was first loaded (before this, the reported voltage
readings can be inaccurate). Having computed the first rolling average we can fix VEM F , which
is the value we take to be the fully charged open circuit voltage of the battery (ie: the voltage that
was available before any load was serviced). We calculate Eobs and Q every 36 seconds for every
battery.
367

fiF OX , L ONG & M AGAZZENI

Figure 21: Voltage against time.
The observed voltage is affected by the load on the battery at the time that we observe it, so we
adjust the observed voltage reading, Eobs , to take into account the internal resistance and load on
the battery. This results in the unloaded observed voltage Vobs :
Vobs = Eobs + 0.34Iobs
We can then calculate the difference between Vobs and VEM F to be:
Vadj = Vobs  VEM F .
Then, to calculate X we first obtain a value F :
F =

B + AD + Vadj
2A

Then:

r

DVadj
A
We use this root of the quadratic equation for X because X  1.
For a given battery, b, to calculate the charge consumed by b at time t, the sum of the current
readings taken so far (measured in milliamps, taken every half second) is divided by a large constant,
7.2  106 , which gives a result in Amp hours. This value is Q, the total charge consumed to date by
b.
The value X, which is the proportion of available charge at current I that has been drawn, is
obtained from the two parameters Eobs and Q, using the voltage model given above. Once we have
Q
.
X and Q, we can compute qmax (I) as X
X=F 

F2 

368

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

We can now evaluate the state of charge of a battery. The variable  is the total capacity,
C, minus the total charge consumed, Q, in Amp hours. This gives us an estimate of the total
remaining charge, but not all of this will be accessible because some of it is bound up in the chemical
properties of the battery. The variable  is the difference between the bound and available charge
wells, enabling us to estimate how long we would need to drain the battery. Since available charge
will always be less than or equal to the bound charge, there is always a pair of values (Inom , Tnom ),
such that, had the battery been run at Inom for time Tnom , it would have reached its current state of
charge. Given that
Q
X=
qmax (Inom )
and using the equation for qmax (I) given in Section 7.2.1, we have that
Ck 0 cXTnom
0
0
= 1  ek Tnom + c(k 0 Tnom  1 + ek Tnom )
Q
Therefore, Tnom is the solution of
0

1 + (c  1)ek T + ck 0 (1 

CX
)T = 0
Q

The time, Tnom , that is nominally required to continuously drain the battery from fully charged,
at current I, is calculated numerically by plugging these equations into the Newton-Raphson
method, with an appropriate initial value (we use 4, since the expected lifetime of the battery at
the discharge rates we are using is about 2-4 hours). Given that:
qmax (I) = Inom  Tnom
we have that:
Inom =

qmax (I)
Tnom

and  is then computed as:
0

Inom (1  ek Tnom )
ck 0
The available charge can be calculated from  and  as:
c(  (1  c))
as discussed in Section 3.2.
The best-of-two policy discussed in Section 3 can now be implemented to always choose the
battery with the highest available charge. Executing this policy requires the state of charge to be
read with reasonable accuracy at the fixed frequency. For example, one might fix the frequency to
be every 6 minutes, and select for the next 6-minute interval the battery with the highest available
charge (which is equal to c(  (1  c)) as explained in Section 3.2).
369

fiF OX , L ONG & M AGAZZENI

7.2.4 R ECHARGING AND OTHER E FFECTS
It is clear that to perform multiple experiments with lead-acid batteries it will be necessary to
recharge them between discharges. Recharging lead-acid batteries is known to have an impact
on their performance: they deteriorate with repeated cycling. However, the gel-type batteries we
used are deep cycle batteries that can be cycled hundreds of times before they reach the end of their
design life.
Manwell and McGowan (1994) have proposed a lifetime model based on a rainflow cyclecounting algorithm which takes into account the fact that recharging damages the batteries and
affects their ability to deliver charge. Given that our batteries were brand new, and we have used each
one no more than 30 times, we hypothesise that the effects of repeated discharging and recharging
will not be significant in the lifetime of our experiment2 . For an extended, or larger scale experiment,
the rainflow model would be of interest, but adopting it, and exploring how it changes the behaviour
of our model, is left for future work.
An additional important effect on battery behaviour is temperature. All of our experiments were
conducted in an office environment with normal working temperatures. One of the factors that
governed our choice of discharge currents was the fact that at high discharge currents the batteries
do warm up noticeably, so the model we are using is likely to cease to be valid without changes to
the parameters. We ignored temperature effects and treat the batteries as though they are used at a
constant standard operating temperature, which is a reasonable approximation.
7.3 The Experiments
We carried out three sets of experiments on an apparatus consisting of two Ritar 6V batteries connected to the circuit shown in Figures 16 and 17. In our simulation tests we demonstrated the
performance of our approach on suites of 8 batteries, but performing the same experiments on the
physical apparatus would have been too time-consuming. Each of our 2-battery experiments took
over 11 hours to drain the batteries and, if anything went wrong during an experiment, such as loss
of communications with the PC, the experiment had to be restarted resulting in the loss of a day or
more.
When performing the experiments we noticed that the Arduino distorts all measured values:
time and voltages, and therefore amps and internal resistance. Its distortions appear consistent
across all experiments, resulting in systematic error. In particular, all of the times we measured
suggest that the Arduino measures 1 hour every 1.4 hours of real time, so a 7 or 8 hour lifetime
measured by the Arduino is actually approximately 10 to 11 hours of real time. We report all data
values directly from the Arduino measurements, unadjusted for the systematic errors, so it can be
borne in mind that our lifetime values are considerably longer when measured in real time. For
consistency, all other times are reported in the same relative measures (in practice, timing of load
control and discharge curves and other values were all performed using the Arduino clock, so the
measurements are entirely consistent with one another).
We randomly generated 10 different load profiles, drawn from the same distribution as we used
to train our policy, each alternating between 0.2 and 0.3 Amps and having intervals of constant
load of durations that are distributed around 30 minutes with a distribution as shown in Figure 22.
2. The experiments we report for load profiles 16 were run with batteries having been cycled up to 15 times. For
later profiles we did observe that some of the batteries showed behaviour that suggested a slight deterioration in
performance and it is possible that lifetimes are lower for these experiments than would be the case for new batteries.

370

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Figure 22: Distribution of load durations used for experiments.
For each load profile we ran best-of-two and the plan-based policy so that we could perform a
direct comparison of lifetime achieved and number of switches performed. This resulted in 16
load-execution experiments. For the first two load profiles we restricted the best-of-two policy to
switch at most every 5 minutes, so that the best-of-two policy and the plan-based policy switched a
similar number of times in an entire run. Our simulation results suggest that the plan-based policy
should switch no more than about 20 times, but our experiments reveal that the noise in the sensor
data leads to errors in the estimation of the state of charge which cause the policy to switch more
frequently than we would anticipate. Frequent switching indicates that the policy is responding to
spurious artifacts in the sensed data and to the variability in the real behaviour of the batteries. We
discuss this further in Section 8.
The plan-based policy was applied every 36 seconds (0.01 hours), reflecting the granularity of
the plans and learned policy. We also ran an experiment in which the best-of-two policy was allowed
to switch every 36 seconds, to ensure that the results we obtained were not biased by offering the
plan-based policy a faster reaction time, to changes in the battery state of charge, than best-of-two.
We wanted to establish whether the plan-based policy can achieve similar lifetimes to the bestof-two policy with a lower numbers of switches. We also wished to confirm that it is better than the
naive but simple policy of sequencing, in which the first battery is used until it is dead, and then the
second battery is used. This should be obvious (the sequencing policy is much worse in simulation),
but the observed behaviour of the plan-based policy is superficially similar to sequencing, since it
favours mostly using one battery until it is heavily discharged before switching to the second battery
for significant intervals, so we thought it useful to perform a physical comparison. In the case of
a 2-battery setup sequencing involves only 1 switch (the minimum number of switches possible in
the two battery case).
We ran 21 complete experiments in total. In all of the plots showing battery voltages during
these experiments, the last lowest point on the battery voltage curves (the red and green curves) are
the points at which the corresponding battery died.
Figure 23 shows the best-of-two policy running on the second load profile. The curves show
the characteristic discharge/recovery pattern, separated by a step separation caused by the internal
resistance of the battery (when the battery is recovering its voltage is open circuit, when it is loaded
it is then reduced by the internal resistance).
371

fiF OX , L ONG & M AGAZZENI

Figure 23: A run showing the behaviour of the best-of-two policy.

Figure 24: A run showing the behaviour of the plan-based policy.

The load and voltage curves for the red curve (battery B1 ) are fuzzy because there is more noise
in the readings from these sensors than for the other battery. This phenomenon is consistently a
problem for B1 and is not dependent on the battery, but appears to be a feature of the circuit itself.
372

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Figure 25: Best-of-two and the plan-based policy, both running on the same load profile. It can be
seen that the lifetime achieved by the plan-based policy is longer, and the number of
switches is also reduced. The y-axis has been removed, but load is measured in tenths
of milliamps and voltage in tenths of millivolts, as before.

The strange striations for the green (B2 ) curve at the start of the graph are due to a failure
of the Arduino to correctly capture the battery voltage over this period, but it does not affect the
performance of the policy (we have simple fail safes to ensure that spurious data of this sort do not
affect our performance).
Figure 24 shows the behaviour of the plan-based policy running on the second load profile. The
top two curves represent the usage of the two batteries, B1 and B2 . Battery B1 (the red curve)
is used for the first 10,000 half-seconds, then B2 is briefly used before the policy switches back
to B1 until about half way through the run. In the second half of the graph, the two batteries are
interleaved, and the rising curves of B1 correspond to the periods in which B2 is in use and B1 is
resting.
The alternating load is represented by the bottom two curves. It can be seen that when the load
changes, the measured voltage changes (the top curve registers a slight blip). This is because of the
internal resistance which means that there is a lower voltage loss in the battery when the current
changes. We would expect this to be about 34mV (if the internal resistance is 0.34) because the
difference in current is 0.1A. It is actually higher than that, but this appears to be because there is
a slight over-reaction to changes in the load, causing the battery voltage to drop sharply when the
battery is first loaded, and then pull back, while the battery tends to recover sharply, and then fall
back in line, when its load is reduced.
Figure 25 shows the best-of-two policy and the plan-based policy both being run on the second
load profile side-by-side. The red plots are B1 and green are B2 . The blue and purple points shows
373

fiF OX , L ONG & M AGAZZENI

Figure 26: Two executions of the plan-based policy on different load profiles. The y-axis has been
removed, but load is measured in tenths of milliamps and voltage in tenths of millivolts,
as before.

where B1 /B2 serviced the load (and the value of the load) for best-of-two, while the black points,
slightly displaced above these, show where B2 serviced the load under the plan-based policy (B1
serviced the load the rest of the time). The voltage curves for the plan-based policy have been offset
from curves for best-of-two so that they can be displayed on the same plot. The labelling on the
y-axis has been removed to avoid confusion. We can see three interesting features:
1. The plan-based policy tends to use B1 first and B2 second, although not sequentially.
2. The plan-based policy runs for longer, demonstrating that increased lifetime is achieved.
3. Best-of-two essentially alternates between the batteries (minor variations are due to slight
discrepancies in the batteries and other factors).
Figure 26 shows a comparison of the plan-based policy working on the first and second load
profiles. The performance of the policy on the first load profile is shown in the upper voltage curves
and the upper load curves, while the curves for the second load profile have been displaced to
differentiate them. The plot highlights the similarity in the way the policy manages the batteries in
each case: the general strategy is to run B1 until it is at the knee, resting it only briefly in this period,
then oscillate between B1 and B2 at low frequency for a while, before entering a period in which
B1 is rapidly switched with B2 as B1 converges on empty. The policy then finishes off with B2 .
374

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Figure 27: The plan-based policy plotted with estimated available charge. The y-axis has been
removed, but load is measured in tenths of milliamps and voltage in tenths of millivolts,
as before. Charge is measured in tenths of milliamp hours.

An interesting difference is a consequence of the (random) loads: B1 is faced with heavier
loads during the first part of the second profile, so it dies faster than in the first profile. However, B2
faces a slightly less arduous time during the second half of the second profile and manages to last
considerably longer. In particular, the load in the interval 30,00033,000 was a high load serviced
by B2 in the first profile, while the same period happens to be a lower load in the second profile.
This is a key reason why B2 dies faster in the first profile: its available charge is depleted in that
period and there is no real opportunity to rest it after that point. The final period of load in the first
profile is a high load and that kills B2 quickly, while the final period of load in the second profile
is a lower one. This allows B2 to recover some of its bound charge over that period, depleting its
available charge more slowly and sustaining it a little longer in that critical period.
In Figure 26 the upper policy execution switches frequently in the window between 41,000 and
43,000 half seconds, just before B1 dies. This is because the plan-based policy includes a default
action to switch to the other battery to avoid the currently loaded battery dying prematurely. The
reason for this is to protect the batteries and the policy from the effects of errors in the sensor data
that propagate into the state of charge model. The effect of the default action in this case is to
cause the policy to switch to B2 when B1 is almost out of charge, but back to B1 as soon as it has
recovered enough to be able to be loaded once again (according to the state of charge model).
Figure 27 shows the policy for the first load profile again, this time plotted with the estimated
available charge (based on the voltage readings and the voltage model). The graph shows several
important features. The black crosshairs mark the estimated available charge (measured in 0.1mAh
units) for B1 and the grey crosshairs show it for B2. The discontinuities are due to the changing
375

fiF OX , L ONG & M AGAZZENI

Figure 28: The sequencing policy showing its shorter lifetime on load profile 2.
load values. There should be no discontinuity, because the model adjusts for the load (using our
estimated internal resistance), but it is clear that there is an additional effect here that we cannot
capture this way. As we have already mentioned, it is also the case that the discrepancy between
battery terminal voltage readings for the different loads should be 0.1A  0.34 = 34mV , where
0.1A is the difference in load and 0.34 is the internal resistance, but the graph shows differences
that are much greater. This effect appears to worsen as the battery discharges (see the widening
gaps between the loaded and unloaded voltages recorded for the batteries in the red/green curves 
particularly for the red curve). However, interestingly, the voltage-capacity model seems to be
marginally less unstable for lower states of charge (the steps get slightly smaller in these cases for
the black curve).
As can also be seen, the available charge model breaks down in some situations (when the
observations cannot be fitted consistently to the initial state we assumed for the battery). This leads
to some of the available charge values being negative (particularly in the 4200045000 period). This
causes the policy to revert to the default action, but the somewhat simplistic implementation of the
default leads to the oscillation between batteries during this period.
Figure 28 shows the results obtained by draining the batteries in sequence, using the second
load profile. This performance is optimal in terms of switching, but the lifetime achieved is much
shorter than that achieved by the plan-based policy and similar to the lifetime of the best-of-two
for this case. The fact that best-of-two does worse than sequential scheduling for this profile is
probably due to variation in the battery behaviour: it seems likely that best-of-two should perform
more similarly to the results in the other load profiles.
It can be clearly seen that the plan-based policy achieves a consistently longer lifetime than the
best-of-two policy, with significantly reduced switching. The results are summarised in Table 5.
376

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Load
Profile

Plan-based Policy
Lifetime Switches

Best-of-two
Lifetime Switches

Sequential
Lifetime Switches

Max.

1
2

7.887
8.033

71
47

7.534
7.000

73
81


7.079


1

8.77
8.91

3
4
5
6
7
8
9
10

7.974
7.831
7.030
7.120
7.669
7.677
8.341
6.972

91
158
17
36
21
88
33
13

7.563
6.998
6.226
7.085
7.645
6.515
5.901
6.890

705
701
609
706
649
584
567
690



















9.04
9.23
9.11
8.81
9.11
8.87
8.91
8.92

Mean

7.653

57.5

6.936

651.4

7.079

1

8.97

Table 5: Table summarising results of physical experiments. Lifetimes are given in hours, but
these are as reported using the Arduino clock and our measurements revealed that an hour
measured by our Arduino was approximately 1.4 hours of real time. The first two experiments used lower switching frequency for the Best-of-two policy: as can be seen, the
increased frequency for the later experiments does not offer any apparent advantage. These
two results are not included in calculating the mean number of switches for the Best-of-two
policy.
A paired t-test on these results shows that they are significant (p = 0.013). We expect that these
improvements will be even more marked in the case of n > 2 batteries, but performing such experiments is the topic of future work. The final column in the table, labelled max shows the
theoretical maximum lifetime of the batteries for the given load profile. These values are probably
rather higher than the maximum value that could be achieved in practice, since the point at which
the batteries are considered dead is based on observed terminal voltages when loaded. The internal
resistance of the batteries means that this point is earlier than it is in the idealised battery model
used in the simulation. The average efficiency of the batteries is 85% with our policy and 77% with
the best-of-two compared with this theoretical maximum, which is consistent with both the expectation that the theoretical value is rather high and with previously reported performance of battery
management systems that typically achieve around 80% efficiency.

8. Future Work
This paper brings together three distinct directions of research. Firstly, the work is concerned with
a specific problem and its solution: the management of multiple batteries. Secondly, we develop
and exploit techniques for planning with PDDL + and continuous non-linear dynamics. Thirdly,
we devise and implement an approach to policy construction based on planning for deterministic
samples. Each of these directions offers scope for further work.
377

fiF OX , L ONG & M AGAZZENI

Figure 29: The battery voltage, load and estimated charge curves for the plan-based policy running
on load profile 4. The y axis shows millivolts, 0.1 milliamps or 0.1 milliamp hours for
each curve respectively.

The research on battery management has potential for real application and our physical experiments reveal that the theoretical results translate into measurable benefits. The physical experiments
show higher switching rates for the plan-based policy control than our simulation results lead one to
expect and we have noted that a key reason for this is the errors in the attempt to diagnose the state
of charge of the batteries from noisy sensed voltage data. We anticipate that more robust sensing
could resolve this problem to some extent, but a further modification is to consider a more careful
implementation of the default action and of the tracking of state of charge. Figure 29 shows that in
the plan-based policy run on the fourth load profile, the estimated available charge is often judged
to be negative! This triggers application of the default action and in many cases these switches are
contrary to the policy choices on either side of the spurious data point. In fact, of the 158 switches
in this execution run, at least 90 are generated by spurious data triggering default actions. Similarly,
for load profiles 13 we can identify at least 50, 8 and 54 cases respectively, in which the default
action causes a switch in batteries against the advice of the policy for more sensible state of charge
estimates on either side of the switches. This strongly suggests that a more careful implementation
of the estimation of the state of charge, respecting the expected continuity of the behaviour, could
lead to much better switching rates and better stability in the behaviour of the policy.
The experiments would obviously benefit from being performed on more a robustly constructed
experimental apparatus and from additional runs to accumulate additional data. We hope to continue to pursue this direction in collaboration with commercial partners who might be interested in
exploiting our ideas to achieve fielded systems.
378

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

The work on continuous planning, particularly for problems that include complex processes
and events, remains a focus of research interest for us. We are now considering problems arising
in different domains, including control of autonomous underwater vehicles and control of power
systems (Bell, Coles, Coles, Fox, & Long, 2009). We are also exploring the ways in which hybrid
planning might interface effectively with lower control levels through a shared model of system
dynamics. The role of dynamic discretisation in managing complex process dynamics, particularly
for non-linear behaviours, is one that we are continuing to explore.
Our work on the construction of policies via classification of trajectory samples built with a
planner applied to sampled initial states is also a direction we are continuing to pursue. Our recent
work on algal bloom mapping (Fox et al., 2012) indicates the directions we are considering. In
particular, the states used in a planning model to allow a planner to solve sampled problem instances
need not be the same as the states that are used in learning a policy. This is important, because
the planner can exploit knowledge available in determinised instances of the problem to find high
quality solutions and we can then hope that by careful selection of the observable elements of the
visited states to be presented to the classifier, the classification process can discover correlations
between the observable states and the actions selected by the planner in those states, in order to
identify effective policy structures. This is a potentially powerful way to approach planning under
uncertainty and we intend to investigate it much further.

9. Conclusions
This paper has presented an interesting and potentially important problem, managing systems powered by multiple independent batteries, and constructed a novel solution to it. In doing so we have
brought together research on planning and policy learning to arrive at a new and powerful approach.
We have experimentally evaluated our plans and learned policies in simulation and these results reveal that our solution can achieve better than 99% efficiency compared with the theoretical optimal
(which is unachievable in practice). Not only do we achieve very high efficiencies, but we do so at
low cost in terms of battery switching. This is beneficial because switching is wasteful of energy
and tends to reduce the quality of service without additional smoothing circuitry that adds to energy
losses.
Having confirmed our results in simulation we have gone on to explore the behaviour of the
ideas in physical tests and those results confirm that real batteries are far less well-behaved than their
simulated counterparts. Nevertheless, the policies we learn continue to behave very successfully 
indeed we get results showing between 5% and 15% lifetime improvements over the best-of-two
policy on equal load profiles, while still achieving lower switching rates.
Our approach to solving the battery usage problem adapts several existing technologies for
automated planning, to solve a problem that can be seen as an MDP. We use Monte Carlo sampling
to generate instances of determinised load profiles and solving these problems using an optimal
deterministic solver, before combining the solutions to form a policy. Adopting a sampling approach
to tackling problem-solving under uncertainty has become increasingly common and one of the
reasons for this is that it usually offers better scaling opportunities than attempting to explicitly
reason with distributions. Our policy construction approach adapts the use of machine learning to
construct a classifier. In the construction of high quality solutions to deterministic problems, we use
a special variable-range discretisation to solve a non-linear continuous optimisation problem with
very high accuracy, while exploring a very small proportion of the state space.
379

fiF OX , L ONG & M AGAZZENI

Our approach is scalable and effective. Although the solution as we implement it for this paper
is domain-specific in several respects, the components are general and we have already begun to
illustrate this point by adapting the approach to other problems. The elements that are most tailored
to our problem are the selection of the discretisation range and the search heuristic. However, we
believe that the characteristics of the multiple battery usage problem are shared, in outline, by other
domains and expect the approach can be adapted to these domains with relative ease.

Acknowledgments
We would like to thank Marijn Jongerden and Boudewijn Haverkort for introducing us to the multiple battery usage problem, and drawing our attention to the scheduling problem and related policybased approaches. We would also like to extend our thanks to the anonymous reviewers and the
handling editor, Carmel Domshlak, for their help in improving the text of the paper.
This work was partially funded by the EPSRC Project Automated Modelling and Reformulation in Planning (EP/G0233650).

References
Alur, R., & Dill, D. L. (1994). A Theory of Timed Automata. Theoretical Computer Science,
126(2), 183235.
Bell, K. R. W., Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2009). The Role of AI Planning as a
Decision Support Tool in Power Substation Management. AI Communications, 22(1), 3757.
Benini, L., Castelli, G., Macii, A., Macii, E., Poncino, M., & Scarsi, R. (2001). Discrete-Time
Battery Models for System-Level Low-Power Design. Very Large Scale Integration (VLSI)
Systems, IEEE Transactions on, 9(5), 630 640.
Benini, L., Macii, A., Macii, E., Poncino, M., & Scarsi, R. (2003). Scheduling Battery Usage in
Mobile Systems. Very Large Scale Integration (VLSI) Systems, IEEE Transactions on, 11(6),
1136  1143.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Chang, H. S., Givan, R., & Chong, E. K. P. (2000). On-line Scheduling via Sampling. In Proceedings of Int. Conf. on Automated Planning and Scheduling (ICAPS), pp. 6271.
Della Penna, G., Intrigila, B., Magazzeni, D., & Mercorio, F. (2009). UPMurphi: a Tool for Universal Planning on PDDL+ Problems. In Proceedings of Int. Conf. on Automated Planning and
Scheduling (ICAPS), pp. 106113.
Eberle, W. A. T. (2008). MOSFET Current Source Gate Drivers, Switching Loss Modeling and
Frequency Dithering Control for MHz Switching Frequency DC-DC Converters. Ph.D. thesis,
Queens University, Kingston, Ontario, Canada.
Fern, A., Yoon, S. W., & Givan, R. (2004). Learning Domain-Specific Control Knowledge from
Random Walks. In Proceedings of Int. Conf. on Automated Planning and Scheduling (ICAPS),
pp. 191199.
Fern, A., Yoon, S. W., & Givan, R. (2006). Approximate Policy Iteration with a Policy Language Bias: solving Relational Markov Decision Processes. J. Artificial Intelligence Research
(JAIR), 25, 75118.
380

fiP LAN - BASED P OLICIES FOR E FFICIENT M ULTIPLE BATTERY L OAD M ANAGEMENT

Fox, M., & Long, D. (2006). Modelling Mixed Discrete-Continuous Domains for Planning. J.
Artificial Intelligence Research (JAIR), 27, 235297.
Fox, M., Long, D., & Magazzeni, D. (2011). Automatic Construction of Efficient Multiple Battery Usage Policies. In Proceedings of Int. Conf. on Automated Planning and Scheduling,
(ICAPS), pp. 7481.
Fox, M., Long, D., & Magazzeni, D. (2012). Plan-based Policy-Learning for Autonomous Feature
Tracking. In Proceedings of Int. Conf. on Automated Planning and Scheduling (ICAPS).
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009). The WEKA
Data Mining Software: An Update. SIGKDD Explorations, 11(1), 1018.
Howey, R., Long, D., & Fox, M. (2004). VAL: Automatic Plan Validation, Continuous Effects
and Mixed Initiative Planning Using PDDL. In Proceedings of Int. Conf. on Tools with AI
(ICTAI), pp. 294301.
Jongerden, M., Haverkort, B., Bohnenkamp, H., & Katoen, J.-P. (2009). Maximizing System Lifetime by Battery Scheduling. In Proceedings of 39th Annual IEEE/IFIP Int. Conf. on Dependable Systems and Networks (DSN 2009), pp. 6372.
Jongerden, M., & Haverkort, B. (2008). Battery Modeling. Tech. rep. TR-CTIT-08-01, Centre for
Telematics and Information Technology, University of Twente.
Jongerden, M., & Haverkort, B. (2009). Which Battery Model to Use?. IET Software (Special Issue
on Performance Engineering), 3(6), 445457.
Manwell, J., & McGowan, J. (1993). Lead Acid Battery Storage Model for Hybrid Energy Systems.
Solar Energy, 50, 399405.
Manwell, J., & McGowan, J. (1994). Extension of the Kinetic Battery Model for Wind/Hybrid
Power Systems. In Proceedings of 5th European Wind Energy Association Conference
(EWEC), pp. 284289.
Mausam, & Weld, D. S. (2008). Planning with Durative Actions in Stochastic Domains. J. Artificial
Intelligence Research (JAIR), 31, 3382.
Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam (2009). A Heuristic Search
Approach to Planning with Continuous Resources in Stochastic Domains. J. Artificial Intelligence Research (JAIR), 34, 2759.
Quinlan, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA.
Rao, R., Vrudhula, S., & Rakhmatov, D. (2003). Analysis of Discharge Techniques for Multiple
Battery Systems. In Proceedings of the 2003 Int. Symposium on Low Power Electronics and
Design (ISLPED 03), pp. 4447.
Sanner, S., & Boutilier, C. (2009). Practical Solution Techniques for First-Order MDPs. Artificial
Intelligence, 173(5-6), 748788.
SBS Implementers Forum (2000). System Management Bus (SMBus) Specification, Version 2.0.
Tech. rep., The System Management Interface Forum, Inc.
Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Incremental Plan Aggregation for Generating Policies in MDPs. In Proceedings of 9th Int. Conf. on Autonomous Agents and MultiAgent Systems (AAMAS), pp. 12311238.
381

fiF OX , L ONG & M AGAZZENI

Wang, T., & Cassandras, C. G. (2011). Optimal Control of Multi-Battery Energy-Aware Systems.
In Proceedings of 50th IEEE Conference on Decision and Control and European Control
Conference (CDC-ECC), pp. 14971502.
Yoon, S. W., Fern, A., & Givan, R. (2007). Using Learned Policies in Heuristic-Search Planning.
In Proceedings of Int. Joint Conf. on Artificial Intelligence (IJCAI), pp. 20472053.

382

fiJournal of Artificial Intelligence Research 44 (2012) 533-585

Submitted 03/12; published 07/12

Domain and Function: A Dual-Space Model
of Semantic Relations and Compositions
Peter D. Turney

peter.turney@nrc-cnrc.gc.ca

National Research Council Canada
Ottawa, Ontario, Canada, K1A 0R6

Abstract
Given appropriate representations of the semantic relations between carpenter and wood
and between mason and stone (for example, vectors in a vector space model), a suitable
algorithm should be able to recognize that these relations are highly similar (carpenter is
to wood as mason is to stone; the relations are analogous). Likewise, with representations
of dog, house, and kennel, an algorithm should be able to recognize that the semantic
composition of dog and house, dog house, is highly similar to kennel (dog house and kennel
are synonymous). It seems that these two tasks, recognizing relations and compositions,
are closely connected. However, up to now, the best models for relations are significantly
different from the best models for compositions. In this paper, we introduce a dual-space
model that unifies these two tasks. This model matches the performance of the best
previous models for relations and compositions. The dual-space model consists of a space
for measuring domain similarity and a space for measuring function similarity. Carpenter
and wood share the same domain, the domain of carpentry. Mason and stone share the
same domain, the domain of masonry. Carpenter and mason share the same function, the
function of artisans. Wood and stone share the same function, the function of materials.
In the composition dog house, kennel has some domain overlap with both dog and house
(the domains of pets and buildings). The function of kennel is similar to the function of
house (the function of shelters). By combining domain and function similarities in various
ways, we can model relations, compositions, and other aspects of semantics.

1. Introduction
The distributional hypothesis is that words that occur in similar contexts tend to have similar
meanings (Harris, 1954; Firth, 1957). Many vector space models (VSMs) of semantics use
a wordcontext matrix to represent the distribution of words over contexts, capturing the
intuition behind the distributional hypothesis (Turney & Pantel, 2010). VSMs have achieved
impressive results at the level of individual words (Rapp, 2003), but it is not clear how to
extend them to the level of phrases, sentences, and beyond. For example, we know how to
represent dog and house with vectors, but how should we represent dog house ?
One approach to representing dog house is to treat it as a unit, the same way we handle
individual words. We call this the holistic or noncompositional approach to representing
phrases. The holistic approach may be suitable for some phrases, but it does not scale up.
With a vocabulary of N individual words, we can have N 2 two-word phrases, N 3 threeword phrases, and so on. Even with a very large corpus of text, most of these possible
phrases will never appear in the corpus. People are continually inventing new phrases, and
we are able to understand these new phrases although we have never heard them before;
we are able to infer the meaning of a new phrase by composition of the meanings of the
c
2012
National Research Council Canada. Reprinted with permission.

fiTurney

component words. This scaling problem could be viewed as an issue of data sparsity, but
it is better to think of it as a problem of linguistic creativity (Chomsky, 1975; Fodor &
Lepore, 2002). To master natural language, algorithms must be able to represent phrases
by composing representations of individual words. We cannot treat all n-grams (n > 1) the
way we treat unigrams (individual words). On the other hand, the holistic approach is ideal
for idiomatic expressions (e.g., kick the bucket) for which the meaning cannot be inferred
from the component words.
The creativity and novelty of natural language require us to take a compositional approach to the majority of the n-grams that we encounter. Suppose we have vector representations of dog and house. How can we compose these representations to represent dog
house ? One strategy is to represent dog house by the average of the vectors for dog and
house (Landauer & Dumais, 1997). This simple proposal actually works, to a limited degree
(Mitchell & Lapata, 2008, 2010). However boat house and house boat would be represented
by the same average vector, yet they have different meanings. Composition by averaging
does not deal with the order sensitivity of phrase meaning. Landauer (2002) estimates that
80% of the meaning of English text comes from word choice and the remaining 20% comes
from word order.
Similar issues arise with the representation of semantic relations. Given vectors for
carpenter and wood, how can we represent the semantic relations between carpenter and
wood ? We can treat carpenter :wood as a unit and search for paraphrases of the relations
between carpenter and wood (Turney, 2006b). In a large corpus, we could find phrases such
as the carpenter cut the wood, the carpenter used the wood, and wood for the carpenter. This
variation of the holistic approach can enable us to recognize that the semantic relations
between carpenter and wood are highly similar to the relations between mason and stone.
However, the holistic approach to semantic relations suffers from the same data sparsity
and linguistic creativity problems as the holistic approach to semantic composition.
We could represent the relation between carpenter and wood by averaging their vectors.
This might enable us to recognize that carpenter is to wood as mason is to stone, but it
would incorrectly suggest that carpenter is to wood as stone is to mason. The problem of
order sensitivity arises with semantic relations just as it arose with semantic composition.
Many ideas have been proposed for composing vectors (Landauer & Dumais, 1997;
Kintsch, 2001; Mitchell & Lapata, 2010). Erk and Pado (2008) point out two problems
that are common to several of these proposals. First, often they do not have the adaptive
capacity to represent the variety of possible syntactic relations in a phrase. For example, in
the phrase a horse draws, horse is the subject of the verb draws, whereas it is the object of
the verb in the phrase draws a horse. The composition of the vectors for horse and draws
must be able to adapt to a variety of syntactic contexts in order to properly model the
given phrases. Second, a single vector is too weak to handle a long phrase, a sentence, or
a document. A single vector can only encode a fixed amount of structural information if
its dimensionality is fixed, but there is no upper limit on sentence length, and hence on the
amount of structure to be encoded (Erk & Pado, 2008, p. 898). A fixed dimensionality
does not allow information scalability.
Simple (unweighted) averaging of vectors lacks adaptive capacity, because it treats all
kinds of composition in the same way; it does not have the flexibility to represent different
modes of composition. A good model must have the capacity to adapt to different situations.
534

fiDomain and Function: A Dual-Space Model

For example, with weighted averaging, the weights can be tuned for different syntactic
contexts (Mitchell & Lapata, 2008, 2010).
Information scalability means that the size of semantic representations should grow in
proportion to the amount of information that they are representing. If the size of the
representation is fixed, eventually there will be information loss. On the other hand, the
size of representations should not grow exponentially.
One case where the problem of information scalability arises is with approaches that
map multiple vectors into a single vector. For example, if we represent dog house by adding
the vectors for dog and house (mapping two vectors into one), there may be information
loss. As we increase the number of vectors that are mapped into a single vector, we will
eventually reach a point where the single vector can no longer contain the information from
the multiple vectors. This problem can be avoided if we do not try to map multiple vectors
into a single vector.
Suppose we have a k-dimensional vector with floating point elements of b bits each. Such
a vector can hold at most kb bits of information. Even if we allow b to grow, if k is fixed,
we will eventually have information loss. In a vector space model of semantics, the vectors
have some resistance to noise. If we perturb a vector with noise below some threshold ,
there is no significant change in the meaning that it represents. Therefore we should think
of the vector as a hypersphere with a radius of , rather than a point. We may also put
bounds [r, +r] on the range of the values of the elements in the vector.1 There is a finite
number N of hyperspheres of radius  that can be packed into a bounded k-dimensional
space (Conway & Sloane, 1998). According to information theory, if we have a finite set
of N messages, then we need at most log2 (N ) bits to encode a message. Likewise, if we
have a finite set of N vectors, then a vector represents at most log2 (N ) bits of information.
Therefore the information capacity of a single vector in bounded k-dimensional space is
limited to log2 (N ) bits.
Past work suggests that recognizing relations and compositions are closely connected
tasks (Kintsch, 2000, 2001; Mangalath, Quesada, & Kintsch, 2004). The goal of our research
is a unified model that can handle both compositions and relations, while also resolving the
issues of linguistic creativity, order sensitivity, adaptive capacity, and information scalability.
These considerations have led us to a dual-space model, consisting of a domain space for
measuring domain similarity (i.e., topic, subject, or field similarity) and a function space
for measuring function similarity (i.e., role, relationship, or usage similarity).
In an analogy a : b :: c : d (a is to b as c is to d; for example, traffic is to street as water is
to riverbed), a and b have relatively high domain similarity (traffic and street come from the
domain of transportation) and c and d have relatively high domain similarity (water and
riverbed come from the domain of hydrology). On the other hand, a and c have relatively
high function similarity (traffic and water have similar roles in their respective domains;
they are both things that flow) and b and d have relatively high function similarity (street
and riverbed have similar roles in their respective domains; they are both things that carry
things that flow). By combining domain and function similarity in appropriate ways, we
1. In models where the vectors are normalized to unit length (e.g., models that use cosine to measure
similarity), the elements must lie within the range [1, +1]. If any element is outside this range, then
the length of the vector will be greater than one. In general, floating point representations have minimum
and maximum values.

535

fiTurney

can recognize that the semantic relations between traffic and street are analogous to the
relations between water and riverbed.
For semantic composition, the appropriate way to combine similarities may depend on
the syntax of the composition. Lets focus on noun-modifier composition as an example.
In the noun-modifier phrase ab (for instance, brain doctor), the head noun b (doctor) is
modified by an adjective or noun a (brain). Suppose we have a word c (neurologist) that
is synonymous with ab. The functional role of the noun-modifier phrase ab is determined
by the head noun b (a brain doctor is a kind of doctor) and b has a relatively high degree
of function similarity with c (doctor and neurologist both function as doctors). Both a and
b have a high degree of domain similarity with c (brain, doctor, and neurologist all come
from the domain of clinical neurology). By combining domain and function similarity, we
can recognize that brain doctor is synonymous with neurologist.
Briefly, the proposal is to compose similarity measures instead of composing vectors.
That is, we apply various mathematical functions to combine cosine similarity measures,
instead of applying the functions directly to the vectors. This addresses the information
loss problem, because we preserve the vectors for the individual component words. (We do
not map multiple vectors into a single vector.) Since we have two different spaces, we also
have flexibility to address the problem of adaptive capacity.2 This model is compositional,
so it resolves the linguistic creativity problem. We deal with order sensitivity by combining
similarity measures in ways that recognize the effects of word order.
It might be argued that what we present here is not a model of semantic composition, but
a way to compare the words that form two phrases in order to derive a measure of similarity
of the phrases. For example, in Section 4.3 we derive a measure of similarity for the phrases
environment secretary and defence minister, but we do not actually provide a representation
for the phrase environment secretary. On the other hand, most past work on the problem
of semantic composition (reviewed in Section 2.1) yields a representation for the composite
phrase environment secretary that is different from the union of the representations of the
component words, environment and secretary.
This argument is based on the assumption that the goal of semantic composition is to
create a single, general-purpose, stand-alone representation of a phrase, as a composite,
distinct from the union of the representations of the component words. This assumption
is not necessary and our approach does not use this assumption. We believe that this
assumption has held back progress on the problem of semantic composition.
We argue that what we present here is a model of semantic composition, but it is composition of similarities, not composition of vectors. Vectors can represent individual words, but
similarities inherently represent relations between two (or more) things. Composing vectors
can yield a stand-alone representation of a phrase, but composing similarities necessarily
yields a linking structure that connects a phrase to other phrases. Similarity composition
does not result in a stand-alone representation of a phrase, but practical applications do
not require stand-alone representations. Whatever practical tasks can be performed with
stand-alone representations of phrases, we believe can be performed equally well (or better)
with similarity composition. We discuss this issue in more depth in Section 6.
2. Two similarity spaces give us more options for similarity composition than one space, just as two types
of characters (0 and 1) give us more options for generating strings than one type of character (0 alone).

536

fiDomain and Function: A Dual-Space Model

The next section surveys related work on the modeling of semantic composition and
semantic relations. Section 3 describes how we build domain and function space. To test
the hypothesis that there is value in having two separate spaces, we also create mono space,
which is the merger of the domain and function spaces. We then present four sets of experiments with the dual-space model in Section 4. We evaluate the dual-space approach with
multiple-choice analogy questions from the SAT (Turney, 2006b), multiple-choice nounmodifier composition questions derived from WordNet (Fellbaum, 1998), phrase similarity rating problems (Mitchell & Lapata, 2010), and similarity versus association problems
(Chiarello, Burgess, Richards, & Pollock, 1990). We discuss the experimental results in
Section 5. Section 6 considers some theoretical questions about the dual-space model. Limitations of the model are examined in Section 7. Section 8 concludes.
This paper assumes some familiarity with vector space models of semantics. For an
overview of semantic VSMs, see the papers in the Handbook of Latent Semantic Analysis
(Landauer, McNamara, Dennis, & Kintsch, 2007), the review in Mitchell and Lapatas
(2010) paper, or the survey by Turney and Pantel (2010).

2. Related Work
Here we examine related work with semantic composition and relations. In the introduction, we mentioned four problems with semantic models, which yield four desiderata for a
semantic model:
1. Linguistic creativity: The model should be able to handle phrases (in the case of
semantic composition) or word pairs (in the case of semantic relations) that it has
never seen before, when it is familiar with the component words.
2. Order sensitivity: The model should be sensitive to the order of the words in a
phrase (for composition) or a word pair (for relations), when the order affects the
meaning.
3. Adaptive capacity: For phrases, the model should have the flexibility to represent
different kinds of syntactic relations. For word pairs, the model should have the
flexibility to handle a variety of tasks, such as measuring the degree of relational
similarity between two pairs (see Section 4.1) versus measuring the degree of phrasal
similarity between two pairs (see Section 4.3).
4. Information scalability: For phrases, the model should scale up with neither loss of
information nor exponential growth in representation size as the number of component
words in the phrases increases. For n-ary semantic relations (Turney, 2008a), the
model should scale up with neither loss of information nor exponential growth in
representation size as n, the number of terms in the relations, increases.
We will review past work in the light of these four considerations.
2.1 Semantic Composition
Let ab be a phrase, such as a noun-modifier phrase, and assume that we have vectors a and
b that represent the component words a and b. One of the earliest proposals for semantic
composition is to represent ab by the vector c that is the average of a and b (Landauer &
537

fiTurney

Dumais, 1997). If we are using a cosine measure of vector similarity, taking the average of a
set of vectors (or their centroid) is the same as adding the vectors, c = a+b. Vector addition
works relatively well in practice (Mitchell & Lapata, 2008, 2010), although it lacks order
sensitivity, adaptive capacity, and information scalability. Regarding order sensitivity and
adaptive capacity, Mitchell and Lapata (2008, 2010) suggest using weights, c = a+b, and
tuning the weights to different values for different syntactic relations. In their experiments
(Mitchell & Lapata, 2010), weighted addition performed better than unweighted addition.
Kintsch (2001) proposes a variation of additive composition
in which c is the sum of a,
P
b, and selected neighbours ni of a and b, c = a + b + i ni . The neighbours are vectors for
other words in the given vocabulary (i.e., other rows in the given wordcontext matrix). The
neighbours are chosen in a manner that attempts to address order sensitivity and adaptive
capacity, but there is still a problem with information scalability due to fixed dimensionality.
Utsumi (2009) presents a similar model, but with a different way of selecting neighbours.
Mitchell and Lapata (2010) found that a simple additive model peformed better than an
additive model that included neighbours.
Mitchell and Lapata (2008, 2010) suggest element-wise multiplication as a composition
operation, c = a fi b, where ci = ai  bi . Like vector addition, element-wise multiplication suffers from a lack of order sensitivity, adaptive capacity, and information scalability.
Nonetheless, in an experimental evaluation of seven compositional models and two noncompositional models, element-wise multiplication had the best performance (Mitchell &
Lapata, 2010).
Another approach is to use a tensor product for composition (Smolensky, 1990; Aerts
& Czachor, 2004; Clark & Pulman, 2007; Widdows, 2008), such as the outer product,
C = a  b. The outer product of two vectors (a and b), each with n elements, is an n  n
matrix (C). The outer product of three vectors is an n  n  n third-order tensor. This
results in an information scalability problem: The representations grow exponentially large
as the phrases grow longer.3 Furthermore, the outer product did not perform as well as
element-wise multiplication in Mitchell and Lapatas (2010) experiments. Recent work with
tensor products (Clark, Coecke, & Sadrzadeh, 2008; Grefenstette & Sadrzadeh, 2011) has
attempted to address the issue of information scalability.
Circular convolution is similar to the outer product, but the outer product matrix is
compressed back down to a vector, c = a ~ b (Plate, 1995; Jones & Mewhort, 2007).
This avoids information explosion, but it results in information loss. Circular convolution
performed poorly in Mitchell and Lapatas (2010) experiments.
Baroni and Zamparelli (2010) and Guevara (2010) suggest another model of composition
for adjective-noun phrases. The core strategy that they share is to use a few holistic vectors
to train a compositional model. With partial least squares regression (PLSR), we can learn
a linear model that maps the vectors for the component nouns and adjectives to linear
approximations of the holistic vectors for the phrases. The linguistic creativity problem is
avoided because the linear model only needs a few holistic vectors for training; there is no
need to have holistic vectors for all plausible adjective-noun phrases. Given a phrase that is
not in the training data, the linear model predicts the holistic vector for the phrase, given
3. There are ways to avoid the exponential growth; for example, a third-order tensor with a rank of 1 on
all three modes may be compactly encoded by its three component vectors. Kolda and Bader (2009)
discuss compact tensor representations.

538

fiDomain and Function: A Dual-Space Model

the component vectors for the adjective and the noun. This works well for adjective-noun
phrases, but it is not clear how to generalize it to other parts of speech or to longer phrases.
One application for semantic composition is measuring the similarity of phrases (Erk &
Pado, 2008; Mitchell & Lapata, 2010). Kernel methods have been applied to the closely
related task of identifying paraphrases (Moschitti & Quarteroni, 2008), but the emphasis
with kernel methods is on syntactic similarity, rather than semantic similarity.
Neural network models have been combined with vector space models for the task of
language modeling (Bengio, Ducharme, Vincent, & Jauvin, 2003; Socher, Manning, & Ng,
2010; Socher, Huang, Pennington, Ng, & Manning, 2011), with impressive results. The goal
of a language model is to estimate the probability of a phrase or to decide which of several
phrases is the most likely. VSMs can improve the probability estimates of a language model
by measuring the similarity of the words in the phrases and smoothing probabilities over
groups of similar words. However, in a language model, words are considered similar to
the degree that they can be exchanged without altering the probability of a given phrase,
without regard to whether the exchange alters the meaning of the phrase. This is like
function similarity, which measures the degree to which words have similar functional roles,
but these language models are missing anything like domain similarity.
Erk and Pado (2008) present a model that is similar to ours in that it has two parts, a
vector space for measuring similarity and a model of selectional preferences. Their vector
space is similar to domain space and their model of selectional preferences plays a role
similar to function space. An individual word a is represented by a triple, A = ha, R, R1 i,
consisting of the words vector, a, its selectional preferences, R, and its inverse selectional
preferences, R1 . A phrase ab is represented by a pair of triples, hA0 , B 0 i. The triple A0 is
a modified form of the triple A that represents the individual word a. The modifications
adjust the representation to model how the meaning of a is altered by its relation to b in
the phrase ab. Likewise, the triple B 0 is a modified form of the triple B that represents b,
such that B 0 takes into account how a affects b.
When A is transformed to A0 to represent the influence of b on the meaning of a, the
vector a in A is transformed to a new vector a0 in A0 . Let rb be a vector that represents
the typical words that are consistent with the selectional preferences of b. The vector a0
is the composition of a with rb . Erk and Pado (2008) use element-wise multiplication for
composition, a0 = a fi rb . The intention is to make a more like a typical vector x that would
be expected for a phrase xb. Likewise, for b0 in B 0 , we have b0 = b fi ra
Erk and Pados (2008) model and related models (Thater, Furstenau, & Pinkal, 2010)
address linguistic creativity, order sensitivity, adaptive capacity, and information scalability,
but they are not suitable for measuring the similarity of semantic relations. Consider the
analogy traffic is to street as water is to riverbed. Let hA0 , B 0 i represent traffic :street and
let hC 0 , D0 i represent water :riverbed. The transformation of A, B, C, and D to A0 , B 0 ,
C 0 , and D0 reinforces the connection between traffic and street and between water and
riverbed, but it does not help us recognize the relational similarity between traffic :street
and water :riverbed. Of course, these models were not designed for relational similarity, so
this is not surprising. However, the goal here is to find a unified model that can handle
both compositions and relations.
539

fiTurney

2.2 Semantic Relations
For semantic relations, we can make some general observations about order sensitivity. Let
a : b and c : d be two word pairs and let simr (a : b, c : d)  < be a measure of the degree
of similarity between the relations of a : b and c : d. If a : b :: c : d is a good analogy, then
simr (a : b, c : d) will have a relatively high value. In general, a good model of relational
similarity should respect the following equalities and inequalities:

simr (a : b, c : d) = simr (b : a, d : c)

(1)

simr (a : b, c : d) = simr (c : d, a : b)

(2)

simr (a : b, c : d) 6= simr (a : b, d : c)

(3)

simr (a : b, c : d) 6= simr (a : d, c : b)

(4)

For example, given that carpenter :wood and mason :stone make a good analogy, it follows
from Equation 1 that wood :carpenter and stone :mason make an equally good analogy. Also,
according to Equation 2, mason :stone and carpenter :wood make a good analogy. On the
other hand, as suggested by Equation 3, carpenter :wood is not analogous to stone :mason.
Likewise, as indicated by Equation 4, it is a poor analogy to assert that carpenter is to stone
as mason is to wood.
Rosario and Hearst (2001) present an algorithm for classifying word pairs according
to their semantic relations. They use a lexical hierarchy to map word pairs to feature
vectors. Any classification scheme implicitly tell us something about similarity. Two word
pairs that are in the same semantic relation class are implicitly more relationally similar
than two word pairs in different classes. When we consider the relational similarity that is
implied by Rosario and Hearsts (2001) algorithm, we see that there is a problem of order
sensitivity: Equation 4 is violated.
Let simh (x, y)  < be a measure of the degree of hierarchical similarity between the
words x and y. If simh (x, y) is relatively high, then x and y share a common hypernym
relatively close to them in the given lexical hierarchy. In essence, the intuition behind
Rosario and Hearsts (2001) algorithm is, if both simh (a, c) and simh (b, d) are high, then
simr (a : b, c : d) should also be high. That is, if simh (a, c) and simh (b, d) are high enough,
then a : b and c : d should be assigned to the same relation class.
For example, consider the analogy mason is to stone as carpenter is to wood. The common hypernym of mason and carpenter is artisan; we can see that simh (mason, carpenter)
is high. The common hypernym of stone and wood is material; hence simh (stone, wood) is
high. It seems that a good analogy is indeed characterized by high values for simh (a, c) and
simh (b, d). However, the symmetry of simh (x, y) leads to a problem. If simh (b, d) is high,
then simh (d, b) must also be high, but this implies that simr (a : d, c : b) is high. That is, we
incorrectly conclude that mason is to wood as carpenter is to stone (see Equation 4).
Some later work with classifying semantic relations has used different algorithms, but
the same underlying intuition about hierarchical similarity (Rosario, Hearst, & Fillmore,
2002; Nastase & Szpakowicz, 2003; Nastase, Sayyad-Shirabad, Sokolova, & Szpakowicz,
2006). We use a similar intuition here, since similarity in function space is closely related
540

fiDomain and Function: A Dual-Space Model

to hierarchical similarity, simh (x, y), as we will see later (Section 4.4). However, including
domain space in the relational similarity measure saves us from violating Equation 4.
Let simf (x, y)  < be function similarity as measured by the cosine of vectors x and y
in function space. Let simd (x, y)  < be domain similarity as measured by the cosine of
vectors x and y in domain space. Like past researchers (Rosario & Hearst, 2001; Rosario
et al., 2002; Nastase & Szpakowicz, 2003; Veale, 2004; Nastase et al., 2006), we look for
high values of simf (a, c) and simf (b, d) as indicators that simr (a : b, c : d) should be high, but
we also look for high values of simd (a, b) and simd (c, d). Continuing the previous example,
we do not conclude that mason is to wood as carpenter is to stone, because wood does not
belong in the domain of masonry and stone does not belong in the domain of carpentry.
Let D be a determiner (e.g., the, a, an). Hearst (1992) showed how patterns of the form
D X such as D Y (a bird such as a crow) or D Y is a kind of X (the crow is a kind
of bird) can be used to infer that X is a hypernym of Y (bird is a hypernym of crow).
A pairpattern matrix is a VSM in which the rows are word pairs and the columns are
various X . . . Y patterns. Turney, Littman, Bigham, and Shnayder (2003) demonstrated
that a pairpattern VSM can be used to measure relational similarity. Suppose we have a
pair-pattern matrix X in which the word pair a : b corresponds to the row vector xi and c : d
corresponds to xj . The approach is to measure the relational similarity simr (a : b, c : d) by
the cosine of xi and xj .
At first the patterns in these pairpattern matrices were generated by hand (Turney
et al., 2003; Turney & Littman, 2005), but later work (Turney, 2006b) used automatically
generated patterns. Other authors have used variations of this technique (Nakov & Hearst,
2006, 2007; Davidov & Rappoport, 2008; Bollegala, Matsuo, & Ishizuka, 2009; O Seaghdha
& Copestake, 2009). All of these models suffer from the linguistic creativity problem.
Because the models are noncompositional (holistic), they cannot scale up to handle the
huge number of possible pairs. Even the largest corpus cannot contain all the pairs that a
human speaker might use in daily conversation.
Turney (2006b) attempted to handle the linguistic creativity problem within a holistic
model by using synonyms. For example, if a corpus does not contain traffic and street within
a certain window of text, perhaps it might contain traffic and road. If it does not contain
water and riverbed, perhaps it has water and channel. However, this is at best a partial
solution. Turneys (2006b) algorithm required nine days to process 374 multiple choice SAT
analogy questions. Using the dual-space model, without specifying in advance what word
pairs it might face, we can answer the 374 questions in a few seconds (see Section 4.1).
Compositional models scale up better than holistic models.
Mangalath et al. (2004) presented a model for semantic relations that represents word
pairs with vectors of ten abstract relational categories, such as hyponymy, meronymy, taxonomy, and degree. The approach is to construct a kind of second-order vector space in
which the elements of the vectors are degrees of similarity, calculated from cosines with a
first-order wordcontext matrix.
For instance, carpenter :wood can be represented by a second-order vector composed of
ten cosines calculated from first-order vectors. In this second-order vector, the value of the
element corresponding to, say, meronymy would be the cosine of two first-order vectors, x
and y. The vector x would be the sum of the first-order vectors for carpenter and wood.
The vector y would be the sum of several vectors for words that are related to meronymy,
541

fiTurney

such as part, whole, component, portion, contains, constituent, and segment. The cosine of
x and y would indicate the degree to which carpenter and wood are related to meronymy.
Mangalath et al.s (2004) model suffers from information scalability and order sensitivity
problems. Information loss takes place when the first-order vectors are summed and also
when the high-dimensional first-order space is reduced to a ten-dimensional second-order
space. The order sensitivity problem is that the second-order vectors violate Equation 3,
because the pairs c : d and d : c are represented by the same second-order vector.
A natural proposal is to represent a word pair a : b the same way we would represent
a phrase ab. That is, whatever compositional model we have for phrases could also be
applied to word pairs. However any problems that the compositional model has with order
sensitivity or information scalability carry over to word pairs. For example, if we represent
a : b by c = a + b or c = a fi b, then we violate Equation 3, because a + b = b + a and
a fi b = b fi a.

3. Three Vector Spaces
In this section, we describe three vector space models. All three spaces consist of word
context matrices, in which the rows correspond to words and the columns correspond to the
contexts in which the words occur. The differences among the three spaces are in the kinds
of contexts. Domain space uses nouns for context, function space uses verb-based patterns
for context, and mono space is a merger of the domain and function contexts. Mono space
was created in order to test the hypothesis that it is useful to separate the domain and
function spaces; mono space serves as a baseline.
3.1 Constructing the WordContext Matrices
Building the three spaces involves a series of steps. There are three main steps, each of
which has a few substeps. The first and last steps are the same for all three spaces; the
differences in the spaces are the result of differences in the second step.
1. Find terms in contexts: input: a corpus and a lexicon, output: terms in contexts.
1.1. Extract terms from the lexicon and find their frequencies in the corpus.
1.2. Select all terms above a given frequency as candidate rows for the frequency
matrix.
1.3. For each selected term, find phrases in the corpus that contain the term within
a given window size.
1.4. Use a tokenizer to split the phrases into tokens.
1.5. Use a part-of-speech tagger to tag the tokens in the phrases.
2. Build a termcontext frequency matrix: input: terms in contexts, output: a
sparse frequency matrix.
2.1. Convert the tagged phrases into contextual patterns (candidate columns).
2.2. For each contextual pattern, count the number of terms (candidate rows) that
generated the pattern and rank the patterns in descending order of their counts.
2.3. Select the top nc contextual patterns as the columns of the matrix.
542

fiDomain and Function: A Dual-Space Model

2.4. From the initial set of rows (from Step 1.2), drop any row that does not match
any of the top nc contextual patterns, yielding the final set of nr rows.
2.5. For each row (term) and each column (contextual pattern), count the number
of phrases (from Step 1.5) containing the given term and matching the given
pattern, and output the resulting numbers as a sparse frequency matrix.
3. Weight the elements and smooth the matrix: input: a sparse frequency matrix,
output: the singular value decomposition (SVD) of the weighted matrix.
3.1. Convert the raw frequencies to positive pointwise mutual information (PPMI)
values.
3.2. Apply SVD to the PPMI matrix and output the SVD component matrices.
The input corpus in Step 1 is a collection of web pages gathered from university websites
by a webcrawler.4 The corpus contains approximately 51010 words, which comes to about
280 gigabytes of plain text. To facilitate finding term frequencies and sample phrases, we
indexed this corpus with the Wumpus search engine (Buttcher & Clarke, 2005).5 The rows
for the matrices were selected from terms (words and phrases) in the WordNet lexicon.6
We found that selecting terms from WordNet resulted in subjectively higher quality than
simply selecting terms with high corpus frequencies.
In Step 1.1, we extract all unique words and phrases (n-grams) from the index.sense file
in WordNet 3.0, skipping n-grams that contain numbers (only letters, hyphens, and spaces
are allowed in the n-grams). We find the n-gram corpus frequencies by querying Wumpus
with each n-gram. All n-grams with a frequency of at least 100 and at least 2 characters
are candidate rows in Step 1.2. For each selected n-gram, we query Wumpus to find a
maximum of 10,000 phrases in Step 1.3.7 The phrases are limited to a window of 7 words
to the left of the n-gram and 7 words to the right, for a total window size of 14 + n words.
We use OpenNLP 1.3.0 to tokenize and part-of-speech tag the phrases (Steps 1.4 and 1.5).8
The tagged phrases come to about 46 gigabytes.9
In Step 2.1, we generate contextual patterns from the part-of-speech tagged phrases.
Different kinds of patterns are created for the three different kinds of spaces. The details
of this step are given in the following subsections. Each phrase may yield several patterns.
The three spaces each have more than 100,000 rows, with a maximum of 10,000 phrases
per row and several patterns per phrase. This can result in millions of distinct patterns, so
we filter the patterns in Steps 2.2 and 2.3. We select the top nc patterns that are shared
by the largest number of rows. Given the large number of patterns, they may not all fit
in RAM. To work with limited RAM, we use the Linux sort command, which is designed
to efficiently sort files that are too large to fit in RAM. For each row, we make a file of
the distinct patterns generated by that row. We then concatenate all of the files for all of
4.
5.
6.
7.

The corpus was collected by Charles Clarke at the University of Waterloo.
Wumpus is available at http://www.wumpus-search.org/.
WordNet is available at http://wordnet.princeton.edu/.
The limit of 10,000 phrases per n-gram is required to make Wumpus run in a tolerable amount of time.
Finding phrases is the most time-consuming step in the construction of the spaces. We use a solid-state
drive (SSD) to speed up this step.
8. OpenNLP is available at http://incubator.apache.org/opennlp/.
9. The tagged phrases are available from the author on request.

543

fiTurney

the rows and alphabetically sort the patterns in the concatenated file. In the sorted file,
identical patterns are adjacent, which makes it easy to count the number of occurrences of
each pattern. After counting, a second sort operation yields a ranked list of patterns, from
which we select the top nc .
It is possible that some of the candidate rows from Step 1.2 might not match any of
the patterns from Step 2.3. These rows would be all zeros in the matrix, so we remove
them in Step 2.4. Finally, we output a sparse frequency matrix F with nr rows and nc
columns. If the i-th row corresponds to the n-gram wi and the j-th column corresponds to
the contextual pattern cj , then the value of the element fij in F is the number of phrases
containing wi (from Step 1.5) that generate the pattern cj (in Step 2.1). In Step 3.2, we use
SVDLIBC 1.34 to calculate the singular value decomposition, so the format of the output
sparse matrix in Step 2.5 is chosen to meet the requirements of SVDLIBC.10
In Step 3.1, we apply positive pointwise mutual information (PPMI) to the sparse frequency matrix F. This is a variation of pointwise mutual information (PMI) (Church &
Hanks, 1989; Turney, 2001) in which all PMI values that are less than zero are replaced
with zero (Niwa & Nitta, 1994; Bullinaria & Levy, 2007). Let X be the matrix that results
when PPMI is applied to F. The new matrix X has the same number of rows and columns
as the raw frequency matrix F. The value of an element xij in X is defined as follows:
fij
pij = Pnr Pnc

j=1 fij

i=1

(5)

Pnc

j=1 fij
pi = Pnr Pnc

(6)

Pnr
f
Pncij
= Pnr i=1

(7)

i=1

pj

i=1



j=1 fij
j=1 fij

pij
pi pj



pmiij = log

pmiij if pmiij > 0
xij =
0 otherwise

(8)
(9)

In this definition, pij is the estimated probability that the word wi occurs in the context
cj , pi is the estimated probability of the word wi , and pj is the estimated probability of
the context cj . If wi and cj are statistically independent, then pij = pi pj (by the definition
of independence), and thus pmiij is zero (since log(1) = 0). The product pi pj is what we
would expect for pij if wi occurs in cj by pure random chance. On the other hand, if there
is an interesting semantic relation between wi and cj , then we should expect pij to be larger
than it would be if wi and cj were indepedent; hence we should find that pij > pi pj , and
thus pmiij is positive. If the word wi is unrelated to (or incompatible with) the context cj ,
we may find that pmiij is negative. PPMI is designed to give a high value to xij when there
is an interesting semantic relation between wi and cj ; otherwise, xij should have a value of
zero, indicating that the occurrence of wi in cj is uninformative.
10. SVDLIBC is available at http://tedlab.mit.edu/dr/svdlibc/.

544

fiDomain and Function: A Dual-Space Model

Finally, in Step 3.2, we apply SVDLIBC to X. SVD decomposes X into the product of
three matrices UVT , where U and V are in column orthonormal form (i.e., the columns
are orthogonal and have unit length, UT U = VT V = I) and  is a diagonal matrix of
singular values (Golub & Van Loan, 1996). If X is of rank r, then  is also of rank r. Let
k , where k < r, be the diagonal matrix formed from the top k singular values, and let Uk
and Vk be the matrices produced by selecting the corresponding columns from U and V.
The matrix Uk k VkT is the matrix of rank k that best approximates the original matrix X,
in the sense that it minimizes the approximation errors. That is, X = Uk k VkT minimizes
kX  XkF over all matrices X of rank k, where k . . . kF denotes the Frobenius norm (Golub
& Van Loan, 1996). The final output is the three matrices, Uk , k , and Vk , that form the
truncated SVD, X = Uk k VkT .
3.2 Domain Space
The intuition behind domain space is that the domain or topic of a word is characterized by
the nouns that occur near it. We use a relatively wide window and we ignore the syntactic
context in which the nouns appear.
For domain space, in Step 2.1, each tagged phrase generates at most two contextual
patterns. The contextual patterns are simply the first noun to the left of the given n-gram
(if there is one) and the first noun to the right (if there is one). Since the window size is 7
words on each side of the n-gram, there are usually nouns on both sides of the n-gram. The
nouns may be either common nouns or proper nouns. OpenNLP uses the Penn Treebank
tags (Santorini, 1990), which include several different categories of noun tags. All of the
noun tags begin with a capital N, so we simply extract the first words to the left and right
of the n-gram that have tags that begin with N. The extracted nouns are converted to lower
case. If the same noun appears on both sides of the n-gram, only one contextual pattern
is generated. The extracted patterns are always unigrams; in a noun compound, only the
component noun closest to the n-gram is extracted.
Table 1 shows some examples for the n-gram boat. Note that the window of 7 words
does not count punctuation, so the number of tokens in the window may be greater than
the number of words in the window. We can see from Table 1 that the row vector for
the n-gram boat in the frequency matrix F will have nonzero values (for example) in the
columns for lake and summer (assuming that these contextual patterns make it through the
filtering in Step 2.3).
For Step 2.3, we set nc to 50,000. In Step 2.4, after we drop rows that are all zero,
we are left with nr equal to 114,297. After PPMI (which sets negative elements to zero)
we have 149,673,340 nonzero values, for a matrix density of 2.62%. Table 2 shows the
contextual patterns for the first five columns and the last five columns (the columns are in
order of their ranks in Step 2.2). The Count column of the table gives the number of rows
(n-grams) that generate the pattern (that is, these are the counts mentioned in Step 2.2).
The last patterns all begin with c because they have the same counts and ties are broken
by alphabetical order.
545

fiTurney

Tagged phrases
would/MD visit/VB Big/NNP Lake/NNP and/CC take/VB our/PRP$
boat/NN on/IN this/DT huge/JJ beautiful/JJ lake/NN ./. There/EX
was/VBD

Patterns
lake

2

the/DT large/JJ paved/JJ parking/NN lot/NN in/IN the/DT boat/NN
ramp/NN area/NN and/CC walk/VB south/RB along/IN the/DT

lot
ramp

3

building/VBG permit/NN ./. / Anyway/RB ,/, we/PRP should/MD
have/VB a/DT boat/NN next/JJ summer/NN with/IN skiing/NN
and/CC tubing/NN paraphernalia/NNS ./.

permit
summer

1

Table 1: Examples of Step 2.1 in domain space for the n-gram boat. The three tagged
phrases generate five contextual patterns.

Column
1
2
3
4
5

Pattern
time
part
years
way
name

Count
91,483
84,445
84,417
84,172
81,960

Column
49,996
49,997
49.998
49,999
50,000

Pattern
clu
co-conspirator
conciseness
condyle
conocer

Count
443
443
443
443
443

Table 2: Contextual patterns for the first and last columns in domain space. CLU is an
abbreviation for Chartered Life Underwriter and other terms, condyle is a round
bump on a bone where it forms a joint with another bone, and conocer is the
Spanish verb to know, in the sense of being acquainted with a person.

3.3 Function Space
The concept of function space is that the function or role of a word is characterized by the
syntactic context that relates it to the verbs that occur near it. We use a more narrow
window for function space than domain space, based on the intuition that proximity to a
verb is important for determining the functional role of the given word. A distant verb is
less likely to characterize the function of the word. We generate relatively complex patterns
for function space, to try to capture the syntactic patterns that connect the given word to
the nearby verbs.
In Step 2.1, each tagged phrase generates up to six contextual patterns. For a given
tagged phrase, the first step is to cut the window down to 3 tokens before the given n-gram
and 3 tokens after it. If any of the remaining tokens to the left of the n-gram are punctuation, the punctuation and everything to the left of the punctuation is removed. If any of
the remaining tokens to the right of the n-gram are punctuation, the punctuation and everything to the right of the punctuation is removed. Lets call the remaining tagged phrase
a truncated tagged phrase.
Next we replace the given n-gram in the truncated tagged phrase with a generic marker,
546

fiDomain and Function: A Dual-Space Model

X. We then simplify the part-of-speech tags by reducing them all to their first character
(Santorini, 1990). For example, all of the various verb tags (VB, VBD, VBG, VBN, VBP,
VBZ) are reduced to V. If the truncated tagged phrase contains no V tag, it generates
zero contextual patterns. If the phrase contains a V tag, then we generate two types of
contextual patterns, general patterns and specific patterns.
For the general patterns, the verbs (every token with a V tag) have their tags removed
(naked verbs) and all other tokens are reduced to naked tags (tags without words). For the
specific patterns, verbs, modals (tokens with M tags), prepositions (tokens with I tags), and
to (tokens with T tags) have their tags removed and all other tokens are reduced to naked
tags. (See Table 3 for examples.)
For both general and specific patterns, to the left of X, we trim any leading naked tags.
To the right of X, we trim any trailing naked tags. A T tag can only be to, so we replace
any remaining naked T tags with to. A sequence of N tags (N N or N N N) is likely a
compound noun, so we reduce the sequence to a single N.
For a given truncated tagged phrase, we now have two patterns, one general pattern
and one specific pattern. If either of these patterns has tokens on both the left and right
sides of X, we make two more patterns by duplicating the X and then splitting the pattern
at the point between the two Xs. If one of the new patterns does not have a verb, we drop
it. Thus we may now have up to three specific patterns and three general patterns for the
given truncated tagged phrase. If the specific and general patterns are the same, only one
of them is generated.
Table 3 shows some examples for the n-gram boat. Note that every pattern must contain
the generic marker, X, and at least one verb.
Truncated tagged phrases
the/DT canals/NNS by/IN boat/NN
and/CC wandering/VBG the/DT

Patterns
X C wandering
by X C wandering

Types
general
specific

2

a/DT charter/NN fishing/VBG boat/NN
captain/NN named/VBN Jim/NNP

fishing X N named
fishing X
X N named

general
general
general

3

used/VBN from/IN a/DT
and/CC lowered/VBD to/TO

used I D X C lowered
used I D X
X C lowered
used from D X C lowered to
used from D X
X C lowered to

general
general
general
specific
specific
specific

1

boat/NN

Table 3: Examples of Step 2.1 in function space for the n-gram boat. The three truncated
tagged phrases generate eleven contextual patterns.

For Step 2.3, we set nc to 50,000. In Step 2.4, after rows that are all zero are dropped,
nr is 114,101. After PPMI, there are 68,876,310 nonzero values, yielding a matrix density
of 1.21%. Table 4 shows the contextual patterns for the first and the last five columns. The
547

fiTurney

last patterns all begin with s because they have the same counts and ties are broken by
alphabetical order.
Column
1
2
3
4
5

Pattern
X is
X N is
is D X
is X
X was

Count
94,312
82,171
79,131
72,637
72,497

Column
49,996
49,997
49,998
49,999
50,000

Pattern
since D X N was
sinking I D X
supplied with X
supports D X N of
suppressed I D X

Count
381
381
381
381
381

Table 4: Contextual patterns for the first and last columns in function space.
The contextual patterns for function space are more complex than the patterns for
domain space. The motivation for this greater complexity is the observation that mere
proximity is not enough to determine functional roles, although it seems sufficient for determining domains. For example, consider the verb gives. If there is a word X that occurs near
gives, X could be the subject, direct object, or indirect object of the verb. To determine the
functional role of X, we need to know which case applies. The syntactic context that connects X to gives provides this information. The contextual pattern X gives implies that
X is the subject, gives X implies X is an object, likely the direct object, and gives to X
suggests that X is the indirect object. Modals and prepositions supply further information
about the functional role of X in the context of a given verb. The verb gives appears in 43
different contextual patterns (i.e., 43 of the 50,000 columns in function space correspond to
syntactic patterns that contain gives).
Many of the row vectors in the function space matrix correspond to verbs. It might
seem surprising that we can characterize the function of a verb by its syntactic relation to
other verbs, but consider an example, such as the verb run. The row vector for run in the
PPMI matrix for function space has 1,296 nonzero values; that is, run is characterized by
1,296 different contextual patterns.
Note that appearing in a contextual pattern is different from having a nonzero value
for a contextual pattern. The character string for the word run appears in 62 different
contextual patterns, such as run out of X. The row vector for the word run has nonzero
values for 1,296 contextual patterns (columns), such as had to X.
3.4 Mono Space
Mono space is simply the merger of domain space and function space. For Step 2.3, we
take the union of the 50,000 domain space columns and the 50,000 function space columns,
resulting in a total nc of 100,000 columns. In Step 2.4, we have a total nr of 114,297
rows. The mono matrix after PPMI has 218,222,254 nonzero values, yielding a density of
1.91%. The values in the mono frequency matrix F equal the corresponding values in the
domain and function matrices. Some of the rows in the mono space matrix do not have
corresponding rows in the function space matrix. For these rows, the corresponding values
are zeros (but there are nonzero elements in these rows, which correspond to values in the
domain matrix).
548

fiDomain and Function: A Dual-Space Model

3.5 Summary of the Spaces
Table 5 summarizes the three matrices. In the following four sets of experiments, we use
the same three matrices (the domain, function, and mono matrices) in all cases; we do not
generate different matrices for each set of experiments. Three of the four sets of experiments
involve datasets that have been used in past by other researchers. We made no special
effort to ensure that the words in these three datasets have corresponding rows in the three
matrices. The intention is that these three matrices should be adequate to handle most
applications without any special customization.
Space
domain
function
mono

Rows (nr )
114,297
114,101
114,297

Columns (nc )
50,000
50,000
100,000

Nonzeros (after PPMI)
149,673,340
68,876,310
218,222,254

Density (after PPMI)
2.62%
1.21%
1.91%

Table 5: Summary of the three spaces.

3.6 Using the Spaces to Measure Similarity
In the following experiments, we measure the similarity of two terms, a and b, by the cosine
of the angle  between their corresponding row vectors, a and b:
sim(a, b) = cos(a, b) =

a
b

kak kbk

(10)

The cosine of the angle between two vectors is the inner product of the vectors, after they
have been normalized to unit length. The cosine ranges from 1 when the vectors point in
opposite directions ( is 180 degrees) to +1 when they point in the same direction ( is 0
degrees). When the vectors are orthogonal ( is 90 degrees), the cosine is zero. With raw
frequency vectors, which necessarily cannot have negative elements, the cosine cannot be
negative, but weighting and smoothing often introduce negative elements. PPMI weighting
does not yield negative elements, but truncated SVD can generate negative elements, even
when the input matrix has no negative values.
The semantic similarity of two terms is given by the cosine of the two corresponding rows
in Uk pk (see Section 3.1). There are two parameters in Uk pk that need to be set. The
parameter k controls the number of latent factors and the parameter p adjusts the weights
of the factors, by raising the corresponding singular values in pk to the power p. The
parameter k is well-known in the literature (Landauer et al., 2007), but p is less familiar.
The use of p was suggested by Caron (2001). In the following experiments (Section 4), we
explore a range of values for p and k.
Suppose we take a word w and list all of the other words in descending order of their
cosines with w, using Uk pk to calculate the cosines. When p is high, as we go down the list,
the cosines of the nearest neighbours of w decrease slowly. When p is low, they decrease
quickly. That is, a high p results in a broad, fuzzy neighbourhood and a low p yields a sharp,
crisp neighbourhood. The parameter p controls the sharpness of the similarity measure.
549

fiTurney

To reduce the running time of SVDLIBC, we limit the number of singular values to
1500, which usually results in less than 1500 singular values. For example, the SVD for
domain space has 1477 singular values. As long as k is not greater than 1477, we can
experiment with a range of k values without rerunning SVDLIBC. We can generate Uk pk
from U1477 p1477 by simply deleting the 1477  k columns with the smallest singular values.
In the experiments, we vary k from 100 to 1400 in increments of 100 (14 values for k)
and we vary p from 1 to +1 in increments of 0.1 (21 values for p). When p is 1, we
give more weight to the factors with smaller singular values; when p is +1, the factors with
larger singular values have more weight. Caron (2001) observes that most researchers use
either p = 0 or p = 1; that is, they use either Uk or Uk k .
Let simf (a, b)  < be function similarity as measured by the cosine of vectors a and b
in function space. Let simd (a, b)  < be domain similarity as measured by the cosine of
vectors a and b in domain space. When a similarity measure combines both simd (a, b) and
simf (a, b), there are four parameters to tune, kd and pd for domain space and kf and pf for
function space.
For one space, it is feasible for us to explore all 14  21 = 294 combinations of parameter
values, but two spaces have 294  294 = 86, 436 combinations of values. To make the search
tractable, we initialize the parameters to the middle of their ranges (kf = kd = 700 and
pf = pd = 0) and then we alternate between tuning simd (a, b) (i.e., kd and pd ) while holding
simf (a, b) (i.e., kf and pf ) fixed and tuning simf (a, b) while holding simd (a, b) fixed. We stop
the search when there is no improvement in performance on the training data. In almost
all cases, a local optimum is found in one pass; that is, after we have tuned the parameters
once, there is no improvement when we try to tune them a second time. Thus we typically
evaluate 294  3 = 882 parameter values (3 because we tune one similarity, tune the other,
and then try the first again to see if further improvement is possible).11
We could use a standard numerical optimization algorithm to tune the four parameters, but the algorithm we use here takes advantage of background knowledge about the
optimization task. We know that small variations in the parameters make small changes
in performance, so there is no need to make a very fine-grained search, and we know that
simd (a, b) and simf (a, b) are relatively independent, so we can optimize them separately.
The rows in the matrices are based on terms in the WordNet index.sense file. In this
file, all nouns are in their singular forms and all verbs are in their stem forms. To calculate
sim(a, b), we first look for exact matches for a and b in the terms that correspond to the
rows of the given matrix (domain, function, or mono). If an exact match is found, then
we use the corresponding row vector in the matrix. Otherwise, we look for alternate forms
of the terms, using the validForms function in the WordNet::QueryData Perl interface to
WordNet.12 This automatically converts plural nouns to their singular forms and verbs to
their stem forms. If none of the alternate forms is an exact match for a row in the matrix,
we map the term to a zero vector of length k.

11. We use Perl Data Language (PDL) for searching for parameters, calculating cosines, and other operations
on vectors and matrices. See http://pdl.perl.org/.
12. WordNet::QueryData is available at http://search.cpan.org/dist/WordNet-QueryData/.

550

fiDomain and Function: A Dual-Space Model

3.7 Composing Similarities
Our approach to semantic relations and compositions is to combine the two similarities,
simd (a, b) and simf (a, b), in various ways, depending on the task at hand or the syntax
of the phrase at hand. In general, we want the combined similarity to be high when the
component similarities are high, and we want the values of the component similarities to be
balanced. To achieve balance, we use the geometric mean to combine similarities, instead
of the arithmetic mean. The geometric mean is not suitable for negative numbers, and the
cosine can be negative in some cases; hence we define the geometric mean as zero if any of
the component similarities are negative:

geo(x1 , x2 , . . . , xn ) =

(x1 x2 . . . xn )1/n if xi > 0 for all i = 1, . . . , n
0 otherwise

(11)

3.8 Element-wise Multiplication
One of the most successful approaches to composition, so far, has been element-wise multiplication, c = a fi b, where ci = ai  bi (Mitchell & Lapata, 2008, 2010). This approach
only makes sense when the elements in the vectors are not negative. When the elements in
a and b are positive, relatively large values of ai and bi reinforce each other, resulting in a
large value for ci . This makes intuitive sense. But when ai and bi are both highly negative,
ci will be highly positive, although intuition says ci should be highly negative. Mitchell and
Lapata (2008, 2010) designed their wordcontext matrices to ensure that the vectors had
no negative elements.
The values in the matrix Uk pk are typically about half positive and half negative. We
use element-wise multiplication as a baseline in some of the following experiments. For a
fair baseline, we cannot simply apply element-wise multiplication to row vectors in Uk pk .
One solution would be to use the PPMI matrix, X, which has no negative elements, but this
would not allow element-wise multiplication to take advantage of the smoothing effect of
SVD. Our solution is to use row vectors from X = Uk k VkT . Although the PPMI matrix,
X, is sparse (see Table 5), X and Uk pk have a density of 100%.
Let a0 and b0 be the vectors in X that correspond to the terms a and b. These row
vectors benefit from smoothing due to truncated SVD, but their elements are almost all
positive. If there are any negative elements, we set them to zero. Let c0 = a0 fi b0 . After
we apply element-wise multiplication to the vectors, we then multiply by Vk kp1 , so that
the resulting vector c = c0 Vk p1
can be compared with other row vectors in the matrix
k
p
Uk k :
p1
T
X(Vk p1
k ) = (Uk k Vk )(Vk k )

=
=
=

Uk k VkT Vk kp1
Uk k p1
k
Uk pk

(12)
(13)
(14)
(15)

Note that, since Vk is column orthonormal, VkT Vk equals Ik , the k  k identity matrix.
551

fiTurney

Similarly, if a is a row vector in Uk pk , we can find its counterpart a0 in X by multiplying
T
a with 1p
k Vk :
T
(Uk pk )(k1p VkT ) = Uk pk 1p
k Vk

(16)

= Uk k VkT

(17)

= X

(18)

Let nn(x) (nn for nonnegative) be a function that converts negative elements in a vector
x to zero:

nn(hx1 , . . . , xn i) = hy1 , . . . , yn i

xi if xi > 0
yi =
0 otherwise

(19)
(20)

Our version of element-wise multiplication may be expressed as follows:
p1
1p T
T
c = (nn(a1p
k Vk ) fi nn(bk Vk )) Vk k

(21)

Another way to deal with element-wise multiplication would be to use nonnegative
matrix factorization (NMF) (Lee & Seung, 1999) instead of SVD. We have not yet found
an implementation of NMF that scales to the matrix sizes that we have here (Table 5). In
our past experiments with smaller matrices, SVD and NMF have similar performance.

4. Experiments with Varieties of Similarities
This section presents four sets of experiments. The first set of experiments presents a dualspace model of semantic relations and evaluates the model with multiple choice analogy
questions from the SAT. The second set presents a model of semantic composition and
evaluates it with multiple choice questions that are constructed from WordNet. The third
set applies a dual-space model to the phrase similarity dataset of Mitchell and Lapata
(2010). The final set uses three classes of word pairs from Chiarello et al. (1990) to test a
hypothesis about the dual-space model, that domain space and function space capture the
intuitive concepts of association and similarity.
4.1 Similarity of Relations
Here we evaluate the dual-space model applied to the task of measuring the similarity of
semantic relations. We use a set of 374 multiple-choice analogy questions from the SAT
college entrance exam (Turney, 2006b). Table 6 gives an example of one of the questions.
The task is to select the choice word pair that is most analogous (most relationally similar)
to the stem word pair.
Let a : b represent the stem pair (e.g., lull :trust). We answer the SAT questions by
selecting the choice pair c : d that maximizes the relational similarity, simr (a : b, c : d), defined
as follows:
552

fiDomain and Function: A Dual-Space Model

Stem:
Choices:

Solution:

(1)
(2)
(3)
(4)
(5)
(3)

lull:trust
balk:fortitude
betray:loyalty
cajole:compliance
hinder:destination
soothe:passion
cajole:compliance

Table 6: An example of a question from the 374 SAT analogy questions. Lulling a person
into trust is analogous to cajoling a person into compliance.

sim1 (a : b, c : d) = geo(simf (a, c), simf (b, d))

(22)

sim2 (a : b, c : d) = geo(simd (a, b), simd (c, d))

(23)

sim3 (a : b, c : d) = geo(simd (a, d), simd (c, b))

sim1 (a : b, c : d) if sim2 (a : b, c : d)  sim3 (a : b, c : d)
simr (a : b, c : d) =
0 otherwise

(24)
(25)

The intent of sim1 is to measure the function similarity across the two pairs. The domain
similarity inside the two pairs is measured by sim2 , whereas the domain similarity across the
two pairs is given by sim3 . The relational similarity, simr , is simply the function similarity,
sim1 , subject to the constraint that the domain similarity inside pairs, sim2 , must not be
less than the domain similarity across pairs, sim3 .
Figure 1 conveys the main ideas behind Equations 22 to 25. We want high function
similarities (indicated by  F) for a : c and b : d, as measured by sim1 . We also prefer
relatively high domain similarities (marked with  D) for a : b and c : d (measured by sim2 ),
in contrast to relatively low domain similarities ( D) for a : d and c : b (as given by sim3 ).13
Using the example in Table 6, we see that lulling a person into trust is analogous to
cajoling a person into compliance, since the functional role of lull is similar to the functional
role of cajole (both involve manipulating a person) and the functional role of trust is similar
to the functional role of compliance (both are states that a person can be in). This is
captured by sim1 . The constraint sim2 (a : b, c : d)  sim3 (a : b, c : d) implies that the
domain similarities of lull :trust (the domain of confidence and loyalty) and cajole :compliance
(the domain of obedience and conformity) should be greater than or equal to the domain
similarities of lull :compliance and cajole :trust.
Analogy is a way of mapping knowledge from a source domain to a target domain
(Gentner, 1983). If a in the source domain is mapped to c in the target domain, then a
should play the same role in the source domain as c plays in the target domain. This is
the theory behind sim1 . If a and b are in the source domain and c and d are in the target
13. We recently came across this same rectangular structure in Lepage and Shin-ichis (1996) paper on
morphological analogy (see their Figure 1). Although our algorithm and our task differ considerably
from the algorithm and task of Lepage and Shin-ichi (1996), we have independently discovered the same
underlying structure in analogical reasoning.

553

fiTurney

D

a
D

b
D

F

c

F

D

d

simr (a : b, c : d)
relational similarity

Figure 1: A diagram of the reasoning behind Equations 22 to 25.  F represents high
function similarity,  D means high domain similarity, and  D indicates low
domain similarity.

domain, then the internal domain similarity of a and b and the internal domain similarity of
c and d should not be less than the cross-domain similarities. This motivates the constraint
sim2  sim3 . Our definition is a natural expression of Gentners (1983) theory of analogy.
Recall the four equations that we introduced in Section 2.2. We repeat these equations
here for convenience:

simr (a : b, c : d) = simr (b : a, d : c)

(26)

simr (a : b, c : d) = simr (c : d, a : b)

(27)

simr (a : b, c : d) 6= simr (a : b, d : c)

(28)

simr (a : b, c : d) 6= simr (a : d, c : b)

(29)

Inspection will show that the definition of relational similarity in Equation 25 satisfies the
requirements of Equations 26, 27, 28, and 29. This can be understood by considering
Figure 1. Equation 26 tells us that we can rotate Figure 1 about its vertical axis without
altering the network of similarities, due to the symmetry of the figure. Equation 27 tells
us that we can rotate Figure 1 about its horizontal axis without altering the network of
similarities.
On the other hand, we cannot swap c and d while holding a and b fixed, because this
would change both the  F and  D links (although it would not change the  D links).
In other words, sim1 and sim3 would be changed, although sim2 would not be affected.
Therefore Equation 28 is satisfied.
Also, we cannot swap b and d while holding a and c fixed, because this would change
the  D and  D links (although it would not change the  F links). In other words, sim2
and sim3 would be changed, although sim1 would not be affected. Therefore Equation 29
554

fiDomain and Function: A Dual-Space Model

is satisfied. We can see that sim1 by itself would violate Equation 29, due to the symmetry
of cosines, simf (b, d) = simf (d, b). The constraint sim2 (a : b, c : d)  sim3 (a : b, c : d) breaks
this symmetry.
Another way to break the symmetry, so that Equation 29 is satisfied, would be to use a
similarity measure that is inherently asymmetric, such as skew divergence. In Equation 25,
the symmetry is broken in a natural way by considering how domain and function similarity
apply to analogies, so there is no need to introduce an inherently asymmetric measure. Also,
note that the symmetries of Equations 26 and 27 are desirable; we do not wish to break
these symmetries.
It would have been reasonable to include simd (a, c) and simd (b, d) in sim3 , but we decided
to leave them out. It seems to us that the function similarities simf (a, c) and simf (b, d),
which should have high values in a good analogy, might cause simd (a, c) and simd (b, d)
to be relatively high, even though they cross domains. If people observe a certain kind
of abstract function similarity frequently, that function similarity might become a popular
topic for discussion, which could result in a high domain similarity.
For example, carpenter :wood is analogous to mason :stone. The domain of carpenter :wood
is carpentry and the domain of mason :stone is masonry. The functional role of carpenter
is similar to the functional role of mason, in that both are artisans. Although carpenter
and mason belong to different domains, their high degree of abstract function similarity
may result in discussions that mention them together, such as discussions about specialized trades, skilled manual labour, the construction industry, and workplace injuries. In
other words, high function similarity between two words may cause a rise in their domain
similarity. Therefore we did not include simd (a, c) and simd (b, d) in sim3 .
When all five choices for a SAT question have a relational similarity of zero, we skip the
question. We use ten-fold cross-validation to set the parameters for the SAT questions. The
same parameter values are selected in nine of the ten folds, kd = 800, pd = 0.1, kf = 300,
and pf = 0.5. After the parameters are determined, all 374 SAT questions can be answered
in a few seconds. Equation 25 correctly answers 191 of the questions, skips 2 questions, and
incorrectly answers 181 questions, achieving an accuracy of 51.1%.
4.1.1 Comparison with Past Work
For comparison, the average score for senior highschool students applying to US universities
is 57.0%. The ACL Wiki lists many past results with the 374 SAT questions.14 Table 7
shows the top ten results at the time of writing. In this table, dual-space refers to the dualspace model using Equation 25. Four of the past results achieved an accuracy of 51.1%
or higher. All four used holistic approaches and hence are not able to address the issue of
linguistic creativity. The best previous algorithm attains an accuracy of 56.1% (210 correct,
4 skipped, 160 incorrect) (Turney, 2006b). The difference between 51.1% and 56.1% is not
statistically significant at the 95% confidence level, according to Fishers Exact Test.
The majority of the algorithms in Table 7 are unsupervised, but Dual-Space, PairClass
(Turney, 2008b), and BagPack (Herdagdelen & Baroni, 2009) use limited supervision. PairClass and BagPack answer a given SAT question by learning a binary classification model
that is specific to the given question. The training set for a given question consists of one
14. See http://aclweb.org/aclwiki/index.php?title=SAT Analogy Questions.

555

fiTurney

Algorithm
LSA+Predication
KNOW-BEST
k-means
BagPack
VSM
Dual-Space
BMI
PairClass
PERT
LRA
Human

Reference
Mangalath et al. (2004)
Veale (2004)
Bicici and Yuret (2006)
Herdagdelen and Baroni (2009)
Turney and Littman (2005)
Bollegala et al. (2009)
Turney (2008b)
Turney (2006a)
Turney (2006b)
Average US college applicant

Accuracy
42.0
43.0
44.0
44.1
47.1
51.1
51.1
52.1
53.5
56.1
57.0

95% confidence
37.247.4
38.048.2
39.049.3
39.049.3
42.252.5
46.156.5
46.156.5
46.957.3
48.558.9
51.061.2
52.062.3

Table 7: The top ten results with the 374 SAT questions, from the ACL Wiki. The 95%
confidence intervals are calculated using the Binomial Exact Test.

positive training example, the stem pair for the question, and ten randomly selected pairs
as (assumed) negative training examples. The induced binary classifier is used to assign
probabilities to the five choices and the most probable choice is the guess. Dual-Space uses
the training set only to tune four numerical parameters. These three algorithms are best
described as weakly supervised.
4.1.2 Sensitivity to Parameters
To see how sensitive the dual-space model is to the values of the parameters, we perform
two exhaustive grid searches, one with a coarse, wide grid and another with a fine, narrow
grid. For each point in the grids, we evaluate the dual-space model using the whole set
of 374 SAT questions. The narrow grid search is centred on the parameter values that
were selected in nine of the ten folds in the previous experiment, kd = 800, pd = 0.1,
kf = 300, and pf = 0.5. Both searches evaluate 5 values for each parameter, yielding a total
of 54 = 625 parameter settings. Table 8 shows the values that were explored in the two grid
searches and Table 9 presents the minimum, maximum, average, and standard deviation of
the accuracy for the two searches.
Grid
Coarse

Fine

Parameter
kd
pd
kf
pf
kd
pd
kf
pf

100
-1.0
100
-1.0
600
-0.3
100
0.3

425
-0.5
425
-0.5
700
-0.2
200
0.4

Values
750 1075
0.0
0.5
750 1075
0.0
0.5
800
900
-0.1
0.0
300
400
0.5
0.6

1400
1.0
1400
1.0
1000
0.1
500
0.7

Table 8: The range of parameter values for the two grid searches.
556

fiDomain and Function: A Dual-Space Model

Grid
Coarse
Fine

Minimum
31.0
42.5

Accuracy
Maximum Average
48.7
40.7
51.6
47.3

Standard deviation
4.1
2.0

Table 9: The sensitivity of the dual-space model to the parameter settings.
The accuracy attained by the heuristic search (described in Section 3.6) with ten-fold
cross-validation, 51.1% (Table 7), is near the best accuracy of the fine grid search using the
whole set of 374 SAT questions, 51.6% (Table 9). This is evidence that the heuristic search is
effective. Accuracy with the coarse search varies from 31.0% to 48.7%, which demonstrates
the importance of tuning the parameters. On the other hand, accuracy with the fine search
spans a narrower range and has a lower standard deviation, which suggests that the dualspace model is not overly sensitive to relatively small variations in the parameter values;
that is, the parameters are reasonably stable. (That nine of the ten folds in cross-validation
select the same parameters is further evidence of stability.)
4.1.3 Parts of Speech
Since domain space is based on nouns and function space is based on verbs, it is interesting
to know how the performance of the dual-space model varies with different parts of speech.
To answer this, we manually labeled all 374 SAT questions with part-of-speech labels. The
labels for a single pair can be ambiguous, but the labels become unambiguous in the context
of the whole question. For example, lull :trust could be noun :verb, but in the context of
Table 6, it must be verb :noun.
Table 10 splits out the results for the various parts of speech. None of the differences
in this table are statistically significant at the 95% confidence level, according to Fishers
Exact Test. A larger and more varied set of questions will be needed to determine how part
of speech affects the dual-space model.
Parts of speech
noun:noun
noun:adjective or adjective:noun
noun:verb or verb:noun
adjective:adjective
verb:adjective or adjective:verb
verb:verb
verb:adverb or adverb:verb
all

Right
97
35
27
9
12
11
0
191

Accuracy
50.8
53.0
49.1
37.5
60.0
64.7
0.0
51.1

Wrong
93
31
28
15
7
6
1
181

Skipped
1
0
0
0
1
0
0
2

Total
191
66
55
24
20
17
1
374

Table 10: Performance of the dual-space model with various parts of speech.

4.1.4 Order Sensitivity
It seems that function space is doing most of the work in Equation 25. If we use sim1 alone,
dropping the constraint that sim2  sim3 , then accuracy drops from 51.1% to 50.8%. This
557

fiTurney

drop is not statistically significant. We hypothesize that the small drop is due to the design
of the SAT test, which is primarily intended to test a students understanding of functional
roles, not domains.
To verify this hypothesis, we reformulated the SAT questions so that they would test
both function and domain comprehension. The method is to first expand each choice pair
c : d by including the stem pair a : b, resulting in the full explicit analogy a : b :: c : d. For each
expanded choice, a : b :: c : d, we then generate another choice, a : d :: c : b. Table 11 shows
the reformulation of Table 6. Due to symmetry, sim1 must assign the same similarity to
both a : b :: c : d and a : d :: c : b. This new ten-choice test evaluates both function and domain
similarities.
Choices:

Solution:

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(6)

lull:trust::balk:fortitude
lull:fortitude::balk:trust
lull:loyalty::betray:trust
lull:trust::betray:loyalty
lull:compliance::cajole:trust
lull:trust::cajole:compliance
lull:destination::hinder:trust
lull:trust::hinder:destination
lull:trust::soothe:passion
lull:passion::soothe:trust
lull:trust::cajole:compliance

Table 11: An expanded SAT question, designed to test both function and domain comprehension. Choices (5) and (6) have the same similarity according to sim1 .

The task with the expanded ten-choice SAT questions is the same as with the original
five-choice questions, to select the best analogy. The solution in Table 11 is the same as the
solution in Table 6, except that the stem pair is explicit in Table 11. The only signficant
change is that five new distractors have been added to the choices. We answer the ten-choice
questions by selecting the choice a : b :: c : d that maximizes simr (a : b, c : d).
On the ten-choice reformulated SAT test, simr (Equation 25) attains an accuracy of
47.9%, whereas sim1 alone (Equation 22) only achieves 27.5%. The difference is statistically
significant at the 95% confidence level, according to Fishers Exact Test. This more stringent
test supports the claim that function similarity is insufficient by itself.
As a further test of the value of two separate spaces, we use a single space for both
simd and simf in Equation 25. The model still has four parameters it can tune, kd , pd , kf ,
and pf , but the same matrix is used for both similarities. The best result is an accuracy of
40.4% on the ten-question reformulated SAT test, using function space for both simd and
simf . This is significantly below the 47.9% accuracy of the dual-space model when simd is
based on domain space and simf is based on function space (95% confidence level, Fishers
Exact Test).
Table 12 summarizes the results. In the cases where the matrix for simd is not used,
the model is based on sim1 alone (Equation 22). In all other cases, the model is based
on simr (Equation 25). For both the five-choice and ten-choice SAT questions, the original
558

fiDomain and Function: A Dual-Space Model

dual-space model is more accurate than any of the modified models. The Significant column
indicates whether the accuracy of a modified model is significantly less than the original
dual-space model (95% confidence level, Fishers Exact Test). The more difficult ten-choice
questions clearly show the value of two distinct spaces.
Algorithm
dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space

Accuracy
51.1
47.3
43.6
37.7
50.8
41.7
35.8
47.9
40.4
38.2
34.8
27.5
25.1
14.4

Significant
no
yes
yes
no
yes
yes
yes
yes
yes
yes
yes
yes

Questions
five-choice
five-choice
five-choice
five-choice
five-choice
five-choice
five-choice
ten-choice
ten-choice
ten-choice
ten-choice
ten-choice
ten-choice
ten-choice

Matrix for simd
domain space
function space
mono space
domain space
not used
not used
not used
domain space
function space
mono space
domain space
not used
not used
not used

Matrix for simf
function space
function space
mono space
domain space
function space
mono space
domain space
function space
function space
mono space
domain space
function space
mono space
domain space

Table 12: Accuracy with the original five-choice questions and the reformulated ten-choice
questions. In the modified models, we intentionally use the wrong matrix (or
no matrix) for simd or simf . The modified models show that accuracy decreases
when only one space is used.

4.1.5 Summary
The dual-space model performs as well as the current state-of-the-art holistic model and
addresses the issue of linguistic creativity. The results with the reformulated SAT questions
support the claim that there is value in having two separate spaces.
As we mentioned in Section 2.2, the task of classifying word pairs according to their
semantic relations (Rosario & Hearst, 2001; Rosario et al., 2002; Nastase & Szpakowicz,
2003) is closely connected to the problem of measuring relational similarity. Turney (2006b)
applied a measure of relational similarity to relation classification by using cosine similarity
as a measure of nearness in a nearest neighbour supervised learning algorithm. The dualspace model (Equation 25) is also suitable for relation classification with a nearest neighbour
algorithm.
4.2 Similarity of Compositions
In this second set of experiments, we apply the dual-space model to noun-modifier compositions. Given vectors for dog, house, and kennel, we would like to be able to recognize that
dog house and kennel are synonymous. We compare the dual-space model to the holistic
approach, vector addition, and element-wise multiplication. The approaches are evaluated
559

fiTurney

using multiple-choice questions that are automatically generated from WordNet, using the
WordNet::QueryData Perl interface to WordNet. Table 13 gives an example of one of the
noun-modifier questions.
Stem:
Choices:

Solution:

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(1)

dog house
kennel
dog
house
canine
dwelling
effect
largeness
kennel

Table 13: An example of a multiple-choice noun-modifier composition question.
In these questions, the stem is a bigram and the choices are unigrams. Choice (1) is
the correct answer, (2) is the modifier, and (3) is the head noun. Choice (4) is a synonym
or hypernym of the modifier and (5) is a synonym or hypernym of the head noun. If no
synonyms or hypernyms can be found, a noun is randomly chosen. The last two choices, (6)
and (7), are randomly selected nouns. Choices (2) and (4) can be either nouns or adjectives,
but the other choices must be nouns.
The stem bigram and the choice unigrams must have corresponding rows in function
space (the space with the least number of rows). The stem bigram must have a noun sense
in WordNet (it may also have senses for other parts of speech). The solution unigram, (1),
must be a member of the synset (synonym set) for the first noun sense of the stem bigram
(the most frequent or dominant sense of the bigram, when the bigram is used as a noun),
and it cannot be simply the hyphenation (dog-house) or concatenation (doghouse) of the
stem bigram.
These requirements result in a total of 2180 seven-choice questions, which we randomly
split into 680 for training (parameter tuning) and 1500 for testing.15 The questions are deliberately designed to be difficult. In particular, all of the approaches are strongly attracted
to choices (2) and (3). Furthermore, we did not attempt to ensure that the stem bigrams are
compositional; some of them may be idiomatic expressions that no compositional approach
could possibly get right. We did not want to bias the questions by imposing theories about
distinguishing compositions and idioms in their construction.
Let ab represent a noun-modifier bigram (dog house) and let c represent a unigram
(kennel). We answer the multiple-choice questions by selecting the unigram that maximizes
the compositional similarity, simc (ab, c), defined as follows:

sim1 (ab, c) = geo(simd (a, c), simd (b, c), simf (b, c))

sim1 (ab, c) if a 6= c and b 6= c
simc (ab, c) =
0 otherwise
15. The questions are available as an online appendix at http://jair.org/.

560

(30)
(31)

fiDomain and Function: A Dual-Space Model

Equations 30 and 31 are illustrated in Figure 2.
a

6=

b

D

D F

6=

c
simc (ab, c)
noun-modifier compositional similarity

Figure 2: A diagram of Equations 30 and 31.
The thinking behind sim1 is that c (kennel ) should have high domain similarity with
both the modifier a (dog) and the head noun b (house); furthermore, the function of the
bigram ab (dog house) is determined by the head noun b (house), so the head noun should
have high function similarity with c (kennel ). We add the constraints a 6= c and b 6= c
because sim1 by itself tends to have high values for sim1 (ab, a) and sim1 (ab, b).16 It seems
plausible that humans use constraints like this: We reason that dog house cannot mean the
same thing as house, because then the extra word dog in dog house would serve no purpose;
it would be meaningless noise.17
The constraints a 6= c and b 6= c could be expressed in terms of similarities, such as
simd (a, c) < t and simd (b, c) < t, where t is a high threshold (e.g., t = 0.9), but this would
add another parameter to the model. We decided to keep the model relatively simple.
When all seven choices for a noun-modifier question have a compositional similarity of
zero, we skip the question. On the training set, the best parameter settings are kd = 800,
pd = 0.3, kf = 100, and pf = 0.6. On the testing set, Equation 31 correctly answers 874
questions, skips 22 questions, and incorrectly answers 604, yielding an accuracy of 58.3%.
4.2.1 Comparison with Other Approaches
Mitchell and Lapata (2010) compared many different approaches to semantic composition in
their experiments, but they only considered one task (the task we examine in Section 4.3).
In this paper, we have chosen to compare a smaller number of approaches on a larger
number of tasks. We include element-wise multiplication in these experiments, because this
approach had the best performance in Mitchell and Lapatas (2010) experiments. Vector
16. In spite of these constraints, it is still worthwhile to include the head noun and the modifier as distractors
in the multiple-choice questions, because it enables us to experimentally evaluate the impact of these
distractors on the various algorithms when the constraints are removed (see Table 15). Also, future users
of this dataset may find a way to avoid these distractors without explicit constraints.
17. In philosophy of language, Grice (1989) argued that proper interpretation of language requires us to
charitably assume that speakers generally do not insert random words into their speech.

561

fiTurney

addition is included due to its historical importance and its simplicity. Although Mitchell
and Lapata (2010) found that weighted addition was better than unweighted addition, we
do not include weighted addition in our experiments, because it did not perform as well as
element-wise multiplication in Mitchell and Lapatas (2010) experiments. We include the
holistic model as a noncompositional baseline.
Table 14 compares the dual-space model with the holistic model, element-wise multiplication, and vector addition. For the latter three models, we try all three spaces.
Algorithm
dual-space
holistic
holistic
holistic
multiplication
multiplication
multiplication
addition
addition
addition

Space
domain and function
mono
domain
function
mono
domain
function
mono
domain
function

Accuracy
58.3
81.6
79.1
67.5
55.7
57.5
46.3
48.3
50.1
39.8

Table 14: Results for the noun-modifier questions.
In this table, dual-space refers to the dual-space model using Equation 31. In the holistic
model, ab is represented by its corresponding row vector in the given space. Recall from
Section 3.1 that, in Step 1.1, the rows in the matrices correspond to n-grams in WordNet,
where n may be greater than one. Thus, for example, dog house has a corresponding
row vector in all three of the spaces. The holistic model simply uses this row vector as
the representation of dog house. For element-wise multiplication, ab is represented using
Equation 21. With the vector addition model, ab is represented by a + b, where the vectors
are normalized to unit length before they are added. All four models use the constraints
a 6= c and b 6= c. All four models use the training data for parameter tuning.
The difference between the dual-space model (58.3%) and the best variation of elementwise multiplication (57.5%) is not statistically significant at the 95% confidence level, according to Fishers Exact Test. However, the difference between the dual-space model
(58.3%) and the best variation of vector addition (50.1%) is significant.
4.2.2 Limitations of the Holistic Approach
For all three spaces, the holistic model is significantly better than all other models, but its
inability to address the issue of linguistic creativity is a major limitation. The 2180 multiplechoice questions that we have used in these experiments were intentionally constructed with
the requirement that the stem bigram must have a corresponding row in function space (see
above). This was done so that we could use the holistic model as a baseline; however, it
gives the misleading impression that the holistic model is a serious competitor with the
compositional approaches. By design, Table 14 shows what the holistic model can achieve
under ideal (but unrealistic) conditions.
562

fiDomain and Function: A Dual-Space Model

Mitchell and Lapatas (2010) dataset, used in the experiments in Section 4.3, illustrates
the limitations of the holistic model. The dataset consists of 324 distinct pairs of bigrams,
composed of 216 distinct bigrams. Of the 216 bigrams, 28 (13%) occur in WordNet. Of
the 324 pairs of bigrams, 13 (4%) contain bigrams that both occur in WordNet. Given
the matrices we use here (with rows based on WordNet), the holistic approach would be
reduced to random guessing for 96% of the pairs in Mitchell and Lapatas (2010) dataset.
It might be argued that the failure of the holistic approach with Mitchell and Lapatas
(2010) dataset is due to our decision to base the rows of the matrices on terms from WordNet.
However, suppose we attempt to build a holistic model for all frequent bigrams. The Web
1T 5-gram corpus (Brants & Franz, 2006) includes a list of all bigrams that appeared 40
or more times in a terabyte of text, a total of 314,843,401 bigrams. Using a compositional
approach, the matrices we use here can represent the majority of these bigrams. On the
other hand, the holistic approach would require a matrix with 314,843,401 rows, which is
considerably beyond the current state of the art.
One possibility is to build a matrix for the holistic approach as needed, for a given
input set of n-grams, instead of building a large, static, multipurpose matrix. There are
two problems with this idea. First, it is slow. Turney (2006b) used this approach for the
SAT analogy questions, but it required nine days to run, whereas the dual-space model can
process the SAT questions in a few seconds, given a static, multipurpose matrix. Second, it
requires a large corpus, and the corpus size must grow exponentially with n, the length of
the phrases. Longer phrases are more rare, so larger corpora are needed to gather sufficient
data to model the phrases. Larger corpora also result in longer processing times.
For a given application, it may be wise to have a predefined list of bigrams with holistic
representations, but it would not be wise to expect this list to be sufficient to cover most
bigrams that would be seen in practice. The creativity of human language use requires
compositional models (Chomsky, 1975; Fodor & Lepore, 2002). Although the holistic model
is included as a baseline in the experiments, it is not a competitor for the other models; it
can only supplement the other models.
4.2.3 Impact of Constraints
If we use sim1 alone (Equation 30), dropping the constraints a 6= c and b 6= c, then accuracy
drops signficantly, from 58.3% to 13.7%. However, all of the models benefit greatly from
these constraints. In Table 15, we take the best variation of each model from Table 14 and
look at what happens when the constraints are dropped.

Algorithm
dual-space
holistic
multiplication
addition

Space
domain and function
mono
domain
domain

constraints
58.3
81.6
57.5
50.1

Accuracy
no constraints
13.7
49.6
8.2
2.5

difference
-44.6
-32.0
-49.3
-47.6

Table 15: The impact of the constraints, a 6= c and b 6= c, on accuracy.

563

fiTurney

4.2.4 Element-wise Multiplication
In Section 3.8, we argued that c = a fi b is not suitable for row vectors in the matrix Uk pk
and we suggested Equation 21 as an alternative. When we use c = a fi b with domain
space, instead of Equation 21, performance drops significantly, from 57.5% to 21.5%.
4.2.5 Impact of Idioms
Some of the gap between the holistic model and the other models may be due to idiomatic
bigrams in the testing questions. One of the most successful approaches to determining
whether a multiword expression (MWE) is compositional or noncompositional (idiomatic)
is to compare its holistic vector representation with its compositional vector representation
(for example, a high cosine between the two vectors suggests that the MWE is compositional,
not idiomatic) (Biemann & Giesbrecht, 2011; Johannsen, Alonso, Rishj, & Sgaard, 2011).
However, this approach is not suitable here, because we do not want to assume that the
gap is entirely due to idiomatic bigrams; instead, we would like to estimate how much of
the gap is due to idiomatic bigrams.
WordNet contains some clues that we can use as indicators that a bigram might be less
compositional than most bigrams (allowing that compositionality is a matter of degree).
One clue is whether the WordNet gloss of the bigram contains either the head noun or the
modifier. For example, the gloss of dog house is outbuilding that serves as a shelter for a
dog, which contains the modifier, dog. This suggests that dog house may be compositional.
We classified each of the 1500 testing set questions as head (the first five characters in
the head noun of the bigram match the first five characters in a word in the bigrams gloss),
modifier (the first five characters in the modifier of the bigram match the first five characters
in a word in the bigrams gloss), both (both the head and the modifier match), or neither
(neither the head nor the modifier match). The four classes are approximately equally
distributed in the testing questions (424 head, 302 modifier, 330 both, and 444 neither). We
match on the first five characters to allow for cases like brain surgeon, which has the gloss
someone who does surgery on the nervous system (especially the brain). This bigram is
classified as both, because the first five characters of surgeon match the first five characters
of surgery.
Table 16 shows how the accuracy of the models varies over the four classes of questions. For the three compositional models (dual-space, multiplication, addition), the neither class is significantly less accurate than the other three classes (Fishers Exact Test,
95% confidence), but the difference is not significant for the holistic model. For the three
compositional models, the neither class is 17% to 20% less accurate than the other classes.
This supports the view that a significant fraction of the wrong answers of the compositional
models are due to noncompositional bigrams.
Another clue for compositionality in WordNet is whether the head noun is a hypernym
of the bigram. For example, surgeon is a hypernym of brain surgeon. We classified each
of the 1500 testing set questions as hyper (the head noun is a member of the synset of the
immediate hypernym for the first noun sense of the bigram; we do not look further up in the
hypernym hierarchy and we do not look at other senses of the bigram) or not (not hyper).
In the testing set, 621 questions are hyper and 879 are not.
564

fiDomain and Function: A Dual-Space Model

Algorithm
dual-space
holistic
multiplication
addition

Space
domain and function
mono
domain
domain

both
63.0
82.7
61.8
53.6

head
63.0
83.7
63.7
56.8

Accuracy
modifier neither
64.6
45.9
82.1
78.4
62.9
44.8
56.3
36.7

all
58.3
81.6
57.5
50.1

Table 16: The variation of accuracy for different classes of bigram glosses.
Table 17 gives the accuracy of the models for each of the classes. This table has the
same general pattern as Table 16. The three compositional models have significantly lower
accuracy for the not class, with decreases from 6% to 8%. There is no significant difference
for the holistic model.
Algorithm
dual-space
holistic
multiplication
addition

Space
domain and function
mono
domain
domain

Accuracy
hyper not
62.0 55.6
81.0 82.0
61.8 54.5
54.8 46.8

all
58.3
81.6
57.5
50.1

Table 17: The variation of accuracy for different classes of bigram hypernyms.

4.2.6 Order Sensitivity
Note that vector addition and element-wise multiplication lack order sensitivity, but Equation 31 is sensitive to order, simc (ab, c) 6= simc (ba, c). We can see the impact of this by
reformulating the noun-modifier questions so that they test for order-sensitivity. First we
expand each choice unigram c by including the stem bigram ab, resulting in the explicit
comparison ab  c. For each expanded choice, ab  c, we then generate another choice,
ba  c. This increases the number of choices from seven to fourteen. Due to symmetry,
vector addition and element-wise multiplication must assign the same similarity to both
ab  c and ba  c.
Table 18 compares the dual-space model with element-wise multiplication and vector addition, using the reformulated fourteen-choice noun-modifier questions. The holistic model
is not included in this table because there are no rows in the matrices for the reversed ba
bigrams (which may be seen as another illustration of the limits of the holistic model). On
this stricter test, the dual-space model is significantly more accurate than both element-wise
multiplication and vector addition (Fishers Exact Test, 95% confidence).
For the dual-space model to perform well with the fourteen-choice questions, we need
both simd and simf . If we drop simd from Equation 31 (function alone in Table 18), then we
are ignoring the modifier and only paying attention to the head noun. Accuracy drops from
41.5% down to 25.7%. If we drop simf from Equation 31 (domain alone in Table 18), then
the equation becomes symmetrical, so the same similarity is assigned to both ab  c and
565

fiTurney

Algorithm
dual-space
multiplication
modified dual-space
modified dual-space
addition

Space
domain and function
domain
function alone
domain alone
domain

Accuracy
41.5
27.4
25.7
25.7
22.5

Table 18: Results for the reformulated fourteen-choice noun-modifier questions.
ba  c. Accuracy drops from 41.5% down to 25.7%.18 The dual-space model is significantly
more accurate than either of these modified dual-space models (Fishers Exact Test, 95%
confidence).
4.2.7 Summary
With the reformulated fourteen-choice noun-modifier questions (Table 18), the dual-space is
significantly better than element-wise multiplication and vector addition. With the original
seven-choice questions (Table 14), the difference is not as large, because these questions do
not test for order. Unlike element-wise multiplication and vector addition, the dual-space
model addresses the issue of order sensitivity. Unlike the holistic model, the dual-space
addresses the issue of linguistic creativity.
4.3 Similarity of Phrases
In this subsection, we apply the dual-space model to measuring the similarity of phrases,
using Mitchell and Lapatas (2010) dataset of human similarity ratings for pairs of phrases.
The dataset includes three types of phrases, adjective-noun, noun-noun, and verb-object.
There are 108 pairs of each type (108  3 = 324 pairs of phrases). Each pair of phrases was
rated by 18 human subjects. The ratings use a 7 point scale, in which 1 signifies the lowest
degree of similarity and 7 signifies the highest degree. Table 19 gives some examples.
Let ab represent the first phrase in a pair of phrases (environment secretary) and let cd
represent the second phrase (defence minister). We rate the similarity of the phrase pairs
by simp (ab, cd), defined as follows:
simp (ab, cd) = geo(simd (a, c), simd (b, d), simf (a, c), simf (b, d))

(32)

This equation is based on the instructions to the human participants (Mitchell & Lapata,
2010, Appendix B), which imply that both function and domain similarity must be high
for a phrase pair to get a high similarity rating. Figure 3 illustrates the reasoning behind
this equation. We want high domain and function similarities between the corresponding
components of the phrases ab and cd.
18. It is only a coincidence that both modified dual-space models have an accuracy of 25.7% on the fourteenchoice questions. Although their aggregate accuracy is the same, on individual questions, the two models
typically select different choices.

566

fiDomain and Function: A Dual-Space Model

Participant
114
114
114
109
109
109
111
111
111

Phrase type
adjective-noun
adjective-noun
adjective-noun
noun-noun
noun-noun
noun-noun
verb-object
verb-object
verb-object

Group
2
2
2
0
0
0
2
2
2

Phrase pair
certain circumstance  particular case
large number  great majority
further evidence  low cost
environment secretary  defence minister
action programme  development plan
city centre  research work
lift hand  raise head
satisfy demand  emphasise need
like people  increase number

Similarity
6
4
2
6
4
1
7
4
1

Table 19: Examples of phrase pair similarity ratings from Mitchell and Lapatas (2010)
dataset. Similarity ratings vary from 1 (lowest) to 7 (highest).

a

b

D F

D F

c

d
simp (ab, cd)
phrasal similarity

Figure 3: A diagram of Equation 32.

4.3.1 Experimental Setup
Mitchell and Lapata (2010) divided their dataset into a development set (for tuning parameters) and an evaluation set (for testing the tuned models). The development set has
6 ratings for each phrase pair and the evaluation set has 12 ratings for each phrase pair.
The development and evaluation sets contain the same phrase pairs, but with judgments by
different participants. Thus there are 6324 = 1, 944 rated phrase pairs in the development
set and 12  324 = 3, 888 ratings in the evaluation set.19
For a more challenging evaluation, we divide the dataset by phrase pairs rather than
by participants. Our development set has 108 phrase pairs with 18 ratings each and the
evaluation set has 216 phrase pairs with 18 ratings each. For each of the three phrase types,
we randomly select 36 phrase pairs for the development set (3  36 = 108 phrase pairs) and
19. The information in this paragraph is based on Section 4.3 of the paper by Mitchell and Lapata (2010)
and personal communication with Jeff Mitchell in June, 2010.

567

fiTurney

72 for the evaluation set (3  72 = 216 phrase pairs). Thus there are 18  108 = 1, 944
ratings in the development set and 18  216 = 3, 888 in the evaluation set.
Mitchell and Lapata (2010) use Spearmans rank correlation coefficient (Spearmans
rho) to evaluate the performance of various vector composition algorithms on the task of
emulating the human similarity ratings. For a given phrase type, the 108 phrase pairs are
divided into 3 groups of 36 pairs each. For each group in the evaluation set, 12 people
gave similarity ratings to the pairs in the given group. Each group of 36 pairs was given
to a different group of 12 people. The score of an algorithm for a given phrase type is the
average of three rho values, one rho for each of the three groups. With 12 people rating 36
pairs in a group, there are 12  36 = 432 ratings. These human ratings are represented by
a vector of 432 numbers. An algorithm only generates one rating for each pair in a group,
yielding 36 numbers. To make the algorithms ratings comparable to the human ratings, the
algorithms ratings are duplicated 12 times, yielding a vector of 432 numbers. Spearmans
rho is then calculated with these two vectors of 432 ratings. For 3 phrase types with 3 rho
values each and 432 ratings per rho value, we have 3,888 ratings.20
We believe that this evaluation method underestimates the performance of the algorithms. Combining ratings from different people into one vector of 432 numbers does not
allow the correlation to adapt to different biases. If one person gives consistently low ratings
and another person gives consistently high ratings, but both people have the same ranking,
and this ranking matches the algorithms ranking, then the algorithm should get a high
score. For a more fair evaluation, we score an algorithm by calculating one rho value for
each human participant for the given phrase type, and then we calculate the average of the
rho values for all of the participants.
For a given phrase type, the 108 phrase pairs are divided into 3 groups of 36 pairs each.
For the development set, we randomly select 12 phrase pairs from each of the 3 groups
(3  12 = 36 phrase pairs per phrase type). This leaves 24 phrase pairs in each of the 3
groups for the evaluation set (3  24 = 72 phrase pairs per phrase type). Each human
participants ratings are represented by a vector of 24 numbers. An algorithms ratings are
also represented by a vector of 24 numbers. A rho value is calculated with these two vectors
of 24 numbers as input. For a given phrase type, the algorithms score is the average of 54
rho values (18 participants per group  3 groups = 54 rho values). For 3 phrase types with
54 rho values each and 24 ratings per rho value, we have 3,888 ratings.
4.3.2 Comparison with Other Approaches
Table 20 compares the dual-space model to vector addition and element-wise multiplication.
We use the development set to tune the parameters for all three approaches. For vector
addition, ab is represented by a + b and cd is represented by c + d. The similarity of ab and
cd is given by the cosine of the two vectors. Element-wise multiplication uses Equation 21
to represent ab and cd. The dual-space model uses Equation 32.
The average correlation of the dual-space model (0.48) is significantly below the average
correlation of vector addition using function space (0.51). Element-wise multiplication with
mono space (0.47) is also significantly below vector addition using function space (0.51). The
20. The information in this paragraph is based on personal communication with Jeff Mitchell in June, 2010.
Mitchell and Lapatas (2010) paper does not describe how Spearmans rho is applied.

568

fiDomain and Function: A Dual-Space Model

Algorithm
human
dual-space
addition
addition
addition
multiplication
multiplication
multiplication

Correlation for
ad-nn nn-nn
0.56
0.54
0.48
0.54
0.47
0.61
0.32
0.55
0.49
0.55
0.43
0.57
0.35
0.58
0.39
0.45

each phrase type
vb-ob avg
0.57
0.56
0.43
0.48
0.42
0.50
0.41
0.42
0.48
0.51
0.41
0.47
0.39
0.44
0.27
0.37

Comment
leave-one-out correlation between subjects
domain and function space
mono space
domain space
function space
mono space
domain space
function space

Table 20: Performance of the models on the evaluation dataset.
difference between the dual-space model (0.48) and element-wise multiplication with mono
space (0.47) is not signficant. The average correlation for an algorithm is based on 162 rho
values (3 phrase types  3 groups  18 participants = 162 rho values = 162 participants).
We calculate the statistical significance using a paired t-test with a 95% significance level,
based on 162 pairs of rho values.
4.3.3 Order Sensitivity
Mitchell and Lapatas (2010) dataset does not test for order sensitivity. Given a phrase pair
ab  cd, we can test for order sensitivity by adding a new pair ab  dc. We assume that
all such new pairs would be given a rating of 1 by the human participants. In Table 21, we
show what happens when this transformation is applied to the examples in Table 19. To
save space, we only give the examples for participant number 114.
Participant
114
114
114
114
114
114

Phrase type
adjective-noun
adjective-noun
adjective-noun
adjective-noun
adjective-noun
adjective-noun

Group
2
2
2
2
2
2

Phrase pair
certain circumstance  particular case
certain circumstance  case particular
large number  great majority
large number  majority great
further evidence  low cost
further evidence  cost low

Similarity
6
1
4
1
2
1

Table 21: Testing for order sensitivity by adding new phrase pairs.
Table 22 gives the results with the new, expanded dataset. With this more stringent
dataset, the dual-space model performs significantly better than both vector addition and
vector multiplication. Unlike element-wise multiplication and vector addition, the dualspace model addresses the issue of order sensitivity.
We manually inspected the new pairs that were automatically rated 1 and found that a
rating of 1 was reasonable in all cases, although some cases could be disputed. For example,
the original noun-noun pair tax charge  interest rate generates the new pair tax charge 
rate interest and the original verb-object pair produce effect  achieve result generates the
new pair produce effect  result achieve. It seems that we have a natural tendency to correct
569

fiTurney

Algorithm
human
dual-space
addition
addition
addition
multiplication
multiplication
multiplication

Correlation for
ad-nn nn-nn
0.71
0.81
0.66
0.37
0.22
0.25
0.15
0.22
0.23
0.23
0.20
0.24
0.18
0.22
0.18
0.19

each phrase type
vb-ob avg
0.73
0.75
0.62
0.55
0.19
0.22
0.18
0.18
0.19
0.22
0.18
0.21
0.18
0.19
0.12
0.17

Comment
leave-one-out correlation between subjects
domain and function space
mono space
domain space
function space
mono space
domain space
function space

Table 22: Performance when the dataset is expanded to test for order sensitivity.
these incorrectly ordered pairs in our minds and then assign them higher ratings than they
deserve. We predict that human ratings of these new pairs would vary greatly, depending
on the instructions that were given to the human raters. If the instructions emphasized the
importance of word order, the new pairs would get low ratings. This prediction is supported
by the results of SemEval 2012 Task 2 (Jurgens, Mohammad, Turney, & Holyoak, 2012),
where the instructions to the raters emphasized the importance of word order and wrongly
ordered pairs received low ratings.
4.3.4 Summary
When the dataset does not test for order sensitivity, vector addition performs slightly better
than the dual-space model. When the dataset tests for order sensitivity, the dual-space
model surpasses both vector addition and element-wise multiplication by a large margin.
4.4 Domain versus Function as Associated versus Similar
Chiarello et al. (1990) created a dataset of 144 word pairs that they labeled similar-only,
associated-only, or similar+associated (48 pairs in each of the three classes). Table 23
shows some examples from their dataset. These labeled pairs were created for cognitive
psychology experiments with human subjects. In their experiments, they found evidence
that processing associated words engages the left and right hemispheres of the brain in
ways that are different from processing similar words. That is, it seems that there is a
fundamental neurological difference between these two types of semantic relatedness.21
We hypothesize that similarity in domain space, simd (a, b), is a measure of the degree to
which two words are associated and similarity in function space, simf (a, b), is a measure of
the degree to which two words are similar. To test this hypothesis, we define similar-only,
simso (a, b), associated-only, simao (a, b), and similar+associated, simsa (a, b), as follows:

ratio(x, y) =

x/y if x > 0 and y > 0
0 otherwise

(33)

21. There is some controversy among cognitive scientists over the distinction between semantic similarity
and association (McRae, Khalkhali, & Hare, 2011).

570

fiDomain and Function: A Dual-Space Model

Word pair
table:bed
music:art
hair:fur
house:cabin
cradle:baby
mug:beer
camel:hump
cheese:mouse
ale:beer
uncle:aunt
pepper:salt
frown:smile

Class label
similar-only
similar-only
similar-only
similar-only
associated-only
associated-only
associated-only
associated-only
similar+associated
similar+associated
similar+associated
similar+associated

Table 23: Examples of word pairs from Chiarello et al. (1990), labeled similar-only,
associated-only, or similar+associated. The full dataset is in their Appendix.

simso (a, b) = ratio(simf (a, b), simd (a, b))

(34)

simao (a, b) = ratio(simd (a, b), simf (a, b))

(35)

simsa (a, b) = geo(simd (a, b), simf (a, b))

(36)

The intention is that simso is high when simf is high and simd is low, simao is high when
simd is high and simf is low, and simsa is high when both simd and simf are high. This is
illustrated in Figure 4.
a

a

a

D F

D F

D F

b

b

b

simso (a, b)

simao (a, b)

simsa (a, b)

similar-only

associated-only

similar+associated

Figure 4: Diagrams of Equations 34, 35, and 36.

571

fiTurney

4.4.1 Evaluation
From the experiments in the three preceding subsections, we have three sets of parameter
settings for the dual-space model. Table 24 shows these parameter values. In effect, these
three sets of parameter setttings give us three variations of the similarity measures, simso ,
simao , and simsa . We will evaluate the three variations to see how well they correspond to
the labels in Chiarello et al.s (1990) dataset.
Similarity
simr (a : b, c : d)
simc (ab, c)
simp (ab, cd)

Description
similarity of relations
similarity of noun-modifier compositions
similarity of phrases

Section
4.1
4.2
4.3

kd
800
800
200

pd
-0.1
0.3
0.3

kf
300
100
600

pf
0.5
0.6
0.6

Table 24: Parameter settings for the dual-space model.
For a given similarity measure, such as simso , we can sort the 144 word pairs in descending order of their similarities and then look at the top N pairs to see how many of them
have the desired label; in the case of simso , we would like to see that the majority of the
top N have the label similar-only. Table 25 shows the percentage of pairs that have the
desired labels for each of the three variations of the three similarity measures. Note that
random guessing would yield 33%, since the three classes of pairs have the same size.

Source of parameters
simr (a : b, c : d)

simc (ab, c)

simp (ab, cd)

N
10
20
30
10
20
30
10
20
30

Percentage of top N with desired label
similar-only associated-only similar+associated
70
90
90
80
85
80
63
77
73
90
90
80
80
70
70
70
67
73
50
90
80
65
80
80
47
77
73

Table 25: Percentage of the top N word pairs with the desired labels.
For all three sets of parameter settings, Table 25 displays a high density of the desired
labels at the tops of the sorted lists. The density slowly decreases as we move down the
lists. This is evidence that the three similarity measures are capturing the three classes of
Chiarello et al. (1990).
As another test of the hypothesis, we use the three similarity measures to create feature
vectors of three elements for each word pair. That is, the word pair a : b is represented by
the feature vector hsimso (a, b), simao (a, b), simsa (a, b)i. We then use supervised learning with
ten-fold cross-validation to classify the feature vectors into the three classes of Chiarello
et al. (1990). For the learning algorithm, we use logistic regression, as implemented in
572

fiDomain and Function: A Dual-Space Model

Weka.22 The results are summarized in Table 26. These results lend further support to the
hypothesis that similarity in domain space, simd (a, b), is a measure of the degree to which
two words are associated and similarity in function space, simf (a, b), is a measure of the
degree to which two words are similar.

Source of parameters
simr (a : b, c : d)
simc (ab, c)
simp (ab, cd)

Accuracy
61.1
59.0
58.3

similar-only
0.547
0.583
0.472

F-measure
associated-only similar+associated
0.660
0.625
0.702
0.490
0.699
0.563

average
0.611
0.592
0.578

Table 26: Performance of logistic regression with the three similarity measures as features.

In Table 25, similar-only seems more sensitive to the parameter settings than associatedonly and similar+associated. We hypothesize that this is because function similarity is
more difficult to measure than domain similarity. Note that the construction of function
space (Section 3.3) is more complex than the construction of domain space (Section 3.2).
Intuitively, it seems easier to identify the domain of a thing than to identify its functional
role. Gentners (1991) work suggests that children master domain similarity before they
become competent with function similarity.

5. Discussion of Experiments
This section discusses the results of the previous section.
5.1 Summary of Results
In Section 4.1, we used 374 multiple-choice analogy questions to evaluate the dual-space
model of relational similarity, simr (a : b, c : d). The difference between the performance of
the dual-space model (51.1% accuracy) and the best past result (56.1% accuracy), using a
holistic model, was not statistically significant. Experiments with a reformulated version
of the questions, designed to test order sensitivity, supported the hypothesis that both
domain and function space are required. Function space by itself is not sensitive to order
and merging the two spaces (mono space) causes a significant drop in performance.
In Section 4.2, we automatically generated 2,180 multiple-choice noun-modifier composition questions with WordNet, to evaluate the dual-space model of noun-modifier compositional similarity, simc (ab, c). The difference between the performance of the dual-space
model (58.3% accuracy) and the state-of-the-art element-wise multiplication model (57.5%
accuracy) was not statistically significant. The best performance was obtained with a holistic model (81.6%), but this model does not address the issue of linguistic creativity. Further
experiments suggest that a significant fraction of the gap between the holistic model and
the other models is due to noncompositional phrases. A limitation of the element-wise multiplication model is lack of sensitivity to order. Experiments with a reformulated version
22. Weka is available at http://www.cs.waikato.ac.nz/ml/weka/.

573

fiTurney

of the questions, designed to test order sensitivitiy, demonstrated a statistically significant
advantage to the dual-space model over the element-wise multiplication and vector addition
models.
In Section 4.3, we used Mitchell and Lapatas (2010) dataset of 324 pairs of phrases to
evaluate the dual-space model of phrasal similarity, simp (ab, cd). A reformulated version of
the dataset, modified to test order sensitivitiy, showed a statistically significant advantage
to the dual-space model over the element-wise multiplication and vector addition models.
In Section 4.4, we used Chiarello et al.s (1990) dataset of 144 word pairs, labeled
similar-only, associated-only, or similar+associated, to test the hypothesis that similarity
in domain space, simd (a, b), is a measure of the degree to which two words are associated
and similarity in function space, simf (a, b), is a measure of the degree to which two words
are similar. The experimental results support the hypothesis. This is interesting because
Chiarello et al. (1990) argue that there is a fundamental neurological difference in the way
people process these two kinds of semantic relatedness.
The experiments support the claim that the dual-space model can address the issues of
linguistic creativity, order sensitivity, and adaptive capacity. Furthermore, the dual-space
model provides a unified approach to both semantic relations and semantic composition.
5.2 Corpus-based Similarity versus Lexicon-based Similarity
The results in Section 4.4 suggest that function similarity may correspond to the kind of
taxonomical similarity that is often associated with lexicons, such as WordNet (Resnik,
1995; Jiang & Conrath, 1997; Leacock & Chodrow, 1998; Hirst & St-Onge, 1998). The
word pairs in Table 23 that are labeled similar-only are the kinds of words that typically
share a common hypernym in a taxonomy. For example, table:bed share the hypernym
furniture. We believe that this is correct, but it does not necessarily imply that lexiconbased similarity measures would be better than a corpus-based approach, such as we have
used here.
Of the various similarities in Section 4, arguably relational similarity, simr (a : b, c : d),
makes the most use of function similarity. By itself, function similarity achieves 50.8% on the
SAT questions (original five-choice version; see Table 12). However, the best performance
achieved on the SAT questions using WordNet is 43.0% (Veale, 2004). The difference is
statistically significant at the 95% confidence level, based on Fishers Exact Test.
Consider the analogy traffic is to street as water is to riverbed. One of the SAT questions
involves this analogy, with traffic :street as the stem pair and water :riverbed as the correct
choice. Both simr (a : b, c : d) (Equation 25) and function similarity by itself (Equation 22)
make the correct choice. We can recognize that traffic and water have a high degree of
function similarity; in fact, this similarity is used in hydrodynamic models of traffic flow
(Daganzo, 1994). However, we must climb the WordNet hierachy all the way up to entity
before we find a shared hypernym for traffic and water. We believe that no manually
generated lexicon can capture all of the functional similarity that can be discovered in a
large corpus.

6. Theoretical Considerations
This section examines some theoretical questions about the dual-space model.
574

fiDomain and Function: A Dual-Space Model

6.1 Vector Composition versus Similarity Composition
In the dual-space model, a phrase has no stand-alone, general-purpose representation, as a
composite phrase, apart from the representations of the component words. The composite
meaning is constructed in the context of a given task. For example, if the task is to measure
the similarity of the relation in dog :house to the relation in bird :nest, then we compose the
meanings of dog and house one way (see Section 4.1); if the task is to measure the similarity
of the phrase dog house to the word kennel, then we compose the meanings of dog and
house another way (see Section 4.2); if the task is to measure the similarity of the phrase
dog house to the phrase canine shelter, then we compose the meanings of dog and house a
third way (see Section 4.3). The composition is a construction that explicitly ties together
the two things that are being compared, and it depends on the nature of the comparison
that is desired, the task that is to be performed. We hypothesize that no single stand-alone,
task-independent representation can be constructed that is suitable for all purposes.
As we noted in the introduction, composition of vectors can result in a stand-alone
representation of a phrase, but composing similarities necessarily yields a linking structure
that connects a phrase to other phrases. These linking structures can be seen in Figures
1 to 4. Intuitively, it seems that an important part of how we understand a phrase is by
connecting it to other phrases. Part of our understanding of dog house is its connection to
kennel. Dictionaries make these kinds of connections explicit. From this perspective, the
idea of an explicit linking structure seems natural, given that making connnections among
words and phrases is an essential aspect of meaning and understanding.
6.2 General Form of Similarities in the Dual-Space Model
In this subsection, we present a general scheme that ties together the various similarities
that were defined in Section 4. This scheme includes similarities between chunks of text
of arbitrary size. The scheme encompasses phrasal similarity, relational similarity, and
compositional similarity.
Let t be a chunk of text (an ordered set of words), ht1 , t2 , . . . , tn i, where each ti is a
word. We represent the semantics of t by T = hD, Fi, where D and F are matrices. Each
row vector di in D, i = 1, 2, . . . , n, is the row vector in domain space that represents the
domain semantics of the word ti . Each row vector fi in F, i = 1, 2, . . . , n, is the row vector in
function space that represents the function semantics of the word ti . To keep the notation
simple, the parameters, kd and pd for domain space and kf and pf for function space, are
implicit. Assume that the row vectors in D and F are normalized to unit length. Note
that the size of the representation T scales linearly with n, the number of words in t, hence
we have information scalability. For large values of n, there will inevitably be duplicate
words in t, so the representation could easily be compressed to sublinear size without loss
of information.
Let t1 and t2 be two chunks of text with representations T1 = hD1 , F1 i and T2 =
hD2 , F2 i, where t1 contains n1 words and t2 has n2 words. Let D1 and D2 have the same
parameters, kd and pd , and let F1 and F2 have the same parameters, kf and pf . Then D1
is n1  kd , D2 is n2  kd , F1 is n1  kf , and F2 is n2  kf . Note that D1 DT
1 is an n1  n1
matrix of the cosines between any two row vectors in D1 . That is, the element in the i-th
575

fiTurney

T
row and j-th column of D1 DT
1 is cos(di , dj ). Likewise, D1 D2 is an n1  n2 matrix of the
cosines between any row vector in D1 and any row vector in D2 .
Suppose that we wish to measure the similarity, sim(t1 , t2 ), between the two chunks of
text, t1 and t2 . In this paper, we have restricted the similarity measures to the following
general form:
T
T
T
T
T
sim(t1 , t2 ) = f (D1 DT
1 , D 1 D 2 , D 2 D 2 , F1 F1 , F1 F2 , F2 F2 )

(37)

In other words, the only input to the composition function f is cosines (and the implicit
parameters, kd , pd , kf , and pf ); f does not operate directly on any of the row vectors in D1 ,
D2 , F1 , and F2 . In contrast to much of the work discussed in Section 2.1, the composition
operation is shifted out of the representations, T1 and T2 , and into the similarity measure,
f . The exact specification of f depends on the task at hand. When T1 and T2 are sentences,
we envision that the structure of f will be determined by the syntactic structures of the
two sentences.23
Consider relational similarity (Section 4.1):

sim1 (a : b, c : d) = geo(simf (a, c), simf (b, d))

(38)

sim2 (a : b, c : d) = geo(simd (a, b), simd (c, d))

(39)

sim3 (a : b, c : d) = geo(simd (a, d), simd (c, b))

sim1 (a : b, c : d) if sim2 (a : b, c : d)  sim3 (a : b, c : d)
simr (a : b, c : d) =
0 otherwise

(40)
(41)

This fits the form of Equation 37 when we have t1 = ha, bi and t2 = hc, di. We can see that
T
T
sim1 is based on cosines from F1 FT
2 , sim2 is based on cosines from D1 D1 and D2 D2 , and
T
sim3 is based on cosines from D1 D2 .
Consider compositional similarity (Section 4.2):

sim1 (ab, c) = geo(simd (a, c), simd (b, c), simf (b, c))

sim1 (ab, c) if a 6= c and b 6= c
simc (ab, c) =
0 otherwise

(42)
(43)

This can be seen as an instance of Equation 37 in which t1 = ha, bi and t2 = hci. In this
T
case, sim1 is based on cosines from D1 DT
2 and F1 F2 . The constraints, a 6= c and b 6= c,
T
can be expressed in terms of cosines from D1 D2 , as simd (a, c) 6= 1 and simd (b, c) 6= 1.
(Equivalently, we could use cosines from F1 FT
2 .) Similar analyses apply to the similarities
in Sections 4.3 and 4.4; these similarities are also instances of Equation 37.
Although the representations T1 and T2 have sizes that are linear functions of the numbers of phrases in t1 and t2 , the size of the composition in Equation 37 is a quadratic
function of the numbers of phrases in t1 and t2 . However, specific instances of this general
equation may be less than quadratic in size, and it may be possible to limit the growth
23. Note that there is no requirement for the two chunks of text, t1 and t2 , to have the same number of
words. That is, n1 does not necessarily equal n2 . In Section 4.2, n1 6= n2 .

576

fiDomain and Function: A Dual-Space Model

to a linear function. Also, in general, quadratic growth is often acceptable in practical
applications (Garey & Johnson, 1979).
With function words (e.g., prepositions, conjunctions), one option would be to treat
them the same as any other words. They would be represented by vectors and their similarities would be calculated in function and domain spaces. Another possibility would be
to use function words as hints to guide the construction of the composition function f . The
function words would not correspond to vectors; instead they would contribute to determining the linking structure that connects the two given chunks of text. The first option
appears more elegant, but the choice between the options should be made empirically.
6.3 Automatic Composition of Similarities
In Section 4, we manually constructed the functions that combined the similarity measures,
using our intuition and background knowledge. Manual construction will not scale up to the
task of comparing any two arbitrarily chosen sentences. However, there are good reasons
for believing that the construction of composition functions can be automated.
Turney (2008a) presents an algorithm for solving analogical mapping problems, such as
the analogy between the solar system and the Rutherford-Bohr model of the atom. Given
a list of terms from the solar system domain, {planet, attracts, revolves, sun, gravity, solar system, mass}, and a list of terms from the atomic domain, {revolves, atom, attracts,
electromagnetism, nucleus, charge, electron}, it can automatically generate a one-to-one
mapping from one domain to the other, {solar system  atom, sun  nucleus, planet
 electron, mass  charge, attracts  attracts, revolves  revolves, gravity  electromagnetism}. On twenty analogical mapping problems, it attains an accuracy of 91.5%,
compared to an average human accuracy of 87.6%.
The algorithm scores the quality of a candidate analogical mapping by composing the
similarities of the mapped terms. The composition function is addition and the individual
component similarities are holistic relational similarities. The algorithm searches through
the space of possible mappings for the mapping that maximizes the composite similarity
measure. That is, analogical mapping is treated as an argmax problem, where the argument
to be maximized is a mapping function. In effect, the output of the algorithm (an analogical
mapping) is an automically generated composition of similarities. The mapping structures
found by the algorithm are essentially the same as the linking structures that we see in
Figures 1 to 4.
We believe that a variation of Turneys (2008a) algorithm could be used to automatically compose similarities in the dual-space model; for example, it should be possible to
identify paraphrases using automatic similarity composition. The proposal is to search for
a composition that maximizes composite similarity, subject to various constraints (such as
constraints based on the syntax of the sentences). Turney (2008a) points out that analogical
mapping could be used to align the words in two sentences, but does not experimentally
evaluate this suggestion.
Recent work (Lin & Bilmes, 2011) has shown that argmax problems can be solved efficiently and effectively if they can be framed as monotone submodular function maximization
problems. We believe that automatic composition of similarities can fit naturally into this
framework, which would result in highly scalable algorithms for semantic composition.
577

fiTurney

Regarding information scalability, the dual-space model does not suffer from information
loss (unlike approaches that represent compositions with vectors of fixed dimensionality),
because the sizes of the representations grow as the lengths of the phrases grow. The growth
might be quadratic, but it is not exponential. There are questions about how to automate
composition of similarities, which may have an impact on the computational complexity of
scaling to longer phrases, but there is evidence that these questions are tractable.

7. Limitations and Future Work
One area for future work is to experiment with longer phrases (more than two words) and
sentences, as discussed in Section 6.3. An interesting topic for research is how parsing might
be used to constrain the automatic search for similarity composition functions.
Here we have focused on two spaces, domain and function, but it seems likely to us
that a model with more spaces would yield better performance. We are currently experimenting with a quad-space model that includes domain (noun-based contextual patterns),
function (verb-based), quality (adjective-based), and manner (adverb-based) spaces. The
preliminary results with quad-space are promising. Quad-space seems to be related to
Pustejovskys (1991) four-part qualia structure.
Another issue we have avoided here is morphology. As discussed in Section 3.6, we used
the validForms function in the WordNet::QueryData Perl interface to WordNet to map
morphological variations of words to their base forms. This implies that, for example, a
singular noun and its plural form should have the same semantic representation. This is
certainly a simplification and a more sophisticated model would use different representations
for different morphological forms of a word.
We have also avoided the issue of polysemy. It should be possible to extend past work
with polysemy in VSMs to the dual-space model (Schutze, 1998; Pantel & Lin, 2002; Erk
& Pado, 2008).
In this paper, we have treated the holistic model and the dual-space model as if they are
competitors, but there are certain cases, such as idiomatic expressions, where the holistic
approach is required. Likewise, the holistic approach is limited by its inability to handle
linguistic creativity. These considerations suggest that the holistic and dual-space models
must be integrated. This is another topic for future work.
Arguably it is a limitation of the dual-space model that there are four parameters to
tune (kd , pd , kf , and pf ). On the other hand, perhaps any model with adaptive capacity
must have some parameters to tune. Further research is needed.
A number of design decisions were made in the construction of domain and function
space, especially in the conversion of phrases to contextual patterns (Sections 3.2 and 3.3).
These decisions were guided by our intuitions. We expect that the exploration and experimental evaluation of this design space will be a fruitful area for future research.
The construction of function space (Section 3.3) is specific to English. It may generalize readily to other Indo-European languages, but some other languages may present a
challenge. This is another topic for future research.
Most of our composite similarities use the geometric mean to combine domain and
function similarities, but we see no reason to restrict the possible composition functions.
578

fiDomain and Function: A Dual-Space Model

Equation 37 allows any composition function f . Exploring the space of possible composition
functions is another topic for future work.
Another question is how formal logic and textual entailment can be integrated into this
approach. The dual-space model seems to be suitable for recognizing paraphrases, but
there is no obvious way to handle entailment. More generally, we have focused on various
kinds of similarity, but when we scale up from phrases (red ball) to sentences (The ball is
red), we encounter truth and falsity. Gardenfors (2004) argues that spatial models are a
bridge between low-level connectionist models and high-level symbolic models. He claims
that spatial models are best for questions about similarity and symbolic models are best
for questions about truth. We do not yet know how to join these two kinds of models.

8. Conclusions
The goal in this research has been to develop a model that unifies semantic relations and
compositions, while also addressing linguistic creativity, order sensitivity, adaptive capacity, and information scalability. We believe that the dual-space model achieves this goal,
although there is certainly room for improvement and further research.
There are many kinds of wordcontext matrices, based on various notions of context;
Sahlgren (2006) gives a good overview of the types of context that have been explored
in past work. The novelty of the dual-space model is that it includes two distinct and
complementary wordcontext matrices that work together synergistically.
With two distinct spaces, we have two distinct similarity measures, which can be
combined in many different ways. With multiple similarity measures, similarity composition becomes a viable alternative to vector composition. For example, instead of multiplying vectors, such as c = a fi b, we can multiply similarities, such as simsa (a, b) =
geo(simd (a, b), simf (a, b)). The results here suggest that this is a fruitful new way to look
at some of the problems of semantics.

Acknowledgments
Thanks to George Foster, Yair Neuman, David Jurgens, and the reviewers of JAIR for
their very helpful comments on an earlier version of this paper. Thanks to Charles Clarke
for the corpus used to build the three spaces, to Stefan Buttcher for Wumpus, to the
creators of WordNet for making their lexicon available, to the developers of OpenNLP,
to Doug Rohde for SVDLIBC, to Jeff Mitchell and Mirella Lapata for sharing their data
and answering questions about their evaluation methodology, to Christine Chiarello, Curt
Burgess, Lorie Richards, and Alma Pollock for making their data available, to Jason Rennie
for the WordNet::QueryData Perl interface to WordNet, and to the developers of Perl Data
Language.

References
Aerts, D., & Czachor, M. (2004). Quantum aspects of semantic analysis and symbolic
artificial intelligence. Journal of Physics A: Mathematical and General, 37, L123
L132.
579

fiTurney

Baroni, M., & Zamparelli, R. (2010). Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010
Conference on Empirical Methods in Natural Language Processing (EMNLP 2010),
pp. 11831193.
Bengio, Y., Ducharme, R., Vincent, P., & Jauvin, C. (2003). A neural probabilistic language
model. Journal of Machine Learning Research, 3, 11371155.
Bicici, E., & Yuret, D. (2006). Clustering word pairs to answer analogy questions. In
Proceedings of the Fifteenth Turkish Symposium on Artificial Intelligence and Neural
Networks (TAINN 2006), Akyaka, Mugla, Turkey.
Biemann, C., & Giesbrecht, E. (2011). Distributional semantics and compositionality 2011:
Shared task description and results. In Proceedings of the Workshop on Distributional
Semantics and Compositionality (DiSCo 2011), pp. 2128, Portland, Oregon.
Bollegala, D., Matsuo, Y., & Ishizuka, M. (2009). Measuring the similarity between implicit
semantic relations from the Web. In Proceedings of the 18th International Conference
on World Wide Web (WWW 2009), pp. 651660.
Brants, T., & Franz, A. (2006). Web 1T 5-gram Version 1. Linguistic Data Consortium,
Philadelphia.
Bullinaria, J., & Levy, J. (2007). Extracting semantic representations from word cooccurrence statistics: A computational study. Behavior Research Methods, 39 (3),
510526.
Buttcher, S., & Clarke, C. (2005). Efficiency vs. effectiveness in terabyte-scale information retrieval. In Proceedings of the 14th Text REtrieval Conference (TREC 2005),
Gaithersburg, MD.
Caron, J. (2001). Experiments with LSA scoring: Optimal rank and basis.. In Proceedings
of the SIAM Computational Information Retrieval Workshop, pp. 157169, Raleigh,
NC.
Chiarello, C., Burgess, C., Richards, L., & Pollock, A. (1990). Semantic and associative
priming in the cerebral hemispheres: Some words do, some words dont . . . sometimes,
some places. Brain and Language, 38, 75104.
Chomsky, N. (1975). The Logical Structure of Linguistic Theory. Plenum Press.
Church, K., & Hanks, P. (1989). Word association norms, mutual information, and lexicography. In Proceedings of the 27th Annual Conference of the Association of Computational Linguistics, pp. 7683, Vancouver, British Columbia.
Clark, S., Coecke, B., & Sadrzadeh, M. (2008). A compositional distributional model of
meaning. In Proceedings of the 2nd Symposium on Quantum Interaction, pp. 133140,
Oxford, UK.
Clark, S., & Pulman, S. (2007). Combining symbolic and distributional models of meaning.
In Proceedings of the AAAI Spring Symposium on Quantum Interaction, pp. 5255,
Stanford, CA.
Conway, J. H., & Sloane, N. J. A. (1998). Sphere Packings, Lattices and Groups. Springer.
580

fiDomain and Function: A Dual-Space Model

Daganzo, C. F. (1994). The cell transmission model: A dynamic representation of highway
traffic consistent with the hydrodynamic theory. Transportation Research Part B:
Methodological, 28 (4), 269287.
Davidov, D., & Rappoport, A. (2008). Unsupervised discovery of generic relationships using
pattern clusters and its evaluation by automatically generated SAT analogy questions.
In Proceedings of the 46th Annual Meeting of the ACL and HLT (ACL-HLT-08), pp.
692700, Columbus, Ohio.
Erk, K., & Pado, S. (2008). A structured vector space model for word meaning in context.
In Proceedings of the 2008 Conference on Empirical Methods in Natural Language
Processing (EMNLP-08), pp. 897906, Honolulu, HI.
Fellbaum, C. (Ed.). (1998). WordNet: An Electronic Lexical Database. MIT Press.
Firth, J. R. (1957). A synopsis of linguistic theory 19301955. In Studies in Linguistic
Analysis, pp. 132. Blackwell, Oxford.
Fodor, J., & Lepore, E. (2002). The Compositionality Papers. Oxford University Press.
Gardenfors, P. (2004). Conceptual Spaces: The Geometry of Thought. MIT Press.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory
of NP-Completeness. Freeman.
Gentner, D. (1983). Structure-mapping: A theoretical framework for analogy. Cognitive
Science, 7 (2), 155170.
Gentner, D. (1991). Language and the career of similarity. In Gelman, S., & Byrnes, J.
(Eds.), Perspectives on Thought and Language: Interrelations in Development, pp.
225277. Cambridge University Press.
Golub, G. H., & Van Loan, C. F. (1996). Matrix Computations (Third edition). Johns
Hopkins University Press, Baltimore, MD.
Grefenstette, E., & Sadrzadeh, M. (2011). Experimenting with transitive verbs in a DisCoCat. In Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural
Language Semantics.
Grice, H. P. (1989). Studies in the Way of Words. Harvard University Press, Cambridge,
MA.
Guevara, E. (2010). A regression model of adjective-noun compositionality in distributional
semantics. In Proceedings of the 2010 Workshop on GEometrical Models of Natural
Language Semantics (GEMS 2010), pp. 3337.
Harris, Z. (1954). Distributional structure. Word, 10 (23), 146162.
Hearst, M. (1992). Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th Conference on Computational Linguistics (COLING-92), pp. 539545.
Herdagdelen, A., & Baroni, M. (2009). Bagpack: A general framework to represent semantic
relations. In Proceedings of the EACL 2009 Geometrical Models for Natural Language
Semantics (GEMS) Workshop, pp. 3340.
581

fiTurney

Hirst, G., & St-Onge, D. (1998). Lexical chains as representations of context for the detection
and correction of malapropisms. In Fellbaum, C. (Ed.), WordNet: An Electronic
Lexical Database, pp. 305332. MIT Press.
Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based on corpus statistics
and lexical taxonomy. In Proceedings of the International Conference on Research in
Computational Linguistics (ROCLING X), pp. 1933, Tapei, Taiwan.
Johannsen, A., Alonso, H. M., Rishj, C., & Sgaard, A. (2011). Shared task system
description: Frustratingly hard compositionality prediction. In Proceedings of the
Workshop on Distributional Semantics and Compositionality (DiSCo 2011), pp. 29
32, Portland, Oregon.
Jones, M. N., & Mewhort, D. J. K. (2007). Representing word meaning and order information in a composite holographic lexicon. Psychological review, 114, 137.
Jurgens, D. A., Mohammad, S. M., Turney, P. D., & Holyoak, K. J. (2012). SemEval-2012
Task 2: Measuring degrees of relational similarity. In Proceedings of the First Joint
Conference on Lexical and Computational Semantics (*SEM), pp. 356364, Montreal,
Canada.
Kintsch, W. (2000). Metaphor comprehension: A computational theory. Psychonomic Bulletin & Review, 7 (2), 257266.
Kintsch, W. (2001). Predication. Cognitive Science, 25 (2), 173202.
Kolda, T., & Bader, B. (2009). Tensor decompositions and applications. SIAM Review,
51 (3), 455500.
Landauer, T. K. (2002). On the computational basis of learning and cognition: Arguments
from LSA. In Ross, B. H. (Ed.), The Psychology of Learning and Motivation: Advances
in Research and Theory, Vol. 41, pp. 4384. Academic Press.
Landauer, T. K., & Dumais, S. T. (1997). A solution to Platos problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge.
Psychological Review, 104 (2), 211240.
Landauer, T. K., McNamara, D. S., Dennis, S., & Kintsch, W. (2007). Handbook of Latent
Semantic Analysis. Lawrence Erlbaum, Mahwah, NJ.
Leacock, C., & Chodrow, M. (1998). Combining local context and WordNet similarity for
word sense identification. In Fellbaum, C. (Ed.), WordNet: An Electronic Lexical
Database. MIT Press.
Lee, D. D., & Seung, H. S. (1999). Learning the parts of objects by nonnegative matrix
factorization. Nature, 401, 788791.
Lepage, Y., & Shin-ichi, A. (1996). Saussurian analogy: A theoretical account and its
application. In Proceedings of the 16th International Conference on Computational
Linguistics (COLING 1996), pp. 717722.
Lin, H., & Bilmes, J. (2011). A class of submodular functions for document summarization.
In The 49th Annual Meeting of the Association for Computational Linguistics: Human
Language Technologies (ACL-HLT), pp. 510520.
582

fiDomain and Function: A Dual-Space Model

Mangalath, P., Quesada, J., & Kintsch, W. (2004). Analogy-making as predication using
relational information and LSA vectors. In Proceedings of the 26th Annual Meeting
of the Cognitive Science Society, p. 1623, Austin, TX.
McRae, K., Khalkhali, S., & Hare, M. (2011). Semantic and associative relations in adolescents and young adults: Examining a tenuous dichotomy. In Reyna, V., Chapman,
S., Dougherty, M., & Confrey, J. (Eds.), The Adolescent Brain: Learning, Reasoning,
and Decision Making, pp. 3966. APA, Washington, DC.
Mitchell, J., & Lapata, M. (2008). Vector-based models of semantic composition. In Proceedings of ACL-08: HLT, pp. 236244, Columbus, Ohio. Association for Computational
Linguistics.
Mitchell, J., & Lapata, M. (2010). Composition in distributional models of semantics.
Cognitive Science, 34 (8), 13881429.
Moschitti, A., & Quarteroni, S. (2008). Kernels on linguistic structures for answer extraction. In Proceedings of the 46th Annual Meeting of the Association for Computational
Linguistics on Human Language Technologies: Short Papers, p. 113116, Columbus,
OH.
Nakov, P., & Hearst, M. (2006). Using verbs to characterize noun-noun relations. In Proceedings of the 12th International Conference on Artificial Intelligence: Methodology,
Systems, and Applications (AIMSA 2006), pp. 233244, Varna, Bulgaria.
Nakov, P., & Hearst, M. (2007). UCB: System description for SemEval Task 4. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval 2007),
pp. 366369, Prague, Czech Republic.
Nastase, V., Sayyad-Shirabad, J., Sokolova, M., & Szpakowicz, S. (2006). Learning nounmodifier semantic relations with corpus-based and WordNet-based features. In Proceedings of the 21st National Conference on Artificial Intelligence (AAAI-06), pp.
781786.
Nastase, V., & Szpakowicz, S. (2003). Exploring noun-modifier semantic relations. In
Proceedings of the Fifth International Workshop on Computational Semantics (IWCS5), pp. 285301, Tilburg, The Netherlands.
Niwa, Y., & Nitta, Y. (1994). Co-occurrence vectors from corpora vs. distance vectors from
dictionaries. In Proceedings of the 15th International Conference On Computational
Linguistics, pp. 304309, Kyoto, Japan.
O Seaghdha, D., & Copestake, A. (2009). Using lexical and relational similarity to classify
semantic relations. In Proceedings of the 12th Conference of the European Chapter of
the Association for Computational Linguistics (EACL-09), Athens, Greece.
Pantel, P., & Lin, D. (2002). Discovering word senses from text. In Proceedings of the Eighth
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
pp. 613619, Edmonton, Canada.
Plate, T. (1995). Holographic reduced representations. IEEE Transactions on Neural Networks, 6 (3), 623641.
Pustejovsky, J. (1991). The generative lexicon. Computational Linguistics, 17 (4), 409441.
583

fiTurney

Rapp, R. (2003). Word sense discovery based on sense descriptor dissimilarity. In Proceedings of the Ninth Machine Translation Summit, pp. 315322.
Resnik, P. (1995). Using information content to evaluate semantic similarity in a taxonomy.
In Proceedings of the 14th International Joint Conference on Artificial Intelligence
(IJCAI-95), pp. 448453, San Mateo, CA. Morgan Kaufmann.
Rosario, B., & Hearst, M. (2001). Classifying the semantic relations in noun-compounds
via a domain-specific lexical hierarchy. In Proceedings of the 2001 Conference on
Empirical Methods in Natural Language Processing (EMNLP-01), pp. 8290.
Rosario, B., Hearst, M., & Fillmore, C. (2002). The descent of hierarchy, and selection in
relational semantics. In Proceedings of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL-02), pp. 247254.
Sahlgren, M. (2006). The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces.
Ph.D. thesis, Department of Linguistics, Stockholm University.
Santorini, B. (1990). Part-of-speech tagging guidelines for the Penn Treebank Project. Tech.
rep., Department of Computer and Information Science, University of Pennsylvania.
(3rd revision, 2nd printing).
Schutze, H. (1998). Automatic word sense discrimination. Computational Linguistics, 24 (1),
97124.
Smolensky, P. (1990). Tensor product variable binding and the representation of symbolic
structures in connectionist systems. Artificial Intelligence, 159216.
Socher, R., Huang, E. H., Pennington, J., Ng, A. Y., & Manning, C. D. (2011). Dynamic
pooling and unfolding recursive autoencoders for paraphrase detection. In Advances
in Neural Information Processing Systems (NIPS 2011), pp. 801809.
Socher, R., Manning, C. D., & Ng, A. Y. (2010). Learning continuous phrase representations
and syntactic parsing with recursive neural networks. In Proceedings of the NIPS-2010
Deep Learning and Unsupervised Feature Learning Workshop.
Thater, S., Furstenau, H., & Pinkal, M. (2010). Contextualizing semantic representations
using syntactically enriched vector models. In Proceedings of the 48th Annual Meeting
of the Association for Computational Linguistics, pp. 948957.
Turney, P. D. (2001). Mining the Web for synonyms: PMI-IR versus LSA on TOEFL. In
Proceedings of the Twelfth European Conference on Machine Learning (ECML-01),
pp. 491502, Freiburg, Germany.
Turney, P. D. (2006a). Expressing implicit semantic relations without supervision. In
Proceedings of the 21st International Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computational Linguistics (Coling/ACL06), pp. 313320, Sydney, Australia.
Turney, P. D. (2006b). Similarity of semantic relations. Computational Linguistics, 32 (3),
379416.
Turney, P. D. (2008a). The latent relation mapping engine: Algorithm and experiments.
Journal of Artificial Intelligence Research, 33, 615655.
584

fiDomain and Function: A Dual-Space Model

Turney, P. D. (2008b). A uniform approach to analogies, synonyms, antonyms, and associations. In Proceedings of the 22nd International Conference on Computational
Linguistics (Coling 2008), pp. 905912, Manchester, UK.
Turney, P. D., & Littman, M. L. (2005). Corpus-based learning of analogies and semantic
relations. Machine Learning, 60 (13), 251278.
Turney, P. D., Littman, M. L., Bigham, J., & Shnayder, V. (2003). Combining independent
modules to solve multiple-choice synonym and analogy problems. In Proceedings of
the International Conference on Recent Advances in Natural Language Processing
(RANLP-03), pp. 482489, Borovets, Bulgaria.
Turney, P. D., & Pantel, P. (2010). From frequency to meaning: Vector space models of
semantics. Journal of Artificial Intelligence Research, 37, 141188.
Utsumi, A. (2009). Computational semantics of noun compounds in a semantic space model.
In Proceedings of the 21st International Joint Conference on Artificial Intelligence
(IJCAI-09), pp. 15681573.
Veale, T. (2004). WordNet sits the SAT: A knowledge-based approach to lexical analogy. In
Proceedings of the 16th European Conference on Artificial Intelligence (ECAI 2004),
pp. 606612, Valencia, Spain.
Widdows, D. (2008). Semantic vector products: Some initial investigations. In Proceedings
of the 2nd Symposium on Quantum Interaction, Oxford, UK.

585

fiJournal of Artificial Intelligence Research 44 (2012) 196

Submitted 01/12; published 05/12

C OLIN: Planning with Continuous Linear Numeric Change
Amanda Coles
Andrew Coles
Maria Fox
Derek Long

AMANDA . COLES @ KCL . AC . UK
ANDREW. COLES @ KCL . AC . UK
MARIA . FOX @ KCL . AC . UK
DEREK . LONG @ KCL . AC . UK

Department of Informatics, Kings College London,
Strand, London WC2R 2LS, UK

Abstract
In this paper we describe COLIN, a forward-chaining heuristic search planner, capable of reasoning with COntinuous LINear numeric change, in addition to the full temporal semantics of
PDDL 2.1. Through this work we make two advances to the state-of-the-art in terms of expressive reasoning capabilities of planners: the handling of continuous linear change, and the handling of duration-dependent effects in combination with duration inequalities, both of which require tightly coupled temporal and numeric reasoning during planning. COLIN combines FF-style
forward chaining search, with the use of a Linear Program (LP) to check the consistency of the
interacting temporal and numeric constraints at each state. The LP is used to compute bounds on
the values of variables in each state, reducing the range of actions that need to be considered for
application. In addition, we develop an extension of the Temporal Relaxed Planning Graph heuristic of CRIKEY 3, to support reasoning directly with continuous change. We extend the range of task
variables considered to be suitable candidates for specifying the gradient of the continuous numeric
change effected by an action. Finally, we explore the potential for employing mixed integer programming as a tool for optimising the timestamps of the actions in the plan, once a solution has
been found. To support this, we further contribute a selection of extended benchmark domains that
include continuous numeric effects. We present results for COLIN that demonstrate its scalability
on a range of benchmarks, and compare to existing state-of-the-art planners.

1. Introduction
There has been considerable progress in the development of automated planning techniques for
domains involving independent temporal and metric conditions and effects (Eyerich, Mattmuller,
& Roger, 2009; Coles, Fox, Long, & Smith, 2008a; Gerevini, Saetti, & Serina, 2006; Edelkamp,
2003; Coles, Fox, Long, & Smith, 2008b). The development of powerful heuristics for propositional
planning has been shown to offer benefits in the solution of extended planning problems, including
planning under uncertainty (Palacios & Geffner, 2009), planning with numbers and planning with
time. However, the combination and integration of metric and temporal features, in which metric
quantities change in time-dependent ways, remains a challenge that has received relatively little
attention.
Interaction between time and numbers in planning problems can occur in many ways. In the
simplest case, using PDDL 2.1 (Fox & Long, 2003), the numeric effects of actions are only updated
instantaneously, and only at the start or end points of actions which are known (and fixed) at the
point of action execution. The corpus of domains from past International Planning Competitions
adhere to these restrictions. Time and numbers can interact in at least two more complex ways. First,
actions can have variable, possibly constrained, durations and the (instantaneous) effects of these
c
2012
AI Access Foundation. All rights reserved.

fiC OLES , C OLES , F OX & L ONG

actions can depend on the values of the durations. This allows domain models to capture the effects
of processes as discretised step effects, but adjusted according to the demands of specific problem
instances. Second, the effects of actions can be considered to be continuous across their execution,
so that the values of metric variables at any time point depend on how long the continuous effects
have been acting on them.
For example, a problem in which sand is loaded into a lorry can be modelled so that the amount
of sand loaded depends on the time spent loading. The first approach is to capture the increase in
the quantity of loaded sand as a step function applied at the end of the loading action. In the second
approach, the process of loading sand is modelled as a continuous and linear function of the time
spent loading, so that the amount of sand in the lorry can be observed at any point throughout the
loading process. If a safety device must be engaged before the lorry is more than three-quarters
full, then only the second of these models will allow a planner to have the necessary access to the
underlying process behaviour to make good planning choices about how to integrate this action into
solutions. There are alternative models exploiting duration-dependent effects to split the loading
action into two parts around the time point at which the safety device must be engaged, but these
alternatives become very complicated with relatively modest changes to the domain.
Continuous change in both of these forms is common in many important problems. These include: energy management, the consumption and replenishment of restricted continuous resources
such as fuel, tracking the progress of chemicals through storage tanks in chemical plants, choreographing robot motion with the execution of tasks, and managing the efficient use of time. In some
cases, a model using discrete time-independent change is adequate for planning. However, discretisation is not always practical: to find a reasonable solution (or, indeed, to find one at all) identifying
the appropriate granularity for discretisation is non-trivial, perhaps requiring a range of choices
that are so fine-grained as to make the discrete model infeasibly large. In other cases, the numeric
change cannot be appropriately discretised, where it is unavoidably necessary to have access to the
values of numeric variables during the execution of actions, in order to manage interactions between
numeric values.
In this paper we present a planner, COLIN, capable of reasoning with both variable, durationdependent, linear change and linear continuous numeric effects. The key advance that COLIN makes
is to be able to reason about time-dependent change through the use of linear programs that combine metric and temporal conditions and effects into the same representation. COLIN is a satisficing
planner that attempts to build good quality solutions to this complex class of problems. Since COLIN
is a forward-searching planner it requires a representation of states, a means to compute the progression of states and a heuristic function to guide the search for a path from the initial to the goal
state. COLIN is built on the planner CRIKEY 3 (Coles, Fox, Long et al., 2008a). However, CRIKEY 3
requires numeric change to be discrete and cannot reason with continuous numeric change, or duration dependent change (where the duration of actions is not fixed in the state in which the action
begins). Being able to reason successfully with problems characterised by continuous change, coping efficiently with a wide range of practical problems that are inspired by real applications, is the
major contribution made by COLIN.
The organisation of the paper is as follows. In Section 2 we explain the features of PDDL 2.1
that COLIN can handle, and contrast its repertoire with that of CRIKEY 3. In Section 4 we define
the problem that is addressed by COLIN. In Section 5 we outline the background in temporal and
metric planning that supports COLIN, before, in Section 6, describing the details of the foundations of COLIN that lie in CRIKEY 3. COLIN inherits its representation of states from CRIKEY 3,
2

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

as well as the machinery for confirming the temporal consistency of plans and the basis for the
heuristic function. In Section 7 we describe systems in the literature that have addressed similar
hybrid discrete-continuous planning problems to those that COLIN is designed to handle. Section 8
explains how state progression is extended in COLIN to handle linear continuous change, and Section 9 describes the heuristic that guides the search for solutions. In Section 10 we consider several
elements of COLIN that improve both efficiency and plan quality, without affecting the fundamental
behaviour of the planner. Since time-dependent numeric change has been so little explored, there
are few benchmarks in existence that allow a full quantitative evaluation. We therefore present
a collection of continuous domains that can be used for such analysis, and we show how COLIN
fares on these. An appendix containing some explanations of technical detail and some detailed
summaries of background work on which COLIN depends, ensures that the paper is complete and
self-contained.

2. Language Features in C RIKEY 3 and COLIN
COLIN builds on CRIKEY 3 by handling the continuous features of PDDL 2.1. C RIKEY 3 was restricted to management of discrete change, while COLIN can handle the full range of linear continuous numeric effects. The only metric functions of PDDL 2.1 that are not in the repertoire of COLIN
are scale-up and scale-down, which are non-linear updates, and the general form of plan metrics. Managing plan metrics defined in terms of domain variables remains a challenge for planning
that has not yet been fully confronted by any contemporary planner. COLIN does handle a restricted
form of quality metric, which exploits an instrumented variable called total-cost. This allows
COLIN to minimise the overall cost of the shortest plan it can find using total-time (the default
metric used by most temporal planners).
In common with CRIKEY 3, COLIN can cope with Timed Initial Literals, an important feature
that was introduced in PDDL 2.2 (Hoffmann & Edelkamp, 2005). PDDL 2.1 is backward compatible
with McDermotts PDDL (McDermott, 2000) and therefore supports ADL (Pednault, 1989). COLIN
does not handle full ADL, but it can deal with a restricted form of conditional effect as seen in the
airplane-landing problem described in section 11. This restricted form allows the cost of an action
to be dependent on the state in which it is applied. More general forms of conditional effect cannot
be handled.
With this collection of features, COLIN is able to fully manage both the discrete and continuous
numeric change that occur directly as a result of its actions. PDDL + (Fox & Long, 2006) further
supports the modelling of continuous change brought about by exogenous processes and events.
These are triggered by actions, but they model the independent continuous behaviour brought about
by the world rather than by the planners direct action. The key additional features of PDDL + that
support this are processes and events. COLIN does not handle these features but is restricted to the
management of continuous change as expressed through the durative action device.
For detailed explanations of the syntaxes and semantics of PDDL 2.1 and PDDL +, including the
semantics on which implementations of state representation and state progression must be constructed, readers should refer to the work of Fox and Long (2003, 2006).
3

fiC OLES , C OLES , F OX & L ONG

Language
PDDL 2.1
PDDL 2.1

Language Feature
Numeric conditions and effects
Continuous numeric effects

C RIKEY 3
yes
no

COLIN
yes
yes

PDDL 2.1

PDDL 2.1

General plan metrics
Use of total-cost
Assign (to discrete variables)
Scale-up/down
#t
Durative actions

no
no
yes
no
no
yes

no
yes
yes
no
yes
yes

PDDL 2.1

Duration inequalities

limited

yes

PDDL 2.2

TILs
Conditional Effects
Other ADL

yes
no
no

yes
partial
no

PDDL 2.1
PDDL 2.1
PDDL 2.1
PDDL 2.1

PDDL
PDDL

Comment
Basic treatment follows Metric-FF
Modification to state representation
Modification to heuristic

Section
Appendix B
Section 8
Section 9

Limited form
Treatment follows Metric-FF

Section 10

As continuous effects
Includes required concurrency
COLIN handles
duration-dependent effects

Only for limited effects

Section 6 and
Appendix C
Sections 8 and 9
Section 6
Section 10

Table 1: Language features handled by CRIKEY 3 and COLIN.

3. Motivation
There are a number of accounts of planning having been successfully applied to real problems,
and the frequency with which applications are reported is increasing. The following examples involve domains with hybrid discrete-continuous dynamics. These dynamics are typically being dealt
with by discretising time, packaging continuous numeric effects into step functions, or integrating
propositional planning techniques with specialised solvers. They are all examples in which hybrid
discrete-continuous reasoning could be exploited to improve plan quality or solution time.
 Operations of refineries (Boddy & Johnson, 2002; Lamba, Dietz, Johnson, & Boddy, 2003)
or chemical plants (Penna, Intrigila, Magazzeni, & Mercorio, 2010), where the continuous
processes reflect flows of materials, mixing and chemical reactions, heating and cooling.
 Management of power and thermal energy in aerospace applications in which power management is critical, such as management of the solar panel arrays on the International Space
Station (Knight, Schaffer, & B.Clement, 2009; Reddy, Frank, Iatauro, Boyce, Kurklu, AiChang, & Jonsson, 2011). For example, Knight et al. (2009) rely on a high-fidelity power
model (TurboSpeed) to provide support for reasoning about the continuous power supply in
different configurations of the solar panels. Power management is a critical problem for most
space applications (including planetary rovers and landers, inspiring the temporal-metriccontinuous Rovers domain used as one of our benchmark evaluation domains in Section 11).
Chien et al. (2010) describe the planner used to support operations on Earth Observing 1 (EO1), where the management of thermal energy generated by instruments is sufficiently important that the on-board planner uses some of its (highly constrained) CPU cycles to model and
track its value. EO-1 inspires the temporal-metric-continuous Satellite benchmark described
in Section 11.
 Management of non-renewable power in other contexts, such as for battery powered devices.
The battery management problem described by Fox et al. (2011) relies on a non-linear model,
4

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

which COLIN must currently reduce to a discrete or linear approximation, coupled with iterated validation and solution refinement, in order to optimise power use. Battery management
is an example of a continuous problem that cannot be solved if the continuous dynamics are
removed.
 Assignment of time-dependent costs as in the Aircraft Landing domain (Dierks, 2005), in
which continuous processes govern the changing costs of the use of the runway as the landing
time deviates from the optimal landing time for each aircraft. This problem inspires the
Aircraft-Landing benchmark domain described in Section 11.
 Choreography of mobile robotic systems: in many cases, operations of robotic platforms
involve careful management of motion alongside other tasks, where the continuous motion
of the robot constrains the accessibility of specific tasks, such as inspection or observation.
Existing examples of hybrid discrete-continuous planning models and reasoning for problems of this kind include work using flow tubes to capture the constraints on continuous
processes (Leaute & Williams, 2005; Li & Williams, 2008). Problems involving autonomous
underwater vehicles (AUVs) inspired the temporal-metric-continuous AUV benchmark presented in Section 11.

4. Problem Definition
COLIN is designed to solve a class of problems that are temporal and metric, and that feature linear
continuous metric change. We refer to this as the class of temporal-metric-continuous problems,
and it contains a substantial subset of the problems that can be expressed in PDDL 2.1.
As a step towards the class of temporal-metric-continuous problems, we recall the definition
of a simple temporal-metric planning problem  one in which there is no time-dependent metric
change. Simple temporal-metric problems can be represented as a tuple hI, A, G, M i, where:
 I is the initial state: a set of propositions and an assignment of values to a set of numeric
variables. Either of these sets may be empty. For notational convenience, we refer to the
vector of numeric values in a given state as v.
 A, a set of actions, each hdur , pre ` , eff ` , pre  , pre a , eff a i, where:
 pre ` (pre a ) are the start (end) conditions of a: at the state in which a starts (ends), these
conditions must hold (for a detailed account of some of the subtleties in the semantics
of action application, see Fox & Long, 2003).
 eff ` (eff a ) are the start (end) effects of a: starting (ending) a updates the world state
according to these effects. A given collection of effects eff x , x  {`, a}, consists of:
 eff 
x , propositions to be deleted from the world state;
 eff +
x , propositions to be added to the world state;
 eff nx , effects acting upon numeric variables.
 pre  are the invariant conditions of a: these must hold at every point in the open interval
between the start and end of a.
 dur are the duration constraints of a, calculated on the basis of the world state in which
a is started, and constraining the length of time that can pass between the start and end
of a. They each refer to the special parameter ?duration, denoting the duration of a.
5

fiC OLES , C OLES , F OX & L ONG

 G, a goal: a set of propositions and conditions over numeric variables.
 optionally M , a metric optimisation function, defined as a function of the values of numeric
variables at the end of the plan, and the special variable total-time, denoting the makespan
of the plan.
A solution to such a problem is a time-stamped sequence of actions, with associated durations, that
transforms the initial state into a state satisfying the goal, respecting all the conditions imposed. The
durations of the actions must be specified explicitly, since it is possible that the action specifications
can be satisfied by different duration values.
PDDL 2.1 numeric conditions used in pre ` , pre a , pre  , dur and G can be expressed in the
form:
hf (v), op, ci, such that op  {, <, =, >, }, c  <
where v is the vector of metric fluents in the planning problem, f (v) is a function applied to the
vector of numeric fluents and c is an arbitrary constant. Numeric effects used in eff ` and eff a are
expressed as:
hv, op, f (v)i, such that op  {=, +=, =, -=, =}
A restricted form of numeric expressions is the set of expressions in Linear Normal Form (LNF).
These are expressions in which f (v) is a weighted sum of variables plus a constant, expressible in
the form w  v + c, for a vector of constants, w. A notable consequence of permitting dur to take the
form of a set of LNF constraints over ?duration is that ?duration need not evaluate to a single
fixed value. For instance, it may constrain the value of ?duration to lie within a range of values,
e.g. (?duration  v1 )  (?duration  v2 ), for some numeric variables v1 and v2 . Restricting
conditions and effects to use only LNFs allows the metric expressions to be captured in a linear
program model, a fact that we exploit in COLIN.
The class of temporal-metric problems is extended to temporal-metric-continuous problems by
two additions:
1. Each action a  A is described with an additional component: a set of linear continuous
numeric effects, cont, of the form hv, ki, k  <, denoting that a increases v at the rate of k
per unit of time. This corresponds to the PDDL 2.1 effect (increase (v) (* #t k)).
2. The start or end effects of actions (eff n` and eff na may, additionally, include the parameter
?duration, denoting the duration of the action, and hence are written:
hv, op, w  v + k.(?duration) + ci s.t. op  {+=, =, -=}, c, k  <
In temporal-metric-continuous problems the relationship between time and numbers is more complex than in temporal-metric problems. The first extension allows the value of a variable v to depend
on the length of time elapsed since the continuous effect acting upon it began. The second extension implies that, if ?duration is not fixed, then the value of variables can depend on the duration
assigned to the action. In fact , very few planners allow the literal ?duration to appear in effects,
even in actions where the value of the parameter is constrained to take a single fixed value by the
duration constraint (e.g. (= ?duration 10)). A typical idiom is to name the intended value of the
duration with a metric fluent in the initial state (e.g. (= (durationOfAction) 10)) and then use this
fluent in the effects.
6

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

(:durative-action saveHard
:parameters ()
:duration (= ?duration 10)
:condition
(and (at start (canSave))
(over all (>= (money) 0)))
:effect
(and (at start (not (canSave)))
(at end (canSave))
(at start (saving))
(at end (not (saving)))
(increase (money) (* #t 1))))

(:durative-action lifeAudit
:parameters ()
:duration (= ?duration (patience))
:condition
(and (at start (saving))
(at end (boughtHouse))
(at end (>= (money) 0)))
:effect (and (at end (happy)))))

(:durative-action takeMortgage
:parameters (?m - mortgage)
:duration (= ?duration (durationFor ?m))
:condition
(and (at start (saving))
(at start (>= (money) (depositFor ?m)))
(over all (<= (money) (maxSavings ?m))))
:effect
(and (at start (decrease (money) (depositFor ?m)))
(decrease (money) (* #t (interestRateFor ?m)))
(at end (boughtHouse))))

Figure 1: Actions for the Borrower Domain.

Temporal-metric-continuous problems form a significant subset of problems expressible in the
PDDL + language (Fox & Long, 2006), including those with linear continuous change within durative
actions. The problems do not include non-linear continuous change, nor do they explicitly represent
events or processes, although the use of certain modelling tricks can capture similar behaviours.
4.1 An Example Problem
As a running example of a temporal-metric-continuous domain we use the problem shown in Figure 1. In this, the Borrower Domain, a borrower can use a mortgage to buy a house. The domain is
simplified in order to focus attention on some key aspects of continuous reasoning and is not proposed as a realistic application. Furthermore, the domain does not exploit variable duration actions,
even though the ability to handle these is a key feature of COLIN. The example illustrates required
concurrency, by means of interesting interactions between multiple actions affecting a single continuous variable, and allows us to demonstrate the differences between alternative heuristics described
in Section 9. Management of required concurrency is also a key feature of COLIN, and domains
with variable durations are discussed later in the paper.
In this domain, to obtain a mortgage it is necessary to have an appropriate active savings plan
and to be able to lay down a deposit. These conditions are both achieved by saving hard, an action
that cannot be applied in parallel with itself, preventing the borrower from building up capital at
an arbitrarily high rate by multiple parallel applications of saveHard. For the sake of the example
we restrict the saving periods to durations of 10 years to produce interesting interactions with the
7

fiC OLES , C OLES , F OX & L ONG

(:objects shortMortgage longMortgage - mortgage)
(:init (= (money) 0)
(canSave)
(= (patience) 4)
(= (depositFor shortMortgage) 5)
(= (durationFor shortMortgage) 10)
(= (interestRateFor shortMortgage) 0.5)
(= (maxSavings shortMortgage) 6)
(= (depositFor longMortgage) 1)
(= (durationFor longMortgage) 12)
(= (interestRateFor longMortgage) 0.75)
(= (maxSavings longMortgage) 6))
(:goal (and (happy)))
(:metric minimize (total-time))

Figure 2: An example problem for the Borrower Domain.

durations of the mortgages in the sample problem. Once a person starts saving he or she is tied into
a 10-year savings plan.
The constraint on being able to start a mortgage leads to required concurrency between saving
and taking a mortgage. The effects of saving and repaying interest therefore combine to yield
different linear effects on the value of the money variable, while the saving action requires this
variable to remain non-negative throughout the duration of the saveHard action. Furthermore, in
order to qualify for tax relief, each mortgage carries a maximum allowed level of savings throughout
the mortgage (which prevents the mortgage being taken too late in the savings plan). Finally, the
lifeAudit action places a constraint on the gap between the end of the saving action and the
point at which the mortgage is completed (and also ensures that the borrower does not end up in
debt). This action acknowledges that borrowers will only be happy if they manage to complete their
mortgages within short periods (limited by their patience) of having to save hard.
The simple problem instance we will consider is shown in Figure 2. Two possible solutions to
this are shown in Figure 3. In the first solution the borrower takes the longer mortgage, which has
the advantage that it can start earlier because it requires a lower deposit. Money rises at rate 1 over
the first part of the saving action, then decreases by 1 when the mortgage starts. It then rises at rate
0.25 (the difference between the saving and mortgage rates) until the saving action concludes, when
it continues to decrease at rate 0.75 until the mortgage ends. The life audit action must start during
a saving action and cannot end until after the end of a mortgage action. In the second solution the
borrower takes the shorter mortgage, but that cannot start as early because it requires a much larger
deposit. As a consequence, the life audit cannot start during the first saving action: the mortgage
finishes too late to be included inside a life audit beginning within the first saving action. To meet
the initial condition of the life audit, the borrower must therefore perform a second saving action
to follow the first. Clearly the first solution is preferable since we are interested in minimising the
makespan.
8

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

money

12 units
1 unit
takeMortgage longMortgage
10 units
saveHard
lifeAudit
4 units

money

10 units
takeMortgage shortMortgage
5 units
10 units

10 units

saveHard

saveHard
lifeAudit
4 units

Figure 3: Possible solutions to the Borrower problem.

5. Background in Metric and Temporal Planning
Most recent work on discrete numeric planning is built on the ideas introduced in the planner MetricFF (Hoffmann, 2003). A discrete numeric planning problem introduces numeric variables into the
planning domain that can hold any real numeric value (or be undefined, if they have not yet been
given a value). Actions can have conditions expressed in terms of these variables, and have effects
that act upon them. To provide heuristic guidance, Metric-FF introduced an extension of the relaxed
planning graph (RPG) heuristic (Hoffmann & Nebel, 2001), the Metric RPG heuristic, supporting
the computation of a relaxed plan for a problems involving discrete numeric change. As with the
propositional RPG heuristic, it performs a forwards-reachability analysis in which the delete effects
of actions are relaxed (ignored). For numeric effects, ignoring decrease effects does not always
relax the problem, as conditions can require that a variable hold a value less than a given constant.
Thus, as the reachability analysis extends forwards, upper- and lower- bounds on the values of
numeric variables are computed: decrease effects have no effect upon the upper bound and increase
effects have no effect upon the lower bound, while assignment effects replace the value of the upper
(lower) bound if the incumbent has a lower (greater) value (respectively) than that which would be
assigned. Deciding whether a precondition is satisfied in a given layer is performed (optimistically)
9

fiC OLES , C OLES , F OX & L ONG

on the basis of these: for a condition w  v  c1 , then an optimistically high value for w  v can
be computed by using the upper bound on each fluent v assigned a value in v if its corresponding
weight in w is positive, or, otherwise, using its lower bound.
An alternative to the use of a Metric RPG is proposed in LPRPG (Coles, Fox, Long et al.,
2008b), where a linear program is constructed incrementally to capture the interactions between
actions. This approach is restricted to actions with linear effects, so is not as general as Metric-FF,
but it provides a more accurate heuristic guidance in handling metric problems and can perform
significantly better in problems where metric resources must be exchanged for one another in order
to complete a solution.
Numeric planning also gives the opportunity to define metric optimisation functions in terms of
metric variables within the problem description. For example, an objective to minimise fuel consumption can be defined for domains where the quantity of fuel available is a metric variable. This
optimisation function can also include the special variable total-time, representing the makespan
(execution duration) of the plan. Most planners are restricted to a weighted sum across variables
(although PDDL 2.1 syntax allows it to be an unrestricted expression across variables). In general,
planners are not yet capable of optimising metric functions effectively: the task of finding any plan
remains difficult. However, there are some planners that attempt to optimise these functions, the
most notable being LPG (Gerevini & Serina, 2000) (and, in domains where the only numeric effects
are to count action cost, LAMA, due to Richter & Westphal, 2010).
Although the introduction of PDDL 2.1 led to an increased interest in temporal planning, earlier
work on planning with time has been influential. IxTeT (Ghallab & Laruelle, 1994) introduced
chronicles, consisting of temporal assertions and constraints over a set of state variables, and timelines which are chronicles for single state variables. Timelines have since been widely used by
planners that have followed a different trajectory of development than that led by the PDDL family of languages (Pell, Gat, Keesing, Muscettola, & Smith, 1997; Frank & Jonsson, 2003; Cesta,
Cortellessa, Fratini, & Oddi, 2009). IxTeT also pioneered the use of many important techniques,
including simple temporal networks and linear constraints.
The language introduced for the planner Temporal Graph Plan (TGP) (Smith & Weld, 1999)
allowed (constant) durations to be attached to actions. The semantics of these actions required their
preconditions, pre, to be true for the entire duration of the action, and the effects of the actions,
eff, to become available instantaneously at their ends. The values of affected variables are treated
as undefined and inaccessible during execution, although the intended semantics (at least in TGP)
is that the values should be considered unobservable during these intervals and, therefore, plans
should be conformant with respect to all possible values of these variables over these intervals. T GP
solves these problems using a temporally extended version of the Graphplan planning graph (Blum
& Furst, 1995) to reason with temporal constraints. A temporal heuristic effective for this form of
temporal planning was developed by Haslum and Geffner (2001) and Vidal and Geffner (2006) have
explored a constraint propagation approach to handling these problems.
Even when using the more expressive temporal model defined in PDDL 2.1, many temporal planners make use of the restricted TGP semantics, exploiting a simplification of the PDDL 2.1 encoding
known as action compression. The compression is performed by setting pre to be the weakest
preconditions of the actions, and eff + (eff  ) to be their strongest add (delete) effects. In the propo1. Conditions w  v  c can be rewritten in this form by negating both sides. Further, those stating w  v = c can be
rewritten as a pair of conditions, w  v  c and (w  v)  c

10

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Action A
Q, not P

P

T

P
Action B
R
P

R

Q,S

Action C

Action D
S

T, G

Ordering of achiever before precondition
Ordering of deleter after precondition

Figure 4: A problem for SAPA.
sitional case, in terms of the action representation introduced earlier, these are:
pre = pre `  ((pre   pre a ) \ eff +
`)

+
eff + = (eff +
` \ eff a )  eff a
+

+
eff  = ((eff 
` \ eff ` )  eff a ) \ eff a

Many modern temporal planners, such as MIPS - XXL (Edelkamp & Jabbar, 2006) and earlier versions of LPG (Gerevini & Serina, 2000), make use of this action compression technique. However,
applying the compression can lead to incompleteness (Coles, Fox, Halsey, Long, & Smith, 2008)
(in particular, a failure to solve certain temporal problems). The issues surrounding incompleteness
were first discussed with reference to the planner CRIKEY (Fox, Long, & Halsey, 2004) and, later,
the problem structures causing this were said to introduce required concurrency (Cushing, Kambhampati, Mausam, & Weld, 2007). The Borrower domain is one example of a problem in which
the compression prevents solution. Both the lifeAudit and takeMortgage actions have initial
preconditions that can only be satisfied inside the interval of the saveHard action, since this action
adds saving at its start, but deletes it at its end.
Required concurrency is a critical ingredient in planning with continuous effects, as both when
change occurs and what change occurs are important throughout the execution of actions. In order to avoid producing poor quality plans or, indeed, excluding possible solutions, we must allow
concurrency between actions wherever the problem description permits it. A nave extension of
the compression approach would discretise continuous numeric change into step function effects
occurring at the ends of the relevant actions, precluding any possibility of managing the interaction
between numeric variables during execution of actions with continuous effects. We therefore build
our approach on a planner capable of reasoning with required concurrency. In the Borrower domain, the mortgage action must overlap with the saving action, but it cannot be too early (to meet
the deposit requirement) or too late (to meet the maximum savings constraint and to ensure that the
life audit can be performed as early as possible). As this example illustrates, problems that include
reasoning with continuous linear change typically also require concurrency.
Several planners are, currently, capable of reasoning with the PDDL 2.1 startend semantics, as
opposed to relying on a compression approach. The earliest PDDL 2.1 planner that reasons successfully with the semantics is VHPOP (Younes & Simmons, 2003), which is a partial-order planner.
11

fiC OLES , C OLES , F OX & L ONG

This planner depends on heuristic guidance based on the same relaxed planning graph that is used in
FF, so the guidance can fail in problems with required concurrency. Nevertheless, the search space
explored by VHPOP includes the interleavings of action start and end points that allow solution of
problems with required concurrency. V HPOP suffers from some of the problems encountered in
earlier partial-order planners and its performance scales poorly in many domains. T PSYS (Garrido,
Fox, & Long, 2002; Garrido, Onainda, & Barber, 2001) is a Graphplan-inspired planner that can
produce plans in domains with required concurrency. Time is represented by successive layers of
the graph, using a uniform time increment for successive layers. This approach is similar to the way
that TGP uses a plan graph to represent temporal structure, but TPSYS supports a model of actions
that separates the start and end effects of actions as dictated by PDDL 2.1 semantics.
Another planner that adopts a Graphplan-based approach to temporal planning is LPGP (Long
& Fox, 2003a), but in its case the time between successive layers is variable. Instead of using layers
of the graph to represent the passage of fixed-duration increments of time, they are used to represent
successive happenings  time points at which state changes occur. The time between successive state changes is allowed to vary within constraints imposed by the action durations whose end
points are fixed at particular happenings. A linear program is constructed, incrementally, to model
the constraints and the solution of the program is interleaved with the selection of action choices.
This approach suffers from most of the weaknesses of a Graphplan planner: the exhaustive iterative
deepening search is impractical for large problems, while computation and storage of mutex relations becomes very expensive in larger problems. Nevertheless, LPGP provides a useful approach to
the treatment of PDDL 2.1 durative actions, by splitting them into their end points which are treated
as instantaneous snap actions. A solution to the (original) planning problem can be expressed in
terms of these, subject to four conditions:
1. Each start snap-action is paired with an end snap-action (and no end can be applied without
its corresponding start having been applied earlier);
2. Between the start and end of an action, the invariants of the action pre are respected;
3. No actions must be currently executing for a state to be considered to be a goal state;
4. Each step in the plan occurs after the preceding step, and the time between the start and end
of an action respect its duration constraints.
S APA (Do & Kambhampati, 2003) is one of the earliest forward-search planners to solve temporal PDDL 2.1 problems. It works with a priority queue of events. When a durative action is started
its end point is queued at the time in the future at which it will be executed. The choice points of
the planner include starting any new action, but also a special wait action, which advances time to
the next entry in the queue, and the corresponding action end point is executed. This allows SAPA to
reason with concurrency and to solve some problems with required concurrency. Unfortunately, its
search space does not include all necessary interleavings to achieve a complete search. For example,
consider the problem illustrated in Figure 4. To solve this problem, action A must start, then action
B must start early enough to allow C to complete before A ends (and deletes P ) and late enough
that action D can start before B ends but end after A ends. All of the actions are required in order
to allow D to be applied, achieving the goal G. After SAPA starts action A, the queue will contain
the end of A. The choices now open are to start B immediately, but this will then end too early to
allow D to execute successfully, or else to complete A, which advances time too far to allow B to
12

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Light Match
Have Light
Unused Match

Have Light
Unused Match

Have Light

Mend Fuse
Needs Fixing Fuse

Have Light

Needs Fixing Fuse

Fixed Fuse

Figure 5: Required Concurrency

exploit effect P of A, preventing C from being executed. In fact, a simpler problem defeats SAPA:
if B were to have end condition Q instead of T and end effect G then C and D can be dispensed
with. However, the additional complexity of the existing example is that it is impossible to infer
when to start B by examination of A and B alone, because the timing constraints on the start of B
depends on both actions C and D and it is not immediately obvious how their temporal constraints
will affect the placement of B. The difficulty in adopting the waiting approach is that it is hard to
anticipate how long to wait if the next interesting time point depends on the interaction of actions
that have not yet even been selected.
A different approach to forward-search temporal planning is explored in the CRIKEY family of
planners (Coles, Fox, Halsey et al., 2008; Coles, Fox, Long et al., 2008a). These planners use the
same action splitting approach used in LPGP, but work with a heuristically guided forward search.
The heuristics in these planners use a relaxed planning graph as a starting point (Hoffmann & Nebel,
2001), but extend it by adding some guidance about the temporal structure of the plan, pruning
choices that can be easily demonstrated to violate temporal constraints and inferring choices where
temporal constraints imply them. The planners use a Simple Temporal Network to model and solve
the temporal constraints between the action end points as they are accumulated during successive
action choices. Split actions have also been used to extend LPG into a temporal version that respects
the semantics of PDDL 2.1 (Gerevini, Saetti, & Serina, 2010) (earlier versions of LPG use the compressed action models described above). Recent work by Haslum (2009) has explored other ways
in which heuristics for temporal planning can be constructed, while remaining admissible.
Temporal Fast Downward (Eyerich et al., 2009), based on Helmerts Fast Downward planner (Helmert, 2006), uses an approach that is a slight refinement of the compressed action model,
allowing some required concurrency to be managed. The authors demonstrate that this planner can
solve the Match problem shown in Figure 5. They mistakenly claim that SAPA cannot solve this
problem because it cannot consider applying an action between starting and ending lighting the
match: in fact, SAPA can apply the mend fuse action after the match is lit, in much the same
way as is done in Temporal Fast Downward. The problem that both planners face is in situations
in which an action must be started some time after the last happening, but before the next queued
event: neither planner includes this choice in its search space.
Huang et al. (2009) developed a temporal planner exploiting the planning-as-SATisfiability
paradigm. This uses a Graphplan-to-SAT encoding, starting with an LPGP action-splitting compilation, and using a fixed time increment between successive layers of the graph. This approach is
13

fiC OLES , C OLES , F OX & L ONG

adequate for problems where an appropriate time increment can be identified, but this is not possible, in general, when there are time-dependent effects in a domain. Furthermore, the approach is
ineffective when there is significant difference between the durations of actions, so that the time increment becomes very short relative to some actions. The planner can produce optimal (makespan)
plans using iterative deepening search. The planner combines existing ideas to achieve its objectives
and it is mainly of interest because of its relationship to other SAT-based approaches to temporal
planning, such as TM - LPSAT discussed below.
C RIKEY 3, and the other planners mentioned, are only capable of solving the simple temporal
planning problems described above. They are restricted to the management of discrete change.
Duration-dependent change cannot be handled by these planners. In fact, not all of these planners
can manage any kind of reasoning with numbers outside the durations of actions. COLIN therefore
significantly extends the competence of other PDDL-compliant temporal planners.

6. C RIKEY3: A Forward-Chaining Temporal Planner
Temporal forward-chaining planners have two kinds of choices to make during the construction of
plans. Firstly, as in the non-temporal case, a choice must be made of which actions to apply (these
choices can be considered to be the planning element of the problem). Secondly, choices must
be made of when to apply the actions (these can be seen as the scheduling choices in construction of solutions). CRIKEY 3 (Coles, Fox, Long et al., 2008a), a temporal forward-chaining planner,
exploits the distinction between these choices, using separate procedures to make the planning decisions (which actions to start or end) and the scheduling decisions (when to place actions on the
timeline). Both of these decisions must be checked for consistency with respect to the existing
temporal constraints to confirm that all the actions can be completely scheduled. In this section,
we briefly describe how CRIKEY 3 performs planning and scheduling, since its architecture forms
the basis for COLIN and the work subsequently described in this paper. Full details of temporal
management in CRIKEY 3 are provided by Coles et al.
CRIKEY 3 uses a forward-chaining heuristic state-space search to drive its planning decisions. It
makes use of the Enforced Hill-Climbing (EHC) algorithm introduced in FF (Hoffmann & Nebel,
2001) and repeated, for convenience, as Algorithm 1. EHC is incomplete, so if a solution cannot
be found CRIKEY 3 plans again, using a weighted A* search. We now discuss how the search described within the basic enforced hill-climbing algorithm of FF can be extended to perform temporal
planning. In order to do this, a number of modifications are required. In particular:
1. get applicable actions(S): the planner must reason with two actions per durative action, a
start action and an end action, rather than applying an action and immediately considering it
to have finished (as in the non-temporal case).
2. get applicable actions(S), apply(a, S): invariant conditions of durative actions must be
maintained throughout their execution, which requires active invariants to be recorded in the
state in order to prevent the application of actions that conflict with them.
3. is goal state(S): for a state to be a goal state (i.e. for the path to it to be a solution plan) all
actions must have completed.
14

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Algorithm 1: Enforced Hill-Climbing Algorithm
Data: P = hA, I, Gi - a planning problem
Result: P , a solution plan
1 best heuristic  evaluate heuristic(I);
2 if best heuristic = 0 then
3
return [];
4 closed  {I};
5 open list  [hI, []i];
6 while open list 6= [] do
7
hS, P i  element removed from the front of open list;
8
applic(S)  get applicable actions(S);
apply helpful filter (applic(S));
9
10
foreach a  applic(S) do
11
S 0  apply(a, S);
12
if S 0 6 closed then
13
add S 0 to closed ;
14
P 0  P followed by a;
if is valid plan(P 0 ) then
15
16
if is goal state(S 0 ) then
17
return P 0 ;
18
19
20
21
22
23
24
25

26

h  evaluate heuristic(S 0 );
if h < best heuristic then
open list  [hS 0 , P 0 i];
best heuristic  h;
break;
else
if h <  then
append hS 0 , P 0 i onto open list;

return with f ailure;

4. is valid plan(P ): the temporal (scheduling) constraints of candidate plans must be respected.
In particular, the duration constraints of durative actions must be satisfied. This is discussed
in Section 6.1.
We consider each of these modifications in turn. First, durative actions are compiled into
two non-temporal actions. A modified version of the LPGP action compilation (Long & Fox,
2003a) is used for this, as described by Coles et al. (2008). Each durative action a, of the form
hdur , pre ` , eff ` , pre  , pre a , eff a i, is split into two non-temporal (in fact, instantaneous) snap
actions of the form hpre, eff i:
 a` = hpre ` , eff ` i
 aa = hpre a , eff a i
15

fiC OLES , C OLES , F OX & L ONG

By performing search with these snap actions, and taking appropriate care to ensure that the
other constraints are satisfied, the restrictions on expressivity imposed by the use of action compression are avoided. It becomes possible to search for a plan in which the start and end points
of different actions are coordinated, solving problems with required concurrency. The price for
this is that the search space is much larger: each original action is replaced by two snap-actions,
so the length of solution plans is doubled. In some circumstances this blow-up can be avoided
by identifying actions that are compression safe (Coles, Coles, Fox, & Long, 2009a), i.e. those
for which the use of action compression does not compromise soundness or completeness. In the
approach described by Coles et al., these actions are still split into start and end snap-actions, but
the end points of compression-safe actions are inserted when either their effects are needed or their
invariants would otherwise be violated by another action chosen for application. As a consequence,
only one search decision point is needed per compression-safe action (choose to apply its start),
rather than two. Recent versions of both CRIKEY 3 and COLIN make use of this restricted action
compression technique in search.
Having split actions into start and end points, modifications to the basic search algorithm are
needed to handle the constraints that arise as a consequence. CRIKEY 3 makes use of an extended
state representation, adding two further elements to the state tuple. The resulting state is defined as
S = hF, P, E, T i, where:
 F represents the facts that hold in the current world state: a set of propositions that are
currently true, W , and a vector, v, recording the values of numeric variables.
 P is an ordered list of snap actions, representing the plan to reach S from the initial state.
 E is an ordered list of start events, recording actions that have started but not yet finished;
 T is a collection of temporal constraints over the actions in the plan to reach F .
The purpose of the start event list E is to record information about the currently executing
actions, to assist in the formation of sound plans. Each entry e  E is a tuple hop, i , dmin, dmax i
where:
 op is the identifier of an action, for which the start snap-action op` has been added to the plan;
 i is the index at which this snap-action was added in the plan to reach S;
 dmin, dmax are the minimum and maximum duration of op, determined in the state in which
op is started.
The minimum and maximum duration of an action can depend on the state in which it is applied
(e.g. the duration of a recharge action may depend on the level of charge at the time of execution),
so durations must be computed based on the state preceding step i. However, once a given action
has started, the bounds on the duration remain fixed. PDDL 2.1 also allows actions to have durations
constrained by conditions that hold at the end of the action, but such actions are not supported by
our planners.
This extended state definition leads to corresponding extensions to get applicable actions(S).
As before, a snap-action is deemed to be logically applicable in a state S if its preconditions pre
are satisfied in S. However, an additional condition must be satisfied: its effects must not violate
16

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

any active invariants. The invariants active in a given state are determined from E  we denote the
invariants in a state S with event list E as:
inv(S) =  e.op.pre 
eE

To apply the end snap-action, aa , there is required to be an entry e  E whose operator entry
op is equal to a. This prevents the planner from attempting to apply the ends of actions that have
not yet been started.
Assuming an action, a, is found to be applicable and chosen as step i of a plan, the function
apply(a, S), applied to a temporally-extended state, S, yields a successor S 0 = hF 0 , P 0 , E 0 , T 0 i.
The first two elements are updated as in the non-temporal case: F 0 = apply(a, F ), and P 0 = P +[a].
To obtain T 0 , we begin by setting T 0 = T . Furthermore, if i > 0:
T 0 = T 0  {  t(i)  t(i  1)}
where t(i) is the variable representing the time at which step i is scheduled to be executed. That
is, the new step must come at least  (a small unit of time) after the preceding step. This separation
respects the requirement that interfering actions must be separated by at least  (Fox & Long, 2003),
but it is strictly stronger than required where actions are not actually mutually exclusive. A more
accurate realisation of the PDDL 2.1 semantics could be implemented, but it would incur a cost while
offering very little apparent benefit. Finally, the resulting value of E 0 (and whether T 0 is changed
further) depends on whether a is a start or end snap-action:
 if a start action a` is applied, E 0 = E + [ha, i, dmin, dmax i], where dmin and dmax correspond to the lower- and upper-bounds of the duration of a, as evaluated in the context of
valuation F .
 if an end action aa is applied, a start entry {e  E | e.op = a} is chosen, and then E 0 is
assigned a value E 0 = E \ e. It will often be the case that there is only one instance of an
action open, so there is only one choice of pairing, but in the case where multiple instances
of the same action are executing concurrently, search branches over the choice of each such
e. For the e chosen, a final modification is then made to T 0 to encode the duration constraints
of the action that has just finished:
T 0 = T 0  {e.dmin  t(i)  t(e.i)  e.dmax }
With this information encoded in each state about currently executing actions, the extension
needed to is goal state(S) is minor: a state S is a goal state if it satisfies the non-temporal version
of is goal state(S), and if the event list of the state, E, is empty.
This search strategy leads to a natural way to handle PDDL 2.2 Timed Initial Literals (TILs)
directly. Dummy TIL actions are introduced, comprising the effects of the TILs at each time
point, and these can be added to the plan if all earlier TIL actions have already been added, and if
they do not delete the invariants of any open action. As a special case, TIL actions do not create
an entry in E: only the facts in F are amended by their execution. They do, however, produce an
updated set of temporal constraints. As with snap actions, if a TIL is added as step i to a plan, the
TIL must fall no earlier than  after the preceding step. Then, T 0 = T 0  {ts  t(i)  t()  ts},
17

fiC OLES , C OLES , F OX & L ONG

where ts is the time-stamp at which the TIL is prescribed to happen,  is the name denoting the
start of the plan and t() = 0. As can be seen, these constraints ensure that the TIL can only occur
at an appropriate time, that any step prior to the TIL must occur before it, and that any step after the
TIL must occur after it.
The changes described in this subsection ensure that the plans produced by CRIKEY 3 are logically sound: the check for logical applicability, coupled with the maintenance of E throughout
search, ensures that no preconditions, either propositional or numeric, can be broken. Use of
get applicable actions(S) only guarantees that actions are logically applicable: there is no guarantee that adding a snap-action to the plan, judged applicable in this way, will not violate the
temporal constraints. For example, it is possible that all preconditions are satisfied in the plan
P = [a` , b` , ba , aa ], so that P is logically sound. However, if the duration of b is greater than
the duration of a then P is not temporally sound. In the next section we discuss how the function
is valid plan(P ) is modified to identify and reject temporally inconsistent plans.
6.1 Temporal Plan Consistency
A state S is only temporally consistent if the steps [0...n  1] in the plan, P , that reaches it can be
assigned values [t(0)...t(n  1)], representing the times of execution of each of the corresponding
steps, respecting the temporal constraints, T . This is checked through the use of is valid plan(P 0 ),
called at line 15 of Algorithm 1  this function call is trivial in the non-temporal case, but in the
temporal case serves to check the temporal consistency of the plan. Any state for which the temporal
constraints cannot be satisfied is immediately pruned from search, since no extension of the action
sequence can lead to a solution plan that is valid.
The temporal constraints T built by CRIKEY 3 in a state S are each expressed in the form:
lb  t(b)  t(a)  ub

where lb, ub  < and 0  lb  ub

These constraints are conveniently expressible as a Simple Temporal Problem (STP) (Dechter,
Meiri, & Pearl, 1989). The variables within the STP consist of the timestamps of actions, and
between them inequality constraints can be specified in the above form. Crucially, for our purposes,
the validity of an STP (and the assignment of timestamps to the events therein) can be determined
in polynomial time by solving a shortest-path problem within a Simple Temporal Network (STN),
a directed-graph representation of an STP. Each event in the STP is represented by a vertex in the
STN. There is an additional node t() to represent time 0 and the time of the first action in the
plan, t(0), is constrained to fall within  of t(). Each constraint in the above form adds two edges
to the graph: one from a to b with weight ub, and one from b to a with weight lb. Attempting
to solve the shortest-path problem from t() to each event yields one of two outcomes: either it
terminates successfully, providing a time-stamp for each step, or it terminates unsuccessfully due
to the presence of a negative-cost cycle within the STN indicating a temporal inconsistency (any
schedule would require at least one step to be scheduled before itself).
In CRIKEY 3, an STP is used to check the temporal consistency of the choices made to reach
each step S, based on the temporal constraints T that must hold over the plan P to reach S, and
additional constraints that can be determined from E: the list of actions that have started, but not yet
finished. The variables vars in the STP can be partitioned into two sets: the t variables, t(i) for
step i  P and the f  variables, one f (i) for each entry hop, i, dmin, dmax i  E. The t variables
correspond to the times of steps that have already been added to the plan, which might be the times
18

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

of start or end points of actions. Some of these time points might correspond to the starts of actions
that have not yet finished and it is this subset of actions (only) that will have associated f variables
associated with the pending end times of those actions. For consistency with the terminology we
introduced in CRIKEY 3 (Coles, Fox, Long et al., 2008a), we use now to refer to the time at which the
next event in the plan will occur (which could be during the execution of the last actions applied).
It is the time point at which the next choice is to be made, either the start of a new action or the
completion of an existing one, and can therefore be seen as the time associated with the final state,
S, generated by the current plan head. There is only ever one timepoint called now and its value
moves forward as the plan head extends. The constraints are then as follows:
 T , constraining the t variables  these ensure the temporal consistency of the steps in the
plan to reach S (and include any constraints introduced for timed initial literals);
 {dmin  f (i)  t(i)  dmax | hop, i, dmin, dmax i  E}  that is, for each future
action end point that has been committed to (but has yet to be applied), the recorded duration
constraint must be respected;
 {  f (i)  t(n  1) | hop, i, dmin, dmax i  E}  that is, each future action end point
must come after the last step in the current plan, to ensure it is in the future.
 t(now )  t(n  1)    that is, the current time (the time at which the next event in the
plan can occur) is at least  after the last event in the plan.
Solving this STP confirms the temporal consistency of the decisions made so far. If the STP
cannot be solved, the state S can be pruned: the plan induced from the startend action representation is temporally invalid. The last two of these categories of constraints are particularly important:
without them, pruning could only be undertaken on the basis of the plan P to reach S. Including
them, however, allows the STP to identify cases where the end point of an action can never be added
to the plan, as doing so would lead to temporal inconsistency. As goal states cannot contain any
executing actions (i.e. E must be empty), this allows CRIKEY 3 to prune states earlier from which
there can definitely be no path to a state in which all end points have been added to the plan.
Timed initial literals are easily managed in the STP using the dummy TIL actions described
earlier. The constraints for each dummy TIL action that has already been applied are included in T .
Each dummy TIL action yet to occur is automatically treated as the end of an action that has yet to
be applied. Thus, an f variable is added for each, and in doing so, the last step in the plan so far is
constrained to come before each TIL event that has yet to happen.

7. Planning with Continuous Numeric Change
The most challenging variants of temporal and numeric problems combine the two to arrive at problems with time-dependent metric fluents. Although problems exhibiting hybrid discrete-continuous
dynamics have been studied in other research communities for some time, for example, in verification (Yi, Larsen, & Pettersson, 1997; Henzinger, Ho, & Wong-Toi, 1995; Henzinger, 1996),
where timed automata capture exactly this kind of behaviour, there has been relatively little work
on continuous dynamics in the planning community.
In PDDL 2.1 the model of mixed discrete-continuous change extends the propositional state transition model to include continuous change on the state variables. There is a state transition system
19

fiC OLES , C OLES , F OX & L ONG

in which discrete changes transition instantaneously between states. While the system is in a particular state, continuous change can occur on the state variables and time passes. As soon as a discrete
change occurs the system changes state. In PDDL + (Fox & Long, 2006) this is extended to allow
exogenous events and processes (controlled by nature) as well as durative actions. This leads to
a formal semantics that is based in the theory of Hybrid Automata (Henzinger, 1996). An action
causes a discrete state change which might trigger a continuous process. This continues over time
until an event is triggered leading into a new state. Some time later another action might be taken.
Early work exploring planning with continuous processes includes the Zeno system of Penberthy and Weld (1994), in which processes are described using differential equations. Zeno suffers
from the same limitations as other partial order planners of its time, being unable to solve large
planning problems without significant aid from a carefully crafted heuristic function. More importantly, a fundamental constraint on its behaviour is that it does not allow concurrent actions to apply
continuous effects to the same variable. This imposes a very significant restriction on the kinds
of problems that can be solved, making Zeno much less expressive than COLIN. This constraint
follows, in part, from the way that the model requires effects to be specified as differential equations, rather than as continuous update effects, so that simultaneous equations must be consistent
with one another rather than accumulating additive effects. As the authors say We must specify the
entire continuous behaviour over the interval [of the durative action] as our semantics insist that all
continuous behaviours are the result of direct, explicit action.
Another early planner to handle continuous processes is McDermotts O PTOP system (McDermott, 2003), which is a heuristic search planner, using a regression-based heuristic. The plausible
progression technique used within O PTOP to guide search is not sufficiently powerful to recognise
interactions that could prevent future application of actions, thereby restricting its scalability on
problems of the form we consider here. O PTOP competed in the International Planning Competition in 2004, where it solved only a small subset of the problems (although, interestingly, those it
solved involved an expressive combination of ADL and temporal windows that no other planner
could manage). O PTOP is an interesting variant on the heuristic forward search approach, since it
avoids grounding the representation, using an approach that is similar to a means-ends linear planning approach to generate relaxed plan estimates of the number of actions required to achieve the
goal from a given state.
7.1 TM-LPSAT
More recently, Shin and Davis developed TM - LPSAT (Shin & Davis, 2005), based on the earlier
LPSAT system (Wolfman & Weld, 1999). T M - LPSAT was the first planner to implement the PDDL +
semantics. It is implemented as a compilation scheme by which a horizon-bounded continuous
planning problem is compiled into a collection of SAT formulas that enforce the PDDL + semantics,
together with an associated set of linear metric constraints over numeric variables. This compiled
formulation is then passed to a SAT-based arithmetic constraint solver, LPSAT. L PSAT consists of
a DPLL solver and an LP solver. The SAT-solver passes triggered constraints to the LP-solver,
which hands back conflict sets in the form of nogoods if the constraints cannot be resolved. If there
is no solution the horizon is increased and the process repeats, otherwise the solution is decoded
into a plan. In order to support concurrency the compilation exploits the LPGP separation of action
start and end points. There are different versions of TM - LPSAT exploiting different solvers: LPSAT
and MathSAT-04 (Audemard, Bertoli, Cimatti, Kornilowicz, & Sebastiani, 2002) have both been
20

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

exploited. The novelty of TM - LPSAT lies in the compilation and decoding phases, since both solvers
are well-established systems.
The compilation scheme of TM - LPSAT implements the full PDDL + semantics. Although this
includes events and processes, which are specific to PDDL +, TM - LPSAT can also handle variable duration durative actions, durative actions with continuous effects and duration-dependent end-effects.
The continuous effects of concurrent actions on a quantity between two time-points are summed
over all actions active on the quantity over the period. Therefore, TM - LPSAT supports concurrent
updates to continuous variables.
T M - LPSAT is an interesting approach, in theory capable of solving a large class of problems
with varied continuous dynamics. However, reported empirical data suggests that the planner is
very slow and unable to solve problems requiring plans of more than a few steps. It is not possible
to experiment further because there is no publicly available implementation of the system.
7.2 Kongming
Hui Li and Brian Williams have explored planning for hybrid systems (Li & Williams, 2008, 2011).
This work has focussed on model-based control, using techniques based on constraint reasoning.
The continuous dynamics of a system are modelled as flow tubes that capture the envelopes of the
continuous behaviours (Leaute & Williams, 2005). The dimensions of these tubes are a function
of time (typically expanding as they are allowed to extend), with the requirement being made that
successive continuous behaviours must be connected by connecting the start of one tube (the precondition surface) to the cross-section of the preceding tube; i.e. the intersection of the two spaces must
be non-empty. The most relevant work in this area is in the development of the planner Kongming,
described by Li and Williams.
Kongming solves a class of control planning problems with continuous dynamics. It is based
on the construction of fact and action layers and flow tubes, within the iterative plan graph structure
introduced in Graphplan (Blum & Furst, 1995). As the graph is developed, every action produces
a flow tube which contains the valid trajectories as they develop over time. Starting in a feasible
region, actions whose preconditions intersect with the feasible region can be applied and the reachable states at any time point can be computed using the state equations of the system. In the initial
state of the system all the variables have single known values. A valid trajectory must pass through
a sequence of flow tubes, but must also meet the constraints specified in the dynamics of the actions
selected. The mutex relation used in Graphplan is extended to the continuous dynamics as well as
the propositional fragment of the language. The graph is iteratively extended as in Graphplan, with
a search for a plan conducted after each successive extension.
The plan-graph encoding of a problem with continuous dynamics is translated into a Mixed
Logical-Quadratic Program (MLQP). The metric objective functions used by the planner to optimise its behaviour can be defined in terms of quadratic functions of state variables. An example
problem considered by Li and Williams (2008) is a 2-d representation of a simple autonomous underwater vehicle (AUV) problem where the AUV can glide, ascend and descend while avoiding
obstacles. The language used is a version of PDDL 2.1 extended to enable dynamics to be encoded.
The continuous nature of the problem lies in the fact that, after a continuous action, the AUV will
be in one of a continuous range of positions determined by the control system. Because Kongming
depends on translation of the planning problems into MLQPs the constraints describing the dynamics of the problem must be linear. Since the effects of continuous actions involve the product of rate
21

fiC OLES , C OLES , F OX & L ONG

of change with time, only one of these values can be treated as a variable. In Kongming it is the
rate of change that is variable, but time is discretised, which contrasts with COLIN in which rates
of change remain constant over continuously variable length intervals. The discretisation of time in
Kongming is exploited to support state updates within the plan graph: successive layers of the graph
are separated by a constant and uniform time increment. This approach suffers from a disadvantage
that the duration of a plan is limited by the number of happenings in the plan, since the solver cannot
realistically solve problems with more than a few tens of layers in the plan graph.
Kongming does not support concurrent continuous updates to the same state variable, so, in
this respect, PDDL 2.1 is more expressive than the extended language used in Kongming. In part
this is due to a difficulty in resolving precisely what is the semantics of the dynamics described in
the actions used by Kongming. Each dynamic constraint specifies limits on the rate of change of a
specific variable: it is unclear whether concurrent actions should be combined by taking the union
or the intersection of the bounds each constraint specifies on the rate of change of a given fluent.

7.3 UPMurphi
One other recently developed planner that uses PDDL 2.1 and reasons with continuous processes is
UPMurphi (Penna, Intrigila, Magazzeni, & Mercorio, 2009). UPMurphi takes a completely different approach to those considered so far. Instead of reasoning about continuous change directly,
UPMurphi works by guessing a discretisation and iteratively refining it if the solution to the discretised problem does not validate against the original problem specification. The iterative driver is the
coarseness of the discretisation, as well as the planning horizon, making it an interestingly different
basic architecture from TM - LPSAT.
UPMurphi begins with the continuous representation of the problem and starts by discretising it.
First the actions are discretised by taking specific values from their feasible ranges. This results in
several versions of each action. Then UPMurphi explores the state space, by explicitly constructing
it under the current discretisation. Plans are constructed using the planning-as-model-checking
paradigm (Cimatti, Giunchiglia, Giunchiglia, & Traverso, 1997): there is no heuristic to guide
search. Once a plan has been found it is then validated against the original continuous model, using
the plan validator (Fox, Howey, & Long, 2005). If it is invalid, the discretisation is refined and the
search resumes. If UPMurphi fails to find a plan at one discretisation it starts again at a finer grained
discretisation. Subsequent refinements lead to ever denser feasible regions, but they are increasingly
complex to construct.
UPMurphi can be used to build partial policies to handle the uncertainty that is likely to arise
in practice during the execution of hybrid control plans. A controller table is initially synthesised,
consisting of the (state,action) pairs of the plan it first constructs. However, this table might lack
some of the states that could be visited by the controller, so it is not robust. The subsequent step is
to robustify the controller by randomly perturbing some of the states and finding new paths from
these new states. Because some of the perturbed states are not reachable, a probability distribution
is used to identify the most likely ones. These are called the safe states. The controller table is
then extended with the safe (state, action) pairs. The controller table, or policy, is referred to as a
Universal Plan.
22

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

7.4 Other Approaches to Continuous Reasoning
A completely different way to manage continuous quantities is to model continuous resource consumption and production in terms of uncertainty about the amount consumed or produced. This
is the approach taken in the HAO* algorithm (Meuleau, Benazera, Brafman, Hansen, & Mausam,
2009) where a Markov Decision Process (MDP) is constructed consisting of hybrid states. Each
state contains a set of propositional variables and also a collection of distributions over resource
consumption and production values. Because the states are hybrid, standard value iteration approaches cannot be used to find policies. A hybrid AO* approach is described which can be used to
find the best feasible policy. The feasible region constructed by HAO* is a continuous distribution
of resource values and the resource is considered to be uncontrollable (unlike in Kongming, where
it is assumed that the executive maintains control over which values in the region are eventually
chosen).
Planning with continuous processes has important applications and, as with many other application areas of planning, this has led to the development of systems that combine generic planning
technology with more carefully tuned domain-specific performance to achieve the necessary combination of problem coverage and performance. A good example of this is the work by Boddy and
Johnson (2002) and colleagues (Lamba et al., 2003) on planning oil refinery operations. This work
uses a quadratic program solver, coupled with heuristically guided assignment to discrete decision
variables (corresponding to actions), to solve real problems.

8. COLIN: Forward Chaining Planning With Continuous Linear Change
In this section we will describe how CRIKEY 3 is extended to reason with duration-dependent and
continuous numeric change, building the planner COLIN ( for COntinuous LINear dynamics). We
decided to give the planner a specific name to highlight its capabilities. As demonstrated in Section 4.1, the key difference introduced with continuous numeric change is that logical and numeric
constraints can no longer be neatly separated from temporal constraints: the values of the numeric
variables in a state depend on the timestamps and durations of actions, and vice versa. The relative
benefits of handling temporal and numeric constraints together, rather than separating them out, are
apparent in the motivating domains outlined in Section 3 and have been amply rehearsed in the
paper describing PDDL + (Fox & Long, 2006).
The need to cope with integrated numeric and temporal constraints raises a number of important
issues for planning with these domains. First, checking whether an action choice is consistent can
no longer be achieved using an STP, as the numeric constraints now interact with the temporal
constraints, and an STP is not sufficiently expressive to capture this. Second, the changing values
of numeric variables over time brings new challenges for determining action applicability: if a
precondition is not satisfied immediately following the application of an action, it might become
satisfied after allowing a certain amount of time to elapse. Finally, there is the need to provide
heuristic guidance. We will cover the first two of these issues in this section, and defer discussion
of the heuristic guidance to the next.
8.1 Temporal-Numeric Plan Consistency Through Linear Programming
We begin with the problem of temporal-numeric plan consistency, as the techniques used in dealing
with this issue can also be amended for use in solving the issues encountered when determining
23

fiC OLES , C OLES , F OX & L ONG

action applicability. Considering the definition of the STP given in Section 6.1, we make the observation that the STP could equally well be written as a linear program (LP). In CRIKEY 3, the
STP is more efficiently solved using a shortest-path algorithm. However, this observation becomes
important when we wish to reason with continuous change in numeric resources alongside the temporal constraints. In this case, we can use an LP to capture both temporal constraints and numeric
constraints, including the interaction between the two. We will now describe how the LP is built,
serving as a replacement for the is valid plan(S) function called during search, which invokes the
STP solver in CRIKEY 3. A diagram of the structure of the LP we create is shown in Figure 6, for
a plan P = [a0 , ..., an2 , an1 ] to reach a state S, where an1 is the action most recently added to
the plan. (For simplicity, it shows a case where the event queue E is empty.)
The construction of the LP begins with the variables and (a subset of) the constraints of the
STP. Each STP variable ti (the time-stamp of the (snap) action ai ) has a corresponding LP variable
stepi (shown across the top of Figure 6), and each STP variable ei (for the future end of the action
at step i) has a corresponding LP variable estep i . We also construct the constraints corresponding
to the total-ordering of action steps, just as in the STP: each step in P is still sequenced (i.e.  
stepi  stepi1 for all n > i > 0), and each future end snap-action has to be later than stepn1
(i.e.   estepi  stepn1 for all estep variables).
We then extend the LP with the numeric constraints of the problem, beginning with the effects
of actions. Since numeric effects can be both discrete and continuous, we create two additional
vectors of variables per step in the plan. The first of these, vi , represents the values of the state
variables v immediately prior to ai being executed (in the case of step 0, vi is equal to the values of
v in the initial state, I). The second, vi0 , contains the values of v immediately after ai is executed.
In Figure 6, the variables in v0 are enumerated as v0 ...vm1 and, similarly, those in v0 0 are shown
0
as v00 ...vm1
. To avoid proliferation of indices we do not further index these values with their
time stamp in Figure 6, so vi is the ith value in v at the time step corresponding to the layer in
which the variable appears. The use of two vectors at each layer is required in order to represent
discrete changes caused by actions: a snap-action can cause the value of a variable to be different
immediately after its execution. To represent this within the LP, if an action at step i has no effect
on a variable v then vi0 = vi 2 . Otherwise, for a discrete effect hv 0 +=w  v + k.(?duration) + ci, a
constraint is introduced to define the value of vi0 :3
vi0 = vi + w  v + k.(ce(i)  cs(i)) + c
where the functions cs(i) and ce(i) denote the time-stamp variables for the corresponding start and
end of the action at step i. If step i is the end of an action, then ce(i) = step i , and cs(i) is the
step variable for the start of the action that finished at step i. Similarly, if step i initiates an action,
then cs(i) = step i , and ce(i) is either estep i if the action has not yet finished or, otherwise, the
step variable for the end of the action started at step i. Therefore, substituting ce(i)  cs(i) for
?duration captures the relationship between the effect of the action and its duration.
2. Note that identities such as this are implemented efficiently by simply not introducing the unnecessary additional
variable. Similarly, while a variable is subject to no effects or conditions it is not added to the LP, but it is only
introduced once it becomes relevant.
3. For effects using the operator -=, i.e. decrease effects, all but the first term on the right-hand side are negated. For
assignment effects, where the operator is =, the first term on the right-hand side (i.e. vi ) is omitted entirely (the value
of v after such an assignment does not depend on the value of v beforehand).

24

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Metric fluents v 0 to v m1
Snapactions 0 to n1 and corresponding timepoint variables

v0

v0

v0

v0

v0

v0

v0

v0

v1

v1

v1

v1

v1

v1

v1

v1

v

v

v

v

v

v

a0

v3

v3

v3
step 2

v3

v m1

v m1

State 2

State 1

v
a n1

step n1

2

v3
...

v m1

2

...

v m1

2

a2

...

v m1

2

...


v m1

step 1

2

...

...

step 0

a1

v3

...

...
State 0

2

v3

v3

v m1

2

v m1
State n

...

2

...

v

Active continuous change affecting (some) variables
Actions cause instantaneous step changes in fluent values
Temporal Constraints
Actions are sequenced and separated:
step i+1 stepi >= 
Where action i starts a durative action, a, that is ended by action j:
dmin(a) <= step j  step i <= dmax(a)
Metric Variable Constraints: Step Effects

Metric Variable Constraints: Continuous Effects

Variables are updated by action effects:

Variables are updated by active continuous effects:
v j = vj +  vj (stepi+1  stepi )

v j in state i+1 is v j in state i updated by effect of a i
including timedependent stepeffects

for values in state i+1, where  v j is determined by the
accumulated effects of active continuous effects

Figure 6: Diagrammatic Representation of the LP Used in COLIN. Note that the subscripts attached
to the v and v 0 fluents in this diagram are indices into the vector of fluents in the state,
while indices on step and a represent different time steps in the plan. The metric fluents
are also notionally indexed by the time step, but this is not shown in the diagram in order
to avoid clutter.

Continuous numeric change occurs between the steps in the plan, rather than at the instant
of execution of the step itself. To capture continuous effects, when building the LP we consider
each step in turn, from the start of the plan, recording the gradient of the total (linear) continuous
change acting upon each variable v  v, where v denotes the gradient active after ai1 and before
the execution of action ai . Under the restrictions on the language handled by COLIN, described
in Section 4, and the total-order constraints between snap-actions, the value of each variable vi
is known and constant within each interval between successive actions: all continuous change is
linear. The gradient on a variable v can only be changed by either starting an action (initiating an
25

fiC OLES , C OLES , F OX & L ONG

adjustment to the prevailing continuous effect on v given by dv
dt += k, for some k  <) or ending an
action (terminating the effect initiated by its start). The values of the  constants can be computed
as follows4 :
 For all variables, v0 = 0; that is, there is no continuous numeric change active on any
variable before the start of the plan.
 If ai has no continuous numeric effect on v then vi+1 = vi ;
 If ai initiates a continuous numeric effect,

dv
dt

 If ai terminates a continuous numeric effect,

+= k, then vi+1 = vi + k;
dv
dt

+= k, then vi+1 = vi  k;

On the basis of these values, we now add constraints to the LP:
vi+1 = vi0 + vi+1 (step i+1  step i )
Again, the distinction between vi and vi0 is important: vi is determined on the basis of any continuous
change in the interval between steps i and i  1, but immediately prior to any discrete effect that
may occur at that step.
Having created variables to represent the values of fluents at each step and having introduced
constraints to capture the effects of actions on them, we now consider the constraints that arise from
the preconditions of each snap-action, the invariants that must be respected between the starts and
ends of actions, and any constraints on the durations of each of the actions in the plan. For each
numeric precondition of the form hv, {, =, }, w  v + ci, that must hold in order to apply step i,
we add a constraint to the LP:
vi {, =, }w  vi + c
For an action a starting at stepi and ending at stepj , the invariants of a are added to the LP in
0
this form, once for each of the vectors of variables [vi0 , vj1
] and [vi+1 , vj ] (vi and v0 j are excluded
because the PDDL 2.1 semantics does not require invariants of an action to hold at its end points). In
the case where the end of the action a (starting at i) has not yet appeared in the plan, the invariants of
a are imposed on all vectors of variables from vi0 onwards: as a must end in the future, its invariants
must not be violated at any step in the current plan after the point where it started.
Finally, we add the duration constraints. For an action a starting at stepi , we denote the variable
corresponding to the time at which a finishes as ce(i), where ce(i) = step j if the end of the action
has been inserted into the plan at step j, or ce(i) = estep i otherwise (as defined above). Then, for
each duration constraint of a, of the form h?duration, {, =, }, w  v + ci, we add a constraint:
ce(i)  step i {, =, }w  vi + c
This process constructs a LP that captures all the numeric and temporal constraints that govern
a plan, and the interactions between them. As with the STP in CRIKEY 3, a solution to the LP
contains values for the variables [step 0 ...step n ], i.e. an assignment of time-stamps to the actions in
the plan. To prevent the LP assigning these variables arbitrarily large (but valid) values, we set the
4. Variables that can be trivially shown to be constant (i.e. where no action has an effect referring to that variable) can
be removed from the LP and replaced throughout by their values in the initial state.

26

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Plan Action

Delta value LP Variable
m0 = 0

saveHard start

LP Constraints

step0

=0

m0

=0

m00
m1 = 1
takeMortgage start
m2 =

1
4

= m0

0

step1

 step0 + 

 step0 + 10

m1

= m00 + 1.(step1  step0 )

0

m01

= m1  1

0

step2
m2

lifeAudit start
m3 =

1
4

saveHard end

= step1 + 
=

m01

+

1
4 .(step2

 step0 + 10  step1 + 12

 step1 )

m02

= m2

step3

 step2 + 

m3

= m02 + 41 .(step3  step2 )

m5 = 0

6

6

 step3 + 
=

m03



3
4 .(step3

= step1 + 12  step2 + 4

 step2 )

m04
lifeAudit end

6

0

= m3

step4
m4

takeMortgage end

0

= step0 + 10  step1 + 12
 step2 + 4

m03
m4 =  34

6

= m4

step5

 step4 + 

= step2 + 4

m5

= m04  0.(step3  step2 )

0

m05

= m5

Table 2: Variables and constraints for the Borrower problem
LP objective function to be to minimise step n , where an is the last step in the plan so far. For the
purposes of the is valid plan(S) function, if the LP built for a plan P to reach a state S cannot be
solved, we can prune the state S from the search space and need not consider it any further: there is
no path from S to a legal goal state. In this way, the LP scheduler can be used as a replacement for
the STP in order to determine plan validity.
8.2 Example: LP for the Borrower Problem
In order to illustrate LP construction for a plan we consider the example Borrower problem introduced in Section 4.1. Recall that one solution plan for this problem has the following structure:
0:
1:
2:
3:
4:
5:

saveHard start
takeMortgage start longMortgage
lifeAudit start
saveHard end
takeMortgage end longMortgage
lifeAudit end.

The LP for this six-step Borrower solution plan contains the variables and constraints shown in
Table 2. The six step variables represent the time-stamps of the six snap-actions in the plan, and the
variable m represents the money that has been saved by the Borrower. In the initial state, m = 0,
27

fiC OLES , C OLES , F OX & L ONG

and hence m0 = 0. Starting the saveHard action has no instantaneous numeric effects, introducing
the constraint m00 = m0 (if it did have an effect on m, for instance an instantaneous increase in the
savings by k, then the constraint would be m00 = m0 + k). Due to the invariant condition of the
saveHard action, that the savings remain above zero, the constraint m00  0 is added: it can be seen
this constraint is duplicated for each mi and m0i during the execution of the saveHard action, to
ensure that the invariant continues to hold. Notice, also, when the action takeMortgage is started,
the invariant for that action (the savings level remains less than or equal to the maxSavings cap)
also appears, and applies to all values of m during its execution. Additional constraints capture
discrete change by connecting the value of m0i to mi . In most cases in this example these values
are equal, but one constraint shows a discrete effect: m01 = m1  1 captures the deduction of the
deposit caused by initiating the takeMortgage action.
As previously described, the temporal constraints in the LP take two forms. First, there are
constraints of the form step i+1  step i + , forcing step i+1 to follow step i , enforcing the sequencing of the snap-actions. Second, duration constraints restrict the duration of actions, e.g.
step3 = step0 + 10 forces that step3 (the end point of saveHard) occurs precisely 10 units (the
duration of saveHard) after step0 , its start snap-action.
The final constraints to consider are those modelling the continuous numeric change. The first
constraint of this type gives the value of m1 after the execution of saveHard start and before
the execution of takeMortgage start. This constraint, m1 = m00 + 1.(step1  step0 ), is based
on the value of m1 , which is 1: the only action currently executing with continuous change on
m is saveHard, which increases it by 1 per unit of time. The second such constraint, m2 =
m01 + 41 .(step2  step1 ), is based on the value of m2 which is now (1  34 ) = 14 , found by adding
the active gradients from both of the actions that have started but not yet finished. This illustrates
how two actions can have active linear continuous effects on the same variable simultaneously. Note
that when saveHard end is applied (at step3 ) the gradient of continuous change (m4 ) becomes
 43 as the only active continuous effect is now that of the takeMortgage action.
Solving the temporal constraints in this problem without considering the metric fluents yields
a solution in which step0 = 0, step1 = , step2 = 8 + 2, step3 = 10, step4 = 12 +  and
step5 = 12 + 2. Unfortunately, this proposal violates the constraint m01  0, since:
m01 = m1  1 = m00 + 1.(step1  step0 )  1 = m0 +   1 = 0 +   1 =   1
and   1. The constraint on the start time of the takeMortgage action cannot be identified
because it is dependent on the discrete initial effect of that action, the active continuous effect of
the saveHard action and the invariant of saveHard. This simple example illustrates the strength
of using the LP to perform the scheduling alongside the resolution of numeric constraints: the
timestamps then satisfy both temporal and numeric constraints.
8.3 TemporalNumeric Search
When performing state-space search, a state, S, is a snapshot of the world along some plan trajectory, coming after one action step and before another. In the absence of continuous numeric change,
the valuations that define S are known precisely: both which propositions hold, and the values of
the numeric variables v. In the presence of continuous numeric change, however, the same does
not hold: if a variable v is undergoing continuous numeric change (or is subject to active durationdependent change) the valuations in a state depend on which snap-actions have been applied so far,
28

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

on the times at which those snap-actions were applied and on how much time has passed since the
last action was applied. Within our representation of the state the time-stamps of the snap-actions in
the plan are not fixed (during plan-construction, the LP is used only to confirm that the plan can be
scheduled subject to the current constraints), so the valuation of numeric fluents in S is constrained
only within ranges determined by the constraints on the temporal variables and the interactions
between them.
As a consequence of the flexibility in the commitment to values for temporal and continuously
changing variables, COLIN requires a different state representation to the one used in CRIKEY 3.
Rather than representing the values of the numeric variables by a single vector v, we use two
vectors: vmax and vmin . These hold the maximum and minimum values, respectively, for each
numeric variable in S. The computation of these bounds on variables can be achieved using a small
extension of the LP described in Section 8.1. For a state S, reached by plan P (where an is the
last step in P ), we add another vector of variables to the LP, denoted vnow , and another time-stamp
variable, step now . The variables in vnow represent the values of each state variable at some point
(at time step now ) along the state trajectory following an . The numeric variables and time-stamp for
now are constrained as if it were an additional action appended to the plan:
 now must follow the previous step, i.e. stepnow  stepn  
 now must precede or coincide with the ends of any actions that have started but not yet
finished, i.e. for each estep(i), estep(i)  step now
 For each variable vnow  vnow , we compute its value based on any continuous numeric
change:
vnow = vn0 + vnow (stepnow  stepn )
 Finally, for every invariant condition hv, {, =, }, w  v + ci of each action that has started
but not yet finished:
vnow {, =, }w  vnow + c
The LP can then be used to find the upper and lower bounds on variables. For each of the variables vnow  vnow , two calls are made to the LP solver: one with objective set to to maximise vnow ,
and one to minimise vnow . These are then taken as the values of vmax and vmin in S. In the simplest case, where a variable v is not subject to (direct or indirect) continuous or duration-dependent
change, the value of v is time-independent, so vmax = vmin , and its value can be determined
through the successive application of the effects of the actions in P , i.e. the mechanism used in
CRIKEY 3, or indeed classical (non-temporal) planning.
Since we have upper and lower bounds on the value of each variable, rather than a fixed assignment, the action applicability function, get applicable actions(S), must be modified. In CRIKEY 3,
an action is said to be applicable in a state S if its preconditions are satisfied. In COLIN, the definition
of what it means for a numeric precondition to be satisfied is different. To preserve completeness,
we employ the mechanism used in metric relaxed planning graphs, as discussed in more detail in
Section B. Specifically, for a numeric precondition w  x  c, we calculate an optimistic value for
w x by using the upper bound on a v  x if its corresponding weight in w is positive, or, otherwise,
using its lower bound. Then, if this resulting value is greater than or equal to c, the precondition is
considered to be satisfied. (As before, for numeric conditions w  x  c, an equivalent precondition in the appropriate form can be obtained by multiplying both sides of the inequality by 1 and
29

fiC OLES , C OLES , F OX & L ONG

Plan Action

Delta value LP Variable
m0 = 0

saveHard start

LP Constraints

step0

=0

m0

=0

m00
m1 = 1
takeMortgage start
mnow =

1
4

= m0

0

step1

 step0 + 

 step0 + 10

m1

= m00 + 1.(step1  step0 )

0

m01

= m1  1

0

 step1 + 

stepnow

Now

mnow

=

m0now

m01

+

1
4 .(stepnow

= mnow

 step1 )

6

 step0 + 10  step1 + 12
0

6

0

6

Table 3: Variables and constraints for the first stages of the Borrower Problem
constraints of the form w  x = c are replaced with the equivalent pair of conditions w  x  c,
w  x  c.)
This test for applicability of an action is relaxed, so it serves only as a filter, eliminating actions
that are certainly inapplicable. For instance, a precondition a + b  3 could be satisfied if the upper
bounds on a and b are both 2, even if the assignment of timestamps to actions within the LP to attain
a = 2 conflicts with that needed to attain b  1. We rely on the subsequent LP consistency check
to determine whether actions are truly applicable. Nonetheless, filtering applicable actions on the
basis of the variable bounds in a state is a useful tool for reducing the number of candidates that
must be individually verified by the LP.
8.3.1 E XAMPLE OF U SE OF now IN THE B ORROWER P ROBLEM
We briefly illustrate the way in which the now variable is constructed and used in the context of the
Borrower problem. Consider the situation after the selection of the first two actions (saveHard start
and takeMortgage start). The LP construction yields the constraints shown in Table 3. Solving
this LP for minimum and maximum values of stepnow gives values of 1 +  and 10 respectively,
meaning that the earliest time at which the third action can be applied will be 1 +  and the latest
will be 10.5 Similarly, solving the LP for minimum and maximum values of mnow gives bounds of

4 and 6. This information could, in principle, constrain what actions can be applied in the current
state.
8.4 Some Comments on LP Efficiency
An LP is solved at every node in the search space, so it is important that this process is made as
efficient as possible. When adding the variable vectors to the LP for each step i, it is only necessary
to consider a state variable, v, if it has become unstable prior to step i, because of one of the
following effects acting on it:
1. direct continuous numeric change, i.e. changing v according to some gradient;
5. In practice, for efficiency, COLIN does not actually solve the LP for minimum and maximum values of stepnow , but
uses the variable only to communicate constraints to the metric variables in this state.

30

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

2. direct duration-dependent change, i.e. a change on v dependent on the duration of an action
(whose duration is non-fixed);
3. discrete change, where the magnitude of the change was based on one or more variables
falling into either of the previous two categories.
All variables that do not meet one of these conditions can be omitted from the LP, as their values
can be calculated based on the successive effects of the actions applied up to step i, and substituted
as a constant within any LP constraints referring to them. This reduces the number of state variables
and constraints that must be added to the LP and also reduces the number of times the LP must
be solved at each state to find variable bounds: irrelevant variables can be eliminated from the
vector vnow . A similar simplification is that, if applying a plan a0 ...an1 reaches a state S where
vmin = vmax , then if there is no continuous numeric change acting on v, v has become stable, i.e.
its value is independent of the times assigned to the preceding plan steps. In this case, until the first
step k at which v becomes unstable, the value of v can be determined through simple application of
discrete effects, and hence v can be omitted from all vj , vj0 , n  1 < j.
A further opportunity we exploit is that the LP solved in each state is similar to that being solved
in its parent state: it represents the same plan, but with an extra snap-action appended to the end. The
lower bounds of the time-stamp variables in the LP can therefore be based on the values computed
in the parent states. Suppose a state S is expanded to reach a state S 0 by applying a snap action, a,
as step i of the plan. At this point, the LP corresponding to the plan will be built and solved with
the objective being to minimise step i . Assuming the plan can indeed be scheduled (if it cannot,
then S 0 is pruned and no successors will be generated from it), the value of the objective function
is stored in S 0 as a lower bound on the time-stamp of a. In all states subsequently reached from S 0 ,
this stored value can be used in the LP as a lower bound on step i  appending actions to the plan
can further constrain and hence increase the value of step i , but it can never remove constraints in
order to allow it to decrease.
As well as storing lower bounds for time-stamp variables, we can make use of the bounds
vmin ,vmax in the state S 0 when generating successors from it. In a state S reached via plan of
length i, applying an action a leads to a state S 0 in which the new action at step i+1 inherits the
constraints imposed previously on step now when calculating the variable bounds in S 0 . Therefore,
the values of vmax and vmin in S serve as upper and lower bounds (respectively) for vi+1 in the LP
built to determine the feasibility of S 0 . Similarly, we can combine any discrete numeric effects of a
with the values of vmax and vmin in S to give bounds on v0 i+1 . For each variable v subject to an
effect, an optimistically large (small) outcome for that effect can be computed on the basis of vmax
0 . Otherwise, for variables upon which a has
and vmin , and taken as the upper (lower) bound of vi+1
0
no discrete effect, vi+1 = vi .
Finally, the presence of timed initial literals (TILs) allows us to impose stricter bounds on the
time-stamp variables. If step j of a plan is the dummy action corresponding to a TIL at time t, the
upper bound on step i , i < j, is t   and the lower bound on each step k , j < k (or any estep
variable) is t + . Similarly, if the plan does not yet contain a step corresponding to a TIL at time
t, the upper bound on all step variables is t  . Furthermore, a TIL at time t corresponds to a
deadline if it deletes some fact p that is present in the initial state, never added by any action, and
never reinstated by any other TIL. In this case:
 if a plan step i requires p as a precondition, then step i  t  ;
31

fiC OLES , C OLES , F OX & L ONG

 if estep i is the end of an action with an end condition p, then estep i  t  ;
 if estep i is the end of an action with an invariant condition p, then estep i  t.

9. Heuristic Computation
The search algorithms described so far in this paper all make use of a heuristic to guide the planner
efficiently through the search space towards the goal. Having introduced the necessary machinery
to support linear continuous numeric and duration-dependent effects we now turn our attention to
the construction of an informed heuristic in the face of time-dependent change.
In Appendices B and C we revisit the standard Metric-FF Relaxed-Planning Graph (RPG)
heuristic and the Temporal RPG (TRPG) used in CRIKEY 3, and provide the details of these approaches for reference. Both of these depend on the initial construction of a reachability graph,
based on the plan graph introduced in Graphplan (Blum & Furst, 1995). The graph consists of alternating layers of facts (f l) and actions (al). In the TRPG, for convenience, we index these layers by
the earliest time they could represent, although they can still be enumerated by consecutive integers
because only finitely many times can be relevant in the process of construction. In this section we
explain how the heuristic computation techniques introduced by these planners can then be modified
to reason with interacting temporalnumeric behaviour. We describe two variants of the heuristic:
a basic version, in which active continuous change is relaxed to discrete step changes, and a refined
variant in which this relaxation is replaced with a more careful approximation of the continuous
values. We show, using the Borrower example, the benefits of the refined approach.
The heuristics are based on the underlying use of a relaxed plan step-count. We use the relaxed
plan makespan as a tie-breaker in ordering plans with the same step-count. Step-count dominates our
heuristic because our first priority is to find a feasible solution to a planning problem and this means
attempting to minimise the number of choices that must be made and resolved during the search.
Of course, the emphasis on rapidly finding a feasible plan can compromise the quality of the plan,
particularly in problems where the step-count is poorly correlated with the makespan. Subsequent
attempts to improve the quality of an initial feasible solution, either by iteratively improving the
solution itself or by further search using the bound derived from the feasible solution to prune the
search space, are possible, but we do not consider them in this work.
9.1 The Basic Integrated Heuristic Computation with Continuous Numeric Effects
The first version of COLIN (Coles, Coles, Fox, & Long, 2009b) introduced three significant modifications to the TRPG used in CRIKEY 3, in order to generate heuristic values in the presence of
continuous and duration-dependent effects. The first modification simply equips the heuristic with
the means to approximate the effects of continuous change.
 If an action a has a continuous effect equivalent to dv
dt += k it is relaxed to an instantaneous
start effect hv, +=, k  dmax (a)i. That is, the effect on the changing variable is treated as
the integral of the effect up to an upper bound on the duration of the action and is applied at
the start of the action. Doing this ensures that the behaviour is relaxed, in contrast to, say,
applying the effect at the end of the action. dmax (a) is calculated at the point where the
action is added to the TRPG, based on the maximum duration constraints of a that refer only
to variables that cannot change after that time (that is, they are state-independent). If no such
32

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

constraints exist, the duration is allowed to be infinite (and variables affected by continuous
effects of the action will then have similarly uninformed bounds).
 If an action a has a discrete duration-dependent effect on a variable v then, when calculating
the maximum (minimum) effect of a upon v (as discussed, in the non-temporal case, in Appendix B), the ?duration variable is relaxed to whichever of dmin(a) or dmax (a) gives
the largest (smallest) effect. Relaxation of this effect is achieved without changing its timing,
so it is associated with the start or end of the action as indicated in the action specification.
The second modification affects any action that has a continuous numeric effect on some variable and either an end precondition or invariant that refers to the same numeric variable. If the
invariant or end precondition places a constraint on the way in which the process governed by the
action can affect the value of a variable, then this constraint is reflected in the corresponding upper
or lower bounds of the value of the variable. Specifically, if an action a decreases v at rate k and has
an invariant or end precondition v  c, then the upper bound on v by the end of the action must be at
least k.(dmin(a)  elapsed (a)) + c, where elapsed (a) is the maximum amount of time for which a
could have been executing in the state being evaluated (0 if a is not currently executing, otherwise,
the maximum from all such entries in E). This condition ensures that the variable could achieve the
necessary value to support the application of the action. It might appear strange that the bound is
set to be higher than c, but the reason is that the relaxation accumulates increase effects and ignores
decrease effects in assessing the upper bound, so it will be necessary, by the end of the action, to
have accumulated increases in the value of the variable that allow for the outstanding consumption
from a in order to still meet the c bound at the end of the action. A corresponding condition is
required for an action that a increases v at rate k, and has an invariant or end precondition v  c,
where the lower bound on v cannot be more than k.(dmin(a)  elapsed (a)) + c. These conditions
are added as explicit additional preconditions to aa for the purposes of constructing the TRPG.
The third modification deals with the problem of constructing an appropriate initialisation of
the bounds for the numeric variables in the first layer of the TRPG. In CRIKEY 3 these values are
initialised to the actual values of the metric variables, since their values in the current state do not
change if time passes without further actions being applied. The same is not true in COLIN, since
any actions that have started, but not yet finished, and which govern a process, will cause variables
to change simply as a consequence of time passing. As the basic heuristic proposed here relies
on being able to integrate continuous numeric change, we determine the variable bounds in fl (0.0)
in two stages. First, the bounds on a variable v are set according to those obtained from the LP
in Section 8.3. Then, for each entry e  E, corresponding to the start of an action, a, with a
continuous effect on v having positive gradient k, the upper bound on v in f l(0.0) is increased by
k.remaining(e). Here, remaining(e) is the maximum amount of time that could elapse between
the state being evaluated and the future end snap-action paired with start event e. The maximum
remaining execution time is calculated by subtracting the lower bound for the amount of time that
has to have elapsed since the start of action a from its maximum duration. In the case where the
gradient is negative, the lower bound is decreased.
9.2 The Refined Integrated Heuristic
Time-dependent change arises from two sources: continuous numeric effects, initiated by start snapactions, and discrete duration-dependent effects which can apply at either end of durative actions.
33

fiC OLES , C OLES , F OX & L ONG

For the purposes of the refined heuristic described in this section, we treat continuous effects and
discrete duration-dependent effects at the ends of actions of these in the same way, attaching a
continuous linear effect acting on each relevant variable to the effects of the appropriate snap-action,
a, denoting the set of all such continuous effects by g(a). For continuous effects, cont(a), initiated
by a` , cont(a)  g(a` ). That is, the gradient effects of the start of a include all of the continuous
effects of a. For duration-dependent effects of an end snap-action aa we split the effect into two
parts:
 a discrete effect of aa , hv, {+=, -=, =}, w  v + k.dmin(a) + ci and
 a gradient effect on v, added to g(aa ). The effect is defined as hv, ki if the original effect used
the operator += or = otherwise, it is hv, ki.
Thus, instantaneously, at the end of aa , the effect of a is available assuming the smallest possible
duration for a is used. As a executes with a greater duration, a continuous effect is applied with
the gradient of the change being taken from the coefficient k of the ?duration variable in the
corresponding effect in a.
Unfortunately, the treatment proposed above cannot be applied to duration-dependent start effects, since the effects are always available at the start of the action, regardless of the duration. Thus,
we employ the approach taken with the basic heuristic used in COLIN: when calculating the maximum (minimum) effect of a` on the affected variable, v, the ?duration variable is substituted
with whichever of dmin(a) or dmax (a) gives the largest (smallest) effect.
Once we have a collection of linear continuous effects, g(a), associated with each snap-action,
a, we can adjust the construction of the TRPG. First, we identify, for each variable, v, an associated
maximum rate of change, vmax (t), following the layer al(t). We set this to be the sum of all the
positive rates of change, affecting v, of any snap-actions in al(t):
v max (t) =

X

X

aal(t)

hv,kig(a)

k

This definition relies on the restriction that only one instance of any action can execute at any
time. If this restriction does not hold, but there is a clear finite bound p(a) on the number of instances
of an action that can execute concurrently, then we incorporate this into the calculation of v max (t)
as follows:
X
X
v max (t) =
p(a) 
k
aal(t)

hv,kig(a)

Where no such finite bound exists, an action could, in principle, be applied arbitrarily many times in
parallel and hence we set v max (t) = .6 Following any layer al(t) at which v max (t) =  we no
longer need to reason about the upper bound of the continuous change on v since the upper bound
on v itself will become  immediately after this layer. It should be noted that this degradation
of behaviour will, in the worst case, lead to the same heuristic behaviour as the basic heuristic
where, again, if arbitrarily many copies of the same action can execute concurrently, the magnitude
of its increase or decrease effects becomes unbounded. The extension of the heuristic to consider
6. We note that, in our experience, the presence of infinitely self-overlapping actions with continuous numeric change
is often a bug in the domain encoding: it is difficult to envisage a real situation in which parallel production is
unbounded.

34

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

continuous effects in a more refined way does not worsen its guidance in this situation. For the
remainder of this section, we consider only variables whose values are modified by actions for
which there are finite bounds on the number of concurrently executing copies allowed.
Armed with an upper bound value for the rate of change of each variable following layer al(t),
we can deduce the maximum value of each variable at any time t0 > t, by simply applying the
appropriate change to the maximum value of the variable at time t. The remaining challenge is to
decide how far to advance t0 in the construction of the TRPG. During construction of the TRPG
in CRIKEY 3 time is constrained to advance by  or until the next action end point, depending on
whether any new facts are available following the most recent action layer (lines 2934 of Algorithm 2). In order to manage the effects of the active continuous processes, we add a third possibility:
time can advance to the earliest value at which the accumulated effect of active continuous change
on a variable can satisfy a previously unsatisfied precondition. The set of preconditions of interest
will always be finite, so, assuming that the variable is subject to a non-zero effect, the bound on the
relevant advance is always defined (or, if the set of preconditions is empty, no advance is required).
We can compute the value of this time as follows. Each numeric precondition may be written as a
constraint on the vector of numeric variables, v, in the form w  v  c, for vectors of constants w
and c. We define the function ub as follows:
X  w[i]  y[i] if w[i]  0
ub(w, x, y) =
w[i]  x[i] otherwise
w[i]w

The upper bound on w  v at t0 is then: ub(w, vmin (t0 ), vmax (t0 )).
The earliest point at which the numeric precondition w  v  c will become satisfied is then the
smallest value of t0 for which ub(w, vmin (t0 ), vmax (t0 ))  c.
As an example, suppose there is an action with a precondition x + 2y  z  c, so that w =
h1, 2, 1i (assuming x, y and z are the only numeric fluents in this case). Substituting this into the
previous equation yields:
ub(h1, 2, 1i, hx, y, zimin (t0 ), hx, y, zimax (t0 )) = 1.xmax (t0 ) + 2.ymax (t0 )  1.zmin (t0 )
= 1.(xmax (t)  (t0  t  ) + xmax (t + ))
+2.(y max (t)  (t0  t  ) + ymax (t + ))
1.(z min (t)  (t0  t  ) + zmin (t + ))
(The values of x, y and z are based on their starting points at t +  because this accounts for any
instantaneous changes triggered by actions in al(t).) If the value of t0 produced by this computation
is infinite, then the maximum possible rate of increase of the expression x + 2y  z must be zero.7
Otherwise, t0 is the time at which a new numeric precondition will first become satisfied due to
active continuous effects and, if this is earlier than the earliest point at which an action end point
can be applied, then the next fact layer in the TRGP will be f l(t0 ).
9.2.1 I MPROVING THE B OUNDS ON VARIABLES IN FACT-L AYER Z ERO
Previously, setting the bounds in fact-layer zero could be thought of as consisting of two stages:
finding initial bounds using the LP and then, because the passage of time could cause these bounds
to further diverge due to active continuous numeric change, integrating this change prior to setting
7. To find t0 requires only a simple rearrangement of the formula to extract t0 directly.

35

fiC OLES , C OLES , F OX & L ONG

bounds for layer zero of the TRPG. With an explicit model of numeric gradients in the planning
graph, we can now reconsider this approach. The intuition behind our new approach here is as
follows:
1. For each variable v, create an associated variable tnow (v) in the LP, and solve the LP to
minimise the value of this variable.
2. Fixing the value of tnow (v) to this lower-bound, maximise and minimise the value of v to find
the bounds on it at this point  these are then used as the bounds on v in fl (0.0).
3. If v > 0 in the current state, then all vmax (t) values in the TRPG are offset by v or,
similarly, if v < 0, all vmin (t) values are offset.
The first of these steps is based on the ideas described in Section 8.3, but the process is subtly
different because we are trying to determine the bounds on v at a given point in time, rather than
those that appear to be reachable. As before, tnow (v) must still come after the most recent plan step
and is used to determine the value of v. This is reflected by the pair of constraints:
tnow (v)  step i  
vnow = vi0 + vnow (tnow (v)  step i )
Additionally, since the now variable is associated with only a single v, rather than having to
be appropriate for all v, we can further constrain it if, necessarily, v cannot be referred to (either
in a precondition, duration or within an effect) until at least after certain steps in the plan, rather
than the weaker requirement of just after the most recent step. For our purposes, we observe that
if all actions referring to v require, delete and then add a fact p, and all possible interaction with p
is of this require-delete-add form, then tnow (v) must come after any plan step that adds p. More
formally, the require-delete-add idiom holds for p if p is true in the initial state, and for each action
a with preconditions/effects on p, the interaction between the action and p can be characterised as
one of the following patterns:
+
1. p  pre ` (a), p  eff 
` (a), p  eff ` (a)
+
2. p  pre a (a), p  eff 
a (a), p  eff a (a)
+
3. p  pre ` (a), p  eff 
` (a), p  eff a (a)

(An action may exhibit either or both of the first two interactions, or just the third.)
The LP variable corresponding to the point at which p is added, which we denote step p , is
determined in one of two ways. First, if p is present in the state being evaluated, step p is the LP
variable corresponding to the plan step that most recently added p. Otherwise, from case 4 above,
we know that p  eff +
a (a) for some action a that is currently executing. In this case, step p is the LP
variable estep i corresponding to the end of a. With this defined variable, we can add the constraint
to the LP:
tnow (v)  step p + 
Solving the LP with the objective being to minimise tnow (v) finds the earliest possible time at
which v can be referred to. Then, fixing tnow (v) to this minimised value, we minimise and maximise
36

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

the bounds on vnow . This gives us bounds on v that are appropriate as early as possible after the
actions in the plan so far.
Having obtained variable bounds from the LP we must, as before, account for the fact that the
passage of time causes the bounds to change if there is active continuous numeric change. Whereas
before we integrated this change prior to the TRPG, we now have a mechanism for handling gradients directly during TRPG expansion. Thus, for each start-event-queue entry e  E corresponding
to the start of an action, A, with a continuous effect on v with a positive (negative) gradient k,
we add a gradient effect on the upper (lower) bound on v to the TRPG. Just as we previously restricted the integrated effect of e by remaining(e), the maximum remaining time until the action
must end, so here we limit how long the gradient effect is active: it starts at al(0.0) and finishes at
al(remaining(e)). Then, for a given fact layer t the value of vmax (t) is updated accordingly:
vmax (t)+=

XX

{k | hv, ki  g(op(e))  k > 0  t  remaining(e)}

eE

Similarly, vmin(t) is amended to account for effects hv, ki, k < 0.
9.3 Using the Two Variants of the Integrated Heuristic in the Borrower Problem
We now illustrate the computation of the two heuristic functions for a choice point in the Borrower
problem. This example shows that the refined heuristic guides the planner to a shorter makespan
plan than the basic heuristic, because the improved heuristic information leads to the selection of
better choices of helpful actions. Consider the situation following execution of the first action,
saveHard start. Figure 7 (top) shows the TRPG and relaxed plan constructed using the basic
heuristic.
The heuristic generates a cost for this state of 5: the four actions shown in the relaxed plan,
together with an extra one to end the saveHard action that has already started. This relaxed plan
generates two helpful actions, to start the lifeAudit and to start takeMortgage short. An attempt to start the lifeAudit action can quickly be dismissed as temporally inconsistent, depending
as it does on boughtHouse becoming true before it ends, so the other helpful action is chosen. Unfortunately, once this action is selected the interaction between the saving process and the deposit
requirement (at least five savings must have been acquired) forces the action to start no earlier than
time 5. This constraint is invisible in the TRPG, because the continuous effect of saveHard has
been abstracted to a start effect, and a full ten savings therefore appear to be available immediately.
A plan can be constructed using the short mortgage, but only by introducing a second saving action
as shown in the lower plan in Figure 3. This is because the start of the short mortgage is pushed so
late that the life audit cannot both overlap the end of the first saveHard action and finish after the
mortgage action.
The lower part of Figure 7 shows what happens when the refined heuristic is used to solve
this problem. The saveHard action starts as before, but this time the heuristic does not relax the
behaviour of the continuous savings process so the long mortgage, which requires a smaller deposit
to initiate it, becomes available before the short mortgage. As a consequence of this, the relaxed
plan selects the long mortgage, and this action starts early enough that the life audit can overlap both
its end and the end of the saveHard action. The planner is correctly guided to the optimal plan, as
shown at the top of Figure 3. The crucial difference between the two heuristics, is that the refined
heuristic is able to access more accurate information about the value of the savings at timepoints
37

fiC OLES , C OLES , F OX & L ONG

0: saveHard_start

saving

10


lifeAudit_start
takeMortgage_start short

money : [20,20]

money : [ ,10]

saveHard_end

canSave

takeMortgage_start long

10+

10+2
lifeAudit_end

saveHard_start
boughtHouse

happy

takeMortgage_end short

0: saveHard_start

saving

1



5

lifeAudit_start
takeMortgage_start long

money : [ ,t]

money : [0.75t,10]

takeMortgage_start short

12

10

money : [t,10]

12+
lifeAudit_end

saveHard_end

canSave

takeMortgage_end long

boughtHouse

happy

Figure 7: The TRPG and relaxed plan for the Borrower problem, following initial execution of
saveHard start at time 0, as constructed using the original version of COLIN (top 
described in Section 9.1) and the revised version (bottom  described in Section 9.2).
Action layers are depicted in rounded rectangles and fact layers in ovals. The action
layers are labelled with their times constructed during the reachability analysis.

after the start of the savehard action. This leads to a finer-grained structure of the TRPG, which
can be seen in the fact that there are six action layers before arrival at the goal, rather than four as in
the case when the basic heuristic is used. The estimated makespan of the final plan is 12 + , while
the makespan according to the basic heuristic is 10 + 2. The basic heuristic leads to a non-optimal
solution because it requires the extra saveHard action, giving a solution makespan of 20 + 2, in
contrast to the makespan of 12 +  of the optimal plan.
The benefit of the refined heuristic, and the extra work involved in constructing the modified
TRPG, is that better helpful actions are chosen and the makespan estimate is therefore more accurate. The choice between similar length plans is made based on makespan. The TRPG, constructed
by the refined heuristic in the Borrower problem, does not even contain the short mortgage action at
an early enough layer for it to be considered by the relaxed plan.
38

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

10. Improving Performance
In this section we present two techniques we use to improve the performance of COLIN. The first
technique, described in Section 10.1, is a generalisation of our earlier exploitation of one-shot actions (Coles et al., 2009a) to the situation in which they encapsulate continuous processes, leading
to faster plan construction in problems with these action types. The second technique, described in
Section 10.2, exploits the LP that defines the constraints within the final plan to optimise the plan
metric. This leads to better quality plans in many cases.
10.1 Reasoning with One-Shot Actions
In earlier work (Coles et al., 2009a) we have observed that there is a common modelling device in
planning domains that leads to use of actions that can only be applied once. We call these actions
one-shot actions. They arise, in particular, when there is a collection of resources that can each be
used only once. The key difference that one-shot actions imply for the TRPG is that continuous
effects generated by one-shot actions lapse once a certain point has been reached:
 If a one-shot action a has a continuous numeric effect on v, and a` first appears in action layer
al(t), then the gradient on v due to this effect of a finishes, at the latest, at al(t + dmax (a)).
 If the end aa of a one-shot action has a duration-dependent effect on v, then the (implicit)
continuous effect acting on v finishes, at the latest, at layer al(t + dmax (a))
The termination point is implied, in both cases, by the fact that the action is one-shot.
We modify the TRPG construction to reflect these restrictions by extending the data recorded
in each action layer to include, for each snap-action action a, the maximum remaining execution
time of a, denoted rem(t, a). For one-shot actions, in the layer al(t) in which a` first appears,
rem(t, a` ) = dmax (a), and when aa first appears, rem(t, aa ) = dmax (a)  dmin(a). For actions
that are not one-shot rem(t, a` ) and rem(t, aa ) are both initialised to . We make three minor
changes to the layer update rules to accommodate the rem values. First, when calculating the active
gradient on a variable v following action layer al(t):
X
X
v max (t) =
p(a) 
k
aal(t)|rem(a,t)>0

hv,kig(a)

As can be seen, only the subset of actions with execution time remaining is considered. Second,
at the next action layer al(t + t) following al(t), the value of each positive rem is decremented
by t, the amount of time elapsed since the previous layer. Third, as a consequence of this, an
additional criterion must be considered when calculating the time-stamp of the next fact-layer, t0 ,
described in Section 9.2. Since the time remaining to complete an action may expire, we may
need to insert an additional fact layer to denote the point at which a rem value reaches 0 and the
continuous effects acting on one or more variables need to be recalculated. The time-stamp of the
earliest such layer is:
t0 = t + min{rem(t, a) > 0 | a  al(t)}
One-shot actions can be exploited still further by improving the upper bound on the duration of
the action a. In the case of actions with state-dependent duration constraints (i.e. where the upperbound is calculated based on variables that can be subjected to the effects of actions), dmax (a) may
39

fiC OLES , C OLES , F OX & L ONG

be a gross over-estimate of the duration of a. Suppose the maximum duration of a is bounded by a
formula w  v + c. In the layer al(t) in which a` appears, we can compute the maximum duration
of a, were it to be started in that layer, based on the variable bounds recorded in f l(t). We could
use this value to determine a bound on the remaining execution time for a. However, at some future
layer f l(t0 ), the variable bounds might have changed, so that beginning a in al(t0 ), and calculating
its maximum duration based on f l(t0 ), would have allowed a to execute for a possibly longer period
of time, allowing its continuous effects to persist for longer.
To remain faithful to the relaxation, the possibility of exploiting this increased duration of a
(by starting a at t0 ) must be included in the TRPG, as well as allowing the possibility of a to start
at t, thereby obtaining its effects sooner. Therefore, each one-shot action is allowed to start in the
earliest layer al(t) in which its preconditions are satisfied, giving it an initial maximum duration of
dmax (a, t) based on the fact later f l(t). But, if a later fact layer f l(t0 ) admits a greater duration
(dmax (a, t0 ), the value of dmax for action a at layer t0 ), the remaining execution time for a is
reconsidered. First, in the simple case, the variables in the duration constraint are changed in f l(t0 ),
but not subject to any active continuous effects. In this case, we apply a pair of dummy effects to
fact layer t00 = t0 + dmax (a, t):
hrem(a` , t00 ) += (dmax (a, t0 )  dmax (a, t))i
and
hrem(aa , t00 ) += (dmax (a, t0 )  dmax (a, t))i.
Note that the increase of the rem values is delayed until layer t00 because, in order to benefit from
the longer duration of a, a must have started in layer t0 .
In the more complex case, the variables in the duration constraint are changed in f l(t0 ) but
the duration is also affected by continuous effects on some of the variables it depends on. In this
situation, each subsequent fact layer might admit a marginally bigger duration for a than the last. To
avoid having to recalculate the new duration for a repeatedly, we schedule a pair of dummy effects
based on the global, layer-independent, maximum value for the duration of a:
hrem(a` , t00 ) += (dmax (a)  dmax (a, t))i
and
hrem(aa , t00 ) += (dmax (a)  dmax (a, t))i.
This relaxation is weaker than it might be, but is efficient to compute.
10.2 Plan Optimisation
A plan metric can be specified in PDDL 2.1 problem files to indicate the measure of quality to
use in evaluating plans. The metric is expressed in terms of the task numeric variables and the
total execution time of the plan (by referring to the variable total-time). The use of an LP in
COLIN offers an opportunity for the optimisation of a plan with respect to such a metric: for a plan
0
consisting of n steps, the numeric variables vn1
are those at the end of the plan, the stepn1 is the
time-stamp of the final step (i.e. the action dictating the makespan of the plan) and the LP objective
can be set to minimise a function over these. The LP must be solved to minimise the time-stamp of
the last action (the makespan of the plan) in order to arrive at a lower bound on the time for the next
action. However, it can also be solved to optimise the plan metric.
40

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Although it is possible to consider ways to use the metric-optimising LP value during plan
construction, to guide the search, we have focussed on a much more limited, but less costly, use: we
only attempt post hoc optimisation, attempting to exploit any flexibility in the temporal structure of
the final plan to optimise the plan quality at the last stage of plan construction.
In order for such post hoc optimisation to be useful, planning problems must have the property
that it is possible to vary the quality metric of a plan by scheduling the same actions to occur at
different times. This is possible in a wide range of interesting situations, such as scheduling aircraft
to land as close to a given target time as possible, taking images from satellites at certain times of day
when the view is clearer, or minimising wasted fuel by penalising the time elapsing between starting
the engine of a plane and its take off. The last of these represents a general class of problems in
which it may be desirable to minimise the amount of time between two activities: a different metric
to the total time taken for plan execution. To capture these interesting cases, we first extend the
language supported by COLIN to allow a limited subset of ADL conditional effects, to allow the
conditions under which an action is executed to vary the effects the action has on the metric value
of the plan. Second, we discuss how a MILP can be built, based on the LP described in Section 8.1,
to support post hoc plan optimisation.
Our planner handles most conditional effects by a standard compilation. However, conditional
effects on metric variables that appear in the plan quality metric and not in the preconditions of
any actions are dealt with differently. We call such variables metric tracking variables and we
exploit the fact that rescheduling a plan can affect the values of these variables without changing
the validity of the plan. An example is shown in Figure 10.2 of an action to land an airplane, with
conditional effects on the metric tracking variable total-cost. The domain is structured so that
all land actions must start at the beginning of the plan, and their end points represent the actual
landing times of the aircraft in the problem. The duration of the actions are set to correspond to the
earliest and latest possible points at which each plane could land. As can be seen, the propositional
effects of the action are the same whether the plane lands early or late: the plane has landed, and is
no longer flying. However, the numeric effects, which are all effects on the metric tracking variable
total-cost, depend on the duration of the action and, in particular, whether the plane has landed
early or late. If the plane lands early, a penalty is paid at a certain rate per unit time that the plane
lands before the desired target value. If the plane lands late, then a fixed cost is paid, in addition
to a penalty (at a different rate) per unit of time the plane lands after the desired target value. By
considering this action as a single action, with a pair of conditional effects, the planner can decide
upon the actions needed to construct a sound plan (in which all the planes have landed) whilst
leaving to the subsequent optimisation phase the decision about whether a plane should be landed
early, late, or on time.
In general, it is straightforward to exploit the LP described in Section 8.1 to attempt to reschedule the actions in a plan to optimise the value of the plan metric (provided that the metric function is
linear). However, if the plan contains actions with conditional effects on metric tracking variables,
it becomes possible to exploit the representation of these effects in an extended LP, using integer
variables, in order to offer a more powerful optimisation step. Each conditional effect will either be
activated or not: we introduce a 0-1 variable to represent which of these is the case for each effect.
The variable is connected to corresponding constraints that determine whether or not the condition
associated with the effect is true or not.
We deal with two kinds of constraints on the 0-1 variables in our MILP encoding of the plan optimisation problem: one is the special case where actions are scheduled against fixed time-windows
41

fiC OLES , C OLES , F OX & L ONG

(:durative-action land
:parameters (?p - plane ?r - runway)
:duration (and (>= ?duration (earliest ?p)) (<= ?duration (latest ?p)))
:condition
(and
(at start (takeOff))
(over all (flying ?p))
(at end (scheduled ?p ?r)))
:effect
(and
(at start (flying ?p))
(at end (landed ?p))
(at end (not (flying ?p)))
(when (at end (< (?duration) (target ?p)))
(at end
(increase (total-cost)
(* (earlyPenaltyRate ?p) (- (target ?p) ?duration)))))
(when (at end (> ?duration (target ?p)))
(at end
(increase (total-cost)
(+ (latePenalty ?p)
(* (latePenaltyRate ?p) (- ?duration (target ?p)))))))
)
)

Figure 8: PDDL Domain with Conditional Effects in the Airplane Landing Problem. The literal
takeOff is a special proposition manipulated by a dummy action to force all the landing
actions to be anchored to the same point in time.

governed by timed initial literals that affect whether the conditions are satisfied or not and the other
is the case where the satisfaction of the conditions is determined by the status of continuous effects
controlled by the actions in the plan (so, for example, the cost of an action might depend on whether
a continuously changing value has passed some threshold or not at the time the action is executed).
Both of these cases can be handled by a straightforward encoding of the linkage between the value
of the 0-1 condition variable and the corresponding conditions (the details are given in Appendix D).
We have also extended the conditional effects to allow them to affect the ?duration variable in an
action, with similar devices for encoding this in the MILP.
The MILP can then be solved as a single and final step in the construction of the plan, optimising
the plan metric quality by rescheduling the actions to best exploit the precise timing of the actions
and their interaction, through these limited conditional effects, on the plan quality.

11. Continuous Linear Benchmark Domains
As COLIN is one of the first planners to support PDDL 2.1 models featuring continuous linear change
and duration-dependent effects8 there are currently no benchmarks available that exploit these fea8. Specifically, duration-dependent effects that depend on non-fixed durations.

42

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

tures. To support our evaluation and to foster future comparisons between planners designed to
solve these problems, we have produced a number of domains with these features9 .
The first of our domains is an extension of the Metric Time variant of the Rovers domain, from
the 2002 International Planning Competition (IPC 2002) (Long & Fox, 2003b). Our focus here is on
the action navigate, responsible for moving a rover from one location to another. In the original
model, it has a discrete effect, at the start of the action, to decrease the energy level of the rover
by 8 units, coupled with a precondition that there must be at least 8 units of energy available. We
replace this with a continuous numeric effect on energy, and an over all condition that energy
must be at least zero during the action. As the duration of the original action was specified as 5, we
use an effect with gradient 8/5. Written thus, the action has the same net effect and conditions:
energy is decreased by 8 units, and must not become negative. This continuous change models more
accurately the use of power during the navigate action: whilst power use may not actually be linear,
it is closer to linear than it is to being instantaneous. To make the model still more realistic, we
introduce a new action into the domain: journey-recharge, shown in Figure 9. By exploiting
interaction between continuous numeric effects on the same variable, we use this action to capture
the option of the rover tilting its solar panels to face the sun whilst navigating between two points.
To account for the power use in reorienting the solar panels, at the start and end of the action, 0.2
units of energy are used. The benefit for this consumption is that, whilst the action is executing, the
energy of the rover is increased according to a constant positive gradient. For our final modification
to the domain, we alter the duration constraint on the existing recharge action. In the original
encoding, the constraint is:
(= ?duration (/ (- 80 (energy ?x)) (recharge-rate ?x))).

This forces the duration of the action to be sufficient to restore the level of charge to 80 (full capacity). In our new formulation, we replace the = with <= so that the duration constraint specifies
the maximum duration for which the battery can be charged: it need not be restored to full capacity
every time the action is applied. Following all three of these modifications, the domain can be used
with the standard IPC 2002 benchmark problems. In addition to this, we have also created some
problems considering just a single rover, where the issue of battery power management is of much
greater importance.
The next of our domains is an extension of the Time variant of the Satellite domain, again
taken from IPC 2002. Here, in our continuous variant of the domain, we make three key changes
to the domain model. First, in the original formulation, a proposition was used to indicate whether
power was available to operate the instrumentation on a given satellite. Switching an instrument
on required and then deleted this fact, and switching it off added it again. Thus, there was no
scope for parallel power usage, and all instrumentation effectively used unit power. Now, we use
a numeric variable to represent power, with preconditions and effects on this variable replacing
the preconditions and effects on the proposition previously used. Second, exploiting the potential
we now have for differing power requirements, instruments can be operated in one of two modes:
cooled, or uncooled. In cooled mode, active sensor cooling is used to reduce sensor noise, enabling
images to be taken in less time. This cooling, however, requires additional energy. Third, and
finally, there is a compulsory sunrise phase at the start of the plan, during which the satellites
9. P DDL domain and problem descriptions for all evaluation tasks are available in the online appendix maintained by
JAIR for this paper.

43

fiC OLES , C OLES , F OX & L ONG

(:durative-action journey-recharge
:parameters (?x - rover ?y - waypoint ?z - waypoint)
:duration (>= ?duration 0.2)
:condition (and (over all (moving ?x ?y ?z))
(over all (<= (energy ?x) 80))
(at start (>= (energy ?x) 0.2))
(at end
(>= (energy ?x) 0.2))
)
:effect (and (at start (decrease (energy ?x) 0.2))
(increase (energy ?x) (* #t (recharge-rate ?x)))
(at end
(decrease (energy ?x) 0.2))
)
)

Figure 9: The journey-recharge action in the continuous-numeric Rovers domain

move from being shaded by the planet, to being in direct sunlight. This leads to an increase in
power availability, modelled as a linear continuous numeric effect attached to an action, sunrise,
that must be applied. Interaction between this effect and the preconditions on powering instruments
ensures they can be operated no sooner than power is available. The problem files we use for this
domain are slightly modified versions of the IPC competition problems, updated to define power
availability as a numeric variable and to encode the power requirements of cooled and uncooled
sensor operation. The problems in this domain have characteristics that are very similar to the
Borrower problem we have used as a running example.
Further exploring the use of continuous numeric effects, our next domain models the operations
of cooperating Autonomous Underwater Vehicles (AUVs). The AUVs move between waypoints
underwater and can perform two sorts of science gathering operations. The first is taking a water
sample from a given waypoint, which can be performed by any AUV in the appropriate location,
and whose water sample chamber is empty. The second is taking an image of a target of interest.
This requires two AUVs to cooperate: one to illuminate the target with a torch, and one to take
an image of it. The AUV domain was inspired by the problem described by Maria Fox in her
invited lecture at the 2009 International Conference on Automated Planning and Scheduling. Once
data has been acquired, it must be communicated to a ship on the surface. As in the Satellite and
Rovers domains, the AUVs are energy-constrained  they have finite battery power  and the
power usage by actions is continuous throughout their execution. The more interesting continuous
numeric aspects of the domain arise from the use of a model of drift. We introduce a variable to
record how far each AUV has drifted from its nominal position, and update this in two ways. First,
all activity in the plan is contained within an action drift with small, positive continuous numeric
effect on the drifted distance. Second, we add a localise action that sets this drifted distance to
zero, with its duration (and hence energy requirements) depending on the drifted distance prior to
its application. This drifting then affects the other domain actions. In the simplest case, to sample
water or take an image at a given location, an AUV cannot have drifted more than two metres, hence
introducing the need to first localise if this is the case. More interestingly, for an AUV shining a
torch, drifting affects how much light is falling on the target. Thus, the shine-torch action for an
AUV ?v has three effects on the amount of light falling on a given target ?t:
44

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

 start: (increase (light-level ?t) (- 1000 (distance-from-waypoint ?v)))
 throughout: (decrease (light-level ?t) (* #t (fall-off)))
 end: decrease (light-level ?t) by any remaining contribution ?v was making to its
illumination.
The constant (fall-off) is pessimistically derived from formul involving the inverse-square
law, giving a linear approximation of the decay in illumination levels due to drift. Then, for the
take-image action itself, its duration is a function of (light-level ?t): the less light available, the longer it requires to take the image.
The final domain we use is the Airplane Landing domain (Dierks, 2005), first posed as a challenge by Kim Larsen in his invited lecture at the 2009 International Conference on Automated
Planning and Scheduling. This problem models the scheduling of landing aircraft on an airport
runway. For each plane, three landing times are specified: the earliest possible landing time, the
latest possible landing time, and the target (desired) landing time. Since time must be allowed for
airplanes to clear the runway once they have landed, and the use of the runway is a heavily subscribed resource, it is not possible for all planes to land at their ideal time. Planes can, therefore,
land early or late, but doing so incurs a penalty. This penalty is modelled by a duration-dependent
effect, as shown earlier in the paper (Figure 10.2 in Section 10). We have been able to construct a
set of airplane landing problems using real data from the Edinburgh Airport arrivals board. Results
from running COLIN on these problems are reported in Section 12.

12. Evaluation
COLIN is a temporal planner, able to solve problems with required concurrency, that can handle
both discrete and continuous metric variables. The first question we address is how costly is the
extension of the underlying CRIKEY 3 system to allow COLIN to manage continuous effects? COLIN
is a particularly powerful planner and there are no other general PDDL 2.1 planners with similar
expressive power available for comparison on the continuous problems. However, the extensions
necessary to support continuous reasoning will add an overhead to the cost of solving problems
where there are no continuous effects. We compare the performance of COLIN with other temporal
planners on a selection of temporal problems without continuous effects (Section 12.1) in order to
evaluate how much overhead is paid by COLIN in setting up and managing (redundant) structures,
in comparison with state-of-the-art planners that do not pay this price.
We then move on to considering the performance of COLIN on problems with continuous dynamics. Our second question is: how much improvement do we obtain from using the refined
heuristic instead of the basic heuristic, when dealing with problems with continuous change? The
planners discussed in Section 7 are not able to scale to large and complex problems, so we compare
the two versions of COLIN. We present their performances on new benchmark problems with continuous processes, setting the foundation for future comparative evaluation of alternative approaches
to these problems.
The third question considered concerns the quality of the solutions produced by COLIN, in
comparison with optimal solutions where these can be found. COLIN is a satisficing planner that
can perform efficiently on a wide range of continuous planning problems, and we are interested
in understanding how much solution quality must be sacrificed in order to obtain the efficiency
achieved by COLIN.
45

fiC OLES , C OLES , F OX & L ONG

Finally, we consider the question: just how expensive is the move from solving an STP (sufficient for purely discrete temporal planning) to solving an LP (necessary for handling continuous
effects)? In particular, is it practical to solve multiple LPs in performing heuristic state evaluations?
Since LP construction and solution is central to the architecture of COLIN it is important that this
can be relied upon to scale appropriately with the range and complexity of problems that COLIN is
expected to solve.
The following experiments consider a large number of domains and domain variants. For the
temporal comparisons we use the Simple Time and Time variants of Depots, Driverlog, Rovers,
Satellite and Zeno, all from IPC 2002, and Airport and Pipes-No-Tankage from IPC 2004. The
Airport variant used here is the Strips Temporal variant.
For the comparisons between the basic and refined heuristics on continuous domains, we use the
new continuous benchmark domains introduced in Section 11: Airplane Landing, Rovers, Satellite
Cooled (the Satellite variant with sensor cooling) and the AUV domain.
For the post-hoc optimisation experiments we use the Airplane Landing problem, the Cafe domain introduced in the empirical analysis of CRIKEY 2 (Coles, Fox, Halsey et al., 2008), a variant of
Airport in which the amount of fuel burned is to be minimised, and a version of Satellite with time
windows, where rewards are obtained by scheduling observations into the tighter windows.
In all cases we use the competition benchmark sets of instances where available. For the continuous Rovers and Satellite domains we used the IPC 2002 Complex Time problem sets. These
instances work with the continuous domain variants and it is possible to get better makespan plans
for them, by respecting the continuous dynamics, than is possible when the same instances are
solved using the discrete domain variants. We generated increasing sized instances for the Airplane Landing domain in which the number of planes to be landed increased (in the nth instance
of the problem, n planes must be landed). We wrote a problem generator for the AUV domain that
increases the number of AUVs, waypoints and goals in the instances (they range from 2 AUVs, 4
waypoints and 1 goal, to 6 AUVs, 16 waypoints and 6 goals). All experiments were run on a 3.4GHz
Pentium D machine, limited to 30 minutes and 1GB of memory.
12.1 Comparison with Existing Temporal Planners
Few temporal planners can actually solve a full range of temporal problems. As we have already
observed, many temporal planners cannot solve problems with required concurrency. Even within
the class of problems that have required concurrency, there are easier problems, which can be solved
by a left packing of actions within the plan and harder ones for which this is not possible. By left
packing we mean that actions that must be executed concurrently with other actions in the plan can
be started at the same time as each other. This property means that the approach adopted in Sapa, of
extending forward search to include a choice to either start a new action or else to advance time to
the earliest point at which a currently executing action terminates, is sufficient to solve the problem.
In contrast, a problem that cannot be left packed will require the possibility of advancing time to
some intermediate point during execution of an action in order to coordinate the correct interleaving
of other actions with it. We describe such problems as requiring temporal coordination. One of
the few planners that can also handle problems requiring temporal coordination is LPG-s (Gerevini
et al., 2010).
We therefore compare COLIN with LPG-td, LPG-s, Sapa and the temporal baseline planner developed for the temporal satisficing track at the 2008 International Planning Competition. Neither
46

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Depots Simple Time

Driverlog Simple Time
100

Colin Solution Time (s)

Colin Solution Time (s)

100

10

1

0.1

10

1

0.1
LPG-TD used
Temp-Baseline used

0.01
0.01

0.1

1
10
Best of Other Solution Time (s)

LPG-TD used
LPG.s used
Temp-Baseline used
0.01
0.01

100

0.1

Rovers Simple Time

100

Satellite Simple Time
100

Colin Solution Time (s)

100

Colin Solution Time (s)

1
10
Best of Other Solution Time (s)

10

1

0.1

10

1

0.1
LPG-TD used
Temp-Baseline used

0.01
0.01

0.1

1
10
Best of Other Solution Time (s)

LPG-TD used
Temp-Baseline used
0.01
0.01

100

0.1

1
10
Best of Other Solution Time (s)

100

Zeno Simple Time
1000

Colin Solution Time (s)

100

10

1

0.1

0.01
0.01

LPG-TD used
Temp-Baseline used

0.1

1
10
Best of Other Solution Time (s)

100

1000

Figure 10: Comparison of time taken to solve problems in simple temporal planning benchmarks.
COLIN is compared to the best of LPG -td, LPG .s, Sapa and a temporal baseline planner,
on each problem file  the shape and colour of the points indicate which planner was
the best and was therefore used in the plot. Planners not appearing in a particular dataset
were not the best on any of the problems in that collection.

the temporal baseline planner, Sapa nor LPG-td can solve problems requiring any kind of temporal
coordination. The temporal baseline planner compiles away temporal information, by using action
47

fiC OLES , C OLES , F OX & L ONG

Depots Time

Driverlog Time
100

Colin Solution Time (s)

Colin Solution Time (s)

100

10

1

0.1

10

1

0.1
LPG-TD used
Temp-Baseline used

0.01
0.01

0.1

1
10
Best of Other Solution Time (s)

LPG-TD used
Temp-Baseline used
0.01
0.01

100

0.1

Rovers Time
100

Colin Solution Time (s)

Colin Solution Time (s)

100

Satellite Time

100

10

1

0.1

10

1

0.1
LPG-TD used
LPG.s used

0.01
0.01

1
10
Best of Other Solution Time (s)

0.1

1
10
Best of Other Solution Time (s)

LPG-TD used
LPG.s used
Temp-Baseline used
0.01
0.01

100

0.1

1
10
Best of Other Solution Time (s)

100

Figure 11: Comparison of time taken to solve problems in more complex temporal planning benchmarks (first set). COLIN is compared to the best of LPG-td, LPG.s, Sapa and a temporal
baseline planner, on each problem file  the shape and colour of the points indicate
which was the best. Planners not appearing in a particular dataset were not the best on
any of the problems in that collection.

compression, and solves problems as if they were non-temporal metric or propositional problems.
When solutions are found, using Metric-FF as the core planning system, the temporal information
is reintroduced by annotating the plan with suitable timestamps based on a critical path analysis.
No details are published about this planner, but the source code and brief information are available
from the IPC 2008 web site. This approach cannot therefore solve problems with required concurrency, but is fast and effective on simpler problems where the temporal actions can be sequenced.
It is straightforward to identify many cases when action compression can be applied safely and this
analysis is implemented in COLIN to reduce the overhead of reasoning with action end points where
it is unnecessary. Therefore, the behaviour of the temporal baseline planner is similar to that of
COLIN when all actions can be safely compressed. In Figures 10, 11 and 12 we show CPU time
comparisons between COLIN and the best performances of Sapa, LPG-td, LPG-s and the temporal baseline planner, across a wide and representative collection of temporal benchmark domains.
Figure 10 shows performance on simple temporal problems, where action durations are all fixed,
while Figures 11 and 12 show results for more complex temporal problems, including those where
48

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Airport Strips Temporal
1000

100

100
Colin Solution Time (s)

Colin Solution Time (s)

Zeno Time
1000

10

1

0.1

0.01
0.01

1
10
Best of Other Solution Time (s)

100

1

0.1

LPG-TD used
LPG.s used

0.1

10

0.01
0.01

1000

LPG-TD used
Temp-Baseline used

0.1

Pipes No-Tankage Temporal

1
10
Best of Other Solution Time (s)

100

1000

Pipes Tankage Temporal
1000

100

Colin Solution Time (s)

Colin Solution Time (s)

100
10

1

10

1

0.1
0.1

LPG-TD used
Temp-Baseline used
0.01
0.01

0.1

1
10
Best of Other Solution Time (s)

0.01
0.01

100

LPG-TD used
Temp-Baseline used

0.1

1
10
Best of Other Solution Time (s)

100

1000

Figure 12: Comparison of time taken to solve problems in more complex temporal planning benchmarks (second set). COLIN is compared to the best of LPG-td, LPG.s, Sapa and a temporal baseline planner, on each problem file  the shape and colour of the points indicate
which was the best. Planners not appearing in a particular dataset were not the best on
any of the problems in that collection.

the duration of actions is determined by the context in which they are executed (although none in
which action effects depend on this), and problems with metric variables. None of these problems
feature required concurrency or other forms of temporal coordination. In these figures, planners not
appearing in a dataset were not the best on any problems in that domain.
Analysis of Figures 1012 shows that COLIN does indeed pay an overhead in computation time
in the solution of temporal problems that do not feature continuous dynamics. The overhead is particularly significant in the simple temporal problems where there is no interesting temporal structure
and the temporal baseline planner tends to perform very well. The overhead paid by COLIN is lower
in the complex temporal problems, where the temporal reasoning required is sometimes more challenging. The makespan results in Figures 13, 14 and 15 show that COLIN produces good quality
plans, especially for the complex temporal problems, although the temporal baseline planner is still
competitive in terms of both CPU time and makespan. This suggests that the temporal structure,
even in the complex temporal benchmarks, is quite simple and that a planner can do well by ignoring
the temporal structure that is present, rather than trying to reason about it in generating plans.
49

fiC OLES , C OLES , F OX & L ONG

Depots Simple Time

Driverlog Simple Time

100

300

250
Colin Solution Quality

Colin Solution Quality

80

60

40

20

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

0
0

20

40
60
Best of Other Solution Quality

80

200

150

100

LPG.s used
Sapa used
Temp-Baseline used

50

0
100

0

50

100
150
200
Best of Other Solution Quality

300

Satellite Simple Time

400

400

350

350

300

300
Colin Solution Quality

Colin Solution Quality

Rovers Simple Time

250

250
200
150
100

250
200
150
100

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

50
0
0

50

100

150
200
250
Best of Other Solution Quality

300

350

LPG-TD used
LPG.s used
Temp-Baseline used

50
0
400

0

50

100

150
200
250
Best of Other Solution Quality

300

350

400

Zeno Simple Time
6000

Colin Solution Quality

5000

4000

3000

2000

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

1000

0
0

1000

2000
3000
4000
Best of Other Solution Quality

5000

6000

Figure 13: Comparison of plan quality in simple temporal planning benchmarks. COLIN is compared to the best of LPG-td, LPG.s, Sapa and a temporal baseline planner, on each problem file  the shape and colour of the points indicate which was the best. Planners
not appearing in a particular dataset were not the best on any of the problems in that
collection.

The detailed results of these experiments, showing raw runtime and quality comparisons between the planners used in this experiment, are presented in Appendix E.
50

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Depots Time

Driverlog Time

400

1000

350
800
Colin Solution Quality

Colin Solution Quality

300
250
200
150

600

400

100
200

LPG-TD used
LPG.s used
Sapa used

50
0

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

0
0

50

100

150
200
250
Best of Other Solution Quality

300

350

400

0

200

Rovers Time

400
600
Best of Other Solution Quality

800

1000

Satellite Time

400

600

350

500
Colin Solution Quality

Colin Solution Quality

300
250
200
150

400

300

200

100
LPG-TD used
LPG.s used
Sapa used

50

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

100

0

0
0

50

100

150
200
250
Best of Other Solution Quality

300

350

400

0

100

200
300
400
Best of Other Solution Quality

500

600

Figure 14: Comparison of plan quality in more complex temporal planning benchmarks (first set).
COLIN is compared to the best of LPG -td, LPG .s, Sapa and a temporal baseline planner,
on each problem file  the shape and colour of the points indicate which was the best.
Planners not appearing in a particular dataset were not the best on any of the problems
in that collection.

12.2 Solving Problems with Continuous Linear Change and Duration-Dependent Effects
Our focus in this section is on examining the scalability of COLIN on the continuous benchmark
domains we have developed and, specifically, on comparing the two variants of the TRPG discussed in Section 9. These are: the basic heuristic, which discretises time, and the refined heuristic,
which is capable of handling continuous numeric change directly. The continuous benchmarks, as
described in Section 11, are characterised by sophisticated temporal structure (including required
concurrency) giving rise to interesting opportunities for concurrent behaviour. Because these problems have time-dependent effects and continuous effects, they are out of the reach of the temporal
planners used in the last experiment. The problems used for this experiment are designed to rely
on the exploitation of these features, so a baseline planner that ignored these continuous dynamics
would be unable to solve the problems.
Results comparing the basic and refined heuristics are shown in Figure 16. Beginning with the
Airplane Landing domain and the Rovers domain variant, the performance is the same when either
51

fiC OLES , C OLES , F OX & L ONG

Zeno Time

Airport Strips Temporal

400

1000

350
800
Colin Solution Quality

Colin Solution Quality

300
250
200
150

600

400

100
200

LPG-TD used
LPG.s used
Sapa used

50
0

LPG-TD used
LPG.s used
Temp-Baseline used

0
0

50

100

150
200
250
Best of Other Solution Quality

300

350

400

0

200

50

40

40

30

20

10

800

1000

Pipes No-Tankage Temporal

50

Colin Solution Quality

Colin Solution Quality

Pipes No-Tankage Temporal

400
600
Best of Other Solution Quality

30

20

10

LPG-TD used
LPG.s used
Temp-Baseline used

0

LPG-TD used
LPG.s used
Temp-Baseline used

0
0

10

20
30
Best of Other Solution Quality

40

50

0

10

20
30
Best of Other Solution Quality

40

50

Figure 15: Comparison of plan quality in more complex temporal planning benchmarks (second
set). COLIN is compared to the best of LPG-td, LPG.s, Sapa and a temporal baseline
planner, on each problem file  the shape and colour of the points indicate which was
the best. Planners not appearing in a particular dataset were not the best on any of the
problems in that collection.

heuristic is used: the relaxed plans found are the same. This is to be expected, because in these two
domains the interaction between time and numbers is relatively limited. In the Airplane Landing
problem, action durations affect a variable used to measure plan cost but that is not used in any
preconditions. Thus, the selection of actions in the TRPG is unaffected. In the Rovers domain, continuous change arises when consuming power during navigate actions, or producing power when
recharging. Capturing the time-dependent nature of these more precisely has no effect on the relaxed plans, as the nature of the relaxation leads it to only rarely require recharge actions, and the
conditions under which these are needed are not affected by whether the effects are integrated or
not. Nevertheless, these two domains illustrate that in guaranteed like-for-like situations, where
the heuristic guidance will be the same, the refined heuristic is only negligibly more expensive to
compute, despite the additional overheads of tracking gradient effects as the TRPG is expanded.
It can also be seen that COLIN scales well across the Airplane Landing instances, although it only
manages to solve 9 of the 14 Rovers problems (these well within two minutes).
52

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Rovers Continuous Time

Airplane Landing Edinburgh Time
1000

100

Basic Heuristic
Refined Heuristic

Refined Heuristic
Basic Heuristic
100
10

Time

Time (s)

10
1

1

0.1
0.1

0.01

0.01
5

10

15

20
25
30
Problem Number

35

40

45

2

50

4

6

Satellite Cooled Time
1000

12

14

Satellite Cooled Makespan
1000

Basic Heuristic
Refined Heuristic

Basic Heuristic
Refined Heuristic

900
800

Makespan

100

Time (s)

8
10
Problem Number

10

700
600
500

1

400
300

0.1

200
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

AUV Time

10
12
Problem Number

14

16

18

20

AUV Makespan

10000

600

Basic Heuristic
Refined Heuristic
1000

500

100

400
Makespan

Time

8

10

300

1

200

0.1

100

0.01

Basic Heuristic
Refined Heuristic

0
5

10

15
20
Problem Number

25

30

5

10

15
20
Problem Number

25

30

Figure 16: Comparison of the Basic and Refined TRPG variants on continuous domains. The boxed
graphs are makespan comparisons for the Satellite Cooled and AUV domains, placed to
the right of their corresponding runtime graphs.

In the Satellite Cooled domain, the runtime taken to find the plans when using the refined
heuristic is comparable to that when using the basic heuristic: in some problems (e.g. 13, 18) it
is slower; but in others (e.g. 12, 15) it is faster. The more interesting comparison to make is in
the makespan data (shown to the right). As can be seen, the refined heuristic generally produces
53

fiC OLES , C OLES , F OX & L ONG

better quality plans. The difference in quality is due to the refined heuristic better capturing the
relationship between time and numbers, leading to better actions being chosen in the relaxed plan.
By way of example, consider the state reached after beginning the sunrise action:
 For the basic heuristic, the LP is used to obtain bounds on the power availability in this state,
with free reign over how much time to allow to elapse. The lower-bound found is slightly
more than zero (corresponding to allowing  time to elapse), and the upper-bound found is
the peak power availability (corresponding to applying the entirety of the sunrise action).
When building a TRPG from these bounds, cooled sensor operation is immediately available,
and hence the goals will always be achieved first by actions using sensor cooling: the duration
of such actions is lower, making them more attractive. The resulting relaxed plan, and hence
helpful actions, will therefore lead search to use sensor cooling.
 With the refined heuristic, the LP is used to obtain bounds on the power availability in this
state, but these bounds must be obtained at the soonest possible point. Thus, the lowerbound is still slightly more than zero, but the upper bound is also only slightly more than
zero. The positive gradients in effect on the power availability variables are then included in
the TRPG, influencing the layers at which different actions become applicable. Specifically,
actions without sensor cooling have lower power requirements, and hence appear at earlier
layers. Then, for goals first achieved by actions not using sensor cooling (where the increased
duration of acquiring the image without cooling is compensated for sufficiently by being able
to start taking the image sooner) the relaxed plan, and hence helpful actions, will not use
sensor cooling for these goals. It can be seen that this situation is closely analogous to the
differences in alternative mortgages in the Borrower domain.
The extent to which this trade-off influences plan quality varies between problems, depending
on the initial orientation of the satellites, and the images required. The least benefit arises if a
satellite requires substantial reorientation to point it towards its first target  if this is the case, the
time taken allows the energy level to rise sufficiently to support sensor cooling. The greatest benefit
arises in the opposite situation, where a satellite requires minimal reorientation  then, switching
on a sensor in its cooled mode will require a substantial amount of time to elapse to support its
energy requirement precondition.
To aid understanding of the scalability implications of these results, the Satellite problems are
based on those used in the 2002 IPC, so are of a similar fundamental size. However, the continuous
reasoning that has been added to them makes the same underlying problems fundamentally much
more difficult to solve.
In the AUV domain, the use of the refined heuristic increases the problem coverage, with 30
problems solved rather than 27. Applying the Wilcoxon Matched-Pairs Signed-Ranks Test to the
paired time-taken data for mutually solved problems, we find that we can reject the null hypothesis
that the refined heuristic is no better than the basic heuristic, with p  0.05. Observing the performance of the planner, this difference in performance arises due to the way in which the drifting
process is handled by the two approaches. Specifically, it is accounted for by the difference in how
the bounds for fact layer zero of the TRPG are calculated. Consider a state in which an action for
an AUV to communicate image data has just been started. The domain encoding ensures that until
communication has completed, the AUV cannot perform any other activities. At this point, prior to
evaluating the state using a TRPG heuristic, the LP is used to give bounds on the values of each state
54

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

variable. Considering just the variable recording how far the communicating AUV has drifted 
the variable (distance-from-waypoint auv0), from now on abbreviated to dfw0:
 The basic heuristic employs the approach set out in Section 8.3. A single now timestamp
variable is introduced, that must come after the action just started, along with an additional
variable and constraint for dfw0. Maximising and minimising the value of this additional
variable yields bounds on dfw0. The lower bound will be infinitesimally larger than it was
prior to starting the action, due to  time having elapsed. The upper bound corresponds to
allowing a large amount of time to elapse.
 The refined heuristic employs the approach set out in Section 9.2.1. Here, a now timestamp
variable is introduced for each task variable, in this case we are concerned with tnow (dfw0).
As in the prior case, this is constrained to be after the action just applied. Additionally,
however, because the domain model enforces that no other action can refer to the value of the
variable until the communicate action has finished, this specific tnow must also come after the
(future) end of the action just applied. The bounds on dfw0 are then found by following the
remaining steps of Section 9.2.1: the LP is solved to minimise the value of this tnow variable,
the value of the variable is fixed to this minimum and then the LP is solved to maximise and
minimise the value of dfw0. Critically, because this tnow variable must come after the end
of the action just applied, rather than just after its start, the lower bound on dfw0 is larger.
The increase in the lower bound on dfw0 then affects whether, in the TRPG, preconditions of
the form (<= (dfw0) c) are considered satisfied in the initial fact layer. If they are not satisfied,
they are delayed until the earliest layer at which a localise action reduces the value of dfw0. This
difference can then affect the relaxed plan found: during solution extraction, if an action A requiring
(<= (dfw0) c) is chosen, then if a localise action was necessary to achieve this in the TRPG, the
action will be added to the relaxed plan. As A cannot come any earlier than after the end of the
communicate action just applied, that is, the point at which the bounds on dfw0 are calculated,
then some sort of localisation is necessary if A is ultimately to be applied. Thus, the bounds for
the refined heuristic here lead to better relaxed plans being found, containing localise actions that
would otherwise be omitted.
To give an indication of the difficulty of these problems, the AUV problems range from problems
with 2 AUVs, 5 waypoints, 2 objectives and 2 goals to those at the harder end with 6 AUVs, 15
waypoints, 6 objectives and 7 goals. The major hurdle preventing COLIN from scaling to even
larger problems is the inability to see that an implicit deadline has been created when a shine-torch
action is started. The AUV shining the torch has finite energy, so if the planner starts a shinetorch action with one AUV, in preparation for another AUV to take an image, but then adds to
the plan some actions involving the second AUV that are unrelated to taking the image, the delay
can lead to there being insufficient energy to shine the torch for long enough to gain the required
exposure when the photograph taking action is eventually started. This leads the planner to a dead
end and it is forced to resort to best-first search, which is much less effective than EHC in this
domain. Such implicit deadlines can occur in many planning problems with temporal coordination
and the issues COLIN faces could be avoided by using a branch-ordering heuristic that promotes
actions whose applicability is time-limited due to the ends of currently-executing actions, or perhaps
through relaxing unnecessary ordering constraints imposed by COLIN due to total order search. Both
of these are out of the scope of this paper, but are interesting avenues for future work.
55

fiC OLES , C OLES , F OX & L ONG

(:durative-action burning-fuel
:parameters (?a - airplane)
:duration
(>= ?duration (* 60 (engines ?a)))
:condition (and (at start (not-burning-fuel ?a))
(at end (taking-off ?a)))
:effect (and (at start (can-start-engines ?a))
(at start (not (not-burning-fuel ?a)))
(increase (wasted-fuel) (* #t (engines ?a)))
)
)

Figure 17: burning-fuel action added to the Airport domain
12.3 Post Hoc Plan Optimisation
In this section we evaluate the effectiveness of our post hoc plan optimisation strategy. As described
in Section 10, the plan optimisation phase occurs after planning is complete and can never change
the actions that are in the plan. By lifting a Partial Order prior to scheduling (Veloso, Perez, &
Carbonell, 1990), we can provide the scheduler with a little more flexibility over the order of actions.
As long as the ordering constraints remaining after this (greedy) partial-order lifting are respected,
the scheduler can reduce plan cost by altering the time-points at which the actions occur and, where
possible, their durations. Minimising an objective other than plan makespan can only have an effect
on plan quality in domains where the metric is sensitive to the times at which the actions are applied,
since, by default, COLIN minimises makespan in the solution of the final LP for a completed plan.
There are few such benchmark domains in the literature, so we make use of the one existing suitable
domain and introduce some new variations on existing benchmarks, in order to test this feature.
The first domain, and the only existing domain with this property, is the Airplane Landing
domain, used earlier in this section, and described in Section 11. Here, the penalties incurred for
each landing depend on whether, and to what extent, it is early or late. Therefore, for a given
sequence of landings, the times assigned to them has an impact on the quality of the plan.
The next two of our benchmark problems are variants of problems introduced in the International
Planning Competitions of 2002 (Long & Fox, 2003b) and 2004 (Hoffmann & Edelkamp, 2005).
First, we consider a modified version of the Satellite domain. We modify the domain by adding
time windows (modelled using TILs) during which there is a clear view of a given objective. If the
photograph of the objective is taken during such a time window, the quality of the plan improves,
as a better quality picture is preferable. In each problem we introduce three such time windows
for each objective, of bounded random duration, during which taking a photograph of the objective
is preferred. The second adapted benchmark is taken from the IPC2004 Airport domain. Where
the Airplane Landing problem described previously is concerned with scheduling landing times for
aircraft, the Airport domain is concerned with coordinating the ground traffic: moving planes from
gates to runways, and eventually to take-off, whilst respecting the physical separation that must be
maintained between aircraft for safety reasons. We add to this domain the metric to minimise the
total amount of fuel burnt between an aircrafts engines starting up and when it eventually takes
off. To capture this in PDDL 2.1, we add the action shown in Figure 17. This action must occur
before a planes engines can be started and cannot then finish until the plane has started to take-off
(hence its duration is at least that of the startup action). Between these two points it increases
56

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

the amount of fuel wasted by a rate proportional to the number of engines fitted to the aircraft:
larger planes (for which the number of engines is greater) waste more fuel per unit of time. In
both the Satellite and the Airport domains we use the standard problem sets from the competitions,
adding any minor changes needed to support the modifications made, whilst leaving the underlying
problems themselves unaltered.
The final domain we consider is the cafe domain, first used to evaluate CRIKEY (Coles, Fox,
Halsey et al., 2008). In this domain, tea and toast must be made and delivered to each table in a
cafe. The kitchen, however, has only one plug socket, preventing the two items from being made
concurrently. This restriction allows the problem to have a number of interesting metric functions:
to minimise the total time to serve all customers (the plan makespan), to minimise the time between
delivery of tea and toast to a given table, or to minimise the amount by which the items have cooled
when each is delivered to the table. We consider the latter two variants here.
The results of our experiments are presented in Figure 18. Starting in the top-left, with the
Airplane Landing domain, post hoc optimisation gives only a modest improvement in plan quality.
This is due to the limited scope for optimisation: even after partial-order lifting, the order in which
the planes are going to land is fixed by the plan, so all that can be adjusted is the precise times at
which the planes are going to land within that ordering.
Moving to the Airport domain variant with the burning-fuel action  Figure 18 top-right 
post hoc scheduling is able to give large improvements in plan quality. In the original plans, before
optimisation, the burning-fuel action for a given plane can be started at any point prior to when
the relevant can-start-engines fact is needed and can be ended at any point after the relevant
taking-off fact is true, so not necessarily in a timely manner. Following post hoc optimisation,
due to the objective function used, each burning-fuel action starts as late as possible and finishes as
early as possible.
In the cafe domain, the results for the two metrics used are shown in the central graphs in
Figure 18. The two diagonal lines correspond to the original plans. On a given problem, the two
plans are identical: only the evaluation metric differs. The two lower lines show the quality of the
plan after scheduling it with respect to the relevant metric. Observing the post-scheduled plans,
the actions are scheduled as one would intuitively expect. When minimising the total delivery
window times, the items for a given table are delivered in succession, even if the first item loses heat
while waiting for the second item to be prepared. In contrast, when minimising heat loss items are
delivered to tables as soon as they have been prepared, even if there is then a delay between the two
items being delivered.
Finally, the results for the variant of the Satellite domain with observation windows is shown
in the bottom-left of Figure 18. Whilst not as marked as the improvements in the previous two
domains, the scheduler is able to make some headway in better scheduling the observations. The
original plan for a given problem will, for each satellite, fix the observations it is to make, and the
order in which they are to be made. There remains enough flexibility to be able to improve plan
quality, reducing plan cost by around a factor of 2.
12.4 Comparison with Optimal Solutions
We investigated the difference in quality between optimal solutions and the solutions produced by
COLIN in order to form an impression of how close to optimal COLIN can get. To do this, we ran
COLIN with an admissible heuristic that uses the makespan estimate produced by the TRPG, using
57

fiC OLES , C OLES , F OX & L ONG

Airplane Landing Edinburgh
20000

Airport Fuel Loss
4500

colin-standard
colin-optimise

18000

4000

16000

3500

14000

3000

Solution Quality

Solution Quality

colin-standard
colin-optimise

12000
10000
8000

2500
2000
1500

6000

1000

4000

500

2000
0

0
5

10

15

20
25
30
Problem Number

35

40

45

50

2

4

6

Cafe (Delivery Window)
1200

8

10
12
Problem Number

14

16

18

Cafe (Heat Loss)

colin-standard
colin-optimise

80

100

colin-standard
colin-optimised

70

80

1000
Delivery Window Metric

20

Heat Loss Metric

60
800

600

60

50
40

40
30

400
20
200

20

10

0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

0
2

4

6

8
10
12
Problem Number

14

16

18

20

Satellite Reward
1200

colin-standard
colin-optimise

Solution Quality

1000

800

600

400

200

0
2

4

6

8

10
12
Problem Number

14

16

18

20

Figure 18: Quality of plans produced by Colin with and without post hoc optimisation. On all four
graphs, lower is better.

the same value for  as is used by COLIN in the results presented in Figures 16 and 18. We call this
variant optimalCOLIN.
In the AUV and Rover domains, there are variable-duration actions in the domain for which the
durations can be chosen to be as small as  when these actions are used in a plan. -length actions
might be chosen, for example, to relocalise having slightly drifted, or to recharge having used a
negligible amount of power. In these domains, optimal search has to consider plans comprising
almost entirely actions of  duration up to the optimal makespan. As an example of the scale of this,
58

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Problem
[2-5] instance
01
02
03
04
05
06
07

optimalCOLIN
makespan time (secs)
20.001
0.00
30.001
0.00
30.001
0.02
40.001
0.29
40.003
3.94
50.003
69.93
-

COLIN

makespan
20.001
34.004
38.007
44.006
48.009
62.01
66.014

time (secs)
0.01
0.01
0.01
0.01
0.02
0.03
0.03

Table 4: Comparison of makespans and solution time for airplane landing problems solved by optimalCOLIN and COLIN using the refined heuristic. Problem 7 could not be solved by
optimalCOLIN within the 1 hour bound.

on AUV problem 1, solved by COLIN, we find a plan with makespan 34.031. Careful analysis by
hand suggests that this plan cannot be improved, so is optimal. OptimalCOLIN must consider plans
of up to 34,031 steps in order to prove that this plan is optimal. This means that this problem is
completely out of the reach of optimal planning.
A similar problem arises in the Rovers domain, where the recharge action can be as little as
 long, and a series of -long recharge actions can be applied, reaching ostensibly different states,
but without making any progress. Clearly, the potential for -duration actions can arise in any
continuous temporal domain. The same problem of search-space explosion will also arise in any
temporal domain where there are orders of magnitude differences between the longest and shortest
possible actions.
However, in the Airplane-Landing and Satellite Cooling domains, there are no variable-duration
actions in these domains that can be made arbitrarily short during search. Therefore, optimalCOLIN
is in principle able to solve problems in these domains. In fact, given 4 Gb of memory and 1 hour
of runtime for each instance, it was able to solve 6 airplane landing instances, as shown in Table 4.
As the table shows, the time required to solve these problems increases very fast: problem 5 could
be solved in 3.94 seconds, problem 6 in 69.93 seconds, and problem 7 could not be solved within
the hour available. On this basis we decided it was unnecessary to extend the time available to
optimalCOLIN as it would be unlikely to cope with large instances.
Table 4 shows that COLIN sacrifices optimality for speed. This sacrifice is important, but it
does pay off in terms of time required to solve problems. COLIN is able to solve 62 of the airplane
landing problems, with no instance taking more than 33.02 seconds to solve.
We found that optimalCOLIN could report a candidate solution to the first Satellite domain instance, within 368 seconds. However, it could not prove within the time available that this solution
was optimal, so we did not include it.
12.5 Costs Associated with LP Scheduling
In the transition from CRIKEY 3 to COLIN we switch from solving an STP at each state to solving
an LP. An important issue to consider is the impact that this has on the time taken to evaluate the
59

fiC OLES , C OLES , F OX & L ONG

feasibility of the plan constructed to reach every state considered in the search. In its default mode
of operation, COLIN uses an STP to evaluate a state unless it has temporalnumeric constructs that
necessitate use of an LP. To evaluate whether or not this is appropriate (or whether always using an
LP would be faster), and to compare the overheads of STP solving with LP solving on equivalent
problems, we created a variant of COLIN that, at every state S, schedules the plan to reach S independently using three different schedulers: the original STP solver used in the standard version
of COLIN, the equivalent LP solved using CPLEX (IBM ILOG CPLEX Optimization Studio) and
the equivalent LP solved using CLP (Lougee-Heimer, 2003). The STP solver used is the incremental STP algorithm due to Cesta and Oddi (1996), as previously used in CRIKEY 3. Each of the LP
solvers is used with the tighter variable bounds described in Section 8.4. In order to evaluate the
cost associated with use of an LP instead of an STP, we modified COLIN to collect data revealing
the costs for each technique applied at each node evaluated during the search for a plan. It is not
possible to compare the performance straightforwardly, simply by running COLIN using an STP
versus COLIN with an LP, because minor variations caused by numerical accuracy can lead to very
different trajectories being followed, masking the intended comparison. As an aside, it is interesting to observe that minor (and essentially uncontrollable) differences in computed makespans for
relaxed plans can lead to significant variations in performance (relaxed plans with equal h-values
are sorted by makespan estimates for search).
As we wish to compare the STP and LP approaches, it is necessary to consider domains with
which both can reason: that is, those without continuous-numeric or duration-dependent effects. In
order to consider some problems for which scheduling is interesting and necessary (in contrast to
the temporally simple problems of Section 12.1) we consider domains with required concurrency.
Currently very few such benchmarks exist, as few planners attempt to solve such problems. We
use representatives of the only competition domains with such features: the compiled timed initial
literal domains from IPC2004, from which we use Airport (with Time Windows) and PipesNoTankage (with deadlines). We also use the Match-Lift and Driverlog Shift domains (Halsey, 2005).
For completeness, we include results for a domain in which the scheduler is not strictly necessary:
the PipesNoTankage Temporal domain from IPC2004.
Figure 19 shows the mean time spent scheduling per state, using each approach, on the problems
from the above domains. We exclude from the graph data from any problems that were solved by
the planner in less than a second, as the accuracy of the profiling data is not sufficiently reliable
to measure the time spent in each scheduler when the overall time taken is small. Since there
was no interesting variation in results between domains we present all data together across three
graphs, sorted by scheduling time per node when using CPLEX. This is intended as a nominal
analogue for how hard the scheduling problems in the given planning problem are. An increase in
the scheduling time for CPLEX generally corresponds to an increase in the scheduling time for CLP
and the STP solver, except on the easier problems where noise can be sufficient to tip the balance
as the figures are small. Note the differing y-axis scales on the three graphs, sorting problems
according to difficulty allows us to display the data with an appropriate y range to distinguish the
results. For the sake of maintaining reasonable y-axis ranges the final problem, problem 60, has
been omitted from the graphs; on this problem the figures were CPLEX 239ms, CLP 139ms and
STP 38ms.
The results in Figure 19 are, of course, not indicative of the scalability of COLIN, as it is running
three schedulers at each state, so is significantly slower than in its usual configuration. In practice, in
domains such as these with no continuous or duration dependent effects, COLIN will automatically
60

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Low Difficulty
0.4

STP
CLP
0.3 CPLEX

MST/State (ms)

0.35
0.25
0.2
0.15
0.1
0.05

1

2

3

4

5

6

7

8

9 10 11 12
Problem Number

13

14

15

16

17

18

19

20

33

34

35

36

37

38

39

40

58

59

Medium Difficulty

MST/State (ms)

1.4

STP
CLP
1.2 CPLEX
1
0.8
0.6
0.4
0.2
21

22

23

24

25

26

27

28

29 30 31 32
Problem Number
High Difficulty

40
MST/State (ms)

35
30

STP
CLP
CPLEX

25
20
15
10
5
0
41

42

43

44

45

46

47

48

49 50 51 52
Problem Number

53

54

55

56

57

Figure 19: Mean Scheduling Time (MST) per State on Temporal Planning Problems. The problem
number appears under the leftmost of the the three corresponding columns in each case.

disable the LP scheduler and use the more efficient STP solver. Further, the planner is here being
run with profiling enabled, so is subject to significant overheads.
61

fiC OLES , C OLES , F OX & L ONG

&
&
&
&
&
&

!"
#"$
# !
" '
(' )
#
)*')' +
(,#
(,
!"
#"$
(' )
(' )

!"

#"$%#

!"
2
#"$%#!"

& # !
-.# **
&
')&
( ' )/ ' - / (
0
-. 0 '
# 11

Figure 20: Time spent in various activities by each of the solvers, CPLEX and CLP, viewed as a proportion of the total time spent by CPLEX. The slice labelled MILPSolverCPX/CLP
is time spent in the destructor for the MILP solver in CPLEX or CLP: this is a housekeeping operation in the implementations (which are both written in C++).

Considering the relative performance of the STP and LP solvers, it is clear that there are overheads incurred by the necessary (for domains with continuous effects) move to using an LP rather
than an STP. The mean ratio of time spent scheduling on the same problems by CPLEX to that
spent using the STP solver is 5.81, the figure for CLP is 3.71. Analysis of the data suggests that
these ratios do not change as problem difficulty increases, rather the overhead is a constant factor
on harder problems.
Despite increased scheduling overheads it is still worth noting that solving the scheduling problem is a relatively small fraction of the cost of the reasoning done at each state. Once the plan
to a given state has been scheduled to check for feasibility the state is evaluated using the temporal RPG heuristic described in Section 9. It is well known, from analysis of the performance of
FF and other forward search planners, that the majority of search time is spent in evaluating this
heuristic. To give an indication of the relative cost of scheduling versus heuristic computation we
give an admissible estimate of the mean fraction of the time spent, per-state, running the scheduler
versus computing the heuristic. This estimate is guaranteed to overestimate the true mean because
in some states the scheduler will demonstrate that the temporal problem has no solution: in such
states the RPG heuristic will never be evaluated, so the heuristic evaluation is actually applied to
fewer states than the scheduler. Nonetheless, our data shows that, across these problems, using the
STP solver scheduling accounts for on average less than 5% of state evaluation time. For CLP and
CPLEX the figures are 13% and 18% respectively. This suggests that, although scheduling does
add some overhead to solving problems, these are relatively small compared to the cost of heuristic
computation.
A perhaps surprising observation that can be made from Figure 19 is that CLP generally solves
the scheduling problems much more efficiently than CPLEX. Given the reputation of CPLEX as a
highly efficient commercial LP solver we wanted to investigate why this is the case on our problems.
62

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

We performed a further analysis of the profiling data, breaking down the results by function call, to
observe the time spent in the various aspects of constructing and solving an LP thorough the CLP
and CPLEX library calls. The data, presented in Figure 20 shows the time spent in each function as
a fraction of the total time taken by CPLEX to schedule plans (each summed across all problems).
The not used section in the CLP data represents the time saved using CLP versus CPLEX. This
presentation means that equally sized slices of each of the pies represent the same length of time
being taken by either of the solvers in their respective methods.
The important insight that we can gain from this data is that most of the time in both of the
LP solvers is not spent in the solve function, indeed it can be observed that the search portion is
negligible: it is barely visible. The majority of time is, in fact, spent in adding rows to the LP
matrix, i.e. in adding constraints to the LP before it is actually solved. Comparing CPLEX to CLP,
it takes over 6 times longer, on average, to add a row to the matrix. The LPs being created for both
are identical, and hence involve adding the same number of rows to the matrix. The other portion
of the chart corresponds to other methods, many of which also take longer than search, but that are
again pre-processing steps such as adding new columns (variables) and setting upper bounds. Since
adding rows to the matrix is a significant portion of the time taken in constructing-then-solving the
LPs in COLIN, this results in a large overhead. The LPs created by COLIN are very small and simple
to solve, compared with the difficult industrial-sized problems for which CPLEX is designed.
Our results suggest that, in fact, the best type of LP solver to use for this task is a relatively
light-weight LP solver, with few overheads, that can create models efficiently, even if perhaps it
would not scale to other large-scale problems. The other notable, although less marked, difference
between the two LP solvers is the time spent in the destructor, called to free up the memory used
by the LP solver after each state has been evaluated. Here, it takes 23 times longer, on average,
to call the destructor for CPLEX than the destructor for CLP. This has less impact than the rowadding overheads, since the LP is only deleted once per state, rather than once per LP constraint. In
general, this would not normally be a noticeable issue when solving a single difficult LP. However,
in COLIN, where the number of LPs solved is equal to the number of states evaluated, this overhead
does become noticeable.
One interesting outcome of this study is that if, in the future, COLIN were to be extended to
non-linear continuous change, requiring the use of a mathematical programming solver at each state
(along with other research developments), the overheads may well not be prohibitive. The search
within the solver, which is where the greater overhead would occur due to this change, is in fact not
the major contributor to the time overheads of using an LP.

13. Conclusions
As the range of problems that can be solved effectively by planners grows, so does the range of
opportunities for the technology to be applied to real problems. In recent years, planning has extended to solve problems with real temporal structure, requiring temporal coordination, problems
that include metric resources and interactions between their use and the causal structure of plans.
We have shown how that range can be extended still further, to include linear continuous process
effects. Each extension of the power of planners demands several steps. The first is to model the
extension in a form that allows the relationship between the constraints imposed on plans by the
new expressiveness, and the actions that can be used to solve the problem, to be properly expressed.
The second step is to develop a means by which to represent the world state consistently, in order
63

fiC OLES , C OLES , F OX & L ONG

to characterise the space in which the search for a plan is conducted. The third step is to develop
a way to compute the progression of states using the action models in this extended representation.
Once this step is complete, it is, in principle, possible to plan: a search space can be constructed
and searched using classic simple search techniques. In practice, this process is unlikely to lead to
solutions of many interesting problems so the fourth step, in order to make the search possible in
large spaces, is to construct an informed heuristic to guide the search.
In this paper we have built on earlier work that completed the first steps, adding the third and
fourth steps that allow us to solve planning problems with continuous effects. The tools we have
used to achieve this are well-established Operations Research tools: LP solvers and their extensions
to MILP solvers. The contributions we have made are to show how these tools can be harnessed to
check consistency of states, to model state progression and to compute heuristics that can successfully guide search in the large spaces that develop for these planning problems.
An additional contribution is that we have established a collection of benchmark problems for
this direction of research in planning. The planning community has witnessed that the creation of
benchmarks and their propagation is a powerful aid in the development of the technology, supporting
clear empirical evaluation and challenging researchers to improve on the results of others. We have
shown that COLIN can solve interesting and complex problems, but there remains much room for
improvement. Apart from extending the capability of the planner by improving the informedness
of its heuristic and by improving the early pruning of dead end states, there is also the opportunity
to extend still further the range of problems that can be expressed and solved. In particular, we
are interested in problems with non-linear continuous effects, such as power and thermal curves. It
seems possible that such non-linear effects might be approached by a similar approach to that used
in COLIN, adapting a NLP solver to the same role as the LP solver in COLIN. Alternatively, it might
be possible to approximate non-linear effects with piecewise linear effects, in much the same way
that we did for the AUV domain described in this paper, but performing the process automatically.
Planning is becoming an increasingly key technology as robotic systems become more powerful
and more complex and we begin to see the limits of low level control strategies in managing the
control of these systems. Autonomy demands more powerful predictive control and it is planning
that offers possible solutions to this problem. Planning with continuous effects will be an important
tool in the collection that we can offer in tackling these new demands.

Acknowledgments

The authors wish to thank the handling editor, Malte Helmert, and the anonymous reviewers for
their considerable contributions to this paper. The authors also wish to thank members of our Planning Group for their helpful discussions during the long gestation of this work.
The authors also wish to acknowledge the EPSRC for their support of this work, specifically
through grants EP/G023360/2 and EP/H029001/2.
64

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Appendix A. Glossary
Name
a  (i, v)
a  (i, v)
Action compression

al

ce(i)
cs(i)

dec(i, v)
D
dmin (dmax)

E
eff +
x
eff 
x
eff nx
estepi

elapsed(a)

f (i)

Description
The lower bound on assignment effects on variable v due to actions at layer i in a reachability graph.
The upper bound on assignment effects on variable v due to actions at layer i in a reachability graph.
A technique for simplifying the structure of durative actions by
treating them as a simple non-durative action with the union of the
effects of both ends of the durative action and the union of their
preconditions.
Action layer in the reachability graph constructed for heuristic purposes.

First Use
62

Function returning the variable corresponding to the end time for
a snap-action at position i in the current plan.
Function returning the variable corresponding to the start time for
a snap-action at position i in the current plan.

21

Set of (discrete) decreasing effects on variable v at layer i in a
reachability graph.
The rate of change of variable v (associated with some state
achieved during the execution of a plan.
The minimum (maximum) duration of an action. We use dmin(a)
(dmax(a)) where the relevant action is required to be explicit and
dmin(a, t) (dmax(a, t)) where the value is anchored to an action
in layer al(t).

62

The event list recording action start times for durative actions
whose end points have not yet been included in a plan.
Propositional add effects of an action, where x, when present, indicates whether at the start or end of the action.
Propositional delete effects of an action, where x, when present,
indicates whether at the start or end of the action.
Numeric effects of an action, where x, when present, indicates
whether at the start or end of the action.
The name of the LP variable corresponding to the time at which a
durative action will finish, having started as the ith step in a plan,
but not having finished within the plan constructed so far.
The maximum time for which action a could have been executing
in a state that is being heuristically evaluated.

13

The variable in the STN in CRIKEY 3 that corresponds to the time
at which a currently incomplete action will eventually finish.

65

62
9

26

21

21
14

4
4
4
20

27

15

fiC OLES , C OLES , F OX & L ONG

Name
fl

Description
Fact layer in the reachability graph constructed for heuristic purposes.

First Use
26

inc(i, v)

Set of (discrete) increasing effects on variable v at layer i in a
reachability graph.
The invariants that are active in state S.

62

Left packing

A structure of plans with concurrency in which all concurrent actions start simultaneously.

39

now

The name of the variable created to represent the time at the end
of the current plan in each STP or LP used to check temporal consistency of a state.

15

hop, i , dmin, dmax i

Event record in a CRIKEY state, containing the durative action, op,
that started at step i, and the minimum and maximum duration of
the action.

14

pre a
pre 
pre `
p(a)

Conditions required to complete an action.
Invariant conditions of a durative action.
Conditions required to initiate an action.
The bound on the number of instances of durative action a that
may execute concurrently.

4
5
4
28

remaining(e)

The maximum amount of remaining time over which an action in
event record e could continue to be executing following a state
being heuristically evaluated.
Information associated with durative action a in al(t) in the reachability analysis constructed by COLIN, indicating how much time
a could continue to execute from this layer.

28

stepi

The name of the LP variable corresponding to the time at which
action ai is applied in a plan.

20

t(i)

The variable in the STP in CRIKEY 3 that represents the time at
which step i in a plan is to be executed.
The property of planning problems that require some for of concurrency in order to manage the interactions between the actions
or deadlines.
Action effects that refer to ?duration, causing numeric fluents to
change by different amounts according to the length of the action
causing the effect.

14

inv(S)

rem(t, a)

Temporal coordination

Time-dependent change

66

14

33

39

2

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Name

Description
Used to describe continuous change: for a complete account
of its use and semantics, see original discussion on its use in
PDDL 2.1 (Fox & Long, 2003).

First Use
3

ub(w, x, y)

Function used to calculate bounds on the effects of continuous numeric change.

29

v

Used to represent the vector of metric fluents associated with a
planning domain, and their values in a state. The vector is treated
as indexable: v[i] is the ith entry in v.
The vector of values of metric fluents at the start of a state, immediately following step effects of application of an action.
The vectors of lower and upper bounds on the values of the numeric variables in a state (during plan construction).

5

Symbol used to represent a vector of constants of equal dimension
to the size of the vector of metric fluents in the relevant planning
problem.

5

#t

v0
vmin , vmax

w

67

21
24

fiC OLES , C OLES , F OX & L ONG

Appendix B. The Metric Relaxed Planning Graph Heuristic
The Relaxed Planning Graph (RPG) heuristic of Metric-FF (Hoffmann, 2003) has been the most
popular numeric planning heuristic over the last decade, being widely used in many planners. The
intuition behind the heuristic is to generalise the delete-relaxation to include numeric variables.
In the case of propositions, the relaxation is to simply ignore propositional delete effects so, as
(relaxed) actions are applied, the set of true propositions is non-decreasing. In the case of numbers,
the relaxation replaces exact assignments to numeric variables with bound constraints for their upper
and lower bounds. Applying relaxed actions extends the bounds by reducing lower bounds with
decrease effects and increasing upper bounds with increase effects. Checking whether a numeric
precondition is satisfied is then simply a matter of testing whether the constraint is satisfied by some
value within the bounds. The delete-relaxed problem can be solved (non-optimally) in polynomial
time, and the number of actions in the resulting relaxed plan can then be taken as a heuristic estimate
of the distance from the evaluated state to the goal.
The purpose of the RPG is to support this heuristic computation. Relaxed planning is undertaken
in two phases: graph expansion, and solution extraction. In the graph expansion phase the purpose
is to build an RPG, identifying which facts and actions become reachable. The RPG consists of
alternate fact layers, consisting of propositions that can hold and optimistic bounds on v, and action
layers, containing actions whose preconditions are satisfied in the preceding fact layer. In the case
of propositional preconditions, a precondition is satisfied if the relevant fact is contained in the
previous layer. In the case of numeric preconditions, these are satisfied if some assignment of the
variables appearing in the precondition, consistent with the upper and lower bounds, lead to it being
satisfied. We define the function ub(w, x, y) as:
X  w[j]  y[j] if w[j]  0
ub(w, x, y) =
w[j]  x[j] otherwise
w[j]w

(this is the same function as is defined in Section 9.2).
Then, denoting a fact layer i as a set of propositions, f l(i), and upper and lower variable bounds
(vmin (i), vmax (i)), a precondition w  v  c of an action in layer i is considered true iff:
ub(w, vmin (i), vmax (i))  c
To seed graph construction, fact layer 0 contains all facts that are true in S. Thus, action layer
0 consists of all actions whose preconditions are satisfied in fact layer 0. Fact layer 1 is then set to
be the optimistic outcome of taking fact layer 0, and applying each of the actions in action layer 0.
More formally, considering propositions, applying the actions in action layer i, i.e. the actions al(i)
leads to a fact layer i + 1 where:
f l(i + 1) = f l(i)  {eff + (a) | a  al(i)}
Considering numbers, in action layer i the set of optimistic increase and decrease effects on a
variable v across all actions are, respectively:
inc(i, v) = {(ub(w, vmin (i), vmax (i)) + c) > 0 | a  al(i) s.t. hv, +=, w  v + ci  eff n (a)}
dec(i, v) = {(ub(w, vmax (i), vmin (i)) + c) < 0 | a  al(i) s.t. hv, +=, w  v + ci  eff n (a)}
68

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

The exchange of the minimum and maximum bounds for v in these two expressions is important:
it causes each expression to be as extreme as possible in the appropriate direction. Similarly, the
optimistic upper and lower bounds on v, following all available assignment effects, are:
a  (i, v) = max{(ub(w, vmin (i), vmax (i)) + c) | a  al(i) s.t.hv, =, w  v + ci  eff n (a)}
a  (i, v) = min{(ub(w, vmax (i), vmin (i)) + c) | a  al(i) s.t.hv, =, w  v + ci  eff n (a)}
The new bounds then become:
vmax (i + 1)[j] = max{a  (i, v[j]), vmax (i)[j] +
vmin (i + 1)[j] = min{a  (i, v[j]), vmin (i)[j] +

X

X

inc(i, v[j])}

dec(i, v[j])}

That is, to find the upper (lower) bounds of v[j] at the next layer, for each we have a choice of
applying the largest (smallest) single assignment effect, or the sum of all increase (decrease) effects. Having computed the bounds of all variables in layer i + 1, graph expansion then continues
iteratively, finding actions applicable in action layer i + 1, and hence the facts in layer i + 2, and
so on. Graph expansion terminates in one of two cases: either a fact layer satisfies all propositional
and numeric goals, or the addition of further layers would never lead to more preconditions being
satisfied  a condition signalled when no new propositions are appearing and the accumulation of
larger or smaller bounds on variables would not lead to any more numeric preconditions becoming
satisfied. In this case, the relaxed problem cannot be solved and hence, in the original problem, no
plan starting from S can reach G. The heuristic value of the state is then set to .
Assuming graph expansion terminates with all goals reached, the second phase is to extract a
solution from the planning graph. This is a recursive procedure, regressing from the goals back to
the initial fact layer. Each fact layer is augmented with a set of goals (facts or numeric preconditions)
that are to be achieved at that layer. Beginning by inserting the top-level goals G into the planning
graph at the first layers at which they each appeared, solution extraction repeatedly picks the latest
outstanding goal in the planning graph and selects a way to achieve it. For propositional goals, a
single action (with an effect adding the goal) is chosen, and its preconditions are inserted as goals
to be achieved (again, at the earliest possible layers). To satisfy the numeric goal w  v  c at layer
i, actions with effects acting upon the variables (with non-zero coefficients) in v are chosen, until
the net increase of w  v, k, is sufficient to allow the residual precondition w  v  c  k to be
satisfied at fact layer i  1. At this point, this residual precondition is added as a goal to be achieved
at layer i  1 (or earlier if possible), and the preconditions of all the actions chosen to support this
precondition are added as goals to be achieved at previous layers.
Solution extraction terminates when all outstanding goals are to be achieved in fact layer 0, since
they are then true in the state being evaluated and need no supporting actions. The actions selected
in solution extraction form the relaxed plan from S to the goal. The length (number of actions) of
this relaxed plan forms the heuristic estimate, h(S). Additionally, the actions in the relaxed plan
that were chosen from action layer 0 form the basis of the helpful actions in S, used to restrict
the states explored by enforced hill-climbing search: any action with an effect in common with the
actions chosen from action layer 0 is considered to be helpful.
69

fiC OLES , C OLES , F OX & L ONG

Appendix C. Temporal Reasoning in Relaxed Planning Graphs
Several approaches have been proposed for building temporal relaxed planning graphs (TRPGs).
There are three additional features that TRPGs can attempt to manage, compared with RPGs:
1. The temporal structure of durative actions: aa can only be applied if a` has been applied
before it.
2. Action durations: end effects of actions are only available at an appropriate delay after they
have started.
3. The PDDL 2.1 startend semantics, allowing effects and preconditions to be attached to both
the starts and ends of actions.
The TRPG employed in Sapa (Do & Kambhampati, 2003) satisfies the first two of these, but
not the third. In Sapa, each action is compressed into a temporally-extended action obeying the
TGP semantics, before discarding delete effects, as a relaxation, and building a TGP -style planning
graph (Smith & Weld, 1999). The use of compression and a time-stamped TGP representation
captures durations and the start-before-end relationships, but the use of compression causes the
heuristic to find false dead-ends in cases where there is required concurrency.
The TRGP used in CRIKEY (Coles, Fox, Halsey et al., 2008) avoids action compression, but
it ignores the durations of actions. A non-temporal RPG is built in terms of the snap-actions used
during search, with an additional precondition on each end snap-action that a particular dummy fact,
added by its corresponding start, has appeared in the preceding fact layer. The use of snap-actions
means no preconditions or effects are lost (ensuring that the heuristic no longer identifies the false
dead-ends created by the approach used in Sapa), but the limitation of the heuristic is that there is
no forced separation between the start and and end of an action, but only an ordering constraint.
In CRIKEY 3 (Coles, Fox, Long et al., 2008a), the heuristic is constructed to combine the
strengths of both of these earlier heuristics, accounting for the durations of actions, whilst also
respecting the startend semantics. We now briefly describe the construction of this TRPG, since it
is the basis for the heuristic used in COLIN. The structure of the TRPG is similar to that constructed
in Metric-FF, but instead of each fact layer being assigned an index, it is assigned a time-stamp
(indicating the minimum amount of time that must pass after the initial layer before the facts in the
layer in question can appear). To capture the durations of actions, we record, for each end action aa ,
the earliest layer tmin (aa ) at which it can appear. This value is set to 0 for all actions that are already
executing in the state being evaluated (as there is no need to first insert the start of the action into
the RPG). For other actions, the value is initialised to , before commencing TRPG construction.
To build a TRPG we follow Algorithm 2. First, a number of initialisation steps are performed.
The time-zero fact layer fl (0) is initialised (at line 1) to contain all the facts true in S 10 . The set
ea is initialised to contain all the end snap-actions that must appear in the TRPG  if an action is
executing, its end has to be reachable (i.e. appear in the TRPG), or else the state S is a dead end.
If ea is empty, and S satisfies the goals G (line 14), then no TRPG need be built, since the plan is
complete.
Following initialisation, the TRPG is expanded, beginning with t = 0 and using the fact layer
f l(t) to determine the action layer al(t). If the preconditions of an action are satisfied in a fact layer
10. For simplicity we omit the handling of numeric fluents from this explanation  this is performed exactly as in the
earlier description of the RPG heuristic implemented in Metric-FF.

70

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Algorithm 2: Building a Temporal RPG in CRIKEY 3.
Data: S = hF, E, T i - state to be evaluated
Result: R = hfls, alsi, a relaxed planning graph
1 fl (0)  F ;
2 fls  hfl (0)i;
3 als  h i;
4 t  0;
5 ea  ;
6 prev al  ;
7 prev fl  fl (0);
8 foreach aa do
9
if {e  E | e.op = a} =  then
10
tmin (aa )  ;
11
else
12
tmin (aa )  0;
13
ea  ea  {aa };
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37

if G  fl (0)  ea =  then return S is a goal state;
while t <  do
fl (t + )  prev fl ;
al (t)  {aa | pre(aa )  fl (t)  tmin (aa )  t};
foreach aa  al (t)  prev al do
fl (t + )  fl (t + )  eff + (aa );
al (t)  al (t)  {a` | pre(a` )  fl (t)};
foreach a`  al (t)  prev al do
fl (t + )  fl (t + )  eff + (a` );
tmin (aa ) = min[tmin (aa ), t + dmin(a)];
als  als + al (t);
fls  fls + fls(t + );
prev al  al (t);
if G  fl (t + )  ea  al (t) then
return R = hfls, alsi;
if prev fl 6= fl (t + ) then
prev fl  fl (t + );
t  t + ;
else
prev fl  fl (t + );
ep = {tmin (aa ) | pre(aa )  fl (t)  tmin (aa ) > t};
if ep 6=  then t  min[ep];
else t  ;
return S is a dead end;

71

fiC OLES , C OLES , F OX & L ONG

fl (t) then whether it can appear in al (t) depends on whether it is a start or end snap-action. The
first and simpler case (line 20) is that, if a start snap-action a` is applicable, it is added to al (t)
and tmin (aa ) is set to t + dmin(a), where dmin(a) is an a priori lower bound on the duration of
a. If there is a state-independent measure of the minimum duration of a, i.e. a minimum duration
constraint referring only to constants, then this is taken as the value of dmin(a). Otherwise, if
all the minimum duration constraints depends on the state in which the action is applied, then
dmin(a) = : all that is certain is that some time must elapse between the start and the end of the
action. The state-dependent terms cannot be evaluated since the TRPG determines a relaxed state,
not a real state.
The second case, covering end snap-actions, is that if the preconditions of an end action aa
become satisfied in a fact layer fl (t), then addition of aa to al (t) depends on whether the start of
the action can have occurred sufficiently far in the past (line 17). If t  tmin (aa ) then aa is added
to al(t); if t < tmin (aa ) < , then aa is postponed until al(tmin (aa )); otherwise, the start of the
action has yet to appear, and aa is postponed until the relevant start appears.
Having determined which actions newly appear in al (t), the fact layer fl (t + ) is updated as
in the non-temporal RPG case, by taking fl (t) and (optimistically) applying the effects of all the
actions in al (t). If f l(t + ) and al(t) do not contain the necessary goals and end snap-actions
(line 27) then it must be decided which fact layer to consider next. Clearly, it is infeasible to create
new fact layers at  spacing between fl (0) and the fact layer at which the goals appear. Fortunately,
it is also unnecessary, as many of the fact and action layers in such a graph would be identical.
Instead, we determine the next fact layer to consider as follows:
 If there are new facts in fl (t+) that were not true in fl (t) (line 29), the next layer to expand is
fl (t + )  the appearance of new and potentially useful facts makes it necessary to consider
whether any actions become applicable in that layer.
 If fl (t + ) = fl (t), then we know that visiting fl (t + ) is futile. In this case (line 34), the
time-stamp of the next fact layer to visit is the earliest future point at which the postponed
end of an action becomes applicable:
min{tmin (aa ) | pre(aa )  f l(t)  tmin (aa ) > t}
If the minimum of these values is  (or undefined) then the state can be pruned and the
procedure exits early, signalling the result to the search procedure.
When a TRPG is successfully constructed (that is, if the starting state is not a dead end) the graph
that is returned contains a finite set of fact and action layers, each associated with a real time value.
Assuming graph expansion terminates with all goals reached, a relaxed solution is extracted.
The solution extraction procedure used in Metric-FF needs one minor modification to be suitable
for use in a TRPG: if the end of an action aa is chosen to support a goal at a given fact layer, then if
the action a is not already executing in the state being evaluated, the corresponding start a` must be
scheduled for selection (at the layer in which it first appeared). The purpose of this corresponds to
that of the dummy facts in CRIKEY: if the end of an action is chosen, its start must also be executed.
As a final remark on this TRPG, timed initial literals (TILs) can be included by employing the
machinery introduced to delay the ends of actions until an appropriate layer. If the dummy TIL
actions {TILj ...TILm } have yet to be applied then tmin (TILj ) = 0.0, since TILj could be applied
in the first action layer. The intuition here is that the state being evaluated is a snapshot of the world,
72

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

taken no earlier than after the end of the previous action, but no later than the point at which the
next TIL event occurs (due to the constraints discussed in Section 6.1). The minimum timestamps
for the later TILs, each TILk  {TILj+1 ...TILm }, are then set relative to this time point:
tmin (TILk ) = ts(TILk )  ts(TILj ).

Appendix D. Post-Hoc Plan Optimisation
This appendix contains details of the MILP construction briefly described in Section 10.2.
D.1 Optimising for Time Windows
First let us consider the simple case where an action do has a conditional effect on a metric-tracking
variable reward (where the objective of the problem is to maximise reward), and where the effect
occurs depends on the truth value of a single proposition p at some time specifier ts relative to the
action do (either at start, over all, or at end):
(when (ts (p)) (at end (increase (reward) k))).
In the case where p can be manipulated by actions, without allowing the MILP to introduce new
actions or completely change the order of the plan steps (with all the complexity these modifications
would entail), there is little scope for optimisation. In the case where the truth value of p is dictated
by timed initial literals (TILs), we have a more interesting case: changing the time-stamps of the
start or the end of a (LP variables step i and step j ), so that the condition is or is not satisfied, has
a direct effect on the metric function. This relationship can be encoded within the LP. By way of
example, consider the case where p becomes true at time a and false at b; then, again, becomes
true at c and false at d. In this case, we have two time-windows that could potentially satisfy the
condition on the effect. Whether the action has to wholly or only partially within one of these
windows depends on the time-specifier attached to p:
 if ts =at start, then a` (step i ) has to lie within one of the time windows;
 if ts =at end, then aa (step j ) has to lie within one of the time windows;
 otherwise, ts =over all, and both a` and aa have to lie within one of the time windows.
In all three cases, the question that must be answered is does the value of this variable lie within
a known range?  the over all case requires a conjunction of two such conditions to hold and,
in the other two cases, only one has to hold. For a given step variable step i , and time window (a, b),
we can introduce into the (MI)LP a binary variable switch ab corresponding to such an observation,
with constraints that take the logical form:
switch ab  (step i > a)  (step i < b)
Thus, if the switch variable takes the value 1, the time-stamp of a point at which p is needed must
fall within the time-window [a, b] and vice versa. By introducing two additional binary variables,
denoted ga and lb, this logical constraint can be represented as a series of inequalities (using N to
73

fiC OLES , C OLES , F OX & L ONG

denote a large number):
step i  (a + )  switch ab
step i + (b  )  switch ab
step i + N  ga
step i  N  lb
switch ab  ga  lb







0
0
a
b
1

The first two constraints encode the forwards implication: if switch ab is set to 1, then step i has
to lie in the range [a + , b  ] (a non-zero amount of separation, here epsilon, is needed under
the PDDL semantics to avoid inspecting the value of p at the same time it is being changed by the
TIL). The latter three constraints encode the reverse implication: if step i is strictly greater than a
and strictly less than b, then both of ga and lb have to hold the value 1 and thus, so does switch ab .
Returning to our example, where the time specifier is over all, and the windows are (a, b)
and (c, d), the constraints that will be added are:
switch ab1
switch ab2
switch ab
switch cd1
switch cd2
switch cd
switch p









(step i > a)  (step i < b)
(step j > a)  (step j < b)
(switch ab1  switch ab2 )
(step i > c)  (step i < d)
(step j > c)  (step j < d)
(switch cd1  switch cd2 )
(switch ab  switch cd )

That is, switch ab is 1 if the entirety of the action do falls within (a, b), switch cd is 1 if it falls
within (c, d) and switch p is 1 if either of these hold. This final switch variable is used to capture
the benefit of the effect itself: if it holds the value 1, we increase the value of reward at the end of
the plan by k, that is, we apply the conditional effect. The variable reward will already appear in
the objective function in the form of the LP variable reward 0n , where n is the last step of the plan.
Thus, we modify the constraints that define reward 0n so that k  switch p is added to this value. This
change will then ensure that the variable providing the value of reward in the objective function
will include the reward of k if the condition on the time at which do was executed holds.
Generalising, we can extend this to the case where the conditional effect depends on the truth
of a formula f consisting of a conjunction of time-specified propositional facts [(ts1 p1 )...(tsj pj )].
For each (tsi pi )  f , we create constraints, as indicated above, so that the switch variable switch pi
can only take the value 1 if pi holds at the time-specifier tsi . This gives us a list of switch variables
s = [switch p1 ...switch pj ]. Then, to encode that in fact the conjunction f must hold, we create a
variable switch f and add the constraints:
j  switch f + 1.switch p1 + ... + 1.switch pj  0
switch f + 1.switch p1 + ... + 1.switch pj  1  j
Defined thus, switch f takes the value of 1 iff each of the switch variables in s takes the value 1,
which is precisely in the case that the conjunct is satisfied. Then, much as before, when updating
the constraint dictating the value of the LP variable reward 0n , we add k  switch f to this value.
D.2 Optimising Numeric-Dependent Conditions
Perhaps more complex than the case of time windows is where the conditions of a conditional effect
depend on the values of the numeric variables in the domain. (The PDDL 2.2 definition (Hoffmann
74

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

& Edelkamp, 2005) does not include the case where TILs change the values of numeric variables11 ,
so we do not consider that case here.) In the simple case, the time-specifier of all the numeric
conditions is either at start or at end. More complicated is the case where one or more of the
time-specifiers is over all. In this case, potentially, all the snap-actions in the plan, between the
start and end of the action to which the condition belongs, could affect whether or not the condition
associated with the effect is met. We must therefore check the status of the condition at each such
point during execution of the action. Suppose we have an action O, where stepk and stepl are the
variables denoting the start and end time-stamps of the action, and where O has a conditional effect
with a numeric precondition in LNF:
when (over all (>= (w  v) c)) (at end (increase (reward) k)).
To encode this, we need to add constraints to ensure that this conditional outcome occurs iff w 
v  c at all times within O. Since all change is linear, then (as with other over all conditions on
O) we only need to check the values of the numeric variables immediately before and immediately
after each action time step within O, and also immediately following the start and immediately
before the end of O itself. Thus, the variables corresponding to values of v that we must examine
are those in the list:
0
0
, vl ].
, ..., vl1 , vl1
e = [vk0 , vk+1 , vk+1
As stated earlier, the case of at start/at end conditions is somewhat easier: for at start,
e = [vk ], and for at end, e = [vl ]. Irrespective of the time specifier, on the basis of this list e,
to capture whether the condition is met, adding a switch variable switch to indicate whether the
condition is met for all vectors, and switch variables [switch t1 ...switch tn ] for each element [1..s] of
the list e, indicating whether it is met for that single vector. The constraints over these (where  is a
small number) are then:


w.e[x]  N + (N + c)  switch

x[1...s]



w.e[x]  (c  ) + N  switch tx

x[1...s]

s  switch + 1.switch t0 + ... + 1.switch ts  1  s.
The first quantification ensures that if switch = 1, a lower bound of c is imposed on w  v for
each element of e. The second quantification ensures that if the vector v at index x in e satisfies
w  v  c, then the corresponding switch variable switch tx has to take the value 1. The third
constraint ensures that if all such switch variables switch tx take the value 1, switch must, too, be set
to 1. Having appropriately constrained the switch variable we can update the constraint governing
the value of the LP variable reward 0n (the value of reward at the end of the plan) to increase it by
the value of k  switch.
D.3 Optimising Time-Dependent Conditions
The final extension is to allow conditional effects to refer not only to the truth values of timed
propositions, or the values of numeric variables, but also to the value of the duration of an action.
11. Timed Initial Fluents have been used in some domain models, as an unofficial extension to the language. The
semantics of such an extension are as straightforward as Timed Initial Literals.

75

fiC OLES , C OLES , F OX & L ONG

This situation appears in our example airplane landing problem (Section 10.2) where the value
(total-cost) is updated by a conditional effect, of which both the condition and the effect depend
on ?duration. We will consider this example in order to show how the MILP can be extended to
handle such updates. First, as in the previous cases, we need to add constraints to ensure that if the
MILP solver chooses to obtain the conditioned outcome of a conditioned effect, then the condition
must be met. So, for the example, we introduce a new variable binary switch variable for each
condition, and some new constraints. For the land action for a plane ?p, starting and finishing at
time-stamps action as step n and step m respectively, we add a pair of constrained switch variables.
For the sake of this example we give these the meaningful names early and late. The constraints
that are added to the LP are then:
target p  step m + step n
step m  step n
target p + step m  step n
step m  step n






N  early
N  (N +   target p)  early
N  late
(target p + )  late

These new constraints ensure that if the plane lands early, the variable early has to take the value
1, and vice versa. Similarly, if it lands late, late must take the value 1 and vice versa. In the case of
our example, the conditional effects of the action are mutually exclusive, though this is not true in
the general case.
Having defined the early and late switch variables, the objective function for the MILP must be
augmented to reflect the conditional outcomes of the action. Two terms must be added  one for
each switch variable  for the effect obtained if the switch variable is 1. Abbreviating the terms
earlyPenaltyRate, latePenaltyRate and latePenalty to epr, lpr and lp, respectively,
the objective terms for plane p are:
early  (epr p)  (target p  (step m  step n ))
late  (lpr p)  ((step m  step n )  target p) + late  (lp p)
Note that unlike in the previous cases, this objective function is now quadratic: the objective
contains terms where a switch variable is multiplied by both a constant and a step variable. This
arises as, unlike in previous cases, the conditional effect is duration dependent  not a fixed, constant value k. Whilst this raises the computational cost of optimising the MILP, the cost is acceptable: it is only incurred once, after a solution plan has been found.

Appendix E. Details of Empirical Evaluation of Colin
The graphs presented here show the detailed runtime and quality comparisons analysed in Section 12. The comparative data is graphed. Since the graphs sometimes superimpose curves over one
another, making it difficult to see how COLIN is performing, Tables 613 show the raw time and
quality results for COLIN compared with average and best times and qualities for all problems. Best
times and qualities are also reported with the corresponding quality or time (respectively) for that
solution, and the planner(s) that generated the best result.

76

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Depots Simple Time
1000

100

100

10

Time (s)

Time (s)

Driverlog Simple Time
1000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

1

1

0.1

0.1

0.01

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

0.01
5

10
Problem Number

15

20

2

4

6

Rovers Simple Time
100

10

Time (s)

Time (s)

10
12
Problem Number

14

16

18

20

14

16

18

20

Satellite Simple Time
100

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

8

1

0.1

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

1

0.1

0.01

0.01
2

4

6

8

10
12
Problem Number

14

16

18

20

14

16

18

20

2

4

6

8

10
12
Problem Number

Zeno Simple Time
10000

1000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

Time (s)

100

10

1

0.1

0.01
2

4

6

8

10
12
Problem Number

Figure 21: Comparison of time taken to solve problems in various simple temporal planning benchmarks by the planners COLIN, LPG-td, LPG.s, Sapa and a temporal baseline planner.
Planners not appearing in a particular dataset did not solve any of the problems in that
collection.

77

fiC OLES , C OLES , F OX & L ONG

Depots Simple Time
600

Driverlog Simple Time
3000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

500

2500

2000
Makespan

400
Makespan

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

300

1500

200

1000

100

500

0

0
5

10
Problem Number

15

20

2

4

6

Rovers Simple Time
400

400

250

Makespan

Makespan

300

10
12
Problem Number

14

16

18

20

14

16

18

20

Satellite Simple Time
500

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

350

8

200
150

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

300

200

100
100
50
0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

14

16

18

20

2

4

6

8

10
12
Problem Number

Zeno Simple Time
7000
6000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

Makespan

5000
4000
3000
2000
1000
0
2

4

6

8

10
12
Problem Number

Figure 22: Comparison of plan quality in problems in various simple temporal planning benchmarks by the planners COLIN, LPG-td, LPG.s, Sapa and a temporal baseline planner.
Planners not appearing in a particular dataset did not solve any of the problems in that
collection.

78

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Depots Time
100

Driverlog Time
10000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

1000

Time (s)

Time (s)

100

1

10

1
0.1
0.1

0.01

0.01
5

10
Problem Number

15

20

2

4

6

8

Rovers Time
100

14

16

18

20

14

16

18

20

Satellite Time
1000

Colin
LPG-TD
LPG.s
Sapa

100

Time (s)

10

Time (s)

10
12
Problem Number

1

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

1
0.1
0.1

0.01

0.01
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

8

10
12
Problem Number

Figure 23: Comparison of time taken to solve problems in more complex temporal planning benchmarks (first set) by the planners COLIN, LPG-td, LPG.s, Sapa and a temporal baseline
planner. Planners not appearing in a particular dataset did not solve any of the problems
in that collection.

79

fiC OLES , C OLES , F OX & L ONG

Zeno Time
1000

Airport Strips Temporal
1000

Colin
LPG-TD
LPG.s
Sapa

100

100

Time (s)

10

Time (s)

Colin
LPG-TD
LPG.s
Temp-Baseline

10

1

1

0.1

0.1

0.01

0.01
2

4

6

8

10
12
Problem Number

14

16

18

20

5

10

15

Pipes No-Tankage Temporal
10000

1000

35

40

45

50

35

40

45

50

Pipes Tankage Temporal
10000

Colin
LPG-TD
LPG.s
Temp-Baseline

1000

Colin
LPG-TD
LPG.s
Temp-Baseline

100
Time (s)

100
Time (s)

20
25
30
Problem Number

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20
25
30
Problem Number

35

40

45

50

5

10

15

20
25
30
Problem Number

Figure 24: Comparison of time taken to solve problems in more complex temporal planning benchmarks (second set) by the planners COLIN, LPG-td, LPG.s, Sapa and a temporal baseline
planner. Planners not appearing in a particular dataset did not solve any of the problems
in that collection.

80

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Depots Time
2000

Driverlog Time

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

1500

7000
6000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

Makespan

Makespan

5000

1000

4000
3000
2000

500

1000
0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

8

Rovers Time
800

1400

600

1200

500

1000

Makespan

Makespan

14

16

18

20

14

16

18

20

Satellite Time
1600

Colin
LPG-TD
LPG.s
Sapa

700

10
12
Problem Number

400

800

300

600

200

400

100

200

0

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

0
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

8

10
12
Problem Number

Figure 25: Comparison of plan quality in more complex temporal planning benchmarks (first set)
by the planners COLIN, LPG-td, LPG.s, Sapa and a temporal baseline planner. Planners
not appearing in a particular dataset did not solve any of the problems in that collection.

81

fiC OLES , C OLES , F OX & L ONG

Zeno Time
400

Airport Strips Temporal
1000

Colin
LPG-TD
LPG.s
Sapa

350

800

Colin
LPG-TD
LPG.s
Temp-Baseline

250

Makespan

Makespan

300

200
150

600

400

100
200
50
0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

5

10

15

Pipes No-Tankage Temporal
140
120

35

40

45

50

35

40

45

50

Pipes Tankage Temporal

Colin
LPG-TD
LPG.s
Temp-Baseline

140
120

Colin
LPG-TD
LPG.s
Temp-Baseline

100
Makespan

100
Makespan

20
25
30
Problem Number

80
60

80
60

40

40

20

20

0

0
5

10

15

20
25
30
Problem Number

35

40

45

50

5

10

15

20
25
30
Problem Number

Figure 26: Comparison of plan quality in more complex temporal planning benchmarks (second
set) by the planners COLIN, LPG-td, LPG.s, Sapa and a temporal baseline planner. Planners not appearing in a particular dataset did not solve any of the problems in that collection.

82

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

COLIN

Time
Quality
depotssimpletime
1
0.03
36.008
2
0.03
54.013
3
13.69 170.037
4
11.67
82.031
5
6
7
2.56
51.024
8
9
10
1.39
90.025
11
12
13
0.17
85.026
14
15
16
0.25
99.025
17
0.48
61.016
18
19
20
21
1.69
96.029
22
driverlogsimpletime
1
0.02
92.006
2
0.16
169.021
3
0.04
67.012
4
0.25
129.018
5
0.11
106.017
6
0.09
114.011
7
0.05
58.011
8
0.19
151.023
9
0.42
213.026
10
0.04
84.021
11
0.04
108.019
12
3.22
380.041
13
1.09
283.039
14
1.45
240.036
15
0.25
283.043
16
17
18
19
20

Average
Time
Quality

Best
Time

Planner

Quality

Planner

LPG -td,TBL

28.000 (0.0)
46.090 (0.374)
80.002 (0.11)
56.24 (0.42)
115.000 (0.11)
156.004 (205.29)
45.001 (0.11)
87.003 (0.48)
190.000 (0.29)
52.000 (0.05)
152.000 (0.26)
133.000 (0.62)
64.001 (0.33)
64.001 (0.96)
186.000 (0.45)
46.000 (0.08)
28.050 (10.728)
105.000 (1.04)
94.000 (0.19)
101.002 (27.84)
73.000 (0.56)
329.007 (111.46)

LPG -s+td

91.001 (0.04)
104.001 (0.03)
40.02 (0.116)
99.001 (0.02)
75.08 (0.957)
64.070 (0.963)
49.090 (0.3)
77.090 (0.869)
150.002 (0.13)
49.090 (0.404)
85.090 (0.474)
274.3 (0.05)
240.003 (0.76)
163.22 (4.388)
157.210 (13.457)
1510.000 (50.78)
653.008 (16.28)
361.67 (79.06)
1478.000 (47.08)
478.000 (6.19)

LPG -s

0.040
0.097
3.462
3.097
1.620
103.400
0.677
0.223
0.625
4.100
7.933
5.880
0.475
0.400
2.655
0.928
2.716
3.217
0.517
10.443
17.448
54.667

34.834
64.243
110.817
74.818
131.250
171.002
59.049
95.784
213.300
81.465
212.845
188.251
79.265
83.767
212.502
85.273
55.261
109.144
118.787
238.291
85.872
406.609

0.0 (28.000)
0.01 (54.11)
0.02 (82.000)
0.04 (88.000)
0.11 (115.000)
1.51 (186.000)
0.01 (82.17)
0.09 (105.000)
0.29 (190.000)
0.03 (88.2)
0.26 (152.000)
0.62 (133.000)
0.02 (82.17)
0.1 (107.3)
0.45 (186.000)
0.04 (98.18)
0.23 (61.000)
1.03 (117.43)
0.14 (164.36)
0.75 (209.000)
0.19 (90.18)
8.95 (536.000)

0.024
0.166
0.039
0.150
0.223
0.241
0.086
0.238
0.301
0.131
0.153
1.012
0.650
1.790
3.299
112.980
7.133
64.420
47.080
6.190

96.025
127.460
59.215
112.460
92.054
93.031
63.838
153.071
204.692
93.645
104.058
339.586
274.338
291.536
278.920
1849.014
790.049
644.560
1478.000
478.000

0.0 (91.05)
0.01 (110.19)
0.01 (40.04)
0.01 (110.15)
0.01 (83.17)
0.02 (74.000)
0.01 (51.09)
0.01 (167.24)
0.04 (232.26)
0.01 (71.11)
0.01 (119.18)
0.05 (274.3)
0.31 (299.000)
0.24 (391.000)
0.14 (278.34)
50.78 (1510.000)
1.86 (1052.000)
21.03 (869.000)
47.08 (1478.000)
6.19 (478.000)

TBL
LPG -td
LPG -td
LPG -td
LPG -td
TBL
LPG -td
LPG -td
TBL
LPG -td
LPG -td
TBL
TBL
LPG -td
TBL
LPG -td
TBL
TBL
LPG -td
TBL
LPG -td
TBL
LPG -td,TBL
LPG -s,TBL

TBL
LPG -td,TBL
LPG -td
TBL
TBL
LPG -td,TBL
TBL
TBL
TBL
LPG -td
LPG -td
TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

Sapa
LPG -s

TBL
LPG -td
LPG -s
LPG -s
LPG -s
LPG -td
LPG -td
LPG -td
LPG -td
LPG -s
LPG -s
LPG -td
LPG -td

Sapa
LPG -td
LPG -td
LPG -s
LPG -td
LPG -s

LPG -s

Sapa
LPG -s

Sapa
Sapa
Sapa
Sapa
LPG -s
Sapa
Sapa
TBL
LPG -s
Sapa
Sapa
LPG -td
LPG -s
TBL
LPG -td
LPG -td

Table 6: Results for Simple Domains: Best results show best time (corresponding quality) and
which planner(s) achieved this time and best quality (corresponding time) and planner(s)
achieving this quality. TBL is the Temporal Baseline planner in this and following tables.

83

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
Quality
roverssimpletime
1
0.02
67.007
2
0.02
48.006
3
0.02
73.01
4
0.02
50.005
5
0.04
126.014
6
0.09
186.028
7
0.04
107.013
8
0.06
119.018
9
0.09
176.028
10
0.11
155.019
11
0.11
161.025
12
0.05
103.014
13
0.22
198.029
14
0.12
170.021
15
0.21
208.038
16
0.26
203.032
17
0.23
267.036
18
0.49
217.039
19
0.72
339.047
20
9.51
392.063
satellitesimpletime
1
0.01
41.008
2
0.01
65.012
3
0.02
50.01
4
0.04
87.019
5
0.05
74.016
6
0.07
72.019
7
0.09
72.022
8
0.14
84.024
9
0.21
95.028
10
0.26
101.029
11
0.37
113.031
12
2.49
137.041
13
13.38 214.061
14
5.11
166.039
15
6.47
183.056
16
5.78
170.045
17
4.52
133.041
18
0.82
107.031
19
27.98 349.075
20

Average
Time
Quality

Best
Time

Planner

Quality

Planner

TBL
TBL
LPG -td
TBL
LPG -td,TBL
LPG -td
TBL
TBL
LPG -td,TBL
TBL
TBL
TBL
TBL
TBL
TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

67.007 (0.02)
45.000 (0.02)
67.089993 (0.15)
45.039997 (0.081)
107.15 (0.01)
183.29 (0.02)
91.001 (0.04)
113.19 (0.02)
156.18999 (0.508)
139.14 (25.24)
161.025 (0.11)
88.08 (1.035)
173.17998 (6.716)
139.000 (0.04)
175.21999 (2.776)
186.20998 (6.67)
218.22993 (9.01)
140.28 (0.15)
297.5 (0.38)
351.000 (0.49)

COLIN

TBL

41.000 (0.01)
65.000 (0.02)
29.000 (0.02)
58.000 (0.01)
61.001 (0.09)
58.09 (0.01)
46.001 (0.13)
41.000 (0.03)
51.001 (0.33)
63.000 (0.05)
72.000 (0.07)
98.000 (0.11)
99.002 (2.75)
68.000 (0.13)
58.001 (2.54)
73.002 (4.12)
92.002 (4.29)
75.002 (1.42)
114.003 (2.57)
137.24 (31.225)

0.032
0.030
0.040
0.030
0.220
0.058
0.146
0.247
0.148
5.110
0.085
0.253
1.565
0.239
0.671
1.464
1.992
2.158
1.058
4.317

72.834
48.223
76.238
51.621
131.461
229.580
97.851
131.066
166.296
158.878
179.322
112.041
227.708
157.483
207.310
208.513
255.936
170.494
319.138
380.932

0.0 (67.08)
0.01 (47.06)
0.0 (77.000)
0.01 (50.06)
0.01 (107.15)
0.01 (277.000)
0.01 (98.13)
0.02 (113.19)
0.02 (159.000)
0.02 (141.23)
0.02 (185.26)
0.01 (90.11)
0.06 (190.33)
0.02 (145.22)
0.04 (215.29)
0.04 (242.000)
0.11 (259.000)
0.1 (160.000)
0.23 (319.000)
0.49 (351.000)

0.022
0.042
0.049
0.080
0.103
0.128
0.179
0.266
0.517
0.563
0.806
2.183
8.604
4.859
10.845
13.916
16.070
2.084
9.740
9.739

43.032
66.310
45.040
78.268
75.259
72.846
67.655
73.267
70.866
79.678
90.667
119.533
165.517
111.078
152.335
143.923
124.495
93.269
170.718
231.793

0.0 (46.07)
0.01 (65.012)
0.01 (58.09)
0.01 (58.000)
0.01 (82.13)
0.01 (58.09)
0.02 (75.12)
0.03 (41.000)
0.04 (58.000)
0.05 (63.000)
0.07 (72.000)
0.11 (98.000)
0.2 (208.000)
0.13 (68.000)
0.17 (183.000)
0.23 (137.000)
0.21 (142.000)
0.1 (101.000)
0.17 (130.000)
0.26 (196.000)

COLIN ,TBL

TBL
LPG -td,TBL
TBL
TBL
TBL
LPG -td,TBL
LPG -td,TBL
LPG -td
LPG -td,TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

LPG -s

Sapa
Sapa
TBL
TBL
LPG -s
TBL
Sapa
Sapa
COLIN

Sapa
Sapa
LPG -td
Sapa
Sapa
Sapa
TBL
TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -s

TBL
LPG -s
LPG -td
LPG -s
LPG -td
LPG -td
LPG -td
LPG -s
LPG -td
LPG -s
LPG -s
LPG -s
LPG -s
LPG -s

Sapa

Table 7: Results for Simple Domains: Best results show best time (corresponding quality) and
which planner(s) achieved this time and best quality (corresponding time) and planner(s)
achieving this quality.

84

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

COLIN

Time
zenosimpletime
1
0.01
2
0.02
3
0.02
4
0.04
5
0.03
6
0.05
7
0.08
8
0.15
9
0.31
10
0.12
11
0.26
12
0.3
13
6.19
14
15
19.48
16
477.47
17
759.19
18
19
48.95
20
163.2

Quality
173.001
592.008
350.007
885.013
656.011
995.016
931.014
895.013
1583.027
1191.022
796.015
1208.027
2062.04
2836.051
3173.045
4947.071
4309.079
5364.096

Average
Time
Quality
0.016
0.033
0.047
0.062
0.121
0.191
0.218
0.440
1.021
0.696
1.785
1.900
5.261
360.254
10.105
127.658
246.098
43.737
22.740
59.687

178.602
666.022
356.619
1226.041
868.832
1456.434
1006.035
869.291
1268.456
1461.053
823.433
1617.856
1303.254
1577.821
2561.808
2394.072
5232.603
2983.101
5043.146
5315.165

Best
Time

Planner

Quality

Planner

0.0 (180)
0.01 (866.05)
0.01 (280.04)
0.01 (936.000)
0.0 (400.06)
0.01 (603.06)
0.01 (706.08)
0.02 (836.07)
0.03 (789.12)
0.03 (743.13)
0.03 (763.1)
0.03 (1199.13)
0.03 (923.14)
0.3 (2068.18)
0.46 (2254.18)
0.86 (1702.24)
2.36 (3436.34)
2.61 (3453.3)
8.91 (3769.36)
6.43 (4578.4)

TBL
TBL
TBL
LPG -td,TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL

173.001 (0.01)
592.008 (0.02)
280.04 (0.01)
885.013 (0.04)
400.06 (0.0)
603.06 (0.01)
706.08 (0.01)
836.07 (0.02)
789.12 (0.03)
743.13 (0.03)
510.050 (8.037)
1166.120 (8.568)
923.14 (0.03)
1169.100 (1433.534)
2254.18 (0.46)
1702.24 (0.86)
3436.34 (2.36)
2383.003 (121.90)
3769.36 (8.91)
4578.4 (6.43)

COLIN
COLIN

TBL
COLIN

TBL
TBL
TBL
TBL
TBL
TBL
Sapa
Sapa
TBL
Sapa
TBL
TBL
TBL
LPG -s
TBL
TBL

Table 8: Results for Simple Domains: Best results show best time (corresponding quality) and
which planner(s) achieved this time and best quality (corresponding time) and planner(s)
achieving this quality.

85

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
Quality
airportstripstemporal
1
0.06
64.007
2
0.06
185.008
3
0.09
202.011
4
0.30
127.019
5
0.26
227.02
6
0.30
301.04
7
0.30
301.04
8
0.52
538.059
9
1.40
516.058
10
0.33
126.017
11
0.35
228.02
12
0.36
265.035
13
0.44
311.034
14
0.71
528.057
15
0.58
365.049
16
1.68
625.076
17
11.47 603.084
18
58.89 777.095
19
38.65 574.076
20
21
21.65
366.1
22
22.52 487.147
23
23.68 510.166
24
31.00 826.156
25
90.81 934.204
26
27
28
29
30
31
32
33
34
35
36
46.83 408.108
37
78.05 672.136
38
49.89 847.217
39
40
41
52.64 895.241
42
43
44
46

Average
Time
Quality
0.030
0.030
0.040
0.120
0.103
0.130
0.130
0.237
1.672
0.130
0.135
0.155
0.170
0.465
0.257
2.738
6.093
25.983
226.607
66.563
80.240
6.178
6.425
8.307
34.577
53.480
5.190
94.760
94.955
5.420
6.820
443.075
14.950
15.710
17.110
16.063
36.820
17.833
476.650
91.395
24.803
841.960
35.450
701.750
289.270

64.026
185.022
200.533
127.070
227.055
251.363
251.363
432.165
433.918
126.062
228.055
239.352
254.852
426.657
357.633
536.440
542.947
652.658
453.467
643.625
305.519
428.104
369.363
493.835
650.231
480.785
511.111
623.910
596.410
641.000
834.000
724.570
859.000
879.000
887.000
350.705
620.047
580.741
962.000
510.004
596.749
579.000
639.506
331.000
737.000

Best
Time
0.01 (64.07)
0.01 (185.000)
0.01 (200.12)
0.02 (127.19)
0.02 (227.2)
0.02 (240.41)
0.02 (240.41)
0.06 (402.6)
0.10 (402.000)
0.01 (126.17)
0.02 (228.2)
0.02 (228.37)
0.03 (237.37)
0.07 (390.57)
0.06 (273.48)
0.14 (558.000)
0.61 (569.000)
0.25 (733.000)
0.50 (413.000)
0.27 (740.000)
0.33 (285.97)
0.78 (286.26)
0.49 (265.28)
0.61 (377.18)
2.47 (539.000)
3.88 (584.000)
7.50 (505.33)
7.53 (706.000)
4.47 (687.000)
5.42 (641.000)
6.82 (834.000)
7.78 (815.000)
14.95 (859.000)
15.71 (879.000)
17.11 (887.000)
1.36 (322.000)
32.41 (831.000)
3.61 (573.000)
476.65 (962.000)
182.79 (584.000)
21.77 (573.000)
841.96 (579.000)
70.90 (573.000)
701.75 (331.000)
289.27 (737.000)

Planner

Quality

Planner

TBL

64.000 (0.02)
185.000 (0.01)
200.000 (0.03)
127.000 (0.04)
227.000 (0.05)
232.000 (0.07)
232.000 (0.07)
394.000 (0.09)
402.000 (0.10)
126.000 (0.05)
228.000 (0.07)
228.37 (0.02)
230.002 (0.14)
390.57 (0.07)
273.48 (0.06)
404.68 (0.24)
417.7 (2.16)
447.88 (18.81)
413.000 (0.50)
450.87 (55.03)
285.000 (0.77)
286.26 (0.78)
264.004 (510.166)
376.003 (826.156)
477.49 (10.45)
377.57 (103.08)
504.004 ()
541.82 (181.99)
505.82 (185.44)
641.000 (5.42)
834.000 (6.82)
634.14 (878.37)
859.000 (14.95)
879.000 (15.71)
887.000 (17.11)
322.000 (1.36)
357.006 (672.136)
322.006 (847.217)
962.000 (476.65)
436.007 ()
322.006 (895.241)
579.000 (841.96)
573.000 (70.90)
331.000 (701.75)
737.000 (289.27)

LGP -td

LGP -td,TBL

TBL
TBL
TBL
TBL
TBL
TBL
LGP -td
TBL
TBL
TBL
TBL
TBL
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
TBL
TBL
TBL
TBL
LGP -td
LGP -td
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td

LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td

TBL
LGP -s

TBL
TBL
TBL
TBL
TBL
LGP -td
TBL
LGP -td
TBL
LGP -s
LGP -s
TBL
TBL
LGP -s
TBL
TBL
LGP -td
LGP -td
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -s
LGP -s
LGP -td
LGP -s
LGP -s
LGP -td
LGP -td
LGP -td
LGP -td

Table 9: Results for More Complex Domains: Best results show best time (corresponding quality) and which planner(s) achieved this time and best quality (corresponding time) and
planner(s) achieving this quality.

86

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

COLIN

Time
Quality
depotstime
1
0.03
59.746
2
0.14
66.79
3
4
67.41
258.125
5
6
7
35.56
129.741
8
9
10
43.34
296.354
11
12
13
0.27
108.493
14
15
16
0.60
50.588
17
18
19
20
21
2.08
76.753
22
driverlogtime
1
0.02
303.006
2
0.17
462.019
3
0.03
202.009
4
0.14
474.019
5
0.20
343.019
6
0.03
275.007
7
0.12
316.012
8
0.43
699.024
9
0.57
730.028
10
0.21
294.031
11
0.16
522.026
12
5.90
1066.038
13
2.84
1052.031
14
6.51
787.034
15
0.27
212.042
16
17
18
19
20

Average
Time
Quality

Best
Time

Planner

Quality

Planner

TBL
TBL
TBL
LGP -td
LGP -td
LGP -td
TBL
LGP -td,TBL
LGP -td
TBL
LGP -td
LGP -td
TBL
TBL
LGP -td
TBL
TBL
LGP -td
TBL
LGP -td
TBL
LGP -td

55.181 (0.01)
60.556 (0.02)
127.592 (0.03)
160.139 (0.04)
777.544 (3.12)
287.543 (2.35)
107.340 (0.12)
108.399 (0.10)
1655.27 (0.97)
151.173 (11.364)
599.323 (1.42)
132.893 (4.33)
82.834 (1.373)
157.701 (1.02)
382.973 (4.16)
26.390 (0.56)
46.2 (0.20)
395.768 (0.89)
366.474 (1.22)
592.561 (7.98)
54.731 (36.794)
343.110 (3.86)

LGP -td

TBL

302 (0.01)
294.090 (0.678)
173.020 (0.131)
402.001 (0.04)
161.090 (0.973)
260 (0.02)
268.1 (0.01)
388.110 (1.244)
591 (0.02)
220.110 (0.415)
306.13 (0.486)
627.260 (1151.634)
597.180 (4.193)
625.150 (7.34)
212.042 (0.27)
3652.008 (28.03)
2238 (3.31)
1476.68 (78.94)
3993 (63.87)
1691.007 (66.56)

LGP -td

0.036
0.103
0.087
17.043
2.970
2.350
8.933
0.240
0.650
11.027
1.020
5.387
0.417
0.427
2.290
4.754
1.977
3.077
0.520
3.743
9.693
47.470

57.698
71.719
141.362
186.587
781.855
287.543
141.337
119.161
1783.468
226.698
726.121
163.032
99.751
216.623
399.697
76.900
87.495
535.942
428.210
880.639
71.388
445.232

0.00 (58.9311)
0.01 (73.2211)
0.03 (127.592)
0.04 (160.139)
2.82 (786.1666)
2.35 (287.543)
0.02 (142.158)
0.10 (108.3988)
0.33 (1911.6665)
0.03 (294.293)
0.32 (608.9167)
0.46 (165.5889)
0.02 (104.436)
0.10 (329.133)
0.42 (416.4197)
0.03 (166.236)
0.19 (88.26)
0.75 (709.8509)
0.14 (486.722)
0.93 (1050.2797)
0.16 (101.373)
3.86 (343.1095)

0.017
0.178
0.044
0.128
0.249
0.280
0.072
0.361
0.193
0.159
0.181
233.369
1.743
3.248
59.469
66.385
9.580
48.780
110.925
41.060

302.625
442.260
279.018
453.060
250.058
266.432
350.041
695.275
748.078
328.450
515.068
1230.325
1218.305
1125.322
766.155
5120.504
2787.062
2319.229
4005.005
3828.003

0.00 (302.05)
0.01 (438.19)
0.01 (173.06)
0.01 (441.15)
0.01 (195.18)
0.02 (260)
0.01 (268.1)
0.01 (894.24)
0.02 (591)
0.01 (394.11)
0.01 (512.18)
0.05 (829.32)
0.32 (903)
0.41 (1161)
0.10 (939.43)
28.03 (3652.0081)
3.31 (2238)
27.48 (2885)
63.87 (3993)
15.56 (5965)

LGP -td,TBL

TBL
TBL
TBL
LGP -td
LGP -td,TBL
TBL
LGP -td
TBL
TBL
TBL
LGP -td
LGP -td
TBL
LGP -s
LGP -td
LGP -td
LGP -td
LGP -td

LGP -td

TBL
LGP -td

TBL
LGP -td
LGP -s
LGP -td

TBL
Sapa
LGP -s
LGP -s
Sapa
LGP -s
LGP -s
LGP -s
LGP -td
TBL
LGP -s
LGP -s
Sapa
LGP -td

Sapa
Sapa
LGP -s
Sapa
LGP -td
TBL
Sapa
LGP -td
Sapa
Sapa
Sapa
Sapa
Sapa
COLIN
LGP -s
LGP -td

TBL
LGP -td
LGP -s

Table 10: Results for More Complex Domains: Best results show best time (corresponding quality) and which planner(s) achieved this time and best quality (corresponding time) and
planner(s) achieving this quality.

87

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
Quality
pipesnotankagetemporal
1
0.03
6.003
2
0.04
20.011
3
0.05
12.008
4
0.07
22.012
5
0.05
14.006
6
0.05
16.009
7
0.06
12.007
8
0.06
16.009
9
0.08
24.013
10
0.08
28.015
11
0.16
11.026
12
1.77
22.554
13
0.27
16.535
14
0.38
14.532
15
0.14
11.526
16
6.78
30.07
17
4.25
11.023
18
1.08
12.529
19
0.19
9.525
20
0.46
17.039
21
0.09
9.017
22
23
0.19
14.018
24
40.46
29.032
25
26
1.89
32.053
27
0.29
11.527
28
0.77
22.551
29
2.46
21.546
30
31
9.21
18.357
32
13.01
35.038
33
10.53
21.874
34
20.52
30.709
35
36
37
38
39
1.19
13.857
40
41
103.46
4.43
49
50

Average
Time
Quality
0.015
0.058
0.040
0.058
0.043
0.060
0.075
0.100
0.113
0.120
300.430
302.110
0.745
0.380
0.785
2.667
1.143
0.900
0.247
7.977
0.080
2.975
0.240
27.015
4.850
4.140
1.613
16.697
5.560
4.665
3.240
4.485
10.530
34.070
24.200
78.245
31.760
64.855
0.967
10.410
34.820
346.235
15.400

7.506
51.526
17.520
83.021
13.017
24.023
16.015
16.520
29.026
36.037
9.544
16.971
15.687
14.446
16.700
31.401
10.544
18.221
9.898
26.681
9.062
36.700
21.340
101.016
32.165
28.148
13.572
42.977
18.272
32.205
16.098
51.504
21.874
39.582
17.334
18.078
36.000
12.822
18.356
34.665
4.173
16.493
18.380

Time
0.00 (6.02)
0.01 (20.09)
0.01 (16.07)
0.01 (16.07)
0.01 (12.000)
0.01 (18.08)
0.01 (12.05)
0.03 (18.000)
0.02 (20.09)
0.02 (28.13)
0.05 (8.15)
0.28 (17.33)
0.05 (11.21)
0.15 (14.000)
0.12 (14.27)
0.48 (40.000)
0.09 (8.15)
0.20 (18.35)
0.11 (9.17)
0.46 (0.46)
0.02 (9.17)
2.05 (23.4)
0.19 (14.018)
13.57 (173.000)
1.12 (42.000)
1.46 (27.39)
0.29 (11.527)
0.77 (22.551)
0.34 (14.27)
1.39 (27.41)
0.17 (16.9367)
0.89 (17.31)
10.53 (21.874)
1.40 (23.370033)
48.40 (24.000)
6.49 (21.156633)
31.76 (36.000)
0.32 (13.6433)
0.17 (12.21)
10.41 (34.665)
0.10 (4.09)
2.15 (16.32)
15.40 (18.38)

Best
Planner
TBL
TBL
TBL
TBL
LGP -td,TBL
TBL
TBL
LGP -td
TBL
TBL
TBL
TBL
TBL
LGP -td
TBL
LGP -td
TBL
TBL
TBL
COLIN

TBL
TBL
COLIN
LGP -td
LGP -td

TBL
COLIN
COLIN

TBL
TBL
TBL
TBL
COLIN

TBL
LGP -td
TBL
LGP -td
TBL
TBL
LGP -td
TBL
TBL
TBL

Quality

Planner

6.000 (0.01)
20.011 (0.04)
12.008 (0.05)
16.07 (0.01)
12.000 (0.01)
16.009 (0.05)
12.007 (0.06)
16.001 (0.19)
20.09 (0.02)
28.015 (0.08)
8.15 (0.05)
11.002 (1200.92)
11.21 (0.05)
13.25 (0.99)
11.526 (0.14)
27.53 (3.41)
8.002 (11.023)
12.529 (1.08)
9.17 (0.11)
14.003 (17.039)
9.000 (0.13)
23.4 (2.05)
14.018 (0.19)
29.032 (40.46)
22.33 (8.58)
25.000 (9.07)
10.19 (0.48)
22.551 (0.77)
14.27 (0.34)
27.41 (1.39)
13.000 (0.34)
17.31 (0.89)
21.874 (10.53)
23.370033 (1.40)
10.669 ()
15.000 (150.00)
36.000 (31.76)
12.000 (129.39)
12.21 (0.17)
34.665 (10.41)
4.000 (0.90)
16.32 (2.15)
18.38 (15.40)

LGP -td
COLIN
COLIN

TBL
LGP -td
COLIN
COLIN
LGP -s

TBL
COLIN

TBL
LGP -s

TBL
TBL
COLIN

TBL
LGP -s
COLIN

TBL
LGP -s
LGP -td

TBL
COLIN
COLIN

TBL
LGP -td

TBL
COLIN

TBL
TBL
LGP -td
TBL
COLIN

TBL
LGP -s
LGP -td
LGP -td
LGP -td

TBL
LGP -td
LGP -td

TBL
TBL

Table 11: Results for More Complex Domains: Best results show best time (corresponding quality) and which planner(s) achieved this time and best quality (corresponding time) and
planner(s) achieving this quality.

88

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

COLIN

Time
Quality
pipestankagetemporal
1
0.04
6.003
2
0.12
24.013
3
0.23
12.008
4
0.52
18.009
5
0.09
14.007
6
0.09
16.01
7
0.26
16.008
8
0.30
18.012
9
10
4.40
36.02
11
0.40
13.031
12
13
1.51
13.53
14
53.09
22.052
15
59.61
17.541
17
18
33.06
11.527
19
20.29
16.537
20
2.54
12.029
21
22
23
24
23.25
31.564
25
983.78
28.558
26
32.55
33.053
27
2.30
10.024
29
191.49
23.548
30
58.98
28.555
31
187.22
32.713
32
33
34
160.42
25.038
37
39
9.14
15.191
40
51.82
21.877
41
269.57
4.93
49
50
82.82
22.378

Average
Time
Quality
0.020
0.147
0.180
0.275
0.153
0.160
1.175
1.275
238.057
26.135
316.585
12.480
6.420
334.625
64.690
1500.780
105.157
252.310
118.323
1.830
77.570
41.080
112.000
710.420
389.255
7.000
364.450
354.695
249.670
696.495
304.470
432.870
598.180
298.620
51.820
138.057
91.770
82.820

8.006
63.371
15.520
26.020
20.017
17.018
18.522
23.031
66.741
57.571
27.601
27.105
13.265
19.357
14.886
31.000
28.626
17.582
24.610
14.595
25.690
30.000
37.782
56.483
31.991
16.012
28.274
30.777
31.041
34.158
21.133
40.065
20.665
22.925
21.877
6.687
17.340
22.378

Time
0.00 (6.02)
0.02 (22.1)
0.06 (16.07)
0.04 (16.07)
0.02 (14.06)
0.02 (14.06)
0.07 (18.08)
0.30 (18.012)
0.95 (104.000)
0.32 (54.26)
0.40 (13.031)
5.08 (43.000)
1.51 (13.53)
9.17 (19.37)
59.61 (17.541)
1500.78 (31.000)
33.06 (11.527)
17.59 (11.21)
2.54 (12.029)
0.11 (10.19)
53.50 (30.000)
41.08 (30.000)
23.25 (31.564)
527.52 (116.500)
32.55 (33.053)
2.30 (10.024)
191.49 (23.548)
58.98 (28.555)
0.84 (31.7833)
179.24 (35.3167)
304.47 (21.133333)
31.22 (33.99)
598.18 (20.665)
9.14 (15.191)
51.82 (21.877)
32.63 (6.13)
91.77 (17.34)
82.82 (22.378)

Best
Planner
TBL
TBL
TBL
TBL
TBL
TBL
TBL
COLIN
LGP -td

TBL
COLIN
LGP -td
COLIN

TBL
COLIN
LGP -td
COLIN

TBL
COLIN

TBL
LGP -td
LGP -td
COLIN
LGP -td
COLIN
COLIN
COLIN
COLIN

TBL
TBL
TBL
TBL
LGP -td
COLIN
COLIN

TBL
TBL
COLIN

Quality

Planner

6.000 (0.03)
22.1 (0.02)
12.008 (0.23)
16.07 (0.04)
14.007 (0.09)
14.06 (0.02)
16.000 (0.31)
18.012 (0.30)
46.22 (6.34)
36.02 (4.40)
13.003 (1235.31)
11.21 (19.88)
13.000 (11.33)
18.000 (1276.24)
12.23 (69.77)
31.000 (1500.78)
11.527 (33.06)
11.21 (17.59)
12.029 (2.54)
10.19 (0.11)
21.38 (101.64)
30.000 (41.08)
31.564 (23.25)
24.39 (619.96)
30.93 (745.96)
10.024 (2.30)
23.548 (191.49)
28.555 (58.98)
29.833 (810.62)
33.000 (1213.75)
21.133333 (304.47)
25.038 (160.42)
20.665 (598.18)
15.191 (9.14)
21.877 (51.82)
4.93 (269.57)
17.34 (91.77)
22.378 (82.82)

LGP -s

TBL
COLIN

TBL
COLIN

TBL
LGP -td
COLIN

TBL
COLIN
LGP -s

TBL
LGP -td
LGP -td

TBL
LGP -td
COLIN

TBL
colin
TBL
TBL
LGP -td
COLIN

TBL
TBL
COLIN
COLIN
COLIN
LGP -td
LGP -td

TBL
COLIN
LGP -td
COLIN
COLIN
COLIN

TBL
COLIN

Table 12: Results for More Complex Domains: Best results show best time (corresponding quality) and which planner(s) achieved this time and best quality (corresponding time) and
planner(s) achieving this quality.

89

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
roverstime
1
0.03
2
0.01
3
0.03
4
0.03
5
0.06
6
40.93
7
0.07
8
0.17
9
10
0.29
11
0.15
12
0.86
13
14
15
16
17
0.70
18
1.35
19
20
92.59
satellitetime
1
0.02
2
0.01
3
0.01
4
0.03
5
0.11
6
0.10
7
0.12
8
0.30
9
0.38
10
0.64
11
0.94
12
3.57
13
21.89
14
6.19
15
8.76
16
22.18
17
15.29
18
3.85
19
57.66
20

Quality
67.007
48.006
63.01
52.006
125.014
273.118
105.017
149.944
177.022
170.881
122.022

230.036
245.864
390.804
129.596
182.916
78.616
140.42
290.12
114.38
126.544
139.608
175.74
295.549
283.351
336.599
433.308
267.73
292.436
336.356
232.66
169.256
520.602

Average
Time
Quality

Best
Time

Planner

Quality

Planner

LGP -td

67.007 (67.007)
46.0007 (0.02)
63.01 (0.03)
52 (0.02)
107.12 (0.702)
273.118 (40.93)
90.538574 (0.411)
134 (0.04)
128.6895 (0.24)
154.48767 (1.448)
170.881 (0.15)
114.130005 (0.682)
237.8161 (0.86)
137.7917 (0.62)
205.3755 (0.10)
210 (0.46)
230.036 (0.70)
155.0909 (0.33)
394.5915 (0.61)
390.804 (92.59)

COLIN

0.048
0.027
0.062
0.040
0.258
14.010
0.138
0.494
0.150
0.534
0.170
0.476
0.560
0.865
0.500
0.460
2.223
1.817
0.610
49.107

73.524
56.269
70.525
52.733
129.069
299.794
107.121
160.906
137.345
192.855
195.395
134.818
292.200
206.147
239.333
210.000
341.230
220.290
394.591
505.667

0.02 (80)
0.01 (48.006)
0.02 (80)
0.02 (52)
0.02 (113.2)
0.08 (284.965)
0.03 (138.9286)
0.04 (134)
0.06 (146)
0.06 (190.3077)
0.07 (200.5)
0.04 (145.5294)
0.26 (346.5833)
0.35 (268.7368)
0.10 (205.3755)
0.46 (210)
0.34 (392.353)
0.33 (155.0909)
0.61 (394.5915)
3.38 (502.7423)

0.026
0.038
0.068
0.099
0.154
0.138
0.265
0.469
0.813
0.949
1.703
9.147
29.900
10.618
34.225
34.882
94.390
5.306
49.424
30.264

193.553
225.716
168.343
319.688
262.900
255.894
222.818
205.241
307.457
262.206
370.878
423.836
504.815
387.271
333.289
510.100
380.053
290.099
527.707
854.958

0.01 (205.28)
0.00 (235.12)
0.01 (78.616)
0.01 (359.28)
0.01 (254.563)
0.01 (264.51)
0.02 (296.16)
0.03 (226.503)
0.05 (351.8529)
0.04 (231.485)
0.07 (283.916)
0.13 (389.4588)
0.23 (464.408)
0.15 (461.855)
0.18 (267.4431)
0.23 (602.7849)
0.24 (378.459)
0.10 (324.406)
0.19 (352.355)
0.24 (584.663)

COLIN
LGP -td
LGP -s, LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -s, LGP -td,TBL
LGP -td
COLIN ,TBL

TBL
TBL
TBL
TBL
TBL
LGP -td,TBL
LGP -td
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
TBL
LGP -td
LGP -td

129.596 (0.02)
182.916 (0.01)
78.616 (0.01)
140.42 (0.03)
162.39699 (0.528)
114.38 (0.10)
126.544 (0.12)
139.608 (0.30)
175.74 (0.38)
231.485 (0.04)
283.351 (0.94)
336.599 (3.57)
433.308 (21.89)
267.73 (6.19)
264.6641 (2.48)
336.356 (22.18)
232.66 (15.29)
169.256 (3.85)
352.355 (0.19)
498.90106 (113.277)

LGP -s
COLIN
LGP -td

Sapa
COLIN

Sapa
LGP -td
LGP -s

Sapa
COLIN

Sapa
LGP -s
LGP -s
LGP -td
LGP -td
COLIN
LGP -td
LGP -td
COLIN
COLIN
COLIN
COLIN
COLIN

Sapa
COLIN
COLIN
COLIN
COLIN
LGP -td
COLIN
COLIN
COLIN
COLIN
LGP -s
COLIN
COLIN
COLIN
LGP -td

Table 13: Results for More Complex Domains: Best results show best time (corresponding quality) and which planner(s) achieved this time and best quality (corresponding time) and
planner(s) achieving this quality.

90

Sapa

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

COLIN

Time
zenotime
1
0.01
2
0.01
3
0.03
4
0.08
5
0.04
6
0.08
7
0.06
8
8.53
9
0.22
10
0.41
11
0.41
12
10.34
13
1.28
14
371.61
15
6.95
16
130.33
17
443.79
18
188.85
19
20

Quality
3.672
23.435
10.089
21.287
8.196
21.966
33.31
43.722
39.949
36.458
22.264
72.139
86.473
117.625
381.626
117.052
77.332
89.082

Average
Time
Quality
0.018
0.019
0.033
0.084
0.075
0.075
0.110
2.250
0.194
0.310
0.271
2.874
1.592
256.813
5.524
43.183
161.243
77.357
73.040
80.660

3.489
23.672
13.336
22.340
22.016
20.921
24.863
30.689
48.528
33.487
25.576
51.105
58.235
72.619
241.318
86.693
118.179
70.542
137.909
91.146

Best
Time

Planner

Quality

Planner

0.01 (0.01)
0.01 (0.01)
0.01 (14.4211)
0.01 (21.708)
0.02 (27.0419)
0.02 (20.8864)
0.01 (25.6744)
0.02 (24.2375)
0.03 (72.1579)
0.06 (46.1848)
0.05 (46.1576)
0.09 (42.1671)
0.07 (42.0593)
0.62 (58.8983)
0.87 (274.8496)
3.07 (67.554)
3.97 (117.1512)
4.48 (56.8345)
9.83 (168.0886)
28.69 (78.4703)

COLIN , LPG -td

3.424 (0.01)
23.431 (0.01)
10.089 (0.03)
21.287 (0.08)
8.196 (0.04)
16.578 (0.17)
18.283 (0.05)
24.238 (0.02)
23.238 (0.395)
20.864 (0.14)
13.666 (0.443)
38.992 (0.846)
42.059 (0.07)
39.064 (651.493)
117.171 (8.644)
54.717 (23.883)
77.332 (443.79)
56.835 (4.48)
107.729 (136.25)
78.470 (28.69)

LPG -td

COLIN , LPG -td
LPG -td
LPG -s
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

LPG -td
COLIN
COLIN
COLIN

Sapa
LPG -s
LPG -td

Sapa
LPG -s

Sapa
Sapa
LPG -td
Sapa
Sapa
Sapa
COLIN
LPG -td
LPG -s
LPG -td

Table 14: Results for More Complex Domains: Best results show best time (corresponding quality) and which planner(s) achieved this time and best quality (corresponding time) and
planner(s) achieving this quality.

91

fiC OLES , C OLES , F OX & L ONG

References
Audemard, G., Bertoli, P., Cimatti, A., Kornilowicz, A., & Sebastiani, R. (2002). A SAT-based approach for solving formulas over boolean and linear mathematical propositions. In Proceedings of the 18th International Conference on Automated Deduction, Vol. 2392, pp. 193208.
Springer-Verlag, LNAI Series.
Blum, A., & Furst, M. (1995). Fast Planning through Planning Graph Analysis. In Proceedings of
the International Joint Conference on Artificial Inteligence (IJCAI).
Boddy, M. S., & Johnson, D. P. (2002). A New Method for the Global Solution of Large Systems of Continuous Constraints. In Proceedings of the 1st International Workshop on Global
Constraint Optimization and Constraint Satisfaction (COCOS), Vol. 2861 of Lecture Notes
in Computer Science, pp. 142156. Springer.
Cesta, A., & Oddi, A. (1996). Gaining Efficiency and Flexibility in the Simple Temporal Problem.
In Proceedings of the 3rd International Workshop on Temporal Representation and Reasoning
(TIME).
Cesta, A., Cortellessa, G., Fratini, S., & Oddi, A. (2009). Developing an End-to-End Planning
Application from a Timeline Representation Framework. In Proceedings of 21st Conference
on Innovative Applications of Artificial Intelligence (IA*AI).
Chien, S. A., Tran, D., Rabideau, G., Schaffer, S. R., Mandl, D., & Frye, S. (2010). Timeline-Based
Space Operations Scheduling with External Constraints. In Proceedings of the International
Conference on AI Planning and Scheduling (ICAPS), pp. 3441.
Cimatti, A., Giunchiglia, F., Giunchiglia, E., & Traverso, P. (1997). Planning via Model Checking:
A Decision Procedure for R. In Recent Advances in AI Planning, 4th European Conference
on Planning, ECP, pp. 130142.
Coles, A. I., Fox, M., Halsey, K., Long, D., & Smith, A. J. (2008). Managing concurrency in
temporal planning using planner-scheduler interaction. Artificial Intelligence, 173, 144.
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008a). Planning with Problems Requiring Temporal
Coordination. In Proceedings of the 23rd AAAI Conference on Artificial Intelligence (AAAI
08).
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008b). A Hybrid Relaxed Planning GraphLP
Heuristic for Numeric Planning Domains. In Proceedings of the 18th International Conference on Automated Planning and Scheduling (ICAPS), pp. 5259.
Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2009a). Extending the Use of Inference in Temporal Planning as Forwards Search. In Proceedings of the 19th International Conference on
Automated Planning and Scheduling (ICAPS 09).
Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2009b). Temporal Planning in Domains with Linear
Processes. In Proceedings of the 21st International Joint Conference on Artificial Intelligence
(IJCAI). AAAI Press.
Cushing, W., Kambhampati, S., Mausam, & Weld, D. (2007). When is temporal planning really
temporal planning?. In Proceedings of the International Joint Conference on AI (IJCAI), pp.
18521859.
92

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Dechter, R., Meiri, I., & Pearl, J. (1989). Temporal Constraint Networks. In Proceedings of Principles of Knowledge Representation and Reasoning (KR), pp. 8393. Toronto, Canada.
Dierks, H. (2005). Finding Optimal Plans for Domains with Restricted Continuous Effects with
UPPAAL-Cora. In ICAPS Workshop on Verification and Validation of Model-Based Planning
and Scheduling Systems.
Do, M. B., & Kambhampati, S. (2003). Sapa: A Multi-objective Metric Temporal Planner. Journal
of Artificial Intelligence Research (JAIR), 20, 155194.
Edelkamp, S. (2003). Taming numbers and durations in a model-checking integrated planning
system. Journal of Artificial Intelligence Research (JAIR), 20, 195238.
Edelkamp, S., & Jabbar, S. (2006). Cost-Optimal External Planning. In Proceedings of the 21st
National (American) Conference on Artificial Intelligence (AAAI). AAAI Press.
Eyerich, P., Mattmuller, R., & Roger, G. (2009). Using the Context-enhanced Additive Heuristic
for Temporal and Numeric Planning. In Proceedings of the 19th International Conference on
Automated Planning and Scheduling (ICAPS 2009). AAAI Press.
Fox, M., & Long, D. (2003). PDDL2.1: An extension of PDDL for expressing temporal planning
domains. Journal of Artificial Intelligence Research (JAIR), 20, 61124.
Fox, M., & Long, D. (2006). Modelling Mixed Discrete-Continuous Domains for Planning. Journal
of Artificial Intelligence Research (JAIR), 27, 235297.
Fox, M., Howey, R., & Long, D. (2005). Validating Plans in the Context of Processes and Exogenous
Events. In Proceedings of the 20th National Conference on Artificial Intelligence and the 17th
Innovative Applications of Artificial Intelligence Conference (AAAI), pp. 11511156.
Fox, M., Long, D., & Halsey, K. (2004). An Investigation into the Expressive Power of PDDL2.1.
In Proceedings of the 16th European Conference of Artificial Intelligence (ECAI).
Fox, M., Long, D., & Magazzeni, D. (2011). Automatic Construction of Efficient Multiple Battery
Usage Policies. In Proceedings of the 21st International Conference on Automated Planning
and Scheduling (ICAPS).
Frank, J., & Jonsson, A. K. (2003). Constraint-Based Attribute and Interval Planning. Constraints,
8(4), 339364.
Garrido, A., Fox, M., & Long, D. (2002). A Temporal Planning System for Durative Actions
of PDDL2.1. In Proceedings of the 15th Eureopean Conference on Artificial Intelligence
(ECAI), pp. 586590.
Garrido, A., Onainda, E., & Barber, F. (2001). A Temporal Planning System for Time-Optimal
Planning. In Proceedings of the 10th Portuguese Conference on Artificial Intelligence, pp.
379392. Springer.
Gerevini, A., Saetti, A., & Serina, I. (2006). An Approach to Temporal Planning and Scheduling
in Domains with Predictable Exogenous Events. Journal of Artificial Intelligence Research
(JAIR), 25, 187231.
Gerevini, A., Saetti, A., & Serina, I. (2010). Temporal Planning with Problems Requiring Concurrency through Action Graphs and Local Search. In Proceedings of the 20th International
Conference on Automated Planning and Scheduling (ICAPS).
93

fiC OLES , C OLES , F OX & L ONG

Gerevini, A., & Serina, I. (2000). Fast Plan Adaptation through Planning Graphs: Local and Systematic Search Techniques. In Proceedings of the 5th International Conference on Artificial
Intelligence Planning Systems (AIPS), pp. 112121.
Ghallab, M., & Laruelle, H. (1994). Representation and Control in IxTeT, a Temporal Planner. In
Proceedings of the 2nd International Conference on Artificial Intelligence Planning Systems
(AIPS), pp. 6167.
Halsey, K. (2005). CRIKEY!: Its co-ordination in temporal planning. Ph.D. thesis, University of
Durham.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In Proceedings of
the 6th European Conference on Planning (ECP01), pp. 121132.
Haslum, P. (2009). Admissible Makespan Estimates for PDDL2.1 Temporal Planning. In Proceedings of the ICAPS Workshop on Heuristics for Domain-Independent Planning.
Helmert, M. (2006). The Fast Downward Planning System. Journal of Artificial Intelligence (JAIR),
26, 191246.
Henzinger, T. (1996). The Theory of Hybrid Automata. In Proceedings of the 11th Annual Symposium on Logic in Computer Science. Invited tutorial., pp. 278292. IEEE Computer Society
Press.
Henzinger, T., Ho, P.-H., & Wong-Toi, H. (1995). A user guide to HYTECH. In E. Brinksma,
W.R. Cleaveland, K.G. Larsen, T. Margaria, and B. Steffen, editors, Tool and Algorithms for
the Construction and Analysis of Systems: (TACAS 95), volume 1019 of Lecture Notes in
Computer Science, pp. 4171.
Hoffmann, J. (2003). The Metric-FF Planning System: Translating Ignoring Delete Lists to Numeric State Variables. Journal of Artificial Intelligence Research (JAIR), 20, 291341.
Hoffmann, J., & Edelkamp, S. (2005). The Deterministic Part of IPC-4: An Overview. Journal of
Artificial Intelligence Research (JAIR), 24, 519579.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. Journal of Artificial Intelligence Research (JAIR), 14, 253302.
Huang, R., Chen, Y., & Zhang, W. (2009). An Optimal Temporally Expressive Planner: Initial
Results and Application to P2P Network Optimization. In Proceedings of the International
Conference on Automated Planning and Scheduling (ICAPS).
Knight, R., Schaffer, S., & B.Clement (2009). Power planning in the international space station
domain. In Proceedings of the 6th International Workshop on Planning and Scheduling for
Space (IWPSS).
Lamba, N., Dietz, M., Johnson, D. P., & Boddy, M. S. (2003). A Method for Global Optimization of
Large Systems of Quadratic Constraints. In Proceedings of the 2nd International Workshop
on Global Optimization and Constraint Satisfaction (COCOS), Vol. 3478 of Lecture Notes in
Computer Science, pp. 6170. Springer.
Leaute, T., & Williams, B. (2005). Coordinating Agile Systems through the Model-based Execution
of Temporal Plans. In Proceedings of the 20th National Conference on AI (AAAI).
Li, H., & Williams, B. (2008). Generative systems for hybrid planning based on flow tubes. In Proc.
18th Int. Conf. on Aut. Planning and Scheduling (ICAPS).
94

fiC OLIN : P LANNING WITH C ONTINUOUS C HANGE

Li, H., & Williams, B. (2011). Hybrid Planning with Temporally Extended Goals for Sustainable
Ocean Observing. In Proceedings of the International Conference of the Association for the
Advancement of AI (AAAI): Special Track on Sustainability and AI.
Long, D., & Fox, M. (2003a). Exploiting a Graphplan Framework in Temporal Planning. In
Proceedings of the 13th International Conference on Automated Planning and Scheduling
(ICAPS), pp. 5261.
Long, D., & Fox, M. (2003b). The 3rd International Planning Competition: Results and Analysis.
Journal of Artificial Intelligence Research (JAIR), 20, 159.
Lougee-Heimer, R. (2003). The Common Optimization INterface for Operations Research. IBM
Journal of Research and Development, 47(1), 5766.
McDermott, D. (2003). Reasoning about Autonomous Processes in an Estimated Regression
Planner. In Proceedings of the 13th International Conference on Automated Planning and
Scheduling (ICAPS).
McDermott, D. V. (2000). The 1998 AI Planning Systems Competition. AI Magazine, 21(2), 3555.
Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam (2009). A Heuristic Search
Approach to Planning with Continuous Resources in Stochastic Domains. Journal of Artificial
Intelligence Research (JAIR), 34, 2759.
Palacios, H., & Geffner, H. (2009). Compiling Uncertainty Away in Conformant Planning Problems
with Bounded Width. Journal of Artificial Intelligence Research (JAIR), 35, 623675.
Pednault, E. P. D. (1989). ADL: Exploring the Middle Ground Between STRIPS and the Situation
Calculus. In Proceedings of the International Conference on Knowledge Representation (KR),
pp. 324332.
Pell, B., Gat, E., Keesing, R., Muscettola, N., & Smith, B. D. (1997). Robust Periodic Planning and
Execution for Autonomous Spacecraft. In Proceedings of the International Joint Conference
on AI (IJCAI), pp. 12341239.
Penberthy, S., & Weld, D. (1994). Temporal Planning with Continuous Change. In Proceedings of
the 12th National Conference on AI (AAAI), pp. 10101015. AAAI/MIT Press.
Penna, G. D., Intrigila, B., Magazzeni, D., & Mercorio, F. (2009). UPMurphi: a Tool for Universal Planning on PDDL+ Problems. In Proceedings of the 19th International Conference on
Automated Planning and Scheduling (ICAPS 2009), pp. 1923. AAAI Press.
Penna, G. D., Intrigila, B., Magazzeni, D., & Mercorio, F. (2010). A PDDL+ Benchmark Problem:
The Batch Chemical Plant. In Proceedings of the International Conference on AI Planning
and Scheduling (ICAPS), pp. 222225.
Reddy, S. Y., Frank, J. D., Iatauro, M. J., Boyce, M. E., Kurklu, E., Ai-Chang, M., & Jonsson,
A. K. (2011). Planning Solar Array Operations on the International Space Station. ACM
Transactions on Intelligent Systems Technology, 2, 124.
Richter, S., & Westphal, M. (2010). The LAMA Planner: Guiding Cost-Based Anytime Planning
with Landmarks. Journal of Artificial Intelligence Research (JAIR), 39, 127177.
Shin, J., & Davis, E. (2005). Processes and Continuous Change in a SAT-based Planner. Artificial
Intelligence, 166, 194253.
95

fiC OLES , C OLES , F OX & L ONG

Smith, D., & Weld, D. S. (1999). Temporal Planning with Mutual Exclusion Reasoning. In Proceedings of the 16th International Joint Conference on AI (IJCAI), pp. 326337.
Veloso, M., Perez, M., & Carbonell, J. (1990). Nonlinear planning with parallel resource allocation.
In Proceedings of the DARPA Workshop on Innovative Approaches to Planning, Scheduling
and Control, pp. 207212.
Vidal, V., & Geffner, H. (2006). Branching and pruning: An optimal temporal POCL planner based
on constraint programming. Artificial Intelligence, 170(3), 298335.
Wolfman, S., & Weld, D. (1999). The LPSAT System and its Application to Resource Planning. In
Proceedings of the 16th International Joint Conference on Artificial Intelligence (IJCAI).
Yi, W., Larsen, K., & Pettersson, P. (1997). UPPAAL in a Nutshell. International Journal of
Software Tools for Technology Transfer, 1(1).
Younes, H. L. S., & Simmons, R. G. (2003). VHPOP: Versatile heuristic partial order planner..
Journal of Artificial Intelligence Research (JAIR), 20, 405430.

96

fiJournal of Artificial Intelligence Research 44 (2012) 709-755

Submitted 04/12; published 08/12

Online Speedup Learning for Optimal Planning
Carmel Domshlak
Erez Karpas

DCARMEL @ IE . TECHNION . AC . IL
KARPASE @ TECHNION . AC . IL

Faculty of Industrial Engineering and Management
Technion - Israel Institute of Technology
Haifa, 32000, Israel

Shaul Markovitch

SHAULM @ CS . TECHNION . AC . IL

Faculty of Computer Science
Technion - Israel Institute of Technology
Haifa, 32000, Israel

Abstract
Domain-independent planning is one of the foundational areas in the field of Artificial Intelligence. A description of a planning task consists of an initial world state, a goal, and a set of actions
for modifying the world state. The objective is to find a sequence of actions, that is, a plan, that
transforms the initial world state into a goal state. In optimal planning, we are interested in finding not just a plan, but one of the cheapest plans. A prominent approach to optimal planning these
days is heuristic state-space search, guided by admissible heuristic functions. Numerous admissible
heuristics have been developed, each with its own strengths and weaknesses, and it is well known
that there is no single best heuristic for optimal planning in general. Thus, which heuristic to
choose for a given planning task is a difficult question. This difficulty can be avoided by combining
several heuristics, but that requires computing numerous heuristic estimates at each state, and the
tradeoff between the time spent doing so and the time saved by the combined advantages of the
different heuristics might be high. We present a novel method that reduces the cost of combining admissible heuristics for optimal planning, while maintaining its benefits. Using an idealized
search space model, we formulate a decision rule for choosing the best heuristic to compute at each
state. We then present an active online learning approach for learning a classifier with that decision
rule as the target concept, and employ the learned classifier to decide which heuristic to compute at
each state. We evaluate this technique empirically, and show that it substantially outperforms the
standard method for combining several heuristics via their pointwise maximum.

1. Introduction
At the center of the problem of intelligent autonomous behavior is the task of selecting the actions
to take next. Planning in AI is best conceived as the model-based approach to automated action
selection (Geffner, 2010). The models represent the current situation, goals, and possible actions.
Planning-specific languages are used to describe such models concisely. The main challenge in
planning is computational, as most planning languages lead to intractable problems in the worst
case. However, using rigorous search-guidance tools often allows for efficient solving of interesting
problem instances.
In classical planning, which is concerned with the synthesis of plans constituting goal-achieving
sequences of deterministic actions, significant algorithmic progress has been achieved in the last
two decades. In turn, this progress in classical planning is translated to advances in more involved
planning languages, allowing for uncertainty and feedback (Yoon, Fern, & Givan, 2007; Palacios
c
2012
AI Access Foundation. All rights reserved.

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

& Geffner, 2009; Keyder & Geffner, 2009; Brafman & Shani, 2012). In optimal planning, the
objective is not just to find any plan, but to find one of the cheapest plans.
A prominent approach to domain-independent planning, and to optimal planning in particular,
is state-space heuristic search. It is very natural to view a planning task as a search problem, and
use a heuristic search algorithm to solve it. Recent advances in automatic construction of heuristics
for domain-independent planning established many heuristics to choose from, each with its own
strengths and weaknesses. However, this wealth of heuristics leads to a new question: given a
specific planning task, which heuristic to choose?
In this paper, we propose selective max  an online learning approach that combines the
strengths of several heuristic functions, leading to a speedup in optimal heuristic-search planning.
At a high level, selective max can be seen as a hyper-heuristic (Burke, Kendall, Newall, Hart, Ross,
& Schulenburg, 2003)  a heuristic for choosing among other heuristics. It is based on the seemingly trivial observation that, for each state, there is one heuristic which is the best for that state.
In principle, it is possible to compute several heuristics for each state, and then choose one according to the values they provide. However, heuristic computation in domain-independent planning is
typically expensive, and thus computing several heuristic estimates for each state takes a long time.
Selective max works by predicting for each state which heuristic will yield the best heuristic
estimate, and computes only that heuristic.
As it is not always clear how to decide what the best heuristic for each state is, we first
analyze an idealized model of a search space and describe how to choose there the best heuristic for
each state in order to minimize the overall search time. We then describe an online active learning
procedure that uses a decision rule formulated for the idealized model. This procedure constitutes
the essence of selective max.
Our experimental evaluation, which we conducted using three state-of-the-art heuristics for
domain-independent planning, shows that selective max is very effective in combining several
heuristics in optimal search. Furthermore, the results show that using selective max results in a
speedup over the baseline heuristic combination method, and that selective max is robust to different parameter settings. These claims are further supported by selective max having been a runnerup ex-aequo in the last International Planning Competition, IPC-2011 (Garca-Olaya, Jimenez, &
Linares Lopez, 2011).
This paper expands on the conference version (Domshlak, Karpas, & Markovitch, 2010) in
several ways. First, we improve and expand the presentation of the selective max decision rule.
Second, we explain how to handle non-uniform action costs in a principled way. Third, the empirical
evaluation is greatly extended, and now includes the results from IPC-2011, as well as controlled
experiments with three different heuristics, and an exploration of how the parameters of selective
max affect its performance.

2. Previous Work
Selective max is a speedup learning system. In general, speedup learning is concerned with improving the performance of a problem solving system with experience. The computational difficulty of
domain-independent planning has led many researchers to use speedup learning techniques in order
to improve the performance of planning systems; for a survey of many of these, see the work of
Minton (1994), Zimmerman and Kambhampati (2003), and Fern, Khardon, and Tadepalli (2011).
710

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

Speedup learning systems can be divided along several dimensions (Zimmerman & Kambhampati, 2003; Fern, 2010). Arguably the most important dimension is the phase in which learning takes
place. An offline, or inter-problem, speedup learner analyzes the problem solvers performance on
different problem instances in an attempt to formulate some rule which would not only improve this
performance but would also generalize well to future problem instances. Offline learning has been
applied extensively to domain-independent planning, with varying degrees of success (Fern et al.,
2011). However, one major drawback of offline learning is the need for training examples  in our
case, planning tasks from the domains of interest.
Learning can also take place online, during problem solving. An online, or intra-problem,
speedup learner is invoked by the problem solver on a concrete problem instance the solver is
working on, and it attempts to learn online, with the objective of improving the solvers performance
on that specific problem instance being solved. In general, online learners are not assumed to be pretrained on some other, previously seen problem instances; all the information they can rely on has to
be collected during the process of solving the concrete problem instance they were called for. Online
learning has been shown to be extremely helpful in propositional satisfiability (SAT) and general
constraint satisfaction (CSP) solving, where nogood learning and clause learning are now among
the essential components of any state-of-the-art solver (Schiex & Verfaillie, 1993; Marques-Silva
& Sakallah, 1996; Bayardo Jr. & Schrag, 1997). Thus, indirectly, SAT- and CSP-based domainindependent planners already benefit from these online learning techniques (Kautz & Selman, 1992;
Rintanen, Heljanko, & Niemela, 2006). However, to the best of our knowledge, our work is the first
application of online learning to optimal heuristic-search planning.

3. Background
A domain-independent planning task (or planning task, for short) consists of a description of an
initial state, a goal, and a set of available operators. Several formalisms for describing planning tasks
are in use, including STRIPS (Fikes & Nilsson, 1971), ADL (Pednault, 1989), and SAS+ (Backstrom
& Klein, 1991; Backstrom & Nebel, 1995). We describe the SAS+ formalism, the one used by
the Fast Downward planner (Helmert, 2006), on top of which we have implemented and evaluated
selective max. Nothing, however, precludes using selective max in the context of other formalisms.
A SAS+ planning task is given by a 4-tuple  = hV, A, s0 , Gi. V = {v1 , . . . , vn } is a set of state
variables, each associated with a finite domain dom(vi ). A complete assignment s to V is called a
state. s0 is a specified state called the initial state, and the goal G is a partial assignment to V . A is
a finite set of actions. Each action a is given by a pair hpre(a), eff(a)i of partial assignments to V
called preconditions and effects, respectively. Each action a also has an associated cost C(a)  R0+ .
An action a is applicable in a state s iff s |= pre(a). Applying a changes the value of each state
variable v to eff(a)[v] if eff(a)[v] is specified. The resulting state is denoted by sJaK. We denote
the state obtained from sequential application of the (respectively applicable) actions a1 , . . . , ak
starting at state s by sJha1 , . . . , ak iK. Such an action sequence is a plan if s0 Jha1 , . . . , ak iK |= G.
In optimal planning, we are interested in finding one of
Pthe cheapest plans, where the cost of a plan
ha1 , . . . , ak i is the sum of its constituent action costs ki=1 C(ai ).
A SAS+ planning task  = hV, A, s0 , Gi can be easily seen as a state-space search problem
whose states are simply complete assignments to the variables V , with transitions uniquely determined by the actions A. The initial and goal states are also defined by the initial state and goal of .
An optimal solution for a state-space search problem can be found by using the A search algorithm
711

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

with an admissible heuristic h. A heuristic evaluation function h assigns an estimate of the distance
to the closest goal state from each state it evaluates. The length of a cheapest path from state s to the
goal is denoted by h (s), and h is called admissible if it never overestimates the true goal distance
 that is, if h(s)  h (s) for any state s. A works by expanding states in the order of increasing
f (s) := g(s) + h(s), where g(s) is the cost of the cheapest path from the initial state to s known so
far.

4. Selective Max as a Decision Rule
Many admissible heuristics have been proposed for domain-independent planning; these vary from
cheap to compute yet not very accurate, to more accurate yet expensive to compute. In general,
the more accurate a heuristic is, the fewer states would be expanded by A when using it. As the
accuracy of heuristic functions varies for different planning tasks, and even for different states of
the same task, we may be able to produce a more robust optimal planner by combining several admissible heuristics. Presumably, each heuristic is more accurate, that is, provides higher estimates,
in different regions of the search space. The simplest and best-known way for doing that is using the point-wise maximum of the heuristics in use at each state. Given n admissible heuristics,
h1 , . . . , hn , a new heuristic, maxh , is defined by maxh (s) := max1in hi (s). It is easy to see that
maxh (s)  hi (s) for any state s and for any heuristic hi . Thus A search using maxh is expected to
expand fewer states than A using any individual heuristic.PHowever, if we denote the time needed
to compute hi by ti , the time needed to compute maxh is ni=1 ti .
As mentioned previously, selective max is a form of hyper-heuristic (Burke et al., 2003) that
chooses which heuristic to compute at each state. We can view selective max as a decision rule dr,
which is given a set of heuristics h1 , . . . , hn and a state s, and chooses which heuristic to compute
for that state. One natural candidate for such a decision rule is the heuristic which yields the highest,
that is, most accurate, estimate:
drmax ({h1 , . . . , hn }, s) := hargmax1in hi (s) .
Using this decision rule yields a heuristic which is as accurate as maxh , while still computing only
one heuristic per state  in time targmax1in hi (s) .
This analysis, however, does not take into account the different computation times of the different heuristics. For instance, let h1 and h2 be a pair of admissible heuristics such that h2  h1 .
A priori, it seems that using h2 should always be preferred to using h1 because the former should
cause A to expand fewer states. However, suppose that on a given planning task, A expands 1000
states when guided by h1 and only 100 states when guided by h2 . If computing h1 for each state
takes 10 ms, and computing h2 for each state takes 1000 ms, then switching from h1 to h2 increases
the overall search time. Using maxh over h1 and h2 only makes things worse, because h2  h1 ,
and thus computing the maximum simply wastes the time spent on computing h1 . It is possible,
however, that computing h2 for a few carefully chosen states, and computing h1 for all other states,
would result in expanding 100 states, while reducing the overall search time when compared to
running A with only h2 .
As this example shows, even given knowledge of the heuristics estimates in advance, it is not
clear what heuristic should be computed at each state when our objective is to minimize the overall
search time. Therefore, we begin by formulating a decision rule for choosing between one of two
heuristics, with respect to an idealized state-space model. Selective max then operates as an online
712

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

s0

s
f2 = c

f1 = c
sg

Figure 1: An illustration of the idealized search space model and the f -contours of two admissible
heuristics

active learning procedure, attempting to predict the outcome of that decision rule and choose which
heuristic to compute at each state.
4.1 Decision Rule with Perfect Knowledge
We now formulate a decision rule for choosing which of two given admissible heuristics, h1 and h2 ,
to compute for each state in an idealized search space model. In order to formulate such a decision
rule, we make the following assumptions:
 The search space is a tree with a single goal, constant branching factor b, and uniform cost
actions. Such an idealized search space model was used in the past to analyze the behavior of
A (Pearl, 1984).
 The time ti required for computing heuristic hi is independent of the state being evaluated;
w.l.o.g. we assume t2  t1 .
 The heuristics are consistent. A heuristic h is said to be consistent if it obeys the triangle
inequality: For any two states s, s0 , h(s)  h(s0 ) + k(s, s0 ), where k(s, s0 ) is the optimal cost
of reaching s0 from s.
 We have: (i) perfect knowledge about the structure of the search tree, and in particular the
cost of the optimal solution c , (ii) perfect knowledge about the heuristic estimates for each
state, and (iii) a perfect tie-breaking mechanism.
Obviously, none of the above assumptions holds in typical search problems, and later we examine
their individual influence on our framework.
Adopting the standard notation, let g(s) be the cost of the cheapest path from s0 to s. Defining
maxh (s) = max(h1 (s), h2 (s)), we then use the notation f1 (s) = g(s) + h1 (s), f2 (s) = g(s) +
h2 (s), and maxf (s) = g(s) + maxh (s). The A algorithm with a consistent heuristic h expands
states in increasing order of f = g + h (Pearl, 1984). In particular, every state s with f (s) <
h (I) = c will surely be expanded by A , and every state with f (s) > c will surely not be
713

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

expanded by A . The states with f (s) = c might or might not be expanded by A , depending on
the tie-breaking rule being used. Under our perfect tie-breaking assumption, the only states with
f (s) = c that will be expanded are those that lie along some optimal plan.
Let us consider the states satisfying f1 (s) = c (the dotted line in Fig. 1) and those satisfying
f2 (s) = c (the solid line in Fig. 1). The states above the f1 = c and f2 = c contours are those
that are surely expanded by A with h1 and h2 , respectively. The states above both these contours
(the grid-marked region in Fig. 1), that is, the states SE = {s | maxf (s) < c }, are those that are
surely expanded by A using maxh (Pearl, 1984, Thm. 4, p. 79).
Under the objective of minimizing the search time, note that the optimal decision for any state
s  SE is not to compute any heuristic at all, since all these states are surely expanded anyway.
Assuming that we still must choose one of the heuristics, we would choose to compute the cheaper
heuristic h1 . Another easy case is when f1 (s)  c . In these states, computing h1 (s) suffices to
ensure that s is not surely expanded, and using a perfect tie-breaking rule, s will not be expanded
unless it must be. Because h1 is also cheaper to compute than h2 , h1 should be preferred, regardless
of the heuristic estimate of h2 for state s.
Let us now consider the optimal decision for all other states, that is, those with f1 (s) < c and
f2 (s)  c . In fact, it is enough to consider only the shallowest such states; in Figure 1, these are the
states on the part of the f2 = c contour that separates between the grid-marked and line-marked
areas. Since f1 (s) and f2 (s) are based on the same g(s), we have h2 (s) > h1 (s), that is, h2 is
more accurate in state s than h1 . If we were interested solely in reducing state expansions, then h2
would obviously be the right heuristic to compute at s. However, for our objective of reducing the
actual search time, h2 may actually be the wrong choice because it might be much more expensive
to compute than h1 .
Let us consider the effects of each of our two alternatives. If we compute h2 (s), then s is
not surely expanded, because f2 (s) = c , and thus whether or not A expands s depends on tiebreaking. As before, we are assuming perfect tie-breaking, and thus s will not be expanded unless
it must be. Computing h2 would cost us t2 time.
In contrast, if we compute h1 (s), then s is surely expanded because f1 (s) < c . Note that not
computing h2 for s and then computing h2 for one of the descendants s0 of s is clearly a sub-optimal
strategy as we do pay the cost of computing h2 , yet the pruning of A is limited only to the search
sub-tree rooted in s0 . Therefore, our choices are really either computing h2 for s, or computing h1
for all the states in the sub-tree rooted in s that lie on the f1 = c contour. Suppose we need to
expand l complete levels of the state space from s to reach the f1 = c contour. Thus, we need to
generate an order of bl states, and then invest bl t1 time in calculating h1 for all these states that lie
on the f1 = c contour.
Considering these two options, the optimal decision in state s is thus to compute h2 iff t2 < bl t1 ,
or to express it differently, if l > logb ( tt12 ). As a special case, if both heuristics take the same time to
compute, this decision rule reduces to l > 0, that is, the optimal choice is simply the more accurate
heuristic for state s.
Putting all of the above cases together yields the decision rule dropt , as below, with ls being the
depth to go from s until f1 (s) = c :
714

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING



h1 , f1 (s) < c , f2 (s) < c



h , f (s)  c
1
1
.
dropt ({h1 , h2 }, s) :=

h1 , f1 (s) < c , f2 (s)  c , ls  logb ( tt12 )



h , f (s) < c , f (s)  c , l > log ( t2 )
2
1
2
s
b t1
4.2 Decision Rule without Perfect Knowledge
The idealized model above makes several assumptions, some of which appear to be very problematic
to meet in practice. Here we examine these assumptions more closely, and when needed, suggest
pragmatic compromises.
First, the model assumes that the search space forms a tree with a single goal state, that the
heuristics in question are consistent, and that we have a perfect tie-breaking rule. Although the
first assumption does not hold in most planning tasks, the second assumption is not satisfied by
many state-of-the-art heuristics (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009; Bonet
& Helmert, 2010), and the third assumption is not realistic, they do not prevent us from using the
decision rule suggested by the model.
The idealized model also assumes that both the branching factor and the heuristic computation
times are constant across the search states. In our application of the decision rule to planning
in practice, we deal with this assumption by adopting the average branching factor and heuristic
computation times, estimated from a random sample of search states.
Finally, the decision rule dropt above requires unrealistic knowledge of both heuristic estimates,
as well as of the optimal plan cost c and the depth ls to go from state until f1 (s) = c . As we
obviously do not have this knowledge in practice, we must use some approximation of the decision
rule.
The first approximation we make is to ignore the trivial cases that require knowledge of c ;
these are the cases where either s is surely expanded, or h1 is enough to prune s. Instead, we apply
the reasoning for the complicated case for all states, resulting in the following decision rule:
(
h1 , ls  logb ( tt12 )
drapp1 ({h1 , h2 }, s) :=
.
h2 , ls > logb ( tt21 )
The next step is to somehow estimate the depth to go ls  the number of layers we need to
expand in the tree until f1 reaches c . In order to derive a useful decision rule, we assume that ls
has a positive correlation with h (s) = h2 (s)  h1 (s); that is, if h1 and h2 are close, then ls is low,
and if h1 yields a much lower estimate than h2 , implying that h1 is not very accurate for s, then the
depth to go until f1 (s) = c is large. Our approximation uses the simplest such correlation  a
linear one  between h (s) and ls , with a hyper-parameter  for controlling the slope.
Recall that in our idealized model, all actions were unit cost, and thus cost-to-go and depthto-go are the same. However, some planning tasks, and notably, all planning tasks from the 2008
International Planning Competition, feature non-uniform action costs. Therefore, our decision rule
converts heuristic estimates of cost-to-go into heuristic estimates of depth-to-go by dividing the
cost-to-go estimate by the average action cost. We do this by modifying our estimate of the depthto-go, ls , with the average action cost, which we denote by c. Plugging all of the above into our
715

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

decision rule yields:
(
h1 ,
drapp2 ({h1 , h2 }, s) :=
h2 ,

h (s)    c  logb ( tt12 )
.
h (s) >   c  logb ( tt21 )

Given b, t1 , t2 , and c, the quantity   c  logb (t2 /t1 ) becomes fixed, and in what follows we denote
it simply by threshold  .
Note that linear correlation between h (s) and ls occurs in some simple cases. The first such
case is when the h1 value remains constant in the subtree rooted at s, that is, the additive error of
h1 increases by 1 for each level below s. In this case, f1 increases by 1 for each expanded level of
the sub-tree (because h1 remains the same, and g increases by 1), and it will take expanding exactly
h (s) = h2 (s)  h1 (s) levels to reach the f1 = c contour. The second such case is when the
absolute error of h1 remains constant, that is, h1 increases by 1 for each level expanded, and so f1
increases by 2. In this case, we will need to expand h (s)/2 levels. This can be generalized to the
case where the estimate h1 increases by any constant additive factor c, which results in h (s)/(c+1)
levels being expanded.
Furthermore, there is some empirical evidence to support our conclusion about exponential
growth of the search effort as a function of heuristic error, even when the assumptions made by the
model do not hold. In particular, the experiments of Helmert and Roger (2008) on IPC benchmarks
with heuristics with small constant additive errors show that the number of expanded nodes most
typically grows exponentially as the (still very small and additive) error increases.
Finally, we remark that because our decision rule always chooses an admissible heuristic, the
resulting heuristic estimate will always be admissible. Thus, even if the chosen heuristic is not the
correct one according to dropt , this will not result in loss of optimality of the solution, but only in
a possible increase in search time.

5. Online Learning of the Decision Rule
While decision rule drapp2 still requires knowledge of h1 and h2 , we can now use it as a binary
label for each state. We can compute the value of the decision rule by paying the computation
time of both heuristics, t1 + t2 , and, more importantly, we can use a binary classifier to predict the
value of this decision rule for some unknown state. Note that we use the classifier online, during the
problem solving process, and the time spent on learning and classification is counted as time spent
on problem solving. Furthermore, as in active learning, we can choose to pay for a label for some
state, where the payment is also in computation time. Therefore we refer to our setting as active
online learning.
In what follows, we provide a general overview of the selective max procedure, and describe
several alternatives for each of its components. Our decision rule states that the more expensive
heuristic h2 should be computed at a search state s when h2 (s)  h1 (s) >  . This decision rule
serves as a binary target concept, which corresponds to the set of states where the more expensive
heuristic h2 is significantly more accurate than the cheaper heuristic h1  the states where, according to our model, the reduction in expanded states by computing h2 outweighs the extra time
needed to compute it. Selective max then uses a binary classifier to predict the value of the decision
rule. There are several steps to building the classifier:
716

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

evaluate(s)
hh, conf idencei := CLASSIFY(s, model)
if (conf idence > ) then
return h(s)
else
label := h1
if h2 (s)  h1 (s) >   c  logb (t2 /t1 ) then label := h2
update model with hs, labeli
return max(h1 (s), h2 (s))
Figure 2: The selective max state evaluation procedure
1. Training Example Collection: We first need to collect training examples, which should be
representative of the entire search space. Several state-space sampling methods are discussed
in Section 5.1.
2. Labeling Training Examples: After the training examples are collected, they are first used to
estimate the average branching factor b, average heuristic computation times t1 and t2 , and
the average action cost c. Once b, t1 , t2 , and c are estimated, we use them to estimate the
threshold  =   c  logb (t2 /t1 ) for the decision rule.
We then generate a label for each training example by calculating h (s) = h2 (s)  h1 (s),
and comparing it to the decision threshold: If h (s) >  , we label s with h2 , otherwise with
h1 . If t1 > t2 we simply switch between the heuristics  our decision is always whether or
not to compute the more expensive heuristic; the default is to compute the cheaper heuristic,
unless the classifier says otherwise.
3. Feature Extraction: Having obtained a set of training examples, we must decide about the
features to characterize each example. Since our target concept is based on heuristic values,
the features should represent the information that heuristics are derived from  typically the
problem description and the current state.
While several feature-construction techniques for characterizing states of planning tasks have
been proposed in previous literature (Yoon, Fern, & Givan, 2008; de la Rosa, Jimenez, &
Borrajo, 2008), they were all designed for inter-problem learning, that is, for learning from
different planning tasks which have already been solved offline. However, in our approach,
we are only concerned with one problem, in an online setting, and thus these techniques are
not applicable. In our implementation, we use the simplest features possible, taking each
state variable as a feature. As our empirical evaluation demonstrates, even these elementary
features suffice for selective max to perform well.
4. Learning: Once we have a set of labeled training examples, each represented by a vector of
features, we can train a binary classifier. Several different choices of classifier are discussed
in Section 5.2.
After completing the steps described above, we have a binary classifier that can be used to
predict the value of our decision rule. However, as the classifier is not likely to have perfect accuracy,
717

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

we further consult the confidence the classifier associates with its classification. The resulting state
evaluation procedure of selective max is depicted in Figure 2. For every state s evaluated by the
search algorithm, we use our classifier to decide which heuristic to compute. If the classification
confidence exceeds a confidence threshold , a parameter of selective max, then only the indicated
heuristic is computed for s. Otherwise, we conclude that there is not enough information to make
a selective decision for s, and compute the regular maximum over h1 (s) and h2 (s). However, we
use this opportunity to improve the quality of our prediction for states similar to s, and update our
classifier by generating a label based on h2 (s)h1 (s) and learning from the newly labeled example.
These decisions to dedicate computation time to obtain a label for a new example constitute the
active part of our learning procedure. It is also possible to update the estimates for b, t1 , t2 , and c,
and change the threshold  accordingly. However, this would result in the concept we are trying
to learn constantly changing  a phenomenon known as concept drift  which usually affects
learning adversely. Therefore, we do not update the threshold  .
5.1 State-Space Sampling
The initial state-space sample serves two purposes. First, it is used to estimate the branching factor
b, the heuristic computation times t1 and t2 , the average action cost c, and then to compute the
threshold  =   c  logb (t2 /t1 ), which is used to specify our concept. After the concept is specified,
the state-space sample also provides us with a set of examples on which the classifier is initially
trained. Therefore, it is important to have an initial state-space sample that is representative of the
states which will be evaluated during search. The number of states in the initial sample is controlled
by a parameter N .
One option is to use the first N states of the search. However, this method is biased towards
states closer to the initial state, and therefore is not likely to represent the search space well. Thus,
we discuss three more sophisticated state-space sampling procedures, all of which are based on
performing random walks, or probes, from the initial state. While the details of these sampling
procedures vary, each such probe terminates at some pre-set depth limit.
The first sampling procedure, which we refer to as biased probes, uses an inverse heuristic
selection bias for choosing the next state to go to in the probe. Specifically, the probability of
choosing state s as the successor from which the random walk will continue is proportional to
1/ maxh (s). This biases the sample towards states with lower heuristic estimates, which are more
likely to be expanded during the search.
The second sampling procedure is similar to the first one, except that it chooses the successor
uniformly, and thus we refer to it as unbiased probes. Both these sampling procedures add all
of the generated states (that is, the states along the probe as well as their siblings) to the statespace sample, and they both terminate after collecting N training examples. The depth limit for all
random walks is the same in both sampling schemes, and is set to some estimate of the goal depth;
we discuss this goal depth estimate later.
The third state-space sampling procedure, referred to here as PDB sampling, has been proposed
by Haslum, Botea, Helmert, Bonet, and Koenig (2007). This procedure also uses unbiased probes,
but only adds the last state reached in each probe to the state-space sample. The depth of each
probe is determined individually, by drawing a random depth from a binomial distribution around
the estimated goal depth.
718

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

Note that all three sampling procedures rely on some estimate of the minimum goal depth.
When all actions are unit cost, the minimum goal depth is the same as h (s0 ), and thus we can use
a heuristic to estimate it. In our evaluation, we used twice the heuristic estimate of the initial state,
2  maxh (s0 ), as the goal depth estimate. However, with non-uniform action costs, goal depth and
cost are no longer measured in the same units. While it seems we could divide the above heuristicbased estimate by the average action cost c, recall that we use the state-space sample in order to
obtain an estimate for estimate c, thus creating a circular dependency. Although it is possible to
estimate c by taking the average cost of all actions in the problem description, there is no reason
to assume that all actions are equally likely to be used. Another option is to modify the above
state-space sampling procedures, and place a cost limit, rather than a depth limit, on each probe.
However, this would pose a problem in the presence of 0-cost actions. In such a case, when a probe
reaches its cost limit yet has a possible 0-cost action to apply, it is not clear whether the probe
should terminate. Therefore, we keep using depth-limited probes and attempt to estimate the depth
of the cheapest goal. We compute a heuristic estimate for the initial state, and then use the number
of actions which the heuristic estimate is based on as our goal depth estimate. While this is not
possible with every heuristic, we use in our empirical evaluation the monotonically-relaxed plan
heuristic. This heuristic, also known as the FF heuristic (Hoffmann & Nebel, 2001), does provide
such information: we first use this heuristic to find a relaxed plan from the initial state, and then use
the number of actions in the relaxed plan as our goal depth estimate.
5.2 Classifier
The last decision to be made is the choice of classifier. Although many classifiers can be used here,
several requirements must be met due to our particular setup. First, both training and classification must be very fast, as both are performed during time-constrained problem solving. Second,
the classifier must be incremental to support active learning. This is achieved by allowing online
updates of the learned model. Finally, the classifier should provide us with a meaningful measure
of confidence for its predictions.
While several classifiers meet these requirements, we found the Naive Bayes classifier to provide
a good balance between speed and accuracy. One note on the Naive Bayes classifier is that it
assumes a very strong conditional independence between the features. Although this is not a fully
realistic assumption for planning tasks, using a SAS+ task formulation in contrast to the classical
STRIPS formulations helps a lot: instead of many highly dependent binary variables, we have a
much smaller set of less dependent ones.
Although, as the empirical evaluation will demonstrate, Naive Bayes appears to be the most
suitable classifier to use with selective max, other classifiers can also be used. The most obvious
choice for a replacement classifier would be a different Bayesian classifier. One such classifier is
AODE (Webb, Boughton, & Wang, 2005), an extension of Naive Bayes, which somewhat relaxes
the assumption of independence between the features, and is typically more accurate than Naive
Bayes. However, this added accuracy comes at the cost of increased training and classification time.
Decision trees are another popular type of classifier that allows for even faster classification.
While most decision tree induction algorithms are not incremental, the Incremental Tree Inducer
(ITI) algorithm (Utgoff, Berkman, & Clouse, 1997) supports incremental updating of decision trees
by tree restructuring, and also has a freely available implementation in C. In our evaluation, we used
ITI in incremental mode, and incorporated every example into the tree immediately, because the
719

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

tree is likely to be used for many classifications between pairs of consecutive updates with training
examples from active learning. The classification confidence with the ITI classifier is obtained by
the frequency of examples at the leaf node from which the classification came.
A different family of possible classifiers is k-Nearest Neighbors (kNN) (Cover & Hart, 1967).
In order to use kNN, we need a distance metric between examples, which, with our features, are
simply states. As with our choice of features, we opt for simplicity and use Euclidean distance
as our metric. kNN enjoys very fast learning time but suffers from slow classification time. The
classification confidence is obtained by a simple (unweighted) vote between the k nearest neighbors.
Another question related to the choice of classifier is feature selection. In some planning tasks,
the number of variables, and accordingly, features, can be over 2000 (for example, task 35 of the
AIRPORT domain has 2558 variables). While the performance of Naive Bayes and kNN can likely be
improved using feature selection, doing so poses a problem when the initial sample is considered.
Since feature selection will have to be done right after the initial sample is obtained, it will have to
be based only on the initial sample. This could cause a problem since some features might appear to
be irrelevant according to the initial sample, yet turn out to be very relevant when active learning is
used after some low-confidence states are encountered. Therefore, we do not use feature selection
in our empirical evaluation of selective max.
5.3 Extension to Multiple Heuristics
To this point, we have discussed how to choose which heuristic to compute for each state when
there are only two heuristics to choose from. When given more than two heuristics, the decision
rule presented in Section 4 is inapplicable, and extending it to handle more than two heuristics is
not straightforward. However, extending selective max to use more than two heuristics is straightforward  simply compare heuristics in a pair-wise manner, and use a voting rule to choose which
heuristic to compute.
While there are many possible such voting rules, we go with the simplest one, which compares
every pair of heuristics, and chooses the winner by a vote, weighted by the confidence for each pairwise decision. The overall winner is simply the heuristic which has the highest total confidence from
all pairwise comparisons, with ties broken in favor of the cheaper-to-compute heuristic. Although
this requires a quadratic number of classifiers, training and classification time (at least with Naive
Bayes) appear to be much lower than the overall time spent on heuristic computations, and thus
the overhead induced by learning and classification is likely to remain relatively low for reasonable
heuristic ensembles.

6. Experimental Evaluation
To evaluate selective max empirically, we implemented it on top of the open-source Fast Downward
planner (Helmert, 2006). Our empirical evaluation is divided into three parts. First, we examine the performance of selective max using the last International Planning Competition, IPC-2011,
as our benchmark. Selective max was the runner-up ex-aequo at IPC-2011, tying for 2nd place
with a version of Fast Downward using an abstraction merge-and-shrink heuristic (Nissim, Hoffmann, & Helmert, 2011), and losing to a sequential portfolio combining the heuristics used in both
runners-up (Helmert, Roger, & Karpas, 2011). Second, we present a series of controlled parametric
experiments, where we examine the behavior of selective max under different settings. Finally, we
720

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

Parameter


N
Sampling method
Classifier

Default value
1
0.6
1000
Biased probes
Naive Bayes

Meaning
heuristic difference bias
confidence threshold
initial sample size
state-space sampling method
classifier type

Table 1: Parameters for the selmax entry in IPC-2011.
compare selective max to a simulated sequential portfolio, using the same heuristics as selective
max.
6.1 Performance Evaluation: Results from IPC-2011
The IPC-2011 experiments (Garca-Olaya et al., 2011) were run by the IPC organizers, on their
own machines, with a time limit of 30 minutes and a memory limit of 6 GB per planning task.
The competition included some new domains, which none of the participants had seen before, thus
precluding the participants from using offline learning approaches.
Although many planners participated in the sequential optimal track of IPC-2011, we report here
only the results relevant to selective max. The selective max entry in IPC-2011 was called selmax,
and consisted of selective max over the uniform action cost partitioning version of hLA (Karpas &
Domshlak, 2009) and hLM-CUT (Helmert & Domshlak, 2009) heuristics. The parameters used for
selective max in IPC-2011 are reported in Table 1. Additionally, each of the heuristics selmax used
was entered individually as BJOLP (hLA ) and lmcut (hLM-CUT ), and we report results for all three
planners. While a comparison of selective max with the regular maximum of hLA and hLM-CUT
would be interesting, there was no such entry at IPC-2011, and thus we can not report on it. In our
controlled experiments, we do compare selective max to the regular maximum, as well as to other
baseline combination methods.
Figure 3 shows the anytime profile of these three planners on IPC-2011 tasks, plotting the number of tasks solved under different timeouts, up to the time limit of 30 minutes. Additionally, Table
2 shows the number of tasks solved in each domain of IPC-2011, after 30 minutes, and includes the
number of problems solved by the winner, Fast Downward Stone Soup 1 (FDSS-1), for reference.
As these results show, selective max solves more problems than each of the individual heuristics
it uses. Furthermore, the anytime profile of selective max dominates each of these heuristics, in the
range between 214 seconds until the full 30 minute timeout. The behavior of the anytime plot with
shorter timeouts is due to the overhead of selective max, which consists of obtaining the initial statespace sample, as well as learning and classification. However, it appears that selective max quickly
compensates for its relatively slow start.
6.2 Controlled Experiments
In our series of controlled experiments, we attempted to evaluate the impact of different parameters
on selective max. We controlled the following independent variables:
 Heuristics: We used three state-of-the-art admissible heuristics: hLA (Karpas & Domshlak,
2009), hLM-CUT (Helmert & Domshlak, 2009), and hLM-CUT+ (Bonet & Helmert, 2010). None
721

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

160

Solved Instances

140

120

100

80

BJOLP
lmcut
selmax

60
0

200

400

600

800
1000
Timeout (seconds)

1200

1400

1600

1800

Figure 3: IPC-2011 anytime performance. Each line shows the number of problems from IPC-2011
solved by the BJOLP, lmcut, and selmax planners, respectively, under different timeouts.
Domain
barman
elevators
floortile
nomystery
openstacks
parcprinter
parking
pegsol
scanalyzer
sokoban
tidybot
transport
visitall
woodworking
TOTAL

BJOLP
4
14
2
20
14
11
3
17
6
20
14
7
10
9
151

lmcut
4
18
7
15
16
13
2
18
12
20
14
6
10
12
167

selmax
4
18
7
20
14
13
4
17
10
20
14
6
10
12
169

FDSS-1
4
18
7
20
16
14
7
19
14
20
14
7
13
12
185

Table 2: Number of planning tasks solved at IPC 2011 in each domain by the BJOLP, lmcut, and
selmax planners. The best result from these 3 planners is in bold. The number of problems
solved by Fast Downward Stone Soup 1 (FDSS-1) in each domain is also included for
reference.

722

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

of these base heuristics yields better search performance than the others across all planning
domains. Of these heuristics, hLA is typically the fastest to compute and the least accurate,
hLM-CUT is more expensive to compute and more accurate, and hLM-CUT+ is the most expensive to compute and the most accurate.1 From the data we have gathered in these experiments,
hLM-CUT takes on average 4.5 more time per state than hLA , and hLM-CUT+ takes 53 more time
per state than hLA . We evaluate selective max with all possible subsets of two or more of these
three heuristics.
While there are other admissible heuristics for SAS+ planning that are competitive with the
three above (for example, Helmert, Haslum, & Hoffmann, 2007; Nissim et al., 2011; Katz &
Domshlak, 2010), they are based on expensive offline preprocessing, followed by very fast
online per-state computation. In contrast, hLA , hLM-CUT and hLM-CUT+ perform most of their
computation online, and thus can be better exploited by selective max.
Additionally, we empirically examine the effectiveness of selective max in deciding whether
to compute a heuristic value at all. This is done by combining our most accurate heuristic,
hLM-CUT+ , with the blind heuristic.
 Heuristic difference bias : The hyper-parameter  controls the tradeoff between computation time and heuristic accuracy. Setting  = 0 sets the threshold  to 0, forcing the decision
rule to always choose the more accurate heuristic. Increasing  increases the threshold, forcing the decision rule to choose the more accurate heuristic h2 only if its value is much higher
than that of h1 . We evaluate selective max with values for  of 0.1, 0.5, 1, 1.5, 2, 3, 4, and 5.
 Confidence threshold : The confidence threshold  controls the active learning part of selective max. Setting  = 0.5 turns off active learning completely, because the chosen heuristic
always comes with a confidence of at least 0.5. Setting  = 1 would mean using active learning almost always, essentially reducing selective max to regular point-wise maximization. We
evaluate selective max with values for  of 0.51, 0.6, 0.7, 0.8, 0.9, and 0.99.
 Initial sample size N : The initial sample size N is an important parameter, not just because it
is used to train the initial classifier before any active learning is done, but also because it is the
only source of estimates for branching factor, average action cost, and heuristic computation
times. It thus affects the threshold  : Increasing N increases the accuracy of the initial
classifier and of the various aforementioned estimates, but also increases the preprocessing
time. We evaluate selective max with values for N of 10, 100, and 1000.
 Sampling method: The sampling method used to obtain the initial state-space sample is important in that it affects this initial sample, and thus the accuracy of both the threshold  and
of the initial classifier. We evaluate selective max with three different sampling methods, all
P
described in Section 5.1: biased probes (selPh ), unbiased probes (selU
h ), and the sampling
method of Haslum et al. (2007) (selPDB
h ).
 Classifier: The choice of classifier is also very important. The Naive Bayes classifier comB
bines very fast learning and classification (selN
h ). A more sophisticated variant of Naive
Bayes called AODE (Webb et al., 2005) is also considered here (selAODE
). AODE is more
h
1. Of course, all three heuristics are computable in polynomial time from the SAS+ description of the planning task.

723

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

Parameter
Heuristics


N
Sampling method
Classifier

Default value
hLA / hLM-CUT
1
0.6
100
PDB (Haslum et al., 2007)
Naive Bayes

Meaning
heuristics used
heuristic difference bias
confidence threshold
initial sample size
state-space sampling method
classifier type

Table 3: Default parameters for selh .
accurate than Naive Bayes, but has higher classification and learning times, as well as increased memory overhead. Another possible choice is using incremental decision trees (Utgoff et al., 1997), which offer even faster classification, but more expensive learning when the
I
tree structure needs to be changed (selIT
h ). We also consider kNN classifiers (Cover & Hart,
1967), which offer faster learning than Naive Bayes, but usually more expensive classificaN
tion, especially as k grows larger (selkN
, for k = 3, 5).
h
Table 3 describes our default values for each of these independent variables. In each of the
subsequent experiments, we vary one of these independent variables, keeping the rest at their default
values. In all of these experiments, the search for each planning task instance was limited to 30
minutes2 and to 3 GB of memory. The search times do not include the time needed for translating
the planning task from PDDL to SAS+ and building some of the Fast Downward data structures,
which is common to all planners, and is tangential to the issues considered in our study. The search
times do include learning and classification time for selective max.
 Heuristics
We begin by varying the set of heuristics in use. For every possible choice of two or more
heuristics out of the uniform action cost partitioning version of hLA (which we simply refer
to as hLA ), hLM-CUT and hLM-CUT+ , we compare selective max to other methods of heuristic
combination, as well as to the individual heuristics. We compare selective max (selh ) to the
regular maximum (maxh ), as well as to a planner which chooses which heuristic to compute
at each state randomly (rndh ). As it is not clear whether the random choice should favor the
more expensive and accurate heuristic or the cheaper and less accurate one, we simply use a
uniform random choice.
This experiment was conducted on all 31 domains with no conditional effects and axioms
(which none of the heuristics we used support) from the International Planning Competitions
19982008. Because domains vary in difficulty and in the number of tasks, we normalize
the score for each planner in each domain between 0 and 1. Normalizing by the number of
problems in the domain is not a good idea, as it is always possible to generate any number
of effectively unsolvable problems in each domain, so that the fraction of solved problems
will approach zero. Therefore, we normalize the number of problems solved in each domain
by the number of problems in that domain that were solved by at least one of our planners.
While this measure of normalized coverage has the undesirable property that introducing a
2. Each search was given a single core of a 3GHz Intel E8400 CPU machine.

724

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

Heuristic

hLA

hLM-CUT

hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost

0.89 (175)
0.98 (345)
0.80 (136)

0.83 (136)
0.96 (343)
0.94 (160)

0.81 (132)
0.94 (336)
0.86 (146)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

(a) Individual Heuristics
Domains
High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

maxh
0.90 (164)
0.97 (345)
0.92 (156)
0.94 (665)

rndh
0.74 (123)
0.95 (342)
0.79 (138)
0.85 (603)

selh
0.93 (174)
0.97 (346)
0.93 (157)
0.95 (677)

hLA / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.84 (149)
0.93 (335)
0.85 (144)
0.89 (628)

0.68 (115)
0.88 (327)
0.71 (122)
0.78 (564)

0.90 (164)
0.96 (342)
0.86 (145)
0.92 (651)

hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.80 (131)
0.94 (336)
0.87 (147)
0.89 (614)

0.75 (122)
0.93 (335)
0.86 (145)
0.87 (602)

0.80 (130)
0.97 (344)
0.93 (156)
0.91 (630)

hLA / hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.84 (149)
0.93 (335)
0.85 (144)
0.89 (628)

0.69 (116)
0.90 (332)
0.75 (130)
0.81 (578)

0.87 (154)
0.97 (345)
0.89 (150)
0.92 (649)

Heuristics
hLA / hLM-CUT

(b) Combinations of two or more heuristics

Table 4: Average normalized coverage, and total coverage in parentheses, broken down by groups
of domains with unit cost actions and high variance in coverage, domains with unit cost
actions and low variance in coverage, and domains with non-uniform action costs. Table
(a) shows the results for A with individual heuristics, and table (b) shows the results for
the maximum (maxh ), random choice (rndh ), and selective max (selh ) combinations of
the set of heuristics listed in each major row.

new planner could change the normalized coverage of the other planners, we believe that
it best reflects performance nonetheless. As an overall performance measure, we list the
average normalized coverage score across all domains. Using normalized coverage means
that domains have equal weight in the aggregate score. Additionally, we list for each domain
the number of problems that were solved by any planner (in parentheses next to the domain
name), and for each planner we list the number of problems it solved in parentheses.
Tables 4 and 5 summarize the results of this experiment. We divided the domains in our
experiment into 3 sets: domains with non-uniform action costs, domains with unit action
costs which exhibited a high variance in the number of problems solved between different
725

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

Heuristics

Domains

hLA

hLM-CUT

hLA / hLM-CUT

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

3.23
3.48
13.23
4.82

2.8
1.14
1.01
1.4

hLA / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

4.01
4.55
13.66
5.85

hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

hLA / hLM-CUT / hLM-CUT+

hLM-CUT+

maxh

rndh

selh

1.0
1.0
1.0
1.0

3.88
2.14
3.99
2.93

1.46
1.2
1.17
1.25

1.77
1.01
1.0
1.16

1.0
1.0
1.0
1.0

3.17
2.38
3.85
2.9

2.16
1.85
1.72
1.89

2.29
1.58
1.32
1.66

1.01
1.01
1.03
1.01

1.0
1.0
1.0
1.0

1.7
1.29
1.18
1.35

1.24
1.19
1.16
1.2

High variance unit cost
Low variance unit cost
Non-uniform cost

4.06
4.65
15.2

3.81
1.59
1.37

1.78
1.02
1.03

1.0
1.0
1.0

3.61
2.05
2.74

2.1
1.57
1.49

TOTAL

6.1

1.91

1.18

1.0

2.56

1.67

Table 5: Geometric mean of ratio of expansions relative to maxh , broken down by groups of domains with unit cost actions and high variance in coverage, domains with unit cost actions
and low variance in coverage, and domains with non-uniform action costs.

planners, and domains with unit action costs which exhibited a low variance in the number of
problems solved between different planners. We make this distinction because we conducted
the following experiments, which examine the effects of the other parameters of selective
max, only on the unit cost action domains which exhibited high variance. Tables 4 and 5
summarize the results for these three sets of domains, as well as for all domains combined.
Detailed, per-domain results are relegated to Appendix A.
Table 4 lists the normalized coverage score, averaged across all domains, and the total number
of problems solved in parentheses. Table 4a lists these for each individual heuristic, and
Table 4b for every combination method of every set of two or more heuristics. Table 5 shows
how accurate each of these heuristic combination methods is. Since, for a given set of base
heuristics, maxh is the most accurate heuristic possible, the accuracy is evaluated relative to
maxh . We evaluate each heuristics accuracy on each task as the number of states expanded
by A using that heuristic, divided by the number of states expanded by A using maxh . We
compute the geometric mean for each domain over the tasks solved by all planners of this
accuracy ratio, and list here the geometric mean over these numbers. Each row lists the
results for a combination of two or three heuristics; for combinations of two heuristics, we
leave the cell representing the heuristic that is not in the combination empty.
Looking at the results of individual heuristics first, we see that the most accurate heuristic
(hLM-CUT+ ) does not do well overall, while the least accurate heuristic (hLA ) solved the most
tasks in total, and hLM-CUT wins in terms of normalized coverage. However, when looking at
the results for individual domains, we see that the best heuristic to use varies, indicating that
combining different heuristics could indeed be of practical value.
We now turn our attention to the empirical results for the combinations of all possible subsets
of two or more heuristics. The results clearly demonstrate that when more than one heuristic
is used, selective max is always better than regular maximum or random choice, both in terms
of normalized coverage and absolute number of problems solved. Furthermore, the poor
performance of rndh , in both coverage and accuracy, demonstrates that the decision rule and
726

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

700

650

Solved Instances

600

550

500

450

400
maxh

350

rndh
selh

300
200

400

600

800
1000
Timeout (seconds)

1200

1400

1600

1800

Figure 4: hLA / hLM-CUT / hLM-CUT+ anytime profile. Each line shows the number of problems from
IPC 1998  2006 solved by the maximum (maxh ), random choice (rndh ), and selective
max (selh ) combination methods of the hLA , hLM-CUT , and hLM-CUT+ heuristics, under
different timeouts.

the classifier used in selective max are important to its success, and that computing only one
heuristic at each state randomly is insufficient, to say the least.
When compared to individual heuristics, selective max does at least as well as each of the
individual heuristics it uses, for all combinations except that of hLM-CUT and hLM-CUT+ . This
is most likely because hLM-CUT and hLM-CUT+ are based on a very similar procedure, and
thus their heuristic estimates are highly correlated. To see why this hinders selective max,
consider the extreme case of two heuristics which have a correlation of 1.0 (that is, yield the
same heuristic values), where selective max can offer no benefit. Finally, we remark that the
best planner in this experiment was the selective max combination of hLA and hLM-CUT .
The above results are all based on a 30 minute time limit, which, while commonly used in the
IPC, is arbitrary, and the number of tasks solved after 30 minutes does not tell the complete
tale. Here, we examine the anytime profile of the different heuristic combination methods, by
plotting the number of tasks solved under different timeouts, up to a timeout of 30 minutes.
Figure 4 shows this plot for the three combination methods when all three heuristics are used.
As the figure shows, the advantage of selh over the baseline combination methods is even
greater under shorter timeouts. This indicates that the advantage of selh over maxh is even
727

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

Heuristics
hLA / hLM-CUT

Overhead
12%

hLA / hLM-CUT+

15%

hLM-CUT / hLM-CUT+

9%

hLA / hLM-CUT / hLM-CUT+

10%

Table 6: Selective max overhead. Each row lists the average percentage of time spent on learning
and classification, out of the total time taken by selective max, for each set of heuristics.

greater than is evident from the results after 30 minutes, and that selh is indeed effective for
minimizing search time. Since the anytime plots for the combinations of pairs of heuristics
are very similar, we omit them here for the sake of brevity.
Finally, we present overhead statistics for using selective max  the proportion of time spent
on learning and classification, including the time spent obtaining the initial state-space sample, out of the total solution time. Table 6 presents the average overhead on selective max
for each of the combinations of two or more heuristics. Detailed, per-domain results are
presented in Table 18 in Appendix A. As these results show, selective max does incur a noticeable overhead, but it is still relatively low. It is also worth mentioning that the overhead
varies significantly between different domains.
We also performed an empirical evaluation of using selective max with an accurate heuristic
alongside the blind heuristic. The blind heuristic returns 0 for goal states, and the cost of
the cheapest action for non-goal states. For this experiment, we chose our most accurate
heuristic, hLM-CUT+ . We compare the performance of A using hLM-CUT+ alone, to that of A
using selective max of hLM-CUT+ and the blind heuristic. Because the blind heuristic returns
a constant value for all non-goal states, the decision rule that selective max uses to combine
some heuristic h with the blind heuristic hb is simply h(s)   + hb , that is, compute h
when the predicted value of h is greater than some constant threshold. Recall that, when
h(s) + g(s) < c , computing h is simply a waste of time, because s will not be pruned.
Therefore, it only makes sense to compute h(s) when h(s)  c  g(s). Note that this
threshold for computing h depends on g(s), and thus is not constant. This shows that a
constant threshold for computing h(s) is not the best possible decision rule. Unfortunately,
the selective max decision rule is based on an approximation that fails to capture the subtleties
of this case.
Table 7 shows the normalized coverage of A using hLM-CUT+ , and A using selective max of
hLM-CUT+ and the blind heuristic. As the results show, selective max has little effect in most
domains, though it does harm performance in some, and in one domain  OPENSTACKS  it
actually performs better than the single heuristic. Table 8 shows the average expansions ratio,
using the number of states expanded by hLM-CUT+ as the baseline; note that using the blind
heuristic never increases heuristic accuracy. As these results show, selective max chooses to
use the blind heuristic quite often, expanding on average more than twice as many states than
A with hLM-CUT+ alone.
728

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

coverage

hLM-CUT+

selh

airport (31)
freecell (13)
logistics00 (17)
mprime (24)
mystery (17)
pipesworld-tankage (9)
satellite (9)
zenotravel (12)

1.00 (31)
1.00 (13)
1.00 (17)
1.00 (24)
1.00 (17)
1.00 (9)
1.00 (9)
1.00 (12)

1.00 (31)
1.00 (13)
1.00 (17)
1.00 (24)
1.00 (17)
1.00 (9)
1.00 (9)
1.00 (12)

blocks (27)
depot (7)
driverlog (14)
grid (2)
gripper (6)
logistics98 (6)
miconic (140)
pathways (5)
pipesworld-notankage (17)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

1.00 (27)
1.00 (7)
1.00 (14)
1.00 (2)
1.00 (6)
1.00 (6)
1.00 (140)
1.00 (5)
1.00 (17)
1.00 (48)
1.00 (7)
1.00 (27)
1.00 (15)
1.00 (6)
1.00 (9)

1.00 (27)
1.00 (7)
1.00 (14)
1.00 (2)
1.00 (6)
1.00 (6)
0.86 (121)
1.00 (5)
1.00 (17)
1.00 (48)
1.00 (7)
1.00 (27)
0.93 (14)
1.00 (6)
1.00 (9)

elevators-opt08-strips (18)
openstacks-opt08-strips (19)
parcprinter-08-strips (21)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (14)

1.00 (18)
0.89 (17)
1.00 (21)
1.00 (27)
1.00 (13)
1.00 (25)
1.00 (11)
1.00 (14)

0.83 (15)
1.00 (19)
1.00 (21)
1.00 (27)
0.77 (10)
1.00 (25)
1.00 (11)
0.93 (13)

TOTAL

1.00 (614)

0.98 (589)

Table 7: Normalized coverage of hLM-CUT+ and selective max combining hLM-CUT+ with the blind
heuristic. Domains are grouped into domains with unit cost actions and high variance in
coverage, domains with unit cost actions and low variance in coverage, and domains with
non-uniform action costs, respectively.

729

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

expansions

hLM-CUT+

selh

airport (31)
freecell (13)
logistics00 (17)
mprime (24)
mystery (18)
pipesworld-tankage (9)
satellite (9)
zenotravel (12)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.0
3.13
1.02
1.22
3.2
4.23
3.11
2.37

blocks (27)
depot (7)
driverlog (14)
grid (2)
gripper (6)
logistics98 (6)
miconic (121)
pathways (5)
pipesworld-notankage (17)
psr-small (48)
rovers (7)
schedule (27)
storage (14)
tpp (6)
trucks-strips (9)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.92
1.36
1.15
7.67
1.0
1.18
14.24
1.0
1.27
2.12
1.56
1.21
5.11
1.6
1.01

elevators-opt08-strips (15)
openstacks-opt08-strips (17)
parcprinter-08-strips (21)
pegsol-08-strips (27)
scanalyzer-08-strips (10)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (13)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

13.41
1.08
1.24
1.01
4.87
1.0
5.86
46.97

GEOMETRIC MEAN

1.0

2.3

Table 8: Average ratio of expanded states between the baseline of hLM-CUT+ and selective max
combining hLM-CUT+ with the blind heuristic. Domains are grouped into domains with
unit cost actions and high variance in coverage, domains with unit cost actions and low
variance in coverage, and domains with non-uniform action costs, respectively.

730

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

The above experiments have varied the heuristics which selective max uses. In the following
experiments, we fix the set of heuristics, and examine the impact of the other parameters of selective max on performance. As we still need to evaluate over 20 different configurations of selective
max, we will focus on eight selected domains: AIRPORT, FREECELL, LOGISTICS 00, MPRIME, MYS TERY , PIPESWORLD - TANKAGE, SATELLITE , and ZENOTRAVEL. These are the eight domains with the
highest observed variance in the number of tasks solved across different planners, out of the unit
action cost domains we used. These domains were chosen in order to reduce the computation time
required for these experiments to a manageable quantity. We excluded domains with non-uniform
action costs, because they use a different method of estimating the goal depth for the state-space
sampling method, which is one of the parameters we examine. Below, we focus on one parameter
of selective max at a time, and present the total number of tasks solved in our eight chosen domains,
under different values of that parameter. Detailed, per-domain results for each parameter appear in
Appendix A.
 hyper-parameter 
Figure 5a plots the total number of problems solved, under different values of . As these
results show, selective max is fairly robust with respect to the value of , unless a very large
value for  is chosen, making it more difficult for selective max to choose the more accurate
heuristic.
Detailed, per-domain results appear in Table 19 in Appendix A, as well as in Figure 6. These
results show a more complex picture, where there seems to be some cutoff value for each
domain, such that increasing  past that value impairs performance. The one exception to
this is the PIPESWORLD - TANKAGE domain, where setting  = 5 helps.
 confidence threshold 
Figure 5b plots the total number of problems solved, under different values of , Detailed,
per-domain results appear in Table 20 in Appendix A. These results indicate that selective
max is also robust to values of , unless it is set to a very low value, causing selective max to
behave like the regular point-wise maximum.
 initial sample size N
Figure 5c plots the total number of problems solved under different values of N . with the
x-axis in logscale. Detailed, per-domain results appear in Table 21 in Appendix A. As the
results show, our default value of N = 100 is the best (of the three values we tried), although
selective max is still fairly robust with respect to the choice of parameter.
 sampling method
Figure 7 shows the total number of problems solved using different methods for the initial
state-space sampling. Detailed, per-domain results appear in Table 22 in Appendix A. As
the results demonstrate, the choice of sampling method can notably affect the performance of
selective max. However, as the detailed results show, this effect is only evident in the FREE CELL domain. We also remark that our default sampling method, PDB, performs worse than
the others. Indeed by using the probe based sampling methods, selective max outperforms A
using hLA alone. However, as this difference is only due to the FREECELL domain, we can not
state with certainty that this would generalize across all domains.
731

fiSolved Instances

D OMSHLAK , K ARPAS , & M ARKOVITCH

174
172
170
168
166
0

0.5

1

1.5

2

2.5


3

3.5

4

4.5

5

0.8

0.85

0.9

0.95

1

Solved Instances

(a) Hyper-parameter 

174
172
170
168
166
0.5

0.55

0.6

0.65

0.7

0.75


Solved Instances

(b) Confidence threshold 

174
172
170
168
166
10

100


1000

(c) Initial Sample Size N
Figure 5: Number of problems solved by selective max under different values for (a) hyperparameter  (b) confidence threshold , and (c) initial sample size N .

732

fiSolved Instances

O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

50
45
40
35
30
25
20
15
10
5

airport
freecell
logistics00
mprime
mystery
pw-tankage
satellite
zenotravel
0

1

2

3

4

5



Figure 6: Number of problems solved by selective in each domain under different values for .

180
160

Solved Instances

140
120
100
80
60
40
20
0

PDB
174

Probe
178
Sampling Method

UnbiasedProbe
180

Figure 7: Number of problems solved by selective max with different sampling methods.

733

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

180
160

Solved Instances

140
120
100
80
60
40
20
0
NB
174

AODE
168

ITI
156
Classifier

3NN
158

5NN
161

Figure 8: Number of problems solved by selective max with different classifiers.
 classifier
Figure 8 shows the total number of problems solved using different classifiers. Detailed,
per-domain results appear in Table 23 in Appendix A. Naive Bayes appears to be the best
classifier to use with selective max, although AODE also performs quite well. Even though
kNN enjoys very fast learning, the classifier is used mostly for classification, and as expected,
kNN does not do well. However, the increased accuracy of k = 5 seems to pay off against
the faster classification when k = 3.
6.3 Comparison with Sequential Portfolios
Sequential portfolio solvers for optimal planning are another approach for exploiting the merits of
different heuristic functions, and they have been very successful in practice, with the Fast Downward
Stone Soup sequential portfolio (Helmert et al., 2011) winning the sequential optimal track at IPC2011. A sequential portfolio utilizes different solvers by running them sequentially, each with a prespecified time limit. If one solver fails to find a solution under its allotted time limit, the sequential
portfolio terminates it, and moves on to the next solver. However, a sequential portfolio solver
needs to know the time allowance for the problem it is trying to solve beforehand, a setting known
as contract anytime (Russell & Zilberstein, 1991). In contrast, selective max can be used in an
interruptible anytime manner, where the time limit need not be known in advance.
Here, we compare selective max to sequential portfolios of A with the same heuristics. As
we have the exact time it took A search using each heuristic alone to solve each problem, we can
determine whether a sequential portfolio which assigns each heuristic some time limit will be able
to solve each problem. Using this data, we simulate the results of two types of sequential portfolio
planners. In the first setting, we assume that the time limit is known in advance, and simulate the
results of a contract portfolio giving an equal share of time to all heuristics. In the second setting, we
simulate an interruptible anytime portfolio by using binary exponential backoff time limits: starting
734

fi700

700

650

650
Solved Instances

Solved Instances

O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

600
550
500

selh
portctr

450

600
550
500

selh
portctr

450

portint

portint

400

400
200

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

200

700

700

650

650

600
550
500

selh
portctr

450

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

hLA / hLM-CUT+
(b)

Solved Instances

Solved Instances

hLA / hLM-CUT
(a)

400

600
550
500

selh
portctr

450

portint

portint

400

400
200

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

200

hLM-CUT / hLM-CUT+
(c)

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

hLA / hLM-CUT / hLM-CUT+
(d)

Figure 9: Anytime profiles of sequential portfolios and selective max. Each plot shows the number of problems solved by selective max (selh ), a simulated contract anytime portfolio
(portctr ), and a simulated interruptible portfolio (portint ) using (a) hLA and hLM-CUT (b)
hLA and hLM-CUT+ (c) hLM-CUT and hLM-CUT+ , and (d) hLA , hLM-CUT , and hLM-CUT+ .

with a time limit of 1 second for each heuristic, we increase the time limit by a factor of 2 if none
of the heuristics were able to guide A to solve the planning problem. There are several possible
orderings for the heuristics here, and we use the de facto best ordering for each problem. We denote
the contract anytime portfolio by portctr , and the interruptible anytime portfolio by portint .
Figure 9 shows the number of problems solved under different time limits for selective max,
the contract anytime sequential portfolio, and the interruptible anytime sequential portfolio. As
these results show, the contract anytime sequential portfolio almost always outperforms selective
max. On the other hand, when the sequential portfolio does not know the time limit in advance, its
performance deteriorates significantly. The best heuristic combination for selective max, hLA and
hLM-CUT , outperforms the interruptible anytime portfolio using the same heuristics, and so does the
735

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

selective max combination of hLM-CUT and hLM-CUT+ . With the other combinations of heuristics,
the interruptible anytime portfolio performs better than selective max.

7. Discussion
Learning for planning has been a very active field since the early days of planning (Fikes, Hart,
& Nilsson, 1972), and is recently receiving growing attention in the community. However, despite
some early work (Rendell, 1983), relatively little work has dealt with learning for state-space search
guided by distance-estimating heuristics, one of the most prominent approaches to planning these
days. Most works in this direction have been devoted to learning macro-actions (see, for example,
Finkelstein & Markovitch, 1998; Botea, Enzenberger, Muller, & Schaeffer, 2005; Coles & Smith,
2007). Recently, learning for heuristic search planning has received more attention: Yoon et al.
(2008) suggested learning (inadmissible) heuristic functions based upon features extracted from
relaxed plans. Arfaee, Zilles, and Holte (2010) attempted to learn an almost admissible heuristic
estimate using a neural network. Perhaps the most closely related work to ours is that of Thayer,
Dionne, and Ruml (2011), who learn to correct errors in heuristic estimates online. Thayer et al. attempt to improve the accuracy of a single given heuristic, while selective max attempts to choose one
of several given heuristics for each state. The two works differ technically on this point. More importantly, however, none of the aforementioned approaches can guarantee that the resulting heuristic
will be admissible, and thus that an optimal solution will be found. In contrast, our focus is on optimal planning, and we are not aware of any previous work that deals with learning for optimal
heuristic search.
Our experimental evaluation demonstrates that selective max is a more effective method for
combining arbitrary admissible heuristics than the baseline point-wise maximization. Also advantageous is selective maxs ability to exploit pairs of heuristics, where one is guaranteed to always
be at least as accurate as the other. For example, the hLA heuristic can be used with two action
cost partitioning schemes: uniform and optimal (Karpas & Domshlak, 2009). The heuristic induced
by the optimal action cost partitioning is at least as accurate the one induced by the uniform action
cost partitioning, but takes much longer to compute. Selective max might be used to learn when
it is worth spending the extra time to compute the optimal cost partitioning, and when it is not. In
contrast, the max-based combination of these two heuristics would simply waste the time spent on
computing the uniform action cost partitioning.
The controlled parametric experiments demonstrate that the right choice of classifier and of
the sampling method for the initial state-space sample is very important. The other parameters of
selective max do not appear to affect performance too much, as long as they are set to reasonable
values. This implies that selective max could be improved by using faster, more accurate, classifiers,
and by developing sampling methods that can represent the state-space well.
Finally, we remark that the Fast Downward Autotune entry in the sequential optimal track of
the 2011 edition of the International Planning Competition, which used ParamILS (Hutter, Hoos,
Leyton-Brown, & Stutzle, 2009) to choose the best configuration for the Fast Downward planner,
chose to use selective-max to combine hLM-CUT and hmax (Bonet, Loerincs, & Geffner, 1997).
This provides further evidence that selective max is a practically valuable method for combining
heuristics in optimal planning.
736

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

coverage

hLA

hLM-CUT

hLM-CUT+

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

Table 9: Detailed per-domain results of A with each individual heuristic. Normalized coverage is
shown, with the number of problems solved shown in parentheses. Domains are grouped
into domains with unit cost actions and high variance in coverage, domains with unit
cost actions and low variance in coverage, and domains with non-uniform action costs,
respectively.

Acknowledgments
The work was partly supported by the Israel Science Foundation (ISF) grant 1045/12.

Appendix A. Detailed Results of Empirical Evaluation
In this appendix, we present detailed per-domain, results of the experiments described in Section 6.
Table 9 shows the normalized coverage and number of problems solved in each domain, for
individual heuristics. The normalized coverage score of planner X on domain D is the number of
problems from domain D solved by planner X, divided by the number of problems from domain
D solved by at least one planner. Tables 10  17 give the results for combinations of two or more
heuristics. Tables 10, 12, 14, and 16 list the normalized coverage of the individual heuristics used,
and of their combination using selective max (selh ), regular maximum (maxh ), and random choice
of heuristic at each state (rndh ) after 30 minutes. Tables 11, 13, 15, and 17 give the geometric
mean of the ratio of expanded states relative to maxh in each domain, over problems solved by
all configurations. The number of tasks solved by all planners is listed in parentheses next to each
domain. The final row gives the geometric mean over the geometric means of each domain.
737

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

coverage

hLA

hLM-CUT

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.91 (30)
0.71 (41)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.85 (28)
0.28 (16)
0.95 (20)
0.75 (18)
0.76 (13)
0.85 (11)
0.70 (7)
0.77 (10)

0.91 (30)
0.84 (49)
1.00 (21)
1.00 (24)
1.00 (17)
0.92 (12)
0.80 (8)
1.00 (13)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
0.80 (4)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.84 (16)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.44 (7)
1.00 (30)
0.92 (11)
0.68 (13)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.89 (17)

TOTAL

0.91 (656)

0.92 (639)

0.94 (665)

0.85 (603)

0.95 (677)

Table 10: Detailed per-domain normalized coverage using hLA and hLM-CUT . Each line shows the
normalized coverage in each domain, with the number of problems solved is shown in
parentheses. Domains are grouped into domains with unit cost actions and high variance
in coverage, domains with unit cost actions and low variance in coverage, and domains
with non-uniform action costs, respectively.

738

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

expansions

hLA

hLM-CUT

maxh

rndh

selh

airport (28)
freecell (15)
logistics00 (20)
mprime (18)
mystery (14)
pipesworld-tankage (11)
satellite (7)
zenotravel (10)

2.88
1.01
1.0
6.34
7.9
1.61
6.27
7.98

1.12
529.61
1.0
1.89
1.15
2.35
1.26
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.61
116.96
1.0
4.2
5.19
1.62
2.32
3.3

2.2
2.14
1.0
1.52
1.17
1.12
1.09
2.02

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (7)
logistics98 (6)
miconic (141)
pathways (4)
pipesworld-notankage (17)
psr-small (49)
rovers (7)
schedule (30)
storage (15)
tpp (6)
trucks-strips (9)

7.4
3.45
7.2
2.15
1.0
7.74
1.0
39.65
2.01
1.27
2.18
1.15
2.16
1.74
46.11

1.0
1.32
1.09
1.73
1.04
1.0
1.0
1.0
2.16
1.0
1.31
1.0
1.0
1.0
1.02

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

2.2
1.91
2.89
1.57
1.02
2.69
1.0
17.91
1.97
1.11
1.77
1.03
1.45
1.42
12.12

1.61
1.3
1.24
1.83
1.0
1.08
1.0
1.0
1.36
1.15
1.09
1.15
1.56
1.0
1.01

elevators-opt08-strips (17)
openstacks-opt08-strips (18)
parcprinter-08-strips (15)
pegsol-08-strips (27)
scanalyzer-08-strips (7)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (12)

21.51
1.17
24.13
3.72
69.2
15.74
12.09
31.6

1.03
1.0
1.0
1.01
1.0
1.07
1.01
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

5.99
1.03
9.34
1.8
21.47
1.33
3.79
5.68

1.37
1.15
1.0
1.01
1.14
1.04
1.44
1.28

GEOMETRIC MEAN

4.82

1.4

1.0

2.93

1.25

Table 11: Detailed per-domain expansions relative to maxh using hLA and hLM-CUT . Each row
shows the geometric mean of the ratio of expanded nodes relative to maxh . Domains are
grouped into domains with unit cost actions and high variance in coverage, domains with
unit cost actions and low variance in coverage, and domains with non-uniform action
costs, respectively.

739

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

coverage

hLA

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.53 (31)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.85 (28)
0.26 (15)
0.95 (20)
0.67 (16)
0.71 (12)
0.62 (8)
0.70 (7)
0.69 (9)

0.91 (30)
0.71 (41)
1.00 (21)
1.00 (24)
1.00 (17)
0.69 (9)
1.00 (10)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.71 (5)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.93 (26)
0.86 (6)
0.93 (13)
0.67 (2)
0.86 (6)
0.83 (5)
0.99 (140)
0.80 (4)
0.83 (15)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.70 (7)

0.93 (26)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.80 (16)
0.95 (21)
0.96 (27)
0.81 (13)
0.77 (23)
0.92 (11)
0.79 (15)

0.59 (13)
0.85 (17)
0.55 (12)
0.96 (27)
0.38 (6)
0.83 (25)
0.92 (11)
0.58 (11)

0.73 (16)
0.85 (17)
1.00 (22)
0.96 (27)
0.81 (13)
0.80 (24)
0.92 (11)
0.79 (15)

TOTAL

0.91 (656)

0.89 (614)

0.89 (628)

0.78 (564)

0.92 (651)

Table 12: Detailed per-domain normalized coverage using hLA and hLM-CUT+ . Each line shows the
normalized coverage in each domain, with the number of problems solved is shown in
parentheses. Domains are grouped into domains with unit cost actions and high variance
in coverage, domains with unit cost actions and low variance in coverage, and domains
with non-uniform action costs, respectively.

740

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

expansions

hLA

hLM-CUT+

maxh

rndh

selh

airport (28)
freecell (13)
logistics00 (16)
mprime (16)
mystery (13)
pipesworld-tankage (8)
satellite (7)
zenotravel (9)

3.05
1.22
1.0
8.45
7.76
2.17
19.26
6.62

1.0
47.57
1.0
1.23
1.11
1.42
1.03
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.43
10.54
1.0
5.2
4.77
1.48
5.94
3.09

2.81
2.05
1.0
1.57
1.7
1.86
4.12
4.04

blocks (26)
depot (6)
driverlog (13)
grid (2)
gripper (5)
logistics98 (5)
miconic (140)
pathways (4)
pipesworld-notankage (15)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (7)

6.97
21.8
11.11
5.04
1.0
6.1
1.0
40.56
3.08
1.31
2.75
1.09
2.29
2.72
46.09

1.0
1.0
1.01
1.01
1.0
1.0
1.0
1.0
1.12
1.0
1.01
1.0
1.0
1.0
1.01

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

2.15
5.46
3.71
2.14
1.0
2.14
1.0
18.03
1.75
1.14
1.81
1.0
1.53
1.88
12.02

4.28
3.96
2.56
4.74
1.0
3.79
1.0
1.0
2.46
1.27
1.45
1.09
2.16
1.17
1.01

elevators-opt08-strips (13)
openstacks-opt08-strips (16)
parcprinter-08-strips (12)
pegsol-08-strips (27)
scanalyzer-08-strips (6)
sokoban-opt08-strips (21)
transport-opt08-strips (11)
woodworking-opt08-strips (11)

28.6
1.17
24.87
4.92
23.07
15.66
15.34
53.27

1.01
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

7.1
1.03
9.23
2.15
6.88
1.33
4.26
8.53

7.46
1.09
1.19
1.0
1.43
1.01
2.84
1.91

GEOMETRIC MEAN

5.85

1.16

1.0

2.9

1.89

Table 13: Detailed per-domain expansions relative to maxh using hLA and hLM-CUT+ . Each row
shows the geometric mean of the ratio of expanded nodes relative to maxh . Domains are
grouped into domains with unit cost actions and high variance in coverage, domains with
unit cost actions and low variance in coverage, and domains with non-uniform action
costs, respectively.

741

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

coverage

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.22 (13)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.82 (27)
0.21 (12)
0.95 (20)
0.88 (21)
0.88 (15)
0.62 (8)
0.70 (7)
0.92 (12)

0.85 (28)
0.22 (13)
0.95 (20)
1.00 (24)
0.94 (16)
0.69 (9)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.89 (16)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.79 (15)

0.82 (18)
0.95 (19)
0.82 (18)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.95 (21)
0.95 (19)
0.91 (20)
0.96 (27)
0.94 (15)
0.83 (25)
0.92 (11)
0.95 (18)

TOTAL

0.92 (639)

0.89 (614)

0.89 (614)

0.87 (602)

0.91 (630)

Table 14: Detailed per-domain normalized coverage using hLM-CUT and hLM-CUT+ . Each line shows
the normalized coverage in each domain, with the number of problems solved is shown in
parentheses. Domains are grouped into domains with unit cost actions and high variance
in coverage, domains with unit cost actions and low variance in coverage, and domains
with non-uniform action costs, respectively.

742

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

expansions

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (26)
freecell (12)
logistics00 (16)
mprime (21)
mystery (16)
pipesworld-tankage (8)
satellite (7)
zenotravel (12)

1.16
9.55
1.0
2.2
1.69
3.09
3.66
1.61

1.0
1.0
1.0
1.01
1.01
1.01
0.98
1.09

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.04
4.37
1.0
1.84
1.52
1.75
2.39
1.3

1.16
1.26
1.0
1.0
1.32
1.61
1.51
1.22

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (6)
logistics98 (6)
miconic (140)
pathways (5)
pipesworld-notankage (16)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

1.02
7.53
1.71
4.03
1.05
1.08
1.0
1.22
3.49
1.03
1.66
1.0
1.07
1.56
1.32

1.0
1.0
1.02
1.0
1.0
1.05
1.0
1.02
1.01
1.0
1.01
1.0
1.0
1.0
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.01
4.07
1.36
1.9
1.03
1.06
1.0
1.13
1.9
1.02
1.28
1.0
1.03
1.16
1.14

1.02
1.25
1.49
1.28
1.05
1.06
1.0
1.22
1.4
1.03
1.3
1.0
1.07
1.56
1.26

elevators-opt08-strips (18)
openstacks-opt08-strips (17)
parcprinter-08-strips (17)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (13)

1.75
1.0
1.71
1.33
1.22
1.04
1.29
1.45

1.09
1.0
1.0
1.01
1.02
1.04
1.01
1.06

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.4
1.0
1.37
1.15
1.14
1.01
1.15
1.26

1.72
1.0
1.0
1.2
1.13
1.03
1.26
1.12

GEOMETRIC MEAN

1.66

1.01

1.0

1.35

1.2

Table 15: Detailed per-domain expansions relative to maxh using hLM-CUT and hLM-CUT+ . Each
row shows the geometric mean of the ratio of expanded nodes relative to maxh . Domains
are grouped into domains with unit cost actions and high variance in coverage, domains
with unit cost actions and low variance in coverage, and domains with non-uniform action
costs, respectively.

743

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

coverage

hLA

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.53 (31)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.79 (26)
0.26 (15)
0.95 (20)
0.75 (18)
0.71 (12)
0.69 (9)
0.70 (7)
0.69 (9)

0.91 (30)
0.57 (33)
0.95 (20)
0.96 (23)
1.00 (17)
0.85 (11)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.71 (5)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
0.83 (5)
0.99 (140)
0.80 (4)
0.83 (15)
0.98 (48)
0.88 (7)
0.93 (28)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.80 (16)
0.95 (21)
0.96 (27)
0.81 (13)
0.77 (23)
0.92 (11)
0.79 (15)

0.64 (14)
0.90 (18)
0.59 (13)
0.96 (27)
0.38 (6)
0.90 (27)
0.92 (11)
0.74 (14)

0.95 (21)
0.80 (16)
0.86 (19)
0.96 (27)
0.94 (15)
0.87 (26)
0.92 (11)
0.79 (15)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

0.89 (628)

0.81 (578)

0.92 (649)

Table 16: Detailed per-domain normalized coverage using hLA , hLM-CUT and hLM-CUT+ . Each line
shows the normalized coverage in each domain, with the number of problems solved is
shown in parentheses. Domains are grouped into domains with unit cost actions and high
variance in coverage, domains with unit cost actions and low variance in coverage, and
domains with non-uniform action costs, respectively.

744

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

expansions

hLA

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (26)
freecell (13)
logistics00 (16)
mprime (18)
mystery (13)
pipesworld-tankage (9)
satellite (7)
zenotravel (9)

2.29
1.22
1.0
9.21
7.85
2.68
18.81
7.26

1.16
417.8
1.0
2.74
1.41
5.08
3.78
1.23

1.0
47.65
1.0
1.21
1.13
1.38
1.01
1.1

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.04
45.83
1.0
4.26
4.48
2.27
4.53
3.07

1.71
6.73
1.0
1.99
1.43
1.93
2.45
2.45

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (5)
logistics98 (5)
miconic (140)
pathways (4)
pipesworld-notankage (15)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

7.59
19.63
11.36
5.04
1.0
6.43
1.0
40.63
3.09
1.31
2.77
1.09
2.3
2.73
60.39

1.02
7.53
1.73
4.06
1.06
1.08
1.0
1.02
4.29
1.03
1.67
1.0
1.07
1.56
1.33

1.0
1.01
1.03
1.01
1.0
1.05
1.0
1.0
1.13
1.0
1.01
1.0
1.01
1.0
1.01

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.58
5.22
2.79
2.15
1.02
1.79
1.0
7.76
2.35
1.1
1.78
0.99
1.33
1.91
6.05

1.67
2.46
2.03
4.91
1.0
1.58
1.0
1.0
2.53
1.24
1.38
1.09
1.58
1.41
1.33

elevators-opt08-strips (14)
openstacks-opt08-strips (16)
parcprinter-08-strips (13)
pegsol-08-strips (27)
scanalyzer-08-strips (6)
sokoban-opt08-strips (21)
transport-opt08-strips (11)
woodworking-opt08-strips (11)

33.16
1.17
45.31
4.94
24.13
16.43
15.5
53.33

1.65
1.0
2.02
1.34
1.5
1.03
1.29
1.37

1.1
1.0
1.0
1.01
1.05
1.05
1.01
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

4.65
1.03
5.91
1.69
5.5
1.14
2.66
4.02

2.9
1.07
1.0
1.26
1.87
1.13
1.82
1.63

GEOMETRIC MEAN

6.1

1.91

1.18

1.0

2.56

1.67

Table 17: Detailed per-domain expansions relative to maxh using hLA , hLM-CUT and hLM-CUT+ .
Each row shows the geometric mean of the ratio of expanded nodes relative to maxh .
Domains are grouped into domains with unit cost actions and high variance in coverage,
domains with unit cost actions and low variance in coverage, and domains with nonuniform action costs, respectively.

745

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

overhead

hLA /hLM-CUT

hLA /hLM-CUT+

hLM-CUT /hLM-CUT+

All Three

airport (28)
freecell (13)
logistics00 (20)
mprime (23)
mystery (17)
pipesworld-tankage (9)
satellite (7)
zenotravel (12)
blocks (26)
depot (7)
driverlog (13)
grid (2)
gripper (7)
logistics98 (6)
miconic (141)
pathways (5)
pipesworld-notankage (17)
psr-small (49)
rovers (7)
schedule (30)
storage (15)
tpp (6)
trucks-strips (9)
elevators-opt08-strips (16)
openstacks-opt08-strips (16)
parcprinter-08-strips (18)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (24)
transport-opt08-strips (11)
woodworking-opt08-strips (14)

4%
4%
8%
7%
3%
11%
14%
15%
21%
45%
29%
26%
13%
15%
1%
5%
22%
8%
15%
13%
18%
2%
3%
32%
15%
2%
9%
2%
5%
12%
5%

7%
8%
7%
7%
3%
11%
18%
35%
35%
29%
45%
17%
13%
31%
4%
1%
17%
11%
24%
13%
12%
1%
2%
75%
9%
6%
2%
4%
2%
23%
5%

1%
13%
2%
6%
8%
10%
10%
26%
2%
14%
26%
1%
5%
6%
3%
4%
20%
3%
26%
5%
2%
2%
12%
8%
10%
1%
28%
10%
14%
7%
2%

9%
1%
6%
3%
2%
5%
8%
21%
5%
10%
21%
6%
22%
5%
4%
7%
22%
12%
19%
24%
10%
3%
7%
9%
23%
5%
15%
1%
7%
3%
4%

AVERAGE

12%

15%

9%

10%

Table 18: Selective max overhead. Each row lists the average percentage of time spent on learning
and classification, out of the total time taken by selective max, in each domain, for each
set of heuristics. Domains are grouped into domains with unit cost actions and high
variance in coverage, domains with unit cost actions and low variance in coverage, and
domains with non-uniform action costs, respectively.

746

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

sel=0.1
h
30
49
21
24
17
12
8
13
174

sel=0.5
h
30
49
21
24
17
12
8
13
174

sel=1
h
30
49
21
24
17
12
8
13
174

sel=1.5
h
30
49
21
24
17
12
8
13
174

sel=2
h
30
49
21
22
17
12
7
12
170

sel=3
h
30
49
21
23
16
12
7
11
169

sel=4
h
30
49
21
21
15
13
7
10
166

sel=5
h
30
49
21
21
15
13
7
10
166

Table 19: Number of problems solved by selective max in each domain with varying values of
hyper-parameter 

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

sel=0.51
h
30
48
21
24
17
12
8
13
173

sel=0.6
h
30
49
21
24
17
12
8
13
174

sel=0.7
h
30
49
21
24
17
12
8
13
174

sel=0.8
h
30
49
21
24
17
12
8
13
174

sel=0.9
h
30
49
21
24
17
12
8
13
174

sel=0.99
h
30
49
21
24
17
12
8
13
174

Table 20: Number of problems solved by selective max in each domain with varying values of
confidence threshold 

Table 18 lists the average overhead of selective max in each domain, for each combination of
two or more heuristics.
Tables 19, 20, 21, 22 and 23 list the number of problems solved in each domain, under various
values for , , N , sampling method and classifier, respectively.

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

=10
selN
h
30
47
21
24
17
12
8
13
172

=100
selN
h
30
49
21
24
17
12
8
13
174

=1000
selN
h
30
46
21
24
17
12
8
13
171

Table 21: Number of problems solved by selective max in each domain with varying values of
initial Sample Size N

747

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

selPDB
h
30
49
21
24
17
12
8
13
174

selP
h
30
53
21
24
17
12
8
13
178

P
selU
h
30
55
21
24
17
12
8
13
180

Table 22: Number of problems solved by selective max in each domain with different sampling
methods. PDB is the sampling method of Haslum et al. (2007), P is the biased probes
sampling method, and U P is the unbiased probes sampling method.

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

B
selN
h
30
49
21
24
17
12
8
13
174

selAODE
h
25
49
20
24
17
12
8
13
168

I
selIT
h
30
34
20
24
17
12
7
12
156

N
sel3N
h
30
35
20
24
17
12
7
13
158

N
sel5N
h
28
46
20
23
17
10
6
11
161

Table 23: Number of problems solved by selective max in each domain with different classifiers

748

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.84 (49)
1.00 (21)
1.00 (24)
1.00 (17)
0.92 (12)
0.80 (8)
1.00 (13)

0.91 (30)
0.91 (53)
0.95 (20)
0.96 (23)
1.12 (19)
0.92 (12)
0.70 (7)
0.92 (12)

0.91 (30)
0.93 (54)
1.00 (21)
0.96 (23)
1.24 (21)
1.00 (13)
0.70 (7)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.89 (17)

0.82 (18)
0.90 (18)
0.82 (18)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.84 (16)

0.86 (19)
0.95 (19)
0.82 (18)
0.96 (27)
1.00 (16)
0.97 (29)
1.00 (12)
0.89 (17)

TOTAL

0.95 (677)

0.94 (672)

0.96 (685)

Table 24: Detailed coverage of portfolio using hLA / hLM-CUT . Number of problems solved by selective max (selh ), a simulated interruptible portfolio (portint ), and a simulated contract
anytime portfolio (portctr ) in each domain using heuristics hLA / hLM-CUT . Domains are
grouped into domains with unit cost actions and high variance in coverage, domains with
unit cost actions and low variance in coverage, and domains with non-uniform action
costs, respectively.

749

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.71 (41)
1.00 (21)
1.00 (24)
1.00 (17)
0.69 (9)
1.00 (10)
0.92 (12)

0.91 (30)
0.91 (53)
0.95 (20)
1.00 (24)
1.12 (19)
0.92 (12)
0.80 (8)
0.85 (11)

0.91 (30)
0.93 (54)
1.00 (21)
1.00 (24)
1.18 (20)
1.00 (13)
0.80 (8)
0.85 (11)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.93 (26)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

0.93 (26)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.70 (7)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.80 (8)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.73 (16)
0.85 (17)
1.00 (22)
0.96 (27)
0.81 (13)
0.80 (24)
0.92 (11)
0.79 (15)

0.82 (18)
0.85 (17)
1.00 (22)
0.96 (27)
0.75 (12)
0.83 (25)
0.92 (11)
0.79 (15)

0.82 (18)
0.85 (17)
1.00 (22)
0.96 (27)
0.94 (15)
0.83 (25)
1.00 (12)
0.79 (15)

TOTAL

0.92 (651)

0.93 (666)

0.94 (676)

Table 25: Detailed coverage of portfolio using hLA / hLM-CUT+ . Number of problems solved by selective max (selh ), a simulated interruptible portfolio (portint ), and a simulated contract
anytime portfolio (portctr ) in each domain using heuristics hLA / hLM-CUT+ . Domains
are grouped into domains with unit cost actions and high variance in coverage, domains
with unit cost actions and low variance in coverage, and domains with non-uniform action
costs, respectively.

750

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.85 (28)
0.22 (13)
0.95 (20)
1.00 (24)
0.94 (16)
0.69 (9)
0.80 (8)
0.92 (12)

0.88 (29)
0.24 (14)
0.95 (20)
1.00 (24)
1.18 (20)
0.69 (9)
0.80 (8)
0.92 (12)

0.88 (29)
0.26 (15)
0.95 (20)
1.00 (24)
1.24 (21)
0.85 (11)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.89 (16)
1.00 (49)
0.88 (7)
0.93 (28)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.95 (21)
0.95 (19)
0.91 (20)
0.96 (27)
0.94 (15)
0.83 (25)
0.92 (11)
0.95 (18)

0.82 (18)
0.90 (18)
1.00 (22)
0.96 (27)
0.81 (13)
0.93 (28)
0.92 (11)
0.79 (15)

0.86 (19)
0.95 (19)
1.00 (22)
0.96 (27)
0.94 (15)
0.93 (28)
0.92 (11)
0.84 (16)

TOTAL

0.91 (630)

0.90 (625)

0.93 (640)

Table 26: Detailed coverage of portfolio using hLM-CUT / hLM-CUT+ . Number of problems solved
by selective max (selh ), a simulated interruptible portfolio (portint ), and a simulated
contract anytime portfolio (portctr ) in each domain using heuristics hLM-CUT / hLM-CUT+ .
Domains are grouped into domains with unit cost actions and high variance in coverage,
domains with unit cost actions and low variance in coverage, and domains with nonuniform action costs, respectively.

751

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.57 (33)
0.95 (20)
0.96 (23)
1.00 (17)
0.85 (11)
0.80 (8)
0.92 (12)

0.91 (30)
0.91 (53)
0.95 (20)
1.00 (24)
1.18 (20)
0.92 (12)
0.80 (8)
0.92 (12)

0.91 (30)
0.93 (54)
1.00 (21)
1.00 (24)
1.18 (20)
0.92 (12)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.95 (21)
0.80 (16)
0.86 (19)
0.96 (27)
0.94 (15)
0.87 (26)
0.92 (11)
0.79 (15)

0.82 (18)
0.90 (18)
1.00 (22)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.84 (16)

0.86 (19)
0.95 (19)
1.00 (22)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.89 (17)

TOTAL

0.92 (649)

0.95 (679)

0.95 (684)

Table 27: Detailed coverage of portfolio using hLA / hLM-CUT / hLM-CUT+ . Number of problems
solved by selective max (selh ), a simulated interruptible portfolio (portint ), and a simulated contract anytime portfolio (portctr ) in each domain using heuristics hLA / hLM-CUT
/ hLM-CUT+ . Domains are grouped into domains with unit cost actions and high variance
in coverage, domains with unit cost actions and low variance in coverage, and domains
with non-uniform action costs, respectively.

Tables 24, 25, 26 and 27 list the normalized coverage in each domain for selective max, and for
the simulated contract and interruptible sequential portfolios.

References
Arfaee, S. J., Zilles, S., & Holte, R. C. (2010). Bootstrap learning of heuristic functions. In Felner,
A., & Sturtevant, N. (Eds.), Proceedings of the Third Annual Symposium on Combinatorial
Search (SoCS 2010), pp. 5260. AAAI Press.
Backstrom, C., & Klein, I. (1991). Planning in polynomial time: the SAS-PUBS class. Computational Intelligence, 7(3), 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational Intelligence, 11(4), 625655.
Bayardo Jr., R. J., & Schrag, R. (1997). Using CSP look-back techniques to solve real-world SAT
instances. In Kuipers, B., & Webber, B. L. (Eds.), Proceedings of the Fourteenth National
Conference on Artificial Intelligence (AAAI 1997), pp. 203208. AAAI Press.
752

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. In Coelho,
H., Studer, R., & Wooldridge, M. (Eds.), Proceedings of the 19th European Conference on
Artificial Intelligence (ECAI 2010), pp. 329334. IOS Press.
Bonet, B., Loerincs, G., & Geffner, H. (1997). A robust and fast action selection mechanism for
planning. In Kuipers, B., & Webber, B. L. (Eds.), Proceedings of the Fourteenth National
Conference on Artificial Intelligence (AAAI 1997), pp. 714719. AAAI Press.
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI planning
with automatically learned macro-operators. Journal of Artificial Intelligence Research, 24,
581621.
Brafman, R., & Shani, G. (2012). A multi-path compilation approach to contingent planning. In
Hoffmann, J., & Selman, B. (Eds.), Proceedings of the Twenty-Sixth AAAI Conference on
Artificial Intelligence (AAAI 2012), pp. 915. AAAI Press.
Burke, E., Kendall, G., Newall, J., Hart, E., Ross, P., & Schulenburg, S. (2003). Hyper-Heuristics:
An Emerging Direction in Modern Search Technology. In Handbook of Metaheuristics, International Series in Operations Research & Management Science, chap. 16, pp. 457474.
Coles, A., & Smith, A. (2007). Marvin: A heuristic search planner with online macro-action learning. Journal of Artificial Intelligence Research, 28, 119156.
Cover, T. M., & Hart, P. E. (1967). Nearest neighbor pattern classification. IEEE Transactions on
Information Theory, 13(1), 21  27.
de la Rosa, T., Jimenez, S., & Borrajo, D. (2008). Learning relational decision trees for guiding
heuristic planning. In Rintanen, J., Nebel, B., Beck, J. C., & Hansen, E. (Eds.), Proceedings
of the Eighteenth International Conference on Automated Planning and Scheduling (ICAPS
2008), pp. 6067. AAAI Press.
Domshlak, C., Karpas, E., & Markovitch, S. (2010). To max or not to max: Online learning for
speeding up optimal planning. In Fox, M., & Poole, D. (Eds.), Proceedings of the TwentyFourth AAAI Conference on Artificial Intelligence (AAAI 2010), pp. 10711076. AAAI Press.
Fern, A. (2010). Speedup learning. In Sammut, C., & Webb, G. I. (Eds.), Encyclopedia of Machine
Learning, pp. 907911. Springer.
Fern, A., Khardon, R., & Tadepalli, P. (2011). The first learning track of the international planning
competition. Machine Learning, 84(1-2), 81107.
Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning and executing generalized robot plans.
Artificial Intelligence, 3, 251288.
Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: A new approach to the application of theorem
proving to problem solving. Artificial Intelligence, 2, 189208.
Finkelstein, L., & Markovitch, S. (1998). A selective macro-learning algorithm and its application
to the NxN sliding-tile puzzle. Journal of Artificial Intelligence Research, 8, 223263.
Garca-Olaya, A., Jimenez, S., & Linares Lopez, C. (2011). The 2011 international planning competition. Tech. rep., Universidad Carlos III de Madrid. http://hdl.handle.net/10016/11710.
Geffner, H. (2010). The model-based approach to autonomous behavior: A personal view. In Fox,
M., & Poole, D. (Eds.), Proceedings of the Twenty-Fourth AAAI Conference on Artificial
Intelligence (AAAI 2010), pp. 17091712. AAAI Press.
753

fiD OMSHLAK , K ARPAS , & M ARKOVITCH

Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent construction of pattern database heuristics for cost-optimal planning. In Holte, R. C., & Howe, A. E.
(Eds.), Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence (AAAI
2007), pp. 10071012. AAAI Press.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths and abstractions: Whats the difference anyway?. In Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings
of the Nineteenth International Conference on Automated Planning and Scheduling (ICAPS
2009), pp. 162169. AAAI Press.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics for optimal sequential planning. In Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings of the Seventeenth
International Conference on Automated Planning and Scheduling (ICAPS 2007), pp. 176
183. AAAI Press.
Helmert, M., & Roger, G. (2008). How good is almost perfect?. In Fox, D., & Gomes, C. P. (Eds.),
Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (AAAI 2008), pp.
944949. AAAI Press.
Helmert, M., Roger, G., & Karpas, E. (2011). Fast Downward Stone Soup: A baseline for building
planner portfolios. In ICAPS 2011 Workshop on Planning and Learning, pp. 2835.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. Journal of Artificial Intelligence Research, 14, 253302.
Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: An automatic algorithm
configuration framework. Journal of Artificial Intelligence Research, 36, 267306.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning with landmarks. In Boutilier, C.
(Ed.), Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI 2009), pp. 17281733.
Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal of Artificial Intelligence
Research, 39, 51126.
Kautz, H., & Selman, B. (1992). Planning as satisfiability. In Neumann, B. (Ed.), Proceedings of the
10th European Conference on Artificial Intelligence (ECAI 1992), pp. 359363. John Wiley
and Sons.
Keyder, E., & Geffner, H. (2009). Soft goals can be compiled away. Journal of Artificial Intelligence
Research, 36, 547556.
Marques-Silva, J. P., & Sakallah, K. A. (1996). GRASP - a new search algorithm for satisfiability.
In Proceedings of the 1996 IEEE/ACM International Conference on Computer-Aided Design
(ICCAD 1996), pp. 220227.
Minton, S. (1994). Machine Learning Methods for Planning. Morgan Kaufmann Publishers Inc.
Nissim, R., Hoffmann, J., & Helmert, M. (2011). Computing perfect heuristics in polynomial time:
On bisimulation and merge-and-shrink abstraction in optimal planning. In Walsh, T. (Ed.),
Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI11),
pp. 19831990. AAAI Press/IJCAI.
754

fiO NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING

Palacios, H., & Geffner, H. (2009). Compiling uncertainty away in conformant planning problems
with bounded width. Journal of Artificial Intelligence Research, 35, 623675.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies for Computer Problem Solving. AddisonWesley.
Pednault, E. P. D. (1989). ADL: Exploring the middle ground between STRIPS and the situation
calculus. In Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings of the First
International Conference on Principles of Knowledge Representation and Reasoning (KR
1989), pp. 324332. Morgan Kaufmann.
Rendell, L. A. (1983). A new basis for state-space learning systems and a successful implementation. Artificial Intelligence, 20(4), 369392.
Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning as satisfiability: Parallel plans and algorithms for plan search. Artificial Intelligence, 170(1213), 10311080.
Russell, S. J., & Zilberstein, S. (1991). Composing real-time systems. In Mylopoulos, J., & Reiter,
R. (Eds.), Proceedings of the 12th International Joint Conference on Artificial Intelligence
(IJCAI 1991), pp. 212217. Morgan Kaufmann.
Schiex, T., & Verfaillie, G. (1993). Nogood recording for static and dynamic constraint satisfaction
problems. Journal of Artificial Intelligence Research, 3, 4855.
Thayer, J. T., Dionne, A. J., & Ruml, W. (2011). Learning inadmissible heuristics during search. In
Bacchus, F., Domshlak, C., Edelkamp, S., & Helmert, M. (Eds.), Proceedings of the TwentyFirst International Conference on Automated Planning and Scheduling (ICAPS 2011), pp.
250257. AAAI Press.
Utgoff, P. E., Berkman, N. C., & Clouse, J. A. (1997). Decision tree induction based on efficient
tree restructuring. Machine Learning, 29(1), 544.
Webb, G. I., Boughton, J. R., & Wang, Z. (2005). Not so naive Bayes: Aggregating one-dependence
estimators. Machine Learning, 58(1), 524.
Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: A baseline for probabilistic planning. In Boddy,
M., Fox, M., & Thiebaux, S. (Eds.), Proceedings of the Seventeenth International Conference
on Automated Planning and Scheduling (ICAPS 2007), pp. 352359. AAAI Press.
Yoon, S., Fern, A., & Givan, R. (2008). Learning control knowledge for forward search planning.
Journal of Machine Learning Research, 9, 683718.
Zimmerman, T., & Kambhampati, S. (2003). Learning-assisted automated planning: looking back,
taking stock, going forward. AI Magazine, 24, 7396.

755

fiJournal of Artificial Intelligence Research 44 (2012) 397-421

Submitted 01/12; published 06/12

Semantic Similarity Measures Applied to an Ontology
for Human-Like Interaction
Esperanza Albacete
Javier Calle
Elena Castro
Dolores Cuadra

EALBACET@INF.UC3M.ES
FCALLE@INF.UC3M.ES
ECASTRO@INF.UC3M.ES
DCUADRA@INF.UC3M.ES

Computer Science Department, Carlos III University,
Madrid 28911, Spain

Abstract
The focus of this paper is the calculation of similarity between two concepts from an ontology
for a Human-Like Interaction system. In order to facilitate this calculation, a similarity function is
proposed based on five dimensions (sort, compositional, essential, restrictive and descriptive)
constituting the structure of ontological knowledge. The paper includes a proposal for computing a
similarity function for each dimension of knowledge. Later on, the similarity values obtained are
weighted and aggregated to obtain a global similarity measure. In order to calculate those weights
associated to each dimension, four training methods have been proposed. The training methods
differ in the element to fit: the user, concepts or pairs of concepts, and a hybrid approach. For
evaluating the proposal, the knowledge base was fed from WordNet and extended by using a
knowledge editing toolkit (Cognos). The evaluation of the proposal is carried out through the
comparison of system responses with those given by human test subjects, both providing a
measure of the soundness of the procedure and revealing ways in which the proposal may be
improved.

1. Introduction
The main purpose of an ontology in a human-like interaction system is to unify the representation
of each concept, relating it to the appropriate terms, as well as to other concepts with which it
shares a semantic relation. Furthermore, the ontological component should also be able to
perform certain inferential processes, such as the calculation of semantic similarity between
concepts. The subject of similarity has been and continues to be widely studied in the fields and
literature of computer science, artificial intelligence, psychology and linguistics. Good similarity
measures are necessary for several techniques from these fields including information retrieval,
clustering, data-mining, sense disambiguation, ontology translation and automatic schema
matching. The present paper focuses on the study of semantic similarity between concepts in an
ontology from the framework of natural interaction.
The principal benefit gained from this procedure is the ability to substitute one concept for
another based on a calculation of the similarity of the two, given specific circumstances. From the
users perspective, the procedure allows for the use of synonyms (terms related to a single
concept) of a concept in the case where the user is not familiar with the original concept itself.
Moreover, semantic similarity offers the possibility to build explanations for clarifying a concept
to the user based on similar concepts, thereby enhancing communicative effectiveness.
2012 AI Access Foundation. All rights reserved.

fiALBACETE, CALLE, CASTRO & CUADRA

On the other hand, the system may also be able to understand a previously-unknown concept,
as long as the user is able to relate it to similar concepts that are previously known by the system.
In this way, the system will learn new concepts and automatically enrich its ontology to improve
future interactions.
The first task of this study is to develop a semantic similarity measure that takes into account
particular ontological dimensions described in an earlier study (Calle, Castro & Cuadra, 2008). In
this approach, the conceptualization comprises seven ontological dimensions: semiotic, sort,
compositional, essential, restrictive, descriptive, and comparative. The first three dimensions have
been previously applied in related works, as will be stated in Section 2. Essential, restrictive and
descriptive dimensions are part of the nature of the concept, can influence human judgment of
similarity and will be detailed in Section 3. The seventh one, comparative dimension, is derived
from previous dimensions and is in charge of calculating the degree of similarity between
ontological concepts.
The second goal of the present article is to evaluate the quality of the mechanism developed
for the calculation of similarities between two concepts in an ontology which is specially
designed for a human-like interaction system (Calle F., 2004). To achieve this, several
experiments have been designed and performed here. Before these experiments and the
consequent evaluation of the semantic similarity measure can be carried out, however, it is
necessary to implement the similarity dimensions defined in the conceptual model and feed the
database with a large number of concepts.
To briefly outline the content that follows in this paper, Section 2 reviews the literature on
similarity measures in ontologies and the methods available for their evaluation. In Section 3, an
approach to similarity measures applied to an ontological model based on several dimensions is
proposed. In Section 4, a detailed explanation is provided of the experiments designed to test the
proposal, as well as the results obtained from their execution. Section 5 discusses the limitations
encountered in the study. Finally, Section 6 presents conclusions for future research.

2. Related Work
The present section of this paper has two main objectives. First, it aims to provide an overview of
the different types of approaches available for the comparison of concepts in ontologies and, in so
doing, to identify the foundations on which the desired similarity measure may be modeled,
taking into account the seven dimensions described in a previous study (Calle et al., 2008).
Secondly, it aims to select the best way to evaluate the results yielded from this desired similarity
measure according to other studies regarding similarity metrics assessment.
Basically two types of methods exist for the comparison of terms in a graph-based ontology:
edge-based methods using graph edges and their types as the data source and node-based methods
using graph nodes and their properties as the main data source. The simplest and most intuitive
similarity measure, the former method is based mainly on the counting of the number of edges in
a path between two terms on a graph (Rada, Mili, Bicknell & Blettner, 1989). Within the edgebased method, two general approaches exist: firstly, a distance approach that selects either the
shortest path or the average of all paths (when more than one path exists) and secondly a common
398

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

path approach that calculates similarity directly by the length of the path from the lowest common
ancestor of the two terms to the root node (Wu & Palmer, 1994). Over the past few years, a
variety of edge-based methods have been defined (Resnik, 1995; Leacock & Chodorow, 1998).
All edge-based methods are grounded in two basic assumptions: firstly, that nodes and links
are uniformly distributed in the ontology, that is, terms at the same depth have the same
specificity (Budanitsky, 1999) and, secondly, that edges at the same level in the ontology indicate
the same semantic distance between terms. However, these suppositions are rarely true in the
majority of ontologies. For this reason, several strategies have been proposed in response to this
fact. One example of such a strategy is the weighting of edges according to their hierarchical
depth or the use of node density and link type (Richardson, Smeaton & Murphy, 1994).
Nevertheless, these strategies do not solve the aforementioned problems due to the fact that terms
at the same depth do not necessarily have the same specificity and that edges at the same level do
not necessarily represent the same semantic distance.
The second, or node-based, method relies on the comparison of the properties of the terms
involved which can be related to the terms themselves, their ancestors or their descendants. A
commonly used concept in these methods is that of information content (IC), providing a measure
of how specific and informative a term is. The IC of a term c can be quantified as the negative
log-likelihood, IC = -log p(c), where p(c) is the probability of the occurrence of c in a specific
corpus, generally being estimated by its annotation frequency. Another approach employed to
obtain the IC is based on the number of children a term has in the ontological structure (Seco,
Veale & Hayes, 2004). The concept of IC can be applied to the common ancestors of two terms in
order to quantify the information they share and, thereby, measure their semantic similarity. In
this way, two main approaches exist. The first is the most informative common ancestor (MICA)
technique in which only the common ancestor with the highest IC is considered (Resnik, 1995).
The second is the disjoint common ancestor (DCA) technique in which all disjoint common
ancestors are considered (the common ancestors that do not subsume any other common
ancestor). In one definition (Lin, 1998), the similarity between two concepts using the node-based
method has been expressed as the ratio between the amount of information needed to state the
commonality between the two concepts and the information needed to fully describe them.
Moreover, a similarity measure for hierarchical ontologies called ontology structure-based
similarity (OSS) has also been defined (Schickel-Zuber, 2007) and whose major ingredient is the
computation of an a-priori score of a concept c, (APS(c)), which shares some similarities with IC
(i.e., both are calculated from the topology and structure of the ontology reflecting the
information contained within and between the concepts).
Additionally, several hybrid methods have also been defined in an attempt to improve the
results of both techniques defined above. In the work of Jiang and Conrath, (1997), for example, a
combined model is defined that is derived from the edge-based notion by adding information
content as a decision factor. The link strength between two concepts is defined as the difference
of information content between them.
With the aim of collecting all different methods and approaches, SimPack, a generic Java
library of similarity measures for use in ontologies, has been created (Bernstein, Kaufmann,
399

fiALBACETE, CALLE, CASTRO & CUADRA

Kiefer & Brki, 2005) and includes the implementation of ontology-based similarity methods
(including edge-based and node-based measures). It is important to note that the majority of the
techniques described to define semantic similarity between concepts have been applied to
hierarchical ontologies whose structure takes into account only one or two dimensions in the
same graph. For example, WordNet (Fellbaum, 1998) consists of an ontological graph with over
100,000 concepts and whose edges model the is_a and part_of relationships. A Perl module
(Pedersen, Patwardhan & Michelizzi, 2004) was implemented for this lexical database with a
variety of semantic similarity measures. Another example of application is the Gene Ontology
(Department of Genetics, Stanford University School of Medicine, California, USA., 2000), one
of the most important ontologies within the bioinformatics community, with over 20,000 concepts
and modeling is_a and part_of relationships in the same graph. Thus, while none of the
techniques described in this section can be supposed to be appropriate in dealing with more than
two dimensions of similarity, they can nevertheless be useful to attempt to define some of the
dimensions in the present studys ontological model.
The second aim of the present section is to review the assessment techniques for ontological
similarity functions used in earlier studies. The gold standard established in the majority of the
experimental evaluations of similarity (Resnik, 1999; Jiang & Conrath, 1997; Altintas, Karsligil,
& Coskun, 2005; Schickel-Zuber, 2007; Bernstein et al., 2005) is based on the experiment
described in Miller and Charles study (1991) which has become the benchmark for determining
the similarity of words in natural language processing research. This experiment relies on the
similarity assessments made by 38 university students when provided with 30 name pairs chosen
a priori to cover high, intermediate and low levels of similarity and when asked to assess the
similarity of their meaning on a scale from 0 (no similarity) to 4 (perfect synonymy). The average
of scored values represents a good estimation of the degree of similarity between two terms.
In certain evaluations based on human judgment (Inkpen, 2007; Bernstein et al., 2005),
variations in the number of participants or the way to administer the questionnaire have been
introduced. In one of these studies (Bernstein et al., 2005), a website containing a survey tool was
designed to perform the evaluation. In the Web experiment, subjects were asked to assess the
similarity between 73 pairs of concepts on a scale from 1 (no similarity) to 5 (identical). Finally,
subjects were also given the possibility of adding comments to their assessment. To evaluate the
quality of the similarity measures, its results were compared with the test subjects assessments
using the corrected Spearman rank correlation coefficient.
It can be concluded that human reasoning is one of the most widely-used methods of
comparison when performing validation of a similarity measure. For this reason, such a
methodology has also been used in the experimentation section of the present study. Since it is
difficult to run a user-based evaluation with complicated ontologies, for example, the Gene
Ontology (Lord, Stevens, Brass & Goble, 2003), it has been deemed necessary here to find or
model an ontology with elements that test subjects could understand. Therefore, once the
ontological module is implemented, it must be populated with a sufficiently good coverage of
domain knowledge, that is, enough knowledge to meet the system requirements.

400

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

3. Theoretical Approach
The conceptual model grounding the present study (Calle et al., 2008) distributes ontological
knowledge into seven different dimensions. The semiotic dimension represents the relationship
between concepts, terms and language. For example, as shown in Figure 1, the concept of the
WordNets synset 3082979 corresponds to a machine that is able to perform calculations
automatically, and one of the terms associated with this concept is computer. Other terms
related to this concept are computing machine, computing device, data processor,
electronic computer and information processing system, all of them also linked to the concept
that corresponds to the English language (synset 6947032).

Figure 1: Example of semiotic dimension representation

The sort dimension represents the is_a relationship between concepts, relates each concept
with other concepts and models a polytree structure. For instance, as shown in Figure 2, the terms
node, server and web site are related to concepts that are instances of computer.

Figure 2: Sort dimension example

The essential dimension represents the general taxonomy of concepts. This taxonomy is
located in the nodes at the top of the polytree represented in the sort dimension. Therefore, the
relations included in its design are already observed in the sort dimension. But since they
organize the knowledge at the higher abstraction level (they are more discriminative) they should
be taken into account separately, adding extra value to similarity measure.
Its design is crucial for attaining good similarity measures, and determines the usefulness of
this dimension. The essential dimension of WordNet (Princeton Univ., 2011), for example,
classifies the concepts into four main linguistic categories (verb, noun, adjective, adverb). Such
approach is the most adequate for a linguistic interaction domain, but may be weaker in a general
interaction domain. This proposal includes an essential design inspired in previous (Calle et al.,
2008) and related works (Gee, 1999; Miller, 1995) and refined through preliminary
experimentation. The design departs from three main categories (abstract, actions and entities)
and develops main classes of concepts, as shown in Figure 3. Finally, it should be added that this
proposal is aimed to general interaction domains, and could be improved if suited to specific
domains for particular interaction systems.

401

fiALBACETE, CALLE, CASTRO & CUADRA

concept
[05835747]

.

.

abstract

action

entity

[05854150]

[06320569]

[00001740]

attribute

circumstance

sui generis

[00024264]

[14512817]

[90000001]

place

time

role

language

[08513718]

[00028270]

[00722061]

[06282651]

activity

environment

[00407535]

[08567235]

.

domain

.

interactive

static

active

[01946439]

[01564315]

[00524481]

[05999266]

unidirectional
comm. agent

communicative
agent

[90000002]

[02956371]

human

mechanical

[02743391]

[02891236]

user

Interaction
system

[10741590]

reactive

cyclic

[02105176]

[00675701]

[05661996]

Figure 3: Essential dimension taxonomy

The compositional dimension represents the part-whole relationship between concepts. In
this way, any concept can have relationships with a collection of concepts that are part of it.
Figure 4 shows some of the concepts that are part of a computer, for example hard disk,
RAM and ALU.
computer
[03082979]

hard disk

RAM

ALU

[03492542]

[04052757]

[02995345]



Figure 4: Compositional dimension example

The restrictive dimension shown in Figure 5 describes the compatibility between concepts
related to some action and the rest. For example, the action to compute is related to the
concepts computer, calculator and laptop, among others.

402

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

computer
[03082979]

Action concept:
to compute

calculator
[02938886]

[00637259]

laptop
[03642806]

Figure 5: Restrictive dimension example

The descriptive dimension shown in Figure 6 is in charge of the relationships between three
kinds of concepts: a generic concept (entity, abstract entity or action), an attribute likely to
characterize that concept, and the domain (of values) on which that attribute is defined. Notice
that there could be several available domains for a given attribute, and that a domain could be
numeric (magnitudes regarding a unit) or enumerated (a concept which is composed of a set of
named values which are also concepts). For example, an instance of the generic concept hard
disk will have a value in the numeric domain of information in bytes for the attribute concept
storage capacity.
Generic concept:
hard disk

Attribute concept:
storage capacity

Domain concept:
Information in bytes

[03492542]

[13562133]

[13626013]

Figure 6: Descriptive dimension example

Finally, the comparative dimension is derived from previous dimensions and is responsible
for calculating in real time the degree of similarity between ontological concepts. This paper, in
fact, focuses precisely on that similarity calculation. Finally, for reasons of efficiency, most
frequently requested similarities can be buffered, that is, stored when calculated, periodically
updated and retrieved when necessary.

4. Proposal
This paper proposes and evaluates a similarity measure based on the combination of individual
similarity measures according to each of the dimensions explained (see Section 3). This
combination will be produced as training across numerous observations that will affect the weight
with which each dimension contributes to the final decision. Training can be performed according
to different criteria. On one hand, different human subjects support their judgments on different
combinations of the dimensions. On the other hand, the nature of the concept determines the most
relevant dimension for each comparison. For example, when comparing the concept scanner
with the concept printer, the sort dimension could be very influential, since both are types of
computer peripherals; however restrictive dimension could not be as influential because they are
related to different actions. The opposite may happen with the concepts teacher and tutorial

403

fiALBACETE, CALLE, CASTRO & CUADRA

because both are related to similar actions according to the restrictive dimension, such as
teaching, while the sort dimension has little influence in this case.
The following step is to describe the similarity measure adapted to the described ontological
dimensions except for the semiotic dimension. Yet not the only approach, similarity in the
semiotic dimension, or similarity between terms is frequently described as the edit distance or
Levenshtein distance (1966), that is, the number of changes necessary to turn one string into
another string. The decision to leave this dimension apart is supported by preliminary studies in
which this measure yields an average error rate above 50% and in some cases over 80%.
Furthermore, for every concept in that study, the accuracy provided by this dimension was lower
than that of some of the other dimensions (the semiotic dimension never produced the best
prediction), being the only dimension which never ranked first when tested separately. For this
reason, it is estimated as it cannot contribute positively to the results (at least, it cannot until it is
properly adapted). Last but not least, during preliminary experimentation of the training including
this dimension, it was observed that each weight tended to zero, and with the drawback of
slowing down convergence of the weights of the rest of dimensions. However, as further work,
some evolution of this similarity measure (supported by knowledge on this dimension) can be
incorporated into the global measure of similarity.
4.1 Inference Mechanisms
This sub-section describes the method used to calculate the degree of similarity between two
given concepts in an ontology. Since ontological knowledge here is structured into different
dimensions, the similarity measure will also be based on these dimensions. Therefore, partial
similarity calculations will be made for the sort, essential, compositional, restrictive and
description dimensions described previously. The resulting overall similarity between the two
concepts is obtained through the calculation of the weighted average of the five partial similarities

where Ss, Sc, Se, Sr and Sd are the similarity measures according to the sort, compositional,
essential, restrictive and description dimensions, respectively. The values w1, w2, w3, w4 and w5
represent the weights assigned to each dimension such that the resulting total similarity between
the two concepts will be a value between 0 (completely different concepts) and 1 (the two
concepts are the same).
The following sections describe in detail the procedures developed for the calculation of each
of the partial similarities.
4.1.1 SIMILARITY ACCORDING TO SORT DIMENSION
The sort dimension represents the is_a relationship between concepts. This dimension has a
polytree structure, allowing a concept to be a descendant of more than one concept. Similarity in
this dimension is often calculated as proportional to the intersection of the list of predecessors of
404

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

both compared concepts regarding the total size of these lists. To define this measure, a variation
of the edge-counting technique  concretely, the conceptual similarity measure defined in the
work of Wu and Palmer (1994)  has been employed. Given two concepts, C1 and C2, this
measure can be defined as

where N1 and N2 are the number of ancestors of C1 and C2, while N3 is the number of common
ancestors of C1 and C2 (in the most advantageous tree if several are found in the polytree).
4.1.2 SIMILARITY ACCORDING TO COMPOSITIONAL DIMENSION
The compositional dimension represents the part-whole relationship between concepts. For this
reason, the most appropriate way to calculate the similarity between two concepts based on this
dimension is through the comparison of the parts (or ingredients) of these concepts. Furthermore,
the calculation must also take into account the fact that a concept may consist of required and
optional concepts. This detail is important when calculating similarity since a greater weight must
be given to the required ingredients appearing in both concepts, while a lower weight is given to
the optional ingredients. The resulting similarity of two concepts, C1 and C2, in terms of the
compositional dimension is obtained by applying the formula:

where N1 is the number of common components arising from the intersection of all
components of concept C1 with those components of concept C2 of type required; N2 is the
number of common components arising from the intersection of all the components of C2 with
those required components of C1; N3 is the number of required components that both C1 and C2
have in common; and N4 is the total number of common components (both required and optional)
of the two concepts; M1 and M2 represent the number of required components of concepts C1 and
C2, respectively. Finally, M3 and M4 indicate the total number of components that C1 and C2 have.
4.1.3 SIMILARITY ACCORDING TO ESSENTIAL DIMENSION
The essential dimension contains a set of abstract concepts which define generic types of
concepts (such as action, entity, abstract, circumstance or attribute). This generic classification
frequently influences human speakers when estimating similarity. Some other works on similarity
calculation posed that concepts are only comparable if included in the same category of
WordNets taxonomy (RiTa.WordNet, 2008). Such approach endows a critical value to this
dimension, while omitting the rest of the classification. What is proposed here is that this
dimension can contribute to similarity estimation as any other (albeit with a certain weight that
could be different than the rest), and that all the concepts observed in the design of the essential
dimension may influence the similarity estimation.

405

fiALBACETE, CALLE, CASTRO & CUADRA

The method for calculating similarity between two concepts C1 and C2 in the essential
dimension is based on the intersection of their essential ancestors (ancestors within the subset of
essential concepts). This is formalized as follows:

where Card(E1) and Card(E2) are, respectively, the total number of essential ancestors of
concepts C1 and C2, while Card(E1  E2) indicates the number of common essential ancestors.
4.1.4 SIMILARITY ACCORDING TO RESTRICTIVE DIMENSION
The restrictive dimension is defined between a concept representing an action and another
concept representing an entity. Similarity in this dimension is calculated in a different way
depending on the type of concepts to be compared. For this reason, two different similarity
measures exist for the dimension: comparing two actions and comparing two entities. Similarity
between two concepts representing an entity will be based on the action concepts that both
entities have in common. The formula used for the calculation of this similarity when comparing
two entities, C1 and C2, is defined as

where M1 and M2 are the number of common actions that have a positive or negative
restrictive relationship with the entities C1 and C2, respectively. The values N1, N2, N3 and N4
represent, respectively, the total number of actions having a positive relationship with the entity
C1, a negative relationship with C1, a positive relationship with the entity C2, and a negative
relationship with C2.
As regards the similarity between two concepts representing an action, this is calculated based
on the set of concepts defined on these actions, being more similar the higher the number of
restricted concepts in common. The formula to calculate the similarity between two action
concepts (C1, C2) of a particular sign (positive or negative) is defined as

where N3 is the number of common entities shared by the two actions, and N1 and N2 are the
total number of entities having a restrictive relationship with C1 and C2, respectively.
4.1.5 SIMILARITY ACCORDING TO DESCRIPTIVE DIMENSION
The description dimension represents the relationship between a concept, an attribute and a value
in a concrete domain. Similarity in this dimension is calculated differently depending on the type
of concepts to be compared, that is, entities, attributes or domains. For pairs of concepts (C1, C2)
representing an entity, the applicable formula is defined as

406

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

where N1 is the number of common attributes without a default value assigned, N2 is the
number of common attributes whose value is the same for both entities and has not been assigned
by default, and N3 is the number of common attributes with the same value where one of them has
been assigned by default. The terms M1 and M2 correspond to the total number of attributes
related to the concepts C1 and C2, respectively.
If both concepts (C1, C2) are attributes, the formula to apply is defined as

where N3 is the number of common values of both attributes, and N1, N2 is the total number of
possible values which can have the attributes C1 and C2, respectively.
Finally, if the concepts to be compared (C1, C2) represent domains, the similarity according to
this dimension is calculated based on the amount of common attributes (for which those domains
apply) and the number of values shared by both domains.

where N3 is the number of common attributes shared by the domains (C1, C2), and N1, N2 are
the total number of attributes associated with them. Finally, M3 is the number of common values
defined in both domains, and M1, M2 are the total number of values of the two domains.
Finally, the concepts to be compared (C1, C2) may be values belonging to a domain, either
enumerated or of a numeric type. For operating domains, it is necessary to define previously a
correspondence between them. Numeric domains can be related through a function (typically, a
lineal proportion). Relating an enumerated domain to a numeric domain can be achieved by
assigning to each enumerated value a fuzzy label in the numeric domain. Finally, the
correspondence between two enumerated domains always involves an intermediate numeric
domain (with a correspondence defined to each of the two other domains). Once the values are
comparable, the formula to measure their similarity is defined as follows:

where Cinf and Csup are, respectively, the lower limit and the upper limit within the range of
values, and C1 and C2 are the correspondent numeric comparable values.
4.2 Preliminary Experimentation
Before testing the proposal, some preliminary experiments were performed to refine it and to
obtain a first perspective on its validity. These experiments have been instructed on a set of
similarity measures obtained from a total of 20 pairs of concepts evaluated by 17 human subjects.
This dataset will be further described in Section 5.1.
407

fiALBACETE, CALLE, CASTRO & CUADRA

Specifically, the individual influence of each dimension in similarity was tested thorough a set
of experiments involving each of them separately. Since there is no combination of them, there is
no need for training either. Figure 7 shows a box plot that represents the error measures produced
individually for each dimension.
100

Error (%)

80
60
40
20
0
Sort

Compositional

Essential

Restrictive

Descriptive

Figure 7: Performance of isolated dimensions of the Ontology

Figure 8 shows that in series of twenty pairs, every dimension produced better prediction than
the others at least once. In fact, the essential dimension provided the best response in almost half
of the cases, while the descriptive dimension was best in just one case.
Restrictive
10%

Descriptive
5%

Sort
30%

Compositiona
l
15%

Essential
40%

Figure 8: Cases in which each dimension is ranked first

This fact can lead to the conclusion that the essential design was appropriate, and that the
descriptive dimension was weak. In further analysis it was found that the latter lacked sufficient
knowledge, and it was improved in this line before evaluation (more knowledge was added).
Despite this improvement, since the analysis and introduction of this knowledge is performed
manually (in contrast to other dimensions, for which knowledge was obtained from WordNet), it
could still be enhanced and this would improve the individual results of this dimension. Besides,
this result is not definitive, since the weights may be different in other interaction domains, and
the volume of the knowledge base is important too. But a useful consequence is that each one of
408

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

the five ontological dimensions can contribute to the similarity function, supporting the
hypothesis that an adequate combination of them may yield better results than any of these
individual approaches.
4.3 Weights Training Methods
Assigning the proper weight to each dimension is crucial to achieving good results. Since a
human test subject does not usually give the same relevance to the five dimensions of similarity, a
basic training program regarding the weights associated with each dimension was developed. This
program is based on the reinforcement learning technique (specifically a variant of the Q learning
algorithm) and it has been implemented in order to determine, through several iterations, the
appropriate value of the weights applied to each dimension (previously defined in Section 4.1) to
minimize the error between the formula result and each human judgment. Therefore, the input to
the training algorithm is the set of similarity judgments made by human test subjects. This
algorithm follows the next steps:
a) An initial step, where the five weights w1, w2, w3, w4 and w5 applied to each dimension
(see formula in Section 4.1) are initialized to 1.
b) For each iteration of the training algorithm, results for each dimension of similarity are
calculated according to the formulas described in the Sections 4.1.1 to 4.1.5.
Subsequently, the five new weights are calculated according to the next criteria:
1. if
2. if
3. Failure to meet conditions 1) and 2),
where parameter i is ranged from 1 to 5 (one for each dimension),
represents each individual score and Y represents a similarity value from 0 to 10 for one
pair of concepts scored by one of the participant.
stands for the increase of the
weight (for the dimension i) at the current iteration, while
represents that increase at
the previous iteration. The max(Simi) and min(Simi) represent the maximum and
minimum similarity individual values, respectively. Finally, stands for the learning rate.
The training can be focused on different points of view, which will be tested and evaluated.
Firstly, a pair-oriented training was implemented in order to individually adjust the weights for
each of the 20 concept pairs, independently of the specific user. The weights are adjusted
individually for each of the pairs of concepts, taking one user per iteration. In this way, after each
iteration, a new array of refined weights is obtained and used for evaluating the similarity. The
test consists of calculating the similarity (with that array of weights) and comparing it with the
human assessment.
Since the degree of significance assigned to each dimension may depend on the subjectivity of
the testers, it was of particular interest to make an adjustment of the weights based on each user.
409

fiALBACETE, CALLE, CASTRO & CUADRA

In this experiment, the training of the weights was performed once for each user and consisted of
20 iterations (one for each pair of concepts). For an iteration of this training algorithm, absolute
error committed in relation to the corresponding pair was calculated. After running the training
for the 17 users, the average of the absolute errors for each of the iterations was calculated.
The third method has been designed in order to address the shortcomings of the pair-oriented
training. It should be indicated that storing an array of the weights for each possible pair of
concepts in a medium sized ontology requires unusually extensive physical resources. Besides, a
significant coverage of the thus defined knowledge would require far too much training. In short,
it is not realistic to develop that method because of the high number of combinations of concepts.
However, through preliminary experimentation it was checked that the weights applied to a pair
were also likely to be applied to other combinations of each of those two concepts. Therefore, a
new training method (feature-oriented) was proposed by slightly modifying the pair-oriented one.
In the feature-oriented method, the array of weights is stored for each concept instead of for each
pair of concepts (which solve both the problems of storage and the extent of training). Each time
one concept is compared to any other, its array of weights will be reviewed and refined. The
similarity calculation for a given pair is based on the aggregation of the arrays of both concepts.
Finally, it was observed that each method showed a different behavior depending on the pair
of concepts compared: the method achieving the worst results on average was also the best for
some specific pairs. Subsequently, a hybrid method was proposed and has been developed,
combining the feature-oriented and user-oriented trainings, aiming to profit the advantages of
each method. The training will be similar to that focused on the user, but for each iteration the
array of weights will be refined to a different degree, taking into account the array stored for each
particular concept. Therefore, if a particular dimension is usually relevant for a concept,
adaptation to the user in that dimension will be strengthened.

5. Evaluation
Once the conceptual model of the ontology has been defined, and the weights training methods
proposed, the next step in this study is to evaluate the proposal. The present section describes the
experiments run for evaluating the proposal, from their design to the results obtained and
discussion. The knowledge base is supported by the relational database management system
Oracle 11g, and the logic of the ontology component (including the inference mechanisms) was
implemented in Java. The knowledge bases were designed to satisfy specific purposes within a
research project. The initial knowledge load was obtained from the large lexical database
WordNet (Fellbaum, 1998) including all the existing concepts (synsets), terms and relationships
(corresponding to sort and compositional dimensions). Since the proposed ontological model
defines more relationships between concepts (essential, restrictive and descriptive), it is necessary
to add more knowledge. The Cognos.Onto tool enables knowledge edition and management for
this specific model. This tool belongs to a larger toolkit, Cognos (Calle et al., 2011) already used
in several research projects. That toolkit seeks to ease the interaction corpus analysis, annotation,
implementation and management, through diverse yet integrated tools aimed to each specific type
of knowledge (pragmatic, NLP related, ontological etc.).
410

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

5.1 Experimental Design and Preparation
First of all, it is necessary to choose an Interaction Domain which will define the entire
experiment. The concepts involved will be a subset of the whole knowledge base, restricted to
that specific domain. The participants will be chosen in order to constitute a good coverage of the
focused domain. Finally, additional knowledge will be fed by experts in that interaction domain
not related to the projects where this research is framed (as the test subjects and any other
participant in the experiments).
The methodology chosen to evaluate the proposed similarity measure is based on Millers
benchmark (Miller & Charles, 1991). Experiments have been designed to determine whether the
result attained through the application of the similarity function on a pair of concepts is reliable
or, in other words, if the result falls within an acceptable range when compared with the similarity
judgments made by human test subjects.
To begin the experimental phase of the study, an initial loading of concepts must first be made
in the proposed ontology. For this reason, WordNets synsets (Princeton Univ., 2011) were taken
as concepts, together with the corresponding semiotics, sort and compositional relationships.
Knowledge domain experts have been responsible for populating the remaining dimensions of the
ontological model (i.e., the essential, restrictive and descriptive) in a subset of 350 concepts,
selected because of their relevance in the interaction domain.
The chosen domain is that labeled as computer science teaching interaction domain within
the Spanish academic socio-cultural environment. This area of knowledge is familiar to the test
subjects who have been selected as heterogeneous in this domain (different roles, ages, and
genders). To perform the evaluation, a test was designed for which the test subject had to rate the
similarity between pairs of concepts. The set of pairs had to meet a basic criterion: at least two
pairs had to be included to explore each of the proposed dimensions, one with clear incidence in
the dimension and another one without (or of little impact).
A total number of twenty-one test subjects were available, from which four outliers were left
apart. They were discarded after checking their judgment because their responses were not
uniform with the rest of the sample. The participant scores follow a normal distribution after
removing the outliers. For that reason, the sample size was calculated through a test of statistical
significance and the result was at least ten subjects to ensure a 99% confidence. Therefore, a
sample size of seventeen participants is sufficient to ensure that the data is representative.The
seventeen subjects were all experts in the interaction domain (technical education), specifically
five technical students, seven researchers and five lecturers. Their ages ranged from 20 to 50 and
were distributed as follows: seven subjects were in the 20-30 year-old range, six in the 30-40
year-old range and the remaining four were in the 40-50 year-old range. With regard to gender,
slightly more than half of them were female (9) and the rest were male (8). The chosen interaction
domain was the applied on the research project THUBAN (TIN2008-02711). Each participant
was provided with a test containing a set of twenty pairs of concepts from this domain. Since the
observations follow a normal distribution, it was determined that the minimum significant sample
size would be sixteen with 99% confidence. Therefore, a set of twenty pairs of concepts provides
significant results. However, in a larger domain, the size of the dataset may be different to attain
411

fiALBACETE, CALLE, CASTRO & CUADRA

statistically significant results. In coherence with some other components of the system where this
proposal was to be integrated, the similarity measures are ranged from zero (no similarity) to ten
(absolutely identical, the same concept). In addition, for each of the pairs, the subjects were asked
to justify their score, indicating the specific parameters of similarity that they took into account in
making their decision.After obtaining the individual survey results, the average total of the human
assessments for each pair of concepts was calculated.Table 1 shows the 20 pairs of concepts
included in the test and to the right of each pair, the range (difference between maximum and
minimum scores), the standard deviation and the average rating assigned by the users.
Pair ID

Pair of concepts

Range

Standard
deviation

Average
similarity

0

Reading lamp  Personal computer

6

1.76

2.71

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

Laptop  Server computer
Teacher  Tutorial
Meeting room  Laboratory
Server computer Microwave
Office  Laboratory
Screen  Blackboard
Stapler  Folder
Plug Power strip
Office  Meeting room
Pencil  CD marker
Associate professor  Teaching Assistant
Associate professor  Bachelor
To write papers  To program
To give a lecture  To teach
Keyboard  Mouse
Fridge  Microwave
Hard disk drive  Pendrive
Scanner  Printer
Poster  Blackboard

6
7
8
8
9
7
7
4
6
3
5
8
7
6
5
7
3
8
6

1.62
1.92
2.15
2.02
2.25
1.83
2.19
1.21
1.69
0.99
1.34
2.53
2.15
1.60
1.41
1.77
0.94
1.89
1.82

6.47
5.06
4.35
2.24
5.76
6.12
3.94
8.29
6.29
7.29
8.06
5.18
4.53
7.76
7.35
5.35
8.47
5.94
4.24

Table 1: Pairs of concepts and average similarity

All the methods are subject to the iteration order (either analyzed pair or human judge), which
can alter the result of the training. In order to avoid this effect and to endow significance to the
results, through preliminary experiments the minimum number of repetitions (with different
order) was determined to reduce stochastic and gain significance (close to 275), and consequently
it was decided to program 300 repetitions with a different order for each method. In the graphs
and tables, error rates of pairs (identified by pair_id) are numbered from 0 to 19, while iterations
are numbered from 1 to 20.
5.2 The Experiments
This section presents the results obtained after the execution of the experiments corresponding to
the four weight adjustment algorithms described in Section 4.3. These experiments were
412

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

performed on a subset of the ontological knowledge stored acquired from the computer science
teaching domain. The first experiment performed was the pair-oriented training and, in order to
evaluate the results of this training, the average of the absolute error was calculated (for each pair)
between the similarity based on each human judgment and the result obtained by applying the
similarity measure proposed according to the following formula:

where i corresponds to an index to iterate over each human judge for a specific pair of
concepts and n is the number of test subjects. Finally, errorpairId represents the absolute error
between the human judgment for that pair and the result obtained through the training algorithm
in that iteration. Table 2 shows the absolute errors calculated in this experiment for each pair of
concepts, as well as the average error which, at about 18.5% comes slightly closer to the scores
provided by the human subjects.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 15.2 14.8 38.3 18.6 19.4 18.1 17.6 18.8 20.2 15.4 13.4 18.0 22.5 19.6 15.2 13.0 15.3 20.9 17.1 19.0 18.5

Table 2: Pair-oriented training error rate

It should be noted that in eleven cases, the error rate is less than the average, in eight cases the
error rate is around the average, and one pair (#2) shows an excessive error rate that requires
further analysis and discussion (see subsection 5.3). Figure 9 shows a comparison of the trend
lines regarding the error rate accumulated by the pair-oriented training algorithm and the
accumulated error by the similarity function without weights training.

Figure 9: Accumulated average error in pair-oriented training

In second place, the absolute error obtained for each pair in the feature-oriented training is
shown in Table 3. These results, compared with those obtained for the pair-oriented training,
show slightly worse performance (with a mean error rate of 20,2%). However, it should be
recalled that this method has other advantages (realistic storage and training extent).
413

fiALBACETE, CALLE, CASTRO & CUADRA

Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 15.0 14.9 38.2 18.4 30.3 22.7 17.5 18.5 20.1 21.6 13.4 24.9 21.2 19.2 15.2 13.0 14.4 20.6 16.8 25.4 20.2

Table 3: Feature-oriented training error rate

The third experiment executed was the user-oriented training. In order to evaluate the results
of this experiment, the average of the absolute error was calculated (for each human judge)
between the similarity based on each human judgment for the 20 pairs of concepts and the result
obtained applying the similarity measure proposed. In this way, the error average has been
calculated as follows:

where i corresponds to an index to iterate over each pair of concepts for a specific user, n is
the number of pairs of concepts and errorpairId represents the absolute error between the human
judgment for that pair and the result of the training algorithm in that iteration.
In this case, the average error rate achieved is 23.9%, even worse than that for the featureoriented training. The absolute error rate obtained for each iteration is shown in Table 4.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 18.6 14.1 40.7 17.9 30.8 16.8 22.9 17.5 37.1 17.1 34.6 35.8 24.3 21.5 31.2 13.6 13.9 27.4 22.3 20.8 23.9

Table 4: User-oriented training error rate

Figure 10 shows a comparison of the trend lines correspondent to the error rate accumulated
by the user-oriented training algorithm and the accumulated error without any weight training. As
can be observed, the user-oriented training trend line follows a downward curve and after 20
iterations reaches an error rate of 23.9%. Comparing both trend lines, it can be concluded that this
training decreases the accumulated error and adapts the calculated similarities to the subjects
judgments, yet it would be desirable to improve that adaptation (since it is still far from featureoriented training).

Figure 10: Accumulated average error in user-oriented training

414

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

As observed, both the user-oriented and the feature-oriented training methods are able to
improve the similarities calculation, becoming noteworthy approaches. Consequently, it has been
found of interest to explore a method which combines both of them. This new hybrid method
departs from the user-oriented approach, and takes into account the weights vector obtained from
the feature-oriented training described in section 4.3. As shown in Table 5, the user error rate has
been successfully reduced to 21.2% with respect to the user-oriented training. However, this
method degrades the performance achieved by the feature alone method.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 16.0 14.3 39.0 16.9 29.4 17.3 22.2 17.4 25.1 18.5 21.5 29.6 22.0 19.9 22.8 13.2 13.1 23.8 19.2 22.8 21.2

Table 5: User-feature hybrid training error rate

5.3 Discussion of Results Obtained
Among the results, concept pair 2 (teacher-tutorial) scored an error rate above 38% and the
average similarity assigned by users (see Table 1) was 5.06. This latter value is significantly high
considering the fact that the first concept refers to a person and the second is a static entity.
Reviewing participant responses to this question, however, it can be understood that test subjects
gave a higher score to the sole feature the concepts have in common, the activity of teaching.
Analyzing the results of this outlier, it appears that the algorithm has a tendency to gradually
increase the weight of the restrictive dimension, but longer training will be necessary to adapt the
weight vector so that the only relevant dimension is the restrictive one. Using a training algorithm
with faster convergence would ensure a good result in this pair, but could adversely affect the
other results. However, convergence is guaranteed with a larger number of users.
Figure 11 shows the comparison of the absolute error obtained in the four experiments
performed in this work (pair-oriented, user-oriented, feature-oriented and hybrid trainings) for
each pair, and also the average results of each method. The first experiment performed, the pairoriented training, achieves the best average error rate, about 18.5%, although in the pair
mentioned above the error exceeded 38%. However, this experiment has a major limitation: a
trained weight vector for each pair of concepts possible cannot be stored due to the large number
of combinations of existing concepts in the ontology. This shortcoming was mitigated with the
development of the feature-oriented training, achieving an error rate about 20.2%, a figure which
is slightly worse than that of the pair-oriented training error. Nevertheless, this result does not
fully reflect the impact of this training because not all test pairs include concepts that appear more
than once in the experiment. If the calculation of the average error is restricted to those pairs
which have concepts repeated in more than one pair, then the error amounts to 22.8%. In any
case, this experiment has an important advantage since its implementation is more realistic and
can be applied to large ontologies.
The user-oriented training was aimed at adapting the weights to each subject in order to
confirm the assumption that not every test subject assigns the same value to all dimensions.
Although the error rate achieved (23.9%) was not as satisfactory as either the pair or the feature415

fiALBACETE, CALLE, CASTRO & CUADRA

oriented trainings, the figure included in the sub-section 5.2 for the training shows a decreasing
trend line which, when compared with the trend line without training, allows for the conclusion
that the user-oriented experiment is able to adapt to each individual judgment. For this reason, an
improvement was attempted with the user-training result through its combination with the
feature-oriented experiment.

Figure 11: Comparison of the experiment results

The hybrid training detailed in Section 5.2 achieved 21.2% in the error rate, which reduces
that of the user-oriented training, and balances the performance of the user-oriented method
(reduces standard deviation). Taking into account that feature-oriented training method depends
on the experience and that for some features the knowledge base might lack of this experience,
the response obtained could not be satisfactory in some cases. In fact, when calculating the error
produced by the feature-oriented method over the dataset (not restricted to repeated pairs) the
result amounted to 22.8%. In sum, the feature-oriented method provides better results but only if
enough knowledge is available. The last results presented in Figure 11 concern an experiment
observing only the sort dimension (which is a frequent method for calculating similarities). Its
average error rate is 24.1%, which is higher than that for any of the four methods discussed. In
addition, it can be observed that the error rate of this experiment is, in several cases, far from the
average error. Figure 12 shows a boxplot comparing the performance of the four training methods
proposed and the sort dimension formula.
416

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

100

Error (%)

80
60
40
20
0
Pair

Feature

User

Hybrid

Sort

Figure 12: Performance of each training method

As can be seen, regarding the error in the predictions, the sort dimension obtains higher
maximum (although also lower minimum), higher median (except for user training) and higher
deviation than the rest. From this graph, it can be concluded that the error rate achieved by the
sort dimension method (used in previous studies of similarity) is greater than the error rate
achieved by the feature training method. In order to check that statistically, a null hypothesis was
formulated (the average error is the same in both methods) and also an alternative hypothesis, (the
average error of the feature-oriented method is lower than the sort dimension method error). The
measure of discrepancy has been calculated for the sample of twenty measures of error (one per
pair) and the result (-1.78) was found to be outside the acceptance range (-1.64, +), therefore the
null hypothesis is rejected and the alternative is accepted with a significance level of 0.05.
Consequently, it is considered true that the error shown by the feature-oriented method is lower
than the error produced by the sort dimension method.
Finally, Figure 13 shows the average final weights of the four experiments. It shows the
relevance taken through the experiments by each dimension, yet it cannot be extrapolated to other
interaction domains. While dependent on the set of pairs chosen for the experiment, these results
show that how all five dimensions are taken into account, with diverse weights.
Descriptive
14%

Sort 26%

Restrictive
12%

Compositional
22%

Essential 26%

Figure 13: Average weights of the ontological dimensions

417

fiALBACETE, CALLE, CASTRO & CUADRA

6. Conclusions and Perspective for Future Research
This paper defines a similarity measure for a multi-dimensional knowledge model of the ontology
type, specifically an ontology aimed at supporting Human-Like Interaction. The proposed
measure is based on five dimensions of ontological knowledge: sort, compositional, essential,
restrictive and descriptive. The five of them are weighted and aggregated in order to obtain a
global similarity measure. The equations applied for each dimension are general and can be used
with other ontologies that observe any of these dimensions, yet observing all of them and
aggregating their similarity result is here proposed for enhanced accuracy.
This solution presents another challenge, in the form of those weights calculation. In fact,
when a person decides the similarity between concepts he unwittingly makes some dimensions
prevail over the others. The criteria may be diverse, and this work has focused on studying the
dependence of these weights on the nature of concepts, either in pairs (pair training method) or
individually (feature training method), both described in Section 4.3. But this work also explores
the influence of the past behavior of users who perform the concept pair evaluations (and
ultimately, the user who owns a device or usually interacts with it). Following this line, a userdependent training is proposed, and finally a hybrid one (merging feature and user benefits) is
included too. All of them have been evaluated and compared in order to ascertain which one
performs better, obtaining the best results for the pair-oriented training.
In order to evaluate the performance of the proposed similarity measure, its results were
recorded and compared with those taken from human test subjects. This evaluation technique has
been applied in several studies about similarity measures and is considered the gold standard. In
the experimental phase, four training algorithms were developed according to different
perspectives. Thus, this phase included a pair-oriented, a feature-oriented, a user-oriented and a
hybrid experiment. In every case, the error rate was calculated with respect to the human subject
assessments. The best results corresponded to the pair-oriented method which achieved an error
rate of 18.5%. Since the implementation of this experiment is not realistic with large ontologies, a
feature-oriented experiment was required despite slightly worsening the results from the previous
experiment, concretely, producing an error rate of 20.2%. However, the feature-oriented
experiment has the big advantage of being able to be applied easily to large ontologies.
Moreover, the user-oriented training aimed to adapt the weights to each subject in order to
confirm the assumption that not every test subject assigns the same value to all dimensions. While
this experiment had the highest error rate of all the algorithms (23.9%), as has been demonstrated,
the error rate follows a decreasing trend line while, if training is not done, the error rate follows
an asymptotic tendency. In addition to this, this experiment shows slightly better results than
taking into account only the sort dimension (which has an average error rate of 24.1% and
maximum 60.4%). For this reason, it can be concluded that the user-oriented experiment is able to
adapt to each individual judgment (although this adaptation is very slow). Finally, the hybrid
experiment combines the feature-oriented and the user-oriented training and, with an error rate of
21.2%, nevertheless manages to reduce the error of the user-oriented training, as well as
balancing the error in the atypical cases common to the rest of the experiments.

418

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

Since the hybrid experiment manages to balance the results of the other experiments,
currently, an improved hybrid algorithm is being developed. In this algorithm the calculation of
the weights of each iteration will be affected depending on the error produced in the feature
experiment for the pair of concepts corresponding to that iteration.
The performance of the training methods proposed is closely related to the available extent of
knowledge. For this reason, authors are also currently working on mechanisms for increasing the
quality and completeness of the ontological knowledge. The manual acquisition of new
knowledge by an expert requires a great deal of resources and it would be desirable to develop an
advanced mechanism to learn new concepts and relations. The challenge is to attain that
knowledge acquisition through human-like interaction with human subjects. Therefore, through
the lifetime of the system, the knowledge bases would be enriched by interacting with the users.
Finally, refinement of similarities formulation is also an interesting line of work, especially in
the semiotic dimension for reintroducing its influence in the global similarity calculation.

Acknowledgments
The development of this approach and its construction as part of the LaBDA-Interactor HumanLike Interaction System, part of the research projects SemAnts (TSI-020110-2009-419) and
THUBAN (TIN2008-02711) and CADOOH (TSI-020302-2011-21), is supported by the Spanish
Ministry of Industry, Tourism and Commerce and the Spanish Ministry of Education,
respectively. Besides, the knowledge bases were populated using the COGNOS toolkit developed
through the research project MA2VICMR (S2009/TIC-1542) supported by the Regional
Government of Madrid.

References
Altintas, E., Karsligil, E., & Coskun, V. (2005). A new semantic similarity measure evaluated in
word sense disambiguation. Procs. of the 15th NODALIDA conference. Joensuu.
Bernstein, A., Kaufmann, E., Kiefer, C., & Brki, C. (2005). SimPack: A Generic Java Library
for Similarity Measures in Ontologies. Zurich: Technical report.
Budanitsky, A. (1999). Lexical semantic relatedness and its application in natural language
processing. University of Toronto. Technical report.
Calle, F. (2004). Interaccin Natural mediante procesamiento intencional: Modelo de Hilos en
dilogos. Thesis, (PhD). Politecnic University of Madrid.
Calle, F. J., Albacete, E., Snchez, E., del Valle, D., Rivero, J., & Cuadra, D. (2009). Cognos: A
Natural Interaction Knowledge Management Toolkit. International Conference on
Applications of Natural Language to Information Systems (NLDB 2009) (pp. 303-304).
Saarbrken, Germany: Lecture Notes in Computer Science.
Calle, F., Castro, E., & Cuadra, D. (2008). Ontological dimensions applied to Natural Interaction.
Procs. of the First International Workshop on Ontologies in Interactive Systems , 91-96 .

419

fiALBACETE, CALLE, CASTRO & CUADRA

Department of Genetics, Stanford University School of Medicine, California, USA. (2000). Gene
ontology: tool for the unification of biology. The Gene Ontology Consortium. Nature
genetics Vol. 25, No. 1. , 25-29.
Fellbaum, C. (1998). WordNet: An Electronic Lexical Database. Cambridge, UK: The MIT Press.
Gee, J.P. (1999). Introduction to Discourse Analysis. Routledge.
Inkpen, D. (2007). Semantic similarity knowledge and its applications. STUDIA UNIV. BABESBOLYAI, INFORMATICA, Volume LII, , 11-22.
Jiang, J. J., & Conrath, D. W. (1997). Semantic Similarity Based on Corpus Statistics and Lexical
Taxonomy. In International Conference Research on Computational Linguistics. Taiwan.
COGNOS Toolkit. (2011). Retrieved July 2011, from
http://labda.inf.uc3m.es/doku.php?id=es:labda_lineas:cognos
RiTa.WordNet: a WordNet library for Java/Processing. (2008). [Online]. Available:
http://www.rednoise.org/rita/wordnet/documentation/
Leacock, C., & Chodorow, M. (1998). Combining Local Context and WordNet Similarity for
Word Sense Identification. An Electronic Lexical Database , 265-283.
Levenshtein, V. I. (1966). Binary codes capable of correcting deletions, insertions and reversals.
Soviet Physics Doklady vol 10 , 707-710.
Lin, D. (1998). An Information-Theoretic Definition of Similarity. Proceedings of the 15th
International Conf. on Machine Learning, (pp. 296-304). Madison, Wisconsin USA.
Lord, P. W., Stevens, R. D., Brass, A., & Goble, C. A. (2003). Investigating semantic similarity
measures across the Gene Ontology: the relationship between sequence and annotation.
Bioinformatics , 1275-1283.
Miller, G. A., & Charles, W. G. (1991). Contextual correlates of semantic similarity. Language
and Cognitive Processes , 1-28.
Miller, G. A. (1995). WordNet: A Lexical Database for English. Communications of the ACM vol
38 ,No. 11: 39-41.
Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet:: Similarity measuring the
relatedness of concepts. Demonstration Papers at HLT-NAACL 2004 (pp. 38-41). Boston,
Massachusetts, USA: Association for Computational Linguistics
Princeton Univ. (February 3, 2011). WordNet: A lexical database for English. Obtenido de
WordNet: A lexical database for English: http://wordnet.princeton.edu/
Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development and application of a metric
on semantic nets. IEEE Trans. on Systems, Man, and Cybernetics. 19. , 17-30.
Resnik, P. (1999). Semantic Similarity in a Taxonomy: An Information-Based Measure and its
Application to Problems of Ambiguity in Natural Language. Journal of Artificial
Intelligence Research , 95-130.
Resnik, P. (1995). Using information content to evaluate semantic similarity in a taxonomy.
IJCAI'95 Proceedings of the 14th international joint conference on Artificial intelligence
(pp 448-453). San Francisco, USA: Morgan Kaufmann Publishers Inc.
420

fiSEMANTIC SIMILARITY MEASURES APPLIED TO AN ONTOLOGY

Richardson, R., Smeaton, A. F., & Murphy, J. (1994). Using WordNet as a Knowledge Base for
Measuring Semantic Similarity between Words. Proceedings of AICS Conference.
Dublin, Ireland: Technical Report.
Schickel-Zuber, V. (2007). OSS: a semantic similarity function based on hierarchical ontologies.
IJCAI'07 Proceedings of the 20th international joint conference on Artifical intelligence
(pp. 551-556). San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
Seco, N., Veale, T., & Hayes, J. (2004). An Intrinsic Information Content Metric for Semantic
Similarity in WordNet. ECAI'2004, the 16th European Conference on Artificial
Intelligence, (pp. 1089-1090). Valencia, Spain .
Wu, Z., & Palmer, M. (1994). Verb semantics and lexical selection. ACL'94 Proceedings of the
32nd annual meeting on Association for Computational Linguistics (pp. 133-138).
Stroudsburg, USA: Association for Computational Linguistics.

421

fiJournal of Artificial Intelligence Research 44 (2012) 141-177

Submitted 11/11; published 05/12

Algorithms and Limits for Compact Plan Representations
Christer Backstrom
Peter Jonsson

christer.backstrom@liu.se
peter.jonsson@liu.se

Department of Computer Science
Linkoping University
SE-581 83 Linkoping, Sweden

Abstract
Compact representations of objects is a common concept in computer science. Automated planning can be viewed as a case of this concept: a planning instance is a compact
implicit representation of a graph and the problem is to find a path (a plan) in this graph.
While the graphs themselves are represented compactly as planning instances, the paths
are usually represented explicitly as sequences of actions. Some cases are known where
the plans always have compact representations, for example, using macros. We show that
these results do not extend to the general case, by proving a number of bounds for compact
representations of plans under various criteria, like efficient sequential or random access
of actions. In addition to this, we show that our results have consequences for what can
be gained from reformulating planning into some other problem. As a contrast to this we
also prove a number of positive results, demonstrating restricted cases where plans do have
useful compact representations, as well as proving that macro plans have favourable access
properties. Our results are finally discussed in relation to other relevant contexts.

1. Introduction
The usage and study of representations of objects that are much smaller than the objects
themselves is commonplace in computer science. Most of us encounter such representations
on a daily basis in the form of zipped files, mp3 files etc. For such practical cases, we usually
talk about compressed objects, while the terms compact and succinct are more common
in theoretical studies. The meaning of the terms vary but a common and interesting case
is when the size of the representation is at most polylogarithmic in the size of the object.
Sometimes it is sufficient to just compute a compact representation of an object, for instance,
when archiving a file. In other cases the representation must also support various operations
efficiently without first unpacking the object into an explicit representation. Performing
operations on a compact representation is often harder than performing the same operation
on an explicit object, but there are cases when a compact representation can make it easier
by emphasising some inherent structure in the object.
One archetypical case of using compact representations is automated planning, although
it is seldom viewed in that way. A planning instance is an implicit representation of a graph
that is typically exponentially larger than its representation, the instance, and where the
solutions, the plans, are paths in this graph. Consider, for example, a Strips instance with
n variables. These variables implicitly define a state space with 2n states and an action with
m preconditions define 2nm arcs in the graph. Similarly, we can define instances where the
paths are of exponential length too. Although the planning instances themselves are already
c
2012
AI Access Foundation. All rights reserved.

fiBackstrom & Jonsson

compact representations, very little attention has been paid to compact representations of
the solutions, which are usually represented explicitly. This paper introduces and analyses
a number of such compact representations.
If we first turn to computer science in general we find that compact representations
of arbitrary strings is an intensively studied field. For example, Charikar et al. (2005) and
Rytter (2003) address the problem of approximating the smallest string representation using
a compressed grammar. Bille et al. (2011) show that such representations permit efficient
access and matching operations, while Jansson, Sadakane, and Sung (2012) demonstrate
representations with efficient edit operations. More structured objects than arbitrary strings
can potentially have more compact representations. The following are some examples,
displaying positive as well as negative results in various areas. Both Galperin and Wigderson
(1983) and Wagner (1986) study the complexity of common graph operations when the
graphs are implicitly represented as circuits that tell whether two vertices are connected.
Balcazar (1996) uses a variant of that approach to study the complexity of search in AI,
using a circuit that generates the adjacency list for a vertex. Bulatov and Dalmau (2006)
present an efficient algorithm for certain CSP problems that relies on using a compact
representation of the set of solutions. Liberatore and Schaerf (2010) study preprocessing in
model checking with focus on the size of the preprocessed parts. Cadoli et al. (2000) study
various formalisms for knowledge representation and study when problems modelled in one
formalism can be transformed into another formalism with at most a polynomially larger
representation.
One approach to compact representations in various areas is the use of macros. This
concept has been widely used for a long time also in planning, although seldom for the
purpose of providing compact representations. An exception is the following case. The 3S
class (Jonsson & Backstrom, 1998b) of planning instances has the property that optimal
plans can be of exponential length but it is always possible to decide in polynomial time
if there is a plan or not. Gimenez and Jonsson (2008) showed that plans for the 3S class
always have a polynomial-size representation using macros, and that macro plans can even
be generated in polynomial time. That is, although the plan may be of exponential length,
and thus necessarily take exponential time to generate, it is possible to generate a compact
representation of it in polynomial time. Jonsson (2009) later demonstrated similar results
for a number of other classes. Although these particular classes of planning instances may
still be too restricted to be of much practical use, the principle of compressing the solution
using macros is an interesting tool both for planning and plan explanation.
Other approaches to compact plan representation appear only sparingly in the literature.
A notable exception is Liberatore (2005a) who studies two concepts for plan representation
that have efficient random access and efficient sequential access respectively. Just like macro
plans these are examples of representing one long plan compactly. We might also consider
representing a large set of plans compactly. For instance, plan recognition may have to
simultaneously consider an exponential number of candidate plans (Geib, 2004). Although
seldom viewed in that way, also a reactive plan is a representation of a large set of plans,
one for each state from which the goal can be reached. It is, however, known that reactive
plans cannot be both compact, efficient and correct in the general case (Jonsson, Haslum,
& Backstrom, 2000), although these properties are important, for instance, in spaceship
applications (Williams & Pandurang Nayak, 1997). Pomdps may similarly be thought of
142

fiAlgorithms and Limits for Compact Plan Representations

as a probabilistic variant of reactive plans and compactness of representations is important
also in this case (Boutilier & Poole, 1996). Yet another case is when the size of the plan
is big but the plan is not necessarily long, which can occur for various types of branching
plans, as in contingent planning (Bonet & Geffner, 2000). These three different concepts
are not isolated from each other. For instance, Bonet (2010) casts contingent planning
into the problem of conformant planning, that is, a branching plan is represented as one
long non-branching plan, with the branches appearing as subplans. In all these cases, it
is interesting to know if the objects in question have compact representations. Although
a compact representation can save space, this may be secondary in many cases. A more
important aspect is that if an object has a compact representation then the object has some
inherent structure that we may exploit also for other purposes. For instance, if we represent
a set of many plans then a representation using recursive macros, or similar, can emphasize
the differences and similarities between the plans. This make both comparisons and other
operations on the plans more efficient. Similarly, in the case of branching plans we might
want to exploit a structure that clearly displays both what two branches have in common
and where they differ.
The positive results on macro representations (Gimenez & Jonsson, 2008; Jonsson, 2009)
prompt the obvious question whether long plans can always be compressed using macros
(or any other method). We show in this paper that this is unlikely, no matter what type
of compact representation we try to use (macro plans, finite automata or whatever). The
remainder of the paper is organized as follows. Section 2 introduces basic notation and
concepts as well as the planning framework used in the paper, and it also contains some
useful definitions for the complexity results. We then first ask, in Section 3, whether all
(optimal) plans for an instance can have compact representations. We find that the answer
is no; it is not possible, neither by macros nor any other method. However, the results do
not exclude that some plans for each instance can have compact solutions. In Section 4 we
thus restrict the question to whether there is a uniform compact representation of one plan
for each solvable instance. More precisely, we ask if there is an algorithm that corresponds
to one compact representation for each solvable instance. We show that such an algorithm
is unlikely to exist if it must also be able to access the actions of the plan in some useful way.
In Section 5 we turn to the non-uniform case, asking if each solvable instance has at least
one plan that has a compact representation. We primarily consider representations that
can efficiently access the actions of the plan sequentially or randomly. We show that also
this seems unlikely in the general case, but that there are interesting special cases where
such representations do exist. In this section we also investigate macro representations
and extend the results by Gimenez and Jonsson in two ways. We prove that all plans
that have a polynomial-size macro representation can be random accessed in polynomial
time without having access to the full plan. However, we also prove that we cannot always
represent plans compactly using macros. In Section 6 we analyse whether we can get around
the problem of long plans by reformulating planning to some other problem. Also this is
answered negatively. If we actually ask for a plan for the original problem, then the problem
is inherently intractable also when using reformulation. However, even if considering only
the decision problem it still seems not possible to make planning simpler by reformulation.
Finally, Section 7 contains a discussion of how the results in the paper are related to and
relevant for various other topics like adding information to guide planners, causal graphs
143

fiBackstrom & Jonsson

and plan explanation. The paper ends with a summary of the results together with a list
of open questions.
Some of the results in this paper have appeared in a previous conference publication
(Backstrom & Jonsson, 2011b).

2. Preliminaries
This section consists of three parts. The first part introduces some general notation and
terminology used in the paper. The second part defines the two planning frameworks used
in the paper, Finite Functional Planning and propositional Strips, and presents some
constructions that will be frequently used. The third part briefly recapitulates the concept
of advice-taking Turing machines and also defines the 3SAT problem that will be used on
several occasions in the paper.
2.1 General Notation and Terminology
A sequence of objects x1 , x2 , . . . , xn is written hx1 , x2 , . . . , xn i, with hi denoting the empty
sequence. Given a set X of objects, the set of all sequences over X, including hi, is denoted
X  . For a set, sequence or other aggregation X of objects, we write |X| to denote the
cardinality (the number of objects) of x and we write ||X|| to denote the size (the number
of bits of the representation) of x. The composition of two functions f and g is denoted
f  g and is defined as (f  g)(x) = f (g(x)).
The negation of a propositional atom x is denoted x. A literal is either an atom or
its negation and the set L(X) of literals over a set X of atoms is defined as L(X) =
{x, x | x  X}. Negation is extended to literals such that ` is the same literal as `. Negation
is also extended to sets such that if X is a set of literals then X = {` | `  X}. Let Y be
a subset of L(X) for some set X of atoms. Then P os(Y ) = {x  X | x  Y } is the set
of atoms that appear positive in Y , N eg(Y ) = {x  X | x  Y } is the set of atoms that
appear negated in Y and Atoms(Y ) = P os(Y )N eg(Y ). The set Y is consistent if P os(Y )
N eg(Y ) is empty and a set Z of atoms satisfies Y if both P os(Y )  Z and N eg(Y )Z = .
The update operator n is a binary function such that given a set X of atoms and a set Y
of literals, X n Y is a set of atoms defined as X n Y = (X  N eg(Y ))  P os(Y ).
2.2 Planning
For positive results on compact representations, we want the results to apply to as general
and powerful planning languages as possible, so the results hold also for all languages that
are more restricted. Hence, we use the Finite Functional Planning formalism (Backstrom &
Jonsson, 2011a), which makes a minimum of assumption about the language, except that
it is a ground language over state variables with finite domains.
Definition 1. A Finite Functional Planning (FFP) frame is a tuple hV, D, Ai where V is an
implicitly ordered set of variables, D : V  N is a domain function that maps every variable
to a finite subset of the natural numbers and A is a set of actions. The frame implicitly
defines the state space S(f ) = D(v1 )  . . .  D(vn ), where v1 , . . . , vn are the variables in
V in order. The members of S(f ) are referred to as states. Each action a in A has two
associated total functions, the precondition pre(a) : S(f )  {0, 1} and the postcondition
144

fiAlgorithms and Limits for Compact Plan Representations

post(a) : S(f )  S(f ). For all pairs of states s, t  S(f ) and actions a  A, a is from s to t
if both
1) pre(a)(s) = 1 and
2) t = post(a)(s).
A sequence  = ha1 , . . . , a` i  A is a plan from a state s0  S(f ) to a state s`  S(f )
if either
1)  = hi and s0 = s` or
2) there are states s1 , . . . , s`1  S(f ) such that ai is from si1 to si (for 1  i  `).
An FFP instance is a tuple p = hV, D, A, I, Gi where f = hV, D, Ai is an FFP frame,
I  S(f ) is a state and G : S(f )  {0, 1} is a total function. A state s  S(f ) is a goal
state for p if G(s) = 1. The goal G is reachable from a state s  S(f ) if there is a plan from
s to some goal state for p. A solution for p is a plan from I to some goal state s  S(f ).
A solution for p is called a plan for p.
The complexity of computing the pre- and postconditions of the actions and of the goal
function is referred to as step complexity. In this paper, we will only consider the subclass
FFP([P]) which consists of all FFP frames and instances with polynomial step complexity.
We will occasionally also consider restrictions of FFP([P]) and use the notation FFP(p) for
the class of all FFP frames f (and instances p) where the action pre- and postconditions
(and G) can all be computed in p(||f ||) time (and in p(||p||) time), where p is a polynomial.
We furthermore say that an FFP([P]) instance p = hV, D, A, I, Gi is deterministic if for
all s  S(p) such that p has a plan from I to s, there is at most one a  A such that
pre(a)(s) = 1. That is, if an instance is deterministic then the planner is never faced with
a choice between two or more actions.
When proving that no compact representation can exist, the result gets stronger if we
use a weaker formalism. That is, we want to use the most restricted formalism possible,
since the results will then automatically apply to all formalisms that are more expressive.
Hence, we will use propositional Strips for such results. There are a number of common
variants of propositional Strips that are known to be equivalent to each other and to the
SAS+ formalism under a strong form of polynomial reduction (Backstrom, 1995). What
we will refer to as Strips in this paper is the variant called propositional Strips with
negative goals (PSN) by Backstrom. It can be defined as a special case of FFP([P]) that
uses binary variables, but we define it here in a more traditional way, treating the variables
as propositional atoms.
Definition 2. A Strips frame is a tuple f = hV, Ai where V is a set of propositional atoms
and A is a set of actions. The state space is defined as S(f ) = 2V and states are subsets
of V . Each action a in A has a precondition pre(a) and a postcondition post(a), which are
both consistent sets of literals over V . For all pairs of states s, t  S(f ) and actions a  A,
a is from s to t if both
1) s satisfies pre(a) and
2) t = s n post(a).
A sequence  = ha1 , . . . , a` i  A is a plan from a state s0  S(f ) to a state s`  S(f )
if either
1)  = hi and s0 = s` or
2) there are states s1 , . . . , s`1  S(f ) such that ai is from si1 to si (for 1  i  `).
145

fiBackstrom & Jonsson

A Strips instance is a tuple p = hV, A, I, Gi such that f = hV, Ai is a Strips frame, I is
a state in S(f ) and G is a consistent set of literals over V . A state s  S(f ) is a goal state
for p if s satisfies G. The goal G is reachable from a state s  S(f ) if there is a plan from
s to some goal state for p. A solution for p is a plan from I to some goal state s  S(f ).
A solution for p is called a plan for p.
The notation a : X  Y will be frequently used to define an action a with precondition X
and postcondition Y .
All negative results will be proven to hold for Strips. However, in most cases the results
hold even for many restricted subclasses of Strips. It would lead too far to survey such
cases in this paper so we will use the restriction to unary actions as an archetypical case
throughout the paper.
Definition 3. A Strips action a is unary if |post(a)| = 1, a set of Strips actions is unary
if all its actions are unary and a Strips frame or instance is unary if its action set is unary.
Unary actions may seem like a very limiting restriction but has been demonstrated as
sufficient in many cases for use in on-board controllers for spacecrafts (Muscettola et al.,
1998; Brafman & Domshlak, 2003). This is not surprising, though, since Strips planning is
PSPACE-complete and remains so even when restricted to unary actions (Bylander, 1994).
Given a Strips instance it is always possible to construct a corresponding Strips instance
that is unary. The following reduction to unary instances is a simplified Strips version of
the reduction used for SAS + (Backstrom, 1992, proof of Theorem 6.7).
Construction 4. Let p = hV, A, I, Gi be a Strips instance. Construct a corresponding
a
instance p 0 = hV 0 , A0 , I 0 , G0 i as follows. Define Vlock = {vlock
| a  A}. Then let V 0 =
0
0
0
V  Vlock , I = I and G = G  Vlock . Define A such that for each a  A, it contains the
following actions:
a },
abegin : pre(a)  Vlock  {vlock
a
a },
aend : post(a)  {vlock }  {vlock
a }  {` }, for each `  post(a).
ai : {vlock
i
i
We leave it without proof that this construction is a polynomial reduction from the class
of Strips instances to the class of unary Strips instances. It is furthermore worth noting
that the construction can easily be modified to use padding with redundant variables to
make all original actions correspond to the same number of actions in the unary instance.
Hence, it is possible to make a reduction where the plans for the unary instance are at most
a constant factor longer than the corresponding plans for the original instance.
We will also make frequent use of Strips instances that include encodings of binary
counters based on the following construction, which uses one action for each bit and can
increment a non-negative integer encoded in binary.
Construction 5. An n-bit binary counter can be encoded in Strips as follows: let V =
{x1 , . . . , xn } and let A contain the n actions
ai : {xi , xi1 , . . . , x1 }  {xi , xi1 , . . . , x1 } (1  i  n).
146

fiAlgorithms and Limits for Compact Plan Representations

The following is a plan for counting from 0 to 16 using a 5-bit counter according to Construction 5:
ha1 , a2 , a1 , a3 , a1 , a2 , a1 , a4 , a1 , a2 , a1 , a3 , a1 , a2 , a1 , a5 i.
While we could modify the binary counter to use only unary actions as described in Construction 4, a more direct way to get unary actions is to count in Gray code.
Construction 6. (Backstrom & Klein, 1991) An n-bit Gray-code counter can be encoded
in Strips as follows: let V = {x1 , . . . , xn } and let A contain the 2n actions
si : {xi , xi1 , xi2 , . . . , x1 }  {xi } (1  i  n),
ri : {xi , xi1 , xi2 , . . . , x1 }  {xi } (1  i  n).
The following is a plan for counting from 0 to 16 with a 5-bit Gray-code counter according
to Construction 6:
hs1 , s2 , r1 , s3 , s1 , r2 , r1 , s4 , s1 , s2 , r1 , r3 , s1 , r2 , r1 , s5 i.
2.3 Complexity Theory
We will use the abbreviation DTM for deterministic Turing machine and NTM for nondeterministic Turing machine. In addition to these standard types, we will also use advice
taking Turing machines of both deterministic and nondeterministic type.
An advice-taking Turing machine M has an associated sequence a1 , a2 , a3 , . . . of advice
strings, a special advice tape and an advice function a, from the natural numbers to the
advice sequence, such that a(n) = an . On input x the advice tape is immediately loaded
with a(||x||). After that M continues in the normal way, except that it also has access to the
advice written on the advice tape. If there exists a polynomial p such that ||a(n)||  p(n),
for all n > 0, then M is said to use polynomial advice. The complexity class P/poly is
the set of all decision problems that can be solved by some advice-taking DTM that runs
in polynomial time using polynomial advice. This can be extended such that, for instance,
NP/poly is defined by the NTMs that run in polynomial time using polynomial advice.
Note that the advice depends only on the size of the input, not on its content. Furthermore,
the advice sequence must only exist; it does not need to be computable. The following two
results from the literature will be used later in this paper.
Theorem 7. a) If NP  P/poly, then the polynomial hierarchy collapses (Karp & Lipton,
1980, Theorem 6.1). b) Let k > 0 be an integer. If pk  pk /poly, then the polynomial
hierarchy collapses to level k + 2 (Yap, 1983, Lemma 7 combined with Theorem 2).
The 3SAT problem consists of instances of the form C = {c1 , . . . , cm } where each ci ,
for 1  i  m, is called a clause and is a set of exactly three literals over some universe
of binary variables. The instance C is satisfiable if there exists some assignment of truth
values to the variables used in C such that at least one literal is true in each ci  C. It
is otherwise unsatisfiable. Deciding satisfiability for 3SAT is NP-complete, while deciding
unsatisfiability is coNP-complete. More precisely, we will use the following definition of
3SAT in this paper.
147

fiBackstrom & Jonsson

Definition 8. For all integers n > 0, let Xn = {x1 , . . . , xn } be a set of variables and let
m(n)
m(n) be the number of possible 3-literal clauses over Xn . Let c1n , c2n , . . . , cn
be some
m(n)
1
2
fixed systematic enumeration of these clauses and let Cn = {cn , cn , . . . , cn }. Each clause
m(n) 1
cin defines three literals such that1 cin = {`1i , `2i , `3i }. Further, let Cn0 , Cn1 , . . . , Cn2
be
i
i
a fixed systematic enumeration of all subsets of Cn , and let s n = hXn , Cn i, for 0  i <
m(n)
2m(n) . Also implicitly define the set En = {e1n , e2n , . . . , en } of atoms and its subsets
Eni = {ejn | cjn  Cni }, for 0  i < 2m(n) .
m(n)

1 is a systematic enumeration of all possible 3SAT instances
The sequence s 0n , s 1n , . . . , s 2n
over n variables, and hence equivalent to the usual definition of 3SAT. Technically speaking,
this is a redundant encoding of 3SAT since it allows instances that specify more variables
than are used in the clauses. This is harmless, however; all non-redundant instances remain,
so we still have all hard instances and neither of the redundantly encoded instances can
be harder than their non-redundant counterpart. Since m(n)  8n3 , the enumerations of
Cn and En can be chosen such that they are polynomial-time computable, and we assume
some such enumerations have been fixed from now on. We also note that a set Eni uniquely
identifies the clause set Cni .

3. Representing Arbitrary Plans Compactly
It is known that there are cases where planning instances have exponential-size plans but
the plans always have a polynomial-size representation (Gimenez & Jonsson, 2008). An
obvious question is thus whether all plans, including those of exponential length, can have
polynomial representations. For one interpretation of the question the answer is trivially yes.
Observation 9. The set of all plans for an arbitrary FFP([P]) instance p has an O(||p||)
size representation, since the instance itself together with a deterministic planning algorithm
that successively enumerates and outputs all plans is such a representation.
Although this is a trivial and not very useful observation it highlights some fundamental issues of representations. Liberatore (2005a) discusses a similar representation, where instead
of specifying an algorithm he defines a lexiographic ordering on the actions. Furthermore,
he adds a plan index to be able to represent a single plan rather than just the whole set of
plans. However, such an index is not unproblematic, as we will see soon.
A more interesting interpretation of our question is whether every single plan for a
particular instance can have a polynomial representation. Even more precisely, is there
a polynomial p such that every plan for every planning instance has a representation of
size O(p(n)), where n is the size of the planning instance? To investigate this question we
consider the most simple compact notation possible, an index number i for each plan for
a particular instance. Since instances may have infinitely many plans, due to cycles in the
state-transition graph, we consider optimal plans only. There is, however, no guarantee that
even such an index is small enougha polynomial number of bits may not be sufficient to
represent it.
1. We sometimes omit index n, when it can be assumed obvious from context, and thus write `ki rather
than `kn,i .

148

fiAlgorithms and Limits for Compact Plan Representations

Construction 10. Given an arbitrary integer n > 0, construct the Strips instance p n =
hVn , An , In , Gn i such that Vn = {x1 , . . . , xn , y}, In = , Gn = {x1 , . . . , xn } and An contains
the actions
ai : {xi , xi1 , . . . , x1 }  {xi , xi1 , . . . , x1 , y} (1  i  n)
bi : {xi , xi1 , . . . , x1 }  {xi , xi1 , . . . , x1 , y} (1  i  n).
Lemma 11. For every integer n > 0, instance pn according to Construction 10 has 22
optimal plans.

n 1

Proof. Let n > 0 be an arbitrary integer and p n a corresponding Strips instance according
to Construction 10. This instance is a binary counter over the variables x1 , . . . , xn as in
Construction 5, except that it has an extra variable y that can be independently set to
true or false, depending on whether an action of type ai or bi is chosen. Since the variables
x1 , . . . , xn can be interpreted as a binary number, let the notation hm, yi represent the
state where x1 , . . . , xn encodes the number m and y is false, and let hm, yi represent the
corresponding state where y is true. Whenever in a state hm, yi or hm, yi (where m < 2n 1)
it is possible to go to either of hm + 1, yi or hm + 1, yi using one action, but to no other
states. The state transition graph for this instance appears in Figure 1. The initial state is
h0, yi and the only goal states are h2n  1, yi and h2n  1, yi. Hence, any plan for p n must
be of length 2n  1. From every state that is not a goal state there are two different actions
to choose between and they lead to different states. However, the goal is reachable from
n
both these states so the choice of action does not matter. Hence, there are 22 1 different
plans for p n .

m=

0

1

2n  1
y=1

2

y=0
goal

init

Figure 1: State-transition graph for proof of Lemma 11.
Although the atom y is redundant in this particular example the whole construction could
be a part of a larger instance, where y does have a purpose. It should also be noted that
the instances used in the proof have only optimal plans; all plans have the same length. All
is now set to prove the previous claim.
Theorem 12. For every integer n > 0, it takes 2n  1 bits to index all optimal plans for
instance pn according to Construction 10.
Proof. Since an m-bit number can distinguish between at most 2m different objects, it
follows from Lemma 11 that at least 2n  1 bits is necessary to index the plans for p n
149

fiBackstrom & Jonsson

This result immediately implies that not all (optimal) plans for a Strips instance can have
polynomial-size representations. This holds even under some restrictions, like unary actions.
If basing Construction 10 on a Gray counter instead of a binary counter then every action
has two postconditions. Rewriting this using Construction 4 yields an equivalent instance
with unary actions using a block of four actions for each action in the original instance.
Although the plans get 4 times longer the number of plans will remain the same. Hence,
Theorem 12 still holds.
This theorem leaves the possibility open that some of the plans for an instance can have
polynomial representations, although not all of them can. An interesting question is thus
how many of the plans for an instance can have polynomial representations? To answer that
question we stray into the field of information theory and Kolmogorov complexity. It is out
of the scope of this paper to treat that field in detail, but loosely speaking, the Kolmogorov
complexity of a string is the size of the smallest DTM that can generate the string with
no input. Let K(x) denote the Kolmogorov complexity of a binary string x. The following
lemma is due to Buhrman et al. (2000, Lm. 1).
Lemma 13. (Incompressibility lemma) Let c be a positive integer. Every set A of cardinality
m has at least m(1  2c ) + 1 elements x with K(x)  blog mc  c.
This lemma can be used to show that the fraction of plans that can be compactly represented
approaches zero as the size of instances approaches infinity.
Theorem 14. Let p be an arbitrary polynomial. Consider instances pn according to Construction 10 for arbitrary integers n > 0. Let t(n) be the total number of plans for
pn and let s(n) be the number of plans that can be represented with at most p(n) bits.
Then limn s(n)
t(n) = 0.
n

Proof. Let p be an arbitrary polynomial. We know from Lemma 11 that t(n) = 22 1 .
For every n > 0, let c(n) = 2n  p(n)  2. The incompressibility lemma then says that
there are at least t(n)(1  2c(n) ) + 1 plans  such that K()  blog t(n)c  c(n). That
is, there are at most 2c(n) t(n)  1 plans  such that K() < blog t(n)c  c(n). Using
the values for t(n) and c(n) above, this simplifies to say that there are at most 2p(n)+1  1
plans  such that K()  p(n). Hence, s(n)  2p(n)+1  1. The theorem then follows since
2p(n)+1 1
0  limn s(n)
= 0.
t(n)  limn 22n 1
This means that even if it is the case that some plans for every solvable instance can have
compact representations, the probability that a particular plan has a compact representation
will be vanishingly low for large instances. Although it is not strictly necessary to use
Kolmogorov complexity to prove Theorem 14 doing so makes the information-theoretic
aspect of compact representations clearer.

4. Uniform Compact Representations of Plans
We now know that we cannot, in general, compress arbitrary exponential plans to subexponential size. But what if we do not choose ourselves which plan to use? The previous
result still leaves open for the possibility that a small fraction of solutions for a planning instance could have compact representations. However, the planner (or an oracle or whatever)
150

fiAlgorithms and Limits for Compact Plan Representations

would then have to choose for us which plan to present us with a compact representation
of. Suppose a planner could actually do this, how would we make use of it? If we still need
the actual plan itself then we cannot avoid its exponential size. Hence, the interesting case
seems to be if we could at least access useful information in the plan efficiently.
The term representation is used in a loose sense here, but need not really be precisely
defined for the moment. It suffices to note that any representation needs both some kind
of data structure and some kind of access algorithm, with the extreme cases being either a
vector of data with the trivial access algorithm or an algorithm that embeds all the data.
What could it mean to access a compact representation efficiently? We will investigate
two such criteria. The first one is that we can efficiently retrieve the actions of the actual
plan sequentially. Our interpretation of efficient will be that actions can be retrieved with
polynomial delay (Johnson, Papadimitriou, & Yannakakis, 1988). The second criterion is
that any action in the actual represented plan can be random accessed in polynomial time,
in the size of the instance.
Before looking at explicit representations for each plan we take a look at the uniform
case, where we have a single representation that covers all instances. More precisely, we
consider the case of a single algorithm that works as a compact representation for some
plan for every solvable instance.
Theorem 15. If there is an algorithm that for any solvable Strips instance p can either
generate some plan for p sequentially with polynomial delay or random access any action
in some plan for p in polynomial time, then P = NP.
Note that this theorem does not follow from the fact that Strips planning is PSPACEcomplete since only solvable instances are considered. Before proving the theorem we need to
introduce some extra technical machinery. We start by encoding 3SAT instances according
to Definition 8 in Strips as follows.
Construction 16. Let n > 0 and i, where 0  i < 2m(n) , be arbitrary integers. Construct
the Strips instance p in = hVn , An , Eni , {goal}i such that Vn = Xn En {cts, ctu, goal, inc}
{v0 , . . . , vm(n) } and An has the actions specified in Table 1.
As previously noted, each subset Eni of En uniquely identifies the 3SAT instance s in by telling
which clauses in Cn are enabled in s in . That is, the initial state selects the particular nvariable instance we are interested in. The actions are partitioned into three groups. Group
I contains the two actions acs and acu, which set the atoms cts and ctu respectively. These
actions block each other and both cts and ctu are initially false, so only one of these atoms
can be set to true in any plan. That is, cts and ctu are mutually exclusive. Group II consists
of actions that all require cts true and group III consists of actions that all require ctu true.
These two groups of actions are thus also mutually exclusive. Hence, every plan must start
with exactly one action from group I and the rest of the plan consists only of actions from
either group II or group III, depending on which the first action is. The intention of this
is the following: if the plan starts with action acs then it commits to verifying that s in is
satisfiable and if the plan starts with action acu then it commits to verifying that s in is not
satisfiable. In either case the plan ends with an action that satisfies the goal only if the plan
has verified the commitment made by the first action. This can be interpreted as viewing
151

fiBackstrom & Jonsson

I

acs : {ctu}  {cts}
acu : {cts}  {ctu}

Commit to prove satisfiability
Commit to prove unsatisfiability

II

aseti : {cts, v0 }  {xi }
avt0 : {cts}  {v0 }

Set xi
Start verification

avt0j : {cts, ejn , vj1 ,}  {vj }
avtkj : {cts, ejn , vj1 , `kj }  {vj }
ags : {cts, vm(n) }  {goal}

Skip disabled clause cj
Verify cj true since `kj true
Conclude instance satisfiable

avf j : {ctu, inc, ejn , `1j , `2j , `3j }  {inc}
aixi : {ctu, inc, xi , xi1 , . . . , x1 }
 {inc, xi , xi1 , . . . , x1 }
agu : {ctu, inc, x1 , . . . , xn }  {goal}

Verify clause cj false
Increment counter

III

Conclude instance unsatisfiable

Index ranges: 1  i  n, 1  j  m(n) and 1  k  3.

Table 1: Actions for Construction 16.
the planner as a theorem prover which first outputs a theorem (the first action in the plan)
and then a proof of the theorem (the rest of the plan).
Lemma 17. For every integer n > 0 and integer i such that 0  i < 2m(n) , the Strips
instance pin according to Construction 16 has the following properties:
1. It can be computed in polynomial time in n.
2. It corresponds to the 3SAT instance sin such that every plan for pin starts with action
acs if sin is satisfiable and otherwise with action acu.
3. It always has at least one plan.
Proof. Property 1 is trivial to prove. To prove property 2, we first note that the initial
state contains only atoms from En . As previously noted, each subset Eni of En uniquely
identifies the 3SAT instance s in by telling which clauses in Cn are enabled in s in .
We have two cases: if the plan starts with action acs then it commits to verifying that
i
s n is satisfiable and if the plan starts with action acu then it commits to verifying that s in
is not satisfiable. In either case the plan ends with an action that satisfies the goal only if
the plan has verified the commitment made by the first action. The details of the two cases
are as follows.
If the plan verifies satisfiability, then it must be of the form
k

m(n)
hacs, aseti1 , . . . , asetih , avt0 , avtk11 , . . . , avtm(n)
, agsi.
{z
}
|
|
{z
}

assign

verify

The assign block has h actions that set a satisfying assignment for x1 , . . . , xn . The verify
k
block consists of one action a = avtj j for each clause cjn . If cjn is enabled (ejn true), then
1  kj  3 and a verifies that `kj in cjn is true for the assignment. Otherwise, if cjn is
152

fiAlgorithms and Limits for Compact Plan Representations

disabled then kj = 0, so a = avt0j which skips over cjn without verifying anything. The
planner has thus
1. committed to verify that s in is satisfiable,
2. chosen a satisfying assignment for x1 , . . . , xn and
3. chosen one literal for each enabled clause as a witness that the clause is true under
this assignment.
The last action ags makes the goal true if these three steps are successful. Note that
this works also for the case where no clause is enabled, which corresponds to the trivially
satisfiable instance with an empty set of clauses. Obviously, there is a plan of this form if
and only if s in is satisfiable.
If the plan instead verifies unsatisfiability, then it must be of the form
hacu, b0 , a1 , b1 , a2 , b2 , . . . , ah , bh , agui,
where h = 2n  1. Except for the first and last actions, this plan can be viewed as two
interleaved sequences
 = ha1 , . . . , ah i = haix1 , aix2 , aix1 , aix3 , . . . , aix1 i
and
 = hb0 , b1 , . . . , bh i.
The aixi actions are increment actions that use x1 , . . . , xn to form a binary counter. Since
these variables correspond to the number 0 in the initial state and there are 2n 1 increment
actions, the subplan  enumerates all possible truth assignments for x1 , . . . , xn . Sequence
 consists only of actions of the type avf j . Each avf j action verifies that the corresponding
clause cjn is enabled and false under the current assignment to x1 , . . . , xn . The aixi actions
require inc to be true and set it false, while the avf j actions instead require inc to be false
and set it true. Hence the plan is synchronised such that it alternates between actions from
the two sequences. Since the first aixi action is preceeded by an avf j action and there is
an avf j action after the last aixi action, it follows that there must be some unsatisfied and
enabled clause for every possible truth assignment, since the synchronization will otherwise
get stuck so the counter cannot increment. That is, there is a plan of this type if and only
if s in is unsatisfiable. The last action agu makes the goal true if this succeeded. Note that
in this case there is no need for actions to skip over disabled clauses since it is sufficient to
demonstrate one enabled clause that is false for each assignment.
It follows that the plan is of the first form if s in is satisfiable and of the second form if
i
s n is unsatisfiable. Furthermore, since the first action is a commitment for the rest of the
plan whether to verify satisfiability or unsatisfiability, it is sufficient to check this action to
decide if s in is satisfiable or not.
Property 3 follows immediately from property 2 since the plan must be of either of the
two forms.
We now have the necessary tools to prove the theorem.
153

fiBackstrom & Jonsson

Proof of Theorem 15. Suppose there is an algorithm with either sequential or random access as stated in the precondition of the theorem. We can then solve any 3SAT instance
s in in polynomial time by asking the algorithm for the first action of some plan for the
corresponding instance p in and tell from this action whether s in is satisfiable. However, this
implies that P = NP.
This proof would still hold if rewriting Construction 16 as described in Construction 4, that
is, Theorem 15 holds even if restricted to the set of unary Strips instances only.

5. Non-Uniform Compact Representations of Plans
Theorem 15 uses a very strong criterion: it requires that one single algorithm can handle
all instances. A more relaxed variant is the non-uniform case, where we allow different
representations for different instances. That is, we will consider compact representations
of single plans under different access criteria. In order to do so we must first define more
precisely what we mean by such representations.
5.1 Compact Representations and Access Mechanisms
We define the concepts Csar and Crar which are representations of action sequences
characterised by their access properties2 .
Definition 18. Let f be an arbitrary function. Let f = hV, D, Ai be an FFP([P]) frame
and let   A . A representation  of  is a DTM. Furthermore:
1.  is f -compact if ||||  f (||f ||) and it runs in f (||f ||) space including the input and
output tapes.
2.  is an f -compact sequential-access representation (f -Csar) of  if it is f -compact,
takes no input and generates the actions in  sequentially in f (||f ||) time for each
successive action.
3.  is an f -compact random-access representation (f -Crar) of  if it is f -compact and
for an arbitrary index i (where 1  i  ||) as input, it outputs action i of  in
f (||f ||) time.
Note that this definition does not require that the representations are computable. We
could have used two separate functions, one to bound the access time and one to bound the
size, which would allow for better precision. However, we choose to use a single function
for both since this makes the theory simpler and clearer while having sufficient precision for
our purposes in this paper. We further consider the output tape as cleared between actions
so the output is a single action, not the sequence . Also note that the space complexity
includes the input and output tapes, which implies that the longest sequence an f -Crar 
2. Note that this definition differs slightly from our previous one (Backstrom & Jonsson, 2011b). First, we
have generalised the definition to allow compact representations for an arbitrary function f , not just an
arbitrary polynomial. Second, in order to improve the precision we no longer use the O() notation but
exact functions. Finally, the representations now have the same restriction for space and time. None of
these changes matter for the results in our previous publication, but only for the details of proofs.

154

fiAlgorithms and Limits for Compact Plan Representations

can represent is less than 2|||| actions since its input is limited to |||| bits. A Csar has no
corresponding limit since it has no input. Furthermore, the time restriction for an f -Csar
can be viewed as a generalisation of the polynomial delay concept which is not restricted to
polynomials. We will often apply this definition to instances rather than frames. Although
this makes a slight difference technically, it is not important in principle and ignoring it
allows for simpler theorems and proofs. We write only Crar and Csar when referring to
the whole family of representations of a particular type.
5.2 Sequential-Access Representations
For sequential access in the non-uniform case we would like to ask if all solvable Strips
instances have at least one plan with a polynomial Csar. Unfortunately, that still remains
an open question. Hence, we consider a more restricted case of this question where we also
require that the Csar must be verifiable within some resource constraint, which we define
as follows.
Definition 19. For every FFP([P]) plan representation type R, define the following decision problem:
Plan Representation Verification
Instance: An FFP([P]) instance p = hV, D, A, I, Gi and a string .
Question: Is  an R-representation of a plan for p?
The complexity of verification is measured in ||p|| + ||||. We can now state the following
theorem about polynomial Csars.
Theorem 20. Let C be an arbitrary complexity class and p an arbitrary polynomial. If
p-Csar verification is in NP C and every solvable Strips instance has at least one plan
with a corresponding p-Csar, then PSPACE  NP C .
Proof. Let p be an arbitrary polynomial. Suppose p-Csar verification is in NPC and every
solvable Strips instance has at least one plan with a corresponding p-Csar. Let p be
an arbitrary Strips instance. We can then decide if p has a plan by guessing a string of
length p(||p||) bits and then check if that string is a p-Csar for some plan for p. This can
be done in polynomial time (in ||p||) using an NTM with an oracle for C since p-Csar
verification is in NPC . However, deciding if a Strips instance has a plan is PSPACEcomplete (Bylander, 1994, Thm. 3.1) so it follows that PSPACE  NPC , since p was
chosen arbitrarily.
That is, a Csar for a planning instance is of limited use if we must first verify that it is
correct before using it, since this verification may be as difficult as solving the instance itself.
Also note that if C is a class in the polynomial hierarchy, then PSPACE  NPC implies a
collapse of this hierarchy. The preceding theorem holds for the restriction to unary Strips
instances, since planning is still PSPACE-complete for this restriction (Bylander, 1994,
Thm. 3.3). In fact, it holds for all restrictions where planning is still PSPACE-complete,
which includes several other cases in Bylanders analysis as well as many subclasses of
SAS+ planning (see Backstrom & Nebel, 1995; Jonsson & Backstrom, 1998a, for overviews
of results).
155

fiBackstrom & Jonsson

Although this result may seem disapointing, it holds only under the condition that we
must check whether the Csar is correct. That means, for instance, that the theorem is
irrelevant if correctness of the Csar is guaranteed by design. One such case is the following.
Theorem 21. Every Strips instance according to Construction 16 has a plan with a
polynomial Csar.
Proof. Consider an arbitrary such instance p in . Add n + 1 extra bits b0 , . . . , bn such that b0
tells if s in is satisfiable or not. If s in is satisfiable then the remaining bits specify a satisfying
assignment such that bi gives the value for vi , and they are otherwise undefined. We claim
there is a simple deterministic algorithm that uses only p in and b0 , . . . , bn and generates a
plan for p in with polynomial delay as follows.
Suppose b0 says that s in is satisfiable and that h of bits b1 , . . . , bn are one. Then there
is a plan for p in of the form
k

m(n)
, agsi.
hacs, aseti1 , . . . , asetih , avt0 , avtk11 , . . . , avtm(n)
{z
}
|
{z
}
|

assign

verify

The actions in the assign block can easily be generated from b1 , . . . , bn . For the avtkj actions,
output avt0j if cjn is not enabled and otherwise output avtkj for the smallest k such that `kj
is true for the specified assignment. Clearly this algorithm works with polynomial delay.
Instead suppose s in is not satisfiable. Then the plan is of the second type and must cycle
through all possible assignments. Doing this and generating the corresponding counting
actions is trivial. For each assignment we must also output an avf j action. Determine
the smallest j such that cjn is enabled but not satisfied for the current assignment, and
output avf j . This can be done in polynomial time since there is only a polynomial number
of clauses.
Clearly this construction is a polynomial Csar for some plan for p in .
The following theorem demonstrates that there are also more general and harder classes
of instances where even optimal plans have polynomial Csars by design.
Theorem 22. There is a subclass X of Strips and a polynomial p such that deciding if
instances of X have a plan is PSPACE-complete and all solvable instances of X have an
optimal plan with a p-Csar.
Proof. PSPACE can be characterised by the class of polynomial-space bounded DTMs.
Bylander (1994, Thm. 3.1) used this fact to demonstrate a polynomial reduction from
PSPACE to Strips planning. We refer to Bylander for details but in brief: given a
machine M with input x he constructs a deterministic Strips instance that has a plan if
and only if M (x) accepts. Hence, it is a polynomial time problem to check that we are in a
valid state and then find the only action, if any, that can be applied in that state. It follows
that there is some polynomial p such that every such solvable Strips instance has a plan
with a p-Csar. Furthermore, since the instance is deterministic it has only one plan, which
must then be optimal.
156

fiAlgorithms and Limits for Compact Plan Representations

An even more general observation is that every deterministic FFP([P]) instance that is
solvable has exactly one plan, which is thus optimal, and that this plan has a polynomial
Csar. As a contrast to this we will next consider a class of instances where solvable instances
always have plans with polynomial Csars but where we have no optimality guarantee. This
example thus illustrates that a Csar is just a representation and that it gives no guarantees
about the actual data it represents. More precisely, the example uses the class of reversible
FFP([P]) instances, where the state-transition graph is symmetric.
Definition 23. An FFP([P]) frame f = hV, D, Ai is reversible if for all pairs of states s
and t in S(f ), whenever there is an action a in A from s to t then there is also an action a0
in A from t to s.
Note that reversible instances are not an easy special case of planning; deciding if there is
a plan or not is still PSPACE-complete (Jonsson et al., 2000, Thm. 18). That is, plans can
still be of exponential length.
Theorem 24. There is a polynomial q such that for all polynomials p, every solvable and
reversible FFP(p) instance has a (q  p)-Csar for some plan.
Proof. Let p = hV, D, A, I, Gi be a solvable FFP(p) instance such that f = hV, D, Ai is
reversible. Consider the algorithm in Figure 2. Optplan is assumed to be an algorithm such
that optplan(s,G) returns the length of the shortest plan from s to G.
If ignoring process B, it is clear that the algorithm outputs an optimal plan for p since
there is a plan by assumption. Process B finds two actions a1 and a2 such that executing
ha1 , a2 i in state s ends up in state s. Such a choice of actions must exist since there is a
plan from s to some goal state and f is reversible. The synchronisation between processes
A and B make all such actions a1 , a2 appear adjacent in that order in the output of the
algorithm, and they do thus not interfere with the plan produced by process A. They just
make the plan longer. Choosing actions in process B can be done by a double loop through
all pairs of actions and checking them.
It is obvious that there is a polynomial r such that process B runs in r(||p||) time. We
can choose r to also allow extra time to run process A in parallel. Let  be p together with
the algorithm. Then ||||  ||p|| + c for some constant c. Choose r such that it also satisfies
n + c  r(n) for all n > 0. Obviously,  is an r-Csar for some plan for p. Choose the
polynomial q such that r(n)  q(p(n)) for all n > 0.
Algorithm Optplan must obviously run in polynomial space, but its complexity is otherwise
not important. The parallel algorithm used in the proof of this theorem is to some extent a
nonsense algorithm. Process A does all the job by consulting an ordinary planning algorithm
(optplan) but gives no time guarantees. Process B, on the other hand, contributes nothing
relevant to the plan but satisfies the access time requirement. That is, process B buys time
for process A to find the plan by generating irrelevant actions frequently enough to satisfy
its time requirements. The wait statements are not strictly necessary but illustrate that we
can tune the step complexity of the algorithm by slowing down process B if desired.
Although this example might, perhaps, be considered somewhat pathological, it clearly
demonstrates that a Csar (just like a Crar) is only a representation. Just like most
other data structures it has certain access properties but does not guarantee any particular
157

fiBackstrom & Jonsson

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

s := I
while G(s) = 0 do
do in parallel
process A:
` = optplan(s, G)
for all a0  A s.t. pre(a0 )(s) = 1 do
t := post(a0 )(s)
if optplan(t, G) < ` then
a := a0 , ` := optplan(t, G)
process B:
while process A running do
choose a1  A s.t. pre(a1 )(s) = 1
u := post(a1 )(s)
choose a2  A s.t. pre(a2 )(u) = 1 and post(a2 )(u) = s
output a1
wait T
output a2
wait T
output a
s := post(a)(s)

Figure 2: Csar algorithm for reversible instances.
properties of the actual data stored. This not uncommon for plan representations either.
For instance, a reactive plan could be constructed to have the same behaviour and still
be considered correct and run in polynomial time and space. We can alternatively use
a random walk algorithm, which will also output actions with polynomial delay. It will
eventually reach the goal if there is a plan, but it will also output a lot of redundant
actions. The algorithm in Figure 2 may, in a sense, be viewed as a derandomized variant
of random walk.
5.3 Random-Access Representations
The case of non-uniform random access is clearer than the case of sequential access. Here
we can answer the question of existence for Crars without any further qualifications about
verifiability.
Theorem 25. If there is a polynomial p such that every solvable Strips instance has at
least one plan with a corresponding p-Crar, then the polynomial hierarchy collapses.
Since this theorem is not conditioned by verifiability of the representations it is a stronger
result than Theorem 20. Before proving the theorem we need to introduce some additional theory.

158

fiAlgorithms and Limits for Compact Plan Representations

Construction 26. Let n > 0 be an arbitrary integer. Construct a Strips instance p n =
hVn , An , , {goal}i such that
Vn = Xn  En  {v0 , . . . , vm(n) }  {svi, sva, sia, sii, sti, t, f, goal}
and An has the actions specified in Table 2.

abi : {svi, sva, sia, sii, sti}  {svi, t}

Begin instance block

aba : {svi, sia}  {sva, f , v0 , v1 , . . . , vm(n) }

Begin assignment block

avtkj : {sva, vj , vj1 , ejn , `kj }  {vj }
avf j : {sva, vj , vj1 , ejn , `1j , `2j , `3j }  {vj , f }

Verify `j true in clause cj
Verify clause cj false

avsj : {sva, vj , vj1 , ejn }  {vj }

Skip disabled clause cj

aaf : {sva, vm(n) , f }  {sva, sia}
aat : {sva, vm(n) , f }  {sva, sia, t}

Verify assignment satisfying
Verify assignment not satisfying

aixi : {sia, xi , xi1 , . . . , x1 }  {sia, xi , xi1 , . . . , x1 }
arx : {sia, xn , . . . , x1 }  {sia, svi, sti, xn , . . . , x1 }

Increment assignment counter
Reset assignment counter

ais : {sti, t}  {sti, sii}
aiu : {sti, t}  {sti, sii}

Verify instance satisfiable
Verify instance unsatisfiable

1
aiij : {sii, ejn , enj1 , . . . , e1 }  {sii, ejn , ej1
n , . . . , en }

Increment instance counter

ari :

m(n)
{sii, en , . . . , e1n }

 {goal}

All instances checked

Index ranges: 1  i  n, 1  j  m(n) and 1  k  3.

Table 2: Actions for Construction 26.
The previous Construction 16 allows plans of two types, either choosing an assignment
and then verifying all clauses by chaining, or enumerating all assignments and demonstrate
one false clause for each. Construction 26 mixes these methods. To check if an instance
is satisfiable the plan must enumerate all variable assignments and for each assignment
it must walk through all clauses by chaining. For each enabled clause it demonstrates
either a true literal or that none of the literals is true, while disabled clauses are skipped
over. Atoms f and t keep track of whether all clauses were true for some assignment, in
m(n)
which case the instance is satisfiable. An extra counter that uses the variables e1n , . . . , en
enumerates all possible subsets Eni of En , thus implicitly enumerating all 3SAT instances
m(n) 1
s 0n , . . . , s 2n
. This counter constitutes an outer loop, so for each Eni , all possible
assignments for x1 , . . . , xn are tested as described above. The plan can be thought of as
implementing the algorithm in Figure 3.
Lemma 27. For all integers n > 0, instance pn according to Construction 26 has the
following properties:
1. It can be computed in polynomial time in n.
159

fiBackstrom & Jonsson

1
for all 3SAT instances s of size n do
2
clear t
3
for all assignments to x1 , . . . , xn do
4
clear f
5
for all clauses cj do
6
if cj disabled in s then
7
do nothing
8
elsif some `kj in cj is satisfied then
9
do nothing
10
else (neither of `1j , `2j or `3j is satisfied)
11
set f
12
if not f then
13
set t
14
if t then
15
report s as satisfiable
16
else
17
report s as unsatisfiable
Figure 3: Algorithmic description of Construction 26.
2. It always has at least one plan.
3. There exist constants an and bn such that for every i, where 0  i < 2m(n) , the action
at position bn i + an in any plan for pn is ais if the 3SAT instance sin is satisfiable and
it is aiu if sin is unsatisfiable.
Proof. In addition to the previous explanation of the construction we note that the instance
is designed to be deterministic. Setting an = 2n (m(n) + 3) + 2 and bn = an + 1 satisfies
the claim, since the action at position bn i + an is ais if s in is satisfiable and it is aiu if it is
unsatisfiable.
All is now set to prove the theorem.
Proof of Theorem 25. Suppose p is a polynomial such that all solvable Strips instances
have at least one plan with a corresponding p-Crar. For each n > 0, let p n be the
corresponding instance according to Construction 26 and let n be a p-Crar for some plan
n for p n . By assumption, such n and n must exist for every n.
Construct an advice-taking DTM M which takes input of the form I in = hp n , ii, where
n and i are integers such that n > 0 and 0  i < 2m(n) . Let i be represented in binary
using exactly m(n) bits. Then, ||I in || is strictly increasing in n and depends only on n.
Let sn = ||I in || (which is well defined since ||I in || does not depend on i). Define the advice
function a such that a(sn ) = n . The advice is thus a p-Crar for some plan for the Strips
instance p n according to Construction 26. (Recall that we only need to know that the
advice exists, not how to find it.) Let an and bn refer to the corresponding constants that
must exist according to Lemma 27. Since M can run whatever algorithm is used to access
n , it follows from the assumptions that M can find action bn i + an in n in polynomial
time in sn . Let it return yes if this action is ais and otherwise return no.
160

fiAlgorithms and Limits for Compact Plan Representations

Given an arbitrary 3SAT instance s in , compute the corresponding input I in for M and
then run M on this instance. By construction, M answers yes if and only if s in is satisfiable. The input I in can be computed in polynomial time in ||s in || and M runs in polynomial time using polynomial advice. Since M solves satisfiability for 3SAT it follows that
NP  P/poly, which is impossible unless the polynomial hierarchy collapses at level 2
according to Theorem 7a.
It is further worth noting that the plans for instances according to Construction 26
contains a subplan for every 3SAT instance of a particular size. Hence, we can alternatively
view such a plan as a representation of a set of exponentially many plans, which shows
that representing one long plan and representing a large set of plans are not fundamentally
different issues.
Also for Crars there are restricted cases where we can prove that they always exist.
One such example is, once again, Construction 16.
Theorem 28. Every Strips instance according to Construction 16 has a plan with a
polynomial Crar.
Proof. Add n+1 extra bits b0 , . . . , bn as explained in the proof of Theorem 21 and construct
a polynomial-time random-access algorithm as follows.
Suppose b0 says that s in is satisfiable and that h of bits b1 , . . . , bn are one. Then there
is a plan for p in of the form
k

m(n)
hacs, aseti1 , . . . , asetih , avt0 , avtk11 , . . . , avtm(n)
, agsi.
|
{z
}
|
{z
}

assign

verify

Since h  n we can construct the whole assign sequence and then determine a specific action
in it in polynomial time. Each of the avtkj actions correspond to a specific clause cjn . Since
the clauses are ordered we can compute j from the index of the action we ask for. If cjn is
not enabled then output avf 0j and otherwise output avf kj for the smallest k such that `kj is
true for the specified assignment b1 , . . . , bn .
Instead suppose s in is not satisfiable. Then all but the first and last actions are interleaved aixi and avf j actions. The aixi actions have the function of a counter over the
variables x1 , . . . , xn . Let i be an arbitrary index i into the plan where i is not the first or
last action. If i is odd, then ai is an aixk action and k can easily be computed from i, so
output aixk . If i is even then ai is an avf j action. The value of x1 , . . . , xn immediately
before ai can easily be computed from i. Use this value and check all enabled clauses in
order until finding a clause cjn that is not satisfied and then output avf j .
Clearly this construction is a polynomial Crar for some plan for p in .
Another and much larger class of instances where plans have Crars will be considered in
the next section.
5.4 Relationships between Compact Representations
In this section we investigate how the Crar and Csar concepts relate to each other. Since
a macro plan can also be viewed as a compact representation we also investigate how macro
161

fiBackstrom & Jonsson

plans relate to our concepts. We start by showing that if there is a polynomial Crar for a
plan then there is also a polynomial Csar for that plan.
Theorem 29. There is a polynomial q such that for all polynomials p, all FFP([P]) frames
f = hV, D, Ai and all   A , if  has a p-Crar, then it also has a (q  p)-Csar.
Proof. Let f be arbitrary FFP([P]) instance and let  be a p-Crar for some plan  for f .
Use an action counter that is initiated to index the first action in the plan. Generate the
actions of the plan sequentially by repeatedly asking  for the action indexed by the counter
and then incrementing the counter. Let 0 denote this algorithm together with . A ||||-bit
counter is sufficient since  must be shorter than 2|||| actions. Suppose it takes r(m) time
to increment an m-bit counter. Then there is a constant c such that ||0 ||  |||| + c, 0 runs
in 2p(||f ||) + c space and 0 runs in p(||f ||) + r(p(||f ||)) + c time. Define the polynomial q as
q(n) = 2r(n)+c. Obviously, ||0 ||  ||||+c  q(||||)  q(p(||f ||)), 2p(||f ||)+c  q(p(||f ||))
and p(||f ||) + r(p(||f ||)) + c  q(p(||f ||)) so 0 is a (q  p)-Csar for .
The opposite of this does not hold, however. In particular, while not all instances according
to Construction 26 have a plan with a Crar they all have a plan with a Csar, so this
construction acts as a separation between the two concepts.
Theorem 30. Unless the polynomial hierarchy collapses, there is no polynomial q such that
for every polynomial p, every Strips instance p and every plan  for p, if  has a p-Csar
then  has a (q  p)-Crar.
Proof. Let X denote the class of Strips instances used in the proof of Theorem 25. Since
these instances are deterministic there is a polynomial p such that every solvable instance
has a p-Csar for some plan. However, it follows from the same proof that there is no
polynomial r such that all instances of X have a plan with an r-Crar. Hence, there is no
polynomial q such that all instances have a plan with a (q  p)-Crar.
Although not previously defined in the paper, it makes sense to also have a look at
macro plans in this context. A macro is a sequence of two or more actions. Macros are
commonly used in planning and treated as a single action by the planner. Macros can
be useful for planning if there are certain subsequences of actions that occur frequently in
plans (Korf, 1987). However, macros may also be used for the purpose of representing a
plan in a more compact and structured way. This is especially true if macros are allowed
to also contain other macros, since this allows hierarchies of macros. For instance, it is well
known that the shortest solution for the Towers-of-Hanoi problem for arbitrary number
of disks can be described by a recursive schema (Gill, 1976, Ex. 319) although the plan
itself is exponential in the number of disks. The 3S class of planning instances (Jonsson &
Backstrom, 1998b) has the property that we can always find out in polynomial time if an
instance has a plan, but the plan itself may be of exponential length and thus cannot be
generated in subexponential time. Gimenez and Jonsson (2008) showed that plans for 3S
instances always have a polynomial-size representation using macros. In fact, such a macro
plan can even be generated in polynomial time although the actual non-macro plan would
take exponential time to generate. This result was later generalised to some other classes
162

fiAlgorithms and Limits for Compact Plan Representations

of planning instances by Jonsson (2009). We will show that polynomial-size macro plans
have an immediate connection to compact plan representations. However, in contrast to
Gimenez and Jonsson we will not discuss how to generate macro plans but only analyse
some of their properties.
Macro plans can be very powerful tools for representing plans compactly. Hence, it is
interesting to identify criteria for when compact macro-plan representations exist and not.
That problem is out of the scope of this paper, but we will give a partial answer to the
question in the following way. It is straightforward to see that a macro plan can be viewed
as a context free grammar (CFG): let the actions be the terminals, let the macros be the
variables, let the macro expansions be the production rules and let the root macro be the
start symbol. We note that if we use macros to represent a single plan, rather than to represent various possibilities for planning, then the macro expansions must be acyclic in order to
produce a unique well-defined plan. Hence, a macro plan can be defined as an acyclic CFG.
When such CFGs are used to represent a single string compactly they are often referred
to as compressed grammars. Furthermore, such a compressed grammar permits efficient
random access into the string it represents; both the access and the necessary preprocessing
is polynomial time in the size of the grammar (Bille et al., 2011). More precisely, consider
a grammar of size n that represents a string of length N with a derivation tree of maximum
height h. After a polynomial time preprocessing, in the size of the grammar, it is possible
to random access any symbol in the string by index in O(log N ) time or, alternatively, in
O(h) time. Such algorithms typically work by first computing the length of the substrings
generated by each rule, the preprocessing step, and then use this information to find the
symbol with a certain index by top-down search. Since the grammar is acyclic we get h  n.
Hence, the following proposition is immediate from the properties of compressed grammars.
Proposition 31. There is a polynomial r such that for every FFP([P]) frame hV, D, Ai
and every macro plan  for a sequence   A ,  can be used to random access any action
in  in r(||||) time.
We thus get the following relationship between macro plans and Crars.
Theorem 32. There is a polynomial p such that for all polynomials q, all FFP([P]) frames
f = hV, D, Ai and all action sequences   A , if  has a macro plan  such that |||| 
q(||f ||) then  has a (p  q)-Crar.
Proof. Let r be a polynomial such that all macro plans 0 can be random accessed in r(||0 ||)
time. Let  be  together with the random access algorithm. Then ||||  |||| + c for some
constant c. Define p such that p(n) = r(n) + c. We get ||||  |||| + c  q(||f ||) + c 
r(q(||f ||)) + c = p(q(||f ||)). Furthermore,  runs in r(||||)  r(q(||f ||)) + c = p(q(||f ||))
space and time. It follows that  is a (p  q)-Crar for .
It follows from Theorem 29 that every plan with a polynomial macro plan also has a
polynomial Crar. That is, the class of polynomial macro plans is a subclass of the class of
polynomial Crars, but we do not know if it is a proper subclass. In any way, these results
do imply that we cannot always find a polynomial macro plan for an instance.
Corollary 33. If there is a polynomial p such that every solvable Strips instance has at
least one plan with a corresponding macro plan of size p(||p||) then the polynomial hierarchy collapses.
163

fiBackstrom & Jonsson

Proof. Immediate from Theorems 25 and 32.

6. Problem Reformulation
Having now concluded that there seems to be little hope that plans can be compactly
represented in the general case, we turn to the idea of problem reformulation to see if that
can be of any help. While this may seem out of place in this context it is, to the contrary, a
quite logical step to take. So far, we have only analysed planning problems and plans, and
that is what the results hold for. It is not obvious that, or when, the results hold also when
planning instances are solved by reformulating them to instances of some other problem. It
is thus hypothetically possible that we could get around the problems with this approach.
However, to say something useful and relevant about this, it is not sufficient to look only at
naive approaches, such as polynomial reductions, so we will investigate a stronger criterion.
The basic idea of reformulation is to transform a planning instance to another equivalent instance, either another planning instance or an instance of some other problem. For
reformulation to be useful, the solution for the new instance must be of use to solve the
original instance, and something must be gained. Often, reformulation is used with the intention that the overall process is faster than solving the original instance directly. Common
variants are to reformulate planning into SAT, CSP, model checking or another planning
problem. Reformulation of planning into SAT was first suggested by Kautz and Selman
(1992) and is still a popular approach to planning. Long, Fox, and Hamdi (2002) discuss
reformulation for planning in general and Edelkamp, Leue, and Visser (2007) discuss the
connections between model checking and planning.
The reformulation process can be viewed as shown in Figure 4. A planning instance p has
a solution  that we can find directly using ordinary planning. Solving p via reformulation
instead follows the indirect path in the figure. First p is reformulated into a new instance
R(p) (of some problem). Then this instance is solved which produces a solution  for R(p).
Finally,  is transformed back into a solution  for p.

p
Direct

R(p)
Indirect




Figure 4: Reformulation of the generation problem.
Obviously, reformulation cannot help us when plans are exponential. Even if the first
two steps of the indirect path took polynomial time and  was of polynomial size, it would
still necessarily take exponential time to transform  into  because  is exponential. That
164

fiAlgorithms and Limits for Compact Plan Representations

is, the problem is inherently intractable whichever method we use to solve it. Reformulation
could potentially speed things up, if  could somehow be used directly as a solution for the
original problem, but that would happen rarely, if at all.
The situation is different, though, if we consider the decision problem rather than the
generation problem, that is, if we ask not for a plan but for whether there is a plan or not.
In this case we can use the solution for R(p) directly, since decision problems have only two
possible answers, yes or no. We may thus escape the inherent intractability. This variant of
reformulation is shown in Figure 5. Since no exponential solution is generated in this case,
reformulation could potentially be more efficient. We know that the decision problem for
Strips is PSPACE-complete in the general case. If the reformulated problem were easier
to solve, then it could be beneficial to first reformulate p to R(p) and ask if that instance
has a solution or not. Then it would be possible to check if there is a solution at all before
embarking on generating a possibly exponentially long plan. Consider, for instance, the
3S class (Jonsson & Backstrom, 1998b) where plans may be of exponential size but it is
always possible to decide in polynomial time if there is a plan. It thus seems like the case
of reformulating decision problems is the most interesting one to look at, and if that does
not give any improvement, then there can hardly be any improvement for plan generation
via reformulation either.

p
Direct

R(p)
Indirect

Yes/No

Yes/No

Figure 5: Reformulation of the decision problem.
Let PE(Strips) denote the decision problem (that is, plan existence) for Strips. The
following two results are trivial, but illustrative.
Theorem 34. a) There exists a decision problem X and a function R such that it holds for
all p  PE( Strips) that R(p)  X and that p and R(p) have the same answer. b) If there
is some complexity class C, some decision problem X  C and a polynomial-time computable
function R such that it holds for all p  PE( Strips) that R(p)  X and that p and R(p)
have the same answer, then PSPACE  C.
Proof. a) Let X = PE(Strips) and R the identity function. b) Immediate, since R is a
polynomial reduction from PE(Strips) to X.
In both cases we reformulate a PSPACE-complete problem into a PSPACE-complete problem, which is not very interesting. If we are to prove anything better, we must obviously
look for an X and an R with more useful restrictions.
165

fiBackstrom & Jonsson

It is important to note that when reformulating planning into some NP-complete problem, for instance SAT, this does not magically make planning NP-complete. The reason
that Strips planning is PSPACE-complete is that it allows exponential solutions. As soon
as we restrict the solutions to be bounded by some fixed polynomial, planning belongs in
NP. Furthermore, encodings of planning instances in SAT typically use atoms to encode
what actions appear at each position in the plan, that is, an exponential number of extra
atoms are required in the general case. Hence, either our original problem was already in
NP or we have to blow up the instance exponentially when reformulating to SAT. In the
latter case, the complexity results are no longer comparable. Also note, that if we deliberately restrict ourselves to ask only if there is a plan of a certain length or shorter, then we
are actually solving a restricted version of the optimization problem, and also in this case
planning itself would be no harder. In fact, it seems most unlikely that planning in general
could be reformulated into a problem in NP. In order to avoid straightforward and naive
approaches to reformulation we consider and analyse reformulations defined as follows.
Definition 35. Let p = hV, A, I, Gi be a Strips instance, let f = hV, Ai and let d = hI, Gi.
Let X be some decision problem. A reformulation of PE(Strips) into X is a pair hR, ri of
functions that maps every instance p = hf , d i  PE(Strips) to a corresponding instance
x = R(r(f ), d )  X such that p and x have the same answer. hR, ri is a polynomial
reformulation if there are also some fixed polynomials p, q such that
1) ||r(f )||  O(p(||f ||)) and
2) R is computable in O(q(||r(f )|| + ||d ||)) time.
We thus consider a reformulation that involves two functions, R and r. Function r is the
main reformulation function, intended to reformulate the difficult part of the instance. We
do not even require this function to be computable, we only require that it exists. Function
R is then used to transform the initial and goal descriptions into something similar that the
new instance can use, and combine this with the result delivered by r into a proper instance
of X. It should be noted that this reformulation concept is similar, although not identical,
to the compilation concept used by Nebel (2000).
Theorem 36. There is no polynomial reformulation of PE( Strips) to some X  NP,
unless the polynomial hierarchy collapses.
Proof. Suppose hR, ri is such a reformulation. For arbitrary integer n > 0, let f un = hVn , An i
be defined as in Construction 16, but without action acs, and let d in = hEni , {goal}i, for all
i such that 0  i < 2m(n) . It follows trivially from the proof of Lemma 17 that instance
p in = hf un , d in i has a solution if and only if s in is unsatisfiable (note that the SAT part of
the instance is disarmed).
Construct an advice-taking NTM M with input I in = hf un , ii, for all n > 0 and 0 
i < 2m(n) , representing i in binary using m(n) bits. Clearly, ||I in || is strictly increasing and
depends only on n, so let sn = ||I in || (for arbitrary i). Define the advice function a such that
a(sn ) = r(f un ). (Note that we only need to know that the advice exists, not how to find it).
Let M first compute d in from I in , and then compute x in = R(a(sn ), d in ) = R(r(f un ), d in ),
both in polynomial time since a(sn ) is given for free as advice. By assumption, x in  X and
has answer yes if and only if p in has a solution. Also by assumption, we have X  NP so
166

fiAlgorithms and Limits for Compact Plan Representations

M can solve x in by guessing a solution and verifying it in polynomial time. Hence, deciding
if p in has a solution is in NP/poly.
For an arbitrary 3SAT instance s in , compute I in in polynomial time. M answers yes for
i
I n if and only if s in is unsatisfiable. However, unsatisfiability for 3SAT is coNP-complete
so it follows that coNP  NP/poly, which is impossible unless the polynomial hierarchy
collapses to level 3, according to Theorem 7b.
This result can be pushed arbitrarily high up in the polynomial hierarchy, thus making it
unlikely that planning could be reformulated to anything simpler at all.
Corollary 37. There is no polynomial reformulation hR, ri of PE( Strips) to some decision
problem X  pk , for k > 1, unless the polynomial hierarchy collapses to level k + 2.
Proof sketch. Construction 16 demonstrates how to encode both existential quantification
(choosing a truth assignment in the sat part) and universal quantification (enumerating
all truth assignments in the unsat part). Hence, it is straightforward to modify it to an
analogous construction for QBF formulae with k alternations. Given that, the rest of the
proof is analogous to the proof of Theorem 36, but M must use an oracle for pk1 . The
same argument leads to pk  pk /poly, which is impossible unless the polynomial hierarchy
collapses to level k + 2, according to Theorem 7b.
Since both these proofs build on Construction 16 and do not rely the exact position
of actions it follows that also this Theorem and Corollary hold when restricted to unary
Strips instances only.

7. Discussion
This section consists of five parts. We first transfer the reformulation theorem to a more
general result about adding information to guide planners, and discuss how that can explain
various results in the literature. We then discuss the potential relationship between causal
graphs and compact representations. This is followed by a discussion on how the results in
the paper could be relevant for plan explanation. The fourth part discusses some related
work on compact representations and compilation. The section ends with a summary of the
results and a list of open questions.
7.1 Reformulation and Additional Information
Theorem 36 has broader consequences than just for reformulation. In fact, it implies that
there is no way to help a planner by adding information to a planning frame, no matter
what information or how we get it, unless we accept that the amount of information is not
always polynomially bounded in the frame size. In the following theorem the function g is
assumed to represent the additional information, and it need not even be computable. We
only require that its result is polynomially bounded.
Theorem 38. Let p be an arbitrary polynomial. Consider a function g and an algorithm
A such that
1. g maps Strips frames to {0, 1} such that ||g(f )||  O(p(||f ||)) for all frames f and
167

fiBackstrom & Jonsson

2. for all Strips instances p = hf, d i, algorithm A answers yes for input hp, g(f )i if
and only if p has a plan.
If A runs in polynomial time, then the polynomial hierarchy collapses.
Proof. Assume there is a function g and an algorithm A with the properties described in
the theorem. Define a function r such that r(f ) = hf , g(f )i for every Strips frame f . Also
define a function R such that R(hf , xi, d ) = hhf , d i, xi for every Strips instance p = hf , d i
and every string x. Then R(r(f ), d ) = hhf , d i, g(f )i = hp, g(f )i, so hR, ri is a polynomial
reformulation of Strips planning into an equivalent problem that algorithm A can solve
in polynomial time. However, no such reformulation can exist according to Theorem 36,
unless the polynomial hierarchy collapses.
This result can be extended upwards in the polynomial hierarchy in the same way as Corollary 37 (no longer requiring A to be a polynomial algorithm). That means that we cannot
make planning simpler by adding a polynomial amount of additional information to a frame
and use a clever algorithm to use that information when planning. Planning will remain as
hard as it is without that extra information. While it may sometimes help to add information to a particular instance to somehow guide the planner, there is no systematic way to
add such information on the frame level if it is required to be of polynomial size.
The planning literature is rich with methods that are intended to make planning more
efficient by adding information in one way or another, although the methods are perhaps
not always thought of as doing so. A non-exhaustive list of such methods, and similar, is
abstraction hierarchies, macros, case-based planning, annotated planning and landmarks.
State space abstraction in planning goes back at least to the Abstrips planner (Sacerdoti, 1974). The main idea is to form abstraction hierarchies on the variables, and thus
implicitly on the actions, such that the planner can plan for the most important goals
first to get an abstract plan that can then be refined into a more detailed plan. Knoblock
(1994) proposed an algorithm for automatically computing such abstraction hierarchies.
While his algorithm was successful on many examples it was demonstrated to sometimes
fail and produce exponential plans for instances that have a linear optimal plan (Backstrom
& Jonsson, 1995). This is not surprising since the use of an abstraction hierarchy can be
viewed as adding information to the planning frame. Automatic generation of abstraction
hierarchies is a systematic way to add information and can thus be treated as a special case
of Theorem 38.
Adding a set of macros to a planning frame is very similar to using abstraction hierarchies, as Knoblock (1993, pp. 110111) noted. A planner that uses abstraction searches for
a plan in an abstract space and then tries to refine each action into a subplan on the lower
lever. A planner that uses macros does not search an abstract space but instead already has
a set of macros available that each correspond to a subplan. Finding a macro that works
and can be expanded is thus very similar to refining an abstract action. Also the use of
macros has been demonstrated to speed up planning considerably in certain cases (Korf,
1987). Macros are typically added on the frame level, and learning has been suggested
as one method to create macros automatically (Korf, 1985). However, macros are typically treated as any other action by the planner and are not expanded until after finding a
plan. Hence, the addition of macros may also backfire and make planning less efficient, just
168

fiAlgorithms and Limits for Compact Plan Representations

as adding redundant actions may do (Haslum & Jonsson, 2000). Once again, this is not
surprising since the addition of macros is addition of information and is thus also covered
by Theorem 38.
Case based planning (see Spalazzi, 2001, for a survey) uses stored plans or plan skeletons
that the planner tries to reuse by modifying and/or extending them. In one sense, this is
similar to macro planning, but with more advanced macros and macro expansion methods.
One can also view it as similar to abstraction, where a plan must be refined in order to
work. The difference is that the abstraction planner finds the plan skeleton by planning in
an abstract space while the case-based planner has a set of such plans stored in a database.
These plans may be handcoded, but are usually the result of learning from previous planning
situations. It is well known that also case-based planning may fail to improve efficiency and
that the cases used must be similar to the actual instance at hand (Nebel & Koehler, 1995;
Liberatore, 2005b). Also this can be explained as a special case of our Theorem 38.
The term annotated planning is sometimes used to refer to a number of similar techniques of adding control information to a planner. Examples are the Prodigy planner
(Veloso et al., 1995) which allows control information like rules for goal ordering and
Tlplan (Bacchus & Kabanza, 2000) which allows adding temporal-logic axioms to control
the planner. While such techniques can be good if using hand-tailored control rules/axioms
for a particular application domain, it is immediate from Theorem 38 that they cannot help
us in the general case.
Planning with landmarks (Hoffmann, Porteous, & Sebastia, 2004) is the idea of adding
explicit subgoals (called landmarks) to a planning instance. The intention is to tell the
planner that the landmarks must be achieved by the plan in order to achieve its overall
goal. Landmarks may also be ordered, to further guide the planner. However, as the
authors themselves point out, deciding if a variable value (or logic formula) is a necessary
subgoal is itself a PSPACE-complete problem. Hence, one usually considers incomplete
sets of landmarks. More interestingly, landmarks differ from the previous methods above in
a very important aspect; landmarks are added on the instance level, not on the frame level.
Although this might not be quite a rigid difference in practice, it seems to be fundamental
in essence. Hence, adding landmarks is a non-uniform case of adding information and it is
thus not immediately covered by Theorem 38. How to meaningfully analyse the non-uniform
case remains an open question.
7.2 Causal Graphs
Knoblock (1994) defined an ordering on the variables of a planning instance which he
used as a guidance for finding abstraction hierarchies. An ordering on the variables was
fundamental also for the 3S class (Jonsson & Backstrom, 1998b) and this ordering implicitly
defined an abstraction hierarchy. The concept of an ordering on the variables with the
intention of defining an abstraction hierarchy, define tractable subclasses etc. is nowadays
usually referred to as a causal graph (see Chen & Gimenez, 2010, for a survey of using
properties of the causal graph to define tractable subclasses of planning). Many papers still
use Knoblocks definition, which is as follows:
For every Strips action a let Vpre(a) = Atoms(pre(a)) and Vpost(a) = Atoms(post(a)). Let
169

fiBackstrom & Jonsson

f = hV, Ai be a Strips frame. The causal graph for f is the directed graph GCG = hV, i
where for all u, v  V , u  v if and only if both u 6= v and there is some a  A such that
u  Vpre(a)  Vpost(a) and v  Vpost(a) .
The idea behind causal graphs is that each strongly connected component of the graph
should correspond to an abstraction level. If applying this definition to examples in this
paper, we find that an instance according to Construction 16 has a causal graph containing
a large strongly connected component. That is, it would not be possible to form any good
abstraction hierarchies for it based on such causal graphs. However, Theorem 25 says that
plans for such instances seem not very likely to have useful compact representations anyway.
Plans for the binary counter in Construction 5 do have polynomial Crars since they have
polynomial macro plans. Yet, the whole causal graph for such an instance is also strongly
connected. On the other hand, plans for the Gray counter in Construction 6 are exponential
and have polynomial Crars too, but the causal graph is acyclic in this case. It thus seems
that the causal graph of the type used by Knoblock and many others is not a sufficient, or
even necessarily useful, tool for judging when plans have compact representations. There
are other variants of causal graphs, though. One example is interaction networks (Chen &
Gimenez, 2010). Another is Jonssons (2009) refined version of Knoblocks causal graph,
defined as follows:
Let f = hV, Ai be a Strips frame. The refined causal graph for f is the directed graph
GRCG = hV, i where for all u, v  V , u  v if and only if u 6= v and either
1) there is some a  A such that u  Vpre(a)  Vpost(a) and v  Vpost(a) or
2) there is some a  A such that u, v  Vpost(a) and either
a) there is some a0  A such that u  Vpost(a0 ) and v 6 Vpost(a0 ) or
b) there is no a0  A such that u 6 Vpost(a0 ) and v  Vpost(a0 ) .

The major difference between this variant and Knoblocks is that if two variables both
appear in the postcondition of the same action, then they do not necessarily form a cycle
in the graph. Hence, unary actions is no longer a prerequisite for acyclic graphs. If using
the refined causal graph, then both the Gray counter and the binary counter have acyclic
graphs, while Construction 16 still has a large strongly connected component. That is, in
these three examples acyclicity of the refined causal graph correlates with whether plans
have compact representations or not. While this correlation seems not to hold in general, the
difference between the two types of causal graphs suggests that further study of variations on
the concept could lead to further insight into the topic of compact representations. Should
this turn out to be fruitful, then it would likely carry over also to other areas where causal
graphs have been used, like model checking (Wehrle & Helmert, 2009).
7.3 Plan Explanation
The results in this paper are also important for plan explanation. Bidot et al. (2010)
suggest that it is important for planning systems (and other AI systems) to be able to
170

fiAlgorithms and Limits for Compact Plan Representations

explain their plans and decisions to the user, or else the user may not trust the system.
Similarly, Southwick (1991) writes:
There seems to be a general agreement amongst those involved in KBS research
that in order to be useful, a system must be able to explain its reasoning to a user.
Although we do not consider any advanced explanation methods, as they do, our results have
implications for what is possible to explain meaningfully. For plan explanation, our results
are not necessarily as bad as for planning. Consider for example a plan for an instance of
Construction 16. In the case where the 3SAT instance is unsatisfiable, almost the whole plan
consists of an alternating sequence of the form ha, b, a, b, a, b, . . .i, where a denotes either
of the actions aix 1 , . . . , aix n and b denotes either of the actions avf 1 , . . . , avf m . The first
group are actions that together implement an increment function, and thus all serve the
same purpose. Similarly, the second group consists of actions that all serve the purpose of
verifying that some clause is false. An abstraction of this action sequence could have the
form hinc, vfy, inc, vfy, inc, vfy, . . .i, where inc denotes any of the counting actions and vfy
any of the verification actions. For the purpose of explanation, it seems useful to replace the
actual actions with such abstract explanations of their functions. This abstract sequence is
easier to understand, and it also allows using macros to compress it, which might further
enhance its explaining power. However, in this particular case, it would probably be even
more useful to abstract the whole sequence into a for loop, or similar. This essentially
boils down to partitioning the set of actions into equivalence classes such that each such
class consist of actions that can be meaningfully seen as implementing the same concept.
It seems both interesting and important to investigate how and when one can partition the
set of actions into equivalence classes useful for such abstractions.
Plan explanation could also mean trace explanation in model checking, where we would
analogously make a long trace shorter and more abstract in order to make it easier to understand. It is well known that there are close ties between planning and model checking, and
that model-checking traces can be viewed as plans and vice versa (Edelkamp et al., 2007).
The number of steps (or clock cycles) can be exponential in the number of state variables;
even if the system is divided into subsystems, individual subsystems may have exponential behaviour which blows up when combined with other subsystems. An exponential-size
plan/trace is not of much use to an engineerit is an almost impossible task to analyse
and understand such a plan. If the planning/verifying system could autonomously find
repetitive patterns, and even recursive repetitive patterns, in the plan and abstract these,
then it would be considerably easier to understand what happens and why. In fact, it may
not be interesting to execute the plan, even in a simulator, so a compact understandable
explanation of the plan may be the actual goal.
Furthermore, Geib (2004) discusses the problem of combinatorial explosion in plan recognition, where an exponential number of plans may share the plan prefix recognized so far.
It could clearly be useful to have structured compact representations of plan candidates
both to save space and to allow for more intelligent operations on these plans. Although
this problem is slightly different from representing a single long plan, we have seen that
these two problems are related.
In all these cases, the primary purpose of a compact representation would thus be to find
and exploit some inherent structure in the plan, or set of plans, rather than to save space.
171

fiBackstrom & Jonsson

7.4 Additional Related Work
Liberatore (2005a) has also studied the problem of representing plans compactly and there
are similarities as well as differences between his results and ours. In contrast to us, he
considers also plans represented as sequences of states, not only sequences of actions. For
both cases, he considers a random access representation as well as a sequential representation. His random-access representation of action sequences (TA) is essentially the same
as our Crar concept, except that he specifies that it must be implemented by a circuit.
The sequential representation of action sequences (SA), on the other hand, is different from
our Csar concept. It is a function that takes a state as input and returns the next state.
Hence, it is more like a restricted type of reactive plan than a Csar, and his results are
thus not immediately comparable to ours. For instance, contrary to our Theorem 29 he
proves that a TA representation cannot be polynomially converted to an SA representation,
which clearly shows that SA and Csar are quite different concepts. His proof that not
all planning instances have plans with an SA representation does thus not obviously carry
over also to Csars. Furthermore, he uses a planning language where actions are modelled
as polynomial-size circuits. This coincides with our class FFP([P]). Hence, his hardness
proofs are weaker than ours since we use the restricted Strips language in those cases. It
should finally be noted that Liberatores Theorem 17 for the case of TA representations is a
result similar to our Theorem 25, but we use different methods and different conditions.
Nebel (2000) defines a concept of compilation between planning languages. Although in
some ways similar to our reformulation concept, there are also differences. A compilation is
a function from a planning frame to another frame in a different planning language. This
compilation need not be resource bounded but the resulting frame must be polynomially
bounded in the original frame. The initial state and goal must then be possible to translate
in polynomial time. That is, the first step corresponds to our function r while the second
step essentially corresponds to our function R. However, Nebel only considers compilation
between planning languages and also requires a concept of modularity that is not present
in our approach. Furthermore, his focus is not on the complexity of the decision problem
but on the question whether the size of solutions is preserved by compilations.
7.5 Conclusions and Open Questions
The current status of our knowledge about non-uniform compact representations can be
visualized as in Figure 6. The outer box represents the set of all solvable Strips instances
while the inner boxes represent the subsets where at least one plan for each instance has a
Csar, Crar or polynomial macro plan. We know classes where at least one plan for each
instance is guaranteed to have a polynomial macro plan, like Towers of Hanoi and 3S. We
also know classes where at least one plan for each instance has a Crar but we do not know
if those plans also have a polynomial macro plan. Construction 16 is such an example. It
is an open question if a plan can have a Crar but no polynomial macro plan. We further
know classes where each instance has a plan with a Csar but where we do not know if they
also have a Crar, for example, the class of reversible systems. However, Construction 26
is a class where all instances have a plan with a Csar but no plan with a Crar, so this
case provides a strict separation between the Csar and Crar concepts. Whether there are
classes of Strips instances where no plan has a Csar remains an open question, though.
172

fiAlgorithms and Limits for Compact Plan Representations

All plans
Plans w. Csar
Plans w. Crar

3S
Towers of
Hanoi

Plans w. poly.
macro plans
?

?

anything
here?

reversible
systems

?

Construction 16

Construction 26

Figure 6: Current status for Csars and Crars.

We thus have the following chain of inclusions
polynomial macro plans  Crar  Csar  Strips,
where we do not know if the first and last inclusions are strict.
Theorem 15 may seem weak since it is only conditioned with P 6= NP. Using similar
techniques as in the proofs of Lemma 27 and Corollary 37 we could encode QBF with
arbitrary number of alternating quantifiers and, hence, push the result up in the polynomial
hierarchy. However, it remains an open question if the condition could be strengthened all
the way to P 6= PSPACE.
While we have argued that a number of results hold also when restricted to unary
instances, and in some cases also other restrictions, this is otherwise a largely unexplored
area. Little is currently known about how various structural and other restrictions affect
the results in this paper. This applies both to whether plans have Csars and Crars and
to whether they have polynomial-size macro plans.
Just as we consider the non-uniform case of compact representations of single plans for
single instances, it might also be interesting to consider the non-uniform case of reformulation and of adding information. However, this seems not straightforward since we could
always reformulate an instance to a single bit telling whether the instance is solvable or not.
Such a reformulation is clearly not interesting so additional criteria are necessary.
We have previously (Backstrom & Jonsson, 2011a) defined a complexity measure based
on padding which is intended to be insensitive to plan length. This concept seems related
to Nebels compilations, although the two concepts are not identical or directly comparable.
It is thus reasonable to believe that also compact representations and padded complexity
are somehow related, especially since padded complexity was motivated by instances with
long plans. However, we do not yet know what this relationship is. Furthermore, it would
173

fiBackstrom & Jonsson

be interesting to consider compilations where we look at the size of compact representations
of plan rather than the size of explicit plans.
Acknowledgments
Malte Helmert, Anders Jonsson and the anonymous reviewers of this paper and the earlier
conference version have provided valuable comments and suggestions.

References
Bacchus, F., & Kabanza, F. (2000). Using temporal logics to express search control knowledge for planning. Artificial Intelligence, 116 (1-2), 123191.
Backstrom, C., & Jonsson, P. (2011a). All PSPACE-complete planning problems are equal
but some are more equal than others. In Proceedings of the 4th International Symposium on Combinatorial Search (SoCS11) Castell de Cardona, Barcelona, Spain, pp.
1017.
Backstrom, C., & Jonsson, P. (2011b). Limits for compact representations of plans. In Proceedings of the 21st International Conference on Automated Planning and Scheduling,
(ICAPS11), Freiburg, Germany, pp. 1825.
Backstrom, C. (1992). Computational Complexity of Reasoning about Plans. PhD dissertation, Linkoping University, Linkoping, Sweden.
Backstrom, C. (1995). Expressive equivalence of planning formalisms. Artificial Intelligence,
76 (1-2), 1734.
Backstrom, C., & Jonsson, P. (1995). Planning with abstraction hierarchies can be exponentially less efficient. In Proceedings of the 14th International Joint Conference on
Artificial Intelligence (IJCAI95), Montreal, QC, Canada, pp. 15991605.
Backstrom, C., & Klein, I. (1991). Planning in polynomial time: The SAS-PUBS class.
Computational Intelligence, 7, 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11, 625656.
Balcazar, J. (1996). The complexity of searching implicit graphs. Artificial Intelligence,
86 (1), 171188.
Bidot, J., Biundo, S., Heinroth, T., Minker, W., Nothdurft, F., & Schattenberg, B. (2010).
Verbal plan explanations for hybrid planning. In Proceedings of the 24th MKWI
related PuK-workshop: Planung/Scheduling und Konfigurieren/Entwurfen (PuK10),
pp. 23092320.
Bille, P., Landau, G., Raman, R., Sadakane, K., Satti, S., & Weimann, O. (2011). Random
access to grammar-compressed strings. In Proceedings of the 22nd ACM-SIAM Symposium on Discrete Algorithms (SODA11), San Fransisco, CA, USA, pp. 373389.
Bonet, B. (2010). Conformant plans and beyond: Principles and complexity. Artificial
Intelligence, 174 (3-4), 245269.
174

fiAlgorithms and Limits for Compact Plan Representations

Bonet, B., & Geffner, H. (2000). Planning with incomplete information as heuristic search
in belief space. In Proceedings of the 5th International Conference on Artificial Intelligence Planning Systems (AIPS00), Breckenridge, CO, USA, pp. 5261.
Boutilier, C., & Poole, D. (1996). Computing optimal policies for partially observable
decision processes using compact representations. In Proceedings of the 13th National
Conference on Artificial Intelligence (AAAI96), Portland, OR, USA, Vol. 2, pp. 1168
1175.
Brafman, R. I., & Domshlak, C. (2003). Structure and complexity in planning with unary
operators. Journal of Artificial Intelligence Research, 18, 315349.
Buhrman, H., Jiang, T., Li, M., & Vitanyi, P. M. B. (2000). New applications of the
incompressibility method: Part II. Theoretical Computer Science, 235 (1), 5970.
Bulatov, A., & Dalmau, V. (2006). A simple algorithm for Maltsev constraints. SIAM
Journal of Computing, 36 (1), 1627.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69 (1-2), 165204.
Cadoli, M., Donini, F., Liberatore, P., & Schaerf, M. (2000). Space efficiency of propositional
knowledge representation formalisms. Journal of Artificial Intelligence Research, 13,
131.
Charikar, M., Lehman, E., Liu, D., Panigrahy, R., Prabhakaran, M., Sahai, A., & Shelat, A.
(2005). The smallest grammar problem. IEEE Transactions on Information Theory,
51 (7), 25542576.
Chen, H., & Gimenez, O. (2010). Causal graphs and structurally restricted planning. Journal of Computer and System Sciences, 76 (7), 579592.
Edelkamp, S., Leue, S., & Visser, W. (2007). Summary of Dagstuhl seminar 06172 on
directed model checking. In Directed Model Checking, No. 06172 in Dagstuhl Seminar
Proceedings. Dagstuhl, Germany.
Galperin, H., & Wigderson, A. (1983). Succinct representations of graphs. Information and
Control, 56 (3), 183198.
Geib, C. (2004). Assessing the complexity of plan recognition. In Proceedings of the 19th
National Conference on Artificial Intelligence (AAAI04), San Jose, CA, USA, pp.
507512.
Gill, A. (1976). Applied Algebra for the Computer Sciences. Prentice Hall. Englewood
Cliffs, NJ.
Gimenez, O., & Jonsson, A. (2008). The complexity of planning problems with simple
causal graphs. Journal of Artificial Intelligence Research, 31, 319351.
Haslum, P., & Jonsson, P. (2000). Planning with reduced operator sets. In Proceedings of the
5th International Conference on Artificial Intelligence Planning Systems (AIPS00),
Breckenridge, CO, USA, pp. 150158.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks in planning. Journal
of Artificial Intelligence Research, 22, 215278.
175

fiBackstrom & Jonsson

Jansson, J., Sadakane, K., & Sung, W.-K. (2012). Compressed random access memory.
ArXiv, abs/1011.1708v2.
Johnson, D. S., Papadimitriou, C. H., & Yannakakis, M. (1988). On generating all maximal
independent sets. Information Processing Letters, 27 (3), 119123.
Jonsson, A. (2009). The role of macros in tractable planning. Journal of Artificial Intelligence Research, 36, 471511.
Jonsson, P., & Backstrom, C. (1998a). State-variable planning under structural restrictions:
Algorithms and complexity. Artificial Intelligence, 100 (1-2), 125176.
Jonsson, P., & Backstrom, C. (1998b). Tractable plan existence does not imply tractable
plan generation. Annals of Mathematics and Artificial Intelligence, 22 (3-4), 281296.
Jonsson, P., Haslum, P., & Backstrom, C. (2000). Towards efficient universal planning: A
randomized approach. Artificial Intelligence, 117 (1), 129.
Karp, R. M., & Lipton, R. J. (1980). Some connections between nonuniform and uniform complexity classes. In Proceedings of the 12th ACM Symposium on Theory of
Computing (STOC80), Los Angeles, CA, USA, pp. 302309.
Kautz, H. A., & Selman, B. (1992). Planning as satisfiability. In Proceedings of the 10th
European Conference on Artificial Intelligence (ECAI92), Vienna, Austria, pp. 359
363.
Knoblock, C. A. (1993). Generating Abstraction Hierarchies: An Automated Approach to
Reducing Search in Planning. Kluwer Academic Publishers. Norwell, MA.
Knoblock, C. A. (1994). Automatically generating abstractions for planning. Artificial
Intelligence, 68 (2), 243302.
Korf, R. E. (1985). Macro-operators: A weak method for learning. Artificial Intelligence,
26 (1), 3577.
Korf, R. E. (1987). Planning as search: A quantitative approach. Artificial Intelligence,
33 (1), 6588.
Liberatore, P., & Schaerf, M. (2010). On the size of data structures used in symbolic model
checking. ArXiv, abs/1012.3018.
Liberatore, P. (2005a). Complexity issues in finding succinct solutions of PSPACE-complete
problems. ArXiv, abs/cs/0503043.
Liberatore, P. (2005b). On the complexity of case-based planning. Journal of Experimental
and Theoretical Artificial Intelligence, 17 (3), 283295.
Long, D., Fox, M., & Hamdi, M. (2002). Reformulation in planning. In Proceedings of
the 5th International Symposium on Abstraction, Reformulation and Approximation
(SARA02), Kananaskis, AB, Canada, Vol. 2371 of Lecture Notes in Computer Science, pp. 1832. Springer.
Muscettola, N., Pandurang Nayak, P., Pell, B., & Williams, B. C. (1998). Remote agent:
To boldly go where no AI system has gone before. Artificial Intelligence, 103 (1-2),
547.
176

fiAlgorithms and Limits for Compact Plan Representations

Nebel, B. (2000). On the compilability and expressive power of propositional planning
formalisms. Journal of Artificial Intelligence Research, 12, 271315.
Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: A theoretical and
empirical analysis. Artificial Intelligence, 76 (1-2), 427454.
Rytter, W. (2003). Application of Lempel-Ziv factorization to the approximation of
grammar-based compression. Theoretical Computer Science, 302 (1-3), 211222.
Sacerdoti, E. D. (1974). Planning in a hierarchy of abstraction spaces. Artificial Intelligence,
5 (2), 115135.
Southwick, R. W. (1991). Explaining reasoning: An overview of explanation in knowledgebased systems. Knowledge Engineering Review, 6, 119.
Spalazzi, L. (2001). A survey on case-based planning. Artificial Intelligence Review, 16,
336.
Veloso, M. M., Carbonell, J. G., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planning and learning: The PRODIGY architecture. Journal of Experimental
and Theoretical Artificial Intelligence Research, 7 (1), 81120.
Wagner, K. (1986). The complexity of combinatorial problems with succinct input representation. Acta Informatica, 23 (3), 325356.
Wehrle, M., & Helmert, M. (2009). The causal graph revisited for directed model checking.
In Proceedings of the 16th International Symposium on Static Analysis (SAS09), Los
Angeles, CA, USA, Vol. 5673 of Lecture Notes in Computer Science, pp. 86101.
Springer.
Williams, B., & Pandurang Nayak, P. (1997). A reactive planner for a model-based executive. In Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI97), Nagoya, Japan, pp. 11781185.
Yap, C.-K. (1983). Some consequences of non-uniform conditions on uniform classes. Theoretical Computer Science, 26, 287300.

177

fiJournal of Artificial Intelligence Research 44 (2012) 275-333

Submitted 12/11; published 6/12

Algorithms for Generating Ordered Solutions for Explicit
AND/OR Structures
Priyankar Ghosh
Amit Sharma
P. P. Chakrabarti
Pallab Dasgupta

priyankar@cse.iitkgp.ernet.in
amit.ontop@gmail.com
ppchak@cse.iitkgp.ernet.in
pallab@cse.iitkgp.ernet.in

Department of Computer Science and Engineering
Indian Institute of Technology Kharagpur
Kharagpur-721302, India

Abstract
We present algorithms for generating alternative solutions for explicit acyclic AND/OR
structures in non-decreasing order of cost. The proposed algorithms use a best first search
technique and report the solutions using an implicit representation ordered by cost. In this
paper, we present two versions of the search algorithm  (a) an initial version of the best first
search algorithm, ASG, which may present one solution more than once while generating
the ordered solutions, and (b) another version, LASG, which avoids the construction of the
duplicate solutions. The actual solutions can be reconstructed quickly from the implicit
compact representation used. We have applied the methods on a few test domains, some of
them are synthetic while the others are based on well known problems including the search
space of the 5-peg Tower of Hanoi problem, the matrix-chain multiplication problem and
the problem of finding secondary structure of RNA. Experimental results show the efficacy
of the proposed algorithms over the existing approach. Our proposed algorithms have
potential use in various domains ranging from knowledge based frameworks to service
composition, where the AND/OR structure is widely used for representing problems.

1. Introduction
The use of AND/OR structures for modeling and solving complex problems efficiently
has attracted a significant amount of research effort over the last few decades. Initially,
AND/OR search spaces were mostly used in problem reduction search for solving complex
problems, logical reasoning and theorem proving, etc., where the overall problem can be
hierarchically decomposed into conjunction and disjunction of subproblems (Pearl, 1984;
Nilsson, 1980). Subsequently, AND/OR structures were also applied in a variety of domains, e.g., for representing assembly plans (Homem de Mello & Sanderson, 1990), generating VLSI floor-plans (Dasgupta, Sur-Kolay, & Bhattacharya, 1995), puzzle solving (Fuxi,
Ming, & Yanxiang, 2003), etc. Traditionally the algorithm AO* (Pearl, 1984; Nilsson, 1980;
Martelli & Montanari, 1978, 1973; Chang & Slagle, 1971) has been used for searching implicitly defined AND/OR structures. An empirical study of AO* can be found in Bonet
and Geffners (2005) work.
In the recent past there has been a renewed research interest towards the application
of AND/OR structures. In various planning problems, including conditional planning to
handle uncertainty, the AND/OR structure (Russell & Norvig, 2003) is a natural form

c
2012
AI Access Foundation. All rights reserved.

fiGhosh, Sharma, Chakrabarti, & Dasgupta

for representation. The problem of generating solutions for such representations has been
studied extensively (Hansen & Zilberstein, 2001; Jimenez & Torras, 2000; Chakrabarti,
1994). Dechter and Mateescu (2007) have presented the explicit AND/OR search space
perspective for graphical models. Different search strategies (best first, branch and bound,
etc.) over the AND/OR search spaces in graphical models are discussed by Marinescu and
Dechter (2007b, 2006). AND/OR search spaces are also used for solving mixed integer
linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu
& Dechter, 2007a), combinatorial optimization in graphical models (Marinescu & Dechter,
2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), which combine the
idea of Multi-Valued Decision Diagrams(MDD) and AND/OR structures, is presented by
Mateescu, Dechter, and Marinescu (2008) and further research along this direction can
be found in the work of Mateescu and Dechter (2008). AND/OR search spaces are also
applied for solution sampling and counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit
AND/OR DAG structure and have been used for various applications including compiling
knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc.
Apart from the domains of planning, constraint satisfaction, knowledge based reasoning,
etc., AND/OR structure based techniques are also widely used for various application based
domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu,
Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision
and graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang and Su (2005) have described
an AND/OR graph search algorithm for composing web services for user requirements. Ma
et al. (2008) have advocated the use of AND/OR trees to capture dependencies between the
inputs and outputs of the component web services and propose a top-down search algorithm
to generate solutions of the AND/OR tree. Further research that uses AND/OR structures
in the context of web service composition can be found in the works of Gu et al. (2010,
2008), Shin et al. (2010) and Yan et al. (2008). Chen et al. (2006) have applied explicit
AND/OR structures for cloth modeling and recognition which is an important problem in
vision and graphics tasks.
Such recent adoption of AND/OR search spaces for a wide variety of AI problems
warrants further research towards developing suitable algorithms for searching AND/OR
structures from different perspectives. In the general setting, the fundamental problem
remains to find the minimum cost solution of AND/OR structures. For a given explicit
AND/OR graph structure, the minimum cost solution is computed using either a topdown or a bottom-up approach. These approaches are based on the principle of dynamic
programming and have complexity which is linear with respect to the size of the search
space. Finding a minimum cost solution of an explicit AND/OR structure is a fundamental
step for the approaches that use an implicit representation and systematically explore the
search space. This is particularly the case for AO* (Nilsson, 1980) where the potential
solution graph (psg) is recomputed every time from the current explicit graph after a node
is expanded. In view of recent research where AND/OR structures are used and leveraged
in a wide variety of problems ranging from planning domain to web service composition,
the need for generating an ordered set of solutions of a given AND/OR structure becomes
imminent. We briefly mention some areas where ordered solutions are useful.

276

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Ordered set of solutions of an explicit AND/OR DAG can be used to develop useful
variants of the AO* algorithm. Currently in AO*, only the minimum cost solution is computed whereas several variants of the A* algorithm exist, where solutions are often sought
within a factor of cost of the optimal solution. These approaches (Ebendt & Drechsler, 2009;
Pearl, 1984) were developed to adapt the A* algorithm for using inadmissible heuristics,
leveraging multiple heuristics (Chakrabarti, Ghose, Pandey, & DeSarkar, 1989), generating
solutions quickly within bounded sub-optimality, etc. Typically these techniques order the
Open list using one evaluation function, and the next element for expansion is selected from
an ordered subset of Open using some other criterion. Similar techniques can be developed
for AO* search if ordered set of potential solutions are made available. That set can be
used for node selection and expansion instead of expanding nodes only from the current
best psg. This opens up an interesting area with significant research potential where the
existing variations of the A* algorithm can be extended for AND/OR search spaces.
In the context of model based programming, the problem of finding ordered set of
solutions has significant importance. Elliott (2007) has used valued sd-DNNFs to represent
the problem and proposed an approach to generate k-best solutions. Since valued sd-DNNFs
have an AND/OR structure, the proposed approach is possibly the earliest algorithm for
generating ordered set of solutions of an AND/OR structure. The problem of finding
ordered set of solutions for graphical models is studied by Flerova and Dechter (2011, 2010).
However these techniques use alternative representations for the algorithm, where AND/OR
search spaces can be constructed (Dechter & Mateescu, 2007) for graphical models. Recent
research involving AOMDD based representation on weighted structures suggested future
extensions towards generalizing Algebraic Decision Diagrams and introduces the notion of
cost in AOMDDs. We envisage that ordered set of solutions finds useful applications in the
context of research around AND/OR decision diagram based representation.
In the domain of service composition, the primary motivation behind providing a set of
alternative solutions ordered by cost is to offer more choices, while trading off the specified
cost criterion (to a limited extent) in favor of other unspecified criteria (primarily from
the standpoint of quality). Shiaa, Fladmark, and Thiell (2008) have presented an approach
for generating a ranked set of solutions for the service composition problem. Typically the
quality criteria are subjective in nature and difficult to express in terms of a single scalar cost
function which is able to combine the cost/price and the quality aspects together. These
aspects of quality are often encountered in the context of serving custom user requirements
where the user prefers to minimize the cost/price of the solution while preserving his/her
preferences. For example, for booking a holiday package for a specific destination, a travel
service portal typically offers a list of packages with various combinations of attractions,
hotel options and meal plans ordered by a single cost criterion, namely, the cost of the
package. In general any product/solution that is composed of a number of components has
a compositional flavor similar to service composition and it becomes important to present
the user a set of alternative solutions ordered by cost so that he/she can select the best
alternative according to his/her preferences.
Dynamic programming formulations typically have an underlying AND/OR DAG structure, which had been formally studied in the past (Martelli & Montanari, 1973). Besides
classical problems like matrix chain multiplication, many other real world optimization problems offer dynamic programming formulations, where alternative solutions ordered by cost
277

fiGhosh, Sharma, Chakrabarti, & Dasgupta

are useful in practice. One example of such a problem is finding the secondary structure of
RNA (Mathews & Zuker, 2004) which is an important problem in Bioinformatics. RNAs
may be viewed as sequences of bases belonging to the set {Adenine(A), Cytocine(C), Guanine(G), Uracil(U)}. RNA molecules tend to loop back and form base pairs with itself and
the resulting shape is called the secondary structure. The primary factor that influences the
secondary structure of RNA is the number of base pairings (higher number of base pairings generally implies more stable secondary structure). Under the well established rules
for base pairings, the problem of maximizing the number of base pairings has an interesting dynamic programming formulation. However, apart from the number of base pairings,
there are other factors that influence the stability, but these factors are typically evaluated
experimentally. Therefore, for a given RNA sequence, it is useful to compute a pool of
candidate secondary structures (in decreasing order of the number of base pairings) that
may be subjected to further experimental evaluation in order to determine the most stable
secondary structure.
The problem of generating ordered set of solutions is well studied in other domains.
For discrete optimization problems, Lawler (1972) had proposed a general procedure for
generating k-best solutions. A similar problem of finding k most probable configurations in
probabilistic expert systems is addressed by Nilsson (1998). Fromer and Globerson (2009)
have addressed the problem of finding k maximum probability assignments for probabilistic modeling using LP relaxation. In the context of ordinary graphs, Eppstein (1990) has
studied the problem of finding k-smallest spanning trees. Subsequently, an algorithm for
finding k-best shortest paths has been proposed in Eppsteins (1998) work. Hamacher and
Queyranne (1985) have suggested an algorithm for k-best solutions to combinatorial optimization problems. Algorithms for generating k-best perfect matching are presented by
Chegireddy and Hamacher (1987). Other researchers applied the k-shortest path problem
to practical scenarios, such as, routing and transportation, and developed specific solutions
(Takkala, Borndorfer, & Lobel, 2000; Subramanian, 1997; Topkis, 1988; Sugimoto & Katoh,
1985). However none of the approaches seems to be directly applicable for AND/OR structures. Recently some schemes related to ordered solutions to graphical models (Flerova &
Dechter, 2011, 2010) and anytime AND/OR graph search (Otten & Dechter, 2011) have
been proposed. Anytime algorithms for traditional OR search space (Hansen & Zhou, 2007)
are well addressed by the research community.
In this paper, we address the problem of generating ordered set of solutions for explicit
AND/OR DAG structure and present new algorithms. The existing method, proposed
by Elliott (2007), works bottom-up by computing k-best solutions for the current node
from the k-best solutions of its children nodes. We present a best first search algorithm,
named Alternative Solution Generation (ASG) for generating ordered set of solutions. The
proposed algorithm maintains a list of candidate solutions, initially containing only the
optimal solution, and iteratively generates the next solution in non-decreasing order of cost
by selecting the minimum cost solution from the list. In each iteration, this minimum cost
solution is used to construct another set of candidate solutions, which is again added to the
current list. We present two versions of the algorithm 
a. Basic ASG (will be referred to as ASG henceforth) : This version of the algorithm
may construct a particular candidate solution more than once;

278

fiGenerating Ordered Solutions for Explicit AND/OR Structures

b. Lazy ASG or LASG : Another version of ASG algorithm that constructs every candidate solution only once.
In these algorithms, we use a compact representation, named signature, for storing the
solutions. From the signature of a solution, the actual explicit form of that solution can
be constructed through a top-down traversal of the given DAG. This representation allows
the proposed algorithms to work in a top-down fashion starting from the initial optimal
solution. Another salient feature of our proposed algorithms is that these algorithms work
incrementally unlike the existing approach. Our proposed algorithms can be interrupted at
any point of time during the execution and the set of ordered solutions obtained so far can
be observed and subsequent solutions will be generated when the algorithms are resumed
again. Moreover, if an upper limit estimate on the number of solutions required is known a
priori, our algorithms can be further optimized using that estimate.
The rest of the paper is organised as follows. The necessary formalisms and definitions
are presented in Section 2. In Section 3, we address the problem of generating ordered set of
solutions for trees. Subsequently in Section 4, we address the problem of finding alternative
solutions of explicit acyclic AND/OR DAGs in non-decreasing order of cost. We present two
different solution semantics for AND/OR DAGs and discuss the existing approach as well as
our proposed approach, along with a comparative analysis. Detailed experimental results,
including the comparison of the performance of the proposed algorithms with the existing
algorithm (Elliott, 2007), are presented in Section 5. We have used randomly constructed
trees and DAGs as well as some well-known problem domains including the 5-peg Tower
of Hanoi problem, the matrix-chain multiplication problem and the problem of finding
the secondary structure of RNA as test domain. The time required and the memory used
for generating a specific number of ordered solutions for different domains are reported in
detail. In Section 6, we outline briefly about applying the proposed algorithms for implicitly
specified AND/OR structures. Finally we present the concluding remarks in Section 7.

2. Definitions
In this section, we describe the terminology of AND/OR trees and DAGs followed by other
definitions that are used in this paper. G = hV, Ei is an AND/OR directed acyclic graph,
where V is the set of nodes and E is the set of edges. Here  and  in G refer to the
AND nodes and OR nodes in the DAG respectively. The direction of edges in G is from
the parent node to the child node. The nodes of G with no successors are called terminal
nodes. The non-terminal nodes of G are of two types  i) OR nodes and ii) AND nodes .
V and V are the set of AND and OR nodes in G respectively, and n = |V |, n = |V |,
and n = |V |. The start (or root) node of G is denoted by vR . OR edges and AND edges
are the edges that emanate from OR nodes and AND nodes respectively.
Definition 2.a [Solution Graph] A solution graph, S(vq ), rooted at any node vq  V , is a
finite sub-graph of G defined as:
a. vq is in S(vq );
b. If vq is an OR node in G and vq is in S(vq ), then exactly one of its immediate
successors in G is in S(vq );
c. If vq is an AND node in G and vq is in S(vq ), then all its immediate successors in
G are in S(vq );
279

fiGhosh, Sharma, Chakrabarti, & Dasgupta

d. Every maximal (directed) path in S(vq ) ends in a terminal node;
e. No node other than vq or its successors in G is in S(vq ).
By a solution graph S of G we mean a solution graph with root vR .




Definition 2.b [Cost of a Solution Graph] In G , every edge eqr  E from node vq to
node vr has a finite non-negative cost ce (hvq , vr i) or ce (eqr ). Similarly every node vq has a
finite non-negative cost denoted by cv (vq ). The cost of a solution S is defined recursively
as follows. For every node vq in S, the cost C(S, vq ) is:


cv (vq ), if vq is a terminal node;



	


cv (vq ) + C(S, vr ) + ce (hvq , vr i) , where vq is an OR node, and

C(S, vq ) =
vr is the successor of vq in S;

	
P


C(S, vj ) + ce (hvq , vj i) , where 1  j  k, vq is an AND node
cv (vq ) +




with degree k, and v1 , . . . , vk are the immediate successors of vq in S.
Therefore the cost of a solution S is C(S, vR ) which is also denoted by C(S). We denote
the optimal solution below every node vq as opt(vq ). Therefore, the optimal solution of the
entire AND/OR DAG G , denoted by Sopt , is opt(vR ). The cost of the optimal solution
rooted at every node vq in G is Copt (vq ), which is defined recursively (for minimum cost
objective functions) as follows:


cv (vq ), if vq is a terminal node;



	



cv (vq ) + min Copt (vj ) + ce (hvq , vj i) , where 1  j  k, vq is an OR node
Copt (vq ) =
with degree k, and v1 , . . . , vk are the immediate successors of vq in G ;


	

cv (vq ) + P Copt (vj ) + ce (hvq , vj i) , where 1  j  k, vq is an AND node




with degree k, and v1 , . . . , vk are the immediate successors of vq in G .
The cost of the optimal solution Sopt of G is denoted by Copt (vR ) or, alternatively, by
Copt (Sopt ). When the objective function needs to be maximized, instead of the min function,
the max function is used in the definition of Copt (vq ).



It may be noted that it is possible to have more than one solution below an OR node
vq to qualify to be the optimal one, i.e., when they have the same cost, and that cost is the
minimum. Ties for the optimal solution below any such OR node vq are resolved arbitrarily
and only one among the qualifying solutions (determined after tie-breaking) is marked as
opt(vq ).
An AND/OR tree, T = hV, Ei, is an AND/OR DAG and additionally satisfies the
restrictions of a tree structure i.e., there can be at most one parent node for any node vq
in T . In the context of AND/OR trees, we use eq to denote the edge that points to
the vertex vq . An alternating AND/OR tree, T = hV, Ei, is an AND/OR tree with the
restriction that there is an alternation between the AND nodes and the OR nodes. Every
child of an AND node is either an OR node or a terminal node, and every children of an OR
node is either an AND node or a terminal node. We use the term solution tree to denote
the solutions of AND/OR trees.
We also discuss a different solution semantics, namely tree based semantics, for AND/OR
DAGs. Every AND/OR DAG can be converted to an equivalent AND/OR tree by traversing
280

fiGenerating Ordered Solutions for Explicit AND/OR Structures

the intermediate nodes in reverse topological order and replicating the subtree rooted at
every node whenever the in-degree of the traversed node is more than 1. The details are
shown in Procedure ConvertDAG. Suppose an AND/OR DAG G is converted to an
equivalent AND/OR tree T . We define the solutions of T as the solutions of G under
tree based semantics.
Procedure ConvertDAG(G )
input : An AND/OR DAG G
output: An equivalent AND/OR tree T
1 Construct a list M , of non-terminal nodes of G , sorted in the reverse topological
order;
2 while M is not empty do
3
vq  Remove the first element of M ;
/* Suppose Ein (vq ) is the list of incoming edges of vq
*/
4
if InDegree(vq ) > 1 then
5
for i  2 to InDegree(vq ) do
6
et  Ein (vq )[i];
Replicate
the sub-tree rooted at vq with vq as the root;
7
Modify the target node of et from vq to vq ;
8
9
end
10
end
11 end
In this paper we use the solution semantics defined in Definition 2.a as the default
semantics for the solutions of AND/OR DAGs. When the tree based semantics is used, it
is explicitly mentioned.
2.1 Example

2, 34

h3i
3, 29

v1

v1

v2

h1i

h1i

h2i

v3

2, 37

v2

v4

2, 8

h1i

v5

h3i

h4i

v6

3, 11

v7
h1i

h1i

h2i

h2i

v9

v10

v11

v12

v13

v14

v15

v9

v10

5

7

6

9

12

15

20

5

7

Figure 1: Alternating AND/OR Tree
281

v6

2, 35

v8

3, 9

h1i

h1i

h1i

h3i

h4i

v7
h3i

2, 41

h4i

v5

40

12
h2i

v3

3, 43

v4

v8

4, 17

h2i

h5i

h1i

35
h5i

2, 89

17

h2i

Figure 2: AND/OR DAG

52

fiGhosh, Sharma, Chakrabarti, & Dasgupta

We present an example of an alternating AND/OR tree in Figure 1. In the figure, the
terminal nodes are represented by a circle with thick outline. AND nodes are shown in the
figures with their outgoing edges connected by a semi-circular curve in all the examples.
The edge costs are shown by the side of each edge within an angled bracket. The cost of the
terminal nodes are shown inside a box. For every non-terminal node vq , the pair of costs,
cv (vq ) and Copt (vq ), is shown inside a rectangle.
In Figure 1 the optimal solution below every node is shown using by thick dashed edges
with an arrow head. The optimal solution of the AND/OR tree can be traced by following
these thick dashed edges from node v1 . The cost of the optimal solution tree is 34. Also,
Figure 2 shows an example of a DAG; the cost of the optimal solution DAG is 89.

3. Generating Ordered Solutions for AND/OR Trees
In this section we address the problem of generating ordered solutions for trees. We use
the notion of alternating AND/OR trees, defined in Section 2, to present our algorithms.
An alternating AND/OR tree presents a succinct representation and so the correctness
proofs are much simpler for alternating AND/OR trees. In Appendix C we show that every
AND/OR tree can be converted to an equivalent alternating AND/OR tree with respect to
the solution space.
It is worth noting that the search space of some problems (e.g. the search space of multipeg Tower of Hanoi problem) exhibit the alternating AND/OR tree structure. Moreover, the
algorithms that are presented for alternating AND/OR trees work without any modification
for general AND/OR trees. In this section, first we present the existing algorithm (Elliott,
2007) briefly, and then we present our proposed algorithms in detail.
3.1 Existing Bottom-Up Evaluation Based Method for Computing Alternative
Solutions
We illustrate the working of the existing method that is proposed by Elliott (2007) for
computing alternative solutions for trees using an example of an alternating AND/OR tree.
This method (will be referred as BU henceforth) computes the k-best solutions in a bottomup fashion. At every node, vq , k-best solutions are computed from the k-best solutions of
the children of vq . The overall idea is as follows.
a. For an OR node vq , a solution rooted at vq is obtained by selecting a solution of a
child. Therefore k-best solutions of vq are computed by selecting the top k solutions
from the entire pool consisting of all solutions of all children.
b. In the case of AND nodes, every child of an AND node vq will have at most k solutions.
A solution rooted at an AND node vq is obtained by combining one solution from every
child of vq . Different combinations of the solutions of the children nodes of vq generate
different solutions rooted at vq . Among those combinations, top k combinations are
stored for vq .
In Figure 3 we show the working of the existing algorithm. At every intermediate node
2-best solutions are shown within rounded rectangle. At every OR node vq , the ith -best
cost. For
solution rooted at vq is shown as a triplet of the form  |{z}
i : < child, solidx >, |{z}
{z
}
|
example, at node v1 the second best solution is shown as  2 : hv2 , 2i, 37; which means
282

fiGenerating Ordered Solutions for Explicit AND/OR Structures

that the 2nd best solution rooted at v1 is obtained by selecting the 2nd best solution of v2 .
Similarly, at every AND node vq , the ith solution rooted at vq is shown as a triplet of the
form  i : |sol vec|, cost triplets. Here sol vec is a comma separated list of solution indices
such that every element of sol vec corresponds to a child of vq . The j th element of sol vec
shows the index of the solution of j th child. For example, the 2nd best solution rooted at v2
is shown as  2 : |2, 1|, 32. This means the 2nd best solution rooted at v2 is computed using
the 2nd best solution of the 1st child (which is v5 ) and the best solution (1st ) of the 2nd
child (which is v6 ). Which index of sol vec corresponds to which child is shown by placing
the child node name above every index position.

2, 34

h3i

3, 29

v2

h5i

2, 8

v5

1 : hv2 , 1i, 34
2 : hv2 , 2i, 37

v1

h1i

h2i

v5 v6
1 : |1, 1|, 29
2 : |2, 1|, 32

v3

2, 37

35

h1i

1 : hv9 , 1i, 8
2 : hv10 , 1i, 11

v7 v8
1 : |1, 1|, 37
1 : |1, 2|, 40

v4

h3i

h4i

v6

3, 11

v7

1 : hv11 , 1i, 11
2 : hv12 , 1i, 15

12

h3i

h2i

v8

4, 17

h1i

h1i

1 : hv13 , 1i, 17
2 : hv14 , 1i, 20
h2i

h1i

h2i

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 3: Example working of the existing algorithm
The existing method works with the input parameter k, i.e., the number of solutions to
be generated have to be known a priori. Also this method is not inherently incremental in
nature, thus does not perform efficiently when the solutions are needed on demand, e.g., at
first, top 20 solutions are needed, then the next 10 solutions are needed. In this case the
top 20 solutions will have to be recomputed while computing next 10 solutions, i.e., from
the 21st solution to the 30th solution. Next we present our proposed top-down approach
which does not suffer from this limitation.
3.2 Top-Down Evaluation Algorithms for Generating Ordered Solutions
So far we have discussed the existing approaches which primarily use bottom-up approach
for computing ordered solutions. Now we propose a top-down approach for generating alternative solutions in the non-decreasing order of cost. It may be noted that the top-down
283

fiGhosh, Sharma, Chakrabarti, & Dasgupta

approach is incremental in nature. We use an edge marking based algorithm, Alternative
Solution Generation (ASG), to generate the next best solutions from the previously generated solutions. In the initial phase of the ASG algorithm, we compute the optimal solution
for a given alternating AND/OR tree T and perform an initial marking of all OR edges.
The following terminology and notions are used to describe the ASG algorithm. In the
context of AND/OR trees, we use eq to denote the edge that points to the vertex vq . We
will use the following definitions for describing our proposed top-down approaches.
Definition 3.c [Aggregated Cost] In an AND/OR DAG G , the aggregated cost, ca , for
an edge eij from node vi to node vj , is defined as : ca (eij ) = ce (eij ) + Copt (vj ).


v1

2, 34

[e2 : 5]

2,3 : 5

h3i

3, 29

3,4 : 1

v2

h1i

h2i

[e3 : 1]

v3

2, 37

v4

35
h5i

2, 8

h1i

v5

h4i

v6

3, 11

h3i

v7

v8

4, 17

12
[e11 : 4]

[e9 : 3]
h1i

9,10 : 3

h2i

h2i

[e13 : 3]
h3i

11,12 : 4

h1i

[e14 : 6] h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 4: Example of OR-edge marking and swap option
Marking of an OR edge : The notion of marking an OR edge is as follows. For an OR
node vq , L(vq ) is the list of OR edges of vq sorted in non-decreasing order of the aggregated
cost of the edges. We define (i,i+1) as the difference between the cost of OR edges, ei and
ei+1 , such that ei and ei+1 emanate from the same OR node vq , and ei+1 is the edge next to
ei in L(vq ). Procedure MarkOR describes the marking process for the OR edges of an OR
node. Intuitively, a mark represents the cost increment incurred when the corresponding
edge is replaced in a solution by its next best sibling. The OR edge having maximum
aggregated cost is not marked.
Consider a solution, Scur , containing the edge ei = (vq , vi ), where ei  Eopt (Scur ). We
mark ei with the cost increment which will be incurred to construct the next best solution
from Scur by choosing another child of vq . In Figure 4 the marks corresponding to OR edges
e2 , e3 , e9 , e11 , e13 , and e14 are [e2 : 5], [e3 : 1], [e9 : 3], [e11 : 4], [e13 : 3], and [e14 : 6].
284

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Procedure MarkOR(vq )
1

2
3
4
5
6
7
8

Construct L(vq ) ; /* List of OR edges of vq sorted in the non-decreasing order of ca
values */
count  number of elements in L(vq ) ;
for i  1 to i = count  1 do
ec  L(vq )[i] ;
en  L(vq )[i + 1] ;
tmp = (ca (en )  ca (ec )) ;
Mark ec with the pair [en : tmp ] ;
end

Definition 3.d [Swap Option] A swap option ij is defined as a three-tuple hei , ej , ij i
where ei and ej emanate from the same OR node vq , ej is the edge next to ei in L(vq ), and
ij = ca (ej )  ca (ei ). Also, we say that the swap option ij belongs to the OR node vq . 


Consider the OR node vq and the sorted list L(vq ). It may be observed that in L(vq )
every consecutive pair of edges forms a swap option. Therefore, if there are k edges in L(vq ),
k1 swap options will be formed. At node vq , these swap options are ranked according to the
rank of their original edges in L(vq ). In Figure 4 the swap options are : (2,3) = he2 , e3 , 5i,
(3,4) = he3 , e4 , 1i, (9,10) = he9 , e10 , 3i, (11,12) = he11 , e12 , 4i, (13,14) = he13 , e14 , 3i, and
(14,15) = he14 , e15 , 6i. Consider the node v1 where L(v1 ) = he2 , e3 , e4 i. Therefore, the swap
options, (2,3) and (3,4) , belong to v1 . At node v1 , the rank of (2,3) and (3,4) are 1 and 2
respectively.
Definition 3.e [Swap Operation] Swap operation is defined as the application of a swap
option ij = hei , ej , ij i to a solution Sm that contains the OR edge ei in the following way:
 . Edge e is
a. Remove the subtree rooted at vi from Sm . Let the modified tree be Sm
i
the original edge of ij .
 , which is constructed at the previous step. Let the
b. Add the subtree opt(vj ) to Sm
 . Edge e is the swapped edge of  .
newly constructed solution be Sm
j
ij
 from S when
Intuitively, a swap operation ij = hei , ej , ij i constructs a new solution Sm
m

Sm contains the OR edge ei . Moreover, the cost of Sm is increased by ij compared to cost
of Sm if C(Sm , vi ) = Copt (vi ).



Our proposed algorithms use a swap option based compact representation, named signature, for storing the solutions. Intuitively, any alternative solution can be described as a
set of swap operations performed on the optimal solution Sopt . It is interesting to observe
that while applying an ordered sequence of swap options, h1 ,    , k i, the application of
each swap operation creates an intermediate alternative solution. For example, when the
first swap option in the sequence, 1 , is applied to the optimal solution, Sopt , a new solution, say S1 , is constructed. Then, when the 2nd swap option, 2 , is applied to S1 , yet
another solution S2 is constructed. Let Si denote the solution obtained by applying the
swap options, 1 ,    , i , on Sopt in this sequence. Although, an ordered sequence of swap
options, like h1 ,    , k i, can itself be used as a compact representation of an alternative
solution, the following key points are important to observe.
A. Among all possible sequences that generate a particular solution, we need to preclude
those sequences which contain redundant swap options (those swap options whose orig285

fiGhosh, Sharma, Chakrabarti, & Dasgupta

inal edge is not present in the solution to which it is applied). This is formally defined
later as superfluous swap options. Also the order of applying the swap options is another important aspect. There can be two swap options, i and j where 1  i < j  k
such that the source edge of j belongs to the sub-tree which is included in the solution
Si only after applying i to Si1 . In this case, if we apply j at the place of i , i.e.,
apply j directly to Si1 , it will have no effect as the source edge of j is not present
in Si1 , i.e., after swapping the location of i and j in the sequence, j becomes a
redundant swap option and the solution constructed would be different for the swapped
sequence from the original sequence. We formally define an order relation on a pair of
swap options based on this observation in the later part of this section and formalize
the compact representation of the solutions based on that order relation.
B. Suppose the swap option j belongs to a node vpj . Now it is important to observe
that the application of j on Sj1 to construct Sj , invalidates the application of all
other swap options that belong to an OR edge in the path from the root node to vpj in
the solution Sj . This is because in Sj the application of any such swap option which
belongs to an OR edge in the path from the root node to vpj would make the swap at
vpj redundant. In fact, for each swap option i belonging to node vpi , where 1  i  j,
the application of all other swap options that belong to an OR edge in the path from
the root node to vpi is invalidated in the solution Sj for the same reason. This condition
restricts the set of swap options that can be applied on a particular solution.
C. Finally, there can be two swap options i and j for 1  i < j  k such that i and
j are independent of each other, that is, (a) applying i to Si1 and subsequently the
application of j to Sj1 , and (b) applying j to Si1 and subsequently the application
of i to Sj1 , ultimately construct the same solution. This happens only when the
original edges of both i and j are present in Si1 , thus application of one swap option
does not influence the application of the other. However, it is desirable to use only one
way to generate solution Sj . In Section 3.3, we propose a variation of the top-down
approach (called LASG) which resolves this issue.
Definition 3.f [Order Relation R] We define an order relation, namely R, between a pair
of swap options as follows.
a. If there is a path from vi to vr in T , where ei and er are OR edges, qi and rj are
swap options, then (qi , rj )  R. For example, in Figure 4 ((3,4) , (13,14) )  R.
b. If pq = hep , eq , pq i and rt = her , et , rt i are two swap options such that vq = vr ,
then (pq , rt )  R. In Figure 4 ((2,3) , (3,4) )  R.


Implicit Representation of the Solutions : We use an implicit representation for
storing every solution other than the optimal one. These other solutions can be constructed
from the optimal solution by applying a set of swap options to the optimal solution in the
following way. If (i , j )  R, i has to be applied before j . Therefore, every solution is
represented as a sequence  of swap options, where i appears before j in  if (i , j )  R.
Intuitively the application of every swap option specifies that the swapped edge will be the
part of the solution. Since the swap options are applied in the specific order R, it may so
happen that an OR edge which had become the part of solution due to the application of an
earlier swap option and may get swapped out due to the application of a later swap option.
286

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Definition 3.g [Superfluous Swap Option] Consider a sequence of swap options  =
h1 ,    , m i corresponding to a solution Sm . Clearly it is possible for a swap option, i ,
where 1  i  m, to be present in the sequence such that the original edge of i is not
present in the solution Si1 which is constructed by the successive applications of swap
options 1 ,    , i1 to solution Sopt . Now the application of i has no effect on Si1 , i.e.,
solution Si is identical to solution Si1 . Each such swap option i is a superfluous swap
option with respect to the sequence  of swap options corresponding to solution Sm .


Property 3.1 The sequence of swap options corresponding to a solution is minimal, if it
has no superfluous swap option.
This property follows from the definition of superfluous swap options and the notion of the
implicit representation of a solution.
Definition 3.h [Signature of a Solution] The minimal sequence of swap options corresponding to a solution, Sm , is defined as the signature, Sig(Sm ), of that solution. It
may be noted that for the optimal solution Sopt of any alternating AND/OR tree T ,
Sig(Sopt ) = {}, i.e., an empty sequence. It is possible to construct more than one signature
for a solution, as R is a partial order. It is important to observe that all different signatures
for a particular solution are of equal length and the sets of swap options corresponding to
these different signatures are also equal. Therefore the set of swap options corresponding
to a signature is a canonical representation of the signature. Henceforth we will use the set
notation for describing the signature of a solution.
v1

2, 39

2,3 : 5

h3i

3, 29

3,4 : 1
h2i

v3

v2

h1i

2, 37

v4

35
h5i

2, 8

h1i

v5

h3i

h4i

v6

3, 11

v7

v8

4, 17

12
h2i

h2i
h1i 
9,10 : 3

h3i

11,12 : 4

h1i

h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 5: A solution, S2 , of the AND/OR tree shown in Figure 4
In Figure 5 we show a solution, say S2 , of the AND/OR tree shown in Figure 4. The
solution is highlighted using thick dashed lines with arrow head. The pair, cv (vq ), C(S2 , vq ),
287

fiGhosh, Sharma, Chakrabarti, & Dasgupta

is shown within rectangles beside each node vq in solution S2 , and we have used the rectangles with rounded corner whenever C(S2 , vq ) 6= Copt (vq ). Since S2 is generated by applying
the swap option (2,3) to solution Sopt , the signature of S2 , Sig(S2 ) = h(2,3) i. Consider
another sequence, 2 = h(2,3) , (9,10) i, of swap options. It is worth noting that 2 also
represents the solution S2 . Here the second swap option in 2 , namely 9,10 , can not be
applied to the solution constructed by applying (2,3) to Sopt as the source edge of (9,10) ,
e9 , is not present in that solution. Hence (9,10) is a superfluous swap option for 2 .
Definition 3.i [Vopt and Eopt ] For any solution graph Sm of an AND/OR DAG G , we
define a set of nodes,
 fiVopt (Sm ), and a set of OR edges, Eopt (Sm ), as:
a. Vopt (Sm	) = vq fi vq in Sm and solution graph Sm (vq ) is identical to the solution graph
opt(vq )
fi

	
b. Eopt (Sm ) = epr fi OR edge epr in Sm , and vr  Vopt (Sm )
Clearly, for any node vq  Vopt (Sm ), if vq is present in Sopt , then  (a) the solution graph
Sm (vq ) is identical to the solution graph Sopt (vq ), and (b) C(Sm , vq ) = Copt (vq )


Definition 3.j [Swap List] The swap list corresponding to a solution Sm , L(Sm ), is the list
of swap options that are applicable to Sm . Let Sig(Sm ) = {1 ,    , m } and i, 1  i  m,
each swap option i belongs to node vpi . The application of all other swap options that
belong to the OR edges in the path from the root node to vpi is invalidated in the solution
Sm . Hence, only the remaining swap options that are not invalidated in Sm can be applied
to Sm for constructing the successor solutions of Sm .
It is important to observe that for a swap option i , if the source edge of i belongs
to Eopt (Sm ), the application is not invalidated in Sm . Hence, for a solution Sm , we construct L(Sm ) by restricting the swap operations only on the edges belonging to Eopt (Sm ).
Moreover, this condition also ensures that the cost of a newly constructed solution can be
computed directly form the cost of the parent solution and the  value of the applied swap
 is constructed form S
option. To elaborate, suppose solution Sm
m by applying jk . The

 ) = C(S ) + 
cost of Sm can be computed directly form C(Sm ) and jk as : C(Sm
m
jk if
ej  Eopt (Sm ). Procedure ComputeSwapList(Sm ) describes the details of computing swap
options for a given solution Sm .


Procedure ComputeSwapList(Sm)
1
2
3

4
5
6

L(Sm )  ; Compute Eopt (Sm );
foreach OR edge ec in Eopt (Sm ) do
if there exists a swap option on edge ec then
/* Suppose ec emanates from OR node vq such that ec = L(vq )[i]. Also ec is
marked with the pair htmp , en i, where en = L(vq )[i + 1]
*/
cn  hec , en , tmp i; Add cn to L(Sm );
end
end

The swap list of the optimal solution, L(Sopt ), in Figure 4, is {(2,3) , (9,10) }. In the
solution S1 , shown in Figure 6, Vopt = {v6 , v10 }, because except node v6 and v10 , for all
other nodes vi in S1 , opt(vi ) 6= S1 (vi ). Here also rectangles with rounded corner are used
when C(S1 , vq ) 6= Copt (vq ). Therefore, Eopt = {e6 , e10 }. Since there exists no swap option
288

fiGenerating Ordered Solutions for Explicit AND/OR Structures

v1

2, 37

2,3 : 5

h3i

3, 32

3,4 : 1
h2i

v2

v3

h1i

2, 37

v4

35
h5i

2, 11

h1i

v5

h4i

v6

3, 11

h3i

v7

v8

4, 17

12
h2i
h1i 
9,10 : 3

h2i

h3i

11,12 : 4

h1i

h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 6: A solution, S1 , of the AND/OR tree shown in Figure 4
on the OR edges, e6 and e10 , the swap list of solution S1 , L(S1 ) = . Hence, for a solution
Sm , L(Sm ) may be empty, though Vopt (Sm ) can never be empty.
Although we use the notation ij to denote a swap option with edge ei as the original
edge and edge ej as the swapped edge, for succinct representation, we also use  with a single
subscript, such as 3 , k , ij etc., to represent a swap option. This alternative representation
of swap options does not relate to any edge.
Definition 3.k [Successors and Predecessors of a Solution] The set of successors and
predecessors of a solution
fi Sm is defined as:
 fi S  can be constructed from S
a. Succ(Sm ) = {Sm
m by applying a swap option that
m
belongs to the swap
fi list of Sm }
 fi S  Succ(S  )}


b. P red(Sm ) = {Sm
m
m

Property 3.2 For any solution Sm of an alternating AND/OR tree T the following state  P red(S ), C(S  )  C(S )
ment holds: Sm
m
m
m

The property follows from the definitions. One special case requires attention. Consider
 ) = C(S ) and S   P red(S ). This case can only arise when a swap
the case when C(Sm
m
m
m
option of cost 0 is applied to Sm . This occurs in the case of a tie.
3.2.1 ASG Algorithm
We present ASG, a best first search algorithm, for generating solutions for an alternating
AND/OR tree in non-decreasing order of costs. The overall idea of this algorithm is as
follows. We maintain a list, Open, which initially contains only the optimal solution Sopt .
At any point of time Open contains a set of candidate solutions from which the next best
289

fiGhosh, Sharma, Chakrabarti, & Dasgupta

solution in the non-decreasing order of cost is selected. At each iteration the minimum cost
solution (Smin ) in Open is removed from Open and added to another list, named, Closed.
The Closed list contains the set of ordered solutions generated so far. Then the successor
set of Smin is constructed and any successor solution which is not currently present in
Open as well as is not already added to Closed is inserted to Open. However as a further
optimization, we use a sublist of Closed, named TList, to store the relevant portion of Closed
such that checking with respect to the solutions in TList is sufficient to figure out whether
the successor solution is already added to Closed. It is interesting to observe that this
algorithm can be interrupted at any time and the set of ordered solutions computed so far
can be obtained. Also, the algorithm can be resumed if some more solutions are needed.
The details of ASG algorithm are presented in Algorithm 4.
Algorithm 4: Alternative Solution Generation (ASG) Algorithm

1

2
3
4
5
6
7
8
9
10
11
12

13
14
15

16
17
18
19
20

input : An alternating AND/OR tree T
output: Alternative solutions of T in the non-decreasing order of cost
Compute the optimal solution Sopt , perform OR edge marking and populate the
swap options;
Create three lists, Open, Closed, and TList, that are initially empty;
Put Sopt in Open;
lastSolCost  C(Sopt );
while Open is not empty do
Smin  Remove the minimum cost solution from Open ;
if lastSolCost < C(Smin ) then
Remove all the elements of TList;
lastSolCost  C(Smin );
end
Add Smin to Closed and TList;
Compute the swap list, L(Smin ), of Smin ;
/* Construct Succ(Smin ) using L(Smin ) and add new solutions to Open
*/
foreach ij  L(Smin ) do
Construct Sm by applying ij to Smin ;
Construct the signature of Sm , Sig(Sm ), by concatenating ij after Sig(Smin );
/* Check whether Sm is already present in Open or in TList
*/
if (Sm not in Open) and (Sm not in TList) then
Add Sm to Open;
end
end
Report the solutions in Closed;

The pseudo-code from Line-1 to Line-4 computes the optimal solution Sopt , performs the
marking of OR edges, populates the swap options, and initializes Open, Closed and TList.
The loop in Line-10 is responsible for generating a new solution every time it is executed
as long as Open is not empty. In Line-6 of the ASG algorithm, the solution that is the
current minimum cost solution in Open (Smin ) is selected and removed from Open. The
TList is populated and maintained from Line-7 to Line-10. The loop in Line-13 generates

290

fiGenerating Ordered Solutions for Explicit AND/OR Structures

the successor solutions of Smin one by one and adds the newly constructed solutions to
Open if the newly constructed solution is not already present in Open as well as not added
to TList (Line-16 does the checking). The proof of correctness of Algorithm 4 is presented
in Appendix A. We discuss the following issues related to Algorithm 4.
Checking for Duplication : In order to check whether a particular solution Si is already
present in Open or TList, the signature of Si is matched with the signatures of the solutions
that are already present in Open and TList. It is sufficient to check the equality between the
set of swap options in the respective signatures because that set is unique for a particular
solution. It may be noted that TList is used as an optimization, which avoids searching the
entire Closed list.
Resolving Ties : While removing the minimum cost solution from the Open list, a tie
may be encountered among a set of solutions. Suppose there is a tie among the set Stie =
{S1 ,    , Sk }. The ties are resolved in the favor of the predecessor solutions, that is,
 

Si , Sj  Stie , (If Si is the predecessor of Sj )  (Si is removed before Sj )
For all other cases the ties are resolved arbitrarily in the favor of the solution which was
added to Open first.
3.2.2 Working of ASG Algorithm
We illustrate the working of the ASG algorithm on the example AND/OR tree shown in
Figure 4. The contents of the different lists obtained after first few iterations of outermost
while loop are shown in Table 1. We use the signature of a solution for representation
purpose. The solutions that are already present in Open and also constructed by expanding
the current Smin , are highlighted with under-braces.
It.
1
2
3
4

Smin
{}
{(9,10) }
{(2,3) }
{(2,3) , (3,4) }

L(Smin )
(2,3) , (9,10)

(3,4)
(11,12) , (13,14)

5

{(2,3) , (3,4) ,
(13,14) }

(11,12) , (14,15)

6

{(2,3) , (3,4) ,

(13,14)

(11,12) }

7

{(2,3) , (3,4) ,
(13,14) , (11,12) }

(14,15)

Open
{(2,3) }, {(9,10) }
{(2,3) }
{(2,3) , (3,4) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) , (11,12) }
{(2,3) , (3,4) , (13,14) , (14,15) }
{(2,3) , (3,4) , (13,14) , (11,12) },
|
{z
}
{(2,3) , (3,4) , (13,14) , (14,15) }

Closed
{}
{}, {(9,10) }
{}, {(9,10) }, {(2,3) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{(2,3) , (3,4) , (13,14) }
{}, {(9,10) }, {(2,3) },

TList
{}
{(9,10) }
{(2,3) }
{(2,3) , (3,4) }
{(2,3) , (3,4) ,
(13,14) }
{(2,3) , (3,4),

{(2,3) , (3,4) }
(11,12) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) , (14,15) }, {}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) ,
{(2,3) , (3,4) , (13,14) ,
{(2,3) , (3,4) }
(13,14) , (11,12) }
(11,12) , (14,15) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) ,
(11,12) }

Table 1: Working of ASG Algorithm
291

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Before entering the outermost while loop (Line 5), ASG computes the optimal solution
Sopt , populates the swap options, and inserts Sopt to Open. Thus, at this point of time, Open
contains only the optimal solution Sopt ; Closed and TList are empty. In the first iteration
Sopt (the signature of Sopt is {}) is selected and removed from Open. Then the swap list of
Sopt , L(Sopt ), is computed. L(Sopt ), consists of two swap options, namely (2,3) and (9,10) .
ASG adds two new solutions {(2,3) } and {(9,10) } to Open. Then solution Sopt is added to
both Closed and TList.
In the next iteration, solution {(9,10) } which has the minimum cost among the solutions
currently in Open, is selected and removed from Open, the swap list {(9,10) } is computed and
subsequently {(9,10) } is added to Open and TList. As it happens, L({(9,10) }) =  (owing to
the fact that Eopt = {e6 , e10 } and there exists no swap option on the OR edges, e6 and e10 ),
thus nothing else happens in this iteration. In the next iteration, solution {(2,3) } is removed
from Open and ultimately solution {(2,3) , (3,4) } is added to Open after adding {(2,3) } to
Closed as well as to TList. Next two iterations proceed in a similar fashion. Now, consider the
6th iteration. In this iteration, solution {(2,3) , (3,4) , (11,12) } is removed from Open, and its
successor set has only one solution, {(2,3) , (3,4) , (11,12) , (13,14) }, which is already present
in Open (inserted to Open in Iteration-5). Therefore, solution {(2,3) , (3,4) , (11,12) , (13,14) }
is not inserted to Open again. We have shown up to Iteration-7 in Table 1.
3.3 Technique for Avoiding the Checking for Duplicates in Open
In this section, we present a technique to avoid the checking done before adding a newly
constructed solution Sm to Open to determine whether Sm is already present in Open. We
first explain the scenario with an example, which is a portion of the previous example
shown in Figure 4. In Figure 7-10, the solutions are shown using thick dashed line with
arrow head. Also the rectangles with rounded corner are used to highlight the fact that the
corresponding node in the marked solution does not belong to the Vopt set of that solution.
v4

2, 37
h4i

3, 11
h2i

4, 17
h3i

11,12 : 4

h4i

h3i

v7
h1i

v4

2, 44

v8

3, 15

h1i

13,14 : 3

h3i

v7

4, 20
h3i

h2i

v8
h1i

h1i

v11

v12

v13

v14

v11

v12

v13

v14

6

9

12

15

6

9

12

15

Figure 8: Solution S3

Figure 7: Running Example

Consider the solutions S1 , S2 and S3 (shown in Figure 9, Figure 10 and Figure 8). Here
(a) L(Sopt ) = {(11,12) , (13,14) }, (b) Succ(Sopt ) = {S1 , S2 },
(c) Sig(S1 ) = {(13,14) }, (d) Sig(S2 ) = {(11,12) }, and (e) Sig(S3 ) = {(13,14) , (11,12) }.
Algorithm 4 constructs the solution S3 (shown in Figure 8) for adding to Open twice 
(i) as a part of adding Succ(S1 ) to Open, and (ii) while adding Succ(S2 ) to Open.
292

fiGenerating Ordered Solutions for Explicit AND/OR Structures

v4

2, 40

h4i

3, 11
h2i

4, 20
h3i

11,12 : 4

h4i

h3i

v7

v4

2, 41

v8

h1i

3, 15

h1i

h3i

v7

4, 17
h3i

h2i

h1i

v8
h1i

13,14 : 3

v11

v12

v13

v14

v11

v12

v13

v14

6

9

12

15

6

9

12

15

Figure 9: Solution S1

Figure 10: Solution S2

We use the following definitions to describe another version of the ASG algorithm, which
constructs the solutions in such a way that the check to find out whether a solution is already
added to Open is avoided.
Definition 3.l [Solution Space DAG(SSDAG)] The solution space DAG of an alternating
AND/OR tree T is a directed acyclic graph (DAG), G s = hV, Ei, where V is the set of all
possible solutions of the AND/OR tree T , and E is the set of edges which is defined as:

fi

fi Sp , Sm  V, and


fi
E = espm fifi espm is a directed edge from node Sp to Sm , and


fi Sm  Succ(Sp )

Clearly Sopt is the root node of G s .




Definition 3.m [Solution Space Tree and Completeness] A solution space tree of an
alternating AND/OR tree T is a tree T s = hV t , E t i where V t  V, where V is the set of
all possible solutions of the AND/OR tree T , and E t is the set of edges which is defined
as:
fi


fi Sp , Sm  V t , and


fi




s
fi
e
is
a
directed
edge
from
node
S
to
S
,
and
p
m
s fi pm
t
E = epm fi

fi Sp  P red(Sm ), and


 

fi S   P red(Sm ), (Sp 6= S  )  there is no edge between S  and Sm . 
p
p
p
The sibling set for a solution Sm , is denoted using Sib(T s , Sm ). A solution space tree T s
for an AND/OR tree is complete if V t = V.


It may be noted that the complete solution space tree of an alternating AND/OR tree
is not necessarily unique. It is possible for an alternating AND/OR tree to have more than
one complete solution space tree. However the solution space DAG for any AND/OR tree
is unique.
Definition 3.n [Native Swap Options of a Solution] Consider a solution Sm of an alternating AND/OR tree T . Suppose Sm is constructed by applying swap option ij to
solution Sp . Since swap option ij = hei , ej , ij i is used to construct Sm , AND node vj is
present in Sm . The native swap options of solution Sm with respect to swap option ij ,
N (Sm , ij ), is a subset of L(Sm ), and comprises of the following swap options :
293

fiGhosh, Sharma, Chakrabarti, & Dasgupta

v1

2, 49

2,3 : 5

h3i

3, 32

3,4 : 1
h2i

v2

v3

h1i

2, 43

v4

35
h5i

2, 11

h1i

v5

h3i

h4i

v6

3, 11

v7

v8

4, 23

12
h2i
h1i 
9,10 : 3

h2i

h3i

11,12 : 4

h1i

h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 11: A solution, S4 , of the AND/OR tree shown in Figure 4
a. jk , where jk is the swap option on the edge ej
b. each t , if t belongs to an OR node vq where vq is a node in Sm (vj )
We use the term N (Sm ) to denote the native swap options when ij is understood from
the context. Intuitively the native swap options for solution Sm are the swap options that
become available immediately after applying ij , but were not available in the predecessor
solution of Sm .



Consider the solution S4 shown in Figure 11 where Sig(S4 ) = {(2,3) , (3,4) , (13,14) }. The
solution is highlighted using thick dashed lines with arrow head. We have used the rectangles with rounded corner beside each node vq in solution S4 , where C(S4 , vq ) 6= Copt (vq ).
Suppose S4 is constructed form solution S3 (where Sig(S3 ) = {(2,3) , (3,4) }) using swap
option (13,14) . Here N (S4 , (13,14) ) = {(14,15) } whereas L(S4 ) = {(11,12) , (14,15) }. Now
consider solution S6 where Sig(S6 ) = {(2,3) , (3,4) , (11,12) , (13,14) ). It is worth observing that applying only the native swap options to S4 instead of all swap options in L(S4 )
prevents the construction of solution S6 from solution S4 . S6 can also be constructed by
applying (13,14) to solution S5 , where Sig(S5 ) = {(2,3) , (3,4) , (11,12) }. However, it may
be noted that (13,14) is not a native swap option of solution S5 .
3.3.1 Lazy ASG Algorithm
The intuition behind the other version of the ASG algorithm is as follows. For a newly
constructed solution Sm , we need to check whether Sm is already present in Open because
Sm can be constructed as a part of computing the successor set of multiple solutions.
Instead of using the entire swap list of a solution to construct all successors at once and
then add those solutions to Open, using the native swap options for constructing a subset of
the successor set ensures the following. The subset constructed using native swap options
294

fiGenerating Ordered Solutions for Explicit AND/OR Structures

consists of only those solutions that are currently not present in Open and thus can be
added to Open without comparing with the existing entries in Open. The construction of
 of S
each remaining successor solution Sm
m and then insertion to Open is delayed until
 is added to Closed.
every other predecessor solution of Sm
Algorithm 5: Lazy ASG (LASG) Algorithm

1

2
3
4
5
6
7
8
9
10
11

12

13

14
15
16

17
18

19
20
21
22
23
24
25
26
27
28

input : An alternating AND/OR tree T
output: Alternative solutions of T in the non-decreasing order of cost
Compute the optimal solution Sopt , perform OR edge marking and populate the
swap options;
Create two lists, Open and Closed, that are initially empty;
Put Sopt in the Closed list;
Create a solution space tree T s with Sopt as root;
Compute the swap list, L(Sopt ), of Sopt ;
Construct Succ(Sopt ) using L(Sopt );
forall Sm  Succ(Sopt ) do
Add Sm to Open;
end
while Open is not empty do
Smin  Remove the minimum cost solution from Open ;
/* Suppose Smin is constructed from Sm applying swap option ij
*/
Add a node corresponding to Smin in T s and connect that node using an edge
from Sm ;
Compute the swap list L(Smin ) and the list of native swap options N (Smin , ij );
/* Expansion using native swap options
*/
foreach tmp  N (Smin , ij ) do
Construct Stmp from Smin by applying tmp ;
Construct the signature of Stmp , Sig(Stmp ), by concatenating tmp after
Sig(Smin );
Add Stmp to Open;
end
/* Lazy Expansion
*/
s
forall Sp  Sib(T , Smin ) do
if ij  L(Sp ) then
Construct Sp from Sp using ij ;
Construct the signature of Sp , Sig(Sp ), by concatenating ij after Sig(Sp );
Add Sp to Open;
end
end
Add Smin to Closed;
end
Report the solutions in Closed;

The solution space tree T s is maintained throughout the course of the algorithm to
 is added to Closed. Based on this idea we
determine when every other predecessor of Sm
295

fiGhosh, Sharma, Chakrabarti, & Dasgupta

present a lazy version of ASG algorithm, named LASG. After selecting the minimum cost
solution from Open, the algorithm explores the successor set of the current minimum cost
solution in a lazy fashion. For a solution Sm , at first a subset of Succ(Sm ) is constructed
using only the native swap options of Sm . The other solutions that belong to Succ(Sm )
are explored as late as possible as described above. For resolving ties, LASG algorithm
uses the same strategy which is used by ASG algorithm. The details of LASG algorithm
are presented in Algorithm 5. The proof of correctness of this algorithm is presented in
Appendix B.
Consider the example tree shown in Figure 7 and solutions S1 and S2 (shown in Figure 9
and Figure 10). Initially the Open will contain only Sopt and N (Sopt ) = {(11,12) , (13,14) }.
When Sopt is selected from Open, both S1 and S2 is added to Open. Next S1 will be selected
followed by S2 . Since, N (S1 ) =  and N (S2 ) = , after selecting S1 or S2 no successor
solutions are constructed using the native swap list. Among the predecessors of S3 , S2 is
added last to Closed. After selecting and removing S2 from Open, solution S3 is constructed
from the previously selected predecessor S1 using the swap option (11,12) which is used to
construct solution S2 from Sopt .
3.3.2 Working of LASG Algorithm (on AND/OR tree in Figure 4)
Before entering the outermost while loop (Algorithm 5, Line 10), LASG computes the
optimal solution Sopt and constructs Succ(Sopt ). Then
 the solutions 	in Succ(Sopt ) are
added to Open and the contents of the Open becomes {(2,3) }, {(9,10) } . The contents of
the different lists when a solution is added to Closed are shown in Table 2. The solutions
are represented using their signatures. The solutions that are added to Open as a result of
lazy expansion, are highlighted using under-brace.
Iteration
1
2
3

Smin
{}
{(9,10) }
{(2,3) }
{(2,3) , (3,4) }

N (Smin )
(2,3) , (9,10)

(3,4)
(11,12) , (13,14)

4

{(2,3) , (3,4) , (13,14) }

(14,15)

5

{(2,3) , (3,4) , (11,12) }



6

{(2,3) , (3,4) , (13,14) ,
(11,12) }



Open
{(2,3) }, {(9,10) }
{(2,3) }
{(2,3) , (3,4) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) , (14,15) }

Closed
{}
{}, {(9,10) }
{}, {(9,10) }, {(2,3) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (13,14) , (14,15) }, {}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) , (13,14) , (11,12) }
{(2,3) , (3,4) }
|
{z
}
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) , (14,15) }, {}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) ,
(11,12) }

Table 2: Working of LASG Algorithm
While generating the first four solutions, the contents of the different lists for LASG
are identical to the contents of the corresponding lists of ASG (shown in Table 1). For
296

fiGenerating Ordered Solutions for Explicit AND/OR Structures

each of these soltuions, the native swap list is equal to the actual swap list of that solution. It is worth noting that, unlike ASG, for LASG the outermost while loop starts
after generating the optimal solution Sopt , thus while generating the same solution the
iteration number for LASG is less than that of ASG by 1. In the 4th iteration, for solution S4 = {(2,3) , (3,4) , (13,14) } the native swap list is not equal to the swap list as
described previously. The same holds true for solution S5 = {(2,3) , (3,4) , (11,12) } and
solution S6 = {(2,3) , (3,4) , (13,14) , (11,12) }. It is important to observe that LASG adds
the solution S6 = {(2,3) , (3,4) , (13,14) , (11,12) } to Open after the generation of solution
S5 = {(2,3) , (3,4) , (11,12) } as a part of lazy expansion (highlighted using under-brace
in Table 2). Whereas, the ASG algorithm adds S6 to Open after generating solution
S4 = {(2,3) , (3,4) , (13,14) }.
3.4 Complexity Analysis and Comparison among ASG, LASG and BU
In this section we present a complexity analysis of ASG and LASG and compare them with
BU. We will use the following parameters in the analysis.
a. n and n denote the total number of nodes and the number of OR nodes in an
alternating AND/OR tree.
b. d denotes the out degree of the OR node having maximum number of children.
c. m denotes the maximum number of OR edges in a solution.
d. o denotes the maximum size of Open. We will present the complexity analysis for
generating c solutions. Therefore the size of Closed is O(c).
3.4.1 Complexity of ASG
Time Complexity : The time complexity of the major steps of Algorithm 4 are as
follows.
a. Computing the first solution can be done in bottom-up fashion, thus requiring O(n )
steps. The edges emanating from an OR node are sorted in the non-decreasing order
of aggregated cost to compute the marks of the OR edges, the marking process takes
O n .d. log d . Since the value
 of d is not very large in general (can be upper bounded
by a constant), O n .d. log d = O(n ).
b. The number of swap options available to a solution can be at most equal to the number
of OR edges in that solution. Thus, the swap list for every solution can be built in
O(m) time. For c solutions, generating swap options take O(c.m).
c. Since the size of the successor set of a solution can be m at most, the size of Open, o
can at most be c.m. Also the size of the TList can at most be equal to c (the size of
Closed).
d. The Open list can be implemented using Fibonacci heap. Individual insert and delete
operation on Open take O(1)(amortized) and O(lg o) time respectively. Hence, for
inserting in the Open and deleting from Open altogether takes O(o. lg o) time which
is O(c.m. log(c.m)).
e. The checking for duplicates requires scanning the entire Open and TList. Since the
length of TList can be at most c, for a newly constructed solution this checking takes
O(c + o) time and at most O(c + o) solutions are generated. Since O(c + o) is actually
O(o), for generating c solutions, this step takes O(o)2 time. Also, the maximum value
297

fiGhosh, Sharma, Chakrabarti, & Dasgupta

of o can be O(c.m). Thus, the time complexity of this step is O(c.m)2 . Clearly this
step dominates O(o. lg o) which is the total time taken for all insertions into the Open
and deletions from Open.
However, this time bound can be further improved if we maintain a hash map of the
solutions in the Open and TList, and in this case the checking for duplicates can be
done in O(o) time. In that case O(o. lg o) (total time taken for all insertions into the
Open and deletions from Open) becomes dominant over the time required for checking
for duplicates.
f. An upper limit estimate of m could be made by estimating the size of a solution tree

which is n for regular and complete alternating AND/OR trees. It is important
to observe that the value of m is independent of the average out degree of a node in
T .
Combining
together we get the time complexity
of ASG algorithm as :

 factors

 the above
2
2
2
2
O n + o = O n + (c.m) = O n + c .n = O(c .n )
Howeverif the additional
hash
is further reduced to : 

 map is used the time complexity



O n + o. lg o = O n + c. n . lg(c.n ) = O n + n .(c. lg c + c. lg n )
Space Complexity: The following data-structures primarily contribute to the space complexity of ASG algorithm.
a. Three lists, namely, Open, Closed, and TList are maintained throughout the course of
the running ASG. This contributes a O(o + c) factor, which is O(o).
b. Since the number of swap options is upper bounded by the total number of OR edges,
constructing the swap list contributes the factor, O(n .d) to the space complexity.
Also marking a solution requires putting a mark at every OR node of the AND/OR
tree, thus adding another O(n ) space which is clearly dominated by the previous
O(n .d) factor.
c. Since the signature of a solution is essentially a set of swap options, the size of a
signature is upper bounded by the total number of swap options available. Combining
the Open and Closed list, altogether (c + o) solutions need to be stored.
Since (c + o)

is O(o), total space required for storing the solutions is O o.n .d .
Combining
 the above factors
 together we get the space complexity of ASG algorithm as :
O o + n .d + o.n .d = O(o.n .d)
When an additional
hash map is used to improve the time complexity, another addi
tional O o.n .d space is required for maintaining the hash map. Although the exact space
requirement is doubled, asymptotically the space complexity remains same.
3.4.2 Complexity of LASG
Time Complexity : Compared to Algorithm 4, Algorithm 5 does not check for the
duplicates and adds the solution to Open only when it is required. Therefore the other
terms in the complexity remain the same except the term corresponding to the checking for
duplicates. However, here T s is created and maintained during the course of Algorithm 5.
Creating and maintaining the tree require O(c) time. Also during the lazy expansion the
swap list of the previously generated sibling solutions are searched (Line 19 and Line 20 of
Algorithm 5). The size of the swap list of any solution is O(m), where m is the maximum
number of OR edges in a solution. Also there can be at most O(m) sibling solutions for a
298

fiGenerating Ordered Solutions for Explicit AND/OR Structures

solution. Therefore the complexity of the lazy expansion is O(c.m2 ). Since O(c.m2 ) is the
dominant factor, the time complexity of LASG is O(c.m2 ) = O(c.n ).
Space Complexity : Compared to ASG algorithm, LASG algorithm does not maintain
the TList. However LASG maintains the solution space tree T s whose size is equal to
the Closed list, thus adding another O(c) factor to the space complexity incurred by ASG
algorithm. It is interesting to observe that the worst case space complexity remains O(o +
n .d + o.n .d) = O(o.n .d) which is equal to the space complexity of ASG algorithm.
3.4.3 Comparison with BU
The time complexity of generating the c best solutions for an AND/OR tree is O(n .c. log c)
and the space complexity is O(n .c). The detailed analysis can be found in the work
of Elliott (2007). Since, n .d = O(n ), the space complexity of both ASG and LASG
algorithm reduces to O(n .c) and the time complexity of LASG is log c factor better than
BU whereas the time complexity of ASG is quadratic with respect to c compared to the
(c. log c) factor of BU. When an additional hash-map is used to reduce the time overhead of
duplicate checking, ASG beats both LASG
 and BU both in terms time complexity, as both

O(n ) and O n .(c. lg c + c. lg n ) is asymptotically lower than O(n .c. log c).
However this worst case complexity is only possible for AND/OR trees where no duplicate solution is generated. Empirical results show that the length of Open, o hardly reaches
O(c.m).

4. Ordered Solution Generation for AND/OR DAGs
In this section, we present the problem of generating solutions in non-decreasing order
of cost for a given AND/OR DAG. We present the working of the existing algorithm for
generating solution for both tree based semantics and default semantics. Next we present
the modifications in ASG and LASG for handling DAG.
4.1 Existing Bottom-Up Algorithm
Figure 12 shows an example working of the existing bottom-up approach, BU, on the
AND/OR DAG in Figure 2. We use the notations that are used in Figure 3 to describe
different solutions in Figure 12 and the generation of the top 2 solutions under tree-based
semantics is shown.
It is important to notice that although BU correctly generates alternative solutions of
an AND/OR DAGs under tree based semantics, BU may generate some solutions which are
invalid under default semantics. In Figure 13 we present a solution of the AND/OR DAG
in Figure 2. This solution is an example of such a solution which is correct under tree-based
semantics but is invalid under default semantics. The solution DAG (highlighted using
thick dashed lines with arrow heads) in Figure 13 will be generated as the 3rd solution of
the AND/OR DAG in Figure 2 while running BU. At every non-terminal node, the entry
(within rectangle) corresponding to the 3rd solution is highlighted using bold face. It may
be noted that the terminal nodes, v9 and v10 , are included in the solution DAG though both
of them emanate from the same parent OR node. Therefore, this solution is not a valid one
under default semantics.
299

fiGhosh, Sharma, Chakrabarti, & Dasgupta

2, 89

v1

v2 v3
1 : |1, 1|, 89
2 : |2, 1|, 90

h1i
3, 43

v2

1 : hv5 , 1i, 43
2 : hv4 , 1i, 44

v4
40

h1i

v7

1 : hv5 , 1i, 41
2 : hv5 , 2i, 44

3, 43

h1i

v7 v8
1 : |1, 1|, 35
2 : |2, 1|, 38

v2

1 : hv9 , 1i, 9
2 : hv10 , 1i, 12

v6

v4

52

40

1 : hv5 , 1i, 43
2 : hv4 , 1i, 44

v5

2, 35

v8

3, 9
h1i

v7

2, 41

v3

h4i

1 : hv5 , 1i, 41
2 : hv5 , 2i, 44
h1i

v7 v8
1 : |1, 1|, 35
2 : |2, 1|, 38

v6
52

h3i

h4i

17

h2i

h2i

h5i

h1i

h3i

h4i
3, 9

v3

h4i
v5

2, 35

2, 41

v1

h1i

h2i

h5i

h1i

2, 89

v2 v3
1 : |1, 1|, 89
2 : |2, 1|, 90
3 : |1, 2|, 92

1 : hv2 , 1i, 34
2 : hv2 , 2i, 37

v8
17

h2i

v9

v10

v9

v10

5

7

5

7

Figure 13: A solution (tree based semantics)

Figure 12: BU approach for AND/OR DAG

Proposed Extension of BU to Generate Alternative Solutions under Default
Semantics : We propose a simple top-down traversal and pruning based extension of
BU to generate alternative solutions under default semantics. While generating the ordered
solutions at any AND node vq by combining the solutions of the children, we do the following.
For each newly constructed solution rooted at vq , a top-down traversal of that solution
starting from vq is done to check whether more than two edges of an OR node are present
in that particular solution (a violation of the default semantics). If such a violation of the
default semantics is detected, that solution is pruned from the list of alternative solutions
rooted at vq . Therefore, at every AND node, when a new solution is constructed, an
additional top-down traversal is used to detect the semantics violation.
4.2 Top-Down Method for DAGs
The proposed top-down approaches (ASG and LASG) are also applicable for AND/OR
DAGs to generate alternative solution DAGs under default semantics. Only the method of
computing the cost increment after the application of a swap option needs to be modified to
incorporate the fact that an OR node may be included in a solution DAG through multiple
paths from the root node. We use the notion of participation count for computing the cost
increment.
Participation Count : The notion of participation count is applicable to the intermediate
nodes of a solution DAG as follows. In a solution DAG, the participation count of an
intermediate node, vq , is the total number of distinct paths connecting the root node, vR ,
and vq . For example, in Figure 14, the optimal solution DAG is shown using thick dashed
lines with arrow heads, and the participation count for every intermediate OR nodes are
shown within a circle beside the node.
300

fiGenerating Ordered Solutions for Explicit AND/OR Structures

v1

h2i

h1i
1

h1i

v2

3, 43

1

h5i

2,5,4 : 1

v4

v1

2, 89

2

h4i

v5

2

h1i

v7

v3

2, 41

3,5,6 : 14

1

h1i

2, 35

v2

3, 44

v6

v4

52

40

1

h5i

h1i

h4i

v5

1

1

17
h2i

h1i

2, 41

3,5,6 : 14

h1i

v6

2, 35
h3i

h4i

v8

v3

52

h3i

3, 9

7,9,10 : 3

h2i

h1i

40
h4i

2, 90

v7

v8

3, 9

7,9,10 : 3

17

h2i

v9

v10

v9

v10

5

7

5

7

Figure 15: Solution DAG S1

Figure 14: AND/OR DAG

We use the notation ijk to denote a swap option in the context of AND/OR DAGs,
where swap option ijk belongs to node vi , the source edge of the swap option is eij from
node vi to node vj , and the destination edge is eik from node vi to node vk .
4.2.1 Modification in the Proposed Top-Down Approach
The ASG algorithm is modified for handling AND/OR DAGs in the following way. The
computation of the successor solution in Line 14 of Algorithm 4 is modified to incorporate
the participation count of the OR node to which the applied swap option belongs. The
overall method is shown in Algorithm 6(in the next page).
In order to apply LASG on AND/OR DAGs, apart from using the above mentioned
modification for computing the cost of a newly generated solution, another modification
is needed for computing the native swap options for a given solution. The modification is
explained with an example. Consider the solution, S1 , shown in Figure 15. S1 is highlighted
using thick dashed lines with arrow heads. The pair, cv (vq ), C(S1 , vq ), is shown within
rectangles beside each node vq ; rectangles with rounded corner are used when C(S1 , vq ) 6=
Copt (vq ). Swap option (2,5,4) was applied to Sopt to generate S1 . After the application
of swap option (2,5,4) , the participation count of node v5 is decremented to 1. Therefore
in S1 there is a path from the root node to node v5 and so node v5 is still present in S1 .
As a result, the swap option (7,9,10) is available to S1 with a participation count equal to
1 for node v7 , whereas (7,9,10) is available to its parent solution Sopt with participation
count 2 for node v7 . In other words, (7,9,10) is not available to S1 and its parent solution
Sopt with the same value of participation count for node v7 . Therefore (7,9,10) becomes the
native swap option of S1 . The generalized definition of native swap options for a solution
is presented below.
Definition 4.o [Native Swap Options of a Solution] Consider a solution Sm of an
AND/OR DAG G , where Sm is constructed by applying swap option hij to solution
Sp . Since swap option hij = hehi , ehj , hij i is used to construct Sm , AND node vj belongs
301

fiGhosh, Sharma, Chakrabarti, & Dasgupta

to Sm . Similarly, if the participation count of node vi remains greater than zero after applying hij to Sm , node vi belongs to Sm . The native swap options of solution Sm with
respect to swap option hij , N (Sm , hij ), a subset of L(Sm ), comprises of the following
swap options :
a. hjk , where hjk is the swap option on the edge ehj
b. each t , if t belongs to an OR node vq where vq is a node in Sm (vj )
c. each t , if node vi is present in Sm and t belongs to an OR node vq where vq is a
node in Sm (vi ).
We use the term N (Sm ) to denote the native swap options when hij is understood from
the context. Intuitively the native swap options for solution Sm are the swap options that
become available immediately after applying hij , but were not available in the predecessor
solution of Sm .


Algorithm 6: ASG Algorithm for AND/OR DAGs
input : An AND/OR DAG G
output: Alternative solutions of G in the non-decreasing order of cost
1 Compute the optimal solution Sopt , perform OR edge marking and populate the
swap options;
2 Create three lists, Open, Closed, and TList, that are initially empty;
3 Put Sopt in Open;
4 lastSolCost  C(Sopt );
5 while Open is not empty do
6
Smin  Remove the minimum cost solution from Open;
7
if lastSolCost < C(Smin ) then
8
Remove all the elements of TList;
9
lastSolCost  C(Smin );
10
end
11
Add Smin to Closed and TList;
12
Compute the swap list, L(Smin ), of Smin ;
/* Construct Succ(Smin ) using L(Smin ) and add new solutions to Open
*/
13
foreach ij  L(Smin ) do
14
Construct Sm by applying ij to Smin ;
15
Construct the signature of Sm , Sig(Sm ), by concatenating ij after Sig(Smin );
16
Let ij belongs to OR node vq , p is the participation count of vq , and  is the
cost increment for ij ;
17
C(Sm ) = C(Sm ) + p  ;
/* Check whether Sm is already present in Open or in TList
*/
18
if (Sm not in Open) and (Sm not in TList) then
19
Add Sm to Open;
20
end
21 end
22 Report the solutions in Closed;
It is worth noting that Definition 4.o of native swap option is a generalization of the
earlier definition of native swap option (Definition 3.n), defined in the context of trees. In
302

fiGenerating Ordered Solutions for Explicit AND/OR Structures

the case of trees, the participation count of any node can be at maximum 1. Therefore,
after the application of a swap option to a solution, the participation count of the node,
to which the original edge of the swap option points to, becomes 0. Therefore the third
condition is never applicable for trees.
LASG (Algo. 5) can be applied on AND/OR DAGs, with the mentioned modification
for computing the cost of a newly generated solution and the general definition of native
swap option to generate ordered solutions under default semantics.
4.2.2 Working of ASG and LASG Algorithm on AND/OR DAG
We describe the working of ASG algorithm on the example DAG shown in Figure 2. Before
entering the outermost while loop, TList and Closed are empty, and Open contains the
optimal solution Sopt . The contents of the different lists obtained after first few cycles of
outermost while loop are shown in Table 3. Each solution is represented by its signature.
The solutions that are already present in Open and also constructed by expanding the
current Smin , are highlighted with under-braces. For example, the solution {(2,5,4) , (3,5,6) }
which is added to Open in Iteration 2 (while constructing the successor solutions of {(2,5,4) })
constructed again in Iteration 5 while expanding solution {(3,5,6) }.
L(Smin )
Open
(2,5,4) , (3,5,6) , (7,9,10)
{(2,5,4) }, {(3,5,6) }, {(7,9,10) }
(3,5,6) , (7,9,10)
{(3,5,6) }, {(7,9,10) }, {(2,5,4) , (3,5,6) },
{(2,5,4) , (7,9,10) }
3 {(2,5,4) , (7,9,10) }

{(3,5,6) }, {(7,9,10) }, {(2,5,4) , (3,5,6) },

It.
1
2

Smin
{}
{(2,5,4) }

4

{(7,9,10) }



{(3,5,6) }, {(2,5,4) , (3,5,6) },

5

{(3,5,6) }

(2,5,4) , (7,9,10)

{(2,5,4) , (3,5,6) }, {(3,5,6) , (7,9,10) }
|
{z
}

Closed
{}
{}, {(2,5,4) }
{}, {(2,5,4) }
{(2,5,4) , (7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }, {(3,5,6) }

Table 3: Example Working of ASG Algorithm on the DAG shown in Figure 2
Now we illustrate the working of LASG algorithm on the example DAG shown in Figure 2. The contents of the different lists when a solution is added to Closed are shown
in Table 4. It is worth noting that for solution S1 = {2,5,4 }, the swap list L(S1 ) =
{(3,5,6) , (7,9,10) } whereas the native swap list N (S1 ) = {(7,9,10) }. The solutions that are
added to Open as a result of lazy expansion, are highlighted using under-brace. For example,
in Iteration 7 LASG adds the solution S5 = {(2,5,4) , (3,5,6) } to Open after the generation
of solution S4 = {3,5,6 } as a part of lazy expansion, whereas the ASG algorithm adds S5
to Open after generating solution S1 = {2,5,4 }.
4.2.3 Generating Solutions under Tree Based Semantics
Unlike the default semantics, ASG or LASG does not have any straight forward extension
for generating solutions under tree based semantics. In Figure 13 we show an example
solution which is valid under tree based semantics, but invalid under default semantics,
because both OR edges emanating form the OR node v7 , namely e(7,9) and e(7,10) , are
303

fiGhosh, Sharma, Chakrabarti, & Dasgupta

N (Smin )
Open
(2,5,4) , (3,5,6) , (7,9,10) {(2,5,4) }, {(3,5,6) }, {(7,9,10) }
(7,9,10)
{(3,5,6) }, {(7,9,10) },
{(3,5,4) , (7,9,10) }
2 {(2,5,4) , (7,9,10) }

{(3,5,6) }, {(7,9,10) },

It.
1

Smin
{}
{(2,5,4) }

3

{(7,9,10) }



{(3,5,6) }

4

{(3,5,6) }

(7,9,10)

{(3,5,6) , (7,9,10) },
{(2,5,4) , (3,5,6) }
|
{z
}

Closed
{}
{}, {(2,5,4) }
{}, {(2,5,4) }
{(2,5,4) , (7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }, {(3,5,6) }

Table 4: Example Working of LASG Algorithm on the DAG shown in Fugure 2

present in this solution. These two OR edges are included in the solution through two
different paths emanating form the root node, v1 . As the existing bottom-up approach
stores the alternative solutions at each node in terms of the solutions of the children of that
node, this representation allows these different paths to be stored explicitly, thus making
BU amenable for generating alternative solutions under tree-based semantics.
On the contrary, our approach works top-down using a compact representation (signature) for storing the solutions. In this signature based representation, it is currently not
possible to store the fact that a particular OR node is included in the solution through two
different paths which may select different child of that OR node. If we use the equivalent
tree constructed form the given graph, our compact representation will work correctly, because in that case, each node would be reachable from the root node through at most one
path. An AND/OR DAG can be converted to its equivalent AND/OR tree representation
using procedure ConvertDAG (described in Section 2) and then ASG or LASG can be applied on the equivalent tree representation in order to generate the alternative solutions
correctly under tree-based semantics. However, in the worst case, procedure ConvertDAG
incurs a space explosion which will blow up the worst case complexity of both ASG and
LASG algorithms. Using our compact representations to generate the ordered solutions
under tree-based semantics for a given AND/OR DAG while containing the space explosion
such that the worst case complexity of our algorithms remain comparable with BU turns
out to be an interesting open problem.

5. Experimental Results and Observations
To obtain an idea of the performance of the proposed algorithms and to compare with
the existing approach, we have implemented the ASG, LASG and BU (existing bottom-up
approach) and tested on the following test domains.
a. A set of synthetically generated AND/OR trees;
b. Tower of Hanoi (TOH) problem;
c. A set of synthetically generated AND/OR DAGs;
d. Matrix-chain multiplication problem; and
e. The problem of determining the secondary structure of RNA sequences.
304

fiGenerating Ordered Solutions for Explicit AND/OR Structures

It may noted that in our implementation of the ASG algorithm, we have implemented the
more space efficient version of ASG algorithm (without a separate hash-map for storing the
solutions in Open and Closed, thereby incurring an extra overhead in time for duplication
checking). Another important point is that for every test case the reported running time of
ASG and LASG for generating a particular number of solutions includes the time required
for constructing the optimal solution graph. The details of the different test domains are
as follows.
5.1 Complete Trees
We have generated a set of complete d-ary alternating AND/OR trees by varying  (a) the
degree of the non-terminal nodes (denoted by d), and (b) the height (denoted by h).
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

100 solutions
ASG
LASG
BU
0.027
0.005
0.004
0.216
0.010
0.015
1.170
0.031
0.068
6.072
0.124
0.257
30.434
0.517
1.180
130.746 2.265
4.952
0.046
0.006
0.005
0.528
0.017
0.037
5.812
0.106
0.343
66.313
1.552
3.973
636.822 12.363 31.043
0.144
0.011
0.033
2.916
0.056
0.573
58.756
1.266
7.698
0.334
0.012
0.081
12.227
0.177
2.066
0.699
0.022
0.161
32.620
0.654
7.464
1.306
0.030
0.287
81.197
1.786 15.892

300 solutions
ASG
LASG
BU
0.086
0.014
0.009
1.448
0.035
0.046
10.098
0.094
0.184
57.757
0.348
0.777
278.453 1.433
3.917
T
6.443
13.277
0.196
0.015
0.018
4.764
0.060
0.153
55.170
0.290
1.733
620.996 3.712
14.323
T
34.150 128.314
1.041
0.025
0.092
25.341
0.181
1.561
544.989 3.327
27.063
2.792
0.036
0.400
102.577 0.443
11.717
5.384
0.071
1.418
288.257 1.566
37.758
12.006
0.092
1.833
785.160 4.284 102.431

500 solutions
ASG
LASG
BU
0.186
0.023
0.020
4.137
0.060
0.097
27.354
0.216
0.407
158.520 0.524
1.641
766.201 2.806
7.257
T
10.306 29.703
0.459
0.026
0.042
10.345
0.088
0.457
156.158 0.494
4.913
T
6.607
33.923
T
55.510 303.785
2.610
0.042
0.123
69.596
0.264
2.107
T
5.172
38.606
7.374
0.062
0.930
283.689 0.827
26.994
15.133
0.134
2.235
832.235 2.594
90.465
29.870
0.179
4.322
T
6.890 241.064

Table 5: Comparison of running time (in seconds) for generating 100, 300, and 500 solutions
for complete alternating AND/OR trees (T denotes the timeout after 15 minutes)
These trees can be viewed as the search space for a gift packing problem, where
(a) the terminal nodes represent the cost of elementary items,
(b) the OR nodes model a choice among the items (elementary or composite in nature)
represented by the children, and
(c) the AND nodes model the repackaging of the items returned by each of the children.
Every packaging incurs a cost which is modeled by the cost of the intermediate AND nodes.
Here the objective is to find the alternative gifts in the order of non-decreasing cost.
Table 5 shows the time required for generating 100, 300, and 500 solutions for various
complete alternating AND/OR trees. We have implemented the ASG, LASG and the
existing bottom-up algorithm and the corresponding running time is shown in the column
with the heading ASG, LASG and BU, respectively. We have used a time limit of 15 minutes
305

fiGhosh, Sharma, Chakrabarti, & Dasgupta

(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

ASG
12.633
52.770
116.582
287.898
664.789
1785.156
17.270
82.609
335.301
1474.477
9139.312
40.285
213.816
1563.770
64.879
529.738
97.703
1264.828
137.527
2628.461

100 solutions
LASG
BU
13.168
11.047
26.152
48.484
63.254
198.234
173.730
797.234
413.855
3193.234
1257.387 12777.234
17.258
11.688
48.086
111.438
184.375
1009.188
1071.352 9088.938
7872.055 81806.688
24.469
47.453
128.629
767.453
1158.582 12287.453
40.355
88.281
343.254
2217.188
58.191
151.047
862.332
5449.797
90.703
242.219
1995.195 11882.781

ASG
28.105
144.730
341.227
832.562
1767.867
T
47.531
235.855
926.004
3234.523
T
121.336
559.734
3209.145
182.270
1254.715
270.027
2747.238
369.086
4869.551

300 solutions
LASG
BU
32.293
14.266
75.355
69.953
165.824
292.703
399.445
1183.703
804.801
4747.703
2047.859 19003.703
49.230
14.812
134.102
152.062
376.766
1387.312
1656.844 12504.562
9565.598 112559.812
67.102
112.609
284.922
1826.359
1699.191 29246.359
110.480
225.781
596.957
5675.000
148.453
372.141
1273.641 13433.391
205.914
576.594
2627.211 28295.281

ASG
41.676
230.168
566.766
1396.758
2942.629
T
76.270
393.113
1507.973
T
T
199.254
917.824
T
305.891
2008.344
443.656
4203.957
606.133
T

500 solutions
LASG
BU
49.832
16.609
128.934
87.922
269.766
373.172
612.184
1514.172
1197.266
6078.172
2849.617
24334.172
80.980
17.938
219.555
192.688
577.766
1765.438
2238.152
15920.188
11251.035 143312.938
116.535
129.016
451.223
2105.266
2240.012
33725.266
179.801
363.281
858.852
9132.812
245.227
593.234
1695.684
21416.984
317.492
910.969
3273.703
44707.781

Table 6: Comparison of space required (in KB) for generating 100, 300, and 500 solutions
for complete alternating AND/OR trees

and the entries marked with T denotes that the time-out occurred for those test cases. The
space required for generating 100, 300, and 500 solutions is reported in Table 6. It can
be observed that in terms of both time and space required, LASG outperforms both ASG
and BU. Between ASG and BU, for most of the test cases BU performs better than ASG
with respect to the time required for generating a specific number of solutions. The space
requirement of ASG and BU for generating a specific number of solutions has an interesting
correlation with the degree(d) and height(h) parameter of the tree. For low numerical values
of the d and the h parameter, e.g., (d, h) combinations like (2, 7), (3, 5) etc., BU performs
better than ASG. On the contrary, for the other combinations, where at least one of these
d and h parameters has a high value, e.g., (d, h) combinations like (2, 17), (7, 5), (4, 9) etc.,
ASG outperforms BU.
5.1.1 Experimentation with Queue with Bounded Length
Since the Open can grow very rapidly, both ASG and LASG incur a significant overhead
in terms of time as well as space to maintain the Open list when the number of solutions
to be generated is not known a priori. In fact, for ASG checking for duplicates in Open is
actually the primary source of time complexity and storing the solutions in Open is a major
contributing factor in space complexity. If the number of solutions that have to generated is
known a priori, the proposed top-down approach can leverage the fact by using a bounded
length queue for implementing Open. When a bounded length queue is used, the time
requirement along with space requirement decreases significantly.
306

fiGenerating Ordered Solutions for Explicit AND/OR Structures

(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

100 solutions
ASG
LASG
BU
0.011
0.008
0.004
0.030
0.011
0.015
0.051
0.031
0.068
0.125
0.103
0.257
0.473
0.421
1.180
2.129
2.199
4.952
0.012
0.009
0.005
0.031
0.018
0.037
0.133
0.102
0.343
1.246
1.143
3.973
10.713 10.313 31.043
0.019
0.008
0.033
0.071
0.055
0.573
1.099
0.998
7.698
0.025
0.013
0.081
0.201
0.161
2.066
0.036
0.018
0.161
0.543
0.460
7.464
0.042
0.029
0.287
1.940
1.705 15.892

300 solutions
ASG LASG
BU
0.003 0.002
0.009
0.008 0.006
0.046
0.020 0.011
0.184
0.043 0.059
0.777
0.168 0.164
3.917
0.766 1.005 13.277
0.003 0.002
0.018
0.012 0.006
0.153
0.048 0.043
1.733
0.477 0.636 14.323
4.160 5.555 128.314
0.006 0.004
0.092
0.026 0.023
1.561
0.443 0.552 27.063
0.009 0.031
0.400
0.083 0.078 11.717
0.014 0.011
1.418
0.240 0.325 37.758
0.020 0.013
1.833
0.807 0.843 102.431

500 solutions
ASG LASG
BU
0.005 0.004
0.020
0.014 0.008
0.097
0.023 0.017
0.407
0.065 0.058
1.641
0.254 0.346
7.257
1.146 1.492 29.703
0.005 0.004
0.042
0.019 0.010
0.457
0.071 0.061
4.913
0.693 0.905 33.923
6.013 7.890 303.785
0.010 0.006
0.123
0.038 0.033
2.107
0.641 0.808 38.606
0.015 0.008
0.930
0.116 0.153 26.994
0.021 0.010
2.235
0.326 0.431 90.465
0.025 0.022
4.322
0.870 1.125 241.064

Table 7: Comparison of running time (in seconds) for generating 100, 300, and 500 solutions
for complete alternating AND/OR trees with bounded length Open queue for ASG
and LASG
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

ASG
10.109
23.875
54.609
135.477
361.859
1071.258
12.008
39.469
169.469
971.930
7075.109
20.664
116.609
1082.633
33.344
324.258
51.742
825.859
78.141
1919.805

100 solutions
LASG
BU
2.383
11.047
4.883
48.484
14.883
198.234
54.883
797.234
214.883
3193.234
854.883 12777.234
2.617
11.688
11.160
111.438
88.047
1009.188
780.027
9088.938
7007.852 81806.688
5.016
47.453
57.016
767.453
889.016 12287.453
10.195
88.281
217.715
2217.188
19.773
151.047
657.648
5449.797
35.742
242.219
1677.051 11882.781

ASG
27.781
64.430
141.203
317.445
738.992
1845.562
34.609
101.320
353.477
1529.031
8763.023
56.703
247.320
1607.859
84.422
565.531
121.031
1227.742
169.297
2542.047

300 solutions
LASG
BU
5.508
14.266
8.008
69.953
18.008
292.703
58.008
1183.703
218.008
4747.703
858.008
19003.703
5.742
14.812
14.285
152.062
91.172
1387.312
783.152
12504.562
7010.977 112559.812
8.141
112.609
60.141
1826.359
892.141
29246.359
13.320
225.781
220.840
5675.000
22.898
372.141
660.773
13433.391
38.867
576.594
1680.176 28295.281

ASG
45.789
104.117
225.969
497.508
1114.422
2615.656
57.617
163.102
537.328
2085.367
10457.797
93.031
377.922
2132.516
135.812
806.797
190.758
1628.797
260.406
3163.438

500 solutions
LASG
BU
8.633
16.609
11.133
87.922
21.133
373.172
61.133
1514.172
221.133
6078.172
861.133
24334.172
8.867
17.938
17.410
192.688
94.297
1765.438
786.277
15920.188
7014.102 143312.938
11.266
129.016
63.266
2105.266
895.266
33725.266
16.445
363.281
223.965
9132.812
26.023
593.234
663.898
21416.984
41.992
910.969
1683.301 44707.781

Table 8: Comparison of space required (in KB) for generating 100, 300, and 500 solutions
for complete alternating AND/OR trees with bounded length Open queue for ASG
and LASG

307

fiGhosh, Sharma, Chakrabarti, & Dasgupta

We show the effect of using bounded length queue to implement Open in Table 7 (reporting the time requirement) and in Table 8 (reporting the memory usage) for generating
100, 300, and 500 solutions, where the number of solutions to be generated are known beforehand. Table 7 and Table 8 show that in this case both ASG and LASG outperforms
BU in terms of time as well as space requirements. Particularly, ASG performs very well in
this setting, outperforming LASG in some cases.
5.1.2 Experimentation to Compare the Incremental Nature
The proposed top-down algorithms are incremental in nature whereas the existing bottomup approach is not incremental. After generating a specified number of ordered solutions,
our methods can generate the next solution incrementally without needing to restart itself,
whereas the existing approach needs to be restarted. For example, after generating the
first 10 ordered solutions, ASG and LASG generate the 11th solution directly from the data
structures maintained so far by these algorithms and perform necessary updates to these
data structures. Whereas, BU needs to be restarted with input parameter 11 for generating
the 11th solution. In Table 9 we compare the time needed to generate the subsequent 11th
solution and 12th solution incrementally after generating first 10 solutions. In order to have
more clarity in the comparison among the running times of the respective algorithms, we
have used higher precision (upto the 6th decimal place) while reporting the running time
in Table 9. Clearly, both ASG and LASG outperform BU for generating the 11th and 12th
solution in terms of the time requirement.
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

first 10
0.002403
0.009111
0.028519
0.097281
0.396460
1.561020
0.001692
0.012097
0.097356
0.934389
7.898530
0.005833
0.051598
0.813028
0.051530
0.172475
0.053422
0.502939
0.033831
1.198354

ASG
11th
0.000201
0.001957
0.003311
0.014776
0.063641
0.251839
0.000158
0.001542
0.013046
0.127943
1.082319
0.000650
0.006956
0.110205
0.001327
0.024262
0.002701
0.061417
0.003706
0.156145

12th
0.000201
0.001302
0.003533
0.015929
0.059229
0.277763
0.000151
0.001572
0.014405
0.156579
1.194090
0.000671
0.007196
0.124750
0.001641
0.024438
0.003092
0.069727
0.003846
0.166501

first 10
0.001003
0.003023
0.006700
0.025877
0.102493
0.446899
0.000683
0.004084
0.031159
0.311128
2.811539
0.002143
0.017046
0.294561
0.004638
0.059751
0.005282
0.184584
0.012862
0.466560

LASG
11th
0.000240
0.000714
0.001250
0.004113
0.014490
0.061422
0.000176
0.000583
0.003948
0.033169
0.282836
0.000303
0.002209
0.027612
0.000753
0.006116
0.000636
0.017116
0.001266
0.038792

12th
0.000123
0.000629
0.001346
0.004918
0.020031
0.082366
0.000112
0.000959
0.004604
0.047594
0.387715
0.000582
0.003115
0.037281
0.000652
0.007197
0.001087
0.024042
0.001282
0.061305

first 10
0.001344
0.003596
0.014628
0.059326
0.238418
0.962635
0.001055
0.009507
0.085610
0.778298
7.037050
0.004181
0.044913
0.727766
0.005963
0.152285
0.010895
0.406947
0.018185
0.929941

BU
11th
0.001359
0.003696
0.015046
0.061393
0.246042
0.989777
0.001101
0.009931
0.089379
0.811176
7.313715
0.004434
0.047867
0.775950
0.006358
0.162527
0.011604
0.435398
0.019567
0.989326

12th
0.001397
0.003895
0.015521
0.062717
0.251746
1.015848
0.001133
0.010336
0.093419
0.846578
7.608619
0.004725
0.050940
0.823442
0.006782
0.173191
0.012556
0.465301
0.020896
1.052566

Table 9: Comparison of running time (in seconds) for generating for first 10 solutions and
then the 11th solution and 12th solution incrementally for complete alternating
AND/OR trees

308

fiGenerating Ordered Solutions for Explicit AND/OR Structures

5.2 Multipeg Tower of Hanoi Problem
Consider the problem of Multipeg Tower of Hanoi (Majumdar, 1996; Gupta, Chakrabarti,
& Ghose, 1992). In this problem,  pegs are fastened to a stand. Initially  disks rest on
the source peg A with small disk on large disk ordering. The objective is to transfer all
 disks from A to the destination peg B with minimum legal moves. In a legal move, the
topmost disk from any tower can be transferred to any other peg with a larger disk as the
topmost disk. The problem of multi-peg tower of Hanoi can be solved recursively as follows.
a. Move recursively the topmost k (k varies from 1 to   1) disks from A to some
intermediate peg, I, using all the pegs.
b. Transfer the remaining   k disks from A to B recursively, using the (  1) pegs
available.
c. Recursively move k disks that were transferred to I previously, from the intermediate
peg I to B, using all the  pegs.
It may be noted that there is a choice for the value of k, which may take any value from 1
to   1. Solutions with different values of k may take different number of moves, and the
solution which incurs minimum number of moves is the optimal solution. This choice of
the value of k is modeled as an OR node, and for every such choice, the problem is divided
into three sub-problems. This decomposition into sub-problems is modeled as an AND
node. Therefore, the search spaces of the multi-peg Tower of Hanoi problem correspond to
alternating AND/OR trees.
#disks
8
9
10
11
12
13

100 solutions
ASG
LASG
BU
0.034
0.030
0.069
0.119
0.116
0.264
0.479
0.635
1.310
2.421
2.178
3.171
7.453
7.448 11.437
25.379 25.115 38.458

300 solutions
ASG
LASG
BU
0.104
0.084
0.252
0.314
0.289
0.942
1.706
1.658
3.305
6.573
6.161
12.998
21.232 21.081 43.358
68.574 67.170 140.392

500 solutions
ASG
LASG
BU
0.200
0.138
0.577
0.590
0.458
2.183
2.303
2.829
7.592
10.651
9.678
29.242
35.825
35.663
99.593
112.411 112.470 332.113

#Opt. No.
of Moves
23
27
31
39
47
55

Table 10: Comparison of running time (in seconds) for alternating AND/OR trees corresponding to the search spaces of 5-peg Tower of Hanoi problem with different
number of disks
#disks
8
9
10
11
12
13

100 solutions
ASG
LASG
BU
ASG
36.664
43.008
416.312
64.516
96.211
111.320
1471.656
131.266
295.672
341.000
5074.219
326.352
957.336
1113.508 17197.312
999.602
3155.086 3664.117 57512.812
3198.156
10339.078 12022.883 190297.969 10412.242

300 solutions
LASG
BU
ASG
80.734
660.062
105.039
154.266
2359.156
166.789
383.453
8161.719
373.453
1158.797 27728.562
1039.367
3719.352 92906.562
3247.547
12078.914 307872.969 10483.570

500 solutions
LASG
BU
117.008
903.812
197.859
3246.656
427.766
11249.219
1204.719 38259.812
3767.617 128300.312
12137.242 425447.969

Table 11: Comparison of space required (in KB) for alternating AND/OR trees corresponding to the search spaces of 5-peg Tower of Hanoi problem with different number
of disks
We have used the search space of 5 peg Tower of Hanoi problem with different number of
disks, , and generated alternative solutions in non-decreasing order of cost using ASG and
309

fiGhosh, Sharma, Chakrabarti, & Dasgupta

LASG algorithms. Here the cost function expresses the number of legal moves. The value
of  is varied from 8 to 13, and in Table 10 and in Table 11, we report the time required and
space required, respectively, for generating 100, 300, and 500 solutions for every test cases.
Experimental results show that the performance of ASG is similar to the performance of
LASG with respect to both space and time. However ASG as well as LASG outperforms
BU with respect to both time and space requirements.
5.3 Randomly Constructed AND/OR DAGs
We have constructed a set of randomly generated AND/OR DAGs and evaluated the ASG,
LASG, and BU algorithm for generating solutions under default semantics. We have used
the proposed extension to the BU algorithm for generating solutions under default semantics.
n

d

60
220
920
33
404
2124
9624
144
744
8844
40884

2
2
2
3
3
3
3
4
4
4
4

100 solutions
ASG LASG
BU
0.027 0.006 0.039
0.060 0.009 0.096
0.363 0.020 0.106
0.020 0.006 0.019
0.203 0.018 0.067
3.550 0.045 0.730
26.659 0.201 14.620
0.065 0.008 0.034
0.877 0.025 0.400
7.422 0.160 26.683
T
1.972
T

300 solutions
ASG
LASG
BU
0.089
0.021 0.158
0.281
0.030 1.100
2.485
0.059 0.266
0.123
0.021 0.098
1.483
0.048 0.257
30.302 0.126 1.681
257.605 0.612 33.382
0.348
0.027 0.217
6.910
0.069 0.994
69.097 0.449 66.558
T
5.819
T

500 solutions
ASG
LASG
BU
0.172
0.033
0.282
0.594
0.051
3.665
6.163
0.100
0.528
0.280
0.032
0.245
4.043
0.083
0.541
85.863 0.215
2.766
710.708 1.194 52.406
0.817
0.049
2.251
18.823 0.118
1.365
194.452 0.927 109.076
T
9.426
T

Table 12: Comparison of running time (in seconds) for generating 100, 300, and 500 solutions for AND/OR DAGs (T denotes the timeout after 15 minutes)
n

d

60
220
920
33
404
2124
9624
144
744
8844
40884

2
2
2
3
3
3
3
4
4
4
4

ASG
11.609
23.141
74.082
13.914
48.867
229.820
772.441
30.648
121.535
471.625
2722.938

100 solutions
LASG
BU
8.875
8.125
16.219
31.312
39.000
106.875
10.492
8.172
35.445
66.938
118.707
389.844
339.676 1996.875
17.332
29.609
65.578
287.109
266.078 2729.297
1256.535
T

ASG
32.852
62.516
220.648
46.117
151.363
705.809
2245.938
85.781
381.133
1183.379
T

300 solutions
LASG
BU
30.797
10.906
46.711
49.562
105.852
172.562
32.539
11.297
101.168
98.188
312.246
621.094
825.984 3321.875
53.961
73.359
168.305
737.891
550.477 6945.703
2353.562
T

ASG
54.094
100.555
371.344
77.445
262.816
1200.336
3732.523
140.312
659.434
1927.961
T

500 solutions
LASG
BU
50.035
13.250
74.379
65.188
168.375
230.375
54.602
14.422
163.273
129.438
507.762
852.344
1327.406 4646.875
93.539
86.641
275.594
883.984
843.484 8419.922
3447.809
T

Table 13: Comparison of space required (in KB) for generating 100, 300, and 500 solutions
for AND/OR DAGs

Table 12 and Table 13 compare the time required and space required for running ASG,
LASG and BU for generating 100, 300, and 500 solutions for every test cases. The first
and second columns of every row provide the size (n ) and the average out-degree (d) of
the DAG. The results obtained for this test domain are similar to the results for randomly
310

fiGenerating Ordered Solutions for Explicit AND/OR Structures

constructed AND/OR trees. It may be noted that in terms of both time and space required,
LASG outperforms both ASG and BU. Between ASG and BU, for most of the test cases
BU performs better than ASG with respect to the time required for generating a specific
number of solutions. Whereas, the space requirement of ASG and BU for generating a
specific number of solutions has an interesting co-relation with the average degree(d) and
the size (n ) parameter of the DAG. For low numerical values of the d and the n
parameter, e.g., (n , d) combinations like (60, 2), (33, 3) etc., BU performs better than
ASG. On the contrary, for the other combinations, where at least one of these n and d
parameter has a high value, e.g., (n , d) combinations like (920, 2), (9624, 3), (40884, 4)
etc., ASG outperforms BU.
5.4 Matrix-Chain Multiplication Problem
We have also used the well-known matrix-chain multiplication (Cormen, Stein, Rivest, &
Leiserson, 2001) problem for experimentation. The search space of the popular dynamic
programming formulation of this problem correspond to AND/OR DAG.
DAG
Cnstr.
#matrices
Time
(Sec)
20
0.033
30
0.200
40
0.898
50
3.033
60
8.335
70
19.591
80
41.960
90
82.578
100
151.814

Sopt
Cnstr.
Time
(Sec)
0.001
0.003
0.008
0.016
0.029
0.046
0.071
0.101
0.143

10 solutions

15 solutions

20 solutions

ASG

LASG

BU

ASG

LASG

BU

ASG

LASG

BU

0.003
0.009
0.019
0.047
0.088
0.140
0.209
0.296
0.409

0.002
0.008
0.018
0.048
0.090
0.142
0.212
0.300
0.412

0.206
2.785
15.580
93.267
342.212
862.387
T
T
T

0.004
0.012
0.024
0.062
0.118
0.187
0.280
0.396
0.546

0.003
0.010
0.024
0.065
0.120
0.190
0.282
0.398
0.548

0.288
4.087
23.414
140.513
509.906
T
T
T
T

0.005
0.015
0.030
0.079
0.148
0.235
0.351
0.496
0.688

0.004
0.012
0.030
0.081
0.151
0.238
0.354
0.499
0.683

0.373
5.406
31.112
187.227
678.718
T
T
T
T

Table 14: Comparison of time required (in seconds) for AND/OR DAGs corresponding to
the search spaces of matrix-chain multiplication with different number of matrices, (T denotes the timeout after 15 minutes)
#matrices
20
30
40
50
60
70
80
90
100

ASG
19.641
66.367
156.559
308.984
537.383
859.844
1290.117
1843.828
2537.582

10 solutions
LASG
20.203
69.273
160.227
315.012
545.117
869.160
1301.406
1857.480
2556.883

BU
160.918
555.684
1317.637
2563.965
4411.855
6978.496
T
T
T

ASG
20.543
67.809
157.738
310.277
538.930
862.133
1293.148
1847.602
2542.746

15 solutions
LASG
21.227
70.695
161.785
316.543
546.512
870.867
1303.426
1859.812
2560.043

BU
234.305
821.902
1960.281
3825.223
6592.508
T
T
T
T

ASG
21.914
69.516
158.758
311.551
539.914
863.977
1295.852
1851.164
2549.352

20 solutions
LASG
22.773
72.523
162.852
318.145
547.551
872.219
1305.090
1861.789
2566.992

BU
303.973
1081.902
2594.207
5075.262
8759.441
T
T
T
T

Table 15: Comparison of space required (in KB) for AND/OR DAGs corresponding to the
search spaces of matrix-chain multiplication with different number of matrices

Given a sequence of matrices, A1 , A2 ,    , An , of n matrices where matrix Ai has dimension pi1  pi , in this problem the objective is to find the most efficient way to multiply
311

fiGhosh, Sharma, Chakrabarti, & Dasgupta

these matrices. The classical dynamic programming approach works as follows. Suppose
A[i,j] denotes matrix that results from evaluating the product, Ai Ai+1    Aj , and m[i, j]
is the minimum number of scalar multiplications required for computing the matrix A[i,j] .
Therefore, the cost of optimal solution is denoted by m[i, j] which can be recursively defined
as :

m[i, j] =


0,

 min

ik<j



if i = j;
	
m[i, k] + m[k + 1, j] + pi1  pk  pj , if i < j.

The choice of the value of k is modeled as OR node and for every such choice, the problem
is divided into three sub-problems. This decomposition into sub-problems is modeled as
an AND node. It is worth noting that unlike the search space of 5-peg ToH problem, the
search space of the matrix-chain multiplication problem corresponds to AND/OR DAG.
We have used the search space for different matrix sequences having varying length and
generated alternative solutions in the order of non-decreasing cost. In Table 14, we report
the time required and in Table 15, we report the memory used for generating 10, 15, and
20 solutions for every test cases.
In Table 14, for each test case, we also report the time required for constructing the
explicit AND/OR DAG from the recursive formulation in the 2nd column, and the optimal
solution construction time in the 3rd column. It is interesting to observe that the relative
performance of ASG and LASG for this search space is very similar to that obtained for 5peg ToH search space though this search space for this domain is AND/OR DAG. Both ASG
and LASG perform approximately the same with respect to time and space requirement.
However, the advantage of ASG as well as LASG over BU with respect to both time and
space requirement is more significant in this domain.
5.5 Generating Secondary Structure for RNA
Another relevant problem where the alternative solutions play an important role is the
computation of the secondary structure of RNA. RNA molecules can be viewed as strings
of bases, where each base belongs to the set {Adenine, Cytocine, Guanine, U racil} (also
denoted as {A, C, G, U }). RNA molecules tend to loop back and form base pairs with itself
and the resulting shape is called secondary structure (Mathews & Zuker, 2004). The stability
of the secondary structure largely depends on the number of base pairings (in general, larger
number of base pairings implies more stable secondary structure). Although there are other
factors that influence the secondary structure, it is often not possible to express these other
factors using a cost function and they are typically evaluated empirically. Therefore, it is
useful to generate a set of possible alternative secondary structures ordered by decreasing
numbering of base pairings for a given RNA which can be further subjected to experimental
evaluation.
The computation of the optimal secondary structure considering the underlying principle of maximizing the number of base-pairings has a nice dynamic programming formulation (Kleinberg & Tardos, 2005). Given an RNA molecule B = hb1 b2    bn i where each
bi  {A, C, G, U }, the secondary structure on B is a set of base pairings, D = {(i, j)}, where
i, j  {1, 2,    n}, that satisfies the following conditions:
312

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Test Case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

Organism Name
Anaerorhabdus Furcosa
Archaeoglobus Fulgidus
Chlorobium Limicola
Desulfurococcus Mobilis
Haloarcula Japonica
Halobacterium Sp.
Mycoplasma Genitalium
Mycoplasma Hyopneumoniae
Mycoplasma Penetrans
Pyrobaculum Aerophilum
Pyrococcus Abyssi
Spiroplasma Melliferum
Sulfolobus Acidocaldarius
Symbiobacterium Thermophilum

# Bases
114
124
111
129
122
120
104
105
103
131
118
107
126
110

Table 16: Details of the RNA sequences used for Experimentation
a. if (i, j)  D, then i + 4 < j : This condition states that the ends of each pair in D are
separated by at least four intermediate bases.
b. The elements of any pair in D consists of either {A, U } or {C, G} (in either order).
c. No base appears in more than one pairings, i.e., D is a matching.
d. If (i, j) and (k, l) are two pairs in D, then it is not possible to have i < k < l < j, i.e.,
no two pairings can cross each other.
Test
Case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

DAG Cnstr.
Time (Sec)
34.464
57.999
26.423
83.943
51.290
46.508
16.766
22.775
18.831
91.419
47.660
22.649
67.913
28.911

Sopt Cnstr.
Time (Sec)
0.042
0.057
0.038
0.065
0.051
0.047
0.029
0.033
0.031
0.073
0.047
0.034
0.061
0.038

ASG
0.094
0.126
0.084
0.144
0.114
0.107
0.068
0.077
0.068
0.167
0.111
0.078
0.140
0.087

5 solutions
LASG
BU
0.095 449.916
0.128 823.493
0.089 363.421
0.152 1089.462
0.116 681.429
0.108 598.419
0.069 210.806
0.078 284.455
0.072 233.999
0.170
T
0.109 627.744
0.079 288.520
0.141 962.641
0.085 366.693

ASG
0.145
0.193
0.135
0.230
0.176
0.166
0.101
0.120
0.109
0.249
0.173
0.116
0.206
0.134

10 solutions
LASG
BU
0.148 893.682
0.198
T
0.133 718.326
0.227
T
0.180 1349.181
0.175
T
0.103 410.817
0.122 559.318
0.111 458.290
0.263
T
0.171 1253.034
0.123 573.602
0.218
T
0.137 724.113

ASG
0.197
0.271
0.183
0.314
0.239
0.226
0.136
0.153
0.144
0.347
0.220
0.165
0.290
0.182

15 solutions
LASG
BU
0.202 1359.759
0.277
T
0.186 1077.094
0.317
T
0.245
T
0.238
T
0.144 621.792
0.165 836.359
0.148 683.411
0.355
T
0.240
T
0.167 849.134
0.288
T
0.186 1072.552

Table 17: Comparison of time required (in seconds) for AND/OR DAGs corresponding to
the search spaces of RNA secondary structure with different number of bases (T
denotes the timeout after 30 minutes)

Under the above mentioned conditions the dynamic programming formulation is as follows.
Suppose P (i, j) denotes the maximum number of base pairings in a secondary structure on
bi    bj . P (i, j) can be recursively defined as :
P [i, j] =


0,

n

	 o
max P [i, j  1], max 1 + P [i, k  1] + P [k + 1, j  1] ,
ik<j

313

if i + 4  j,

if i + 4 < j.

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Here, a choice of the value of k is modeled as an OR node and for every such choice,
the problem is divided into three sub-problems. This decomposition into sub-problems is
modeled as an AND node. We have experimented with the search space of this problem for
the set of RNA molecule sequences obtained from the test-cases developed by Szymanski,
Barciszewska, Barciszewski, and Erdmann (2005). The details of the test cases are shown
in Table 16.
For every test cases, we report the time required in Table 17 for generating 5, 10, and 15
solutions. For the same setting, the space required is reported in Table 18. In Table 17, for
each test case, we also report the time required for constructing the explicit AND/OR DAG
from the recursive formulation in the 2nd column, and the time required for constructing the
optimal solution time in the 3rd column. We use a high value of time-out (1800 seconds) in
order to gather the running time required by BU. We limit the maximum solutions generated
at 15 because for generating higher number of solutions, BU is timed out for most of the
test cases. It is worth noting that the result obtained for this domain is very similar to the
result obtained for the matrix-chain multiplication problem domain. Both space and time
wise ASG and LASG perform similarly and they outperform BU significantly with respect
to time as well as space requirement.
Test
Case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

ASG
1647.555
2254.531
1473.852
2606.242
2045.930
1912.227
1101.125
1293.812
1170.094
2984.773
1974.695
1295.141
2438.898
1475.477

5 solutions
LASG
1694.688
2310.008
1516.922
2665.820
2097.414
1963.367
1138.633
1333.336
1207.633
3047.539
2022.906
1335.883
2496.469
1517.828

BU
7409.336
9902.953
6629.891
11358.945
9021.273
8499.570
5087.680
5855.547
5352.477
T
8641.422
5924.664
10657.945
6627.844

ASG
1651.273
2258.773
1477.492
2610.875
2049.844
1916.422
1104.422
1297.750
1173.023
2990.211
1979.344
1297.273
2442.961
1478.555

10 solutions
LASG
1697.797
2315.258
1521.750
2671.711
2101.836
1968.305
1142.023
1338.070
1211.523
3053.977
2030.922
1339.516
2502.625
1521.352

BU
14656.469
T
13103.492
T
17875.430
T
10036.938
11560.203
10562.766
T
17119.820
11701.695
T
13099.055

ASG
1654.367
2262.492
1480.555
2615.719
2052.867
1921.117
1108.047
1302.242
1176.352
2994.773
1983.664
1299.805
2447.172
1482.234

15 solutions
LASG
1700.492
2318.008
1526.797
2675.633
2106.000
1972.172
1144.109
1342.484
1213.906
3059.781
2038.461
1341.914
2506.703
1525.344

BU
21846.156
T
19518.625
T
T
T
14924.820
17211.406
15718.617
T
T
17420.719
T
19519.742

Table 18: Comparison of space required (in KB) for AND/OR DAGs corresponding to the
search spaces of RNA secondary structure with different number of bases

5.6 Observations
The experimental data shows that the LASG algorithm generally outperforms the ASG
algorithm and the existing bottom-up approach in terms of the running time for complete
alternating AND/OR trees and AND/OR DAGs. Whereas, for the other problem domains,
i.e., the 5-peg Tower of Hanoi problem, the matrix-chain multiplication problem, and the
problem of determining secondary structure of RNA sequences, the overall performance of
the ASG algorithm is similar to the performance of the LASG algorithm. This behavior
can be explained from the average and maximum length statistics of Open list, reported in
Table 19 - Table 23, for these above mentioned test domains.
314

fiGenerating Ordered Solutions for Explicit AND/OR Structures

In the case of complete trees and random DAGs, for ASG algorithm, the average as well
as the maximum size of Open grows much faster than that of LASG algorithm (Table 19
and Table 20), with the increase in the size of the tree/DAG.
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

100 solutions
ASG
LASG
avg.
max.
avg. max.
235
383
75
159
994
1894
73
120
2427
4709
156
306
5546
10947
524
1149
11744
23291
384
523
24264
48333
655
841
304
549
120
242
1561
3015
172
346
5496
10899
191
289
17336
34542
486
691
53139 106155
1138 1216
734
1427
103
176
3748
7383
194
381
16282
32451
422
488
1216
2352
146
307
7261
14446
249
335
1781
3489
141
276
12362
24651
297
342
2433
4765
261
508
19311
38435
450
529

300 solutions
ASG
LASG
avg.
max.
avg. max.
435
629
179
289
2657
4931
220
528
6935
13537
483
1005
16266
32076
1550 2726
34836
69160
677
1121
T
T
1087 1611
740
1323
341
652
4359
8400
579
1260
16272
32244
387
661
51954 103549
956
1754
T
T
1267 1569
2062
4006
256
503
10928
21489
678
1467
48786
97196
687
1131
3407
6555
496
1053
21652
42972
470
888
5089
9911
507
1126
36868
73323
461
789
7072
13910
747
1483
57754 115116
687
961

500 solutions
ASG
LASG
avg.
max.
avg. max.
545
792
236
372
4103
7569
449
1069
11251
21843
851
1771
26748
52724
2261 3844
57673 114367
983
1824
T
T
1527 2819
1107
1972
539
1007
7026
13588
1012 2084
26904
53271
622
1368
T
T
1460 2672
T
T
1432 1776
3322
6375
452
1065
17932
35222
1265 2837
T
T
1025 1807
5508
10694
852
1742
35850
71054
832
1781
8250
16035
971
2164
61221 121958
749
1573
11595
22809
1204 2273
T
T
984
1922

Table 19: Average and maximum length of Open while generating 100, 300, and 500 solutions for complete alternating AND/OR trees
n

d

60
220
920
33
404
2124
9624
144
744
8844
40884

2
2
2
3
3
3
3
4
4
4
4

100 solutions
ASG
LASG
avg.
max.
avg. max.
181
338
39
63
479
854
77
133
1530
2957
116
227
202
409
58
102
1001
1969
236
447
5008
9911
374
626
14422 28666
394
491
510
990
56
101
2407
4760
253
485
7522
14931
258
437
T
T
749
804

300 solutions
ASG
LASG
avg.
max.
avg. max.
428
768
131
282
1144
2058
210
417
4289
8278
332
639
604
1193
154
281
2958
5799
675 1256
14803 29314
851 1569
43087 85825
746 1339
1374
2563
187
458
7166
14204
590 1018
22254 44062
847 1831
T
T
852 1004

500 solutions
ASG
LASG
avg.
max.
avg. max.
643
1138
219
411
1721
3139
329
612
6902
13305
512
946
978
1875
234
422
4874
9781
1013 1810
24442
48357
1337 2527
71547 142327
1254 2756
2140
3996
376
868
11874
23558
885
1655
36743
72740
1565 3493
T
T
961
1215

Table 20: Average and maximum length of Open while generating 100, 300, and 500 solutions for randomly constructed AND/OR DAGs

Since ASG algorithm checks for the presence of duplicates while expanding a solution, the
time required for duplication checking grows rapidly for these test domains. Hence, the
overall time required for generating a specific number of solutions also increases rapidly
(faster than both BU and LASG) with the increase in the size of the tree/DAG. As a result,
BU outperforms ASG with respect to the time requirement for trees and DAGs. However
315

fiGhosh, Sharma, Chakrabarti, & Dasgupta

the memory used for generating a specific number of solutions increases moderately (slower
than BU) with the increase in the size of the tree/DAG. Therefore with respect to space
requirement, ASG outperforms BU for larger trees and DAGs.
Between LASG and BU, the time as well as the memory requirement of BU increases
faster than that of LASG when the degree of the AND/OR tree or DAG increases. This
happens because, for BU, the time taken for merging the sub-solutions at the AND nodes
and memory required for storing alternative solutions that are rooted at different nodes
increases rapidly with the increase in the degree of that node.
On the contrary, for the other test domains, 5-peg Tower of Hanoi problem, matrix-chain
multiplication problem, and the probelm of finding secondary structure of RNA sequences,
the average and the maximum size of Open for both ASG and LASG are comparable (Table 21, Table 22 and Table 23). Therefore, for the LASG algorithm, the time saved by
avoiding the duplication checking is compensated by the extra overhead of maintaining the
solution space tree and the checks required for lazy expansion. Hence the running time as
well as the space requirement are almost same for both algorithms for these three above
mentioned problem domains.
Moreover, due to the low values of the average and the maximum size of Open, ASG
outperforms BU with respect to both time requirement and memory used for these three
test domains. For these three domains also, between LASG and BU, the time as well as the
memory requirement of BU increases faster than that of LASG when the size of the search
space (AND/OR tree or DAG) increases.

6. Ramifications on Implicitly Specified AND/OR Structures
In this section, we briefly discuss use of our proposed algorithms for generation of alternative
solutions in the non-decreasing order of cost for implicit AND/OR search spaces. One
possible way is to extend the standard AO for generating a given number of solutions,
say k, as follows. Instead of keeping only one potential solution graph(psg), at any stage k
psgs can be computed on the explicitly constructed search space and instead of expanding
one node, k nodes, (that is, one node from each psg), can be expanded at once. After
expanding the nodes, k psgs are recomputed once again. Since the cost of the nodes are
often recomputed after expanding nodes, the swap options associated with any such node
have to be updated after every such recomputation.
Another possible approach could be to run AO until it generates the optimal solution.
At this point of time the swap options can be computed on the explicit portion of the
graph and swap option with minimum cost can be applied to the optimal solution. Then
the resulting psg is again expanded further resulting in the expansion of the explicit graph.
The swap options are re-evaluated to incorporate the cost update. Again the next best psg
is computed. This process continues till the second best solution is derived. Now among the
remaining successor psgs of the first solution and the successor psgs of second solution, the
most promising psg is selected and expanded. This process continues till the third solution
is found. Then the successor psgs are also added to the already existing pool of candidate
psgs. These two broad steps, (a) selecting the next best psg from the pool of candidate
psgs, and then (b) keeping on expanding the explicit graph till the next best solution is
found, is continued till k solutions are found.
316

fiGenerating Ordered Solutions for Explicit AND/OR Structures

# disks
8
9
10
11
12
13

100 solutions
ASG
LASG
avg. max. avg. max.
55
92
41
68
66
122
42
71
109
183
53
79
132
218
76
140
219
385
85
147
259
482
118
200

300 solutions
ASG
LASG
avg. max. avg. max.
111
186
91
174
163
331
119
252
216
367
142
283
296
611
177
373
473
776
234
492
675 1240
252
437

500 solutions
ASG
LASG
avg. max. avg. max.
174
375
135
235
265
484
198
382
345
693
234
447
486
882
291
558
668
1200
404
724
1016 1828
377
697

Table 21: Average and maximum length of Open while generating 100, 300, and 500 solutions for 5-peg Tower of Hanoi problem with different number of disks
# matrices
20
30
40
50
60
70
80
90
100

10 solutions
ASG
LASG
avg. max. avg. max.
46
87
25
39
84
162
71
126
73
123
58
90
86
151
75
126
91
144
76
112
136
234
85
122
181
324
94
132
226
414
103
142
307
576
167
259

15 solutions
ASG
LASG
avg. max. avg. max.
68
121
34
59
123
230
94
157
98
182
73
129
120
211
100
169
118
189
94
137
188
329
103
147
258
469
112
157
328
609
122
167
445
823
216
337

20 solutions
ASG
LASG
avg. max. avg. max.
90
176
46
95
160
293
116
192
125
226
90
152
151
266
123
205
151
267
108
160
243
437
117
170
335
607
127
180
427
777
136
190
583 1145
262
477

Table 22: Average and maximum length of Open while generating 10, 15, and 20 solutions
for matrix-chain multiplication problems
Test case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

5 solutions
ASG
LASG
avg. max. avg. max.
45
84
41
74
50
95
50
95
47
90
46
89
50
93
49
90
47
86
45
74
49
93
47
84
42
81
42
80
46
89
44
84
40
77
39
73
59
116
59
113
55
106
54
105
33
64
31
51
51
98
51
97
41
78
40
73

10 solutions
ASG
LASG
avg. max. avg. max.
93
176
75
125
100
192
94
170
90
168
82
142
101
194
87
155
98
186
87
149
105
200
95
168
83
157
73
119
97
188
86
159
80
147
70
119
128
251
116
212
115
225
110
211
67
116
55
98
103
193
100
185
82
154
69
112

15 solutions
ASG
LASG
avg. max. avg. max.
135
249
95
143
146
266
125
197
132
244
115
210
152
292
119
197
140
246
114
184
155
294
127
206
121
231
92
138
144
277
120
214
115
214
93
146
189
350
161
280
171
317
166
321
95
172
78
135
149
276
140
239
120
231
97
176

Table 23: Average and maximum length of Open while generating 5, 10, and 15 solutions
for generating secondary structure of RNA sequences

317

fiGhosh, Sharma, Chakrabarti, & Dasgupta

It is important to observe that both methods heavily depend on incorporating the updates in the explicit DAG like adding nodes, increase in the cost, etc., and recomputing the
associated swap options along with the signatures that use those swap options. Handling
dynamic updates in the DAG efficiently and its use in implicit AND/OR search spaces
remains an interesting future direction.

7. Conclusion
In our work we have presented a top-down algorithm for generating solutions of a given
weighted AND/OR structure (DAG) in non-decreasing order of cost. Ordered solutions
for AND/OR DAGs are useful for a number of areas including model based programming,
developing new variants of AO*, service composition based on user preferences, real life
problems having dynamic programming formulation, etc. Our proposed algorithm has two
advantages  (a) it works incrementally, i.e., after generating a specific number of solutions,
the next solution is generated quickly, (b) if the number of solutions to be generated is
known a priori, our algorithm can leverage that to generate solutions faster. Experimental
results show the efficacy of our algorithm over the state-of-the-art. This also opens up
several interesting research problems and development of applications.

8. Acknowledgments
We thank the anonymous reviewers and the editor, Prof. Hector Geffner, for their valuable
comments which have enriched the presentation of the paper significantly. We also thank
Prof. Abhijit Mitra, International Institute of Information Technology, Hyderabad, India,
for his valuable inputs regarding the test domain involving secondary structure of RNA. We
thank Aritra Hazra and Srobona Mitra, Research Scholar, Department of Comp. Sc. &
Engg., Indian Institute of Technology Kharagpur, India, for proof reading the paper.

Appendix A. Proof of Correctness of Algorithm 4
Lemma A.1 Every solution other than the optimal solution Sopt can be constructed from
Sopt by applying a sequence of swap options according to the order R.
Proof: [Lemma A.1] Every solution other than Sopt of an alternating AND/ OR tree T
is constructed by choosing some non optimal edges at some OR nodes. Consider any other
solution Sm , corresponding to which the set of non-optimal OR edges is S and suppose
|S  | = m. We apply the relation R to S to obtain an ordered sequence  of OR edges
where e1 , e2  , e1 appears before e2 in  if (e1 , e2 )  R. We show that there exists a
sequence  of swap options that can be constructed for S . For every OR edge eij of 
(here eij is the ith edge of  and 1  i  m), we append the subsequence of OR edges
ei1 , . . . , eij 1 before eij , where ei1 , . . . , eij are the OR edges that emanate from the same
parent vq , and ei1 , . . . , eij 1 are the first ij  1 edges in L(vq ).
We get a sequence of OR edges aug from  by the above mentioned augmentation.
aug is basically a concatenation of subsequences 1 , . . . , m , where i is a sequence of edges
ei1 , . . . , eij such that ei1 , . . . , eij are the OR edges that emanate from the same parent vq ,
and ei1 , . . . , eij are the first ij edges in L(vq ). We construct  from aug as follows. From
318

fiGenerating Ordered Solutions for Explicit AND/OR Structures

every i , we construct i = hi1 ,i2 , . . . , ij 1,ij i, where ik ,ik +1 = heik , eik +1 , ik ,ik +1 i and
i1  ik  (ij  1).  is constructed by concatenating every individual i . Hence there exists
a sequence of swap options  corresponding to every other solution Sm .


Definition A.p [Default Path] From Lemma A.1, every non-optimal solution Sm can
be constructed from the initial optimal solution by applying a sequence of swap options,
(Sm ), according to the order R. The sequence of solutions that is formed following (Sm )
corresponds to a path from Sopt to Sm in SSDAG G s . This path is defined as the default
path, Pd (Sm ), for Sm .
Lemma A.2 The SSDAG of an alternating AND/OR tree T contains every alternative
solution of T .
Proof: [Lemma A.2] We prove this by induction on the length of the default path Pd of
the solutions.
[Basis (n = 1) :] Consider the swap list of Sopt . The solutions whose default path length
is equal to 1 form the Succ(Sopt ). Therefore these solutions are present in G.
[Inductive Step :] Suppose the solutions whose default path length is less than or equal
to n are present in G. We prove that the solutions having default path length equal to
n + 1 are also present in G. Consider any solution Sm where Pd (Sm ) = n + 1. Let (Sm ) =
 where (S  ) = h ,    ,  i. Since P (S  ) =
h1 ,    , n , n+1 i. Consider the solution Sm
1
n
d m
m
s


  V, and swap option 
n, Sm
n+1  L(Sm ), there is a directed edge from Sm to Sm in G .
Hence every solution having a default path length equal to n + 1 is also present in G.


Lemma A.3 For any alternating AND/OR tree T , Algorithm 4 adds solutions to Closed
(at Line 11) in non-decreasing order of cost.
Proof: [Lemma A.3] Consider the following invariants of Algorithm 4 that follow from
the description of Algorithm 4.
a. The minimum cost solution from Open is always removed at Line 6 of Algorithm 4.
b. The cost of the solutions that are added in Open, while exploring the successor set of
a solution Sm (at Line 13 of Algorithm 4), are greater than or equal to C(Sm ).
From these two invariants it follows that Algorithm 4 adds solutions to Closed (at Line 11)
in non-decreasing order of cost.
Lemma A.4 For any alternating AND/OR tree T , for every node of the SSDAG of T ,
Agorithm 4 generates the solution corresponding to that node.
Proof: [Lemma A.4] From Lemma A.3 it follows that Algorithm 4 generates the solutions
in the non-decreasing order of cost. By generating a solution Sm , we mean adding Sm to
Closed (at line 11 of Algorithm 4). For the purpose of proof by contradiction, let us assume
that Algorithm 4 does not generate solution Sm . Also let Sm be the first occurrence of this
319

fiGhosh, Sharma, Chakrabarti, & Dasgupta

scenario while generating solutions in the mentioned order. According to Lemma A.1, there
exists a sequence of swap options  = 1 , . . . , k corresponding to Sm . Also consider the
 whose sequence of swap options is  =  , . . . , 
solution Sm
1
k1 . According to Property 3.2,

C(Sm )  C(Sm ). Consider the following two cases:
 ) < C(S ): Since S
a. C(Sm
m
m is the first instance of the incorrect scenario, and Algo is generated
rithm 4 generates the solutions in the non-decreasing order of cost, Sm
prior to Sm .
 ) = C(S ): Since Algorithm 4 resolves the tie in the favor of the parent solution,
b. C(Sm
m
 will be
and Sm is the first instance of the incorrect scenario  in this case also Sm
generated prior to Sm .
 . When S  was generated by Algorithm 4,
The swap option k belongs to the swap list of Sm
m


that is, when Sm was added to Closed, Sm was also expanded and the solutions which can
 applying one swap option, were added to the Open list. Since S
be constructed from Sm
m
 applying one swap option  , S
was constructed from Sm
was
also
added
to
the
Open
m
k
 . Therefore S
while exploring the successors of Sm
m will also be eventually generated by
Algorithm 4 - a contradiction.



Lemma A.5 For any alternating AND/OR tree T , Algorithm 4 does not add any solution
to Closed (at Line 11 of Algorithm 4) more than once.
Proof: [Lemma A.5] For the purpose of contradiction, let us assume that Sm is the first
solution that is added to Closed twice. Therefore Sm must have been added to Open twice.
Consider the following facts.
a. When Sm was added to Closed for the first time, the value of lastSolCost was C(Sm ),
and Sm was added to TList.
b. From the description of Algorithm 4 it follows that the contents of TList are deleted
only when the value of lastSolCost increases.
c. From Lemma A.3 it follows that Algorithm 4 generates the solutions in non-decreasing
order of cost. Hence, when Sm was generated for the second time, the value of
lastSolCost did not change from C(Sm ).
From the above facts it follow that Sm was present in TList when Sm was added to Open
for the second time. Since, while adding a solution to Open, Algorithm 4 checks whether it
is present in TList (at Line 16 of Algorithm 4); Algorithm 4 must had done the same while
adding Sm to Open for the second time. Therefore Sm could not be added Open for the
second time  a contradiction.


Theorem A.1 Sj  V, Sj is generated (at Line 11) by Algorithm 4 only once and in the
non-decreasing order of costs while ties among the solutions having same costs are resolved
as mentioned before.
Proof: [Theorem A.1] Follows from Lemma A.2, Lemma A.3, Lemma A.4 and Lemma A.5.


320

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Appendix B. Proof of Correctness of Algorithm 5
Definition B.q [Reconvergent Paths in Solution Space DAG] Two paths, (i) p1 =
Si11      Si1n and (ii) p2 = Si21      Si2m , in the SSDAG G s of an alternating
AND/OR tree T are reconvergent if the following holds:
a. Si11 = Si21 , i.e. the paths start from the same node;
b. Si1n = Si1m , i.e. the paths ends at the same node;

c. (j  [2, n  1])(k  [2, m  1]), Si1j 6= Si2k ; i.e. the paths do not have any common
intermediate node.
Definition B.r [Order on Generation Time] In the context of Algorithm 5, we define an
order relation, t  V  V, where (Sp , Sq ) t if Sp is generated by Algorithm 5 before Sq .
Here V is set of vertices in SSDAG G s of an alternating AND/OR tree T .
Lemma B.1 Algorithm 5 adds the solutions to the Closed list in the non-decreasing order
of costs.
Proof: [Lemma B.1] Consider the following invariants of Algorithm 5 that follow from
the description of Algorithm 5.
a. The minimum cost solution from Open is always removed at line 11 of Algorithm 4.
b. Algorithm 5 expands any solution, say Sp , in two phases. At the first phase Sp is
expanded using the native swap options of Sp . The solutions that are added to Open
as a result of the application of the native swap options, will have cost greater than or
equal to C(Sp ). In the second phase, i.e., during lazy expansion, Sp is again expanded
using a non native swap option. A solution Sp may undergo the second phase  times
where 0    (|L(Sp )|  |N (Sp , k )|) and k is used to construct Sp . In every lazy
expansion of Sp , a new solution is added to Open. Consider a solution Sm which is
 using  by Algorithm 5 where S   P red(S ). Suppose swap
constructed from Sm
m
j
m
option i  L(Sm ), and i 
/ N (Sm , j ), i.e., i is not a native swap option of Sm .
 ). Suppose S and S  are the successors of S and S  respectively,
Clearly i  L(Sm
m
c
m
c
i
i
 
constructed by the application of i , i.e., Sm
 Sc , and Sm 
Sc . Also let Sc is
added to Closed after Sm .
Consider the fact that Algorithm 5 does not apply swap option i to Sm , that is, Sc is
 )  C(S ), C(S  )  C(S ).
not added to Open until Sc is added to Closed. Since C(Sm
m
c
c
According to Algorithm 5, i is applied to Sm (during the lazy expansion), and Sc is
added to Open right after Sc is added to Closed. Consider the time period between
adding Sm and adding Sc to Closed. During that period, every solution that is added
to Closed has cost between C(Sm ) and C(Sc ), i.e., the cost is less or equal to C(Sc ). In
general, the application of a swap option to add a solution to Open is delayed by such
an amount of time, say , so that all the solutions, which are added to Closed during
this  time interval, have cost less than or equal to the solution under consideration.
321

fiGhosh, Sharma, Chakrabarti, & Dasgupta

From the above facts it follow that Algorithm 5 adds the solutions to the Closed list in
non-decreasing order of costs.


Lemma B.2 Any two reconvergent paths in the SSDAG G s of an alternating AND/OR
tree T are of equal length.
Proof: [Lemma B.2] Consider the paths:












1
2
n
1
2
(i) p1 = S1 
Sp 
   
Sn , and (ii) p2 = S1 
Sp 
   m
 Sn .

The edges in the paths represent the application of a swap option to a solution. Now p1
and p2 start from the same solution and also end at the same solution. Therefore the sets of
swap options that are used in these paths are also same. Hence the lengths of those paths
are equal, that is, in the context of p1 and p2 , n = m.
Lemma B.3 For any set of reconvergent paths of any length n, Algorithm 5 generates at
most one path.
Proof: [Lemma B.3] The following cases are possible.
[Case 1 (n = 2) :] Consider the following two paths:








1
2
1
2
(i) p1 = S1 
S2 
S3 , and (ii) p2 = S1 
S2 
S3 .

It is obvious that 1 = 2 and 2 = 1 . Suppose S2 t S2 . Here Algorithm 5 does not
apply the swap option 1 to S2 . Therefore p2 is not generated by Algorithm 5.
[Case 2 (Any other values of n) :] In this case, any path belonging to the set of reconvergent paths, consists of n different swap options, suppose 1 ,    , n . Also the start
node and the end node of the paths under consideration are Sp and Sm . Consider the nodes
in the paths having length 1 from Sp . Clearly there can be n such nodes.
Among those nodes, suppose Algorithm 5 adds Sp1 to Closed first, and Sp1 is constructed
from Sp by applying swap option 1 . According to Algorithm 5, 1 will not be applied to
any other node that is constructed from Sp and is added to Closed after Sp1 . Therefore,
all those paths starting from Sp , whose second node is not Sp1 , will not be generated by
Algorithm 5. We can use the similar argument on the paths from Sp1 to Sm of length n  1
to determine the paths which will not be generated by Algorithm 5. At each stage, a set of
paths will not be grown further, and at most one path towards Sm will continue to grow.
After applying the previous argument n times, at most one path from Sp to Sm will be
constructed. Therefore Algorithm 5 will generate at most one path from Sp to Sm .


Definition B.s [Connection Relation Rc and Rc ] We define connection relation, Rc , a
symmetric order relation for a pair of OR nodes, vq and vr , belonging to an alternating
AND/OR tree T as:
(vq , vr )  Rc | if in T there exists an AND node vp , from which
there exist two paths, (i) p1 = vp  . . .  vq , and

(ii) p2 = vp  . . .  vr
322

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Similarly the connection relation, Rc , is defined between two swap options as follows. Consider two swap options iq and jr , where iq = hei , eq , iq i and jr = hej , er , jr i. Suppose
OR edges ei and eq emanate from vp , and OR edges ej and er emanate from vt . Now
(iq , jr )  Rc if (vp , vt )  Rc .
Definition B.t [Mutually Connected Set] For a solution Sm , a set Vm of OR nodes is
mutually connected, if

v1 , v2  Vm , (v1 6= v2 )  {(v1 , v2 )  Rc }
Consider the set of OR nodes, Vm = {v1 ,    , vk }, where swap option j belongs to vj and
1  j  k. Here the set of swap options Vm = {1 ,    , k } is mutually connected.
Lemma B.4 Suppose Sm is a solution of an alternating AND/OR tree T , P red(Sm ) =
{S1 ,    , Sk }, and swap option j is used to construct Sm from Sj where 1  j  k. The
swap options 1 ,    , k are mutually connected.
Proof: [Lemma B.4] Since Sm is constructed from S1 ,    , Sk by applying 1 ,    , k respectively, 1 ,    , k are present in the signature of Sm . Suppose set s = {1 ,    , k }.
We have to show that

a , b  s , (a , b )  Rc

For the purpose of proof by contradiction, let us assume (i1 , i2 ) 
/ Rc . Also Sm is constructed by applying i1 and i2 to Si1 and Si2 respectively. Consider the path p1 in SSDAG
of T which starts from Sopt and ends at Sm , and along p1 , Si1 is the parent of Sm . Now
along this path, i2 is applied before the application of the swap option i1 . Similarly consider the path p2 in SSDAG of T which starts from Sopt and ends at Sm , and along p2 ,
Si2 is the parent of Sm . Along this path, i1 is applied before the application of the swap
option i2 .
Suppose i1 and i2 belongs to OR node v1 and v2 respectively. Since along path p1 , i1
is the swap option which is applied last, Sm contains node v1 . Similarly along path p2 , i2
is the swap option which is applied last. Hence Sm contains node v2 . Therefore, there must
be an AND node vr in T , from which there exist paths to node v1 and v2  implies that
(i1 , i2 )  Rc . We arrive at a contradiction that proves 1 ,    , k are mutually connected.



Definition B.u [Subgraph of SSDAG] Consider a solution Sp of an alternating AND/OR
tree Tand mutually connected set Vm of OR nodes in Sp , where vq  Vm , C(Sp , vq ) =
s (S , V ) = hV
Copt (vq ) . The subgraph Gsub
p m
sub , Esub i of the SSDAG with respect to Sp and
Vm is defined as follows. Vsub consists of only those solutions which can be constructed from
Sp by applying a sequence of swap options belonging to Vm , and Esub is the set of edges
corresponding to the swap options that belong to Vm .
s (S , V )
Lemma B.5 The number of total possible distinct solutions at each level d in Gsub
p m

,
where
|V
|
=
n.
is n+d2
m
n1

323

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Proof: [Lemma B.5] Consider the swap options that belong to the nodes in Vm . With
s (S , V ) is represented by a sequence
respect to these swap options, every solution Sr in Gsub
p m
of numbers of length n, Seq(Sr ), where every number corresponds to a distinct node in Vm .
The numerical value of a number represent the rank of the swap option that is chosen for
a node vq  Vm . According to the representation, at each level:
i. the sum of numbers in Seq(Sr ) of a solution, Sr , is equal to the sum of numbers in
Seq(Sr ) of any other solution, Sr , in that same level;
ii. the sum of numbers in Seq(Sr ) of a solution, Sr , is increased by 1 from the sum of
numbers in Seq(Sr ) of any solution, Sp , of the previous level.
Hence, at the dth level, there are n slots and d  1 increments that need to be made to
Seq(Sr ). This is an instance of the well known combinatorial problem of packing n + d  1
objects in n slots
with the restriction of keeping at least one object per slot. This can be
n+d2
done in n1 ways.


Theorem B.1 The solution space tree constructed by Algorithm 5 is complete.
Proof: [Theorem B.1] For the purpose of contradiction, suppose Sm is the first solution
which is not generated by Algorithm 5. Also P red(Sm ) = {Spi } and Sm can be constructed
from Spi by applying qi , where 1  i  k. From Lemma B.4 it follows that the set of
swap options {qi | 1  i  k} is mutually connected. Therefore the set of OR nodes Vm to
which the swap options belong is also mutually connected. Suppose |Vm | = n.
Consider the solution Sq , where Vm is mutually connected, and for 1  i  k, every qi
belongs to the set of native swap options of Sq with respect the swap option that is used to
construct Sq . Clearly

vt  Vm , C(Sq , vt ) = Copt (vt )

We argue that Sq is generated by Algorithm 5 because Sm is the first solution which is
s of T s rooted at S , where only
not generated by Algorithm 5. Consider the subtree Tsub
q
the edges corresponding to swap options that belong to Vm are considered. Now we prove
s is equal to the
that the number of solutions generated by Algorithm 5 at every level of Tsub
s
number of solutions at the same level in Gsub (Sq , Vm ).
Consider the solution Sq and the set Succ(Sq ). Suppose Succ(Sq , Vm ) is the set of
successor solutions that are constructed from Sq by applying the swap options belonging

is the minimum cost solution in Succ(Sq , Vm ). According to
to the nodes in Vm , and Smin

Algorithm 5 initially Succ(Smin ) is partially explored by using the set of native swap options

of Smin
. Any other non native swap option, b , that belongs to the nodes in Vm , is used to


explore Succ(Smin
), right after the sibling solution of Smin
, constructed by applying b to Sq,
is added to Closed. Consider the fact that for solution Sq , vt  Vm , C(Sq , vt ) = Copt (vt )
holds. Therefore all the swap options belonging to Vm will also be eventually used to explore

the successors of Smin
. Similarly the second best successor of Sq will be able use all but

.
one swap option, c , which is used to construct Smin

s
The immediate children of Smin in Tsub will consist of all solutions, that can be obtained


by the application of one swap option in Vm to Smin
. The native swap list of Smin
contains
the swap option ranking next to c . The swap options, that are used to construct the other
324

fiGenerating Ordered Solutions for Explicit AND/OR Structures


n  1 sibling solutions of Smin
, will be used again during lazy expansion, which accounts


for another n  1 children of Smin
. Hence there would be n children of Smin
.
s
Similarly, the second best successor of Sq in Tsub will have n  1 immediate children.
s will have n  2 children and so on. Now the children
The third best successor of Sq in Tsub
of these solutions will again have children solutions of their own, increasing the number
of solutions at each level of the tree. This way, with each increasing level, the number of
solutions present in the level keeps increasing. We prove the following proposition as a part
of proving Theorem B.1.
s ) is given by
Proposition B.1 At any level d, the number of solutions N (d, n, Tsub


n
X
n+d2
s
s
N (d, n, Tsub ) =
N (d  1, k, Tsub ) =
n1
k=1

Proof: [Proposition B.1] At second level, there are n solutions. These give rise to

k=1

k+

n1
X

k+

k=1

n2
X
k=1

k

k=1

solutions at third level. Similarly at fourth level we have
n
X

n
X

s
s
) + ... + 1
) + N (3, n  1, Tsub
k.... + 1 = N (3, n, Tsub

We can extend this to any level d and the result is as follows.
s
) = 1
N (1, n, Tsub

s
) = n
N (2, n, Tsub


n
X
n+1
s
N (3, n, Tsub ) =
k=
2
k=1

s
N (4, n, Tsub
)

=

n
X
k=1

s
N (3, k, Tsub
)

=




n+2
3

s by induction on the depth d.
We determine the number of solutions at any level of Tsub

[Basis (d = 1) :]

s ) = n.
Clearly, N (1, n, Tsub



[Inductive Step :] Suppose, at dth level the number of solutions is n+d2
= n+d2
n1
d1 .
Therefore at d + 1th level,

 



n
X
n+d2
n+d3
n+d1
s
s
N (d + 1, n, Tsub ) =
+
N (d, k, Tsub ) =
+  + 1 =
d1
d1
n1
k=1

Since Algorithm 5 does not generate duplicate node, and from Proposition B.1 the
s (S , V ) at any level is equal to the number of solutions in
number of solutions in Gsub
q
m
s (S , V ) is also generated by
s
that level of Tsub , at any level the set of solutions in Gsub
q m
s (S , V ), will
s
Algorithm 5 through Tsub . Therefore, the level, at which Sm belongs in Gsub
q m
also be generated by Algorithm 5. Therefore Sm will also be generated by Algorithm 5  a
contradiction which establishes the truth of the statement of Theorem B.1.


325

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Appendix C. Conversion between AND/OR Tree and Alternating
AND/OR Tree
An AND/OR tree is a generalization of alternating AND/OR tree where the restriction of
strict alternation between AND and OR nodes are relaxed. In other words an intermediate
OR node can be a child of another intermediate OR node and the similar parent child
relation is also allowed for AND node. We present an algorithm to convert an AND/OR to
an equivalent alternating AND/OR tree.
We use two operations namely, folding and unfolding for the conversions. Corresponding
to every edge, a stack, update-list, is used for the conversions. In an AND/OR tree, consider
two nodes, vq and vr , of similar type (AND/OR) and they are connected by an edge er .
Edges, e1 ,    , ek emanate from er .
[Folding OR Node :] Suppose vq and vr are OR nodes. The folding of vr is performed
as follows.
 The source of the edges e1 ,    , ek are changed from vr to vq and the costs are updated
as ce (ei )  ce (ei ) + ce (er ) + cv (vr ) where 1  i  k, that is the new cost is the sum
of the old cost and the cost of the edge that points to the source of ei . The triplet
hvr , cv (vr ), ce (er )i is pushed into the update-list of ei , 1  i  k.
 The edge er along with node vr is removed from vq .
[Folding AND Node :] Suppose vq and vr are AND nodes. The folding of vr is performed as follows.
 The source of the edges e1 ,    , ek are changed from vr to vq . One of the edges among
e1 ,    , ek , suppose ei , is selected arbitrarily and the cost is updated as ce (ei ) 
ce (ei ) + ce (er ) + cv (vr ) where 1  i  k. The triplet hvr , cv (vr ), ce (er )i is pushed into
the update-list of ei , whereas the triplet hvr , 0, 0i is pushed into the update-list of ej ,
where 1  j  k and j 6= i.
 The edge er along with node vr is removed from vq .
The unfolding operation is the reverse of the folding operation and it is same for both
OR and AND nodes. It works on a node vq as follows.
Procedure Unfold(node vq )
1
2
3
4
5
6
7
8
9
10
11

forall edge ei that emanate from vq do
if the update list of ei is not empty then
hvt , c1 , c2 i  pop(update list of ei );
if there exists no edge et from vq that points to the node vt then
Create a node vt , and connect vt using edge et from vq ;
cv (vt )  c1 ;
ce (et )  c2 ;
else if c2 6= 0 then
ce (et )  c2 ;
end
end

326

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Function Convert takes the root node of AND/OR tree and transforms it to an equivalent
alternating AND/OR tree recursively.
Function Convert(vq )
1
2
3
4
5
6

7

if every child of vq is a terminal node then
if vq and its parent vp are of same type then
Apply f old operation to vq ;
end
else
foreach child vr of vq , where vr is an intermediate AND/OR node do
Convert(vr );
end

Function Revert takes the root node of an alternating AND/OR tree and converts it to the
original AND/OR tree recursively.
Function Revert(vq )
1
2
3
4
5
6

if every child of vq is a terminal node then
return;
Perform unf old operation to vq ;
foreach child vr of vq do
Revert(vr );
end

The overall process of generating alternative solutions of an AND/OR tree is as follows.
The AND/OR tree is converted to an alternating AND/OR tree using Convert function,
and the solutions are generated using ASG algorithm. The solutions are transformed back
using the Revert function. The proof of correctness is presented below.
C.1 Proof of Correctness
Suppose in an AND/OR tree T two nodes, vq and vr , are of similar type (AND/OR) and
they are connected by an edge er . Edges e1 ,    , ek emanate from er . Now fold operation
1 is the AND/OR tree which is generated by the application
is applied to vq and vr . Let T
of the f old operation.
Lemma C.1 In the context mentioned above, we present the claim of in the following two
propositions.
Proposition C.1 The set of solutions of T having node vq can be generated from the set
1 having node v by applying the unfold operation to v of the solutions of
of solutions of T
q
q
T .
1 of T 1 that contains node v , there exists a soluProposition C.2 For every solution Sm
q

1
tion Sm of T that can be generated from Sm by applying unfold to vq .

Proof: [Proposition C.1] We present the proof for the following cases. Consider any
solution of Sm of T that contains node vq .
327

fiGhosh, Sharma, Chakrabarti, & Dasgupta

a. vq and vr are OR nodes: There are two cases possible.
1. vr is absent from Sm : Since the fold operation modifies the edge er only, all
1 . Therefore S
the other edges from vq in T are also present in T
m will also
1
be present in the solution set of T and it will remain unchanged after the
application of unfold operation.
2. vr is present in Sm : Since there are k distinct OR edges emanating from vr ,
let any one of those OR edges, say ei , is present in Sm . We prove that there is
1 of T 1 , such that the application of unfold operation to S 1 will
a solution Sm
m

generate Sm . The application of fold operation to the node vr modifies the source
1 .
and the cost of edge ei from vr to vq and ce (ei ) to ce (ei ) + ce (er ) + cv (vr ) in T
1 is a solution of T 1 , where the edge e is present in S 1 . Also other
Suppose Sm
i
m

1 and S
than the subtree rooted at vq , the remaining parts of Sm
m are identical
1
1
with each other. Clearly Sm exists as a solution of T and the application of
1 generates S .
unfold operation to vq in Sm
m
b. vq and vr are AND nodes: Since vq is an AND node Sm will contain all of the
AND edges that emanate from vq . Therefore edge er and vr both will be present in
1 of T 1 , such that the following holds.
Sm . Consider the solution Sm

1.
1. vq is present in Sm

2. The subtrees rooted at the children of vq other than vr in Sm are identical with
1 .
the subtrees rooted at those children of vq in Sm
1 and S are identical
3. Other than the subtree rooted at vq , remaining parts of Sm
m
with each other.
1 exists as a solution of T 1 and the application of unfold operation to v
Clearly Sm
q

1
in Sm generates Sm .
 of T
1
Any other solution Sm
 that does not contain node vq , is a valid solution for T
as well.



Proof: [Proposition C.2] We present the proof for the following cases. Consider any
1 of T 1 that contains node v .
solution Sm
q

a. vq and vr are OR nodes: Since vq is an OR node, exactly one OR edge ei of vq will
1 . There are two cases possible.
belong to Sm
1 : Since the fold operation modifies
1. ei was not modified while folding vr in T
the edge er and the OR edges of vr only, all the other edges from vq in T are
1 . Since e was not modified during folding, the same solution
also present in T
i
1
Sm is also a valid solution for T .
1 : Suppose e connects v and v in
2. ei was modified while folding vr in T
i
q
i
1 and generate solution S .
1
Sm . Apply the unfold operation to the node vq in Sm
m
The edge ei will be replaced with edge er which connects vq and vr and then ei
will connect vr and vi . We argue that Sm is a valid solution of T since the

328

fiGenerating Ordered Solutions for Explicit AND/OR Structures

subtree rooted at vi is not modified by the sequence of  (a) the folding of vr to
1 from T , and (b) the unfolding of v to construct S from S 1 .
construct T
q
m

m
1 will contain all of the
b. vq and vr are AND nodes: Since vq is an AND node, Sm
AND edges that emanate from vq . There are two types of AND edges emanating from
1 and they are (a) Type-1 : the edges from v that are also present in T
vq in T
q
 from
vq , (b) Type-2 : the edges that are added to vq by folding and these edges are from
1 and generate solution
vr in T . Apply the unfold operation to the node vq in Sm
Sm . Sm will contain Type-1 edges, and another edge er from vq . In Sm , vq and vr
are connected by er and the Type-2 edges are originated from vr . We argue that Sm
is a valid solution of T since the subtree rooted at nodes pointed by Type-2 edges
1 from T ,
are not modified by the sequence of  (a) the folding of vr to construct T

1.
and (b) the unfolding of vq to construct Sm from Sm


1 of T 1 that does not contain node v is valid solution for T
Clearly any solution Sm
q
 as

well.



Lemma C.2 If function Convert is applied to the root node of any AND/OR tree T , an
alternating AND/OR tree T is generated.
Proof: [Lemma C.2] Function Convert traverses every intermediate node in a depth first
manner. Consider any sequence of nodes, vq1 , vq2 ,    , vqn of same type, where vqi is the
parent of vqi+1 in T and 1  i < n. Obviously, the fold operation is applied to vqi+1
before vqi , where 1  i < n. In other words, the fold operation applied to the sequence of
nodes in the reverse order and after folding vqi+1 , all the edges of vqi+1 are modified and
moved to vqi , where 1  i < n. When the function call Convert(vq2 ) returns, all the edges
of vq2 ,    , vqn are already moved to vq1 and the sequence of nodes, vq1 , vq2 ,    , vqn are
flattened. Therefore, every sequence of nodes of same type are flattened, when the function
call Convert(vR ) returns, where vR is the root of T and an alternating AND/OR tree
T is generated.
Lemma C.3 If function Revert is applied to an alternating AND/OR tree T , the updatelist of every edge in T becomes empty.
Proof: [Lemma C.3] Follows from the description of Revert.
Theorem C.1 For any AND/OR tree T , it is possible to construct an alternating AND/OR
tree T using function Convert, where the set of all possible solutions of T is generated
in the order of their increasing cost by applying Algorithm 4 to T , and then converting
individual solutions using function Revert.
Proof: [Theorem C.1] According to Lemma C.2, after the application of function Convert
to T an alternating AND/OR tree T is generated. Consider the intermediate AND/OR
0 , T 1 ,    , T n are the
trees that are the generated after folding every node in T . Let T


n . Since T i is generated from T i+1
0 = T , T
=
T
sequence of AND/OR trees and T





329

fiGhosh, Sharma, Chakrabarti, & Dasgupta

i , where 0  i < n, according
after folding exactly one node in T
i can be generated from T i+1 by unfolding the same
solutions of T

Lemma C.3, for any solution of T , Revert unfolds every node vq in
vq was folded by Convert while transforming T to T . Therefore
can be generated from the solutions of T .

to Lemma C.1, the
node. According to
that solution, where
the solutions of T

References
Bonet, B., & Geffner, H. (2005). An algorithm better than AO ?. In Proceedings of the
20th national conference on Artificial intelligence - Volume 3, pp. 13431347. AAAI
Press.
Chakrabarti, P. P. (1994). Algorithms for searching explicit AND/OR graphs and their
applications to problem reduction search. Artif. Intell., 65 (2), 329345.
Chakrabarti, P. P., Ghose, S., Pandey, A., & DeSarkar, S. C. (1989). Increasing search
efficiency using multiple heuristics. Inf. Process. Lett., 32 (5), 275275.
Chang, C. L., & Slagle, J. R. (1971). An admissible and optimal algorithm for searching
AND/OR graphs. Artif. Intell., 2 (2), 117128.
Chegireddy, C. R., & Hamacher, H. W. (1987). Algorithms for finding k-best perfect matchings. Discrete Applied Mathematics, 18 (2), 155165.
Chen, H., Xu, Z. J., Liu, Z. Q., & Zhu, S. C. (2006). Composite templates for cloth modeling
and sketching. In Proceedings of the 2006 IEEE Computer Society Conference on
Computer Vision and Pattern Recognition - Volume 1, pp. 943950. IEEE Computer
Society.
Cormen, T. H., Stein, C., Rivest, R. L., & Leiserson, C. E. (2001). Introduction to Algorithms
(2nd edition). McGraw-Hill Higher Education.
Darwiche, A. (1999). Compiling knowledge into decomposable negation normal form. In
Proceedings of the 16th international joint conference on Artifical intelligence - Volume
1, pp. 284289. Morgan Kaufmann Publishers Inc.
Darwiche, A. (2001). Decomposable negation normal form. J. ACM, 48, 608647.
Dasgupta, P., Sur-Kolay, S., & Bhattacharya, B. (1995). VLSI floorplan generation and
area optimization using and-or graph search. In VLSI Design, 1995., Proceedings of
the 8th International Conference on, pp. 370 375.
Dechter, R., & Mateescu, R. (2007). AND/OR search spaces for graphical models. Artif.
Intell., 171 (2-3), 73106.
Ebendt, R., & Drechsler, R. (2009). Weighted A search - unifying view and application.
Artificial Intelligence, 173 (14), 1310  1342.
Elliott, P. (2007). Extracting the k best solutions from a valued And-Or acyclic graph.
Masters thesis, Massachusetts Institute of Technology.
Elliott, P., & Williams, B. (2006). DNNF-based belief state estimation. In Proceedings of
the 21st national conference on Artificial intelligence - Volume 1, pp. 3641. AAAI
Press.
330

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Eppstein, D. (1990). Finding the k smallest spanning trees. In Proc. 2nd Scandinavian
Worksh. Algorithm Theory, No. 447 in Lecture Notes in Computer Science, pp. 38
47. Springer Verlag.
Eppstein, D. (1998). Finding the k shortest paths. SIAM J. Comput., 28 (2), 652673.
Flerova, N., & Dechter, R. (2010). M best solutions over graphical models. In 1st Workshop
on Constraint Reasoning and Graphical Structures.
Flerova, N., & Dechter, R. (2011). Bucket and mini-bucket schemes for m best solutions
over graphical models. In GKR 2011(a workshop of IJCAI 2011).
Fromer, M., & Globerson, A. (2009). An LP view of the m-best MAP problem. In Advances
in Neural Information Processing Systems (NIPS) 22, pp. 567575.
Fuxi, Z., Ming, T., & Yanxiang, H. (2003). A solution to billiard balls puzzle using ao
algorithm and its application to product development. In Palade, V., Howlett, R., &
Jain, L. (Eds.), Knowledge-Based Intelligent Information and Engineering Systems,
Vol. 2774 of Lecture Notes in Computer Science, pp. 10151022. Springer Berlin /
Heidelberg.
Gogate, V., & Dechter, R. (2008). Approximate solution sampling (and counting) on
AND/OR spaces. In CP, pp. 534538.
Gu, Z., Li, J., & Xu, B. (2008). Automatic service composition based on enhanced service
dependency graph. In Web Services, 2008. ICWS 08. IEEE International Conference
on, pp. 246 253.
Gu, Z., Xu, B., & Li, J. (2010). Service data correlation modeling and its application in
data-driven service composition. Services Computing, IEEE Transactions on, 3 (4),
279291.
Gupta, P., Chakrabarti, P. P., & Ghose, S. (1992). The Towers of Hanoi: generalizations,
specializations and algorithms. International Journal of Computer Mathematics, 46,
149161.
Hamacher, H. W., & Queyranne, M. (1985). K best solutions to combinatorial optimization
problems. Annals of Operations Research, 4, 123143.
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. J. Artif. Intell. Res. (JAIR),
28, 267297.
Hansen, E. A., & Zilberstein, S. (2001). LAO  : A heuristic search algorithm that finds
solutions with loops. Artificial Intelligence, 129 (1-2), 35  62.
Homem de Mello, L., & Sanderson, A. (1990). AND/OR graph representation of assembly
plans. Robotics and Automation, IEEE Transactions on, 6 (2), 188 199.
Jimenez, P., & Torras, C. (2000). An efficient algorithm for searching implicit AND/OR
graphs with cycles. Artif. Intell., 124, 130.
Kleinberg, J., & Tardos, E. (2005). Algorithm Design. Addison-Wesley Longman Publishing
Co., Inc., Boston, MA, USA.
Lang, Q. A., & Su, Y. (2005). AND/OR graph and search algorithm for discovering composite web services. International Journal of Web Services Research, 2 (4), 4664.
331

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Lawler, E. L. (1972). A procedure for computing the k best solutions to discrete optimization
problems and its application to the shortest path problem. Management Science,
18 (7), pp. 401405.
Ma, X., Dong, B., & He, M. (2008). AND/OR tree search algorithm in web service composition. In PACIIA 08: Proceedings of the 2008 IEEE Pacific-Asia Workshop on
Computational Intelligence and Industrial Application, pp. 2327, Washington, DC,
USA. IEEE Computer Society.
Majumdar, A. A. K. (1996). Generalized multi-peg Tower of Hanoi problem. The Journal
of the Australian Mathematical Society. Series B. Applied Mathematics, 38, 201208.
Marinescu, R., & Dechter, R. (2005). AND/OR branch-and-bound for solving mixed integer
linear programming problems. In CP, p. 857.
Marinescu, R., & Dechter, R. (2006). Memory intensive branch-and-bound search for graphical models. In AAAI.
Marinescu, R., & Dechter, R. (2007a). Best-first AND/OR search for 0/1 integer programming. In CPAIOR, pp. 171185.
Marinescu, R., & Dechter, R. (2007b). Best-first AND/OR search for graphical models. In
AAAI, pp. 11711176.
Marinescu, R., & Dechter, R. (2009a). AND/OR branch-and-bound search for combinatorial
optimization in graphical models. Artif. Intell., 173 (16-17), 14571491.
Marinescu, R., & Dechter, R. (2009b). Memory intensive AND/OR search for combinatorial
optimization in graphical models. Artif. Intell., 173 (16-17), 14921524.
Martelli, A., & Montanari, U. (1973). Additive AND/OR graphs. In Proceedings of the
3rd international joint conference on Artificial intelligence, San Francisco, CA, USA.
Morgan Kaufmann Publishers Inc.
Martelli, A., & Montanari, U. (1978). Optimizing decision trees through heuristically guided
search. Commun. ACM, 21, 10251039.
Mateescu, R., & Dechter, R. (2008). AND/OR multi-valued decision diagrams for constraint
networks. In Concurrency, Graphs and Models, pp. 238257.
Mateescu, R., Dechter, R., & Marinescu, R. (2008). AND/OR multi-valued decision diagrams (AOMDDs) for graphical models. J. Artif. Intell. Res. (JAIR), 33, 465519.
Mathews, D. H., & Zuker, M. (2004). RNA secondary structure prediction. In Encyclopedia
of Genetics, Genomics, Proteomics and Bioinformatics. John Wiley & Sons, Ltd.
Nilsson, D. (1998). An efficient algorithm for finding the m most probable configurations
in probabilistic expert systems. Statistics and Computing, 8, 159173.
Nilsson, N. J. (1980). Principles of artificial intelligence. Tioga Publishing Co.
Otten, L., & Dechter, R. (2011). Anytime AND/OR depth-first search for combinatorial
optimization. In SoCS.
Pearl, J. (1984). Heuristics: intelligent search strategies for computer problem solving.
Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.
332

fiGenerating Ordered Solutions for Explicit AND/OR Structures

Russell, S., & Norvig, P. (2003). Artificial Intelligence: A Modern Approach (2nd edition
edition)., chap. Planning, pp. 375461. Prentice-Hall, Englewood Cliffs, NJ.
Shiaa, M. M., Fladmark, J. O., & Thiell, B. (2008). An incremental graph-based approach
to automatic service composition. IEEE International Conference on Services Computing, 4 (2), 4664.
Shin, D. H., Jeon, H. B., & Lee, K. H. (2010). A sophisticated approach to composing
services based on action dominance relation. In Services Computing Conference (APSCC), 2010 IEEE Asia-Pacific, pp. 164 170.
Subramanian, S. (1997). Routing algorithms for dynamic, intelligent transportation networks. Masters thesis, Virginia Technical Univ., Dept. of Civil Engineering.
Sugimoto, K., & Katoh, N. (1985). An algorithm for finding k shortest loopless paths
in a directed network. Trans. Information Processing Soc. Japan, 26, 356364. In
Japanese.
Szymanski, M., Barciszewska, M. Z., Barciszewski, J., & Erdmann, V. A. (2005). 5S Ribosomal RNA Database. http://biobases.ibch.poznan.pl/5SData/. Online Database.
Takkala, T., Borndorfer, R., & Lobel, A. (2000). Dealing with additional constraints in the
k-shortest path problem. In Proc. WM 2000.
Topkis, D. M. (1988). A k-shortest path algorithm for adaptive routing in communications
networks. Trans. Communications, 36 (7), 855859.
Yan, Y., Xu, B., & Gu, Z. (2008). Automatic service composition using AND/OR graph. In
E-Commerce Technology and the Fifth IEEE Conference on Enterprise Computing,
E-Commerce and E-Services, 2008 10th IEEE Conference on, pp. 335338.

333

fiJournal of Artificial Intelligence Research 44 (2012) 491-532

Submitted 11/11; published 07/12

Riffled Independence for Efficient Inference
with Partial Rankings
Jonathan Huang

jhuang11@stanford.edu

James H. Clark Center
Stanford University, Stanford CA 94305, USA

Ashish Kapoor

akapoor@microsoft.com

Microsoft Research
One Microsoft Way
Redmond WA 98052-6399, USA

Carlos Guestrin

guestrin@cs.cmu.edu

Gates Hillman Complex, Carnegie Mellon University,
5000 Forbes Avenue, Pittsburgh, PA 15213, USA

Abstract
Distributions over rankings are used to model data in a multitude of real world settings
such as preference analysis and political elections. Modeling such distributions presents
several computational challenges, however, due to the factorial size of the set of rankings
over an item set. Some of these challenges are quite familiar to the artificial intelligence
community, such as how to compactly represent a distribution over a combinatorially large
space, and how to efficiently perform probabilistic inference with these representations.
With respect to ranking, however, there is the additional challenge of what we refer to as
human task complexity  users are rarely willing to provide a full ranking over a long list
of candidates, instead often preferring to provide partial ranking information.
Simultaneously addressing all of these challenges  i.e., designing a compactly representable model which is amenable to efficient inference and can be learned using partial
ranking data  is a difficult task, but is necessary if we would like to scale to problems
with nontrivial size. In this paper, we show that the recently proposed riffled independence
assumptions cleanly and efficiently address each of the above challenges. In particular, we
establish a tight mathematical connection between the concepts of riffled independence and
of partial rankings. This correspondence not only allows us to then develop efficient and
exact algorithms for performing inference tasks using riffled independence based representations with partial rankings, but somewhat surprisingly, also shows that efficient inference
is not possible for riffle independent models (in a certain sense) with observations which do
not take the form of partial rankings. Finally, using our inference algorithm, we introduce
the first method for learning riffled independence based models from partially ranked data.

1. Probabilistic Modeling of Ranking Data: Three Challenges
Rankings arise in a number of machine learning application settings such as preference analysis for movies and books (Lebanon & Mao, 2008) and political election analysis (Gormley
& Murphy, 2007; Huang & Guestrin, 2010). In many of these problems, it is of great interest
to build statistical models over ranking data in order to make predictions, form recommendations, discover latent trends and structure and to construct human-comprehensible data
summaries.
c
2012
AI Access Foundation. All rights reserved.

fiHuang, Kapoor & Guestrin

Modeling distributions over rankings is a difficult problem, however, due to the fact that
as the number of items being ranked increases, the number of possible rankings increases
factorially. This combinatorial explosion forces us to confront three central challenges when
dealing with rankings. First, we need to deal with storage complexity  how can we compactly represent a distribution over the space of rankings?1 Then there is algorithmic complexity  how can we efficiently answer probabilistic inference queries given a distribution?
Finally, we must contend with what we refer to as human task complexity, which is a
challenge stemming from the fact that it can be difficult to accurately elicit a full ranking over
a large list of candidates from a human user; choosing from a list of n! options is no easy task
and users typically prefer to provide partial information. Take the American Psychological
Association (APA) elections, for example, which allow their voters to rank order candidates
from favorite to least favorite. In the 1980 election, there were five candidates, and therefore
5! = 120 ways to rank those five candidates. Despite the small candidate list, most voters
in the election preferred to only specify their top-k favorite candidates rather than writing
down full rankings on their ballots (see Figure 1). For example, roughly a third of voters
simply wrote down their single favorite candidate in this 1980 election.
These three intertwined challenges of storage, algorithmic, and human task complexity
are the central issues of probabilistic modeling for rankings, and models that do not efficiently
handle all three sources of complexity have limited applicability. In this paper, we examine
a flexible and intuitive class of models for rankings based on a generalization of probabilistic
independence called riffled independence, proposed in our recent work (Huang & Guestrin,
2009, 2010). While our previous papers have focused primarily on representational (storage
complexity) issues, we now concentrate on inference and incomplete observations (i.e., partial
rankings), showing that in addition to storage complexity, riffle independence based models
can efficiently address issues of algorithmic and human task complexity.
In fact the two issues of algorithmic and human task complexity are intricately linked
for riffle independent models. By considering partial rankings, we give users more flexibility
to provide as much or as little information as they care to give. In the context of partial
ranking data, the most relevant inference queries also take the form of partial rankings. For
example, we might want to predict a voters second choice candidate given information about
his first choice. One of our main contributions in this paper is to show that inference for
such partial ranking queries can be performed particularly efficiently for riffle independent
models.
The main contributions of our work are as follows:2
 We reveal a natural and fundamental connection between riffle independent models
and partial rankings. In particular, we show that the collection of partial rankings
over an item set form a complete characterization of the space of observations upon
1. Note that it is common to wonder why one would care to represent a distribution over all rankings if the
number of sample rankings is never nearly as large. This problem that the number of samples is always
much smaller than n! however, means that most rankings are never observed, limiting our ability to
estimate the probability of an arbitrary ranking. The only way to overcome the paucity of samples is to
exploit representational structure, which is very much in alignment with solving the storage complexity
issue.
2. This paper is an extended presentation of our paper (Huang, Kapoor, & Guestrin, 2011) which appeared
in the 2011 Conference on Uncertainty in Artificial Intelligence (UAI) as well as results from the first
authors dissertation (Huang, 2011).

492

fiEfficient Inference With Partial Rankings

First
Choice

Second
Choice

Third
Choice

Fourth
Choice

Fifth
Choice

# of
votes

5

3

4

2

1

37

3

4

5

1

2

30

1

2

3

---

---

27

3

---

---

---

---

1198

4

1

3

---

---

15

1

3

---

---

---

302

3

1

2

5

4

186

Figure 1: Example partial ranking data (taken from the American Psychological Association
election dataset, 1980)

which one can efficiently condition a riffle independent model. As a result, we show
that when ranked items satisfy the riffled independence relationship, conditioning on
partial rankings can be done efficiently, with running time O(n|H|), where |H| denotes
the number of model parameters.
 We prove that, in a sense (which we formalize), it is impossible to efficiently condition
riffle independent models on observations that do not take the form of partial rankings.
 We propose the first algorithm that is capable of efficiently estimating the structure
and parameters of riffle independent models from heterogeneous collections of partially
ranked data.
 We show results on real voting and preference data evidencing the effectiveness of our
methods.

2. Riffled Independence For Rankings
A ranking, , of items in an item set  is a one-to-one mapping between  and a rank
set R = {1, . . . , n} and is denoted using vertical bar notation as  1 (1)| 1 (2)| . . . | 1 (n).
We say that  ranks item i1 before (or over) item i2 if the rank of i1 is less than the
rank of i2 . For example,  might be {Corn, P eas, Apples, Oranges} and the ranking
Corn|P eas|Apples|Oranges encodes a preference of Corn over Peas which is in turn preferred over Apples and so on. The collection of all possible rankings of item set  is denoted
by S (or just Sn when  is implicit).
Since there are n! rankings of n items, it is intractable to estimate or even explicitly
represent arbitrary distributions on Sn without making structural assumptions about the
underlying distribution. While there are many possible simplifying assumptions that one can
make, we focus on an approach that we have proposed in recent papers (Huang & Guestrin,
2009, 2010) in which the ranks of items are assumed to satisfy an intuitive generalized notion
of probabilistic independence known as riffled independence. In this paper, we argue that
riffled independence assumptions are particularly effective in settings where one would like
to make queries taking the form of partial rankings. In the remainder of this section, we
review riffled independence.
493

fiHuang, Kapoor & Guestrin

The riffled independence assumption posits that rankings over the item set  are generated by independently generating rankings of smaller disjoint item subsets (say, A and
B) which partition , and piecing together a full ranking by interleaving (or riffle shuffling)
these smaller rankings together. For example, to rank our item set of foods, one might first
rank the vegetables and fruits separately, then interleave the two subset rankings to form a
full ranking. To formally define riffled independence, we use the notions of relative rankings
and interleavings.
Definition 1 (Relative ranking map). Given a ranking   S and any subset A  , the
relative ranking of items in A, A (), is a ranking,   SA , such that (i) < (j) if and
only if (i) < (j).
Definition 2 (Interleaving map). Given a ranking   S and a partition of  into disjoint
sets A and B, the interleaving of A and B in  (denoted, AB ()) is a (binary) mapping
from the rank set R = {1, . . . , n} to {A, B} indicating whether a rank in  is occupied by A
or B. As with rankings, we denote the interleaving of a ranking by its vertical bar notation:
[AB ()](1)|[AB ()](2)| . . . |[AB ()](n).
Example 3. Consider a partitioning of an item set  into vegetables A = {Corn, P eas}
and fruits B = {Apples, Oranges}, as well as a full ranking over these four items:  =
Corn|Oranges|P eas|Apples. In this case, the relative ranking of vegetables in  is A () =
Corn|P eas and the relative ranking of fruits in  is B () = Oranges|Apples. The interleaving of vegetables and fruits in  is AB () = A|B|A|B.
Definition 4 (Riffled Independence). Let h be a distribution over S and consider a subset
of items A   and its complement B. The sets A and B are said to be riffle independent
if h decomposes (or factors) as:
h() = mAB (AB ())  fA (A ())  gB (B ()),
for distributions mAB , fA and gB , defined over interleavings and relative rankings of A and
B respectively. In other words, A and B are riffle independent if the relative rankings of
A and B, as well as their interleaving are mutually independent. We refer to mAB as the
interleaving distribution and fA and gB as the relative ranking distributions.
Riffled independence has been found to approximately hold in a number of real datasets
(Huang & Guestrin, 2012). When such relationships can be identified in data, then instead
of exhaustively representing all n! ranking probabilities, one can represent just the factors
mAB , fA and gB , which are distributions over smaller sets.
2.1 Hierarchical Riffle Independent Models
The relative ranking factors fA and gB are themselves distributions over rankings. To further
reduce the parameter space, it is natural to consider hierarchical decompositions of item sets
into nested collections of partitions (like hierarchical clustering). For example, Figure 2.1
shows a hierarchical decomposition where vegetables are riffle independent of fruits among
the healthy foods, and these healthy foods are, in turn, riffle independent of the subset of
desserts: {Doughnuts, M &M s}.
494

fiEfficient Inference With Partial Rankings

{C,P,A,O,D,M}

{D,M}

{C,P,A,O}

Doughnuts, M&Ms

{C,P}

{A,O}

Corn, Peas

Apples, Oranges

Figure 2: An example of a hierarchy over six food items.
For simplicity, we restrict consideration to binary hierarchies, defined as tuples of the
form H = (HA , HB ), where HA and HB are either (1) null, in which case H is called a leaf,
or (2) hierarchies over item sets A and B respectively. In this second case, A and B are
assumed to form a nontrivial partitioning of the item set.
Definition 5. We say that a distribution h factors riffle independently with respect to a
hierarchy H = (HA , HB ) if item sets A and B are riffle independent with respect to h,
and both fA and gB factor riffle independently with respect to subhierarchies HA and HB ,
respectively.
Like Bayesian networks, these hierarchies represent families of distributions obeying a
certain set of (riffled) independence constraints and can be parameterized locally. To draw
from such a model, one generates full rankings recursively starting by drawing rankings of
the leaf sets, then working up the tree, sequentially interleaving rankings until reaching the
root. The parameters of these hierarchical models are simply the interleaving and relative
ranking distributions at the internal nodes and leaves of the hierarchy, respectively.
In general, the number of total parameters required to represent a hierarchical riffle
independent model can (as with Bayesian networks) still scale exponentially in the number

of items. For example, the number of interleavings of p items with n  p items is np .
It is often the case however, that much fewer parameters are necessary. For example, thin
models (Huang & Guestrin, 2012), in which the number of items factored out of the model at
each stage of the hierarchy is never more than a small constant k, can always be represented
with a (degree k) polynomial number of parameters. We will use |H| to refer to the number
of parameters necessary for representing a distribution which factors according to hierarchy
H.
By decomposing distributions over rankings into small pieces (like Bayesian networks
have done for other distributions), these hierarchical models allow for better interpretability,
efficient probabilistic representation, low sample complexity, efficient MAP optimization,
and, as we show in this paper, efficient inference.
Example 6. In Figure 3(a), we reproduce the hierarchical structure that was learned using
a fully ranked subset of the APA data consisting of 5000 training examples in Huang and
Guestrin (2012). There were five candidates in the election: (1) William Bevan, (2) Ira
Iscoe, (3) Charles Kiesler, (4) Max Siegle, and (5) Logan Wright (Marden, 1995). Strikingly,
the structure that is learned using an algorithm (maximum likelihood) which knows nothing
about the underlying politics of the APA, has leaf nodes which correspond exactly to the
political coalitions that dominated the APA in the 1980 election  the research psychologists
495

fiHuang, Kapoor & Guestrin

A={12345}

B={1345}

C={2}
Community
psychologists

mB,C()
.14

B|C|B|B|B

.19

B|B|C|B|B

.25

B|B|B|C|B

.25

B|B|B|B|C

.18



mD,E()



fC()

D|D|E|E

.28

2

1.00

D|E|D|E

.12

D|E|E|D

.12

D={13}

E={45}

E|D|D|E

.14

Research
psychologists

Clinical
psychologists

E|D|E|D

.12

E|E|D|D

.22

(a) Hierarchical structure learned
via MLE using 5000 full rankings
from the APA dataset.


C|B|B|B|B



fD()



fE()

1|3

.50

4|5

.48

3|1

.50

5|4

.52

(b) Riffle independent model parameters learned via MLE using
5000 full rankings from the APA dataset.

Figure 3: Example hierarchical model for the APA election. Candidates are enumerated
as: (1) William Bevan, (2) Ira Iscoe, (3) Charles Kiesler, (4) Max Siegle, and (5)
Logan Wright (Marden, 1995).

(candidates 1 and 3), the clinical psychologists (candidates 4 and 5), and the community
psychologists (candidate 2).
In Figure 3(b), we plot the corresponding parameter distributions that are learned via
maximum likelihood. There are three relative ranking distributions, each corresponding to a
political party, as well as two interleaving distributions (one for the interleaving of research
and clinical psychologists, and one for the interleaving of the community psychologist and all
remaining candidates). Since each parameter distribution is constrained to sum to 1, there
are a total of 11 free parameters.
2.2 Model Estimation
In this paper we estimate riffle independent models based on the methods introduced in our
earlier work. Given the hierarchial structure of a model, the maximum likelihood parameter
estimates of a hierarchical riffle independent model are straightforward to compute via frequency estimates. But how to estimate the correct structure of a model is a more challenging
problem. The key insight lies in noticing that if two subsets A and B are riffle independent,
then for any i  A and j, k  B, the independence relation (i)  ((j) < (k)) must hold.
Our structure learning algorithms operate by hunting for these tripletwise independence
relations within the data. We defer interested readers to the details in (Huang & Guestrin,
2012).
496

fiEfficient Inference With Partial Rankings

Note that in our earlier work, we assumed that our algorithms have access to a dataset
consisting of i.i.d. full rankings provided by users. In the current work, we will relax our
assumptions by allowing for users to provide partially ranked data. One assumption throughout, however, is that each user has a full ranking in mind over the items. In particular, our
current work does not address the incomplete ranking problem, in which users might not
have seen all of the items (we discuss possible extensions to the incomplete ranking setting
in Section 9.

3. Decomposable Observations
Given a prior distribution, h, over rankings and an observation O, Bayes rule tells us that
the posterior distribution, h(|O), is proportional to L(O|)  h(), where L(O|) is the
likelihood function. This operation of conditioning h on an observation O is typically computationally intractable since it requires multiplying two n! dimensional functions, unless
one can exploit structural decompositions of the problem. In this section, we describe a decomposition for a certain class of likelihood functions over the space of rankings in which the
observations are factored into simpler parts. When an observation O is decomposable in
this way, we show that one can efficiently condition a riffle independent prior distribution on
O. For simplicity in this paper, we focus primarily on subset observations whose likelihood
functions encode membership with some subset of rankings in Sn .
Definition 7 (Subset observations). A subset observation O is a binary observation whose
likelihood is proportional to the indicator function of some subset of Sn  i.e.,

1 if   O
.
L(O|) =
0 otherwise
As a running example, we will consider the class of first place observations throughout
the chapter (we will consider far more general observation models in later sections). The first
place observation O =Corn is ranked first, for example, is associated with the collection of
rankings placing the item Corn in first place (O = { : (Corn) = 1}). We are interested in
computing the posterior h(|  O). Thus in the first place scenario, we are given a voters
top choice and we would like to infer his preferences over the remaining candidates.
Given a partitioning of the item set  into two subsets A and B, it is sometimes possible
to decompose (or factor ) a subset observation involving items in  into smaller subset observations involving A, B and the interleavings of A and B independently. Such decompositions
can often be exploited for efficient inference.
Example 8.
 Consider the first place observation
O = Corn is ranked first,
which can be decomposed into two independent observations  an observation on the
relative ranking of Vegetables, and an observation on the interleaving of Vegetables and
Fruits:
497

fiHuang, Kapoor & Guestrin

 OA = Corn is ranked first among Vegetables,
 OA,B = First place is occupied by a Vegetable.
To condition on O in this case, one updates the relative ranking distribution over
Vegetables (A) by zeroing out rankings of vegetables which do not place Corn in first
place, and updates the interleaving distribution by zeroing out interleavings which do
not place a Vegetable in first place, then normalizes the resulting distributions.
 An example of a nondecomposable observation is the observation
O = Corn is in third place.
To see that O does not decompose (with respect to Vegetables and Fruits), it is enough
to notice that the interleaving of Vegetables and Fruits is not independent of the relative
ranking of Vegetables. If, for example, an element   O interleaves A (Vegetables)
and B (Fruits) as AB () = A|B|A|B, then since (Corn) = 3, the relative ranking
of Vegetables is constrained to be A () = P eas|Corn. Since the interleavings and
relative rankings are not independent, we see that O cannot be decomposable.
Formally, we use riffle independent factorizations to define decomposability with respect
to a hierarchy H of the item set.
Definition 9 (Decomposability). Given a hierarchy H over the item set, a subset observation O decomposes with respect to H if its likelihood function L(O|) factors riffle
independently with respect to H.
When subset observations and the prior decompose according to the same hierarchy, we
can show (as in Example 8) that the posterior also decomposes.
Proposition 10. Let H be a hierarchy over the item set. Given a prior distribution h and
a subset observation O which both decompose with respect to H, the posterior distribution
h(|O) also factors riffle independently with respect to H.
Proof. Denote the likelihood function corresponding to O by L (in this proof, it does not
matter that O is assumed to be a subset observation  the result holds for arbitrary
likelihoods).
We use induction on the size of the item set n = ||. The base case n = 1 is trivially
true. Next consider the general case where n > 1. The posterior distribution, by Bayes rule,
can be written h(|O)  L()  h(). There are now two cases. If H is a leaf node, then
the posterior h0 trivially factors according to H, and we are done. Otherwise, L and h both
factor, by assumption, according to H = (HA , HB ) in the following way:
L() = mL (AB ())fL (A ())gL (B ()), and h() = mh (AB ())fh (A ())gh (B ()).
Multiplying and grouping terms, we see that the posterior factors as:
h(|O) = [mL  mh ](AB ())  [fL  fh ](A ())  [gL  gh ](B ()).
To show that h(|O) factors with respect to H, we need to demonstrate (by Definition 5)
that the distributions [fL  fh ] and [gL  gh ] (after normalizing) factor with respect to HA and
498

fiEfficient Inference With Partial Rankings

HB , respectively. Since fL and fh both factor according to the hierarchy HA by assumption
and |A| < n since H is not a leaf, we can invoke the inductive hypothesis to show that the
posterior distribution, which is proportional to fL  fh must also factor according to HA .
Similarly, the distribution proportional to gL  gh must factor according to HB .

4. Complete Decomposability
The condition of Proposition 10, that the prior and observation must decompose with respect to exactly the same hierarchy, is a sufficient one for efficient inference, but it might at
first glance seem so restrictive as to render the proposition useless in practice. To overcome
this limitation of hierarchy specific decomposability, we explore a special family of observations (which we call completely decomposable) for which the property of decomposability
does not depend specifically on a particular hierarchy, implying in particular that for these
observations, efficient inference is always possible (provided that efficient representation of
the prior distribution is also possible).
To illustrate how an observation can decompose with respect to multiple hierarchies over
the item set, consider again the first place observation O =Corn is ranked first. We argued
in Example 8 that O is a decomposable observation. Notice however that decomposability
for this particular observation does not depend on how the items are partitioned by the
hierarchy. Specifically, if instead of Vegetables and Fruits, the sets A = {Corn, Apples} and
B = {P eas, Oranges} are riffle independent, a similar decomposition of O would continue
to hold, with O decomposing as an observation on the relative ranking of items in A (Corn is
first among items in A), and an observation on the interleaving of A and B (First place is
occupied by some element of A).
To formally capture this notion that an observation can decompose with respect to
arbitrary underlying hierarchies, we define complete decomposability:
Definition 11 (Complete decomposability). We say that a subset observation O is completely decomposable if it decomposes with respect to every possible hierarchy over the item
set . We denote the collection of all possible completely decomposable (subset) observations as C. See Figure 4 for an illustration of the set C.
Conceptually, completely decomposable observations correspond to indicator functions
that are as riffle independent as possible. Complete decomposability is a guarantee for an
observation O that one can always exploit any available factorized structure of the prior
distribution in order to efficiently condition on O.
Proposition 12. Let H be any binary hierarchy over the item set. Given a prior h which
factorizes with respect to H, and a completely decomposable observation O, the posterior
h(|O) also decomposes with respect to H.
Proof. Proposition 12 follows as a simple corollary to Proposition 10.
Example 13. The simplest example of a completely decomposable observation is the uniform observation Ounif = S , which includes all possible rankings and corresponds to a
uniform indicator function unif over rankings. Given any hierarchy H, unif can be shown
to decompose riffle independently with respect to H, where each factor is also uniform, and
hence Ounif is completely decomposable.
499

fiHuang, Kapoor & Guestrin

H1

H6

H2

Completely
Decomposable
Observations

H5

H3

H4

Figure 4: A diagram illustrating the collection of completely decomposable observations, C.
Each shaded region (labeled Hi ) above represents the family of subset observations
over Sn which decompose with respect to the hierarchy Hi . The collection C can be
seen as the intersection over all such shaded regions, and subset observations which
lie inside of this intersection are ones for which conditioning can be performed in
linear time (in the number of model parameters).

The uniform observation is of course not particularly interesting in the context of Bayesian
inference, but on the other hand, given the stringent conditions in Definition 11, it is not
obvious that nontrivial completely decomposable observations can even exist. Nonetheless,
there do exist nontrivial examples (such as the first place observations), and in the next
section, we exhibit a rich and general class of completely decomposable observations.

5. Complete Decomposability of Partial Ranking Observations
In this section we discuss the mathematical problem of fully characterizing the class of
completely decomposable observations. Our main contribution in this section is to show
that completely decomposable observations correspond precisely to partial rankings of the
item set.
Partial rankings. We begin our discussion by introducing partial rankings, which allow
for items to be tied with respect to a ranking  by dropping verticals from the vertical bar
representation of .
Definition 14 (Partial ranking observation). Let 1 , 2 ,. . . , r be an ordered collection
of subsets which partition  (i.e., i i =  and i  j =  if i 6= j). The partial ranking
observation 3 corresponding to this partition is the collection of rankings which rank items
3. As remarked by Ailon (2007), we note that The term partial ranking used here should not be confused
with two other standard objects: (1) Partial order, namely, a reflexive, transitive anti-symmetric binary

500

fiEfficient Inference With Partial Rankings

in i before items in j if i < j. We denote this partial ranking as 1 |2 | . . . |r and say
that it has type  = (|1 |, |2 |, . . . , |r |). We denote the collection of all partial rankings
(over n items) as P.
Each partial ranking as defined above can be viewed as a coset of the subgroup S =
S1  S2      Sr . Given the type  and any full ranking   S , there is only one
partial ranking of type  containing , thus we will therefore equivalently denote the partial
ranking 1 |2 | . . . |r as S , where  is any element of 1 |2 | . . . |r . Note that this coset
notation allows for multiple rankings  to refer to the same partial ranking S .
The space of partial rankings as defined above captures a rich and natural class of
observations. In particular, partial rankings encompass a number of commonly occurring
special cases, which have traditionally been modeled in isolation, but in our work (as well
as recent works such as Lebanon & Lafferty, 2003; Lebanon & Mao, 2008) can be used in a
unified setting.
Example 15. Partial ranking observations include:
 (First place, or Top-1 observations): First place observations correspond to partial
rankings of type  = (1, n  1). The observation that Corn is ranked first can be
written as Corn|Peas,Apples,Oranges.
 (Top-k observations): Top-k observations are partial rankings with type  = (1, . . . , 1, n
k). These generalize the first place observations by specifying the items mapping to the
first k ranks, leaving all n  k remaining items implicitly ranked behind. For example,
the observation that Corn is ranked first and Peas is ranked second can be written as
Corn|Peas|Apples,Oranges.
 (Desired/less desired dichotomy): Partial rankings of type  = (k, n  k) correspond to
a subset of k items being preferred or desired over the remaining subset of n  k items.
For example, partial rankings of type (k, n  k) might arise in approval voting in which
voters mark the subset of approved candidates, implicitly indicating disapproval of the
remaining n  k candidates.
 (Ratings): Finally, partial rankings can come in the form of rating data where, for
example, restaurants are rated as, ?, ??, or ? ? ?. A corresponding partial ranking
would thus tie restaurants that are rated with the same number of stars, while ranking
restaurants with more stars above restaurants with fewer stars.
 (Trivial observations): Partial rankings of type  = (n) refer to trivial observations
whose likelihood functions are uniform on the entire space of rankings, S . The trivial
observation for rankings of the item set  = {Corn, P eas, Apples}, for example, can
simply be written simply as Corn, P eas, Apples.
To show how partial ranking observations decompose, we will exhibit an explicit factorization with respect to a hierarchy H over items. For simplicity, we begin by considering the
single layer case, in which the items are partitioned into two leaf sets A and B. Our factorization depends on the following notions of consistency of relative rankings and interleavings
with a partial ranking.
relation; and (2) A ranking of a subset of  [which we discuss in Section 9 as incomplete rankings]. In
search engines, for example, although only the top-k elements of  are returned, the remaining n  k
are implicitly assumed to be ranked behind [and therefore, search engines return partial rankings].

501

fiHuang, Kapoor & Guestrin

Definition 16 (Restriction consistency). Given a partial ranking S  = 1 |2 | . . . |r and
any subset A  , we define the restriction of S  to A as the partial ranking on items in
A obtained by intersecting each i with A. Hence the restriction of S  to A is:
[S ]A = 1  A|2  A| . . . |r  A.
Given a ranking, A of items in A, we say that A is consistent with the partial ranking
S  if A is a member of the restriction of S  to A, [S ]A .
Definition 17 (Interleaving consistency). Given an interleaving AB of two sets A, B which
partition , we say that AB is consistent with a partial ranking S  = 1 | . . . |r (with
type ) if the first 1 entries of AB contain the same number of As and Bs as 1 , and the
second 2 entries of AB contain the same number of As and Bs as 2 , and so on. Given a
partial ranking S , we denote the collection of consistent interleavings as [S ]AB .
For example, consider the partial ranking
S  = Corn, Apples|P eas, Oranges,
which places a single vegetable and a single fruit in the first two ranks, and a single vegetable
and a single fruit in the last two ranks. Alternatively, S  partially specifies an interleaving
AB|AB. The full interleavings A|B|B|A and B|A|B|A are consistent with S  (by dropping
vertical lines) while A|A|B|B is not consistent (since it places two vegetables in the first two
ranks).
Using the notions of consistency with a partial ranking, we show that partial ranking
observations are decomposable with respect to any binary partitioning (i.e., single layer
hierarchy) of the item set.
Proposition 18 (Single layer hierarchy). For any partial ranking observation S  and any
binary partitioning of the item set (A, B), the indicator function of S , S  , factors riffle
independently as:
S  () = mAB (AB ())  fA (A ())  gB (B ()),

(5.1)

where the factors mAB , fA and gB are the indicator functions for consistent interleavings
and relative rankings, [S ]AB , [S ]A and [S ]B , respectively.
The single layer decomposition of Proposition 18 can be turned into a recursive decomposition for partial ranking observations over arbitrary binary hierarchies, which establishes
our main result. In particular, given a partial ranking S  and a prior distribution which
factorizes according to a hierarchy H, we first condition the topmost interleaving distribution by zeroing out all parameters corresponding to interleavings which are not consistent
with S , and normalizing the distribution. We then need to condition the subhierarchies
HA and HB on relative rankings of A and B which are consistent with S , respectively.
Since these consistent sets, [S ]A and [S ]B , are partial rankings themselves, the same
algorithm for conditioning on a partial ranking can be applied recursively to each of the
subhierarchies HA and HB . To be precise, we show that:
Theorem 19. Every partial ranking is completely decomposable (P  C).
502

fiEfficient Inference With Partial Rankings

prcondition (Prior hprior , Hierarchy H, Observation S  = 1 |2 | . . . |r )
if isLeaf(H) then
forall  do

hprior () if   S 
hpost () 
;
0
otherwise
Normalize (hpost ) ;
return (hpost );
else
forall  do

mprior ( ) if   [S ]AB
mpost ( ) 
;
0
otherwise
Normalize (mpost ) ;
f (A ) prcondition (fprior , HA , [S ]A ) ;
g(B ) prcondition (gprior , HB , [S ]B ) ;
return (mpost , fpost , gpost );

Algorithm 1: Pseudocode for prcondition, an algorithm for recursively conditioning a hierarchical riffle independent prior distribution on partial ranking observations. See Definitions 16
and 17 for [S ]A , [S ]B , and [S ]AB . The runtime of prcondition is O(n  |H|), where |H|
is the number of model parameters. Input: All parameter distributions of the prior hprior represented in explicit tabular form, and an observation S  in the form of a partial ranking. Output:
All parameter distributions of the posterior hpost represented in explicit tabular form.

Since the proof of Theorem 19 is fairly straight forward given the form of the factorization (Equation 5.1), it is deferred to the Appendix. As a consequence of Theorem 19 and
Proposition 12, conditioning on partial ranking observations can be performed efficiently.
See Algorithm 1 for details on our recursive conditioning algorithm.
What is the running time complexity of conditioning on a partial ranking? The recursion
of Algorithm 1 operates on each parameter distribution once, setting the probabilities of
the interleavings or relative rankings in each such distribution to either zero or not, then
normalizing. To decide whether to zero out a probability or not, one must check a partial
ranking for consistency against either an interleaving or relative ranking, which requires at
most O(n) time. Therefore, in total, Algorithm 1 requires O(n  |H|) time, where |H| is
the total number of model parameters. Notice that the complexity of conditioning depends
linearly on the complexity of the prior  whenever the prior distribution can be compactly
represented, efficient inference for partial ranking observations is also possible. As we have
stated in Section 2, |H| can in general scale exponentially in n, but for thin chain models,
in which the number of items factored out of the model at each stage is never more than
a small constant k, verifying interleaving or relative ranking consistency can be performed
in constant time, implying that the conditioning operation is linear in the number of model
parameters, and guaranteed to be polynomial in n.
Example 20. In this example, we consider conditioning the APA distribution from Example 6 on the observation O that Candidate 3 is ranked in first place, which can also
be represented as the partial ranking O = 3|1, 2, 4, 5. Recall that candidate 3 was Charles
Kiesler, who was a research psychologist.
In Figure 5(a) we show again the structure and parameters of the prior distribution for
the APA election data, highlighting in particular the interleavings and relative rankings which
503

fiHuang, Kapoor & Guestrin



mB,C()



C|B|B|B|B

.14

C|B|B|B|B

mB,C()
0

B|C|B|B|B

.19

B|C|B|B|B

.22

B|B|C|B|B

.25

B|B|C|B|B

.29

B|B|B|C|B

.25

B|B|B|C|B

.29

B|B|B|B|C

.18

B|B|B|B|C

.21



mD,E()



fC()



mD,E()



fC()

D|D|E|E

.28

2

1.00

D|D|E|E

.54

2

1.00

D|E|D|E

.12

D|E|D|E

.23

D|E|E|D

.12

D|E|E|D

.23

E|D|D|E

.14

E|D|D|E

0

E|D|E|D

.12

E|D|E|D

0

E|E|D|D

.22

E|E|D|D

0



fD()



fE()



fD()



fE()

1|3

.50

4|5

.48

1|3

0

4|5

.48

3|1

.50

5|4

.52

3|1

1.00

5|4

.52

(a) Structure and parameters of the prior distribution (with consistent relative rankings and interleavings highlighted).

(b) Structure and parameters of the posterior distribution after conditioning.

Figure 5: Example of conditioning the APA hierarchy (from Example 6) on the first place
observation that Candidate 3 is ranked in first place.

are consistent with O. For example, of the possible interleavings of research psychologists
(D) with clinical psychologists (E), the interleavings that are consistent with O are those
which rank a research psychologist first among the research and clinical psychologists. There
are therefore only three consistent interleavings: D|D|E|E, D|E|D|E, and D|E|E|D.
Conditioning on O sets all relative rankings and interleavings which are not consistent
with O to zero and normalizes each resulting parameter distribution. The resulting riffle
independent representation of the posterior distribution is shown in Figure 5(b).

5.1 An Impossibility Result
It is interesting to consider what completely decomposable observations exist beyond partial
rankings. One of our main contributions is to show that there are no such observations.
Theorem 21 (Converse of Theorem 19). Every completely decomposable observation takes
the form of a partial ranking (C  P).
Together, Theorems 19 and 21 form a significant insight into the nature of rankings,
showing that the notions of partial rankings and riffled independence are deeply connected.
In fact, our result shows that it is even possible to define partial rankings via complete
decomposability!
As a practical matter, Theorem 21 shows that there is no algorithm based on simple
multiplicative updates to the parameters which can exactly condition on observations which
do not take the form of partial rankings. The computational complexity of conditioning on
observations which are not partial rankings remains open. We conjecture that approximate
inference approaches may be necessary for efficiently handling more complex observations.
504

fiEfficient Inference With Partial Rankings

5.2 Proof of the Impossiblity Result (Theorem 21)
We now turn to proving Theorem 21. Since this proof is significantly longer and less obvious
than the proof for its converse (Theorem 19), we sketch the main ideas that drive the proof
here and refer interested readers to details in the Appendix.
Recall that the definition of the linear span of a set of vectors in a vector space is the
intersection of all linear subspaces containing that set of vectors. To prove Theorem 21, we
introduce analogous concepts of the span of a set of rankings.
Definition 22 (rspan and pspan). Let X  Sn be any collection of rankings. We define
pspan(X) to be the intersection of all partial rankings containing X. Similarly, we define
rspan(X) to be the intersection of all completely decomposable observations containing X.
More formally,
\
\
pspan(X) =
S , and rspan(X) =
O.
O:XO, OC

S :XS 

For example, if X = {Corn|P eas|Apples, Apples|P eas|Corn}, it can be checked that
the only partial ranking of all three items containing both items of X is the entire set itself.
Thus pspan(X) = Corn, P eas, Apples.
Our proof strategy is to establish two claims: (1) that the pspan of any set is always
a partial ranking, and (2) that in fact, the rspan and pspan of a set X are exactly the
same sets. Since claim (1) is a fact about partial rankings and does not involve riffled
independence, we defer all related proofs to the Appendix. Thus we have:
Lemma 23. For any X  Sn , pspan(X) is a partial ranking.
Proof. See Appendix.
The following discussion will instead sketch a proof of claim (2). We first show, however,
that Theorem 21 must hold if it is indeed true that claims (1) and (2) hold.
Proof. (of Theorem 21): Given some O  C, we want to show that O  P. By claim
(2), rspan(O) = pspan(O). Since O is an element of C, however, we also have that
O = rspan(O), and thus that O = pspan(O). Finally Lemma 23 (claim (2)) guarantees
that pspan(O) is a partial ranking, and so we conclude that O  P.
We now proceed to establish the claim that rspan(X) = pspan(X). The following
proposition lists several basic properties of the rspan that we will use in several of the
proofs. They all follow directly from definition so we do not write out the proofs.
Proposition 24.
I. (Monotonicity) For any X, X  rspan(X).
II. (Subset preservation) For any X, X 0 such that X  X 0 , rspan(X)  rspan(X 0 ).
III. (Idempotence) For any X, rspan(rspan(X)) = rspan(X).
One inclusion of our proof that rspan(X) = pspan(X) follows directly from the fact
that P  C (Theorem 19):
505

fiHuang, Kapoor & Guestrin

formPspan(X)
X0  X; t  0;
while S , S 0  0  Xt which disagree on the relative ordering of items a1 , a2 do
Xt   ;
foreach S   Xt do
Add any partial ranking obtained by deleting a vertical bar from S  between items
a1 and a2 to Xt ;
t  t + 1;
return (any element of Xt ) ;

Algorithm 2: Pseudocode for computing pspan(X). formPspan(X) takes a set of partial
rankings (or full rankings) X as input and outputs a partial ranking. This algorithm iteratively
deletes vertical bars from elements of X until they are in agreement. Note that it is not necessary
to keep track of t, but we do so here to ease notation in the proofs. Nor is this algorithm the most
direct way of computing pspan(X), but again, it simplifies the proof of our main theorem.

Lemma 25. For any subset of orderings, X, rspan(X)  pspan(X).
Proof. Fix a subset X  Sn and let  be any element of rspan(X). We would like to show
 to be an element of pspan(X). Consider any partial ranking S   P which covers X
(i.e.,  0  S  for all  0  X). We want to see that   S . By Theorem 19, P  C,
and therefore, S   C. Since   rspan(X), and  0  S  for all  0  X, we conclude,
by definition of rspan, that   S . Since this holds for any partial ranking covering X,
  pspan(X).
What remains is the task of establishing the reverse inclusion:
Proposition 26. For any subset of orderings, X, rspan(X)  pspan(X).
To prove Proposition 26, we consider the problem of computing the partial ranking span
(pspan) of a given set of rankings X. In Algorithm 2, we show a simple procedure based
on iteratively finding rankings in X which disagree on the pairwise ranking of two items,
and replacing those rankings by a partial ranking in which a vertical bar between those two
elements have been removed. We show that this algorithm provably outputs the correct
result.
Proposition 27. Given a set of rankings X as input, Algorithm 2 outputs pspan(X).
Proof. See Appendix.
As a final step before being able to prove Proposition 26, we prove the following two
technical lemmas which relate the computation of the pspan in Algorithm 2 to riffled independence, and really form the heart of our argument. In particular, for a completely
decomposable observation O  C, Lemma 28 below shows how a ranking contained in O
can force other rankings to also be contained in O.
Lemma 28. Let O  C and suppose there exist 1 , 2  O which disagree on the relative
ranking of items i, j  . Then the ranking obtained by swapping the relative ranking of
items i, j within any 3  O must also be contained in O.
506

fiEfficient Inference With Partial Rankings

Proof. Let h be the indicator distribution corresponding to the observation O. We will
show that swapping the relative ranking of items i, j in 3 will result in a ranking which is
assigned nonzero probability by h, thus showing that this new ranking is contained in O.
Let A = {i, j} and B = \A. Since O  C, h must factor riffle independently according
to the partition (A, B). Thus,
h(1 ) = m(AB (1 ))  f (A (1 ))  g(B (1 )) > 0, and
h(2 ) = m(AB (2 ))  f (A (2 ))  g(B (2 )) > 0.
Since 1 and 2 disagree on the relative ranking of items in A, this factorization implies in
particular that both f (A = i|j) > 0 and f (A = j|i) > 0. Since h(3 ) > 0, it must also
be that each of m(AB (3 )), f (A (3 )), and g(B (3 )) have positive probability. We can
therefore swap the relative ranking of A, A , to obtain a new ranking which has positive
probability since all of the terms in the decomposition of this new ranking have positive
probability.
Lemma 29 below provides conditions under which removing a vertical bar from one of
the rankings in X will not change the support of a completely riffle independent distribution. To illustrate with an example, consider a completely decomposable observation O
which contains the partial ranking S  = Corn, P eas|Apples, Oranges as a subset. What
Lemma 29 guarantees is that, if, in addition, there exists any element  in O which disagrees
with S  on the relative ordering of, say, P eas and Oranges, then in fact the partial ranking
S 0  0 = Corn, P eas, Apples, Oranges (with the bar removed from S ) must also be a
subset of O. Formally,
Lemma 29. Let S  = 1 | . . . |i |i+1 | . . . |k be a partial ranking on item set , and
S 0  0 = 1 | . . . |i  i+1 | . . . |k , the partial ranking in which the sets i and i+1 are
merged. Let a1  ij=1 j and a2  kj=i+1 j . If O is any element of C such that S   O
and there additionally exists a ranking   O which disagrees with S  on the relative
ordering of a1 , a2 , then S 0  0  O.
Proof. The key strategy in our proof of Lemma 29 is to argue that large subsets of rankings
must be contained in a completely decomposable observation O by decomposing rankings
into transpositions and invoking the technical lemma from above (Lemma 28) repeatedly.
See the Appendix for details.
We now can use Lemma 29 to show that the reverse inclusion of Proposition 26 also
holds, establishing that the two sets rspan(X) and pspan(X) are in fact equal and thereby
proving the desired result, that C  P.
Proof. (of Proposition 26) At each iteration t, Algorithm 2 producesS
a set of partial rankings,
Xt . We denote the union of all partial rankings at time t as Xt  S Xt S . Note that
X0 = X and XT = pspan(X). The idea of our proof will be to show that at each iteration
t, the following set inclusion holds: rspan(Xt )  rspan(Xt1 ). If indeed this holds, then
507

fiHuang, Kapoor & Guestrin

after the final iteration T , we will have shown that:
pspan(X) = XT ,

(Proposition 27)

 rspan(XT ),

(Monotonicity, Proposition 24)

 rspan(X0 ),

(since rspan(Xt )  rspan(Xt1 ), shown below),

 rspan(X)

(X0 = X, see Algorithm 2)

which would prove the Proposition.
It remains now to show that rspan(Xt )  rspan(Xt1 ). We claim that Xt  rspan(Xt1 ).
Let   Xt . If   Xt1 , then since Xt1  rspan(Xt1 ), we have   rspan(Xt1 ) and
the proof is done. Otherwise,   Xt \Xt1 . In this second case, we use the fact that
at iteration t, the vertical bar between i and i+1 was deleted from the partial ranking S  = 1 | . . . |i |i+1 | . . . |k (which is a subset of Xt1 ) to form the partial ranking
S 0  0 = 1 | . . . |i  i+1 | . . . |k . (which is a subset of Xt ). Furthermore, in order for the
vertical bar to have been deleted by the algorithm, there must have existed some partial
ranking (and therefore some full ranking  0 ) that disagreed with S  on the relative ordering of items a1 , a2 on opposite sides of the bar. Since   Xt \Xt1 we can assume that
  S 0  0 .
We now would like to apply Lemma 29. Note that for any O  C such that Xt1  O,
we also have S   O, since S   Xt1 . An application of Lemma 29 then shows that
S 0  0  O and therefore that   O.
We have shown in fact that   O holds for any observation O  C such that Xt1 
O, and therefore taking the intersection of supports over all O  C, we see that Xt 
rspan(Xt1 ). Taking the rspan of both sides yields:
rspan(Xt )  rspan(rspan(Xt1 )),
 rspan(Xt1 ).

(Subset preservation, Proposition 24)

(Idempotence, Proposition 24)

5.3 Going Beyond Subset Observations
Though we have stated all of our results so far for subset observations, we now comment
on what our theory would look like if we had considered general likelihood functions. In
order to avoid confusion, we here refer to a more general class of functions that we call completely decomposable functions, instead of the completely decomposable subset observations
of Definition 11.
Definition 30. A function h : Sn  R is called a completely decomposable function if it
factors riffle independently with respect to every hierarchy over the item set . We denote
e
the collection of all possible completely decomposable functions as C.
e are very nearly the same. It is quite simple to restate Theorem 19
As we discuss, C and C
with respect to the general case of completely decomposable functions:
Theorem. Every partial ranking indicator function is a completely decomposable function.
508

fiEfficient Inference With Partial Rankings

Unfortunately, the proof of its converse (Theorem 21) does not easily generalize, and
instead can only be used to show that the support ({  Sn : h() > 0}) of every completely
decomposable function is a partial ranking. It is natural, however, to suspect that a full
converse does indeed exist  that every completely decomposable function is proportional to
the indicator function of some partial ranking. In fact, this suspected converse only almost
holds. We have:
Theorem. If h is any completely decomposable function supported on a partial ranking
S  = 1 | . . . |r where |i | =
6 2 for all i = 1, . . . , r, then h is proportional to the indicator
function on S .
Proof. See Appendix.
Example 31. For completely decomposable functions, it is not possible to do away with the
assumption that |i | =
6 2 for all i. As an example, the function defined below as:

 2/3 if  = Corn|P eas|Apples
1/3 if  = P eas|Corn|Apples ,
h() =

0
otherwise
is supported on the partial ranking S  = Corn, P eas|Apples (where |1 | = 2), and is not
proportional to any indicator function (i.e., it is not uniform on rankings which are not
assigned positive probability).
However, it is still possible to show that h is a completely decomposable function. To
prove so, it is necessary to establish only three things: that {Corn, P eas} and {Apples}
are riffle independent, that {Corn, Apples} and {P eas} are riffle independent, and that
{P eas, Apples} and {Corn} are riffle independent. For example, with respect to the partitioning into sets A = {Corn, Apples} and B = {P eas}, we see that
h() = m(AB ())  f (A ())  g(B ()),
where:

 2/3
1/3
m(AB ) =

0

if AB = A|B|A
if AB = B|A|A ,
if AB = A|A|B


f (A ) =

1
0

if {AC} = A|C
,
otherwise

g(B ) = 1.

Therefore, when |i | = 2, it is possible to have completely decomposable functions which
are not uniform on their supports.
5.4 Conditioning on Noisy Observations
We conclude this section with a remark on handling noise in observations. While we have
assumed in this paper that observed partial rankings are always consistent with a users
underlying full ranking, there are situations in which one may wish to model a noisier
setting, where the partial rankings may be misreported with some small probability. A
natural model that accounts for noise, for example, might be:

1   if   O
L(O|) =
.
(5.2)

|O|1 otherwise
509

fiHuang, Kapoor & Guestrin

If a prior distribution factorizes with respect to a hierarchy H, then conditioning on the
noisy likelihood of Equation 5.2 results in a posterior distribution which can be written
as a weighted mixture of the prior distribution and the posterior that would have resulted
from conditioning on a noise-free observation. While each component of this posterior
distribution factorizes with respect to H, the mixture itself does not factor in general (and
should not factor according to our theory). As a result, iteratively conditioning on multiple
partial rankings according to the noisy likelihood function above would quickly lead to
an unmanageable number of mixture components. We therefore believe that approximate
inference methods for conditioning on multiple noisy partial ranking observations is a fruitful
area for further research.

6. Model Estimation from Partially Ranked Data
In many ranking based applications, datasets are predominantly composed of partial rankings rather than full rankings due to the fact that for humans, partial rankings are typically
easier and faster to specify. In addition, many datasets are heterogeneous, containing partial
ranking of different types. For example, in the American Psychological Assoication as well
as the Irish House of Parliament elections, voters are allowed to specify their top-k candidate
choices for any value of k (see Figures 7(a) and 7(b)). In this section we use the efficient
inference algorithm proposed in Section 5 for estimating a riffle independent model from
partially ranked data. Because estimating a model using partially ranked data is typically
considered to be more difficult than estimating one using only full rankings, a common practice (e.g., see Huang & Guestrin, 2010) has been to simply ignore the partial rankings in a
dataset. The ability of a method to incorporate all of the available data however, can lead
to significantly improved model accuracy as well as wider applicability of that method. In
this section, we propose the first efficient method for estimating the structure and parameters
of a hierarchical riffle independent model from heterogeneous datasets consisting of arbitrary
partial ranking types. Central to our approach is the idea that given someones partial preferences, we can use the efficient algorithms developed in the previous section to infer his full
preferences and consequently apply previously proposed algorithms which are designed to
work with full rankings.
6.1 Censoring Interpretations of Partial Rankings
The model estimation problem for full rankings is stated as follows. Given i.i.d. training
examples  (1) , . . . ,  (m) (consisting of full rankings) drawn from a hierarchical riffle independent distribution h, recover the structure and parameters of h.
In the partial ranking setting, we again assume i.i.d. draws, but that each training
example  (i) undergoes a censoring process producing a partial ranking consistent with  (i) .
For example, censoring might only allow for the ranking of the top-k items of  (i) to be
observed. While we allow for arbitrary types of partial rankings to arise via censoring, we
make a common assumption that the partial ranking type resulting from censoring  (i) does
not depend on  (i) itself.
510

fiEfficient Inference With Partial Rankings

6.2 Algorithm
We treat the model estimation from partial rankings problem as a missing data problem. As
with many such problems, if we could determine the full ranking corresponding to each observation in the data, then we could apply algorithms which work in the completely observed
data setting. Since full rankings are not given, we utilize an Expectation-Maximization (EM)
approach in which we use inference to compute a posterior distribution over full rankings
given the observed partial ranking. In our case, we then apply the algorithms from Huang
and Guestrin (2010, 2012) which were designed to estimate the hierarchical structure of a
model and its parameters from a dataset of full rankings.
Given an initial model h and a collection of training examples {O(1) , O(2) , . . . , O(m) }
consisting of partial rankings, our EM-based approach alternates between the following two
steps until convergence is achieved.
 (E-step): For each observation, O(i) = S (i)  (i) , in the training examples, we use
inference to compute a posterior distribution over the full ranking  that could have
generated O(i) via censoring, h(|O(i) = S (i)  (i) ). Since the observations take the
form of partial rankings and are hence completely decomposable, we use the efficient
algorithms in Section 5 to perform the E-step.
 (M-step): In the M-step, one maximizes the expected log-likelihood of the training
data with respect to the model. When the hierarchical structure of the model has been
provided, or is known beforehand, our M-step can be performed using standard methods for optimizing parameters. When the structure is unknown, we use a structural
EM approach, which is analogous to methods from the graphical models literature for
structure learning from incomplete data (Friedman, 1997, 1998).
Unfortunately, the (riffled independence) structure learning algorithm of Huang and
Guestrin (2010) is unable to directly use the posterior distributions computed from
the E-step. Instead, observing that sampling from riffle independent models can be
done efficiently and exactly (as opposed to, for example, MCMC methods), we simply
sample full rankings from the posterior distributions computed in the E-step and
pass these full rankings into the structure learning algorithm of Huang and Guestrin
(2010). The number of samples that are necessary, instead of scaling factorially, scales
according to the number of samples required to detect riffled independence (which
under mild assumptions is polynomial in n, Huang & Guestrin, 2010).

7. Related Work
Rankings and permutations have recently become an active area of research in machine
learning due in part to the hinge role that they play in information retrieval and preference
elicitation. Algorithms such as the RankSVM (Joachims, 2002) and RankBoost (Freund,
Iyer, Schapire, & Singer, 2003), for example, have been successful in the large scale ranking
problems that appear in web search. The main aims of our work differ from these web
scale settings however  instead of seeking a single optimal ranking with respect to some
objective function, we seek an understanding of a large collection of rankings via density
estimation. In the following, we outline two major lines of research which have influenced
our work.
511

fiHuang, Kapoor & Guestrin

7.1 Additive and Multiplicative Decompositions
Our paper builds in particular upon a thread of recent work on tractable models for permutation data based on function decompositions. Kondor, Howard, and Jebara (2007) and
Huang, Guestrin, and Guibas (2008, 2009) considered additive decompositions of a distribution into a weighted sum of Fourier basis functions. These papers show that low-frequency
Fourier assumptions can often be effective for coping with the representational complexity
of working with distributions over permutations. They show in particular that conditioning
prior distributions on the low frequency likelihood functions that often arise in multiobject
tracking problems can be performed especially efficiently.
Unfortunately, low frequency assumptions are not as applicable for distributions defined
over rankings, and to address ranking problems specifically, Huang and Guestrin (2009,
2010) introduced the concept of riffled independence as a useful generalization of probabilistic independence for rankings. Using multiplicative decompositions based on riffled
independence, we showed that it is possible to learn the hierarchical structure of a model
given a fully ranked dataset. While our previous papers on the topic of riffled independence
focused more on problems related to efficiently representing distributions, the main focus of
our current paper lies in efficient reasoning/inference and tackling human task complexity
by considering partial rankings.
It is interesting to note that while it is natural and efficient to condition a Fourier based
representation on low-frequency observations (involving a very small number of items) such
as O =Alice is in third place, a multiplicative decomposition based on riffled independence
would not be able to efficiently condition on the same observation. On the other hand,
multiplicative decompositions allow us to condition on top-k observations efficiently (independently of the size of k), whereas top-k observations would be difficult to handle in a
Fourier theoretic setting (except for very small k).
7.2 Mallows Models
Our work also fits into a larger body of research about the well known Mallows distribution
over rankings, parameterized by:
h(; , 0 )  d (,0 ) ,

(7.1)

where the function d refers to the Kendalls tau distance metric on rankings. A Mallows
distribution (Equation 7.1) can always be shown to be a special case of a hierarchical riffle independent model in which items are sequentially factored out of the model one by
one (Huang, 2011) (see Figure 6).
Mallows models (as well as other similar distance based models) have the advantage
that they can compactly represent distributions for very large n, and admit conjugate prior
distributions (Meila, Phadnis, Patterson, & Bilmes, 2007). Estimating parameters has been
a popular problem for statisticians  recovering the optimal 0 from data is known as the
consensus ranking or rank aggregation problem and is known to be N P -hard (Bartholdi,
Tovey, & Trick, 1989). Many authors have focused on approximation algorithms instead.
Like Gaussian distributions, Mallows models tend to lack flexibility, and so Lebanon and
Mao (2008) propose a nonparametric model of ranked (and partially ranked) data based
on placing weighted Mallows kernels on top of training examples, which, as they show, can
512

fiEfficient Inference With Partial Rankings

{Corn,Peas,Apples,Oranges,Doughnuts}

{Corn}

{Peas,Apples,Oranges,Doughnuts}

{Peas}

{Apples,Oranges,Doughnuts}
{Apples}

{Oranges,Doughnuts}
{Oranges}

{Doughnuts}

Figure 6: A Mallows model always factors according to what we refer to as a chain
structure in which items are factored out one by one. The Mallows distribution over five items from our food item set with mode (or central ranking) at
0 = Corn|P eas|Apples|Oranges|Doughnuts, for example, must factor according to the above hierarchical structure.

realize a far richer class of distributions, and can be learned efficiently. However, they do
not address the inference problem, and it is not immediately clear in many Mallows models
papers whether one can efficiently perform inference operations like marginalization and
conditioning in such models. Riffle independent models, on the other hand, encompass a
class of distributions which is both rich as well as interpretable, and additionally, we have
identified precise conditions under which efficient conditioning is possible (the conditions
being that the observations take the form of partial rankings).
There are several recent works to model partial rankings using Mallows based models.
Busse, Orbanz, and Buhmann (2007) learned finite mixtures of Mallows models from topk data (also using an EM approach). Lebanon and Mao (2008), as we have mentioned,
developed a nonparametric model based on Mallows models which can handle arbitrary
types of partial rankings. In both settings, a central problem is to marginalize a Mallows
model over all full rankings which are consistent with a particular partial ranking. To do so
efficiently, both papers rely on the fact (first shown in Fligner & Verducci, 1986) that this
marginalization step can be performed in closed form. This closed form equation of Fligner
and Verducci (1986), however, can be seen as a very special case of our setting since Mallows
models can always be shown to factor riffle independently according to a chain structure.
Specifically, to compute the sum over rankings which are consistent with a partial ranking
S , it is necessary to condition on S , and to compute the normalization constant of the
resulting function. The conditioning step can be performed using the methods that we have
described in this paper, and the normalization constant can be computed by multiplying
the normalization constant of each factor of the hierarchical decomposition. Thus, instead
of resorting to the more complicated mathematics of inversion combinatorics, our theory of
complete decomposability offers a simple conceptual way to understand why Mallows models
can be conditioned efficiently on partial ranking observations.
513

fiHuang, Kapoor & Guestrin

Finally in recent related work, Lu and Boutilier (2011) considered an even more general
class of observations based on DAG (directed acyclic graph) based observations in which
probabilities of rankings which are not consistent with a DAG of relative ranking relations
are set to zero. Lu and Boutilier show in particular that the conditioning problem for
their DAG-based class of observations is #P -hard. They additionally propose an efficient
rejection sampling method for performing probabilistic inference within the general class
of DAG observations and prove that the sampling method is exact for the class of partial
rankings that we have discussed in this paper.

8. Experiments
In this section, we demonstrate our method for learning hierarchical riffle independent models from partial rankings on simulated data as well as real datasets taken from different
domains. In all experiments, we initialize distributions to be uniform, and do not use random restarts.
8.1 Datasets
In addition to roughly 5000 full rankings, the APA dataset has over 10,000 top-k rankings of
5 candidates. In previous work, we had used only the full rankings of the APA data (Huang
& Guestrin, 2010, 2012), but now we are able to use the entire dataset. Figure 7(a) plots,
for each k  {1, . . . , 5}, the number of ballots in the APA data of length k.
Likewise, the Meath dataset (Gormley & Murphy, 2007) which was taken from the 2002
Irish Parliament election has over 60,000 top-k rankings of 14 candidates. As with the APA
data, we had used only the full rankings of the Meath data in previous work, but here we use
the entire dataset. Figure 7(b) plots, for each k  {1, . . . , 14}, the number of ballots in the
Meath data of length k. In particular, note that the vast majority of ballots in the dataset
consist of partial rather than full rankings, with over half of the electorate preferring to list
only their favorite three or four candidates. We can run inference (Algorithm 1) on over
5000 top-k examples for the Meath data in 10 seconds on a dual 3.0 GHz Pentium machine
with an unoptimized Python implementation. Using brute force inference, we estimate
that the same job would require roughly one hundred years.
We extracted a third dataset from a database of searchtrails collected by White and
Drucker (2007), in which browsing sessions of roughly 2000 users were logged during 20082009. In many cases, users are unlikely to read articles about the same news story twice,
and so it is often possible to think of the order in which a user reads through a collection
of articles as a top-k ranking over articles concerning a particular story/topic. The ability
to model visit orderings would allow us to make long term predictions about user browsing
behavior, or even recommend curriculums over articles for users. We ran our algorithms on
roughly 300 visit orderings for the eight most popular posts from www.huffingtonpost.com
concerning Sarah Palin, a popular subject during the 2008 U.S. presidential election. Since
no user visited every article, there are no full rankings in the data and thus there does not
even exist the option of learning using only the subset of full rankings.
514

fiEfficient Inference With Partial Rankings

number of votes

number of votes

6000
5000

4000
3000
2000
1000

20,000

10,000

0

0

1

2

2
3
4
5
number of candidates

4

6

8 10 12 14
k

(a) APA election data

(b) Irish election data

Figure 7: Histograms of top-k ballot lengths in the APA and Irish election datasets. Whereas
the majority of the electorate provided full rankings in the APA election data
(probably due to the fact that there were only five candidates), the vast majority
of voters in the Irish election data provided only their top-3 or top-4 choices.
{12345}

{12345}
{12345}

{2}

{2345}

{2}

{2345}
{1345}

{345}

{1}
{3}

{45}

(a) Structure learned using
only the subset of full rankings
(out of the 300 given training
examples)

{345}

{1}
{5}

{34}

(b) Structure learned using all
training examples after 1 iteration of EM

{13}
Research

{2}
Community
psychologists

{45}
Clinical

(c) Structure learned using all
training examples after structural convergence (3 iterations)

Figure 8: Structure learning with a subset of the APA dataset (300 rankings, randomly
sampled, including both full and partial rankings).

8.2 APA Structure Learning Results
Due to the unordinarily large number of full rankings in the APA data, the gains made by
additionally using partially ranked data are insignificant. To better illustrate the benefits of
partial rankings, we subsampled a dataset of 300 rankings (including both full and partial
rankings) and present results with this smaller dataset. Performing structure learning using
only the full rankings of these 300 training examples (consisting of roughly 100 examples),
one obtains the structure in Figure 8(a), which can be seen to not match the correct
structure of Figure 3(a) which was learned using 5000 full rankings. Figures 8(b) and 8(c)
515

fiHuang, Kapoor & Guestrin

training time (seconds)

test log-likelihood

x 10 4
-2
-3
-4
-5

-6
EM

Flat-EM

4

training time (seconds)

test log-likelihood

-5
-5.2
-5.4
-5.6
-5.8
-6
k>2

10
5

0
EM

Flat-EM Uniform
Fill-In

(b) Training time comparison of our
EM approach against the FlatEM and
Uniform Fill-In methods.

x 10

k>1

15

Uniform
Fill-In

(a) Test set log-likelihood comparison
of our EM approach against the FlatEM
and Uniform Fill-In methods.

k>0

20

2.5
2
1.5

1

k>3

(c) Test set log-likelihoods, training
only with top-t rankings with t larger
than a fixed k.

k>0

k>1

k>2

k>3

(d) Training times, training only with
top-t rankings with t larger than a fixed
k.

Figure 9: APA experimental results  each experiment repeated with 200 bootstrapped
resamplings of the data

plot the results of our EM algorithm with the former displaying the resulting structure after
just a single EM iteration and the latter the result after structural convergence, which occurs
by the third iteration, showing that our method can learn the correct structure given just
300 training examples.
We compared our EM algorithm against two alternative baseline approaches that we
refer to in our plots as FlatEM and Uniform Fill-in. The FlatEM algorithm is the same as
the EM algorithm above except for two details: (1) it performs conditioning exhaustively
instead of exploiting the factorized model structure, and (2) it performs the M-step without
sampling. The Uniform Fill-in approach treats every top-k ranking in the training set as
a uniform collection of votes for all of the full rankings consistent with that top-k ranking,
and is accomplished by using just one iteration of our EM algorithm.
In Figure 9(a) we plot test set loglikelihoods corresponding to each approach, with EM
and FlatEM having almost identical results and both performing much better than the
Uniform Fill-in approach. On the other hand, Figure 9(b), which compares running times
of the three approaches, shows that FlatEM can be far more costly (for most datasets, it
cannot even be run in a reasonable amount of time).
516

fiEfficient Inference With Partial Rankings

1st iteration

2nd iteration

{0,1,2,3,4,5,6,7}

3rd iteration

{0,1,2,3,4,5,6,7}
{0,1,2,3,4,5,6,7}

{5}

{0,1,2,3,4,6,7}

{5}

{0,1,2,3,4,6,7}
{5}

{0,1,2,3,4,7}

{6}

{0,1,2,3,4,7}

{0,1,2,3,4,6,7}

{7}
{0,1,2,3,4,7}

{0,1,2,3,4}

{7}

{0,1,2,3,4}

{6}
{0,2,3}

{0,2,3}

{1,4}

Log likelihood: -818.6579
(a)

{0,2,3}

{7}

{1,4,6}

{1,4}

Log likelihood: -769.2369
(b)

Log likelihood: -767.2760
(c)

Figure 10: Iterations of Structure EM for the Sarah Palin data with structural changes at
each iteration highlighted in red. Structural convergence occurs after just three
iterations. Note that this structure was discovered using only visit orders, and
that no text information from pages was incorporated in the learning process.
This figure is best viewed in color.

To verify that partial rankings do indeed make a difference in the APA data, we plot
the results of estimating a model from the subsets of APA training data consisting of top-k
rankings with length larger than some fixed k. Figures 9(c) and 9(d) show the log-likelihood
and running times for k = 0, 1, 2, 3 with k = 0 being the entire training set and k = 3
being the subset of training data consisting only of full rankings. As our results show,
including partial rankings does indeed help on average for improving test log-likelihood
(with diminishing returns).
8.3 Structure Discovery with EM with Larger n.
Our experiments have led to several observations about using EM for learning with partial
rankings. First, we observe that typical runs converge to a fixed structure quickly, with no
more than three EM iterations. Figure 10 shows the progress of EM on the Sarah Palin
data, whose structure converges by the third iteration. As expected, the log-likelihood
increases at each iteration, and we remark that the structure becomes more interpretable
 for example, the leaf set {0, 2, 3} corresponds to the three posts about Palins wardrobe
before the election, while the posts from the leaf set {1, 4, 6} were related to verbal gaffes
made by Palin during the campaign. Notice that this structure is discovered purely using
data about visit orders and that no text information was used in our experiments.
517

fiHuang, Kapoor & Guestrin

-2.72

x 104

test log-likelihood

# of EM iterations before
convergence

30

25
20
15

10

EM with
decomposable
conditioning

-2.8

[Lebanon & Mao, 08]

-2.84
-2.88

5
0

-2.76

0

0 1 2 3 4 5 6 7 8 9 10 11 12
k

250 1000 4000 16000 64000
# of partial rankings in training set
(in addition to full rankings)

(a)

(b)

Figure 11: (a): Number of EM iterations required for convergence if the training set only
contains rankings of length longer than k. (b): Density estimation from synthetic
data. We plot test loglikelihood when learning from 343 full rankings and between
0 and 64,000 additional partial rankings.

5000 training
examples

4

Test log-likelihood

x 10
-4.5

Ours

-4.6

25000 training
examples

5

x 10
-1.26

[LM08]

[LM08]

-1.28

Ours

-1.3

-4.7

Ours

-1.32

[LM08]
Ours

-4.8

[LM08]

-1.34

-4.9

Full only

Mixed (Full+Partial)

Full only

Mixed (Full+Partial)

Figure 12: Density estimation from small (5000 examples) and large subsets (25000 examples) of the Meath data. We compare our method against the work by Lebanon
and Mao (2008) in two settings: (1) training on all available data and (2) training
on the subset of full rankings.

Secondly, the number of EM iterations required to reach convergence in log-likelihood
depends on the types of partial rankings observed. We ran our algorithm on subsets of
the Meath dataset, each time training on m = 2000 rankings all with length larger than
518

fiEfficient Inference With Partial Rankings

some fixed k. Figure 11(a) shows the number of iterations required for convergence as a
function of k (with 20 bootstrap trials for each k). We observe fastest convergence for
datasets consisting of almost-full rankings and slowest convergence for those consisting of
almost-empty rankings, with almost 25 iterations necessary if one trains using rankings of
all types. Finally we remark that the model obtained after the first iteration of EM is
interesting and can be thought of as the result of pretending that each voter is completely
ambivalent regarding the n  k unspecified candidates.
8.4 The Value of Partial Rankings
We now verify again with larger n that using partial rankings in addition to full rankings
allows us to achieve better density estimates. We first learned models from synthetic data
drawn from a hierarchy, training using 343 full rankings plus varying numbers of partial
ranking examples (ranging between 0-64,000). We repeat each setting with 20 bootstrap
trials, and for evaluation, we compute the log-likelihood of a testset with 5000 examples.
For speed, we learn a structure H only once and fix H to learn parameters for each trial.
Figure 11(b), which plots the test log-likelihood as a function of the number of partial
rankings made available to the training set, shows that we are indeed able to learn more
accurate distributions as more and more data in the form of partial rankings are made
available.
8.5 Comparing to a Nonparametric Model
Comparing the performance of riffle independent models to other approaches was not possible in previous work since we had not been able to handle partial rankings. Using the
methods developed in our current paper, however, we compare riffle independent models
with the state-of-the-art nonparametric estimator of Lebanon and Mao (2008) (to which we
hereby refer as the LM08 estimator) on the same data (setting their regularization parameter to be C =1,2,5, or 10 via a validation set). Figure 11(b) shows (naturally) that when the
data are drawn synthetically from a riffle independent model, then our EM method significantly outperforms the LM08 estimator. We remark that in theory, the LM08 is guaranteed
to catch up in performance (under appropriate conditions) given enough training examples.
For the Meath data, which is only approximately riffle independent, we trained on subsets
of size 5,000 and 25,000 (testing on remaining data). For each subset, we evaluated our EM
algorithm for learning a riffle independent model against the LM08 estimator when (1)
using only full ranking data, and (2) using all data. As before, both methods do better
when partial rankings are made available.
For the smaller training set, the riffle independent model performs as well or better than
the LM08 estimator. For the larger training set of 25,000, we see that the nonparametric
method starts to perform slightly better on average, the advantage of a nonparametric
model being that it is guaranteed to be consistent, converging to the correct model given
enough data. The advantage of riffle independent models, however, is that they are simple,
interpretable, and can highlight global structures hidden within the data.
519

fiHuang, Kapoor & Guestrin

9. Future Directions
There remain several possible extensions to the current work. We list a few such open
questions and extensions in the following.
9.1 Inference with Incomplete Rankings
We have shown in this paper that one can exploit riffled independence structure to condition
on an observation if and only if it takes the form of a partial ranking. While the space of
partial rankings is both rich and useful in many settings, it does not cover an important class
of observations: that of incomplete rankings, which are defined to be a ranking (or partial
ranking) of a subset of the itemset . For example, Theorem 21 shows that the conditioning problem for pairwise observations of the form Apples are preferred over Bananas is
nondecomposable. Note that top-k rankings are considered to be complete rankings since
they implicitly rank all other items in the last n  k positions.
How then, can we tractably condition on incomplete rankings? One possible approach
is to convert to a Fourier representation using the methods from (Huang & Guestrin, 2012),
then conditioning on a pairwise ranking observation using the Fourier domain conditioning
algorithm proposed in (Huang et al., 2008). This Fourier domain approach would be useful if one were particularly interested in low-order marginal probabilities of the posterior
distributions.
When the Fourier approach is not viable, another option may be to assume that the
posterior distribution takes on a particular riffle independent structure (in the same way
that mean field methods from the graphical models literature would assume a factorized
posterior). The research question of interest is: which hierarchical structure should be used
for the purposes of approximating the posterior?
9.2 Reexamining Data Independence Assumptions
In this paper, we have assumed throughout that training examples are independent and
identically distributed. However in practice these are not always safe assumptions as a
number of factors can impact the validity of both. For example, in an internet survey in
which a user must perform a series of preference ranking tasks in sequence, a concern is that
the users prior ranking tasks may bias the results of his future rankings.
Another source of bias lies in the reference ranking that may be displayed, in which the
user is asked to rearrange items by dragging and dropping. On the one hand, showing
everyone the same reference ranking may bias the resulting data. But on the other hand,
showing every user a different reference ranking may mean that the training examples are
not exactly identically distributed.
Yet another form of bias lies in the partial ranking types that are reported in data. To
formulate our EM algorithm, we have assumed that a users preferences does not influence
whether he chooses to, say, report a full ranking instead of a top-3 ranking. In practice,
however, partial ranking types and user preferences are often correlated. In the Irish elections, for example, where there is typically only one Sinn Fein candidate, those who rank
Sinn Fein first are typically more likely to have only reported their top-1 choice.
520

fiEfficient Inference With Partial Rankings

Understanding, identifying, and finally, learning in spite of the different types of biases
that may occur in eliciting preference data remains a fundamental problem in ranking.
9.3 Probabilistic Modeling of Strategic Voting
It is interesting to consider the differences between the actual vote distributions considered in
this paper against the approximate riffle independent distributions. Take the APA dataset,
for example, in which the optimal approximation by a riffle independent hierarchy reflects
the underlying political coalitions within the organization. Upon comparison between the
approximation and the empirical distribution, however, some marked differences arise. For
example, the riffle independent approximation underestimates the number of votes obtained
by candidate 3 (a research psychologist) who ultimately won the election.
One possible explanation for the discrepancy may lie in the idea that voters tend to vote
strategically in APA elections, placing stronger candidates of opposing political coalitions
lower in the ranking, rather than revealing their true preferences. An interesting line of
future work lies in detecting and studying the presence of such strategic voting in election
datasets. Open questions include (1) verifying mathematically whether strategic voting does
indeed exist in, say, the APA election data, and (2) if so, why the strategic voting effect is
not strong enough to overwhelm our riffled independence structure learning algorithms, and
(3) how strategic voting can manifest itself in partial ranking votes.

10. Conclusion
In probabilistic reasoning problems, it is often the case that certain data types suggest
certain distribution representations. For example, sparse dependency structure in the data
often suggests a Markov random field (or other graphical model) representation (Friedman,
1997, 1998). For low-order permutation observations (depending on only a few items at a
time), recent work (Huang et al., 2009; Kondor, 2008) has shown that a Fourier domain
representation is appropriate. For preference ranking scenarios, one must contend with
human task complexity  the difficulty involved for a human to rank a long list of items
and often leads to partially, instead of fully ranked data. In this paper, we have shown that
when data takes the form of partial rankings, then hierarchical riffle independent models are
a natural representation.
As with conjugate priors, we showed that a riffle independent model is guaranteed to
retain its factorization structure after conditioning on a partial ranking (which can be performed in efficiently). Most surprisingly, our work shows that observations which do not
take the form of partial rankings are not amenable to simple multiplicative update based
conditioning algorithms. Finally, we showed that it is possible to learn hierarchical riffle
independent models from partially ranked data, significantly extending the applicability of
previous work.

Acknowledgments
This project was formulated and largely conducted during an internship by Jonathan Huang
at Microsoft Research. Additional work was supported in part by ONR under MURI
N000140710747, and ARO under MURI W911NF0810242. Carlos Guestrin was funded
521

fiHuang, Kapoor & Guestrin

in part by NSF Career IIS-064422. We thank Eric Horvitz, Ryen White, Dan Liebling, and
Yi Mao for discussions.

Appendix A. Proofs
In this appendix, we provide supplementary proofs of some of the theoretical results in this
paper.
A.1 Proof of Theorem 19
To prove Theorem 19 (as well as later results), we will refer to rank sets.
Definition 32. Given a partial ranking of type , we denote the rank set occupied by
i by Ri . Note that Ri depends only
on  and can be written as R1 = {1, . . . , 1 },
P
R2 = {1 + 1, . . . , 1 + 2 }, . . . , Rr = { r1
i=1 i + 1, . . . , n}.
And we will refer to the following basic fact regarding rank sets:
Proposition 33.   S  = 1 | . . . |r if and only if for each i, (i ) = Ri .
Proof. (of Theorem 19) We use induction on the size of the itemset. The cases n = 1, 2 are
trivial since every distribution on S1 or S2 factors riffle independently. We now consider the
more general case of n > 2.
Fix a partial ranking S  = 1 |2 | . . . |r of type  and a binary partition of the item
set into subsets A and B. We will show that the indicator function S  factors as:
S  () = m(AB ())  f (A ())  g(B ()),

(A.1)

where factors m, f and g are the indicator functions for the set of consistent interleavings,
[S ]AB , and the sets of consistent relative rankings, [S ]A and [S ]B , respectively. If
Equation A.1 is true, then we will have shown that S  must decompose with respect
to the top layer of H. To show that S  decomposes hierarchically, we must also show
that the relative ranking factors fA and gB decompose with respect to HA and HB , the
subhierarchies over the item sets A and B. To establish this second step (assuming that
Equation A.1 holds), note that fA and gB are indicator functions for the restricted partial
rankings, [S ]A and [S ]B , which themselves are partial rankings over smaller item sets
A and B. The inductive hypothesis (and the fact that A and B are assumed to be strictly
smaller sets than ) then shows that the functions fA and gB both factor according to their
respective subhierarchies.
We now turn to establishing Equation A.1. It suffices to prove that the following two
statements are equivalent:
I. The ranking  is consistent with the partial ranking S  (i.e.,   S ).
II. The following three conditions hold:
(a) The interleaving AB () is consistent with S  (i.e., AB ()  [S ]AB ), and
(b) The relative ranking A () is consistent with S  (i.e., A ()  [S ]A ), and
(c) The relative ranking B () is consistent with S  (i.e., B ()  [S ]B ).
522

fiEfficient Inference With Partial Rankings

 (I  II): We first show that   S  implies conditions (a), (b) and (c).
(a) If   S , then for each i,
|j  Ri : AB (j) = A| = |j  Ri :  1 (j)  A|,
= |k  i : k  A|,

(by Definition 2)

(by Proposition 33)

= |i  A|.
The same argument (replacing A with B) shows that for each i, we have |j 
Ri : AB (j) = B| = |i  B|. These two conditions (by Definition 17) show that
AB is consistent with S .
(b) If   S , then (by Definition 14)  ranks items in i before items in j for any
i < j. Intersecting each i with A, we also see that  ranks any item in i  A
before any item in j  A for all i, j. By Definition 2, A () also ranks any item
in i  A before any item in j  A for all i, j. And finally by Definition 16 again,
we see that A () is consistent with the partial ranking S .
(c) (Same argument as (b)).
 (II  I): We now assume conditions (a), (b), and (c) to hold, and show that   S .
By Proposition 33 it is sufficient to show that if an item k  i , then (k)  Ri . To
prove this claim, we show by induction on i that if an item k  i  A, then (k)  Ri
(and similarly if k  i  B, then (k)  Ri ).
Base case. In the base case (i = 1), we assume that k  1 A, and the goal is to show
that (k)  R1 . By condition (a), we have that AB ()  [S ]AB . By Definition 17,
this means that: |1  A| = {j  R1 : [AB ()](j) = A} = {j  R1 :  1 (j)  A}. In
words, there are m = |1  A| items from A which lie in rank set R1 = {1, . . . , 1 }. To
show that an item k  A maps to a rank in R1 , we now must show that in the relative
ranking of elements in A, k is among the first m. By condition (b), A ()  [S ]A ,
implying that the item subset 1  A occupies the first m positions in the relative
ranking of A. Since k  1  A, item k is among the first m items ranked by A ()
and therefore (k)  R1 . A similar argument shows that k  1  B implise that
(k)  R1 .
Inductive case. We now show that if k  i  A, then (k)  Ri . By condition (b),
A ()  [S ]A , implying that the item subset i A (and hence, item k) occupies the
first m = |i  A| positions in the relative ranking of A beyond the items i1
j=1 (j 
A). By the inductive hypothesis and mutual exclusivity, these items, together with
i1
i1
j=1 (j  B) occupy ranks j=1 Rj , and therefore (k)  R` for some `  i. On the
other hand, condition (a) assures us that |i  A| = {j  Ri :  1 (j)  A}  or in
other words, that the ranks in Ri are occupied by exactly m items of A. Therefore,
(k)  Ri . Again, a similar argument shows that k  i  B implies that (k)  Ri .

A.2 The pspan of a Set is Always a Partial Ranking
To reason about the pspan of a set of rankings, we first introduce some basic concepts
regarding the combinatorics of partial rankings. The collection of partial rankings over 
523

fiHuang, Kapoor & Guestrin

forms a partially ordered set (poset) where S 0  0  S  if S  can be obtained from S 0  0 by
dropping vertical lines. For example, on S3 , we have that 1|2|3  12|3. The Hasse diagram
is the graph in which each node corresponds to a partial ranking and a node x is connected
to node y via an edge if x  y and there exists no partial ranking z such that x  z  y
(see Lebanon & Mao, 2008). At the top of the Hasse diagram is the partial ranking 1, 2, . . . , n
(i.e., all of S ) and at the bottom of the Hasse diagram lie the full rankings. See Figure 13
for an example of the partial ranking lattice on S3 .
Lemma 34. [Lebanon & Mao, 2008] Given any two partial rankings S , S 0  0 , there
exists a unique supremum of S  and S 0  0 (a node Ssup sup such that S   Ssup sup
and S 0  0  Ssup sup , and any other such node is greater than Ssup sup ). Similarly, there
exists a unique infimum of S  and S 0  0 .
Lemma 35. Given two partial rankings S , S 0  0 , the relation S 0  0  S  holds if and
only S  lies above S 0  0 in the Hasse diagram.
Proof. If S  lies above S 0  0 in the Hasse diagram, then S 0  0  S  is trivial since S 
can be obtained by dropping vertical bars of S 0  0 . Now given that S  does not lie above
S 0  0 , we would like to show that S 0  0 6 S . Let Sinf inf be the unique infimum of
S  and S 0  0 as guaranteed by Lemma 34. By the definition of the Hasse diagram, both
S  and S  can be obtained by dropping verticals from the vertical bar representation
of Sinf inf . Since S  does not lie above S 0  0 , there must be a vertical bar that was
dropped by S 0  0 which was not dropped by S  (if there does not exist such a bar, then
S 0  0  S ), and hence there must exist a pair of items i, j separated by a single vertical
bar in S  but unseparated in S 0  0 . Therefore there exists   S 0  0 such that (j) < (i)
even though there exists no such   S . We conclude that S 0  0 6 S .
Lemma 36 (Lemma 23 in main body). For any X  Sn , pspan(X) is a partial ranking.
Proof. Consider any subset X  Sn . A partial ranking containing every element in X
must be an upper bound of every element of X in the Hasse diagram by Lemma 35. By
Lemma 34, there must exist a unique least upper bound (supremum) of X, Ssup sup , such
that for any common upper bound S  of X, S  must also be an ancestor of Ssup sup and
hence Ssup sup  S . We therefore see that any partial ranking containing X must be a
superset of Ssup sup . On the other hand, Ssup sup is itself a partial ranking containing X.
Since pspan(X) is the intersection of partial rankings containing X, we have pspan(X) =
Ssup sup and therefore that pspan(X) must be a partial ranking.
A.3 Proofs for the Claim that rspan(X) = pspan(X)
To simplify the notation in some of the remaining proofs, we introduce the following definition.
Definition 37 (Ties). Given a partial ranking S  = 1 | . . . |r , we say that items a1 and
a2 are tied (written a1  a2 ) with respect to S  if a1 , a2  i for some i.
The following basic properties of the tie relation are straightforward.
Proposition 38.
524

fiEfficient Inference With Partial Rankings

123
1|23

12|3

13|2

2|13

3|12

23|1

1|2|3

1|3|2

2|1|3

3|1|2

2|3|1

3|2|1

Figure 13: The Hasse diagram for the lattice of partial rankings on S3 .
I. With respect to a fixed partial ranking S , the tie relation, , is an equivalence relation
on the item set (i.e., is reflexive, symmetric and transitive).
II. If there exist ,  0  S  which disagree on the relative ranking of items a1 and a2 ,
then a1  a2 with respect to S .
III. If S   S 0  0 , and a1  a2 with respect to S , then a1  a2 with respect to S 0  0 .
IV. If a1  a2 with respect to S , and (a1 ) < (a3 ) < (a2 ) for some item a3   and
some   S , then a1  a2  a3 .
Proposition 39. Given a set of rankings X as input, Algorithm 2 outputs pspan(X).
Proof. We prove three things, which together prove the proposition: (1) that the algorithm
terminates, (2) that at each stage the elements of X are contained in pspan(X), and (3)
that upon termination, pspan(X) is contained in each element of X.
1. First we note that the algorithm must terminate in finitely many iterations of the while
loop since at each stage at least one vertical bar is removed from a partial ranking,
and when all of the vertical bars have been removed from the elements of X, there are
no disagreements on relative ordering.
2. We now show that at any stage in the algorithm, every element of Xt is a subset of
the pspan(X). At initialization, of course, if S   X0 , then it is simply a singleton
set consisting of an element of X, and therefore S   pspan(X).
Suppose now that S   pspan(X) for every S   Xt . If S  is replaced by S 
in Xt+1 , then we want to show that S   pspan(X) as well. From Algorithm 2,
for some j, if S  = 1 | . . . |j |j+1 | . . . |r , S  can be written as 1 | . . . |j 
j+1 | . . . |r , where the vertical bar between j and j+1 is deleted due to the existence
of some partial ranking in Xt , S 0  0  Xt which disagrees with S  on the relative
ordering of items a1 , a2 on opposite sides of the bar. Since S  and S 0  0 are both
subsets of pspan(X) by assumption, we know that a1  a2 with respect to pspan(X)
(Proposition 38, II). Suppose now that a1  i and a2  i0 . Then for any x  i
and y  i0 , we have x  a1 and y  a2 with respect to pspan(X) by (III) of
Proposition 38. Moreover, by (I, transitivity), we see that x  y with respect to
pspan(X). for any two elements of i and i0 . By (IV) of Proposition 38, all the
items lying in i , i+1 , . . . , i0 are thus tied with respect to pspan(X) and therefore
removing any bar between items a1 and a2 (producing, for example, S ) results in a
partial ranking which is a subset of pspan(X).
525

fiHuang, Kapoor & Guestrin

3. Finally, upon termination, if some ranking   X is not contained in some element
S   Xt , then there would exist two items a1 , a2 whose relative ranking  and S 
disagree upon, which is a contradiction. Therefore, every element S   Xt contains
every element of X and thus pspan(X)  S  for every S   Xt .

Lemma 40. Let S  = 1 | . . . |i |i+1 | . . . |k be a partial ranking on item set , and
S 0  0 = 1 | . . . |i  i+1 | . . . |k , the partial ranking in which the sets i and i+1 are
merged. Let a1  ij=1 j and a2  kj=i+1 j . If O is any element of C such that S   O
and there additionally exists a ranking   O which disagrees with S  on the relative
ordering of a1 , a2 , then S 0  0  O.
Proof. We will fix a completely decomposable O and again work with h, the indicator
distribution corresponding to O. Let   S 0  0 . To prove the lemma, we need to establish
that h() > 0. Let  0 be any element of S  such that  0 (k) = (k) for all k  \(i i+1 ).
Since S   supp(h) by assumption, we have that h( 0 ) > 0.
Since  0 and  match on all items except for those in i  i+1 , there exists a sequence
of rankings  0 ,  1 ,  2 , . . . ,  m =  such that adjacent rankings in this sequence differ only
by a pairwise exchange of items b1 , b2  i  i+1 . We will now show that at each step
along this sequence, h( t ) > 0 implies that h( t+1 ) > 0, which will prove that h() > 0.
Suppose now that h( t ) > 0 and that  t and  t+1 differ only by the relative ranking of
items b1 , b2  i  i+1 (without loss of generality, we will assume that  t (b2 ) <  t (b1 ) and
 t+1 (b1 ) <  t+1 (b2 )).
The idea of the following paragraph is to use the previous lemma (Lemma 28) to prove
that  t+1 has positive probability and to do so, it will be necessary to argue that there
exists some ranking  0 such that h( 0 ) > 0 and  0 (b1 ) <  0 (b2 ) (i.e.,  0 disagrees with  t
on the relative ranking of b1 , b2 ). Let  be any element of S . If a1  i , rearrange 
such that a1 is ranked first among elements of i . If a2  i+1 , further rearrange  such
that a2 is ranked last among elements of i+1 . Note that  is still an element of S  after
the possible rearrangements and therefore h() > 0. We can assume that (b2 ) < (b1 )
since otherwise we will have shown what we wanted to show. Thus the relative ordering of
a1 , a2 , b1 , b2 within  is a1 |b2 |b1 |a2 . Note that we treat the case where the items a1 , a2 , b1 , b2
are distinct, but the same argument follows in the cases when a1 = b2 or a2 = b1 .
Now since  disagrees with S  on the relative ordering of a1 , a2 by assumption (and
hence disagrees with ), we apply Lemma 28 to conclude that swapping the relative ordering
of a1 , a2 within  (obtaining a2 |b2 |b1 |a1 ) results in a ranking,  0 , such that h( 0 ) > 0.
Finally, observe that  and  0 must now disagree on the relative ranking of a2 , b2 , and
invoking Lemma 28 again shows that we can swap the relative ordering of a2 , b2 within 
(obtaining a1 |a2 |b1 |b2 ) to result in a ranking  0 such that h( 0 ) > 0. This element  0 ranks
b1 before b2 , which is what we wanted to show.
We have shown that there exist rankings which disagree on the relative ordering of b1
and b2 with positive probability under h. Again applying Lemma 28 shows that we can swap
the relative ordering of items b1 , b2 within  t to obtain  t+1 such that h( t+1 ) > 0, which
concludes the proof.
526

fiEfficient Inference With Partial Rankings

A.4 Uniformity of C Functions Over a Partial Ranking
We have thus far shown that any element of C must be supported on some partial ranking.
In the following, we show that (up to a certain class of exceptions), such an element must
assign uniform probability to all members of this partial ranking.
Theorem 41. If h is any completely decomposable function supported on a partial ranking
S  = 1 | . . . |r where |i | =
6 2 for all i = 1, . . . , r, then h is uniform on S  (i.e.,
1
Q
h() =
|i | for all   S ).
i

To establish Theorem 41, we must establish two supporting results: (1) Lemma 42 which
factors h into r smaller completely decomposable functions, each of which is nonzero everywhere on its domain, and (2) Theorem 43 which establishes uniformity for any completely
decomposable function which is nonzero everywhere on its domain.
Lemma 42. Any completely decomposable Q
function, h, supported on the partial ranking
S  = 1 | . . . |r , must factor as: h() = ri=1 h((i )), where each factor distribution
h((i )) is itself a completely decomposable function on Si .
Proof. Since h is completely decomposable, we have that (i ) is riffle independent of
(\i ) for each i. Since h is supported on the partial ranking S  = )1 | . . . |r , however,
the interleaving of i with its complement is deterministic and therefore we conclude in fact
that (i ) is fully independent
of (\i ). Since (i )  (\i ) for each i, we have the
Qr
factorization: h() = i=1 h((i )).
We now turn to establishing that each factor h((i )) is itself a completely decomposable
observation. Fix i = 1 (without loss of generality) and consider any partition of the set 1
into subsets A  B. We would like to see that the sets A and B are riffle independent of each
other with respect to h((1 )). Since h is assumed to be completely decomposable, we know
that A is riffle independent of its complement, B(\1 ). In other words, if B = B(\1 ),
then the variables A (), AB , B (the relative ranking of A, the interleaving of A with all
remaining items, and the relative ranking of all remaining items, respectively) are mutually
independent. We then observe that (1) the interleaving of A and B, AB , is a deterministic
function of the interleaving of AB and (2) the relative ranking of B, B , is a deterministic
function of B , thus proving that A , AB and B are mutually independent and hence that
A and B are riffle independent.
Theorem 43. Let h a completely decomposable function such that h() > 0 for all   Sn
for n > 2. Then for any two rankings 1 , 2 which differ by a single transposition, we have
h(1 ) = h(2 ).
Our proof strategy for Theorem 43 will involve examining the ratio between the two
probabilities h(1 ) and h(2 ). We then define an operation transforming 1 and 2 into new
rankings 10 and 20 such that the ratio between the rankings is preserved (i.e., h(1 )/h(2 ) =
h(10 )/h(20 )). By performing a sequence of such ratio-preserving operations, we show that:
h(1 )
h(2 )
=
,
h(2 )
h(1 )
from which Theorem 43 easily follows.
527

fiHuang, Kapoor & Guestrin

We will use two types of operations which transform a ranking into a new ranking: (1)
changing the interleaving of two sets A and B within a ranking , and (2), changing the
relative ranking of a set A within a ranking . More precisely, given a ranking  and a
partitioning of the item set into subsets A and B, we can uniquely index  as a triplet
(, A , B ), where  = A,B (), A = A (), and B = B (). The two operations are
defined as follows:
1. Changing the interleaving of A, B within  to  0 : yields the new ranking  0 which is
indexed by ( 0 , A , B ).
0 (or  0 ): yields the new
2. Changing the relative ranking of A (or B) within  to A
B
0
0
0
ranking  which is indexed by (, A , B ) [or (, A , B )].

If we use the above operations to obtain from 10 and 20 , we are interested in conditions
under which this transformation is ratio-preserving (i.e., h(1 )/h(2 ) = h(10 )/h(20 )). The
following lemma provides sufficient conditions for ratio-preservation.
Lemma 44. Let h be any completely decomposable function and consider 1 , 2  Sn such
that h(2 ) > 0. Then for any partitioning of the item set into subsets A and B, we have:
1. If 1 and 2 match on the interleaving of A and B (i.e., A,B (1 ) = AB (2 )), then
h(10 )
h(1 )
0
0
h(2 ) = h(20 ) , where 1 and 2 are formed by changing the interleaving of the sets A
and B within 1 and 2 to be any new interleaving  0 .
2. If 1 and 2 match on the relative ranking of A (or B) (i.e., A (1 ) = A (2 ) (or
h( 0 )
h(1 )
= h(10 ) , where 10 and 20 are formed by changing the
B (1 ) = B (2 ))), then h(
2)
2
0
relative ranking of set A (or B) within 1 and 2 to be any new relative ranking A
0
(or B ).
Proof. Since the proofs of parts 1 and 2 are nearly identical, we just prove part 1 here.
Since h  C, the sets A and B are riffle independent by assumption, and hence we have the
factorizations:
h(1 )
m(1 )  f (1A )  g(2B )
=
.
h(2 )
m(2 )  f (2A )  g(2B )

If 1 and 2 match on the interleaving of the sets A and B, then we have that  = 1 = 2 ,
and thus the interleaving terms, m(1 ) and m(2 ) are the same in both the numerator and
denominator.
On the other hand, if we examine the ratio between h(10 ) and h(20 ), we also see that
the interleaving terms must cancel:
h(1 )
m(10 )  f (1A )  g(2B )
=
.
h(2 )
m(20 )  f (2A )  g(2B )

We therefore have that:
f (1A )  g(piB
h(10 )
h(1 )
1 )
=
=
.
A
B
h(2 )
h(20 )
f (2 )  g(2 )

528

fiEfficient Inference With Partial Rankings

Having now established Lemma 44, we turn to establishing three short claims (using
the lemma) that will allow us to prove finally prove Theorem 43. It is interesting to note
that we require n > 2 (strictly) in claim III below in which we swap the order of i and j
in numerator and denominator. The third item k in our proof below can be thought of as
playing the role of a dummy variable analogous to the temporary storage variables that one
might use in implementing a swap function. The necessity of this third item is precisely why
our result does not hold in the special case that n = 2.
Proposition 45. Let h : Sn  R be a completely decomposable function with n > 2 with
h() > 0 for all   Sn . We have the following equivalences (where in each of the below
ratios, entries which have not been explicitly written out are assumed to match identically
in both the numerator and denominator).
I.

II.

h(i|j| . . . |k| . . . )
h(i|j|k| . . . )
=
.
h(j|i| . . . |k| . . . )
h(j|i|k| . . . )
h(. . . |i| . . . |j| . . . )
h(i|j| . . . )
=
.
h(. . . |j| . . . |i| . . . )
h(j|i| . . . )

III.

h(j|i|k| . . . )
h(i|j|k| . . . )
=
.
h(j|i|k| . . . )
h(i|j|k| . . . )

Proof.
I. Equality holds in I since 1 and 2 match on the interleaving of the sets A = {k} with
B = \{k}. Thus we can change the interleaving of A and B in both 1 and 2 so
that item k is inserted in rank 3 while preserving the ratio.
II. Equality holds in II since 1 and 2 match on the interleaving of the sets A = {i, j}
with B = \{i, j}. Thus we can change the interleaving of A and B in both 1 and
2 so that items i and j occupy the first two ranks while preserving the ratio between
h(1 ) and h(2 ).
III. In the following we use 1 and 2 to refer to the arguments in the numerator and
denominator, respectively, of the preceding line.
h(i|j|k| . . . )
h(i|k|j| . . . )
=
,
h(j|i|k| . . . )
h(k|i|j| . . . )
h(j|i|k| . . . )
=
,
h(j|k|i| . . . )
h(i|j|k| . . . )
=
,
h(i|k|j| . . . )
h(k|j|i| . . . )
=
,
h(k|i|j| . . . )
h(j|i|k| . . . )
=
,
h(i|j|k| . . . )

(since 1 , 2 match on the relative ranking of {j, k})
(since 1 , 2 match on the interleaving of {j} with \{j})
(since 1 , 2 match on the relative ranking of {i, j})
(since 1 , 2 match on the relative ranking of {i, k})
(since 1 , 2 match on the interleaving of {k} with \{k}).

529

fiHuang, Kapoor & Guestrin

Proof. (of Theorem 43) We want to show that if two rankings differ by a single transposition,
then they are assigned equal probability under h. Suppose then that 2 is obtained from
1 by swapping the ranks of items i and j. Additionally, let k be any item besides i and j
(such an item must exist since n > 2). In the following, we use Proposition 45 to show that
h(1 )/h(2 ) = h(2 )/h(1 ). As before, entries which have not been explicitly written out
are assumed to match identically in both the numerator and denominator.
h(. . . |i| . . . |j| . . . )
h(i|j| . . . )
h(1 )
=
=
, (by Prop. 45, Part II)
h(2 )
h(. . . |j| . . . |i| . . . )
h(j|i| . . . )
h(i|j| . . . |k| . . . )
h(i|j|k| . . . )
=
=
, (by Prop. 45, Part I)
h(j|i| . . . |k| . . . )
h(j|i|k| . . . )
h(j|i|k| . . . )
, (by Prop. 45, Part III)
=
h(i|j|k| . . . )
h(j|i| . . . |k| . . . )
=
, (by Prop. 45, Part I)
h(i|j| . . . |k| . . . )
h(j|i| . . . )
h(. . . |j| . . . |i| . . . )
=
=
, (by Prop. 45, Part II)
h(i|j| . . . )
h(. . . |i| . . . |j| . . . )
h(2 )
=
.
h(1 )

Since we have assumed h(1 ) and h(2 ) > 0, we must conclude that h(1 ) = h(2 ).
Finally, we assemble all of our supporting results to prove Theorem 41.
Proof. (of Theorem 41) By Lemma 42, a completely decomposable function h must factor
as:
r
Y
h() =
h((i )),
(A.2)
i=1

where each factor distribution h((i )) is itself a completely decomposable function on Si .
By assumption, |i | 6= 2. If |i | = 1, then its corresponding factor h((i )) must trivially
be uniform. Otherwise, we have that |i | > 2. In this latter case, we apply Theorem 43 to
h((i )) to show that it must assign equal probability to any two rankings that differ by a
single transposition. However, given any rankings 1 , 2  Si , we can obtain a sequence of
transpositions that transforms 1 into 2 , and therefore, Theorem 43 in fact implies that the
factor h((i )) is constant on all inputs. Having proved that each factor in Equation A.2 is
constant, we conclude that h must be constant on its support.

References
Ailon, N. (2007). Aggregation of partial rankings, p-ratings and top-m lists. In Proceedings
of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, SODA 07,
New Orleans, Louisiana.
Bartholdi, J. J., Tovey, C. A., & Trick, M. (1989). Voting schemes for which it can be
difficult to tell who won. Social Choice and Welfare, 6(2).
530

fiEfficient Inference With Partial Rankings

Busse, L. M., Orbanz, P., & Buhmann, J. (2007). Cluster analysis of heterogeneous rank
data. In The 24th Annual International Conference on Machine Learning, Corvallis,
Oregon.
Fligner, M. A., & Verducci, J. S. (1986). Distance based ranking models. Journal of the
Royal Statistical Society, 48.
Freund, Y., Iyer, R., Schapire, R. E., & Singer, Y. (2003). An efficient boosting algorithm for
combining preferences. Journal of Machine Learning Research (JMLR), 4, 933969.
Friedman, N. (1997). Learning belief networks in the presence of missing values and hidden variables. In Proceedings of the Fourteenth International Conference on Machine
Learning, ICML 97, pp. 125133, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.
Friedman, N. (1998). The bayesian structural em algorithm. In The 14th Conference on
Uncertainty in Artificial Intelligence, UAI 98, Madison, Wisconsin.
Gormley, C., & Murphy, B. (2007). A latent space model for rank data. In Proceedings
of the 2006 conference on Statistical network analysis, ICML06, pp. 90102, Berlin,
Heidelberg. Springer-Verlag.
Huang, J., Kapoor, A., & Guestrin, C. (2011). Efficient probabilistic inference with partial
ranking queries. In The 27th Conference on Uncertainty in Artificial Intelligence, UAI
11, Barcelona, Spain.
Huang, J. (2011). Probabilistic Reasoning and Learning on Permutations: Exploiting Structural Decompositions of the Symmetric Group. Ph.D. thesis, Carnegie Mellon University.
Huang, J., & Guestrin, C. (2009). Riffled independence for ranked data. In Bengio, Y.,
Schuurmans, D., Lafferty, J., Williams, C. K. I., & Culotta, A. (Eds.), Advances in
Neural Information Processing Systems 22, NIPS 08, pp. 799807. MIT Press.
Huang, J., & Guestrin, C. (2010). Learning hierarchical riffle independent groupings from
rankings. In Proceedings of the 27th Annual International Conference on Machine
Learning, ICML 10, pp. 455462, Haifa, Israel.
Huang, J., & Guestrin, C. (2012). Uncovering the riffled independence structure of ranked
data. Electronic Journal of Statistics, 6, 199230.
Huang, J., Guestrin, C., & Guibas, L. (2008). Efficient inference for distributions on permutations. In Platt, J., Koller, D., Singer, Y., & Roweis, S. (Eds.), Advances in Neural
Information Processing Systems 20, NIPS 07, pp. 697704. MIT Press, Cambridge,
MA.
Huang, J., Guestrin, C., & Guibas, L. J. (2009). Fourier theoretic probabilistic inference
over permutations. Journal of Machine Learning Research (JMLR), 10, 9971070.
Joachims, T. (2002). Optimizing search engines using clickthrough data. In Proceedings of
the eighth ACM SIGKDD international conference on Knowledge discovery and data
mining, KDD 02, pp. 133142, New York, NY, USA. ACM.
Kondor, R., Howard, A., & Jebara, T. (2007). Multi-object tracking with representations
of the symmetric group. In Meila, M., & Shen, X. (Eds.), Proceedings of the Eleventh
531

fiHuang, Kapoor & Guestrin

International Conference on Artificial Intelligence and Statistics March 21-24, 2007,
San Juan, Puerto Rico, Vol. Volume 2 of JMLR: W&CP.
Kondor, R. (2008). Group theoretical methods in machine learning. Ph.D. thesis, Columbia
University.
Lebanon, G., & Lafferty, J. (2003). Conditional models on the ranking poset. In S. Becker,
S. T., & Obermayer, K. (Eds.), Advances in Neural Information Processing Systems
15, NIPS 02, pp. 415422, Cambridge, MA. MIT Press.
Lebanon, G., & Mao, Y. (2008). Non-parametric modeling of partially ranked data. In Platt,
J. C., Koller, D., Singer, Y., & Roweis, S. (Eds.), Advances in Neural Information
Processing Systems 20, NIPS 07, pp. 857864, Cambridge, MA. MIT Press.
Lu, T., & Boutilier, C. (2011). Learning mallows models with pairwise preferences. In
The 28th Annual International Conference on Machine Learning, ICML 11, Bellevue,
Washington.
Marden, J. I. (1995). Analyzing and Modeling Rank Data. Chapman & Hall.
Meila, M., Phadnis, K., Patterson, A., & Bilmes, J. (2007). Consensus ranking under the
exponential model. Tech. rep. 515, University of Washington, Statistics Department.
White, R., & Drucker, S. (2007). Investigating behavioral variability in web search. In
Proceedings of the 16th international conference on World Wide Web, WWW 07,
Banff, Alberta, Canada. ACM.

532

fiJournal of Artificial Intelligence Research 44 (2012) 383-395

Submitted 01/12; published 06/12

Research Note
Narrative Planning: Compilations to Classical Planning
Patrik Haslum

PATRIK . HASLUM @ ANU . EDU . AU

Australian National University, Canberra
and Optimisation Research Group, NICTA

Abstract
A model of story generation recently proposed by Riedl and Young casts it as planning, with
the additional condition that story characters behave intentionally. This means that characters have
perceivable motivation for the actions they take. I show that this condition can be compiled away (in
more ways than one) to produce a classical planning problem that can be solved by an off-the-shelf
classical planner, more efficiently than by Riedl and Youngs specialised planner.

1. Introduction
The classical AI planning model, which assumes that actions are deterministic and that the planner
has complete knowledge of and control over the world, is often thought to be too restricted, in that
many potential applications problems appear to have requirements that do not fit in this model. Recently, however, it has been shown that some problems thought to go beyond the classical model can
nevertheless be solved by classical planners by means of compilation, i.e., a systematic remodelling
of the problem such that a classical plan for the reformulated problem meets also the non-classical
requirements. A striking example is the work of Palacios and Geffner (2006), who showed that conformant planning (generating plans that are robust to certain forms of uncertainty) can be compiled
into a classical planning problem. Another example, closer to the topic of this paper, is the work
by Porteous, Teutenberg, Pizzi and Cavazza (2011), who use a planner to generate variations of a
drama by encoding constraints on the sequencing of events within it.
This paper is about another problem of this kind: planning a fabula, meaning the event structure,
or plot, of a story.1 The fabula planning problem considered was formulated by Riedl and Young
(2010). Its main difference from classical planning is a notion of intentionality: actions in a story
are taken by different characters, and for the story to be considered believable, characters should
behave intentionally, i.e., they should have (perceivable) motivations for the actions they take. Riedl
and Young argue that [the fact that classical planners do not take into account character intentions]
limits the applicability of off-the-shelf planners as techniques for generating stories, and develop
instead a narrative planner, IPOCL, which extends a traditional partial-order causal link planner
with a mechanism to enforce that plans respect character intentionality. I will show that fabula
planning, as defined by Riedl and Young, can be compiled into a classical planning problem, and
hence can in fact be solved by any off-the-shelf classical planner. This does not preclude using an
extended formalism, like that introduced by Riedl and Young, which is better suited for the purpose
of modelling fabula planning problems, since the compilation is easily automated. The advantage of
this is obvious: it allows to bring to bear on the narrative planning problem the entirety of existing,
1. The telling of the story, or discourse, is distinct from the fabula (e.g., Gervas 2009). The aforementioned work by
Porteous et al. can be seen as the application of planning to generating different discourses of a given fabula.
c
2012
AI Access Foundation. All rights reserved.

fiH ASLUM

and future, work on algorithms for classical planning, at a dramatically reduced cost in development
time and effort. It is not surprising to find that classical planners run on the compiled problem are
far more efficient than the IPOCL algorithm, as well as capable of doing more, like finding a set of
diverse plans.
There are different theories about what distinguishes a story from an arbitrary sequence of
events, i.e., what gives it its storiness (e.g., Gervas 2009; Mateas & Sengers, 1999). My aim is
not to criticise the particular model of narrative planning proposed by Riedl and Young but merely
to show that the criterion they adopted  character intentionality  can be achieved by a classical
planner without modification, by simply restating the problem that is given to the planner to solve.
Whether this can be done also for other models of narrative generation is an open question.

2. Narrative Planning and Intentional Plans
This is a story about how King Jafar becomes married to Jasmine. There is a magic genie. This is
also a story about how the genie dies.
(From the textual representation of the story generated by IPOCL; Riedl & Young 2010.)
Riedl and Young observe that there are many parallels between plans and narrative at the level of
fabula. Both are sequences of events that change the state of the (story) world. For a story to be
perceived as coherent and plausible, the event sequence must be logically possible (i.e., preconditions achieved before an event takes place) and connected by causes and effects (i.e., each event
contributes something to the story, by setting the stage for later events). The goal of a story, in
this view, is the end state that the storys author has in mind; Riedl and Young call this the story
outcome, to distinguish it from character goals. For a story to be believable, characters in it should
appear to be intentional agents: a characters actions should not only be possible, and contribute to
the outcome of the story, but should be perceivable as contributing to the goals that the character
has (which are not necessarily the same as the authors goal). This can be seen as a non-redundancy
requirement on subsets of the plan: each action done by each character in the story should directly
or indirectly contribute to achieving a goal of the character. Of course, goals of a character can
change throughout the course of the story, as they are influenced by other characters, or events in
the world around them. But each such change of a characters goals must also have a cause.
To illustrate narrative planning, and to evaluate the believability of plans generated by IPOCL,
Riedl and Young (appendix A.1, p. 254256) use the following small example scenario. The dramatis personae are:
 King Jafar, who lives in The Castle;
 Aladdin, a Knight loyal to Jafar;
 Jasmine, a beautiful woman, who also lives in The Castle;
 a Genie, who is imprisoned in a Magic Lamp; and
 a Dragon, who lives at The Mountain and possesses the Lamp at the start of the story.
Characters can travel between the two locations. A knight can slay a monster (only the Dragon and
the Genie are monsters). A character can take things from a dead character (pillage), and can give
things to another character (the Lamp is the only item of interest). A character who has the Lamp
can summon the Genie, thereby gaining control over it. The Genie, by magic, can cause a character
to fall in love with another character. Two characters who are in love, and not otherwise engaged,
can marry. The goals of the story are (married Jafar Jasmine) and (dead Genie). Note that these
goals represent the story outcome; they are not (initially) intended by any character.
384

fiNARRATIVE P LANNING : C OMPILATIONS TO C LASSICAL P LANNING

Riedl and Young distinguish two types of planning actions: intentional actions, which correspond to actions taken by one or more story characters (actors of the action), and happenings,
which do not have actors and correspond to accidental events, forces of nature, etc. The classifications of actions as intentional or happenings, and the assignment of the role of actor(s) to parameters
of intentional actions, are part of the domain theory. Examples of happenings in the scenario above
are for a character to fall in love with another who is beautiful, and for a scary monster to frighten
another character.
Character intentions are modelled by modal literals of the form (intends A f ), where A is a character and f is a fact, i.e., a normal literal. Intentions arise as an effect of actions, either happenings
or character actions. For example, the happening (fall-in-love ?man ?woman) has the effect (loves
?man ?woman) and establishes the intention (intends ?man (married ?man ?woman)). Similarly,
the action (deliver-witty-insult ?speaker ?hearer ?victim), in which ?speaker is the actor, could have
the effect (amused ?hearer), but also the unintended (by the speaker) effect (intends ?victim (dead
?speaker)). A special category of actions that cause intentions are delegating actions, where one
character commands (or persuades, or bribes, or otherwise influences) another to achieve something.
For example, (order ?king ?knight ?goal) has the effect (intends ?knight ?goal).
Riedl and Young define their notion of intentionality in the context of partially ordered causal
link (POCL) plans.2 The following definition summarises definitions 3, 5 and 6 (pp. 232234) in
their article:
Definition 1 An intentional plan is one in which every occurrence of an intentional action is part of
some frame of commitment. A frame of commitment is a subset S  of steps (i.e., action occurrences)
in the plan, associated with a modal literal (intends A g), satisfying four requirements: (1) Character A is an actor of every step in S  . (2) There is a final step sfin  S  that makes g true. (3) There is
a motivating step sm in the plan, which adds (intends A g) and which precedes all steps in S  . Well
say there is a motivational link from sm to every step in the frame of commitment, S  . Note that sm
is not part of S  . (4) From each step in S  other than sfin there is a path of causal or motivational
links to sfin . A complete (fabula) plan is one that is both intentional and valid in the classical sense.
Condition (4) above departs slightly from the definitions stated by Riedl and Young: they require
only that each step in S  temporally precedes sfin . That would appear to be too promiscuous, since
it allows any unrelated action to be incorporated into a frame of commitment by adding spurious
temporal constraints. Their IPOCL algorithm, however, will only incorporate a step into an existing
frame of commitment if the step has a causal link to a step already in the frame, or can serve as
motivating step for a frame of commitment whose final step has a causal link to a step already in
the frame (cf. items 1 and 2 on page 235 of their article). Hence, the frames that their algorithm
generates always satisfy condition (4).

3. Compilation 1: Explicit Justification Tracking
The first compilation is based on explicit tracking of the justifications, in the form of causal and
motivating links, for actions in the plan. It is inspired by the work of Karpas and Domshlak (2011)
on pruning redundant action sequences from the search space, which also relies on a notion of
justification of actions.
2. A detailed account of POCL planning can be found in the paper by McAllester and Rosenblitt (1991) and in most AI
textbooks.

385

fiH ASLUM

We will use three kinds of modal literals: (intends A f ) and (delegated A f ), where A is a
character and f a fact, and (justified f I), where f is a fact and I an intention, i.e., a modal literal of
the first form. The intends modality is part of the narrative planning problem specification, where
it can appear in action effects and in the initial state. The other modalities are used only to describe
the compilation. Of course, modal conditions cannot be expressed directly in a classical planning
formalism like PDDL. In a PDDL model, they are replaced by a separate modal predicate for each
predicate (resp. combination of two predicates) that can appear in a non-modal fact, whose arguments is the concatenation of all arguments in the modal literal. For example, (intends Aladdin (has
Jafar Lamp)) is replaced by (intends-has Aladdin Jafar Lamp), and (justified (at Aladdin Mountain)
(intends Aladdin (has Jafar Lamp))) is replaced by (justified-at-has Aladdin Mountain Aladdin Jafar
Lamp).
In the compiled problem, each intentional action is associated with an intention of the actions
actor(s). This intention is a precondition of the action. If the action itself does not achieve the
intention, it creates an outstanding obligation to make use of at least one of its effects to achieve the
precondition of some other action, done by the same actor, that contributes, directly or indirectly,
to achieving the intention. This is modelled by the justified modality. As explained earlier, actions
can have modal effects of the form (intends B f ), i.e., to make a character (different from the actor)
intend a goal. This is modelled by the delegated modality.
For each intentional action, (a ~x), of the narrative planning problem, the compiled problem
has one distinct action for each combination of an intention (intends xA (p ~y )), where xA is the
parameter that represents the actor of (a ~x), and an effect (e ~z) of (a ~x). We name this compiled
action (a-e-because-intends-p ~x ~y ), and call (e ~z) the chosen effect. Note that the parameters ~z of the
chosen effect are composed from a subset of the parameters ~x of the action, and possibly explicit
constants. Action (a-e-because-intends-p ~x ~y ) can be read as character xA performs action (a ~x)
to achieve the effect (e ~z) as a step towards achieving the characters intended goal (p ~y ). If (e ~z)
can unify with (p ~y ), the action must be further broken into two cases: one where they are forced
to equal and one where they are forced to be distinct. For an intentional action with more than one
actor, the compiled problem must have a distinct action for each (possible and relevant) choice of
effect and intention for each actor. For a happening (i.e., action without an actor) there is only one
corresponding action in the compiled problem.
The justified and delegated modalities combine to track causal and motivational links in the
compiled problem. All (possible and relevant) justified literals are true in the initial state, and
required to be true in the goal state. Action (a-e-because-intends-p ~x ~y ) makes the chosen effect
unjustified, by deleting (justified (e ~z) (intends xA (p ~y ))). Since the goal requires all justified literals
to hold, the plan must include some action, by the same actor and with the same intention, whose
precondition requires (e ~z); no other action will make (justified (e ~z) (intends xA (p ~y ))) true again. If
the chosen effect is a modal literal (intends zA (q z~ )) it is the subgoal (q z~ ) that becomes unjustified,
and it also becomes delegated to the second character, zA . This provides the motivational link
from the action (a-e-because-intends-p ~x ~y ) to any action that zA takes to achieve (q z~ ). Delegation
ends when the character achieves the goal. While a goal is delegated, no other character may achieve
the goal. This ensures the step that created the delegation is eventually justified, by the character
who performed it making use of the achieved fact (q z~ ).
Let (a ~x) be an intentional action, xA the parameter that represents its actor, (e ~z) the chosen
effect and (intends xA (p ~y )) the intention of the actor. The preconditions of the compiled action
(a-e-because-intends-p ~x ~y ) are:
386

fiNARRATIVE P LANNING : C OMPILATIONS TO C LASSICAL P LANNING

(1)
(2)
(3a)
(3b)
(3c)
(4)

all preconditions of (a ~x);
(intends xA (p ~y ));
w (delegated w (q z~ )), for each effect of (a ~x) that is of the form (intends zA (q z~ ));
w 6= xA (delegated w (p ~y )), if (p ~y ) is an effect of (a ~x);
w (delegated w (q z~ )), for any other effect (q z~ ) of (a ~x) that is not an intends modal literal.
(intends zA (q z~ )), if (e ~z) is a modal literal of the form (intends zA (q z~ )).

In a plan for the compiled problem, sets of actions with the same associated intention form a frame
of commitment. Precondition (2) ensures all steps in that frame are preceded by a motivating step.
Precondition (4) ensures there is at most one (intentional) motivating step. Preconditions (3ac)
ensure that no action can be taken that delegates (a) or achieves (bc) a goal that is already delegated
to another character.
The effects of the compiled action are:
(1) all effects of (a ~x);
(2) (justified (q ~v ) (intends xA (p ~y ))), for each (non-static) precondition (q ~v ) of (a ~x).
(3a) (justified (q z~ ) (intends xA (p ~y ))) and (delegated zA (q z~ )), if (e ~z) is a modal literal of the
form (intends zA (q z~ ));
(3b) (justified (e ~z) (intends xA (p ~y ))), if (e ~z) is not an intends literal and (e ~z) does not equal
(p ~y );
(4) (delegated xA (e ~z)), if (e ~z) equals (p ~y );
Effects (2) and (3) make the preconditions of the action justified, and the chosen effect unjustified,
as explained above. If the chosen effect is a modal intends literal (case 3a), it is the intended subgoal
that becomes unjustified, and also delegated to the other character. Effect (4) ends the delegation of
a goal when the action is the final step in a frame of commitment. (Note, however, that the action
will have this effect even if the goal was not delegated; this does not matter.)
If the chosen effect (e ~z) can be unified with (p ~y ), the compiled action must be split into two:
one with the additional precondition ~z = ~y , ensuring that they are equal, and one with the additional
precondition ~z 6= ~y , ensuring that they are not. This is necessary since the effects of the compiled
action depend on whether (e ~z) equals (p ~y ) or not. Furthermore, as mentioned above, if the original
action (a ~x) has more than one actor, the compiled problem has one action for every combination
of an intention and a chosen effect for each actor. In this case, conditions on (p ~y ) and (e ~z) in the
schema above should be interpreted for each actor separately. That is, if (pi ~y i ) and (ei ~zi ) are the
intention and chosen effect of actor xiA , the compiled action has the effect (justified (ei ~zi ) (intends
xiA (pi ~y i ))) if (ei ~zi ) is not an intends literal and (ei ~zi ) does not equal (pi ~y i ) (item 3b), regardless of
whether (ei ~zi ) equals (pj ~y j ) for some j 6= i, or vice versa.
To illustrate the compilation, consider the following action from the example scenario by Riedl
and Young (appendix A.1, p. 255), here written in a more PDDL-like syntax:
(:action slay
:parameters (?knight - knight ?monster - monster ?where - place)
:actors (?knight)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where))
:effect (and (not (alive ?monster)) (dead ?monster)))

The actor of this action is the knight. Consider the intention (intends ?knight (dead ?who)). The
action has only one relevant choice of effect, (dead ?monster) (the negative literal does not appear
in any action precondition or the goal). However, since the intention unifies with the chosen effect,
387

fiH ASLUM

the compiled problem must still include two actions, one for ?who = ?monster and one for ?who 6=
?monster:
(:action slay-1-because-intends-dead
:parameters (?knight - knight ?monster - monster ?where - place)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)
(intends ?knight (dead ?monster))
(not (exists (?c) (and (not (= ?c ?knight)) (delegated ?c (dead ?monster))))))
:effect (and (not (alive ?monster)) (dead ?monster)
(justified (at ?knight ?where) (intends ?knight (dead ?monster)))
(justified (at ?monster ?where) (intends ?knight (dead ?monster)))
(not (delegated ?knight (dead ?monster)))))
(:action slay-2-because-intends-dead
:parameters (?knight - knight ?monster - monster ?where - place ?who - monster)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)
(intends ?knight (dead ?who))
(not (exists (?c) (delegated ?c (dead ?monster))))
(not (= ?who ?monster)))
:effect (and (not (alive ?monster)) (dead ?monster)
(justified (at ?knight ?where) (intends ?knight (dead ?who)))
(justified (at ?monster ?where) (intends ?knight (dead ?who)))
(not (justified (dead ?monster) (intends ?knight (dead ?who))))))

(The alive literals dont need justification, because there is no way to make them true unless true
initially.) Corresponding to the intention (intends ?knight (has ?who ?what)) the compiled problem
will have the action:
(:action slay-because-intends-has
:parameters (?knight ?monster ?where ?who ?what)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)
(intends ?knight (has ?who ?what))
(not (exists (?c) (delegated ?c (dead ?monster)))))
:effect (and (not (alive ?monster)) (dead ?monster)
(justified (at ?knight ?where) (intends ?knight (has ?who ?what)))
(justified (at ?monster ?where) (intends ?knight (has ?who ?what)))
(not (justified (dead ?monster) (intends ?knight (has ?who ?what))))))

To prove the correctness of the compilation in general, we will need the concept of a toggling
action (Hickmott & Sardina, 2009). An action is toggling w.r.t. an effect of the action iff the
actions precondition implies the negation of the effect. That is, if the action makes true a fact f , its
precondition must include f , or some fact f  that is mutex with f , and if the action makes f false,
it must require f to be true. An action that is not toggling can be transformed into an equivalent set
of actions that are, though the size of this set is exponential in the number of non-toggling effects
of the original action.
Theorem 2 Let P be a narrative planning problem, in which each action is toggling w.r.t. its effects.
Let P  be the compiled problem as described above. Every plan S for P  is intentional.
Proof: Consider a step s in S, that is an instance of an action (a-e-because-intends-p ~x ~y ). Let A
be the actor (i.e., the constant bound to the actor parameter xA of a) and (e ~z) the chosen effect of
(a ~x). The action will be part of a frame of commitment with the goal (p ~y ). By construction, the
388

fiNARRATIVE P LANNING : C OMPILATIONS TO C LASSICAL P LANNING

precondition of (a-e-because-intends-p ~x ~y ) includes (intends A (p ~y )). There must be a motivating
step that establishes this precondition, as otherwise S would not be classically valid.
If (e ~z) equals (p ~y ), then s is itself the final step in the frame of commitment.
If (e ~z) does not equal (p ~y ) and is not a modal literal, then (a-e-because-intends-p ~x ~y ) destroys
(justified (e ~z) (intends A (p ~y )). Since all such literals are goals in P  , there must be a later step, s ,
that re-establishes it. By construction, this can only be an action that has A as actor, (intends A (p ~y ))
as the associated intention, and (e ~z) as a precondition. If there is no step between s and s that adds
(e ~z), there must be a causal link labelled with (e ~z) from s to s (since actions are toggling, (e ~z) was
not true before s). There cannot be only a step sadd between s and s that adds (e ~z), because if so,
the action associated with sadd would be applied in a state where one of its effects, (e ~z), is already
true, and thus not toggling. Suppose there are steps sdel and sadd taking place between s and s , such
that sdel destroys (e ~z) and sadd makes it true again; if there are several such steps, let sdel be the first
and sadd the last, so that there is a causal link from sadd to s . Since actions are toggling sdel requires
(e ~z), so there is a causal link from s to sdel . If there is no chain of causal links from sdel to sadd , the
subplan consisting of steps up to and including s and all causal predecessors of sadd (which do not
include sdel ) must be executable, and results in an execution where the action associated with sadd
is again applied in a state where one of its effects, (e ~z), is already true, and hence is not toggling.
Thus, there must be a chain of causal links from sdel to sadd , and therefore from s to s . Since s is
part of the same frame of commitment as s (it has the same motivating intention), and there can only
be a finite number of steps in this frame of commitment that causally follow s, repeated application
of this reasoning leads to the conclusion that there must be a chain of causal links from s to the final
step of the frame.
If (e ~z) is a modal literal of the form (intends zA (q z~ )), (a-e-because-intends-p ~x ~y ) destroys
(justified (q z~ ) (intends A (p ~y )), and adds (delegated zA (q z~ )). As above, there must be a step
s , in the same frame of commitment as s, that re-establishes (justified (q z~ ) (intends A (p ~y )). By
construction, (delegated w (q z~ )) can be true for at most one character w at any time (any action that
adds a delegation requires that no other character has it), and only the character currently holding
the delegation of (q z~ ) can make it true. Thus, there is (by the same argument as above) a causal
chain from the final step of the delegates frame of commitment with goal (q z~ ) to s . Because
actions in the compiled problem are toggling w.r.t. intends literals, step s must have a causal chain
to the precondition (intends zA (q z~ )) of each action in the frame of commitment of the delegate,
and thus serves as the motivating step for this frame. Thus, there is a chain of motivating and causal
links from s to s , and following the same argument as above, therefore from s to the final step of
the frame of commitment that s belongs to.
2
It may be noted that some apparently reasonable story plans are disallowed. For example, a character
cannot delegate a goal that he himself intends to another character. This, however, is a consequence
of Riedl and Youngs definition of intentional plans, not of the compilation (and hence applies
also to the IPOCL planner): the final step in a frame of commitment must achieve the intended
goal and must be an action by the actor that holds this intention (conditions 1 & 2 of Definition
1). This rules out delegating ones own goals. If desired, it would not be difficult to modify the
compilation to allow this kind of secondary delegation: it requries only adding the exception w 6=
xA to precondition (3a) and an effect like (4) for this case. A plan also cannot have a character
trying and failing by multiple means to achieve his goals. Again, this is a consequence of Riedl and
Youngs definition, not of the compilation: every action taken by a character must have a chain of
389

fiH ASLUM

causal or motivational links to the final step (condition 4 of Definition 1). This rules out characters
taking actions that prove ultimately futile.
Theorem 2 shows that the compilation is sound. The question of whether it is also complete, i.e.,
whether existence of an intentional plan for a narrative planning problem P always implies existence
of a plan for the compiled problem P  , is somewhat complicated. At first glance, given an intentional
plan S for P , it appears a plan S  for the compiled problem P  could be constructed by selecting
for each action a in S a suitable representative a-. . .-because-. . ., with intentions and chosen effects
to match the frames of commitment to which a belongs in S. Since S is intentional, each frame of
commitment is preceded by a motivating step, ensuring the intends preconditions of the compiled
action are satisified, and if a is not the final step, there is a causal link from at least one of its effects
to another step, ensuring that deleted justified literals are restored. There is, however, one point
where the correspondence can fail, due to the restriction of the compiled problem that a delegated
goal can only be achieved by the character that it was delegated to: Suppose character A delegates
goal g to character B, i.e., character A performs an intentional action whose only (relevant) effect
is (intends B g). For the plan to be intentional, there must be a frame of commitment belonging
to character B, with the associated intention (intends B g); this frame must have a final step which
achieves g, and that step must be the source of a causal link to some step performed by character A,
belonging to same the frame of commitment of A as the step that established the motivation. Yet,
nothing prevents another character, C, from achieving g for his own purposes, as long as character
B also achieves g. The compiled problem, however, does not allow character C to achieve g as long
as it is delegated to B, i.e., in between the motivating step by A and the final step by B. This could
be remedied through a more elaborate justification tracking mechanism, that distinguishes the same
fact when achieved by different characters.
From a practical perspective, the combinations of actions with intentions, and modal literals,
present in the compiled problem can be restricted to those that are possible and relevant. For
example, the initial state and goal only needs to include those justified literals that can actually be
negated by some possibly applicable action (which can be found by standard relaxed reachability
analysis). In the example scenario, the fact that a character has the Lamp can never causally contribute to, e.g., the goal of the character having another item (there are no other items to have) or the
goal of murdering another character. Thus, actions like pillage-because-intends-dead or order-hasbecause-intends-has and order-has-because-intends-dead can never be part of valid plan. Most of
this information could be found by simple techniques like back-chaining relevance analysis.
Applying the compilation to Riedl and Youngs example scenario, and applying a classical planner, using forward-chaining A* search with the LM-Cut heuristic (Helmert & Domshlak, 2009), to
the compiled problem, produces the plan shown in figure 1. The planner outputs a sequence of
actions, which is transformed to a partially ordered plan by a polynomial time post-processing step
(Backstrom, 1998). Enumerating all shortest plans reveals two variations: one in which Jafar travels
back to the Castle to marry Jasmine, and one in which Jafar orders Aladdin to bring him the Lamp,
and both climactic events (the wedding and Aladding slaying the Genie) take place at the Castle.
(The latter is the one Riedl and Young report was found by IPOCL, shown in Figure 15, p. 259,
of their article.) Note that it is not possible for Jafar to command Aladdin to make (loves Jasmine
Jafar) true, because Aladdin has no means to achieve this goal other than by delegating it to the
Genie, which, as explained above, is not permitted by the definition of a frame of commitment.
Finding shortest plans is not an end in itself: rather, it is a side effect of the fact that a planner
will usually seek to achieve the story outcome in the simplest way. This can be somewhat at odds
390

fiNARRATIVE P LANNING : C OMPILATIONS TO C LASSICAL P LANNING

Figure 1: A story plan generated for the example problem. Motivational links are drawn in gray.
The dashed edge is an ordering constraint. The outlines group actions that form a frame
of commitment for a character. To avoid clutter, causal links for justified predicates are
not shown; instead, causal links from the chosen effect of each action are drawn in bold.
It can be seen that each chosen effect, except for final steps, links (directly or indirectly)
to a precondition of an action in the same frame of commitment.

391

fiH ASLUM

with making the story interesting. Porteous and Cavazza (2009) argue that complexification, i.e.,
making the story more convoluted in order to make it more interesting, can be achieved by posting
additional author goals in the form of PDDL3 trajectory constraints, specifying that some fact must
be achieved at some point in the plan; that some fact must never be true at any point; or that some
fact must be achieved before another. PDDL3 trajectory constraints can also be compiled away
(Gerevini, Haslum, Long, Saetti & Dimopoulos, 2008). Methods for generating a diverse set
of plans (Srivastava, Kambhampati, Nguyen, Do, Gerevini & Serina, 2007) could also be used to
automate complexification.
The total time to generate the plan is around 45 seconds (and of that, only half is actual search;
the rest is grounding and preprocessing.) The time required for the compilation itself is less than a
second. This is in stark contrast to the running time of the IPOCL planner on this problem, reported
to be over 12 hours even with a problem-specific search heuristic (Riedl & Young, 2010). However,
this example represents a very small problem. It contains only the actions and objects necessary to
form the intended story plan, and no more. A more realistic scenario is a problem specification
that contains many possible actions and objects that are not relevant to the story outcome, or that
allow the construction of materially different plans for that goal. The size of the compiled problem
can grow quite quickly as the size of the original narrative planning problem increases. As an
example, a larger version of the same problem, including three more actions and a few more items,
none directly relevant to achieving the outcome, takes nearly 30 minutes to solve.

4. Compilation 2: Meta-Planning
If only I had the Magic Lamp, thought Jafar. Then I could summon the Genie to gain control over
it. If I controlled the Genie, I could command it to make Jasmine love me.
The second compilation is based on simulating the characters process of forming intentions by
making plans, using explicit character planning actions. It has some similarity to Wolfe and Russells (2011) use of explicit establishment of intentions as a means to guide plan search more efficiently. Compared to the justification-tracking compilation, it is less complex but also less stringent:
plans for a meta-planning compiled problem are not guaranteed to be intentional, according to the
definition of Riedl and Young, although most of the time they will be.
A meta-planning action allows a character to adopt the intention of achieving the precondition
of an action that achieves a goal that the character already intends. To avoid characters making plans
that they never act on, a counter tracks the number of intentions each character has, and is required
to be zero at the end of the plan.3 The counter can be represented by the standard propositional
encoding (though this limits the depth of intentions a character can hold), or by a numeric fluent.
Let (a ~x) be an intentional action, xA the parameter that represents its actor, and (e ~z) its chosen
effect. The corresponding action in the compiled problem has the additional precondition (intends
xA (e ~z)) and effects (intends xA (e ~z)) and decreases xA s intention count by 1. In other words, to
take an action, the actor must have one of its effects in his current set of intentions, and performing
the action releases the actor from that intention. If (e ~z) is a modal literal of the form (intends zA
(q z~ )), the precondition and effect refer instead to (q z~ ), and the action also increases the intention
count of zA , i.e., the effect is to move (q z~ ) from the intention set of xA to that of character zA .
Happenings that add character intentions must also increase the intention count.
3. Some exceptions must be made: for example, if a character dies, he obviously cannot act on any outstanding intentions, but this should not invalidate the plan.

392

fiNARRATIVE P LANNING : C OMPILATIONS TO C LASSICAL P LANNING

For each precondition (p ~y ) of (a ~x), the compiled problem also has an action (plan-to-a ~x),
with precondition (intends xA (e ~z)) and effects (intends xA (p ~y )) and increasing xA s intention
count. If (a ~x) has several preconditions, an order of achievement among them can be enforced by
adding subsets of those preconditions to the meta-planning actions. For example, the action (give
?who ?what ?to-who ?where) has the preconditions: (has ?who ?what); (at ?who ?where); and (at
?to-who ?where). Adding (has ?who ?what) to the precondition of the meta-planning action that
establishes (intends ?who (at ?who ?where)) forces a character who intends to give something to
not only plan to acquire the item, but to actually do so, before planning to travel (if necessary) to
a place where the recipient of the gift is. Some necessary and reasonable constraints on the order
of achievement of action preconditions may be found by landmark ordering analysis (Hoffmann,
Porteous, & Sebastia, 2004). Manually adding further constraints to meta-planning actions gives
them some flavour of (a simulation of) methods in HTN planning (Erol, Nau, & Hendler, 1994).
The reason why the meta-planning compilation does not guarantee intentional plans is that while
it forces characters to motivate any action by a plan, it does not force them to monitor that their
plans are still valid when the action takes place. For example, if Aladdin plans to slay the Dragon
in order to pillage the Lamp, but a thief steals the Lamp from the Dragon while Aladdin is on
his way to the Mountain, Aladdin still has license to slay the Dragon, even though this no longer
contributes to getting him the Lamp (in fact, he must slay the Dragon to avoid being left with
an unfulfilled intention). In part, this could be rectified by encoding a more elaborate structure
of character plans than just the set of outstanding goals. For example, a directed graph encoding
could track dependency relations between intentions, and their dependence on story world facts.
This may also provide a basis for allowing characters to revise their plans in the face of changed
circumstances.
Limited computational experiments with the meta-planning compilation suggest that while it
produces much smaller (ground) problems than the justification-tracking compilation, these can
still be harder for current heuristic search-based planners to solve.

5. Conclusion
Research into the classical planning problem has developed a wide array of, sometimes highly
effective, methods for solving such problems. Through compilations, the capabilities of existing
classical planners can be leveraged to solve many more problems than those that on the surface
appear to be classical planning problems. Like the loyal knight of the story, a classical planner
will committedly try to solve whatever task is set before it, as expressed by the planning domain
specification. The trick is setting it the right task.
As noted, the narrative planning model defined by Riedl and Young has some limitations. For
example, it does not allow to create a story in which a character tries but fails to achieve a goal.
Brenner (2010) describes an approach to story generation that interleaves classical planning for
individual characters goals, based on the characters state of knowledge, with plan execution, i.e.,
adding events to the story. This permits the system to generate stories where characters are forced to
abandon their plans after learning new facts, or postpone planning until crucial facts become known.
Brenner claims that it would be quite difficult to describe [such a plot] with a single plan, let alone
generate it with a single planner run. It does indeed appear quite difficult, but whether or not it is
impossible remains an open question.

393

fiH ASLUM

Acknowledgments
I wish to thank Alban Grastien, Malte Helmert, Robert Mattuller and the reviewers for useful
comments on drafts of this paper. This work was supported by the Australian Research Council discovery project DP0985532 Exploiting Structure in AI Planning. NICTA is funded by the
Australian Government as represented by the Department of Broadband, Communications and the
Digital Economy and the Australian Research Council through the ICT Centre of Excellence program.

References
Backstrom, C. (1998). Computational aspects of reordering plans. Journal of AI Research, 9, 99
137.
Brenner, M. (2010). Creating dynamic story plots with continual multiagent planning. In Proc. 24th
AAAI Conference on Artificial Intelligence, pp. 15171522.
Erol, K., Nau, D., & Hendler, J. (1994). HTN planning: Complexity and expressivity. In Proc.
National Conference on Artificial Intelligence (AAAI94), pp. 11231128.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2008). Deterministic planning
in the fifth international planning competition: PDDL3 and experimental evaluation of the
planners. Artificial Intelligence, 173(5-6), 619668.
Gervas, P. (2009). Computational approaches to storytelling and creativity. AI Magazine, 30(3),
4962.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths and abstractions: Whats the difference anyway?. In Proc. 19th International Conference on Automated Planning and Scheduling (ICAPS09).
Hickmott, S., & Sardina, S. (2009). Optimality properties of planning via Petri net unfolding: A formal analysis. In Proc. 19th International Conference on Automated Planning and Scheduling
(ICAPS09), pp. 170177.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks in planning. Journal of AI
Research, 22, 215278.
Karpas, E., & Domshlak, C. (2011). Living on the edge: Safe search with unsafe heuristics. In Proc.
ICAPS11 Workshop on Heuristics for Domain-Independent Planning, pp. 5358.
Mateas, M., & Sengers, P. (1999). Narrative intelligence. In Narrative Intelligence: Papers from
the AAAI Fall Symposium. AAAI Press.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. In Proc. 9th National
Conference on Artificial Intelligence.
Palacios, H., & Geffner, H. (2006). Compiling uncertainty away: Solving conformant planning
problems using a classical planner (sometimes). In Proc. 21st National Conference on Artificial Intelligence (AAAI06).
Porteous, J., & Cavazza, M. (2009). Controlling narrative generation with planning trajectories: the
role of constraints. In Proc. 2nd International Conference on Interactive Digital Storytelling,
pp. 234245.
394

fiNARRATIVE P LANNING : C OMPILATIONS TO C LASSICAL P LANNING

Porteous, J., Teutenberg, J., Pizzi, D., & Cavazza, M. (2011). Visual programming of plan dynamics using constraints and landmarks. In Proc. 21st International Conference on Automated
Planning and Scheduling (ICAPS11), pp. 186193.
Riedl, M., & Young, R. (2010). Narrative planning: Balancing plot and character. Journal of AI
Research, 39, 217268.
Srivastava, B., Kambhampati, S., Nguyen, T., Do, M., Gerevini, A., & Serina, I. (2007). Domain
independent approaches for finding diverse plans. In Proc. 20th International Conference on
Artificial Intelligence (IJCAI07), pp. 20162022.
Wolfe, J., & Russell, S. (2011). Bounded intention planning. In Proc. of the 22nd International
Joint Conference on AI (IJCAI11), pp. 20392045.

395

fiJournal of Artificial Intelligence Research 44 (2012) 179-222

Submitted 10/10; published 05/12

Improving Statistical Machine Translation
for a Resource-Poor Language
Using Related Resource-Rich Languages
Preslav Nakov

pnakov@qf.org.qa

Qatar Computing Research Institute
Qatar Foundation
Tornado Tower, Floor 10, P.O. Box 5825
Doha, Qatar

Hwee Tou Ng

nght@comp.nus.edu.sg

Department of Computer Science
National University of Singapore
13 Computing Drive
Singapore 117417

Abstract
We propose a novel language-independent approach for improving machine translation
for resource-poor languages by exploiting their similarity to resource-rich ones. More precisely, we improve the translation from a resource-poor source language X1 into a resourcerich language Y given a bi-text containing a limited number of parallel sentences for X1 -Y
and a larger bi-text for X2 -Y for some resource-rich language X2 that is closely related
to X1 . This is achieved by taking advantage of the opportunities that vocabulary overlap
and similarities between the languages X1 and X2 in spelling, word order, and syntax offer:
(1) we improve the word alignments for the resource-poor language, (2) we further augment
it with additional translation options, and (3) we take care of potential spelling differences
through appropriate transliteration. The evaluation for IndonesianEnglish using Malay
and for SpanishEnglish using Portuguese and pretending Spanish is resource-poor shows
an absolute gain of up to 1.35 and 3.37 BLEU points, respectively, which is an improvement over the best rivaling approaches, while using much less additional data. Overall, our
method cuts the amount of necessary real training data by a factor of 25.

1. Introduction
Recent developments in statistical machine translation (SMT), e.g., the availability of efficient implementations of integrated open-source toolkits like Moses (Koehn, Hoang, Birch,
Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, &
Herbst, 2007), have made it possible to build a prototype system with decent translation
quality for any language pair in a few days or even hours. This is so in theory. In practice,
doing so requires having a large set of parallel sentence-aligned texts in two languages (bitexts) for that language pair. Such large high-quality bi-texts are rare; except for Arabic,
Chinese, and some official languages of the European Union (EU), most of the 6,500+ world
languages remain resource-poor from an SMT viewpoint.
c
2012
AI Access Foundation. All rights reserved.

fiNakov & Ng

The number of resource poor languages becomes even more striking if we consider language pairs instead of individual languages. Moreover, even resource-rich language pairs
could be poor in bi-texts for a specific domain, e.g., biomedical.
While manually creating a small bi-text could be relatively easy, building a large one is
hard and time-consuming. Thus, most publicly available bi-texts for SMT come from parliament debates and legislation of multi-lingual countries (e.g., French-English from Canada,
and Chinese-English from Hong Kong), or from international organizations like the United
Nations and the European Union. For example, the Europarl corpus of parliament proceedings consists of about 1.3M parallel sentences (up to 44M words) per language for 11
languages (Koehn, 2005), and the JRC-Acquis corpus provides a comparable amount of European legislation in 22 languages (Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis,
& Varga, 2006).
Due to the increasing volume of EU parliament debates and the ever-growing European
legislation, the official languages of the EU are especially privileged from an SMT perspective. While this includes classic SMT languages such as English and French (which were
already resource-rich), and some important international ones like Spanish and Portuguese,
many of the rest have a limited number of speakers and were resource-poor until a few years
ago. Thus, becoming an official language of the EU has turned out to be an easy recipe for
getting resource-rich in bi-texts quickly.
Our aim is to tap the potential of the EU resources so that they can be used by other nonEU languages that are closely related to one or more official languages of the EU. Examples
of such EUnon-EU language pairs include SwedishNorwegian, BulgarianMacedonian1 ,
Romanian-Moldovan2 and some other. After Croatia joins the EU, Serbian, Bosnian, and
Montenegrin3 will also be able to benefit from Croatian gradually turning resource-rich (all
four languages have split from Serbo-Croatian after the breakup of Yugoslavia in the 90s
and remain mutually intelligible). The newly-made EU-official (and thus not as resourcerich) Czech and Slovak languages are another possible pair of candidates. SpanishCatalan,
Irish-Gaelic Scottish, Standard GermanSwiss German, and ItalianMaltese4 are other good
examples. As we will see below, even such resource-rich languages like Spanish and Portuguese can benefit from the proposed approach. Of course, many pairs of closely related
languages that could make use of each others bi-texts can also be found outside of Europe:
one such example is MalayIndonesian, with which we will be experimenting below. Other
non-EU language pairs that could potentially benefit include Modern Standard Arabic
Dialectical Arabic (e.g., Egyptian, Levantine, Gulf, or Iraqi Arabic), MandarinCantonese,
RussianUkrainian, TurkishAzerbaijani, HindiUrdu, and many other.
1. There is a heated linguistic debate about whether Macedonian represents a separate language or is a
regional literary form of Bulgarian. Since there are no clear criteria for distinguishing a dialect from a
language, linguists are divided on this issue. Politically, the Macedonian language is not recognized by
Bulgaria (which refers to it as the official language of the Republic of Macedonia in accordance with its
constitution) and by Greece (mostly because of the dispute over the use of the name Macedonia).
2. As with Macedonian, there is a debate about the existence of the Moldovan language. While linguists
generally agree that Moldovan is one of the dialects of Romanian, politically, the national language of
Moldova can be called both Moldovan and Romanian.
3. There is a serious internal political division in Montenegro on whether the national language should be
called Montenegrin or just Serbian.
4. Though, Maltese might benefit from Arabic more than from Italian.

180

fiImproving SMT for a Resource-Poor Language

Below we propose using bi-texts for resource-rich language pairs to build better SMT
systems for resource-poor pairs by exploiting the similarity between a resource-poor language and a resource-rich one. More precisely, we build phrase-based SMT systems that
translate from a resource-poor language X1 into a resource-rich language Y given a small
bi-text for X1 -Y and a much larger bi-text for X2 -Y , where X1 and X2 are closely related.
We are motivated by the observation that related languages tend to have (1) similar word
order and syntax, and, more importantly, (2) overlapping vocabulary, e.g., casa (house)
is used in both Spanish and Portuguese; they also have (3) similar spelling. This vocabulary overlap means that the resource-rich auxiliary language can be used as a source of
translation options for words that cannot be translated with the resources available for the
resource-poor language. In actual text, the vocabulary overlap might extend from individual words to short phrases (especially if the resource-rich languages has been transliterated
to look like the resource-poor one), which means that translations of whole phrases could
potentially be reused between related languages. Moreover, the vocabulary overlap and
the similarity in word order can be used to improve the word alignments for the resourcepoor language by biasing the word alignment process with additional sentence pairs from
the resource-rich language. We take advantage of all these opportunities: (1) we improve
the word alignments for the resource-poor language, (2) we further augment it with additional translation options, and (3) we take care of potential spelling differences through
appropriate transliteration.
We apply our approach to IndonesianEnglish using Malay and to SpanishEnglish
using Portuguese and Italian (and pretending that Spanish is resource-poor), achieving
sizable performance gains (up to 3.37 BLEU points) when using additional bi-texts for
a related resource-rich language. We further show that our approach outperforms the
best rivaling approaches, while using less additional data. Overall, we cut the amount of
necessary real training data by a factor of 25.
Our approach is based on the phrase-based SMT model (Koehn, Och, & Marcu, 2003),
which is the most commonly used state-of-the-art model today. However, the general ideas
can easily be extended to other SMT models, e.g., hierarchical (Chiang, 2005), treelet
(Quirk, Menezes, & Cherry, 2005), and syntactic (Galley, Hopkins, Knight, & Marcu, 2004).
The remainder of this article is organized as follows: Section 2 provides an overview
of related work, Section 3 presents a motivating example in several languages, Section 4
introduces our proposed approach and discusses various alternatives, Section 5 describes
the datasets we use, Section 6 explains how we transliterate Portuguese and Italian to look
like Spanish automatically, Section 7 presents our experiments and discusses the results,
Section 8 analyses the results in more detail, and, finally, Section 9 concludes and suggests
possible directions for future work.

2. Related Work
Our general problem formulation is a special case of domain adaptation. Moreover, there are
three basic concepts that are central to our work: (1) cognates between related languages,
(2) machine translation between closely related languages, and (3) pivoting for statistical
machine translation. We will review the previous work on these topics below, while also
mentioning some other related work whenever appropriate.
181

fiNakov & Ng

2.1 Domain Adaptation
The Domain adaptation (or transfer learning) problem arises in situations where the training and the test data come from different distributions, thus violating the fundamental
assumption of statistical learning theory. Our problem is an instance of the special case of
domain adaptation, where in-domain data is scarce, but there is plenty of out-of-domain
data. Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daume and Marcu (2006), Jiang and Zhai (2007a, 2007b),
Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples.
Unfortunately, these techniques are not directly applicable to machine translation, which
is much more complicated, and leaves a lot more space for variety in the proposed solutions.
This is so despite the limited previous work on domain adaptation for SMT, which has
focused almost exclusively on adapting European parliament debates to the news domain as
part of the annual competition on machine translation evaluation at the WMT workshop.
To mention just a few of the proposed approaches, Hildebrand, Eck, Vogel, and Waibel
(2005) use information retrieval techniques to choose training samples that are similar to
the test set as a way to adapt the translation model, while Ueffing, Haffari, and Sarkar
(2007) adapt the translation model in a semi-supervised manner using monolingual data
from the source language. Snover, Dorr, and Schwartz (2008) adapt both the translation
and the language model, using comparable monolingual data in the target language. Nakov
and Ng (2009b) adapt the translation model for phrase-based SMT by combining phrase
tables using extra features indicating the source of each phrase; we will use this combination
technique as part of our proposed approach below. Finally, Daume and Jagarlamudi (2011)
address the domain shift problem by mining appropriate translations for the unseen words.
2.2 Cognates
Cognates are defined as pairs of source-target words with similar spelling (and thus likely
similar meaning), for example, developpement in French vs. development in English. Many
researchers have used likely cognates co-occurring in parallel sentences in the training bi-text
to improve word alignments and ultimately build better SMT systems.
Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, and Yarowsky
(1999) extracted such likely cognates for Czech-English, using one of the variations of the
longest common subsequence ratio or LCSR (Melamed, 1995) described by Tiedemann
(1999) as a similarity measure. They used these cognates to improve word alignments
with IBM models 14 in three different ways: (1) by seeding the parameters of IBM model
1, (2) by constraining the word co-occurrences when training IBM models 14, and (3) by
adding the cognate pairs to the bi-text as additional sentence pairs. The last approach
performed best and was later used by Kondrak, Marcu, and Knight (2003) who demonstrated improved SMT for nine European languages. It was further extended by Nakov,
Nakov, and Paskaleva (2007), who combined LCSR and sentence-level co-occurrences in
a bi-text with competitive linking (Melamed, 2000), language-specific weights, and Web
n-gram frequencies.
Unlike these approaches, which extract cognates between the source and the target
language, we use cognates between the source and some other related language that is
different from the target. Moreover, we only implicitly rely on the existence of such cognates;
182

fiImproving SMT for a Resource-Poor Language

we do not try to extract them at all, and we leave them in their original sentence contexts.5
Note that our approach is orthogonal to this kind of cognate extraction from the original
training bi-text, and thus the two can be combined (which we will do in Section 7.7).
Another relevant line of research is on using cognates to adapt resources for one language
to another one. For example, Hana, Feldman, Brew, and Amaral (2006) adapt Spanish
resources to Brazilian Portuguese to train a part-of-speech tagger.
Cognates and cognate extraction techniques have been used in many other applications,
e.g., for automatic translation lexicon induction. For example, Mann and Yarowsky (2001)
induce translation lexicons between a resource-rich language (e.g., English) and a resourcepoor language (e.g., Portuguese) using a resource-rich bridge language that is closely related
to the latter (e.g., Spanish). They use pre-existing translation lexicons for the sourceto-bridge mapping step (e.g., English-Spanish), and string distance measures for finding
cognates for the bridge-to-target step (e.g., Spanish-Portuguese). This work was extended
by Schafer and Yarowsky (2002), and later by Scherrer (2007), who relies on graphemic
similarity for inducing bilingual lexicons between Swiss German and Standard German.
Koehn and Knight (2002) describe several techniques for inducing translation lexicons
from monolingual corpora. Starting with unrelated German and English corpora, they look
for (1) identical words, (2) cognates, (3) words with similar frequencies, (4) words with
similar meanings, and (5) words with similar contexts. This is a bootstrapping process,
where new translation pairs are added to the lexicon at each iteration.
More recent work on automatic lexicon induction includes that by Haghighi, Liang,
Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009).
Finally, there is a lot of research on string similarity that has been applied to cognate
identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a
stochastic transducer. Tiedemann (1999) and Mulloni and Pekar (2006) learn automatically the regular spelling changes between two related languages, which they incorporate in
similarity measures based on LCSR and on MEDR, respectively. Kondrak (2005) proposes
a formula for measuring string similarity based on LCSR with a correction that addresses
its general preference for short words. Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity. Rappoport
and Levent-Levi (2006) learn substring correspondences for cognates, using the string-level
substitutions framework of Brill and Moore (2000). Finally, Inkpen, Frunza, and Kondrak
(2005) compare several orthographic similarity measures for cognate extraction.
While cognates are typically extracted between related languages, there are words with
similar spelling between unrelated languages as well, e.g., Arabic, Chinese, Japanese, and
Korean proper names are transliterated to English, which uses a different alphabet. See
the work of Oh, Choi, and Isahara (2006) for an overview and a comparison of different
transliteration models, as well as the proceedings of the annual NEWS named entities workshop, which features shared tasks on transliteration mining and generation (Li & Kumaran,
2010). Transliteration can be modeled using character-based machine translation techniques
(Matthews, 2007; Nakov & Ng, 2009a; Tiedemann & Nabende, 2009), which are related to
the character-based SMT model of Vilar, Peter, and Ney (2007), and Tiedemann (2009).
5. However, in some of our experiments, we extract cognates for training a transliteration system from the
resource-rich source language X2 into the resource-poor one X1 .

183

fiNakov & Ng

2.3 Machine Translation between Closely Related Languages
Yet another relevant line of research is on machine translation between closely related languages, which is arguably simpler than general SMT, and thus can be handled using wordfor-word translation and manual language-specific rules that take care of the necessary morphological and syntactic transformations. This has been tried for a number of language pairs
including CzechSlovak (Hajic, Hric, & Kubon, 2000), TurkishCrimean Tatar (Altintas &
Cicekli, 2002), and IrishScottish Gaelic (Scannell, 2006), among others. More recently, the
Apertium open-source machine translation platform at http://www.apertium.org/ has
been developed, which uses bilingual dictionaries and manual rules to translate between
a number of related languages, including SpanishCatalan, SpanishGalician, Occitan
Catalan, and Macedonian-Bulgarian. In contrast, we have a language-independent, statistical approach, and a different objective: translate into a third language X.
A special case of this same line of research is the translation between dialects of the
same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect
of a language and a standard version of that language, e.g., between some Arabic dialect
(e.g., Egyptian) and Modern Standard Arabic (Bakr, Shaalan, & Ziedan, 2008; Sawaf,
2010; Salloum & Habash, 2011). Here again, manual rules and/or language-specific tools
are typically used. In the case of Arabic dialects, a further complication arises by the
informal status of the dialects, which are not standardized and not used in formal contexts
but rather only in informal online communities6 such as social networks, chats, Twitter and
SMS messages. This causes further mismatch in domain and genre.
Thus, translating from Arabic dialects to Modern Standard Arabic requires, among
other things, normalizing informal text to a formal form. In fact, this is a more general
problem, which arises with informal sources like SMS messages and Tweets for any language
(Han & Baldwin, 2011). Here the main focus is on coping with spelling errors, abbreviations, and slang, which are typically addressed using string edit distance, while also taking
pronunciation into account. This is different from our task, where we try to reuse good,
formal text from one language to help improve SMT for another language.
A closely related relevant line of research is on language adaptation and normalization,
when done specifically for improving SMT into another language. For example, Marujo,
Grazina, Lus, Ling, Coheur, and Trancoso (2011) described a rule-based system for adapting Brazilian Portuguese (BP) to European Portuguese (EP), which they used to adapt BP
English bi-texts to EPEnglish. Unlike this work, which heavily relied on language-specific
rules, our approach is statistical and largely language-independent; more importantly, we
have a different objective: translate into a third language X.
2.4 Pivoting
Another relevant line of research is improving SMT using additional languages as pivots.
Callison-Burch, Koehn, and Osborne (2006) improved phrase-based SMT from Spanish
and French to English using source-language phrase-level paraphrases extracted using the
pivoting technique of Bannard and Callison-Burch (2005) and eight additional languages
from the Europarl corpus (Koehn, 2005).
6. The Egyptian Wikipedia is one notable exception.

184

fiImproving SMT for a Resource-Poor Language

For example, using German as a pivot, they extracted English paraphrases from a parallel English-German bi-text by looking for English phrases that were aligned to the same
German phrase: e.g., if under control and in check were aligned to unter controlle, they were
hypothesized to be paraphrases with some probability. Such Spanish/French paraphrases
were added as additional entries in the phrase table of an SpanishEnglish/FrenchEnglish
phrase-based SMT system and paired with the English translation of the original Spanish/French phrase. The system was then tuned with minimum error rate training (MERT)
(Och, 2003), adding an extra feature penalizing low-probability paraphrases; this yielded
huge increase in coverage (from 48% to 90% of the test word types when 10K training
sentence pairs were used), and up to 1.8 BLEU points of absolute improvement.
Unlike this kind of pivoting, which can only improve source-language lexical coverage,
we augment both the source- and the target-language sides. Second, while pivoting ignores
context when extracting paraphrases, we do take it into account. Third, by using as an
additional language one that is related to the source, we are able to get increase in BLEU
that is comparable and even better than what pivoting achieves with eight pivot languages.
On the negative side, our approach is limited in that it requires that the auxiliary language
X2 be related to source language X1 , while the pivoting language Z does not have to be
related to X1 nor to the target language Y . However, we only need one additional parallel
corpus (for X2 -Y ), while pivoting needs two: one for X1 -Z and one for Z-Y . Finally, note
that our approach is orthogonal to pivoting, and thus the two can be combined (which we
will do in Section 7.8).
We should note that pivoting is a more general technique, which has been widely used
in statistical machine translation, e.g., for triangulation, where one wants to build a FrenchGerman machine translation system from a French-English and an English-German bi-text,
without an access to a French-German bi-text. In that case, pivoting can be done at
the sentence-level, e.g., by cascading translation systems, first translating from French to
English, and then translating from English to German (de Gispert & Mario, 2006; Utiyama
& Isahara, 2007) or at the phrase-level, e.g., using the phrase table composition, which
can be done off-line (Cohn & Lapata, 2007; Wu & Wang, 2007), or it can be integrated in
the decoder (Bertoldi, Barbaiani, Federico, & Cattoni, 2008). It has been also shown that
pivoting can outperform direct translation, e.g., translating from Arabic to Chinese could
work better using English as a pivot than if done directly (Habash & Hu, 2009). Moreover,
it has been argued that English might not always be the optimal choice of a pivot language
(Paul, Yamamoto, Sumita, & Nakamura, 2009). Finally, pivoting techniques have been also
used at the word-level, e.g., for translation lexicon induction between Japanese and German
using English (Tanaka, Murakami, & Ishida, 2009), or for improving word alignments (Filali
& Bilmes, 2005; Kumar, Och, & Macherey, 2007). Pivot languages have also been used for
lexical adaptation (Crego, Max, & Yvon, 2010).
Overall, all these more general pivoting techniques aim to build a machine translation
system for a new (resource-poor) language pair X-Y , assuming the existence of bi-texts X-Z
and Z-Y for some auxiliary pivoting language Z, e.g., they would be useful for translating
between Malay and Indonesian, by pivoting over English. In contrast, we are interested
in building a better system for translating not from X to Y but from X to Z, e.g., from
Indonesian to English. We further assume that the bi-text for X-Z is small, while the one
for Z-Y is large, and we require that X and Y be closely related languages.
185

fiNakov & Ng

Another related line of research is on statistical multi-source translation, which focuses
on translating a text given in multiple source languages into a single target language (Och
& Ney, 2001; Schroeder, Cohn, & Koehn, 2009). This situation arises for a small number
of resource-rich languages in the context of the United Nations or the European Union, but
it could hardly be expected for resource-poor languages.

3. Motivating Example
Consider Article 1 of the Universal Declaration of Human Rights:
All human beings are born free and equal in dignity and rights. They are endowed
with reason and conscience and should act towards one another in a spirit of
brotherhood.
and let us see how it is translated in the closely related Malay and Indonesian and the more
dissimilar Spanish and Portuguese.
3.1 Malay and Indonesian
Malay (aka Bahasa Malaysia) and Indonesian (aka Bahasa Indonesia) are closely related
Astronesian languages, with about 180 million speakers combined. Malay is official in
Malaysia, Singapore and Brunei, and Indonesian is the national language of Indonesia.
The two languages are mutually intelligible to a great extent, but they differ in orthography/pronunciation and vocabulary.
Malay and Indonesian use a unified spelling system based on the Latin alphabet, but
they exhibit occasional differences in orthography due to diverging pronunciation, e.g.,
kerana vs. karena (because) and Inggeris vs. Inggris (English) in Malay and Indonesian,
respectively. More rarely, the differences are historical, e.g., wang vs. uang (money).
The two languages differ more substantially in vocabulary, mostly because of loan words,
where Malay typically follows the English pronunciation, while Indonesian tends to follow
Dutch, e.g., televisyen vs. televisi, Julai vs. Juli, and Jordan vs. Yordania. For words
of Latin origin that end on -y in English, Malay uses -i, while Indonesian uses -as, e.g.,
universiti vs. universitas, kualiti vs. kualitas.
While there are many cognates between the two languages, there are also some false
friends, which are words identically spelled but with different meanings in the two languages.
For example, polisi means policy in Malay but police in Indonesian. There are also many
partial cognates, e.g., nanti means both will (future tense marker) and later in Malay
but only later in Indonesian. As a result, fluent Malay and fluent Indonesian can differ
substantially. Consider, for example, the Malay and the Indonesian versions of Article 1 of
the Universal Declaration of Human Rights (from the official website of the United Nations):
 Malay: Semua manusia dilahirkan bebas dan samarata dari segi kemuliaan
dan hak-hak. Mereka mempunyai pemikiran dan perasaan hati dan hendaklah bertindak di antara satu sama lain dengan semangat persaudaraan.
 Indonesian: Semua orang dilahirkan merdeka dan mempunyai martabat dan hak-hak yang sama. Mereka dikaruniai akal dan hati nurani dan
hendaknya bergaul satu sama lain dalam semangat persaudaraan.
186

fiImproving SMT for a Resource-Poor Language

Semantically, the overlap is substantial, and a native speaker of Indonesian can understand most of what the Malay version says, but would find parts of it not quite fluent.
In the above example, there is only 50% overlap at the individual word level (overlapping
words are underlined). In fact, the actual vocabulary overlap is much higher, e.g., there
is only one word in the Malay text that does not exist in Indonesian: samarata. Other
differences are due to the use of different morphological forms, e.g., hendaklah vs. hendaknya
(conscience), both derivational variants of hendak (want).
Of course, word choice in translation is often a matter of taste, and thus not all differences above are necessarily required. To test this, we asked a native speaker of Indonesian
to adapt the Malay version to Indonesian while preserving as many words as possible. This
yielded the following, arguably somewhat less fluent, Indonesian version, which only has six
words that are not in the Malay version:
 Indonesian (closer to Malay): Semua manusia dilahirkan bebas dan mempunyai martabat dan hak-hak yang sama. Mereka mempunyai pemikiran dan
perasaan dan hendaklah bergaul satu sama lain dalam semangat persaudaraan.
Note the increase in the average length of the matching phrases for this adapted version.
3.2 Spanish and Portuguese
Spanish and Portuguese also exhibit a noticeable degree of mutual intelligibility, but differ
in pronunciation, spelling, and vocabulary. Unlike Malay and Indonesian, however, they
also differ syntactically and exhibit a high level of spelling differences; this can be seen from
the translation of Article 1 of the Universal Declaration of Human Rights:
 Spanish: Todos los seres humanos nacen libres e iguales en dignidad y
derechos y, dotados como estan de razon y conciencia, deben comportarse fraternalmente los unos con los otros.
 Portuguese: Todos os seres humanos nascem livres e iguais em dignidade
e em direitos. Dotados de razao e de consciencia, devem agir uns para com os
outros em esprito de fraternidade.
We can see that the exact word-level overlap between the Spanish and the Portuguese
is quite low: about 17% only. Still, we can see some overlap at the level of short phrases,
not just at the word level.
Spanish and Portuguese share about 90% of their vocabulary and thus the observed level
of overlap may appear surprisingly low. The reason is that many cognates between the two
languages exhibit minor spelling variations. These variations can stem from different rules
of orthography, e.g., senhor vs. senor in Portuguese and Spanish, but they can also be due
to genuine phonological differences. For example, the Portuguese suffix -cao corresponds to
the Spanish suffix -cion, e.g., evolucao vs. evolucion. Similar systematic differences exist
for verb endings like -ou vs. -o (for 3rd person singular, simple past tense), e.g., visitou vs.
visito, or -ei vs. -e (for 1st person singular, simple past tense), e.g., visitei vs. visite. There
are also occasional differences that apply to a particular word only, e.g., dizer vs. decir,
Mario vs. Mario, and Maria vs. Mara.
187

fiNakov & Ng

Going back to our example, if we ignore the spelling variations between the cognates in
the two languages, the overlap jumps significantly:
 Portuguese (cognates transliterated to Spanish):
Todos los seres humanos nacen libres e iguales en dignidad y en derechos.
Dotados de razon y de conciencia, deben agir unos para con los otros en
esprito de fraternidad.
All words in the above sentence are Spanish, and most of the differences from the official
Spanish version above are due to different word choice by the translator; in fact, the sentence
can become fluent Spanish if agir unos par is changed to comportarse los unos con.

4. Method
The above examples suggest that it may be feasible to use bi-texts for one language to improve SMT for some related language, possibly after suitable transliteration of the cognates
in the additional language to match the target spelling.
Thus, below we describe two general strategies for improving phrase-based SMT from
some resource-poor language X1 into a target language Y , using a bi-text X2 -Y for a
related resource-rich language X2 : (a) bi-text concatenation, with possible repetitions of
the original bi-text for balance, and (b) phrase table combination, where each bi-text is
used to build a separate phrase table, and then the two phrase tables are combined. We
discuss the advantages and disadvantages of these general strategies, and we propose a
hybrid approach that combines their strengths while trying to avoid their limitations.
4.1 Concatenating Bi-texts
We can simply concatenate the bi-texts for X1 -Y and X2 -Y into one large bi-text and use
it to train an SMT system. This offers several potential benefits.
First, it can yield improved word alignments for the sentences that came from the X1 -Y
bi-text, e.g., since the additional sentences can provide new contexts for the rare words in
that bi-text, thus potentially improving their alignments, which in turn could yield better
phrase pairs. Rare words are known to serve as garbage collectors (Brown, Della Pietra,
Della Pietra, Goldsmith, Hajic, Mercer, & Mohanty, 1993) in the IBM word alignment
models. Namely, a rare source word tends to align to many target language words rather
than allowing them to stay unaligned or to align to other source words. The problem is not
limited to IBM word alignment models (Brown, Della Pietra, Della Pietra, & Mercer, 1993);
it also exists for the HMM model of Vogel, Ney, and Tillmann (1996). See Graca, Ganchev,
and Taskar (2010) for a detailed discussion and examples of the garbage collector effect.
Moreover, concatenation can provide new source-language side translation options, thus
increasing lexical coverage and reducing the number of unknown words; it can also provide
new useful non-compositional phrases on the source-language side, thus yielding more fluent
translation output. It also offers new target-language side phrases for known source phrases,
which could improve fluency by providing more translation options for the language model
to choose from. Finally, inappropriate phrases including words from X2 that do not exist in
X1 will not match the test-time input, while inappropriate new target-language translations
still have the chance to be filtered out by the language model.
188

fiImproving SMT for a Resource-Poor Language

However, simple concatenation can be problematic. First, when concatenating the small
bi-text for X1 -Y with the much larger one for X2 -Y , the latter will dominate during word
alignment and phrase extraction, thus hugely influencing both lexical and phrase translation
probabilities, which can yield poor performance. This can be counter-acted by repeating
the small bi-text several times so that the large one does not dominate. Second, since the bitexts are merged mechanically, there is no way to distinguish between phrases extracted from
the bi-text for X1 -Y from those coming from the bi-text for X2 -Y . The former are for the
target language pair and thus probably should be preferred, while using the latter should
be avoided since they might contain inappropriate translations for some words from X1 .
For example, a phrase pair from the Indonesian-English bi-text could (correctly) translate
polisi as police, while one from the Malay-English bi-text could (correctly for Malay, but
inappropriately for Indonesian) translate it as policy. This is because the Malay word polisi
and the Indonesian word polisi are false friends.
We experiment with combining the original and the additional training bi-text in the
following three ways:
 cat1: We simply concatenate the original and the additional training bi-text to form
a new training bi-text, which we use to train a phrase-based SMT system.
 catk: We concatenate k copies of the original and one copy of the additional training
bi-text to form a new training bi-text. The value of k is selected so that the original
bi-text approximately matches the size of the additional bi-text.
 catk:align: We concatenate k copies of the original and one copy of the additional
training bi-text to form a new training bi-text. We generate word alignments for this
concatenated bi-text. Then we throw away all sentence pairs and their alignments,
except for one copy of the original bi-text. Thus, effectively we induce word alignments
for the original bi-text only, while using the concatenated bi-text to estimate the
statistics about them. We then use these alignments to build a phrase table for the
original bi-text.
The first and the second method represent simple and balanced bi-text concatenation,
respectively. The third method is a version of the second one, where the additional bi-text
is only used to improve the word alignments for the original bi-text, but is not used for
phrase extraction. Thus, it isolates the effect of improved word alignments from the effect
of improved vocabulary coverage that the additional training bi-text can provide. cat1
and catk:align will be the basic building blocks of our more sophisticated approach below.
4.2 Combining Phrase Tables
An alternative way of making use of the additional training bi-text for the resource-rich
language pair X2 -Y in order to train an improved phrase-based SMT system for X1  Y is
to build separate phrase tables from X1 -Y and X2 -Y , which can then be (a) used together,
e.g., as alternative decoding paths, (b) merged, e.g., using one or more extra features to
indicate the bi-text each phrase pair came from, or (c) interpolated, e.g., using simple linear
interpolation.
189

fiNakov & Ng

Building two separate phrase tables offers several advantages. First, the preferable
phrase pairs extracted from the bi-text for X1 -Y are clearly distinguished from (or given
a higher weight in the linear interpolation compared to) the potentially riskier ones from
the X2 -Y bi-text. Second, the lexical and the phrase translation probabilities are combined
in a principled manner. Third, using the X2 -Y bi-text, which is much larger than that
for X1 -Y is not problematic any more: it will not dominate as was the case with simple
concatenation above. Finally, as with bi-text merging, there are many additional sourceand target-language phrases, which offer new translation options. On the negative side, the
opportunity is lost to improve word alignments for the sentences in the X1 -Y bi-text.
We experiment with the following three phrase table combination strategies:
 Two-tables: We build two separate phrase tables, one for each of the two bi-texts,
and we use them as alternative decoding paths (Birch, Osborne, & Koehn, 2007).
 Interpolation: We build two phrase tables, Torig and Textra , for the original and for
the additional bi-text, respectively, and we use linear interpolation to combine the
corresponding conditional probabilities: Pr(e|s) =  Prorig (e|s) + (1  ) Prextra (e|s).
We optimize the value of  on the development dataset, i.e., we run MERT for merged
phrase tables generated using different values of , and we choose the value that gives
rise to the phrase table that achieves the highest tuning BLEU score. In order to
reduce the search space, we only try five values for  (.5, .6, .7, .8 and .9), i.e., we
reduce the tuning to this discrete set, and we use the same  for all four conditional
probabilities in the phrase table.
 Merge: We build two separate phrase tables, Torig and Textra , for the original and for
the additional training bi-text, respectively. We then concatenate them, giving priority to Torig as follows: We keep all source-target phrase pairs from Torig , adding to
them those source-target phrase pairs from Textra that were not present in Torig . For
each source-target phrase pair added, we retain its associated conditional probabilities (forward/reverse phrase translation probability, and forward/reverse lexicalized
phrase translation probability) and the phrase penalty.7 We further add up to three
additional features to each entry in the new table: F1 , F2 , and F3 . The value of F1 is
1 if the source-target phrase pair originated from Torig , and 0.5 otherwise. Similarly,
F2 =1 if the source-target phrase pair came from Textra , and F2 =0.5 otherwise. The
value of F3 is 1 if the source-target phrase pair was in both Torig and Textra , and
0.5 otherwise. Thus, there are three possible feature value combinations: (1;0.5;0.5),
(0.5;1;0.5) and (1;1;1); the last one is used for a phrase pair that was in both Torig and
Textra . We experiment with using (1) F1 only, (2) F1 and F2 , and (3) F1 , F2 , and F3 .
We set the weights for all phrase table features, including the standard five and the
additional three, using MERT. We further optimize the number of additional features
(one, two, or three) on the development set, i.e., we run MERT for phrase tables with
one, two, and three extra features and we choose the phrase table that has achieved
the highest BLEU score on tuning, as suggested in the work of Nakov (2008).
7. In theory, we should also re-normalize the probabilities since they may not sum to one. In practice, this
is not that important since the log-linear phrase-based SMT model does not require that the features be
probabilities at all, e.g., F1 , F2 , F3 , and the phrase penalty are not probabilities.

190

fiImproving SMT for a Resource-Poor Language

4.3 Proposed Approach
Taking into account the potential advantages and disadvantages of the above two general
strategies, we propose an approach that tries to get the best from each of them, namely: (i )
improved word alignments for X1 -Y , by biasing the word alignment process with additional
sentence pairs from X2 -Y , and (ii ) increased lexical coverage, by using additional phrase
pairs that the X2 -Y bi-text can provide. This is achieved by using Merge to combine the
phrase tables for catk:align and cat1. The process can be described in more detail as
follows:
1. Build a balanced bi-text Brep , which consists of the X1 -Y bi-text repeated k times
followed by one copy of the X2 -Y bi-text. Generate word alignments for Brep , then
truncate them, only keeping word alignments for one copy of the X1 -Y bi-text. Use
these word alignments to extract phrases, and build a phrase table Trep trunc .
2. Build a bi-text Bcat that is a simple concatenation of the bi-texts for X1 -Y and X2 -Y .
Generate word alignments for Bcat , extract phrases, and build a phrase table Tcat .
3. Generate a merged phrase table by combining Trep trunc and Tcat . The merging gives
priority to Trep trunc and uses extra features indicating the origin of each entry in the
combined phrase table.

5. Datasets
We experiment with the following bi-texts and monolingual English data:
 Indonesian-English (in-en):
 train: 28,383 sentence pairs (0.8M, 0.9M words);
 dev: 2,000 sentence pairs (56.6K, 63.3K words);
 test: 2,000 sentence pairs (58.2K, 65.0K words);
 monolingual English en in : 5.1M words.
 Malay-English (ml-en):
 train: 190,503 sentence pairs (5.4M, 5.8M words);
 dev: 2,000 sentence pairs (59.7K, 64.5K words);
 test: 2,000 sentence pairs (57.9K, 62.4K words);
 monolingual English en ml : 27.9M words.
 Spanish-English (es-en):
 train: 1,240,518 sentence pairs (35.7M, 34.6M words);
 dev: 2,000 sentence pairs (58.9K, 58.1K words);
 test: 2,000 sentence pairs (56.2K, 55.5K words);
 monolingual English en es:pt : 45.3M words (the same as for pt-en and it-en).
191

fiNakov & Ng

 Portuguese-English (pt-en):





train: 1,230,038 sentence pairs (35.9M, 34.6M words).
dev: 2,000 sentence pairs (59.3K, 58.5K words);
test: 2,000 sentence pairs (56.5K, 55.7K words);
monolingual English en es:pt : 45.3M words (the same as for es-en and it-en).

 Italian-English (it-en):





train: 1,565,885 sentence pairs (43.5M, 44.1M words);
dev: 2,000 sentence pairs (56.8K, 57.7K words);
test: 2,000 sentence pairs (57.4K, 60.3K words);
monolingual English en es:it : 45.3M words (the same as for es-en and pt-en).

The lengths of the sentences in all bi-texts above are limited to 100 tokens. For each of
the language pairs, we have a development and a testing bi-text, each with 2,000 parallel
sentence pairs. We made sure the development and the testing bi-texts shared no sentences with the training bi-texts; we further excluded from the monolingual English data
all sentences from the English sides of the development and the testing bi-texts.
The training bi-text datasets for es-en, pt-en, and it-en were built from v.3 of the
Europarl corpus, excluding the Q4/2000 portion of the data (2000-10 to 2000-12), out of
which we created our testing and development datasets.
We built the in-en bi-texts from comparable texts that we downloaded from the Web.
We translated the Indonesian texts to English using Google Translate, and we matched8
them against the English texts using a cosine similarity measure and heuristic constraints
based on document length in words and in sentences, overlap of numbers, words in uppercase, and words in the title. Next, we extracted pairs of sentences from the matched
document pairs using competitive linking (Melamed, 2000), and we retained the ones whose
similarity was above a pre-specified threshold. The ml-en bi-text was built similarly.
For all pairs of languages, the monolingual English text for training the language model
consists of the English side of the corresponding bi-text plus some additional English text
from the same source.
Note that the monolingual data for training an English language model is the same
for Spanish, Portuguese, and Italian since the es-en, pt-en, and it-en are from the same
origin: in fact, with very few exceptions, the sentences in these bi-texts can be aligned
over English to make a es-en-pt-it four-text, since they are all translations (from English
and other languages) of the same original parliamentary debates. Thus, the English side of
es-en, pt-en, and it-en, and of the unaligned English sentences have the same distribution.
This is not the case, however, for Malay and Indonesian, which come from different
sources and are on different topics  they discuss issues in Malaysia and Indonesia, respectively. In particular, they differ a lot in the use of named entities: names of persons,
locations, and organizations that they talk about. This is why we have separate monolingual texts to train English language models for ml-en and in-en; as we will see below, they
do indeed yield different performance for SMT.
8. Note that the automatic translations were used for matching only; the final bi-text contained no automatic translations.

192

fiImproving SMT for a Resource-Poor Language

6. Transliteration
As we mentioned above, our approach relies on the existence of a large number of cognates between related languages. While linguists define cognates as words derived from a
common root9 (Bickford & Tuggy, 2002), computational linguists typically ignore origin,
defining them as words in different languages that are mutual translations and have a similar orthography (Melamed, 1999; Mann & Yarowsky, 2001; Bergsma & Kondrak, 2007).
Here we adopt the latter definition.
As we have seen in Section 3, transliteration can be very helpful for languages like
Spanish and Portuguese, which have many regular spelling differences. Thus, we build a
system for automatic transliteration from Portuguese to Spanish, which we train on a list
of automatically extracted pairs of likely cognates. We apply this system on the Portuguese
side of the pt-en training bi-text.
Classic approaches to automatic cognate extraction look for non-stopwords with similar
spelling that appear in parallel sentences in a bi-text (Kondrak et al., 2003). In our case,
however, we need to extract cognates between Spanish and Portuguese given pt-en and
es-en bi-texts only, i.e., without having a pt-es bi-text. Although it is easy to construct a
pt-es bi-text from the Europarl corpus, we chose not to do so since, in general, synthesizing
a bi-text for X1 -X2 would be impossible: e.g., it cannot be done for ml-in given our training
datasets for in-en and ml-en since their English sides have no sentences in common.
Thus, we extracted the list of likely cognates between Portuguese and Spanish from
the training pt-en and es-en bi-texts using English as a pivot as follows: We started with
IBM model 4 word alignments, from which we extracted four conditional lexical translation
probabilities: Pr(pj |ei ) and Pr(ei |pj ) for Portuguese-English, and Pr(sk |ei ) and Pr(ei |sk )
for Spanish-English, where pj , ei , and sk stand for a Portuguese, an English and a Spanish
word, respectively. Following Wu and Wang (2007), we then induced conditional lexical
translation probabilities Pr(pj |sk ) and Pr(sk |pj ) for Portuguese-Spanish as follows:
Pr(pj |sk ) =

i Pr(pj |ei , sk ) Pr(ei |sk )

P

Assuming pj is conditionally independent of sk given ei , we can simplify this:
Pr(pj |sk ) =

i Pr(pj |ei ) Pr(ei |sk )

P

Similarly, for Pr(sk |pj ), we obtain
Pr(sk |pj ) =

i Pr(sk |ei ) Pr(ei |pj )

P

We excluded all stopwords, words of length less than three, and those containing digits.
We further calculated Prod(pj , sk ) = Pr(pj |sk ) Pr(sk |pj ), and we excluded all PortugueseSpanish word pairs (pj , sk ) for which Prod(pj , sk ) < 0.01. The value of 0.01 has been
previously suggested for filtering phrase pairs obtained using pivoting (Callison-Burch, 2008,
2012; Denkowski & Lavie, 2010; Denkowski, 2012). From the remaining pairs, we extracted
likely cognates based on Prod(pj , sk ) and on the orthographic similarity between pj and sk .
Following Melamed (1995), we measured the orthographic similarity using the longest
common subsequence ratio (lcsr), defined as follows:
9. E.g., Latin tu, Old English thou, Greek su, and German du are all cognates meaning 2nd person singular.

193

fiNakov & Ng

lcsr(s1 , s2 ) =

|LCS(s1 ,s2 )|
max(|s1 |,|s2 |)

where lcs(s1 , s2 ) is the longest common subsequence of s1 and s2 , and |s| is the length of s.
We retained as likely cognates all pairs for which lcsr was 0.58 or higher; this value
was found by Kondrak et al. (2003) to be optimal for a number of language pairs in the
Europarl corpus.
Finally, we performed competitive linking (Melamed, 2000), assuming that each Portuguese wordform had at most one Spanish best cognate match. Thus, using the values of
Prod(pj , sk ), we induced a fully-connected weighted bipartite graph. Then, we performed
a greedy approximation to the maximum weighted bipartite matching in that graph, i.e.,
competitive linking, as follows: First, we accepted as cognates the cross-lingual pair (pj , sk )
with the highest Prod(pj , sk ) in the graph, and we discarded the words pj and sk from further consideration. Then, we accepted the next highest-scored pair, and we discarded the
involved wordforms and so forth. The process was repeated until there were no matchable
word pairs left.
Note that our cognate extraction algorithm has three components: (1) orthographic,
based on lcsr, (2) semantic, based on pivoting over English, and (3) competitive linking.
The semantic component is very important and makes the extraction of false friends
very unlikely. Consider for example the Spanish-Portuguese word pairs largo  largo and
largo  longo. The latter is a pair of true cognates, but the former is a pair of false
friends since largo means long in Spanish but wide in Portuguese. The word largo appears
8,489 times in the es-en bi-text and 432 times in the pt-en bi-text. However, having
different meanings, they do not get aligned to the same English word with high probability,
which results in very low scores for the conditional probabilities: Pr(pj |sk ) = 0.000464 and
Pr(sk |pj ) = 0.009148; thus, Prod(pj , sk ) = 0.000004, which is below the 0.01 threshold.
As a result, the false friend pair largo  largo does not get extracted. In contrast, the
true cognate pair largo  longo does get extracted because the corresponding conditional
probabilities for it are 0.151354 and 0.122656, respectively, and their product is 0.018564,
which is above 0.01 (moreover, lcsr = 0.6, which is above the 0.58 threshold).
The competitive linking component helps prevent issues related to word inflection that
cannot be handled using pivoting alone. For example, the word for green in both Spanish
and Portuguese has two forms: verde for singular, and verdes for plural. Without competitive linking, we would extract not only verde  verde (Prod(pj , sk ) = 0.353662) and
verdes  verdes (Prod(pj , sk ) = 0.337979), but also the incorrect word pairs verde  verdes
(Prod(pj , sk ) = 0.109792) and verdes  verde (Prod(pj , sk ) = 0.106088). Competitive linking, however, prevents this by asserting that no Portuguese and no Spanish word can have
more than one true cognate, which effectively eliminates the wrong pairs.
Thus, taken together, the semantic component and competitive linking make the extraction of false friends very unlikely. Still, occasionally, we do get some wrong alignments
such as intrusa  intrusas, where a singular form is matched with a plural form, which
occurs mostly in the case of rare words like intrusa (intruder, feminine) whose alignments
tend to be unreliable, and for which very few inflected forms are available to competitive
linking to choose from.
Note that the described transliteration system is focusing more on precision and less
on recall. This is because the extracted likely cognate pairs are going to be used to train
194

fiImproving SMT for a Resource-Poor Language

an SMT-based transliteration system. This system will have a translation component,
which should be able to generate many options, and a target language model component,
which would help filter those options. The translation component should tend to generate
good options, and thus it needs to be trained primarily on instances of systematic, regular
differences, such as evolucao  evolucion, from which the suffix change -cao  -cion can be
learned. Occasional differences such as dizer  decir cannot be generalized and thus are
less useful (they are also less frequent, and thus missing some of them is arguably not so
important), but they can be simply memorized by the model as whole words and still used.
We should also note that our focus on precision of cognate pair extraction does not mean
that we are going to extract primarily cognate pairs with very few spelling differences. As
we explained above, spelling is just one component of our cognate pair extraction approach;
there are also a semantic and a competitive linking component, which could eliminate many
candidates with close spelling and prefer others with more dissimilarities (recall the correct
choice of largo  longo over the wrong largo  largo).
Note that the generality of our transliteration approach is not necessarily compromised
by the fact that LCSR requires that the languages use the same writing system. For example, Cyrillic-written Serbian and Roman-written Croatian can still be compared using
LCSR, after an initial letter-by-letter mapping between the Cyrillic and the Roman alphabets, which is generally straightforward. Of course, even when using the same alphabet,
languages can have different orthographical conventions, which might make them look more
divergent than what the actual phonetics would suggest, e.g., compare qui/chi, gui/ghi,
glio/llo in Spanish and Italian. Even though LCSR between the Italian-Spanish cognates
chi and qui is lower than our threshold of 0.58, the correspondence between them as strings
can still be learned from longer cognates, e.g., macchina and maquina. This would then
allow the transliteration system to convert chi into qui as a word.
Going back to the actual experiments, as a result of the cognate extraction procedure,
we ended up with 28,725 Portuguese-Spanish cognate pairs, 9,201 (or 32.03%) of which had
spelling differences. For each pair in the list of cognate pairs, we added spaces between any
two adjacent letters for both wordforms, and we further appended the start and the end
characters ^ and $. For example, the cognate pair evolucao  evolucion became
^ e v o l u c a o $  ^ e v o l u c i o n $
We randomly split the resulting list into a training (26,725 pairs) and a development
dataset (2,000 pairs), and we trained and tuned a character-level phrase-based monotone
SMT system similar to Finch and Sumita (2008) to transliterate a Portuguese wordform
into a Spanish wordform. We used a Spanish language model trained on 14M word tokens
(obtained from the above-mentioned 45.3M-token monolingual English corpus after excluding punctuation, stopwords, words of length less than three, and those containing digits):
one per line and character-separated with added start and end characters as in the above
example. We set both the maximum phrase length and the language model order to ten;
we found these values by tuning on the development dataset. We tuned the system using
MERT, and we saved the feature weights. The tuning BLEU was 95.22%, while the baseline
BLEU, for leaving the Portuguese words intact, was 87.63%.
195

fiNakov & Ng

Finally, we merged the training and the tuning datasets and we retrained. We used the
resulting system with the saved feature weights to transliterate the Portuguese side of the
training pt-en bi-text, which yielded a new ptes -en training bi-text.
We repeated the same procedure for Italian-English. We extracted 25,107 ItalianSpanish cognate pairs, 14,651 (or 58.35%) of which had spelling differences. Then, we
split the list into a training (23,107 pairs) and a development dataset (2,000 pairs), and
trained a character-level phrase-based monotone SMT system as we did for Spanish-English;
the tuning BLEU was 94.92%. We used the resulting system to transliterate the Italian
side of the training it-en bi-text, thus obtaining a new ites -en training bi-text.
We also applied transliteration to Malay into Indonesian, even though we knew that
the spelling differences between these two languages were rare. We extracted 5,847 likely
cognate pairs, 844 (or 14.43%) of which had spelling differences, which we used to train a
transliteration system. The highest tuning BLEU was 95.18% (for maximum phrase size
and LM order of 10), but the baseline was 93.15%. We then re-trained the system on the
combination of the training and the development datasets, and we transliterated the Malay
side of the training ml-en bi-text, which yielded a new mlin -en training bi-text.

7. Experiments and Evaluation
Below we describe our baseline system, and we further perform various experiments to assess
the similarity between the original (Indonesian and Spanish) and the auxiliary languages
(Malay and Portuguese). We then improve IndonesianEnglish and SpanishEnglish SMT
using Malay and Portuguese, respectively, as auxiliary languages.
We also take a closer look at improving SpanishEnglish SMT, performing a number of
additional experiments. First, we try using an additional language that is more dissimilar
to Spanish, substituting Portuguese with Italian. Second, we experiment with two auxiliary
languages simultaneously: Portuguese and Italian. Finally, we combine our method with
two orthogonal rivaling approaches: (1) using cognates between the source and the target
language (Kondrak et al., 2003), and (2) source-language side paraphrasing with a pivot
language (Callison-Burch et al., 2006).
7.1 Baseline SMT System
In the baseline, we used the following setup: We first tokenized and lowercased both sides of
the training bi-text. We then built separate directed word alignments for EnglishX and
XEnglish (X{Indonesian, Spanish}) using IBM model 4 (Brown, Della Pietra, Della
Pietra, & Mercer, 1993), we combined them using the intersect+grow heuristic (Koehn
et al., 2007), and we extracted phrase pairs of maximum length seven. We thus obtained
a phrase table where each phrase pair is associated with the five standard parameters:
forward and reverse phrase translation probabilities, forward and reverse lexical translation probabilities, and phrase penalty. We then trained a log-linear model using standard
SMT feature functions: trigram language model probability, word penalty, distance-based10
distortion cost, and the parameters from the phrase table.
10. We also tried lexicalized reordering (Koehn, Axelrod, Mayne, Callison-Burch, Osborne, & Talbot, 2005).
While it yielded higher absolute BLEU scores, the relative improvement for a sample of our experiments
was very similar to that achieved with distance-based re-ordering.

196

fiImproving SMT for a Resource-Poor Language

We set all weights by optimizing BLEU (Papineni, Roukos, Ward, & Zhu, 2002) using
MERT on a separate development set of 2,000 sentences (Indonesian or Spanish), and we
used them in a beam search decoder (Koehn et al., 2007) to translate 2,000 test sentences
(Indonesian or Spanish) into English. Finally, we detokenized the output, and we evaluated
it against a lowercased gold standard using BLEU.
7.2 Cross-lingual Translation Experiments
#
1
2
3
4
5
6

Train
ml-en
mlin -en
ml-en
ml-en
ml-en
mlin -en

Dev
ml-en
ml-en
ml-en
in-en
in-en
in-en

Test
ml-en
ml-en
in-en
in-en
in-en
in-en

LM
enml
enml
enml
enml
enin
enin

10K
44.93
38.99
13.69
13.98
15.56
16.44

20K
46.98
40.96
14.58
14.75
16.38
17.36

40K
47.15
41.02
14.76
14.91
16.52
17.62

80K
48.04
41.88
15.12
15.51
17.04
18.14

160K
49.01
42.81
15.84
16.27
17.90
19.15

Table 1: Malay-Indonesian cross-lingual SMT experiments: training on Malay
and testing on Indonesian for different number of training ml-en sentence pairs. Columns 2-5 present the bi-texts used for training, development,
and testing, and the monolingual data used to train the English language model.
The following columns show the resulting BLEU (in %) for different numbers of mlen training sentence pairs. Lines 1-2 show the results when training, tuning, and
testing on Malay, followed by lines 3-6 on results for training on Malay but testing
on Indonesian. Here mlin stands for Malay transliterated as Indonesian, and enml
and enin refer to the English side of the ml-en and in-en bi-text, respectively.

Here, we study the similarity between the original and the auxiliary languages.
First, we measured the vocabulary overlap between the original and the auxiliary languages. For Spanish and Portuguese, this was feasible since our training pt-en and es-en
bi-texts are from the same time span in the Europarl corpus and their English sides largely
overlap. We found 110,053 Portuguese and 121,444 Spanish word types in the pt-en and esen bi-texts, respectively, and 44,461 of them were identical, which means that 40.40% of the
Spanish word types are present on the Portuguese side of the pt-en bi-text. Unfortunately,
we could not directly measure the vocabulary overlap between Malay and Indonesian in the
same way since the English sides of the in-en and ml-en bi-texts do not overlap in content.
Second, following the general experimental setup of the baseline system, we performed
cross-lingual experiments, training on one language pair and testing on another one, in
order to assess the cross-lingual similarity for Indonesian-Malay and Spanish-Portuguese,
and the potential of combining their corresponding training bi-texts. The results are shown
in Tables 1 and 2. As we can see, this cross-lingual evaluation  training on ml-en (pt-en)
instead of in-en (es-en), and testing on in (es) text  yielded a huge decrease in BLEU
compared to the baseline: three times (for Malay) to five times (for Spanish)  even for
very large training datasets, and even when a proper English LM and development dataset
were used: compare line 1 to lines 3-5 in Table 1, and line 1 to lines 3-4 in Table 2.
197

fiNakov & Ng

#
1
2
3
4
5
6
7

Train
pt-en
ptes -en
pt-en
pt-en
ptes -en
es-en
es-en

Dev
pt-en
pt-en
pt-en
es-en
es-en
es-en
es-en

Test
pt-en
pt-en
es-en
es-en
es-en
es-en
pt-en

LM
enes:pt
enes:pt
enes:pt
enes:pt
enes:pt
enes:pt
enes:pt

10K
21.28
10.91
4.40
4.91
8.18
22.87
2.99

20K
23.11
11.56
4.77
5.12
9.03
24.71
3.14

40K 80K
24.43 25.72
12.16 12.50
4.57 5.02
5.64 5.82
9.97 10.66
25.80 27.08
3.33 3.54

160K
26.43
12.83
4.99
6.35
11.35
27.90
3.37

320K
27.10
13.27
5.32
6.87
12.26
28.46
3.94

640K 1.23M
27.78 27.96
13.48 13.71
5.08
5.34
6.44
7.10
12.69 13.79
29.51 29.90
4.18
3.99

Table 2: Portuguese-Spanish cross-lingual SMT experiments: training on Portuguese and testing on Spanish for different number of training pt-en
sentence pairs. Lines 1-2 show the results when training, tuning, and testing
on Portuguese, lines 3-5 are for training on Portuguese but testing on Spanish,
and lines 6-7 are for training on Spanish and testing on Spanish or Portuguese.
Columns 2-5 present the bi-texts used for training, development, and testing, and
the monolingual data used to train the English language model. The following
columns show the resulting BLEU (in %) for different numbers of training sentence pairs. Here ptes stands for Portuguese transliterated as Spanish. The English
LMs for pt-en and es-en are the same (marked as enes:pt ).

For Portuguese-Spanish, we further show results in the other direction, training on
Spanish and testing on Portuguese: compare line 6 to line 7 in Table 2. The results show a
comparable, slightly larger, drop in BLEU for that direction. We did not carry out reverse
direction experiments for Malay-Indonesian since we do not have enough parallel in-en data.
Third, we experimented with transliteration changing Malay to look like Indonesian
and Portuguese to look like Spanish. This caused the BLEU score to double for Spanish
(compare line 5 to lines 3-4 in Table 2, but improved far less for Indonesian (compare line 6 to
lines 3-5 in Table 1). Training on the transliterated data and testing on Malay/Portuguese
yielded about 10% relative decrease for Malay but 50% for Portuguese11 : compare line 1 to
line 2 in Tables 1 and 2. Thus, unlike Spanish and Portuguese, we found far less systematic
spelling variations between Malay and Indonesian. A closer inspection confirmed this: many
extracted likely Malay-Indonesian cognate pairs with spelling differences were in fact forms
of a word existing in both languages, e.g., kata and berkata (to say).
One interesting result in Table 1 is that switching the language model trained on enml
to one trained on enin yields significant improvements (compare lines 4 and 5 in Table 1).
This may appear striking since the former monolingual English text is about five times
bigger than the latter one, yet, this smaller language model yields better results. This is
due to a partial domain shift, especially, with respect to named entities: even though both
texts are in English and from the same domain, they discuss events in different countries,
which involve country-specific cities, companies, political parties and their leaders; a good
language model should be able to prefer good English translations of such named entities.
11. Interestingly, as lines 2 and 5 in Table 2 show, a system trained on 1.23M transliterated ptes -en sentence
pairs performs equally well when translating Portuguese and Spanish input text: 13.71% vs. 13.79%.

198

fiImproving SMT for a Resource-Poor Language

7.3 Improving IndonesianEnglish SMT using Malay

Figure 1: Impact of k on BLEU for catk for different number of extra ml-en
sentence pairs in IndonesianEnglish SMT. Shown are BLEU scores for
different numbers of k = 1,2,. . .,16 repetitions of in-en when concatenated to
10000n pairs from ml-en, n  {1,2,4,8,16}.

First, we study the impact of k on catk. for IndonesianEnglish SMT using Malay
as an additional language. We tried all values of k such that 1k16 with 10000n extra
ml-en sentence pairs, n{1,2,4,8,16}. As we can see in Figure 1, the highest BLEU scores
are achieved for (n; k){(1;2),(2;2),(4;4),(8;7),(16;16)}, i.e., when k  n. Thus, in order to
limit the search space, we used this relationship between k and n in our experiments (also
for Portuguese and Spanish). We should note that there is a lot of fluctuation in the results
in Figure 1, which is probably due to the small sizes of the training corpora. Given this
fluctuation, the results should not be over-interpreted, e.g., it may be just by chance that
there are peaks in the different curves at just the right places. Still, the overall tendency
is visible: we need to keep the balance between the original and the auxiliary bi-texts.
Tables 3 and 4 show the results for experiments on improving IndonesianEnglish SMT
using 10K, 20K, . . ., 160K additional pairs of ml-en parallel sentences. Table 3 compares
the performance of our approach to the baseline and to the three concatenation methods described in Section 4.1: cat1, catk, and catk:align, while Table 4 compares
the performance of our approach to various alternative ways of combining two phrase tables, namely, using alternative decoding paths, phrase table interpolation, and phrase table
merging, which were introduced in Section 4.2.
199

fiNakov & Ng

in-en
28.4K
28.4K
28.4K
28.4K
28.4K

ml-en
10K
20K
40K
80K
160K

Baseline
23.80<
23.80<
23.80<
23.80<
23.80<

cat1
24.29<
24.37<
24.38
24.17<

24.43<

catk
24.29<
(1)

24.48(2)

24.54(4)

24.65<
(8)
<
25.00(16)

catk:align
24.01<
(1)
<
24.35<
(2)
<
24.39<
(4)
24.18<
(8)

24.27<
(16)

Our approach
24.51(2;1) (+0.72)
<
24.70(2;2) (+0.90)
<
24.73(4;2) (+0.93)
<
24.97(8;3) (+1.17)
<
25.15(16;3) (+1.35)
<

Table 3: Improving IndonesianEnglish SMT using different numbers of additional Malay-English sentence pairs (varying the amount of additional
data): concatenations, repetitions, truncations, and our approach. The
baseline is for 28,383 in-en sentence pairs only. Shown are the BLEU scores (in %)
for different approaches. A subscript shows the best parameter value(s) found on
the development set and used on the test set to produce the given result: the first
value is the number of repetitions of the original bi-text while the second value,
if any, is the number of extra features added to the phrase table. The BLEU
scores that are statistically significantly better than the baseline/our approach are
marked on the left/right side by < (for p < 0.01) or  (for p < 0.05).

in-en
28.4K
28.4K
28.4K
28.4K
28.4K

ml-en
10K
20K
40K
80K
160K

Baseline
23.80<
23.80<
23.80<
23.80<
23.80<

Two Tables

23.79<
24.24<
24.27<
24.11<
<
24.58<

Interpolation
23.89<
(.9)
24.22<
(.8)
24.27<
(.8)

24.46<
(.8)
<
24.58<
(.8)

Merge
23.97<
(3)

24.46<
(3)
24.43
(3)
<
24.67(3)
<
24.79
(3)

Our approach
24.51(2;1) (+0.72)
<
24.70(2;2) (+0.90)
<
24.73(4;2) (+0.93)
<
24.97(8;3) (+1.17)
<
25.15(16;3) (+1.35)
<

Table 4: Improving IndonesianEnglish SMT using different numbers of additional Malay-English sentence pairs (varying the amount of additional
data): comparing our approach to various alternatives. The baseline is
for 28,383 in-en sentence pairs only. Shown are the BLEU scores (in %) for different approaches. A subscript shows the best parameter value(s) found on the
development set and used on the test set to produce the given result: for merging
methods, the first value is the number of repetitions of the original bi-text while
the second value, if any, is the number of extra features added to the phrase table;
for interpolation, we show the weight of the phrase pairs from in-en. The BLEU
scores that are statistically significantly better than the baseline/our approach are
marked on the left/right side by < (for p < 0.01) or  (for p < 0.05).

Several interesting general observations about Tables 3 and 4 can be made. First,
using more additional Indonesian-English sentences yields better results. Second, with one
exception, all experiments yield improvements over the baseline. Third, the improvements
are always statistically significant for our approach, according to Collins, Koehn, and
Kucerovas (2005) sign test.
200

fiImproving SMT for a Resource-Poor Language

Overall, among the different bi-text combination strategies, our approach performs
best, followed by catk, merge, and interpolation, which are very close in performance;
these three strategies are the only ones to consistently yield higher BLEU as the number of
additional ml-en sentence pairs grows. Methods like cat1, catk:align, and two-tables
are somewhat inconsistent in that respect. The latter method performs worst and is the
only one to go below the baseline (for 10K ml-en sentence pairs).
One possible reason for the relatively bad performance of two-tables could be that it
has to tune more weights compared to the other models: each phrase table has its own
feature weights, which means five additional features. It is well known that MERT cannot
handle too many features (Chiang, Knight, & Wang, 2009; Hopkins & May, 2011), and
we believe this is our case as it takes 3035 iterations to finish, while the other methods
normally only need 78 iterations. A closer look at MERT revealed two further issues: (1)
The n-best list had many identical translations, i.e., spurious ambiguity became an even
bigger problem. (2) In MERT, identical translations had different feature values, which
could have confused the optimization. We believe these problems were caused by the fact
that often two identical translations would be found that use the same phrases but from
the different tables and thus with different scores.
Note also the high values of the interpolation parameter  in Table 4: 0.80.9. They
indicate that the original bi-text needs to be weighted higher than the auxiliary one, thus
supporting the need for balanced concatenations with repetitions of the original bi-text,
and indirectly explaining why catk performs better than cat1 in Table 3.
7.4 Improving SpanishEnglish SMT using Portuguese
Next, we experiment with using Portuguese to improve SpanishEnglish SMT.
The results are shown in Tables 5 and 6. Overall, they are consistent with those for
IndonesianEnglish SMT using the additional Malay-English bi-text (shown in Tables 3
and 4 above). We can further observe that, as the size of the original bi-text increases, the
gain in BLEU decreases, which is to be expected. Note also that here transliteration is very
important: it doubles the absolute gain in BLEU achieved by our method.
Table 7 compares the performance of our technique for 160K vs. 1.23M additional
pt-en parallel sentence pairs, with and without transliteration for training bi-texts with
different numbers of parallel es-en sentence pairs (10K, 20K, . . ., 320K). The table shows
the importance of transliteration, which is responsible for about half of the improvement
over the baseline brought by our method. In fact, for small original es-en bi-texts (10K,
20K, 40K), using 160K of transliterated additional pt-en sentence pairs works better than
using 1.23M additional non-transliterated pt-en sentence pairs (which is eight times bigger).
For example, given 10K of original training es-en sentence pairs, going from 160K to 1.23M
additional pt-en sentence pairs improves BLEU by 0.25% only (from 23.98% to 24.23%),
while using 160K of transliterated pt-en data yields an improvement of 1.75% (from 23.98%
to 25.73%). The impact of transliteration should not be surprising: we have already seen
it in Table 2, where, comparing lines 4 and 5, we can see that transliterating Portuguese
to look like Spanish effectively doubles the BLEU score: from 4.91% to 8.18% for 10K, and
from 7.10% to 13.79% for 1.23M parallel training sentence pairs.
201

fiNakov & Ng

es-en pt-en Translit.
10K 160K
no
yes
20K 160K
no
yes
40K 160K
no
yes
80K 160K
no
yes
160K 160K
no
yes

Baseline
22.87<
22.87<
24.71<
24.71<
25.80<
25.80<
27.08
27.08<
27.90
27.90

cat1
23.54<
<
25.26
<
25.19<
<
26.16
26.24<
<
26.78
27.23
27.26<
27.83<

28.14
<

catk
23.83<
(16)
<
25.42(16)
<
25.29<
(8)
<
26.18
(8)
25.92<
(4)
<
26.93(4)
27.09<
(2)

27.53(2)
27.83<
(1)

28.14(1)
<

catk:align
22.93<
(16)
<
23.31<
(16)
24.91<
(8)
24.88<
(8)
25.99<
(4)
25.88<
(4)
27.01<
(2)
27.09<
(2)
27.94(1)
28.06(1)

Our method
23.98(16;3) (+1.11)
<
25.73(16;3) (+2.86)
<
25.65(8;2) (+0.94)
<
26.36(8;3) (+1.65)
<
26.49(4;2) (+0.69)
<
26.95(4;3) (+1.15)

27.30(2;2) (+0.22)
<
27.49(2;3) (+0.41)
28.05(1;3) (+0.15)
28.16(1;2) (+0.26)

<

Table 5: Improving SpanishEnglish SMT using 160K additional PortugueseEnglish sentence pairs (varying the amount of original data): concatenations, repetitions, truncations, and our method. The first column contains
the number of original (es-en) sentence pairs. Column 3 shows whether transliteration was used; the following columns list the BLEU scores (in %) for different
methods. A subscript shows the best parameter value(s) found on the development set and used on the test set to produce the given result: the first value is
the number of repetitions of the original bi-text while the second value, if any, is
the number of extra features added to the phrase table. The BLEU scores that
are statistically significantly better than the baseline/our method are marked on
the left/right side by < (for p < 0.01) or  (for p < 0.05).

Note that the impact of transliteration diminishes as the size of the es-en bi-text grows.
This should not be surprising: as the size of the good original es-en bi-text grows, there is
less and less to be learned from the additional pt-en bi-text, regardless of whether with or
without transliteration.
7.5 Improving SpanishEnglish SMT Using Italian
Here, we experiment with Italian as an auxiliary language for improving SpanishEnglish
phrase-based SMT. Figure 2 shows the results when using Italian and Portuguese as auxiliary languages in our method with transliteration. We can see a major consistent drop in
BLEU score when using Italian instead of Portuguese. For example, for 10K es-en sentence
pairs and 160K additional pt-en/it-en sentence pairs, there is an absolute drop in BLEU
by about 0.9%: we have 25.73% vs. 24.82%, respectively. Moreover, for 160K original es-en
sentence pairs, our method goes slightly below the baseline (by -0.05) when using it-en
while there is a small improvement (by +0.26) for pt-en.
Still, Figure 2 shows that Italian, which is more dissimilar to Spanish than Portuguese, is
useful as an auxiliary language for smaller sizes of the original es-en training bi-text. Thus,
we can conclude that while the degree of similarity between the auxiliary and the source
language does matter, more dissimilar languages are still potentially useful as auxiliary
languages.
202

fiImproving SMT for a Resource-Poor Language

es-en pt-en Translit.
10K 160K
no
yes
20K 160K
40K 160K
80K 160K
160K 160K

no
yes
no
yes
no
yes
no
yes

Baseline
22.87<
22.87<
24.71<
24.71<
25.80<
25.80<
27.08
27.08<
27.90
27.90

Two tables
<
23.81
<
25.29
<

25.22
<
26.07
25.96<
<
26.68

26.89<
27.20<
27.99
28.11

Interpol.
<
23.73(.5)
<
25.22<
(.5)


25.02<
(.5)
<
26.07(.7)
26.15<
(.6)
<
26.43(.7)
27.04<
(.8)
27.42(.5)
27.72(.5)

28.13(.6)

Merge
23.60(2)
<
25.16<
(2)

Our method
23.98(16;3) (+1.11)
<
25.73(16;3) (+2.86)

<

<

25.32
(3)
<
26.04<
(3)
25.99<
(3)
<
26.64(3)
27.02<
(3)
27.29
(3)
27.95(2)

28.17(2)

<

<

25.65(8;2) (+0.94)
26.36(8;3) (+1.65)
<
26.49(4;2) (+0.69)
<
26.95(4;3) (+1.15)

27.30(2;2) (+0.22)
<
27.49(2;3) (+0.41)
28.05(1;3) (+0.15)
28.16(1;2) (+0.26)
<

Table 6: Improving SpanishEnglish SMT using 160K additional PortugueseEnglish sentence pairs (varying the amount of original data): comparing
our method to various alternatives. The first column contains the number
of original (es-en) sentence pairs. Column 3 shows whether transliteration was
used; the following columns list the BLEU scores (in %) for different methods.
A subscript shows the best parameter value(s) found on the development set and
used on the test set to produce the given result: for merging methods, the first
value is the number of repetitions of the original bi-text while the second value, if
any, is the number of extra features added to the phrase table; for interpolation,
we show the weight of the phrase pairs from in-en. The BLEU scores that are
statistically significantly better than the baseline/our method are marked on the
left/right side by < (for p < 0.01) or  (for p < 0.05).

7.6 Improving SpanishEnglish SMT Using Both Portuguese and Italian
After having seen that both Portuguese and Italian are useful as auxiliary languages, we
tried to use them both together. The experiments were carried out in the same way as when
we used a single auxiliary language, except that now we had to double the usual number
of repetitions k of the original bi-text so that the auxiliary bi-texts do not dominate it
for catk:align. For example, for 10K original es-en training sentence pairs and 160K
auxiliary pt-en and 160K it-en sentence pairs, we need to include 32 copies of the original
bi-text instead of 16, as we were doing before.
The results for the combination are shown in Figure 2. Comparing them to the results
when using pt-en data only, we can see that there is a small but consistent improvement. For
example, for 10K original es-en sentence pairs, 160K additional pt-en and 160K additional
it-en sentence pairs, there is an absolute increase in BLEU scores by 0.18%: from 25.73%
to 25.91%. The size of the absolute improvement when using 20K, 40K, 80K, and 160K
additional pt-en and it-en sentence pairs is comparable: about 0.10-0.20% on average.
Thus, there are potential gains when using multiple auxiliary languages simultaneously.
203

fiNakov & Ng

System
baseline
our method: 160K pt-en pairs
 improvement
our method: 1.23M pt-en pairs
 improvement
our method: 160K pt-en, translit.
 improvement
our method: 1.23M pt-en, translit.
 improvement

10K
22.87
23.98
+1.11
24.23
+1.36
25.73
+2.86
26.24
+3.37

20K
24.71
25.65
+0.94
25.70
+0.99
26.36
+1.65
26.82
+2.11

40K
25.80
26.49
+0.69
26.78
+0.98
26.95
+1.15
27.47
+1.67

80K
27.08
27.30
+0.22
27.49
+0.41
27.49
+0.41
27.85
+0.77

160K
27.90
28.05
+0.15
28.22
+0.32
28.16
+0.26
28.50
+0.60

320K
28.46
28.52
+0.06
28.58
+0.12
28.43
-0.03
28.70
+0.24

Table 7: SpanishEnglish: testing our method using 160K vs. 1.23M additional
pt-en sentence pairs, with and without transliteration. Shown are BLEU
scores (in %) and absolute improvement over the baseline for training bi-texts
with different numbers of parallel es-en sentence pairs (10K, 20K, . . ., 320K) and
a fixed number of additional pt-en sentence pairs: 160K and 1.23M. All statistically
significant improvements over the baseline are marked with a  (for p < 0.01) and
with a  (for p < 0.05).

7.7 Combining Our Method with the Cognate Extraction Technique of
Kondrak et al. (2003)
Next, we combined our method with the cognate extraction technique of Kondrak et al.
(2003), where pairs of likely cognates are extracted from the original training bi-text and
then added to that bi-text as additional 1-word-to-1-word sentence pairs.
System
baseline
cognates
 improvement (baseline)
our (1.23M pt-en pt-en) + cognates
 improvement (baseline)
 improvement (our: 1.23M pt-en)
our (1.23M pt-en, transl.) + cognates
 improvement (baseline)
 improvement (our: 1.23M, transl.)

10K
22.87
23.50
+0.63
24.55
+1.68
+0.32
26.35
+3.48
+0.11

20K
24.71
25.22
+0.51
25.98
+1.27
+0.28
26.78
+2.07
-0.04

40K
25.80
26.31
+0.51
26.73
+0.93
-0.05
27.34
+1.54
-0.13

80K
27.08
27.38
+0.30
27.67
+0.59
+0.18
27.79
+0.71
-0.06

160K
27.90
28.10
+0.20
28.33
+0.43
+0.11
28.50
+0.60
+0.00

320K
28.46
28.74
+0.28
28.90
+0.44
+0.32
28.68
+0.22
-0.02

Table 8: SpanishEnglish: combining our method with the cognate extraction
technique of Kondrak et al. (2003). Shown are BLEU scores (in %) and
absolute improvements (over the baseline and over our method) for training bitexts with different numbers of parallel es-en sentence pairs (10K, 20K, . . ., 320K)
and fixed number of additional pt-en sentence pairs (1.23M), with and without
transliteration. The statistically significant improvements are marked with a  (for
p < 0.01) and with a  (for p < 0.05).

204

fiImproving SMT for a Resource-Poor Language

28.5

27.5

26.5

25.5

baseline
+it-en
+pt-en
+it-en +pt-en

24.5

23.5

22.5
10K

20K

40K

80K

160K

Figure 2: Improving SpanishEnglish SMT using 160K Italian-English and
160K Portuguese-English additional sentence pairs (varying the
amount of original data) and transliteration.

The results for adding these cognates to the training es-en bi-text, i.e., for our reimplementation of their algorithm, are shown in the top lines of Table 8. We can see an
absolute improvement of 0.5% BLEU for es-en of size up to 40K, and the improvement is
statistically significant.
Next, we combined our method with the cognate extraction method as follows: first, we
augmented the original es-en bi-text with cognate pairs, and then we used this augmented
bi-text instead of es-en in our method. Table 8 shows the results for the combination of
our method with cognate extraction (BLEU scores in % and absolute improvements over
the baseline and over our method) for training bi-texts with different numbers of parallel
es-en sentence pairs (10K, 20K, . . ., 320K) and fixed number of additional pt-en sentence
pairs (1.23M), with and without transliteration. As we can see, it is worth combining our
method with the cognate extraction technique of Kondrak et al. (2003) for small original
es-en datasets, e.g., 10K or 20K (in which cases statistically significant improvements occur
over using our method only), but only when our method does not use transliteration.
205

fiNakov & Ng

We found it interesting that combining our method with the cognate extraction technique of Kondrak et al. (2003) does not help so much when we used transliteration compared
to when we do not use it. Thus, we further analyzed the case of 10K es-en sentence pairs
and 1.23M pt-en pairs. The cognate extraction technique yielded 25,362 Spanish-English
likely cognate pairs, including 10,611 unique Spanish words. The Portuguese side of the
1.23M pt-en data contained only 14 or 0.13% of these 10,611 unique Spanish words. Thus,
the information that these Spanish-English likely cognates provide for word alignments
and phrase pairs is clearly complementary to what the pt-en bi-text gives. However, after
transliteration, the source side of the 1.23M ptes -en bi-text contained 8,867 or 83.56% of
the 10,611 unique Spanish words in the Spanish-English likely cognate pairs. This drastic
jump means that the Spanish-English likely cognate pairs have little to add on top of what
ptes -en already provides, and explains the lack of improvement when combined with our
method when transliteration is used.
7.8 Combining Our Method with the Phrase Table Pivoting Technique of
Callison-Burch et al. (2006)
Finally, we combined our method with the phrase table pivoting technique of Callison-Burch
et al. (2006) since they are orthogonal.
First, we tried to reproduce the phrase table pivoting experiments of Callison-Burch
et al. (2006), which turned out to be complicated (even though we used their original
code to do the pivoting) because of various differences in our experimental setups: (1) we
used Moses instead of Pharaoh for translation; (2) we used IRSTLM instead of SRILM
for language modeling; (3) we used different tokenization; (4) we used a maximum phrase
length of up to seven instead of ten; (5) we created our training/dev/test dataset out of
Europarl v.3, which is different from the version of the Europarl corpus that was available
in 2006 (which also implies a different baseline, etc.).
The results are shown in Table 9. The bottom three lines show the results reported
by Callison-Burch et al. (2006), while the top three lines report the BLEU scores for our
reproduction of their experiments, in which about 1.3M pairs were used for each of eight
additional pivot languages: Danish, Dutch, Finnish, French, German, Italian, Portuguese,
and Swedish. While our BLEU scores are lower, they are good enough for studying the
potential of combining the two methods.
The combination was carried in the following way: after we had built the final merged
phrase table for our method, we paraphrased its source side through pivoting using the
method of Callison-Burch et al. (2006). The middle lines of the table show the BLEU
scores (in %) of the combined method and absolute improvements (over the baseline and
over our method) for training bi-texts with different numbers of parallel es-en sentence pairs
(10K, 20K, . . ., 320K) and fixed amount of additional pt-en pairs (160K and 1.23M pairs),
with and without transliteration.
The results show that it is worth combining our method with phrase table pivoting for
small es-en datasets, e.g., 10K or 20K (in which cases, statistically significant improvements
occur over using our method only), but only when our method does not use transliteration,
as was the case for the cognate extraction technique of Kondrak et al. (2003).
206

fiImproving SMT for a Resource-Poor Language

Our Experiments
baseline
Pivoting (+8 pairs  1.3M)
 improvement (baseline)
our (160K pt-en) + pivoting
 improvement (over the baseline)
 improvement (over our method)
our (1.23M pt-en) + pivoting
 improvement (over the baseline)
 improvement (over our method)
our (160K pt-en, transl.) + pivoting
 improvement (over the baseline)
 improvement (over our method)
our (1.23M pt-en, transl.) + pivoting
 improvement (over the baseline)
 improvement (over our method)
Callison-Burch et al. (2006)
baseline
Pivoting (+8 pairs  1.3M)
 improvement (over the baseline)

10K
22.87
23.33
+0.46
24.32
+1.45
+0.34
24.64
+1.77
+0.41
25.82
+2.95
+0.09
26.39
+3.52
+0.15

20K
24.71
24.88
+0.17
25.95
+1.24
+0.30
26.18
+1.47
+0.48
26.49
+1.78
+0.13
27.01
+2.30
+0.19

40K
25.80
26.10
+0.30
26.70
+0.90
+0.21
26.87
+1.07
+0.09
27.06
+1.26
+0.11
27.53
+1.73
+0.06

80K
27.08
27.06
-0.02
27.36
+0.28
+0.06
27.60
+0.52
+0.11
27.51
+0.43
+0.02
27.77
+0.69
-0.08

160K
27.90
28.09
+0.19
28.02
+0.12
-0.03
28.35
+0.45
+0.13
28.35
+0.45
+0.19
28.58
+0.68
+0.08

320K
28.46
28.49
+0.03
28.56
+0.10
+0.04
28.69
+0.23
+0.11
28.58
+0.12
+0.15
28.66
+0.20
-0.04

22.6
23.3
+0.7

25.0
26.0
+1.0

26.5
27.2
+0.7

26.5
28.0
+1.5

28.7
29.0
+0.3

30.0
30.0
+0.0

Table 9: SpanishEnglish: combining our method with the phrase table pivoting
technique of Callison-Burch et al. (2006). Shown are BLEU scores (in %)
and absolute improvements (over the baseline and over our method) for training
bi-texts with different numbers of parallel es-en sentence pairs (10K, 20K, . . .,
320K) and fixed amount of additional pt-en pairs: (1) about 1.3M pairs for each
of eight additional languages in pivoting, and (2) 160K and 1.23M pairs for one
language (Portuguese) for our method (with and without transliteration). The
last three lines show the results of the phrase table pivoting experiments reported
in Callison-Burch et al. (2006) while the first three lines show our reproduction of
these experiments. The statistically significant improvements are marked with a
 (for p < 0.01) and with a  (for p < 0.05).

Again, we found it interesting that pivoting does not help so much with transliteration
as without it. Thus, we had a closer look at the interaction of pivoting and transliteration
for 10K es-en sentence pairs and 160K pt-en pairs. In particular, we looked at the number
of usable phrase pairs with respect to the test data, i.e., those phrase pairs whose source side
matches the test data, and we found that without pivoting, using transliteration increases
this number from 657,541 to 1,863,950, i.e., by 183.47%, while using pivoting and transliteration increases this number from 819,324 to 2,214,580, i.e., by 170.29%. This lower relative
increase in the number of usable phrases is one possible explanation of the corresponding
lower increase in BLEU: which is +0.34 and +0.09 absolute, respectively, without and with
transliteration.
207

fiNakov & Ng

8. Analysis and Discussion
Below, we perform deeper analysis of our method and of the obtained results.
8.1 Merging Phrase Tables
Here we compare merging catk:align and cat1 (with 1-3 extra features, as was described
above), to two simpler alternatives: (a) substituting cat1 with ml-en, and (b) merging
the phrase tables derived from the original bi-texts, in-en and ml-en.
We further implement and evaluate the following alternative to our method: (c) train
the alignment models on the combined bi-text that consists of k copies of in-en and one
copy of ml-en, then truncate the alignments appropriately, and build two separate phrase
tables. The first table is catk:align as in our method (built on one copy of in-en), and the
second one is a similar phrase table that corresponds to ml-en. Unlike (a) above, the word
alignments in that second phrase table are influenced by the k copies of in-en. We will refer
to this second phrase table as ml :catk:align. The motivation for trying this alternative
is that it is (1) a bit simpler to implement, and (2) somewhat symmetric for both phrase
tables. Yet, just like in our method, the alignment models benefit from more data, while
the phrase tables remain language-specific and thus can be combined using extra features.
Table 10 compares our method (line 3) to the above-described three alternatives, (a),
(b) and (c), for different numbers of training ml-en sentence pairs. As we can see, overall,
our method (line 3) performs best, while the newly described alternative (c), shown on line
4, is ranked second. Merging phrase tables derived from the original bi-texts in-en and
ml-en is worst (line 1), which can be explained by the fact that it cannot benefit from
improved word alignments for the small in-en bi-text (unlike the other combinations, and
most notably the one at line 2). However, it is not so easy to explain from this table alone
why our method is better than the other two alternatives.
Thus, we looked into the phrase tables and the unknown words, for the case of 160K
ml-en additional sentence pairs. The results are shown in Table 11, which offers a very good
insight: the two good performing combinations at lines 3-4 simply have larger phrase tables
compared to those on lines 1-2. More importantly, this translates into a higher number
of phrase pairs that are potentially usable for translating the test sentences, i.e., match
the input at test time. Naturally, more translation options mean a larger search space and
thus more opportunities to find better translations, which explains the better performance
of the combinations at lines 3-4. The table also compares the number of unknown word
types and word tokens when translating the test data. We can see that our method has the
lowest number of unknowns, which can explain its good performance. On the other hand,
the numbers of unknown words are comparable for the other three methods.
In summary, Table 11 shows two important factors influencing BLEU: (i ) total and used
number of phrase pairs, and (ii ) number of unknown word types and tokens at translation
time. Our method ranks best in both criteria, while the second best method at line 4 ranks
second on the first factor but last on the second one (but close to the other methods).
Thus, we could conclude that the impact of unknown words on BLEU is limited when the
differences are small. The phrase table size seems to correlate somewhat better with BLEU,
at least for the two best performing methods. Finally, comparing line 2 to lines 3-4, we can
further conclude that using the in-en bi-text to help align the ml-en bi-text is beneficial.
208

fiImproving SMT for a Resource-Poor Language

To get even better insight, we looked at the characteristics of the tables that are being
combined: (1) phrase table sizes and overlap, (2) number of distinct source phrases and
overlap, and (3) average differences in the four standard scores in the merged tables for
shared phrase pairs: inverse phrase translation probability (f |e), inverse lexical weighting
pw (f |e), direct phrase translation probability (e|f ), and direct lexical weighting pw (e|f ).
The results are shown in Table 12. The table shows that our method combines phrase
tables that have a much higher overlap (10-50 times higher!), both in terms of number of
phrase pairs and number of distinct source phrases. Moreover, the absolute differences in
the scores for the shared phrase pairs are about halved (i.e., they are very similar) for the
two phrase tables that are combined by our method, cat1 and catk:align, compared
to those for phrase tables combined by the three alternative approaches, as the last four
columns in Table 12 show. This high similarity in the scores for cat1 and catk:align
could be one possible explanation of their very similar performance as shown in Table 3.
Thus, our method wins by combining two tables that have already been made more
similar, and thus more appropriate for combination. A key element of this is to build the
second table from a concatenation of the ml-en and the in-en bi-texts, where the in-en bitext has a minor influence on word alignment (it is simply much smaller), but much more
influence on phrase extraction and scoring. This makes the resulting phrase table much
more similar to the first phrase table (which has also been made similar to the second table,
but via word alignments only), but also much bigger than if trained on ml-en data only
(14M vs. 11M phrase pairs); this in turn yields a larger merged phrase table despite the
higher overlap between the tables that are being merged.
1
2
3
4

Merged Phrase Tables
in-en
ml-en
catk:align ml-en
catk:align cat1
catk:align ml :catk:align

10K
23.97
24.11
24.51
24.14

20K
24.46
24.56
24.70
24.54

40K
24.43
24.54
24.73
24.65

80K
24.67
24.62
24.97
24.72

160K
24.79
25.02
25.15
25.08

Table 10: Merging phrase tables for Indonesian-English SMT: BLEU scores.
BLEU shown in % for different numbers of training ml-en sentence pairs.

8.2 Transliteration
Here we have a closer look at transliteration: studying how many words it affects and its
impact on the number of unknown words (also known as OOVs, out-of-vocabulary words).
First, we look at the number of word types and word tokens that changed in the process
of transliteration of the source side of the additional training bi-text. The results are shown
in Table 13. We can see that transliterating Malay to Indonesian affects a very small
number of words: 7.61% of the word types and 5.78% of the word tokens. This should not
be surprising since the spelling differences between Malay and Indonesian are very limited,
as we explained in Section 3.1. In contrast, transliterating Portuguese to Spanish changes
44.71% of the word types and 23.17% of the word tokens, which agrees with our observations
in Sections 3.2 and 6. Italian is even more affected by transliteration than Portuguese: with
70.45% of the word types and 34.37% of the word tokens changed.
209

fiNakov & Ng

1
2
3
4

Merged Phrase Tables
in-en
ml-en
catk:align ml-en
catk:align cat1
catk:align ml :catk:align

Phrase Pairs
Total
# Used % Used
14.23M
1.28M
9.02%
14.07M
1.25M
8.88%
15.83M
1.70M
10.71%
14.92M
1.37M
9.17%

Unknown
Types Tokens
1411
1917
1413
1906
1300
1743
1445
1933

BLEU
24.79
25.02
25.15
25.08

Table 11: Merging phrase tables derived from in-en and ml-en (160K): number
of phrase pairs and unknown words. Shown are the total number of phrase
pairs in the merged phrase table and the number of phrase pairs used to decode
the test data, followed by the number of unknown word types and tokens, and
the BLEU score (in %).

Merged Phrase Tables
1 in-en
ml-en
2 catk:align
3 catk:align
4 catk:align

ml-en
cat1
ml:catk:align

Phrase Pairs
PT1 PT2 both
3.2M 11.1M 72.1K

Source Phrases
PT1 PT2 both
1.1M 7.7M 10.3K

2.23%

0.91%

0.65%

1.2M 7.7M 11.1K

2.51%

0.95%

3.1M 14.0M 1.2M

1.2M 8.8M 0.6M
49.40%

0.21 0.05 0.13 0.05

6.54%

3.1M 11.9M 87.6K

1.2M 7.6M 11.6K

2.85%

0.99%

0.73%

0.40 0.18 0.19 0.10

0.14%

39.39%

8.67%

0.40 0.18 0.19 0.10

0.13%

3.1M 11.1M 77.1K
0.70%

Avg. Score Diff.
(f |e) pw (f |e) (e|f ) pw (e|f )

0.40 0.18 0.18 0.09

0.15%

Table 12: Comparison of the phrase tables merged in Tables 10 and 11. Shown
are the number of phrase pairs / source phrases in each phrase table and the
number/percent of them that appear in both tables. The last four columns
show the average absolute differences in the four standard phrase table scores for
phrase pairs that appear in both tables; these scores are inverse phrase translation
probability (f |e), inverse lexical weighting pw (f |e), direct phrase translation
probability (e|f ), and direct lexical weighting pw (e|f ).

One important reason for this higher number of changes would be that, unlike Spanish
and Portuguese, Italian does not form plural for nouns and adjectives by adding an -s
but by a vowel change. For example, the singular form of the adjective meaning green is
verde in all three languages: Spanish, Portuguese, and Italian. However, its plural form
differs: it is verdes regardless of gender in both Spanish and Portuguese, but it is verdi
(plural masculine) or verde (plural feminine) in Italian. Thus, transliterating Portuguese
to Spanish would leave verdes intact, but for Italian, changes would be needed. Given
the frequency of the use of plural for nouns and adjectives, we can expect many more
differences for ItalianSpanish than for PortugueseSpanish. Overall, the small number of
word types/tokens changed explains why transliteration was of limited use for Malay but
so important for Spanish and Italian.
210

fiImproving SMT for a Resource-Poor Language

1

Transliteration
MalayIndonesian

Word Types
Changed
Total
8,259
108,595

2

PortugueseSpanish

52,303

7.61%

5.78%

116,989

44.71%

3

ItalianSpanish

Word Tokens
Changed
Total
316,444
5,472,372
8,315,835

35,889,877

23.17%

88,767

126,005

70.45%

14,962,680

43,530,246

34.37%

Table 13: Transliteration: number of words in the training data that changed.
Shown are the number of word types and word tokens that changed, compared
to the total number of word types and tokens on the source side of the different
training bi-texts.

1
2
3
4
5

Bi-text(s)
ml-en
mlin -en
in-en
in-en+ml-en
in-en+mlin -en

Sentences
160K
160K
28.4K
28.4K+160K
28.4K+160K

Unknown
Types Tokens
3,115
7,101
2,912
7,288
1,547
2,101
1,170
1,532
1,182
1,544

BLEU
17.90
19.15
23.80
24.43
24.72

Table 14: Unknown words for the Indonesian test dataset. Shown are the number of
unknown word types and word tokens, and Bleu score in % for different training
bi-texts and simple bi-text concatenations (cat1). The counts are with respect
to the training bi-text; the actual number of unknown words at translation time
can differ. Indonesian bi-texts were for tuning and testing and enin monolingual
data was used for language modeling.

Next, we studied the impact of transliteration on the number of unknown words for
the test data. Table 14 shows the results for Indonesian, using Indonesian bi-texts for
tuning and testing and enin monolingual data for language modeling. Comparing lines 1
and 2, we can see that transliteration has a very limited impact on reducing the number
of unknown word types when training on Malay data: the number of unknown word types
drops only slightly from 3,115 to 2,912, while the number of unknown word tokens actually
grows, from 7,101 to 7,288. Yet, there is an improvement in BLEU, from 17.90 to 19.15.
This improvement is consistent for all n-gram scores included in BLEU: 1-gram (48.46 vs.
50.12), 2-gram (22.09 vs. 23.46), 3-gram (12.49 vs. 13.54), and 4-gram (7.67 vs. 8.44).
Thus, apparently, the number of unknown word types is more important than the number
of unknown word tokens. Moving down to line 3, we can see that the number of unknown
word types is only halved when training on Indonesian instead of Malay, which confirms
once again the similarity between Indonesian and Malay. Comparing lines 4 and 5, we can
see that when we concatenate the Malay and Indonesian training bi-texts, the impact of
transliteration is minimal: both in terms of word types/tokens and BLEU.
211

fiNakov & Ng

1
2
3
4
5
6
7
8
9
10
11

Bi-text(s)
pt-en
ptes -en
it-en
ites -en
es-en
es-en+it-en
es-en+ites -en
es-en+pt-en
es-en+ptes -en
es-en+pt-en+it-en
es-en+ptes -en+ites -en

Sentences
160K
160K
160K
160K
160K
160K+160K
160K+160K
160K+160K
160K+160K
160K+160K+160K
160K+160K+160K

Unknown
Types Tokens
3,973
17,580
1,574
10,337
5,529
23,088
2,413
13,492
362
440
347
406
316
374
273
295
240
257
264
280
221
232

Bleu
6.35
11.35
4.06
9.38
27.90
27.65
27.69
27.83
28.14
27.89
28.02

Table 15: Unknown words for the Spanish test dataset. Shown are the number of
unknown word types and word tokens, and Bleu score in % for different training
bi-texts and simple bi-text concatenations (cat1). The counts are with respect
to the training bi-text; the actual number of unknown words at translation time
can differ. Spanish bi-texts were used for tuning and testing.

The relative differences in the number of unknown words are much more sizeable when
transliterating Portuguese/Italian to Spanish, as Table 15 shows. Comparing lines 1-2 and
3-4, we can see the number of unknown word types/tokens is about halved, while BLEU
doubles. This confirms once again the importance of transliteration for these languages.
Going down to line 5, we can see a 10-15 times drop in the number of unknown word types
when training on the Spanish bi-text. This drop looks drastic compared to that for Malay in
Table 14, but it can be partly explained by the larger size of the training es-en bi-text, which
contains 160K sentence pairs compared to only 28.4K pairs for in-en. Since the es-en bi-text
has reduced the number of unknown word types to 362, it becomes very hard to reduce this
number further. Still, as lines 6-11 show, concatenating es-en with pt-en and it-en yields
sizable improvements over using es-en only. Moreover, transliteration helps consistently in
reducing the number of unknown words further and these reductions are bigger than those
for Malay not only in relative, but also in absolute terms. Still, these reductions in the
number of unknown words are not so great in absolute terms, and thus the corresponding
differences in BLEU are small. Yet, transliteration yields consistent improvement for all
concatenations: Spanish+Italian, Spanish+Portuguese, and Spanish+Portuguese+Italian.
Overall, we can conclude that large relative drops in the number of unknown words
correspond to sizable improvements in BLEU; however, the results for small relative differences are less conclusive: they correspond to small fluctuation in BLEU for Portuguese and
Italian but to somewhat larger differences for Malay. This could be a feature of the much
lower token/type ratio for Malay, which is an agglutinative language, and thus quite rich in
wordforms: as Table 13 shows, the token/type ratio is only about 50 for Malay, while it is
about 307 and 345 for Portuguese and Italian, respectively.
212

fiImproving SMT for a Resource-Poor Language

8.3 Relative Improvement
Finally, we address the important question of how much real data our method saves.
Figure 3 compares graphically the improvements over the baseline using our method
with 160K vs. 1.23M pt-en sentence pairs and transliteration for different number of original
training es-en sentence pairs. We can see from this figure that, with 10K real training
es-en sentence pairs, using 160K additional pt-en and our method yields a BLEU score
that is comparable to what is achieved with 40K real es-en sentence pairs, i.e., we cut
the necessary real data by a factor of four. We can further see that using 1.23M pt-en
sentence pairs improves this factor to five. Similarly, for 20K real es-en training sentence
pairs, our method achieves a BLEU score that would require 33.5 times as much real
training es-en data for the baseline system to match.
Figure 4 summarizes these statistics, showing how many times more real data would
be needed for the baseline to match the performance of our method. We can see that we cut
this by a factor of 1.54 and 25, when using 160K and 1.23M additional pt-en sentences.

29

28

27

26

25

baseline
24

our method: 160K
our method: 1.23M

23

22
10K

20K

40K

80K

160K

320K

Figure 3: SpanishEnglish: improvements over the baseline using our method
with 160K vs. 1.23M pt-en sentence pairs and transliteration for different
number of original training es-en sentence pairs.

213

fiNakov & Ng

6

our method: 160K
5

our method: 1.23M
4

3

2

1

0
10K

20K

40K

80K

160K

Figure 4: Trade-off between SpanishEnglish and PortugueseEnglish data.
Shown is the number of times we need to grow the original es-en training data in
order to achieve the same BLEU score as when using our method and 160K/1.23M
additional pt-en sentence pairs with transliteration.

9. Conclusion
We have proposed a novel language-independent method for improving statistical machine
translation for resource-poor languages by exploiting their similarity to related resource-rich
ones. We have achieved significant gains in BLEU, which improve over the best rivaling
approaches, while using much less additional data.
We further studied the impact of using a less closely related language as an auxiliary
language (Italian instead of Portuguese for improving SpanishEnglish SMT), we tried
using both Portuguese and Italian together as auxiliary languages, and we combined our
method with two orthogonal rivaling approaches: (1) using cognates between the source
and the target language, and (2) source-language side paraphrasing with a pivot language.
All these experiments yielded statistically significant improvements for small datasets.

214

fiImproving SMT for a Resource-Poor Language

Based on the experimental results, we can make several interesting conclusions:
1. We have shown that using related languages can help improve SMT: we achieved up
to 1.35 and 3.37 improvement in BLEU for in-en (+ml-en) and es-en (+pt-en).
2. While simple concatenation can help, it is problematic when the additional sentences
out-number the ones from the original bi-text.
3. Concatenation can work very well if the original bi-text is repeated enough times so
that the additional bi-text does not dominate.
4. Merging phrase tables giving priority to the original bi-text and using additional
features is a good strategy.
5. Part of the improvement when combining bi-texts is due to increased vocabulary
coverage but another part comes from improved word alignments. The best results
are achieved when these two sources are first isolated and then combined (our method).
6. Transliteration can help a lot in case of systematic spelling variations between the
original and the additional source languages.
7. Overall, we reduce the amount of necessary real training data by a factor of 25.
In future work, we would like to extend our approach in several interesting directions.
First, we want to make better use of multi-lingual parallel corpora, e.g., while we had access
to a Spanish-Portuguese-English corpus, we used it as two separate bi-texts Spanish-English
and Portuguese-English. Second, we would like to try using auxiliary languages that are
related to the target language. Finally, we would like to experiment with more sophisticated
ways to get the auxiliary language closer to the source that go beyond simple transliteration.

Acknowledgments
We would like to thank the anonymous reviewers for their constructive comments and
suggestions, which have helped us improve the quality of the manuscript. This research
was supported by research grant POD0713875, and by the Singapore National Research
Foundation under its International Research Centre @ Singapore Funding Initiative and
administered by the IDM Programme Office.

References
Al-Onaizan, Y., Curin, J., Jahr, M., Knight, K., Lafferty, J., Melamed, D., Och, F. J.,
Purdy, D., Smith, N., & Yarowsky, D. (1999). Statistical machine translation. Tech.
rep., CLSP, Johns Hopkins University, Baltimore, MD.
Altintas, K., & Cicekli, I. (2002). A machine translation system between a pair of closely
related languages. In Proceedings of the 17th International Symposium on Computer
and Information Sciences, ISCIS 02, pp. 192196, Orlando, FL.
Bakr, H. A., Shaalan, K., & Ziedan, I. (2008). A hybrid approach for converting written
Egyptian colloquial dialect into diacritized Arabic. In Proceedings of the 6th International Conference on Informatics and Systems, INFOS 08, Cairo, Egypt.
215

fiNakov & Ng

Bannard, C., & Callison-Burch, C. (2005). Paraphrasing with bilingual parallel corpora. In
Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,
ACL 05, pp. 597604, Ann Arbor, MI.
Bergsma, S., & Kondrak, G. (2007). Alignment-based discriminative string similarity. In
Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, ACL 07, pp. 656663, Prague, Czech Republic.
Bertoldi, N., Barbaiani, M., Federico, M., & Cattoni, R. (2008). Phrase-based statistical machine translation with pivot languages. In Proceedings of the International Workshop
on Spoken Language Translation, IWSLT 08, pp. 143149, Honolulu, HI.
Bickford, A., & Tuggy, D. (2002).
Electronic glossary of linguistic terms.
http://www.sil.org/mexico/ling/glosario/E005ai-Glossary.htm.
Birch, A., Osborne, M., & Koehn, P. (2007). CCG supertags in factored statistical machine
translation. In Proceedings of the Second Workshop on Statistical Machine Translation, WMT 07, pp. 916, Prague, Czech Republic.
Brill, E., & Moore, R. C. (2000). An improved error model for noisy channel spelling correction. In Proceedings of the 38th Annual Meeting on Association for Computational
Linguistics, ACL 00, pp. 286293, Hong Kong.
Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., Goldsmith, M. J., Hajic, J., Mercer,
R. L., & Mohanty, S. (1993). But dictionaries are data too. In Proceedings of the
Workshop on Human Language Technology, HLT 93, pp. 202205, Princeton, NJ.
Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., & Mercer, R. L. (1993). The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19 (2), 263311.
Callison-Burch, C. (2008). Syntactic constraints on paraphrases extracted from parallel
corpora. In Proceedings of the 2008 Conference on Empirical Methods in Natural
Language Processing, pp. 196205.
Callison-Burch, C. (2012). How-to guide for extracting syntactically constrained paraphrases.. http://www.cs.jhu.edu/ccb/howto-extract-paraphrases.html. Retrieved
2012-05-14.
Callison-Burch, C., Koehn, P., & Osborne, M. (2006). Improved statistical machine translation using paraphrases. In Proceedings of the main conference on Human Language
Technology Conference of the North American Chapter of the Association for Computational Linguistics, HLT-NAACL 06, pp. 1724, New York, NY.
Chan, Y. S., & Ng, H. T. (2005). Word sense disambiguation with distribution estimation.
In Proceedings of the 19th International Joint Conference on Artificial Intelligence,
IJCAI 05, pp. 10101015, Edinburgh, UK.
Chan, Y. S., & Ng, H. T. (2006). Estimating class priors in domain adaptation for word
sense disambiguation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational
Linguistics, COLING-ACL 06, pp. 8996, Sydney, Australia.
216

fiImproving SMT for a Resource-Poor Language

Chan, Y. S., & Ng, H. T. (2007). Domain adaptation with active learning for word sense
disambiguation. In Proceedings of the 45th Annual Meeting of the Association for
Computational Linguistics, ACL 07, pp. 4956, Prague, Czech Republic.
Chiang, D. (2005). A hierarchical phrase-based model for statistical machine translation.
In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, ACL 05, pp. 263270, Ann Arbor, MI.
Chiang, D., Knight, K., & Wang, W. (2009). 11,001 new features for statistical machine
translation. In Proceedings of Human Language Technologies: The Annual Conference
of the North American Chapter of the Association for Computational Linguistics,
NAACL-HLT 09, pp. 218226, Boulder, CO.
Cohn, T., & Lapata, M. (2007). Machine translation by triangulation: Making effective use
of multi-parallel corpora. In Proceedings of the 45th Annual Meeting of the Association
for Computational Linguistics, ACL 07, pp. 728735, Prague, Czech Republic.
Collins, M., Koehn, P., & Kucerova, I. (2005). Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL 05, pp. 531540, Ann Arbor, MI.
Crego, J. M., Max, A., & Yvon, F. (2010). Local lexical adaptation in machine translation
through triangulation: SMT helping SMT. In Proceedings of the 23rd International
Conference on Computational Linguistics, COLING 10, pp. 232240, Beijing, China.
Dahlmeier, D., & Ng, H. T. (2010). Domain adaptation for semantic role labeling in the
biomedical domain. Bioinformatics, 26 (8), 10981104.
Daume, III, H., & Jagarlamudi, J. (2011). Domain adaptation for machine translation by
mining unseen words. In Proceedings of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Technologies, ACL-HLT 11, pp. 407
412, Portland, OR.
Daume, III, H., & Marcu, D. (2006). Domain adaptation for statistical classifiers. J. Artif.
Int. Res., 26, 101126.
de Gispert, A., & Mario, J. (2006). Catalan-English statistical machine translation without parallel corpus: Bridging through Spanish. In Proceedings of the 5th Workshop
on Strategies for developing Machine Translation for Minority Languages at LREC,
SALTMIL 06, pp. 6568, Genoa, Italy.
Denkowski,
M.
(2012).
README
file
of
Parex
paraphrase extractor.. https://github.com/mjdenkowski/parex/blob/master/README.
Retrieved 2012-05-14.
Denkowski, M., & Lavie, A. (2010). METEOR-NEXT and the METEOR paraphrase tables:
Improved evaluation support for five target languages. In Proceedings of the Joint 5th
Workshop on Statistical Machine Translation and MetricsMATR, pp. 339342.
Filali, K., & Bilmes, J. (2005). Leveraging multiple languages to improve statistical MT
word alignments. In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 05, Cancun, Mexico.
217

fiNakov & Ng

Finch, A., & Sumita, E. (2008). Phrase-based machine transliteration. In Proceedings of the
Workshop on Technologies and Corpora for Asia-Pacific Speech Translation, TCAST
08, pp. 1318, Hyderabad, India.
Galley, M., Hopkins, M., Knight, K., & Marcu, D. (2004). Whats in a translation rule?.
In Proceedings of the Human Language Technology Conference of the North American
Chapter of the Association for Computational Linguistics, HLT-NAACL 04, pp. 273
280, Boston, MA.
Garera, N., Callison-Burch, C., & Yarowsky, D. (2009). Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL 09, pp. 129137, Boulder, CO.
Graca, J., Ganchev, K., & Taskar, B. (2010). Learning tractable word alignment models
with complex constraints. Comput. Linguist., 36, 481504.
Habash, N., & Hu, J. (2009). Improving Arabic-Chinese statistical machine translation
using English as pivot language. In Proceedings of the Fourth Workshop on Statistical
Machine Translation, WMT 09, pp. 173181, Athens, Greece.
Haghighi, A., Liang, P., Berg-Kirkpatrick, T., & Klein, D. (2008). Learning bilingual lexicons from monolingual corpora. In Proceedings of the 46th Annual Meeting of the
Association for Computational Linguistics, ACL 08, pp. 771779, Columbus, OH.
Hajic, J., Hric, J., & Kubon, V. (2000). Machine translation of very close languages. In
Proceedings of the Sixth Conference on Applied Natural Language Processing, ANLP
00, pp. 712, Seattle, WA.
Han, B., & Baldwin, T. (2011). Lexical normalisation of short text messages: Makn sens
a #twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, ACL-HLT 11, pp. 368378,
Portland, Oregon.
Hana, J., Feldman, A., Brew, C., & Amaral, L. (2006). Tagging Portuguese with a Spanish tagger using cognates. In Proceedings of the International Workshop on CrossLanguage Knowledge Induction, CrossLangInduction 06, pp. 3340, Trento, Italy.
Hildebrand, A. S., Eck, M., Vogel, S., & Waibel, A. (2005). Adaptation of the translation
model for statistical machine translation based on information retrieval. In Proceedings
of the 10th Annual Conference of the European Association for Machine Translation,
EAMT 05, pp. 133142, Budapest, Hungary.
Hopkins, M., & May, J. (2011). Tuning as ranking. In Proceedings of the 2011 Conference
on Empirical Methods in Natural Language Processing, EMNLP 11, pp. 13521362,
Edinburgh, Scotland, UK.
Inkpen, D., Frunza, O., & Kondrak, G. (2005). Automatic identification of cognates and
false friends in French and English. In Proceedings of the International Conference on
Recent Advances in Natural Language Processing, RANLP 05, pp. 251257, Borovets,
Bulgaria.
218

fiImproving SMT for a Resource-Poor Language

Jiang, J., & Zhai, C. (2007a). Instance weighting for domain adaptation in NLP. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,
ACL 07, pp. 264271, Prague, Czech Republic.
Jiang, J., & Zhai, C. (2007b). A two-stage approach to domain adaptation for statistical
classifiers. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, CIKM 07, pp. 401410, Lisbon, Portugal. ACM.
Klementiev, A., & Roth, D. (2006). Named entity transliteration and discovery from multilingual comparable corpora. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association for
Computational Linguistics, HLT-NAACL 06, pp. 8288, New York, NY.
Koehn, P. (2005). Europarl: A parallel corpus for evaluation of machine translation. In
Proceedings of the Tenth Machine Translation Summit, MT Summit 05, pp. 7986,
Phuket, Thailand.
Koehn, P., Axelrod, A., Mayne, A. B., Callison-Burch, C., Osborne, M., & Talbot, D.
(2005). Edinburgh system description for the IWSLT speech translation evaluation. In
Proceedings of the International Workshop on Spoken Language Translation, IWSLT
05, Pittsburgh, PA.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B.,
Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., & Herbst, E.
(2007). Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.
Demonstration session, ACL 07, pp. 177180, Prague, Czech Republic.
Koehn, P., & Knight, K. (2002). Learning a translation lexicon from monolingual corpora. In
Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition, pp. 916,
Philadelphia, PA.
Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. In Proceedings of the Conference of the North American Chapter of the Association for
Computational Linguistics on Human Language Technology, NAACL 03, pp. 4854,
Edmonton, Canada.
Kondrak, G. (2005). Cognates and word alignment in bitexts. In Proceedings of the Tenth
Machine Translation Summit, MT Summit 05, pp. 305312, Phuket, Thailand.
Kondrak, G., Marcu, D., & Knight, K. (2003). Cognates can improve statistical translation
models. In Proceedings of the Conference of the North American Chapter of the
Association for Computational Linguistics on Human Language Technology, NAACL
03, pp. 4648, Edmonton, Canada.
Kumar, S., Och, F. J., & Macherey, W. (2007). Improving word alignment with bridge
languages. In Proceedings of the Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural Language Learning, EMNLP-CoNLL
07, pp. 4250, Prague, Czech Republic.
Li, H., & Kumaran, A. (Eds.). (2010). NEWS 10: Proceedings of the 2010 Named Entities
Workshop, Uppsala, Sweden.
219

fiNakov & Ng

Mann, G. S., & Yarowsky, D. (2001). Multipath translation lexicon induction via bridge
languages. In Proceedings of the second meeting of the North American Chapter of
the Association for Computational Linguistics on Language technologies, NAACL 01,
pp. 18, Pittsburgh, PA.
Marujo, L., Grazina, N., Lus, T., Ling, W., Coheur, L., & Trancoso, I. (2011). BP2EP
 Adaptation of Brazilian Portuguese texts to European Portuguese. In Proceedings
of the 15th Conference of the European Association for Machine Translation, EAMT
11, pp. 129136, Leuven, Belgium.
Matthews, D. (2007). Machine transliteration of proper names. Masters thesis, School of
Informatics, University of Edinburgh.
Melamed, D. (1995). Automatic evaluation and uniform filter cascades for inducing N-best
translation lexicons. In Proceedings of the Third Workshop on Very Large Corpora,
VLC 95, pp. 184198, Cambridge, MA.
Melamed, D. (1999). Bitext maps and alignment via pattern recognition. Computational
Linguistics, 25 (1), 107130.
Melamed, D. (2000). Models of translational equivalence among words. Computational
Linguistics, 26 (2), 221249.
Mulloni, A., & Pekar, V. (2006). Automatic detection of orthographic cues for cognate
recognition. In Proceedings of the 5th International Conference on Language Resources
and Evaluation, LREC 06, pp. 23872390, Genoa, Italy.
Nakov, P. (2008). Improved statistical machine translation using monolingual paraphrases.
In Proceedings of the 18th European Conference on Artificial Intelligence, ECAI 08,
pp. 338342, Patras, Greece.
Nakov, P., Nakov, S., & Paskaleva, E. (2007). Improved word alignments using the Web
as a corpus. In Proceedings of the International Conference on Recent Advances in
Natural Language Processing, RANLP 07, pp. 400405, Borovets, Bulgaria.
Nakov, P., & Ng, H. T. (2009a). Improved statistical machine translation for resource-poor
languages using related resource-rich languages. In Proceedings of the Conference
on Empirical Methods in Natural Language Processing, EMNLP 09, pp. 13581367,
Singapore.
Nakov, P., & Ng, H. T. (2009b). NUS at WMT09: Domain adaptation experiments for
English-Spanish machine translation of news commentary text. In Proceedings of the
Fourth Workshop on Statistical Machine Translation, WMT 09, pp. 7579, Athens,
Greece.
Och, F. J. (2003). Minimum error rate training in statistical machine translation. In
Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,
ACL 03, pp. 160167, Sapporo, Japan.
Och, F. J., & Ney, H. (2001). Statistical multi-source translation. In Proceedings of MT
Summit VIII. Machine Translation in the Information Age, MT Summit 01, pp. 253
258, Santiago de Compostela, Spain.
220

fiImproving SMT for a Resource-Poor Language

Oh, J.-H., Choi, K.-S., & Isahara, H. (2006). A comparison of different machine transliteration models. J. Artif. Int. Res., 27, 119151.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: a method for automatic
evaluation of machine translation. In Proceedings of the 40th Annual Meeting on
Association for Computational Linguistics, ACL 02, pp. 311318, Philadelphia, PA.
Paul, M., Yamamoto, H., Sumita, E., & Nakamura, S. (2009). On the importance of pivot
language selection for statistical machine translation. In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the
Association for Computational Linguistics, NAACL-HLT 09, pp. 221224, Boulder,
CO.
Quirk, C., Menezes, A., & Cherry, C. (2005). Dependency treelet translation: Syntactically
informed phrasal SMT. In Proceedings of the 43rd Annual Meeting of the Association
for Computational Linguistics, ACL 05, pp. 271279, Ann Arbor, MI.
Rappoport, A., & Levent-Levi, T. (2006). Induction of cross-language affix and letter
sequence correspondence. In Proceedings of the International Workshop on CrossLanguage Knowledge Induction, CrossLangInduction 06, pp. 1724, Trento, Italy.
Ristad, E., & Yianilos, P. (1998). Learning string-edit distance. IEEE Trans. Pattern Anal.
Mach. Intell., 20 (5), 522532.
Salloum, W., & Habash, N. (2011). Dialectal to standard Arabic paraphrasing to improve
Arabic-English statistical machine translation. In Proceedings of the First Workshop
on Algorithms and Resources for Modelling of Dialects and Language Varieties, pp.
1021, Edinburgh, Scotland, UK.
Sawaf, H. (2010). Arabic dialect handling in hybrid machine translation. In Proceedings
of the 9th Conference of the Association for Machine Translation in the Americas,
AMTA 10.
Scannell, K. (2006). Machine translation for closely related language pairs. In Proceedings
of the LREC2006 Workshop on Strategies for Developing Machine Translation for
Minority Languages, Genoa, Italy.
Schafer, C., & Yarowsky, D. (2002). Inducing translation lexicons via diverse similarity
measures and bridge languages. In Proceedings of the 6th Conference on Natural
Language Learning, COLING 02, pp. 17, Taipei, Taiwan.
Scherrer, Y. (2007). Adaptive string distance measures for bilingual dialect lexicon induction. In Proceedings of the 45th Annual Meeting of the ACL: Student Research
Workshop, ACL 07, pp. 5560, Prague, Czech Republic.
Schroeder, J., Cohn, T., & Koehn, P. (2009). Word lattices for multi-source translation.
In Proceedings of the 12th Conference of the European Chapter of the Association for
Computational Linguistics, EACL 09, pp. 719727, Athens, Greece.
Snover, M., Dorr, B., & Schwartz, R. (2008). Language and translation model adaptation
using comparable corpora. In Proceedings of the Conference on Empirical Methods in
Natural Language Processing, EMNLP 08, pp. 857866, Honolulu, HI.
221

fiNakov & Ng

Steinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., Tufis, D., & Varga, D.
(2006). The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages.
In Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC 06, pp. 21422147, Genoa, Italy.
Tanaka, R., Murakami, Y., & Ishida, T. (2009). Context-based approach for pivot translation services. In Proceedings of the 21st International Joint Conference on Artifical
intelligence, IJCAI 09, pp. 15551561, Pasadena, CA.
Tiedemann, J. (1999). Automatic construction of weighted string similarity measures. In
Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and
Very Large Corpora, EMNLP-VLC 99, pp. 213219, College Park, MD.
Tiedemann, J. (2009). Character-based PSMT for closely related languages. In Proceedings
of the 13th Annual Conference of the European Association for Machine Translation,
EAMT 09, pp. 1219, Barcelona, Spain.
Tiedemann, J., & Nabende, P. (2009). Translating transliterations. International Journal
of Computing and ICT Research, 3 (1), 3341.
Ueffing, N., Haffari, G., & Sarkar, A. (2007). Semi-supervised model adaptation for statistical machine translation. Machine Translation, 21, 7794.
Utiyama, M., & Isahara, H. (2007). A comparison of pivot methods for phrase-based statistical machine translation. In Human Language Technologies 2007: The Conference
of the North American Chapter of the Association for Computational Linguistics;
Proceedings of the Main Conference, NAACL-HLT 07, pp. 484491, Rochester, NY.
Vilar, D., Peter, J.-T., & Ney, H. (2007). Can we translate letters?. In Proceedings of
the Second Workshop on Statistical Machine Translation, pp. 3339, Prague, Czech
Republic.
Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment in statistical translation. In Proceedings of the 16th conference on Computational linguistics, COLING
96, pp. 836841, Copenhagen, Denmark.
Wu, H., & Wang, H. (2007). Pivot language approach for phrase-based statistical machine
translation. Machine Translation, 21 (3), 165181.
Zhang, X. (1998). Dialect MT: a case study between Cantonese and Mandarin. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and
17th International Conference on Computational Linguistics, COLING-ACL 98, pp.
14601464, Montreal, Quebec, Canada.

222

fiJournal of Artificial Intelligence Research 44 (2012) 97-140

Submitted 2/2012; published 5/2012

Solving Limited Memory Influence Diagrams
Denis Deratani Maua
Cassio Polpo de Campos
Marco Zaffalon

denis@idsia.ch
cassio@idsia.ch
zaffalon@idsia.ch

Istituto Dalle Molle di Studi sullIntelligenza Artificiale (IDSIA)
Galleria 2, Manno, 6928 Switzerland

Abstract
We present a new algorithm for exactly solving decision making problems represented as
influence diagrams. We do not require the usual assumptions of no forgetting and regularity;
this allows us to solve problems with simultaneous decisions and limited information. The
algorithm is empirically shown to outperform a state-of-the-art algorithm on randomly
generated problems of up to 150 variables and 1064 solutions. We show that these problems
are NP-hard even if the underlying graph structure of the problem has low treewidth and
the variables take on a bounded number of states, and that they admit no provably good
approximation if variables can take on an arbitrary number of states.

1. Introduction
Influence diagrams (Howard & Matheson, 1984) are graphical models aimed at the representation of problems of decision making under uncertainty. Traditionally, they are designed
to handle situations involving a single, non-forgetful decision maker. Limited memory influence diagrams (hereafter LIMIDs) are generalizations of influence diagrams that allow for
decision making with limited information, as in the case of simultaneous decisions, bounded
memory controllers and non-communicating cooperative agents (Zhang, Qi, & Poole, 1994;
Lauritzen & Nilsson, 2001; Poupart & Boutilier, 2003; Detwarasiti & Shachter, 2005). More
precisely, LIMIDs relax the regularity and no forgetting assumptions of influence diagrams,
namely, that there is a complete temporal ordering over the decision variables, and that any
disclosed information (i.e., decisions and observations made) is remembered and considered
for future decisions. These assumptions might not only be hard to meet in some applications, but they might lead to an exponential growth in the size of policies, and consequently
to intractability.
Solving a (limited memory) influence diagram refers to finding an optimal plan of action,
that is, a combination of decision rules, or policies, that associate any possible observation
to an action. Optimality is understood as maximizing expected utility. This task has been
empirically and theoretically shown to be very hard (de Campos & Ji, 2008). In fact, we
show here that solving a LIMID is NP-hard even if we admit only singly connected diagrams
with bounded number of states per variable,1 and that devising an algorithm that produces
provably good approximate solutions within any fixed factor is unlike to exist even for
diagrams of low treewidth.
1. A diagram is singly connected if the underlying (undirected) graph contains no cycles.
2012 AI Access Foundation. All rights reserved.

fiMaua, de Campos, & Zaffalon

Lauritzen and Nilsson (2001) have shown that LIMIDS that satisfy certain graphstructural conditions (which no forgetting and regularity imply) can be solved exactly by
a dynamic programming procedure with complexity exponential in the treewidth. Hence,
solving such LIMIDs is computationally similar to performing probabilistic inference in
Bayesian networks (Koller & Friedman, 2009). In fact, the single policy updating (SPU)
algorithm of Lauritzen and Nilsson (2001) performs a local search in the space of policies
and at each step performs a probabilistic inference to evaluate each candidate solution.
However, many problems fail to meet the conditions necessary for SPU achieving optimality, and in these cases SPU might converge to a local optimum that is much inferior to the
actual (global) optimum. To circumvent this problem, de Campos and Ji (2008) formulated
the credal reformulation (CR) algorithm that maps a LIMID into a mixed integer linear
programming problem. They showed that the CR algorithm is able to solve small problems exactly and to obtain good approximations for medium-sized problems by relaxing the
integrality constraints.
We show in this paper that LIMIDs can be solved exactly by a variable elimination
scheme that simultaneously propagates sets of (partial) solutions. Although the algorithm
runs in exponential time in the worst case (which is just to be expected, as the problem
is NP-hard), we show that for many problem instances it is possible to obtain an optimal
solution efficiently by pruning solutions that are Pareto-dominated by others. At the heart
of the algorithms efficiency is the property that at any moment during variable elimination
local Pareto dominance implies global Pareto dominance, that is, that a partial solution
that is Pareto-dominated by another partial solution cannot be part of an optimal solution,
and hence can be safely discarded. We show experimentally that the pruning of Paretodominated local solutions can enormously save computational resources, and enable us to
compute exact solutions for much bigger problems than previous algorithms. In fact, the
algorithm is orders of magnitude faster than the CR algorithm on randomly generated
diagrams containing up to 150 variables and 1064 strategies.
The paper is organized as follows. Section 2 describes the LIMID formalism and presents
new results about the complexity of solving a LIMID. The variable elimination algorithm
for computing exact solutions is presented in Section 3, and evaluated in Section 4. At last,
Sections 5 and 6 contain related work and a final discussion. To improve readability, some
of the proofs and supporting results are given in the appendix.

2. Limited Memory Influence Diagrams
In this section, we describe the LIMID formalism, state the complexity of solving a LIMID
instance, and show that any LIMID can be transformed into an equivalent (in terms of
maximum expected utility) diagram whose utilities are nonnegative and decision variables
have no parents. Such LIMIDs are the input of our algorithm in the next section. We start
with an example of a decision problem with limited information, which we use throughout
the rest of the paper to illustrate and motivate concepts. Although this example (which
is essentially a team coordination problem) is rather simple, it can easily be extended to
account for more realistic scenarios.
98

fiSolving LIMIDs

2.1 The Fire Dispatching Problem
A particular fire station contains a group of firefighters divided in three units. The fire
dispatcher decides which units to dispatch for each reported accident. Each dispatched
unit costs -1 utile, and units not dispatched cost no utiles. In case of fire, the higher
the number of dispatched teams the higher the chances of minimum damage (which implies
saving lives and preventing third-party financial losses). To make things simple, we consider
that an accident can be handled either appropriately, in which case we say it is a success,
or inappropriately, in which case we say it is a failure. Ideally, the dispatcher wants to
maximize the chance of success while minimizing the number of dispatched teams (and
hence the cost of the operation). A successful operation is rewarded with 7/2 utiles, while
a failure gets zero utiles.
2.2 Variables and Domains
In the formalism of (limited memory) influence diagrams, the quantities and events of
interest are represented by three distinct types of variables or nodes.2 Chance variables
represent events on which the decision maker has no control, such as outcomes of tests or
consequences of actions. Decision variables represent the options available to a decision
maker. Finally, value variables represent additive parcels of the utility associated to a state
of the world. The set of all variables considered relevant for a problem is denoted by U.
Each variable X in U has an associated domain X , which is the finite non-empty set of
values that X can assume. The elements of X are called states. We assume the existence
of the empty domain  , {}, which contains a single element  which is not in any
other domain. Decision and chance variables are assumed to have domains different from
the empty domain, whereas value variables are always associated to the empty domain.
In the fire dispatching problem, we can represent the act of dispatching or not the
unit i by a decision variable Ti ; hence we have three decision variables T1 , T2 , and T3
with domains T1 = T2 = T3 = {a, w}, where a stands for act and means the unit is
dispatched, while w stands for wait and means the unit is not dispatched. The outcome
of the incident after the assignment of units is represented by a binary chance variable O
with domain O = {s, f } (representing success and failure, respectively), and evaluated
by a value variable V (which is associated to  ). There are also individual costs per unit
dispatched, which are modeled by three value variables V1 , V2 and V3 . The set of relevant
variables for the problem is then U = {T1 , V1 , T2 , V2 , T3 , V3 , O, V }.
The domain x of a set of variables x = {X1 , . . . , Xn }  U is given by the Cartesian
product X1      Xn of the variable domains. Thus, an element u  U defines a
state of the world, that is, a realization of all actions and events of interest. If x and y are
sets of variables such that y  x  U, and x is an element of the domain x , we write
xy to denote the projection of x onto the smaller domain y , that is, xy  y contains
only the components of x that are compatible with the variables in y. By convention,
x , . The cylindrical extension of y  y to x is the set y x , {x  x : xy = y}.
Often, we write X1    Xn to denote the set {X1 , . . . , Xn } and, if clear from the context,
X to denote the singleton {X}. For instance, if x = {T1 , O} and y = {T1 }, then x =
2. We make no distinction between a node in the graphical representation of a decision problem and its
corresponding variable.

99

fiMaua, de Campos, & Zaffalon

{(a, s), (w, s), (a, f ), (w, f )}. Also, if x = (w, s)  x then xy = w and xO = s. The
cylindrical extension of s  O to x is given by sx = {(a, s), (w, s)}.
2.3 Operations Over Real-Valued Functions
Some operations over real-valued functions need to be defined. Let f and g be functions
over domains x and y , respectively. The product f g is defined as the function over the
domain xy such that (f g)(w) = f (wx )g(wy ) for any w of its domain. Sum of functions
is defined analogously: (f + g)(w) = f (wx ) + g(wy ). Notice that product and sum of
functions are associative and commutative, and that product distributes over sum, that is,
f g = gf , f + g = gP+ f , and f (g + h) = f g + f h. If f is a function over x , and y  U,
the sum-marginalP y f returns
w of its
P a function over x\y such that for any element
P
domain we have ( y f )(w) = xwx f (x). Notice that if y  x = , then y f = f . Also,
the sum-marginal operation
inherits
commutativity
P
P P
P Pand associativity from addition of real
numbers, and hence xy f = x\y y f = y\x x f .
If {fxy }yy is a set containing functions fxy of domain x , one for each element of y ,
y
we write fxy to denote the function that for all w  xy satisfies fxy (w) = fxw (wx ).
For instance, if X and Y are two binary-valued variables with domains X = {x1 , x2 }
y
y
y
and Y = {y 1 , y 2 }, and fX1 and fX2 are two functions over X such that fX1 (x1 ) = 1/2,
y2
y2
y1
Y is such that
fX (x2 ) = 1/2, fX (x1 ) = 0 and fX (x2 ) = 1, then the function fX
y

y

Y
fX
(x2 , y 1 ) = fX1 (x2 ) = 1/2 ,

y

Y
fX
(x2 , y 2 ) = fX2 (x2 ) = 1 .

Y
fX
(x1 , y 1 ) = fX1 (x1 ) , = 1/2

y

Y
fX
(x1 , y 2 ) = fX2 (x1 ) , = 0

When clear from the context, we write 1 to denote a function that returns one to all
values in its domain and 0 to denote a function that returns always zero. For x  x , the
indicator function Ix returns one if x = x and zero otherwise.
If f and g are functions over a domain x and k is a real number, the expressions f  g
and f = k denote that f (x)  g(x) and f (x) = k, respectively, for all x  x (e.g., in the
y
previous example we have fX1 = 1/2). Finally, any function over a domain containing a
single element (e.g., the empty domain) is identified with the real number it returns.
2.4 Definition
A LIMID L consists of a direct acyclic graph (DAG) over the set of variables U annotated
with variable types (decision, chance and value), together with a collection of (conditional)
probability mass functions (one per chance variable) and utility functions (one per value
variable). The value nodes in the graph are assumed to have no children. The precise
meaning of the arcs varies according to the type of node to which they point. Arcs entering
chance and value nodes denote stochastic and functional dependency, respectively; arcs
entering decision nodes describe information awareness at the time the decision is made.
For each variable X in U, we denote by paX the set of parents of X, that is, the set of
nodes of from which there is an arc pointing to X. Similarly, we let chX denote the set of
children of X (i.e., nodes to which there is an arc from X), and faX , paX  {X} denote
its family. We let C, D and V be a partition of U in sets of chance, decision and value
variables, respectively. Each chance variable C in C has an associated set {p
C :   paC }
100

fiSolving LIMIDs

V1

V2

V3

T1

T2

T3

uV1 (a) = uV2 (a) = uV3 (a) = 1
uV1 (w) = uV2 (w) = uV3 (w) = 0

O

pTO1 ,T2 ,T3 (s, t1 , t2 , t3 ) = I(a,a,a)
uV (s) = 7/2
uV (f ) = 0

V
Figure 1: A LIMID representing the fire dispatching problem.
of (conditional) probability mass functions p
C quantifying the decision makers beliefs about
states x  C conditional on a state  of its parents (if C has no parents, it has a single
probability mass function assigned). Using the notation introduced in the previous section,
we equivalently represent the set of probability mass functions associated to a variable C by
pa
a function pC C . We assume any chance variable X  C to be stochastically independent of
its non-descendant non-parents given its parents. Each value variable V  V is associated
with a real-valued utility function uV over paV , which quantifies the (additive) contribution
of the states of its parents to the overall utility. Thus, thePoverall utility of a state x  CD
is given by the sum of utility functions, that is, u(x) = V V uV (xpaV ).
2.5 A LIMID for the Fire Dispatching Problem
Figure 1 depicts a LIMID for the fire dispatching problem. In the graph, chance, decision
and value variables are represented by ovals, rectangles and diamonds, respectively. The
value variables V1 , V2 and V3 have associated utility functions uV1 , uV2 and uV3 , respectively,
representing the cost per unit dispatched. The utility of the outcome is quantified by the
function uV associated to the value variable V . The chance variable O has associated
a function pTO1 ,T2 ,T3 that quantifies the conditional probabilities P (O = o|T1 = tT1 , T2 =
tT2 , T3 = tT3 ) of success (o = s) or failure (o = f ) given a joint decision t  T1 ,T2 ,T3 .
According to the model in the figure, dispatching the three units results in certain success,
whereas dispatching less than three units leads to a failure.
2.6 Policies and Strategies
For any decision variable D  D with at least one parent, a policy D specifies an action
for each possible state configuration of its parents, that is, D : paD  D . If D has no
parents, then D is a state in D . The set of all policies D for a variable D is denoted by
D . For instance, a policy T1 for the first unit in the running example is a state from T1 .
The space of policies for T1 is given by T1 = {a, w}.
Let  , DD D denote the space of possible combination of policies. An element
s = (D )DD   is said to be a strategy for L. Given a policy D and a state   paD , let

p
D denote a probability mass function for D conditional on paD =  such that pD = ID () .
If D has no parents, then pD = ID is an unconditional probability mass function over D .
101

fiMaua, de Campos, & Zaffalon

pa

To simplify notation, we sometimes write pD D irrespective of whether D has any parent.
pa
There is a one-to-one correspondence between functions pD D and policies D  D such
paD
that specifying a policy D is equivalent to specifying pD and vice-versa. We denote the
pa
set of all functions pD D obtained in this way by PD . So, for instance, PT1 = {Ia , Iw }.
A strategy s induces a joint probability mass function over the variables in C  D by
Y pa Y pa
ps ,
pC C
pD D ,
(1)
CC

DD

and has an associated expected utility
Es [L] ,

X

ps

CD

X

uV .

(2)

V V

Notice that the two sums in Eq. (2) have different semantics. The outer (leftmost) sum
denotes the sum-marginal of the S
set of variables C D, whereas the inner (rightmost) denotes
the overall utility function over V V paV that results from the sum of functions uV .
In the fire dispatching problem, there are eight possible strategies consisting of a decision
to act or wait for each of the units, for example, s = (T1 , T2 , T3 ) = (a, w, a) is a possible
strategy. The policy T1 = a that dispatches unit T1 induces a probability mass function
pT1 = Ia on T1 . Likewise, the policy T2 = w induces a function pT2 = Iw , and the policy
T3 = a induces pT3 = Ia . The strategy s = (a, w, a) then induces the joint probability
mass function such that for x  O,T1 ,T2 ,T3
T1 ,T2 ,T3
ps (x) = pO
(x)pT1 (xT1 )pT2 (xT2 )pT3 (xT3 ) ,

and has an expected utility of
X
Es [L] =
ps [uV1 + uV2 + uV3 + uV ]
O,T1 ,T2 ,T3

=

X

h
i
ps (x) uV1 (xT1 ) + uV2 (xT2 ) + uV3 (xT3 ) + uV (xO ) = 2 .

xO,T1 ,T2 ,T3

The optimal strategy s = (a, a, a) that dispatches all units, on the other hand, has an
expected utility of Es [L] = 1/2.
2.7 Theoretical Complexity
The treewidth of a graph measures its resemblance to a tree and is given by the number
of vertices in the largest clique of the corresponding triangulated moral graph minus one
(Bodlaender, 1996). As in Bayesian networks, the complexity of solving a LIMID is strongly
affected by its treewidth. Given a LIMID L of treewidth , we can evaluate the expected
utility of any given strategy s in time and space at most exponential in  (Koller & Friedman,
2009). Hence, if  is bounded by a constant, computing Es [L] takes (at most) polynomial
time in the input size.
The primary task of a LIMID is to find a strategy s with maximal expected utility,
that is, to find s   such that
Es [L]  Es [L]
102

for all s.

(3)

fiSolving LIMIDs

The value Es [L] is called the maximum expected utility of L and it is denoted by MEU[L].
For most real problems, enumerating all the strategies is prohibitively costly. In fact,
computing the MEU in bounded treewidth diagrams is NP-hard (de Campos & Ji, 2008),
and, as the following result implies, it remains NP-hard in even simpler LIMIDs.
Theorem 1. Given a singly connected LIMID with treewidth equal to two, and with variables having at most three states, deciding whether there is a strategy with expected utility
greater than a given k is NP-complete.
The proof, based on a reduction from the partition problem (Garey & Johnson, 1979),
is given in the appendix.
Under the usual assumptions of complexity theory, when a problem is NP-hard to solve
the best available options are (i) trying to devise an algorithm that runs efficiently on
many instances but has exponential worst-case complexity, or (ii) trying to develop an
approximation algorithm that for all instances provides in polynomial time a solution that
is provably within a certain range of the optimal solution. In Section 3, we take option (i),
and present an algorithm that efficiently computes optimal solutions for many LIMIDs, but
runs in exponential time for many others. In the following we state a result that suggests
that alternative (ii) is most likely unfeasible, even if we consider only diagrams of bounded
treewidth.
Given  > 1, a -approximation algorithm (for solving a LIMID) obtains a strategy s
such that
MEU[L]
 Es [L] .
(4)

If we set  = 1/(1  ), for 0 <  < 1, then a -approximation algorithm finds a solution
whose induced relative error is at most , that is,
MEU[L]  Es [L]
 .
MEU[L]

(5)

The following result indicates that provably good approximation algorithms do not exist
unless P=NP.
Theorem 2. Given a singly connected LIMID L with bounded treewidth, (unless P=NP)
there is no polynomial time -approximation algorithm, for any 1 <  < 2 , where  is the
number of numerical parameters (i.e., probabilities and utilities) required to specify L.
We defer the proof to the appendix. The result asserts that any algorithm that finds
solutions to LIMIDs in polynomial time cannot guarantee a relative error smaller than
1  2 , even if the set of inputs is restricted to LIMIDs of bounded treewidth. Hence, any
polynomial-time algorithm for LIMIDs must eventually produce very poor solutions, with
relative error close to one for large models. An exception is when both treewidth and the
number of states per variable are bounded. In such cases, we have shown constructively
in an early work (Maua, de Campos, & Zaffalon, 2011) that there is a -approximation
algorithm that runs in polynomial time.
103

fiMaua, de Campos, & Zaffalon

2.8 Constraining LIMIDs to Nonnegative Utilities
In principle, the utilities associated to value variables in a LIMID can take on any real
value. This complicates the ordering between functions that we use in the algorithm we
devise here. Fortunately, we can easily and efficiently transform any LIMID L into an
equivalent LIMID L0 where all utilities are nonnegative and whose optimal strategies s are
also optimal strategies in L. Moreover, obtaining Es [L] from Es [L0 ] for any strategy s is
straightforward.
Let L be a LIMID and let k denote the smallest utility value associated to any of the
value variables, that is, for all V  V it follows that k  uV , and there is V such that
uV (x) = k for some x  paV . The following transformation generates a new LIMID L0
whose value variables are associated only to nonnegative values.
Transformation 3. For each value variable V  V, substitute its associated utility function
uV with a new utility function u0V = uV  k.
The transformation shifts the utility functions so that uV  0, and makes uV (x) = 0 for
at least one V and x  paV . Since it affects only value variables, any strategy for L (the
LIMID before the transformation) is also a valid strategy for L0 (the transformed LIMID).
The expected utilities of a strategy s in L and L0 are related according to the following
result.
Proposition 4. For any strategy s, Es [L] = Es [L0 ] + k|V|.
Proof. The expected utility of s with respect to L0 is given by
Es [L0 ] =

X

=

X
x

V

=

X

X

ps (x)

x

X

u0V (xpaV )

V

X
ps (x)
[uV (xpaV )  k]
ps (x)

x

uV (xpaV )  k|V|

X

ps (x)

x

V

= Es [L]  k|V| ,
where the last step follows from

P

x ps (x)

= 1.

An optimal strategy s for L satisfies Es [L]  Es [L] for all s, and hence Proposition 4
ensures that Es [L] = Es [L0 ]+k|V|  Es [L0 ]+k|V| = Es [L], which implies that s is also an
optimal strategy for L0 . Similarly, if s is an optimal strategy for L0 , we have by the same
proposition that Es [L0 ] = Es [L]  k|V|  Es [L]  k|V| = Es [L0 ] for all s, and therefore s
is also optimal for L. The following corollary summarizes these results.
Corollary 5. A strategy s for L0 is an optimal strategy if and only if it is also an optimal
strategy for L.
104

fiSolving LIMIDs

Consider the running example once more. The smallest utility value is k = 1. The
utilities associated to the value variables of the transformed LIMID L0 are given by
u0V (s) = 9/2

u0V (f ) = 1

u0V1 (a) = 0

u0V1 (w) = 1

u0V2 (a) = 0

u0V2 (w) = 1

u0V3 (a) = 0

u0V3 (w) = 1 .

The strategy s = (a, w, a) has expected utility Es [L0 ] = Es [L]  k|V| = 2  (1)4 = 2.
The optimal strategy s = (a, a, a) obtains Es [L0 ] = 9/2.
In the rest of the paper, we consider only LIMIDs with nonnegative utilities, which due
to Proposition 4 does not incur any loss of generality.
2.9 Decision Nodes with Many Parents Versus Parentless Decision Nodes
A policy for a decision variable with no parents corresponds to a choice of one of its states.
Hence, the space of policies of such nodes contains a number of policies that is polynomial in
the input. On the other hand, the cardinality of the space of policies for decision nodes with
many parents is exponential in the number of states of the parents. To see this, consider a
ten-state decision variable D. If D has no parents then the space of policies D contains 10
4
policies. However, if D has four ternary parent nodes, the space D contains 103 = 1081
policies.
One might then wonder whether LIMIDs whose decision nodes have many parents are
more difficult to solve than LIMIDs with parentless decision nodes. We will show that,
at least from a theoretical perspective, this is not the case, and that any LIMID can be
efficiently mapped into a MEU-equivalent LIMID where decision nodes have no parents.
We then show how an optimal strategy for the original diagram can be produced from an
optimal strategy for the transformed diagram. This is particularly relevant for algorithms
that search the space of policies, as is the case of the algorithm we devise here, and it allow
us, without loss of generality, to focus on LIMIDs whose decision nodes have no parents.
Before formally describing the transformation and showing that it produces a diagram
with equal MEU, let us first give an idea of how and why it works. To this end, consider a
LIMID L and a decision node D with at least one parent (e.g., the diagram in Figure 2(a)),
and let  1 , . . . , m denote the configurations in paD . A policy D maps a configuration
pa
 i to a decision d  D . A function pD D associated to a policy D can be seen as a
i
set of probability mass functions pT1 , . . . , pTm where pTi = p
D = ID ( i ) , that is, each
function pTi represents a choice of a state of D for a fixed configuration  i of the parents.
Recall that a policy associated to a parentless variable is simply a choice of a state. The
transformation replaces the decision variable D with m decision variables T1 , . . . , Tm and m
chance variables X1 , . . . , Xm such that each policy Ti corresponds to a decision D (i ) of the
original variables policy (see diagram in Figure 2(b)). The chain X1      Xm of chance
variables is responsible for making only the policy Ti active when the parents assume
configuration  i , as it occurs with D , by either blocking or allowing information to
flow according to the value of the parents of D. Thus, the parents of D act as a selector that
105

fiMaua, de Campos, & Zaffalon

paD

paD
D

X1

X2

chD

T1

T2



(a)

Xm

chD

Tm
(b)

Figure 2: A piece of a diagram before (a) and after (b) Transformation 6.

decides which of the probability mass functions pTi associated to decision nodes T1 , . . . , Tm is
going to be used, so that the transformed diagram acts as the original one. The probability
X
,Ti ,paD
mass functions of pXi1
are set to ensure that Xi = Ti if paD =  i and Xi = Xi1
i
otherwise.
Transformation 6. Consider a LIMID L and a decision node D with at least one parent,
and let  1 , . . . , m denote the configurations in paD . Remove D and add m = |paD |
chance nodes X1 , . . . , Xm and m decision nodes T1 , . . . , Tm with domains Xi = Ti = D
(for i = 1, . . . , m). Add an arc from every parent of D to each of X1 , . . . , Xm , an arc from
every Xi to Xi+1 , with i < m, and an arc from every Ti to Xi , i = 1, . . . , m. Add an arc
from Xm to each child of D. Associate to X1 the function


if xpaD =  1 and xX1 = xT1
1,
T ,pa
pX11 D (x) = 0,
if xpaD =  1 and xX1 6= xT1


1/m if xpaD 6=  1 .
For each node Xi , i = 2, . . . , m, associate a function


1, if (xpaD 6=  i



0, if (xpaD 6= 
X
,Ti ,paD
i
pXi1
(x)
=
i
pa
D

1, if (x
= i



0, if (xpaD = 
i

and
and
and
and

xXi
xXi
xXi
xXi

= xXi1 )
6= xXi1 )
= xTi )
6= xTi ) .

pa

Finally, the functions pX X for each child X of D have D substituted by Xm in their domain,
without altering the numerical values.
Figure 2 depicts a decision node with many parents (on the left) and the new sub-diagram
generated by Transformation 6 (on the right). It is not difficult to see that the treewidth
of the transformed diagram is increased by at most three, because the subgraph containing
the new nodes, the parents of D and the children of D is triangulated and contains cliques
with at most |paD  {Xi , Xi1 , Di }| variables.3 Also, the transformation for two different
decision variables affect different parts, and hence transforming a diagram in a diagram
with parentless decisions does not increase the treewidth by more than three. The following
result states that also optimality of strategies is preserved by the transformation.
3. Since the treewidth is given by the size of largest clique in the triangulated moral graph minus one, |paD |
is a lower bound on the treewidth of the original graph.

106

fiSolving LIMIDs

Proposition 7. Let L0 be the result of applying Transformation 6 on a decision variable
D in a LIMID L, s0 denote a strategy for L0 , and T1 , . . . , Tm denote the corresponding
policies for T1 , . . . , Tm in s0 . Let also D be a policy for D such that D ( i ) = Ti for all
 i  paD . Finally, let s be a strategy for L obtained by substituting T1 , . . . , Tm in s0 with
D (and keeping the remaining policies). Then s is an optimal strategy for L if and only if
s0 is an optimal strategy for L0 .
The proof is in the appendix. For each decision variable D in the original LIMID, the
transformed model contains m chance variables specifying m|D |3 values, and m decision
nodes with |D | states. If the treewidth of the original diagram is bounded, then m is
bounded and the transformation takes polynomial time.4 In the example of a ten-state
decision variable with four ternary parents, the transformation replaces the decision variable
D with 34 = 81 decision variables whose space of policies contain 10 elements each, besides
the 81 chance variables. The combined space of policies, that is, T1      T81 contains
also 1081 elements, so that the total search space is still (doubly) exponential in the input.
However, algorithms can take advantage of the smaller local policy spaces to reach better
solutions, and this is particularly true for the algorithm we devise later on.
In the rest of the paper we assume without loss of generality that decision nodes have
no parents and utilities are nonnegative.

3. Solving LIMIDs
In this section, we describe a new algorithm for solving LIMIDs exactly by propagating
multiple non-dominated solutions. We start by defining the basic algebraic structure of
our algorithm, which is given by the framework of valuation algebra. We show that this
framework alone, similar to the one used by SPU, might lead to poor accuracy. We thus
extend the framework with sets of valuations that attempt to improve accuracy by increasing
complexity. Efficiency is obtained by pruning sets so that their cardinality is kept as small
as possible without affecting accuracy.
3.1 Valuation Algebra
The basic ingredients of our algorithmic framework for representing and handling information in LIMIDs are the so called valuations, which encode information (probabilities, utilities
and policies) about the elements of a domain. Each valuation is associated to a subset of the
variables in U, called its scope. More concretely, a valuation  with scope x is a pair (p, u)
of nonnegative real-valued functions p and u over the domain x ; we refer to p and u as
the probability and utility part, respectively, of . Often, we write x to make explicit the
scope x of a valuation . For any x  U, we denoted the set of all possible
S valuations with
scope x by x . The set of all possible valuations is thus given by  , xU x . The set
 is closed under two basic operations of combination and marginalization. Combination
represents the aggregation of information and is defined as follows.
Definition 8. If  = (p, u) and  = (q, v) are valuations with scopes x and y, respectively,
its combination    is the valuation (pq, pv + qu) with scope x  y.
4. If the treewidth is not bounded then the output of any algorithm, that is, an optimal strategy, might
take space exponential in the input.

107

fiMaua, de Campos, & Zaffalon

Marginalization, on the other hand, acts by coarsening information:
Definition 9. If  = (p, u) is a valuationP
with scope
P x, and y is a set of variables such that
y  x, the marginal y is the valuation ( x\y p, x\y u) with scope y. In this case, we say
that z , x \ y has been eliminated from , which we denote by z .
Notice that our definitions of combination and marginalization slightly differ from previous works on influence diagrams (e.g., Lauritzen & Nilsson, 2001), which usually require
a division of the utility part by the probability part. The removal of the division operation
turns out to be an important feature when we discuss maximality of valuations later on,
but otherwise our definition is equivalent to valuations with division, in the sense that one
could easily reformulate message-passing algorithms like SPU using our definition.
In terms of computational complexity, combining two valuations  and  with scopes
x and y, respectively, requires 3|xy | multiplications and |xy | additions of numbers;
computing y , where y  x, costs |xy | operations of addition. In other words, the cost
of combining or marginalizing a valuation is exponential in the cardinality of its scope (and
linear in the cardinality of its domain). Hence, we wish to work with valuations whose
scope is as small as possible. The following result shows that our framework respects the
necessary conditions for computing efficiently with valuations (in the sense of keeping the
scope of valuations obtained from combinations and marginalizations of other valuations
minimal).
Proposition 10. The system (, U, , ) satisfies the following three axioms of a (weak)
labeled valuation algebra (Shenoy & Shafer, 1990; Kohlas, 2003).
(A1) Combination is commutative and associative, that is, for any 1 , 2 , 3   we have
that
1  2 = 2  1 ,
1  (2  3 ) = (1  2 )  3 .
(A2) Marginalization is transitive, that is, for z  z and y  x  z we have that
y
(x
= y
z )
z .

(A3) Marginalization distributes over combination, that is, for x  x , y  y and
x  z  x  y we have that
(x  y )z = x  yyz .
Proof. (A1) follows directly from commutativity, associativity and distributivity of product
and sum of real-valued functions, and (A2) follows directly from commutativity of the summarginal operation. To show (A3), consider any two valuations (p, u) and (q, v) with scopes
x and y, respectively, and a set z such that x  z  x  y. By definition of  and , we
have that


X
X
[(p, u)  (q, v)]z = 
pq,
(pv + qu) .
xy\z

108

xy\z

fiSolving LIMIDs

Since x  y \ z = y \ z, and p and u are functions over x , it follows that

 

X
X
X
X
X

q
v+u
q, p
(pv + qu) = p
pq,
xy\z

y\z

xy\z

y\z

y\z



X X
v ,
= (p, u)  
q,
y\z

y\z

which equals (p, y)  (q, v)yz .
The following result by Kohlas (2003, Section 2.2) is a direct consequence of (A3) that
we shall use to prove the correctness of our algorithm.
Lemma 11. If x  x , y  y , z  y and z  x = , then (x  y )z = x  z
y .
The primary goal of a valuation algebra is the computation of marginal valuations of
the form  = (1      m ) . Let {X1 , . . . , Xn } be the set of variables appearing in the
scopes of 1 , . . . , m . The marginal  can be computed efficiently by a variable elimination
procedure5 that receives a set  = {1 , . . . , m } and a permutation  of the variables
(1)
(k )
X1 , . . . , Xn , and for i = 1, . . . , n replaces all valuations i , . . . , i i whose scope contains


(1)
(k ) (Xi )
variable (Xi ) with the marginal i = i      i i
. Algorithm 1 describes the
procedure. The algorithm returns a valuation j      k , where j , . . . , k  n , which
equals  by Axioms (A1)(A3) (Kohlas, 2003, Section 4.1).
Algorithm 1 VariableElimination(x,,)
Input: A permutation  of the variables x = {X1 , . . . , Xn } and a set of valuations  =
{1 , . . . , m } over subsets of x
Output: The marginal valuation (1      m )
1: Let 0  
2: for i  1 to n do
(1)
(k)
3:
Let i , . . . , i denote the valuations in i1 whose scope contains (Xi )


(1)
(k) (Xi )
4:
Compute i = i      i
(1)

(k)

Let i  i1  {i } \ {i , . . . , i }
6: end for
7: return the combination of all valuations in n

5:

The complexity of the variable elimination procedure is given by the size of the largest
valuation i generated in the loop. This valuation might have a size exponential in the
size of valuations 1 , . . . , m given as input, but, as we discuss later on, there are certain
conditions under which the size of i is bounded and the procedure takes time polynomial
in the input.
5. Variable elimination algorithms are also known in the literature as fusion algorithms (Shenoy & Shafer,
1990) and bucket elimination (Dechter, 1999).

109

fiMaua, de Campos, & Zaffalon

3.2 Computing Expected Utilities
We can use the valuation algebra framework introduced to compute the expected utility of a
given strategy using variable elimination. Let s = (D )DD   be a strategy for a LIMID
L whose expected utility we want to compute, and  be a permutation of the variables in
C  D. We assume that the decision nodes in L have no parents (otherwise we need first
to apply Transformation 6), so that the strategy s is simply a configuration in D . The
procedure in Algorithm 2 computes the expected utility induced by the strategy s. The
pa
procedure calls variable elimination with a set  that contains a valuation C = (pC C , 0)
for each chance variable, a valuation V = (1, uV ) for each value variable, and a valuation
D = (ID , 0) for each decision variable. We have the following result.
Algorithm 2 ExpectedUtility(L, , s)
Input: A LIMID L whose decision nodes have no parents, a permutation  of the variables
in C  D, and a strategy s = (D )DD  
Output: The expected utility of s
1: Let   
2: for C  C do
pa
3:
Add C = (pC C , 0) to 
4: end for
5: for V  V do
6:
Add V = (1, uV ) to 
7: end for
8: for D  D do
9:
Add D = (ID , 0) to 
10: end for
11: Let s  VariableElimination(C  D, , )
12: return the utility part of s

Proposition 12. The procedure described in Algorithm (2) returns the expected utility of
the strategy s.
Proof. Let s be the output of the Variable Elimination Algorithm. According to Axioms
(A1)(A3), we have that s =   , where
"
# "
# "
#
O pa
O
O

=
pC C , 0 
(ID , 0) 
(1, uV ) .
CC

DD

V V

Let p and u denote the probability and
of s . By definition of
P utility part, respectively,
Q
pa
combination, we have that  = (ps , ps V V uV ), where ps = PXCD pX X as in (1). Since
ps isP
a probability
P distribution over C  D, it follows that p = xCD ps (x) = 1. Finally,
u = CD ps V V uV , which equals Es [L] by (2).
Consider the LIMID of the fire dispatching problem (Figure 1) and the strategy s =
(a, w, a) whose expected utility we want to compute using the procedure above. We assume
110

fiSolving LIMIDs

that the utilities are nonnegative (i.e., we have already applied Transformation 3). According to the procedure in Algorithm 2, we first generate the set  = {O = (pTO1 ,T2 ,T3 , 0), V1 =
(1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 = (Ia , 0), T2 = (Iw , 0), T2 =
(Ia , 0)}. For X1 = O, X2 = T1 , X3 = T2 , X4 = T3 , let  be a permutation of the variables
such that (Xi ) = Xi for i = 1, . . . , 4. The variable elimination algorithm with  and  as
input produces the valuations
1 = (V  O )O

2 = (V1  T1  1 )T1

3 = (V2  T2  2 )T2

4 = (V3  T3  3 )T3

during its loop, and outputs the valuation s = 4 = (1, 2). Similarly, to compute the
expected utility of the optimal strategy s = (a, a, a) we run variable elimination with
 = {O = (pTO1 ,T2 ,T3 , 0), V1 = (1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 =
(Ia , 0), T2 = (Ia , 0), T2 = (Ia , 0)}, which then outputs s = (1, 9/2).
In general, the described procedure can take time exponential in the input. However,
when L has bounded treewidth it can be shown that there exists a permutation  for
which the procedure takes time polynomial in the input. (e.g., Koller & Friedman, 2009,
Section 23.4.3). Hence, if the space of strategies is sufficiently small, we can find an optimal
strategy by simply ranking strategies according to their expected utilities. However, we do
not expect this to be feasible for any realistic diagram as the space of strategies increases
exponentially with the number of decision nodes (assuming they have no parents), even in
diagrams of bounded treewidth and bounded number of states per variable.
3.3 Local Search Algorithms
As a first attempt to design a fast algorithm to solve LIMIDs, one might suggest a local
search scheme that starts with a random solution and repeatedly explores its neighborhood
in order to find a solution with higher expected utility. If the treewidth of the diagram is
bounded, the expected utility of each neighbor solution can be efficiently computed, so the
complexity of the algorithm is given by the size of the neighborhood. A possible approach
is then to define the neighborhood of a solution to be the strategies obtained by changing
a single policy, which gives a local search space polynomial in the input. Algorithm 3
describes a greedy procedure that at each step looks for a new policy that improves on
the current best solution. The algorithm is guaranteed to find a strategy which is locally
optimal in its neighborhood, that is, it cannot be improved by changing only one of its
policies. Lauritzen and Nilsson (2001) stated sufficient conditions that a diagram has to
satisfy in order to guarantee that the solution produced by a local search procedure is
(globally) optimal. Unfortunately, as the following example shows, these conditions are
violated by even structurally very simple chain diagrams, and in such cases a local search
procedure might output local optima of very poor accuracy.
Consider the LIMID of our running example, and suppose we start with strategy s0 =
(a, w, a), which has expected utility 2. At the first step we might try to improve the policy
for T1 , producing strategy s = (w, w, a) whose expected utility is 3. Since this is higher
than the expected utility of the initial solution, we set sbest  s and update the highest
expected utility found. Next, we try to search for a better policy for T2 , and we generate
strategy s = (w, a, a). This strategy has an expected utility of 2, which is less than the
111

fiMaua, de Campos, & Zaffalon

Algorithm 3 GreedyPolicySearch(L, , s0 )
Input: A LIMID L, a permutation  of the variables in C  D, and an initial strategy
s0 = (D )DD
Output: A locally optimum strategy sbest
1: Let sbest  s0 and Esbest [L]  ExpectedUtility(L, , s0 )
2: repeat
3:
Generate a new candidate strategy s by replacing a single policy D in sbest
4:
Compute Es [L]  ExpectedUtility(L, , s)
5:
if Es [L] > Esbest [L] then
6:
Set sbest  s and Esbest [L]  Es [L]
7:
end if
8: until current solution cannot be further improved in this way
9: return sbest

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 3: A chain structure diagram with n decision variables.
expected utility of the best solution found so far. Finally, we look for a better policy for T3 ,
which leads us to strategy s = (w, w, w), whose expected utility is 4. Since this is better
than our current best solution we set sbest  s and update the associated expected utility.
Since no change of a single policy can improve this strategy, the algorithm halts with a
solution whose expected utility is 4 against a maximum expected utility of 9/2 achieved by
strategy s = (a, a, a) (more than 10% relative error), or, in terms of the original diagram
(by means of Proposition 4), an expected utility of zero against a maximum expected utility
of 1/2.
The procedure we have just described is very similar to the SPU algorithm, and it
illustrates the pitfalls of a local search. In fact, SPU will output just the same local optimum
(but it would start with a uniform policy for every decision variable). Note that the solution
obtained by the greedy local search on the example degrades as the ratio of the utility of
success (achieved only by strategy (a, a, a)) and the utility of failure increases. For instance,
if the utility of success were increased to u0V (s) = 10 and the utility of failure remained the
same, that is, if u0V (f ) = 0, the algorithm would reach a solution whose expected utility is
4, an error of 60% relative to the maximum expected utility of 10. Moreover, cases where
SPU performs poorly are not rare. For instance, the plots in Figure 4 show SPUs relative
performance in chain diagrams like the one in Figure 3. Each diagram was generated by
independently sampling each conditional distribution associated to a chance node from a
symmetric Dirichlet distribution with parameter 1/m, where m is the number of variable
states. The maximum expected utility of each diagram was computed using the algorithm
we devise here, which took less than 3 seconds on any diagram in the experiment.
Each (blue) point in the plots in Figure 4 depict the relative error of SPU on a given
diagram. The (red) line indicates the third quartile of each fixed configuration. The di112

fiSolving LIMIDs

0.6

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Relative error

0.5
0.4
0.3
0.2
0.1
0
10
20
30
40
50
Number of decision nodes

10
20
30
40
50
Number of states per variable

Figure 4: Relative performance of SPU on randomly generated chain diagrams. Each (blue)
circle depicts an experiment and the (red) line depicts the third quartile.
agrams in the left hand-side plot were obtained with the number of states fixed at 15,
while the diagrams on the right had the number of decision variables fixed in ten. For
example, we see from the third quartile line on the right-hand side plot that in 25% of the
chain diagrams of 20 states and ten decision variables, SPU returned a strategy s such that
(MEU[L]  Es [L])/ MEU[L]  0.1. Also, there were cases where SPU obtains up to 70%
relative error. On the other hand, we see that in the majority of the cases the solution
returned by SPU achieved a relative error of less than 10%. All in all, these experiments
show that local search is effective in many cases, but may produce very poor results.
3.4 Ordered Valuations
Can we also exploit the redundancy in the computation of expected utility of neighboring
strategies to decide whether a candidate solution improves the current solution without
having to run variable elimination completely? For instance, when evaluating the quality
of a new candidate strategy that differs from the current best strategy only by the policy
associated to T1 , can we have any insight by inspecting two valuations 2 produced by
variable elimination in the example in Section 3.2 using two different strategies? Fortunately,
the answer is yes, and to show this we need the concept of ordered valuations.
Let us define a partial order (i.e., a reflexive, antisymmetric and transitive relation) over
, the set of all possible valuations, as follows.
Definition 13. For any two valuations  = (p, u) and  = (q, v) in , we say that 
dominates  (conversely, we say that  is dominated by ), and we write   , if  and
 have equal scope, p  q, and u  v.
If  and  have scope x, deciding whether  dominates  costs at most 2|x | operations
of comparison of numbers. The following result shows that the algebra of valuations is
monotonic with respect to dominance.
Proposition 14. The system (, U, , , ) satisfies the following two additional axioms
of an ordered valuation algebra (Haenni, 2004).
113

fiMaua, de Campos, & Zaffalon

(A4) Combination is monotonic with respect to dominance, that is,
if x  x and y  y then (x  y )  (x  y ) .
(A5) Marginalization is monotonic with respect to dominance, that is,
y
if x  x then y
x  x .

Proof. (A4). Consider two valuations (px , ux ) and (qx , vx ) with scope x such that (px , ux ) 
(qx , vx ), and two valuations (py , uy ) and (qy , vy ) with scope y satisfying (py , uy )  (qy , vy ).
By definition of , we have that px  qx , ux  vx , py  qy and uy  vy . Since all
functions are nonnegative, it follows that px py  qx qy , px uy  qx vy and py ux  qy vx .
Hence, (px , ux )  (py , uy ) = (px py , px uy + py ux )  (qx qy , qx vy + qy vx ) = (qx , vx )  (qy , vy ).
(A5). Let y be a subset of x. It follows from monotonicity of  with respect to addition of
real numbers that

 

X
X
X
X
(px , ux )y = 
px ,
ux   
qx ,
vx  = (qx , vx )y .
x\y

x\y

x\y

x\y

Hence, the result follows.
Axioms (A4) and (A5) assert that combination and marginalization preserve the partial
ordering between valuations. This allow us to detect suboptimal strategies early in the
variable elimination procedure. Consider comparing the strategies s = (w, w, w) and s0 =
(w, a, w) for the LIMID of our running example. At the third iteration of the loop (i.e.,
when i = 3), the variable elimination procedure produces valuations s3 = (ps3 , us3 ) and
0
0
0
s3 = (ps3 , us3 ) for the strategies s and s0 , respectively, such that
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 3 ,

us3 (w) = 3 ,

0

ps3 (w) = 1 ,

0

0

us3 (w) = 2 .

ps3 (a) = 1 ,

0

us3 (a) = 2 ,
0

0

0

Thus, s3  s3 . Since s4 = (sT3  V3  s3 )T3 and s4 = (sT3  V3  s3 )T3 , we know
0
by Axioms (A4) and (A5) that s4  s4 , and hence that Es0 [L]  Es [L]. Therefore, there is
no need to continue the execution of variable elimination for s0 , as its expected value cannot
be higher than that of s.
Unfortunately, suboptimal solutions do not always produce valuations that are dominated by an optimal one during variable elimination. As an example, consider strategies
s = (a, w, a) and s = (a, a, a). At the third step, variable elimination generates valuations



s3 = (ps3 , us3 ) and s3 = (ps3 , us3 ) such that
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 2 ,

us3 (w) = 2 ,




ps3 (w) = 1 ,



us3 (w) = 1 .

ps3 (a) = 1 ,



us3 (a) = 9/2 ,
114

fiSolving LIMIDs



Thus, even though s is an optimal strategy, s3 6 s3 .
The algorithm we devise later on exploits that fact that some suboptimal solutions can
be early detected and eliminated from the search space. Because some suboptimal solutions
might not be eliminated during variable elimination, the algorithm runs in exponential time
in the worst case, but this is just to be expected, as the problem is NP-hard. Fortunately,
our experiments with random problems suggest that situations like this are not frequent.
3.5 Sets of Valuations
The multiple runs of variable elimination for different inputs but same elimination ordering (i.e., a permutation of the variables) are represented by sets in the framework of the
algorithm we devise later on. For instance, we might consider the set 3 of all valuations
3 produced by variable elimination at the third iteration of the loop for every possible
strategy. Due to the monotonicity of combination and marginalization with respect to ,
we can immediately halt the computation of valuations from 3 that are dominated by
some other, that is, we can remove dominated valuations from 3 . This is formalized by
the concept of maximal valuations and the operator max:
Definition 15. Given a finite set of valuations   , we say that    is maximal if for
all    such that    it holds that   . The operator max returns the set max()
of maximal valuations of .
If x is a set with m valuations of scope x, the set of maximal valuations max(x ) can
be obtained by m2 comparisons   , where (, )  x  x .
When all valuations in the set x have the same scope x, we say that x also have scope
x. We can extend combination and marginalization to sets of valuations as follows.
Definition 16. If x and y are any two sets of valuations in ,
x  y , {x  y : x  x , y  y }
denotes the set obtained from all combinations of a valuation in x and a valuation in y .
Definition 17. If x  x is a set of valuations with scope x and y  x,
y
y
x , {x : x  x }

denote the set of valuations obtained by element-wise marginalization of valuations to y.
It can be checked that sets of valuations with combination and marginalization defined
element-wise satisfy axioms (A1)(A3), and therefore form a valuation algebra. Hence,
Lemma 11 applies also for sets of valuations with marginalization and combination defined
as above.
Lemma 18. If x  x and y  y are two sets of valuations with scope x and y,
respectively, and z is a set of variables such that z  y and z  x = , then (x  y )z =
x  yz .
Proof. The result follows from element-wise application of Lemma 11 to (x  y )z 
(x  y )z .
115

fiMaua, de Campos, & Zaffalon

3.6 Solving LIMIDs Exactly
We are now ready to describe the MultiplePolicyUpdating (MPU) algorithm, which
solves arbitrary LIMIDs exactly. The algorithm assumes that the decision nodes have no
variables, and that utilities are nonnegative, hence Transformations 6 and 3 have to be
applied before running the algorithm in case some of these assumptions fail.
Consider a LIMID L and a permutation  of the variables in C  D, and let n = |C  D|.
pa
The algorithm is initialized by generating a set S0 that contains a singleton {(pC C , 0)}
for each chance variable C, a singleton {(1, uV )} for each value variable V and a set of
valuations {(pD , 0)}, which contains one element (pD , 0) per policy D , for each decision
variable D. Then a set-valued variable elimination is performed for the sets of valuations
in S0 , with dominated valuations being discarded after each set marginalization. Finally,
an optimal solution is obtained from the utility part of the single maximal valuation in the
set combination of all sets of valuations in Sn obtained after the variable elimination. The
procedure is detailed in Algorithm 4.
Algorithm 4 MultiplePolicyUpdating(L, )
Input: A LIMID L and a permutation  of the variables in C  D
Output: The maximum expected utility
1: Let S0  
2: for C  C do
pa
3:
Add a singleton {(pC C , 0)} to S0
4: end for
5: for V  V do
6:
Add a singleton {(1, uV )} to S0
7: end for
8: for D  D do
9:
Add a set {(Id , 0) : d  D } to S0
10: end for
11: for i  1 to n do
(1)
(k)
12:
Let i , . . . , i denote
whose
h the sets in Si1
 scope contains (Xi )
i
(1)
(k) (Xi )
13:
Compute i = max i      i
(1)

(k)

Let Si  Si1  {i } \ {i , . . . , i }
15: end for
16: Let S denote the set combination of all sets in Sn
17: return the utility part u of (p, u)  max(S)

14:

Since all variables have been eliminated at the end of the loop, the valuations in sets
in S have empty scope and have both their probability and utility parts identified with
numbers. Hence, the algorithm outputs an expected utility (i.e., a real number) at line 17.
Let us illustrate the algorithm with an example. Once more, consider the LIMID L of the
fire dispatching problem after applying Transformation 3 and assume the same elimination
ordering of the variables used in the example in Section 3.2. We start with an empty set
116

fiSolving LIMIDs

S0 . O is the only chance variable, and we add a set
O = {(pTO1 ,T2 ,T3 , 0)}
to S0 . Then we add the sets
V1 = {(1, u0V1 )} ,

V2 = {(1, u0V2 )} ,

V3 = {(1, u0V3 )} ,

V = {(1, u0V )}

to S0 due to the value variables V1 , V2 , V3 and V , respectively. The decision variable T1
causes a set
T1 = {(Ia , 0), (Iw , 0)}
with scope T1 to be included in S0 , and similarly, for variables T2 and T3 , that is, we add
the sets
T2 = {(Ia , 0), (Iw , 0)} ,

T3 = {(Ia , 0), (Iw , 0)} ,

with scopes T2 and T3 , respectively, to S0 , obtaining S0 = {O , V1 , V2 , V3 , V , T1 , T2 , T3 }.
In the first iteration (i = 1) of the variable elimination loop (lines 1115), we have that


1 = max [V  O ]O = {(p1 , u1 )} ,
where p1 and u1 are functions over T1 ,T2 ,T3 such that p1 = 1 and u1 (a, a, a) = 9/2, and
u1 (x) = 1 for all x 6= (a, a, a). Note that 1 is a singleton since only singletons were
involved is its computation. In the second iteration we have that


w
2 = max [V1  T1  1 ]T1 = {(pa2 , ua2 ), (pw
2 , u2 )} ,
w
a
w
a
where pa2 , ua2 , pw
2 , u2 are functions over T2 ,T3 such that p2 = p2 = 1, u2 (a, a) = 9/2,
a
w
u2 (x) = 1 for all x 6= (a, a), and u2 = 2. Note that we have labeled the functions
according to the policies T1 that generated them. This allows us to easily extract the
optimal strategy at the end of the algorithm.
In the third iteration we need to compute


3 = max [V2  T2  2 ]T2
(a,a)

= max({(p3
(a,a)

= {(p3
(a,a)

(a,a)

(a,w)

(a,a)

, u3

(a,a)

(a,w)

), (p3

(w,w)

(a,w)

, u3

(w,w)

, u3

), (p3

, u3

(a,w)

(w,w)

(w,w)

(w,w)

), (p3

(w,w)

, u3

)})

)} ,
(a,a)

where p3 , u3 , p3
, u3
, p3
, u3
are functions over T3 such that p3
=
(a,w)
(w,w)
(a,a)
(a,a)
(a,w)
(w,w)
p3
= p3
= 1, u3 (a) = 9/2, u3 (w) = 1, u3
= 2, and u3
= 3. Note that
the valuation associated to the policies T2 = w and T2 = a do not appear in 3 because
(a,w) (a,w)
they generate a valuation equal to (p3
, u3
). This implies that strategies (a, w, w)
and (w, a, w) have the same expected utility, and also strategies (a, w, a) and (w, a, a).
117

fiMaua, de Campos, & Zaffalon

In the last iteration, we generate the set


4 = max [V3  T3  3 ]T3
(a,a,a)

(a,a,a)

= max({(p4

, u4

(a,a,a)

(a,a,a)

= {(p4

, u4

(a,a,a)

(a,a,a)

(w,w,a)

), (p4

(w,w,a)

, u4

(a,a,w)

), (p4

(a,a,w)

, u4

(w,w,w)

), (p4

(w,w,w)

, u4

)})

)} ,
(w,w,a)

(w,w,a)

(a,a,w)

(a,a,w)

(w,w,w)

(w,w,w)

where p4
, u4
, p4
, u4
, p4
, u4
, p4
, u4
are functions over
(a,a,a)
(w,w,a)
(a,a,w)
(w,w,w)
(a,a,a)
the empty set such that p4
= p4
= p4
= p4
= 1, u4
= 9/2,
(w,w,a)
(a,a,w)
(w,w,w)
u4
= 3, u4
= 2, and u4
= 4.
(a,a,a)
Finally, we have that S4 = {4 }, so the algorithm returns u4
= 9/2, which is the
expected utility of the optimal strategy (a, a, a). As one can see, the optimal strategy is
easily recovered by labeling valuations with their corresponding policies.
Differently from other message-passing algorithms that obtain approximate solutions
to LIMIDs by (repeatedly) propagating a single valuation (e.g., the SPU algorithm), the
MPU algorithm computes exact solutions by propagating several maximal valuations that
correspond to partial combinations of local decision rules. The efficiency of the algorithm in
handling the propagation of many valuations derives from the early removal of valuations
performed by the max operation in the propagation step.
Consider the set L , {s : s  }, where each s is given by
"

#
O

s =

pa

pC C , 0



"


CC

#
O

DD

(Id , 0) 

#!

"
O

(1, uV )

V V

such that the functions Id are consistent with the policies in s. It is not difficult to see that
#

"
O

L =

	
pa
pC C , 0

CC



#
O

{(Id , 0) : d  D } 

#!

"
O

{(1, uV )}

V V

DD




=

"

O

X 

.

X S0

Hence, by Proposition 12 we have that each s in L is a valuation with probability part
one and utility part equal to the expected utility of some strategy s in . Since the relation
 induces a strict (linear) order over L , the MEU of the diagram equals the utility part of
the (single) valuation in max(L ). The
N variable elimination procedure in the propagation
step is responsible
Nfor obtaining max( Sn ) = max(L ) more efficiently by distributing
max and  over X S0 X , which allows for a significant reduction in the cardinalities of
sets and scopes of valuations produced.
We now formally prove the correctness of the algorithm. We start by showing that max
distributes over marginalization and combination:
Lemma 19. (Distributivity of maximality). If x  x and y  y are two finite sets of
ordered valuations and z  x, the following holds.
118

fiSolving LIMIDs

(i) max(x  max(y )) = max(x  y );
(ii) max(max(x )z ) = max(z
x ).
Proof. Part (i) has been shown by Fargier, Rollon, and Wilson (2010, Lemma 1(iv)). We
use a similar proof to show that part (ii) also holds. First, we show that max(z
x ) 
z
z
max(max(x ) ). Assume, to show a contradiction, that there is an element x  max(z
x ),
where x  x , which is not an element of max(max(x )z ). By definition of max(x ), there
z
z
z
is x  max(x ) such that x  x . Hence, (A5) implies z
x  x , and because x  x
z
z
z
z
it follows that z
/ max(max(x )z )
x = x , and therefore x  max(x ) . Since x 
there is z  max(max(x )z ) such that z
x  z . But this contradicts our initial assumpz
tion since z  x .
Let us now show that max(xz )  max(max(x )z ). Assume by contradiction that
z
z
there is z  max(max(x )z ) \ max(z
x ). Since z  x , there is z  max(x ) such
z
that z  z . But we have shown that max(x )  max(max(x )z ), hence z = z and
z  max(z
x ), a contradiction.
At any iteration i of the propagation step, the combination of all sets in the current pool
of sets Si produces the set of maximal valuations of the initial factorization marginalized
to Xi+1 , . . . , Xn :
Lemma 20. For i  {0, 1, . . . , n}, it follows that

{X1 ,...,Xi } 


O
O


max 

 ,
 = max 
S0

Si

where for each i, Si is the collection of sets of valuations generated at the i-th iteration of
the propagation step of MPU.
Proof. By induction on i. The basis (i = 0) follows trivially.
Assume the result holds at i, that is,



{X1 ,...,Xi } 
O
O


max 

 .
 = max 
Si

S0

By eliminating Xi+1 from both sides and then applying the max operation we get to

{X1 ,...,Xi } Xi+1 

Xi+1 
O

 O 




max max 



 = max max 
.




S0

Si

119

fiMaua, de Campos, & Zaffalon

Applying Lemma 19(ii) to both sides and (A2) to the left-hand side yields


{X1 ,...,Xi+1 } 
Xi+1 
 O 

 O 

max 


 = max 

S0

Si



= max 

Xi+1 
O

  




O



Bi+1

Si \Bi+1



= max 



Xi+1 
 O

  max 




O

Bi+1

Si \Bi+1


= max 


O



  i 

Si \Bi+1


= max 


O

 ,

Si+1

where the passage from the first to the second identity follows from element-wise application
of (A1) and Lemma 11, the third follows from the second by Lemma 19(i), and the last two
follow from the definitions of i and Si+1 , respectively.
We are now able to show the correctness of the algorithm in solving LIMIDs exactly.
Theorem 21. Given a LIMID L, MPU outputs MEU[L].

N
Proof. The algorithm returns the utility part of a valuation (p, u) in max
 , which,
S
n
N
 
by Lemma 20 for i = n, equals max

. By definition of S0 , any valuation 
S0

N
in
S0  satisfies
"
=

#
O
CC


pa
pC C , 0

"


#
O

DD

(Id , 0) 

"

#
O

(1, uV ) ,

V V

for some combination of decisions (d)
N  D , which corresponds to a strategy in , and
there is exactly one valuation  
S0  for each strategy in . Hence, by Propo
N
sition 12, the set
contains a pair (1, Es [L]) for every strategy s inducing
S0 
a distinct expected utility. Moreover, since functions with empty scope correspond to

N
numbers, the relation  specifies a total ordering over the valuations in
,
S0 
 be a strategy associated to (p, u). Since
which implies a single maximal
element.
Let
s
N
 
(p, u)  max

, it follows from maximality that Es [L]  Es [L] for all s, and
S0
hence u = MEU[L].
120

fiSolving LIMIDs

3.7 Complexity Analysis
As with any variable elimination, the complexity of the algorithm depends on the permutation  given as input. The time complexity of the algorithm is given by the cost of creating
the sets of valuations in the initialization step plus the overall cost of the combination and
marginalization operations performed during the propagation step. Regarding the initialization step, the loops for chance and value variables generate singletons, and thus take time
linear in the input. Since decision nodes have no parents, each set D added due to a decision variable D contains D , |D | valuations. Let  , maxDD D be the cardinality of
the largest domain of a decision variable. Then the initialization loop for decision variables
takes O(|D|) time, which is polynomial in the input. Let us now analyze the propagation
step. The running time of propagating (sets of) valuations is exponential in the maximum
number of variables in the scope of the valuations generated during the loop step. This
number depends on the permutation  chosen and is in the best case equal to the treewidth
of the diagram plus one. Although finding an optimal permutation (i.e., one that leads to
a minimum maximum number of variables per scope) is an NP-hard task, we can generate
permutations  using the standard heuristics for variable elimination in Bayesian networks,
such as minimizing the number of fill-ins or the cardinality of the domain of the neighbor
set, which have been empirically shown to produce good elimination orderings (Jensen &
Nielsen, 2007; Koller & Friedman, 2009).
Consider a permutation  that induces a maximum number of variables per scope of
, and a diagram with bounded number of states per variable . Then the cost of each
combination or marginalization is bounded by a constant, and the complexity depends
only on the number of operations performed. Moreover, we have in this case that   .
Let  denote the cardinality of the largest set i , for i = 1, . . . , n. Thus, computing i
requires at most  |U |1 operations of combination (because
that is the maximum number
N
of sets that we might need to combine to compute Bi  in the propagation step) and
 operations of marginalization. In the worst case,  is equal to |D|  O(|D| ), that is, all
sets associated to decision variables have been combined without discarding any valuation.
Hence, the worst-case complexity of the propagation step is exponential in the number of
decision variables, even if the width of the elimination ordering and the number of states per
variable are bounded. Note however that this is a very pessimistic scenario and, on average,
the removal of non-maximal elements greatly reduces the complexity, as the experiments in
Section 4 show.
3.8 Reverse Topological Ordering
The valuations used by MPU specify twice as many numbers as the cardinality of the domain
of their associated scope. It is possible to decrease the number of numerical parameters per
valuation the algorithm needs to handle by a factor of two by constraining the elimination
of variables to follow a reverse topological ordering according to the diagram, that is, by
requiring each variable to be processed only after all its descendants have been processed.
As the following result shows, any reverse topological ordering produces valuations whose
probability part equals one in all coordinates.

121

fiMaua, de Campos, & Zaffalon

A

B

V1

D

C

E

V2

F

Figure 5: A LIMID in which a reverse topological ordering increases treewidth.

Proposition 22. If  defines a reverse topological ordering over the variables in C  D,
then for i = 1, . . . , n the valuations in i have probability part p = 1, where 1 is the function
that always returns the unity.
Proof. We show the result by induction on i. Regarding the basis, we have from the reverse
topological ordering that X1 is a variable containing only value nodes as children. Hence,
paX
B1 = {X1 }  {{(1, uV )} : V  chX1 }, where by definition X1 equals {(pX1 1 , 0)} if
paX

paX

X1 is a chance node, and {(pX1 1 , 0) : pX1 1  PX1 } if it is a decision node. It follows
P
paX P
paX P
that 1 = max({( X1 pX1 1 , X1 pX1 1 V chX uV )}). Since for any   paX , p
X1
1
1
P
paX
1
is a probability mass function over X1 , we have that p =
= 1. Assume by
X1 pX1
N
inductive hypothesis
that
the
result
holds
for
1,
.
.
.
,
i

1,
and
let

,
x
Bi \S0 . Then
N
i = max([ Bi S0 ]  x ). By inductive hypothesis all valuations in a set  in Bi \ S0
have probability part p = 1. Hence, by definition of combination, the valuations in x
contain also probability part equal to one. The reverse topological ordering implies that
by the time variable Xi is processed in the propagation step, all its children have been
paX
processed. Hence, the only element of Bi  S0 is the set Xi , which equals {(pXi i , 0)} if Xi
paX

paX

is a chance node, {(pXi i , 0) : pXi i  PXi } if Xi is a decision node, and {(1, uXi )} if it is a
value node. Thus, we have that i = max(Xi  x ). The case when Xi is a value node is
immediate, since any valuation in i is the result of a combination of two valuations with
probability part equal to one. If Xi is not a value node then


 X


paX X paX
paX
i = max 
pXi i ,
pXi i ux : (pXi i , 0)  faXi , (1, ux )  x 
Xi

Xi



 X


paX
paX
= max  1,
pXi i ux : (pXi i , 0)  Xi , (1, ux )  x  ,
Xi

since p
Xi is a probability mass function for any   paX .
i

The result states that if we assume a reverse topological elimination ordering, then MPU
needs to care only about the utility part of the valuations. Unfortunately, constraining the
elimination order might increase the complexity of the algorithm, as the following example
shows.
Consider the LIMID in Figure 5, where all variables are assumed binary (we omit the
specification of probabilities and utilities as they are not relevant for the matter). After
122

fiSolving LIMIDs

the initialization, we have that S0 = {A , B , C , D , E , F , V1 , V2 }. Using a reverse
topological elimination ordering implies we first have to eliminate E, which generates the
set


1 = max [E , V1  V2 ]E = {(1, u1 )} ,

whose single element (1, u1 ) has scope {A, C, D, F } and size 24 = 16. Eliminating variables
in the ordering F, C, B, A, D, E, on the other hand, generates the following sets.


1 = max [F  V2  C ]F = {(p1 , u1 )} ,


2 = max [C  E  1 ]C = {(p2 , u2 )} ,

 n
o
(d) (d)
3 = max [B  D ]B = (p3 , u3 ) : d  D ,

 n
o
(d) (d)
4 = max [A  V1  3 ]A = (p4 , u4 ) : d  D ,
 n
o

(d) (d)
5 = max [2  4 ]D = (p5 , u5 ) : d  D ,
 n
o

(d)
=
(1,
u
)
:
d


.
6 = max E
D
5
6
The scopes of the valuations in 1 , 2 , 3 , 4 , 5 and 6 are, respectively, {E, C}, {D, E},
{D, A}, {E, D}, {E} and {}. As one can see, the largest valuation generated using ordering
F, C, B, A, D, E contains two variables in its scope and therefore has size 22 = 4. This is
a four-fold decrease in size compared to the size of the set 1 generated using the reverse
topological ordering.
Notice however that even though using reverse topological ordering might increase the
size of the valuations generated during variable elimination, it does not necessarily results
in higher complexity for the MPU. This is because the overall complexity of the algorithm
depends not only on the size of the largest valuation generated but also on the cardinality of
the generated sets, and it is possible that a reverse topological ordering induces significantly
smaller sets, as it produces valuations whose probability parts are always equal to one, which
might increase the number of dominated elements.

4. Experiments
We evaluate the performance of the algorithm on random LIMIDs generated in the following
way. Each LIMID is parameterized by the number of decision nodes d , |D|, the number
of chance nodes c , |C|, the maximum cardinality of the domain of the family of a chance
variable C , maxC |faC |, and the maximum cardinality of the domain of the family of
a decision variable D , maxD |faD |. We set the number of value nodes v to be d + 2.
For each variable Xi , i = 1, . . . , c + d + v, we sample Xi to contain from 2 to 4 states.
Then we repeatedly add an arc from a decision node with no children to a value node
with no parents (so that each decision node has at least one value node as children). This
step guarantees that all decisions are relevant for the computation of the MEU. Finally, we
repeatedly add an arc that neither makes the domain of a variable greater than the given
bounds nor makes the treewidth more than 10, until no arcs can be added without exceeding
123

fiMaua, de Campos, & Zaffalon

the bounds.6 Note that this generates diagrams where decision and chance variables have
at most log2 D  1 and log2 C  1 parents, respectively. Once the DAG is obtained, we
randomly sample the probability mass functions and utility functions associated to chance
and value variables, respectively.
We compare MPU against the CR algorithm of de Campos and Ji (2008) in 1620 LIMIDs
randomly generated by the described procedure with parameters 5  d  50, 8  c  50,
8  D  64 and 16  C  64. MPU was implemented in C++ and tested in the
same computer as CR.7 Table 1 contrasts the running times of each algorithm (averages 
standard deviation) for different configurations of randomly generated LIMIDs. Each row
contains the percentage of solved diagrams (SCR and SMPU ) and time performance (TCR
and TMPU ) of each of the algorithms for N diagrams randomly generated using parameters
d, c, v, D , and C . For each fixed parameter configuration, MPU outperforms CR by
orders of magnitude (line 12 contains the only case in which the average running time of
CR is lower than MPUs, but note that in this case CR solve it only one instance, whereas
MPU solved 86% of the instances). Also, CR was unable to solve most of the diagrams with
more than 50 variables, whereas MPU could solve diagrams containing up to 150 variables
and with D  32. Both algorithms failed to solve diagrams with D = 64. A diagram is
consider unsolved by an algorithm if the algorithm was not able to reach the exact solution
within the limit of 12 hours. All in all, MPU appears to scale well on the number of nodes
(i.e., on d, c and v) but poorly on the domain cardinality of the family of decision variables
(i.e., on D ).
A good succinct measure of the hardness of solving a LIMID is the total number of
strategies ||, which represents the size of the search space in a brute-force approach. ||
can also be loosely interpreted as the total number of alternatives (over all decision variables)
in the problem instance. Figure 6 depicts running time against number of strategies in a
log-log scale for the two algorithms on the same test set of random diagrams. For each
algorithm, only solved instances are shown, which covers approximately 96% of the cases
for MPU, and 68% for CR. We note that MPU solved all cases that CR solved (but not the
opposite). Again, we see that MPU is orders of magnitude faster than CR. Within the limit
of 12 hours, MPU was able to compute diagrams containing up to 1064 strategies, whereas
CR solved diagrams with at most 1025 strategies.
The reduction in complexity obtained by the removal of non-maximal valuations during
the propagation step can be checked in Figure 7, which shows the maximum cardinality of
a set i generated in the propagation step in contrast to the number of strategies. For each
diagram (a point in the figure) solved by MPU, the cardinality of the sets remains bounded
above by 106 while we vary the number of strategies (which equals the largest cardinality
of a propagated set in the worst case where no valuation is discarded). This shows that the
worst-case analysis in Section 3.7 is very pessimistic.
6. Since current algorithms for checking whether the treewidth of a graph exceeds a fixed k are too slow
for k  5 (Bodlaender, 1996), we resort to a greedy heuristic that resulted in diagrams whose actual
treewidth ranged from 5 to 10.
7. We used the CR implementation available at http://www.idsia.ch/~cassio/id2mip/ and CPLEX
(http://www.ilog.com) as mixed integer programming solver. Our implementation of MPU can be
downloaded at http://www.idsia.ch/~cassio/mpu/.

124

fiSolving LIMIDs

N

d

c

v

D

C

SCR (%)

TCR (s)

SMPU (%)

TMPU (s)

60
60
60
60
60
60
60
60
30
30
60
30
30
60
60
90
30
60
30
30
60
60
30
60
60
60
60
30
60
30
30
30
30

5
5
5
10
10
10
10
10
10
10
10
10
10
10
20
20
20
20
20
20
20
10
10
20
20
20
30
30
30
30
30
50
50

8
8
8
8
8
8
28
28
28
28
28
28
28
28
8
8
8
8
8
8
8
78
78
58
58
58
38
38
38
88
88
48
48

7
7
7
12
12
12
12
12
12
12
12
12
12
12
22
22
22
22
22
22
22
12
12
22
22
22
32
32
32
32
32
52
52

12
16
8
12
16
8
12
16
16
32
32
32
64
8
12
16
16
32
32
64
8
16
32
12
16
8
12
16
8
12
8
12
8

16
16
16
16
16
16
16
16
64
16
32
64
64
16
16
16
64
32
64
64
16
16
16
16
16
16
16
16
16
16
16
16
16

100
100
100
98
93
100
96
83
10
93
0
3
0
100
93
38
30
0
0
0
100
60
70
50
11
96
28
0
96
0
60
0
10

6  45
9  43
6  51
15  53
107  273
0.4  0.2
1175  6126
3340  8966
2838  1493
1070  2461

73  0

13
2687  7564
5443  10070
9660  10303



7  20
5944  9920
3820  8127
6455  9344
11895  12662
849  4098
3416  4827

2261  6572

3448  5837

5014  2974

100
100
100
100
100
100
100
100
96
100
93
86
0
100
100
98
100
78
76
0
100
100
100
100
100
100
98
100
100
100
100
96
100

0.006  0.01
0.02  0.05
0.002  0.01
0.02  0.02
103  786
0.007  0.01
0.05  0.08
0.2  0.2
47  142
0.2  0.4
905  2847
2440  7606

0.01  0.007
155  1196
270  1822
29  84
938  1417
1592  3402

0.02  0.008
0.5  0.5
0.6  1
522  4011
2  11
0.07  0.04
35  214
2  10
0.1  0.03
230  1027
0.2  0.1
1753  7405
0.5  0.09

Table 1: Performance of MPU and CR on randomly generated LIMIDs (numbers are
rounded down).

125

fiMaua, de Campos, & Zaffalon

105

MPU
CR

Running time (s)

104
103
102
101
100
101
102
101

1020
1040
1060
Number of strategies (||)

Maximum set cardinality (maxi |i |)

Figure 6: Running time of MPU and CR on randomly generated LIMIDs.
106
105
104
103
102
101
100
101

1020
1040
1060
Number of strategies (||)

Figure 7: Maximum number of valuations in a set during the propagation step of MPU.

5. Related Work
Influence diagrams were introduced by Howard and Matheson (1984) as a concise language
for the specification of utility-based decision problems. There is a substantial literature that
formalizes influence diagrams and develop algorithms under the premises of no forgetting
and regularity (Cooper, 1988; Qi & Poole, 1995; Shachter & Peot, 1992). We point the
interested reader to the works of Jensen and Nielsen (2007) and Koller and Friedman (2009).
Zhang et al. (1994) studied families of LIMIDs that could be solved by dynamic programming, such as LIMIDs respecting no forgetting and regularity. The SPU algorithm
of Lauritzen and Nilsson (2001) solves these cases in polynomial time if the diagram has
126

fiSolving LIMIDs

bounded treewidth. To the best of our knowledge, the only attempt to (globally) solve arbitrary LIMIDs exactly without recurring to an exhaustive search on the space of strategies
is the CR algorithm of de Campos and Ji (2008) against which we compare our algorithm.
Shenoy and Shafer (1990) introduced the framework of valuation algebras, which states
the basic algebraic requirements for efficient computation with valuations. More recently,
Haenni (2004) incorporated partially ordered preferences in the algebra to enable approximate computation. Fargier et al. (2010) then extended the framework with a preference
degree structure in order to capture the common algebraic structure of optimization problems based on a partial order. The algebra we develop in Section 3 can be partly casted in
this framework.
The PFU framework of Pralet, Verfaillie, and Schiex (2007) subsumes many formalisms
of probabilistic reasoning, constraint satisfaction and decision making. When it comes
to decision problems the framework is geared towards sequential decision making under
equivalent assumptions of non-forgetting, although the authors mention the possibility of
extending it to limited information decision scenarios.
The variable elimination algorithm we develop here is conceptually close to the message
passing algorithm of Dubus, Gonzales, and Perny (2009). Their algorithm, however, does
not handle uncertainty and target primarily the obtention of Pareto-efficient solutions for
a specific class of multi-objective optimization problems.
There is a close relation between maximum a posteriori (MAP) inference in Bayesian
networks and LIMIDs whose decision variables have no parents. In this sense, the algorithm of de Campos (2011), which solves MAP by propagating Pareto efficient probability
potentials in a join tree, relates to ours.

6. Conclusion
Solving limited memory influence diagrams is a very hard task. The complexity results
presented here show that the problem is NP-hard even for diagrams with bounded treewidth
and number of states per variable, and that obtaining provably good approximations in
polynomial time is unlikely if the number of states is not small.
Despite the theoretical hardness of the problem, we developed an algorithm that in
spite of its exponential worst-case complexity performed empirically well on a large set of
randomly generated problems. The algorithms efficiency is based on the early removal of
suboptimal solutions, which helps the algorithm to drastically reduce the search space.
Designing good heuristics for elimination orderings with our algorithm seems to be
a more complex task than with standard variable elimination algorithms (e.g., for belief
updating in Bayesian networks), because there is a second component, the cardinality of a
set, that together with domain cardinalities we wish to minimize. In fact, some preliminary
experimentation has shown that favoring set cardinality at expense of domain cardinality
might be a good approach. Unlike standard variable elimination, given an elimination
ordering and a LIMID, it does not seem to be possible to determine the true complexity
of MPU in advance (i.e., prior to running the algorithm). It is an open question whether
MPUs complexity can be estimated beforehand, and which heuristics for finding elimination
orderings perform better.
127

fiMaua, de Campos, & Zaffalon

Acknowledgments
This work was partially supported by the Swiss National Science Foundation (SNSF)
grants no. 200020 134759/1, 200020 137680/1 and 200020 132252, Hasler Foundation grant
no. 10030, and the Canton Ticino Computational Life Sciences Project. We thank the
reviewers for pointing us to related work and making a number of comments that helped
us improve the readability of the paper. A short version of this paper appeared in NIPS
11 (Maua & de Campos, 2011).

Appendix A. Missing Proofs
This section contains long proofs and supporting results that were left out of the main part
of the text to improve readability.
The following two lemmas are used in the proof of Theorem 1 later on.
Lemma 23. If   2 is a real number and i is a nonnegative integer then 2 + 2(i+3) <
i
2+2 .
Proof. Since 2  22 , we have that 2 + 2(i+3) = 2 + 22  2i1  2 (1 + 2i1 ), and
i
it is sufficient to show that 1 + 2i1 < 22 . From the Binomial Theorem we have that
i

(1 + 2

i1 2i

)

=

2  i
X
2
k=0

k

(2i1 )k .

For k = 0, . . . , 2i , we have that
 i
2
2i (2i  1)    (2i  k + 1)
=
 (2i )k .
k
k!
Hence,
i

(1 + 2

i1 2i

)

i

2
2

X
X
X
i k i1 k
k

(2 ) (2
) =
2 
2k = 2 ,
k=0

2i

and therefore 1 + 2i1 < 2

k=0

k=0

.
4

Lemma 24. If 0  x  1/2 then 2x1 + 2x1  2x .
Proof. We obtain the result by approximating the functions on the left- and right-hand side
of the inequalities by their truncated Taylor expansions f (x) and g(x), respectively, and
4
then showing that 2x1 + 2x1  f (x)  g(x)  2x . The n-th order Taylor expansion of
the left-hand side around zero is given by
Tn (x) = 1 +

n/2
X
[ln(2)]2k
k=1

(2k)!

x2k .

Clearly, the series converges and hence 2x1 + 2x1 = limn Tn (x). Moreover, for any
n, the residual Rn (x) = 2x1 + 2x1  Tn (x) is positive because the terms of the sum are
128

fiSolving LIMIDs

all non negative. Thus,
f (x) = T2 (x) = 1 +

[ln(2)]2 2
x  2x1 + 2x1 .
2

In a similar fashion, we apply the variable change y = x4 on the right-hand side and
obtain its Taylor expansion around zero, given by
Tn0 (y) = 1 +
=1+

n
X
[ln(2)]k
k=1
n
X
k=1

k!

yk

[ln(2)]k 4k
x ,
k!

which also converges and has positive residual. Hence,
4

2x = lim Tn0 (x)
n

= 1 + x4 ln(2) + x2 ln(2)


X
[ln(2)]k1
k=2

 1 + x4 ln(2) + x2 ln(2)


X
k=2

= 1 + x4 ln(2) +

[ln(2)]2
32

1

k!
!

!
x4k2

24k1

x2 = g(x) .

The inequality is obtained by noticing that [ln(2)]k1 /k! < 1/2, x  1/2  ln(2) and that
the geometric series

X
k=2

1
24k1


 
  
1 X 1 k
1
ln(2)
1 X 1 k
< 7
= 6 <
.
= 7
4
2
2
2
2
2
32
k=0

k=0

Finally, since x2  1/4 < 15 ln(2)/32 we have that


ln(2)
2
g(x) = 1 + x ln(2) x +
32


15
ln(2)
2
< 1 + x ln(2)
ln(2) +
32
32
2
[ln(2)] 2
=1+
x = f (x) .
2
2

4

Hence, 2x  g(x)  f (x)  2x1 + 2x1 and the result holds.
The following result shows that solving LIMIDs is NP-hard even if we assume bounded
treewidth and number of states per variable.
129

fiMaua, de Campos, & Zaffalon

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 8: LIMID used to solve the partition problem in the Proof of Theorem 1.

Proof of Theorem 1. Given a strategy s, deciding whether Es [L] > k can be done in polynomial time (Koller & Friedman, 2009), so the problem is in NP. Hardness is shown using
a reduction from the partition problem, which is NP-complete (Garey & Johnson, 1979)
and can be stated as follows. PGiven a set
P of n positive integers a1 , . . . , an , is there a set
I  A = {1, . . . , n} such that iI ai = iA\I ai ? We assume that n > 3.
P
P
Let a = 21 iA ai . An even partition is a subset I  A that achieves iI ai = a.
To solve partition, we consider the rescaled problem (dividing every element
by a), so that
P
vP
i = ai /a  2 are the elements and we look for a partition such that
iI vi = 1 (because
v
=
2).
iA i
Consider the following LIMID with topology as in Figure 8. There are n binary decision
nodes labeled D1 , . . . , Dn . Each decision Di can take on states d1 and d2 . The chain of
chance nodes has n + 1 ternary variables X0 , X1 , . . . , Xn with states x, y, and z. There is
an arc from Xn to the single value node R. For notational purposes, we specify a function
f over the domain {x, y, z} as a triple (f (x), f (y), f (z)). The value node has an associated
utility function uR = (0, 0, 1). For i = 1, . . . , n, each chance node Xi has an associated set
of conditional probability mass functions given by
d1 ,x
= (ti , 0, 1  ti ),
pX
i

d2 ,x
= (1, 0, 0),
pX
i

pdX1i,y = (0, 1, 0),

pdX2i,y = (0, ti , 1  ti ),

pdX1i,z = (0, 0, 1),

pdX2i,z = (0, 0, 1),
DX

for ti  [0, 1] (we specify these variables later on). Note that pXii i1 (w) = 0 for every
w  faXi such that wXi 6= wXi1 and wXi 6= z. Finally, we define pX0 = (1/3, 1/3, 1/3).
Given a strategy s = (D1 , . . . , Dn ), let I , {i : Di = d1 } be the index set of policies
in s such that Di () = d1 . We have that
Es [L] =

X

pX0

CD

n
Y

!
DX
pXii i1 pDi

i=1


=

X

X

pX0


Xn

uR

n
Y


D Xi1

pXii

i=1

CD\{Xn }

Let
ps , pX0

n
Y

D Xi1

pXii

i=1

130

pDi

pDi  uR .

fiSolving LIMIDs

and
X

pXn ,

n
Y

pX0

D Xi1

pXii

i=1

CD\{Xn }

X

pDi =

ps .

CD\{Xn }
D Xn1

For w  CD such that wXn = x (i.e., for w  xCD ) it follows that pXnn
0 if and only if wXn1 = x. But for wXn1

(wfaXn ) 6=

D
Xn2
= x we have that pXn1
(wfaXn1 ) 6= 0
n1
DX
Also, for any i  {1, . . . , n}, pXii i1 (wfaXi )

if and only if wXn2 = x and so recursively.
equals ti if i  I and 1 otherwise. Hence,
( Q
1
ti , if wXi = x for i = 1, . . . , n  1
ps (w) = 3 iI
0,
otherwise,
and

n

1Y
ti .
ps (w) =
3
CD

X

pXn (x) =

iI

wx

Likewise, it holds for w  y CD that
( Q
ps (w) =

1
3

iA\I ti ,

0,

if wXi = y for i = 1, . . . , n  1
otherwise,

and therefore
pXn (x) =

n
1 Y
ti .
3
iA\I

Since pXn is a probability mass function on Xn , pXn (z) = 1  pXn (x)  pXn (y), and
X
pXn uR
Es [L] =
Xn

= 1  pXn (x)  pXn (y)
1Y
1 Y
=1
ti 
ti .
3
3
iI

iA\I

Let us assume initially that ti = 2vi . The reduction from the original problem in
this way is not polynomial, and we will use it only as an upper bound for the outcome of
the reduction we obtain later. It is not difficult
to see
P
P that Es [L] is a concave function of
v1 , . . . , vn that achieves its maximum at iI vi = iA\I vi = 1. Since each strategy s
defines a partition of A and vice-versa, there is an even partition if and only if MEU[L] =
1  1/3(1/2 + 1/2) = 2/3.
We will now show a reduction that encodes the numbers ti in time and space polynomial
in b, the number of bits used to encode the original problem. This part is in close analogy
with the last part of the proof of hardness of MAP in Bayesian networks by de Campos
(2011, Theorem 10).
By setting ti to represent 2vi with 6b + 3 bits of precision (rounding up if necessary),
that is, by choosing ti so that 2vi  ti < 2vi + i , where 0  i < 2(6b+3) , we have that
131

fiMaua, de Campos, & Zaffalon

2vi  ti < 2vi + 2(6b+3) , which implies (by using Lemma 23 with  = vi  2 and
6b
i = 6b) that 2vi  ti < 2vi +2 .
Assume that an even partition I exists. Then8
P
Y
6b
6b
5b
ti < 22 n iI vi = 21+2 n  21+2 ,
iI

Y

6b n

t i < 22

P

iA\I

vi

6b n

= 21+2

5b

 21+2

,

iA\I

and

5b


22
1  1+25b
5b
2
+ 21+2
=1
.
MEU[L] > 1 
3
3

(6)

5b

Let r be equal to 22
encoded with 5b + 3 bits of precision (and rounded up), that is,
5b
5b
2
2
(5b+3)
2
r<2
+2
, which implies (by Lemma 24 with  = 25b  2 and i = 5b)
that
5b
5b
5b
15b
4b
22
 r < 22 +2
= 22
< 22 .
(7)
The reduction is done by verifying whether MEU[L] > 1  r/3. We already know that an
even partition has an associated strategy which obtains an expected utility greater than
1  r/3, because of Equality (6) and the fact that r is rounded up. Let us consider the
case where an even partition does not exist. We want to show that in this case MEU[L] 
4b
1  22 /3, which by Inequality (7) implies MEU[L] < 1  r/3. Since there is not an even
partition, any strategy induces
a partition such
P
P that, for some integer a  c  a different
from zero, we have that iI ai = ac and iA\I ai = a+c, because the original numbers
ai are positive integers that add up to 2a. It follows that
Y
Y
ti +
ti = 2c/a1 + 2c/a1 .
iI

iA\I

The right-hand side of the equality is a function on c  {a, . . . , a}\{0}, which is symmetric
with respect to the y-axis (i.e., f (c) = f (c)) and monotonically increasing for c > 0.
Therefore, it obtains its minimum at c = 1. Hence,
Y
Y
ti +
ti  21/a1 + 21/a1 .
iI

iA\I

Since n > 3 implies a  2 (because the numbers ai are positive integers), we have by
Lemma 24 that
4
21/a1 + 21/a1  21/a .
Each number ai is encoded with at least log2 ai bits, and therefore b  log2 (a1 ) +    +
log2 (an ) = log2 (a1    an ). The latter is greater than or equal to log2 (a1 +    + an ), and
hence is also greater than log2 a. Thus, we have that a  2b , which implies a4  24b and
4
4b
therefore 1/a4  24b and 21/a  22 . Hence,
4b

21/a1 + 21/a1  22

.

8. Since the number of bits used to encode the partition problem must be greater than or equal to n, we
have that n/2b  n/b  1, and hence 2(j+1)b n < 2jb , for any j > 0.

132

fiSolving LIMIDs

Thus, if an even partition does not exist we have that


4b
Y
22
1 Y
ti   1 
MEU[L] = 1 
ti +
< 1  r/3 .
3
3
iI

iA\I

To summarize, we have built a LIMID L in polynomial time since each ti was specified
DX
using O(b) bits and there are n functions pXii i1 , each encoding 18 numbers (which are
either 1, 0 or ti ), and 2n + 2 variables with bounded number of states. We have shown that
there is a one-to-one correspondence between partitions of A in the original problem and
strategies of L, and that for a given rational r = f (b) encoded with O(b) bits the existence
of an even partition is equivalent to MEU[L] > 1  r/3.
The following lemma is used in the proof of Theorem 2. A similar result has been shown
by Park and Darwiche (2004, Lemma 9).
Lemma 25. For any x  1 it follows that x + 1/2 > 1/ ln(1 + 1/x).
Proof. Let f (x) = ln(1 + 1/x)  1/(x + 1/2). Then
f 0 (x) = 

x2

1
1
+ 2
,
+ x x + x + 1/4

which is strictly negative for x  1 since x2 +x < x2 +x+1/4. Hence, f (x) is a monotonically
decreasing function for x  1. Because limx f (x) = 0, f (x) is strictly positive in [1, ).
Thus, the result follows from ln(1 + 1/x) > 1/(x + 1/2), since x  1.
We now show that approximately solving LIMIDs of bounded treewidth for any given
minimum performance is NP-hard.
Proof of Theorem 2. We will show that for any fixed 0 <  < 1 the existence of a polynomial

time 2 -approximation algorithm for solving a LIMID would imply the existence of a
polynomial time algorithm for the CNF-SAT problem, which is known to be impossible
unless P=NP (Garey & Johnson, 1979). A very similar reduction was used by Park and
Darwiche (2004, Theorem 8) to show an analogous inapproximability result for maximum a
posteriori inference in Bayesian networks. Notice that for any 1 <  < 2 there is 0 <  < 1

such that  = 2 , hence the existence of an -approximation algorithm implies the existence

of a 2 -approximation, and it suffices for the desired result to show that the latter cannot
be true (unless P=NP).
A clause is a disjunction of literals, each literal being either a boolean variable or its
negation. We say that a clause is satisfied if, given an assignment of truth values to its
variables, at least one of the literals evaluates to 1. Thus, we can decide if a truth-value
assignment satisfies a clause in time linear in the number of variables. The CNF-SAT
problem is defined as follows. Given a set of clauses C1 , . . . , Cm over (subsets of ) boolean
variables X1 , . . . , Xn , is there an assignment of truth values to the variables that satisfies
all the clauses?
For a positive integer q that we specify later on, consider the LIMID obtained as follows
(the topology is depicted in Figure 9). For each boolean variable Xi we add q binary
133

fiMaua, de Campos, & Zaffalon

B1
Dn1

Sn1

Dn2

Bq
Dnq

Sn2

.
.
.
D11



B2

.
.
.

S11

D12

Snq

.
.
.
D1q

S12

S01

U

S1q
S0q

S02

Figure 9: Graph structure of the LIMID used in the proof of Theorem 2.

decision variables Di1 , . . . , Diq and q chance variables Si1 , . . . , Siq with domain {0, 1, . . . , m}.
Additionally, there are q clause selector variables S01 , . . . , S0q taking values on {1, 2, . . . , m},
q binary variables B 1 , . . . , B q , and a value node U with B q as parent. As illustrated in
Figure 9, the LIMID consists of q replicas of a polytree-shaped diagram over variables
D1j , . . . , Dnj , S0j , . . . , Snj , B j , and the probability mass functions for the variables B 1 , . . . , B q
are chosen so as to make the expected utility equal the product of the expected utilities of
each replica. In any of the replicas (i.e., for j  {1, . . . , q}), a variable Dij (i = 1, . . . , n)
represents an assignment of truth value for Xi and has no parents. The selector variables
S0j represent the choice of a clause to process, that is, S0j = k denotes clause Ck is being
processed, and by summing out S0j we process all clauses. Each variable Sij , for i =
j
1, . . . , n and j = 1, . . . , q, has Dij and Si1
as parents. The variables B j have Snj and, if
j > 1, B j1 as parents. For all j, we assign uniform probabilities to S0j , that is, pS j , 1/m.
0

For j = 1, . . . , q, we set the probabilities associated to variables S1j , . . . , Snj so that if Ck is
the clause selected by S0j then Sij is set to zero if Ck is satisfied by Di but not by any of
j
D1 , . . . , Di1 , and Sij = Si1
otherwise. Formally, for x  {S j ,Dj ,S j } we have that
i



1,




j j
D S
1,
p ji i1 (x) ,
Si
1,




0,

i

i1

j

j

if xSi = xSi1 = 0 ;
j

j

if xSi = 0 and xSi1 = k  1 and Xi = xDi satisfies Ck ;
j

j

if xSi = xSi1 = k  1 and Xi = xDi does not satisfy Ck ;
otherwise.

Notice that for S1j the first case never occurs since S0j takes values on {1, . . . , m}. For any
j
joint state configuration x of S0j , . . . , Snj , D1j , . . . , Dnj such that xS0 = k  {1, . . . , m} (i.e.,
j
clause Ck is being processed) and xSn = 0, it follows that
!
n
j
Y
Dij Si1
pS j
p j
pDj (x)
0

i=1

Si

i

equals 1/m only if for some 0 < i  n clause Ck is satisfied by Xi = xDi but not
j
by any of X1 = xD1 , . . . , Xi1 = xDi1 , variables S1j , . . . , Si1
all assume value k (i.e.,
134

fiSolving LIMIDs

j

j

j

j

xS1 =    = xSi1 = k), and xSi =    = xSn = 0. Otherwise, it equals 0. Hence, for
any (partial) strategy sj = (Dj , . . . , Dnj ) we have for x = 0 that
1




j
psS j (x)
n

 X

,

S j ,...,S j

pS j

0

n1

0

n
Y
i=1

j
Dij Si1

p

Sij



SAT (sj )
pD j 
(x)
=
,
i
m


j
D1j ,...,Dn

where SAT (sj ) denotes the number of clauses satisfied by the truth-value assignment of
j

Sn B
X1 , . . . , Xn according to sj . Each variable B j is associated to a function pB
j
for x  faBj ,

j
B j = xB j1 and xSn

= 0;
1, if x
j j1
j
j
pSBnj B (x) = 1, if xB = 0 and xSn 6= 0 ;


0, otherwise;

j1

such that

0

where for B 1 we assume xB = 1. Hence, we have for any joint state configuration x of
B 1 , . . . , B q , Sn1 , . . . , Snq that

q
1
B 1 =    = xB q = 1 and xSn

=    = xSn = 0;
1, if x
j j1
1
q
1

pSBnj B  (x) = 1, if xB =    = xB = 0 and xSn 6= 0;


j=1
0, otherwise.




q
Y

Finally, we set the utility functionu associated to U to return 1 if B q = 1 and 0
j j1
Q
1
q
1
otherwise. In this way, u qj=1 pSBnj B
(x) equals 1 if xB =    = xB = 1 and xSn =
q

   = xSn = 0 and zero otherwise. Thus, for any strategy s = (s1 , . . . , sq ), where sj =
Dj , . . . , Dnj , it follows that
1

Es [L] =

X

u

CD

=

q
Y

u

B 1 ,...,B q
1 ,...,S q
Sn
n

=

=

j1

pS j

0

j=1

X

X

j

pSBnj B
q
Y

j

pSBnj B

u

B 1 ,...,B q j=1
1 ,...,S q
Sn
n
q
Y
j
psS j (0) =
n
j=1

i=1

j1

j=1

q
Y

n
Y

p

j
Dij Si1

Sij

X

i

pS j

j
S0j ,...,Sn1
j
j
D1 ,...,Dn
j

Sn B
pB
j

j1

pD j

0

n
Y
i=1

p

j
Dij Si1

Sij

pD j
i

j

psS j

n

q
1 Y
SAT (sj ) .
mq
j=1

If the instance of CNF-SAT problem is satisfiable then there is an optimum strategy s
such that SAT (sj ) = m for all j, and MEU[L] = 1. On the other hand, if the instance
135

fiMaua, de Campos, & Zaffalon

is not satisfiable, we have for all j and strategy s that SAT (sj )  m  1, and hence
MEU[L]  (m  1)q /mq . For some given 0 <  < 1, let q be a positive integer chosen so

that 1/2 > mq /(m + 1)q . We show later on that q can be obtained from a polynomial

on the input. If the CNF-SAT instance is satisfiable, a 2 -approximation algorithm for
MEU[L] returns a value Es [L] such that
q 


m1 q
MEU[L]
m
>
,
Es [L] 
>
m+1
m
2 
where the rightmost strict inequality follows from m/(m + 1) > (m  1)/m. On the other
hand, if the CNF-SAT instance is not satisfiable, the approximation returns


m1 q
Es [L]  MEU[L] 
.
m


Hence, we can use a 2 -approximation algorithm to solve CNF-SAT by checking whether its
output E[L] > (m1)q /mq . Since q and m are positive integers, the test bound (m1)q /mq
can be obtained in polynomnial time.
It remains to show that the reduction is polynomial in the input. The LIMID contains
q(2n + 2) + 1 variables, each requiring the specification of at most 2(m + 1)2 numbers in
{0, 1/m, 1}. So , the number of numerical parameters in L, is polynomially bounded by
q(m + 1)2 (4n + 4) + 2. Therefore, it suffices to show that q is a polynomial on m and n. By
definition, q obeys


1 q
2

1+
> 2[q(m+1) (4n+4)+2] ,
m
which is equivalent to


1
q ln 1 +
m



> q  [(m + 1)2 (4n + 4) + 2] ln 2

[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 + m
! 1
1
[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 + m

 q 1 >

q>

Since (by Lemma 25) m + 1/2 > 1/ ln(1 + 1/m) and 2 > ln(2), it suffices to choose q such
that
 1
q > (2m + 1)[(m + 1)2 (4n + 4) + 2] 1 .
2+1



In other words, q is polynomially bounded by m 1 4n 1 . Therefore, if MEU[L] can

be approximated in polynomial time with an ratio no greater than 2 then we can solve
CNF-SAT in polynomial time.
The next result show that Transformation 6 preserves expected utility of strategies, and
that strategies can be easily mapped back and forward between original and transformed
diagrams.
136

fiSolving LIMIDs

paD =  j

X1

X2

T1

T2



Xj1

Xj

Xj+1

Tj1

Tj

Tj+1



Xm

chD

Tm

Figure 10: Reasoning of the proof of Transformation 6.

T ,pa

X

,T ,pa

Proof of Proposition 7. By looking at the definition of the functions pX11 D and pXii1 i D ,
for i = 2, . . . , m, we can see that when paD selects  j , that is, conditional on paD =  j ,
the variable Xj is independent of Xj1 and for i = 1, . . . , m, i 6= j, the variable Xi is
independent of Ti . In other words, we have that
T

Pr(Xj |Xj1 , Tj , paD =  j ) = Pr(Xj |Tj , paD =  j ) , pXjj .
and, for any i 6= j,
X

Pr(Xi |Xi1 , Ti , paD =  j ) = Pr(Xi |Xi1 , paD =  j ) , pXii1 .
We can visualize this situation by removing the arc from Xj1 to Xj and all the arcs from
Ti to Xi for i 6= j in the diagram of Figure 2(b) (the arcs leaving paD can also be removed
as we are conditioning on a value of paD ), which results in the diagram in Figure 10. Note
that in principle the case for j = 1 deserves special attention, as the X1 does not depend
on any other Xi variable, and the function associated to X1 slightly differ from others.
Nevertheless, a similar reasoning can be applied. We will omit the case for j = 1 for the
sake of simplicity.
It follows from the previous reasoning that


pXjm , Pr(Xm |paD =  j )
m
X
X
Y
T
X
=
(pX1 pT1 )(pXjj pTj )
pXii1 pTi
T1 ,...,Tm X1 ,...,Xm1

=

X

pTj

Tj

X

i=2,i6=j
T

pXjj

m
Y

X

i=j+1

Xj ,...,Xm1

X

pXi1
i

X1 ,...,Xj1

|
=

X
Tj

pTj

X
Xj ,...,Xm1

T

pXjj

m
Y

X

pXii1 .

i=j+1

137

pX1

j1
Y

X

pXi1
i

i=2

X

m
Y

pTi

T1 ,...,Tm \Tj i=1,i6=j

{z

=1

}

fiMaua, de Campos, & Zaffalon

X

When paD =  j , each function pXi1
for i 6= j equals the indicator function IXi =Xi1 , by
i
T

design, and pXjj = IXj =Tj . We thus have that

pXjm

=

X

X

pTj

Tj

m
Y

IXj =Tj

IXi =Xi1 .

i=j+1

Xj ,...,Xm1

For each term of the outer sum over Tj , the inner sum over Xj , . . . , Xm1 differs from zero
only when Tj = Xj = Xj+1 =    = Xm , in which case it equals one. Hence, we have that
X

pXjm =
pTj IXm =Tj
Tj

= pTj .
pa

Now consider a strategy s0 = (T1 , . . . , Tm , . . . ) for L0 , and let pXmD be a function that

equals pXjm for every value  j  paD . Let also D be a policy for the original decision
variable D in L such that D ( j ) = Tj for all j, and s be a strategy for L obtained by
substituting policies T1 , . . . , Tm with D in s0 . Finally, let pT1 , . . . , pTm be the distributions
pa
induced by the policies for T1 , . . . , Tm in s0 , and pD D be the distribution induced by D .
paD
Since for each value  j of paD we have that pXm ( j ) = pTj , and since by design Xm = D ,
pa
pa
it follows that pXmD = pD D . Hence, for each combination of policies T1 , . . . , Tm in L0 we
can derive a corresponding policy in L. The converse is also true: for each policy D we can
pa
pa
generate T1 , . . . , Tm such that pXmD = pD D (simply choose Ti = D ( j ) for all i). Thus,
there is a one-to-one correspondence between policies T1 , . . . , Tm and policies D , and a
pa
pa
one-to-one correspondence between the induced functions pXmD and pD D .
It remains to show that a combination of policies T1 , . . . , Tm and a corresponding policy
D induce the same expected utility. Let C 0 and D0 denote, respectively, the set of chance
and decision variables in L0 , and C and D the set of chance and decision variables in L.
Also, for a given strategy s for L, let
Y
pa
p0s ,
pX X .
CD\{D}
pa

Note that the above function is independent of the choice of policy D , and that ps = p0s pD D .
Given any strategy s0 for L0 we have that
X
X
Es0 [L0 ] =
ps0
uV
C 0 D0

=

X

V V

p0s

T ,pa
pX11 D

C 0 D0

m
Y

X
,T ,pa
pXii1 i D

i=2

m
Y

!
pTi

=

p0s

X

uV

V V

CD\{D}

X X
C 0 \C D0 \D

X

X

CD\{D} Xm

pa

pXmD p0s

X

m
Y

X

pXii1

i=2

{z

|
=

T ,paD

pX11

uV

V V

i=1

!
X

X

P
paD
= Xm pXm

uV

V V

138

,Ti ,paD

m
Y

pTi

i=1

}

fiSolving LIMIDs

=

X

X

pa

pD D p0s

X

ps

CD

X

uV

V V

CD\{D} D

=

X

uV

V V

= Es [L] ,
where s is the strategy for L obtained from s0 by substituting T1 , . . . , Tm with the corresponding policy D .

References
Bodlaender, H. L. (1996). A linear-time algorithm for finding tree-decompositions of small
treewidth. SIAM Journal on Computing, 25 (6), 13051317.
Cooper, G. F. (1988). A method for using belief networks as influence diagrams. Fourth
Workshop on Uncertainty in Artificial Intelligence.
de Campos, C. P. (2011). New results for the MAP problem in Bayesian networks. In
Proceedings of the 22nd International Joint Conference on Artificial Intelligence, pp.
21002106.
de Campos, C. P., & Ji, Q. (2008). Strategy selection in influence diagrams using imprecise probabilities. In Proceedings of the 24th Conference in Uncertainty in Artificial
Intelligence, pp. 121128.
Dechter, R. (1999). Bucket elimination: A unifying framework for reasoning. Artificial
Intelligence, 113 (1-2), 4185.
Detwarasiti, A., & Shachter, R. D. (2005). Influence diagrams for team decision analysis.
Decision Analysis, 2, 207228.
Dubus, J.-P., Gonzales, C., & Perny, P. (2009). Multiobjective optimization using GAI
models. In Proceedings of the 21st International Joint Conference on Artificial Intelligence, pp. 19021907.
Fargier, H., Rollon, E., & Wilson, N. (2010). Enabling local computation for partially
ordered preferences. Constraints, 15, 516539.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory
of NP-Completeness. W. H. Freeman.
Haenni, R. (2004). Ordered valuation algebras: a generic framework for approximating
inference. International Journal of Approximate Reasoning, 37 (1), 141.
Howard, R. A., & Matheson, J. E. (1984). Influence diagrams. In Readings on the Principles
and Applications of Decision Analysis, pp. 721762. Strategic Decisions Group.
Jensen, F. V., & Nielsen, T. D. (2007). Bayesian Networks and Decision Graphs (2nd
edition). Information Science and Statistics. Springer.
Kohlas, J. (2003). Information Algebras: Generic Structures for Inference. Springer-Verlag,
New York, USA.
139

fiMaua, de Campos, & Zaffalon

Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press.
Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with
limited information. Management Science, 47, 12351251.
Maua, D. D., & de Campos, C. P. (2011). Solving decision problems with limited information. In Advances in Neural Information Processing Systems 24, pp. 603611.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2011). Solving limited memory influence
diagrams. ArXiv:1109.1754v2 [cs.AI].
Park, J. D., & Darwiche, A. (2004). Complexity results and approximation strategies for
MAP explanations. Journal of Artificial Intelligence Research, 21, 101133.
Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. In Advances in Neural
Information Processing Systems 16 (NIPS).
Pralet, C., Verfaillie, G., & Schiex, T. (2007). An algebraic graphical model for decision with
uncertainties, feasibilities, and utilities. Journal of Artificial Intelligence Research, 29,
421489.
Qi, R., & Poole, D. (1995). A new method for influence diagram evaluation. Computational
Intelligence, 11, 498528.
Shachter, R. D., & Peot, M. A. (1992). Decision making using probabilistic inference methods. In Proceedings of the 8th Conference on Uncertainty in Artificial Intelligence,
pp. 276283.
Shenoy, P., & Shafer, G. (1990). Axioms for probability and belief-function propagation.
In Proceedings of the 4th Conference on Uncertainty in Artificial Intelligence, pp.
169198.
Zhang, N. L., Qi, R., & Poole, D. (1994). A computational theory of decision networks.
International Journal of Approximate Reasoning, 11 (2), 83158.

140

fi