journal of artificial intelligence research                 

submitted        published      

heuristic search when time matters
ethan burns
wheeler ruml

eaburns at cs unh edu
ruml at cs unh edu

department of computer science
university of new hampshire
durham  nh       usa

minh b  do

minh b do at nasa gov

planning and scheduling group
sgt inc 
nasa ames research center
moffett field  ca       usa

abstract
in many applications of shortest path algorithms  it is impractical to find a provably
optimal solution  one can only hope to achieve an appropriate balance between search
time and solution cost that respects the users preferences  preferences come in many
forms  we consider utility functions that linearly trade off search time and solution cost 
many natural utility functions can be expressed in this form  for example  when solution
cost represents the makespan of a plan  equally weighting search time and plan makespan
minimizes the time from the arrival of a goal until it is achieved  current state of theart approaches to optimizing utility functions rely on anytime algorithms  and the use
of extensive training data to compute a termination policy  we propose a more direct
approach  called bugsy  that incorporates the utility function directly into the search 
obviating the need for a separate termination policy  we describe a new method based on
off line parameter tuning and a novel benchmark domain for planning under time pressure
based on platform style video games  we then present what we believe to be the first
empirical study of applying anytime monitoring to heuristic search  and we compare it
with our proposals  our results suggest that the parameter tuning technique can give the
best performance if a representative set of training instances is available  if not  then bugsy
is the algorithm of choice  as it performs well and does not require any off line training 
this work extends the tradition of research on metareasoning for search by illustrating the
benefits of embedding lightweight reasoning about time into the search algorithm itself 

   introduction
many problems in artificial intelligence can be formulated as shortest path problems  which
can be solved using heuristic search algorithms such as a   hart  nilsson    raphael 
       unfortunately  because state spaces often grow exponentially with problem size  it is
usually infeasible to find optimal solutions to shortest path problems of practical interest 
instead  practitioners tend to settle for suboptimal solutions  which can often be found more
efficiently but will be more expensive to execute  one is left with the choice of spending a
long time searching for a cheap solution  or a little time searching for an expensive one  we
argue for a new approach that is not strictly concerned with optimizing solution cost  but
with optimizing a utility function given in terms of both solution cost and search time  with
c
    
ai access foundation  all rights reserved 

fiburns  ruml    do

such a utility function  a user can specify a preference between search time and solution
cost  and the algorithm handles the rest 
we consider utility functions given as a linear combination of search time and solution
cost  this is an important form of utility function for two reasons  first  it is easily elicited
from a user if not already explicitly in their application domain  for example  if cost is
given in monetary terms  it is usually possible to ask how much time one is willing spend to
decrease the solution cost by a certain amount  second  if the solution cost is given in terms
of time  i e   the cost represents the time required for the agent to execute the solution   then
this form of utility function can be used to optimize what we call goal achievement time 
by weighting search time and execution time equally  a utility aware search will attempt to
minimize the sum of the two  thus attempting to behave such that the agent will achieve
its goal as quickly as possible 
most existing techniques for this problem are based on anytime algorithms  dean  
boddy         a general class of algorithms that emit a stream of solutions of decreasing
cost until converging on an optimal one  with sufficient knowledge about the performance
profile of an anytime algorithm  which represents the probability that it will decrease its
solution cost by a certain amount given its current solution cost and additional search time 
it is possible to create a stopping policy that is aware of the users preference for trading
solving time for solution cost  hansen   zilberstein        finkelstein   markovitch        
there are two disadvantages to using anytime algorithms to trade off solving time for
solution cost  the first is that the profile of the anytime algorithm must be learned off line
on a representative set of training instances  in many settings  such as domain independent
planning  the problem set is unknown  so one cannot easily assemble a representative training set  also  it is often not obvious which parameters of a problem affect performance so
it can be difficult to tell if a problem set is representative  even if an instance generator
is available  the instances that it generates may not represent those seen in the real world 
the second issue is that  while the stopping policy is aware of the users preference for time
and cost  the underlying anytime algorithm is oblivious and will emit the same stream of
solutions regardless of the desired trade off  the policy must simply do the best that it can
with the solutions that are found  and the algorithm may waste a lot of time finding many
solutions that will simply be discarded  only the search algorithm itself is fully aware of
the possible candidate solutions that are available and their relative estimated merits 
this paper presents four main contributions  first  we combine anytime heuristic search
with the dynamic programming based monitoring technique of hansen and zilberstein
        to the best of our knowledge  we are the first to apply anytime monitoring to
anytime heuristic search  second  we present a very simple portfolio based method that
estimates a good parameter to use for a bounded suboptimal search algorithm to optimize
a given utility function  third  we present bugsy  a best first search algorithm that does
not rely on any off line training  yet accounts for the users preference between search time
and solution cost   one important difference between bugsy and most previous proposals
for trading off deliberation time and solution cost is that bugsy considers the trade off directly in the search algorithm  whereas previous techniques  such as those based on anytime
algorithms  only consider the trade off externally to the actual search algorithm  finally 
   a previous version of bugsy was proposed by ruml and do         see appendix a for a discussion of
the improvements incorporated in the version presented here 

   

fiheuristic search when time matters

we present the results of a set of experiments comparing the portfolio based method  anytime monitoring  and bugsy  along with utility oblivious algorithms such as a  and greedy
best first search  real time search algorithms  and decision theoretic a   dta   russell  
ericwefald         a previously proposed utility aware search  while there has been much
work discussing the trade off between deliberation and solution cost  to the best of our
knowledge we are the first to implement and thoroughly evaluate many of these ideas in the
context of heuristic search 
the results of our experiments reveal two surprises  first  if a representative set of
training instances is available  the most effective approach is the very simple technique of
selecting a bound to use for a bounded suboptimal search  surprisingly  this convincingly
dominates anytime algorithms with monitoring in our tests  second  neither bugsy or
anytime search with monitoring dominates the other  bugsy does not require any off line
training  yet surprisingly  bugsy can perform as well as the methods that use training data 
if a representative problem set is not available  then bugsy is the algorithm of choice  this
work extends the tradition of research on metareasoning for planning by illustrating the
benefits of embedding lightweight reasoning about time into the search algorithm itself 

   background
in this section we briefly describe heuristic search  present some terminology used in the
remainder of this paper  and discuss the type of utility functions we are addressing 
    heuristic search
as considered in this paper  heuristic search is a technique for finding the shortest path
between nodes in a weighted graph  many problems can be specified in this form  since it
is typical for these graphs to be much too large to represent explicitly  algorithms usually
generate the graph lazily using a function called expand  the expand function returns the
successors of a node in the graph  we call the process of evaluating the expand function on
a node expanding the node  and when expanding a node we say that we are generating its
successors 
a   hart et al         is probably the best known heuristic search algorithm  it maintains two sets of nodes  the open list contains the frontier nodes that have been generated
but not yet expanded  and the closed list contains nodes that have already been expanded
 a common optimization is is for the closed list to also include nodes that are already on the
open list too   and therefore represent duplicate states if encountered again  the open list
is sorted on f  n    g n    h n   where g n  is the cost of the path from the initial node to
node n  and h n  is the heuristic estimate of the cheapest path cost from n to any goal node
reachable from n  the algorithm proceeds by removing a node with the minimum f value
from the open list  expanding it  putting its children on the open list  and putting the node
on the closed list  if a  removes a goal node from its open list  then it stops searching and
returns the path to the goal as the solution  finally  if the heuristic never over estimates
the cost to go then it is called admissible  with an admissible heuristic  a  returns optimal
solutions 
dechter and pearl        prove that if the heuristic satisfies a property called consistency
 for all nodes n and m  h n   h m    c n  m   where c n  m  is the cost of the cheapest
   

fiburns  ruml    do

path between n and m   then a  expands the fewest possible nodes required to prove the
optimality of its solution with the given heuristic  in practice a  often takes too long
 helmert   roger         thus given its optimal efficiency it is infeasible to look for optimal
solutions to many problems  instead  one must settle for suboptimal solutions  with the
hope that it is possible to find a sufficiently cheap solution within a reasonable amount of
time and memory 
    suboptimal search
greedy best first search  michie   ross        is a popular suboptimal search algorithm 
it proceeds like a   but orders its open list only on the heuristic  h n   with the idea that
remaining search effort correlates with remaining solution cost  in other words  it assumes
that it will be easier to find a path to the goal from nodes with low h  when strictly
attempting to minimize search time  thayer and ruml        show that greedy best first
search on a different heuristic  d  can be more effective  instead of estimating cost to go  as
is done by traditional h functions  the d heuristic  called a distance estimate  estimates the
number of remaining search nodes on the path to the cheapest solution beneath a node  in
practice  distance estimates are as readily available as cost to go heuristics and can provide
much better performance when used in greedy best first search on domains where less cost
to go is not directly correlated with less search to go  we call greedy best first search using
the d heuristic speedy search  in analogy to greedy search 
while greedy best first search can find solutions very quickly  there is no bound on the
cost of its solutions  bounded suboptimal search algorithms remedy this problem  weighted
a   pohl        is perhaps the most common of these techniquesit proceeds just like a  
but it orders the open list on f   n    g n    w  h n   with w     the weighting parameter 
w  puts more emphasis on the heuristic estimate than the cost of arriving at a node  thus
it is greedier than a  and it often finds suboptimal solutions much faster than a  finds
optimal ones  in addition  the weight provides a bound on the suboptimality of its solutions 
the solutions are no more than w times the cost of the optimal solution  pohl         unlike
greedy best first search  weighted a  lets the user select a weight  allowing it to provide
either cheaper solutions or faster solutions depending on their needs 
we refer the reader to the work of thayer        for a more in depth study of suboptimal
and bounded suboptimal search algorithms  including many that use d heuristics 
    utility functions
so far  we have described a   which optimizes solution cost  bounded suboptimal search 
which finds solutions within a constant factor of optimal  and greedy best first search  which
attempts to minimize solver time  often  none of these are really desired  optimal solutions
require an impractical amount of resources  one rarely requires solutions strictly within a
given bound of optimal  and unboundedly suboptimal solutions are too costly  instead  we
propose optimizing a simple utility function given as a linear combination of search time
and solution cost 
u  s  t     wf  g   s    wt  t 
   
where s is a solution  g   s  is the cost of the solution  t is the time at which the solution is
returned  wf and wt are user specified weights used to express a preference for trading off
   

fiheuristic search when time matters

search time and solution cost  the number of time units that the user is willing to spend to
achieve an improvement of one cost unit is wf  wt   this quantity is usually easily elicited
from users if it is not already explicit in the application domain  the cost of the empty
solution  g        is a user specified value that defines the utility achieved in the case that
the search gives up without returning a solution
a linear utility function has two main benefits  first  they are fairly expressive  for
example  one can optimize for cost if the both the solution and search time are given in
monetary terms  this situation can occur in cloud computing environments where computation time costs money  a linear utility function can also capture optimal or greedy search
by using   for the weight on execution time and solution cost respectively  additionally  a
linear utility function can express goal achievement time by weighting search time equally
with solution makespan  some practical examples where minimizing goal achievement time
is desired include robotic and video game pathfinding problems  in these settings  a user
often does not care about optimal solutions if they take too long to find  they may only
care about achieving the goal as quickly as possible 
as a demonstration of minimizing goal achievement time  we have made a video of
a   speedy search  and bugsy solving a pathfinding video game pathfinding problem 
it is available in the online appendix of this paper or on the web  http   youtu be 
yluf  v plu  the video includes three panels  each showing an agent using a different
search algorithm  since they do not focus on finding cost optimal solutions  both the
speedy and bugsy agents begin moving almost immediately  the a  agent stands still for
a long time while it plans an optimal path  and it doesnt start moving until after bugsy
has arrived at the goal  while all of this is occurring  the speedy agent is following an
extremely circuitous path  it doesnt reach the goal until approximately    seconds after
a   we didnt show these agonizing seconds in the video  and instead stopped the recording
as soon as a  reached the goal  clearly  the bugsy agent  which optimizes goal achievement
time  not solution cost or search time  is preferred in this scenario 
while quite expressive  linear utility functions are also rather simple  one main benefit
of the simplicity is that  with a fixed utility function  the passage of time decays all utility
values at the same rate  this simplification allows us to ignore all time that has passed before
the current decision point  we can then express utility values in terms of the utility of each
outcome starting at the current moment in time  without this benefit  the mere passage
of time would change the relative ordering between the utilities of different outcomes  we
would need to re compute all utility values at every point in time in order to select the best
outcome 
we only consider linear utility functions in this work  but it should be noted that one
could consider other more expressive functions  step functions  for example  can represent
deadlines where after a certain amount of time has elapsed the utility of acting greatly
decreases  bugsy does not support such functions  but the anytime monitoring technique
discussed in section     has no restrictions on the utility functions that it can optimize 
anytime monitoring can naturally handle more expressive functions  like step functions 

   previous work
next we describe some previous techniques for trading off solver time for solution cost 
   

fiburns  ruml    do

    monitoring anytime algorithms
much previous work in optimizing utility functions of solving time and cost  such as equation    has focused on finding stopping policies for anytime algorithms  anytime algorithms
 dean   boddy        are a general class of algorithms that find not one solution  but
a stream of solutions with strictly decreasing cost  they get their name because one can
stop an anytime algorithm at any time to get its current best solution  anytime algorithms
are an attractive candidate for optimizing a utility function  since there is more than just
a single solution from which to pick  there is more opportunity to choose a solution with
a greater utility than when using an algorithm that just finds a single solution  different
solutions will be found at different times  and if we knew the time at which the algorithm
would find each of its solutions and the cost of those solutions  then we could compute
their utilities and return the solution that maximizes utility  unfortunately  it is usually
not possible to know what solutions an anytime algorithm will return without running it 
instead  while the algorithm is running  one must continually make the decision  stop now 
or keep going 
deciding when to stop is no easy task  because the utility of a solution depends not only
on its cost but also on the time needed to find it  on one hand  stopping early can reduce
the amount of computation time at the expense of having a more costly solution  on the
other hand  if the algorithm continues  it may not reduce the solution cost by enough to
justify the extra computation time  in this case  the final utility can be worse than it would
have been had the algorithm stopped earlier  with a little extra information  however  it
is possible to create a reasonable policy 
the near optimal response time algorithm  nora  shekhar   dutta        provides
one very simple stopping policy for optimizing goal achievement time  nora  simply stops
the anytime algorithm when the current search time is a user specified factor of the current
incumbent solutions execution time  shekhar and dutta        prove that the  if the search
stops when the time is a factor  of the incumbent solution cost  then the goal achievement
time will be within a factor of min               of the optimal goal achievement time 
our use of nora is slightly different than that of shekhar and dutta         they
did not apply nora to anytime heuristic search  instead  they evaluated it empirically
on database query optimization problems  which are tree search problems  where every leaf
node is a possible solution  they also describe how one could use nora in an a  search 
but they make the assumption that if a  is stopped early without reaching the goal then
a heuristic planning procedure can be used to achieve the goal after executing the partial
solution found by a   such a procedure is often not available  when using nora with
anytime heuristic search  as we do here  each incumbent solution is guaranteed to reach
the goal  the only disadvantage is that  as with all anytime stopping policies  it cannot do
better than the best solution found by the utility oblivious anytime algorithm 
nora finds a solution within a specified bound on the optimal goal achievement time 
instead  hansen and zilberstein        present a dynamic programming based technique
for building an optimal stopping policy for any utility function  it requires one extra piece
of information  the profile of the anytime algorithm  hansen and zilberstein define the
profile as a probability distribution over the cost of the solution returned by the algorithm 
conditioned on its current solution cost and the additional time it is given to improve
   

fiheuristic search when time matters

its solution  p  qj  qi   t   where qj and qi are two possible solution costs and t is the
additional time  the profile allows for reasoning about how the solution cost may decrease
if the algorithm is given more time to improve it  while this requires extra knowledge  we
performed a small experiment  not shown here  and found that the optimal policy found
using dynamic programming performs better than the simpler nora technique 
hansen and zilbersteins technique monitors the progress of the anytime algorithm by
evaluating the stopping policy at discrete time intervals  if the algorithm considers stopping
every t time units  then the utility achievable at time t when the algorithms current
solution costs qi is 

u  qi   t 
if d   stop 
   
v  qi   t    max p
p
 q
 q
 
t v
 q
 
t
 
t 
if
d   continue
d
j i
j
j
and the stopping policy is 

 qi   t    argmax
d



u  qi   t 
if d   stop 
p
p
 q
 q
 
t v
 q
 
t
 
t 
if
d   continue
j i
j
j

   

where u is the user specified utility function and p is the profile of the anytime algorithm 
they also show a more sophisticated technique that accounts for the cost of evaluating the
policy  however  for the algorithms presented in this paper  the cost of evaluating the policy
consists of a mere array lookup and is essentially free 
since the profile of an anytime algorithm is usually not known  it must be estimated  it
is possible to estimate the profile off line if one has access to a representative set of training instances  to estimate the profile  the algorithm can be run on each of the training
instances and a   dimensional histogram can be created to represent the conditional probability distribution  p  qj  qi   t   needed to compute the stopping policy  cf  equation    
appendix c gives a more detailed description of our implementation of this procedure 
    anytime heuristic search
anytime algorithms are a very general class and there are many anytime algorithms for
heuristic search  likhachev  gordon    thrun        hansen   zhou        richter 
thayer    ruml        van den berg  shah  huang    goldberg        thayer  benton   
helmert         in this paper we use anytime repairing a   ara   likhachev et al        
since it tended to give the best performance over other approaches according to experiments
done by thayer and ruml         ara  executes a series of weighted a  searches  each
with a smaller weight than the previous  since the weight bounds the solution cost  the
looser bounds on early iterations tend to find costly solutions quickly  as time passes and
the weight decreases  so does solution cost  eventually converging to optimal  ara  also
has special handling for duplicates that are encountered during search that enables it to be
more efficient while still guaranteeing a bound on each of its solutions 
like most anytime heuristic search algorithms  ara  has parameters  before running
ara   the user must select the weight schedule  which is typically comprised of an initial
weight and the amount by which to decrement the weight after each solution is found  the
behavior of ara  varies with different weight schedules  for our experiments  we used
an initial weight of     and a decrement of       this schedule was used by likhachev
   

fiburns  ruml    do

a
 
   
h  
b
d  
d

 

h    
d  

h  
c
d  
   
 
e

figure    a small example graph 
et al          and we found that it gave the best performance when compared to several
alternative schedules on the domains we considered 
given a fixed weight schedule  an anytime heuristic search algorithm will emit a fixed
stream of solutions for a given problem instance  the algorithm does not take the users
utility function into account  the same solutions will be found regardless of whether the
user wants any solution as fast as possible or the optimal solution at all costs  figure  
shows a small  concrete example  where the goal is to find a path from node a to node e 
each node is labelled with its heuristic value  h  and the number of nodes remaining
to the goal  d   and edges are labelled with their costs  if the user wants an optimal
solution  then the algorithm would ideally return the path a  b  c  e  however  if the user
wants any solution as fast as possible  then it may be better to find the solution a  d  e 
as it has fewer nodes  and may be found in fewer expansions  ara  only considers cost 
not distance  so with an initial weight less than         the longer  cheaper  solution will be
found regardless of the users preference  it is up to the monitoring technique to select the
best that it can from the solutions that are found 
    contract search
dionne  thayer  and ruml        consider the problem of contract search  where a goal
must be returned by a hard deadline  unlike real time search  korf         where only the
agents next action must be ready by the deadline  contract search requires the algorithm to
return a complete path to a goal  like optimizing a utility function  contract search must be
aware not only of the cost of solutions but also of the amount of time required to find them 
while the conventional approaches to contract search use anytime algorithms  dionne et al 
       present deadline aware search  das  which considers search time directly 
the basic idea behind das is to consider only states that lead to solutions deemed
reachable within the deadline  two different estimates are used to determine this set of
nodes  an estimate of the maximum length solution path that the search can explore before
the deadline arrives  called dmax   and an estimate of the distance to the solution beneath
   

fiheuristic search when time matters

each search node on the open list  in other words d  states for which d  dmax   are deemed
reachable  all other states are pruned  the search expands non pruned nodes in best first
order on f   g   h  updating its dmax and d estimates on line  if the updates cause all
remaining nodes to be pruned while there is remaining time before the deadline  das uses a
recovery mechanism to repopulate the open list from the set of pruned nodes and continues
searching until the deadline is reached 
as mentioned previously  d estimates are as readily available as normal cost to go heuristics  h  for most domains  this leaves the question of how to estimate dmax   dionne et al 
       show that simply using the remaining number of possible expansions  computed via
the expansion rate and remaining time  is not appropriate due to a phenomenon that they
call search vacillation  when a best first search expands nodes  it typically does not expand straight down a single solution path  instead it considers multiple solution paths at the
same time  expanding some nodes from each  when it does this  it is said to be vacillating
between many different paths  and it may not return to work on a particular path until
it has performed many expansions along others  to account for vacillation  dionne et al 
introduce a metric called expansion delay that estimates the number of additional expansions performed by a search between the expansion of two successive nodes along a single
t
texp
path  they define dmax   rem
delay   where trem is the time remaining before the deadline 
texp is the average expansion rate  and delay is the average expansion delay  they compute
the average expansion delay by averaging the difference in the algorithms total expansion
count between when each node is expanded and when it was generated 
dionne et al         showed experimentally that das performs favorably to anytimebased approaches and alternative contract search algorithms  indicating that an approach
that directly considers search time may also be beneficial for utility function optimization 

   off line bound selection
we now turn to the first of the two new methods introduced in this paper 
in this section  we will present a very simple technique for trading search time for
solution cost that is based on bounded suboptimal search  recall that bounded suboptimal
search algorithms return solutions that are guaranteed to be within a user specified factor of
the optimal solution cost  in practice  few applications require an actual bound  instead the
bound is used by practitioners as a parameter that can be tweaked to speed up the search
if it is not finding solutions quickly enough  the fact that the bound can trade search time
for solution cost makes it a prime candidate for automatic parameter tuning  rice        
that is exactly what we propose 
as with the anytime methods discussed in the previous section  off line bound selection requires a representative set of training instances  the instances are used to gather
information about how a bounded suboptimal search trades off search time for solution
cost  the only other requirement is that the user select a set of diverse bounds to try as
parameters to the search algorithm  the algorithm is then run on each of the n training instances with each suboptimality bound  creating a list of n pairs for each bound 
sols b   h c    t           cn   tn  i where b is the bound passed as a parameter to the algorithm 
ci is the cost of the solution to the ith training instance and ti is the time at which the ith
solution was found  given a utility function u   cost  time  r  we can select the bound
   

fiburns  ruml    do

that gives the greatest expected utility on the training set 


x
 
bound u   argmax 

u  c  t 
 sols b  
b

   

 c t sols b  

in our experiments  we select a different weight to use for each utility function from the
set                            and     it may be possible to reduce the number of weights
in the training set by using linear interpolation to estimate the performance of parameters
between those used for training  this simple approach can also be extended to select over
a portfolio of different algorithms in addition to different bounds  it may be beneficial  for
example  to include both a  and speedy search in the portfolio  as these algorithms will
likely be selected if cheap solutions are required or if a solution must be found very quickly 
we will see in section   that this very simple technique outperforms ara  using an anytime
monitor in our experimental evaluation  in fact  if a representative set of training instances
is available  then this technique tends to perform better than all other algorithms that we
evaluate 
a related technique is the dove tailing method of valenzano  sturtevant  schaeffer  buro 
and kishimoto         their approach is presented as a way of side stepping the need for
parameter tuning by running all parameter settings simultaneously  they found that  with
dove tailing  weighted ida   korf        was able to return its first solution much faster 
as the dove tailing greatly reduced the high variance in solving times for any given weight 
they also found that dove tailing over different operator orderings was effective for ida  
the main difference between the work by valenzano et al  and ours is that we have quite
different goals  our concern is not to find the first solution more quickly  but rather to select
a setting that better optimizes a user specified utility function  as such  our approach does
not run multiple settings at the same time and instead selects a single parameter to run in
a single search  in fact  the approaches are complementary  given any of our utility aware
algorithms that have parameters  one could use dove tailing to avoid the need to perform
offline parameter selection 

   best first utility guided search
anytime search is not aware of utility  monitoring and bound selection require training  in
this section  we present bugsy    a utility aware search algorithm that does not require any
off line training 
    expansion order
like a   bugsy is a best first search  but instead of ordering its open list on f   bugsy
orders its open list on an estimate of the utility of the outcome resulting from each node
expansion  since utility is dependent on time  the mere passage of time affects the utility
values  this differs from most traditional search algorithms where the values used to order
expansions remain constant  recall  however  that when using a linear utility function 
all utility values decay at the exact same rate  given this  bugsy ignores all past time
   bugsy is an acronym for best first utility guided searchyes 

   

fiheuristic search when time matters

and compares the utility estimates assuming that time begins at the current decision point 
while these utility values will not match the utility of the ultimate outcome  they still
preserve relative order of the different choices that the agent can make 
to understand bugsys ordering function  we will first consider the best utility of the
outcome resulting from each node expansion as computed by an oracle  if we had foreknowledge of a maximum utility outcome  the only purpose of the search algorithm would be to
achieve it by expanding the nodes along the path from the initial node in order to build the
solution path  since our utility function is given as a linear combination of solution cost
and search time  the utility value of this outcome can be written in terms of the cost and
length of a  possibly empty  maximum utility outcome  s 
u     wf  g   s    wt  d  s   texp  

   

where g   s  is the cost of the path s  recall that the cost of the empty path is a user specified
constant   d  s  is the number of nodes on s  and texp is the time required to expand a node  
given the maximum utility value u    the best utility of the outcome resulting from
expanding a node n is 
 
u
if n leads to a maximum utility outcome

   
u  n   

u  wt  texp otherwise
in other words  the utility we get from expanding a node that leads to a maximum utility
outcome is the maximum utility  expanding any other node is simply a waste of time  and
has a utility of the maximum utility minus the cost of performing the unnecessary expansion 
in practice  we do not know the maximum utility  so we must rely on estimates  bugsy
uses two estimates to approximate the maximum utility  first  it estimates the cost of the
solution that it will find beneath each node as  f   note that f is an estimate  not only
because the heuristic is an estimate of the true cost to go  but also because the cheapest
solution beneath a node may not be the solution of greatest utility  see appendix a for
possible alternatives  second it estimates the number of expansions required to find a
solution beneath each node n  exp n   one crude estimate for remaining expansions is d 
the distance heuristic that estimates the remaining nodes on the solution path  in reality 
bugsy will experience search vacillation  as discussed earlier  expanding more nodes than
just those along a single solution path  to account for this vacillation  we use the expansion
delay technique of dionne et al         and we estimate exp n    delay  d n   that is  we
expect each of the remaining d n  steps to a goal will require delay expansions 
bugsy can either choose to expand a node  or it can stop and return the empty solution 
this is one way in which bugsy differs from a   bugsy decides among actions at the search
level  such as terminating the search  or expanding one of the many open nodes   whereas
a  is committed to expanding nodes in a fixed order  in bugsy each node on the open
list represents a possible outcome  so bugsys maximum utility can be estimated using the
maximum of the utility estimates of all open nodes and equation   


u   max max  wf  f  n    wt  d n   delay  texp    u        
   
nopen

   note that expansion time is not constant in general  because it includes time to add and remove elements
from data structures like the open list 

   

fiburns  ruml    do

bugsy initial   u   
   open   initial    closed    
   do
  
n  remove node from open with highest u n  value
  
if n is a goal  return it
  
add n to closed
  
for each of ns children c 
  
if c is not a goal and u c      or an old version of c is in open or closed
  
skip c
  
else add c to open
   
if the expansion count is a power of two
   
re compute u n  for all nodes on the open list using the most recent estimates
   
re heapify the open list
    loop to step  
figure    pseudo code for bugsy 
once the estimate u is found  it would be possible to substitute it for u  in equation  
to estimate u  n   the utility of the outcome from expanding each node on the open list 
however  bugsy is only going to expand one node  so there is no need to estimate u  n 
for each open node  bugsy simply expands the node with the best estimated outcome 
additionally  instead of computing the maximization in equation   from scratch each time
it is about to expand a node  bugsy simply orders its open list on u n     wf  f  n    wt 
d n delay texp    each iteration popping off the node with the maximum u n  for expansion 
in this way  the algorithm directly attempts to maximize utility 
recall figure    which shows two paths from an initial node  a  to a goal node  e 
because bugsy accounts for distance in its utility function  it will find the shorter path a 
d  e if their utility function sufficiently emphasizes finding solutions quickly over finding
cheaper solutions  on the other hand  if the utility function gives a preference to finding
cheap solutions then bugsy will spend the extra search time to find the cheaper path  a 
b  c  e 
    implementation
figure   shows high level pseudo code for bugsy  for clarity  the code elides the details of
computing u n  values  the algorithm proceeds like a   selecting the open node with the
highest u n  for expansion  line     if this node is a goal  then it is returned as the solution
 line     otherwise the node is put on the closed list  line    and its children are generated 
each new child is put onto the open list  line    except duplicate nodes and nodes for which
expansion is estimated to have a negative utility  which occurs when the utility of returning
no solution is greater than that of continuing the search   these are discarded  lines     
bugsy estimates the current expansion time and the expansion delay online  and these
estimates can change after each expansion  instead of re sorting the open list after each
expansion  bugsy re sorts whenever the number of nodes that it has expanded is a power
   

fiheuristic search when time matters

of two  the utility of each open node is re computed using the latest set of estimates for
texp and expansion delay  as described in section       and the open list is re heapified
 lines        we describe this re sorting step in greater detail in section     
    stopping
bugsy orders its open list in decreasing order of u n   and stops searching when the maximum estimated utility is less than that of returning the empty solution  while it may be
possible to continue searching in an anytime fashion after the first goal is found  from a
utility perspective this is not the correct approach  we prove that here 
theorem   assuming the expansion time texp is constant  h is admissible  and exp never
overestimates the expansions to go  at the time that bugsy finds its first solution  s  the
solutions bugsy would find beneath the remaining nodes would result in less utility than
immediately returning s 
proof  let t be the current time at which bugsy found solution s  the utility of returning
s is u  s  t     u  s     wf f   s  wt t    where u  s  is the utility of returning s now  and
f   s  is the cost of solution s  note that because h is admissible and s is a goal  h s      
g s    g   s   f  s    f   s   and therefore u s    u  s   also exp never overestimates the
expansions to go so exp s       since s was chosen for expansion u n   u  s  for every
node n on the open list 
let t n  be the minimum amount of additional time bugsy requires to find the solution
beneath any unexpanded node n  t n   texp since bugsy must at least expand n  so for
each node n on the open list  the best utility that bugsy could achieve by going straight
to the cheapest goal under n is 
u  n     wf  f   n    wt   t n    t   

  wf  f  n    wt   t n    t     since f  n   f   n  due to the admissibility of h

  wf  f  n    wt   exp n   texp   t     since exp never overestimates

  u n   by the definition of u n 

 u  s   since u  s    u s  and s was chosen for expansion  not n

this justifies bugsys strategy of returning the first goal node that it selects for expansion 
it should be noted that bugsys estimate of exp n    delay  d n  is not a lower bound  but
as we will see in the later sections  this stopping criterion performs quite well in practice 
    heuristic corrections
many best first search algorithms use admissible heuristic estimates that never overestimate
the true cost to go  the proof of optimality of a  and the proofs of bounded suboptimality
of bounded suboptimal search algorithms rely crucially on the admissibility property of the
heuristic  bugsy does not fixate on cost optimal solutions and does not guarantee bounded
cost  instead  bugsy attempts to optimize a utility function for which solution cost is only
one of two terms  since there are no strict cost guarantees  bugsy is free to drop the
admissibility requirement if more informed but inadmissible estimates are available 
   

fiburns  ruml    do

thayer  dionne  and ruml        show that inadmissible estimates can provide better
performance for bounded suboptimal search  one such technique attempts to correct the
heuristic estimates on line using the average single step error between the heuristic values
of a node and its best child  thayer et al  show that while this technique provides good
search guidance  it is actually less accurate at estimating the true cost to go values than
the standard admissible heuristics  for bugsy  this is undesirable  as it does not need
good guidance  but proper estimates  thayer et al  also show that learning the heuristic
off line with linear regression can provide more accurate estimates  unfortunately  using
such off line training would negate one of bugsys main benefits  it is a matter of empirical
evaluation as to whether any of these techniques will provide better performance for bugsy 
in section      we show that using the standard admissible heuristics often gives the best
performance anyway 
    resorting
instead of requiring off line training as in the previous approaches  bugsy uses on line
estimates to order nodes on its open list  first  while many analyses regard texp as as a
constant  it can in practice depend on log time heaps  cache behavior  and multiprogramming overhead  among other factors  so our implementation of bugsy estimates texp as
a global average computed during search  second  bugsys expansion delay estimate is
calculated as the global average of the difference in expansion count from when each node
was generated to when it was expanded  this too must be done on line  unfortunately  the
on line estimates may change at each node expansion  and navely using the latest estimates
to compute the u value for newly generated nodes can lead to poor performance  this is
due to the comparisons used to order the open list  instead of fair comparisons based on
the estimated utility of each node  the recent and very fresh estimates of new nodes will be
compared with the old and possibly more stale estimates of nodes that have been open for
a long time 
to alleviate this problem  our implementation of bugsy uses two sets of estimates 
one stable set used to order the open list  and one ever changing set maintaining the most
recent estimates  at certain points throughout the search  bugsy copies the most upto date estimates into the stable set  recomputes the utility values of all open nodes  and
re sorts the open list  our open list is implemented as a binary heap so it can re establish
the heap property in linear time in the number of elements on the heap  unfortunately  it
would still be very expensive to do this at every node expansion  so  instead  bugsy reorders
the open list exponentially less frequently as the search progressesit only reorders when
the number of expansions is a power of two  we prove that this logarithmic scheme only
adds a constant amount of overhead per expansion when amortized over the entire search 
theorem   in a search space that grows geometrically with a finite branching factor  the
overhead of reordering the open list on power of two expansions is constant for each expansion when amortized over the search 
proof  let b be the maximum branching factor  the maximum number of nodes that can
be on the open list after n expansions is n  n    bn  n   n b      the total cost of all
   

fiheuristic search when time matters

re sorting after n expansions is no more than 
lg n

x
i  

lg n
i

o n        

x
i  

o  i   b       by definition of n
lg n

  c b    

x

 i   for some c      by definition of o

i  
lg n  

  c b      

     by the identity

 c b         lg n    

pj

i
i    

   j     

  c b      n    

  o n 


so  the overhead per expansion is constant when amortized over all expansions  it is a
matter of empirical evaluation to determine if this constant overhead is detrimentalwe
address this in section     

   experimental evaluation
all the techniques discussed above involve approximations and estimations that may or may
not work well in practice  in this section  we present results of an experimental comparison
of the techniques to better understand their performance  all of these algorithms and
domains were implemented in c    the source code is available at https   github com 
eaburns search 
    overview
in the following sections  we answer several questions experimentally  first  we would like
to ensure that our monitored ara  algorithm is performing at its best by comparing the
profile learned off line with an oracle  as we will see  the off line profile  while only an
estimate of the true profile of the algorithm  is quite well informed 
in section      we proved that re sorting only adds a constant overhead per expansion
when amortized over the entire search  it is a matter of empirical evaluation to determine
whether or not the benefits outweigh this overhead  our experiments show that re sorting
with a logarithmic schedule greatly outperforms bugsy without re sorting 
in section     we pointed out that bugsy does not require admissible heuristic estimates 
and in fact it may perform better with inadmissible  but more accurate heuristics  we show
how bugsy performs with admissible heuristics  and with two different types of corrected
heuristics  overall  we conclude that the best configuration is bugsy with the standard
admissible heuristics 
we discussed expansion delay in section      we show results that demonstrate that
using expansion delay is better than simply using d as the estimate of expansions to the
goal  then we compare two variants of bugsy  one that ignores newly generated nodes
that are found to already be on the closed list  we call these duplicate nodes  and one
that reinserts these nodes onto the open list if they have better utility estimates than their
   

fiburns  ruml    do

previously closed version  ignoring duplicates always performs better in some domains  and
in others it performs better only when the preference is for very short search times 
then  we compare a   speedy search  monitored ara   weighted a  with a learned
weight  and bugsy  we find that the simplest approach of learning a good weight for
weighted a  gives the best performance  we also find that bugsy  which doesnt use
any off line training  performs about as well as monitored ara   which does use off line
training  therefore  if training instances are available  we recommend the simple weighted
a  approach where the weight is selected based on performance on the training set  if no
training instances are available bugsy is the algorithm of choice 
lastly  we compare bugsy to both real time search and dta  on the platform pathfinding domain  in both experiments  bugsy achieves the best utility 
    domains
in order to verify that our results hold for a variety of different problems  we performed our
experiments on four different domains  the domains that we used are described briefly in
the following paragraphs  with more detailed descriptions given in appendix b 
         puzzle
the    puzzle is a popular heuristic search benchmark that has a small branching factor
and few duplicates  for this domain  we used the reasonably informed manhattan distance
heuristic  and our implementation followed the heavily optimized solver presented by burns 
hatem  leighton  and ruml         we ran the     instances created by korf         and
in plots including a  we only use results on the    instances solvable by a  in  gb of
memory 
      pancake problem
the pancake problem is another standard puzzle with a large constant branching factor 
in our experiments  we used instances with    pancakes  and the gap heuristic  helmert 
       since many of these problems were too difficult for a   we used ida  instead of a 
on this domain 
      platform pathfinding
the platform domain is a pathfinding domain of our own creation with dynamics based on
a   dimensional platform style video game  where the player must jump between platforms
to traverse a maze  video games often naturally have an element of time pressure  it
has a large state space and many cycles  but a reasonably informed heuristic based on
visibility navigation  the instances used in our experiments were created randomly  using
the generator described in appendix b  this domain is also of particular interest because its
action costs are given in units of time  each action is   ms   so the objective of minimizing
goal achievement time can be expressed as a linear combination of search time and solution
cost 
   

fiheuristic search when time matters

      grid pathfinding
grid pathfinding is a popular heuristic search benchmark  motivated by robotics and video
games  in our experiments  we used two different cost models  and two different movement
models  the cost models were the standard unit cost model and the life cost model which
assigns action costs such that the shortest  most direct path is more expensive than a longer 
more circuitous path  this captures the popular adage that time is money  instances were
           grids with uniformly distributed obstacles  our heuristics were based on the
manhattan distance heuristic for four way grids  and the octile distance heuristic for eightway grids  the octile distance heuristic is a simple modification to manhattan
distance

that multiplies the shorter of the horizontal and vertical displacement by   to accounts
for eight way move costs 
    anytime profile accuracy
we want to ensure that our implementation works well and our training instance sets are
representative enough that monitored ara  can perform at its best  in this subsection  we
evaluate the accuracy of the stopping policies created using the estimated anytime profiles
by comparing them to an oracle  since the stopping policy is only guaranteed to be optimal
for the true algorithm profile  it is a matter of empirical study to determine whether or not
the estimated profile will lead to a good policy 
to estimate the profile used by the monitored version of ara   we ran ara  with a
 gb memory limit or until convergence on       separate test instances for each domain 
next  we created a histogram by discretizing the costs and times of each of the solutions into
       bins             we experimented with different utility functions by varying the
ratio wf  wt in equation    small values of wf  wt give a preference to finding solutions more
quickly  whereas large values prefer finding cheaper solutions  in the case of the platform
game  for example  this can be viewed as a way to change the speed at which the agent
moves  a slow agent might benefit from more search in order to find a shorter path  but a
fast agent can execute a path quickly  and may prefer to find any feasible solution as fast
as possible 
figure   shows the results of this experiment  the box plots represent the distribution
of utility values found by ara  using the estimated stopping policy  given as the factor of
the oracles utility  the oracle finds all solutions of the anytime algorithm until it converges
on the optimal solution  then it picks the solution which would have maximized the utility
function  since the utility values are negative  larger factors represent smaller  more negative  utilities and thus a worse outcome  the boxes surround the second and third quartiles 
the whiskers extend to the extremes  and circles show values that are more than     the
inter quartile range outside of the box  the center line of each box shows the median  and
the gray rectangles show the     confidence interval on the means  each box represents a
different wf  wt as shown on the x axis  there is a reference line drawn across at y      the
point where the oracle and estimated policy performed equally as well   and in many cases
the boxes are so narrow that they are indistinguishable from this line 
some points in these figures lie very slightly below the y     line  indicating instances
where the oracle performed worse than the estimated policy  this is possible due to the
variance in solving times  in our experiment  the ara  runs used to compute the oracles
   

fiburns  ruml    do

platform
factor of oracle

factor of oracle

   puzzle
 
   
   
 e  

 e    e    e  
cost time preference

 
 
 

 

 e  

 e  
 e  
 e  
cost time preference

  way unit grids

   pancake
factor of oracle

   

factor of oracle

 

   
   
 

    
    
 
    

 e  

 e    e    e  
cost time preference

 

 e  

 e    e    e  
cost time preference

  way unit grids

 

  way life grids
factor of oracle

factor of oracle

     
   
    
    

     
     
     

 e  

 e    e    e  
cost time preference

 

 e  

 e    e    e  
cost time preference

 

  way life grids
factor of oracle

     
     
     
 
 e  

 e    e    e  
cost time preference

 

figure    comparison of the optimal stopping policy and the learned stopping policy 
   

fi   puzzle

 

   

 

 
  

  

log   cost time preference

 

  

   

 
  

log   cost time preference

   

 
  

 

 

   

   

 
  

  

log   cost time preference

  

log   cost time preference

 

  way life grids
log   factor of best utility

   

  

  

log   cost time preference

no resort
resort

 

  way life grids
log   factor of best utility

  way unit grids
log   factor of best utility

  way unit grids

platform
   

log   factor of best utility

 

log   factor of best utility

log   factor of best utility

heuristic search when time matters

  

 

 
  

  

log   cost time preference

  

figure    bugsy  resorting the open list  circles  vs not  boxes  
utilities occasionally found solutions more slowly than the ara  runs using the estimated
stopping policy  in other words  it is caused by the non determinism inherent in a utility
function that depends on solving time  as is obvious in the figure  these instances are quite
rare and usually happened for small values of wf  wt   where miniscule time differences have
a large effect on utility 
from these results  we conclude that our monitored ara  implementation performs
quite well  as the stopping policy often stopped on the best solution available from those
emitted by the underlying anytime algorithm 
    to resort or not to resort 
in section     we proved that re sorting bugsys open list on power of two expansions only
added a constant overhead per expansion when amortized over the search  it is a matter of
empirical evaluation to determine whether or not this overhead is worth the effort  while
other re sorting schedules are possible  we only tried re sorting on power of two expansions 
figure   shows the utility achieved by bugsy both with and without re sorting  the
x axes show the wf  wt ratio determining the preference for solution cost and search time
on a log   scale  as with the previous plots  smaller values indicate a preference for faster
search times and larger values indicate a preference for cheaper solutions  the y axes show
the factor of the utility achieved by the best technique on each instance  again on a log  
scale  a y value of log         indicates the best utility achieved by any technique on a given
   

fiburns  ruml    do

instance  values greater than zero indicate less utility  points show the mean value over all
test instances with error bars giving the     confidence intervals  from these plots  we
can see that re sorting the open list led to significant improvements in all domains  on the
pancake puzzle  bugsy without re sorting was unable to solve any of the instances within
a  gb memory limit  in our remaining experiments  we always enable re sorting on an
exponential schedule 
    heuristic corrections
in section      we mentioned that bugsy does not require admissible heuristic estimates 
as it provides no guarantees on solution cost  in this section we compare bugsy using the
standard admissible heuristics to bugsy using both on line and off line corrected heuristics 
following thayer et al          our on line heuristic correction used a global average of the
single step heuristic error between each node and its best offspring  and our off line heuristic
was a linear combination of h  g  depth  and d  for each node  the coefficients for each term
in the off line heuristic were learned by solving a set of training problems and using linear
least squares regression 
the comparison is shown in figure    the plots are in the same style as figure    typically the on line correction technique performed worstsome times significantly worse
than the other two  we attribute this to its poor accuracy as observed by thayer et al 
        on some problems  such as the    puzzle and the   way unit cost grid pathfinding  the off line correction technique performed best  but in general the simple admissible
heuristics were the best or were competitive with the best  for the remainder of our experiments  we chose to use the simplest variant without any corrections as it did not require
any off line training  which is one of bugsys main benefits   and it was never the worst
and was often the best or near the best 
    expansion delay
in section     we described why simply using d as an approximation for exp n   the number
of nodes expanded to arrive at the goal beneath node n  is inaccurate  the search algorithm
does not expand just the nodes along the path to a goal  but instead it vacillates between
different solutions  to account for the search vacillation  we choose to estimate exp n   
delay  d n   where delay is the average expansion delaythe average number of nodes
expanded before the search makes progress along a single path to a goal  in this subsection 
we show experimentally that using expansion delay provides much better performance than
using d alone 
figure   shows two versions of bugsy  one that uses expansion delay  labelled with
exp  delay  and one that does not  labelled without exp  delay  it is clear from this
figure that using expansion delay is beneficial  also  we can see that on the right side of the
plots  where cheaper solutions are preferred to short search times  using expansion delay is
about the same as just using d by itself  this is because wf is relatively large compared to
wt for these utility functions  so the exp n  term has little influence on the utility estimates 
   

fiheuristic search when time matters

   puzzle

   

log   factor of best utility

log   factor of best utility

 

log   factor of best utility

   pancake

platform
online
none
offline

   

   

 

 
  

  

  

log   factor of best utility

log   factor of best utility

    

 
  

    

 
  

  

 

log   cost time preference
  way life grids

log   factor of best utility

  way life grids
log   factor of best utility

 

    

 

log   cost time preference

   

    

 
  

  

log   cost time preference
  way unit grids

    

  

  

 

log   cost time preference

  way unit grids

  

    

 
  

 

log   cost time preference

    

  

    

    

 
  

log   cost time preference

  

  

log   cost time preference

figure    bugsy  heuristic corrections 

    duplicate dropping
suboptimal search algorithms do not expand nodes in strict order of increasing f   consequently  they can expand a node  and later re generate the same node via a cheaper path 
we call such re generations duplicates  and when they are generated via cheaper paths we
say that they are inconsistent  because their current path cost  and subsequently the cost
of the paths to all of their descendants  is more expensive than necessary  likhachev et al  
       in the face of inconsistent nodes  a search algorithm can put the already expanded
node back on the open list with a cost that accounts for the new  cheaper path  when
the node comes to the front of the open list  it will be re expanded and the inconsistency
   

fiburns  ruml    do

platform

   

   

   pancake

   

log   factor of best utility

log   factor of best utility

log   factor of best utility

   puzzle

   

   

 

 
  

  

  

log   cost time preference

 

  

  

  

log   cost time preference

without exp  delay
with exp  delay

log   factor of best utility

log   factor of best utility

   

  

 

  

  

  

  

log   cost time preference

 

  way unit grids

 

   
   
   
 

  

  

  

log   cost time preference

 

  

  

  

log   cost time preference

  way life grids

 

  way life grids

   

log   factor of best utility

log   factor of best utility

   

 

  way unit grids
   

   

   

   

 

   

   

   

 
  

  

  

  

log   cost time preference

  

  

log   cost time preference

figure    bugsy  expansion delay 
will propagate through to all of its descendants  unfortunately  if there are a lot of such
inconsistencies  then the search algorithm can spend a lot of time re expanding the same
nodes over and over again  an alternative technique is to simply ignore the inconsistency
and drop all duplicate nodes when they are generated  dropping duplicates can reduce the
search effort needed to find a goal at the cost of finding more expensive solutions  whether
or not dropping duplicates is beneficial typically depends on the domain  thayer   ruml 
      
figure   shows a comparison of bugsy both with and without duplicate dropping  on
the platform  tiles  and pancake domains using duplicate dropping is nearly always better
than re expanding duplicates  on the grid pathfinding problems with the notable excep   

fiheuristic search when time matters

    

   

    

   pancake
log   factor of best utility

platform
log   factor of best utility

log   factor of best utility

   puzzle
   
   
   
   

    

    

 

 
  

  

  

log   cost time preference

 

 
  

  

  

log   cost time preference

duplicate reexpansion
duplicate dropping

    

    

 

  

  

  

 

    

    
    
 

  

  

  

log   cost time preference

 

  

  

  

log   cost time preference

 

  way life grids
log   factor of best utility

  way life grids
log   factor of best utility

  

log   cost time preference

  way unit grids
log   factor of best utility

log   factor of best utility

  way unit grids
    

  

 

   
   
   
 

     
     
     
 

  

  

  

  

log   cost time preference

  

  

log   cost time preference

figure    bugsy  duplicate dropping 

tion of   way life cost gridsre expanding duplicate nodes seems to give better performance
except where solutions are needed as quickly as possible  on the left hand side of the plots  
this is reasonable  because duplicate dropping tends to sacrifice solution cost in order to
reduce search time  note also  that the values on the y axes of these plots are very small  so
while the results are statistically significant  the difference between the two techniques on
the grid problems where duplicate re expansion performs better is quite small  in the next
section we will see that a  actually achieves the most utility in many of the cases where
duplicate re expansion outperforms duplicate dropping 
   

fiburns  ruml    do

platform

log   factor of best utility

log   factor of best utility

   puzzle
   

   

 

 
  

  

log   cost time preference

 

  

  

log   cost time preference

 

log   factor of best utility

   pancake
a
pee y
ugsy
a a

   

  

 
  

 

log   cost time preference

 

figure    comparison of techniques 

    comparing techniques
now that we understand the most promising configurations of the techniques we are studying  we can finally turn our attention to comparing them 
figures   and   show a comparison of the three different techniques for utility aware
search  these plots are larger than the previous plots to improve clarity  because they
have more lines  the plots include a   speedy search  bugsy  ara  with monitoring
 ara    and weighted a  with the weight chosen automatically for each different utility
function from the set                            and     wa    as we would expect  when the
preference was for shorter search times  on the left end of the x axis   a  performed poorly 
as it stubbornly stuck to optimal solutions  speedy search  however  performed quite well 
as the preference shifted toward desiring cheaper solutions  a  began to do better whereas
speedy did worse  the utility aware techniques were much more robust than both a  and
   

fiheuristic search when time matters

  way unit grids
log   factor of best utility

log   factor of best utility

  way unit grids

   

 

   

 
  

  

log   cost time preference

 

  

 

log   factor of best utility

  way life grids

log   factor of best utility

  way life grids

  

log   cost time preference

 

 
  

  

log   cost time preference

  

  

  

log   cost time preference

  

figure    comparison of techniques  continued  
speedy  neither of which take the users preference for search time and solution cost into
account at all 
of the utility aware techniques  both bugsy and weighted a  with an automatically
selected weight performed the best  bugsy was better on both the    puzzle and the
platform domain  on the grid problems  bugsy and weighted a  had roughly the same
performance on the right side of the x axes  on the left side  bugsy tended to get worse
relative to the other utility aware techniques  and ara  with an anytime monitor was often
the best performer  however  ara  performed significantly worse in the middle and on
the right hand portion of the plot in some domains  leading us to recommend the weighted
a  technique as a simpler and more robust approach 
the utility aware techniques often performed as well as a  when low cost solutions were
preferred  when fast solutions were preferred  these techniques sometimes outperformed
speedy search  this likely indicates that solution cost still played a roll in the final utility
   

fiburns  ruml    do

log   factor of best utility

orz   d

   

   

 
  

bugsy

ara 

  

 

log   cost time preference
wa 
a 
speedy

figure     grid pathfinding on a video game map 
on the left most points in some of the plots  ara  tended to achieve greater utility than
bugsy when solutions were needed quickly  but when cheaper solutions were preferred 
bugsy tended to be better than ara   on most domains  ara  had a spike of low utility
for ratios between        and    with the peak appearing between     and     for life cost
grids  this peak approximately coincides with the utility functions for which the estimated
profile performed worse than the oracle as shown in figure    possibly indicating that more
than       training instances were required for these utility functions 
overall  the utility aware techniques were able to achieve much greater utility than the
utility oblivious a  and speedy algorithms  this is not terribly surprising  surprisingly  the
results also suggest that our very simple parameter tuning technique can often give the best
performance if a representative set of training instances is available  if not  then bugsy
is the algorithm of choice as it performs well and does not require any off line training 
indeed  by putting reasoning about search time into the search algorithm itself  bugsy can
be competitive with techniques requiring previous experience 
    limitations
in the previous set of experiments  we saw that the utility aware algorithms outperformed
both speedy search and a  for a wide range of utility functions  in this section  we look at
one domain for which this tends not to be the case  video game grid maps 
video games are one of the main motivations for research in grid pathfinding problems 
sturtevant        observed that grid maps created by game designers often exhibit very
different properties from maps generated algorithmically  figure    shows a comparison of
bugsy  monitored ara   weighted a  with an automatically selected weight  speedy  and
   

fiheuristic search when time matters

figure     grid pathfinding on a video game map 

   
   
  

   

  speedy time

   

planning time

execution time

   

  speedy time

  speedy nodes

nodes expanded

   
   
  

 

 

  

instance

  

   
   
  

 

 

  

instance

  

 

 

  

instance

  

figure     nodes expanded  search time  and execution time 
a  on the dragon age origins map orz   d from the benchmark set of sturtevant  this
map is shown in figure     it has a fairly wide open area at the top  with a more closed off
bottom half containing rooms and hallways  the format of the plot in this figure is the
same as those in the previous subsection  as we can see  a  gave the best performance for
a large range of utility functions  and bugsy actually never outperformed speedy or a 
in the entire experiment  neither did ara   and wa  only gave the best performance at
a single data point   we hypothesized that bugsys poor performance was because these
problems are very easy to solve  and bugsys extra computation overhead  while very small 
was more prominent 
to explore this hypothesis  we plotted the performance of bugsy given as the difference
from that of speedy using a single utility function given by wf         wt      this is the
   

fiburns  ruml    do

left most utility function in figure     a function for which here speedy search performed
the best and bugsy performed poorly  figure    shows the number of nodes expanded 
the time spent executing  and the time spent searching for bugsyas percentages of the
equivalent values for speedy search  the data points were gathered on a random sample
of    instances from sturtevants        scenario set for the orz   d map  values below
the line at      represent instances where bugsy expanded fewer nodes or spent less
time searching or executing  and values above the line represent instances where bugsy
expanded more nodes or spent more time than speedy  the x axes shows the rank of the
instances in the sample in increasing order of their optimal solution lengths 
as we can see in figure     bugsy expanded about the same number of nodes and
had very similar execution times to speedy  for problems with larger optimal solution
costs bugsy had slightly less execution time  the major difference in performance between
these two algorithms  however  is shown in the right most plot where we can see that bugsy
required more search time than speedy search on almost every instance  since bugsy and
speedy expanded about the same number of nodes  this additional time must be due to
bugsys small amount of extra overhead incurred from re sorting and computing utility 
we conclude that  barring this extra overhead  bugsy would have performed as well as the
best performer for this utility function  in domains where node expansion and heuristic
computation isnt so simplistic  this overhead would be insignificant 
     training set homogeneity
in section     we showed that our weighted a  approach outperformed other techniques
in all domains  with the notable exception of the platform domain and    puzzle  where
bugsy was the best  additionally  compared to other domains  the weighted a  technique
performed relatively poorly on video game pathfinding  cf  figure    where wa  is outperformed by the utility oblivious approaches at all points except for one   we believe
that the poor performance of wa  on these domains is due to heterogeneous training sets 
to verify this  we looked at the mean and standard deviation in the optimal path lengths
for problems in all of our domains  the optimal path length can be viewed as a proxy
for problem difficulty  and a high standard deviation in this statistic points to a diverse
set of instancessome very easy to solve  and some quite difficult  for both the platform
and video game path finding domains  the standard deviation in optimal path length was
greater than     of the mean  more than twice that of the other domains  note that  in
domains such as the video game map  the variety in the layout of different areas of the map
means that instances will inherently differ in their characteristicsmerely gathering more
instances will not produce a more homogeneous set  this evidence supports our hypothesis
that weighted a s performance can be greatly hindered in situations where a representative
training set is not available 
     real time search
the main focus for our study is algorithms for off line searchthey find entire paths to the
goal before any execution begins  in real time search  korf         search and execution
can happen in parallel  but an agent is only allowed a fixed amount of time to plan before
it must perform each action  real time search has the possibility of being more efficient
   

fiheuristic search when time matters

than off line search in terms of goal achievement time  because if all search happens in
parallel with execution  then goal achievement time is simply the execution time plus the
small amount of time required to find the very first action  this in contrast to the off line
approach where goal achievement time is the sum of the entire search time and the execution
time  in some situations  however  starting execution before having a complete plan to a
goal is not acceptable  as it may lead an agent into a dead end from which it can no longer
reach any goal  so real time search may not be applicable  examples of domains with deadends include robotics  manufacturing  ruml  do  zhou    fromherz         and spacecraft
control  exactly those applications involving high value or danger  where automation is
most worthwhile  in these cases  it is desirable to find an entire plan guaranteed to reach
the goal  before any execution begins 
hernandez  baier  uras  and koenig        introduce a model for comparing real time
algorithms to off line techniques such as a   called the game time model  the game time
model partitions time into uniform intervals  and the agent can execute a single action
during each interval  path planning can happen in parallel with execution  the agent can
plan step t during the execution of step t     and the goal is to move the agent from its start
location to its goal location in as few time intervals as possible  minimizing goal achievement
time  the same objective that we discuss in section    the game time model is a special
case of the utility functions considered in this paper where solution cost is given in discrete 
fixed duration units of time 
real time search provides two benefits  first  it may be possible to reduce the goal
achievement time by allowing search and execution to happen at the same time  and second 
the agent can start moving toward its goal right awaya necessary property for video games 
this leaves us with the question of whether or not real time search algorithms can achieve
better goal achievement time than the off line utility aware methods  on one hand  realtime search algorithms spend very little time searching without making progress toward
the goal  on the other hand  real time search algorithms tend to make decisions based on
very local information and can find more costly solutions  in their results  hernandez et al 
report that their best approach solves problems on initially known grid maps in about the
same number of time intervals as a   in the previous section  we showed that the utilityaware techniques outperformed a  for most utility functions  in this section  we compare
a state of the art real time search algorithm called lss lrta   koenig   sun        to
bugsy on the platform pathfinding domain  
as with our previous experiments  we tested all algorithms with a variety of values for
the ratio wf  wt   since we are interested in goal achievement time  we set wt     and
we calculate search time in units of seconds  this means that wf represents the number
of seconds in one unit of execution costthe speed of the agent  we set the real time
constraint for lss lrta  such that it was allowed to plan for the duration of one unit
of execution  and so it always had its next action ready for execution when its currently
executing action completed 
   we do not compare to time bounded a   tba  bjornsson  bulitko    sturtevant         the method
that performed the best for hernandez et al          because the platform domain forms a directed search
graph  and tba  only works on undirected search graphs  we also did not compare with the newer
f  lrta   sturtevant         because it did not perform as well as lss lrta  on the platform domain 
which has directed edges 

   

fiburns  ruml    do

platform
log   factor of best gat

   

lss lrta 
a 
speedy
bugsy

   

   

 
  

  

  

log   w f   w t

  

 

figure     comparison of bugsy and real time search 
figure    shows the results of the comparison  as we can see  lss lrta  gives rather
poor performance  its goal achievement times nearly match that of a   but bugsy was able
to achieve the goal much faster  this shows that simply allowing search and execution to
take place in parallel is not sufficient to reduce goal achievement time  it can be better to
spend time searching the solution all of the way to the goal if the alternative is to spend a
long time executing a poor plan 
     decision theoretic a 
decision theoretic a   dta   russell   ericwefald        is a utility aware algorithm that
allows for concurrent search and execution  it is based on ideas from real time heuristic
search  but unlike traditional real time search  where each action is emitted after a fixed
amount of search  dta  decides when to stop searching and emit an action using a decisiontheoretic analysis  at any time there is a single best top level action with the lowest cost
estimate  the search emits this action if it is decided that the utility of emitting the
action outweighs the utility of further search  dta  uses an approximation  found by
off line training  of how the solution cost estimate for each top level action improves with
additional search  using a consistent heuristic  this estimate can only increase  nilsson 
       so dta  stops searching when it decides that the time required to raise the best
actions estimated cost to the point that it is no longer the best action will be more costly
than the expected gain from determining that there is a different best action 
compared to bugsy  dta  is relatively myopic because it only considers the cost of
search involved in selecting individual actions  dta  does not consider the additional search
required by the solution path to which it commits by choosing an action  where bugsy
uses both d and expansion delay to reason about the required search effort for the entire
   

fiheuristic search when time matters

log   factor of best utility

platform  small instances 
speedy
a 
dta 
bugsy

   

   

   

 
  

  

  

log   w f   w t

  

 

figure     comparison of bugsy and dta  
path beneath a node  dta  only reasons about the search required to determine the best
action to emit right now 
we implemented dta  to assess how a utility aware real time search might compare
to a utility aware off line search for planning under time pressure  figure    shows the
results of a comparison between dta  and bugsy on the platform pathfinding domain 
unfortunately  dta  had fairly poor performance  so our experiment used smaller instances
consisting of   x   blocks  instead of the   x   block instances used in previous experiments 
following russell and ericwefald         we gathered off line training data for dta  using
states sampled uniformly with a probability of     from among those visited by a real time
search algorithm  russell and ericwefald         used an algorithm called slrta   but
we used lss lrta   because it is the current state of the art  our training set consisted
of       x   platform instances  we also verified our implementation by ensuring that
it compared favorably to a  and speedy search on the    puzzlethe same domain used
by russell and ericwefaldusing a variety of different utility functions  from figure    
we can see dta  often had significantly worse utility than bugsy  often performing only
slightly better than speedy search  and sometimes performing worse than a   for example 
when cheap solutions were desired 

   related work
because bugsy uses estimates of its own search time to select whether to terminate or continue  and to select which node to expand  it may be said to be engaging in metareasoning 
that is  reasoning about which reasoning action to take  there has been much work on this
topic in ai since the late     s  dean   boddy        and continuing today  cox   raja 
      
   

fiburns  ruml    do

dean and boddy        consider the problem faced by an agent that is trying to respond
to predicted events while under time constraints  unlike our setting  their concern is with
choosing how much time to allocate for prediction and how much to allocate for deliberation  to solve this type of time dependent planning problem  they suggest the use of  and
also coined the term  anytime algorithms  unlike the anytime based techniques discussed
previously  which attempt to find a stopping policy to optimize a utility function  dean
and boddy used anytime algorithms as a means for allowing different allocations of time
between predicting and deliberation  later  boddy and dean        show how anytime
algorithms and their time dependent planning framework can be used by a delivery agent
that must traverse a set of waypoints on a grid  by allocating time between the ordering of
waypoints and the planning used to travel between them  dean  kaelbling  kirman  and
nicholson        also adapt the technique for scheduling deliberation and execution when
planning in the face of uncertainty 
garvey and lesser        present design to time methods that advocate using all available time to find the best possible solution  unlike anytime approaches that can be interrupted at any time  the design to time method requires the time deadline to be given
upfront  this way  the algorithm can spend all of its time focusing on finding a single
good solution  instead of possibly wasting time finding intermediate results  design to time
also differs from contract techniques like das  dionne et al          because in the designto time framework there must be a predefined set of solvers with known  or predictable 
solution times and costs  the design to time method will select an appropriate solver for
the problem and deadline  possibly interleaving different solvers if deemed appropriate  the
information about cost and solutions times  which design to time methods require  is usually unavailable and must be learned off line  techniques like das and bugsy  on the other
hand  only use information that can be computed on line 
hansen  zilberstein  and danilchenko        show how heuristic search with inadmissible
heuristics can be used to make anytime heuristic search algorithms  like the techniques
presented in this paper  they consider the problem of trading off search effort for solution
quality  to this end  they propose one possible optimization function for anytime heuristic
search search that attempts to maximize the rate at which the algorithm decreases solution
cost  like the anytime monitoring technique shown in section      their evaluation function
relies on learning the profile of the anytime algorithm offline  in their analysis of the  puzzle  they conclude that  while their method had good anytime behavior  there was little
benefit of using it instead of trial and error based hand tuning  this is not surprising given
the strong performance demonstrated by offline tuned weighted a  in our experiments 
more recently  thayer et al         proposed an approach for minimizing the time between solutions in anytime algorithms  they demonstrate that their new state of the art
algorithm performs well on a wide variety of domains  and it can be more robust than
previous approaches  like bugsy  their technique relies on using d heuristics to estimate
the search effort required to find solutions  however  they only focus on solutions that will
require the least amount of effort  and do not optimize for a trade off of search time for
solution cost 
in addition to controlling expansion decisions  metareasoning can also be used during
heuristic evaluation  often search algorithms will use the maximum value computed over
multiple heuristics as a more accurate estimate of cost to goal  for some problems  like
   

fiheuristic search when time matters

domain independent planning  heuristics are quite expensive  so the increased accuracy
gained via maximizing over many heuristics may not be worth the increased computation
time  domshlak  karpas  and markovitch        introduce an on line learning technique
to decide on a single heuristic to compute for each state  instead of computing many and
taking the max 
other related work using metareasoning to control combinatorial search has been done in
the area of constraint satisfaction problems  csps   and boolean satisfiability  sat   tolpin
and shimony        use rational metareasoning to decide when to compute value ordering
heuristics in a csp solver  the focus of the work was on value ordering heuristics that
gave solution count estimates  the solver only bothered to compute the heuristic at decision
points where it was deemed worthwhile  their experiments demonstrate that the new
metareasoning variant outperformed both the variant that always computed the heuristic
and one that computed the heuristic randomly  horvitz  ruan  gomes  kautz  selman 
and chickering        apply bayesian structure learning to csps and sat problems  they
consider the problem of quasi group completion  and unlike tolpin and shimony        who
use on line metareasoning to control search  they use off line bayesian learning over a set
of hand selected variables to predict whether instances will be long or short running 
there has been a lot of work on attempting to estimate the size of search trees offline  burns   ruml        knuth        chen        kilby  slaney  thiebaux    walsh 
      korf  reid    edelkamp        zohavi  felner  burch    holte         this is a
related topic  as it is concerned with estimating search effort before an entire search has
been performed  one may imagine leveraging such a technique to predict search time in
an algorithm like bugsy  unfortunately  these estimation methods can be rather costly in
terms of computation time  so they are not suitable as an estimator that is needed at every
single node generation  another possibility is to use off line estimations to find parameters
that affect the performance of search on a given domain  this knowledge could be helpful for
creating the representative training sets used by algorithms like weighted a  and anytime
monitoring  which require off line training 

   conclusions
we have investigated utility aware search algorithms that take into account a user specified
preference trading off search time and solution cost  we presented three different techniques
for addressing this problem  the first method was based on previous work in the area of
learning stopping policies for anytime algorithms  to the best of our knowledge  we are the
first to demonstrate these techniques in the area of heuristic search  the second method was
a novel use of algorithm selection for bounded suboptimal search that chooses the correct
weight to use for weighted a  for a given utility function  the last technique that we
presented was the bugsy algorithm  bugsy is the only technique of the three that does
not require off line training 
we performed an empirical study of these techniques in the context of heuristic search 
investigated the effect of the parameters of each algorithm on performance  and compared
the different techniques to each other  surprisingly  the simplest technique of learning a
weight for weighted a  was able to achieve the greatest utility on many problems  outperforming the conventional anytime monitoring approach  also surprisingly  bugsy  an
   

fiburns  ruml    do

algorithm that does not use any off line training  performed just as well as the off line
techniques that had the advantage of learning from thousands of off line training instances 
if a representative set of training instances is not available then bugsy is the algorithm
of choice  overall  the utility aware methods outperformed both a  and speedy search
for a wide range of utility functions  this demonstrates that heuristic search is no longer
restricted to solely optimizing solution cost  freeing a user from the choice of either slow
search times or expensive solutions 
unlike previous methods for trading deliberation time for solution quality  bugsy considers the trade off directly in the search algorithmdeciding  for each node  whether the
result of expansion is worth the time  this new approach provides an alternative to anytime algorithms  instead of returning a stream of solutions and relying on an external
process to decide when additional search effort is no longer justified  the search process
itself makes such judgments based on the node evaluations available to it  our empirical
results demonstrate that bugsy provides a simple and effective way to solve shortest path
problems when computation time matters  we would suggest that search procedures are
usefully thought of not as black boxes to be controlled by an external termination policy
but as complete intelligent agents  informed of the users goals and acting rationally on the
basis of the information they collect so as to directly maximize the users utility 

acknowledgments
we greatly appreciate feedback and suggestions from shlomo zilberstein and scott kiesel 
we would also like to think richard korf for pointing out the work of shekhar and dutta
        we are also grateful for support from the nsf  grant         and grant          
the darpa cssg program  grant d  ap        and a university of new hampshire
dissertation year fellowship  a preliminary version of bugsy was presented by ruml and
do         see appendix a  elisabeth crawford assisted with the original version during a
summer internship at parc 

appendix a  previous bugsy
a previous version of bugsy was proposed by ruml and do         however  this early
realization differs substantially from the one presented here  it used aggressive duplicate
re expansion  heuristic corrections  and it only used d to estimate the remaining expansions
until a goal is reached  in section     we showed that duplicate dropping outperforms duplicate re expansion in many domains  we found that inadmissible heuristics performed
poorly  cf section      in practice  even when compared to the standard admissible estimates  also  to temper the inadmissible of its corrected estimates  the previous bugsy
multiplied its heuristic estimates by an arbitrary weight  min       wt  wf           our version does not require this ad hoc fix  we discussed why d is a poor estimate for the number
of remaining expansions in section      and in section     we showed  experimentally  that
using expansion delay performs much better than just using d alone 
recall that bugsy uses f and d to approximate the cost and path length of the best
utility outcome that is enabled by the expansion of the node  note  however  that the f and
d function used throughout this paper refer to the cheapest solution beneath a node n  and
   

fiheuristic search when time matters

this may not be the goal that results in the maximum utility  to better assess the available
outcomes  the previous version of bugsy computed two utility estimates for each node  one
for the cheapest solution beneath the node and the other for the nearest solution in terms of
node expansions  in non unit cost domains  these two estimates may differ  for example  on
the life cost grid pathfinding domains  the cheapest solution usually involves moving toward
the top of the grid where actions are cheap  but the nearest solution will follow a straight line
path to the goal  in general  there can be a large number of different solutions through each
search node  and the solutions may cover a whole spectrum of different cost time trade offs 
by considering more than just the cheapest solution  as was done in our implementation 
it may be possible to find solutions with better utility  on the other hand  it may be too
costly to compute multiple heuristics for each node  so whether or not this modification is
beneficial depends on the domain 

appendix b  domains
we performed our experiments on a variety of different domains  which we describe in
further detail here 
b      puzzle
the    puzzle is one of the most popular benchmark domains for heuristic search algorithms 
it consists of a   by   frame into which    tiles have been placed  one slot of the board
does not contain a tile  it is called the blank  tiles that are above  below  left of or right
of the blank may be slid into the blank slot  the objective of the    puzzle is to slide tiles
around in order to transform an initially scrambled puzzle into the goal state with the blank
in the upper left corner and the tiles ordered     going from left to right  top to bottom 
this domain is interesting because plans are hard to find  the branching factor is small and
varies little from its mean of about       korf et al          there are few duplicates  and
the heuristic is reasonably informed 
in our experiments we use the popular        puzzle instances created by korf        
in plots that include a   however  we only used the    instances solvable by a  in  gb of
memory  the average optimal solution length for these instances was       for our training
set  we generated       instances using a   million step random walk back from the goal
position  we used the manhattan distance heuristic  which sums the vertical and horizontal
distance that each tile must move to arrive at its goal position  our implementation follows
the heavily optimized solver presented by burns et al         
b   pancake puzzle
the pancake puzzle  dweighter        gates   papadimitriou        is another permutation
puzzle  it consists of a stack of differently sized pancakes numbered  n   the pancakes
must be presented at a fancy breakfast  so a chef needs to sort the originally unordered
stack of pancakes by continually sticking a spatula into the stack and reversing the order of
the pancakes above  said another way  the pancake problem involves sorting a sequence of
numbers by using only prefix reversal operations  this simple problem is interesting because
it creates a search graph with a large branching factor  the number of pancakes minus one  
   

fiburns  ruml    do

figure     a screenshot of the platform pathfinding domain  left   and a zoomed out image
of a single instance  right   the knight must find a path from its starting
location  through a maze  to the door  on the right side in the left image  and
just above the center in the right image  

for our experiments  we used    randomly generated    pancake puzzle instances  and our
training set consisted of       randomly generated instances  we used the powerful gap
heuristic of helmert         which sums the number of pairs of adjacent pancakes that are
not in sequence 
b   platform pathfinding
the platform domain is a pathfinding domain of our own creation with dynamics based
on a   dimensional platform style video game  written partially by the first author  called
mid    the left image of figure    shows a screenshot from mid  the goal is for the knight
to traverse a maze from its initial location  jumping from platform to platform  until it
reaches the door  mid is an open source game available from http   code google com p 
mid game  for our experiments the game physics of the game were ported from c to c  
and were embedded in our c   search codebase  we generated       training instances
and     test instances using the level generator from mid  an example instance is shown
on the right panel in figure     the domain is unit cost and has a large state space with
a well informed heuristic 
the available actions are different combinations of controller keys that may be pressed
during a single iteration of the games main loop  left  right  and jump  left and right move
to the knight in the respective directions  holding both at the same time is never considered
by the search domain  as the movements would cancel each other out  leaving the knight in
   the other author was steve mccoy  who also drew the tile graphics shown in figure    

   

fiheuristic search when time matters

place   and the jump button makes the knight jump  if applicable  the knight can jump
to different heights by holding the jump button across multiple actions in a row up to a
maximum of    the actions are unit cost  so the cost of an entire solution is the number of
game loop iterations  called frames  required to execute the path  each frame corresponds
to   ms of game play 
each state in the state space contains the x  y position of the knight using doubleprecision floating point values  the velocity in the y direction  x velocity is not stored as
its determined solely by the left and right actions   the number of remaining actions for
which pressing the jump button will add additional height to a jump  and a boolean stating
whether or not the knight is currently falling  the knight moves at a speed of      units per
frame in the horizontal direction  it jumps at a speed of   units per frame  and to simulate
gravity while falling      units per frame are added to the knights downward velocity up to
a maximum of    units per frame 
for further details on the platform domain  please refer to the source code repository
given at the start of section   
b     level generator
the instances used in our experiments were created using the level generator from mid  a
special maze generator that builds   dimensional platform mazes on a      grid of blocks 
each block is either open or occluded  and to ensure solvability given the constraints imposed
by limited jump height  the generator builds the maze by stitching together pieces from a
hand created portfolio  each piece consists of a number of blocks that are either free or
occluded  and a start and end location for which traversability is ensured within the piece 
a piece can be added to the grid at any location for which it fits  a piece fits if it does not
occlude a block that belongs to a previously placed piece  the maze is built using a depthfirst procedure  a piece is selected at random and if it fits in the grid with its start location
lined up with the end location of its predecessor then it is placed and the procedure recurs 
the number of successors of each node is chosen uniformly from the range    inclusive  and
the procedure backtracks when there are no pieces that fit on the previous block  once the
maze is constructed  blocks that do not belong to any piece are marked as occluded  the
right image in figure    shows a sample of a level generated by this procedure  the source
code for the level generator is available in the mid source repository mentioned above 
b     heuristic
we developed a heuristic for the platform domain that is based on visibility navigation
 nilsson         each maze is pre processed to convert its grid representation into a set of
polygons representing each connected component of occluded cells in the level  the space
is then scaled to account for the movement speed of the knight  the knight can fall faster
than it can move in the horizontal direction  so the polygons end up squished vertically
and stretched horizontally  the visibility navigation problem is then solved in reverse from
the four corners of the goal cell to the center of every non occluded cell of the maze  to
maintain admissibility  the cost of each edge in the visibility problem is not the length
of

the visibility line  but instead is the maximum of the length of the line divided by   and
the x and y displacements between the end points of the line  this accounts for the fact
   

fiburns  ruml    do

figure     the visibility navigation instance for the platform domains heuristic  the visibility path between the initial state and the goal state is drawn in red 

that the knight can bemoving both horizontally and vertically at the same time  and that
moving a distance of   in the scaled space still takes only a single frame 
during search  the heuristic value of a state is computed in one of two different ways 
if the straight line path from the center of the knight to the goal is not occluded then the
maximum of the x and y distances to the goal scaled down by travel speed is used as the
heuristic estimate  otherwise  the heuristic is the cost of the path in the visibility graph
from the center of the cell that contains the knights center point minus the maximum of
the x and y distance  in number of frames  of the knights center point to the center of
its cell  figure    shows the same map from the right image of figure     scaled  broken
into polygon components  and with the visibility path between the initial state and the goal
state drawn in red 
b   grid pathfinding
our final domain was grid pathfinding  this is a very popular domain in both video games
and robotics  as such it has garnered much attention in the heuristic search community  in
our experiments  we used      x      grids with both four way and eight way connectivity
and uniform obstacle distributions  for four way connected grids  each cell was blocked
with a probability of       and for eight way connected grids cells were blocked with a
probability       we also consider two different cost models  the standard
 unit cost model
in which horizontal and vertical moves cost   and diagonal moves cost    the other is
called the life cost model  where each move has a cost equal to the row number from which
the move took place  causing cells toward the top of the grid to be preferred  with the
life cost model  short direct solutions can be found quickly  however they will be relatively
expensive  while a least cost solution involves many annoying economizing steps  ruml  
do         this model can be viewed as an instantiation of the popular belief that time is
money  as one can choose to incur additional cost for a shorter and simpler path  for each
combination of movement model and cost model  we generated    test instances and      
training instances  finally  we used the manhattan distance heuristic for four connected
grids and the octile distance heuristic for eight connected grids  for the life cost model our
   

fiheuristic search when time matters

heuristics also took into account the fact that moving toward the top of the grid then back
down may be cheaper than a direct path 

appendix c  anytime policy estimation
it can be challenging to write algorithms that rely on off line training data  if the algorithm
behaves unexpectedly  then it is unclear if there is a bug in the implementation  a bug in the
off line learning procedure  or if the training set is merely insufficiently representative  in
this appendix  we describe how we implemented and verified our procedure for estimating
an anytime profile 
figure    shows the pseudocode for building a profile based on the description given
by hansen and zilberstein         the algorithm accepts a set of solution streams as
input  one stream for each solved instance  then proceeds in two steps  the first step is
the count solutions function that counts the number of times each solution cost was
improved upon  the function iterates through each solution  line     computes the bin of a
histogram into which its cost value falls  line     then for each subsequent solution a count
is added to qqtcounts for each time step for which the first solution improved to the second
solution  in addition  the number of total improvements for each solution and time bin are
counted in the qtcounts array  the costbin and timebin functions bin cost and time values
respectively by returning an integer for the corresponding index in the histogram 


q  qmin
costbin q   
 qmax  qmin   ncost


t  tmin
timebin t   
 tmax  tmin   ntime
 
the second step is the probabilities function that converts the counts computed in
the first step into normalized probability values  this is achieved by dividing the number
of t steps for which a solution of cost qi improved to a solution of cost qj  qqtcounts 
by the total number of steps for which a solution of cost qi was improved  qtcounts  and
lines      the probability values are smoothed by adding half of the smallest probability
to each bin representing a solution cost improvement  this step removes zero probabilities 
allowing improvement to be considered  finally  the probabilities are normalized so that
the probability of all non decreasing cost solutions for each current cost and time step sum
to one  lines        once the profile is computed  it is saved to disk for later use when
computing the stopping policy 
we found that it was extremely useful to have a simple way to validate our policies
while debugging our implementation  one option is to create a stopping policy  run ara 
with monitoring on a handful of instances and with a handful of utility functions to verify
that it gives the expected behavior  unfortunately  this approach was rather cumbersome
and prone to error  as it only evaluated the policy on the small number of instances that we
were willing to run by hand  instead  we chose to validate our implementation by plotting
the polices generated from the training data on different utility functions  by plotting
the extreme policies that only care about solution cost and search time  along with some
intermediate policies that trade off the two  it was much simpler to debug our code 
   

fiburns  ruml    do

profile streams 
   qtcounts  qqtcounts  count solutions streams 
   return probabilities qtcounts  qqtcounts 
count solutions streams 
   qtcounts  new int ncost  ntime     initialized to zero 
   qqtcounts  new int ncost  ncost  ntime     initialized to zero 
   for s in streams
  
for i from   to  s 
  
qi  costbin s i  cost 
  
qcur  qi   tcur   
  
   count cost at each time increment after solution i 
   
for j from i     to  s 
   
qnext  costbin s j  cost 
   
tnext  timebin s j  time  s i  time 
   
   current solution cost up to the time of solution j 
   
for t   tcur to tnext   
   
increment qtcounts qi   t 
   
increment qqtcounts qcur   qi   t 
   
qcur  qnext   tcur  tnext
   
   last solution cost up to the final time 
   
for t   tcur to ntime
   
increment qtcounts qi   t 
   
increment qqtcounts qcur   qi   t 
    return qtcounts  qqtcounts
probabilities qtcounts  qqtcounts 
    probs  new float ncost  ncost  ntime 
    for qi from   to ncost
   
for t from   to ntime
   
if qtcounts qi   t      then continue
   
for qj from   to ncost
   
probs qj   qi   t   qqtcounts qj   qi   t  qtcounts qi   t 
    smoothing  add half of smallest probability to all elements of probs with improving solution cost 
       normalize 
    for qi from   to ncost
   
for t from   to ntime
   
sum   
   
for qj from   to ncost
   
sum  sum   probs qj   qi   t 
   
for qj from   to ncost
   
probs qj   qi   t   probs qj   qi   t  sum
    return probs

figure     pseudocode for profile estimation 

figure    shows some of the plots created for the platform domain  each plot has cost
on the y axis and time on the x axis  green circles represent inputs for which the policy
says to keep searching  and red crosses represent inputs for which the policy says to stop
   

fiheuristic search when time matters

 a 

 b 

    

   

   

   

    

cost

    

cost

cost

    

 c 

    

   

time

   

time

   

    

   

   

   

time

figure     three different policies   a  prefers cheaper solutions at any expense  wf  
   wt        b  attempts to trade some search time for some solution cost  wf  
     wt       and  c  prefers to have any solution as fast as possible  wf      wt  
   

searching and return the solution  as expected  the policy always continues when the goal
is to minimize solution cost and always stops when the goal is to minimize search time  cf 
the left most and right most plots in figure    respectively   the center plot shows that
we also successfully found policies that trade search time for solution cost by only stopping
once the cost is sufficiently low  finally  in the left most plot  the bottom most and rightmost sides of the policy always stop as our implementation chose to stop when there was
no training data available to estimate the profile for the given input values 

references
bjornsson  y   bulitko  v     sturtevant  n          tba   time bounded a   in proceedings
of the twenty first international joint conference on artificial intelligence  ijcai     pp         
boddy  m     dean  t          solving time dependent planning problems   in proceedings
of the eleventh international joint conference on artificial intelligence  ijcai     
vol     pp         
burns  e   hatem  m   leighton  m  j     ruml  w          implementing fast heuristic
search code  in proceedings of the fifth annual symposium on combinatorial search
 socs     
burns  e     ruml  w          iterative deepening search with on line tree size prediction 
annals of mathematics and artificial intelligence  s        
chen  p  c          heuristic sampling  a method for predicting the performance of tree
searching programs  siam journal on computing                 
cox  m  t     raja  a          metareasoning  thinking about thinking  mit press 
   

fiburns  ruml    do

dean  t     boddy  m          an analysis of time dependent planning  in proceedings of
the seventh national conference on artificial intelligence  aaai      pp       
dean  t   kaelbling  l  p   kirman  j     nicholson  a          planning with deadlines in
stochastic domains  in proceedings of the eleventh national conference on artificial
intelligence  vol       p       washington  dc 
dechter  r     pearl  j          the optimality of a   in kanal  l     kumar  v   eds   
search in artificial intelligence  pp          springer verlag 
dionne  a  j   thayer  j  t     ruml  w          deadline aware search using on line measures of behavior  in proceedings of the fourth annual symposium on combinatorial
search  socs     
domshlak  c   karpas  e     markovitch  s          to max or not to max  online learning
for speeding up optimal planning  in aaai conference on artificial intelligence
 aaai      pp           
dweighter  h          elementary problem e      american mathematical monthly          
     
finkelstein  l     markovitch  s          optimal schedules for monitoring anytime algorithms  artificial intelligence                 
garvey  a  j     lesser  v  r          design to time real time scheduling  systems  man
and cybernetics  ieee transactions on                   
gates  w  h     papadimitriou  c  h          bounds for sorting by prefix reversal  discrete
mathematics               
hansen  e  a     zhou  r          anytime heuristic search  journal of artificial intelligence
research                 
hansen  e  a     zilberstein  s          monitoring and control of anytime algorithms  a
dynamic programming approach  artificial intelligence              
hansen  e  a   zilberstein  s     danilchenko  v  a          anytime heuristic search  first
results  tech  rep   university massachusetts  amherst 
hart  p  e   nilsson  n  j     raphael  b          a formal basis for the heuristic determination of minimum cost paths  ieee transactions on systems science and cybernetics 
ssc               
helmert  m          landmark heuristics for the pancake problem  in proceedings of the
third symposium on combinatorial search  socs     
helmert  m     roger  g          how good is almost perfect  in proceedings of the
twenty third aaai conference on artificial intelligence  aaai     
hernandez  c   baier  j   uras  t     koenig  s          time bounded adaptive a   in
proceedings of the eleventh international joint conference on autonomous agents
and multiagent systems  aamas     
horvitz  e   ruan  y   gomes  c   kautz  h   selman  b     chickering  m          a
bayesian approach to tackling hard computational problems  in proceetings of the
seventeenth conference on uncertainty in artificial intelligence  uai     
   

fiheuristic search when time matters

kilby  p   slaney  j   thiebaux  s     walsh  t          estimating search tree size  in
proceedings of the twenty first national conference on artificial intelligence  aaai    
knuth  d  e          estimating the efficiency of backtrack programs  mathematics of
computation                   
koenig  s     sun  x          comparing real time and incremental heuristic search for
real time situated agents  autonomous agents and multi agent systems             
    
korf  r  e          iterative deepening a   an optimal admissible tree search  in proceedings of the ninth international joint conference on artificial intelligence  pp 
         
korf  r  e          real time heuristic search  artificial intelligence                   
korf  r  e   reid  m     edelkamp  s          time complexity of iterative deepening a  
artificial intelligence                  
likhachev  m   gordon  g     thrun  s          ara   anytime a  with provable bounds
on sub optimality  advances in neural information processing systems  nips     
   
michie  d     ross  r          experiments with the adaptive graph traverser  in machine
intelligence    pp         
nilsson  n  j          a mobile automaton  an application of artificial intelligence techniques  in proceedings of the first international joint conference on artificial intelligence  ijcai      pp         
nilsson  n  j          principles of artificial intelligence  tioga publishing co 
pohl  i          heuristic search viewed as path finding in a graph  artificial intelligence 
          
rice  j  r          the algorithm selection problem  advances in computers            
richter  s   thayer  j  t     ruml  w          the joy of forgetting  faster anytime search
via restarting  in proceedings of the twentieth international conference on automated
planning and scheduling  icaps      pp         
ruml  w   do  m   zhou  r     fromherz  m  p          on line planning and scheduling  an
application to controlling modular printers  journal of artificial intelligence research 
               
ruml  w     do  m  b          best first utility guided search  in proceedings of the   th
international joint conference on artificial intelligence  ijcai      pp           
russell  s     ericwefald         do the right thing  studies in limited rationality  the
mit press 
shekhar  s     dutta  s          minimizing response times in real time planning and
search  in proceedings of the eleventh international joint conference on artificial
intelligence  ijcai      pp          citeseer 
   

fiburns  ruml    do

sturtevant  n          benchmarks for grid based pathfinding  transactions on computational intelligence and ai in games                  
sturtevant  n  r          distance learning in agent centered heuristic search  in proceedings
of the fourth annual symposium on combinatorial search  socs     
thayer  j          faster optimal and suboptimal heuristic search  ph d  thesis  university
of new hampshire 
thayer  j  t   benton  j     helmert  m          better parameter free anytime search by
minimizing time between solutions  in proceedings of the fifth annual symposium on
combinatorial search  socs     
thayer  j  t   dionne  a     ruml  w          learning inadmissible heuristics during
search  in proceedings of the twenty first international conference on automated
planning and scheduling  icaps     
thayer  j  t     ruml  w          faster than weighted a   an optimistic approach to
bounded suboptimal search  in proceedings of the eighteenth international conference
on automated planning and scheduling  icaps     
thayer  j  t     ruml  w          using distance estimates in heuristic search  in proceedings of the nineteenth international conference on automated planning and scheduling  icaps     
thayer  j  t     ruml  w          anytime heuristic search  frameworks and algorithms 
in proceedings of the third annual symposium on combinatorial search  socs     
tolpin  d     shimony  s  e          rational deployment of csp heuristics  in proceedings of the twenty second international joint conference on artificial intelligence
 ijcai     
valenzano  r  a   sturtevant  n   schaeffer  j   buro  k     kishimoto  a          simultaneously searching with multiple settings  an alternative to parameter tuning for
suboptimal single agent search algorithms  in proceedings of the twentieth international conference on automated planning and scheduling  icaps     
van den berg  j   shah  r   huang  a     goldberg  k          ana   anytime nonparametric a   in proceedings of twenty fifth aaai conference on artificial intelligence
 aaai     
zohavi  u   felner  a   burch  n     holte  r          predicting the performance of ida 
using conditional distributions  journal of artificial intelligence research            
   

   

fi