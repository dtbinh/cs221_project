journal artificial intelligence research                  

submitted        published      

framing image description ranking task 
data  models evaluation metrics
micah hodosh
peter young
julia hockenmaier

mhodosh  illinois edu
pyoung  illinois edu
juliahmr illinois edu

department computer science
university illinois
urbana  il        usa

abstract
ability associate images natural language sentences describe
depicted hallmark image understanding  prerequisite applications sentence based image search  analogy image search  propose
frame sentence based image annotation task ranking given pool captions 
introduce new benchmark collection sentence based image description search 
consisting       images paired five different captions provide
clear descriptions salient entities events  introduce number systems
perform quite well task  even though based features
obtained minimal supervision  results clearly indicate importance
training multiple captions per image  capturing syntactic  word order based 
semantic features captions  perform in depth comparison human
automatic evaluation metrics task  propose strategies collecting human
judgments cheaply large scale  allowing us augment collection
additional relevance judgments captions describe image  analysis shows
metrics consider ranked list results query image sentence
significantly robust metrics based single response per query  moreover  study suggests evaluation ranking based image description systems
may fully automated 

   introduction
ability automatically describe entities  events scenes depicted image
possibly ambitious test image understanding  advances task
significant practical implications  since billions images web
personal photo collections  ability efficiently access wealth information
contain hampered limitations standard image search engines  must rely
text appears near image  datta  joshi  li    wang        popescu  tsikrika   
kludas         lot work multi label classification problem
associating images individual words tags  see  e g   blei   jordan        barnard 
duygulu  forsyth  freitas  blei    jordan        feng   lapata        deschacht   moens 
      lavrenko  manmatha    jeon        makadia  pavlovic    kumar        weston 
bengio    usunier         much harder problem automatically associating images
complete sentences describe recently begun attract attention 

     ai access foundation  rights reserved 

fihodosh  young   hockenmaier

    related work
although approaches framed sentence based image description task mapping images sentences written people  farhadi  hejrati  sadeghi  young  rashtchian 
hockenmaier    forsyth        ordonez  kulkarni    berg         research
area focused task automatically generating novel captions  kulkarni  premraj 
dhar  li  choi  berg    berg        yang  teo  daume iii    aloimonos        li  kulkarni  berg  berg    choi        mitchell  dodge  goyal  yamaguchi  stratos  han  mensch 
berg  berg    daume iii        kuznetsova  ordonez  berg  berg    choi        gupta 
verma    jawahar         argue paper framing image description natural language generation problem introduces number linguistic difficulties detract
attention underlying image understanding problem wish address  since
sentence based image description retrieval system requires ability associate images
captions describe depicted them  argue important evaluate
mapping images sentences independently generation aspect  research caption generation ignored image search task  arguably
much greater practical importance 
systems cited either evaluated data set group released
earlier work  rashtchian  young  hodosh    hockenmaier         sbu captioned photo dataset  ordonez et al          data set consists       images
pascal voc      object recognition challenge annotated five descriptive captions purposely collected task  sbu data set consists one
million images captions harvested flickr  gupta et al         system
use grubinger  clough  mller  deselaerss        iapr tc    data set  consists
       images paired longer descriptions 
although details differ  models rely existing detectors define map images
explicit meaning representation language consisting fixed number scenes  objects
 or stuff   attributes spatial relations  farhadi et al         kulkarni et al        
li et al         yang et al         ordonez et al         mitchell et al         
unclear well detector based approaches generalize  models evaluated
pascal voc      data set  farhadi et al         kulkarni et al         li et al        
yang et al         mitchell et al         rely detectors may trained
images contained corpus  kuznetsova et al         select test set       images
sbu data set detectors work well  moreover  among systems
evaluated pascal voc      data set  kulkarni et al          li et al         
li et al         mitchell et al s        results may directly comparable  since different
research groups report different evaluation metrics use different parts data set
test training data  evaluation generation systems generally well known
difficult  see  e g   dale   white        reiter   belz         typically requires expensive
human judgments consider quality content selection  what
described  surface realization  the fluency generated text   syntactic
pragmatic issues confound purely semantic question whether image correctly
described caption 

   

fiframing image description ranking task

    approach
paper  focus task associating images sentences drawn large 
predefined pool image descriptions  descriptions generated automatically
harvested web  feng   lapata        ordonez et al          written
people asked describe them  argue evaluating ability select
rank  rather generate  appropriate captions image direct test
fundamental semantic question well associate images sentences
describe well  framing image description ranking task number
additional advantages  first  allows us handle sentence based image annotation
search unified framework  allowing us evaluate whether advances one task
carry other  second  framing image description ranking problem greatly
simplifies evaluation  establishing parallel description retrieval 
use metrics evaluate tasks  moreover  show rank
original caption  easily determined automatically  leads metrics correlate
highly systems rankings obtained human judgments  even underestimate
actual performance  show standard automatic metrics bleu  papineni 
roukos  ward    zhu        rouge  lin        used evaluate
caption generation systems show poor correlation human judgments  leading us
believe evaluation caption generation system automated 
perform large scale human evaluation  since sentences data set image
descriptions written people  need collect purely semantic judgments whether
describe images system associated with  since judgments
independent task  use evaluate image description retrieval
systems  since collect judgments image caption pairs publicly available
data set  establish common benchmark enables direct comparison different
systems  believe another advantage caption generation task  since
many possible ways describe image  generation systems liberty
less specific describe image  makes direct comparison
independently obtained judgments quality two different systems difficult 
since one system may aiming solve much harder task other  implies
unless system outputs common benchmark collection images made publicly
available  cannot shared  objective evaluation would allow community
measure progress difficult problem  since caption generation systems
need able determine well caption describes image  data set could
potentially used evaluate semantic component 
    contributions outline paper
section    discuss need new data set image description introduce
new  high quality  data set image description enable community compare
different systems benchmark  pascal voc      data set      
images  rashtchian et al         used number image description systems
 farhadi et al         kulkarni et al         li et al         yang et al         mitchell et al  
      gupta et al          number shortcomings limit usefulness  first 
domain relatively limited  captions relatively simple  second  since
   

fihodosh  young   hockenmaier

images drawn data used pascal voc      object classes challenge 
difficult guarantee fair evaluation description systems rely off the shelf
object detectors  e g   felzenszwalb  mcallester    ramanan        data set  since
may possible identify images detectors trained on 
experiments paper therefore based larger  diverse  data set      
images  unlike data sets pair images sentences merely related
image  feng   lapata        ordonez et al          image data sets
paired five different captions purposely written describe image 
section    describe image description systems  image description
novel task  remains largely unknown kind model  kind
visual linguistic features requires  instead unidirectional mapping images
sentences common current caption generation systems  map images
sentences space  allows us apply system image search
retrieving images closest query sentence  image description
annotating images sentences closest it  technique use 
kernel canonical correlation analysis  kcca  bach   jordan         already
successfully used associate images  hardoon  szedmak    shawe taylor        hwang
  grauman        hardoon  saunders  szedmak    shawe taylor        image regions
 socher   li        individual words sets tags  canonical correlation
analysis  hotelling        used associate images related wikipedia
articles ten different categories  rasiwasia  pereira  coviello  doyle  lanckriet  levy 
  vasconcelos         however  performance techniques much
stringent task associating images sentences describe depicted
evaluated  compare number text kernels capture different linguistic
features  experimental results  discussed section    demonstrate importance
robust textual representations consider semantic similarity words  hence take
linguistic diversity different captions associated image account 
visual features relatively simple  number image description systems  farhadi et al  
      kulkarni et al         li et al         yang et al         kuznetsova et al         largely
rely trained detectors  e g  obtain explicit intermediate meaning representation
depicted objects  scenes events  approach would ultimately require separate
detectors  hence labeled training data  term phrase chosen meaning
representation language  show image features capture low level
perceptual properties fact work surprisingly well larger data set
in domain detectors available 
section    consider question evaluation  use number different metrics
compare systems  since focus problem learning appropriate mapping
images captions  follow standard machine learning practice evaluate
ability function generalize unseen examples  hence  separate pool
captions images used testing used train systems  first consider
metrics quality single image caption pair  compare automatically computed
scores detailed human judgments  examine metrics evaluate ranked
lists returned systems  analysis reveals that  current level performance 
differences models may become apparent single caption per image
considered  commonly done caption generation systems  even two models
   

fiframing image description ranking task

equally likely fail return suitable caption first result  still prefer
one likely rank good captions higher other  since arguably
provides better approximation semantic space images near captions
describe well  since test pool contains single gold item query 
first consider metrics based rank recall gold item  show
simpler  binary judgments image descriptions good approximations
fine grained human judgments collected large scale via crowdsourcing 
augment test pool data set relevance judgments  hope
add usefulness community resource benchmark  judgments
show actual performance systems higher recall gold item
indicates  however  comparison system rankings obtained via different metrics
suggests differences rank recall gold item correlate highly
difference performance according binary relevance judgments 

   new data set image description
used crowdsourcing collect descriptive captions large number images
people animals  mostly dogs   describing data set annotation methodology  discuss kind captions useful image description  motivate
need create new data sets task 
    mean image description 
since automatic image description relatively novel task  worth reflecting
means describe images  wish say image  fact
substantial body work image description related image libraries  jaimes  jaimes 
  chang        shatford        useful revisit purpose  argue
three different kinds image descriptions commonly distinguished  one
type  so called conceptual descriptions  relevance image understanding aim achieve automatic captioning  conceptual image descriptions identify
depicted image  may abstract  e g   concerning mood
picture may convey   image understanding mostly interested concrete descriptions
depicted scene entities  attributes relations  well events
participate in  focus actually image  conceptual descriptions
differ so called non visual descriptions  provide additional background information cannot obtained image alone  e g  situation  time location
image taken  perceptual descriptions capture low level visual properties
images  e g   whether photograph drawing  colors shapes dominate  little interest us  unless link properties explicitly depicted
entities  among concrete conceptual descriptions  distinction drawn specific descriptions  may identify people locations names 
generic descriptions  which may  e g   describe person woman skateboarder 
scene city street room   exception iconic entities
recognized  e g   well known public figures landmark locations eiffel
tower  argue image understanding focus information captured

   

fihodosh  young   hockenmaier

bbc captions
 feng lapata      

consumption
soared
real price
drink fallen

amd destroys
central vision

sbu captioned photo dataset  flickr 
 ordonez et al       

downers grove
don t chew couch
train station  our condo pee kitchen
building
mama 
background  
way ag store
chicago 

iapr tc   data set
 grubinger et al       

blue white airplane standing grey airport 
man red cones standing front two
red dressed hostesses two passengers directly
stairs front airplane  brown landscape
high dark brown mountains snow covered
summits light grey sky background 

figure    data sets images captions
generic descriptions  leaves question obtain data set images paired
suitable descriptions train automatic description systems on 
    need new data sets
dearth images associated text available online  argue
text suitable task  work  notably natural language
processing community  focused images news articles  feng   lapata              
however  images often used illustrate stories  little direct connection
text  figure    left   furthermore  even captions describe depicted event 
tend focus information cannot obtained image itself  similarly 
people provide captions images upload websites flickr  figure   
center   often describe situation images taken in  rather
actually depicted image  is  captions often provide non visual overly
specific information  e g   naming people appearing image location
image taken   simple reason people typically provide kinds
generic conceptual descriptions use purposes  gricean maxims
relevance quantity  grice        entail image captions written people
usually provide precisely kind information could obtained image
itself  thus tend bear tenuous relation actually depicted  or 
state succinctly  captions usually written seen along images
accompany  users may wish bore readers obvious 
ordonez et al         harvested images captions flickr create
sbu captioned photo dataset  discard vast majority images
captions actually descriptive  analysis random sample    
images final data set revealed majority          captions describe
information cannot obtained image  e g   naming people
locations appearing image   substantial fraction          describe small
detail image otherwise commentary image  examples
issues shown figure    center   makes data set less useful kind
image understanding interested in  unless refer specific entities one may
actually wish identify  e g   celebrities famous landmarks appear image  
proper nouns little help learning visual properties entity types unless one
   

fiframing image description ranking task

data set       flickr images   crowd sourced captions
man tricks bicycle ramps front crowd 
man bike executes jump part competition crowd watches 
man rides yellow bike ramp others watch 
bike rider jumping obstacles 
bmx biker jumps ramp 
group people sit table front large building 
people drinking walking front brick building 
people enjoying drinks table outside large brick building 
two people seated table drinks 
two people sitting outdoor cafe front old building 

figure    data set images paired generic conceptual descriptions
infer kind entity refer to   iapr tc    data set  grubinger et al  
       consists        photographs potentially useful purposes  since
contains descriptions recognized image without prior information
extra knowledge  however  descriptions  consist often multiple sentences
sentence fragments  tendency lengthy  average length       words 
overly detailed  instead focusing salient aspects photograph  example 
photo airplane figure    right   two hostesses barely visible
nevertheless described detail 
    data sets
since kinds captions normally provided images describe images
themselves  collected data sets images captions  captions
obtained using crowdsourcing service provided amazon mechanical turk
annotate image five descriptive captions  asking people describe
people  objects  scenes activities shown picture without giving
information context picture taken  able
obtain conceptual descriptions focus information obtained
image alone  annotation process quality control described detail
rashtchian et al        s paper  annotated two different data sets manner 
      pascal voc      data set
first data set produced relatively small  consists       images randomly selected training validation set pascal      object recognition
challenge  everingham  gool  williams  winn    zisserman         used
large number image description systems  farhadi et al         kulkarni et al         li
et al         yang et al         mitchell et al         gupta et al          since almost
systems  the exception gupta et al         rely detectors trained
   data set ordonez et al         differs significantly content ours  collection
focuses images eventualities  i e  people animals something  majority ordonez et
al s images          depict people animals  e g   still lifes  landscape shots  

   

fihodosh  young   hockenmaier

images data set  felzenszwalb et al          unclear well
approaches would generalize domains labeled data train detectors
available  captions pascal data set relatively simple  example 
since data set contains many pictures depict focus people something      captions contain verb  additional     captions
contain common static verbs sit  stand  wear  look 
      flickr  k data set
work reported paper therefore collected larger  diverse data set
consisting       images flickr com website  unlike static pascal
images  images data set focus people animals  mainly dogs  performing
action  examples data set shown figure    images chosen
six different flickr groups   tend contain well known people locations 
manually selected depict variety scenes situations  order avoid
ungrammatical captions  allowed workers united states passed
brief spelling grammar test devised annotate images 
interested conceptual descriptions  annotators asked write sentences describe
depicted scenes  situations  events entities  people  animals  objects  
collected multiple captions image considerable degree variance
way many images described  consequence  captions
images often direct paraphrases other  entity event situation
described multiple ways  man vs  bike rider  tricks vs  jumping  
everybody mentions bike rider  everybody mentions crowd ramp 
dynamic nature images reflected described 
captions data set average length      words  compared      words
pascal data set      pascal captions contain verb
sit  stand  wear  look      captions flickr  k set contain
verb  additional     contain common verbs  data sets  flickr
training test development splits human relevance judgments used evaluation
test items  section    publicly available   online appendix paper contains
instructions workers  including qualification test pass
allowed complete tasks 

   systems sentence based image description
since image description requires ability associate images sentences  image
description systems viewed terms affinity function f  i  s  measures
degree association images sentences  evaluate ability compute
affinity functions measuring performance two tasks depend directly them 
given candidate pool sentences scand candidate pool images icand   sentencebased image retrieval aims find image icand maximizes f  i  sq   query
sentence sq scand   conversely  image annotation aims find sentence scand
   groups called strangers   wild child  kids action   dogs action  read rules  
outdoor activities  action photography  flickr social  two people photo 
   http   nlp cs illinois edu hockenmaiergroup data html

   

fiframing image description ranking task

maximizes f  iq   s  query image iq icand   cases  f  i  s  course
maximized image sentence pairs sentence describes image well 
image search 
image annotation 

  arg maxiicand f  i  sq  


   

  arg maxsscand f  iq   s 

formulation completely general  although will  evaluation purposes  define
scand set captions originally written images icand  
case  scand could also  example  defined implicitly via caption generation
system  order evaluate well f generalizes unseen examples  evaluate
system test pools itest stest drawn domain disjoint
training data dtrain    itrain   strain   development data ddev    idev   sdev   
challenge defining f lies fact images sentences drawn two
different spaces  s  paper  present two different kinds image description
systems  one based nearest neighbor search  nn   uses technique called
kernel canonical correlation analysis  kcca  bach   jordan        hardoon et al         
rely set known image sentence pairs dtrain    hi  si  
    nearest neighbor search image description
nearest neighbor based systems use unimodal text image similarity functions directly
first find image sentence pair training corpus dtrain contains closest
item query  score items space similarity
item pair 
image retrieval  fnn  i  sq      inn   i 

hinn   snn   arg max fs  sq   st      
hit  st idtrain

image annotation  fnn  iq   s    fs  snn   s  hinn   snn   arg max  iq    
hit  st idtrain

despite simplicity  nearest neighbor systems non trivial baselines 
task annotating images tags keywords  methods annotate unseen images
tags nearest neighbors among training images known achieve competitive performance  makadia et al          similar methods recently proposed
image description  ordonez et al          since task address allow
us return items training data  requires us rerank pool unseen captions
images  nearest neighbor search requires two similarity functions  nearestneighbor systems use image representation kcca based systems  described
section      main nearest neighbor system  nn  nn idf
f     treats five captions
associated training image single document  reweights token
inverse document frequency  idf  w   defines similarity two sentences
f  measure  harmonic mean precision recall  computed idf reweighted
bag of words representation  dtrain  w  subset training images whose captions
word w appears least once  inverse document frequency  idf  w defined
 dtrain  
w   log  dtrain
 w       idf reweighting potentially helpful task  since words
describe fewer images may particularly discriminative captions 
   

fihodosh  young   hockenmaier

appendix  provide results nn systems use text representation
two kcca systems 
    kernel canonical correlation analysis image description
systems present based technique called kernel canonical correlation
analysis  bach   jordan        hardoon et al          first provide brief introduction 
explain apply task 
      kernel canonical correlation analysis  kcca 
kcca extension canonical correlation analysis  hotelling         takes
training data consisting pairs corresponding items hxi   yi drawn two different
feature spaces  xi x   yi y   finds maximally correlated linear projections x
sets items newly induced common space z  since linear projections
raw features may capture patterns necessary explain pairing
data  kcca implicitly maps original items higher order spaces x     via
kernel functions kx   hx  xi   x  xj  i  compute dot product two data points
xi xj higher dimensional space x   without requiring explicit computation
mapping x   kcca operates two resulting kernel matrices kx  i  j   
hx  xi   x  xj  i ky  i  j    hy  yi    yj  i evaluate kernel functions
pairwise combinations items training data  returns two sets projection weights 
  maximize correlation two  projected  kernel matrices 
        arg max q
 

  kx ky
   k x     kx      k y     ky  

   

cast generalized eigenproblem  kx  i   ky  ky  i   kx      
solved partial gram schmidt orthogonalization  hardoon et al         socher   li 
       regularization parameter penalizes size possible solutions  used
avoid overfitting  arises matrices invertible 
one disadvantage kcca requires two kernel matrices training
data kept memory training  becomes prohibitive large data
sets  cause problems here  since training data consists      
items  see section      
      using kcca associate images sentences
kcca successfully used associate images  hardoon et al         hwang  
grauman        hardoon et al         image regions  socher   li        individual
words sets tags  case  two original spaces x     correspond
images sentences describe them  images first mapped vectors ki  i 
whose elements ki  i  t    ki  it   i  evaluate image kernel function ki t th
image dtrain   similarly  sentences mapped vectors ks  s  evaluate
sentence kernel function ks sentences dtrain   learned projection weights
      map ki  i  ks  s  induced space z  expect images
appear near sentences describe well  kcca based image annotation
   

fiframing image description ranking task

search system  therefore define f cosine similarity  sim  points new space 
fkcca  i  s    sim ki  i   ks  s  

   

describe image text kernels used kcca systems 
    image kernels
contrast much work done image description  assumes existence
large number preexisting detectors  image representations used paper
basic  rely three different kinds low level pixel based perceptual
features capture color  texture  varma   zisserman        shape information
form sift descriptors  lowe        vedaldi   fulkerson         believe
establishes important baseline  leave question complex image
representations affect performance future work  use two different kinds kernels 
histogram kernel k histo   represents image single histogram feature
values computes similarity two images intersection histograms 
pyramid kernel k py  lazebnik  schmid    ponce         represents image
pyramid nested regions  computes similarity two images terms
intersection histograms corresponding regions  cases  compute separate
kernel three types image features average result 
      histogram kernel  k histo  
image xi represented histogram hi discrete valued features  hi  v 
fraction pixels xi value v  similarity two images xi xj defined
intersection histograms  i e  percentage pixels mapped
onto pixel feature value image 
k xi   xj    

v
x

min hi  v   hj  v  

   

v  

combine three kernels based different kinds visual features  kc captures color 
represented three cielab coordinates  kt captures texture  represented descriptors capture edge information different orientations centered pixel  varma
  zisserman         ks based sift descriptors  capture edge shape information manner invariant changes rotation illumination 
shown distinct across possible objects image lowe        vedaldi   fulkerson 
      use     color words      texture words     sift words  obtained unsupervised fashion k means clustering       points     images pascal
     data set  everingham et al          final histogram kernel k histo average
responses three kernels kchisto   kthisto   kshisto   taken pth power 

p
  x
k histo  xi   xj    
kfhisto  xi   xj  
   
 
f  c s t 

   

fihodosh  young   hockenmaier

      pyramid kernel k py
spatial pyramid kernel  lazebnik et al         generalization histogram kernel
captures similarities global  local level  image xi
represented multiple levels scale l  l            level partitions
image smaller smaller grid cl    l  l cells  c       c       c        
cell c represented histogram hic   similarity images xi xj level l 
iijl   turn defined sum histogram similarities corresponding cells
 l        cl level 
iijl

 

cl x
v
x

min hic  v   hjc  v  

   

c  l v  

although similarities level l subsume fine grained level l      iijl
iijl      similarities hold fine grained level deemed important  since
indicate greater local similarity  pyramid kernel therefore proceeds
fine grained  l   l  coarsest  whole image  scale  l       weights
 
similarities first encountered level l  iijl iijl      ll
 

k

py

 xi   xj    

iijl

 

l 
x
l  

 
 i l iijl    
 ll ij

   

l

 

    x  
 
il
 l ij
 ll   ij
l  

compute three separate pyramid kernels kcpy   ktpy   kspy based
color  texture sift features described above  combine single pyramid
kernel k py   equation   
    basic text kernels
examine three different basic text kernels  bag words  bow  kernel  hwang
graumans        tagrank kernel  truncated string kernel  tri  
      bag words kernel  bow 
since bag of words representations successfully used tasks involving text
images  e g   grangier   bengio        hardoon et al          include basic bag
words kernel  ignores word order represents caption simply vector
word frequencies  bow kernel function defined cosine similarity
corresponding bag words vectors  either merge five captions training item
single document  bow    reduce training item single  arbitrarily chosen 
caption  bow    words frequency reweighted idf score 
 dtrain  
nearest neighbor approach  idf weight word w defined w   log  dtrain
 w      
dtrain  w  subset training images whose captions word w appears least

   

fiframing image description ranking task

once  found square root w  bow 
idf score w  bow idf   



idf  

give better results standard

      tag rank kernel  tagrank 
hwang grauman        apply kcca keyword based image annotation retrieval 
focus data set image paired list tags ranked importance  propose new kernel kind data  so called tag rank kernel
 tagrank  variant bag words kernel aims capture relative importance tags reweighting according position list  although hwang
grauman evaluate ability system associate images entire
sentences  consider another data set lists tags correspond
words descriptive captions  argue linear order words captions
reflects relative importance corresponding objects image  words
appear beginning sentence describe salient aspects image 
tagrank kernel  sentence represented two vectors   a  r   a 
weight word based absolute position  first words sentence
always assigned high weight  absolute tag rank representation  caption
mapped vector  a     a           a  v       v   size vocabulary   a i 
depends absolute position pi wi  if wi occurs multiple times s  pi averaged
positions   wi occur s   a i       otherwise 
 a i   

 
log       pi  

   

 r  weight word depends current position compares distribution positions occupies training data  intuition behind relative rank
representation words higher weight occur earlier sentence usual  here  caption mapped vector  r     r           r v    relative
tag ranks  again  wi appear s   r i       otherwise wi relative tag rank
 r i  indicates percent occurrences training data appear position pi  
defining
p nik number times word wi appears position k training data 
ni   k nik total frequency wi training data 
ppi
 r i     

k   nik

    

ni

final kernel kt given average two   kernels computed  r  a  
  normalization terms  
 



 
v
v
 
  x   ri  k   rj  k   
  x   ai  k   aj  k   
kt  xi   xj    
exp
  exp
    
 
 
 ri  k     rj  k 
  
 ai  k     aj  k 
k  

k  

since image training data associated multiple  independently generated captions  evaluate kernel separately sentence pair average
response  instead treating multiple sentences single document 
   

fihodosh  young   hockenmaier

tagrank kernel relatively sensitive overall sentence length  especially cases
subject preceded multiple adjectives modifiers  a large brown
dog vs  dog    english  absolute tag rank generally assign high weights
subjects sentences  lower weight verbs  even lower weight objects scene
descriptions  tend follow main verb  relative tag rank may downweight
verbs  objects scene descriptions much  as long always used similar
positions sentence  
      trigram kernel  tri 
since bag of words representations ignore words appear close
sentence  lose important information  image small child red hair playing
large brown dog white carpet looks quite different one small white dog
playing large red ball brown grass  although descriptions share majority
words  capture information  define trigram kernel truncated variant
string kernels  shawe taylor   cristianini        considers many single
words two captions share  many short sequences  pairs triples  words
occur both 
word sequence w   w     wk ordered list words  sentence   s     sn contains
w  w s  long words w appear order specified w  is 
sentence large white dog runs catches red ball beach  when lemmatized 
contains subject verb object triple dog catch ball subject verb location
triple dog run beach  formally  every substring  i  j    si    sj starts si   w   
ends sj   wk   contains w considered match w  ms w set
substrings match sequence w 
ms w     i  j    w   w     wk si    sj   w    si   wk   sj  

    

w restricted individual words  k       string kernels identical standard
bow kernel 
match strings s  pair substrings  i  j   i    j     s 
match word sequence w  standard string kernels k s  s    weight matches
 
 
factor  ji     j     depends adjustable parameter respective
length matching substrings 
k s  s     

x

x

x

 

 

 ji     j    

    

w  i j ms w  i   j    ms   w

order distinguish length matching subsequence  l w  
length gaps  i  j   i    j      replace two parameters   g   reformulate
as 
k s  s     

x

x

x

 

 

    l w 
 l w 
 ji     j

g

    

w  i j ms w  i   j    ms   w

found gap score g      means gaps penalized 
match score       perform best task 
   

fiframing image description ranking task

although string kernels generally defined sequences arbitrary length  k   
found allowing longer sequences seem impact performance task
incurred significant computational cost  intuitively  word pairs triplets represent
linguistic information need capture beyond bow representation  since
include head modifier dependencies large dog vs  small dog subject verb object
dependencies child play dog vs  dog play ball  therefore consider sequences
length k    w restricted sequences length k   ms w    ms w   
yields following trigram kernel  tri  
ktri  s  s     

x

ms w ms   w  l w 


    

w k 

deal differences sentence length  normalize kernel response
two examples geometric mean two example responses themselves 
since trigram kernel captures sequences merely coincidental 
large white red  may seem advantageous use richer syntactic representations
dependency tree kernels  moschitti  pighin    basili         consider word
tuples correspond syntactic dependencies  however  kernels significantly
expensive compute  initial experiments indicated may perform
well trigram kernel  believe due fact image captions
contain little syntactic variation  hence surface word order may sufficient
differentiate e g  agent action  whose mention subject
sentence  participants entities  whose mentions appear verb  
hand  many image captions contain lot syntactic ambiguity  e g 
multiple prepositional phrases   vocabulary distinct standard
parsers trained on  may able benefit using richer
representation simply able recover sufficient accuracy 
order capture
relative importance words  reweight sequences

idf  or idf  weight theirqwords 
w defined before  idf weight
j
sequence w   wi    wj w  
idf weighted trigram kernel ktriidf
k i wk  
 tri 



idf  

therefore

ktriidf  s  s     

x

w ms w ms   w  l w 


    

w k 

    extending trigram kernel lexical similarities
one obvious shortcoming basic text kernels require exact matches
words  cannot account fact situation  event  entity
described variety ways  see figure   examples   one way capturing
linguistic diversity lexical similarities allow us define partial matches
words based semantic relatedness  lexical similarity found success
tasks  e g  semantic role labeling  croce  moschitti    basili        
fully exploited image description  ordonez et al         define explicit equivalence classes
synonyms hyponyms increase natural language vocabulary corresponding
object detectors  e g  word dalmatian may trigger dog detector  
   

fihodosh  young   hockenmaier

change underlying  pre trained detectors themselves  ignoring potential
variation appearance between  e g   different breeds dog  similarly  yang et al s       
generative model produce variety words type detected object scene 
given object scene label  word choice independent visual features 
therefore investigate effect incorporating different kinds lexical similarities
trigram kernel allow us capture partial matches words 
explore effect incorporating lexical similarities tag rank kernel  since
unclear affect computation ranks within sentence 
      string kernels lexical similarities
since standard lexical similarities sims  w  wi   necessarily yield valid kernel functions 
follow bloehdorn  basili  cammisa  moschitti        use similarities
map word w vectors w
  n  dimensional space  defined fixed vocabulary
size n   vector component w
   i  corresponds similarity w wi defined
 
    

w
   i    sims  w  wi  

define corresponding word kernel function  w  w     captures partial
match words w w  according   cosine angle w
  w
  s   
 w  w      cos  
ws   w
  s   

    

may defined subset vocabulary  similarity words outside
vocabulary defined identify function  standard string kernel 
similarity sequences w w  length l defined product word
kernels corresponding pairs sequence elements wi   wi   
 w  w     

l


 wi   wi   

    

i  

 w     w   s  w    w       l w      l w   set sequences non zero
match w  string kernel ks similarity is 
ks  s  s     

x

x

ms w ms   w   l w 
 w    w 


    

w w   w 


idf
 
obtain
idf weighted version kernel  ks  s     inner term multiplied w w   
x x p
ks  s  s     
w w  ms w ms   w  l w 
 w    w 
    

w w   w 

experiments  use trigram variants kernels  restrict w
sequences length k   
consider three different kinds lexical similarities  wordnet based lin similarity
 lin         lin    distributional similarity metric  d    novel alignment based
   

fiframing image description ranking task

similarity metric  a    takes advantage fact image associated
five independently generated captions  metrics computed training corpus 
distributional similarity computed british national corpus  bnc consortium 
       corpora lemmatized  stop words removed similarities
computed  since almost pair words non zero similarity  word kernel
matrices dense  since similarities close zero 
little effect resulting kernel  therefore zero entries smaller     
alignment based kernel less      distributional kernel dc  
      lin similarity kernel  lin  
lins        similarity relies hypernym hyponym relations wordnet  fellbaum 
      well corpus statistics  wordnet directed graph nodes  synsets 
represent word senses edges indicate is a relations  parent sense  e g   dog   
hypernym children  e g   poodle  dachshund     kernels based lins similarity
found perform well tasks text categorization  bloehdorn et al         
exception farhadi et al          incorporate lins similarity
model  evaluate benefit obtain it  wordnets hypernym hyponym
relations used superficially associating images text  weston et al  
      ordonez et al         gupta et al          lin similarity two word senses si   sj
defined
  log p  lcs si   sj   
simlin  si   sj    
    
log p  si     log p  sj  
lcs s    s    refers lowest common subsumer s  s  wordnet  i e 
specific synset ancestor  hypernym  s  s    p  s  probability
randomly drawn word instance synset descendants  hyponyms  
use training data estimate p  s   follow bloehdorn et al         assigning
word w frequent  first  noun sense sw wordnet      hence  represent
word w wordnet sense vector w
  lin lin similarities hypernyms h sw   
 log f  si   

log f  s   log f  si   
w
  lin  i   
 


 

si h s 
sw   si
otherwise

    

      distributional similarity  dc  
distributional similarity metrics based observation words similar
tend appear similar contexts  jurafsky   martin         components
w
  dc non negative pointwise mutual information scores  pmi  w wi   computed
corpus c 


pc  w  wi  
    
w
  dc  i    max    log 
pc  w pc  wi  
pc  w  probability random sentence c contains w  pc  w  wi  
probability random sentence c contains w wi   compute two variants
   

fihodosh  young   hockenmaier

metric  dic computed image captions training corpus 
defined cooccurrences       words appear least   times corpus 
dbnc uses british national corpus  bnc consortium         defined
      words appear least   times corpora  considers pmi scores
        words appear least   times bnc 
      alignment based similarity  a  
propose novel  alignment based  similarity metric  a    takes advantage
fact image associated five independently generated captions 
specifically designed capture likely two words describe event
entity data set  borrow concept alignment machine translation
 brown  pietra  pietra    mercer         instead aligning words sentences two
different languages  align pairs captions describe image  results
similarity metric better coverage data set wordnet based metrics 
much specific distributional similarities capture broad topical relatedness
rather semantic equivalence  instead aligning complete captions  found
beneficial align nouns verbs independently other  ignore parts
speech  create two versions training corpus  one consisting nouns
caption  another one consisting verbs caption 
use giza    och   ney        train ibm alignment models     brown et al        
pairs noun verb captions image obtain two sets translation
probabilities  one nouns  pn   w   one verbs  pv   w    finally  combine
noun verb translation probabilities sum weighted relative frequency
word w tagged noun  pn  w   verb  pv  w   training corpus 
ith entry wa therefore 
w
   i    pn  wi  w pn  w    pv  wi  w pv  w 

    

define noun verb vocabulary follows  words appear least   times
noun  tagged noun least     occurrences  considered
nouns  since verbs polysemous nouns  leading broader translation
probabilities  often mistagged nouns domain  include words
verbs tagged verbs least    times  least     occurrences 
results      noun     verb lemmas  including    nouns verbs 
use opennlp pos tagger lemmatization 
      comparing similarity metrics  figure   
figure   illustrates different similarity metrics  using words rider swim
examples  distributional similarities high words topically related
 e g   swim pool    alignment similarity tends high words used
describe entity  usually synonyms hyper hyponyms  activity swim
paddle  distributional similarities obtained image captions
specific domain  bnc similarities much broader help overcome data
sparsity  although bnc relatively low coverage kinds sports occur
data set  lin similarity associates swim hypernyms sport activity 
   

fiframing image description ranking task

comparing similarity metrics  five words similar rider swim
alignment
strain
wi


wi

rider

biker
bicyclist
cyclist
bmx
bicycler

    
    
    
    
    

bike
dirt
motocross
motorcycle
ride

    
    
    
    
    

ride
horse
race
bike
jockey

swim

retrieve
paddle
dive
come
wade

    
    
    
    
    

pool
trunk
water
dive
goggles

    
    
    
    
    

fish
water
sea
pool
beach

corpus
w

distributional
strain
bnc
dic wi
dbnc

lin
strain
wi

lin

    
    
    
    
    

traveler
cyclist
bicyclist
horseman
jockey

    
    
    
    
    

    
    
    
    
    

bathe
sport
football
activity
soccer

    
    
    
    
    

figure    comparison lexical similarities noun rider verb swim
kinds sport football soccer  makes least suitable similarity
task  see section       experimental results   since terms
considered similar purposes identifying different ways visually similar
events entities described 
      combining different similarities
combining different distributional alignment based similarities allows us
capture different strengths method  define averaged similarity
captures aspects distributional similarities computed corpora 
dbnc  w  w      dic  w  w   
    
 
every distributional kernel  w  w     define variant d a  w  w   
incorporates alignment based similarities taking maximum either kernel  
dbnc ic  w  w     

d a  w  w      max a  w  w      w  w    

    

   evaluation procedures metrics image description
order evaluate scoring functions f  i  s  image caption pairs  need evaluate
ability associate previously unseen images captions other  analogy
caption generation systems  first examine metrics aim measure quality
single image description pair  section       here  focus image annotation task 
restrict attention first caption returned test item  subset
systems  collect graded human judgments small number native speakers
american english  investigate whether expert judgments approximated
   operation may preserve positive definiteness matrix required valid kernel 
simply means effectively use  plain  cca representation 

   

fihodosh  young   hockenmaier

automatically computed bleu  papineni et al         rouge  lin   hovy       
scores  simpler crowdsourced human judgments collected much
larger scale  section      consider approaches evaluation aim measure
quality ranked list image caption pairs returned system  allow us
evaluate large number systems  reasons space  focus discussion
subset systems  refer interested reader appendix b
complete results  since candidate pool contains one sentence image originally
associated query image sentence  first compare systems rank recall
original item  metrics computed automatically 
considered lower bounds actual performance  since image may associated
number captions describe well perhaps minor errors  show
crowdsourced human judgments mapped binary relevance judgments
correlate well fine grained expert judgments  consider metrics based
relevance judgments 
    experimental setup
describe data  tasks  systems evaluate experiments 
      data
since pascal      data set contains total       images  perform
experiments exclusively flickr  k set  split       images corpus  see
section      three disjoint sets  training data dtrain   hitrain   strain consists
      images  associated five captions  whereas test development data 
dtest ddev   consist       images associated one  arbitrarily chosen  caption 
captions preprocessed spellchecking linux spell  normalizing compound words
 e g   t shirt  shirt  tee shirt t shirt   stop word removal  lemmatization 
      tasks
evaluate systems two tasks  sentence based image annotation  or description 
sentence based image search  image search  task return ranked list
      images itest captions  queries  stest   image annotation defined
analogously retrieval problem  task return ranked list       captions
stest       test  query  images itest   cases  ranked lists
produced independently       possible queries 
      systems
total    different systems  uses either nearest neighbor approach
kcca  paired different combination image text representations 
purposes discussing different evaluation metrics  focus small number
systems  best performing nearest neighbor based system  nn  nn idf
f    
small number kcca based systems different text kernels  bow  bow 
use simple bag of words kernel  tagrank uses
hwang graumans       

idf
kernel  tri  uses trigram kernel  tri sem  tri a dbnc ic appendix b  uses
   

fiframing image description ranking task



idf reweighted trigram kernel distributional alignment based similarities 
exception bow   arbitrarily selected single caption
training image  models use five captions training images  bow  
merge single document  cases  follow moschitti       
sum kernel responses cross product sentences normalization 
systems  including nn  use pyramid kernel image representation 
large scale evaluations section      scores models given appendix b 
systems use hardoon et al s        kcca implementation  allows us
vary regularization parameter   vary n  number dimensions  largest
eigenvalues  learned projection allowable values parameters based
early exploratory experiments  experiments reported paper  sampled
  possible values                   n chosen    possible values range
            two additional parameters fixed advance text
image kernel pair  image kernels either squared cubed  text kernels
regularized multiplying values diagonal factor range         
kernel two tasks  image annotation search   use
development set pick five settings n maximize recall original
item first result  five settings maximize recall among first five results 
five settings maximize recall among first ten results  yielding total   
different models pair kernels task  query image  annotation 
caption  search  test set     models returns ranking       test
items  sentences images   combine    rankings  use borda counts  van erp  
schomaker         simple  deterministic method rank aggregation  n items
ranked  system assigns score n r item ranks position r       n   
final rank item determined sum scores across systems 
break ties items median ranks across models 
    metrics quality individual image caption pairs
consider metrics consider quality ranked list results  section      
first examine metrics measure quality individual image caption pairs 
      human evaluation graded expert judgments
expert scores decision well caption describes image ultimately requires
human judgment  caption generation task  number different evaluation schemes
proposed image description  ordonez et al         presented judges
caption produced model asked make forced choice random
image image caption produced for  kuznetsova et al         asked judges
choose captions two models given test image  forced
choice tasks may give clear ranking models  cannot compared across different
experiments unless output system made publicly available  one advantage
framing image description ranking task different systems compared
directly test pool  forced choice evaluations directly measure
quality captions  following common practice natural language generation  yang
et al         kulkarni et al         evaluated captions graded scale relevance
   

fihodosh  young   hockenmaier

    describes image
without errors
 score     

selected caption    
    describes image
minor errors
 score     

    somewhat
related image
 score     

    unrelated
image
 score     

girl wearing
yellow shirt
sunglasses smiles 

man climbs
sheer wall
ice 

miami basketball
player dribbles
arizona state player 

group people
walking city street
warm weather 

boy jumps
blue pool
water 

dog grassy field 
looking up 

basketball players
action 

man riding motor
bike kicks dirt 

dogs pulling
sled
sled race 

two little girls
practice martial
arts 

snowboarder
air snowy
mountain 

child jumping
tennis court 

boy blue life
jacket jumps
water 

black dog
purple collar
running 

figure       rating scale fine grained expert judgments  actual examples
returned best model  tri sem 
readability  li et al         added creativity score  mitchell et al        
compared systems based whether captions describe main aspects images 
introduce objects appropriate order  semantically correct  seemed
written human 
since captions test pool produced people  need evaluate
linguistic quality  focus semantic correctness  order obtain
fine grained assessment description quality  asked three different judges score imagecaption pairs returned systems graded scale      judges   
adult native speakers american english  mostly recruited among local graduate
student population  contrast anonymous crowdsourcing based evaluation described
section        refer experts  rating scale illustrated figure  
actual examples returned models  score   means caption describes
image perfectly  without mistakes   score   caption almost describes
image  minor mistakes allowed  e g  number entities   whereas score
  indicates caption describes aspects image  could
used description  score   indicates caption bears relation
image  online appendix paper contains annotation guidelines  annotators
took average ten minutes per    image caption pairs  image caption pairs
judged independently three different annotators  inter annotator agreement  measured
krippendorffs          high            artstein   poesio         final score
image caption pair obtained averaging three individual scores  since
time consuming evaluation  judged highest ranked caption
test image annotation task  focused subset models described
above  gauge difficulty task data set  include random
baseline  since evaluate single caption image  interested
percentage images suitable caption returned  therefore show
models cumulative distribution test items scores thresholds ranging
   

fiframing image description ranking task

quality first caption  image annotation 
cumulative distribution expert scores    x 
                                 
       
       
bow 
       
bow 
   
    
tagrank    
    

   
   
   
    
    

   
   
    
    
    

   
    
    
    
    

   
    
    
    
    

   
    
    
    
    

tri sem     

    

    

    

    

    

random
nn

    

table    cumulative distribution expert judgments    scale  figure     indicating
percentage image caption pairs judged given score  scores
averaged three judges  superscripts indicate statistically significant difference
tri sem     p        p         p       
         threshold interpreted less strict mapping
fine grained scores binary relevance judgments  order assess whether difference
models given threshold reaches statistical significance  use mcnemars
significance test  paired  non parametric test advocated evaluation
binary classifiers  dietterich         given output models b
set items  mcnemars test considers items bs output differ  the
discordant pairs output  test null hypothesis outputs drawn
underlying population  among discordant pairs  compares proportion
items model successful model b proportion items
model b successful model not  results tables  superscripts indicate
whether difference model tri sem statistically significant     p     
  p         p        
expert results  table    first interpret expert scores binary relevance
judgments  therefore show cumulative distribution different thresholds in 
see clear differences random baseline  nn  kcca models
thresholds  differences nn random model  well
kcca model nn highly significant  p          threshold  random
baseline returns perfect caption      images  good caption  assuming
threshold            images  best kcca model  tri sem  returns
perfect caption       good caption       images  however 
differences among kcca models subtle  may become apparent
lower thresholds  significant difference bow  tagrank
threshold  significantly better bow   p          thresholds
     above  tri sem outperforms models  differences bow 
tagrank reach statistical significance threshold considered
suitable caption lowered either       p              p                p        
      p           lack statistical significance partially explained
fact mcnemars test relatively low power percentage items
two models successful low  case higher thresholds here 

   

fihodosh  young   hockenmaier

show sections             significant difference
tri sem two models image annotation extend analysis
beyond highest ranked caption  shows evaluations based
single caption returned per image may fail uncover significant differences models
become apparent multiple results considered  may important
consider performance annotation retrieval  image retrieval task 
see tri sem significantly outperforms models even first
result considered  table   reveals another artefact mcnemars test  since
based absolute differences performance number discordant pairs 
difference bow  tri sem thresholds          considered less
significant bow  tri sem thresholds  even though
bow s scores lower bow s  table    present systems average expert
scores  use fishers randomization test determine statistical significance  according
evaluation  tri sem significantly better models  p       
cases   since average score tri sem       difference reflected
higher thresholds cumulative distribution shown table   
      automatic evaluation bleu rouge
since human judgments expensive time consuming collect  examine
well approximated bleu  papineni et al         rouge  lin        
two standard metrics machine translation summarization 
bleu rouge scores bleu rouge scores computed automatically
number reference captions  used evaluate number caption
generation systems  kulkarni et al         ordonez et al         li et al         kuznetsova
et al         yang et al         gupta et al          although unclear well
correlate human judgments task 
given caption image associated set reference captions ri  
bleu score proposed image caption pair  i  s  based n gram precision
ri   rouge based corresponding n gram recall  common
image description  consider unigram based scores  only      possible imagecaption pairs test non zero bigram based bleu   score        set
non zero bleu   score   ignore bleus brevity penalty  since data set
relatively little variation sentence length  would avoid penalizing short 
generic captions include details otherwise correct  hence  cs  w 
number times word w occurs s 
p

bleu i  s   
rouge i  s 

 

min cs  w  maxrri cr  w  
p
ws cs  w 
p
p
min cs  w  cr  w  
rri
p wrp
rr
wr cr  w 
ws

    



reference candidate captions preprocessed  first tokenize sentences
opennlp  tools  break hyphenated words  stripping non alphanumeric
   http   opennlp apache org

   

fiframing image description ranking task

avg  score first caption
 image annotation 
expert

bleu


rouge

bow 
bow 
tagrank

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

tri sem

    

    

    

random
nn



table    comparison averaged scores according   point expert evaluation  figure     bleu rouge  using five test captions reference  superscripts indicate
statistically significant difference tri sem     p        p         p       
hyphen characters  converting words lower case  following work lin
        use stemmer  porter        remove stopwords compute rouge
scores  compute bleu rouge score system average bleu
rouge scores items test set  
use fishers randomization test  fisher        smucker  allan    carterette       
assess statistical significance difference models  paired 
sampling based test evaluates null hypothesis results models
b produced underlying distribution  sample  scores
b assign test item randomly reassigned two models  p values
obtained comparing actual difference bs performance
fraction samples equal greater difference models  sample        
reassignments entire test set 
bleu rouge results  table    table   shows average bleu rouge scores
highest ranked caption pairs returned image annotation systems  computed
reference pool consisting five original captions test image  including
caption randomly selected part candidate pool   scores
lead broad conclusions average expert scores  metrics find clear
differences  p           random baseline models 
well nn kcca models  none find significant difference
bow  tagrank  tri sem outperforms kcca models according
metrics  expert evaluation rouge find much larger difference
bow   experts  p         rouge  p          tagrank  experts  p         
rouge  p           bleu finds significant difference tagrank  p         
bow   p          indicates bleu may less well suited identify
subtle differences systems 
agreement bleu rouge expert scores since difficult measure
directly well bleu rouge scores agree expert judgments  consider
   systems bleu score usually computed corpus level  since dealing
unigram scores evaluate systems sentences corpus  averaged sentence level
bleu scores systems report almost identical  r          corpus level bleu scores 

   

fihodosh  young   hockenmaier

number different relevance thresholds type score  b   r   e    turn
binary relevance judgments  allows us use cohens        measure
agreement corresponding binarized scores  since bleu rouge
require set reference captions test image  compare four different ways
defining set reference captions  for detailed scores  see tables     appendix  
since data set contains multiple descriptions image  first use five
captions reference  setting  bleu reaches best agreement          
e       b       e     b      however  high bleu
scores generally obtained system proposes original caption  rouge
much lower agreement           expert scores  obtained r     vs 
e     e      r     e      since data sets may
one caption per image  evaluate reference corpus consists
single caption test pool  case  metrics reach highest
agreement expert threshold e        bleu          rouge          
thresholds b      r      conclude neither bleu rouge
useful scenario  since require high thresholds capture
often system returned reference caption 
bleu rouge used evaluate caption generation systems  cannot
assume generated caption identical one reference captions  therefore
examine extent bleu rouge scores agree human judgments
candidate pool contains human generated captions  disjoint reference captions  first use reference corpus four captions per image  excluding caption
use candidate pool  case  three metrics show significantly lower agreement
human judgments candidate pool contains reference caption  bleu
reaches         with b     e      rouge reaches       
 with r     e       simulate case single caption per
image available  evaluate reference corpus consisting one
four captions  case  agreement human judgments even lower  bleu reaches
        rouge reaches         results suggest bleu rouge
appropriate metrics pool candidate captions contain reference
captions  lead us question usefulness evaluation caption generation
systems  consistent findings reiter belz         studied
bleu rouge scores evaluate natural language generation systems  concluded
may useful metrics fluency  poor measures content quality 
    metrics large scale evaluation image description systems
metrics consider first caption returned image cannot capture fact
better model score good captions higher captions  even fails
consider best possible caption  since systems return ranked list results
item  examine metrics allow us evaluate quality list 
contrast human evaluations described section     above  evaluate
image retrieval systems  first consider metrics computed automatically 
recall median rank item  image sentence  originally associated
query sentence image  section         show use crowdsourcing

   

fiframing image description ranking task

performance  rank original item
r k  percentage queries original item among top x responses 
median r  median rank original item
r  

image annotation
r   r    median r

bow 
bow 
tagrank
tri 

   
   
   
   
   

   
    
    
    
    

   
    
    
    
    

tri sem

   

    

    

nn

     
    
    
    
    
    

r  

image retrieval
r   r    median r

   
   
   
   
   

   
    
    
    
    

   
    
    
    
    

   

    

    

     
    
    
    
    
    

table    model performance measured rank original image caption   
correct response   r k  percentage queries correct response among
first x results  median r  median position correct response ranked list
results  superscripts indicate statistically significant difference tri sem     p      
  p       
collect large number human judgments  section         use relevance
judgments define two additional metrics  rate success  akin recall 
r precision  established information retrieval metric  section         although
metrics allow us evaluate systems  focus discussion small set
systems considered far  refer interested reader section b appendix
scores systems 
      recall median rank original item
one advantage ranking framework position original caption image
among complete list       test items determined automatically  since better
system should  average  assign higher rank original items worse system 
use ranks define number different evaluation metrics 
recall  r k  median rank scores since query associated
single gold result  need concerned precision  however  recall position k
 r k   i e  percentage test queries model returns original item among
top k results  useful indicator performance  especially context search 
user may satisfied first k results contain single relevant item  focus
k             r    r    r      since binary metric  for query  gold item
either found among top k results not   use mcnemars test identify
statistically significant differences models  conversely  median rank indicates
k system recall      i e  number results one would
consider order find original item half queries   here  use fishers
randomization identify significant differences models 
recall  r k  median rank results  table    results table   confirm
earlier observation nn baseline clearly beaten kcca models  p        
metrics models  except r   search  difference bow 
   

fihodosh  young   hockenmaier

p value p          since r   annotation scores based image caption
pairs expert scores table    compare directly  difference
r   expert scores  even strictest threshold     experts  indicates
measures capture often original caption returned viewed
lower bound actual performance  tri sem returns original caption first
     images  human judges found captions describe      
images without errors  discrepancy even larger bow        vs       
tagrank       vs         consequence  automatically computed r   scores
indicate erroneously statistically significant difference quality
first captions returned tri sem returned bow  tagrank  even
though differences significant according human evaluation  however 
metrics based first caption may fail identify differences
models become apparent metrics  example  r   reveals
significant difference tri  tri sem annotation task  although
difference highly significant according metrics  section        present
results large scale human evaluation confirm actual differences
tri sem tri  annotation identified first caption
taken account 
table    section b provides recall median rank scores models 
      collecting binary relevance judgments large scale
order perform human evaluation system goes beyond measuring quality
highest ranked result  would obtain relevance judgments imagecaption pairs among top k results query  since two tasks 
total    different systems  set consists         distinct image caption pairs
k       rendering exhaustive evaluation four point scale described section      
infeasible  therefore needed reduce total number judgments needed 
define simpler annotation task could completed less time  crowdsourcing
platforms amazon mechanical turk offer new possibilities evaluation
enable us collect large number human judgments rapidly inexpensively 
number researchers evaluated caption generation systems mechanical turk
 ordonez et al         yang et al         kuznetsova et al         kulkarni et al         li
et al          experiments performed scale analysis 
evaluated well crowdsourced judgments task approximate
obtained smaller pool judges given detailed instructions 
examine whether crowdsourcing allows us collect reliable relevance judgments
large scale evaluation image description systems 
crowdsourcing task presented workers images paired ten
different captions  asked indicate  via checkboxes  captions describe
image  adapted guidelines developed fine grained annotation
caption describes image minor errors  corresponding score  
  point scale  would still permitted receive positive score  guidelines
found online appendix paper  individual task consisted six different
images  paired ten captions  included copy guidelines  accessed
   

fiframing image description ranking task

amazon mechanical turk service provided crowdflower com  makes
easy include control items quality control  one six images task
control item  generated taking random images development
set  using one three original captions correct responses  adding
another nine seven randomly selected captions  which verified manually
describe image  incorrect responses  used workers judged    
control items correctly  image caption pair annotated three different
annotators  at total cost       final score image caption pair
computed average number positive judgments received 
filtering unlikely image caption pairs order reduce number annotations
needed  devised filter based bleu scores  papineni et al         filter imagecaption pairs whose caption dissimilar five captions originally written
image highly unlikely describes image  found filter based
unigram bleu   scores combination stemming stop word removal
standardly done lins        rouge script  bleupre   proved particularly effective 
threshold bleupre      filters       possible              image caption
pairs test set  eliminates      pairs expert score     
greater       pairs expert score   greater  slightly higher cutoff
bleupre      would filter       image caption pairs  discard      
image caption pairs expert score           image caption pairs
expert score    among         image caption pairs actually wished
obtain judgments for       filter eliminates        reducing number pairs
needed annotate         since setup required us pair image number
captions multiple     annotated additional        image caption
pairs filtered out  allowing us evaluate performance filter 
      filtered pairs  mechanical turk judges decided caption
describe image        them  majority annotators thought so 
found standard bleu   without preprocessing effective filter  threshold
bleu       misses      good captions  with expert score        
filtering     entire data set  whereas threshold bleu       filters
    entire data set  misses       good captions 
agreement crowdsourced expert judgments use cohens
measure agreement crowdsourced expert judgments  table   
appendix   best agreement obtained crowdsourced scores threshold
      i e  least two three judges think caption describes image 
expert scores threshold       one expert thinks caption describes
image perfectly two agree think describes image minor
errors  two experts think describes image perfectly one thinks
least related           significantly better approximation expert
scores possible either bleu rouge  examine precision  recall
f scores approximate relevance judgments achieve compared
relevance judgments obtained binarizing expert judgments  table           
items perfect expert score  and       items almost perfect expert
score      identified  least       items pass threshold
   

fihodosh  young   hockenmaier

expert score     greater  i e  majority experts agreed caption describes
image perfectly minor errors   using threshold      adds       suitable
image caption pairs       test images paired original caption  among
      test captions      still describe single image      describe two test images     
three      describe four images  among       test images     
single  i e  original  caption      two possible captions      three possible
captions      four captions 
      large scale evaluation relevance judgments
crowdsourced relevance judgments allow us define two new metrics  rate
success  s k  r precision  believe r precision reliable indicator
overall performance  since summarizes human judgments single number
depend arbitrary cutoff  therefore use section       in depth
analysis impact different linguistic features models incorporate  s k
rate success scores motivated fact search engines commonly return multiple
results once  since users may satisfied long results contain least one
relevant item  s k scores provide direct measure utility hypothetical users 
rate success  s k  scores rate success metric  s k  analogous
recall based r k scores used table    intended measure utility
system hypothetical user  indicates percentage test items least
one relevant result found among highest ranked k results  following analysis
section        image caption pair considered relevant majority judges say
caption describes image 
rate success results  table    table   confirms nn performs clearly
worse kcca models  differences tri sem
models shown table   highly statistically significant  p          metrics except
s   annotation scores  where  agreement expert scores table   
differences nn bow  significant  unclear quality first
caption tri sem returns annotation significantly better returned
models  since outperforms metrics  s k scores
table   indicate tri sem returns relevant caption among top    responses
      images  relevant image       captions  comparison
expert scores table   shows s   annotation scores lie expert scores
threshold           comparison r k results table   shows
s   scores least twice high corresponding r   scores  is 
highest ranked response often relevant item originally associated
query original gold item itself 
r precision scores given crowdsourced relevance judgments  test image may
associated multiple relevant captions  test caption may
deemed relevant multiple images besides one originally written for 
queries variable number relevant answers  performance retrieval systems
commonly measured terms r precision  manning  raghavan    schtze         unlike
s k scores  metric depend arbitrary cutoff  summarizes
   

fiframing image description ranking task

rate success  s k 
 percentage items relevant response among top x results 
image annotation
s  
s  
s   

image retrieval
s  
s  
s   

bow 
bow 
tagrank
tri 

   
    
    
    
    

    
    
    
    
    

    
    
    
    
    

   
    
    
    
    

    
    
    
    
    

    
    
    
    
    

tri sem

    

    

    

    

    

    

nn

table    rate success  s k  indicates percentage test items top x
results contain least one relevant response  superscripts indicate statistically significant
difference tri sem     p        p         p      
r precision
annotation
nn



search


total

bow 
bow 
tagrank
tri 

   
    
    
    
    

   
   
    
    
    

   
    
    
    
    

tri sem

    

    

    

table    model performance measured r precision  statistically significant differences tri sem     p        p         p     
performance system single number  allowing us rank models according
overall performance  see section       below   s k scores measure
whether least one relevant items ranked highly  r precision requires relevant
items ranked highly  therefore better indicator quality mapping
images sentences  since better mapping prefer relevant captions
images irrelevant caption image 
r precision system query qi ri known relevant items test data
defined precision rank ri  i e  percentage relevant items among top ri
responses returned s   r precision obtained averaging test queries 
use fishers randomization test assess whether differences models
reaches statistical significance 
r precision results  table    table   gives r precision model types
used collecting expert judgments  section         see nearest neighbor
baseline clearly kcca models  p           r precision indicates
little difference bow   bow  tagrank terms overall performance  although tagrank tri  outperform bow  slightly search  p          
statistically significant difference among three models bow 
tri  search  p          contrast human evaluation considered
   

fihodosh  young   hockenmaier

r precision

tri 
ann  search

 idf
ann  search

ann 

 align
search

 align idf
ann  search

tri 

    

    

    ii

    

    aaa

    aa

    a

    aaa ii

 dbnc
 dic
 dbnc ic

    dd
    dd
    dd

    dd
    ddd
    ddd

    
    
    d

    ddd
    ddd
    ddd

    
    
    aa

    a
    
    dd

    
    
    

    a
    
    

table    effect adding idf weighting  i   alignment based similarities  a  distributional similarities  d  tri  model  bolded scores indicate tri   top left 
tri sem  tri   align idf dbnc ic   bottom right   superscripts indicate statistically
significant differences result addition corresponding feature  x   p     
xx         xxx   p        dc   distributional similarities computed corpus c  the
bnc  training corpus image captions  ic   both 
first result  table     tri sem clearly outperforms models annotation
retrieval  for differences p          table    appendix b shows scores
models 
      measuring impact linguistic features  table   
results presented far indicate clearly tri sem outperforms simpler tri 
model  considered impact individual text features distinguish
two models  since r precision summarizes performance system single
number  allows us easily perform analysis 
using r precision model comparison table   shows results ablation
study compares r precision tri  tri sem trigrambased kcca models use subset tri sems additional features  basic tri 
model yields bolded scores shown top left corner  tri sems scores given
bottom right corner  top row contains models capture distributional
similarities  bottom three rows corresponds addition one kind
distributional similarity  computed bnc  image captions training
corpus  corpora  corresponding model top column  first column
contains models capture idf reweighting alignment based similarities 
second column corresponds addition idf reweighting models first
column  third column adds alignment based similarities models first
column  last column adds idf reweighting alignment based similarities 
scores compared second third column  superscripts indicate addition particular feature leads statistically significant improvement
model include feature otherwise identical  is 
superscripts show addition distributional similarity metric leads significant improvement model top cell column  superscripts
indicate addition idf reweighting leads significant improvement
corresponding model without idf reweighting immediately preceding cell

   

fiframing image description ranking task

row  superscripts third column show addition alignment based
similarity leads significant improvement model without idf reweighting shown
first column row  superscripts fifth column show
addition alignment based similarity model idf reweighting shown
second column row leads significant improvement 
impact idf weighting  distributional alignment based similarities
idf weighting almost always beneficial  improvements obtained adding
idf weighting given text kernel reach statistical significance  indicated superscripts table    two cases  performance basic tri  model image
annotation  performance alignment based tri  model image search 
contrast  adding lexical similarities leads almost always significant highly significant
improvement  distributional similarities  d superscripts  beneficial basic
tri  model tasks  help idf weighted tri  model image search  distributional similarities computed corpora significantly improve performance
alignment based tri  model incorporate idf weighting  adding
alignment based tri  model without idf weighting leads improvement
search  while helping slightly decreasing performance annotation  albeit
significantly so   improvements search reach statistical significance
similarities computed corpora added  conversely  adding alignment based
similarities non idf weighted tri  model distributional similarities
corpora leads significant improvement annotation  finally  top cell last
column shows adding alignment based similarities idf weighted tri  model
leads significant improvement tasks  although impact search even
greater  comparing models performance alignment based tri  model without
idf weighting shows case  idf weighting helps search  bottom
cells column show adding alignment based similarities models already
use idf weighting distributional similarities  adding idf weighting models
distributional alignment based similarities generally lead minor improvements 
table   shows whether difference performance obtained addition
one kind feature reaches statistical significance  worth noting model
captures lexical similarities kind significantly better basic tri 
model tasks  p      search  p          annotation   idf reweighting
leads significant improvement annotation task  p          moreover 
difference tri sem       search       annotation  basic tri  kernel
idf reweighting       search       annotation  highly significant  p        search 
p          annotation  
impact lins similarity shown table   performance tri lin  
model augments trigram kernel lins        wordnet based similarity 
tri sem include lins similarity  since found development tri lin
performed similarly worse basic tri  model automatic r k median
rank scores  reflected tri lin r precision scores      annotation  tri  
           search  tri          lins similarity may simply coarse
purposes  shown table    hypernym relations wordnet lead associate terms
swimming football other  even though semantically
   

fihodosh  young   hockenmaier

correlation system rankings
s k r k
annotation


  
  
   

    
    
    

    
    
    

correlation system rankings
r precision

search


    
    
    

 a  s k vs  r k

    
    
    

annotation


r  
r  
r   
median rank

    
    
    
     

    
    
    
     

search


    
    
    
     

    
    
    
     

 b  r precision vs  r k median rank

table    correlation  spearmans kendalls   system rankings obtained
human metrics  s k r precision  automated scores  r k median rank 
related fact different kinds sports activities  visually
dissimilar  considered related systems 
      human evaluations approximated automatic techniques 
r precision s k scores require human judgements  therefore cannot applied
datasets judgements yet collected whose scale may prohibit
ever creating definitive set judgements  however  evaluation intended measure
relative progress image description rather absolute performance  automatic
metrics may sufficient approximation  since yield similar ranking systems
r precision s k scores  table   a  shows correlations rankings
nn kcca systems  n       obtained s k scores obtained
corresponding r k scores  table   b  shows correlations r precision
automatic metrics  report two rank correlation coefficients  spearmans
kendalls   first observe system rankings obtained via r   correlate highly
either r precision s   based rankings  hand  observe
r    r     median rank scores correlate well r precision r  
r    correlate well corresponding s k metrics  suggests rankingbased metrics significantly robust metrics consider quality
first result  moreover  results indicate framework  systems
expected rank pool images sentences written people  may enable large scale 
fully automated  evaluation image description systems require equally
large scale effort collect human judgments 

   summary contributions conclusions
paper  proposed frame image description task selecting ranking
descriptions among large pool descriptions provided people  framework
provides direct test purely semantic aspects image description need
concerned difficulties involved automatic generation syntactically
correct pragmatically appropriate sentences  introduced new data set
images paired multiple captions  used data set evaluate number
nearest neighbor kcca based models sentence based image annotation well
   

fiframing image description ranking task

converse task sentence based image search  experiments indicate importance
capturing lexical similarities  finally  performed in depth analysis different
evaluation metrics image description 
    advantages framing image description ranking task
one main motivations framing image description ranking rather
generation problem question objective  comparable evaluation ability
understand depicted images  order make progress challenging
task  important define tasks evaluation metrics allow objective
comparison different approaches  argued task ranking pool
captions written people attractive number reasons  first  results obtained
data set compared directly  second  human evaluation easier
generated captions since needs focus factual correctness description rather
grammaticality  fluency  creativity  third  statistically significant differences
systems may become apparent single caption per image considered 
finally  ranking makes possible automate evaluation  e g  considering position
original caption  moreover  framing image description ranking task establishes
clear parallels image retrieval  allowing metrics used tasks 
    data set
flickr  k data set       images  paired five crowdsourced captions 
unique resource image description  although much smaller sbu corpus
 ordonez et al          believe generic conceptual descriptions corpus
useful image understanding original flickr captions sbu data set 
data set perhaps similar iapr data set  grubinger et al  
       captions corpus shorter  focus salient aspects
image  focus images people animals  iapr data set covers
slightly different domain  including city pictures landscape shots typically
depict focus people  distinct advantage corpus pairs image
multiple  independently written captions  results indicate using
single caption training time leads significant increase performance 
shown use multiple captions define alignment based lexical similarity
may useful image description standard distributional wordnet based
similarities 
    models
paper first apply kernel canonical correlation analysis  kcca  sentencebased image description  results show kcca significantly outperforms nearest
neighbor based approaches data set       training images       test images
 although may scale better large data sets ordonez et al s       
sbu corpus  memory requirements train kcca may prohibitive   one
advantage kcca based approaches image description systems geared
specifically towards caption generation applied image de 

   

fihodosh  young   hockenmaier

scription  image retrieval  results indicate performance
tasks fairly similar 
important difference approach taken paper image
description systems features used models presented computed minimal supervision  feature relies supervised classifier
alignment based similarity  uses pos tagger identify nouns verbs  despite
simplicity underlying features  models achieve relatively high performance 
considering difficulty task  although      chance randomly
chosen test caption describe test image well  fine grained human judgments reveal
image annotation  first caption returned best kcca system good
description     test images  furthermore  large scale evaluation shows
best system  almost     chance suitable image caption
returned among first ten results  results indicate two main reasons
high performance  availability multiple captions image training
time  use robust text representations capture lexical similarities rather
requiring strict equality words  however  clear task remains
far solved  leave question kcca may benefit models
rely richer visual linguistic features detector responses rich syntactic
analyses future work 
    evaluating ranking based image description systems
main advantage framing image description ranking problem allows
direct comparison different approaches  since evaluated data set 
makes possible borrow established evaluation metrics information retrieval 
use metrics data sets sentence based image annotation image
search 
one hand  shown crowdsourcing used collect large number
binary judgments image caption pairs relatively low price  crowdsourced judgments correlate well fine grained judgments  able collect
human judgments large scale particularly important retrieval based approaches
image description  since number relevance judgments need collected
test collection may significantly larger number judgments commonly
used evaluate single caption generation system  however  experiments image
annotation provided example human judgments first caption returned
test image reveal differences systems become apparent
results taken account  fine grained evaluation indicates evaluations
based single result may require potentially much larger number test items
order reveal robust statistically significant differences  among human evaluation
metrics compared  believe r precision computed crowdsourced
relevance judgments robust  r precision standard metric evaluating
ranked retrieval results items varying number relevant responses  since
yields single score  makes particularly easy compare systems  however 
s k scores  measure percentage items top k responses contain
relevant result  perhaps direct measure useful system may prac 

   

fiframing image description ranking task

tice  release crowdsourced relevance judgments collected order
enable others evaluate image description system data  hope
establish benchmark used direct fair large scale comparison
arbitrary number image description systems 
hand  shown framework systems evaluated ability rank pool images sentences may make possible perform
fully automated evaluation  contrary current practice  analysis indicates clearly
standard metrics bleu rouge reliable indicators
well captions describe images  even bleu rouge style preprocessing used
effective filter implausible image caption pairs  although consider humangenerated captions  stipulate similar observations may hold automatically generated captions  since similar criticisms bleus appropriateness generation
machine translation evaluation well known  reiter   belz        callison burch  osborne    koehn         however  ranking based framework test query associated
gold response originally associated with  results indicate
metrics based rank gold item lead similar conclusions human judgments  suggest evaluation ranking based image description task
automated  performed potentially much larger scale examined here 
    implications evaluation caption generation systems
image description can  should  treated problem natural language
generation community  automatically generating captions indistinguishable
captions written people  an evaluation criterion used mitchell et al        
comparison caption generation systems  requires much ability
provide factually correct information image  believe linguistic
issues need solved generation setting need evaluated separately
ability decide whether given caption describes image  unclear kinds
evaluations performed e g  mitchell et al  could ever automated  since question
natural automatically produced caption seems may always require human judgment 
human experiments expensive  since system generates captions 
judgments collected anew system experiment  since
consensus constitutes good image description  independently obtained human
assessments different caption generation systems compared directly 
means direct comparison systems  e g  performed mitchell et al   typically
possible within one research group  since common data set different
system outputs publicly available  although automatic scores bleu rouge
may still useful caption generation measures fluency  reiter   belz        
shown reliable metrics well caption describes image 
especially candidate pool disjoint reference captions  suggests
evaluation syntactic pragmatic aspects caption generation task
automated  may rely human judgments  however  may
possible use framework proposed paper evaluate semantic affinity
functions f  i  s  implicitly used caption generations systems 

   

fihodosh  young   hockenmaier

acknowledgments
gratefully acknowledge support project national science foundation
iis medium grant          career award          cns         ci p 

appendix a  agreement approximate metrics expert
human judgments
tables     use cohens kappa    measure agreement bleu rouge
scores expert judgments  selected thresholds yield optimal results 
table     a  shows agreement crowdsourced judgments expert
judgments  since best agreement expert scores obtained crowdsourced
judgments using threshold      table     b  measures precision recall resulting binary relevance judgments binarized expert judgments obtained varying
thresholds 

appendix b  performance systems
following tables give results models  section   body paper  nn
idf
corresponds nn idf
f    tri sem corresponds tri a dbnc ic  
r k median rank scores table    gives recall median rank original
item  section        models 
agreement expert bleu rouge scores  cohens  
case    scand sref
  reference captions test image  scand sref   r   
expert
e

   

bleu b
   
   

   

rouge r
   
   

    
   
   
   
   

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

  reference caption test image  scand   sref   r   gold  
expert
e

   

bleu
       

   

    
   
   
   
   

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

rouge
       
    
    
    
    
    

    
    
    
    
    

table    agreement  cohens   binarized expert bleu rouge scores
pool candidate captions contains test images reference caption s  

   

fiframing image description ranking task

agreement expert bleu rouge scores  cohens  
case    scand   sref
  reference captions  test image  r   
expert
e

   

bleu
       

   

rouge
       

    
   
   
   
   

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

  reference caption test image  r   other  
expert
e

   

bleu
       

   

rouge
       

    
   
   
   
   

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

table    agreement  cohens   binarized expert bleu rouge scores
pool candidate captions may contain test images reference caption s  

agreement expert
lay scores  cohens  
expert
e
    
   
   
   
   

    
    
    
    
    
    

lay vs  expert
relevance judgments  l        

lay l
       
    
    
    
    
    

    
    
    
    
    

 a  agreement  cohens   relevance judgments obtained expert
scores  relevance   score e   lay
scores  relevance   score l  

e

precision

recall

f 

    
   
   
   
   
   

    
    
    
    
    
    

    
    
    
    
    
    

    
    
    
    
    
    

 b  precision  recall  f  scores binarized lay scores  l        
binarized expert scores varying
thresholds e  

table     comparing relevance judgments obtained lay scores
obtained expert scores

   

fihodosh  young   hockenmaier

s k r precision scores table    gives s k success rate  section       
r precision scores  section        models  based crowdsourced human
judgments  section        

   

fiframing image description ranking task

performance models  automatic evaluation 
 r k  percentage queries original item top x results
median r  median rank original item 
r  

image annotation
r   r    median r

r  

image search
r   r    median r

nn f 
nn idf
f 
nn bow 
nn tri best 

   
   
   
   

   
   
   
   

   
   
   
   

     
     
     
     

   
   
   
   

   
   
   
   

   
   
   
   

     
     
     
     

bow 
tri 

   
   

    
    

    
    

    
    

   
   

    
    

    
    

    
    

bow histo
bow 
bow idf

bow  idf
tagrank

   
   
   
   
   

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

   
   
   
   
   

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

tri histo
tri 

   
   

    
    

    
    

    
    

   
   

    
    

    
    

    
    

tri lin
tri dbnc
tri dic
tri dbnc ic

   
   
   
   

    
    
    
    

    
    
    
    

    
    
    
    

   
   
   
   

    
    
    
    

    
    
    
    

    
    
    
    

tri a
tri a dbnc
tri a dic
tri a dbnc ic

   
   
   
   

    
    
    
    

    
    
    
    

    
    
    
    

   
   
   
   

    
    
    
    

    
    
    
    

    
    
    
    

   

    

    

    

   

    

    

    

   
   
   

    
    
    

    
    
    

    
    
    

   
   
   

    
    
    

    
    
    

    
    
    

   
   
   

    
    
    

    
    
    

    
    
    

   
   
   

    
    
    

    
    
    

    
    
    

idf histo
tri a d
bnc ic

   

    

    

    

   

    

    

    

idf
a dbnc ic

   

    

    

    

   

    

    

    



tri 

idf



idf
tri 
dbnc
idf
tri 
dic
idf
tri dbnc ic


idf
tri a

idf
tri 
a dbnc
idf
tri a d
ic



tri 

table     performance models  measured percentage test items
original item returned among top         results 
well median rank

idf
idf
original item  section    nn f    nn  tri a dbnc ic   tri sem 

   

fihodosh  young   hockenmaier

performance models  human evaluation 
s k  percentage items relevant response among top x results
r prec  r precision computed relevant responses
s  
nn f 
nn idf
f 
nn bow 
nn tri best 

image annotation
s   s    r prec 

s  

image search
s   s    r prec 

   
   
   
   

    
    
    
    

    
    
    
    

   
   
   
   

   
   
   
   

    
    
    
    

    
    
    
    

   
   
   
   

bow 
tri 

    
    

    
    

    
    

    
    

    
    

    
    

    
    

   
   

bow histo
bow 
bow idf

bow  idf
tagrank

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

   
    
    
    
    

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

   
    
    
    
    

tri histo
tri 

    
    

    
    

    
    

   
    

    
    

    
    

    
    

    
    

tri lin
tri dbnc
tri dic
tri dbnc ic
tri a
tri a dbnc
tri a dic
tri a dbnc ic

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    

    

    

    

    

    

    

    

    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    
    
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

tri 
tri 
tri 
tri 
tri 
tri 
tri 
tri 
tri 


idf

idf

bnc
idf

ic
idf
dbnc ic

idf


idf
a d
bnc
idf
a dic

idf histo
a dbnc ic

idf
a dbnc ic

table     performance models  measured percentage test items
return item deemed relevant according crowdsourced judgments
among top         results 
r precision computed judgments 

idf
idf
section    nn f    nn  tri a dbnc ic   tri sem 

   

fiframing image description ranking task

references
artstein  r     poesio  m          inter coder agreement computational linguistics 
computational linguistics                 
bach  f  r     jordan  m  i          kernel independent component analysis  journal
machine learning research         
barnard  k   duygulu  p   forsyth  d   freitas  n  d   blei  d  m     jordan  m  i         
matching words pictures  journal machine learning research              
blei  d  m     jordan  m  i          modeling annotated data  sigir       proceedings
  th annual international acm sigir conference research development
information retrieval  pp          toronto  ontario  canada 
bloehdorn  s   basili  r   cammisa  m     moschitti  a          semantic kernels text
classification based topological measures feature similarity  proceedings
 th ieee international conference data mining  icdm        pp          hong
kong  china 
bnc consortium         british national corpus  version    bnc xml edition  
http   www natcorp ox ac uk 
brown  p  f   pietra  v  j  d   pietra  s  a  d     mercer  r  l          mathematics
statistical machine translation  parameter estimation  computational linguistics 
               
callison burch  c   osborne  m     koehn  p          re evaluation role bleu
machine translation research  proceedings   th conference european chapter association computational linguistics  eacl   pp         
trento  italy 
cohen  j          coefficient agreement nominal scales  educational psychological measurement               
croce  d   moschitti  a     basili  r          structured lexical similarity via convolution
kernels dependency trees  proceedings      conference empirical
methods natural language processing  emnlp   pp            edinburgh  uk 
dale  r     white  m   eds            workshop shared tasks comparative evaluation natural language generation  position papers  arlington  va  usa 
datta  r   joshi  d   li  j     wang  j  z          image retrieval  ideas  influences 
trends new age  acm computing surveys                  
deschacht  k     moens  m  f          text analysis automatic image annotation 
proceedings   th annual meeting association computational linguistics  acl   pp            prague  czech republic 
dietterich  t  g          approximate statistical tests comparing supervised classification
learning algorithms  neural computation                   
everingham  m   gool  l  v   williams  c   winn  j     zisserman  a         
pascal visual object classes challenge       voc      results  http   www 
pascal network org challenges voc voc     workshop  
   

fihodosh  young   hockenmaier

farhadi  a   hejrati  m   sadeghi  m  a   young  p   rashtchian  c   hockenmaier  j    
forsyth  d          every picture tells story  generating sentences images 
proceedings european conference computer vision  eccv   part iv  pp 
      heraklion  greece 
fellbaum  c          wordnet  electronic lexical database  bradford books 
felzenszwalb  p   mcallester  d     ramanan  d          discriminatively trained  multiscale  deformable part model  proceedings      ieee conference computer vision pattern recognition  cvpr   pp      anchorage  ak  usa 
feng  y     lapata  m          automatic image annotation using auxiliary text information  proceedings   th annual meeting association computational
linguistics  human language technologies  acl     hlt   pp          columbus 
oh  usa 
feng  y     lapata  m          many words picture worth  automatic caption generation news images  proceedings   th annual meeting association
computational linguistics  acl   pp            uppsala  sweden 
fisher  r  a          design experiments  olyver boyd  edinburgh  uk 
grangier  d     bengio  s          discriminative kernel based approach rank images
text queries  ieee transactions pattern analysis machine intelligence 
             
grice  h  p          logic conversation  davidson  d     harman  g  h   eds   
logic grammar  pp        dickenson publishing co   encino  ca  usa 
grubinger  m   clough  p   mller  h     deselaers  t          iapr benchmark  new
evaluation resource visual information systems  ontoimage       workshop
language resources content based image retrieval lrec       pp       
genoa  italy 
gupta  a   verma  y     jawahar  c          choosing linguistics vision describe
images  proceedings twenty sixth aaai conference artificial intelligence 
toronto  ontario  canada 
hardoon  d  r   saunders  c   szedmak  s     shawe taylor  j          correlation approach automatic image annotation  li  x   zaane  o  r     li  z  h   eds   
advanced data mining applications  vol       lecture notes computer science  pp          springer berlin heidelberg 
hardoon  d  r   szedmak  s  r     shawe taylor  j  r          canonical correlation
analysis  overview application learning methods  neural computation     
         
hotelling  h          relations two sets variates  biometrika                   
hwang  s     grauman  k          learning relative importance objects tagged
images retrieval cross modal search  international journal computer vision 
                

   

fiframing image description ranking task

jaimes  a   jaimes  r     chang  s  f          conceptual framework indexing visual
information multiple levels  internet imaging       vol       proceedings
spie  pp       san jose  ca  usa 
jurafsky  d     martin  j  h          speech language processing   nd edition   prentice
hall 
krippendorff  k          content analysis  introduction methodology  sage 
kulkarni  g   premraj  v   dhar  s   li  s   choi  y   berg  a  c     berg  t  l         
baby talk  understanding generating simple image descriptions  proceedings
     ieee conference computer vision pattern recognition  cvpr  
pp           
kuznetsova  p   ordonez  v   berg  a   berg  t     choi  y          collective generation
natural image descriptions  proceedings   th annual meeting association computational linguistics  volume    long papers   pp          jeju
island  korea 
lavrenko  v   manmatha  r     jeon  j          model learning semantics pictures  thrun  s   saul  l     schlkopf  b   eds    advances neural information
processing systems     cambridge  ma  usa 
lazebnik  s   schmid  c     ponce  j          spatial pyramid matching  s  dickinson 
a  leonardis  b  s     tarr  m   eds    object categorization  computer human
vision perspectives  chap      pp          cambridge university press 
li  s   kulkarni  g   berg  t  l   berg  a  c     choi  y          composing simple image descriptions using web scale n grams  proceedings fifteenth conference
computational natural language learning  conll   pp          portland  or 
usa 
lin  c  y          rouge  package automatic evaluation summaries  mariefrancine moens  s  s   ed    text summarization branches out  proceedings
acl    workshop  pp        barcelona  spain 
lin  c  y     hovy  e  h          automatic evaluation summaries using n gram cooccurrence statistics  proceedings      human language technology conference north american chapter association computational linguistics
 hlt naacl   pp        edmonton  ab  canada 
lin  d          information theoretic definition similarity  proceedings fifteenth international conference machine learning  icml   pp          madison 
wi  usa 
lowe  d  g          distinctive image features scale invariant keypoints  internationa
journal computer vision                
makadia  a   pavlovic  v     kumar  s          baselines image annotation  international
journal computer vision                
manning  c  d   raghavan  p     schtze  h          introduction information retrieval 
cambridge university press 

   

fihodosh  young   hockenmaier

mitchell  m   dodge  j   goyal  a   yamaguchi  k   stratos  k   han  x   mensch  a   berg 
a   berg  t     daume iii  h          midge  generating image descriptions
computer vision detections  proceedings   th conference european
chapter association computational linguistics  eacl   pp          avignon  france 
moschitti  a          syntactic semantic kernels short text pair categorization 
proceedings   th conference european chapter association
computational linguistics  eacl   pp          athens  greece 
moschitti  a   pighin  d     basili  r          tree kernels semantic role labeling 
computational linguistics                 
och  f  j     ney  h          systematic comparison various statistical alignment
models  computational linguistics               
ordonez  v   kulkarni  g     berg  t  l          im text  describing images using   million
captioned photographs  advances neural information processing systems    
pp           
papineni  k   roukos  s   ward  t     zhu  w  j          bleu  method automatic
evaluation machine translation  proceedings   th annual meeting association computational linguistics  acl   pp          philadelphia  pa  usa 
popescu  a   tsikrika  t     kludas  j          overview wikipedia retrieval task
imageclef       clef  notebook papers labs workshops   padua  italy 
porter  m  f          algorithm suffix stripping  program                 
rashtchian  c   young  p   hodosh  m     hockenmaier  j          collecting image annotations using amazons mechanical turk  naacl workshop creating speech
language data amazons mechanical turk  pp          los angeles  ca 
usa 
rasiwasia  n   pereira  j  c   coviello  e   doyle  g   lanckriet  g  r   levy  r     vasconcelos  n          new approach cross modal multimedia retrieval  proceedings
international conference multimedia  mm   pp          new york  ny 
usa 
reiter  e     belz  a          investigation validity metrics automatically evaluating natural language generation systems  computational linguistics 
               
shatford  s          analyzing subject picture  theoretical approach  cataloging
  classification quarterly          
shawe taylor  j     cristianini  n          kernel methods pattern analysis  cambridge
university press 
smucker  m  d   allan  j     carterette  b          comparison statistical significance
tests information retrieval evaluation  proceedings sixteenth acm conference information knowledge management  cikm   pp          lisbon 
portugal 

   

fiframing image description ranking task

socher  r     li  f  f          connecting modalities  semi supervised segmentation
annotation images using unaligned text corpora  proceedings      ieee
conference computer vision pattern recognition  cvpr   pp          san
francisco  ca  usa 
van erp  m     schomaker  l          variants borda count method combining
ranked classifier hypotheses  proceedings seventh international workshop
frontiers handwriting recognition  iwfhr   pp          nijmegen  netherlands 
varma  m     zisserman  a          statistical approach texture classification
single images  international journal computer vision           
vedaldi  a     fulkerson  b          vlfeat  open portable library computer
vision algorithms  http   www vlfeat org  
weston  j   bengio  s     usunier  n          large scale image annotation  learning rank
joint word image embeddings  machine learning               
yang  y   teo  c   daume iii  h     aloimonos  y          corpus guided sentence generation natural images  proceedings      conference empirical methods
natural language processing  emnlp   pp          edinburgh  uk 

   


