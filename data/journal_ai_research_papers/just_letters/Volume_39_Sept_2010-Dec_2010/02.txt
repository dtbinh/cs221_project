journal of artificial intelligence research                 

submitted        published      

the lama planner 
guiding cost based anytime planning with landmarks
silvia richter

silvia richter nicta com au

iiis  griffith university  australia
and nicta qrl  australia

matthias westphal

westpham informatik uni freiburg de

albert ludwigs universitat freiburg
institut fur informatik
freiburg  germany

abstract
lama is a classical planning system based on heuristic forward search  its core feature is
the use of a pseudo heuristic derived from landmarks  propositional formulas that must be true
in every solution of a planning task  lama builds on the fast downward planning system  using
finite domain rather than binary state variables and multi heuristic search  the latter is employed to
combine the landmark heuristic with a variant of the well known ff heuristic  both heuristics are
cost sensitive  focusing on high quality solutions in the case where actions have non uniform cost 
a weighted a search is used with iteratively decreasing weights  so that the planner continues to
search for plans of better quality until the search is terminated 
lama showed best performance among all planners in the sequential satisficing track of the
international planning competition       in this paper we present the system in detail and investigate which features of lama are crucial for its performance  we present individual results for
some of the domains used at the competition  demonstrating good and bad cases for the techniques
implemented in lama  overall  we find that using landmarks improves performance  whereas the
incorporation of action costs into the heuristic estimators proves not to be beneficial  we show that
in some domains a search that ignores cost solves far more problems  raising the question of how
to deal with action costs more effectively in the future  the iterated weighted a search greatly
improves results  and shows synergy effects with the use of landmarks 

   introduction
in the last decade  heuristic search has become the dominant approach to domain independent satisficing planning  starting with the additive heuristic by bonet and geffner         implemented
in the hsp planning system  much research has been conducted in search of heuristic estimators
that are efficient to calculate yet powerful in guiding the search towards a goal state  the ff planning system by hoffmann and nebel         using a heuristic estimator based on relaxed planning
graphs  broke ground by showing best performance among all fully automated systems at the international planning competition in       and continues to be state of the art today  ever since 
heuristic search approaches have played a prominent role in the classical or sequential satisficing
tracks of the biennial competition  with fast downward  helmert        winning in      and sgplan  chen  wah    hsu        placing first in      
the lama planning system is the youngest member in this line  winning the sequential satisficing track at the international planning competition  ipc  in       lama is a classical planning
c
    
ai access foundation  all rights reserved 

firichter   westphal

system based on heuristic search  it follows in the footsteps of hsp  ff  and fast downward and
uses their earlier work in many respects  in particular  it builds on fast downward by extending it
in three major ways 
   landmarks  in lama  fast downwards causal graph heuristic is replaced with a variant of
the ff heuristic  hoffmann   nebel        and heuristic estimates derived from landmarks 
landmarks are propositional formulas that have to become true at some point in every plan
for the task at hand  porteous  sebastia    hoffmann         lama uses landmarks to
direct search towards those states where many landmarks have already been achieved  via
preferred operators  landmarks are also used as an additional source of search control which
complements the heuristic estimates  in recent work  we have shown this use of landmarks
in addition to the ff heuristic to improve performance  by leading to more problems being
solved and shorter solution paths  richter  helmert    westphal        
   action costs  both the landmark heuristic we proposed earlier  richter et al         and the
ff heuristic have been adapted to use action costs  however  lama does not focus purely on
the cost to go  i  e   the estimated cost of reaching the goal from a given search node  there
is a danger that a cost sensitive planner may concentrate too much on finding a cheap plan 
at the expense of finding a plan at all within a given time limit  lama weighs the estimated
cost to go  as a measure of plan quality  against the estimated goal distance  as a measure of
remaining search effort  by combining the values for the two estimates 
   anytime search  lama continues to search for better solutions until it has exhausted the
search space or is interrupted  after finding an initial solution with a greedy best first search 
it conducts a series of weighted a searches with decreasing weights  restarting the search
each time from the initial state when an improved solution is found  in recent work  we have
shown this approach to be very efficient on planning benchmarks compared to other anytime
methods  richter  thayer    ruml        
at the international planning competition       lama outperformed its competitors by a
substantial margin  this result was not expected by its authors  as their previous work concerning
lamas putative core feature  the landmark heuristic  richter et al          showed some  but
not tremendous improvement over the base configuration without landmarks  this paper aims to
provide a reference description of lama as well as an extensive evaluation of its performance in
the competition 
 detailed description of lama  we present all distinguishing components of the planner
in detail  describing how landmarks are generated and used in lama  how action costs are
incorporated into the heuristic estimators and how the anytime search proceeds  some aspects of lama have been presented in previous publications  richter et al              
helmert         however  aspects that have not been adequately covered in those publications  in particular the procedure for finding landmarks  are described here in detail  other
relevant aspects described in previous work  like the landmark heuristic  are summarised for
the convenience of the reader  our aim is that this paper  together with previous ones  form a
comprehensive picture of the lama system 
 experimental evaluation of lama  building on this  we conduct an experimental evaluation focusing on the aspects that differentiate lama from predecessor systems like ff and
   

fithe lama planner  guiding cost based anytime planning with landmarks

fast downward  we do not repeat comparisons published in earlier work  like the comparison
between lamas anytime method and other anytime algorithms  richter et al          or the
comparison of lamas methods for handling landmarks to alternative landmark approaches
 richter et al          instead  we aim to elicit how much the performance of the lama
system as a whole is enhanced by each of the three distinguishing features described above
 landmarks  action costs and anytime search   to answer this question  we contrast several
variations of our planner using various subsets of these features 
we find that using cost sensitive heuristics did not pay off on the ipc      benchmark tasks 
our results show that the cost sensitive variant of the ff heuristic used in lama performs significantly worse than the traditional unit cost version of the same heuristic  similarly  all other
cost sensitive planners in the competition fared worse than the baseline planner ff that ignored action costs  demonstrating that cost based planning presents a considerable challenge  while we do
not conduct a full analysis of the reasons for this  we showcase the problems of the cost sensitive ff
heuristic in some example domains and provide informed hypotheses for the encountered effects 
landmarks prove to be particularly helpful in this context  while in the unit cost case landmarks
only lead to a moderate increase in performance  in the case of planning with action costs they
substantially improve coverage  the number of problems solved   thus effectively mitigating the
problems of the cost sensitive ff heuristic in lama  the anytime search significantly improves
the quality of solutions throughout and even acts in synergy with landmarks in one domain 

   preliminaries
we use a planning formalism with state variables of finite  rather than binary  range  similar to the
one employed by helmert         it is based on the sas  planning model  backstrom   nebel 
       but extends it with conditional effects  while lama also handles axioms in the same way
as fast downward  helmert         we do not formalise axioms here  since they are not important
for our purposes 
definition    planning tasks in finite domain representation  fdr tasks 
a planning task in finite domain representation  fdr task  is given by a   tuple hv  s    s    o  ci
with the following components 
 v is a finite set of state variables  each with an associated finite domain dv  
a fact is a pair hv  di  also written v   d   where v  v and d  dv   a partial variable
assignment s is a set of facts  each with a different variable   we use set notation such as
hv  di  s and function notation such as s v    d interchangeably   a state is a variable
assignment defined on all variables v 
 s  is a state called the initial state 
 s  is a partial variable assignment called the goal 
 o is a finite set of operators  an operator hpre  effi consists of a partial variable assignment
pre called its precondition  and a finite set of effects eff  effects are triplets hcond  v  di 
where cond is a  possibly empty  partial variable assignment called the effect condition  v is
the affected variable and d  dv is called the new value for v 
   

firichter   westphal

 c   o  n   is an integer valued non negative action cost function 
an operator o   hpre  effi  o is applicable in a state s if pre  s  and its effects are consistent 
i  e   there is a state s  such that s   v    d for all hcond  v  di  eff where cond  s  and s   v    s v 
otherwise  in this case  we say that the operator o can be applied to s resulting in the state s  and
write s o  for s   
for operator sequences    ho            on i  we write s   for s o           on    only defined if each operator is applicable in the respective state   the operator sequence  is called a plan if s   s     
p
the cost of  is the sum of the action costs of its operators  ni   c oi   
each state variable v of a planning task in finite domain representation has an associated directed
graph called the domain transition graph  which captures the ways in which the value of v may
change  jonsson   backstrom        helmert         the vertex set of this graph is dv   and it
contains an arc between two nodes d and d  if there exists an operator that can change the value of
v from d to d    formally 
definition    domain transition graph
the domain transition graph  dtg  of a state variable v  v of an fdr task hv  s    s    o  ci is
the digraph hdv   ai which includes an arc hd  d  i iff d   d    there is an operator hpre  effi  o with
hcond  v  d  i  eff  and for the union of conditions pre  cond it holds that either it contains v   d or
it does not contain v   d for any d  dv  

   system architecture
lama builds on the fast downward system  helmert         inheriting the overall structure and
large parts of the functionality from that planner  like fast downward  lama accepts input in
the pddl    level   format  fox   long        edelkamp   hoffmann         including adl
conditions and effects and derived predicates  axioms   furthermore  lama has been extended
to handle the action costs introduced for ipc       helmert  do    refanidis         like fast
downward  lama consists of three separate components 
 the translation module
 the knowledge compilation module
 the search module
these components are implemented as separate programs that are invoked in sequence  in the
following  we provide a brief description of the translation and knowledge compilation modules 
the main changes in lama  compared to fast downward  are implemented in the search module 
which we discuss in detail 
    translation
the translation module  short translator  transforms the pddl input into a planning task in finitedomain representation as specified in definition    the main components of the translator are an
efficient grounding algorithm for instantiating schematic operators and axioms  and an invariant
   

fithe lama planner  guiding cost based anytime planning with landmarks

synthesis algorithm for determining groups of mutually exclusive facts  such fact groups are consequently replaced by a single state variable  encoding which fact  if any  from the group is satisfied
in a given world state  details on this component can be found in a recent article by helmert        
the groups of mutually exclusive facts  mutexes  found during translation are later used to
determine orderings between landmarks  for this reason  lama does not use the finite domain
representations offered at ipc       object fluents   but instead performs its own translation from
binary to finite domain variables  while not all mutexes computed by the translation module are
needed for the new encoding of the planning task  the module has been extended in lama to retain
all found mutexes for their later use with landmarks 
further changes we made  compared to the translation module described by helmert  were
to add the capability of handling action costs  implement an extension concerning the parsing of
complex operator effect formulas  and limit the runtime of the invariant synthesis algorithm  as
invariant synthesis may be time critical  in particular on large  grounded  pddl input  we limit the
maximum number of considered mutex candidates in the algorithm  and abort it  if necessary  after
five minutes  note that finding few or no mutexes does not change the way the translation module
works  if no mutexes are found  the resulting encoding of the planning task contains simply the
same  binary domain  state variables as the pddl input  when analysing the competition results 
we found that the synthesis algorithm had aborted only in some of the tasks of one domain  cyber
security  
    knowledge compilation
using the finite domain representation generated by the translator  the knowledge compilation module is responsible for building a number of data structures that play a central role in the subsequent
landmark generation and search  firstly  domain transition graphs  see definition    are produced
which encode the ways in which each state variable may change its value through operator applications and axioms  furthermore  data structures are constructed for efficiently determining the set of
applicable operators in a state and for evaluating the values of derived state variables  we refer to
helmert        for more detail on the knowledge compilation component  which lama inherits
unchanged from fast downward 
    search
the search module is responsible for the actual planning  two algorithms for heuristic search are
implemented in lama   a  a greedy best first search  aimed at finding a solution as quickly as
possible  and  b  a weighted a search that allows balancing speed against solution quality  both
algorithms are variations of the standard textbook methods  using open and closed lists  the greedy
best first search always expands a state with minimal heuristic value h among all open states and
never expands a state more than once  in order to encourage cost efficient plans without incurring
much overhead  it breaks ties between equally promising states by preferring those states that are
reached by cheaper operators  i  e   taking into account the last operator on the path to the considered
state in the search space   the cost of the entire path could only be used at the expense of increased
time or space requirements  so that we do not consider this   weighted a search  pohl       
associates costs with states and expands a state with minimal f    value  where f     w  h   g  the
weight w is an integer     and g is the best known cost of reaching the considered state from the
   

firichter   westphal

initial state  in contrast to the greedy search  weighted a search re expands states whenever it finds
cheaper paths to them 
in addition  both search algorithms use three types of search enhancements inherited from fast
downward  helmert        richter   helmert         firstly  multiple heuristics are employed
within a multi queue approach to guide the search  secondly  preferred operators  similar to the
helpful actions in ff  allow giving precedence to operators that are deemed more helpful than
others in a state  thirdly  deferred heuristic evaluation mitigates the impact of large branching
factors assuming that heuristic estimates are fairly accurate  in the following  we discuss these
techniques and the resulting algorithms in more detail and give pseudo code for the greedy best first
search  the weighted a search is very similar  so we point out the differences between the two
algorithms along the way 
multi queue heuristic search  lama uses two heuristic functions to guide its search  the namegiving landmark heuristic  see section     and a variant of the well known ff heuristic  see section     the two heuristics are used with separate queues  thus exploiting strengths of the utilised
heuristics in an orthogonal way  helmert        roger   helmert         to this end  separate
open lists are maintained for each of the two heuristics  states are always evaluated with respect to
both heuristics  and their successors are added to all open lists  in each case with the value corresponding to the heuristic of that open list   when choosing which state to evaluate and expand next 
the search algorithm alternates between the different queues based on numerical priorities assigned
to each queue  these priorities are discussed later 
deferred heuristic evaluation  the use of deferred heuristic evaluation means that states are
not heuristically evaluated upon generation  but upon expansion  i  e   when states are generated in
greedy best first search  they are put into the open list not with their own heuristic value  but with
that of their parent  only after being removed from the open list are they evaluated heuristically 
and their heuristic estimate is in turn used for their successors  the use of deferred evaluation in
weighted a search is analogous  using f   instead of h as the sorting criterion of the open lists 
if many more states are generated than expanded  deferred evaluation leads to a substantial reduction in the number of heuristic estimates computed  however  deferred evaluation incurs a loss of
heuristic accuracy  as the search can no longer use h values or f    values to differentiate between the
successors of a state  all successors are associated with the parents value in the open list   preferred
operators are very helpful in this context as they provide an alternative way to determine promising
successors 
preferred operators  operators that are deemed particularly useful in a given state are marked
as preferred  they are computed by the heuristic estimators along with the heuristic value of a
state  see sections   and     to use preferred operators  in the greedy best first search as well as
in the weighted a search  the planner maintains an additional preferred operator queue for each
heuristic  when a state is evaluated and expanded  those successor states that are reached via a
preferred operator  the preferred states  are put into the preferred operator queues  in addition to
being put into the regular queues like the non preferred states   analogously to regular states  any
state preferred by at least one heuristic is added to all preferred operator queues  this allows for
cross fertilisation through information exchange between the different heuristics   states in the
preferred operator queues are evaluated earlier on average  as they form part of more queues and
have a higher chance of being selected at any point in time than the non preferred states  in addition 
   

fithe lama planner  guiding cost based anytime planning with landmarks

lama  like the ipc      version of fast downward  gives even higher precedence to preferred
successors via the following mechanism  the planner keeps a priority counter for each queue 
initialised to    at each iteration  the next state is removed from the queue that has the highest
priority  whenever a state is removed from a queue  the priority of that queue is decreased by    if
the priorities are not changed outside of this routine  this method will alternate between all queues 
thus expanding states from preferred queues and regular queues equally often  to increase the use
of preferred operators  lama increases the priorities of the preferred operator queues by a large
number boost of value      whenever progress is made  i  e   whenever a state is discovered that has
a better heuristic estimate than previously expanded states  subsequently  the next      states will
be removed from preferred operator queues  if another improving state is found within the     
states  the boosts accumulate and  accordingly  it takes longer until states from the regular queues
are expanded again 
alternative methods for using preferred operators include the one employed in the yahsp
system  vidal         where preferred operators are always used over non preferred ones  by contrast  our scheme does not necessarily empty the preferred queues before switching back to regular
queues  in the ff planner  hoffmann   nebel         the emphasis on preferred operators is even
stronger than in yahps  the search in ff is restricted to preferred operators until either a goal is
found or the restricted search space has been exhausted  in which case a new search is started without preferred operators   compared to these approaches  the method for using preferred operators
in lama  in conjunction with deferred heuristic evaluation  has been shown to result in substantial
performance improvement and deliver best results in the classical setting of operators with unit costs
 richter   helmert         the choice of      as the boost value is not critical here  as we found
various values between     and       to give similarly good results  only outside this range does
performance drop noticeably 
note that when using action costs  the use of preferred operators may be even more helpful
than in the classical setting  for example  if all operators have a cost of    a heuristic using pure
cost estimates might assign the same heuristic value of   to all states in the state space  giving no
guidance to search at all  preferred operators  however  still provide the same heuristic guidance
in this case as in the case with unit action costs  while this is an extreme example  similar cases
appear in practice  e  g  in the ipc      domain openstacks  where all operators except for the one
opening a new stack have an associated cost of   
pseudo code  algorithm   shows pseudo code for the greedy best first search  the main loop
 lines       runs until either a goal has been found  lines       or the search space has been
exhausted  lines        the closed list contains all seen states and also keeps track of the links
between states and their parents  so that a plan can be efficiently extracted once a goal state has
been found  line      in each iteration of the loop  the search adds the current state  initially the
start state  to the closed list and processes it  lines        unless the state has been processed
before  in which case it is ignored  line      by contrast  weighted a search processes states again
whenever they are reached via a path with lower cost than before  and updates their parent links
in the closed list accordingly  then the search selects the next open list to be used  the one with
highest priority  line      decreases its priority and extracts the next state to be processed  lines
       the processing of a state includes calculating its heuristic values and preferred operators
with both heuristics  lines      expanding it  and inserting the successors into the appropriate open
   

firichter   westphal

global variables 
   hv  s    s    o  ci
regff   pref ff   reglm   pref lm
best seen value
priority
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

  planning task to solve
  regular and preferred open lists for each heuristic
  best heuristic value seen so far for each heuristic
  numerical priority for each queue

function expand state s 
progress  false
for h   ff  lm  do
h s   preferred ops h  s   heuristic value of s and preferred operators given h
if h s    best seen value h  then
progress  true
best seen value h   h s 
if progress then
  boost preferred operator queues
priority pref ff    priority pref ff         
priority pref lm    priority pref lm         
succesor states    s o    o  o and o applicable in s  
for s   succesor states do
for h   ff  lm  do
add s  to queue regh with value h s 
  deferred evaluation
 
if s reached by operator o  preferred ops h  s  then
add s  to queue pref ff with value ff s   and to queue pref lm with value lm s 
function greedy bfs lama
closed list  
for h   ff  lm  do
  initialize ff and landmark heuristics
best seen value h   
for l   reg  pref   do
  regular and preferred open lists for each heuristic
lh  
priority lh     
current state  s 
loop
if current state   closed list then
if s   s  then
extract plan  by tracing current state back to initial state in closed list
return 
closed list  closed list   current state 
expand state current state 
if all queues are empty then
return failure
  no plan exists
q  non empty queue with highest priority
priority q   priority q    
  get lowest valued state from queue q
current state  pop state q 
algorithm    the greedy best first search with search enhancements used in lama 
   

fithe lama planner  guiding cost based anytime planning with landmarks

lists  lines        if it is determined that a new best state has been found  lines       the preferredoperator queues are boosted by       lines       
      restarting anytime search
lama was developed for the international planning competition      and is tailored to the conditions of this competition in several ways  in detail  those conditions were as follows  while in
previous competitions coverage  plan quality and runtime were all used to varying degrees in order
to determine the effectiveness of a classical planning system  ipc      introduced a new integrated
performance criterion  each operator in the pddl input had an associated non negative integer
action cost  and the aim was to find a plan of lowest possible total cost within a given time limit
of    minutes per task  given that a planner solves a task at all within the time limit  this new
performance measure depends only on plan quality  not on runtime  and thus suggests guiding the
search towards a cheapest goal rather than a closest goal as well as using all of the available time to
find the best plan possible 
guiding the search towards cheap goals may be achieved in two ways  both of which lama
implements  firstly  the heuristics should estimate the cost to go  i  e   the cost of reaching the goal
from a given state  rather than the distance to go  i  e   the number of operators required to reach the
goal  both the landmark heuristic and the ff heuristic employed in lama are therefore capable of
using action costs  secondly  the search algorithm should not only take the cost to go from a given
state into account  but also the cost necessary for reaching that state  this is the case for weighted
a search as used in lama  to make the most of the available time  lama employs an anytime
approach  it first runs a greedy best first search  aimed at finding a solution as quickly as possible 
once a plan is found  it searches for progressively better solutions by running a series of weighted
a searches with decreasing weight  the cost of the best known solution is used for pruning the
search  while decreasing the weight over time makes the search progressively less greedy  trading
speed for solution quality 
several anytime algorithms based on weighted a have been proposed  hansen   zhou       
likhachev  ferguson  gordon  stentz    thrun         their underlying idea is to continue the
weighted a search past the first solution  possibly adjusting search parameters like the weight or
pruning bound  and thus progressively find better solutions  the anytime approach used in lama
differs from these existing algorithms in that we do not continue the weighted a search once it
finds a solution  instead  we start a new weighted a search  i  e   we discard the open lists of
the previous search and re start from the initial state  while resulting in some duplicate effort  these
restarts can help overcome bad decisions made by the early  comparatively greedy  search iterations
with high weight  richter et al          this can be explained as follows  after finding a goal state
sg   the open lists will usually contain many states that are close to sg in the search space  because the
ancestors of sg have been expanded  furthermore  those states are likely to have low heuristic values
because of their proximity to sg   hence  if the search is continued  even after updating the open
lists with lower weights   it is likely to expand most of the states around sg before considering states
that are close to the initial state  this can be critical  as it means that the search is concentrating
on improving the end of the current plan  as opposed to its beginning  a bad beginning of a plan 
however  may have severe negative influence on its quality  as it may be impossible to improve the
quality of the plan substantially without changing its early operators 
   

firichter   westphal

   
    
   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   

g 

   
   

s

   
   

   
   
   
   
   
   
   
   

g 

 a  initial search  w    

   
   
   
   
   
   

   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
   

   
   

x

s

   
   

x
x
x
x

g 

           
            
           
            
           
            
       
        

   
   
   
   

g 

 b  continued search  w      

   
   
   
   

   
   

s

   
   

   
   
   
   
   
   

   
   
   
   
   
   
   
   

g 

   
   
   
   
   
   
   
   

g 
 c  restarted search  w      

figure    the effect of low h bias  for all grid states generated by the search  h values are shown
above f    values   a  initial weighted a search finds a solution of cost     b  continued search
expands many states around the previous open list  grey cells   finding another sub optimal solution
of cost     c  restarted search quickly finds the optimal solution of cost   

   

fithe lama planner  guiding cost based anytime planning with landmarks

consider the example of a search problem shown in figure    the task is to reach a goal state
 g  or g   from the start state s in a gridworld  where the agent can move with cost   to each of
the   neighbours of a cell if they are not blocked  the heuristic values are inaccurate estimates of
the straight line goal distances of cells  in particular  the heuristic values underestimate distances
in the left half of the grid  we conduct a weighted a search with weight   in figure  a  assuming
for simplicity a standard textbook search  i  e   no preferred operators and no deferred evaluation  
because the heuristic values to the left of s happen to be lower than to the right of s  the search
expands states to the left and finds goal g  with cost    the grey cells are generated  but not
expanded in this search phase  i  e   they are in the open list  in figure  b  the search continues with
a reduced weight of      a solution with cost   consists in turning right from s and going to g  
however  the search will first expand all states in the open list that have an f    value smaller than   
after expanding a substantial number of states  the second solution it finds is a path which starts off
left of s and takes the long way around the obstacle to g   again with cost    if we instead restart
with an empty open list after the first solution  figure  c   fewer states are expanded  the critical
state to the right of s is expanded quickly and the optimal path is found 
note that in the above example  it is in particular the systematic errors of the heuristic values
that leads the greedy search astray and makes restarts useful  in planning  especially when using
deferred evaluation  heuristic values may also be fairly inaccurate  and restarts can be useful  in
an experimental comparison on all tasks from ipc      to ipc       richter et al         this
restarting approach performed notably better than all other tested methods  dominating similar algorithms based on weighted a  hansen  zilberstein    danilchenko        hansen   zhou       
likhachev  gordon    thrun        likhachev et al          as well as other anytime approaches
 zhou   hansen        aine  chakrabarti    kumar        
      using cost and distance estimates
both heuristic estimators used in lama are cost sensitive  aiming to guide the search towards
high quality solutions  focusing a planner purely on action costs  however  may be dangerous  as
cheap plans may be longer and more difficult to find  which in the worst case could mean that the
planner fails to find a plan at all within the given time limit  zero cost operators present a particular
challenge  since zero cost operators can always be added to a search path for free  even a costsensitive search algorithm like weighted a may explore very long search paths without getting
closer to a goal  methods have been suggested that allow a trade off between the putative cost to go
and the estimated goal distance  gerevini   serina        ruml   do         however  they require the user to specify the relative importance of cost versus distance up front  a choice that was
not obvious in the context of ipc       lama gives equal weight to the cost and distance estimates by adding the two values during the computation of its heuristic functions  for more details 
see sections   and     this measure is a very simple one  and its effect changes depending on the
magnitude and variation of action costs in a problem  the smaller action costs are  the more this
method favours short plans over cheap plans  for example    zero cost operators result in an estimated cost of    whereas   operators of cost   result in an estimated cost of    lama would thus
prefer the   operators of cost   over the   zero cost operators  by contrast  when the action costs
in a planning task are larger than the length of typical plans  the cost estimates dominate the distance estimates and lama is completely guided by costs  nevertheless this simple measure proves
useful on the ipc      benchmarks  outperforming pure cost search in our experiments  more so   

firichter   westphal

a
c

b

e

plane

box
d
truck

figure    a simple logistics task  transport the box from location b to location e 

phisticated methods for automatically balancing cost against distance  for example by normalising
the action costs in a given task with respect to their mean or median  are a topic of future work 

   landmarks
landmarks are subgoals that must be achieved in every plan  they were first introduced by porteous 
sebastia and hoffmann        and were later studied in more depth by the same authors  hoffmann 
porteous    sebastia         using landmarks to guide the search for a solution in planning is an
intuitive approach that humans might use  consider the well known benchmark domain logistics 
where the goal is to deliver objects  e  g  boxes  between various locations using a fleet of vehicles 
cities consist of sets of locations  where trucks may transport boxes within the city  whereas planes
have to be used between cities  an example logistics task is shown in figure    arguably the first
mental step a human would perform  when trying to solve the task in figure    is to realise that the
box must be transported between the two cities  from the left city  locations ad  to the right city
 location e   and that therefore  the box will have to be transported in the plane  this in turn means
that the box will have to be at the airport location c  so it can be loaded into a plane  this partitions
the task into two subproblems  one of transporting the box to the airport at location c  and one of
delivering it from there to the other city  both subproblems are smaller and easier to solve than the
original task 
landmarks capture precisely these intermediate conditions that can be used to direct search  the
facts l    box is at c and l    box is in plane are landmarks in the task shown in figure   
this knowledge  as well as the knowledge that l  must become true before l    can be automatically
extracted from the task in a preprocessing step  hoffmann et al         
lama uses landmarks to derive goal distance estimates for a heuristic search  it measures
the goal distance of a state by the number of landmarks that still need to be achieved on the path
from this state to a goal  orderings between landmarks are used to infer which landmarks should
be achieved next  and whether certain landmarks have to be achieved more than once  in addition 
preferred operators  helmert        are used to suggest operators that achieve those landmarks that
need to become true next  as we have recently shown  this method for using landmarks leads to
substantially better performance than the previous use of landmarks by hoffmann et al   both in
terms of coverage and in terms of plan quality  richter et al          we discuss the differences
between their approach and ours in more detail in section      in the following section we define
   

fithe lama planner  guiding cost based anytime planning with landmarks

a
plane 
e

c

b
box

plane 
f

truck 

d
truck 

figure    extended logistics task  transport the box from location b to location f 
landmarks and their orderings formally  including some useful special cases that can be detected
efficiently 
    definitions
hoffmann et al         define landmarks as facts that are true at some point in every plan for a
given planning task  they also introduce disjunctive landmarks  defined as sets of facts of which
at least one needs to be true at some point  we subsume their landmark definitions into a more
general definition based on propositional formulas  as we believe this to be useful for future work
on the topic of landmarks  it should be noted  however  that lama currently only supports fact
landmarks and disjunctions of facts  for more details  see section       hoffmann et al  show that
it is pspace hard to determine whether a given fact is a landmark  and whether an ordering holds
between two landmarks  their complexity results carry over in a straight forward way to the more
general case of propositional formulas  so we do not repeat the proofs 
definition    landmark
let    hv  s    s    o  ci be a planning task in finite domain representation  let    ho            on i be
an operator sequence applicable in s    and let i  j              n  
 a propositional formula  over the facts of  is called a fact formula 
 a fact f is true at time i in  iff f  s   ho            oi i  
 a fact formula  is true at time i in  iff  holds given the truth value of all facts of  at time
i  at any time i       is not considered true 
 a fact formula  is a landmark of  iff in each plan for    is true at some time 
 a propositional formula  over the facts of  is added at time i in  iff  is true at time i in
  but not at time i     it is considered added at time   if it is true in s    
 a fact formula  is first added at time i in  iff  is true at time i in   but not at any time j   i 
note that facts in the initial state and facts in the goal are always landmarks by definition 
the landmarks we discussed earlier for the example task in figure   were all facts  however 
more complex landmarks may be required in larger tasks  consider an extended version of the
   

firichter   westphal

example  where the city on the right has two airports  and there are multiple planes and trucks 
as depicted in figure    the previous landmark l    box is at c is still a landmark in our
extended example  however  l    box is in plane has no corresponding fact landmark in this
task  since neither box is in plane   nor box is in plane   is a landmark  the disjunction box
is in plane   box is in plane    however  is a landmark  in the following we refer to landmarks
that are facts as fact landmarks  and to disjunctions of facts as disjunctive landmarks  while the
use of disjunctive landmarks has been shown to improve performance  compared to using only fact
landmarks  richter et al          more complex landmarks introduce additional difficulty both with
regard to their detection and their handling during planning  as mentioned before  lama currently
only uses fact landmarks and disjunctive landmarks  rather than general propositional formulas  the
extension to more complex types of landmarks is an interesting topic of future work   see keyder 
richter and helmert        for a discussion of conjunctive landmarks  
various kinds of orderings between landmarks can be defined and exploited during the planning
phase  we define three types of orderings for landmarks  which are equivalent formulations of the
definitions by hoffmann et al         adapted to the fdr setting 
definition    orderings between landmarks
let  and  be landmarks in an fdr planning task  
 we say that there is a natural ordering between  and   written     if in each plan
where  is true at time i   is true at some time j   i 
 we say that there is a necessary ordering between  and   written  n   if in each plan
where  is added at time i   is true at time i    
 we say that there is a greedy necessary ordering between  and   written  gn   if in
each plan where  is first added at time i   is true at time i    
natural orderings are the most general  every necessary or greedy necessary ordering is natural 
but not vice versa  similarly  every necessary ordering is greedy necessary  but not vice versa 
knowing that a natural ordering is also necessary or greedy necessary allows deducing additional
information about plausible temporal relationships between landmarks  as described later in this
section  also  the landmark heuristic in lama uses this knowledge to deduce whether a landmark
needs to be achieved more than once  as a theoretical concept  necessary orderings   is always true
in the step before   are more straightforward and appealing than greedy necessary orderings   is
true in the step before  becomes true for the first time   however  methods that find landmarks
in conjunction with orderings can often find many more landmarks when using the more general
concept of greedy necessary orderings  hoffmann et al          lama follows this paradigm and
finds greedy necessary  as well as natural  orderings  but not necessary orderings  in our example in
figure    box is in truck   must be true before box is at c and also before box is at f  the first
of these orderings is greedy necessary  but not necessary  and the second is neither greedy necessary
nor necessary  but natural 
hoffmann et al         propose further kinds of orderings between landmarks that can be usefully exploited  for example  reasonable orderings  which were first introduced in the context of
top level goals  koehler   hoffmann         are orderings that do not necessarily hold in a given
planning task  however  adhering to these orderings may save effort when solving the task  in our
example task  it is reasonable to load the box onto truck  before driving the truck to the airport at
   

fithe lama planner  guiding cost based anytime planning with landmarks

c  however  this order is not guaranteed to hold in every plan  as it is possible  though not reasonable  to drive the truck to c first  then drive to b and collect the box  and then return to c  the idea
is that if a landmark  must become false in order to achieve a landmark   but  is needed after  
then it is reasonable to achieve  before   as otherwise  we would have to achieve  twice   the
idea may be applied iteratively  as we are sometimes able to find new  induced reasonable orderings
if we restrict our focus to plans that obey a first set of reasonable orderings  hoffmann et al  call
the reasonable orderings found in such a second pass obedient reasonable orderings  the authors
note that conducting more than two iterations of this process is not worthwhile  as it typically does
not result in notable additional benefit  the following definition characterises these two types of
orderings formally 
definition    reasonable orderings between landmarks
let  and  be landmarks in an fdr planning task  
 we say that there is a reasonable ordering between  and   written  r   if for every plan
 where  is added at time i and  is first added at time j with i   j  it holds that  is not true
at time m with m   i              j  and  is true at some time k with j  k 
 we say that a plan  obeys a set of orderings o  if for all orderings  x   o  regardless
of their type  it holds that  is first added at time i in  and  is not true at any time j  i 
 we say that there is an obedient reasonable ordering between  and  with regard to a set of
orderings o  written  o
r   if for every plan  obeying o where  is added at time i and 
is first added at time j with i   j  it holds that  is not true at time m with m   i              j 
and  is true at some time k with j  k 
our definitions are equivalent to those of hoffmann et al          except that we care only
about plans rather than arbitrary operator sequences  allowing us to  theoretically  identify more
reasonable orderings  in practice  we use the same approximation techniques as hoffmann et al  
thus generating the same orderings 
a problem with reasonable and obedient reasonable orderings is that they may be cyclic  i  e  
chains of orderings  r  x       r  for landmarks  and  may exist  hoffmann et al         
this is not the case for natural orderings  as their definition implies that they cannot be cyclic in
solvable tasks 
in addition  the definitions as given above are problematic in special cases  note that the definition of a reasonable ordering  r  includes the case where there exist no i   j such that  is
added at time i and  is first added at time j  i  e   the case where it holds that in all plans  is first
added  a  before or  b  at the same time as    while  a  implies that reasonable orderings are a
generalisation of natural orderings  which might be regarded as a desirable property   b  may lead
to undesirable orderings  for example  it holds that  r  and  r  for all pairs    that are
first added at the same time in all plans  for instance if  and  are both true in the initial state 
similarly  it holds that  r  for all   we use these definitions despite their weaknesses here 
and simply note that our planner does not create all such contentious orderings  lama does not
create reflexive orderings  r   and  r  with    true in the initial state is only created if it
is assumed or proven that  must be true strictly after  at some point in any plan  see also section
   according to personal communication with the authors  this case was overlooked by hoffmann et al 

   

firichter   westphal

truck  at d
truck  at b

box at b

box in truck 
truck  at c
plane  at c  plane  at c

box at c

box in plane   box in plane 
box at f
figure    partial landmark graph for the example task shown in figure    bold arcs represent natural
orderings  dashed arcs represent reasonable orderings 

        a re definition of reasonable orderings  addressing the problems of the definition by hoffmann et al  and identifying precisely the wanted unwanted cases  is a topic of future work  closely
connected is the question whether reasonable orderings should be interpreted as strict orderings 
where  should be achieved before   as in the definition of obedience above   or whether we allow
achieving  and  simultaneously  we use the strict sense of obedience for reasons of consistency
with the previous work by hoffmann et al   and because it aligns better with our intended meaning of
reasonable orderings  even though this strict interpretation of obedience does not fit the contentious
cases discussed above 
landmarks and orderings may be represented using a directed graph called the landmark graph 
a partial landmark graph for our extended example is depicted in figure    the following section
    contains an extensive description of how landmarks and their orderings are discovered in lama 
readers not interested in the exact details of this process may skip this description  as it is not central
to the rest of this paper  section     discusses how our approach for finding and using landmarks
relates to previous work  section   describes how landmarks are used as a heuristic estimator in
lama 
    extracting landmarks and orderings
as mentioned before  deciding whether a given formula is a landmark and deciding orderings between landmarks are pspace hard problems  thus  practical methods for finding landmarks are
incomplete  they may fail to find a given landmark or ordering  or unsound  they may falsely declare a formula to be a landmark  or determine a false ordering   several polynomial methods have
been proposed for finding fact landmarks and disjunctive landmarks  such as back chaining from
the goals of the task  using criteria based on the relaxed planning graph  porteous et al         hoffmann et al         porteous   cresswell         and forward propagation in the planning graph
 zhu   givan        
   

fithe lama planner  guiding cost based anytime planning with landmarks

the algorithm used in lama for finding landmarks and orderings between them is partly based
on the previous back chaining methods mentioned above  adapting them to the finite domain representation including conditional effects  in addition  our algorithm exploits the finite domain representation by using domain transition graphs to find further landmarks  we discuss the differences
between our method and the previous ones in detail in section      the idea of back chaining is to
start from a set of known landmarks and to find new fact landmarks or disjunctive landmarks that
must be true in any plan before an already known landmark may become true  this procedure starts
from the set of all goal facts  and stops when no more new landmarks can be found  our method
identifies new landmarks and orderings by considering  for any given fact landmark or disjunctive
landmark  that is not true in the initial state 
 the shared preconditions of its possible first achievers  these are the operator preconditions
and effect conditions shared by all effects that can potentially first achieve   this method
has been adapted from previous work  see section      
 for fact landmarks v   d  the domain transition graph  dtg  of v  here  we identify nodes
in the dtg  i  e   values d  of v  that must necessarily be traversed in order to reach d 
 a restricted relaxed planning graph lacking all operators that could possibly achieve    there
are some subtleties involving conditional effects that will be explained later   every landmark
which does not occur in the last level of this graph can only be achieved after  
as in previous work  porteous et al         hoffmann et al          we subsequently use the discovered landmarks and orderings to derive reasonable and obedient reasonable orderings in a postprocessing step  in the following  we give a detailed description of each step of the procedure for
finding landmarks and orderings in lama  high level pseudo code for our algorithm  containing
the steps described in the following sections             is shown in algorithm   
      back chaining  landmarks via shared preconditions of possible first achievers
first achievers of a fact landmark or disjunctive landmark  are those operators that potentially
make  true and can be applied at the end of a partial plan that has never made  true before  we
call any fact a that is a precondition for each of the first achievers a shared precondition  as at least
one of the first achievers must be applied to make  true  a must be true before  can be achieved 
and a is thus a landmark  with the ordering a gn   any effect condition for  in an operator
can be treated like a precondition in this context  as we are interested in finding the conditions that
must hold for  to become true  we will in the following use the term extended preconditions of an
operator o for  to denote the union of the preconditions of o and its effect conditions for   the
extended preconditions shared by all achievers of a fact are calculated in line    of algorithm    in
addition  we can create disjunctive landmarks  by selecting  from the precondition facts of the first
achievers  sets of facts such that each set contains one extended precondition fact from each first
achiever  line      as one of the first achievers must be applied to make  true  one of the facts in
 must be true before   and the disjunction  is thus a landmark  with the ordering  gn   since
the number of such disjunctive landmarks is exponential in the number of achievers of   we restrict
ourselves to disjunctions where all facts stem from the same predicate symbol  which are deemed
most helpful  hoffmann et al          furthermore  we discard any fact sets of size greater than
four  though we found this restriction to have little impact compared to the predicate restriction 
   

firichter   westphal

global variables 
   hv  s    s    o  ci
lg   hl  oi
queue
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

  planning task to solve
  landmark graph of 
  landmarks to be back chained from

function add landmark and ordering    x  
if  is a fact and   l       and      then
  prefer fact landmarks
l  l     
  remove disjunctive landmark
o  o       x      x       l  
  remove obsolete orderings
if   l       and var    var      then   abort on overlap with existing landmark
return
if    l then
  add new landmark to graph
l  l    
queue  queue    
o  o    x  
  add new ordering to graph
function identify landmarks
lg  hs    i
  landmark graph starts with all goals  no orderings
queue  s 
further orderings  
  additional orderings  see section       
while queue    do
  pop queue 
if s       then
rrpg  the restricted relaxed plan graph for 
preshared  shared extended preconditions for  extracted from rrpg
for   preshared do
add landmark and ordering    gn  
predisj  sets of facts covering shared extended preconditions for  given rrpg
for   predisj do
if s       then
add landmark and ordering    gn  
if  is a fact then
prelookahead  extract landmarks from dtg of the variable in  using rrpg
for   prelookahead do
add landmark and ordering      
potential orderings  potential orderings      f   f never true in rrpg  
add further orderings between landmarks from potential orderings

algorithm    identifying landmarks and orderings via back chaining  domain transition graphs and
restricted relaxed planning graphs 

   

fithe lama planner  guiding cost based anytime planning with landmarks

p 

a

b

t 

e

t 

c

p 

d

f

figure    domain transition graph for the location of the box in our extended example  figure    

since it is pspace hard to determine the set of first achievers of a landmark   hoffmann et al  
       we use an over approximation containing every operator that can possibly be a first achiever
 porteous   cresswell         by intersecting over the extended preconditions of  possibly  more
operators we do not lose correctness  though we may miss out on some landmarks  the approximation of first achievers of  is done with the help of a restricted relaxed planning graph  during
construction of the graph we leave out any operators that would add  unconditionally  and we also
ignore any conditional effects which could potentially add   when the relaxed planning graph
levels out  its last set of facts is an over approximation of the facts that can be achieved before  in
the planning task  any operator that is applicable given this over approximating set and achieves 
is a possible first achiever of  
      landmarks via domain transition graphs
given a fact landmark l    v   l   we can use the domain transition graph of v to find further fact
landmarks v   l   line     as follows  if the dtg contains a node that occurs on every path from
the initial state value s   v  of a variable to the landmark value l  then that node corresponds to a
landmark value l  of v  we know that every plan achieving l requires that v takes on the value l   
hence the fact l     v   l    can be introduced as a new landmark and ordered naturally before l  to
find these kinds of landmarks  we iteratively remove one node from the dtg and test with a simple
graph algorithm whether s   v  and l are still connected  if not  the removed node corresponds to
a landmark  we further improve this procedure by removing  as a preprocessing step  all nodes for
which we know that they cannot be true before achieving l  these are the nodes that correspond to
facts other than l and do not appear in the restricted rpg that never adds l  removing these nodes
may decrease the number of paths reaching l and may thus allow us to find more landmarks 
consider again the landmark graph of our extended example  shown in figure    most of its
landmarks and orderings can be found via the back chaining procedure described in the previous
section  because the landmarks are direct preconditions for achieving their successors in the graph 
there are two exceptions  box in truck   and box at c  these two landmarks are however found
with the dtg method  the dtg in figure   immediately shows that the box location must take on
both the value t  and the value c on any path from its initial value b to its goal value f 
   

firichter   westphal

      additional orderings from restricted relaxed planning graphs
the restricted relaxed planning graph  rrpg  described in section        which for a given landmark  leaves out all operators that could possibly achieve   can be used to extract additional
orderings between landmarks  any landmark  that does not appear in this graph cannot be reached
before   and we can thus introduce a natural ordering     for efficiency reasons  we construct
the rrpg for  only once  line      i  e   when needed to find possible first achievers of  during
the back chaining procedure  we then extract all orderings between  and facts that can only be
reached after   line      for all such facts f that are later recognised to be landmarks  we then
introduce the ordering   f  line     
      overlapping landmarks
due to the iterative nature of the algorithm it is possible that we find disjunctive landmarks for
which at least one of the facts is already known to be a fact landmark  in such cases  we let fact
landmarks take precedence over disjunctive ones  i  e   when a disjunctive landmark is discovered
that includes an already known fact landmark  we do not add the disjunctive landmark  conversely 
as soon as a fact landmark is found that is part of an already known disjunctive landmark  we discard
the disjunctive landmark including its orderings    and add the fact landmark instead  to keep the
procedure and the resulting landmark graph simple  we furthermore do not allow landmarks to
overlap  whenever some fact from a newly discovered disjunctive landmark is also part of some
already known landmark  we do not add the newly discovered landmark  all these cases are handled
in the function add landmark and ordering  lines       
      generating reasonable and obedient reasonable orderings
we want to introduce a reasonable ordering l r l  between two  distinct  fact landmarks l and
l  if it holds that  a  l  must be true at the same time or after first achieving l  and  b  achieving
l  before l would require making l  false again to achieve l  we approximate both  a  and  b  as
proposed by hoffmann et al         with sufficient conditions  in the case of  a   we test if l   s  or
if we have a chain of natural or greedy necessary orderings between landmarks l   l          ln  
with n      ln    l  and a greedy necessary ordering l  gn ln   for  b  we check whether  i  l
and l  are inconsistent  i  e   mutually exclusive  or  ii  all operators achieving l have an effect
that is inconsistent with l    or  iii  there is a landmark l   inconsistent with l  with the ordering
l   gn l 
inconsistencies between facts can be easily identified in the finite domain representation if the
facts are of the form v   d and v   d    i  e   if they map the same variable to different values  in
addition  lama uses the groups of inconsistent facts computed by its translator component 
in a second pass  obedient reasonable orderings are added  this is done with the same method
as above  except that now reasonable orderings are used in addition to natural and greedy necessary
orderings to derive the fact that a landmark l  must be true after a landmark l  finally  we use a
simple greedy algorithm to break possible cycles due to reasonable and obedient reasonable orderings in the landmark graph  where every time a cycle is identified  one of the involved reasonable or
   note that an ordering  f  g    neither implies f   nor g   in general  conversely     f  g  neither
implies   f nor   g 

   

fithe lama planner  guiding cost based anytime planning with landmarks

obedient reasonable orderings is removed  the algorithm removes obedient reasonable orderings
rather than reasonable orderings whenever possible 
    related work
orderings between landmarks are a generalisation of goal orderings  which have been frequently
exploited in planning and search in the past  in particular  the approach by irani and cheng  irani  
cheng        cheng   irani        is a preprocessing procedure like ours that analyses the planning
task to extract necessary orderings between goals  which are then imposed on the search algorithm 
a goal a is ordered before a goal b in this approach if in any plan a is necessarily true before b 
koehler and hoffmann        introduce reasonable orderings for goals 
hoffmann et al          in an article detailing earlier work by porteous et al          introduce
the idea of landmarks  generalise necessary and reasonable orderings from goals to landmarks  and
propose methods for finding and using landmarks for planning  the proposed method for finding
landmarks  which was subsequently extended by porteous and cresswell         is very closely
related to ours  hoffmann et al  propose a method for finding fact landmarks that proceeds in three
stages  first  potential landmarks and orderings are suggested by a fast candidate generation procedure  second  a filtering procedure evaluates a sufficient condition for landmarks on each candidate
fact  removing those which fail the test  third  reasonable and obedient reasonable orderings between the landmarks are approximated  this step is largely identical in their approach and ours 
except that we use different methods to recognise inconsistencies between facts 
the generation of landmark candidates is done via back chaining from the goal much like in
our approach  and intersecting preconditions over all operators which can first achieve a fact f
and appear before f in the relaxed planning graph  note that even if all these operators share a
common precondition l  there might be other first achievers of f  appearing after f in the relaxed
planning graph  that do not have l as a precondition  and hence l is not a landmark  to test whether
a landmark candidate l found via back chaining is indeed a landmark  hoffmann et al        
build a restricted relaxed planning task leaving out all operators which could add l  if this task is
unsolvable  then l is a landmark  this is a sufficient  but not necessary condition  if l is necessary
for solving the relaxed task it is also necessary for solving the original task  while the converse is not
true  this verification procedure guarantees that the method by hoffmann et al  only generates true
landmarks  however  unsound orderings may be established due to unsound landmark candidates 
while the unsound landmarks are pruned after failing the verification test  unsound orderings may
remain 
porteous and cresswell        propose the alternative approximation for first achievers of a
fact f that we use  they consider all first achievers that are possibly applicable before f and
thus guarantee the correctness of the found landmarks and orderings  they also find disjunctive
landmarks  our method for landmark detection differs from theirs by adding detection of landmarks
via domain transition graphs  and detection of additional orderings via restricted relaxed planning
graphs  porteous and cresswell additionally reason about multiple occurrences of landmarks  if the
same landmark has to be achieved  made false again and re achieved several times during all plans  
which we do not 
the approach by hoffmann et al         exploits landmarks by decomposing the planning task
into smaller subtasks  making the landmarks intermediary goals  instead of searching for the goal
of the task  it iteratively aims to achieve a landmark that is minimal with respect to the orderings  in
   

firichter   westphal

detail  it first builds a landmark graph  with landmarks as vertices and orderings as arcs   possible
cycles are broken by removing some arcs  the sources s of the resulting directed acyclic graph are
handed over to a base planner as a disjunctive goal  and a plan is generated to achieve one of the
landmarks in s   this landmark  along with its incident arcs  is then removed from the landmark
graph  and the process repeats from the end state of the generated plan  once the landmark graph
becomes empty  the base planner is asked to generate a plan to the original goal   note that even
though all goal facts are landmarks and were thus achieved previously  they may have been violated
again  
as a base planner for solving the subtasks any planner can be used  hoffmann et al        
experimented with ff  they found that the decomposition into subtasks can lead to a more directed search  solving larger instances than plain ff in many domains  however  we found that
their method leads to worse average performance on the ipc benchmarks from      to      when
using fast downward as a base planner  richter et al          furthermore  the method by hoffmann et al  often produces solutions that are longer than those produced by the base planner  as
the disjunctive search control frequently switches between different parts of the task which may
have destructive interactions  sometimes this even leads to dead ends  so that this approach fails on
solvable tasks  by contrast  our approach incorporates landmark information while searching for
the original goal of the planning task via a heuristic function derived from the landmarks  see next
section   as we have recently shown  this avoids the possibility of dead ends and usually generates
better quality solutions  richter et al         
sebastia et al         extend the work by hoffmann et al  by employing a refined preprocessing technique that groups landmarks into consistent sets  minimising the destructive interactions
between the sets  taking these sets as intermediary goals  they avoid the increased plan length
experienced by hoffmann et al          however  according to the authors this preprocessing is
computationally expensive and may take longer than solving the original problem 
zhu and givan        propose a technique for finding landmarks by propagating necessary
predecessor information in a planning graph  their definition of landmarks encompasses operators
that are necessary in any plan  called action landmarks   and they furthermore introduce the notion
of a causal landmark for fact landmarks that are required as a precondition for some operators
in every plan  they argue that fact landmarks which are not causal are accidental effects and
do not warrant being sought explicitly  their algorithm computes action landmarks and causal
fact landmarks at the same time by propagating information during the construction of a relaxed
planning graph  an extended variant of their algorithm is also able to infer multiple occurrences
of landmarks  gregory et al         build on their work to find disjunctive landmarks through
symmetry breaking 
similar to our work  zhu and givan        use the causal fact landmarks and action landmarks
to estimate the goal distance of a given state  to this end  they treat each fact landmark as a virtual
action  sets of operators that can achieve the fact landmark  and obtain a distance estimate by bin
packing  the items to be packed into bins are the real landmark actions  singletons  and virtual
actions  where each bin may only contain elements such that a pairwise intersection of the elements
is non empty  zhu and givan employ a greedy algorithm to estimate the minimum number of bins
and use this value as distance estimate  their experimental results are preliminary  however  and do
not demonstrate a significant advantage of their method over the ff planner 
   

fithe lama planner  guiding cost based anytime planning with landmarks

   the landmark heuristic
the lama planning system uses landmarks to calculate heuristic estimates  since we know that
all landmarks must be achieved in order to reach a goal  we can approximate the goal distance of
a state s reached by a path  i  e   a sequence of states   as the estimated number of landmarks that
still need to be achieved from s onwards  these landmarks are given by

l s    b l   accepted s     reqagain s   
where l is the set of all discovered landmarks  accepted s    is the set of accepted landmarks 
and reqagain s    is the set of accepted landmarks that are required again  with the following
definitions based on a given landmarks graph  l  o   

 


  l   s     and    x    o
   hi





 
 
accepted s    b 
       hoi
accepted s             l   s    



 

 and   x    o     accepted s           

reqagain s    b   accepted s      s     
 
and s      or   gn    o      accepted s   
a landmark  is first accepted in a state s if it is true in that state  and all landmarks ordered
before  are accepted in the predecessor state from which s was generated  once a landmark has
been accepted  it remains accepted in all successor states  for the initial state  accepted landmarks
are all those that are true in the initial state and do not have any predecessors in the landmark graph 
an accepted landmark  is required again if it is not true in s and  a  it forms part of the goal or
 b  it must be true directly before some landmark   i  e    gn   where  is not accepted in s 
in the latter case  since we know that  must still be achieved and  must be true in the time step
before   it holds that  must be achieved again  the number  l s     is then the heuristic value
assigned to state s  pseudo code for the heuristic is given in algorithm   
the landmark heuristic will assign a non zero value to any state that is not a goal state  since
goals are landmarks that are always counted as required again per condition  a  above  however 
the heuristic may also assign a non zero value to a goal state  this happens if plans are found that
do not obey the reasonable orderings in the landmark graph  in which case a goal state may be
reached without all landmarks being accepted   hence  we need to explicitly test states for the goal
condition in order to identify goal states during search 
note that this heuristic is path dependent  i  e   it depends on the sequence of states by which s
is reached from the initial state  this raises the question of what happens if a state s can be reached
via several paths  in lama  the heuristic for a state is calculated only once  when it is first reached 
an alternative option would be to re evaluate s each time a new path to s is discovered  taking into
account the information of all paths to s known at the time  as karpas and domshlak        note 
we can calculate the landmarks that are accepted in s given a set of paths p to s as accepted s  p  b
t
p accepted s     since it holds that any landmark that is not achieved along all paths   p must
   in the special case where  r  and  and  can become true simultaneously  we could avoid this by accepting
both  and  at once  buffet   hoffmann         or we could modify our definition of reasonable orderings such
that  r  does not hold unless  must become true strictly after   the general problem that goal states may be
assigned a non zero value  however  still persists even with these modifications 

   

firichter   westphal

global variables 
   hv  s    s    o  ci
lg   hl  oi
accepted

  planning task to solve
  landmark graph of 
  landmarks accepted in states evaluated so far

function lm count heuristic s   
if    hi then
  initial state

 
accepted s       l   s      and    x    o
else
   ho            on  i for    ho            on i
parent  s      
  accepted parent      has been calculated before
reached      l   s     and   x    o     accepted parent       
accepted s     accepted parent       reached
notaccepted  l   accepted s   
reqgoal    n  accepted s      s      and s       
o
reqprecon    accepted s      s      and      gn    o     accepted s   
return  notaccepted  reqgoal  reqprecon 
algorithm    the landmark count heuristic 

be achieved from s onwards  the heuristic value of s can then be derived from this in an analogous
way as before 
the landmark heuristic as outlined above estimates the goal distance of states  i  e   the number
of operator applications needed to reach the goal state from a given state  to participate in ipc      
we made this function cost sensitive by weighting landmarks with an estimate of their minimum
cost  apart from estimating goal distance by counting the number of landmarks that still need to
be achieved from a state  we estimate the cost to go from a state by the sum of all minimum costs
of those landmarks  the cost counted for each landmark is the minimum action cost of any of
its first achievers   alternative  more sophisticated methods for computing the costs of landmarks
are conceivable and are a potential topic of future work   the heuristic value lama assigns to
a state is however not its pure cost to go estimate  but rather the sum of its cost estimate and its
distance estimate  by thus accounting for both the costs to go and the goal distances of states  this
measure aims to balance speed of the search and quality of the plans  and in particular counter act
the problems that may arise from zero cost operators  see section      
we also generate preferred operators along with the landmark heuristic  an operator is preferred
in a state if applying it achieves an acceptable landmark in the next step  i  e   a landmark whose predecessors have already been accepted  if no acceptable landmark can be achieved within one step 
the preferred operators are those which occur in a relaxed plan to a nearest acceptable landmark  a
nearest landmark in the cost unaware setting is one that is relaxed reachable with a minimal number
of operators  while in the cost sensitive setting it is a landmark reachable with the cheapest hadd cost
 see section     where again both cost and distance estimates are taken into account  this nearest
landmark can be computed by building a relaxed planning graph or  equivalently  performing a relaxed exploration  which is what lama does  see section     and determining the earliest or least
costly occurrence of an acceptable landmark in this structure  a relaxed plan to this landmark is
   

fithe lama planner  guiding cost based anytime planning with landmarks

then extracted  and the operators in this plan form preferred operators if they are applicable in the
current state 

   the cost sensitive ff add heuristic
when we first introduced the landmark heuristic  richter et al          it proved not to be competitive on its own  compared to established heuristics like the ff heuristic  hoffmann   nebel 
       however  the joint use of the ff heuristic and the landmark heuristic in a multi heuristic
search improved the performance of a planning system  compared with only using the ff heuristic 
this is thus the path lama follows  the ff heuristic is based on a relaxation of the planning task
that ignores delete effects  which in fdr tasks translates to allowing state variables to hold several
values simultaneously 
the ff heuristic for a state s is computed in two phases  the first phase  or forward phase 
calculates an estimate for each fact in the planning task of how costly it is to achieve the fact from
s in a relaxed task  concurrently  it selects an operator called best support for each fact f  which
is a greedy approximation of a cheapest achiever  an achiever a of f where the costs of making a
applicable and applying it are minimal among all achievers of f  when starting in s   in the second
phase  a plan for the relaxed task is constructed based on the best supports for each fact  this is done
by chaining backwards from the goals  selecting the best supports of the goals  and then recursively
selecting the best supports for the preconditions of already selected operators  the union of these
best supports then constitutes the relaxed plan  i  e   for each fact its best support is only added to
the relaxed plan once  even if the fact is needed several times as a precondition   the length of the
resulting relaxed plan is the heuristic estimate reported for s 
the forward phase can be viewed as propagating cost information for operators and facts in
a relaxed planning graph  hoffmann   nebel         however  this graph does not need to be
explicitly constructed to compute the heuristic  instead  a form of generalised dijkstra cheapestpath algorithm as described by liu  koenig and furcy        is used in lama  which propagates
costs from preconditions to applicable operators and from operators to effects  in this method  each
operator and fact is represented only once  reducing the time and space requirements from o nk  
where n is the size of the relaxed planning task and k the depth of the relaxed planning graph  to
o n   in order to deal with conditional effects  operators with n effects are split into n operators
with one effect each  and the corresponding effect conditions are moved into the preconditions of
those operators  if any of those n operators is selected for inclusion in the relaxed plan  the original
operator is included instead  again  each operator is included in the relaxed plan only once  
the cost estimate for an operator in the original ff heuristic is its depth in the relaxed planning
graph  which in the case of planning with unit cost operators is equivalent  fuentetaja  borrajo   
linares lopez        to propagating costs via the hmax criterion  bonet   geffner         the hmax
criterion estimates the cost of an operator by the maximum over the costs of its preconditions  plus
the action cost of the operator itself    when planning without action costs   the cost of a fact is
estimated as the cost of its cheapest achiever  or zero if the fact is true in the current state s  while
originally proposed for unit cost planning  this heuristic can be adapted to cost based planning in a
straightforward way by using action costs in the cost propagation phase  and reporting the total cost
of the resulting relaxed plan  rather than its length  as the heuristic estimate 
using other criteria for cost propagation results in variations of the ff heuristic  bryce   kambhampati        fuentetaja et al          one variant that has been previously proposed in the litera   

firichter   westphal

ture  do   kambhampati        is to use the hadd criterion  bonet   geffner         it is similar to
the hmax criterion except for estimating the cost of operators via the sum  rather than the maximum 
of the costs for their preconditions  we will in the following use the term ff add for this variant of
the ff heuristic  independently of us  keyder and geffner        implemented the ff add heuristic
which they call ha in their planner ff ha   at ipc       a formal specification of the ff add heuristic
can be found in their paper  the heuristic function in lama is similar to this cost sensitive ff add
heuristic  however  as with the landmark heuristic  lama is not purely guided by action costs 
but rather uses both cost and distance estimates equally  this means that during cost propagation 
each operator contributes its action cost plus   for its distance  rather than just its action cost  to the
propagated cost estimates 

   experiments
to evaluate how much each of the central features of lama contributes to its performance  we
have conducted a number of experiments comparing different configurations of these features  we
focus our detailed evaluation on the benchmark tasks from the international planning competition
 ipc        as we are interested in the setting of planning with action costs  the effect of landmarks
in classical planning tasks without actions costs has been studied in previous work  richter et al  
       but we provide summarising results for this case  using the domains of ipcs           in
section      the benchmark set of ipc      comprises   domains with    tasks each  resulting in a
total of     tasks  for one of the domains  openstacks   two different formulations were available
 strips and adl   as in the competition  we report the better result of those two formulations for
each planner 
as described in section    lama builds on the platform provided by fast downward in three
major ways      through the use of landmarks      by using cost sensitive heuristics to guide search
for cheap plans  and     by employing anytime search to continue to search for better solutions while
time remains  to examine the usefulness of landmarks  we conduct experiments with and without
them  while keeping all other planner features fixed  the use of action costs in lama is the result of
a number of design decisions  both the landmark heuristic and the ff add heuristic have been made
cost sensitive  however  rather than focusing purely on action costs  lama uses both distance
estimates and cost estimates in combination  see section      to balance speed and quality of the
search  to measure the benefit of this combining approach  we test three different approaches to
dealing with costs   a  using the traditional cost unaware heuristics  distance estimates    b  using
purely cost sensitive heuristics  though using distance estimates for tie breaking   and  c  using
the combination of the distance and cost estimates  as in lama  the different choices regarding
landmarks and approaches to action costs thus result in the following six planner configurations 
 f  use the cost unaware ff add heuristic  estimating goal distance  
 fc   use the purely cost sensitive ff add heuristic  estimating cost to go  
 f c   use the ff add heuristic that combines action costs and distances 
 fl  use the cost unaware variants of both the ff add heuristic and the landmark heuristic 
 flc   use the purely cost sensitive variants of both heuristics 
 fl c   use the variants that combine action costs and distances for both heuristics 
   

fithe lama planner  guiding cost based anytime planning with landmarks

note that in contrast to the setting of optimal planning  karpas   domshlak         the landmark
heuristic by itself is not competitive in our case  and landmarks in lama are used only to provide
additional information to an already guided search  as such  we do not include any configurations using only landmarks as heuristic estimators in our detailed results  however  we provide
summarising results supporting our claim that they are not competitive 
each configuration is run with iterated  anytime  search  when highlighting the contribution
of the iterated search  we report first solutions vs  final solutions  where the final solution of a
configuration is the last  and best  solution it finds within the    minute timeout   note that the
quality of a solution is always determined by its cost  irrespective of whether the heuristic used to
calculate it is cost sensitive or not   when discussing the three possible approaches to costs  costunaware search  purely cost sensitive search  or lamas combination of distances and costs  we
write x  xc   and x c to denote the three cost approaches independently of the heuristics used 
we measure performance using the same criterion that was employed at ipc       helmert
et al          each planner configuration is run for    minutes per task  after the timeout  a planner
aggregates the ratio c  c to its total score if c is the cost of the plan it has found  and c is the cost of
the best known solution  e  g   a reference solution calculated by the competition organisers  or the
best solution found by any of the participating planners  
experiments were run on the hardware used in the competition  a cluster of machines with intel
xeon cpus of     ghz clock speed  the time and memory limits were set to the same values as
in the competition  using a timeout of    minutes and a memory limit of   gb  in the following 
we first provide a general overview of the results  then we discuss special cases  i  e   domains
where the results for certain configurations deviate from the overall trend  and try to give plausible
explanations for why this may happen 
    overview of results
in this section  we show that the purely cost based ff add configuration fc solves significantly
fewer tasks than its cost unaware counterpart f  while fc finds higher quality solutions  this does
not make up for its low coverage  number of solved tasks  when measuring performance with the
ipc criterion  using landmarks improves quality slightly  so that cost unaware search using landmarks  fl  achieves the highest ipc performance score amongst our configurations  when using
the cost sensitive ff add heuristic  adding landmarks  resulting in the configurations flc and fl c  
increases coverage substantially  while incurring only a small loss in quality  iterated search improves the scores of all configurations significantly  lastly  using the combination of cost and
distance estimates in the heuristics  x c   is superior to pure cost based search when using iterated search  together  using landmarks and the combination of cost and distance estimates  fl c  
achieves nearly the same performance as the fl configuration 
in the following  we support these findings with experimental data  in section        performance in terms of the ipc score   we show that the cost sensitive ff add heuristic by itself scores
lowly in terms of the ipc criterion  but that landmarks and the combination of cost and distance estimates together make up for this bad performance  furthermore  our results demonstrate the magnitude of the impact that iterated search has on the performance scores  in section        coverage  
we show that the bad performance of the cost sensitive ff add heuristic is due to solving fewer
tasks  and that the use of landmarks mitigates this problem  in section        quality   we present
data showing that the purely cost sensitive ff add heuristic finds higher quality plans than the cost   

firichter   westphal

domain

base

c 

cyber security
elevators
openstacks
parc printer
peg solitaire
scanalyzer
sokoban
transport
woodworking
total
 total ipc      

 
  
  
  
  
  
  
  
  
   
     

 
  
  
  
  
  
  
 
  
   
     

domain

f

cyber security
elevators
openstacks
parc printer
peg solitaire
scanalyzer
sokoban
transport
woodworking
total

  
  
  
  
  
  
  
  
  
   

ipc planners
ff ha   ff has  
  
 
 
  
  
  
  
  
  
   
     

  
  
 
  
  
  
  
  
  
   
     

first solutions
fl flc
fc
f c

fl c

  
 
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
 
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

lama
  
  
  
  
  
  
  
  
  
   
     

slowed lama
  
   

fl c

  
  
  
  
  
  
  
  
  
   
  

  
  
  
  
  
  
  
  
  
   
  

  
  
  
  
  
  
  
  
  
   
  

final solutions  iterated search 
f
fc
f c
fl flc fl c
  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

table    performance scores  rounded to whole numbers  for planners scoring      points at
ipc       top  and our   experimental configurations  bottom   scores for ipc planners were recalculated  see text   lama    and     refer to the results achieved by lama when slowed
down by factors of    and      respectively  fl c is essentially the same as the ipc planner lama 

unaware ff add heuristic in the first search  but that with iterated search  this difference all but
disappears  furthermore  after iterated search the intermediate approach of using cost and distance
estimates scores higher than the purely cost based search  lamas approach of using landmarks
and the combination of cost and distance estimates  fl c   thus effectively mitigates the bad performance of the cost sensitive ff add heuristic 
      performance in terms of the ipc score
the scores of all planners scoring more than     points at ipc      are shown in the top part of
table    apart from lama  this includes a base planner run by the competition organisers  ff with
a preprocessing step that compiles away action costs   the ff ha   and ff has   planners by keyder
   

fithe lama planner  guiding cost based anytime planning with landmarks

and geffner        and the c  planner by lipovetzky and geffner         the plans found by
these planners have been obtained from the competition website  helmert et al          however 
the scores for those plans depend on the best known solutions for the tasks  the scores we show
here thus differ from the ones published at ipc       as we have re calculated them to reflect new
best solutions found in our experiments  to illustrate the magnitude of the change  the original total
scores of the ipc planners are shown in parentheses in the last table row 
while the configuration fl c results in essentially the same planner as  the ipc version of 
lama  we report its results again  as some minor corrections have been implemented in lama
since the competition  in addition  the planner makes arbitrary decisions at some points during
execution due to underlying programming library methods  leading to varying results  however 
as table   shows these differences between fl c and lama are very small  we have furthermore
added columns to the table showing the hypothetical results for lama that would be obtained if its
search were slowed down by the constant factors    and      respectively  i  e   the results obtained
when cutting of the search after   minutes  or    seconds  respectively   the numbers show that
lama still outperforms the other ipc planners even with a severe handicap  demonstrating that the
good performance of lama is not mainly due to an efficient implementation 
the bottom part of table   contains the results for our six experimental configurations after the
first search iteration  left  and after the    minute timeout  right   as can be seen  both the use of
landmarks and iterated search lead to significant improvements in performance  even with just one
of those two features our planner performs notably better than any of its competitors from ipc      
 note however that the baseline planner performed very badly in cyber security due to problems
with reading very large task descriptions   in combination  the benefits of landmarks and iterated
search grow further  in cost unaware search the use of landmarks results in   additional score points
for the first solutions  but in   additional points for the final solutions  similar results hold for the
cost sensitive configurations  this is mainly due to the openstacks domain  where using landmarks
is highly detrimental to solution quality for the first solutions  iterated search mitigates the problem
by improving quality to similar levels with and without landmarks  overall  there is thus a slight
synergy effect between landmarks and iterated search  making the joint benefit of the two features
larger than the sum of their individual contributions  the effect of landmarks in the openstacks
domain is discussed in more detail later 
the use of cost sensitive search did not pay off in our experiments  cost unaware search is
always at least roughly equal  and often substantially better than the cost sensitive configurations 
cost sensitive planning seems to be not only a problem for lama  but also for the other participating planners at ipc       notably  all cost sensitive competitors of lama fare worse than the
cost ignoring baseline  in lama  best performance is achieved by using cost unaware search with
landmarks and iterated search  however  using the combination of cost and distance estimates instead  fl c   leads to performance that is almost equally good  in particular  fl c is substantially
better than the pure cost search flc if iterated search is used 
a more detailed view on the same data is provided in figure    where we show the performance
over time for our six experimental configurations  a data point at     seconds  for example  shows
the score the corresponding planner would have achieved if the timeout had been     seconds  as
the top panel shows  cost sensitive search is consistently worse than cost unaware search when using
only the ff add heuristic  using landmarks  see centre panel   the two settings fl and fl c achieve
better performance than f  though fl c needs   minutes to surpass f  while fl does so within  
seconds  pure cost search  even with landmarks  flc    performs worse than f at all times  the
   

firichter   westphal

   
   

score

   
   
   
f
fc
f c

   
   
 

  

   
time  seconds 

    

   
   

score

   
   
   
f
fl
flc
fl c

   
   
 

  

   
time  seconds 

    

   
   

score

   
   
   
f
fl
flc
fl c

   
   
 

  

   
time  seconds 

    

figure    score over time using iterated search  top and centre panel  and without iterated search 
i  e   showing first solutions only  bottom panel  

   

fithe lama planner  guiding cost based anytime planning with landmarks

domain

base

c 

ff ha  

ff has  

lama

fl c

cyber security
elevators
openstacks
parc printer
peg solitaire
scanalyzer
sokoban
transport
woodworking
total

 
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

domain

f

fc

f c

fl

flc

fl c

cyber security
elevators
openstacks
parc printer
peg solitaire
scanalyzer
sokoban
transport
woodworking
total

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

  
  
  
  
  
  
  
  
  
   

table    coverage for planners scoring      points at ipc       top  and our   experimental
configurations  bottom   results of the ipc planners have been taken from the competition  fl c is
essentially the same as the ipc planner lama 

bottom panel of figure   shows that when not using iterated search  the performance of the   best
configurations fl  f  fl c   and flc is fairly similar eventually  but the cost sensitive approaches
need more time than the cost unaware configurations to reach the same performance levels 
      coverage
the bad performance of cost sensitive search is surprising  given that our performance criterion
awards higher scores to cheaper plans  one explanation could be that this is mainly due to different coverage  if finding plans of high quality is substantially harder than finding plans of low
quality  then focusing on nearest goals rather than cheapest goals may solve more tasks within a
given time limit  in table   we show the coverage for all considered planners and configurations 
the numbers confirm that when not using landmarks  the coverage of cost unaware search is indeed
substantially higher than the coverage of cost sensitive search  however  with landmarks  the differences in coverage between the various cost approaches are small  in particular  landmarks do not
improve coverage further for the cost unaware search  but bring the cost sensitive configurations up
   

firichter   westphal

domain
cyber security
elevators
openstacks
parc printer
peg solitaire
scanalyzer
sokoban
transport
woodworking
total

domain
cyber security
elevators
openstacks
parc printer
peg solitaire
scanalyzer
sokoban
transport
woodworking
total

fc   f
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

fc   f
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

f c   f
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

f c   f
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

flc   fc
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

flc   fc
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

fl c   f c
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

fl c   f c
tasks c  ratio
  
  
  
  
  
  
  
  
  
   

    
    
    
    
    
    
    
    
    
    

table    average ratio of the first solution costs  top  and best solution costs after iterative search
 bottom  for various pairs of configurations on their commonly solved tasks 
to the same coverage level as the cost unaware search  landmarks thus seem to be very helpful in
overcoming the coverage problems of cost sensitive search 
as mentioned before  the landmark heuristic by itself is however not competitive  using only
the landmark heuristic and not the ff add heuristic results in ipc      performance scores between
    and     with iterated search  and coverage points between     and     for the three possible
cost settings  this is substantially worse then the performance scores greater than     and coverage
points greater than     achieved by any of the other lama configurations 
      quality
as a next step  we look purely at solution quality  firstly  we want to answer the question whether
the improvement in coverage achieved by landmarks in the cost sensitive search comes at a price
in solution quality  i  e   whether using landmarks directs the search to close goals rather than cheap
goals  secondly  we would like to know how the solution quality differs between the cost sensitive
and the cost unaware configurations  in particular  how much quality do we lose by combining
   

fithe lama planner  guiding cost based anytime planning with landmarks

distance and cost estimates  x c   as opposed to using pure cost search  xc    the score used at ipc
     and in table   incorporates both coverage and quality information by counting unsolved tasks
as    a method that allows ranking several planners solving different subsets of the total benchmark
set  when we are interested in examining quality independent of coverage  we must restrict our focus on those tasks solved by all compared planners  table   contains quality information comparing
the solution costs of several configurations  where we compare configurations pair wise in order
to maximise the number of commonly solved tasks  the top part of table   contains comparisons
involving the first solutions found by each configuration  while the bottom part of the table concerns
the best solutions found after iterative search  for each pair of configurations we show the number
of tasks solved by both  and the geometric mean of the cost ratio for the plans they find 
as expected  the cost sensitive configurations fc and f c find cheaper plans than the costunaware configuration f on average  where in particular the pure cost search fc finds high quality
first plans  see the first column in the top part of the table   for both fc and f c   however  the difference to f is not very large  in some domains  most notably in elevators  the plans found by the
cost sensitive heuristics are actually worse than the plans found by cost unaware search 
landmarks deteriorate quality for the first plans of fc   but f c   which starts out with a worse
quality than fc   is not noticeably further deteriorated by landmarks  for both configurations  however  the main negative impact through landmarks is in the openstacks domain  where plans become
nearly twice as expensive for fc   and     more expensive for f c   by contrast  in the remaining
  domains average plan quality for both configurations with landmarks is even slightly better on
average than without landmarks 
we note that iterative search has a remarkable impact on the relative performance of the different configurations  when looking at the solutions found after iterative search  fc actually performs
worse than f c   whereas it is the other way round for the first solutions  compare the first two
columns in the top row versus the bottom row of the table   this can be explained to some extent
by the fact that the same reasons that cause fc to have low coverage also prevent it from improving much over time  as we will show in selected domains later  the cost sensitive heuristic often
expands many more nodes than the cost unaware search  leading to the observed behaviour  this is
most likely due to the fact that finding plans of high quality is hard and thus unsuccessful in many
of the benchmark tasks  for example  in some domains cost sensitive search leads to large local
minima that do not exist for cost unaware search  more generally  good plans are often longer than
bad plans  which may lead to increased complexity in particular in domains where the heuristic
values are inaccurate  we will showcase the problems of cost sensitive search in more detail in the
elevators and parc printer domains later on 
with iterative search  landmarks do not deteriorate quality for either fc nor f c on average  as
the negative impact of the openstacks domain is no longer present   this effect in the openstacks
domain will be discussed in more detail later  
summarising our findings  we can say that landmarks effectively support the cost sensitive
ff add heuristic in finding solutions  without steering the search away from good solutions  similarly  combining distance and cost estimates as in x c leads the search to finding solutions quickly
without overly sacrificing quality  as is demonstrated by its superior anytime performance compared
to pure cost search 
by way of example  we now present detailed results for four of the nine competition domains 
we choose domains that we deem to be of particular interest because the results in them either exaggerate or contradict the general trends discussed so far  the domains elevators and parc printer
   

firichter   westphal

 
 
 
 
 
 
 
 
 
figure    an example elevators task 

highlight the problems of cost sensitive search  in cyber security cost sensitive search performs
uncharacteristically well  and openstacks is a domain where landmarks do not lead to the usual
improvement  but rather to a deterioration of performance 
    elevators
the elevators domain models the transportation of passengers in a building via fast and slow elevators  where each elevator has a certain passenger capacity and can access certain floors  passengers
may have to change elevators to get to their final destination  and furthermore the two different types
of elevators have different associated cost functions  this is in contrast to the miconic domain  used
in an earlier international planning competition  bacchus         which also models the transporting of passengers via elevators  but where there is only one elevator that can access all floors with
just one  unit cost  operator  in elevators  the floors in the building are grouped into blocks  overlapping by one floor  slow elevators only operate within a block and can access all floors within
their block  fast elevators can access all blocks  but only certain floors within each block  in the
first    ipc tasks every second floor  and in the other    tasks every fourth floor   fast elevators are
usually more expensive than slow elevators except for a distance of two floors  where both elevator
types cost the same  however  fast elevators may sometimes be advantageous when transporting
passengers between blocks  as they avoid the need for passengers to switch elevators on the shared
floor between blocks   and they usually have a higher capacity 
an example task with eight floors  grouped into two blocks  is shown in figure    there are a
total of four elevators  two slow ones and two fast ones  the cost function used in the    ipc tasks
for moving an elevator from its current location to a target floor is     n for slow elevators and      n
for fast elevators  where n is the distance travelled  the number of floors between the current location
of the elevator and its target   operators concerning passengers boarding and leaving elevators are
free of cost  assuming this cost function  it is cheaper in this example to transport the passenger
located at floor   using the two slow elevators  changing at floor    than using a direct fast elevator 
elevators is one of the domains where configurations using the cost sensitive ff add heuristic
solve far fewer problems than their cost unaware counterparts  using landmarks increases coverage 
but does not solve the problem completely  furthermore  it is notable that on the problems that the
cost sensitive configurations do solve  their solutions often have worse quality than the solutions of
the cost unaware configurations  table   illustrates this fact for the first solutions found when using
   

fithe lama planner  guiding cost based anytime planning with landmarks

task
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
avg 

quality  ipc score 
f
fc
f c
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    
         
    

f
  
  
  
  
  
  
  
  
  
  
  
  
  
   
  
  

length
fc
  
  
  
  
  
  
  
  
  
  
  
  
   
   
  
  

f c
  
  
  
  
  
  
  
  
  
  
  
  
  
   
  
  

table    comparison of plan qualities  measured via the ipc scores  and plan lengths for the first
solutions of f  fc   and f c in elevators  shown are all tasks solved by all three configurations  with
bold print indicating the best solution 

only the ff add heuristic  with iterative search  not shown   the solution quality for f c improves to
a similar level as that of f  whereas fc remains substantially worse 
while we do not have a full explanation for why the configurations involving the cost sensitive
ff add heuristic perform so badly in this domain  several factors seem to play a role  firstly  in its
attempt to optimise costs  the cost sensitive ff add heuristic focuses on relatively complex solutions
involving mainly slow elevators and many transfers of passengers between elevators  where the
relaxed plans are less accurate  i  e   translate less well to actual plans   than in the case for the
cost unaware heuristic  secondly  the costs associated with the movements of elevators dominate
the heuristic values  causing local minima for the cost sensitive heuristic  thirdly  the capacity
constraints associated with elevators may lead to plateaus and bad quality plans in particular for the
cost sensitive heuristic  in the following sections  we describe each of these factors in some detail 
lastly  we found that the deferred heuristic evaluation technique used in lama  see section      did not perform well in this domain  when not using deferred evaluation  the fc configuration solves   additional tasks  though the quality of solutions remains worse than with the f
configuration   this partly explains why the ff ha   planner by keyder and geffner        has a
substantially higher coverage than our fc configuration in this domain  while the two planners use
the same heuristic  they differ in several aspects  apart from deferred evaluation these aspects include the search algorithm used  greedy best first search vs  enhanced hill climbing  and the method
for using preferred operators  maintaining additional queues for preferred states vs  pruning all nonpreferred successor states  
   

firichter   westphal

f
fc
f c

slow moves
   
   
   

fast moves
  
  
  

ratio fast slow
    
     
     

table    total elevator moves and ratio of fast slow moves in the first solutions found by the f  fc  
and f c configurations  on the    elevators instances solved by all three configurations 
      slow vs  fast elevators
when examining the results  we found that the fc and f c configurations tend to produce plans
where slow elevators are used for most or all of the passengers  while the f configuration uses
fast elevators more often  cf  table     this is not surprising  as for each individual passenger 
travelling from their starting point to their destination tends to be cheaper in a slow elevator  unless
the distance is very short   whereas fewer operators are typically required when travelling in a fast
elevator  the independence assumptions inherent in the ff add heuristic  see section    lead to
constructing relaxed plans that aim to optimise the transportation of each passenger individually 
rather than taking synergy effects into account 
the plans produced by fc and f c are also longer  on average  than the plans produced by f  see
table     one reason for this being that the predominant use of slow elevators requires passengers
to change between elevators more often  as plans become longer and involve more passengers
travelling in each of the slow elevators  heuristic estimates may become worse  for example  the
relaxed plans extracted for computation of the heuristic are likely to abstract away more details if
more passengers travel in the same elevator  e  g   since once a passenger has been picked up from
or delivered to a certain location  the elevator may teleport back to this location with no extra
cost in a relaxed plan to pick up or deliver subsequent passengers   generally  we found that the
relaxed plans for the initial state produced by fc and f c tend to be similar in length and cost to those
produced by f  but the final solutions produced by fc and f c are worse than those of f  one reason
for this is probably that the increased complexity of planning for more passenger change overs
between elevators in combination with worse relaxed plans poses a problem to the cost sensitive
ff add heuristic 
      local minima due to elevator movement costs
since action costs model distances  the total cost of a relaxed plan depends on the target floors
relative to the current position of an elevator  for both fc and f c   the action costs of moving the
elevator usually dominate the estimates of the ff add heuristic  consider the two example tasks in
figure    which differ only in the initial state of the elevators  the elevators need to travel to all
three floors in a solution plan  but due to abstracted delete effects a relaxed plan for the initial state
will only include operators that travel to the two floors other than the starting floor of the elevator
 i  e   the elevator can be teleported back to its starting floor without cost   in the left task  the
relaxed cost of visiting all three floors is lower than in the right task  as the cost is in the left task is
the sum of going from floor   to floor    and going from floor   to floor    resulting in a total cost
of               in the right task  the relaxed cost for visiting all floors is the cost of going from
floor   to floor    and from floor   to floor    resulting in a total cost of               in the left
task  once the passenger has boarded the elevator on floor    all immediate successor states have a
   

fithe lama planner  guiding cost based anytime planning with landmarks

action cost

action cost

 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 

figure    action cost effects in elevators in a relaxed setting  travelling   floors costs     while
travelling   floors costs     both tasks have the same solution cost       but the left task has a lower
relaxed cost      than the right task      

worse heuristic estimate due to the movement costs of the elevator  in particular  the correct action
of moving the elevator up to floor    to deliver the passenger  results in a state of worse heuristic
value  if we increased the number of waiting passengers at floor    the planning system would
therefore try boarding all possible subsets of passengers before moving the elevator  and even once
the elevator is moved up to floor    the heuristic estimate will only improve after the passenger has
been dropped off and either  a  the elevator has moved back to floor    or  b  the second passenger
has boarded and the elevator has moved down to floor   
consequently  movement costs may dominate any progress obtained by transporting passengers
for a number of successive states  in other words  the planner often has to blindly achieve some
progress and move the elevators towards a middle position given the remaining target floors  in
order for the cost sensitive heuristic to report progress  for the cost unaware heuristic  the situation
is less severe  as the number of elevator movements in the relaxed plan does not increase  and
hence the planner encounters a plateau in the search space rather than a local minimum  the use of
preferred operators may help to escape from the plateau relatively quickly  whereas a local minimum
is much harder to escape from  two approaches exist that may circumvent this problem  firstly 
the use of enforced hill climbing  hoffmann   nebel        rather than greedy best first search
is likely to avoid exploration of the entire local minima  in this approach  a breadth first search
is conducted from the first state of a minima plateau until an improving state is found  secondly 
an improved heuristic could be used that approximates the optimal relaxed cost h  more exactly 
the cost minima shown in figure   is brought about by the independence assumptions inherent in
the ff add heuristic  which estimate the relaxed cost for each goal fact individually in the cheapest
possible way  an optimal relaxed plan  however  costs the same in the left task as in the right task  a
more accurate approximation of the optimal relaxed cost h  could therefore mitigate the described
cost minima  keyder and geffner        have recently proposed such an improvement of the ff add
heuristic  and shown it to be particularly useful in the elevators and parc printer domains 
   in keyder   geffners approach  the relaxed plan extracted by the ff add heuristic is improved by iteratively    
selecting a fact f      fixing all operators that are not related to f  because they do not contribute to achieving f nor
rely on its achievement   and     computing a cheaper way of achieving f given the operators that were fixed in the
previous step 

   

firichter   westphal

      plateaus due to capacity constraints
in general  the relaxed plans in the elevators domain are often of bad quality  one of the reasons is
the way the capacity of elevators is encoded in the operators for passengers boarding and leaving
elevators  for any passenger p transported in an elevator e  one of the preconditions for p leaving e
is that n passengers be boarded in e  where n is a number greater than    when constructing a relaxed
plan  the ff add heuristic recursively selects operators that achieve each necessary precondition in
the cheapest way  this results in boarding the passenger that is closest to e in the initial state  even
if this passenger p  is different from p  to achieve the condition that some passenger is boarded 
the relaxed plan will then contain operators for both boarding p and p  into e  and may furthermore
contain other operators for boarding p  into whatever elevator e  is deemed best for transporting p   
hence  the relaxed plans often contain many unnecessary boarding operators 
as mentioned in section      the greedy best first search in lama breaks ties between equally
promising operators by trying the cheaper operator first  consequently  the zero cost operators for
passengers boarding and leaving elevators are tried first in any state  we found that as soon as one
passenger is boarded into a certain elevator  the relaxed plans in the next state are often substantially
different  in that more passengers are being assigned to that same elevator  this can be explained
by the fact that as soon as one passenger is in an elevator  the precondition for leaving that elevator
which is having at least one person boarded  is fulfilled  rather than incurring additional cost   in
some example tasks we examined  we found that this effect results in committing to bad boarding
operators  lama may initially try some bad boarding operator  e  g  boarding the nearest passenger
into an elevator to satisfy a capacity precondition for another passenger  as described above  the
relaxed plan in the successor state then assigns more passengers to this elevator  at lower cost  due
to the improved heuristic value of the successor state  lama retains this plan prefix  even though
the first operator was a bad one  it is plausible  though we did not explore it experimentally  that
this effect is stronger for the configurations involving the cost sensitive heuristic  as the costs of
their relaxed plans vary more strongly from one state to the next 
more importantly  the capacity constraints lead to plateaus in the search space  as correct boarding and leaving operators are often not recognised as good operators  for example  if the capacity of
an elevator is c  then boarding the first c    passengers that need to be transported with this elevator
usually leads to improved heuristic values  however  boarding the c th passenger does not result in
a state of better heuristic value if there are any further passengers that need to be transported via
the same elevator  because the c th passenger boarding destroys the precondition that there must be
room in the elevator for other passengers to board  similarly  the correct leaving of a passenger may
not lead to an improved heuristic value if it makes the elevator empty and other passengers need to
be transported with that elevator later  because the last passenger leaving destroys the precondition
for leaving that there must be at least one passenger boarded  
these effects exist for both the cost sensitive and the cost unaware heuristic  however  they
typically occur within the plateaus  f  or local minima  fc   f c   created by the elevator positions 
as described in the previous section  which means they affect the cost sensitive configurations more
severely  the plateaus become particularly large when several passengers are waiting on the same
floor  e  g  when passengers are accumulating on the floor shared by two blocks in order to switch
elevators  the planner then tries to board all possible subsets of people into all available elevators  as
the zero cost boarding and leaving operators are always tried first   moving the elevators and even
dropping off passengers at other floors  and may still fail to find a state of better heuristic value 
   

fithe lama planner  guiding cost based anytime planning with landmarks

first plans
final plans

fc
f c
fc
f c

solved
  
  
  
  

original tasks
qual    f qual    f
 
  
 
  
 
  
 
 

no capacity constraints
solved qual    f qual    f
  
  
 
  
  
 
  
 
  
  
  
  

table    relative qualities of solutions in the original elevators domain and in a modified variant of
the domain where elevators have unlimited capacity  shown is the total number of tasks solved by
the cost sensitive configurations fc and f c   as well as the number of tasks where these configurations find a better worse plan than the cost unaware configuration f 
when examining the number of states in local minima for each of the configurations  we found that
fc and f c indeed encounter many more such states than f  for example  the percentage of cases in
which a state is worse than the best known state is typically around      in rare cases      for f 
for fc and f c   on the other hand  the numbers are usually more than      often more than     
and in large problems even up to     
to verify that the capacity constraints indeed contribute to the bad performance of the costsensitive heuristic in this domain  we removed these constraints from the ipc tasks and ran the
resulting problems with the f  fc and f c configurations  not surprisingly  the tasks become much
easier to solve  as elevators can now transport all passengers at once  more interestingly though 
the bad plan qualities produced by the cost sensitive configurations  relative to the cost unaware
configuration  indeed become much less frequent  as table   shows 
in summary  our findings suggest that the bad performance of the cost sensitive ff add heuristic
in the elevators domain is due to bad quality relaxed plans  brought about by the focus on slow
elevators and the capacity constraints  and plateaus and local minima in the search space  resulting
from the movement costs of elevators and the capacity constraints  
    parc printer
the parc printer domain  do  ruml    zhou        models the operation of a multi engine printer
capable of processing several printing jobs at a time  each sheet that must be printed needs to pass
through several printer components starting in a feeder and then travelling through transporters 
printing engines and possibly inverters before ending up in a finishing tray  the various sheets
belonging to a print job must arrive in the correct order at the same finisher tray  but may travel
along different paths using various printing engines  there are colour printing engines and ones that
print in black and white  where colour printing is more expensive  the action costs of operators
are comparatively large  ranging from      to more than          colour printing is the most
expensive operator  while operators for printing in black and white cost roughly half as much  and
operators for transporting sheets are relatively cheap 
like in the elevators domain  the cost sensitive ff add heuristic did not perform well here 
with fc and f c failing to solve many of the tasks that the cost unaware configuration f is able to
solve   note that fc and f c perform very similarly in this domain  as the large action costs outweigh the distance estimates in f c    however  in contrast to the elevators domain  the fc and f c
configurations result in notably improved plan quality compared to f  an overview of the number
   

firichter   westphal

tasks solved out of   
avg  quality of first solution
avg  quality of final solution

f
  
    
    

f c
  
    
    

fl
  
    
    

fl c
  
    
    

table    coverage vs  quality in the parc printer domain  average qualities are average ipc scores
calculated only on those tasks solved by all configurations 

of problems solved and the average quality of first solutions is shown in table    when using landmarks  the differences between cost sensitive and cost unaware configurations are strongly reduced 
with all three landmark configurations achieving a better performance than the f configuration 
like in elevators  we found the quality of relaxed plans to be poor  in the cost unaware case 
a relaxed plan transports sheets from a feeder to the finishing tray via a shortest path  irrespective
of whether a suitable printing engine lies on this path  as any path from feeder to finishing tray
passes through some printing engine  this frequently involves printing a wrong image on a paper 
while additional operators in the relaxed plan handle the transportation from a feeder to a suitable
printing engine to print the correct image on the sheet as well  when the cost sensitive heuristic is
used  relaxed plans furthermore become substantially longer  using many transportation operators
to reach a cheap printing engine  analogously to the elevators domain  the increased complexity
associated with longer plans  in combination with the bad quality of the relaxed plans  is thus
likely to be the reason for the bad performance of the cost sensitive heuristic  however  landmarks
mitigate the problem  as the numbers of solved tasks in table   clearly show  landmarks found
in this domain encompass those for printing a correct image on each sheet  where a disjunctive
landmark denotes the possible printers for each sheet  this helps to counteract the tendencies of the
cost sensitive ff add heuristic to transport sheets to the wrong printers 
in summary  parc printer is like elevators a domain where the cost sensitive ff add heuristic
performs badly  though in contrast to elevators the problem here is purely one of coverage  not of solution quality  even more than in elevators  landmarks overcome the problems of the cost sensitive
configurations  improving them to a similar performance levels as the cost unaware configurations 
    cyber security
the cyber security domain stands out as a domain where the cost sensitive configurations perform
significantly better than their cost unaware counterparts  especially when looking at first solutions 
 iterative search reduces the gap  but does not close it completely   the domain models the vulnerabilities of computer networks to insider attacks  boddy  gohde  haigh    harp         the task
consists in gaining access to sensitive information by using various malware programs or physically
accessing computers in offices  action costs model the likelihood of the attack to fail  i  e   the risk
of being exposed  for example  many actions in the office of the attacker  like using the computer 
do not involve any cost  whereas entering other offices is moderately costly  and directly instructing
people to install specific software has a very high associated cost  in particular  action costs are used
to model the desire of finding different methods of attack for the same setting  for example  several
tasks in the domain differ only in the costs they associate with certain operators 
in the cyber security domain  taking action costs into account pays off notably  while the fc and
f c configurations solve   and   problems less  respectively  than the f configuration  see table    
   

fithe lama planner  guiding cost based anytime planning with landmarks

ipc score for first solutions
ipc score for final solutions

f
     
     

fl
     
     

f c
     
     

fl c
     
     

table    ipc scores in the cyber security domain 

they nevertheless result in a better total score  using landmarks  both cost sensitive configurations
are improved such that they solve all problems while maintaining the high quality of solutions 
resulting in an even larger performance gap between flc        points  and fl c        points  on
the one side  and fl        points  on the other side 
the plans found by the cost unaware search often involve physically accessing computers in
other offices or sending viruses by email  and as such result in large cost  lower costs can be
achieved by more complex plans making sophisticated use of software  as opposed to the elevators
and parc printer domains  the relaxed plans in cyber security are of very good quality  this
explains why the performance of the cost sensitive heuristic is not negatively impacted by longer
plans  using iterative search improves the performance of fl and f to nearly the same levels as
their cost sensitive counterparts  see table    
    openstacks
the openstacks domain models the combinatorial optimisation problem minimum maximum simultaneous open stacks  fink   vo        gerevini  haslum  long  saetti    dimopoulos        
where the task is to minimise the storage space needed in a manufacturing facility  the manufacturer receives a number of orders  each comprising a number of products  only one product can be
made at a time  and the manufacturer will always produce the total required quantity of a product
 over all orders  before beginning the production of a different product  from the time the first product in an order has been produced to the time when all products in the order have been produced 
the order is said to be open and requires a stack  a temporary storage space   the problem consists
in ordering the products such that the maximum number of stacks open at any time is minimised 
while it is easy to find a solution for this problem  any product order is a solution  requiring n
stacks in the worst case where n is the number of orders   finding an optimal solution is np hard 
the minimisation aspect is modelled in the planning tasks via action costs  in that only the operator
for opening new stacks has a cost of    while all other operators have zero cost  this domain was
previously used at ipc       gerevini et al          while that earlier formulation of the domain
has unit costs  it is equivalent to the cost formulation described above  since the number of operators that do not open stacks is the same in every plan for a given task  minimising plan length is
equivalent to minimising action costs 
we noticed that in this domain using landmarks resulted in plans of substantially worse quality 
compared to not using landmarks  in particular  this is true for the first plans found  whereas the
use of anytime search improves the results for both configurations to similar levels  across all cost
settings  using the landmark heuristic in combination with the ff add heuristic typically produces
plans where the majority of orders is started very early  resulting in a large number of simultaneously open stacks  whereas using only the ff add heuristic leads to plans in which the products
corresponding to open orders are manufactured earlier  and the starting of new orders is delayed
until earlier orders have been shipped  this is mainly due to the fact that no landmarks are found by
   

firichter   westphal

    
    

f c
fl c

expanded nodes

    
    
    
    
    
    
    
   
 
 

  

  
tasks

  

  

  

figure    number of expanded search nodes with and without landmarks in the first search iteration
 best first search  in the openstacks domain 

lama regarding the opening of stacks  which means that due to the choice of action costs in this
domain  all landmarks have cost zero and the landmark heuristic is not able to distinguish between
plans of different cost  the landmarks found by lama relate to the starting and shipping of orders
as well as the making of products   however  even if landmarks regarding the opening of stacks
were found  they would not be helpful  landmarks state that certain things must be achieved  not
that certain things need not be achieved  landmarks can thus not be used to limit the number of
open stacks  the landmark orderings are furthermore not helpful for deciding an order between
products  as all product orders are possiblewhich means that no natural orderings exist between
the corresponding landmarksand no product order results in the form of wasted effort captured
by reasonable landmark orderings 
as mentioned above  all landmarks found by lama have a minimal cost of zero  therefore 
the landmark heuristic fails to estimate the cost to the goal  and distinguishes states only via the
number of missing started or shipped orders and products   these goal distance estimates are used
directly in fl  combined with the all zero landmark heuristic cost estimates in fl c   and as tiebreakers amongst the zero cost estimates in flc   resulting in the same relative ranking of states by
the landmark heuristic in all three cases   as soon as one stack is open  for each order o the operator
that starts o achieves a landmark that is minimal with respect to landmark orderings  namely the
landmark stating that o must be started   and the planner thus tends to start orders as soon as possible 
the landmark heuristic is not able to take into account future costs that arise through bad product
orderings  this is also a problem for the ff add heuristic  albeit a less severe one  the ff add
heuristic accounts for the cost of opening  exactly  one new stack whenever at least one more stack
is needed  and the heuristic will thus prefer states that do not require any further stacks 
the landmark heuristic does  however  provide a good estimate of the goal distance  since
the landmark heuristic prefers states closer to a goal state with no regard for costs  its use results
   if the size of disjunctions were not limited in lama  it would always find a landmark stacks avail    
stacks avail         stacks avail n  stating that at least one of the n stacks must be open at some point  however  any landmark stating that two or more stacks need to be open would require a more complex form of landmarks
involving conjunction  which lama cannot handle 

   

fithe lama planner  guiding cost based anytime planning with landmarks

 

plan quality

   

   

   

   

 

f c
fl c
 

  

  
tasks

  

  

  

figure     plan quality  measured via the ipc scores  with and without landmarks in the first search
iteration  best first search  in the openstacks domain 

 
  
  
  
  
cost   
  
  
  
  
 
    

plan quality

   
   
   
   
 

f c
fl c

   
time  seconds 
 

  

  
tasks

  

  

    

 

  
  
  
   tasks
  

  

figure     effect of iterative search in the openstacks domain  left  plan quality  ipc score  of the
best plan found within    minutes with and without landmarks  right  evolution of plan costs with
landmarks  fl c   over time 
in plans where stacks are opened as needed  this is reflected in our empirical results  where the
additional use of the landmark heuristic drastically reduces the number of expanded search nodes
 see figure     but leads to higher cost plans  see figure      without iterative search  the lama
configuration fl c only achieves       points for this domain  compared to       points when not
using landmarks  configuration f c   
using iterative search  the negative effect of the landmarks on quality is mitigated  as can be
seen in figure     fl c generates up to    distinct  and each time improved  plans per problem  in
the end  the difference in points is merely       for fl c vs        for f c   this score is reached
after less than   minutes of iterated search per task 
thus  openstacks is an example for a domain where landmarks are detrimental to solution
quality  however  using landmarks provides the benefit of speeding up planning by reducing the
   

firichter   westphal

number of expanded nodes  this allows iterative search to effectively improve solution quality in
the given time limit such that the final results of using landmarks are similar to those of not using
landmarks 
    domains from previous competitions
tables   and    show results on the ipc domains from previous years             as these domains do not contain action costs  the cost sensitive configurations of lama are not applicable and
lama runs with the fl configuration  the configurations examined for lama are thus fl and
f  both with iterated search and without  where fl with iterated search is shown as lama  also
given are the results for two ipc winning systems of previous years  ff and fast downward  for
both ff and fast downward  we ran current versions  in particular fast downward has evolved
substantially since its      competition version  the original causal graph heuristic having been
replaced with the better context enhanced additive heuristic  helmert   geffner         after correspondence with the authors  the version of fast downward used here is the one featuring in recent
work by richter and helmert        
as table   shows  lama performs better than both ff and fast downward in terms of the
ipc      criterion  this is true even if we turn off landmarks or iterated search in lama  but
not if we turn off both options simultaneously  when viewing the large difference between the
scores of iterated versus non iterated search in lama  note that on these domains no best known
reference results were used in the score calculation  in contrast to the      tasks  for most of which
such reference results were generated manually or with domain specific solvers by the competition
organisers   this means that the planner producing the best solution for a task is awarded the
highest possible score of    even though better solutions might exist  this may skew results in favour
of the planner that delivers cheaper solutions  i  e   exaggerate the differences between planners 
table    shows that lamas edge over fast downward is due to higher quality solutions rather
than coverage  as fast downward solves more problems  compared to ff  lama has better coverage  with the gap between lama and ff being substantially larger than the gap between lama
and fast downward  note that the f and lama configurations roughly correspond to the results
published as base and heur in earlier work  richter et al          however  subsequent changes
to the code to support action costs negatively affect in particular the philosophers domain  where
we observe a significant decrease in coverage  this is also one of the reasons for the difference in
coverage between lama and the closely related fast downward system 
comparing the various experimental configurations for lama  we note that the use of landmarks leads to moderate improvements in both coverage and solution quality  as mentioned above 
iterative search significantly improves performance in terms of the ipc      score 

   conclusion and outlook
in this article  we have given a detailed account of the lama planning system  the system uses
two heuristic functions in a multi heuristic state space search  a cost sensitive version of the ff
heuristic  and a landmark heuristic guiding the search towards states where many subgoals have
already been achieved  action costs are employed by the heuristic functions to guide the search
to cheap goals rather than close goals  and iterative search improves solution quality while time
remains 
   

fithe lama planner  guiding cost based anytime planning with landmarks

domain

ff

f  downw 

lama

f

flfirst

ffirst

airport     
assembly     
blocks     
depot     
driverlog     
freecell     
grid    
gripper     
logistics          
logistics          
miconic      
miconic full adl      
miconic simple adl      
movie     
mprime     
mystery     
openstacks     
optical telegraphs     
pathways     
philosophers     
pipesworld notank      
pipesworld tank      
psr small     
rovers     
satellite     
schedule      
storage     
tpp     
trucks     
zenotravel     
total       
psr large     
psr middle     

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
    



  
  
  
  
  
  
 
  
  
  
   
  
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

table    performance scores  rounded to whole numbers  for ff  fast downward and lama as
well as experimental alternative configurations of lama  f  without landmarks  flfirst   without
iterated search  ffirst   without landmarks and without iterated search  

   

firichter   westphal

domain

ff

f  downw 

lama

f

airport     
assembly     
blocks     
depot     
driverlog     
freecell     
grid    
gripper     
logistics          
logistics          
miconic      
miconic full adl      
miconic simple adl      
movie     
mprime     
mystery     
openstacks     
optical telegraphs     
pathways     
philosophers     
pipesworld notank      
pipesworld tank      
psr small     
rovers     
satellite     
schedule      
storage     
tpp     
trucks     
zenotravel     
total       
psr large     
psr middle     

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
  
  
  
  
  
  
  
  
   
  
  
  
  
    



  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

  
  
  
  
  
  
 
  
  
  
   
   
   
  
  
  
  
 
  
  
  
  
  
  
  
   
  
  
  
  
    
  
  

table     coverage  problems solved  for ff  fast downward and lama as well as the experimental f configuration of lama without landmarks 

   

fithe lama planner  guiding cost based anytime planning with landmarks

we have conducted an extensive experimental study on the set of benchmark tasks from the
last international planning competition  in order to identify how much each of the features of our
planner contributes to its performance in the setting of planning with action costs  we discussed
overall results and provided plausible explanations for deviating behaviour in some special cases 
the most noticeable outcome of our experiments is that using cost sensitive heuristics did not
produce the desired outcome  in particular  the cost sensitive ff add heuristic performs significantly
worse than the ff add heuristic that ignores costs  this is due to the cost sensitive heuristic solving
far fewer tasks while leading to little improvement in solution quality on the tasks that it does solve 
especially when using iterated search  when investigating the reasons for this effect  we found that
the cost sensitive ff add heuristic reacts strongly to bad relaxed plans  i  e   it is in particular in
those domains where the relaxed plans computed by the heuristic have low quality that the costsensitive heuristic is likely to perform worse than the cost unaware heuristic  as we showed for the
elevators domain  action costs may also introduce local minima into the search space where without
action costs the search space of the ff add heuristic would have plateaus  moreover  the increased
complexity of planning for a cheaper goal that is potentially further away from the initial state may
lead to worse performance 
landmarks prove to be very helpful in this context  as they mitigate the problems of the costsensitive ff add heuristic  using landmarks  the coverage of cost sensitive search is improved to
nearly the same level as that of cost unaware search  while not deteriorating solution quality  despite
the mitigating effect of landmarks  however  lama would still have achieved a slightly higher
score at ipc      if it had simply ignored costs  rather than using cost sensitive heuristics  for
cost unaware search  we found landmarks to improve coverage and solution quality in the domains
from the ipcs           on the domains from ipc       landmarks improved solution quality
for the cost unaware search  but did not further increase the  already very high  coverage 
iterative search improves results notably for all of our experimental configurations  raising the
score of lama by a quarter on the ipc      domains  in the openstacks domain  we could
furthermore observe a synergy effect between the iterative search and landmarks  while landmarks
usually improve quality  in this domain they lead to bad plans by not accounting for action costs 
however  they speed up planning so that the planner evaluates substantially fewer states  iterative
search then effectively improves on the initial bad plans while benefiting from the speed up provided
by the landmarks  in general  we can use landmarks as a means to quickly find good solutions  while
using iterative search as a way to improve plan quality over time  overall  we found that the domains
used at ipc      constitute a varied benchmark set that reveals various strengths and weaknesses
in our planning system 
building on the results presented in this article  we identify several directions for future work 
firstly  our results suggest that more research into cost sensitive heuristics is needed  we would
like to conduct a more thorough analysis of the short comings of the cost sensitive ff add heuristic  to answer the question whether and how they might be overcome  keyder and geffner       
propose a method for extracting better relaxed plans from the best supports computed by the costsensitive ff add heuristic  resulting in improved coverage  however  the large ledge of the costunaware heuristic in our experiments suggests that the cost unaware ff add heuristic is still better than the improved cost sensitive heuristic by keyder and geffner  it would be interesting to
examine to what degree the problems we experienced with the ff add heuristic extend to other
delete relaxation heuristics  and whether heuristics not based on the delete relaxation could be more
effectively adapted to action costs  in addition  future work could explore the benefit of combin   

firichter   westphal

ing traditional distance estimators and cost sensitive heuristics in more sophisticated ways than the
mechanism currently used in lama  see the discussion in section        
secondly  we believe it to be useful for future research to improve the definition of reasonable
orderings  eliminating the problems of the definition by hoffmann et al  mentioned in section     
thirdly  we would like to extend the use of landmarks in our system in several ways  for one  our
current approach does not take into account whether the same landmark must be achieved several
times  supporting such multiple occurrences of landmarks would be beneficial in the openstacks
domain  for example  as it could help to minimise the creation of stacks by accounting for their
costs  while methods exist for detecting the multiplicity of landmarks  porteous   cresswell       
zhu   givan         it will be crucial to develop techniques for deriving orderings between the
individual occurrences of such landmarks  furthermore  we would like to extend lama to support
more complex landmarks like conjunctions or other simple formulas  in addition to representing
and using such landmarks in the landmark heuristic this involves the development of new methods
for detecting them along with their corresponding orderings 

acknowledgments
the authors thank malte helmert  charles gretton  sylvie thiebaux and patrik haslum as well as
the anonymous reviewers for helpful feedback on earlier drafts of this paper 
the computing resources for our experiments were graciously provided by pompeu fabra university  we thank hector palacios for his support in conducting the experiments 
nicta is funded by the australian government  as represented by the department of broadband  communications and the digital economy  and the australian research council  through the
ict centre of excellence program 
this work was partially supported by deutsche forschungsgemeinschaft as part of the transregional collaborative research center sfb tr   spatial cognition  project r   logospace  

references
aine  s   chakrabarti  p  p     kumar  r          awa   a window constrained anytime heuristic search algorithm  in veloso  m  m   ed    proceedings of the   th international joint
conference on artificial intelligence  ijcai        pp           
bacchus  f          the aips   planning competition  ai magazine              
backstrom  c     nebel  b          complexity results for sas  planning  computational intelligence                
boddy  m   gohde  j   haigh  t     harp  s          course of action generation for cyber security
using classical planning  in biundo  s   myers  k     rajan  k   eds    proceedings of the
fifteenth international conference on automated planning and scheduling  icaps       
pp        aaai press 
bonet  b     geffner  h          planning as heuristic search  artificial intelligence              
bryce  d     kambhampati  s          a tutorial on planning graph based reachability heuristics 
ai magazine              
   

fithe lama planner  guiding cost based anytime planning with landmarks

buffet  o     hoffmann  j          all that glitters is not gold  using landmarks for reward shaping
in fpg  in proceedings of the icaps      workshop on planning and scheduling under
uncertainty 
chen  y   wah  b  w     hsu  c  w          temporal planning using subgoal partitioning and
resolution in sgplan  journal of artificial intelligence research             
cheng  j     irani  k  b          ordering problem subgoals  in sridharan  n  s   ed    proceedings
of the   th international joint conference on artificial intelligence  ijcai        pp     
     morgan kaufmann 
do  m  b     kambhampati  s          sapa  a scalable multi objective heuristic metric temporal
planner  journal of artificial intelligence research             
do  m  b   ruml  w     zhou  r          on line planning and scheduling  an application to controlling modular printers  in proceedings of the twenty third aaai conference on artificial
intelligence  aaai        pp            aaai press 
edelkamp  s     hoffmann  j          pddl     the language for the classical part of the  th
international planning competition  tech  rep       albert ludwigs universitat freiburg 
institut fur informatik 
fink  a     vo  s          applications of modern heuristic search methods to pattern sequencing
problems  computers and operations research              
fox  m     long  d          pddl     an extension to pddl for expressing temporal planning
domains  journal of artificial intelligence research            
fuentetaja  r   borrajo  d     linares lopez  c          a unified view of cost based heuristics  in
icaps      workshop on heuristics for domain independent planning  pp       
gerevini  a   haslum  p   long  d   saetti  a     dimopoulos  y          deterministic planning
in the fifth international planning competition  pddl  and experimental evaluation of the
planners  artificial intelligence                  
gerevini  a     serina  i          lpg  a planner based on local search for planning graphs with
action costs  in ghallab  m   hertzberg  j     traverso  p   eds    proceedings of the sixth
international conference on artificial intelligence planning and scheduling  aips        pp 
      aaai press 
gregory  p   cresswell  s   long  d     porteous  j          on the extraction of disjunctive landmarks from planning problems via symmetry reduction  in proceedings of the fourth international workshop on symmetry and constraint satisfaction problems  pp       
hansen  e  a     zhou  r          anytime heuristic search  journal of artificial intelligence
research             
hansen  e  a   zilberstein  s     danilchenko  v  a          anytime heuristic search  first results 
technical report cmpsci        university of massachusetts  amherst 
helmert  m          the fast downward planning system  journal of artificial intelligence research             
helmert  m          concise finite domain representations for pddl planning tasks  artificial
intelligence              
   

firichter   westphal

helmert  m   do  m     refanidis  i          ipc       deterministic part  web site  http   ipc 
informatik uni freiburg de 
helmert  m     geffner  h          unifying the causal graph and additive heuristics  in rintanen 
j   nebel  b   beck  j  c     hansen  e   eds    proceedings of the eighteenth international
conference on automated planning and scheduling  icaps        pp          aaai press 
hoffmann  j     nebel  b          the ff planning system  fast plan generation through heuristic
search  journal of artificial intelligence research             
hoffmann  j   porteous  j     sebastia  l          ordered landmarks in planning  journal of
artificial intelligence research             
irani  k  b     cheng  j          subgoal ordering and goal augmentation for heuristic problem
solving  in mcdermott  j  p   ed    proceedings of the   th international joint conference
on artificial intelligence  ijcai        pp            morgan kaufmann 
jonsson  p     backstrom  c          state variable planning under structural restrictions  algorithms and complexity  artificial intelligence                  
karpas  e     domshlak  c          cost optimal planning with landmarks  in proceedings of the
  st international joint conference on artificial intelligence  ijcai        pp           
keyder  e     geffner  h          heuristics for planning with action costs revisited  in proceedings
of the   th european conference on artificial intelligence  ecai        pp         
keyder  e     geffner  h          trees of shortest paths vs  steiner trees  understanding and improving delete relaxation heuristics  in proceedings of the   st international joint conference
on artificial intelligence  ijcai        pp           
keyder  e   richter  s     helmert  m          sound and complete landmarks for and or graphs 
in coelho  h   studer  r     wooldridge  m   eds    proceedings of the   th european conference on artificial intelligence  ecai        pp         
koehler  j     hoffmann  j          on reasonable and forced goal orderings and their use in an
agenda driven planning algorithm  journal of artificial intelligence research             
likhachev  m   ferguson  d   gordon  g  j   stentz  a     thrun  s          anytime search in
dynamic graphs  artificial intelligence                    
likhachev  m   gordon  g  j     thrun  s          ara   anytime a  with provable bounds
on sub optimality  in thrun  s   saul  l  k     scholkopf  b   eds    advances in neural
information processing systems     nips       
lipovetzky  n     geffner  h          inference and decomposition in planning using causal consistent chains  in gerevini  a   howe  a   cesta  a     refanidis  i   eds    proceedings of the
nineteenth international conference on automated planning and scheduling  icaps       
aaai press 
liu  y   koenig  s     furcy  d          speeding up the calculation of heuristics for heuristic
search based planning  in proceedings of the eighteenth national conference on artificial
intelligence  aaai        pp          aaai press 
pohl  i          heuristic search viewed as path finding in a graph  artificial intelligence        
    
   

fithe lama planner  guiding cost based anytime planning with landmarks

porteous  j     cresswell  s          extending landmarks analysis to reason about resources and
repetition  in proceedings of the   st workshop of the uk planning and scheduling special
interest group  plansig      pp       
porteous  j   sebastia  l     hoffmann  j          on the extraction  ordering  and usage of landmarks in planning  in cesta  a     borrajo  d   eds    pre proceedings of the sixth european
conference on planning  ecp        pp        toledo  spain 
richter  s     helmert  m          preferred operators and deferred evaluation in satisficing planning  in gerevini  a   howe  a   cesta  a     refanidis  i   eds    proceedings of the nineteenth international conference on automated planning and scheduling  icaps        pp 
        aaai press 
richter  s   helmert  m     westphal  m          landmarks revisited  in proceedings of the
twenty third aaai conference on artificial intelligence  aaai        pp          aaai
press 
richter  s   thayer  j  t     ruml  w          the joy of forgetting  faster anytime search via
restarting  in brafman  r   geffner  h   hoffmann  j     kautz  h   eds    proceedings of the
twentieth international conference on automated planning and scheduling  icaps       
aaai press  to appear 
roger  g     helmert  m          the more  the merrier  combining heuristic estimators for satisficing planning  in brafman  r   geffner  h   hoffmann  j     kautz  h   eds    proceedings
of the twentieth international conference on automated planning and scheduling  icaps
       pp          aaai press 
ruml  w     do  m  b          best first utility guided search  in veloso  m  m   ed    proceedings
of the   th international joint conference on artificial intelligence  ijcai        pp      
     
sebastia  l   onaindia  e     marzal  e          decomposition of planning problems  ai communications              
vidal  v          a lookahead strategy for heuristic search planning  in zilberstein  s   koehler  j  
  koenig  s   eds    proceedings of the fourteenth international conference on automated
planning and scheduling  icaps        pp          aaai press 
zhou  r     hansen  e  a          beam stack search  integrating backtracking with beam search 
in biundo  s   myers  k     rajan  k   eds    proceedings of the fifteenth international
conference on automated planning and scheduling  icaps        pp        aaai press 
zhu  l     givan  r          landmark extraction via planning graph propagation  in icaps     
doctoral consortium  pp         

   

fi