journal artificial intelligence research                 

submitted        published      

intrusion detection using continuous time bayesian networks
jing xu
christian r  shelton

jingxu   cs   ucr   edu
cshelton   cs   ucr   edu

department computer science engineering
university california  riverside
riverside  ca        usa

abstract
intrusion detection systems  idss  fall two high level categories  network based systems
 nids  monitor network behaviors  host based systems  hids  monitor system calls 
work  present general technique systems  use anomaly detection 
identifies patterns conforming historic norm  types systems  rates change
vary dramatically time  due burstiness  components  due service difference  
efficiently model systems  use continuous time bayesian networks  ctbns  avoid
specifying fixed update interval common discrete time models  build generative models
normal training data  abnormal behaviors flagged based likelihood
norm  nids  construct hierarchical ctbn model network packet traces
use rao blackwellized particle filtering learn parameters  illustrate power
method experiments detecting real worms identifying hosts two publicly
available network traces  mawi dataset lbnl dataset  hids  develop novel
learning method deal finite resolution system log file time stamps  without losing
benefits continuous time model  demonstrate method detecting intrusions
darpa      bsm dataset 

   introduction
misuse abuse computer systems critical issue system administrators  goal
detect attacks attempt compromise performance quality particular host machine 
time consuming error prone acquire labeled data contains good bad
behaviors build classifier  additionally  frequency attacks developed make maintaining database previously seen attacks inefficient even infeasible 
anomaly detection identify new attacks even attack type unknown beforehand  unsupervised learning allows anomaly detector adapt changing environments  thereby extending
domain usefulness  modeling normal behavior historic clean data  identify
abnormal activity without direct prior model attack simply comparing deviation
learned norm 
network based intrusion detection system  nids   network packet traces monitored 
network traffic traces collect information networks data stream provide external
view network behavior  host based intrusion detection system  hids   internal state
computing system analyzed  system call logs convenient way monitoring executing
programs behavior operating system calls 
systems composed activities happen dramatically different time granularity 
users alternate busily using computer resting  busy period  burst
action may cause peak network traffic flow operating system usage  however 
c
    
ai access foundation  rights reserved 

fix u   helton

resting period  computer maintains regular running pattern  network system activities much less intense  e g  automatically checking email every minutes  even within
global modes variations  therefore  dynamic model requires discretizing
time efficient  develop intrusion detection techniques using continuous time bayesian
networks  ctbns   nodelman  shelton    koller        data types  although two
data completely different formats semantic meaning  demonstrate flexibility
continuous time generative model  such ctbn  describe either 
first effort detect anomalies network traffic traces  nids   abnormal traffic must
differ way normal traffic patterns  difference may subtle
difficult detect  subtle attack  longer attack take
stress patience attacker  looking summarized information flow statistics
helpful  especially stealthy worms mingle well normal traffic sacrificing
spreading speed scale  we  therefore  feel looking abnormalities detailed network
traffic flow level utile method finding attacks  network flow given host machine
sequence continuous time asynchronous events  furthermore  events form complex
structured system  statistical dependencies relate network activities packet emissions
connections  employ ctbns reason structured stochastic network processes 
ctbn model contains number observed network events  packet emissions concurrent port connections changes   allow model descriptive  add latent
variables tie activity variables together  exact inference method longer feasible 
therefore  use rao blackwellized particle filtering  rbpf  estimate parameters 
second effort detect intrusions using system call logs  hids   system log file contains ordered list calls made computers operating system executing program 
focus analyzing ordering context sequence  rather simply counting
overall statistics  ctbn natural way modeling sequential data  finite
resolution computer clock  system calls issued within clock tick assigned
time stamp  therefore data stream consists long periods time activity  followed
sequences calls order correctly recorded  exact timing information lost 
poses new challenge ctbn reasoning  present learning method type
data without resorting time discretization 
validate nids technique mawi dataset lbnl dataset  hids
technique darpa      bsm dataset  applications give good results compared
method 
section   discuss related work intrusion detection  section   review continuoustime markov processes continuous time bayesian networks  section   describe ctbn
model rbpf inference algorithms nids problem  section   describe
ctbn model parameter estimation algorithm hids  including deal imprecise timing measurements  section   show experimental results applications 

   related work
much previous work intrusion detection focuses one area either detecting
network traffic mining system call logs  work eskin  arnold  prerau  portnoy 
stolfo        similar approach apply method kinds
   

fii ntrusion etection using ctbn

data  map data elements feature space detect anomalies determining points
lie sparse regions using cluster based estimation  k nearest neighbors one class svm 
use data dependent normalization feature map network traffic data spectrum kernel
system call traces 
    nids
network traffic data  build upon previous work  xu   shelton         made
assumption network activities independent across different ports  allowed us
factorize model port level submodels standard exact inference techniques could used
parameter learning  paper  remove restriction  application specific
reason traffic independent ports  tying traffic together  model describes
complicated structural dependencies among variables  derive rao blackwellized particle
filtering algorithm estimate parameters model  work differs
interested intrusion detection problem  host identity recognition well 
signature based detection algorithm  share many assumptions karagiannis 
papagiannaki  faloutsos         particular  assume access
internals machines networks  rules methods malan
smith         cha         qin lee         eskin et al          however  differ
approach rely preset values  require human intervention interpretation 
assume access network wide traffic information  network wide data human
intervention advantages  lead difficulties  data collation face
attack increased human effort   chose leave solution 
many learning  adaptive  methods proposed network data 
example  zuev moore        soule  salamatian  taft  emilion  papagiannali        approach problem classification task requires labeled data  dewaele 
fukuda  borgnat        profile statistical characteristics anomalies using random projection techniques  sketches  reduce data dimensionality multi resolution non gaussian
marginal distribution extract anomalies different aggregation levels  goal papers
usually detect attacks rather classify non attacks traffic type  applied attack
detection  would risk missing new types attacks  furthermore  frequently treat
network activity separately  instead considering temporal context 
lakhina  crovella  diot        nice summary adaptive  or statistical  methods
look anomaly detection  instead classification   use entropy based method
entire network traffic  many methods  ye  emran  chen  vilbert
        use either statistical tests subspace methods assume features connections
packets distributed normally  rieck laskov        model language features
n grams words connection payloads  xu  zhang  bhattacharyya        use
unsupervised methods  concentrate clustering traffic across whole network  similarly 
soule  salamatian  taft        build anomaly detector based markov models 
network traffic patterns whole function host level 
work soule et al         similar statistical flavor work 
fit distribution  in case  histogram modeled dirichlet distribution  network data 
however  model flow level statistics  whereas work level individual connections 
additionally  attempting network wide clustering flows instead anomaly detection 
   

fix u   helton

work moore zuev         approach  models traffic graphical models 
particular  naive bayes networks  goal categorize network traffic instead detecting
attacks  kruegel  mutz  robertson  valeur        present bayesian approach detecting
problem event classification task care whether host attack
interval 
work lazarevic  ertoz  kumar  ozgur  srivastava        similar work 
one papers attempt find attacks host level  employ nearest neighbor 
mahalanobis distance approach  density based local outliers method  using    features
connections  although methods make standard i i d  assumption data
 and therefore miss temporal context connection  use    features  compared
features   compare results section    closest prior work  agosta 
duik wasser  chandrashekar  livadas        present adaptive detector whose threshold
time varying  similar work rely model based algorithms 
employ host internal states cpu loads available us 
great variety previous work  work novel detects
anomalies host level using timing features network activities  consider
connection  or packet  isolation  rather complex context  capture statistical
dynamic dependencies packets connections find sequences network traffic
anomalous group 
    hids
previous work detecting intrusions system call logs roughly grouped two categories  sequence based feature based  sequence based methods focus sequential order
events feature based methods treat system calls independent data elements 
method belongs former category since use ctbn model dynamics sequences 
time delay embedding  tide  sequence time delay embedding  stide  two examples
sequence based methods  forrest  a hofmeyr  somayaji    a longstaff        a hofmeyr  forrest    somayaji         generalize data building database storing previously seen
system call sub sequences  test looking subsequences database  methods
straightforward often achieve good results  compare experiments  tandon
chan        look richer set attributes return value arguments associated
system call make use system call names 
feature based methods hu  liao  vemuri        use dataset use 
darpa      bsm dataset  training data noisy try find classification
hyperplane using robust support vector machines  rsvms  separate normal system call profiles
intrusive ones  eskin        works noisy data  make assumption
training data contains large portion normal elements anomalies  present mixture
distribution normal abnormal data calculate likelihood change data point
moved normal part abnormal part get optimum data partition 
yeung ding        try use techniques  provide dynamic static behavioral models system call data  dynamic method  hidden markov model  hmm 
used model normal system events likelihood calculated testing sequence
compared certain threshold  work system call traces problem close
   

fii ntrusion etection using ctbn

framework since build dynamic model sequential data compute
likelihood testing example score  different ctbn models continuous time dynamics rather time sliced behaviors  static method  represent
normal behavior command occurrence frequency distribution measure distance
testing example norm cross entropy  dataset use kdd archive dataset 
    work
simma et al         use continuous time model reason network traffic  apply
method find dependences exterprise level services  model non markovian 
deals network events basic observational unit 
estimate parameters large network build network traffic data  use
rao blackwellized particle filters  rbpfs   doucet  de freitas  murphy  russel        propose
rbpf algorithm dynamic bayesian networks works discrete time fashion exploiting
structure dbn  ng  pfeffer  dearden        extend rbpf continuous time dynamic systems apply method k   experimental mars rover nasa ames research
center  model hybrid system containing discrete continuous variables 
use particle filters discrete variables unscented filters continuous variables 
work similar apply rbpf ctbn  model contains discrete
variables evidence continuous time  as opposed snapshots system
state  

   continuous time bayesian networks
begin briefly reviewing definition markov processes continuous time bayesian
networks  ctbns  
    homogeneous markov process
finite state  continuous time  homogeneous markov process xt described initial distribution px  and  given state space v al x     x         xn    n n matrix transition intensities 



qx  


qx 
q x  x 
  
 

q x  x 
qx 
  
 

q xn x 

q xn x 

      q x  xn
      q x  xn
  
  
 
 
      qxn




 


p
qxi xj intensity  or rate  transition state xi state xj qxi   j  i qxi xj  
transient behavior xt described follows  variable x stays state x time
exponentially distributed parameter qx   probability density function f xt remaining
x duration fx  q  t    qx exp qx t     expected time next transition
given state currently x   qx   upon transitioning  x shifts state x  probability
xx    qxx   qx   note given qx   xx  qxx  iosmorphic  sometime gives formulae
terms xx  simplifies expression 
distribution state process x future time t  px  t   computed
directly qx   px  distribution x time    represented vector   then  letting
   

fix u   helton

exp matrix exponential 
px  t    px  exp qx t   
    complete data
complete data hmp represented set trajectories           n    trajectory
complete set state transitions      xd   td   x d     meaning x stayed state xd
duration td   transitioned state x d   therefore know exact state variable
x time    
    sufficient statistics likelihood
given hmp full data d  likelihood single state transition     xd   td   x d   

lx  q    d     qxd exp qxd td    xd x d    
likelihood function decomposed transition 


lx  q    d     
lx  q   d   
lx     d  
dd

dd


 x x   
    qxm  x  exp qx  x    
xx 
  
x x    x

x

take log function  get log likelihood 
lx  q    d    lx  q   d    lx     d 
x
x
 
 m  x  ln qx   qx  x   
 x  x    ln xx      
x    x

x

 x  x   


 x  sufficient statistics hmp
model   x  x    number
p
times x transitions state x x    denote  x    x   x  x     total number
times system leaves state x   x  total duration x stays state x 
    learning complete data
estimate parameters transition intensity matrix q  maximize log likelihood function  yields maximum likelihood estimates 
qx  

 x 
 
 x 

xx   

 x  x   
 
 x 

    incomplete data
incomplete data hmp composed partially observed trajectories           n   
trajectory consists set     sd   td   dt   observations  sd subsystem  a
nonempty subset states x  process  triplets specifies interval
evidence  states variable x subsystem sd time td time td   dt 
observations may duration free  i e   observe x sd time t  know
long stayed there  called point evidence generalized using triplet
notation described setting duration    partially observed trajectory 
observe sequences subsystems  observe state transitions within subsystems 
   

fii ntrusion etection using ctbn

    expected sufficient statistics expected likelihood
consider possible completions partially observed trajectory specify transitions
consistent partial trajectory  combining partial trajectory completion 
get full trajectory  define d               n    completions partial trajectories
d  given model  distriubtion d    given d 
data d    expected sufficient statistics respect probability density possible completions data  x    x  x     x   expected log likelihood
e lx  q    d       e lx  q   d       e lx     d    
x
x
 m  x  ln qx   qx  x   
 
 x  x    ln xx      
x    x

x

    learning incomplete data
expectation maximization  em  algorithm used find local maximum likelihood
partial trajectory  em algorithm iterates following e step step
convergence derived likelihood function 
e step  given current hmp parameters  compute expected sufficient statistics   x  
 x  x     x  data set d  complex part algorithm  give
details below 
step  computed expected sufficient statistics  update new model parameters
next em iteration 
 x  x   
 x 
  xx   
 
qx  
 x 
 x 
show calculate expected sufficient statistics using forward backward
message passing method 
trajectory devided n intervals interval separated
adjacent event changes  assume trajectory spans time interval        let  v  w 
observed evidence time v w  including events time stamp v w  let
 v  w  set evidence excluding v w  let subsystem states
restricted interval 
define
  p  xt       t      p    t      xt  
vectors  indexed possible assignments xt    similarly  define corresponding
distribution excludes certain point evidence follows 
  p  xt       t   

t    p    t      xt    

denote j vector  s except j th position    denote ij matrix
 s except element i th row j th column   
able show derived expected sufficient statistics  time 
z
e t  x    
p  xt         x dt
 
n
  z ti  
x
 
 
p  xt         x dt  
p         
ti
i  

   

fix u   helton

constant fraction beginning last line serves make total expected time
j sum   integral interval expressed
z

w

z

w

v exp qs  t v  xx exp qs  w t  w dt  

p  xt         x dt  
v

v

qs qx except elements correspond transitions set
  
equation expected transition counts similarly defined 
n  

e m  x  x      

x
qx x 
 
 
ti x x  t i
p         
i  
n
  z ti  
x
 
ti exp qs  t ti   x x  exp qs  ti   t  ti   dt   
i  

ti

integrals appearing e t   e m   computed via standard ode solver 
runge kutta method  press  teukolsky  vetterling    flannery         method uses
adaptive step size move quickly times expected changes slowly
times rapid transitions 
remaining problem calculate   let qss  transitioning intensity
matrix hmp one subsystem another     matrix qx  
elements corresponding transitions   non zero 
ti   ti  exp qsi   ti ti      
ti   ti qsi  si  
ti   exp qsi  ti   ti   ti    
ti   qsi  si ti  
forward backward calculation  trivial answer queries
p  xt   x           

 
xx  
p    

    continuous time bayesian networks
hmps good modeling many dynamic systems  limitations
systems multiple components state space grows exponentially number
variables  hmp model variable independencies therefore use unified
state x represent joint behavior involving components system 
section  show continuous time bayesian network used address issue 
nodelman et al         extend theory hmps present continuous time bayesian networks  ctbns   model joint dynamics several local variables allowing transition
model local variable x markov process whose parametrization depends
subset variables u  
   

fii ntrusion etection using ctbn

    definition
first give definition inhomogeneous markov process called conditional markov process  critical concept us formally introduce ctbn framework 
definition    nodelman  shelton    koller        conditional markov process x inhomogeneous markov process whose intensity matrix varies function current values set
discrete conditioning variables u   parametrized using conditional intensity matrix  cim 
qx u set homogeneous intensity matrices qx u   one instantiation values u u  
call u parents x  set u empty  cim simply standard intensity
matrix 
cims provide way model temporal behavior one variable conditioned
variables  putting local models together  joint structured model continuous
time bayesian network 
definition    nodelman et al         continuous time bayesian network n set stochastic processes x consists two components  initial distribution px    specified bayesian
network b set random variables x  continuous transition model  specified using
directed  possibly cyclic  graph g whose nodes x x  ux denotes parents x g 
variable x x associated conditional intensity matrix  qx ux  
dynamics ctbn quantitatively defined graph  instantaneous evolution
variable depends current value parents graph  quantitative description
variables dynamics given set intensity matrices  one value parents 
means transition behavior variable controlled current values parents 
standard notion d separation bayesian networks carries ctbns 
graphs cyclic variables represent processes  not single random variables   implications
little different  variable  process  still independent non descendants given parents 
still independent everything given markov blanket  any variable either parent 
child  parent child   cycles cause parents children  provided
considered both  definitions still hold  importantly  notion given works
full trajectory variable question known  therefore  x grandchildren
independent given xs childrens values single instant  rather  independent
given xs childrens full trajectories time   last time interest 
amalgamate variables ctbn together  get single homogeneous markov
process joint state space  joint state intensity matrix  rate   assigned
transition involves changing one variables value exact time 
intensities found looking value corresponding conditional intensity matrix
variable changes  diagonal elements negative row sums 
forward sampling done quickly ctbn without generating full joint intensity
matrix  keep track next event time variable  sampled relevant exponential distribution given current values parent   select earliest
event time change variable  sampling multinomial distribution implied row
variables relevant intensity matrix   next event time variable changed
children must resampled  variables time must resampled due
memoriless property exponential distribution  way sequence events  a trajectory 
sampled 
   

fix u   helton

     learning
context ctbns  model parameters consist ctbn structure g  initial distribution p  parameterized regular bayesian network  conditional intensity matrices  cims 
variable network  section  assume ctbn structure known us 
focus parameter learning  assume model irreducible  initial
distribution p  becomes less important context ctbn inference learning  especially
time range becomes significantly large  therefore  parameter learning context
estimate conditional intensity matrices qxi  ui variable xi   ui set
parent variables xi  
       l earning c omplete data
nodelman et al         presented efficient way learn ctbn model fully observed
trajectories  complete data  know full instantiations variables whole
trajectory  know cim governing transition dynamics variable
time  sufficient statistics  x  x   u  number times x transitions state x
x  given parent instantiation u  x u  p
total duration x stays state x
given parent instantiation u  denote  x u    x   x  x   u  
likelihood function decomposed

ln  q    d   
lxi  qxi  ui   d lxi  xi  ui   d  
   
xi x


lx  qx u   d   

yy
u

 x u 

qx u

exp qx u  x u  

   

x


lx     d   

yy
u


 
xx
   u  x  x  u   

   

x x    x

put functions together take log  get log likelihood component
single variable x 
lx  q    d    lx  q   d    lx     d 
xx
 
 x u  ln qx  u  q x u   x u 
u

 

x

xx x
u

 x  x   u  ln xx   u    

   

x x    x

maximizing log likelihood function  model parameters estimated
qx u  

 x u 
 
 x u 

xx   u  

   

 x  x   u 
 
 x u 

   

fii ntrusion etection using ctbn

       l earning ncomplete data
nodelman  shelton  koller        present expectation maximization  em  algorithm
learn ctbn model partially observed trajectories d  expected sufficient statistics
 x  x   u   expected number times x transitions state x x  parent set
u takes values u   x u   expected p
amount time x stays state x
parent instantiation u  denote  x u  x   x  x   u   expected log likelihood
decomposed way equation    except sufficient statistics  x  x   u    x u 
 x u  replaced expected sufficient statistics  x  x   u    x u   x u  
em algorithm ctbn works essentially way hmp  expectation step calculate expected sufficient statistics using inference method  will described
section        maximization step update model parameters 

qx u  

 x u 
 
 x u 

xx   u  

 x  x   u 
 
 x u 

     inference
given ctbn model  partially  observed data  would query model 
example  may wish calculate expected sufficient statistics em algorithm 
       e xact nference
nodelman et al         provide exact inference algorithm using expectation maximization
reason learn parameters partially observed data  exact inference algorithm requires flattening variables single markov process performing inference
hmp  problem makes state space grow exponentially large  therefore  exact
inference method feasible problems small state spaces 
       pproximate nference
issue addressed below  much work done ctbn approximate inference  nodelman  koller  shelton        present expectation propagation algorithm  saria 
nodelman  koller        give another message passing algorithm adapts time granularity  cohn  el hay  friedman  kupferman        provide mean field variational approach 
el hay  friedman  kupferman        show gibbs sampling method approach using monte
carlo expectation maximization  fan shelton        give another sampling based approach
uses importance sampling  el hay  cohn  friedman  kupferman        describe different expectation propagation approach 
estimate parameters models build two applications  nids hids  
employ inference algorithms including exact inference rao blackwellized particle filtering
 rbpf  algorithm  depending model size  ng et al         extended rbpf ctbns 
model hybrid system containing discrete continuous variable  used particle
filters discrete variables unscented filters continuous variable  work
similar work method applying rbpf ctbns  model contains discrete
variables evidence continuous intervals 
   

fix u   helton

port
  
    
   
   
    
   
     
     

description
world wide web http
http alternate
http protocol tls ssl
authentication service
talarian tcp
pop  protocol tls ssl
unknown
unknown

port
  
   
   
   
    
    
    
   

description
world wide wed http
netbios session service
http protocol tls ssl
microsoft ds
msnp
gadget gate   way
at c license manager
post office protocol   version  

figure    ranking frequent ports mawi dataset  left  lbnl dataset  right  

     ctbn applications
although inference learning algorithms well developed ctbns 
applications real world problems  nodelman horvitz        used ctbns
reason users presence availability time  ng et al         used ctbns monitor
mobile robot  nodelman et al         used ctbns model life event history  fan shelton
       modeled social networks via ctbns  previous work  xu   shelton        presented
nids host machine using ctbns  include hids 

   anomaly detection using network traffic
section  present algorithm detect anomalies network traffic data using ctbns 
focus single host network  sequence timing events  e g  packet
transimission connection establishment  important network traffic flow  matters
many connections initiated past minute  timing 
evenly spaced trace probably normal  came quick burst suspicious 
similarly  sequence important  connections made sequentially increasing ports
likely scanning virus  whereas set ports random order likely
normal traffic  merely simple examples  would detect complex
patterns 
typical machine network may diverse activities various service types  e g 
http  smtp   destination port number roughly describes type service particular network activity belongs  worms propagate malicious traffic toward certain well known
ports affect quality associated services  looking traffic associated different
ports sensitive subtle variations appear aggregate trace information
across ports  figure   shows popular ports ranked frequencies network
traffic datasets use  described depth later   services are  extent 
independent other  therefore model ports traffic ctbn submodel 
denote whole observed traffic sequences particular host  j traffic
associated port j 
   

fii ntrusion etection using ctbn

g

n
h

pin

pout

cinc

cdec

figure    ctbn model network traffic plate model  n number port  

    ctbn model network traffic
use port level submodel previous work  xu   shelton         latent
variable h four fully observed toggle variables  pin   pout   cinc   cdec  
nodes packet in  pin   packet out  pout   represent transmission packet
host  intrinsic state  transmission packet essentially instantaneous
event  therefore events  or transitions  without state  modeled using
toggle variable event evidence change state variable rate
transition associated state required same 
nodes connection increase cin connection decrease cdec together describe status
number concurrent connections c active host  notice c increase
decrease one given event  the beginning ending time connection   assume
arrival new connection termination existing connection independent
number connections  thus intensity connection starts  or stops 
connections  therefore  modeled toggle variables 
node h   states represent different abstract attributes machines internal state 
toggle variables  pin   pout   cinc cdec   allowed change   states
h required rate states    hidden states per toggle
variable chosen balance expressive power model efficiency 
previous work  assumed traffic associated different ports independent
other  port level submodels isolated  remove restriction introducing
another latent variable g ties port submodels together  full model shown figure   
    parameter learning using rbpf
calculate expected sufficient statistics e step em parameter learning  exact
inference algorithm nodelman et al         flattens variables joint intensity matrix
reasons resulting homogeneous markov process  time complexity exponential
number variables  example    port models  network contains    variables
total  approximate inference techniques clique tree algorithm  nodelman et al         
message passing algorithms  nodelman et al         saria et al          importance sampling  fan
   

fix u   helton

  shelton        gibbs sampling  el hay et al         overcome problem sacrificing
accuracy 
notice model nice tree structure makes rao blackwellized particle
filtering  rbpf  perfect fit  rbpf uses particle filter sample portion variables
analytically integrates rest  decomposes model structure efficiently thus reduces
sampling space 
denote n port level hidden variables h         hn   posterior
distribution
qn
whole model factorized p  g  h         hn       p  g     i   p  hi   g     note
g hi processes  probability density complete trajectories  use
particle filter estimate gs conditional distribution p  g     set sampled trajectories
g  difficult sample directly posterior distribution  use importance sampler
sample particle proposal distribution particles weighted ratio
likelihood posterior distribution likelihood proposal distribution  doucet
et al          since variable g latent parents  use forward sampling
sample particles p  g  weight particle simply likelihood
conditioned trajectory g  fan   shelton         port level submodel dseparated rest network  given full trajectory g  see section     d separation
ctbns   since small  only   hidden states   marginalized exactly 
is  calculate p  i   g   where portion trajectory submodel i  exactly 
marginalizing hi   recursions section     
expected sufficient statistics  ess  variable x ctbn tx u  x u   expected amount time x stays state x given parent instantiation u  mx u  x  x   u  
expected number transitions state x x  given xs parent instantiation u  let g p  g  
 
             particles  define likelihood weights wi   pp g g 
  let
p
w   wi sum weights  general importance sampling allows expected
sufficient statistic estimated following way  ss sufficient statistic 

e g h       hn  p  g h       hn      ss g  h            hn   
  egp  g    eh       hn p  h       hn  g     ss g  h            hn   
  x
wi eh       hn p  h       hn  gi      ss g   h            hn     

w


expected sufficient statistics whole model two categories  depend
g  ess g   depend port model k  ess g  hk   k    ess g  simply
summation counts  the amount time g stays state  number times g
transitions one state another  particles  weighted particle weights 

egp  g     ss g  

  x
wi ss g    
w


   

   

fii ntrusion etection using ctbn

function wholemodel estep
input  current model   evidence
output  expected sufficient statistics ess
ess     ess g   ess s    g           ess sn   g  
initialize ess empty
particle g  g             g    g p  g 
sj  s            sn  
 p  j  g    ess sj   g      submodel estep g    sj    j  
sj  s            sn  
q
ess sj   g    ess sj   g    k  j p  k  g   ess sj   g  
i 
essgi   countgss gq
ess g    ess g    j p  j  g   essgi
return ess

figure    rao blackwellized particle filtering estep whole model
ess g  hk   k   calculated submodel independently 
eg h       hn p  g h       hn      ss g  hk   k   
z
  x
wi

p  hk  g   k  ss g   hk   k   dhk
w
hk

q
z
  x j p  j  g  
p  hk  g   k  ss g   hk   k   dhk
 
w
p    
hk

z
x

 

p  j  g  
p  hk   k  g  ss g   hk   k   dhk  
w
hk


   

j  k

integrals possible trajectories hidden process hk   first line holds
d separation  we need average submodel k  given assignment g   second
line expands weight  last line combines weight term submodel k terms
integral get likelihood hk submodel data  constant proportionality
p
cancel subsequent maximization  reconstructed noting x tx u  x u 
total time
r interval 
last integral  hk p  hk   k  g  ss g   hk   k   dhk   p  j  g   calculated using
technique described nodelman et al          exact ess calculation  calculations
similar integrals section      except intensity matrices change interval
interval  they function sampled trajectory gi   
full e step algorithm shown figure    sk represents variables submodel
k   function submodel estep calculates expected sufficient statistics likelihood
subnet model  equation     function countgss counts empirical time transition statistics
sampled trajectory g  equation    
em  use ess true sufficient statistics maximize likelihood
respect parameters  regular ctbn variable x  such hidden variable g
h   equation   performs maximization  toggle variables  e g  pi   likelihood
   

fix u   helton

component toggle variable


mp

qpi  ui exp qpi  u  u   u  

u

found setting qx u value  qpi  u   x  tieing parameters 
simplifying product x equation    thus maximum likelihood parameter estimate
qpi  u  

mpi
 u   u 

mpi number events variable pi qpi  u parameter  rate
switching 
synchronize particles end window  see section      resample
normal particle filter points  is  propagate particles forward  stop
end window  resample based weights  continue new set
particles  general  particles aligned time  except resampling points 
    online testing using likelihood
ctbn model fitted historic data  detect attacks computing likelihood
window data  see section      model  likelihood falls threshold 
flag window anomalous  otherwise  mark normal 
experiments  fix window fixed time length  tw   therefore 
window interest starts time   wish calculate p   t    tw             s  t 
represents observed connections packets time time t  again  use rbpf
estimate probability  samples time represent prior distribution p  g          
propagating forward across window length tw produces set trajectories g 
g   submodel k evalute p  k  t    tw     g   exact marginalization  the sum
vector  tw   forward message   weighted average  over samples g k   product
submodel probabilities estimate p    t    tw            

   anomaly detection using system calls
turn problem detecting anomalies using system call logs 
    ctbn model system calls
system call logs monitor kernel activities machines  record detailed information
sequence system calls operating system  many malicious attacks host revealed
directly internal logs 
analyze audit log format suns solaris basic security module  bsm  praudit audit
logs  user level kernel event record least three tokens  header  subject  return 
event begins header format of  header  record length bytes  audit record version
number  event description  event description modifier  time date  subject line consists of 
subject  user audit id  effective user id  effective group id  real user id  real group id  process
id  session id  terminal id consisting device machine name  return return
value indicating success event closes record 
   

fii ntrusion etection using ctbn

h

s 

s 

sn

figure    ctbn model system call data

 

s   s        sk

ti   ti   t

ti t

ti

ti   ti   t

time

figure    system call traces finite resolution clock  resolution    
construct ctbn model similar port level network model  individual system calls
s         sn   event description fields header token  transiently observed 
happen instantaneously duration  treat toggle variables packets
network model  introduce hidden variable h parent system calls variables
allow correlations among them  hidden variable designed model internal state
machine  although semantic meaning imposed method  put together  system
call model looks figure   
state space hidden variable h size m  transition rate matrix h



qh  


qh 
q h  h 
  
 

q h  h 
qh 
  
 

q hm h 

q hm h 

      q h  hm
      q h  hm
  
  
 
 
      qhm




 


transition intensity rate toggle variable given current value parent h
qs hi             m 
estimate ctbn model parameters  use expectation maximization  em 
algorithm  expected sufficient statistics need calculate model
mhi hj   expected number times h transitions state j 
thi   expected amount time h stays state i 
ms hi   expected number times system call evoked h state i 
   

fix u   helton

maximum likelihood parameters
mhi hj
thi
ms hi
 
 
thi

q hi hj  
qs hi

    parameter estimation finite resolution clocks
finite resolution computer clocks  multiple instantaneous events  system calls 
occur within single clock tick  therefore audit logs  batch system calls may recorded
executed time point  rather real time stamp  result finite
time accuracy  however  correct order events kept logs  is  know exactly
system call s  follows s  recorded order audit logs  thus system
call timings partially observed  type partial observation previously
considered ctbn inference  typical trajectory       system call data shown
figure    batch system calls evoked time ti next clock tick 
followed quiet period arbitrary length  yet another bunch events time
ti   on 
let t  t  denote evidence interval  t   t    t  t   denote evidence  t   t   
t   t  denote evidence  t   t    define vectors
ti   p ht     ti  


t i   p t   t  ht   




ht value h prior transition ti   ht  value afterward 


define vectors
ti   p hti     t   


ti   p ti  t  hti  
evidence transition time ti included  follow forward backward algorithm
compute ti ti ti event  this  split interval  ti   ti    
spike period  ti   ti      t one resolution clock   batch
system calls  quite period  ti     ti     events exist  propagations
separately 
spike period  ti   ti      observed event sequence s    s         sk   construct
artificial markov process x following intensity matrix 




qx  



qh q   
   
 
  qh q       
 
  
  
  
  
  
 
 
 
 
 
 
 
      qh qk
 
 
   
  qh
   





 



fii ntrusion etection using ctbn





qh  


p
qh  ss qs h 
q h  h 
  
 

qh 

q hm h 

q h  h 
p
ss qs h 
  
 

   
   
  
 
      qhm

q hm h 

q h  hm
q h  hm
  
 
p
ss qs hm











qi  


qsi  h 
 
  
 
 

 
qsi  h 
  
 

   
   
  
 

 
 
  
 

 

 

qsi  hm







x tracks evidence sequence s  s      sk   qx square block matrix dimension
 k       block matrix  subsystem x k     blocks states 
first block represents state h events  second block represents h exactly
one event  s    happens  third block represents h s  followed s  happens 
on  last block represents h events finish executing order  subsystem
zero transition intensities everywhere except along sequence pass  diagonal qh
matrix qh except transition intensities system call variables
subtracted  full system includes transitions observed 
transition rates set zero  to force system agree evidence   conditioning
change diagonal elements rate matrix  nodelman et al          within
k     states block  h freely change value  therefore  non diagonal elements
qh intensities qh   upon transitioning  x transit state
another according event sequence  therefore  blocks   matrices except
immediate right diagonal blocks  transition behavior described matrix
qi   qi   intensities non diagonal entries h change simultaneously 
diagonal element qi  h  h  intensities event si happening  given current value
hidden state h 
take forward pass example describe propagation  backward pass
performed similarly  right ti   ti dimensions  expand m k      dimensions
form ti non zero probabilities first states  ti describes
distribution subsystem x  ti eqx represents probability distribution time ti    
given prefix observed sequence occurred  take last state probabilities
condition entire sequence happening  thus resulting m dimensional vector  ti  t  
quiet period  ti     ti      evidence observed  therefore ti  t propagated
ti   using qh   rate matrix conditioned h events occuring 
ti     ti  t exp qh  ti   ti     
done full forward backward pass whole trajectory  calculate expected sufficient statistics mhi hj   thi ms hi   again  refer work nodelman
et al         algorithm 
   

fix u   helton

    testing using likelihood
learned model normal process system call logs  calculate
log likelihood future process model  log likelihood compared
predefined threshold  threshold  possible anomaly indicated  single
hidden variable  calculations done exactly 

   evaluation
evaluate methodology  constructed experiments two different types data  network
traffic traces system call logs  following sections  show experiment results
tasks 
dynamic bayesian network  dbn  another popular technique graphical modeling
temporal data  slice time  events without state changes  instantaneous events 
difficult model  reasonable time resolution result multiple events
variable one time period  standard way encoding dbn  use toggle
variable  records parity number events time interval  furthermore 
nids  events bursty  active times  multiple packets emited per second 
inactive times  may activity hours  finding suitable sampling rate
maintains efficency model difficult  hids  problem acute 
know way modeling timing ambiguity dbn without throwing away timing
information adding mathematical framework essentially turns dbn ctbn
described here  general  could find suitable way apply dbn problems
without essentially turning dbn ctbn finely slicing time applying
numeric tricks speed inference amount converting stochastic matrices rate
matrices using numeric integration matrix exponential 
compared current adaptive methods problem individually  include nearest neighbor  support vector machines  sequence time delaying embedding  give
details methods below 
    experiment results network traffic
section  present experiment results nids 
      datasets
verify approach two publicly available real network traffic trace repositories  mawi
working group backbone traffic mawi lbnl icsi internal enterprise traffic lbnl 
mawi backbone traffic part wide project collected raw daily packet
header traces since       records network traffic inter pacific tunnel
japan usa  dataset uses tcpdump ip anonymizing tools record    minute
traces every day  consists mostly traffic japanese universities  experiment 
use traces january  st  th                  connections total time
one hour 
lbnl traces recorded medium sized site  emphasis characterizing internal enterprise traffic  publicly released anonymized form  lbnl data collects
   

fii ntrusion etection using ctbn

  packets flowing source destination
  packets flowing destination source
  connections source last   seconds
  connections destination last   seconds
  different services source last   seconds
  different services destination last   seconds
  connections source last     connections
  connections destination last     connections
  connections port source last     connections
  connections port destination last     connections
figure    features nearest neighbor approach work  lazarevic et al         
    hours network traces thousands internal hosts  publicly released  take
one hour traces january  th        the latest date available             total connections 
      w orm etection
start problem worm detection  split traffic traces host  half training
half testing  learn ctbn model training data hosts  since
network data available clean traffic known intrusions  inject real attack traces
testing data  particular  inject ip scanner  w   mydoom  slammer  slide
fixed time window testing traces  report single log likelihood value sliding
window  compare predefined threshold  threshold  predict
abnormal time period  define ground truth window abnormal attack
traffic exists interval  normal otherwise  window size use    seconds 
consider windows contain least one network event 
compare method employing rbpf previous factored ctbn model  xu  
shelton         connection counting  nearest neighbor  parzen window detector  yeung   chow 
       one class svm spectrum string kernel  leslie  eskin    noble        
connection counting method straightforward  score window number
initiated connections window  worms aggregate many connections short time 
method captures particular anomaly well 
make nearest neighbor competitive  try extract reasonable set features  follow
feature selection work lazarevic et al          use total    features 
features available data  available shown figure    notice
features associated connection record  apply nearest neighbor method
window based testing framework  first calculate nearest distance connection inside
window training set  which composed normal traffic only   assign maximum
among score window  similarly  parzen window approach  apply
feature set assign maximum density among connections inside window
score window 
besides feature based algorithms  would see sequence based
approaches compare methods  algorithms widely used network anomaly
detection  approach  treat traffic traces stream data sequential contexts
   

fix u   helton

 

 

   

   

   

   

   

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf   

   

 
 

    

    
    
false positive rate

    

   

   

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf   

   

 
 

   

    

    

   

   

 
 

   

 

   

   

   

   

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf   

 
 

    

    
    
false positive rate

ip scanning

    

   

   

   

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf   

   

 
 

    

    
    
false positive rate

mydoom

    

   

true positive rate

 

   

    

    
    
false positive rate

    

   

slammer

 

   

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf   

   

mydoom

true positive rate

true positive rate

lbnl

ip scanning

    
    
false positive rate

true positive rate

 

true positive rate

true positive rate

mawi

explored  one class svm spectrum string kernel chosen comparison 
implemented spectrum kernel libsvm library  chang   lin         give network
activities  such connection starting ending  packet emmision receipt  inside portlevel submodel distinct symbol  sequence symbols fed algorithm inputs 
decision surface trained normal training traffic  testing  sliding window 
distance window string decision hyperplane reported window score 
tried experiments using edit distance kernel  results dominated spectrum
kernel  report here 

   

   

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf   

   

 
 

    

    
    
false positive rate

    

   

slammer

figure    roc curves testing results ip scanning attack  mydoom attack slammer attack 
         top  mawi  bottom  lbnl 

injecting attack traffic  randomly pick starting point somewhere first half
test trace insert worm traffic duration equal times length full testing
trace  shorter is  harder detect anomaly  choose      
experiments work challenge detection tasks  scaled back rates
worms  running full speed  worm easy detect method  slows
 and thus blends background traffic better   becomes difficult detect  let
scaling rate  e g      indicates worm running one tenth normal speed  
method  set state space variable g   variable h    use
    samples particle filtering  resample particles every    seconds  svm
spectrum kernel method  choose sub sequence length   parameter     
show roc curves methods figure    curves show overall performance    active hosts dataset  point curves corresponds
   

fii ntrusion etection using ctbn

 

 

   

   
true positive rate

true positive rate

different threshold algorithm  ctbn method out performs algorithms except
single case mydoom attack background lbnl traffic  many cases 
advantages ctbn approach pronounced 
mawi data  factored non factored ctbn models perform comparably 
believe data captures connections traverse trans pacific link 
therefore  connections machine represented  makes reasoning
global pattern interaction machine difficult  lbnl data  one attack  ip
scanning  shows advantage non factored model  one attack  mydoom  shows distinct
advantage  one attack  slammer  indicates advantage  depending desired false
positive rate  demonstrate advantage jointly modeling traffic across ports 
although clear advantage uniform traffic patterns attack types 

   

   

   

   

   

   
connection count
ctbn  rbpf   

 
 

    

    
    
false positive rate

    

connection count
ctbn  rbpf   

   

 
 

    

    
    
false positive rate

    

   

figure    roc curves testing results slammer attack mawi dataset demonstrating
effect slowing attack rate  left          right         

show roc curves shift scale back worm running speed figure   
firewalls built sensitive block malicious traffic  worms act stealthy
sneak through  demonstrate robustness method compared best competitor
 connection counts  speed worms attack 
      h ost dentification
identifying individual hosts based network traffic patterns another useful application
model  instance  household usually installs network router  family members
computer connected router  outside internet  network traffic going
router behaves coming one peer  actually coming different people 
dad possibly read sports news kids surf social networks  interesting well
useful tell family member contributing current network traffic  host identification
used combat identity theft  network identity abused attacker  host
identification techniques help network administrator tell whether current network traffic
host consistent usual pattern not 
   

fix u   helton

first set experiments construct host model fitting competition    
hosts picked worm detection tasks lbnl dataset compose testing pool  learn
coupled ctbn model host  split test traces  clean  particular host
segments lengths    seconds  segments  compute log likelihood
segment learned model hosts  including own   label segment
host achieves highest value  compute confusion matrix c whose element cij
equals fraction test traces host model j highest log likelihood  expect
see highest hit rates fall diagonals ideally host best described
model  table   shows results dataset lbnl  vast majority traffic windows
assigned correct host  exception host    diagonals distinctly higher
elements row  comparison  performed experiment using svm
spectrum kernel method  again  selected sub sequence length   parameter
     tried multiple methods normalization  of distance hyperplane 
variations parameters  produced poor results almost windows assigned
single host  omit table results 
host
 
 
 
 
 
 
 
 
 
  

 
    
    
 
 
 
 
    
 
    
 

 
 
 
           
           
 
 
 
 
 
 
           
           
 
         
           
              
              

 
 
 
 
 
  
 
 
 
      
 
 
      
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                     
    
           
      
 
 
 
      
 
    
 
      
      
 
                
      
 
                
    

figure    confusion matrix lbnl host identification using ctbn
second experiment host traffic differentiation task  mingle network traffic
another host analyzed host  expect detection method successfully tell apart
two  verify idea  pick one host among    choose lbnl dataset
split traffic evenly training testing  learn model training data 
testing data  randomly choose period inject another hosts traffic worm 
goal identify period abnormal since hosts traffic longer behavior 
figure    displays results two combination tests  parameters injecting
traffic worm                  left graph  nearest neighbor parzen
window curve overlap  ctbn curves overlap  right graph  coupled ctbn curve
substantially outperforms curves 
    experiment results system call logs
section  present experiment results hids 
   

fi 

 

   

   

   
   

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf  

   
 
 

    

    
    
false positive rate

    

true positive rate

true positive rate

ntrusion etection using ctbn

nearest neighbor
connection count
parzen window
svmspectrum
ctbn  factored
ctbn  rbpf  

   
   
   
 
 

   

    

    
    
false positive rate

    

   

figure     roc curves testing results host identification lbnl data  left  host   
nearest neighbor curve parzen window curve overlap  ctbn curves overlap 
right  host   

week
 
 
 
 
 
 
 

  normal
processes
   
   
   
   
   
   
   

  attack
processes
 
 
  
   
  
  
 

system call
close
ioctl
mmap
open
fcntl
stat
access

  occurrence
      
     
     
     
    
    
    

system call
execve
chdir
chroot
unlink
chown
mkdir
chmod

  occurrence
    
    
   
  
  
 
 

figure     left  darpa bsm process summary  right  darpa bsm system call summary
      dataset
dataset used      darpa intrusion detection evaluation data set mit lincoln
laboratory  seven weeks training data contain labeled network based attacks midst
normal background data publicly available darpa website  solaris basic security
module  bsm  praudit audit data system call logs provided research analysis  follow
kang  fuller  honavar        cross index bsm logs produce labeled list file
labels individual processes  resulting statistics shown left table figure    
frequency system calls appearing dataset summarized descending order
right figure    
      nomaly etection
experimental goal detect anomalous processes  train ctbn model normal
processes test mixture normal attack processes  state space
   

fi 

 

   

   
true positive rate

true positive rate

x u   helton

   
   
ctbn
svmspectrum
stide
nearest neighbor

   
 
 

    

    
    
false positive rate

    

   
   
ctbn
svmspectrum
stide
nearest neighbor

   

    

 
 

    

    
    
false positive rate

    

    

figure     roc curves bsm data detection  left  training week   combined testing
results week      right  training week   test week    stide curve
ctbn curve overlap

hidden variable h set    log likelihood whole process learned model
represents score process  compare score predefined threshold classify
process normal one system abuse 
implement sequence time delaying embedding  stide  stide frequency threshold
 t stide  comparison  warrender  forrest    pearlmutter         two algorithms build
database previously seen normal sequences system calls compare testing sequences
it  straightforward perform well empirically system call log
datasets  choose parameter k  sequence length    h  locality frame length 
    results t stide shown following resulting graphs since overlapped
stide almost cases 
approaches compare nearest neighbor one class svm spectrum
string kernel edit distance kernel  follow hu et al         transform process
feature vector  consisting occurrence numbers system call process  nearest
distance testing process training set processes assigned score 
one class svm  processes composed strings system calls  normal processes used
learning bounding surface signed distance assigned score  set subsequence length   parameter      again  since edit distance kernel results
dominated spectrum kernel  show them 
figure    displays results two experiment settings  left graph  train
model normal processes week   test processes weeks     
right graph  train normal processes week   test processes week
   richest attack processes volume  attacks relatively rare compared normal
traffic  interested region roc curves small false positive rates 
show curves area false positive rate falls region           
ctbn method beats nearest neighbor svm spectrum kernel experiments  stide
performs slightly better method combined test  achieves accuracy
   

fii ntrusion etection using ctbn

experiment using week   testing week    advantage ctbn model
stide easily combined prior knowledge data sources  such
network data nids   demonstrate loss performance flexibility 

   conclusions
realm temporal reasoning  introduced two additions ctbn literature  first 
demonstrated rao blackwellized particle filter continuous evidence  second  demonstrated learn reason data contains imprecise timings  still refraining
discretizing time 
realm intrusion detection  demonstrated framework performs well two
related tasks different data types  concentrating purely event timing  without
consideration complex features  able out perform existing methods  continuoustime nature model aided greatly modeling bursty event sequences occur systems
logs network traffic  resort time slicing  either producing rapid slices
inefficient quite periods  lengthy slices miss timing bursty events 
combination two sources information  system calls network events  would
straight forward model produced  believe would result accurate
detection  collection data difficult  however  leave interesting next step 

acknowledgments
project supported intel research uc micro  air force office scientific
research  fa                 defense advanced research project agency  hr               

references
agosta  j  m   duik wasser  c   chandrashekar  j     livadas  c          adaptive anomaly
detector worm detection  workshop tackling computer systems problems
machine learning techniques 
a hofmeyr  s   forrest  s     somayaji  a          intrusion detection using sequences system
calls  journal computer security            
cha  b          host anomaly detection performance analysis based system call neuro fuzzy
using soundex algorithm n gram technique  systems communications  icw  
chang  c  c     lin  c  j          libsvm  library support vector machines  http   
www csie ntu edu tw cjlin libsvm 
cohn  i   el hay  t   friedman  n     kupferman  r          mean field variational approximation
continous time bayesian networks  uncertainty artificial intelligence 
dewaele  g   fukuda  k     borgnat  p          extracting hidden anomalies using sketch non
gaussian multiresulotion statistical detection procedures  acm sigcomm 
doucet  a   de freitas  n   murphy  k     russel  s          rao blackwellised particle filtering
dynamic bayesian networks  uncertainty artificial intelligence 
   

fix u   helton

el hay  t   cohn  i   friedman  n     kupferman  r          continuous time belief propagation 
proceedings twenty seventh international conference machine learning 
el hay  t   friedman  n     kupferman  r          gibbs sampling factorized continous time
markov processes  uncertainty artificial intelligence 
eskin  e          anomaly detection noisy data using learned probability distributions 
international conference machine learning 
eskin  e   arnold  a   prerau  m   portnoy  l     stolfo  s          geometric framework
unsupervised anomaly detection  detecting intrusions unlabeled data  barbara  d    
jajodia  s   eds    applications data mining computer security  kluwer 
fan  y     shelton  c  r          sampling approximate inference continuous time bayesian
networks  symposium artificial intelligence mathematics 
fan  y     shelton  c  r          learning continuous time social network dynamics  proceedings twenty fifth international conference uncertainty artificial intelligence 
forrest  s   a hofmeyr  s   somayaji  a     a longstaff  t          sense self unix processes  ieee symposium security privacy  pp         
hu  w   liao  y     vemuri  v          robust support vector machines anomaly detection
computer security  international conference machine learning applications 
kang  d  k   fuller  d     honavar  v          learning classifiers misuse detetction using
bag system calls representation  ieee international conferences intelligence
security informatics 
karagiannis  t   papagiannaki  k     faloutsos  m          blinc  multilevel traffic classification
dark  acm sigcomm 
kruegel  c   mutz  d   robertson  w     valeur  f          bayesian event classification intrusion
detection  annual computer security applications conference 
lakhina  a   crovella  m     diot  c          mining anomalies using traffic feature distributions 
acm sigcomm  pp       
lazarevic  a   ertoz  l   kumar  v   ozgur  a     srivastava  j          compare study anomaly
detection schemes network intrusion detection  siam international conference data
mining 
lbnl 
lbnl icsi enterprise tracing project  
enterprise tracing overview html  

http   www icir org 

leslie  c   eskin  e     noble  w  s          spectrum kernel  string kernel svm protein
classification  pacific symposium biocomputing           
malan  d  j     smith  m  d          host based detection worms peer peer cooperation  workshop rapid malcode 
mawi  mawi working group traffic archive   http   mawi nezu wide ad jp mawi  
moore  a  w     zuev  d          internet traffic classification using bayesian analysis techniques 
acm sigmetrics 
ng  b   pfeffer  a     dearden  r          continuous time particle filtering  national conference
artificial intelligence  pp           
   

fii ntrusion etection using ctbn

nodelman  u     horvitz  e          continuous time bayesian networks inferring users presence activities extensions modeling evaluation  tech  rep  msr tr         
microsoft research 
nodelman  u   koller  d     shelton  c  r          expectation propagation continuous time
bayesian networks  uncertainty artificial intelligence  pp         
nodelman  u   shelton  c  r     koller  d          continuous time bayesian networks  uncertainty artificial intelligence  pp         
nodelman  u   shelton  c  r     koller  d          learning continuous time bayesian networks 
uncertainty artificial intelligence  pp         
nodelman  u   shelton  c  r     koller  d          expectation maximization complex duration
distributions continuous time bayesian networks  uncertainty artificial intelligence 
pp         
press  w  h   teukolsky  s  a   vetterling  w  t     flannery  b  p          numerical recipes c
 second edition   cambridge university press 
qin  x     lee  w          attack plan recognition prediction using causal networks  annual
computer security application conference  pp         
rieck  k     laskov  p          language models detection unknown attacks network
traffic  journal computer virology 
saria  s   nodelman  u     koller  d          reasoning right time granularity  uncertainty
artificial intelligence 
simma  a   goldszmidt  m   maccormick  j   barham  p   black  r   isaacs  r     mortier  r 
        ct nor  representing reasoning events continuous time  uncertainty artificial intelligence 
soule  a   salamatian  l   taft  n   emilion  r     papagiannali  k          flow classification
histogram  acm sigmetrics 
soule  a   salamatian  k     taft  n          combining filtering statistical methods
anomaly detection  internet measurement conference  pp         
tandon  g     chan  p  k          learning useful system call attributes anomaly detection 
florida artificial intelligence research society conference  pp          
warrender  c   forrest  s     pearlmutter  b          detecting intrusions using system calls  alternative data models  ieee symposium security privacy  ieee computer society 
xu  j     shelton  c  r          continuous time bayesian networks host level network intrusion
detection  european conference machine learning 
xu  k   zhang  z  l     bhattacharyya  s          profiling internet backbone traffic  behavior
models applications  acm sigcomm 
ye  n   emran  s  m   chen  q     vilbert  s          multivariate statistical analysis audit trails
host based intrusion detection  ieee transactions computers                
yeung  d  y     chow  c          parzen window network intrusion detectors  international
conference pattern recognition 
   

fix u   helton

yeung  d  y     ding  y          user profiling intrusion detection using dynamic static
behavioral models  advances knowledge discovery data mining               
zuev  d     moore  a          internet traffic classification using bayesian analysis techniques 
acm sigmetrics 

   


