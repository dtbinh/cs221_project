journal of artificial intelligence research                  

submitted       published      

research note

finding a path is harder than finding a tree

christopher meek

meek microsoft com

microsoft research 
redmond  wa            usa

abstract

i consider the problem of learning an optimal path graphical model from data and show
the problem to be np hard for the maximum likelihood and minimum description length
approaches and a bayesian approach  this hardness result holds despite the fact that the
problem is a restriction of the polynomially solvable problem of finding the optimal tree
graphical model 
   introduction

the problem of learning graphical models has received much attention within the artificial intelligence community  graphical models are used to represent and approximate joint
distributions over sets of variables where the graphical structure of a graphical model represents the dependencies among the set of variables  the goal of learning a graphical model
is to learn both the graphical structure and the parameters of the approximate joint distribution from data  in this note  i present a negative hardness result on learning optimal
path graphical models 
path graphical models are an interesting class of graphical models with respect to learning  this is due the fact that  in many situations  restricting attention to the class of path
models is justified on the basis of physical constraints or temporal relationships among the
variables  one example of this is the problem of identifying the relative positions of loci on
a segment of dna  e g   boehnke  lange   cox         in addition  one might be interested
in obtaining a total order over a set of variables for other purposes such as visualization
 e g   ma   hellerstein        
the main positive results on the hardness of learning graphical models are for learning
tree graphical models  these have been presented for maximum likelihood  ml  criterion
 edmonds        chow   liu        and adapted to a bayesian criterion by heckerman 
geiger    chickering         two np hardness results for learning graphical models have
appeared in the literature  those are the np hardness of finding the optimal bayesian
network structure with in degree greater than or equal to two using a bayesian optimality
criterion  chickering        and the problem of finding the ml optimal polytree  dasgupta 
      
in this note  i present a proof of the hardness of finding an optimal path graphical
models for the maximum likelihood  ml  criterion  the minimum description length  mdl 
criterion  and a bayesian scoring criterion  unlike the ml hardness result of dasgupta  i
provide an explicit construction of a polynomial sized data set for the reduction and  unlike
the bayesian hardness result of chickering         i use a common  uninformative  prior 

c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fimeek

   optimal graphical models

one of the primary goals when learning a graphical model is to obtain an approximate joint
distribution over a set of variables from data  in this note  i focus on directed graphical
models for a set of discrete variables fx            x g  one component of a directed graphical
model is its directed graphical structure that describes dependencies between the variables 
a directed graphical model represents a family of distributions that factor according to the
graphical structure g of the directed graphical model  more specifically 
n

p  x            x    
g

n

y p  x jpa
n

  

i

g

 x   
i

i

where pa  x   denotes the possibly empty set of parents of vertex x in graph g  the
subscript g is omitted when it is clear from context  the most common methods guiding
the choice of a distribution from a family of distributions are maximum likelihood estimation
and bayesian estimation  given a graphical structure and a set of cases for the variables
 also a prior distribution over the distributions in the case of the bayesian approach   these
methods provide an approximate joint distribution  for more details on graphical models
and estimation see heckerman        
this leaves open the question of how one should choose the appropriate graphical structure  in the remainder of this section  i present the maximum likelihood  ml  criterion  the
minimum discrimination length  mdl  criterion  and a bayesian criterion for evaluating
directed graphical models given a set of cases d  a value of the variable x is denoted by
x and a value of the set of variables pa x   is denoted by pa x    the number of cases in
d in which x   x and pa x     pa x   is denoted by n  x   pa x    and the total number
of cases in d is denoted by n  
one important property common to these scoring criteria is that the scores factor according to the graphical structure of the model  that is  the score for a graph g and data
set d can be written as a sum of local scores for each of the variables
g

i

i

i

i

i

i

i

i

i

i

score g  d   

i

i

x localscore x   pa x    
i

i

i

the local score for a variable x is only a function of the counts for x and pa x   in the
data set d and the number of possible assignments to the variables x and pa x    thus
the structure of the graphical model determines which particular variables and counts are
needed in the computation of the local score for a variable 
the log maximum likelihood scoring criterion for a graphical model is
i

score

ml

x localscore

 g  d   

ml

i

i

i

i

 x   pa x   
i

i

i

localscore

ml

 x   pa x      n  h  x jpa x   
i

i

d

i

i

   

where h  x jpa x    is the empirical conditional entropy of x given its parents  and is
equal to
n  x   pa x    n  x   pa x   
log
 
n
n  pa x   
   
d

i

i

x

i

i

i

i

i

i

xi  pa xi

   

fifinding a path is harder than finding a tree

one practical shortcoming of the ml score is that in comparing two models with graphical
structure g and g  where g contains a proper subset of the edges of g  the ml score will
never favor g  thus  when using an ml score to choose among models without restricting
the class of graphical structures  a fully connected structure is guaranteed to have a maximal
score  this is problematic due to the potential for poor generalization error when using the
resulting approximation  this problem is often called overfitting  when using this principle
it is best to restrict the class of alternative structures under consideration in some suitable
manner 
the minimum description length score can be viewed as a penalized version of the ml
score

score

m dl

 g  d    score

d log n

 g  d 

x localscore
ml

 

 

m dl

 g  d 

i

localscore

m dl

 x   pa x     
i

i

  pa x        x  
 

localscore

i

ml

p

i

    log n

   

where d      pa x        x       and   y   is used to denote the number of possible
distinct assignments for a set of variables y and the number of assignments for the empty
set of variables is           the penalty term leads to more parsimonious models  thus 
alleviating the overfitting problem described above 
finally  a bayesian score requires a prior over the alternative models and  for each model 
a prior over the distributions  a commonly used family of priors for directed graphical models is described by cooper   herskovits         in their approach  one assumes a uniform
prior on alternative graphs  p  g       and an  uninformative  prior over distributions 
these assumptions lead to the following scoring function 
i

i

score

i

bayes

 g  d    log p  djg    log p  g 
 
localscore
 x   pa x   

x

bayes

i

i

i

localscore

bayes

 x   pa x     
i

log

y

i

 

pa xi

   x      
   
x
 
     n  pa x     
 
i

i

i

y n  x   pa x    
i

i

   

xi

although not as apparent as in the mdl score  the bayesian score also has a built in
tendency for parsimony that alleviates the problems of overfitting  the hardness results
presented below can be extended to a variety of alternative types of priors including the
bde prior with an empty prior model  see heckerman et al        
the problem of finding the optimal directed graphical model for a given class of structures g and data d is the problem of finding the structure g   g that maximizes score g  d  
   

fimeek

   np hardness of finding optimal paths

in this section  i consider the problem of finding the optimal directed graphical model
when the class of structures is restricted to be paths  a directed graphical structure is a
path if there is one vertex with in degree zero and all other vertices have in degree one  i
show that the problem of finding the optimal path directed graphical model is np hard for
the commonly used scoring functions described section    to demonstrate the hardness
of finding optimal paths the problem needs to be formulated as a decision problem  the
decision problem version of finding the optimal path directed graphical model is as follows
the optimal path  op  decision problem  is there a path graphical model with
score greater than or equal to k for data set d 
in this section i prove the following theorem 
theorem   the optimal path problem is np hard for the maximum likelihood score  the
minimum description length score and a bayesian score 

to prove this  i reduce the hamiltonian path  hp  decision problem to the op decision
problem 
the hamiltonian path  hp  decision problem  is there a hamiltonian path in
an undirected graph g 
a hamiltonian path for an undirected graph g is a non repeating sequence of vertices
such that each vertex in g occurs on the path and for each pair of adjacent vertices in
the sequence there is an edge in g  let the undirected graph g   hv  e i have vertex set
v   fx            x g and edge set e  
the hp decision problem is np complete  loosely speaking  this means that the hp
decision problem is as computationally dicult as a variety of problems for which no known
algorithm exists that runs in time that is a polynomial function of the size of the input 
theorem   indicates that the op decision problem is at least as dicult as any np complete
problem  for more information about the hp decision problem and np completeness see
garey   johnson        
i reduce the hp decision problem for g to the op decision problem by constructing a
set of cases d with the following properties 
n

  x       x  
i

 i 

j

localscore x        localscore x        

 ii 

localscore x   fx g    fff  fi g

 iii 

i

i

j

ff fi

j

localscore x   fx g    localscore x   fx g 

 iv 

localscore x   fx g    fi iff fx   x

 v 

j

i

i

i

j

i

   

j

j

g e

fifinding a path is harder than finding a tree

for such a data set  the problem of the existence of a hamiltonian path is equivalent
to the existence of a path graphical model with score equal to k       jv j     fi
where jv j   n is the number of vertices in the undirected graph g  thus  to reduce the
hp problem to the op problem one needs to eciently construct a polynomial sized data
set with these properties  in other words  by such a construction  a general hp decision
problem can be transformed into an op decision problem  because the size of the input
to the op problem is a polynomial function of the size of the input for the hp problem  if
one can find an algorithm solve the op problem in polynomial time then all np complete
problems can be solved in polynomial time 
i construct a data set for graph g assuming that each variable is ternary to satisfy
condition  i   for each pair of vertices x and x  i   j   for which there is an edge in g 
add the following   cases in which every variable x  k    i  j   is zero 
i

j

k

x        x
     
     
     
     
     
     
     
     

i

 

x x          x
 
     
 
     
 
     
 
     
 
     
 
     
 
     
 
     
i

i

j

 

x

j

 
 
 
 
 
 
 
 

x          x
     
     
     
     
     
     
     
     
j

n

for each pair of vertices x and x  i   j   for which there is not an edge in g  add the
following   cases 
i

j

x        x
     
     
     
     
     
     
     
     

i

 

x x          x
 
     
 
     
 
     
 
     
 
     
 
     
 
     
 
     
i

i

j

 

x

j

 
 
 
 
 
 
 
 

x          x
     
     
     
     
     
     
     
     
j

n

for a set of cases constructed as described above  the pairwise counts for a pair of variables
x and x connected by an edge in g are
i

j

x

i

x

j

 
 
 
    n   n        n      n   
 
  n   
 
 
  n   
 
 
 
   

fimeek

the pairwise counts for a pair of variables x and x not connected by an edge in g are
i

j

x

i

x

j

 
 
 
    n   n        n      n   
 
  n   
 
 
 
  n   
 
 

condition  ii  is satisfied because the marginal counts for each variable are identical  there
are two types of pairwise count tables  thus  there are at most two values for a given type
of pairwise localscore  by using the two pairwise count tables and equations       and   
one can easily verify that the local scores for the two tables satisfy condition  iii   it follows
from the symmetry in the two types of pairwise tables and condition  ii  that condition  iv 
is satisfied  it follows from the construction that condition  v  is satisfied  furthermore 
the set of cases is eciently constructed and has a size which is polynomially bounded by
the size of the graph g proving the result 
   conclusion

in this note  i show that the problem of finding the optimal path graphical models is nphard for a variety of common learning approaches  the negative result for learning optimal
path graphical models stands in contrast to the positive result on learning tree graphical
models  this hardness result highlights one potential source of the hardness  that is 
one can make an easy problem dicult by choosing an inappropriate subclass of models 
perhaps  by carefully choosing a broader class of models than tree graphical models one can
identify interesting classes of graphical models for which the problem of finding an optimal
model is tractable 
another interesting class of graphical models not described in this note is the class of
undirected graphical models  e g   lauritzen         the methods for learning undirected
graphical models are closely related to the methods described in section    in fact  for the
case of undirected path models  the scoring formulas described in section   are identical
for each of the common approaches  therefore  the np hardness result for directed path
models presented in this note also applies to problem of learning undirected path models 
finally  it is important to note that good heuristics exist for the problem of finding
weighted hamiltonian paths  karp   held         these heuristics can be used to identify
good quality path models and rely on the fact that the optimal tree model can be easily
found and will have a score at least as large as any path model 
references

boehnke  m   lange  k     cox  d          statistical methods for multipoint radiation
hybrid mapping  american journal of human genetics                
chickering  d          learning bayesian networks is np complete  in fisher  d     lenz 
h   eds    learning from data  pp           springer verlag 
chow  c     liu  c          approximating discrete probability distributions with dependence trees  ieee transactions on information theory              
   

fifinding a path is harder than finding a tree

cooper  g     herskovits  e          a bayesian method for the induction of probabilistic
networks from data  machine learning             
dasgupta  s          learning polytrees  in proceedings of the fifteenth conference on
uncertainty in artificial intelligence  stockholm  sweden  pp           morgan kaufmann 
edmonds  j          optimum branching  j  res  nbs    b          
garey  m     johnson  d          computers and intractability  a guide to the theory of
np completeness  w h  freeman  new york 
heckerman  d          a tutorial on learning with bayesian networks  in jordan  m   ed   
learning in graphical models  pp           kluwer academic publishers 
heckerman  d   geiger  d     chickering  d          learning bayesian networks  the
combination of knowledge and statistical data  machine learning              
karp  r     held  m          the traveling salesman problem and minimum spanning trees 
part ii  mathematical programming          
lauritzen  s          graphical models  oxford university press 
ma  s     hellerstein  j          ordering categorical data to improve visualization  in
proceedings of the ieee symposium on information visualization  pp        

   

fi