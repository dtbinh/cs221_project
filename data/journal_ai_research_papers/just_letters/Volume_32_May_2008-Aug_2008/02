journal artificial intelligence research                 

submitted        published      

graphical model inference optimal control stochastic
multi agent systems
bart van den broek
wim wiegerinck
bert kappen

b vandenbroek science ru nl
w wiegerinck science ru nl
b kappen science ru nl

snn  radboud university nijmegen  geert grooteplein    
nijmegen  netherlands

abstract
article consider issue optimal control collaborative multi agent
systems stochastic dynamics  agents joint task
reach number target states  dynamics agents contains additive control
additive noise  autonomous part factorizes agents  full observation
global state assumed  goal minimize accumulated joint cost  consists
integrated instantaneous costs joint end cost  joint end cost expresses joint
task agents  instantaneous costs quadratic control factorize
agents  optimal control given weighted linear combination single agent
single target controls  single agent single target controls expressed terms
diffusion processes  controls  closed form expressions  formulated
terms path integrals  calculated approximately metropolis hastings
sampling  weights control interpreted marginals joint distribution
agent target assignments  structure latter represented graphical
model  marginals obtained graphical model inference  exact inference
graphical model break large systems  approximate inference methods
needed  use naive mean field approximation belief propagation approximate
optimal control systems linear dynamics  compare approximate inference
methods exact solution  show accurately compute optimal
control  finally  demonstrate control method multi agent systems nonlinear
dynamics consisting    agents reach equal number target states 

   introduction
topic control multi agent systems characterized many issues  originating
various sources  including wide variety possible execution plans  uncertainties
interaction environment  limited operation time supporting resources 
demand robustness joint performance agents  issues encountered
in  example  air traffic management  tomlin  pappas    sastry        van leeuwen 
hesseling    rohling         formation flight  ribichini   frazzoli        hu  prandini 
  tomlin         radar avoidance unmanned air vehicles fighter aircraft  pachter  
pachter        kamal  gu    postlethwaite        larson  pachter    mears        shi 
wang  liu  wang    zu         persistent area denial  subramanian   cruz       
liu  cruz    schumacher        castanon  pachter    chandler        
many control approaches multi agent systems  stochastic influences dynamics
agents taken account assumed negligible  dynamics
c
    
ai access foundation  rights reserved 

fivan den broek  wiegerinck   kappen

modeled deterministically  system truly deterministic  agents
optimally controlled open loop controls  however  stochastic influences
dynamics large ignored  open loop controls become far optimal 
multi agent system longer modeled deterministically 
usual
approach control multi agent systems stochastic dynamics model system
markov decision processes  mdp   boutilier        sadati   elhamifar        
principle  solved discrete space time backward dynamic programming 
however  discretization make joint state space multi agent system increase
exponentially number agents  basic dynamic programming approach
generally infeasible  boutilier         attempt overcome exploit structures
problem describe system factored mdp  general structures
conserved value functions  exact computations remain exponential
system size  guestrin  koller  parr      a  guestrin  venkataraman  koller
     b  assumed predefined approximate structure value functions  thereby
provided efficient approximate mdp model multi agent systems  similar approach
taken becker  zilberstein  lesser  goldman               assuming independent
collaboration agents global reward function  resulting transition independent
decentralized mdps 
paper concentrate multi agent systems agents joint task
reach number target states  model multi agent system
continuous space time  following approach wiegerinck  van den broek 
kappen         make following assumptions  agents assumed
complete accurate knowledge global state system  assumption    
dynamics agent additive control disturbed additive wiener noise
 assumption     performance agents valued global cost function 
integral instantaneous costs plus end cost  joint task agents modeled
end cost  instantaneous costs assumed quadratic control
 assumption     noise level dynamics agents inversely proportional
control cost  assumption     finally  assume autonomous dynamics
instantaneous costs factorize agents  assumption    
assumptions      optimal control problem partially solved finding
optimal expected cost to go  satisfies so called stochastic hamilton jacobibellman  shjb  equation  optimal expected cost to go given  optimal
control provided gradient optimal expected cost to go adopting assumption    shjb equation nonlinear partial differential equation  pde  
nonlinearity makes difficult solve  common approach solving shjb equation
assume  addition assumption    instantaneous costs end cost
cost function quadratic state  dynamics linear
state wellthis known linear quadratic control  optimal expected cost to go
quadratic state time varying coefficients  problem reduces
solving riccati equations coefficients satisfy  stengel        ksendal        
otherwise  approximation methods needed  approximate approach given
iterative linear quadratic gaussian method  todorov   li         yields locally optimal feedback control  valid case little noise  instead follow approach
fleming        adopt assumption    assumption shjb equation
  

figraphical model inference mas optimal control

transformed linear pde performing logarithmic transformation  solution
equals expectation value stochastic integral diffusion process  general 
closed form expression  paper estimate expression formulating
path integral  kappen      a      b   estimate latter using metropolishastings sampling  several ways estimate path integral 
hamilton monte carlo sampling laplace approximation  covered
paper 
structure optimal expected cost to go generally complex due
dynamic couplings agents  adopting assumption    agents
coupled joint end cost  solely determines structure
optimal expected cost to go  result state transition probabilities factorize
agents  follows optimal control becomes weighted combination
single agent single target controls  weights given joint distribution
agent target assignments  joint distribution structure joint end
cost  structure joint distribution representable factor graph 
optimal control problem becomes graphical model inference problem  wiegerinck et al  
       complexity graphical model inference exponential tree width
factor graph  exact inference possible using junction tree algorithm 
given graph sufficiently sparse number agents large 
complex situations approximate inference methods necessary  show
optimal control accurately approximated polynomial time  using naive mean
field  mf  approximation belief propagation  bp   makes distributed coordination
possible multi agent systems much larger could treated
exact inference 
paper organized follows  sections      provide review
single multi agent stochastic optimal control framework  developed kappen      a      b  wiegerinck et al          example  rederive linear
quadratic control  general solution given terms path integral  explain
approximated metropolis hastings sampling 
section    give factor graph representation end cost function  discuss two graphical model approximate inference methods  naive mean field approximation
belief propagation  show approximation optimal control
methods obtained replacing exact weights controls respective
approximations 
section    present numerical results  make comparison approximate
optimal controls  infered naive mean field approximation  belief propagation
greedy method  exact optimal control  multi agent system
   agents linear dynamics two dimensional state space  two target
states  furthermore  present results control multi agent systems nonlinear
dynamics four dimensional state space  agents control forward velocity
driving direction  controls approximated combination metropolishastings sampling  infer path integrals  naive mean field approximation  infer
agent target assignments  allowed us control systems    agents
   target states  results regarding nonlinear dynamics illustrative
purpose 
  

fivan den broek  wiegerinck   kappen

   stochastic optimal control single agent
consider agent k dimensional continuous state space rk   state x t  evolving
time according controlled stochastic differential equation
dx t    b x t   t dt   u x t   t dt   dw t  

   

accordance assumptions     introduction  control agent
rk  valued function u x t  t  noise dynamics modeled wiener
process w t   i e   normally distributed k dimensional stochastic process continuous
time mean   variance t  k k matrix represents variance
noise  autonomous dynamics modeled b  rk  valued function
x t  t  state change dx t  sum noisy control autonomous
dynamics 
behavior agent valued cost function  given agents state x t    x
present time t  control u  expected future cost agent 



z
 

c u  x  t    eux t  x t     
kru x     k    v  x       
   
 

expectation eux t taken respect probability measure x t 
solution     given control law u condition x t    x  cost
combination end cost  x t     function end state x t   
integral instantaneous costs  instantaneous cost sum state control
dependent term  state dependent term v  x      cost state x  
time   function v arbitrary  represents environment agent 
control dependent term    kru x     k  cost control state x   time  
kzk    z z euclidean norm  r full rank k k matrix  quadratic
control  accordance assumption   introduction  assumption   
r related variance noise control via relation
   r r    

   

scalar 
expected cost to go time minimized controls u defines optimal
expected cost to go
j x  t    min c u  x  t  
   
u

appendix a  explained due linear quadratic form optimization
problemthe dynamics     linear action u  cost function     quadratic
actionthe minimization performed explicitly  yielding nonlinear partial differential equation j  so called stochastic hamilton jacobi bellman  shjb  equation 
minimum attained
u x  t     r r   x j x  t  

   

optimal control  note explicitely depends state x agent
time t  making feedback control 
  

figraphical model inference mas optimal control

optimal expected cost to go re expressed terms diffusion process  for
derivation  refer appendix a  
j x  t    log z x  t 

   

z x  t  expectation value



z
 
 
z x  t    ex t exp  y t   
v  y     



   

y   diffusion process y t    x satisfying uncontrolled dynamics 
dy     b y     d   dw   

   

substituting relations              find optimal control terms z x  t  
u x  t    x log z x  t  

   

example    consider agent one dimension state x t  described dynamical equation     without autonomous dynamics  b       instantaneous cost v zero 
end cost quadratic function around target state  
 y   


 y     
 

diffusion process y   satisfies uncontrolled dynamics     normally distributed
around agents state x   y t  time variance     t   hence state
transition probability agent go  x  t   y    space time given
gaussian density


 y x  
 y   x  t    p
 
exp  
   t t 
     t t 
 

expectation value     given integral

z x  t   

z

 

 y 

dy y   x  t e

 





r   
 x   
exp  
 
  r   
   t   r    

relation     used  optimal control follows         reads
u x  t   

x
 
  r   

result well known  stengel        
  

    

fivan den broek  wiegerinck   kappen

    path integral formulation
example   shows simple system autonomous dynamics  b      costs
due environment  v       write control explicitly 
uncontrolled dynamics normally distributed  consequently expectation value
    quadratic end cost closed form expression  general situation b
v arbitrary  longer exists explicit expression expectation value 
optimal control obtained approximation  discuss
done taking path integral approach  kleinert         detailed derivation
expressions presented given appendix b 
path integral approach  write expectation value     path integral 
z x  t    lim z  x t     t   

    

 

x t      x  t   
 

z  x t     t      p
det      n

z

dx t         

z

 

dx tn   e  x t        x tn   t     

integral paths  x t             x tn    discrete time  start x t    kept fixed
n   t  taken continuous time limit sending length time steps
  ti   ti zero  note limit n goes infinity paths become infinite
dimensional objects  function exponent cost path 
 x t             x tn    t     
 x t     

n
 
x

v  x ti    ti    

n
 
x
i  

i  


 

 
x ti     x ti  

r
b x ti    ti  
 
 


optimal control becomes weighted average controls derived single
path 
u x t     t      lim
 

z

dx t         

z

dx tn   p x t             x tn    t    u x t             x tn    t         

weights given
 

p x t             x tn    t      p

e  x t        x tn   t   
det      n z  x t     t   

 

control derived path  x t             x tn    reads
u x t             x tn    t     

x t    x t   
b x t     t    


note depends first two entries x t    x t    path 
   

    

figraphical model inference mas optimal control

    path integration metropolis hastings sampling
path integral formulation      optimal control generally computed 
integral uncountably many paths  exist several ways
approximate it  natural approach goes stochastic sampling paths  several methods
stochastic sampling exist  one use known metropolis hastings
sampling  hastings         implementation time discretized  take
limit      decreasing zero  instead keep fixed value  sample path
sequence  xs  t             xs  tn    vectors state space rk   x t      x
current state agent current time t    t  according equation      
need xs  t    xs  t    derive control sample path  x t             x tn    
metropolis hastings sampling ensures different paths properly weighted  hence
optimal control approximated follows 
u x t     t   

hx t   i x t   
b x t     t    
t  t 

    

hx t   i mean value xs  t    taken sample paths  pseudo code
algorithm given algorithm   
algorithm    metropolis hastings sampling
input  initial path  x t             x tn   
      
   repeat times 
   define gaussian proposal distribution centered around  x t             x tn   
variance equal noise
   draw sample path  x  t             x  tn    proposal distribution

     exp    x t     x t             x tn    t       x t     x  t             x  tn    t   
    
  
set  x t             x tn       x  t             x  tn   
   else
  
set  x t             x tn       x  t             x  tn    probability
    end
     xs  t             xs  tn       x t             x tn   
         
    end repeat
    compute approximate control equation     

   stochastic optimal control multi agent system
turn issue optimally controlling multi agent system n agents 
principle  theory developed single agent straightforwardly generalizes multiagent situation  agent k dimensional state xa satisfies dynamics similar
    
dxa  t    ba  xa  t   t dt   ua  x t   t dt   dwa  t  
    
accordance assumptions        introduction  note control
agent depends state xa   joint state x    x            xn  
   

fivan den broek  wiegerinck   kappen

system  system joint cost function similar      depending joint
state x joint control u    u            un   system 



n z
x
 
u
u
 

c  x  t    ex t  x t     
kra ua  x     k   v  xa        
 

a  

expectation eux t taken respect probability measure x t 
solution      given control law u condition x t    x  cost
combination joint end cost  x t     function joint end state x t   
integral instantaneous costs  instantaneous cost factorizes agents 
accordance assumption   introduction  agent  sum state
dependent term v  xa       control dependent term    kra ua  xa      k    similar
single agent case  accordance assumption   introduction  control cost
agent related noise agents dynamics via relation
   ra ra     
agent  joint cost function minimized joint
control  yielding optimal expected cost to go j  optimal expected cost to go
expressed terms diffusion process via relation
j x  t    log z x  t  
z x  t  joint expectation value
  
 
n z
 x
 
v  ya      
z x  t    ex t exp  y t   




    

a  

y   t           yn  t  diffusion processes     y            yn   y t    x  satisfying
uncontrolled dynamics
dya      ba  ya      d   dwa    

             n 

    

multi agent equivalent optimal control     reads
ua  x  t    xa log z x  t  

    

show optimal control agent understood expected
control  is  integral target states ya transition probability target
times optimal control target  end  write expectation     
integral end state 
z
n

 
z x  t    dye  y 
za  ya     xa   t  
    
a  

za  ya     xa   t  implicitly defined



z
z
 
v  ya      
dya za  ya     xa   t f  ya     exa  t f  ya  t    exp

   

figraphical model inference mas optimal control

arbitrary functions f   substituting           yields
z
ua  x  t    dya pa  ya  x  t  ua  ya   xa   t 

    


ua  ya   xa   t    xa log za  ya     xa   t 

    

optimal control agent go state xa current time state ya
end time   pa  ya  x  t  marginal
n


 
 
p y x  t   
za  ya     xa   t  
e  y 
z x  t 
a  

    discrete end states
agents fulfill task arriving number target states end time
according initially specified way  example  arrive
target  arrive different targets  targets considered regions
g            gm state space  end cost modeled follows 
 

e  y   

x


w s 

n


wa  ya   sa   

 

wa  ya   sa     e  ya  sa    

    

a  

sum runs assignments    s            sn   agents regions gsa    ya   sa  
cost function associated region gsa   returning low cost end state ya agent
lies region gsa high cost otherwise  w s  weight  grading assignments
thereby specifying joint task agents  assignments result better
fulfillment task higher weight  situation agents go
target  example  vector assigns agent different target
low weight w s  
choice end cost  equation      factorizes
z x  t   

x



za  sa   xa   t   

z

w s 

n


za  sa   xa   t 

a  

dya za  ya     xa   t wa  ya   sa   

    

interpretation za  sa   xa   t  log za  sa   xa   t  expected cost agent
move xa target sa   optimal control      single agent becomes
ua  x  t   


x

p sa  x  t ua  sa   xa   t  

    

sa   


ua  sa   xa   t    xa log za  sa   xa   t 
   

    

fivan den broek  wiegerinck   kappen

control agent go target sa   weights p sa  x  t  single agent
marginals
x
p s x  t 
    
p sa  x  t   
s sa

joint distribution
n


 
p s x  t   
za  sa   xa   t  
    
w s 
z x  t 
a  


 
 
weight p s x 
pnt  equals ratio exp j s  x  t    exp j x  t    j s  x  t   
log w s  a   log za  sa   x  t  optimal expected cost to go case agents
predetermined targets specified assignment s  assignment agents
targets low expected cost j s  x  t  yield high weight p s x  t  
associated single agent single target controls ua  sa   xa   t  predominant
optimal controls ua  x  t  
    metropolis hastings sampling multi agent systems
general  controls ua  sa   xa   t  marginals p sa  x  t  optimal control      closed form solution  inferred approximately 
controls ua  sa   xa   t  approximated metropolis hastings sampling discussed
section      inference marginals involves inference path integral formulations za  sa   xa   t  
z
z
 
 
za  sa   xa   t    lim p
dxa  t          dxa  tn  e  xa  t        xa  tn   t   sa  
 
n
 
det    
xa  t      xa   t   

s xa  t             xa  tn    t    sa      xa  t    sa  
 

n
 
x

v  xa  ti    ti    

i  

n
 
x
i  


 

 
xa  ti     xa  ti  

ra
ba  xa  ti    ti  
 
 


value za  sa   xa   t  generally hard determine  mackay         possible approximations include maximum posteriori  map  estimate inclusion variance
sample paths  third approximation take average path costs
estimate log za  sa   xa   t   means entropy distribution path
integral neglected 

   graphical model inference
additional computational effort multi agent control compared single agent control
lies computation marginals p sa  x  t  joint distribution p s x  t  
involves sum mn assignments s  small systems feasible  large
systems summation performed efficiently  efficient approach
provided graphical model inference  relies factor graph representation
joint distribution 
   

figraphical model inference mas optimal control

   

   

 

   

 

   

 

   

 

figure    example factor graph multi agent system four agents  couplings
represented factors a                                           

    factor graph representation joint distribution
complexity joint distribution part determined weights w s  end
cost function       weights determine agents consider states
agents  complex case  way one agent takes state another agent
account depend states agents  situation less complicated
agent considers states agents independently states others 
means joint end cost factorized form 

w s   
wa  sa   
    


subsets agents  structure represented graphically so called factor
graph  kschischang  frey    loeliger         see figure   example  agents
factors nodes factor graph  represented circles squares respectively 
edge agent factor member subset a 
is  wa factorization w depends sa        immediate
joint distribution p s x  t  factorizes according factor graph 
    junction tree algorithm
efficient inference distribution p s x  t  means factor graph representation
accomplished using junction tree algorithm  lauritzen   spiegelhalter        
complexity algorithm exponential induced tree width graph  small
tree width expected systems factor graph sparse  case
agents take states account limited number agents 
implies multi agent systems sparse graphs limited number targets
tractable  wiegerinck et al          factor graph figure   example sparse
graph  hand  agent take state agent account 
junction tree algorithm really help  underlying factor graph fully
connected tree width graph equals number agents system 
exact computation optimal control intractable large complex multiagent systems  since junction tree algorithm requires memory exponential tree
width factor graph  instead use graphical model approximate inference
methods approximately infer marginals       proceed discussion
two methods  naive mean field  mf  approximation  jordan  ghahramani  jaakkola 
  saul        belief propagation  bp   kschischang et al         yedidia  freeman   
weiss        
   

fivan den broek  wiegerinck   kappen

    naive mean field approximation
starting point note optimal expected cost to go log partition sum 
known free energy  consider variational free energy
x
f  q    h log wiq
hlog za iqa h q  


h iq h iqa denote expectation values respect distribution q marginals
qa respectively  h q  entropy q 
x
h q   
q s  log q s  


optimal expected cost to go equals variational free energy minimized distributions q  naive mean field approximation
one considers variational free energy
q
restricted factorized distributions q s    qa  sa    minimum
f  q 
jmf   min
q
q 

qa

upper bound optimal expected cost to go j  equals j case agents
uncoupled  f zero gradient local minima  is 
  

f  q   s    qn  sn   
qa  sa  

             n 

    

additional constraints normalization distributions qa   solutions set
equations implicitly given mean field equations
za  sa  hw sa iq
qa  sa     pn


sa    za  sa  hw sa iq

    

hw sa iq conditional expectation w q given sa  

x
qa  sa   w s            sn   
hw sa iq  
s       sn  sa

  a

mean field equations solved means iteration  procedure results
convergence local minimum free energy 
mean field approximation optimal control found taking gradient
respect x minimum jmf free energy  similar exact case
optimal control gradient optimal expected cost to go  equation      
using       find
x
 
ua  x  t    xa jmf  x  t   
qa  sa  ua  xa   t  sa   




similar exact case  average single agent single target optimal controls
ua  xa   t  sa   given equation       average taken respect mean
field approximate marginal qa  sa   agent a 
   

figraphical model inference mas optimal control

    belief propagation
belief propagation  approximate free energy bethe free energy 
minimize latter  bethe free energy defined
fbethe   qa   qa     

x

h log wa iqa



x

h log za iqa



x

h qa    



x

 na   h qa   



    
function beliefs qa  sa   qa  sa    non negative normalized functions
satisfy consistency relations 
 

x

qa  sa     qa  sa   

sa a

h qa   h qa   entropies beliefs qa qa   na denotes number
neighbors node factor graph 
belief propagation algorithm computes beliefs  kschischang et al         
case joint distribution p factor graph representation tree  belief propagation converge beliefs exact marginals p  bethe free energy
beliefs equals optimal expected cost to go j  factor graph representation
p contains cycles  may still apply belief propagation  yedidia et al         showed
fixed points algorithm correspond local extrema bethe free energy 
particular  advanced variations algorithm  heskes  albers    kappen       
teh   welling        yuille        guaranteed converge local minima bethe
free energy  heskes        
find bp approximation optimal control taking gradient
minimum jbethe bethe free energy 
x
 
ua  x  t    xa jbethe  x  t   
qa  sa  ua  xa   t  sa   




ua  xa   t  sa   given equation       similar exact case mean field
approximation  bp approximation optimal control average single agent
single target optimal controls  average taken respect belief qa  sa   

   numerical results
section  present numerical results simulations optimal control multiagent systems  problem computing optimal controls      consists two parts 
inference single agent single target controls       inference
marginals      global distribution agent target assignments  dynamics linear  instantaneous costs v zero  single agent single target
controls given closed form  multi agent systems therefore know issue
infering marginal distributions  section     consider multi agent systems
kind  section     deals general problem infering optimal controls
dynamics nonlinear instantaneous costs v nonzero  sections
   

fiexpected target

van den broek  wiegerinck   kappen

position

 
 
 
 

   

 
time

   

 

 
 
 
 

 a  positions

   

 
time

   

 

 b  expected targets

figure    two agents  noise control positions  need reach target locations      end time      agent different target location 
positions  a  expected targets  b  time 

joint end cost given equation      
w s   

n

a b

wa b  sa   sb   

c

wa b  sa   sb     exp sa  sb  
n

    




 
    
 ya   sa      ya sa     
wa  ya   sa     exp  ya   sa    

 
c determines coupling strength agents  sa target
states 
    linear dynamics
begin illustration optimal control showing simulation exactly
solvable stochastic multi agent system  system two agents one dimension 
agents satisfy dynamics      ba equal zero  two target states  x        
x          task agents one go different target 
instantaneous costs v cost function zero  end cost function given
equations                      c      negative sign coupling
strength c implies repulsion agents  control cost parameter r equals   
noise level   lies      agents start x     time      end time lies
     prevent overshooting targets  udt small compared distance
target states  done choosing dt        t         
p
figure   shows agents positions expected targets
sa      p sa  x  t sa
time  see time      agents decided target
go  remain two targets  then       final decision
seems made  delayed choice due symmetry breaking cost togo time increases  symmetry breaking  better keep options open 
see effect noise is  symmetry breaking  time short wait
longer choice made  phenomenon typical multi modal problems 
proceed quantitative comparison different control methods arise
exact approximate inferences marginals joint distribution      
   

figraphical model inference mas optimal control

 

  

 

 

cpu time

cost difference

 
 
 
 
 
 
 

  

 

  

 

  

 

   

       
noise

   

  

 

 a  costs

 

   

       
noise

   

 

 b  cpu time

figure    deviation optimal cost  a  required cpu time seconds
 b  functions noise  lines represent exact      greedy      mf
   bp    control 

example consider multi agent system n      agents two dimensional
state space zero instantaneous costs  v      autonomous dynamics  ba      
end cost function given equations                  two targets located
                            c        control cost matrix r equals
identity matrix  agents start        time      end time lies     
time steps size dt        t         
approximations naive mean field approximation belief propagation  described section    greedy control  greedy control mean time step
agent chooses go nearest target  include approximation
simple requires little computation time  reasons obvious choice
naive approximation  greedy control policy neglects choices
agents  expect give inferior performance 
approximation  figure   a  shows cost approximate  optimal 
control minus cost exact  optimal  control  averaged     simulations 
different noise levels  noise samples used approximate exact
control  see naive mean field approximation belief propagation yield
costs average coincide cost exact control  average cost difference
methods significantly differ zero  greedy control 
hand  yields costs significantly higher costs exact control 
deterministic limit converge cost exact control  controls
coincide  figure   b  shows cpu time required calculation controls
different control methods  average cpu time entire simulation 
simulation consists    time steps  time step control calculated
agent  observe greedy control least    times faster methods 
exact control nearly     times time consuming methods  belief
propagation gives performance considered noise levels bit quicker
naive mean field approximation  may result implementation details 
done simulations attractive coupling c        returned results similar
ones repulsive coupling c       presented here 
   

ficumulative control cost

van den broek  wiegerinck   kappen

  
  
  
 
 
 

   

 
time

   

 

figure    cumulative control cost time  case strong repulsive coupling
c     low noise level          curves represent exact      mf
    bp control    

although figure   suggests belief propagation naive mean field approximation
perform equally well  always case  since certain combinations noise
level coupling strength bp control costly mf control exact
control  origin difference lies symmetry breaking  tends occur
later bp earlier mf compared exact control  observe
figure    shows cumulative cost time control methods
multi agent system  coupling strength c     fixed noise level         
cumulative costs averages     simulations  cost mf control lies
bit higher cost exact control  whereas cost bp control initially
lower cost control methods        starts increase
much faster eventually ends higher  including end costs  found total costs
           exact control             mf control           bp
control  suggests better early symmetry breaking late
symmetry breaking 
time required computing control various methods depends
number agents multi agent system  figure   shows required cpu time
function number agents n two dimensional multi agent system considered
above  see exact method requires cpu time increases exponentially
number agents  may expected theory 
exact method uses junction tree algorithm complexity exponential
tree width underlying graph  i e   exponential n  greedy method 
cpu time increases linearly number agents  agreement
fact greedy control coupling agents  required cpu
time increases polynomially mean field approximation belief propagation 
    nonlinear dynamics
turn multi agent systems nonlinear dynamics  control systems 
must approximate graphical model inference well single agent singletarget control problem       consider multi agent system agents move
   

figraphical model inference mas optimal control

 

  
cpu time

 

  

 

  

 

  

 

  

  

  

  
agents

  

  

figure    required cpu time seconds calculation controls different
number agents  exact      greedy      mf     bp control    

two dimensions four dimensional state specified agents location
 xa   ya    forward velocity va   driving direction   dynamics agent
given equations
dxa   va cos dt
dya   va sin dt
dva   ua dt   dwa
da   dt   da  
first two equations model kinematics agents position given forward
velocity driving direction  last two equations describe control speed
driving direction application forward acceleration ua angular velocity
  noise control modeled standard normal wiener processes wa
noise level parameters   note noise act dimensions
control  although control space counts less dimensions
state space  example fit general framework  refer appendix c
details 
look two different tasks  first task obstacle avoidance multiagent system three agents  agents reach one three target locations
avoid obstacles environment  target location reached precisely
one agent  model end cost function  given equations                 
  c        targets located                             
agents arrive zero velocity  control cost matrix r identity matrix 
       instantaneous cost v equaled      locations obstacles  zero
otherwise  agents start time      end time lies       time steps dt
size      starting locations agents                             
agents start zero velocity  sample paths discrete time paths twodimensional space forward velocity v driving direction   specified
values times ti                    n      nt
  n      value
time t  equals current state one agents  value time tn equals
one target end states  control agent one targets computed
   

fivan den broek  wiegerinck   kappen

  

  

  

  

  

  

  

  

  

  

 

 

  

  

  

  

  

 

 a  trajectories

 

  

  

  

  

  

 b  sample paths

figure    three agents  noise control forward velocities driving directions  reach three targets  marked x  environment containing
number walls  agent starts different location  marked o 
zero forward velocity  agent arrive different target
zero velocity without hitting walls   a  trajectories agents
followed reach targets   b  sample paths 

metropolis hastings sampling paths  according subsection      proposal
distribution  n  dimensional gaussian  centered around agents current planned
path  variance equal noise level agents dynamics  expectation
values za  sa   xa   t  estimated average costs sample paths 
tried map estimation za  sa   xa   t  inclusion variance sample paths 
former show significant difference  latter returned estimates
fluctuated heavily  figure   a  shows environment trajectories agents
starting locations targets  agent manages avoid obstacles
arrive one targets zero velocity  target reached different
agent 
second task coordination multi agent system shown figure   a   system instantaneous costs  v       agents move
initial positions number target locations  arrive
locations zero velocity horizontal driving direction  equal number
agents target locations  agent reach different target  initial
locations aligned vertically  target locations  vertical displacement two  thus agents coordinate movements order
reach targets satisfactory way 
agents start time    end time lies      make time steps size

dt     n
     n      dt         time step controls computed
metropolis hastings sampling paths naive mean field approximation infer
marginals pa  sa  x  t  weigh single agent single target controls  equations     
      sample paths discretized seven equidistant time points
present time end time  proposal distribution taken gaussian 
   

figraphical model inference mas optimal control

centered around agents current planned path variance equal noise
level agents dynamics  figure   a  shows example trajectories system
   agents  obtained    sample paths per agent target combination 
observe agents reach targets  target reached precisely one
agent  required  due noise second order dynamics agents  takes
agents less effort approach target remain there  since former allows
exploitation noise latter requires constant correction state changes
caused noise  result trajectories agents curved
elongated would expected situation without noise  simulation
carried well larger number agents  figure   b  shows required cpu time
function number agents  exact mf inference marginals
agents  note complexity graphical model inference problem scales
nn   n number agents  exact inference using junction tree algorithm
feasible n      

   discussion
studied use graphical model inference methods optimal control stochastic
multi agent systems continuous space time agents joint task
reach number target states  rather discretizing  commonly done typically
makes large systems intractable due curse dimensionality  followed approach
developed wiegerinck et al          modeling system continuous space time 
certain assumptions dynamics cost function  solution given
terms path integral 
path integral computed closed form special cases 
linear quadratic case  general approximated  done
variety methods  method considered paper mcmc sampling 
dimension sample paths kept low  n      limit curvature sample
paths  gain limiting curvature variance samples reduced
less samples needed  limiting curvature  however  introduce bias 
addition  presence obstacles insufficient curvature would make sampler return
sample paths run obstacles  believe advanced mcmc
methods hybrid mc sampling  duane  kennedy  pendleton    roweth       
overrelaxation  neal        improve inference path integrals 
apart mcmc sampling  approximation methods one could
consider  laplace approximation variational approximation  laplace
approximation becomes exact noiseless limit could useful low noise regimes
well  variational approximation approximates path integral      gaussian
process  archambeau  opper  shen  cornford    shawe taylor         could particularly useful high noise regime  drawback variational approach  however 
cannot straightforwardly applied situations infinite instantaneous costs 
hard obstacles environment considered here 
wiegerinck et al         showed systems sufficiently sparse
single agent single target controls determined closed form  e g  linearquadratic control time independent coefficients  exact inference achieved using
   

fivan den broek  wiegerinck   kappen

  

  

  

  

  

 

  

  

  

  

  
  

  

  

 

 

 

  

  

 a  trajectories
 

  

 

cpu time

  

 

  

 

  

 

  

 

  

  
  
number agents

  

 b  cpu time

figure     a  trajectories    agents starting locations    targets x   b 
required cpu time seconds function number agents 
number targets equal number agents  lines represent exact
    mf    inference marginals 

   

figraphical model inference mas optimal control

junction tree algorithm  van den broek  wiegerinck  kappen        considered
multi agent system second order dynamics  linear autonomous dynamics zero
instantaneous costs  showed graphical model inference naive mean field approximation significantly outperformed greedy inference  showed close
optimal result achieved well dense systems  using graphical model approximate
inference methods  approximation methods considered naive mean field
approximation belief propagation  demonstrated performances example
system exact inference significantly time consuming  mean field approximation showed work well  returning costs control equal optimal ones  belief
propagation performed similarly  certain value ratio coupling strength
noise level  symmetry breaking control process takes place earlier
mean field approximation compared exact inference  later belief propagation  early symmetry breaking increase costs coordination much 
however  late symmetry breaking does  making performance belief propagation
suboptimal 
variations considered case possible within general framework 
wiegerinck  van den broek  kappen        discuss situations agents sequentially
visit number targets  end time fixed  focusses prefered
trajectories state space time  instead prefered states end time 
achieved modeling path cost way similar modeled end cost 
problem agents intercept moving target noisy dynamics
covered there 
control formalism developed kappen      a      b  applied multi agent
coordination wiegerinck et al         article  demands noise
control act dimensions  one way satisfy constraint assume
agents identical  addition  single agent dynamics
noise control act dimensions  saw two dimensional
second order system section     condition satisfied natural way  however 
general one think examples control problems equation     violated 
interesting future direction research investigate extend path integral
approach used approximation cases 
paper assumes joint state space agents observable agents 
large multi agent systems  however  realistic agent observes
state states agents physically nearby  approach
directly apply situations  depending joint task agents  may
valid approximation optimal control sub system consisting agents
one agent observe  task agents avoid collisions 
sufficient consider states agents nearby  task go
target crucial information states
agents  natural alternative deal partial observability describe multi agent
system decentralized pomdp  seuken   zilberstein         clear however 
approach would combine path integral formalism 
topic learning addressed paper  clearly great
interest  however  one could argue sampling procedure compute path integral
   

fivan den broek  wiegerinck   kappen

corresponds learning environment  discussion line thought
found  kappen        
many possible model extensions worthwhile exploring future research 
obvious examples bounded controls  limited observation global state
system  issues already interest study single agent situation  others
apply typically multi agent situation  context physical agents  introducing penalties collisions agents would become relevant  typically  types
model extensions solution closed form  require additional
approximate numerical methods  suggestions given kappen      a      b  
acknowledgments
thank reviewers useful comments  thank joris mooij making
available useful software  www mbfys ru nl  jorism libdai    research part
interactive collaborative information systems  icis  project  supported dutch
ministry economic affairs  grant bsik      

appendix a  stochastic optimal control
appendix give derivation               starting              
     detailed discussions found many works stochastic optimal control 
example kushner         fleming rishel         fleming         ksendal
        stengel         kappen      a      b  
optimal expected cost to go j state x time defined
j x  t    min c u  x  t  
u


u

c  x  t   

eux t


z
 x t     










 
 
kru x     k   v  x     
 

    

    

expected cost given control law u  equations        
main text  first show j satisfies stochastic hamilton jacobi bellman  shjb 
equation


 
   
 

j   min
kruk    b   u  x j   tr x j   v  
    
u
 
 

boundary condition j x       x   equation derived following way 
moment time holds


z
 
 
u
ds
kru x s   s k   v  x s   s 
j x  t   
c  x       
 



z
 
 
u
kru x s   s k   v  x s   s   
ds
  min ex t j x       
u
 

min eux t
u

first line follows dividing integral two integrals  one
one   using definition cost function c  second line
   

figraphical model inference mas optimal control

follows definition j  rewriting yields


z
j x      j x  t 
 
 
u
 
    min ex t
ds
 
kru x s   s k   v  x s   s   
u


 
taking limit obtain


dj x t   t   
 
u
  kru x t   t k   v  x t   t   
    min ex t
u
dt
 

    

subsequently  apply dj x t   t  well known chain rule diffusion processes 
dj x t   t   

x j x t   t 


xi

dxi  t   

j x t   t 
  x   j x t   t 
dt  
dxi  t dxj  t       

 
xi xj
i j

differs chain rule deterministic processes contains term
quadratic dx  extra term vanish  wiener process appearing
dynamics     quadratic variation increases linear time 
eux t  dwi  t dwj  t     ij dt 

    

follows expectation dxi  t dxj  t  equal    ij dt  substituting dynamics           taking expectation values  using       obtain


 
j x  t 
j x  t 
j x  t 
u
dt    b x  t    u x  t  
dt   tr
dt 
ex t  dj x t   t    

x
xx
substitution equation      yields equation      
minimum right hand side equation      given
u    r r   x j 
optimal control 
minimization      removed inserting optimal control  yields
nonlinear equation j  remove nonlinearity using logarithmic transformation  introduce constant   define z x  t  j x  t    log z x  t  

 
 
u r ru   u x j     z    x z   r r   x z 
 
 


   
 
   
tr x j
 
z  x z  x z z   tr x  z  
 
 
 

terms quadratic x z vanish r related via equation     
   r r    
relation satisfied  shjb equation becomes



v
 

 
z  
b x tr x z

 
  hz 
   

    

fivan den broek  wiegerinck   kappen

h linear operator acting function z 
equation      must solved backwards time boundary condition z x     
 

e  x    present solution terms forward diffusion process  common approach theory stochastic processes give solutions partial differential equations
terms diffusion processes  solution equation      expectation value



z
 
 
z x  t    ex t exp  y t   
v  y       



    

y   process satisfies uncontrolled dynamics
dy     b y     d   dw   
y t    x  expectation ex t taken respect probability measure
y   satisfies uncontrolled dynamics condition y t    x  clear     
matches boundary condition  verify satisfies equation       let


z
 
v  y       
i t    exp

see

 
v  y t   t i t dt 


let f function f  y    exp    y    use chain rule stochastic
processes apply f  y t    find
di t   

k
k
x
f  y t   
  x   f  y t   
dyi  t    
dyi  t  dyj  t  
df  y t     
yi
 
yi yj
i  
i j  


f  y t   
 b y t     d   dw t   
 



 
 
f  y t   
tr
d 
 
yy

choose       dt combine identity previous one
obtain
df  y t   i t    f  y t   di t    i t df  y t   
  hf  y t   i t dt   f  y t   i t dw t   
taking expectation value sides makes term f  y t   i t dw t   disappear 
remaining part 
de  f  y t   i t      f  y t   i t   dt 
equation      
   

figraphical model inference mas optimal control

appendix b  path integral formulation
going write expectation value     path integral  partitioning time
interval n intervals equal length     t    t            tn    
expectation value written follows 
z x  t   

z

dx       

z

 

dxn e  xn  

n
 


z xi     ti     xi   ti  

    

i  

x    x z xi     ti     xi   ti   implicitly defined




z
z

  ti  

dxi   z xi     ti     xi   ti  f  xi       e f  xi     exp
v  y      fiy ti     xi
ti

arbitrary functions f   limit infinitesimal   z xi     ti     xi   ti   satisfy


 
z xi     ti     xi   ti      xi     ti    xi   ti   exp v  xi   ti    
    


 xi     ti    xi   ti   transition probability uncontrolled dynamics     go
 xi   ti    xi     ti     space time  transition probability given


 
k    xi   xi b xi   ti   k 
 
 xi     ti    xi   ti     p
exp
 
det      
follows dynamics

xi   xi   b xi   ti     w
infinitesimal time interval observation wiener process w normally distributed around zero variance   using equation      may rewrite
transition probability

   

 
 
x

x
i  

exp
 xi     ti    xi   ti     p
r
b xi   ti  
    

 
 
 

det    

obtain path integral representation z x  t  combining equations           
     limit going zero 
z x  t    lim z  x    t   

    

 

x    x  t    t 
 



z  x    t      p
det      n

 x            xn   t       xn    

n
 
x

z

dx       

v  xi   ti    

z

n
 
x
i  

i  

   

 

dxn e  x       xn  t   


 

xi   xi
 

b xi   ti  
r
 
 


fivan den broek  wiegerinck   kappen

optimal control given equation     proportional gradient
log z x  t   substituting path integral representation      z x  t   find
u x    t      lim
 

  lim
 

z

z

dx       
dx       

z

z

 

e  x       xn  t   

dxn p
x 
det      n z  x  t   




 
 x            xn   t   


dxn p x            xn   t   u x            xn   t   


u x            xn   t     




x  x 
b x    t   

 

e  x       xn  t   
p x            xn   t      p
 
det      n z  x    t   

note control u x            xn   t    results path  x            xn   depends
first two entries x  x  path 

appendix c  dimension reduction
derivation path integral appendix b given case
state control k dimensional  particular case dimensions
state controlled deduced taking limit infinite control cost along
dimensions without control  control along latter dimensions becomes zero 
seen equation      noise dimensions equal zero accordance
relation      path integral formalism transition probabilities     
reduce delta functions along dimensions without control  implications
mcmc sampling dimension space sample reduced 
since sampling performed dimensions noise 

references
archambeau  c   opper  m   shen  y   cornford  d     shawe taylor  j          variational inference
diffusion processes  advances neural information processing systems 
becker  r   zilberstein  s   lesser  v     goldman  c  v          transition independent decentralized markov decision processes  proceedings second international joint conference
autonomous agents multiagent systems  pp       
becker  r   zilberstein  s   lesser  v     goldman  c  v          solving transition independent
decentralized markov decision processes  journal artificial intelligence research         
    
boutilier  c          planning  learning coordination multiagent decision processes 
proceedings sixth conference theoretical aspects rationality knowledge  pp 
       
castanon  d  a   pachter  m     chandler  p  r          game deception  proceedings
  rd ieee conference decision control  pp           
duane  s   kennedy  a   pendleton  b     roweth  d          hybrid monte carlo  physics letters
b                  
   

figraphical model inference mas optimal control

fleming  w  h          exit probabilities optimal stochastic control  applied mathematics
optimization            
fleming  w  h     rishel  r  w          deterministic stochastic optimal control  springerverlag  new york 
guestrin  c   koller  d     parr  r       a   multiagent planning factored mdps  advances
neural information processing systems  vol      pp           
guestrin  c   venkataraman  s     koller  d       b   context specific multiagent coordination
planning factored mdps  eighteenth national conference artificial intelligence 
pp         
hastings  w          monte carlo sampling methods using markov chains applications 
biometrika                
heskes  t          stable fixed points loopy belief propagation minima bethe free
energy  advances neural information processing systems  vol      pp         
heskes  t   albers  k     kappen  b          approximate inference constrained optimization 
proceedings   th conference uncertainty artificial intelligence  pp         
hu  j   prandini  m     tomlin  c          conjugate points formation constrained optimal
multi agent coordination  case study  siam journal control optimization         
         
jordan  m   ghahramani  z   jaakkola  t     saul  l          introduction variational methods
graphical models  learning graphical models  mit press  cambridge 
kamal  w  a   gu  d  w     postlethwaite  i          real time trajectory planning uavs using
milp  proceedings  th ieee conference decision control  european
control conference       pp           
kappen  h  j       a   path integrals symmetry breaking optimal control theory  journal
statistical mechanics  theory experiment  p      
kappen  h  j       b   linear theory control nonlinear stochastic systems  physical review
letters                  
kappen  h  j          introduction stochastic control theory  path integrals reinforcement
learning  aip conference proceedings  vol       pp         
kleinert  h          path integrals quantum mechanics  statistics  polymer physics  financial markets  world scientific  singapore 
kschischang  f  r   frey  b  j     loeliger  h  a          factor graphs sum product
algorithm  ieee transactions information theory                 
kushner  h  j          stochastic stability control  academic press inc   new york 
larson  r  a   pachter  m     mears  m          path planning unmanned air vehicles
engaging integrated radar network  proceedings aiaa guidance  navigation 
control conference exhibit 
lauritzen  s     spiegelhalter  d          local computations probabilities graphical structures application expert systems  with discussion   j  royal statistical society
series b             
liu  y   cruz  j  b     schumacher  c  j          pop up threat models persistent area denial 
ieee transactions aerospace electronic systems                 
mackay  d  j          information theory  inference  learning algorithms  cambridge university press 
neal  r  m          learning graphical models  pp          kluwer academic publishers 
   

fivan den broek  wiegerinck   kappen

ksendal  b          stochastic differential equations  introduction applications  springerverlag 
pachter  l     pachter  m          optimal paths avoiding radiating source  proceedings
  th ieee conference decision control  pp           
ribichini  g     frazzoli  e          efficient coordination multiple aircraft systems  proceedings
  nd ieee conference decision control  vol     pp           
sadati  n     elhamifar  e          semi decentralized control multi agent systems based
redundant manipulator optimization methods  proceedings  th ieee international
workshop advanced motion control  pp         
seuken  s     zilberstein  s          formal models algorithms decentralized decision making
uncertainty  journal autonomous agents multi agent systems 
shi  x   wang  x   liu  y   wang  c     zu  c          optimization fighter aircraft evasive trajectories radar threats avoidance  proceedings      ieee international conference
control automation  pp         
stengel  r          optimal control estimation  dover publications  new york 
subramanian  s  k     cruz  j  b          adaptive models pop up threats multi agent
persistent area denial  proceedings   nd ieee conference decision control 
pp         
teh  y     welling  m          unified propagation scaling algorithm  advances
neural information processing systems  vol      pp         
todorov  e     li  w          generalized iterative lqg method locally optimal feedback
control constrained nonlinear stochastic systems  proceedings american control
conference  pp         
tomlin  c   pappas  g  j     sastry  s          conflict resolution air traffic management  study
multiagent hybrid systems  ieee transactions automatic control                 
van den broek  b   wiegerinck  w     kappen  b          optimal control large stochastic multiagent systems  proceedings seventh symposium adaptive learning agents
multi agent systems  pp      
van leeuwen  p   hesseling  h     rohling  j          scheduling aircraft using constraint satisfaction 
electronic notes theoretical computer science             
wiegerinck  w   van den broek  b     kappen  b          stochastic optimal control continuous
space time multi agent systems  proceedings   nd conference uncertainty
artificial intelligence  pp         
wiegerinck  w   van den broek  b     kappen  b          optimal on line scheduling stochastic
multi agent systems continuous space time  proceedings sixth international joint
conference autonomous agents multiagent systems  pp         
yedidia  j   freeman  w     weiss  y          generalized belief propagation  advances neural
information processing systems  vol      pp         
yuille  a          cccp algorithms minimize bethe kikuchi free energies  convergent
alternatives belief propagation  neural computation                   

   


