journal of artificial intelligence research                    

submitted        published      

dynamic control in real time heuristic search
vadim bulitko

bulitko   ualberta   ca

department of computing science  university of alberta
edmonton  alberta  t g  e   canada

mitja lustrek

mitja   lustrek   ijs   si

department of intelligent systems  jozef stefan institute
jamova          ljubljana  slovenia

jonathan schaeffer

jonathan   cs   ualberta   ca

department of computing science  university of alberta
edmonton  alberta  t g  e   canada

yngvi bjornsson

yngvi   ru   is

school of computer science  reykjavik university
kringlan    is     reykjavik  iceland

sverrir sigmundarson

sverrir   sigmundarson   landsbanki   is

landsbanki london branch  beaufort house 
   st botolph street  london ec a  qr  great britain

abstract
real time heuristic search is a challenging type of agent centered search because the agents
planning time per action is bounded by a constant independent of problem size  a common problem
that imposes such restrictions is pathfinding in modern computer games where a large number of
units must plan their paths simultaneously over large maps  common search algorithms  e g   a  
ida   d   ara   ad   are inherently not real time and may lose completeness when a constant
bound is imposed on per action planning time  real time search algorithms retain completeness
but frequently produce unacceptably suboptimal solutions  in this paper  we extend classic and
modern real time search algorithms with an automated mechanism for dynamic depth and subgoal
selection  the new algorithms remain real time and complete  on large computer game maps  they
find paths within    of optimal while on average expanding roughly a single state per action  this
is nearly a three fold improvement in suboptimality over the existing state of the art algorithms
and  at the same time  a    fold improvement in the amount of planning per action 

   introduction
in this paper we study the problem of agent centered real time heuristic search  koenig        
the distinctive property of such search is that an agent must repeatedly plan and execute actions
within a constant time interval that is independent of the size of the problem being solved  this
restriction severely limits the range of applicable heuristic search algorithms  for instance  static
search algorithms such as a   hart  nilsson    raphael        and ida   korf         re planning
algorithms such as d   stenz         anytime algorithms such as ara   likhachev  gordon   
thrun        and anytime re planning algorithms such as ad   likhachev  ferguson  gordon 
stentz    thrun        cannot guarantee a constant bound on planning time per action  lrta 
c
    
ai access foundation  all rights reserved 

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

can  but with potentially low solution quality due to the need to fill in heuristic depressions  korf 
      ishida        
as a motivating example  consider an autonomous surveillance aircraft in the context of disaster response  kitano  tadokoro  noda  matsubara  takahashi  shinjou    shimada         while
surveying a disaster site  locating victims  and assessing damage  the aircraft can be ordered to fly
to a particular location  radio interference may make remote control unreliable thereby requiring a
certain degree of autonomy from the aircraft by using ai  this task presents two challenges  first 
due to flight dynamics  the ai must control the aircraft in real time  producing a minimum number
of actions per second  second  the aircraft needs to reach the target location quickly due to a limited
fuel supply and the need to find and rescue potential victims promptly 
we study a simplified version of this problem which captures the two ai challenges while abstracting away from robot specific details  specifically  in line with most work in real time heuristic
search  e g   furcy   koenig        shimbo   ishida        koenig        botea  muller    schaeffer        hernandez   meseguer      a      b  likhachev   koenig        sigmundarson  
bjornsson        koenig   likhachev        we consider an agent on a finite search graph with the
task of traveling a path from its current state to a given goal state  within this context we measure
the amount of planning the agent conducts per action and the length of the path traveled between the
start and the goal locations  these two measures are antagonistic as reducing the amount of planning per action leads to suboptimal actions and results in longer paths  conversely  shorter paths
require better actions that can be obtained by larger planning effort per action 
we use navigation in grid world maps derived from computer games as a testbed  in such games 
an agent can be tasked to go to any location on the map from its current location  examples include
real time strategy games  e g   blizzard         first person shooters  e g   id software         and
role playing games  e g   bioware corp          size and complexity of game maps as well as the
number of simultaneously moving units on such maps continues to increase with every new generation of games  nevertheless  each game unit or agent must react quickly to the users command
regardless of the maps size and complexity  consequently  game companies impose a time peraction limit on their pathfinding algorithms  for instance  bioware corp   a major game company
that we collaborate with  sets the limit to     ms for all units computing their paths at the same time 
search algorithms that produce an entire solution before the agent takes its first action  e g   a 
of hart et al         lead to increasing action delays as map size increases  numerous optimizations
have been suggested to remedy these problems and decrease the delays  for a recent example deployed in a forthcoming computer game refer to sturtevant         real time search addresses the
problem in a fundamentally different way  instead of computing a complete  possibly abstract  solution before the first action is to be taken  real time search algorithms compute  or plan  only a few
first actions for the agent to take  this is usually done by conducting a lookahead search of fixed
depth  also known as search horizon  search depth or lookahead depth  around the agents
current state and using a heuristic  i e   an estimate of the remaining travel cost  to select the next
few actions  the actions are then taken and the planning execution cycle repeats  e g   korf        
since the goal state is not reached by most such local searches  the agent runs the risks of heading
into a dead end or  more generally  selecting suboptimal actions  to address this problem  real time
heuristic search algorithms update  or learn  their heuristic function with experience  most existing
algorithms do a constant amount of planning  i e   lookahead search  per action  as a result  they
tend to waste cpu cycles when the heuristic function is fairly accurate and  conversely  do not plan
enough when the heuristic function is particularly inaccurate  additionally  they compute heuris   

fidynamic c ontrol in r eal  t ime h euristic s earch

tic with respect to a distant global goal state which can put unrealistic requirements on heuristic
accuracy as we demonstrate in this paper 
in this paper we address both problems by making the following three contributions  first  we
propose two ways for selecting lookahead search depth dynamically  on a per action basis  second 
we propose a way for selecting intermediate subgoals on a per action basis  third  we apply these
extensions to the classic lrta   korf        and the state of the art real time pr lrts  bulitko 
sturtevant  lu    yau        and demonstrate the improvements in performance  the resulting
algorithms are the new state of the art in real time search  to illustrate  on large computer game
maps the new algorithms find paths within    of the optimal while expanding only a single state
for any action  for comparison  the previous state of the art  pr lrts  is    times slower per
action while finding paths that are between two and three times more suboptimal  furthermore  the
dynamically controlled lrta  and pr lrts are one to two orders of magnitude faster per action
than a   weighted a  and the state of the art partial refinement a   pra    sturtevant   buro 
       finally  unlike a  and its modern extensions used in games  the new algorithms are provably
real time and do not slow down as maps become larger 
the rest of the paper is organized as follows  in section   we formulate the problem of real time
heuristic search and show how the core lrta  algorithm can be extended with dynamic lookahead
and subgoal selection  section   analyzes related research  section   provides intuition for dynamic
control in search  in section   we describe two approaches to dynamic lookahead selection  one
based on induction of decision tree classifiers  section      and one based on precomputing a depth
table using state abstraction  section       in section   we present an approach to selecting subgoals
dynamically  section   evaluates the efficiency of these extensions in the domain of pathfinding  we
conclude with a discussion of applicability of the new approach to general planning 
this paper extends our conference publication  bulitko  bjornsson  lustrek  schaeffer    sigmundarson        with a new set of features for the decision tree approach  a new way of selecting
subgoals  an additional real time heuristic search algorithm  pr lrta   extended with dynamic
control  numerous additional experiments and a more detailed presentation 

   problem formulation
we define a heuristic search problem as a directed graph containing a finite set of states and weighted
edges  with a single state designated as the goal state  at every time step  a search agent has a single
current state  vertex in the search graph  and takes an action by traversing an out edge of the current
state  each edge has a positive cost associated with it  the total cost of edges traversed by an agent
from its start state until it arrives at the goal state is called the solution cost  we require algorithms
to be complete and produce a path from start to goal in a finite amount of time if such a path exists 
in order to guarantee completeness for real time heuristic search we make the assumption of safe
explorability of our search problems  namely  all costs are finite and the goal state is reachable from
any state that the agent can possibly reach from its start state 
formally  all algorithms discussed in this paper are applicable to any such heuristic search problem  to keep the presentation focused and intuitive as well as to afford a large scale empirical
evaluation  we will use a particular type of heuristic search problems  pathfinding in grid worlds 
for the rest of the paper  however  we will discuss applicability of the new methods we suggest to
other heuristic search problems in section     and to general planning problems in section   
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

in computer game map settings  states are vacant square grid cells  each cell is connected to
four cardinally  i e   west  north  east  south  and four diagonally neighboring cells  outbound
edges of a vertex are moves available in the corresponding cell and in the rest of the paper we
will
 use the terms action and move interchangeably  the edge costs are   for cardinal moves and
  for diagonal moves  an agent plans its next action by considering states in a local search space
surrounding its current position  a heuristic function  or simply heuristic  estimates the  remaining 
travel cost between a state and the goal  it is used by the agent to rank available actions and select
the most promising one  in this paper we consider only admissible heuristic functions which do not
overestimate the actual remaining cost to the goal  an agent can modify its heuristic function in any
state to avoid getting stuck in local minima of the heuristic function  as well as to improve its action
selection with experience 
the defining property of real time heuristic search is that the amount of planning the agent does
per action has an upper bound that does not depend on the problem size  we enforce this property
by setting a real time cut off on the amount of planning for any action  any algorithm that exceeds
such a cut off is discarded  fast planning is preferred as it guarantees the agents quick reaction to a
new goal specification or to changes in the environment  we measure mean planning time per action
in terms of cpu time as well as a machine independent measure  the number of states expanded
during planning  a state is called expanded if all of its successor states are considered generated
in search  the second performance measure of our study is sub optimality defined as the ratio of
the solution cost found by the agent to the minimum solution cost  ratios close to one indicate
near optimal solutions 
the core of most real time heuristic search algorithms is an algorithm called learning realtime a   lrta    korf         it is shown in figure   and operates as follows  as long as the goal
state sglobal goal is not reached  the algorithm interleaves planning and execution in lines   through   
in our generalized version we added a new step at line   for selecting a search depth d and goal sgoal
individually at each execution step  the original algorithm uses fixed d and sglobal goal for all planning
searches   in line    a d ply breadth first search with duplicate detection is used to find frontier states
precisely d actions away from the current state s  for each frontier state s  its value is the sum of
the cost of a shortest path from s to s  denoted by g s  s   and the estimated cost of a shortest path
from s to sgoal  i e   the heuristic value h s  sgoal     we use the standard path max technique  mero 
      to deal with possible inconsistencies in the heuristic function when computing g   h values 
as a result  g   h values never decrease along any branch of such a lookahead tree  the state that
minimizes the sum is identified as sfrontier in line    the heuristic value of the current state s is
updated in line    we keep separate heuristic tables for the different goals   finally  we take one step
towards the most promising frontier state sfrontier in line   

   related research
most algorithms in single agent real time heuristic search use fixed search depth  with a few notable
exceptions  russell and wefald        proposed to estimate the utility of expanding a state and use
it to control lookahead search on line  to do so one needs to estimate how likely an additional search
is to change an actions estimated value  inaccuracies in such estimates and the overhead of metalevel control led to reasonable but unexciting benefits in combinatorial puzzle and pathfinding 
an additional problem is the relatively low branching factor of combinatorial puzzles which makes
it difficult to eliminate parts of search space early on  the same problem is likely to occur in grid   

fidynamic c ontrol in r eal  t ime h euristic s earch

lrta  sstart   sglobal goal  
  s  sstart
  while s    sglobal goal do
 
select search depth d and goal sgoal
 
expand successor states up to d actions away  generating a frontier
 
find a frontier state sfrontier with the lowest g s  sfrontier     h sfrontier   sgoal  
 
update h s  sgoal   to g s  sfrontier     h sfrontier   sgoal  
 
change s one step towards sfrontier
  end while
figure    lrta  algorithm with dynamic control 
based pathfinding  finally  their method adds substantial implementation complexity and requires
non trivial changes to the underlying search algorithm  in contrast  our approach to search depth
selection can be easily interfaced with any real time search algorithm with a search depth parameter
without modifying the existing code 
ishida        observed that lrta  style algorithms tend to get trapped in local minima of their
heuristic function  termed heuristic depressions  the proposed remedy was to switch to a limited
a  search when a heuristic depression is detected and then use the results of the a  search to
correct the depression at once  this is different from our approach in two ways  first  we do not
need a mechanism to decide when to switch between real time and a  search and thus avoid the
need to hand tune control parameters of ishidas control module  instead  we employ an automated
approach to decide on search horizon depth for every action  additionally  we do not spend extra
time filling in all heuristic values within the heuristic depression by a  estimates 
bulitko      a  showed that optimal search depth selection can be highly beneficial in realtime heuristic search  he linked the benefits to avoiding the so called lookahead pathologies where
deeper lookahead leads to worse moves but did not suggest any practical way of selecting lookahead depth dynamically  such a way was proposed in      via the use of a generalized definition
of heuristic depressions  bulitko         the proposed algorithm extends the search horizon incrementally until the search finds a way out of the depression  after that all actions leading to the found
frontier state are executed  a cap on the search horizon depth is set by the user  the idea of precomputing a depth table of heuristic values for real time pathfinding was first suggested by lustrek
and bulitko         this paper extends their work as follows   i  we introduce intermediate goals 
 ii  we propose an alternative approach that does not require map specific pre computation and  iii 
we extend and evaluate a state of the art algorithm in addition to the classic lrta  
there is a long tradition of search control in two player search  high performance game playing
programs for games like chess and checkers rely extensively on search to decide on which actions
to take  the search is performed under strict real time constraints where programs have typically
only minutes or seconds for deliberating on the next action  instead of using a fixed depth lookahead strategy the programs employ sophisticated search control mechanisms for maximizing the
quality of their action decisions within the given time constraints  the search control techniques
can be coarsely divided into three main categories  move ordering  search extensions reductions 
and time allotment  one of the earlier works on dynamic move ordering is the history heuristic technique  schaeffer         and more recent attempts include work on training neural networks  kocsis         there exist a large variety of techniques for adjusting the search horizon
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

for different branches within the game tree  interesting continuations are explored more deeply
while less promising ones are terminated prematurely  whereas most of the early techniques were
static  the research focus has shifted towards more dynamic control as well using machine learning
approaches for automatic parameterization  buro        bjornsson   marsland         to the best
of our knowledge  none of these techniques have been applied to single agent real time search 

   intuition for dynamic search control
it has been observed in the literature that common heuristic functions are not uniformly inaccurate  pearl         namely  they tend to be more accurate closer to the goal state and less accurate
farther away  the intuition for this fact is as follows  heuristic functions usually ignore certain constraints of the search space  for instance  the manhattan distance heuristic in a sliding tile puzzle
would be perfectly accurate if the tiles could pass through each other  likewise  euclidian distance
on a map ignores obstacles  the closer a state is to a goal the fewer constraints a heuristic function
is likely to ignore and  as a result  the more accurate  i e   closer to the optimal solution cost  the
heuristic is likely to be 
this intuition motivates adaptive search control in real time heuristic search  first  when heuristic values are inaccurate  the agent should conduct a deeper lookahead search to compensate for the
inaccuracies and maintain the quality of its actions  deeper lookaheads have been generally found
beneficial in real time heuristic search  korf         though lookahead pathologies  i e   detrimental
effects of deeper lookaheads on action quality  have been observed as well  bulitko  li  greiner   
levner        bulitko      b  lustrek        lustrek   bulitko         as an illustration  consider
figure    every state on the map is shaded according to the minimum lookahead depth that an
lrta  agent should use to select an optimal action  darker shades correspond to deeper lookahead
depths  notice that many areas are bright white  indicating that the shallowest lookahead of depth
one will be sufficient  we use this intuition for our first control mechanism  dynamic selection of
lookahead depth in section   

figure    a partial grid world map from a computer game baldurs gate  bioware corp         
shades of grey indicate optimal search depth values with white representing one ply 
completely black cells are impassable obstacles  e g   walls  
   

fidynamic c ontrol in r eal  t ime h euristic s earch

dynamic search depth selection helps eliminate wasted computation by switching to shallower
lookahead when the heuristic function is fairly accurate  unfortunately  it does not help when the
heuristic function is grossly inaccurate  instead  it calls for very deep lookahead in order to select
an optimal action  such a deep search tremendously increases planning time and  sometimes  leads
to violating a real time cut off on planning time per move  to address this issue  in section   we
propose our second control mechanism  dynamic selection of subgoals  the idea is straightforward 
if being far from the goal leads to grossly inaccurate heuristic values  let us move the goal closer
to the agent  thereby improving heuristic accuracy  we do this by computing the heuristic function
with respect to an intermediate  and thus nearby  goal as opposed to a distant global goal  the
final destination of an agent  since an intermediate goal is closer than the global goal  the heuristic
values of states around an agent will likely be more accurate and thus the search depth picked by
our first control mechanism is likely to be shallower  once the agent gets to an intermediate goal  a
next intermediate goal is selected so that the agent makes progress towards its actual global goal 

   dynamic search depth selection
first  we define optimal search depth as follows  for each  s  sglobal goal   state pair  a true optimal action a  s  sglobal goal   is to take an edge that lies on an optimal path from s to sglobal goal  there can be
more than one optimal action   once a  s  sglobal goal   is known  we can run a series of progressively
deeper lrta  searches from state s  the shallowest search depth that yields a  s  sglobal goal   is the
optimal search depth d  s  sglobal goal    not only may such search depth forfeit lrta s real time
property but it is also impractical to compute  thus  in the following subsections we present two
different practical approaches to approximating optimal search depth  each of them equips lrta 
with a dynamic search depth selection  i e   realizing the first part of line   in figure     the first
approach uses a decision tree classifier to select the search depth based on features of the agents
current state and its recent history  the second approach uses a pre computed depth database based
on an automatically built state abstraction 
    decision tree classifier approach
an effective classifier needs input features that are not only useful for predicting the optimal search
depth  but are also efficiently computable by the agent in real time  the features we use for our
classifier were selected as a compromise between these two considerations  as well as for being domain independent  the features were calculated based on properties of states an agent has recently
visited  as well as features gathered by a shallow pre search from an agents current state  example
features are  the distance from the state the agent was in n steps ago  estimate of the distance to
agents goal  the number of states visited during the pre search phase that have updated heuristics 
in appendix a all the features are listed and the rationale behind them is explained 
the classifier predicts the optimal search depth for the current state  the optimal depth is the
shallowest search depth that returns an optimal action  for training the classifier we must thus label
our training states with optimal search depths  however  to avoid pre computing optimal actions  we
make the simplifying assumption that a deeper search always yields a better action  consequently  in
the training phase the agent first conducts a lookahead search to a pre defined maximum depth  dmax  
to derive the optimal action  under our assumption   the choice of the maximum depth is domain
dependent and would typically be set as the largest depth that still guarantees the search to return
within the acceptable real time requirement for the task at hand  then a series of progressively
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

shallower searches are performed to determine the shallowest search depth  ddt   that still returns
the optimal action  during this process  if at any given depth an action is returned that differs
from the optimal action  the progression is stopped  this enforces all depths from ddt to dmax to
agree on the best action  this is important for improving the overall robustness of classification  as
the classifier must generalize over a large set of states  the depth ddt is set as the class label for the
vector of features describing the current state 
once we have a classifier for choosing the lookahead depth  lrta  can be augmented with it
 line   in figure     the overhead of using the classifier consists of the time required for collecting
the features and running them through the classifier  its overhead is negligible as the classifier itself
can be implemented as a handful of nested conditional statements  collecting the features takes
somewhat more time but  with a careful implementation  such overhead can be made negligible as
well  indeed  the four history based features are all efficiently computed in small constant time  and
by keeping the lookahead depth of the pre search small  e g   one or two  the overhead of collecting
the pre search features is usually dwarfed by the time the planning phase  i e   the lookahead search 
takes  the process of gathering training data and building the classifier is carried out off line and its
time overhead is thus of a lesser concern 
    pattern database approach
a nave approach would be to precompute the optimal depth d for each  s  sgoal   state pair  there
are two problems with this approach  first  d  s  sgoal   is not a priori upper bounded independently
of the map size  thereby forfeiting lrta s real time property  second  pre computing d  s  sgoal  
or a  s  sgoal   for all pairs of  s  sgoal   states on  for instance  a          cell computer game map
has prohibitive time and space complexity  we solve the first problem by capping d  s  sgoal   at a
fixed constant c     henceforth called cap   we solve the second problem by using an automatically built abstraction of the original search space  the entire map is partitioned into regions  or
abstract states  and a single search depth value is pre computed for each pair of abstract states  during run time a single search depth value is shared by all children of the abstract state pair  figure    
the search depth values are stored in a table which we will refer to as pattern database or pdb for
short  in the past  pattern databases have been used to store approximate heuristic values  culberson
  schaeffer        and important board features  schaeffer         our work appears to be the first
use of pattern databases to store search depth values 
computing search depths for abstract states speeds up pre computation and reduces memory
overhead  both important considerations for commercial computer games   in this paper we use
previously published clique abstraction  sturtevant   buro         it preserves the overall topology
of a map but requires storing the abstraction links explicitly   the clique abstraction works by
finding fully connected subgraphs  i e   the cliques  of the original graph and abstracting all states
within such a clique into a single abstract state  two abstract states are connected by an abstract
action if and only if there is a single original action that leads from a state in the first clique to a
state in the single clique  figure     the costs of the abstract actions are computed as euclidean
distances between average coordinates of all states in the cliques 
in typical grid world computer game maps  a single application of clique abstraction reduces
the number of states by a factor of two to four  on average  at the abstraction level of five  i e   after
five applications of the abstraction procedure   each region contains about one hundred original
   an alternative is to use the regular rectangular tiles  e g   botea et al         

   

fidynamic c ontrol in r eal  t ime h euristic s earch

figure    a single optimal lookahead depth value shared among all children of an abstract state 
this is a memory efficient approximation to the true per ground state values in figure   

level    original graph 

level  

level  

figure    two iterations of the clique abstraction procedure produce two abstract levels from the
ground level search graph 
 or ground level  states  thus  a single search depth value is shared among about ten thousand
state pairs  as a result  five level clique abstraction yields a four orders of magnitude reduction in
memory and about two orders of magnitude reduction in pre computation time  as analyzed later  
on the downside  higher levels of abstraction effectively make the search depth selection less and
less dynamic as the same depth value is shared among progressively more states  the abstraction
level for a pattern database is a control parameter that trades pre computation time and pattern
database size for on line performance of the algorithm that uses such a database 
two alternatives to storing the optimal search depth are to store an optimal action or the optimal
heuristic value  the combination of abstraction and real time search precludes both of them  indeed 
sharing an optimal action computed for a single ground level representative of an abstract region
among all states in the region may cause the agent to run into a wall  figure    left   likewise 
sharing a single heuristic value among all states in a region leaves the agent without a sense of
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

a
g

    

    

    

    

    

    

    

    

    

    

a

    

    

    

g

figure    goal is shown as g  agent as a  abstract states are the four tiles separated by dashed lines 
diamonds indicate representative states for each tile  left  optimal actions are shown for
each representative of an abstract tile  applying the optimal action of the agents tile in the
agents current location leads into a wall  right  optimal heuristic value  h   for lower
left tiles representative state        is shared among all states of the tile  as a result  the
agent has no preference among the three legal actions shown 
direction as all states in its vicinity would look equally close to the goal  figure    right   this is in
contrast to sharing a heuristic value among all states within an abstract state  known as pattern 
when using optimal non real time search algorithms such as a  or ida   culberson   schaeffer 
       in the case of real time search  agents using either alternative are not guaranteed to reach
a goal  let alone minimize travel  on the contrary  sharing the search depth among any number of
ground level states is safe because lrta  is complete for any search depth 
we compute a single depth table per map off line  figure     in line   the state space is abstracted   times  lines   through   iterate through all pairs of abstract states  for each pair  s    s goal   
representative ground level states s and sgoal  i e   ground level states closest to centroids of the regions  are picked and the optimal search depth value d is calculated for them  to do this  dijkstras
algorithm  dijkstra        is run over the ground level search space  v  e  to compute the true
minimal distances from any state to sgoal   once the distances are known for all successors of s  an
optimal action a  s  sgoal   can be computed greedily  then the optimal search depth d  s  sgoal   is
computed as previously described and capped at c  line     the resulting value is stored for the pair
of abstract states  s    s goal   in line    figures   and   show optimal search depth values for a single
goal state on a grid world game map with and without abstraction respectively 
during run time  an lrta  agent going from state s to state sgoal takes its search depth from the
depth table value for the pair  s    s goal    where s  and s goal are images of s and sgoal under an   level
abstraction  the additional run time complexity is minimal as s    s goal   d s    s goal   can be computed
with a small constant time overhead on each action 
in building such a pattern database dijkstras algorithm is run v  times  on the graph  v  e 
 a time complexity of o v   v log v   e   on sparse graphs  i e   e   o v     the optimal
search depth is computed v   times  each time  there are at most c lrta  invocations with the total
   for brevity  we use v and e to mean both sets of vertices edges and their sizes  i e    v   and  e   

   

fidynamic c ontrol in r eal  t ime h euristic s earch

buildpatterndatabase v  e  c    
  apply an abstraction procedure   times to  v  e  to compute abstract space s     v    e   
  for each pair of states  s    s goal    v   v  do
 
select s  v as a representative of s   v 
 
select sgoal  v as a representative of s goal  v 
 
compute c capped optimal search depth value d for state s with respect to goal sgoal
 
store capped d for pair  s    s goal  
  end for
figure    pattern database construction 
complexity of o bc   where b is the maximum degree of v   thus  the overall time complexity is
o v   v log v   e   v  bc     the space complexity is lower because we store optimal search depth
values only for all pairs of abstract states  o v      table   lists the bounds for sparse graphs 
table    reduction in complexity due to state abstraction 

time
space

no abstraction
o v   log v  
o v    

  level abstraction
o v  v log v  
o v    

reduction
v  v 
 v  v    

    discussion of the two approaches
selecting the search depth with a pattern database has two advantages  first  the search depth values
stored for each pair of abstract states are optimal for their non abstract representatives  unless either
the value was capped or the states in the local search space have been visited before and their heuristic values have been modified  this  conditional  optimality is in contrast to the classifier approach
where no optimal actions are ever computed as deeper searches are merely assumed to lead to a
better action  the assumption does not always hold  a phenomenon known as lookahead pathology  found in abstract graphs  bulitko et al         as well as in grid based pathfinding  lustrek  
bulitko         the second advantage is that we do not need features of the current state  recent
history and pre search  the search depth is retrieved from the depth table simply on the basis of the
current states identifier  such as its coordinates 
the decision tree classifier approach has two advantages over the depth table approach  first 
the classifier training does not need to happen in the same search space that the agent operates in  as
long as the training maps used to collect the features and build the decision tree are representative
of run time maps  this approach can run on never before seen maps  e g   user created maps in
a computer game   second  there is a much smaller memory overhead with this method as the
classifier is specified procedurally and no pattern database needs to be loaded into memory 
note that both approaches assume that there is a structure to the heuristic search problem at
hand  namely  the pattern database approach shares a single search depth value across a region of
states  this works most effectively if the states in the region are indeed such that the same lookahead
depth is the best for all of them  our abstraction mechanism forms regions on the basis of the search
graph structure  with no regard for search depth  as the empirical study will show  clique abstraction
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

seems to be the right choice for pathfinding  however  the choice of the best abstraction technique
for a general heuristic search problem is an open question 
similarly  the decision tree approach assumes that states that share similar feature values will
also share the best search depth value  it appears to hold to a large extent in our pathfinding domain
but feature selection for arbitrary heuristic search problems is an open question as well 

   dynamic goal selection
the two methods just described allow the agent to select an individual search depth for each state 
however  as in the original lrta   the heuristic is still computed with respect to the global goal
sgoal   to illustrate  in figure    the map is partitioned into eight abstract states  in this case      
square tiles  whose representative states are shown as diamonds       an optimal path between
the agent  a  and the goal  g  is shown as well  a straight line distance heuristic will ignore the
wall between the agent and the goal and will lead the agent in a south western direction  an lrta 
search of depth    or higher is needed to produce an optimal action  such as    thus  for any
cap value below     the agent will be left with a suboptimal action and will spend a long time
above the horizontal wall raising heuristic values  spending large amounts of time in corners and
other heuristic depressions is the primary weakness of real time heuristic search agents and  in this
example  is not remedied by dynamic search depth selection due to the cap 

 

 

 

 

a

 

g

 

 

 

figure    goal is shown as g  agent as a  abstract states are the eight tiles separated by dashed
lines  diamonds indicate ground level representative for each tile  an optimal path is
shown  entry points of the path into abstract states are marked with circles 

 a compute sintermediate goal goal for  s  sgoal  
 b compute capped optimal search depth value d for s with respect to sintermediate goal
  store  d   sintermediate goal   for pair  s    s goal  
figure    switching sgoal to sintermediate goal   replaces lines    of figure   
   

fidynamic c ontrol in r eal  t ime h euristic s earch

figure    the three maps used in our experiments 
to address this issue  we switch to intermediate goals in our pattern database construction as well as
on line lrta  operation  in the example in figure   we now compute the heuristic around a with
respect to an intermediate goal marked with a double border circle on the map  consequently  an
eleven times shallower search depth is needed for an optimal action towards the next abstract state
 right most upper tile   our approach replaces lines       in figure   with those in figure    in line
 a  we compute an intermediate goal sintermediate goal as the ground level state where an optimal path
from s to sgoal enters the next abstract state  these entry points are marked with circles in figure   
we compared entry states to centroids of abstract states as intermediate goals  bulitko et al        
and found the former superior in terms of algorithms performance  note that an optimal path is
easily available off line after we run the dijkstras algorithm  section      
once an intermediate goal is computed  line  b computes a capped optimal search depth for s
with respect to the intermediate goal sintermediate goal   the depth computation is done as described
in section      the search depth and the intermediate goal are then added to the pattern database
in line    at run time  the agent executes lrta  with the stored search depth and computes the
heuristic h with respect to the stored goal  i e   sgoal is set to sintermediate goal in line   of figure     in
other words  both search depth and agents goal are selected dynamically  per action 
this approach works because heuristic functions used in practice tend to become more accurate for states closer to the goal state  therefore  switching from a distant global goal to a nearby
intermediate goal makes the heuristics around the current state s more accurate and leads to a shallower search depth necessary to achieve an optimal action  as a result  not only does the algorithm
run more quickly with the shallower search per move but also the search depth cap is reached less
frequently and therefore most search depth values actually result in optimal moves 

   empirical evaluation
this section presents results of an empirical evaluation of algorithms with dynamic control of search
depth and goals against classic and state of the art published algorithms  all algorithms avoid reexpanding states during planning for each move via a transposition table  we report sub optimality
in the solution found and the average amount of computation per action  expressed in the number
of states expanded  we believe that all algorithms can be implemented in such a way that a single
expanded state takes the same amount of time  this was not the case in our testbed as some code
was more optimized than other  for that reason and to avoid clutter  we report cpu times only in
section      we used a fixed tie breaking scheme for all real time algorithms 
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

we use grid world maps from a computer game as our testbed  game maps provide a realistic
and challenging environment for real time search and have been seen in a number of recent publications  e g   nash  daniel    felner        hernandez   meseguer         the original maps were
sized        to        cells  figure     in line with sturtevant and buro        and sturtevant
and jansen         we also experimented with the maps upscaled up to           closer in size
to maps used in modern computer games  note that while all three maps depicted in the figure are
outdoor type maps  we also ran preliminary experiments in indoor type game maps  e g   the one
shown in figure     the trends were similar and we decided to focus on the larger outdoor maps 
there were     search problems defined on each of the three original size maps  the start and
goal locations were chosen randomly  although constrained such that optimal solution paths cost
between    and     in order to generate more difficult instances  the upscaled maps had the    
problems upscaled as well  each data point in the plots below is an average of     problems   
maps     runs each   a different legend entry is used for each algorithm  and multiple points
with the same legend entry represent alternative parameter instantiation of the same algorithm  the
heuristic function used is octile distance  a natural extension of the manhattan distance for maps
with diagonal actions  to enforce the real time constraint we disqualified all parameter settings that
caused an algorithm to expand more than      states for any move on any problem  such points
were excluded from the empirical evaluation  maps were known a priori off line in order to build
decision tree classifiers and pattern databases 
we use the following notation to identify all algorithms and their variants  algorithmname
 x  y  where x and y are defined as follows  x denotes search depth control  f for fixed search
depth  dt for search depth selected dynamically with a decision tree  oracle for search depth
selected with a decision tree oracle  see the next section for more details  and pdb for search depth
selected dynamically with pattern databases  y denotes goal state selection  g when the heuristic
is computed with respect to a single global goal  pdb when the heuristic is computed with respect
to an intermediate goal with pattern databases  for instance  the classic lrta  is lrta   f  g  
our empirical evaluation is organized into eight parts as follows  section     describes six
algorithms that compute their heuristic with respect to a global goal and discusses their performance 
section     describes five algorithms that use intermediate goals  section     compares global and
intermediate goals  section     studies the effects of path refinement with and without dynamic
control  secton     pits the new algorithms against state of the art real time and non real time
algorithms  we then provide an algorithm selection guide for different time limits on planning per
move in section      finally  section     considers the issue of amortizing off line pattern database
build time over on line pathfinding 
    algorithms with global goals
in this subsection we describe the following algorithms that compute their heuristic with respect to
a single global goal  i e   do not use intermediate goals  
   lrta   f  g  is learning real time a   korf         for each action it conducts a breadthfirst search of fixed depth d around the agents current state  then the first move towards
the best depth d state is taken and the heuristic of the agents previous state is updated using
korfs mini min rule   we used d                     
   instead of using lrta  we could have used rta   our experiments showed that in grid pathfinding there is no
significant performance difference between the two for a search depth beyond one  indeed for deeper searches the

   

fidynamic c ontrol in r eal  t ime h euristic s earch

   lrta   dt  g  is lrta  in which the search depth d is dynamically controlled by a decision
tree as described in section      we used the following parameters  dmax                 
and a history trace of length n       for building the decision tree classifier in weka  witten   frank        the pruning factor was set to      and the minimum number of data items
per leaf to     for the original size maps and    for the upscaled ones  as opposed to learning
a tailor made classifier for each game map  a single common decision tree classifier was built
based on data collected from all the maps  using    fold cross validation   this was done to
demonstrate the ability of the classifier to generalize across maps 
   lrta   oracle  g  is lrta  in which the search depth is dynamically controlled by
an oracle  such an oracle always selects the best search depth to produce a move given by
lrta   f  g  with a fixed lookahead depth dmax  bulitko et al          in other words 
the oracle acts as a perfect decision tree and thus sets an upper bound on lrta   dt  g 
performance  the oracle was run for dmax                   and only on the original size
maps as it proved prohibitively expensive to compute it for upscaled maps  note that this is
not a practical real time algorithm and is used only as a reference point in our experiments 
   lrta   pdb  g  is lrta  in which the search depth d is dynamically controlled by a
pattern database as described in section      for original size maps  we used an abstraction
level                      and a depth cap c                              for upscaled maps 
we used an abstraction level                      and a depth cap c                             
considering the size of our maps  a cap value of      or      means virtually capless search 
   k lrta   f  g  is a variant of lrta  proposed by koenig         unlike the original
lrta   it uses a  shaped lookahead search space and updates heuristic values for all states
within it using dijkstras algorithm   the number of states that k lrta  expands per move
took on these values                                        
   p lrta   f  g  is prioritized lrta   a variant of lrta  proposed by rayner  davison 
bulitko  anderson  and lu         it uses a lookahead of depth   for all moves  however  for
every state whose heuristic value is updated  all its neighbors are put onto an update queue 
sorted by the magnitude of the update  thus  the algorithm propagates heuristic function
updates in the space in the fashion of prioritized sweeping  moore   atkeson         the
control parameter  queue size  was set to                                       for original
size maps and                            for upscaled maps 
in figure    we evaluate the performance of the new dynamic depth selection algorithms on the
original size maps  we see that both the decision tree and the pattern database approach do improve
significantly upon the lrta  algorithm  expanding two to three times fewer states for generating
solutions of comparable quality  furthermore  they perform on par with current state of the art realtime search algorithms without abstraction  as can seen when compared with k lrta   f  g   the
solutions generated are of acceptable quality for our domain  e g       suboptimal   even when
expanding only     states per action  also of interest is that the decision tree approach performs
likelihood of having multiple actions with equally low g   h cost is very high  reducing the distinction between rta 
and lrta   by using lrta  we can have agents learn over repeated trials 
   we also experimented with a  shaped lookahead in our new algorithms and found it inferior to breadth first lookahead for deeper searches 

   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

original size maps

realtime cutoff      

 
lrta   f  g 
lrta   oracle  g 
lrta   dt  g 
lrta   pdb  g 
p lrta   f  g 
k lrta   f  g 

suboptimality  times 

   
 
   
 
   

 

 

   

   
   
   
mean number of states expanded per move

   

   

figure     global goal algorithms on original size maps 
quite close to its theoretical best case  as seen when compared to lrta   oracle  g   this
shows that the features we use  although seemingly simplistic  do a good job at predicting the most
appropriate search depth 
we ran similar sets of experiments on the upscaled maps  however  none of the global goal
algorithms generated solutions of acceptable quality given the real time cut off  the solutions were
between     and       suboptimal   the experimental results for the upscaled maps are provided
in appendix b  this shows the inherent limitations of global goal approaches  in large search
spaces they cannot compete on equal footing with abstraction based methods  this brings us to the
intermediate goal selection methods 
    algorithms with intermediate goals
in this section we describe the algorithms that use intermediate goals during search  to the best
of our knowledge  there is only one previously published real time heuristic search algorithm that
does so  thus  we compare it to the new algorithms proposed in this paper  given that intermediate
goals increase the performance of all algorithms significantly  we present results only on the more
challenging upscaled maps  the full roster of algorithms used in this section is as follows 
   pr lrta   f  g  is path refinement learning real time search  bulitko et al         
the algorithm has two components  it runs lrta  with a fixed search depth d and a global
goal in an abstract space  abstraction level   in a clique abstraction hierarchy  and refines
the first move using a corridor constrained a  running on the original ground level map  
constraining a  to a small set of states  collectively called a corridor by sturtevant and buro
   the algorithm was actually called pr lrts  bulitko et al          based on findings by lustrek and bulitko        
we modified it to refine only a single abstract action in order to reduce its susceptibility to lookahead pathologies 
this modification is equivalent to substituting the lrts component with lrta   hence  in the rest of the paper  we
call it pr lrta  

   

fidynamic c ontrol in r eal  t ime h euristic s earch

       or tunnel by furcy         speeds it up and makes it real time if the corridor size
is independent of map size  bulitko  sturtevant    kazakevich         while the heuristic
is computed in the abstract space with respect to a fixed global goal  the a  component
computes a path from the current state to an intermediate goal  this qualifies pr lrta  to
enter this section of empirical evaluation  the control parameters are as follows  abstraction
level                       lrta  lookahead depth d                    and lrta  heuristic
weight                          is imposed on g in line   of figure    
   lrta   f  pdb  is lrta  with fixed search depth that uses a pattern database only to select
intermediate goals  the control parameters are as follows  abstraction level                     
and search depth d                                                                
   lrta   pdb  pdb  is lrta  generalized with dynamic search depth and intermediate goal selection with pattern databases as presented in sections     and    the control parameters are as follows  abstraction level                      and lookahead cap
c                             
   pr lrta   pdb  g  is pr lrta  whose lrta  component is equipped with dynamic search depth but uses a global  abstract  goal with respect to which it computes its abstract heuristic  the pattern database for the search depth is constructed
for the same abstraction level   that the lrta  component runs on  making the component as optimal as the lookahead cap allows  we used abstraction level   
                  and lookahead cap c                        
we also ran a version of pr lrta   pdb  g  where the pattern database is constructed at abstraction level    above the level   where lrta  operates  table     we used          
                                                                                 
   pr lrta   pdb  pdb  is the same as the two database version of pr lrta   pdb  g 
except it uses the second database for goal selection as well as depth selection  we used
                                                                                            table    
table    pr lrta   pdb  g and pdb  uses lrta  at abstraction level   to define a corridor within
which it refines the path using a   dynamic depth  and goal  selection is performed either
at abstraction level   or        
abstraction level
  
 
 

single abstraction pr lrta  pdb g 
abstract level lrta 
dynamic depth selection
corridor constrained ground level a 

dual abstraction pr lrta  pdb  g pdb  
dynamic depth  and goal  selection
abstract level lrta 
corridor constrained ground level a 

the pattern database for the algorithms presented above stores a depth value and an intermediate
ground level goal for each pair of abstract states  we present performance results for algorithms
with intermediate goals in sections        and then analyze the complexity of pattern database
computation and its effects on performance in section     
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

upscaled maps

realtime cutoff       

  
lrta   f  g 
lrta   f  pdb 

  

suboptimality  times 

  
  
  
  
 
 
 
 
 

   

   

   
   
    
    
mean number of states expanded per move

    

    

figure     effects of intermediate goals  lrta   f  g  versus lrta   f  pdb  

    global versus intermediate goals
sections     and     presented algorithms with global and intermediate goals respectively  in this
section we compare algorithms across the two groups  to include lrta   pdb  g   we increased
the real time cut off from      to       for all graphs in this section  we start with the baseline lrta  with fixed lookahead  the effects of adding intermediate goal selection are dramatic 
lrta  with intermediate goals  f  pdb  finds five times better solutions while being three orders
of magnitude faster than lrta  with global goals  f  g   see figure      we believe that this is a
result of the octile distance heuristic being substantially more accurate around a goal  consequently 
lrta   f  pdb  is benefiting from a much better heuristic function 
in the second experiment  we equip both versions with dynamic search depth control and compare lrta   pdb  g  with lrta   pdb  pdb  in figure     the performance gap is now less
dramatic  while the planning speed up is still around three orders of magnitude  the suboptimality
advantage went down from five to two times  again  note that we had to increase the real time
cut off by an order of magnitude to get more points in the plot 
finally  we evaluate what is more beneficial  dynamic depth control or dynamic goal control by
comparing the baseline lrta   f  g  with lrta   pdb  g  and lrta   f  pdb  in figure     it is
clear that dynamic goal selection is a much stronger addition to the baseline lrta  than dynamic
search depth selection  dynamic depth selection sometimes actually performs worse than fixed
depth  as evidenced by the data points above the lrta   f  g  line  this happens primarily with
high abstraction levels and small caps  when the optimal lookahead depth is computed at a high
abstraction level  the same depth value is shared among many ground level states  the selected
depth value can be beneficial near the entry point into the abstract state  but if the abstract state
is too large  the depth is likely to become inappropriate for ground level states further away  for
example  if the optimal depth at the entry point is    it can be worse than a moderate fixed depth
   

fidynamic c ontrol in r eal  t ime h euristic s earch

upscaled maps

realtime cutoff       
lrta   pdb  g 
lrta   pdb  pdb 

  

suboptimality  times 

  
  
 
 
 
 
 

   

   

   
   
   
   
mean number of states expanded per move

   

   

figure     effects of intermediate goals  lrta   pdb  g  versus lrta   pdb  pdb  
upscaled maps

realtime cutoff       

  
lrta   f  g 
lrta   f  pdb 
lrta   pdb  g 

  

suboptimality  times 

  
  
  
  
 
 
 
 
 

   

   

   
   
    
    
mean number of states expanded per move

    

    

figure     dynamic search depth control versus dynamic goal control 

in ground level states far from the entry point  small caps compound the problem by sometimes
preventing the selection of the optimal depth even at the entry point 
while not shown in the plot  running both  i e   lrta   pdb  pdb   leads to only marginal further improvements  this is because the best parameterizations of lrta   f  pdb  already expands
only a single state per move virtually at all times  consequently  the only benefit of adding dynamic
depth control is a slight improvement in suboptimality  more on this in the next section 
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

upscaled maps

realtime cutoff      

   
lrta   f  pdb 
lrta   pdb  pdb 
pr lrta   f  g 
pr lrta   f  pdb 
pr lrta   pdb  pdb 
pr lrta   pdb  g 

suboptimality  times 

   

   

   

   

 

 

 

  
  
mean number of states expanded per move

  

  

figure     effects of path refinement  lrta  versus pr lrta  
    effects of path refinement
path refinement algorithms  denoted by the pr prefix  run learning real time search  lrta   in an
abstract space and refine the path by running a  at the ground level  non pr algorithm do not run
a  at all as their real time search happens in the ground level space  we examine the effects of pathrefinement by comparing lrta  and pr lrta   note that even the statically controlled baseline
pr lrta   f  g  uses intermediate goals in refining its abstract actions  we match it by using
dynamic intermediate goal selection in lrta   thus  we compare four versions of pr lrta    f 
g    pdb  g    f  pdb  and  pdb  pdb  to two versions of lrta    f  pdb  and  pdb  pdb  
the results are found in figure     for the sake of clarity  we show the high performance area by
capping the number of states expanded per move at    and suboptimality at     
the best parameterizations of lrta  find near optimal solutions while expanding just one state
per move at virtually all times  this is astonishing performance because one state expansion per
move corresponds to search depth of one and is the fastest possible operation of any algorithm in
our framework  thus  lrta   f  pdb  and lrta   pdb  pdb  are virtually unbeatable in terms of
planning time  on the other hand  pr lrta  incurs planning overhead due to its path refinement
component  i e   running a corridor constrained a    as a result  pr lrta  also finds nearlyoptimal solutions but incurs at least five times higher planning cost per move  dynamic control in
pr lrta  results in moderate performance gains 
    comparison to the existing state of the art
traditionally  computer games have used a  for pathfinding needs  stout         as map size and
the number of simultaneously planning agents increase  game developers find even highly optimized
implementations of a  insufficient  as a result  variants of a  that use state abstraction have been
used  sturtevant         another way of speeding up a  is to introduce a weight in computing travel
cost through a state  if this is done as f   g   h      then values of  below   make the agent
   

fidynamic c ontrol in r eal  t ime h euristic s earch

more greedy  more weight is put on h  which usually leads to fewer states expanded at the price of
suboptimal solutions  in this section  we compare the new algorithms to weighted a   korf       
and state of the art partial refinement a   pra    sturtevant   buro         note that neither
algorithm is real time and  thus  the planning times per move are map size specific  that is  with
larger maps  a s and pra s planning times per move will increase as these algorithms compute a
complete  abstract  path between start and goal states before they take the first move  for instance 
for the maps we used pra  expands      states on its most expensive move  weighted a  with
      expands       states and the classic a  expands       states on their worst moves  thus  to
include these two algorithms in our comparison we had to effectively remove the real time cut off 
the results are found in table    dynamically controlled lrta  is one to two orders of magnitude faster in average planning time per move  it produces shorter paths than the existing stateof the art real time algorithm  pr lrta   and the fastest weighted a  we tried  the original a 
is provably optimal in solution quality and pra  is nearly optimal  we argue that with hundreds
of units simultaneously planning their paths in a computer game  lrta   pdb  pdb s low planning time per move and real time guarantees are worth its      path length suboptimality  e g      
screen pixels versus the optimal     screen pixels  

table    comparison of high performance algorithms  best values are in bold  standard errors are
reported after  
algorithm  parameters
pr lrta   f  g          d            
lrta   pdb  pdb          c       
a 
weighted a   f      g   h
pra 

planning per move
            
            
            
            
            

suboptimality  times 
            
            
      
            
            

    best solution quality under a time limit
in this section we identify the algorithms that deliver the best solution quality under a time limit 
specifically  we impose a hard limit on planning time per move  expressed in the number of states
expanded  any algorithm that exceeds the limit on even a single move made in any of the    
problems on upscaled maps is excluded from consideration  among the remaining algorithms  we
select the one with the highest solution quality  i e   the lowest suboptimality   the results are found
in table    all algorithms expand at least one state per move for some move  leaving the first row
empty  lrta   f  pdb  d            is the best choice when the time limit is between one and
eight states expanded per move  as the limit rises  more expensive but more optimal algorithms
become affordable  note that all the best choices are dynamically controlled algorithms until the
time limit rises to      states  at this point  non real time pra  takes over ending the domain
of real time algorithms  such cross over point is specific to problem and map sizes  with larger
problems maps  pra s maximum planning time per move will necessarily increase  making it the
best choice only for progressively higher planning time per move limits 
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

table    best solution quality under a strict limit on planning time per move  planning time is
in the states expanded per move  for the sake of readability  suboptimality is shown as
percentage  e g                        
planning time limit
 
      
       
        
         
          
          
           
            
            
             
         

algorithm  parameters
lrta   f  pdb  d           
lrta   f  pdb  d           
lrta   f  pdb  d           
lrta   f  pdb  d           
lrta   f  pdb  d           
lrta   f  pdb  d            
pr lrta   pdb  g  c                    
pr lrta   pdb  g  c                    
pr lrta   pdb  g  c                      
pra 
a 

suboptimality    
        
       
       
       
       
       
       
       
       
       
  

    amortization of pattern database build time
our pattern database approach invests time into computing a pdb for each map  in this section
we study the amortization of this off line investment over multiple problem instances  pdb build
times on a   ghz pentium cpu are listed in table   for a single map  consider algorithm lrta 
 pdb  pdb  with a cap c      and with pattern databases built at level        on average  it has
solution suboptimality of       while expanding       states per move in        microseconds  its
closest statically controlled competitor is pr lrta   f  g  with        d              which has
suboptimality of       while expanding an average of       states per move in         microseconds  thus  lrta   pdb  pdb  is about     microseconds faster on each move  consequently 
         moves are necessary to recoup the off line pdb build time of    hours  with each move
taking about    microseconds  lrta  will have a lower total run time after the first four hours
of pathfinding  we computed such recoup times for all parameterizations of lrta   pdb  pdb 
whose closest statically controlled competitor was slower per move  the results are found in table  
and demonstrate that lrta   pdb  pdb  recoups the pdb build time in the first     to    hours of
its pathfinding time  note that the numbers are highly implementation and domain specific  in particular  our code for building pdbs leaves substantial room for optimization  for the completeness
sake  we report detailed times in appendix c 

   discussion of empirical results
in this section we recap the trends we have observed in the previous sections  dynamic selection of
lookahead with either the decision tree or the pdb approach helps reduce planning time per move
as well as solution suboptimality  section       as a result  lrta  becomes competitive with such
modern algorithms as koenigs lrta   however  all real time search algorithms with global goals
do not scale well to large maps 
   

fidynamic c ontrol in r eal  t ime h euristic s earch

table    pattern database for an average        map  computed for intermediate goals  database
size is listed as the number of abstract state pairs  suboptimality and planning per move
are listed for a representative algorithm  lrta   pdb  pdb  with a cap c      
abstraction level
 
 
 
 
 
 
 
 

size
         
        
        
        
        
        
        
        

time
est    years
est      months
est    days
   hours
  hours
  hour
   minutes
   minutes

planning per move
   
   
    
     
     

suboptimality  times 
     
     
     
     
     

table    amortization of pdb build times  for each dynamically controlled lrta   we list the
statically controlled pr lrta  that is the closest in terms of solution suboptimality 
lrta   pdb  pdb 
c            
c            
c            
c            
c            
c            
c            
c            

pr lrta   f  g 
       d             
       d             
       d             
       d             
       d             
       d             
       d             
       d             

amortization moves
        
        
        
        
        
        
        
        

amortization run time
  hours
    hours
    hours
  hours
    hours
  hours
     hours
   hours

adding intermediate goals brings even the classic lrta  on par with the previous state of theart real time search algorithm pr lrta  and is a much stronger addition than dynamic lookahead
depth selection  section       using both dynamic lookahead depth and subgoals brings further
improvements  as section     details  lrta  equipped with both dynamic lookahead depth and
subgoal selection expands barely over a state per move and has less than    solution suboptimality 
while it is not better than previous state of the art algorithms pr lrta   pra  and a  in both
solution quality and planning time per move  we believe that the trade offs it makes are appealing in
practice  to aid practitioners further  we provide an algorithm selection guide in section     which
makes it clear that lrta  with dynamic subgoal selection are the best algorithms when the time
per move is severely limited  the speed advantage they deliver over the state of the art pr lrta 
algorithm allows them to recoup the pdb build time in several hours of pathfinding 

   current limitations and future work
this project opens several interesting avenues for future research  in particular  it would be worthwhile to investigate performance of the algorithms in this paper in dynamic environments  e g   a
bridge gets destroyed in a real time strategy game or the goal moves away from the agent  
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

another area of future research is application of the proposed algorithms to general planning 
heuristic search has been a successful approach in planning with such planners as asp  bonet 
loerincs    geffner         the hsp family  bonet   geffner         ff  hoffmann        
sherpa  koenig  furcy    bauer        and ldfs  bonet   geffner         in line with recent
planning work  likhachev   koenig        and bonet and geffner         we did not evaluate
proposed algorithms for general strips style planning problem  nevertheless  we do believe that
our new real time heuristic search algorithms may also offer benefits to a wider range of planning
problems  indeed  the core heuristic search algorithm extended in this paper  lrta   was previously applied to general planning  bonet et al          the extensions we introduced may have a
beneficial effect in a similar way to how the b lrta  improved the performance of asp planner 
subgoal selection has been long studied in planning and is a central part of our intermediate goal
depth table approach  decision trees for search depth selection are induced from sample trajectories through the space and appear scalable to general planning problems  the only part of our
approach that requires solving numerous ground level problems optimally is pre computation of
optimal search depth in the pdb approach  we conjecture that the approach will still be effective if 
instead of computing the optimal search depth based on an optimal action a   one were to solve a
relaxed planning problem and use the resulting action in place of a   the idea of deriving heuristic
guidance from solving relaxed problems is quite common to both planning and the heuristic search
community 

    conclusions
real time pathfinding is a non trivial problem where algorithms must trade solution quality for the
amount of planning per move  these two measures are antagonistic and thus we are interested in
pareto optimal algorithms which are not outperformed in both measures by any other algorithms 
the classic lrta  provides a smooth trade off curve  parameterized by the lookahead depth  since
its introduction in       a variety of extensions have been proposed  the most recent extension 
pr lrts  bulitko et al         was the first application of automatic state abstraction in real time
search  in a large scale empirical study with pathfinding on game maps  pr lrts outperformed
many other algorithms with respect to several antagonistic measures  bulitko et al         
in this paper we also employ automatic state abstraction but instead of using it for pathrefinement  we pre compute pattern databases and use them to select the amount of planning and
intermediate goals dynamically  per move  several mechanisms for such dynamic control are proposed and can be used with virtually any existing real time search algorithm  as a demonstration 
we equip both the classic lrta  and the state of the art pr lrts with our dynamic control  the
resulting improvements are substantial  for instance  lrta  equipped with pdb based control for
lookahead and intermediate goal selection significantly outperforms the existing state of the art  pr
lrts  simultaneously in planning per move and solution quality  furthermore  on average it expands only a little more than one state per move which is the minimum amount of planning for an
lrta  based algorithm 
the new algorithms compare favorably to a  and its state of the art extension  pra   which
are presently popular industrial choices for pathfinding in computer games  stout        sturtevant 
       first  per move planning time of our algorithms is provably unaffected by any increase in
map size  second  we are two orders of magnitude faster than a  and one order of magnitude
faster than pra  in planning time per move  these improvements come at the price of about   
   

fidynamic c ontrol in r eal  t ime h euristic s earch

suboptimality  likely to be unnoticed by a computer game player in most scenarios  thus it appears
that not only the new algorithms redefine the state of the art in the real time search arena but also
that they are well suited for industrial applications 

acknowledgments
sverrir sigmundarson was at the school of computer science  reykjavik university during this
project  we appreciate consultation by robert c  holte and detailed feedback from the anonymous
reviewers  this research was supported by grants from the national science and engineering research council of canada  nserc   albertas informatics circle of research excellence  icore  
slovenian ministry of higher education  science and technology  icelandic centre for research
 rannis   and by a marie curie fellowship of the european community programme structuring
the era under contract number mirg ct              special thanks to nathan sturtevant for
his development and support of hog 

appendix a  decision tree features
we devised two different categories of classifier features  the first consists of features based on the
agents recent history  whereas the second contains features sampled by a shallow pre search from
the agents current state  thus  collectively  the features in the two categories make predictions
based on both the agents recent history as well as its current situation 
the first category has the four features listed in table    these features are computed at each
execution step  some of them are aggregated over the most recent states the agent was in  which is
done in an incremental fashion for an improved performance  the parameter n is set by the user and
controls how long a history to aggregate over  we use the notation s  to refer to the state the agent
was in one step ago  s  for the state two steps ago  etc   the agent thus aggregates over states s   
     sn   feature f  provides a rough estimate of the location of the agent relative to the goal  the
distance to the goal state can affect the required lookahead depth  for example because heuristics
closer to the goal are usually more accurate  this feature makes it possible for the classifier to make
decisions based on that if deemed necessary  features f   known as mobility  and f  provide a
measure of how much progress the agent has made towards reaching the goal in the past few steps 
frequent state revisits may indicate a heuristic depression and a deeper search is usually beneficial
in such situations  ishida         feature f  is a measure of inaccuracies and inconsistencies in the
heuristic around the agent  again  many heuristic updates may warrant a deeper search 
the features in the second category are listed in table    they are also computed at each execution step  before the planning phase starts  a shallow lookahead pre search is performed to gather
information about the nearby part of the search space  the types of features in this category can
be coarsely divided into features that  i  compute the fraction of states on the pre search lookahead
frontier that satisfy some property   ii  compare the action chosen by the pre search to previous
actions  either of the previous state or taken the last time the current state was visited   and  iii 
check heuristic estimates of the immediate successors of the current state  feature f  is a rough
measure of the density of obstacles in the agents vicinity  the more obstacles there are  the more
beneficial a deeper search might be  feature f  is an indicator of the difficulty of traversing the
local area  if the proportion is high  many states have been updated  possibly suggesting a heuristic
depression  as for feature f    if a pre search selects the same action again this might indicate that
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

table    history based classifier features 
feature
f 
f 
f 
f 

description
the initial heuristic estimate of the distance from the current state to the goal 
hoctile  s  sglobal goal   
the heuristic estimate of the distance between the current state and the state the
agent was in n steps ago  h s  sn   
the number of distinct states the agent visited in the last n steps 
  s    s         sn    
p
the total volume of heuristic updates over the last n steps  ni   hafter update  si   
hbefore update  si    line   in figure    
table    pre search based classifier features 

feature
f 
f 
f 

f 
f 
f  
f  

description
the ratio of the actual number of states on the pre search frontier to the expected
number of states if there were no obstacles on the map 
the fraction of frontier states with an updated heuristic value 
a boolean feature telling whether the action chosen by the pre search is the same
as the action chosen by the planning phase the last time this state was visited  if
this is the first time the state is visited this feature is false 
a boolean feature telling whether the direction suggested by the pre search is the
same as the direction the agent took the previous step 
the ratio between the current states heuristic and the best successor state suggested
by the pre search  h s  sgoal   h s  sgoal   
a boolean feature telling whether the best action proposed by the pre search phase
would lead to a successor state with an updated heuristic value 
a boolean feature telling whether the heuristic value of the current state is larger
than the heuristic value of the best immediate successor found by the pre search 

the heuristic values in this part of the search space are already mutually consistent and thus only a
shallow lookahead is needed  the same applies to feature f    features f  to f   compare the current
state to the successor state suggested by the pre search 

appendix b  experiments on upscaled maps using global goals
empirical results of running the global goal algorithms on upscaled maps are shown in figure    
the lrta   dt  g  shows a significant improvement over lrta   f  g   making it comparable in
quality to the existing state of the art algorithms  on par with p lrta   f  g  and slightly better
than k lrta   f  g  when allowed to expand over     states per move  it is also worth noting that
lrta   pdb  g  is no longer competitive with the other algorithms and  in fact  does not make
the real time cut off of      states for any of its parameters combinations  and thus is not shown in
the plot   the reason lies with the fact that the problems are simply too difficult for lrta  to find
an optimal move with a small lookahead depth  for instance  with abstraction level       and cap
   

fidynamic c ontrol in r eal  t ime h euristic s earch

c       lrta   pdb  g  has suboptimality of       unfortunately  its lookahead depth hits the cap
in     of all visited states  as a result  the algorithm expands an average of      states per move
which disqualifies it under a cut off of      
upscaled maps

realtime cutoff      

  
lrta   f  g 
lrta   dt  g 
p lrta   f  g 
k lrta   f  g 

  

suboptimality  times 

  
  
  
  
 
 
 
 
 

   

   

   
   
   
   
mean number of states expanded per move

   

   

figure     performance of global goal algorithms on upscaled maps 
looking collectively at the small and upscaled up map results  lrta   dt  g  demonstrates
excellent performance among the global goal algorithms as it is both robust with respect to map
upscaling and one of the more efficient ones  the only comparable algorithm is k lrta   f  g   
however  within the provided      states cut off limit  none of the real time global goal algorithms
returned solutions that would be considered of an acceptable quality in pathfinding  indeed  even
the best solutions found are approximately four times worse than the optimal 

appendix c  pattern database build times
in order to operate lrta  and pr lrta  that use both lookahead depth and intermediate goals controlled dynamically  we build pattern databases  each pattern database is built off line and contains
a single entry for each pair of abstract states  there are three types of entries   i  intermediate goal
which is a ground level entry state in the next abstract state   ii  capped optimal lookahead depth
with respect to the intermediate goal and  iii  optimal lookahead depth with respect to the global
goal  when running algorithms with capped lookaheads  i e   c         we need two databases
per map  one containing intermediate goals and one containing capped optimal lookahead depths 
when running effectively uncapped algorithms  i e   c        or c         we also need a third
database with lookahead depths for global goals  see appendix d for further discussion   tables  
and     report build times and lrta   pdb  pdb  performance when capped  i e   when we have
to build only two pattern databases   tables    and    report build times and performance with
effectively no cap  i e   when we have built all three pattern databases  
finally  in the interest of speeding up experiments we did not in fact compute pattern databases
for all pairs of abstract states  instead  we took advantage of prior benchmark problem availability
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

table    pattern databases for an average          map  computed for intermediate goals 
database size is listed as the number of abstract state pairs  suboptimality and planning
per move are listed for lrta   pdb  pdb  with a cap c      
abstraction level
 
 
 
 
 
 
 
 

size
         
        
        
        
        
        
        
        

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
    
     
     

suboptimality  times 
     
     
     
     
     

table     pattern databases for an average          map  computed for intermediate goals 
database size is listed as the number of abstract state pairs  suboptimality and planning
per move are listed for lrta   pdb  pdb  with a cap c      
abstraction level
 
 
 
 
 
 
 
 

size
         
        
        
        
        
        
        
        

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
    
     
     

suboptimality  times 
     
     
     
     
     

and computed pdbs only for abstract goal states that come into play in the problems that our agents
were to solve  thus  the times in the tables are our estimates for all possible pairs 

appendix d  intermediate goals and loops
as shown by korf in his original paper  lrta  is complete for any lookahead depth when its
heuristic is taken with respect to a single global goal  such completeness guarantee is lost when one
uses intermediate goals  i e   for lrta   f  pdb   lrta   pdb  pdb  as well as the pr lrta 
counter parts   indeed  while in an abstract tile a  the dynamic goal control module will guide
the agent towards an entry state in tile b  however  on its way  the agent may stumble in different
abstract tile c  as soon as it happens  the dynamic control module may select an entry state in tile
a as its new intermediate goal  the unsuspecting agent heads back to a and everything repeats 
to combat such loops we equipped all algorithms that use intermediate goals with a state reentrance detector  namely  as soon as an agent re visits a ground level state  the dynamic control
switches from an intermediate goal to the global goal  additionally  a new lookahead depth is selected  ideally  such lookahead depth should be the optimal depth with respect to the global goal 
   

fidynamic c ontrol in r eal  t ime h euristic s earch

table     pattern databases for an average          map  computed for intermediate goals 
database size is listed as the number of abstract state pairs  suboptimality and planning
per move are listed for lrta   pdb  pdb  with a cap c      
abstraction level
 
 
 
 
 
 
 
 

size
         
        
        
        
        
        
        
        

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
    
     
     

suboptimality  times 
     
     
     
     
     

table     pattern databases for an average          map  computed for intermediate goals 
database size is listed as the number of abstract state pairs  suboptimality and planning
per move are listed for lrta   pdb  pdb  with a cap c      
abstraction level
 
 
 
 
 
 
 
 

size
         
        
        
        
        
        
        
        

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
     
     
     

suboptimality  times 
     
     
     
     
     

capped at c  unfortunately  computing optimal lookahead depths for global goals is quite expensive
off line  tables    and      given that loops occur fairly infrequently  we do not normally compute
optimal lookahead depths for global goals  instead  when a state re visit is detected  we switch to
global goals and simply set the lookahead to cap c  doing so saves off line pdb computation time
but sometimes causes the agent to conduct a deeper search  c plies  than really necessary  
an alternative solution to be investigated in future research is to progressively increase lookahead on line when re visits are detected  i e   every time a re visit occurs  lookahead depth at that
state is increased by a certain number of plies  

   the only exception to this practice were the cases of c        and c        where setting lookahead depth d to c
would have immediately disqualified the algorithm  provided a reasonable real time cut off  consequently  for these
two cap values  we did invest a large amount of time and computed effectively uncapped optimal lookahead depth
with respect to global goals 

   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

table     pattern databases for an average          map  computed for global goals  database
size is listed as the number of abstract state pairs  suboptimality and planning per move
are listed for lrta   pdb  pdb  with a cap c        
abstraction level
 
 
 
 
 
 
 
 

size
         
        
        
        
        
        
        
        

time
est      years
est     years
est    years
   days
     days
    days
    hours
    hours

planning per move
   
   
    
    
     

suboptimality  times 
     
     
     
     
     

table     pattern databases for an average          map  computed for global goals  database
size is listed as the number of abstract state pairs  suboptimality and planning per move
are listed for lrta   pdb  g  with a cap c      
abstraction level
 
 
 
 
 
 
 
 

size
         
        
        
        
        
        
        
        

time
est     years
est    months
est     days
     hours
    hours
    hours
   minutes
   minutes

   

planning per move
     
     
     
     
     

suboptimality  times 
     
     
      
     
      

fidynamic c ontrol in r eal  t ime h euristic s earch

references
bioware corp          baldurs gate   published by interplay  http   www bioware com bgate  
november          
bjornsson  y     marsland  t  a          learning extension parameters in game tree search  inf 
sci                 
blizzard         warcraft    reign of chaos  http   www blizzard com war  
bonet  b     geffner  h          planning as heuristic search  artificial intelligence          
    
bonet  b     geffner  h          learning depth first search  a unified approach to heuristic search
in deterministic and non deterministic settings  and its application to mdps  in proceedings
of the international conference on automated planning and scheduling  icaps   pp     
     cumbria  uk 
bonet  b   loerincs  g     geffner  h          a fast and robust action selection mechanism for
planning   in proceedings of the national conference on artificial intelligence  aaai   pp 
        providence  rhode island  aaai press   mit press 
botea  a   muller  m     schaeffer  j          near optimal hierarchical path finding  journal of
game development            
bulitko  v       a   lookahead pathologies and meta level control in real time heuristic search 
in proceedings of the   th euromicro conference on real time systems  pp        porto 
portugal 
bulitko  v       b   lookahead pathologies and meta level control in real time heuristic search  in
proceedings of the   th euromicro conference on real time systems  pp       
bulitko  v          learning for adaptive real time search  tech  rep  http   arxiv org abs cs ai 
         computer science research repository  corr  
bulitko  v   bjornsson  y   lustrek  m   schaeffer  j     sigmundarson  s          dynamic control in path planning with real time heuristic search  in proceedings of the international
conference on automated planning and scheduling  icaps   pp        providence  ri 
bulitko  v   li  l   greiner  r     levner  i          lookahead pathologies for single agent search 
in proceedings of the international joint conference on artificial intelligence  ijcai   pp 
          acapulco  mexico 
bulitko  v   sturtevant  n     kazakevich  m          speeding up learning in real time search via
automatic state abstraction  in proceedings of the national conference on artificial intelligence  aaai   pp            pittsburgh  pennsylvania 
bulitko  v   sturtevant  n   lu  j     yau  t          graph abstraction in real time heuristic
search  journal of artificial intelligence research  jair             
buro  m          experiments with multi probcut and a new high quality evaluation function for
othello  in van den herik  h  j     iida  h   eds    games in ai research  pp        u 
maastricht 
culberson  j     schaeffer  j          searching with pattern databases  in csci  canadian ai
conference   advances in artificial intelligence  pp          springer verlag 
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

culberson  j     schaeffer  j          pattern databases  computational intelligence            
    
dijkstra  e  w          a note on two problems in connexion with graphs   numerische mathematik 
          
furcy  d          itsa   iterative tunneling search with a   in proceedings of the national
conference on artificial intelligence  aaai   workshop on heuristic search  memory based
heuristics and their applications  boston  massachusetts 
furcy  d     koenig  s          speeding up the convergence of real time search  in proceedings
of the national conference on artificial intelligence  aaai   pp         
hart  p   nilsson  n     raphael  b          a formal basis for the heuristic determination of
minimum cost paths  ieee transactions on systems science and cybernetics               
hernandez  c     meseguer  p       a   improving convergence of lrta  k   in proceedings of
the international joint conference on artificial intelligence  ijcai   workshop on planning
and learning in a priori unknown or dynamic domains  edinburgh  uk 
hernandez  c     meseguer  p       b   lrta  k   in proceedings of the   th international joint
conference on artificial intelligence  ijcai   edinburgh  uk 
hernandez  c     meseguer  p          improving real time heuristic search on initially unknown
maps  in proceedings of the international conference on automated planning and scheduling
 icaps   workshop on planning in games  p     providence  rhode island 
hoffmann  j          a heuristic for domain independent planning and its use in an enforced hillclimbing algorithm  in proceedings of the   th international symposium on methodologies
for intelligent systems  ismis   pp         
id software         doom   published by id software  http   en wikipedia org  wiki doom  december          
ishida  t          moving target search with intelligence  in proceedings of the national conference
on artificial intelligence  aaai   pp         
kitano  h   tadokoro  s   noda  i   matsubara  h   takahashi  t   shinjou  a     shimada  s         
robocup rescue  search and rescue in large scale disasters as a domain for autonomous agents
research  in man  systems  and cybernetics  pp         
kocsis  l          learning search decisions  ph d  thesis  university of maastricht 
koenig  s          a comparison of fast search methods for real time situated agents  in proceedings of the international joint conference on autonomous agents and multiagent systems
 aamas   pp         
koenig  s          agent centered search  ai magazine                
koenig  s   furcy  d     bauer  c          heuristic search based replanning  in proceedings of the
int  conference on artificial intelligence planning and scheduling  pp         
koenig  s     likhachev  m          real time adaptive a   in proceedings of the international
joint conference on autonomous agents and multiagent systems  pp         
korf  r          depth first iterative deepening   an optimal admissible tree search  artificial
intelligence               
   

fidynamic c ontrol in r eal  t ime h euristic s earch

korf  r          real time heuristic search  artificial intelligence                 
korf  r          linear space best first search  artificial intelligence           
likhachev  m   ferguson  d   gordon  g   stentz  a     thrun  s          anytime dynamic a   an
anytime  replanning algorithm  in proceedings of the international conference on automated
planning and scheduling  icaps  
likhachev  m   gordon  g  j     thrun  s          ara   anytime a  with provable bounds on
sub optimality  in thrun  s   saul  l     scholkopf  b   eds    advances in neural information processing systems     mit press  cambridge  ma 
likhachev  m     koenig  s          a generalized framework for lifelong planning a   in proceedings of the international conference on automated planning and scheduling  icaps  
pp        
lustrek  m          pathology in single agent search  in proceedings of information society conference  pp          ljubljana  slovenia 
lustrek  m     bulitko  v          lookahead pathology in real time path finding  in proceedings of
the national conference on artificial intelligence  aaai   workshop on learning for search 
pp          boston  massachusetts 
mero  l          a heuristic search algorithm with modifiable estimate  artificial intelligence     
     
moore  a     atkeson  c          prioritized sweeping  reinforcement learning with less data and
less time  machine learning             
nash  a   daniel  k     felner  s  k  a          theta   any angle path planning on grids  in
proceedings of the national conference on artificial intelligence  pp           
pearl  j          heuristics  addison wesley 
rayner  d  c   davison  k   bulitko  v   anderson  k     lu  j          real time heuristic search
with a priority queue  in proceedings of the international joint conference on artificial
intelligence  ijcai   pp            hyderabad  india 
russell  s     wefald  e          do the right thing  studies in limited rationality  mit press 
schaeffer  j          the history heuristic and alpha beta search enhancements in practice  ieee
transactions on pattern analysis and machine intelligence  pami                 
schaeffer  j          search ideas in chinook  in van den herik  h  j     iida  h   eds    games in
ai research  pp        u  maastricht 
shimbo  m     ishida  t          controlling the learning process of real time heuristic search 
artificial intelligence              
sigmundarson  s     bjornsson  y          value back propagation vs  backtracking in realtime search  in proceedings of the national conference on artificial intelligence  aaai  
workshop on learning for search  pp          boston  massachusetts  usa 
stenz  a          the focussed d  algorithm for real time replanning  in proceedings of the
international joint conference on artificial intelligence  ijcai   pp           
stout  b          the basics of a  for path planning  in game programming gems  charles river
media 
   

fib ulitko   l u strek   s chaeffer   b j ornsson   s igmundarson

sturtevant  n          memory efficient abstractions for pathfinding  in proceedings of the third
conference on artificial intelligence and interactive digital entertainment  pp        stanford  california 
sturtevant  n     buro  m          partial pathfinding using map abstraction and refinement  in
proceedings of the national conference on artificial intelligence  pp           
sturtevant  n     jansen  r          an analysis of map based abstraction and refinement  in
proceedings of the  th international symposium on abstraction  reformulation and approximation  whistler  british columbia 
witten  i  h     frank  e          data mining  practical machine learning tools and techniques
  nd edition   morgan kaufmann  san fransisco 

   

fi