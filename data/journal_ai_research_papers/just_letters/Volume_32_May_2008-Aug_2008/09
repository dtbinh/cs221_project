journal artificial intelligence research                    

submitted        published      

dynamic control real time heuristic search
vadim bulitko

bulitko   ualberta   ca

department computing science  university alberta
edmonton  alberta  t g  e   canada

mitja lustrek

mitja   lustrek   ijs   si

department intelligent systems  jozef stefan institute
jamova          ljubljana  slovenia

jonathan schaeffer

jonathan   cs   ualberta   ca

department computing science  university alberta
edmonton  alberta  t g  e   canada

yngvi bjornsson

yngvi   ru  

school computer science  reykjavik university
kringlan    is     reykjavik  iceland

sverrir sigmundarson

sverrir   sigmundarson   landsbanki  

landsbanki london branch  beaufort house 
   st botolph street  london ec a  qr  great britain

abstract
real time heuristic search challenging type agent centered search agents
planning time per action bounded constant independent problem size  common problem
imposes restrictions pathfinding modern computer games large number
units must plan paths simultaneously large maps  common search algorithms  e g   a  
ida   d   ara   ad   inherently real time may lose completeness constant
bound imposed per action planning time  real time search algorithms retain completeness
frequently produce unacceptably suboptimal solutions  paper  extend classic
modern real time search algorithms automated mechanism dynamic depth subgoal
selection  new algorithms remain real time complete  large computer game maps 
find paths within    optimal average expanding roughly single state per action 
nearly three fold improvement suboptimality existing state of the art algorithms
and  time     fold improvement amount planning per action 

   introduction
paper study problem agent centered real time heuristic search  koenig        
distinctive property search agent must repeatedly plan execute actions
within constant time interval independent size problem solved 
restriction severely limits range applicable heuristic search algorithms  instance  static
search algorithms a   hart  nilsson    raphael        ida   korf         re planning
algorithms d   stenz         anytime algorithms ara   likhachev  gordon   
thrun        anytime re planning algorithms ad   likhachev  ferguson  gordon 
stentz    thrun        cannot guarantee constant bound planning time per action  lrta 
c
    
ai access foundation  rights reserved 

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

can  potentially low solution quality due need fill heuristic depressions  korf 
      ishida        
motivating example  consider autonomous surveillance aircraft context disaster response  kitano  tadokoro  noda  matsubara  takahashi  shinjou    shimada        
surveying disaster site  locating victims  assessing damage  aircraft ordered fly
particular location  radio interference may make remote control unreliable thereby requiring
certain degree autonomy aircraft using ai  task presents two challenges  first 
due flight dynamics  ai must control aircraft real time  producing minimum number
actions per second  second  aircraft needs reach target location quickly due limited
fuel supply need find rescue potential victims promptly 
study simplified version problem captures two ai challenges abstracting away robot specific details  specifically  line work real time heuristic
search  e g   furcy   koenig        shimbo   ishida        koenig        botea  muller    schaeffer        hernandez   meseguer      a      b  likhachev   koenig        sigmundarson  
bjornsson        koenig   likhachev        consider agent finite search graph
task traveling path current state given goal state  within context measure
amount planning agent conducts per action length path traveled
start goal locations  two measures antagonistic reducing amount planning per action leads suboptimal actions results longer paths  conversely  shorter paths
require better actions obtained larger planning effort per action 
use navigation grid world maps derived computer games testbed  games 
agent tasked go location map current location  examples include
real time strategy games  e g   blizzard         first person shooters  e g   id software        
role playing games  e g   bioware corp          size complexity game maps well
number simultaneously moving units maps continues increase every new generation games  nevertheless  game unit agent must react quickly users command
regardless maps size complexity  consequently  game companies impose time peraction limit pathfinding algorithms  instance  bioware corp   major game company
collaborate with  sets limit     ms units computing paths time 
search algorithms produce entire solution agent takes first action  e g   a 
hart et al         lead increasing action delays map size increases  numerous optimizations
suggested remedy problems decrease delays  for recent example deployed forthcoming computer game refer sturtevant         real time search addresses
problem fundamentally different way  instead computing complete  possibly abstract  solution first action taken  real time search algorithms compute  or plan 
first actions agent take  usually done conducting lookahead search fixed
depth  also known search horizon  search depth lookahead depth  around agents
current state using heuristic  i e   estimate remaining travel cost  select next
actions  actions taken planning execution cycle repeats  e g   korf        
since goal state reached local searches  agent runs risks heading
dead end or  generally  selecting suboptimal actions  address problem  real time
heuristic search algorithms update  or learn  heuristic function experience  existing
algorithms constant amount planning  i e   lookahead search  per action  result 
tend waste cpu cycles heuristic function fairly accurate and  conversely  plan
enough heuristic function particularly inaccurate  additionally  compute heuris   

fidynamic c ontrol r eal  t ime h euristic earch

tic respect distant global goal state put unrealistic requirements heuristic
accuracy demonstrate paper 
paper address problems making following three contributions  first 
propose two ways selecting lookahead search depth dynamically  per action basis  second 
propose way selecting intermediate subgoals per action basis  third  apply
extensions classic lrta   korf        state of the art real time pr lrts  bulitko 
sturtevant  lu    yau        demonstrate improvements performance  resulting
algorithms new state art real time search  illustrate  large computer game
maps new algorithms find paths within    optimal expanding single state
action  comparison  previous state of the art  pr lrts     times slower per
action finding paths two three times suboptimal  furthermore 
dynamically controlled lrta  pr lrts one two orders magnitude faster per action
a   weighted a  state of the art partial refinement a   pra    sturtevant   buro 
       finally  unlike a  modern extensions used games  new algorithms provably
real time slow maps become larger 
rest paper organized follows  section   formulate problem real time
heuristic search show core lrta  algorithm extended dynamic lookahead
subgoal selection  section   analyzes related research  section   provides intuition dynamic
control search  section   describe two approaches dynamic lookahead selection  one
based induction decision tree classifiers  section      one based precomputing depth
table using state abstraction  section       section   present approach selecting subgoals
dynamically  section   evaluates efficiency extensions domain pathfinding 
conclude discussion applicability new approach general planning 
paper extends conference publication  bulitko  bjornsson  lustrek  schaeffer    sigmundarson        new set features decision tree approach  new way selecting
subgoals  additional real time heuristic search algorithm  pr lrta   extended dynamic
control  numerous additional experiments detailed presentation 

   problem formulation
define heuristic search problem directed graph containing finite set states weighted
edges  single state designated goal state  every time step  search agent single
current state  vertex search graph  takes action traversing out edge current
state  edge positive cost associated it  total cost edges traversed agent
start state arrives goal state called solution cost  require algorithms
complete produce path start goal finite amount time path exists 
order guarantee completeness real time heuristic search make assumption safe
explorability search problems  namely  costs finite goal state reachable
state agent possibly reach start state 
formally  algorithms discussed paper applicable heuristic search problem  keep presentation focused intuitive well afford large scale empirical
evaluation  use particular type heuristic search problems  pathfinding grid worlds 
rest paper  however  discuss applicability new methods suggest
heuristic search problems section     general planning problems section   
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

computer game map settings  states vacant square grid cells  cell connected
four cardinally  i e   west  north  east  south  four diagonally neighboring cells  outbound
edges vertex moves available corresponding cell rest paper

use terms action move interchangeably  edge costs   cardinal moves
  diagonal moves  agent plans next action considering states local search space
surrounding current position  heuristic function  or simply heuristic  estimates  remaining 
travel cost state goal  used agent rank available actions select
promising one  paper consider admissible heuristic functions
overestimate actual remaining cost goal  agent modify heuristic function
state avoid getting stuck local minima heuristic function  well improve action
selection experience 
defining property real time heuristic search amount planning agent
per action upper bound depend problem size  enforce property
setting real time cut off amount planning action  algorithm exceeds
cut off discarded  fast planning preferred guarantees agents quick reaction
new goal specification changes environment  measure mean planning time per action
terms cpu time well machine independent measure number states expanded
planning  state called expanded successor states considered generated
search  second performance measure study sub optimality defined ratio
solution cost found agent minimum solution cost  ratios close one indicate
near optimal solutions 
core real time heuristic search algorithms algorithm called learning realtime a   lrta    korf         shown figure   operates follows  long goal
state sglobal goal reached  algorithm interleaves planning execution lines     
generalized version added new step line   selecting search depth goal sgoal
individually execution step  the original algorithm uses fixed sglobal goal planning
searches   line    d ply breadth first search duplicate detection used find frontier states
precisely actions away current state s  frontier state s  value sum
cost shortest path s  denoted g s  s   estimated cost shortest path
sgoal  i e   heuristic value h s  sgoal     use standard path max technique  mero 
      deal possible inconsistencies heuristic function computing g   h values 
result  g   h values never decrease along branch lookahead tree  state
minimizes sum identified sfrontier line    heuristic value current state
updated line    we keep separate heuristic tables different goals   finally  take one step
towards promising frontier state sfrontier line   

   related research
algorithms single agent real time heuristic search use fixed search depth  notable
exceptions  russell wefald        proposed estimate utility expanding state use
control lookahead search on line  one needs estimate likely additional search
change actions estimated value  inaccuracies estimates overhead metalevel control led reasonable unexciting benefits combinatorial puzzle pathfinding 
additional problem relatively low branching factor combinatorial puzzles makes
difficult eliminate parts search space early on  problem likely occur grid   

fidynamic c ontrol r eal  t ime h euristic earch

lrta  sstart   sglobal goal  
  sstart
     sglobal goal
 
select search depth goal sgoal
 
expand successor states actions away  generating frontier
 
find frontier state sfrontier lowest g s  sfrontier     h sfrontier   sgoal  
 
update h s  sgoal   g s  sfrontier     h sfrontier   sgoal  
 
change one step towards sfrontier
  end
figure    lrta  algorithm dynamic control 
based pathfinding  finally  method adds substantial implementation complexity requires
non trivial changes underlying search algorithm  contrast  approach search depth
selection easily interfaced real time search algorithm search depth parameter
without modifying existing code 
ishida        observed lrta  style algorithms tend get trapped local minima
heuristic function  termed heuristic depressions  proposed remedy switch limited
a  search heuristic depression detected use results a  search
correct depression once  different approach two ways  first 
need mechanism decide switch real time a  search thus avoid
need hand tune control parameters ishidas control module  instead  employ automated
approach decide search horizon depth every action  additionally  spend extra
time filling heuristic values within heuristic depression a  estimates 
bulitko      a  showed optimal search depth selection highly beneficial realtime heuristic search  linked benefits avoiding so called lookahead pathologies
deeper lookahead leads worse moves suggest practical way selecting lookahead depth dynamically  way proposed      via use generalized definition
heuristic depressions  bulitko         proposed algorithm extends search horizon incrementally search finds way depression  actions leading found
frontier state executed  cap search horizon depth set user  idea precomputing depth table heuristic values real time pathfinding first suggested lustrek
bulitko         paper extends work follows   i  introduce intermediate goals 
 ii  propose alternative approach require map specific pre computation  iii 
extend evaluate state of the art algorithm addition classic lrta  
long tradition search control two player search  high performance game playing
programs games chess checkers rely extensively search decide actions
take  search performed strict real time constraints programs typically
minutes seconds deliberating next action  instead using fixed depth lookahead strategy programs employ sophisticated search control mechanisms maximizing
quality action decisions within given time constraints  search control techniques
coarsely divided three main categories  move ordering  search extensions reductions 
time allotment  one earlier works dynamic move ordering history heuristic technique  schaeffer         recent attempts include work training neural networks  kocsis         exist large variety techniques adjusting search horizon
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

different branches within game tree  interesting continuations explored deeply
less promising ones terminated prematurely  whereas early techniques
static  research focus shifted towards dynamic control well using machine learning
approaches automatic parameterization  buro        bjornsson   marsland         best
knowledge  none techniques applied single agent real time search 

   intuition dynamic search control
observed literature common heuristic functions uniformly inaccurate  pearl         namely  tend accurate closer goal state less accurate
farther away  intuition fact follows  heuristic functions usually ignore certain constraints search space  instance  manhattan distance heuristic sliding tile puzzle
would perfectly accurate tiles could pass other  likewise  euclidian distance
map ignores obstacles  closer state goal fewer constraints heuristic function
likely ignore and  result  accurate  i e   closer optimal solution cost 
heuristic likely be 
intuition motivates adaptive search control real time heuristic search  first  heuristic values inaccurate  agent conduct deeper lookahead search compensate
inaccuracies maintain quality actions  deeper lookaheads generally found
beneficial real time heuristic search  korf         though lookahead pathologies  i e   detrimental
effects deeper lookaheads action quality  observed well  bulitko  li  greiner   
levner        bulitko      b  lustrek        lustrek   bulitko         illustration  consider
figure    every state map shaded according minimum lookahead depth
lrta  agent use select optimal action  darker shades correspond deeper lookahead
depths  notice many areas bright white  indicating shallowest lookahead depth
one sufficient  use intuition first control mechanism  dynamic selection
lookahead depth section   

figure    partial grid world map computer game baldurs gate  bioware corp         
shades grey indicate optimal search depth values white representing one ply 
completely black cells impassable obstacles  e g   walls  
   

fidynamic c ontrol r eal  t ime h euristic earch

dynamic search depth selection helps eliminate wasted computation switching shallower
lookahead heuristic function fairly accurate  unfortunately  help
heuristic function grossly inaccurate  instead  calls deep lookahead order select
optimal action  deep search tremendously increases planning time and  sometimes  leads
violating real time cut off planning time per move  address issue  section  
propose second control mechanism  dynamic selection subgoals  idea straightforward 
far goal leads grossly inaccurate heuristic values  let us move goal closer
agent  thereby improving heuristic accuracy  computing heuristic function
respect intermediate  thus nearby  goal opposed distant global goal
final destination agent  since intermediate goal closer global goal  heuristic
values states around agent likely accurate thus search depth picked
first control mechanism likely shallower  agent gets intermediate goal 
next intermediate goal selected agent makes progress towards actual global goal 

   dynamic search depth selection
first  define optimal search depth follows   s  sglobal goal   state pair  true optimal action  s  sglobal goal   take edge lies optimal path sglobal goal  there
one optimal action    s  sglobal goal   known  run series progressively
deeper lrta  searches state s  shallowest search depth yields  s  sglobal goal  
optimal search depth  s  sglobal goal    may search depth forfeit lrta s real time
property impractical compute  thus  following subsections present two
different practical approaches approximating optimal search depth  equips lrta 
dynamic search depth selection  i e   realizing first part line   figure     first
approach uses decision tree classifier select search depth based features agents
current state recent history  second approach uses pre computed depth database based
automatically built state abstraction 
    decision tree classifier approach
effective classifier needs input features useful predicting optimal search
depth  efficiently computable agent real time  features use
classifier selected compromise two considerations  well domain independent  features calculated based properties states agent recently
visited  well features gathered shallow pre search agents current state  example
features are  distance state agent n steps ago  estimate distance
agents goal  number states visited pre search phase updated heuristics 
appendix features listed rationale behind explained 
classifier predicts optimal search depth current state  optimal depth
shallowest search depth returns optimal action  training classifier must thus label
training states optimal search depths  however  avoid pre computing optimal actions 
make simplifying assumption deeper search always yields better action  consequently 
training phase agent first conducts lookahead search pre defined maximum depth  dmax  
derive optimal action  under assumption   choice maximum depth domain
dependent would typically set largest depth still guarantees search return
within acceptable real time requirement task hand  series progressively
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

shallower searches performed determine shallowest search depth  ddt   still returns
optimal action  process  given depth action returned differs
optimal action  progression stopped  enforces depths ddt dmax
agree best action  important improving overall robustness classification 
classifier must generalize large set states  depth ddt set class label
vector features describing current state 
classifier choosing lookahead depth  lrta  augmented
 line   figure     overhead using classifier consists time required collecting
features running classifier  overhead negligible classifier
implemented handful nested conditional statements  collecting features takes
somewhat time but  careful implementation  overhead made negligible
well  indeed  four history based features efficiently computed small constant time 
keeping lookahead depth pre search small  e g   one two  overhead collecting
pre search features usually dwarfed time planning phase  i e   lookahead search 
takes  process gathering training data building classifier carried off line
time overhead thus lesser concern 
    pattern database approach
nave approach would precompute optimal depth  s  sgoal   state pair 
two problems approach  first   s  sgoal   priori upper bounded independently
map size  thereby forfeiting lrta s real time property  second  pre computing  s  sgoal  
 s  sgoal   pairs  s  sgoal   states on  instance          cell computer game map
prohibitive time space complexity  solve first problem capping  s  sgoal  
fixed constant c    henceforth called cap   solve second problem using automatically built abstraction original search space  entire map partitioned regions  or
abstract states  single search depth value pre computed pair abstract states  run time single search depth value shared children abstract state pair  figure    
search depth values stored table refer pattern database pdb
short  past  pattern databases used store approximate heuristic values  culberson
  schaeffer        important board features  schaeffer         work appears first
use pattern databases store search depth values 
computing search depths abstract states speeds pre computation reduces memory
overhead  both important considerations commercial computer games   paper use
previously published clique abstraction  sturtevant   buro         preserves overall topology
map requires storing abstraction links explicitly   clique abstraction works
finding fully connected subgraphs  i e   cliques  original graph abstracting states
within clique single abstract state  two abstract states connected abstract
action single original action leads state first clique
state single clique  figure     costs abstract actions computed euclidean
distances average coordinates states cliques 
typical grid world computer game maps  single application clique abstraction reduces
number states factor two four  average  abstraction level five  i e  
five applications abstraction procedure   region contains one hundred original
   alternative use regular rectangular tiles  e g   botea et al         

   

fidynamic c ontrol r eal  t ime h euristic earch

figure    single optimal lookahead depth value shared among children abstract state 
memory efficient approximation true per ground state values figure   

level    original graph 

level  

level  

figure    two iterations clique abstraction procedure produce two abstract levels
ground level search graph 
 or ground level  states  thus  single search depth value shared among ten thousand
state pairs  result  five level clique abstraction yields four orders magnitude reduction
memory two orders magnitude reduction pre computation time  as analyzed later  
downside  higher levels abstraction effectively make search depth selection less
less dynamic depth value shared among progressively states  abstraction
level pattern database control parameter trades pre computation time pattern
database size on line performance algorithm uses database 
two alternatives storing optimal search depth store optimal action optimal
heuristic value  combination abstraction real time search precludes them  indeed 
sharing optimal action computed single ground level representative abstract region
among states region may cause agent run wall  figure    left   likewise 
sharing single heuristic value among states region leaves agent without sense
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson


g

    

    

    

    

    

    

    

    

    

    



    

    

    

g

figure    goal shown g  agent a  abstract states four tiles separated dashed lines 
diamonds indicate representative states tile  left  optimal actions shown
representative abstract tile  applying optimal action agents tile
agents current location leads wall  right  optimal heuristic value  h   lower
left tiles representative state        shared among states tile  result 
agent preference among three legal actions shown 
direction states vicinity would look equally close goal  figure    right  
contrast sharing heuristic value among states within abstract state  known pattern 
using optimal non real time search algorithms a  ida   culberson   schaeffer 
       case real time search  agents using either alternative guaranteed reach
goal  let alone minimize travel  contrary  sharing search depth among number
ground level states safe lrta  complete search depth 
compute single depth table per map off line  figure     line   state space abstracted   times  lines     iterate pairs abstract states  pair  s    s goal   
representative ground level states sgoal  i e   ground level states closest centroids regions  picked optimal search depth value calculated them  this  dijkstras
algorithm  dijkstra        run ground level search space  v  e  compute true
minimal distances state sgoal   distances known successors s 
optimal action  s  sgoal   computed greedily  optimal search depth  s  sgoal  
computed previously described capped c  line     resulting value stored pair
abstract states  s    s goal   line    figures     show optimal search depth values single
goal state grid world game map without abstraction respectively 
run time  lrta  agent going state state sgoal takes search depth
depth table value pair  s    s goal    s  s goal images sgoal   level
abstraction  additional run time complexity minimal s    s goal   d s    s goal   computed
small constant time overhead action 
building pattern database dijkstras algorithm run v  times  graph  v  e 
time complexity o v   v log v   e   sparse graphs  i e   e   o v     optimal
search depth computed v   times  time  c lrta  invocations total
   brevity  use v e mean sets vertices edges sizes  i e    v    e   

   

fidynamic c ontrol r eal  t ime h euristic earch

buildpatterndatabase v  e  c    
  apply abstraction procedure   times  v  e  compute abstract space s     v    e   
  pair states  s    s goal   v  v 
 
select v representative s  v 
 
select sgoal v representative s goal v 
 
compute c capped optimal search depth value state respect goal sgoal
 
store capped pair  s    s goal  
  end
figure    pattern database construction 
complexity o bc   b maximum degree v   thus  overall time complexity
o v   v log v   e   v  bc     space complexity lower store optimal search depth
values pairs abstract states  o v      table   lists bounds sparse graphs 
table    reduction complexity due state abstraction 

time
space

abstraction
o v   log v  
o v    

  level abstraction
o v  v log v  
o v    

reduction
v  v 
 v  v    

    discussion two approaches
selecting search depth pattern database two advantages  first  search depth values
stored pair abstract states optimal non abstract representatives  unless either
value capped states local search space visited heuristic values modified   conditional  optimality contrast classifier approach
optimal actions ever computed deeper searches merely assumed lead
better action  assumption always hold phenomenon known lookahead pathology  found abstract graphs  bulitko et al         well grid based pathfinding  lustrek  
bulitko         second advantage need features current state  recent
history pre search  search depth retrieved depth table simply basis
current states identifier  coordinates 
decision tree classifier approach two advantages depth table approach  first 
classifier training need happen search space agent operates in 
long training maps used collect features build decision tree representative
run time maps  approach run never before seen maps  e g   user created maps
computer game   second  much smaller memory overhead method
classifier specified procedurally pattern database needs loaded memory 
note approaches assume structure heuristic search problem
hand  namely  pattern database approach shares single search depth value across region
states  works effectively states region indeed lookahead
depth best them  abstraction mechanism forms regions basis search
graph structure  regard search depth  empirical study show  clique abstraction
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

seems right choice pathfinding  however  choice best abstraction technique
general heuristic search problem open question 
similarly  decision tree approach assumes states share similar feature values
share best search depth value  appears hold large extent pathfinding domain
feature selection arbitrary heuristic search problems open question well 

   dynamic goal selection
two methods described allow agent select individual search depth state 
however  original lrta   heuristic still computed respect global goal
sgoal   illustrate  figure    map partitioned eight abstract states  in case     
square tiles  whose representative states shown diamonds       optimal path
agent  a  goal  g  shown well  straight line distance heuristic ignore
wall agent goal lead agent south western direction  lrta 
search depth    higher needed produce optimal action  such    thus 
cap value     agent left suboptimal action spend long time
horizontal wall raising heuristic values  spending large amounts time corners
heuristic depressions primary weakness real time heuristic search agents and 
example  remedied dynamic search depth selection due cap 

 

 

 

 



 

g

 

 

 

figure    goal shown g  agent a  abstract states eight tiles separated dashed
lines  diamonds indicate ground level representative tile  optimal path
shown  entry points path abstract states marked circles 

 a compute sintermediate goal goal  s  sgoal  
 b compute capped optimal search depth value respect sintermediate goal
  store  d   sintermediate goal   pair  s    s goal  
figure    switching sgoal sintermediate goal   replaces lines    figure   
   

fidynamic c ontrol r eal  t ime h euristic earch

figure    three maps used experiments 
address issue  switch intermediate goals pattern database construction well
on line lrta  operation  example figure   compute heuristic around
respect intermediate goal marked double border circle map  consequently 
eleven times shallower search depth needed optimal action towards next abstract state
 right most upper tile   approach replaces lines       figure   figure    line
 a  compute intermediate goal sintermediate goal ground level state optimal path
sgoal enters next abstract state  entry points marked circles figure   
compared entry states centroids abstract states intermediate goals  bulitko et al        
found former superior terms algorithms performance  note optimal path
easily available off line run dijkstras algorithm  section      
intermediate goal computed  line  b computes capped optimal search depth
respect intermediate goal sintermediate goal   depth computation done described
section      search depth intermediate goal added pattern database
line    run time  agent executes lrta  stored search depth computes
heuristic h respect stored goal  i e   sgoal set sintermediate goal line   figure    
words  search depth agents goal selected dynamically  per action 
approach works heuristic functions used practice tend become accurate states closer goal state  therefore  switching distant global goal nearby
intermediate goal makes heuristics around current state accurate leads shallower search depth necessary achieve optimal action  result  algorithm
run quickly shallower search per move search depth cap reached less
frequently therefore search depth values actually result optimal moves 

   empirical evaluation
section presents results empirical evaluation algorithms dynamic control search
depth goals classic state of the art published algorithms  algorithms avoid reexpanding states planning move via transposition table  report sub optimality
solution found average amount computation per action  expressed number
states expanded  believe algorithms implemented way single
expanded state takes amount time  case testbed code
optimized other  reason avoid clutter  report cpu times
section      used fixed tie breaking scheme real time algorithms 
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

use grid world maps computer game testbed  game maps provide realistic
challenging environment real time search seen number recent publications  e g   nash  daniel    felner        hernandez   meseguer         original maps
sized               cells  figure     line sturtevant buro        sturtevant
jansen         experimented maps upscaled         closer size
maps used modern computer games  note three maps depicted figure
outdoor type maps  ran preliminary experiments indoor type game maps  e g   one
shown figure     trends similar decided focus larger outdoor maps 
    search problems defined three original size maps  start
goal locations chosen randomly  although constrained optimal solution paths cost
       order generate difficult instances  upscaled maps    
problems upscaled well  data point plots average     problems   
maps     runs each   different legend entry used algorithm  multiple points
legend entry represent alternative parameter instantiation algorithm 
heuristic function used octile distance natural extension manhattan distance maps
diagonal actions  enforce real time constraint disqualified parameter settings
caused algorithm expand      states move problem  points
excluded empirical evaluation  maps known priori off line order build
decision tree classifiers pattern databases 
use following notation identify algorithms variants  algorithmname
 x  y  x defined follows  x denotes search depth control  f fixed search
depth  dt search depth selected dynamically decision tree  oracle search depth
selected decision tree oracle  see next section details  pdb search depth
selected dynamically pattern databases  denotes goal state selection  g heuristic
computed respect single global goal  pdb heuristic computed respect
intermediate goal pattern databases  instance  classic lrta  lrta   f  g  
empirical evaluation organized eight parts follows  section     describes six
algorithms compute heuristic respect global goal discusses performance 
section     describes five algorithms use intermediate goals  section     compares global
intermediate goals  section     studies effects path refinement without dynamic
control  secton     pits new algorithms state of the art real time non real time
algorithms  provide algorithm selection guide different time limits planning per
move section      finally  section     considers issue amortizing off line pattern database
build time on line pathfinding 
    algorithms global goals
subsection describe following algorithms compute heuristic respect
single global goal  i e   use intermediate goals  
   lrta   f  g  learning real time a   korf         action conducts breadthfirst search fixed depth around agents current state  first move towards
best depth state taken heuristic agents previous state updated using
korfs mini min rule   used                    
   instead using lrta  could used rta   experiments showed grid pathfinding
significant performance difference two search depth beyond one  indeed deeper searches

   

fidynamic c ontrol r eal  t ime h euristic earch

   lrta   dt  g  lrta  search depth dynamically controlled decision
tree described section      used following parameters  dmax                
history trace length n       building decision tree classifier weka  witten   frank        pruning factor set      minimum number data items
per leaf     original size maps    upscaled ones  opposed learning
tailor made classifier game map  single common decision tree classifier built
based data collected maps  using    fold cross validation   done
demonstrate ability classifier generalize across maps 
   lrta   oracle  g  lrta  search depth dynamically controlled
oracle  oracle always selects best search depth produce move given
lrta   f  g  fixed lookahead depth dmax  bulitko et al          words 
oracle acts perfect decision tree thus sets upper bound lrta   dt  g 
performance  oracle run dmax                  original size
maps proved prohibitively expensive compute upscaled maps  note
practical real time algorithm used reference point experiments 
   lrta   pdb  g  lrta  search depth dynamically controlled
pattern database described section      original size maps  used abstraction
level                     depth cap c                             upscaled maps 
used abstraction level                     depth cap c                            
considering size maps  cap value           means virtually capless search 
   k lrta   f  g  variant lrta  proposed koenig         unlike original
lrta   uses a  shaped lookahead search space updates heuristic values states
within using dijkstras algorithm   number states k lrta  expands per move
took values                                        
   p lrta   f  g  prioritized lrta  variant lrta  proposed rayner  davison 
bulitko  anderson  lu         uses lookahead depth   moves  however 
every state whose heuristic value updated  neighbors put onto update queue 
sorted magnitude update  thus  algorithm propagates heuristic function
updates space fashion prioritized sweeping  moore   atkeson        
control parameter  queue size  set                                       original
size maps                            upscaled maps 
figure    evaluate performance new dynamic depth selection algorithms
original size maps  see decision tree pattern database approach improve
significantly upon lrta  algorithm  expanding two three times fewer states generating
solutions comparable quality  furthermore  perform par current state of the art realtime search algorithms without abstraction  seen compared k lrta   f  g  
solutions generated acceptable quality domain  e g       suboptimal   even
expanding     states per action  interest decision tree approach performs
likelihood multiple actions equally low g   h cost high  reducing distinction rta 
lrta   using lrta  agents learn repeated trials 
   experimented a  shaped lookahead new algorithms found inferior breadth first lookahead deeper searches 

   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

original size maps

realtime cutoff      

 
lrta   f  g 
lrta   oracle  g 
lrta   dt  g 
lrta   pdb  g 
p lrta   f  g 
k lrta   f  g 

suboptimality  times 

   
 
   
 
   

 

 

   

   
   
   
mean number states expanded per move

   

   

figure     global goal algorithms original size maps 
quite close theoretical best case  seen compared lrta   oracle  g  
shows features use  although seemingly simplistic  good job predicting
appropriate search depth 
ran similar sets experiments upscaled maps  however  none global goal
algorithms generated solutions acceptable quality given real time cut off  the solutions
          suboptimal   experimental results upscaled maps provided
appendix b  shows inherent limitations global goal approaches  large search
spaces cannot compete equal footing abstraction based methods  brings us
intermediate goal selection methods 
    algorithms intermediate goals
section describe algorithms use intermediate goals search  best
knowledge  one previously published real time heuristic search algorithm
so  thus  compare new algorithms proposed paper  given intermediate
goals increase performance algorithms significantly  present results
challenging upscaled maps  full roster algorithms used section follows 
   pr lrta   f  g  path refinement learning real time search  bulitko et al         
algorithm two components  runs lrta  fixed search depth global
goal abstract space  abstraction level   clique abstraction hierarchy  refines
first move using corridor constrained a  running original ground level map  
constraining a  small set states  collectively called corridor sturtevant buro
   algorithm actually called pr lrts  bulitko et al          based findings lustrek bulitko        
modified refine single abstract action order reduce susceptibility lookahead pathologies 
modification equivalent substituting lrts component lrta   hence  rest paper 
call pr lrta  

   

fidynamic c ontrol r eal  t ime h euristic earch

       tunnel furcy         speeds makes real time corridor size
independent map size  bulitko  sturtevant    kazakevich         heuristic
computed abstract space respect fixed global goal  a  component
computes path current state intermediate goal  qualifies pr lrta 
enter section empirical evaluation  control parameters follows  abstraction
level                      lrta  lookahead depth                   lrta  heuristic
weight                        imposed g line   figure    
   lrta   f  pdb  lrta  fixed search depth uses pattern database select
intermediate goals  control parameters follows  abstraction level                    
search depth                                                               
   lrta   pdb  pdb  lrta  generalized dynamic search depth intermediate goal selection pattern databases presented sections        control parameters follows  abstraction level                     lookahead cap
c                            
   pr lrta   pdb  g  pr lrta  whose lrta  component equipped dynamic search depth uses global  abstract  goal respect computes abstract heuristic  pattern database search depth constructed
abstraction level   lrta  component runs on  making component optimal lookahead cap allows  used abstraction level  
                  lookahead cap c                       
ran version pr lrta   pdb  g  pattern database constructed abstraction level    level   lrta  operates  table     used         
                                                                                 
   pr lrta   pdb  pdb  two database version pr lrta   pdb  g 
except uses second database goal selection well depth selection  used
                                                                                           table    
table    pr lrta   pdb  g pdb  uses lrta  abstraction level   define corridor within
refines path using a   dynamic depth  and goal  selection performed either
abstraction level          
abstraction level
  
 
 

single abstraction pr lrta  pdb g 
abstract level lrta 
dynamic depth selection
corridor constrained ground level a 

dual abstraction pr lrta  pdb  g pdb  
dynamic depth  and goal  selection
abstract level lrta 
corridor constrained ground level a 

pattern database algorithms presented stores depth value intermediate
ground level goal pair abstract states  present performance results algorithms
intermediate goals sections        analyze complexity pattern database
computation effects performance section     
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

upscaled maps

realtime cutoff       

  
lrta   f  g 
lrta   f  pdb 

  

suboptimality  times 

  
  
  
  
 
 
 
 
 

   

   

   
   
    
    
mean number states expanded per move

    

    

figure     effects intermediate goals  lrta   f  g  versus lrta   f  pdb  

    global versus intermediate goals
sections         presented algorithms global intermediate goals respectively 
section compare algorithms across two groups  include lrta   pdb  g   increased
real time cut off            graphs section  start baseline lrta  fixed lookahead  effects adding intermediate goal selection dramatic 
lrta  intermediate goals  f  pdb  finds five times better solutions three orders
magnitude faster lrta  global goals  f  g   see figure      believe
result octile distance heuristic substantially accurate around goal  consequently 
lrta   f  pdb  benefiting much better heuristic function 
second experiment  equip versions dynamic search depth control compare lrta   pdb  g  lrta   pdb  pdb  figure     performance gap less
dramatic  planning speed up still around three orders magnitude  suboptimality
advantage went five two times  again  note increase real time
cut off order magnitude get points plot 
finally  evaluate beneficial  dynamic depth control dynamic goal control
comparing baseline lrta   f  g  lrta   pdb  g  lrta   f  pdb  figure    
clear dynamic goal selection much stronger addition baseline lrta  dynamic
search depth selection  dynamic depth selection sometimes actually performs worse fixed
depth  evidenced data points lrta   f  g  line  happens primarily
high abstraction levels small caps  optimal lookahead depth computed high
abstraction level  depth value shared among many ground level states  selected
depth value beneficial near entry point abstract state  abstract state
large  depth likely become inappropriate ground level states away 
example  optimal depth entry point    worse moderate fixed depth
   

fidynamic c ontrol r eal  t ime h euristic earch

upscaled maps

realtime cutoff       
lrta   pdb  g 
lrta   pdb  pdb 

  

suboptimality  times 

  
  
 
 
 
 
 

   

   

   
   
   
   
mean number states expanded per move

   

   

figure     effects intermediate goals  lrta   pdb  g  versus lrta   pdb  pdb  
upscaled maps

realtime cutoff       

  
lrta   f  g 
lrta   f  pdb 
lrta   pdb  g 

  

suboptimality  times 

  
  
  
  
 
 
 
 
 

   

   

   
   
    
    
mean number states expanded per move

    

    

figure     dynamic search depth control versus dynamic goal control 

ground level states far entry point  small caps compound problem sometimes
preventing selection optimal depth even entry point 
shown plot  running  i e   lrta   pdb  pdb   leads marginal improvements  best parameterizations lrta   f  pdb  already expands
single state per move virtually times  consequently  benefit adding dynamic
depth control slight improvement suboptimality next section 
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

upscaled maps

realtime cutoff      

   
lrta   f  pdb 
lrta   pdb  pdb 
pr lrta   f  g 
pr lrta   f  pdb 
pr lrta   pdb  pdb 
pr lrta   pdb  g 

suboptimality  times 

   

   

   

   

 

 

 

  
  
mean number states expanded per move

  

  

figure     effects path refinement  lrta  versus pr lrta  
    effects path refinement
path refinement algorithms  denoted pr prefix  run learning real time search  lrta  
abstract space refine path running a  ground level  non pr algorithm run
a  real time search happens ground level space  examine effects pathrefinement comparing lrta  pr lrta   note even statically controlled baseline
pr lrta   f  g  uses intermediate goals refining abstract actions  match using
dynamic intermediate goal selection lrta   thus  compare four versions pr lrta    f 
g    pdb  g    f  pdb   pdb  pdb  two versions lrta    f  pdb   pdb  pdb  
results found figure     sake clarity  show high performance area
capping number states expanded per move    suboptimality     
best parameterizations lrta  find near optimal solutions expanding one state
per move virtually times  astonishing performance one state expansion per
move corresponds search depth one fastest possible operation algorithm
framework  thus  lrta   f  pdb  lrta   pdb  pdb  virtually unbeatable terms
planning time  hand  pr lrta  incurs planning overhead due path refinement
component  i e   running corridor constrained a    result  pr lrta  finds nearlyoptimal solutions incurs least five times higher planning cost per move  dynamic control
pr lrta  results moderate performance gains 
    comparison existing state art
traditionally  computer games used a  pathfinding needs  stout         map size
number simultaneously planning agents increase  game developers find even highly optimized
implementations a  insufficient  result  variants a  use state abstraction
used  sturtevant         another way speeding a  introduce weight computing travel
cost state  done f   g   h    values   make agent
   

fidynamic c ontrol r eal  t ime h euristic earch

greedy  more weight put h  usually leads fewer states expanded price
suboptimal solutions  section  compare new algorithms weighted a   korf       
state of the art partial refinement a   pra    sturtevant   buro         note neither
algorithm real time and  thus  planning times per move map size specific  is 
larger maps  a s pra s planning times per move increase algorithms compute
complete  abstract  path start goal states take first move  instance 
maps used pra  expands      states expensive move  weighted a 
     expands       states classic a  expands       states worst moves  thus 
include two algorithms comparison effectively remove real time cut off 
results found table    dynamically controlled lrta  one two orders magnitude faster average planning time per move  produces shorter paths existing stateof the art real time algorithm  pr lrta   fastest weighted a  tried  original a 
provably optimal solution quality pra  nearly optimal  argue hundreds
units simultaneously planning paths computer game  lrta   pdb  pdb s low planning time per move real time guarantees worth      path length suboptimality  e g      
screen pixels versus optimal     screen pixels  

table    comparison high performance algorithms  best values bold  standard errors
reported  
algorithm  parameters
pr lrta   f  g                    
lrta   pdb  pdb          c       
a 
weighted a   f      g   h
pra 

planning per move
            
            
            
            
            

suboptimality  times 
            
            
      
            
            

    best solution quality time limit
section identify algorithms deliver best solution quality time limit 
specifically  impose hard limit planning time per move  expressed number states
expanded  algorithm exceeds limit even single move made    
problems upscaled maps excluded consideration  among remaining algorithms 
select one highest solution quality  i e   lowest suboptimality   results found
table    algorithms expand least one state per move move  leaving first row
empty  lrta   f  pdb             best choice time limit one
eight states expanded per move  limit rises  expensive optimal algorithms
become affordable  note best choices dynamically controlled algorithms
time limit rises      states  point  non real time pra  takes ending domain
real time algorithms  cross over point specific problem map sizes  larger
problems maps  pra s maximum planning time per move necessarily increase  making
best choice progressively higher planning time per move limits 
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

table    best solution quality strict limit planning time per move  planning time
states expanded per move  sake readability  suboptimality shown
percentage  e g                        
planning time limit
 
      
       
        
         
          
          
           
            
            
             
         

algorithm  parameters
lrta   f  pdb            
lrta   f  pdb            
lrta   f  pdb            
lrta   f  pdb            
lrta   f  pdb            
lrta   f  pdb             
pr lrta   pdb  g  c                   
pr lrta   pdb  g  c                   
pr lrta   pdb  g  c                     
pra 
a 

suboptimality    
        
       
       
       
       
       
       
       
       
       
  

    amortization pattern database build time
pattern database approach invests time computing pdb map  section
study amortization off line investment multiple problem instances  pdb build
times   ghz pentium cpu listed table   single map  consider algorithm lrta 
 pdb  pdb  cap c      pattern databases built level        average 
solution suboptimality       expanding       states per move        microseconds 
closest statically controlled competitor pr lrta   f  g                    
suboptimality       expanding average       states per move         microseconds  thus  lrta   pdb  pdb      microseconds faster move  consequently 
        moves necessary recoup off line pdb build time    hours  move
taking    microseconds  lrta  lower total run time first four hours
pathfinding  computed recoup times parameterizations lrta   pdb  pdb 
whose closest statically controlled competitor slower per move  results found table  
demonstrate lrta   pdb  pdb  recoups pdb build time first        hours
pathfinding time  note numbers highly implementation domain specific  particular  code building pdbs leaves substantial room optimization  completeness
sake  report detailed times appendix c 

   discussion empirical results
section recap trends observed previous sections  dynamic selection
lookahead either decision tree pdb approach helps reduce planning time per move
well solution suboptimality  section       result  lrta  becomes competitive
modern algorithms koenigs lrta   however  real time search algorithms global goals
scale well large maps 
   

fidynamic c ontrol r eal  t ime h euristic earch

table    pattern database average        map  computed intermediate goals  database
size listed number abstract state pairs  suboptimality planning per move
listed representative algorithm  lrta   pdb  pdb  cap c      
abstraction level
 
 
 
 
 
 
 
 

size
        
       
       
       
       
       
       
       

time
est    years
est      months
est    days
   hours
  hours
  hour
   minutes
   minutes

planning per move
   
   
    
     
     

suboptimality  times 
     
     
     
     
     

table    amortization pdb build times  dynamically controlled lrta   list
statically controlled pr lrta  closest terms solution suboptimality 
lrta   pdb  pdb 
c            
c            
c            
c            
c            
c            
c            
c            

pr lrta   f  g 
                  
                  
                  
                  
                  
                  
                  
                  

amortization moves
       
       
       
       
       
       
       
       

amortization run time
  hours
    hours
    hours
  hours
    hours
  hours
     hours
   hours

adding intermediate goals brings even classic lrta  par previous state of theart real time search algorithm pr lrta  much stronger addition dynamic lookahead
depth selection  section       using dynamic lookahead depth subgoals brings
improvements  section     details  lrta  equipped dynamic lookahead depth
subgoal selection expands barely state per move less    solution suboptimality 
better previous state of the art algorithms pr lrta   pra  a 
solution quality planning time per move  believe trade offs makes appealing
practice  aid practitioners further  provide algorithm selection guide section    
makes clear lrta  dynamic subgoal selection best algorithms time
per move severely limited  speed advantage deliver state of the art pr lrta 
algorithm allows recoup pdb build time several hours pathfinding 

   current limitations future work
project opens several interesting avenues future research  particular  would worthwhile investigate performance algorithms paper dynamic environments  e g  
bridge gets destroyed real time strategy game goal moves away agent  
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

another area future research application proposed algorithms general planning 
heuristic search successful approach planning planners asp  bonet 
loerincs    geffner         hsp family  bonet   geffner          hoffmann        
sherpa  koenig  furcy    bauer        ldfs  bonet   geffner         line recent
planning work  likhachev   koenig        bonet geffner         evaluate
proposed algorithms general strips style planning problem  nevertheless  believe
new real time heuristic search algorithms may offer benefits wider range planning
problems  indeed  core heuristic search algorithm extended paper  lrta   previously applied general planning  bonet et al          extensions introduced may
beneficial effect similar way b lrta  improved performance asp planner 
subgoal selection long studied planning central part intermediate goal
depth table approach  decision trees search depth selection induced sample trajectories space appear scalable general planning problems  part
approach requires solving numerous ground level problems optimally pre computation
optimal search depth pdb approach  conjecture approach still effective if 
instead computing optimal search depth based optimal action   one solve
relaxed planning problem use resulting action place   idea deriving heuristic
guidance solving relaxed problems quite common planning heuristic search
community 

    conclusions
real time pathfinding non trivial problem algorithms must trade solution quality
amount planning per move  two measures antagonistic thus interested
pareto optimal algorithms outperformed measures algorithms 
classic lrta  provides smooth trade off curve  parameterized lookahead depth  since
introduction       variety extensions proposed  recent extension 
pr lrts  bulitko et al         first application automatic state abstraction real time
search  large scale empirical study pathfinding game maps  pr lrts outperformed
many algorithms respect several antagonistic measures  bulitko et al         
paper employ automatic state abstraction instead using pathrefinement  pre compute pattern databases use select amount planning
intermediate goals dynamically  per move  several mechanisms dynamic control proposed used virtually existing real time search algorithm  demonstration 
equip classic lrta  state of the art pr lrts dynamic control 
resulting improvements substantial  instance  lrta  equipped pdb based control
lookahead intermediate goal selection significantly outperforms existing state art  pr
lrts  simultaneously planning per move solution quality  furthermore  average expands little one state per move minimum amount planning
lrta  based algorithm 
new algorithms compare favorably a  state of the art extension  pra  
presently popular industrial choices pathfinding computer games  stout        sturtevant 
       first  per move planning time algorithms provably unaffected increase
map size  second  two orders magnitude faster a  one order magnitude
faster pra  planning time per move  improvements come price   
   

fidynamic c ontrol r eal  t ime h euristic earch

suboptimality  likely unnoticed computer game player scenarios  thus appears
new algorithms redefine state art real time search arena
well suited industrial applications 

acknowledgments
sverrir sigmundarson school computer science  reykjavik university
project  appreciate consultation robert c  holte detailed feedback anonymous
reviewers  research supported grants national science engineering research council canada  nserc   albertas informatics circle research excellence  icore  
slovenian ministry higher education  science technology  icelandic centre research
 rannis   marie curie fellowship european community programme structuring
era contract number mirg ct              special thanks nathan sturtevant
development support hog 

appendix a  decision tree features
devised two different categories classifier features  first consists features based
agents recent history  whereas second contains features sampled shallow pre search
agents current state  thus  collectively  features two categories make predictions
based agents recent history well current situation 
first category four features listed table    features computed
execution step  aggregated recent states agent in 
done incremental fashion improved performance  parameter n set user
controls long history aggregate over  use notation s  refer state agent
one step ago  s  state two steps ago  etc   agent thus aggregates states s   
     sn   feature f  provides rough estimate location agent relative goal 
distance goal state affect required lookahead depth  example heuristics
closer goal usually accurate  feature makes possible classifier make
decisions based deemed necessary  features f   known mobility  f  provide
measure much progress agent made towards reaching goal past steps 
frequent state revisits may indicate heuristic depression deeper search usually beneficial
situations  ishida         feature f  measure inaccuracies inconsistencies
heuristic around agent  again  many heuristic updates may warrant deeper search 
features second category listed table    computed execution step  planning phase starts  shallow lookahead pre search performed gather
information nearby part search space  types features category
coarsely divided features  i  compute fraction states pre search lookahead
frontier satisfy property   ii  compare action chosen pre search previous
actions  either previous state taken last time current state visited    iii 
check heuristic estimates immediate successors current state  feature f  rough
measure density obstacles agents vicinity  obstacles are 
beneficial deeper search might be  feature f  indicator difficulty traversing
local area  proportion high  many states updated  possibly suggesting heuristic
depression  feature f    pre search selects action might indicate
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

table    history based classifier features 
feature
f 
f 
f 
f 

description
initial heuristic estimate distance current state goal 
hoctile  s  sglobal goal   
heuristic estimate distance current state state
agent n steps ago  h s  sn   
number distinct states agent visited last n steps 
  s    s         sn    
p
total volume heuristic updates last n steps  ni   hafter update  si  
hbefore update  si    line   figure    
table    pre search based classifier features 

feature
f 
f 
f 

f 
f 
f  
f  

description
ratio actual number states pre search frontier expected
number states obstacles map 
fraction frontier states updated heuristic value 
boolean feature telling whether action chosen pre search
action chosen planning phase last time state visited 
first time state visited feature false 
boolean feature telling whether direction suggested pre search
direction agent took previous step 
ratio current states heuristic best successor state suggested
pre search  h s  sgoal   h s  sgoal   
boolean feature telling whether best action proposed pre search phase
would lead successor state updated heuristic value 
boolean feature telling whether heuristic value current state larger
heuristic value best immediate successor found pre search 

heuristic values part search space already mutually consistent thus
shallow lookahead needed  applies feature f    features f  f   compare current
state successor state suggested pre search 

appendix b  experiments upscaled maps using global goals
empirical results running global goal algorithms upscaled maps shown figure    
lrta   dt  g  shows significant improvement lrta   f  g   making comparable
quality existing state of the art algorithms  par p lrta   f  g  slightly better
k lrta   f  g  allowed expand     states per move  worth noting
lrta   pdb  g  longer competitive algorithms and  fact  make
real time cut off      states parameters combinations  and thus shown
plot   reason lies fact problems simply difficult lrta  find
optimal move small lookahead depth  instance  abstraction level       cap
   

fidynamic c ontrol r eal  t ime h euristic earch

c       lrta   pdb  g  suboptimality       unfortunately  lookahead depth hits cap
    visited states  result  algorithm expands average      states per move
disqualifies cut off      
upscaled maps

realtime cutoff      

  
lrta   f  g 
lrta   dt  g 
p lrta   f  g 
k lrta   f  g 

  

suboptimality  times 

  
  
  
  
 
 
 
 
 

   

   

   
   
   
   
mean number states expanded per move

   

   

figure     performance global goal algorithms upscaled maps 
looking collectively small upscaled map results  lrta   dt  g  demonstrates
excellent performance among global goal algorithms robust respect map
upscaling one efficient ones  the comparable algorithm k lrta   f  g   
however  within provided      states cut off limit  none real time global goal algorithms
returned solutions would considered acceptable quality pathfinding  indeed  even
best solutions found approximately four times worse optimal 

appendix c  pattern database build times
order operate lrta  pr lrta  use lookahead depth intermediate goals controlled dynamically  build pattern databases  pattern database built off line contains
single entry pair abstract states  three types entries   i  intermediate goal
ground level entry state next abstract state   ii  capped optimal lookahead depth
respect intermediate goal  iii  optimal lookahead depth respect global
goal  running algorithms capped lookaheads  i e   c         need two databases
per map  one containing intermediate goals one containing capped optimal lookahead depths 
running effectively uncapped algorithms  i e   c        c         need third
database lookahead depths global goals  see appendix discussion   tables  
    report build times lrta   pdb  pdb  performance capped  i e  
build two pattern databases   tables       report build times performance
effectively cap  i e   built three pattern databases  
finally  interest speeding experiments fact compute pattern databases
pairs abstract states  instead  took advantage prior benchmark problem availability
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

table    pattern databases average         map  computed intermediate goals 
database size listed number abstract state pairs  suboptimality planning
per move listed lrta   pdb  pdb  cap c      
abstraction level
 
 
 
 
 
 
 
 

size
        
       
       
       
       
       
       
       

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
    
     
     

suboptimality  times 
     
     
     
     
     

table     pattern databases average         map  computed intermediate goals 
database size listed number abstract state pairs  suboptimality planning
per move listed lrta   pdb  pdb  cap c      
abstraction level
 
 
 
 
 
 
 
 

size
        
       
       
       
       
       
       
       

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
    
     
     

suboptimality  times 
     
     
     
     
     

computed pdbs abstract goal states come play problems agents
solve  thus  times tables estimates possible pairs 

appendix d  intermediate goals loops
shown korf original paper  lrta  complete lookahead depth
heuristic taken respect single global goal  completeness guarantee lost one
uses intermediate goals  i e   lrta   f  pdb   lrta   pdb  pdb  well pr lrta 
counter parts   indeed  abstract tile a  dynamic goal control module guide
agent towards entry state tile b  however  way  agent may stumble different
abstract tile c  soon happens  dynamic control module may select entry state tile
new intermediate goal  unsuspecting agent heads back everything repeats 
combat loops equipped algorithms use intermediate goals state reentrance detector  namely  soon agent re visits ground level state  dynamic control
switches intermediate goal global goal  additionally  new lookahead depth selected  ideally  lookahead depth optimal depth respect global goal 
   

fidynamic c ontrol r eal  t ime h euristic earch

table     pattern databases average         map  computed intermediate goals 
database size listed number abstract state pairs  suboptimality planning
per move listed lrta   pdb  pdb  cap c      
abstraction level
 
 
 
 
 
 
 
 

size
        
       
       
       
       
       
       
       

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
    
     
     

suboptimality  times 
     
     
     
     
     

table     pattern databases average         map  computed intermediate goals 
database size listed number abstract state pairs  suboptimality planning
per move listed lrta   pdb  pdb  cap c      
abstraction level
 
 
 
 
 
 
 
 

size
        
       
       
       
       
       
       
       

time
est    years
est      months
est    days
     hours
    hours
    hours
   minutes
   minutes

planning per move
   
    
     
     
     

suboptimality  times 
     
     
     
     
     

capped c  unfortunately  computing optimal lookahead depths global goals quite expensive
off line  tables         given loops occur fairly infrequently  normally compute
optimal lookahead depths global goals  instead  state re visit detected  switch
global goals simply set lookahead cap c  saves off line pdb computation time
sometimes causes agent conduct deeper search  c plies  really necessary  
alternative solution investigated future research progressively increase lookahead on line re visits detected  i e   every time re visit occurs  lookahead depth
state increased certain number plies  

   exception practice cases c        c        setting lookahead depth c
would immediately disqualified algorithm  provided reasonable real time cut off  consequently 
two cap values  invest large amount time computed effectively uncapped optimal lookahead depth
respect global goals 

   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

table     pattern databases average         map  computed global goals  database
size listed number abstract state pairs  suboptimality planning per move
listed lrta   pdb  pdb  cap c        
abstraction level
 
 
 
 
 
 
 
 

size
        
       
       
       
       
       
       
       

time
est      years
est     years
est    years
   days
     days
    days
    hours
    hours

planning per move
   
   
    
    
     

suboptimality  times 
     
     
     
     
     

table     pattern databases average         map  computed global goals  database
size listed number abstract state pairs  suboptimality planning per move
listed lrta   pdb  g  cap c      
abstraction level
 
 
 
 
 
 
 
 

size
        
       
       
       
       
       
       
       

time
est     years
est    months
est     days
     hours
    hours
    hours
   minutes
   minutes

   

planning per move
     
     
     
     
     

suboptimality  times 
     
     
      
     
      

fidynamic c ontrol r eal  t ime h euristic earch

references
bioware corp          baldurs gate   published interplay  http   www bioware com bgate  
november          
bjornsson  y     marsland  t  a          learning extension parameters game tree search  inf 
sci                 
blizzard         warcraft    reign chaos  http   www blizzard com war  
bonet  b     geffner  h          planning heuristic search  artificial intelligence          
    
bonet  b     geffner  h          learning depth first search  unified approach heuristic search
deterministic non deterministic settings  application mdps  proceedings
international conference automated planning scheduling  icaps   pp     
     cumbria  uk 
bonet  b   loerincs  g     geffner  h          fast robust action selection mechanism
planning   proceedings national conference artificial intelligence  aaai   pp 
        providence  rhode island  aaai press   mit press 
botea  a   muller  m     schaeffer  j          near optimal hierarchical path finding  journal
game development            
bulitko  v       a   lookahead pathologies meta level control real time heuristic search 
proceedings   th euromicro conference real time systems  pp        porto 
portugal 
bulitko  v       b   lookahead pathologies meta level control real time heuristic search 
proceedings   th euromicro conference real time systems  pp       
bulitko  v          learning adaptive real time search  tech  rep  http   arxiv org abs cs ai 
         computer science research repository  corr  
bulitko  v   bjornsson  y   lustrek  m   schaeffer  j     sigmundarson  s          dynamic control path planning real time heuristic search  proceedings international
conference automated planning scheduling  icaps   pp        providence  ri 
bulitko  v   li  l   greiner  r     levner  i          lookahead pathologies single agent search 
proceedings international joint conference artificial intelligence  ijcai   pp 
          acapulco  mexico 
bulitko  v   sturtevant  n     kazakevich  m          speeding learning real time search via
automatic state abstraction  proceedings national conference artificial intelligence  aaai   pp            pittsburgh  pennsylvania 
bulitko  v   sturtevant  n   lu  j     yau  t          graph abstraction real time heuristic
search  journal artificial intelligence research  jair             
buro  m          experiments multi probcut new high quality evaluation function
othello  van den herik  h  j     iida  h   eds    games ai research  pp        u 
maastricht 
culberson  j     schaeffer  j          searching pattern databases  csci  canadian ai
conference   advances artificial intelligence  pp          springer verlag 
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

culberson  j     schaeffer  j          pattern databases  computational intelligence            
    
dijkstra  e  w          note two problems connexion graphs   numerische mathematik 
          
furcy  d          itsa   iterative tunneling search a   proceedings national
conference artificial intelligence  aaai   workshop heuristic search  memory based
heuristics applications  boston  massachusetts 
furcy  d     koenig  s          speeding convergence real time search  proceedings
national conference artificial intelligence  aaai   pp         
hart  p   nilsson  n     raphael  b          formal basis heuristic determination
minimum cost paths  ieee transactions systems science cybernetics               
hernandez  c     meseguer  p       a   improving convergence lrta  k   proceedings
international joint conference artificial intelligence  ijcai   workshop planning
learning priori unknown dynamic domains  edinburgh  uk 
hernandez  c     meseguer  p       b   lrta  k   proceedings   th international joint
conference artificial intelligence  ijcai   edinburgh  uk 
hernandez  c     meseguer  p          improving real time heuristic search initially unknown
maps  proceedings international conference automated planning scheduling
 icaps   workshop planning games  p     providence  rhode island 
hoffmann  j          heuristic domain independent planning use enforced hillclimbing algorithm  proceedings   th international symposium methodologies
intelligent systems  ismis   pp         
id software         doom   published id software  http   en wikipedia org  wiki doom  december          
ishida  t          moving target search intelligence  proceedings national conference
artificial intelligence  aaai   pp         
kitano  h   tadokoro  s   noda  i   matsubara  h   takahashi  t   shinjou  a     shimada  s         
robocup rescue  search rescue large scale disasters domain autonomous agents
research  man  systems  cybernetics  pp         
kocsis  l          learning search decisions  ph d  thesis  university maastricht 
koenig  s          comparison fast search methods real time situated agents  proceedings international joint conference autonomous agents multiagent systems
 aamas   pp         
koenig  s          agent centered search  ai magazine                
koenig  s   furcy  d     bauer  c          heuristic search based replanning  proceedings
int  conference artificial intelligence planning scheduling  pp         
koenig  s     likhachev  m          real time adaptive a   proceedings international
joint conference autonomous agents multiagent systems  pp         
korf  r          depth first iterative deepening   optimal admissible tree search  artificial
intelligence               
   

fidynamic c ontrol r eal  t ime h euristic earch

korf  r          real time heuristic search  artificial intelligence                 
korf  r          linear space best first search  artificial intelligence           
likhachev  m   ferguson  d   gordon  g   stentz  a     thrun  s          anytime dynamic a  
anytime  replanning algorithm  proceedings international conference automated
planning scheduling  icaps  
likhachev  m   gordon  g  j     thrun  s          ara   anytime a  provable bounds
sub optimality  thrun  s   saul  l     scholkopf  b   eds    advances neural information processing systems     mit press  cambridge  ma 
likhachev  m     koenig  s          generalized framework lifelong planning a   proceedings international conference automated planning scheduling  icaps  
pp        
lustrek  m          pathology single agent search  proceedings information society conference  pp          ljubljana  slovenia 
lustrek  m     bulitko  v          lookahead pathology real time path finding  proceedings
national conference artificial intelligence  aaai   workshop learning search 
pp          boston  massachusetts 
mero  l          heuristic search algorithm modifiable estimate  artificial intelligence     
     
moore  a     atkeson  c          prioritized sweeping  reinforcement learning less data
less time  machine learning             
nash  a   daniel  k     felner  s  k  a          theta   any angle path planning grids 
proceedings national conference artificial intelligence  pp           
pearl  j          heuristics  addison wesley 
rayner  d  c   davison  k   bulitko  v   anderson  k     lu  j          real time heuristic search
priority queue  proceedings international joint conference artificial
intelligence  ijcai   pp            hyderabad  india 
russell  s     wefald  e          right thing  studies limited rationality  mit press 
schaeffer  j          history heuristic alpha beta search enhancements practice  ieee
transactions pattern analysis machine intelligence  pami                 
schaeffer  j          search ideas chinook  van den herik  h  j     iida  h   eds    games
ai research  pp        u  maastricht 
shimbo  m     ishida  t          controlling learning process real time heuristic search 
artificial intelligence              
sigmundarson  s     bjornsson  y          value back propagation vs  backtracking realtime search  proceedings national conference artificial intelligence  aaai  
workshop learning search  pp          boston  massachusetts  usa 
stenz  a          focussed d  algorithm real time replanning  proceedings
international joint conference artificial intelligence  ijcai   pp           
stout  b          basics a  path planning  game programming gems  charles river
media 
   

fib ulitko   l u strek   chaeffer   b j ornsson   igmundarson

sturtevant  n          memory efficient abstractions pathfinding  proceedings third
conference artificial intelligence interactive digital entertainment  pp        stanford  california 
sturtevant  n     buro  m          partial pathfinding using map abstraction refinement 
proceedings national conference artificial intelligence  pp           
sturtevant  n     jansen  r          analysis map based abstraction refinement 
proceedings  th international symposium abstraction  reformulation approximation  whistler  british columbia 
witten  i  h     frank  e          data mining  practical machine learning tools techniques
  nd edition   morgan kaufmann  san fransisco 

   


