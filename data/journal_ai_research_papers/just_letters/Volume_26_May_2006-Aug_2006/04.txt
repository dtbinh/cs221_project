journal of artificial intelligence research                  

submitted        published      

convexity arguments for efficient minimization of the
bethe and kikuchi free energies
tom heskes

t heskes science ru nl

iris  faculty of science  radboud university nijmegen
toernooiveld         ed  nijmegen  the netherlands

abstract
loopy and generalized belief propagation are popular algorithms for approximate inference in markov random fields and bayesian networks  fixed points of these algorithms
have been shown to correspond to extrema of the bethe and kikuchi free energy  both of
which are approximations of the exact helmholtz free energy  however  belief propagation does not always converge  which motivates approaches that explicitly minimize the
kikuchi bethe free energy  such as cccp and ups 
here we describe a class of algorithms that solves this typically non convex constrained
minimization problem through a sequence of convex constrained minimizations of upper
bounds on the kikuchi free energy  intuitively one would expect tighter bounds to lead to
faster algorithms  which is indeed convincingly demonstrated in our simulations  several
ideas are applied to obtain tight convex bounds that yield dramatic speed ups over cccp 

   introduction
pearls belief propagation  pearl        is a popular algorithm for inference in bayesian
networks  it is known to be exact in special cases  e g   for tree structured  singly connected 
networks with just gaussian or just discrete nodes  but also on networks containing cycles 
so called loopy belief propagation empirically often leads to good performance  approximate
marginals close to exact marginals   murphy  weiss    jordan        mceliece  mackay 
  cheng         the notion that fixed points of loopy belief propagation correspond to
extrema of the so called bethe free energy  yedidia  freeman    weiss        is an important
step in the theoretical understanding of this success 
the kikuchi free energy  kikuchi        is a generalization of the bethe free energy that
can lead to better approximations of the exact helmholtz free energy  just like fixed points
of loopy belief propagation correspond to extrema of the bethe free energy  fixed points
of an algorithm called generalized belief propagation  yedidia et al         correspond to
extrema of the kikuchi free energy 
a problem with loopy and generalized belief propagation is that they do not always
converge to a stable fixed point  new algorithms  yuille        teh   welling        have
been derived that therefore explicitly minimize the bethe and kikuchi free energy  as we will
describe in section    minimization of the kikuchi free energy corresponds to a usually nonconvex constrained minimization problem  non convex constrained minimization problems
are known to be rather difficult to solve  so in section   we will first derive sufficient
conditions for the kikuchi free energy to be convex  over the set of constraints   in section  
we will then derive a class of converging double loop algorithms  in which each inner loop
corresponds to constrained minimization of a convex bound on the kikuchi free energy 
c
    
ai access foundation  all rights reserved 

fiheskes

and each outer loop step to a recalculation of this bound  based on the intuition that the
tightest bound yields the fastest algorithm  we come up with several ideas to construct
tight bounds  we will see that yuilles        cccp algorithm corresponds to a special
case of a rather loose bound and discuss the relationship with the ups algorithm by teh
and welling        in section      the simulations in section   illustrate the use of tight
convex bounds on several inference problems  implications and other issues are discussed
in section    technical details are treated in the appendices 

   the kikuchi approximation
exact inference in graphical models is often intractable  in this section we will introduce
the kikuchi approximation as a particular example of a variational approach towards approximate inference 
    graphical models
an undirected graph g    v  e  consists of set of nodes or vertices v               n   that
are joined by a set of edges e  we place at each node i a variable xi which takes values in
a finite discrete alphabet  the vector containing all variables is denoted x   x            xn   
let  be a subset of v   we call  a region  a clique is any fully connected subset of v   c is
a set of cliques  the potential  also referred to as compatibility or kernel function    x  
is a strictly positive function that only depends on the variables that are part of the clique
  we define the probability distribution or probability mass function
pexact  x  

  y
  x    
z

   

c

where z is the normalizing constant  often called partition function  the hammersleyclifford theorem  besag        guarantees us that the underlying probability process is
markov with respect to the graph and  vice versa  that the distribution of any markov random field over g that is strictly positive can be expressed in this form  through the process
of moralization  any directed graphical model  bayesian network  can be transformed into a
corresponding undirected model  consequently  the probability distribution corresponding
to a bayesian network can also be written in the form      lauritzen        
computing the partition function z  as well as computing marginals on subsets of variables  in principle requires summation over an exponential number of states  to circumvent
this exponential summation there are two kinds of approaches  sampling techniques and
variational methods  with sampling  one draws samples from the exact probability distribution  the variational methods try to find an approximation to the exact probability
distribution 
    variational methods
variational methods are often derived from an approximation of the so called free energy
x
xx
p x   log   x    
p x  log p x   e p   s p   
   
f  p    
c x

x

   

fiefficient minimization of the kikuchi free energy

the first term  e p   is referred to as the energy  the second term s p  as the entropy 
functional minimization of f  p  with respect to functions p x  under the constraint that
p x  is properly normalized yields pexact  x   furthermore  the partition function z then
follows from
 log z   f  pexact    
when we stick to the exact free energy      we do not really gain anything  the entropy
part s p  still consists of a sum over exponentially many terms  variational methods are
based on a tractable approximation of the free energy  they can be roughly divided into two
classes  the mean field and the kikuchi approximations  in the mean field approach one
confines the minimization of the free energy to a restricted class t of  tractable  probability
distributions instead of considering the class p of all probability distributions 
 log z   f  pexact     min f  p   min f  p   
pp

pt

the crux is to choose the class t such that the entropy s p  becomes tractable for all p  t  
note however that this restriction typically also affects the energy term e p   jordan 
ghahramani  jaakkola    saul        jaakkola   jordan        
the kikuchi approximation of the free energy     leaves the energy term as is and
approximates the entropy s p  through a combination of marginal entropies 
x
x
s p   
p x  log p x   
c s  p 
r

x

 

x

c

r

x

p x   log p x    

   

x

here r denotes a collection of so called regions  the parameters c are called moebius or
overcounting numbers 
      partially ordered sets
following pakzad and anantharam               we will use the language of partially ordered
sets or posets  specifically  the collection r of regions can be viewed as such a poset where
the ordering is defined with respect to the inclusion operator   a region  includes a
region     written       if all variables in   are also part of   we use     to denote
strict inclusion  i e       and       we say that  covers   in r  written       if
    and there exists no    r such that          we can visualize a poset with a
so called hasse diagram or region graph  see the examples below   given a particular poset
r  its hasse diagram gr is a directed acyclic graph  whose vertices are the elements of r 
and whose edges corresponds to the cover relationships  that is  there is an edge from  to
  iff      
    the cluster variation method
in kikuchis        original cluster variation method  cvm   the collections of regions and
overcounting numbers are constructed as follows  we start by defining a collection o of
outer regions  the minimal choice is the original set of cliques c  but we can also choose to
   

fiheskes

combine cliques and construct larger ones  similar to the process of triangulation  lauritzen 
       for convenience  we redefine the potentials correspondingly  i e   such that there is
precisely one potential   x   per outer region   see the example below  
given these outer regions  we construct new regions by taking the intersections of these
outer regions  the intersections of intersections  and so on  until no more intersections can
be made  we will refer to the regions constructed in this way as inner regions  combined
in the collection i  the collection of all regions r in     is now the union of the outer and
inner regions  r   o  i 
the overcounting or moebius numbers in the original cvm follow from the moebius
formula
x
   
c     
c   
  

by definition we have c     for all outer regions   o 
the bethe free energy can be considered a special case of the kikuchi free energy  in the
bethe free energy there are no intersectionspof intersections  i e   there is only one level of
inner regions with c      n where n  o    equals the number of outer regions
covering inner region  
      alternatives
several alternatives to the original cvm  with weaker constraints and or other constraints
on the choice of regions and overcounting numbers  have been proposed recently  yedidia 
freeman  and weiss        present an overview  the particular choice of inner regions
subsets and overcounting numbers in junction graphs  aji   mceliece        and join
graphs  dechter  kask    mateescu        leads to an entropy approximation in which
all overcounting numbers for the inner regions are negative  the resulting algorithms are
very similar to the junction tree algorithm  but then applied to a graph with loops  the
entropy approximation that follows from the original cluster variation method takes into
account all entropy contributions up to the level of the outer regions in a consistent manner
and  on theoretical grounds  there seems to be no reason to deviate from that  pakzad
  anantharam         in this paper  we therefore focus on the original cluster variation
method  but our analysis holds much more generally for any poset or region graph 
    constrained minimization
the kikuchi approximation of the free energy only depends on the marginals p x   for
all   r  we now replace the minimization of the exact free energy over the complete
distribution p x  by minimization of the kikuchi free energy
xx
x x
fkikuchi  q    
q  x   log   x    
c
q  x   log q  x  
   
o x

r

   

x

fiefficient minimization of the kikuchi free energy

over all pseudo marginals q   q     r  under the consistency and normalization constraints
q  x      r x
x

q  x       r

 positive 

  a 

 normalized 

  b 

 consistent 

  c 

x

x

q   x      q  x      r   

x   

referring to the class of pseudo marginals satisfying these constraints as q  we have the
approximation
 log z  min fkikuchi  q   
qq

furthermore  the hope is that the pseudo marginals q  x   corresponding to this minimum are accurate approximations of the exact marginals pexact  x    the kikuchi free
energy and corresponding marginals are exact if the hasse diagram turns out to be singlyconnected  pakzad   anantharam        
    illustration
for illustration of the main concepts  we consider a probability model with   variables
 nodes  and pairwise interactions between each of the nodes as visualized in figure   a  
in obvious shorthand notation  the exact distribution is of the form
  y
 
pexact  x   
ij  xi   xj                        
z
z
 i j 

note here that potentials originally defined on single nodes can always be incorporated in
the definition of the two node potentials  the region graph corresponding to the minimal
choice of outer regions  i e   equivalent to the potential subsets  is given in figure   b  
with the outer regions all pairs of nodes  the inner regions subsets are all single nodes  in
fact  in this case the region graph is equivalent to a so called factor graph  kschischang 
frey    loeliger        and the kikuchi approximation of the free energy boils down to a
bethe approximation 
xx
qij  xi   xj   log ij  xi   xj  
fkikuchi  q    
 i j  xi  xj

 

xx

qij  xi   xj   log qij  xi   xj    

 i j  xi  xj

x
x
    ni  
qi  xi   log qi  xi    
i

xi

where ni     is the number of outer regions containing the inner region i 
the cluster variation method allows us to choose larger outer regions  for example 
consisting of all triples  i  j  k   we redefine the factorization of the potentials such that
pexact  x   

  y
ijk  xi   xj   xk                      
z
 i j k 

   

fiheskes

 
x 

x 

ee
ee yyy
eyey
yy eee
y
e
yy

 

 

 

 

 

     i      i      i     
    
    
   ii
ii 
ii 
u
u
u
u
ii
ii
u
   iii
uu
uu 
   iii  iiii  iuiuiuiu
uu 
u
  
i
ii uu ii uu

iuiu
iu
  iiii

uuuii
uu i
 
 
 
 

x 

x 

  

 a  markov random field 

  

  

  

 b  hasse diagram for the bethe approximation 

 

 

 

 

       i        i        i        

ii    
iu
iu

ii
uuii
uuii 
 uuu iii uuu iii
 ii    


ii  
i
i
u
u



i
i
u
u i
ii   
i
u
u


ii
ii
 uuu
ii  
uu



i
i
u
i
 uu
 i
 i
uu

     i      i      i     
    
    
   ii
ii 
ii 
u
u
u
u
i
i
i
u
u
ii
ii uu    uu   
ii
         
  
  
u
   iiii  iiii  uuiuiuii
uu 
ii
ii uuu
ii uu
  



ui

 ii
uuuii
uu i
 
 
 
 
 

 

 

 

 c  region graph for the kikuchi approximation 
figure    region graphs for the bethe and kikuchi approximations  lines between nodes
in the markov random field  a  indicate edges  in the region graphs  b  and  c  
the outer regions are drawn at the highest level  lines indicate the covering
relationship  where lower regions are covered by the higher regions  the oblique
numbers are the overcounting numbers that follow from the moebius formula 
the bethe approximation  b  corresponds to the minimal approximation with
the outer regions equivalent to the cliques in the graph  here all pairs of nodes 
the particular kikuchi approximation  c  follows by taking for the outer regions
all node triples 

   

fiefficient minimization of the kikuchi free energy

for example through  distribute symmetrically 
 

                  

 

                  

 

                  

 

                    
or through  assign to the first outer region 
             
          
       
        
the corresponding region graph is given in figure   c   now the first level inner regions
are all pairs of nodes and the second level inner regions are all single nodes  with overcounting numbers    and    respectively  the kikuchi approximation of the entropy boils down
to
x
x
x
skikuchi  q   
sijk 
sij  
si  
 i j k 

 i j 

i

the intuitive reasoning behind this approximation is as follows  the sum over all threenode entropies overcounts the two node interactions  each combination  i  j  appears twice
rather than once   which therefore have to be discounted once  but now the single node
interactions are too much discounted  overcounting number    times   appearances  compared with the   appearances with overcounting number   in the three node entropies  
yielding the overcounting number                       
    generalized and loopy belief propagation
to summarize  finding the kikuchi approximation of the partition function z boils down
to minimization of the kikuchi free energy with respect to a set of pseudo marginals under
linear constraints between them  introducing lagrange multipliers for these constraints  it
can be shown that fixed points of a popular algorithm called loopy belief propagation correspond to extrema of the bethe free energy and  more generally  fixed points of generalized
belief propagation to extrema of the kikuchi free energy  yedidia et al          however 
these algorithms are not guaranteed to converge to a minimum and in practice do get stuck
in for example limit cycles  this explains the search for convergent alternatives that directly
minimize the kikuchi free energy  which will be the topic of the rest of this paper 

   convexity of the kikuchi free energy
in this section we will derive sufficient conditions for the kikuchi free energy to be convex
over the set of consistency constraints      this is relevant because if the kikuchi free
energy is indeed convex over the constraint set  it must have a unique minimum and the
minimization problem is relatively straightforward  furthermore  the argument that we will
   

fiheskes

use in deriving these conditions will play an important role in the construction of efficient
minimization algorithms later on 
    sufficient conditions
we have to consider the kikuchi free energy     as a function of the pseudo marginals q 
in reasoning about convexity  we can disregard the energy term being linear in q  the
entropy terms give either a convex or a concave contribution  depending on whether the
corresponding overcounting numbers are positive or negative  respectively  ignoring the
constraints      the free energy     is convex if and only if all concave contributions vanish 
i e   c     for all   r  
however  we really only care about the subspace induced by the constraints      therefore we introduce the notion of convexity over the set of constraints  we call the free energy
convex over the set of constraints     if
f  q         q     f  q           f  q         q   q  q  
note that  since the constraints are all linear  if q  and q  satisfy the constraints      then
so does q         q    in the following  when we talk about convexity of the kikuchi free
energy  the conditioning on the constraint set is implicitly assumed 
one way to proceed is to make use of the  consistency  constraints to express the kikuchi
free energy in terms of the outer region pseudo marginals only and then study its convexity 
our approach is along these lines  in particular  we will replace inner region pseudomarginals that correspond to concave contributions by outer region pseudo marginals  the
pseudo marginals corresponding to convex contributions are of no concern  in fact  we may
be able to use these convex contributions as well to compensate for some of the concave
contributions 
to make this reasoning more precise  we define positive regions  or perhaps better 
nonnegative    r    with r      r  c      o  i  and negative regions   r  
with r     r  c       i   the idea  formulated in the following theorem  is then
that the kikuchi free energy is convex if we can compensate the concave contributions of
the negative regions r by the convex contributions of the positive regions r   
theorem      the kikuchi free energy is convex over the set of constraints     if there
exists an allocation matrix a between positive regions   r  and negative regions
  r satisfying
a      only if   

  can be used to compensate  

  a 

a   
x
a  c

 positivity 

  b 

 sufficient amount of resources 

  c 

 sufficient compensation 

  d 

r 



x

a   c  

r



   

fiefficient minimization of the kikuchi free energy

proof first of all  we note that we do not have to worry about the energy terms that are
linear in q  in other words  to prove the theorem we can restrict ourselves to showing that
minus the entropy


x
x
s q     
c s  q   
 c  s  q  
r 

r

is convex over the set of constraints 
as an intermediate step  let us consider the combination of a convex entropy contribution
of a positive region   r  with the concave entropy contribution of a negative inner region
  r   where  is a subset of  
x
x
  q    s  q   s  q    
q  x   log q  x   
q  x   log q  x  
x

 

x

q  x   log q  x   

 

x

q  x   log q  x  

x

x

x

x

x



q  x   

x

x 



q  x   x   log q  x   x    

where we used the standard definitions
x
q  x  
q  x   and q  x   x   
q  x   
 
q  x  
x
 

in the first step  we applied the constraint q  x     q  x   and extended the summation
over x in the second term to a summation over x   in the second step we basically turned
the difference between two entropies into  a weighted sum of  conditional entropies  the
difference    which now only depends on q   is  from lemma a   in appendix a  convex
in q   in other words  the concave contribution from s is fully compensated by the convex
contribution s   yielding an overall convex term in the relevant set of constraints 
the resulting operation is now a matter of resource allocation  for each concave contribution  c  s we have to find convex contributions s to compensate for it  let a denote
the amount of resources that we take from positive region   r  to compensate for
negative region   r   obviously  a positive region can only compensate negative regions
that it contains  so a     when  is not a subset of   which explains condition   a  
now  in shorthand notation and with a little bit of rewriting


x
x
 c  s 
c s 
s q     
r 

 

x

r 

 

x

r 



c 



c 

r

x

a  



x



x







a  s 

a  s 

x x

r  

   

x

r





x

a  



a  s  s   

x



x

r






a   c   s

x





a   c   s  

fiheskes

p
convexity of the first term is guaranteed
p if c   a      c   of the second term if
a      b   and of the third term if  a   c        d  

    checking the conditions

checking the conditions of theorem     can be cast in the form of a linear programming
problem  for example as follows  we define an auxiliary variable  replacing condition   c 
by
x
   
a    c   r  variable compensation 


then we solve the linear programming problem that attempts to maximize the single variable  under all constraints implied by the four conditions  the interpretation is that we
try to use the available resources to compensate for as much of the concave contributions
as we can  if we find a solution     all conditions are satisfied  the kikuchi free energy
is convex over the set of constraints and has a unique minimum  if the optimal  turns
out to be smaller than    there is no matrix a satisfying all constraints and convexity of
the kikuchi free energy is not guaranteed by theorem     
instead of solving the linear program  we can often get away with simpler checks  for
example  we can guess a particular a and check whether the conditions     hold  an obvious
choice is
x
c
a    with n
  
 
n
r  


which satisfies condition   c  and when substituted into   d  yields the condition
x

c  

r   

c
 
n


r  

   

similarly  the choice
a  

x
 c  
 
with
n

 

n 

r  
 

satisfies condition   d  and yields the condition
x

r  

c
  c    r 
n 


    

when substituted into   c   if     or      holds  theorem     guarantees convexity of the
kikuchi free energy 
the above two conditions are sufficient  but not necessary for theorem     to apply  a
necessary condition is
x
x
c   
    
c  
r

r 

which is easily derived by summing condition   d  over all   r and substituting condition   c   if condition      fails  we cannot use theorem     to prove convexity of the
kikuchi free energy 

   

fiefficient minimization of the kikuchi free energy

we would like to conjecture that the conditions in theorem     are not only sufficient 
but also necessary for convexity of the kikuchi free energy  we will not pursue this any
further here  because it is irrelevant for our current purposes  furthermore  it may not
be that relevant in practice either  since convexity by itself is a sufficient but not necessary condition for a unique minimum  tatikonda and jordan         heskes         ihler 
fisher  and willsky        give conditions for convergence of loopy belief propagation and
uniqueness of the minimum of the corresponding bethe free energy  these conditions do not
only depend on the graphical structure  but also on the  strength of the  kernels   x   
    related work
chiang and forney        present similar ideas  about convex entropy terms compensating
concave terms in the set of constraints  and derive conditions for convexity of the bethe
free energy with pairwise potentials  the resulting conditions are formulated in terms of
single node marginals  which may be difficult both to validate in practice and to generalize
to the kikuchi case 
closely related to our theorem     is the following theorem of pakzad and anantharam
             
theorem       pakzad   anantharam              the kikuchi free energy     is convex
over the set of consistency constraints imposed by a collection of regions r  and hence the
constrained minimization problem has a unique solution  if the overcounting numbers c
and c  satisfy 
x
x
s  r 
c  
c      
    
  r s 
s  

s

in words  for any subset s of r  the sum of overcounting numbers of elements of s and all
their ancestors in r must be nonnegative 
in fact  using halls        matching theorem  it can be shown that the conditions    
in our theorem     are equivalent to the conditions      in theorem      the latter are
more direct and do not require the solution of a linear program 
both theorem     and theorem     can be used to show that the bethe free energy for
graphs with a single loop is convex over the set of constraints  heskes        mceliece  
yildirim        pakzad   anantharam              
    minimization of the convex kikuchi free energy
if the kikuchi free energy is convex  it is not only guaranteed to have a unique minimum 
but this minimum is also relatively easy to find with a message passing algorithm similar
to standard  loopy  belief propagation 
the basic idea is as follows  we here focus on the case in which all overcounting numbers
are positive  the case with negative overcounting numbers is more involved and worked
out in appendix b  furthermore  here and in the rest of this paper we ignore the positivity
constraints   a   it is easy to check that these are satisfied at the solutions we obtain  we
introduce lagrange multipliers     x   for the consistency constraints as well as  for the

   

fiheskes

normalization constraints and construct the lagrangian


xx
x
l q      fkikuchi  q   
q   x   
    x   q  x   
   
 

 

x




x   

x

   

x
x



q  x    

    

minimization of the kikuchi free energy under the appropriate consistency and normalization constraints is  in terms of this lagrangian  equivalent to
min fkikuchi  q    min max l q     
q

qq



where the minimization over q is now unconstrained  standard results from constrained
optimization  e g   luenberger        tell us that
min max l q     max min l q     
q





q

with equality for convex problems under linear equality constraints  that is  for convex
problems we are allowed to interchange the maximum over  and the minimum over q 
furthermore  the optimal q    corresponding to the minimum of the lagrangian      as
a function of  is unique  since l q    is convex in q for all   substitution of the solution
then yields the so called dual
l     min l q      l q        

    

q

this dual is concave in  and has a unique maximum 
many algorithms can be used to find the maximum of the dual       a particular
one  derived in appendix b  is given in algorithm    it slightly differs from those presented
by yedidia et al         and yuille        by sending messages  messages are directly related
to lagrange multipliers  only between inner regions and outer regions  i e   never between
inner regions subsets and other inner regions  the price one has to pay is that the update in
line   depends on the overcounting number c   for the bethe free energy  with c      n  
we obtain the standard  loopy  belief propagation update rules  the particular ordering
in algorithm    running over inner regions and updating the messages between an inner
region and all its neighboring outer regions  guarantees that the dual      increases at each
iteration    the local partition functions z and z in lines    and   are chosen such as
to normalize the pseudo marginals q  x   and q  x    this normalization is not strictly
necessary  but helps to prevent numerical instability  algorithm   can be initialized by
setting all messages   x       and skipping lines   to   at the first iteration 
   for positive overcounting numbers c   the argumentation with negative overcounting numbers is more
complicated and may require damping of the updates to achieve convergence  see appendix b for details 

   

fiefficient minimization of the kikuchi free energy

algorithm   message passing algorithm for constrained minimization of a kikuchi free
energy 
  

while converged do

  

for all   i do

  
  

for all   o     do
x
q  x    
q  x  
x 

  

  x    

q  x  
  x  

  

end for

  

q  x    

  

for all   o     do
q  x  
  x    
  x  
y
 
q  x    
  x  
  x  
z
i 

 
n  c
  y
  x  
z o 


  
   



   

end for

   

end for

   

end while

   double loop algorithms for guaranteed convergence
even when the kikuchi free energy is not convex  we can still run algorithm   in the
hope that it converges to a fixed point  this fixed point then must correspond to an
extremum of the kikuchi free energy under the appropriate constraints  yedidia et al  
       even better  empirically for the general kikuchi free energy and provably for the
bethe free energy  heskes         this extremum is in fact a minimum  however  in practice
this single loop  algorithm does not always converge and we have to resort to double loop
algorithms to guarantee convergence to a minimum of the kikuchi free energy 
    the general procedure
we introduce a class of such double loop algorithms based on the following theorem 
   note that single loop here refers to the message passing algorithm and has nothing to do with the
notion of a single loop in the graphical model 

   

fiheskes

theorem      given a function fconvex  q  q   with properties
fconvex  q  q    fkikuchi  q 

q q q

fconvex  q  q    fkikuchi  q  and
fi
fconvex  q  q   fifi
fkikuchi  q 
fi   
q
q
q  q

fconvex  q  q   is convex in q  q

 bound 

   a 

qq

 touching 

   b 

q q

 convex 

   c 

the algorithm
qn     argmin fconvex  q  qn    

    

qq

with qn the pseudo marginals at iteration n  is guaranteed to converge to a local minimum
of the kikuchi free energy fkikuchi  q  under the appropriate constraints 
proof it is immediate that the kikuchi free energy decreases with each iteration 
fkikuchi  qn      fconvex  qn     qn    fconvex  qn   qn     fkikuchi  qn    
where the first inequality follows from condition    a   upper bound  and the second from
the definition of the algorithm  the gradient property    b  ensures that the algorithm is
only stationary in points where the gradient of fkikuchi is zero  by construction qn  q for
all n 
see figure   for an illustration of the algorithm and the proof  in fact  the convexity
of fconvex has not been used to establish the proof  but  as argued in section      from an
algorithmic point of view constrained minimization of a convex functional is much simpler
than constrained minimization of a non convex functional  this general idea  replacing
the minimization of a complex functional by the consecutive minimization of an easier
to handle upper bound of this functional  forms the basis of popular algorithms such as
the em algorithm  dempster  laird    rubin        neal   hinton        and iterative
scaling iterative proportional fitting  darroch   ratcliff        jirousek   preucil        
intuitively  the tighter the bound  the faster the algorithm 
    bounding the concave terms
as a first step  to lay out the main ideas  we build a convex bound by removing all concave
entropy contributions for   i   to do so  we will make use of the linear bound
x
x

q  x   log q  x    
    
q  x   log q  x    
x

x

which directly follows from
 

kl q   q  

 

x
x

 

q  x  
q  x   log 
q  x  

   

 

fiefficient minimization of the kikuchi free energy

   
   

   

figure    illustration of the proposed algorithm and corresponding convergence proof  at
iteration n  fconvex  q  qn    dashed line  is a convex bound of the non convex
fkikuchi  q   solid line   they touch at qn   point      where fconvex  qn   qn    
fkikuchi  qn   
at the minimum  point      we have fconvex  qn     qn   
fconvex  qn   qn    the corresponding kikuchi free energy  point      obeys
fkikuchi  qn      fconvex  qn     qn   because of the bounding property 

with kl the kullback leibler divergence  our choice fconvex then reads

 x
xx
x
q  x  
   

fconvex  q  q    
q  x   log
q  x   log q  x  
c
 
  x  
 x
x
i 


x
x
x
x
 c     
q  x         
 c  

q  x   log q  x    
i

i

x

x

it is easy to check that this functional has properties    a  and    c   the last term has
been added to fulfill property    b   next we make the crucial observation that  using the
   
constraints     and for fixed q   we can rewrite fconvex in the normal form     

 x x
xx
q  x  
   
fconvex
 q  q    
q  x   log
 
c
q  x   log q  x     c q        

 x
 


 x
x


where c q  evaluates to zero for all q  q and where   which implicitly depends on q  
and c are defined through

x  c  
  i

log q  x   and c 
 
    
log   x    log   x    
c i 
n
i  



that is  we can always to incorporate the terms now linear in q in the energy term by
redefinition of the potentials  here we have chosen to distribute each of these terms equally
over the n neighboring outer regions  but other choices are possible as well 
   

fiheskes

the term c q  in      evaluates to zero for all q  q and is thus irrelevant to the
optimization in the inner loop  it consists of terms such as the last one in      that only
   
serve to make the bound fconvex satisfy    b   in the construction of other bounds below 
we will ignore such terms  they do not affect the algorithm in any way   
   
now that we have fconvex both convex and in normal form  we can use algorithm   to
solve the constrained problem       the resulting double loop algorithm can be described
in two lines 
outer loop  recompute  from      with q   qn  
inner loop  run algorithm   with  for  and c for c  yielding qn    
in each inner loop  we can initialize the messages to the converged values of the previous
inner loop 
    bounding the convex terms
in this section we will show that in many cases we can make the algorithm both better
and simpler  the idea is to bound not only the concave  but also the convex entropy
contributions from inner regions  that is  we enforce c      i and set


xx
q  x  
   

fconvex  q  q    
q  x   log
 
    
  x  
 x
with now
log   x    log   x   

x c
log q  x    
n

    



   

let us first explain why the algorithm based on fconvex is simpler than the one based on
in       all reference to inner regions has disappeared  in fact  the only constraints
that we have to care about are that the outer regions pseudo marginals should agree on
their intersections  consequently  in the inner loop  algorithm     we only have to run over
those inner regions  that are direct intersections of the outer regions  that is  those  for
which there exist outer regions  and  such that x   x  x   similar arguments can be
used for the algorithm based on      as well  neglecting all negative inner regions   i
that do not correspond to direct intersections of outer regions  in practice  however  most
negative inner regions are direct intersections of the outer regions  whereas many positive
inner regions arise at the next level  from intersections of intersections  see for instance the
example of figure    where all six negative inner regions are direct intersections of outer
regions  in contrast with all four positive inner regions 
   
from       but now applied to the positive inner regions  it is clear that fconvex  q  q   
   
   
   
fconvex  q  q    when it is a bound  fconvex is a tighter bound than fconvex and we can expect
   
the algorithm based on fconvex to perform better  it remains to be shown under which
   
conditions fkikuchi  q   fconvex  q  q    this is where the following theorem comes in 
   
fconvex  

   alternatively  we could relax condition    b  to the statement that the gradients of fconvex and fkikuchi
only have to be equal in the subspace orthogonal to the constraints  with this milder condition  c q 
as well as the last term      are no longer needed 

   

fiefficient minimization of the kikuchi free energy

theorem      the functional fconvex in      is a convex bound of the kikuchi free energy     if there exists an allocation matrix a between negative inner regions   i
and positive inner regions   i  satisfying
a      only if   

  can be used to compensate  

   a 

a   
x
a   c  

 positivity 

   b 

 sufficient amount of resources 

   c 

 sufficient compensation 

   d 

i



x

a  c

i 



proof not surprisingly  the proof follows the same line of reasoning as the proof of theorem      first we consider the combination of a concave entropy contribution from   i
as in      with a convex entropy contribution from   i       
x
x

q  x   log q  x    
q  x   log q  x   
x

x



x

q  x   log q  x    

x

x

q  x   log q  x    

    

x

which follows from

q  x   x  
  
q  x   q  x   x   
q  x   x  
x



x
q  x  
q  x   q  x  
 
q  x  
log
 
  x  
q
 x
 
q
 x
 
q






x
x







where we recognize the term between braces as a kullback leibler divergence between two
probability distributions 
   
to show that the difference between fconvex and fkikuchi is nonnegative  we should be
able to compensate each of the concave contributions c for all   i  with convex contributions from   i with     without exceeding the available amount of resources
 c    in shorthand notation  with
 
 
x
q  x  
k 
 
q  x   log 
q  x  
x


we have the decomposition
x
x
x
   
fconvex
 fkikuchi   
c k  
c k
 c  k 
i

 

x

i



 c   

x





a  k  

i

x x

i 

a  k  k    

i 

x

i 

   




x





a  c  k     

fiheskes

      
 

 

 

 

 

    

     

     

     

    

 

 

 

   
 

    

    

    

   

   

   

   

   

   

   

   

   

   

                           

 

 

 

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 a  outer regions 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 b  region graph 
figure    smallest example showing that the conditions for theorem     need not always
hold for a region graph and overcounting numbers constructed with the cluster
variation method   a  visualization of the outer regions  black means that the
variable    to    is part of the outer region    to    
 b  region graph with overcounting numbers in boldface  the positive overcounting numbers at the third level just outweigh the negative overcounting numbers at the second level 

where the inequality follows since each of the terms itself is guaranteed to be nonnegative
when the conditions      are satisfied 
as above  the conditions of theorem     can be checked with a linear program  having
generated many different sets of overcounting numbers resulting from the moebius formula      we started wondering whether the conditions      are perhaps automatically satisfied  however  exhaustively checking all possible outer region combinations given a fixed
number of variables  we did come up with a counterexample  the smallest counterexample
that violates the conditions for theorem      is illustrated in figure   
even if  as in this counterexample  not all positive inner regions can be compensated for
by negative inner regions  it will pay to get rid of as many as possible  finding the optimal
assignment may be a complex problem  but heuristics are easy to find  see appendix c  
    pulling out a tree or more
   

in the previous section we tightened the convex bound fconvex of the kikuchi free energy
fkikuchi by bounding convex contributions from positive regions as well  another way to
get a tighter bound is to bound only part of the concave contributions from the negative

   

fiefficient minimization of the kikuchi free energy

inner regions  we will first illustrate this by considering the bethe free energy  i e   just
non overlapping negative inner regions  nodes  with c      n  
the bethe free energy is convex for singly connected structures  inspired by teh and
welling         we choose a set of nodes   ibound such that the remaining nodes   ifree
become singly connected and take


xx
x
x
q  x  
   

fconvex  q  q    
q  x   log
 
    n  
q  x   log q  x  
  x  
 x
x
ifree
x
x
 
    n  
    
q  x   log q  x    
ibound

x

that is  we bound the entropy terms corresponding to the bounded nodes   ibound and
simply keep the entropy terms correspond to the free nodes   ifree   by construction
fconvex satisfies all conditions       furthermore  it can be rewritten in the normal form    
with definitions

x    n
 
ibound

log   x    log   x   
 
log q  x   and c 
 

n
n
 ifree
i
 
bound



note that the resulting inner loop algorithm is not completely equivalent to running standard belief propagation on the tree of all free nodes  we do have to send messages to and
from the bounded nodes   ibound as well to enforce the constraints q  x     q  x   for
     
rather than pulling out a single tree  we can also pull out a convex combination of
trees  that is  suppose that we have several bounds  each of them the result of pulling
out a particular tree and with a corresponding set of overcounting numbers ci   then any
convex combination
x
x
c  
wi ci with wi    and
wi    
i

i

also corresponds to a convex bound  more generally  we can combine the ideas in this
and the previous section by choosing c such that the resulting bound is just convex  a
procedure for doing so is given in appendix c  basically  we first try to shield as much of
the concave entropy contributions by convex entropy contributions as we can  next  we
tighten the bound further by incorporating convex contributions in the linear bounds of the
concave contributions that we did not manage to shield in the first step  both steps can be
cast in the form of an easy to solve linear programming problem 
    related work
   

the double loop algorithm described in section     and based on fconvex is closely related
to yuilles        cccp  concave convex procedure  algorithm  although originally formulated in a completely different way  cccp applied for minimization of the kikuchi free
energy can also be understood as a particular case of the general procedure outlined in
theorem      more specifically  it is based on bounding the concave contributions with
x
x
x
 c  
q  x   log q  x   
q  x   log q  x      c      
q  x   log q  x         
x

x

x

   

fiheskes

which is to be compared with       that is  before bounding the concave entropy contributions  part of these concave terms are taken over to the convex side  the reason for
doing so is that the cccp algorithm requires the functional to be convex  independent of
the constraints involved    our procedure  on the other hand  makes use of the fact that
the functional only has to be convex over the set of constraints  this allows us to use
tighter bounds  yielding more efficient and sometimes simpler algorithms  on a less important note  the inner loop algorithm and in particular the message passing scheme applied
by yuille        is somewhat different 
   
the double loop algorithm based on fconvex in      is inspired by teh and wellings
       ups  unified propagation and scaling  algorithm  the difference is that where we
bound the entropy contributions from nodes on the tree  in ups these nodes  and thus
the entropy contributions  are clamped to the values resulting from the previous inner loop 
that is  each inner loop in the ups algorithm corresponds to minimizing


xx
x
x
q  x  
ups

fconvex  q  q    
q  x   log
 
    n  
q  x   log q  x  
  x  
 x
x
ifree
x
x

    n  
q  x   log q  x    
iclamped

x

under the constraints
q  x     q  x   ifree     yet q  x     q  x   iclamped    
this boils down to an iterative scaling algorithm  which is also relatively easy to solve 
at each outer loop iteration  a different choice is made for ifree and iclamped   the ups
algorithm can be understood as coordinate descent and is guaranteed to converge to a
local minimum of bethe free energy  under appropriate conditions on the choices made for
   
ifree and iclamped    the inner loop that results from fconvex also allows for changes in the
marginals q  x   for   ibound   i e   is more flexible and can make larger steps  loosely
   
ups   furthermore  in our approach we
speaking  fconvex is again a tighter bound than fconvex
can but do not have to choose different subdivisions between bounded and free nodes
within each inner loop 
wainwright  jaakkola  and willsky      b      a  present similar ideas  exploiting the
convexity of the bethe free energy on tree structures  wainwright et al       b  use the
tree structure to obtain a more efficient implementation of loopy belief propagation  without
however guaranteeing convergence  wainwright et al       a  show that particular convex
combinations of convex bethe free energies lead to convex bounds on the exact helmholtz
free energy      in these bounds  the overcounting numbers of the inner regions still follow
the moebius relation      but the overcounting numbers for the outer regions are smaller
than or equal to    constrained minimization of such a bound is very similar to constrained
   
minimization of fconvex and the algorithm used by wainwright  jaakkola  and willsky       
is indeed closely related to algorithm   
   the procedure described by yuille        often even moves part of the convex terms to the concave side 
this makes the  implicit  bound even worse and the corresponding algorithm slower  in the following
we will stick to the more favorable interpretation of the cccp algorithm that is based on the implicit
bound      

   

fiefficient minimization of the kikuchi free energy

   simulations
intuitively  we would expect the algorithms based on the tightest bound to converge the
fastest in terms of outer loop iterations  however  with larger steps in the outer loop 
we might need more inner loop iterations to achieve convergence in the inner loop  the
following simulations are designed to check this 
    general set up
in the simulations we compare four different algorithms  each of them based on a different
bound 
just convex the tightest bound of the kikuchi free energy that is just convex  based on
the ideas described in section     and appendix c 
negative to zero the bound obtained by setting all negative overcounting numbers to
zero  as explained in section     
all to zero the bound described in section     that follows by setting all overcounting
numbers  both negative and positive  to zero  in all models considered below  the
overcounting numbers satisfy the conditions of theorem      i e   setting them to zero
indeed yields a bound on the kikuchi free energy  note further that all to zero is
equivalent to negative to zero for the bethe free energy 
cccp the  rather favorable interpretation of the  bound implicit in yuilles        cccp
algorithm  as explained in section     
algorithm   is applied in the inner loop of all these algorithms  the only difference
between them is the setting of the overcounting numbers c implied by the bound  each
inner loop runs until a preset convergence criterion is met  specifically  we end the inner loop
when all inner region marginals change less then       with this criterion all algorithms
happened to converge  which probably would also have been the case with looser criteria 
for example  yuille        reports that two inner loop iterations were sufficient to obtain
convergence 
in all simulations we report on the kullback leibler  kl  divergence between exact and
approximate marginals  either summed over all nodes or over a subset of nodes  plots for
the different error functions all look very much the same  the kikuchi bethe free energy
itself is somewhat less illustrative  when it is very close to its minimum  the marginals and
thus kl divergence can still change considerably  we visualize the kl divergence both as
a function of outer loop iterations and as a function of floating point operations  where we
count only the necessary operations involved in the inner loop and outer loop updates  i e  
not those involved in convergence checks  computing the kl divergence  and so on   in
comparing the number of inner loop iterations used by the different algorithms to meet the
convergence criterion  we scale the outer loop iterations relative to the outer loop iterations
of the just convex algorithm  that is  for each number of outer loop iterations used by an
algorithm to reach a particular level of accuracy  we consider the corresponding number of
outer loop iterations used by the just convex algorithm to reach the same level 

   

fiheskes

 a 

 b 
just convex
negative to zero
cccp
kldivergence

kldivergence

just convex
negative to zero
cccp
 

  

 

 

  

 

  

  
 

  

  
  
  
outerloop iterations

   

 

 

 
flops

 

 
 

x   

figure    bethe approximation on a      boltzmann grid  kullback leibler divergence
between exact and approximate single node marginals as a function of the outerloop iterations  a  and floating point operations  b  for three different algorithms 

we have done simulations on quite a number of different problems and problem instances  involving both markov random fields and bayesian networks  the results shown
here are exemplary and meant to illustrate the more general findings that we will summarize
below 
    bethe free energy on a boltzmann grid
our first set of simulations concerns the minimization of the bethe free energy on a boltzmann grid of      nodes with pairwise interactions of the form


tj
ti
    
ij  xi   xj     exp wij   xi      xj         xi         xj    
ni
nj
where ni is the number of neighbors of node i  i e     for a corner node    for other nodes
on the boundary  and   for nodes in the middle  weights wij and biases ti are drawn at
random from a normal distribution with mean zero and standard deviation      in the
bethe approximation the outer regions are all pairs of neighboring nodes 
figure   shows the summed kl divergence between exact and approximate single node
marginals as a function of the number of outer loop iterations  a  and as a function of
the number of floating point operations  b  for the just convex  negative to zero  and
cccp algorithms  it can be seen that  as expected  the just convex algorithms converges
faster than the negative to zero algorithm  which itself converges faster than the cccp algorithm  the speed up in terms of outer loop iterations translates into an almost equivalent
speed up in terms of flops  indeed  as can be seen in figure   a   the number of inner loop
iterations required by the just convex algorithm is just slightly higher than that of the
other two algorithms 
the curves in figure   a  can be mapped onto each other with a rough linear scaling
of the number of outer loop iterations  this is also suggested by the straight lines in
   

fiefficient minimization of the kikuchi free energy

 

outerloop iterations

  

 b 
number of innerloop iterations

 a 
just convex
negative to zero
cccp

 

  

 

  
 
  

 
 
 
 
 

 

just convex
negative to zero
cccp

  
outerloop iterations

  
  
  
  
outerloop iterations  scaled 

figure    bethe approximation on a      boltzmann grid   a  outer loop iterations of
the just convex algorithm versus the corresponding outer loop iterations of the
other two algorithms   b  number of inner loop iterations needed to meet the
convergence criterion as a function of the outer loop iterations  scaled according
to  a  

figure   a   the slope of these lines relate to each other as          by definition   and     
for just convex  negative to zero and cccp  respectively  see also the convergence rates
in table     the following argumentation shows that there is a striking correspondence
between these numbers and the respective bounds 
the negative overcounting numbers
p
for the bethe free energy fkikuchi
p add up to i c        for the respective convex
bounds fconvex   these sums are i c           and     if we now translate these into
the fraction of negative overcounting mass that is bounded  i e  
p
p
i c 
i c
p
 
i c

we obtain  respectively          by definition   and       that is  there appears to be an
almost linear relationship between the tightness of the bound  here expressed in the fraction
of concave entropy contributions that is bounded linearly  and the speed of convergence 
we have noticed the same almost linear relationship in all other simulations involving a
bethe free energy  no positive overcounting numbers  
    kikuchi free energy on a boltzmann grid

our second set of simulations is also on a    boltzmann grid  where now the outer regions
are chosen to be all squares of four neighboring nodes  potentials are of the form      with
weights and biases drawn from a normal distribution with standard deviation   and     
respectively  note that the size of the weights is much larger than in the previous set of
simulations  to make the problem still a bit of a challenge for the kikuchi approximation 
with these weights  the bethe approximation does very badly  summed kullback leibler
   

fiheskes

 a 

 b 

 

 

  
just convex
negative to zero
all to zero
cccp

 

  

kldivergence

kldivergence

  

 

  

just convex
negative to zero
all to zero
cccp

 

  

 

  

 

   
   
   
outerloop iterations

   

 

 

  
flops

  
 

x   

figure    kikuchi approximation on a      boltzmann grid  kullback leibler divergence
between exact and approximate single node marginals as a function of the outerloop iterations  a  and floating point operations  b  for four different algorithms 

divergence larger than      both for the bethe and for the kikuchi algorithm  the singleloop algorithm has convergence problems  for the bethe approximation it typically gets
stuck in a limit cycle and for the kikuchi approximation it tends to diverge  in total there
are           outer regions and                 negative inner regions  all node pairs
that correspond to intersections of the outer regions  and           positive inner regions
 all single nodes that correspond to intersections of the node pairs  
figure   shows the kl divergence between approximate and exact single node marginals
for the four different algorithms in terms of the outer loop iterations  a  and floating point
operations  b   it can be seen that the ordering in  a  is again as expected  the tighter the
bound  the faster the algorithm  in terms of floating point operations  the just convex and
all to zero algorithm get much closer together 
part of the explanation is given in figure    the just convex algorithm requires considerably more inner loop iterations to meet the same convergence criterion  the other
effect is that the all to zero algorithm in its inner loop only runs over the     negative
inner regions instead of all     positive and negative inner regions  this makes that each
inner loop iteration of all to zero requires a factor     less floating point operations than
an inner loop iteration of the other three algorithms 
here it is more difficult to find a quantitative relationship between the tightness of
the bounds and the  asymptotic  convergence rates  one of the complications is that not
only the negative  but also the positive overcounting numbers play a role  in any case  all
algorithms still seem to converge linearly  with faster convergence rates for tighter bounds 
these convergence rates  expressed as the time scale of the corresponding exponential decay
 kl t   kl    exp t     with t and  in outer loop iterations   are summarized in
table   

   

fiefficient minimization of the kikuchi free energy

 

outerloop iterations

  

 b 
number of innerloop iterations

 a 
just convex
negative to zero
all to zero
cccp

 

  

 

  

 

  
 
  

  
  
  
  
 
 

 

  
outerloop iterations

just convex
negative to zero
all to zero
cccp

 

  
  
  
  
outerloop iterations  scaled 

figure    kikuchi approximation on a      boltzmann grid   a  outer loop iterations of
the just convex algorithm versus the corresponding outer loop iterations of the
other three algorithms   b  number of inner loop iterations needed to meet the
convergence criterion as a function of the outer loop iterations  scaled according
to  a  

figure    graphical structure of the qmr like network 
    a qmr network
our third set of simulations concerns a qmr like  quick medical reference  bayesian
network  heckerman        jaakkola   jordan         a bipartite graph with a layer of
disease nodes and a layer of findings  the particular network used in these simulations has
been generated with the bayes net toolbox  murphy         it contains    finding nodes 
of which    are observed  positive   and    hidden disease nodes  see figure    the diseases
have bernoulli probability distributions with a prior drawn at random between   and      
the findings have noisy or conditional probability distributions without leakage  diseases
and findings are linked randomly with probability      the absence of leakage  large amount
of findings  and strong connectivity make this a relatively difficult inference problem  as
outer regions we take the subsets implied by the conditional probability distribution  i e  
each outer region consists of a disease and all findings linked to it  figure   gives the
corresponding region graph 

   

fiheskes

                                
                                                                   
 

 

 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 
 

figure    region graph resulting from the qmr like network 

 a 
just convex
negative to zero
all to zero
cccp

  

  

 

  

 

   
   
   
outerloop iterations

just convex
negative to zero
all to zero
cccp

 

kldivergence

 

kldivergence

 b 

   

 

  

 

 

 

 
flops

 

  
 

x   

figure     kikuchi approximation on a qmr like network  kullback leibler divergence
between exact and approximate single node marginals as a function of the outerloop iterations  a  and floating point operations  b  for four different algorithms 

   

fiefficient minimization of the kikuchi free energy

 b 
number of innerloop iterations

outerloop iterations

 a 
just convex
negative to zero
all to zero
cccp

 

  

 

  

 

  
 
  

  

  
  
  
  
 
 

 

  
outerloop iterations

just convex
negative to zero
all to zero
cccp

  

 
  
  
outerloop iterations  scaled 

  

figure     kikuchi approximation on a qmr like network   a  outer loop iterations of the
just convex algorithm versus the corresponding outer loop iterations of the
other three algorithms   b  number of inner loop iterations needed to meet the
convergence criterion as a function of the outer loop iterations  scaled according
to  a  

original
just convex
negative to zero
all to zero
cccp

    
    
 
 
  

bethe
 

 
 
   
      
      
      

kikuchi
 

       
   
 
  
    
  
 
 
  
          

   
   
 
 
  

qmr
 

  
  
 
  
  
 
  
      

table    summary of asymptotic convergence   is the time constant  with time in outerloop iterations  in the exponential decay  and sums of negative and positive overcounting numbers in the original kikuchi bethe free energy and the convex bounds
used by the different algorithms 

the results can be found in figure    and     they are comparable with those for the
kikuchi approximation on the boltzmann grid  also here the single loop algorithm fails
to converge  the just convex algorithm converges much faster than the other three algorithms  but requires more inner loop iterations and is less efficient than the all to zero algorithm  which makes the latter preferable in terms of floating point operations  however 
it is relatively straightforward to speed up the just convex algorithm  first  we probably
do not need that many inner loop iterations for the outer loop to converge properly  and
secondly  where we now bound part of each entropy contribution  a more efficient choice
would have as many zero overcounting numbers as possible 

   

fiheskes

    general findings
here we summarize some of the points that have been illustrated above and that we have
encountered in many other simulations as well 
 the tighter the  convex  bound used in the inner loop  the faster the convergence in
terms of outer loop iterations 
 the number of outer loop iterations needed to meet a prespecified convergence criterion tends to decrease with a looser bound  but never nearly enough to compensate
for the slower convergence in the outer loop 
 in fact  we have only observed a strong dependency between this number of inner loop
iterations and the tightness of the bound if the bound is just convex and the problem
is hard in the sense that a single loop algorithm would fail to converge 
 in terms of floating point operations  a looser bound that sets all overcounting numbers
in the inner loop to zero  can beat a tighter bound with negative overcounting numbers 
the slower convergence in terms of outer loop iterations is compensated by a more
efficient inner loop 
pelizzola        tests several convergent algorithms on kikuchi approximations of problems in statistical physics and reports similar findings  also in this study  the just convex algorithm  described for the first time by heskes  albers  and kappen         clearly outperforms all competitors 

   discussion
this article is based on the perspective that we are interested in minima of the kikuchi
free energy under appropriate constraints  finding such a minimum then becomes a possibly non convex constrained minimization problem  here  as well as in other studies  the
approach has been to solve this non convex problem through sequential constrained minimization of convex bounds on the kikuchi free energy  on the presumption that tighter
bounds yield faster algorithms  we have worked out several ideas to construct tight convex
bounds  the simulation results in this article as well as those obtained by pelizzola       
clearly validate this presumption and show that the speed ups can be very significant 
heskes  zoeter  and wiegerinck        apply these bounds for  approximate  parameter
learning in directed graphical models 
the double loop algorithms considered in this article are all based on convex bounds
of the kikuchi free energy  in principle  this is not necessary  our only concern is that
the inner loop algorithm converges and this might well be the case for tighter bounds  one
practical solution is to simply choose a  tight  bound on the kikuchi free  check whether the
inner loop algorithm does converge  and restart with a looser bound if not  alternatively 
we can construct tighter bounds making use of conditions for guaranteed convergence of
belief propagation such as those derived by tatikonda and jordan         heskes        
ihler et al         for the bethe approximation 
it has been suggested that non convergence of single loop generalized loopy belief propagation by itself is an indication that the kikuchi bethe approximation is inaccurate  the
   

fiefficient minimization of the kikuchi free energy

results in section     and     show that this need not always be the case  apparently  there
does exist a middle range of problems where the kikuchi free energy is not easy to minimize  but does yield decent approximations  it is on these problems that the algorithms
described in this article are useful 

acknowledgments
the author would like to thank wim wiegerinck  onno zoeter  kees albers  and bert kappen for fruitful discussions and the anonymous reviewers for their constructive comments 
this work has been supported in part by the dutch technology foundation stw 

appendix a  convexity of the difference between two entropies
this appendix treats two lemmas on the convexity of the difference between two entropies 
the first one is used in the proof of theorem      a similar lemma is used by mceliece and
yildirim        
lemma a    the difference between two entropies
x
x
q  x   log q  x  
q  x   log q  x   
  q   
x

x

 

x
x

is convex in q  



q  x   

x

x 



q  x   x   log q  x   x  

proof we take a step backwards and write  out as

  q    

x
x





 q  x   
 
q  x   log 
x

q  x   

x 

when taking derivatives  we best interpret the table q   specifying the value q  x   for each
possible realization x   as a vector with x playing the role of an index  taking second
derivatives  we then obtain
hx  x  q   

     q  
 
 
  
 
ix  x 
i
q  x  q  x  
q  x     q  x   x  x

with ix x    if all elements of x and x are equal and zero otherwise 

   

fiheskes

next we would like to show that this matrix is positive semi definite  i e   that for all
tables q  again to be interpreted as vectors with indices x  
  

x

q x  hx  x  q  q x    

x  x

x


 x q    x   x  
x

 

 

q  x    x  
x x


 

x q x  q x  

i
q  x  
q  x   x  x

x  x



q x    x  q x    x   

x q    x  

x

x   x 



q  x  


i  
hp



x  x q    x    x  
x  q x    x  
 
 p
 

q  x    x  

x  q  x    x   
x x





 

from cauchys inequality 

x

a k

k

x

b k 

k

 

x
k

ak bk

  

 

it follows that the term between braces is indeed semi positive q
for each realization of x  
to see this  we make the substitutions x   k  q x    x    q  x    x    ak   and
q
q  x    x    bk to find
        

x
k

a k

p
 
k ak bk  
 p
  
 
k bk
 

the following related lemma is used in appendix b 

lemma a    the difference between two entropies
x
x
  q   q   
q  x   log q  x   
q  x   log q  x  
x

x

is convex in  q   q   
proof the hessian matrix has components
hx  x



     q  
 
 
ix  x

q  x  q  x  
q  x    

hx  x



     q  
 

 
i

q  x  q  x  
q  x   x  x

hx  x



q  x  
     q  
  
i
   

q  x  q  x  
q  x   x  x

   

fiefficient minimization of the kikuchi free energy

convexity requires that for any q    q  x    q  x    
q  x   q  x  

  
 

x q   x  

 

hx  x
hx  x

hx  x
hx  x

x q  x  q  x  

q  x  


x
q  x   q  x    

 
q  x  
 
q  x   q  x  
x
x

q  x  



x

 

 

q  x  
q  x  



x q  x  q   x  
q   x  

x



appendix b  minimizing a convex kikuchi free energy
in this appendix  we derive algorithm   for minimizing a convex kikuchi free energy under
appropriate linear constraints  to simplify notation  we will use the convention that  runs
over outer regions  and  over inner regions 
first  we note that in principle it is not necessary to explicitly take into account all
constraints      since some constraints are implied by others  obviously  the constraint
between two inner region marginals 
q   x     q  x   for some      
is implied by corresponding constraints between the inner region marginals and an outer
region subsuming both inner regions 
q  x      q   x    and q  x     q  x   for some        
that is  we do not have to take into account constraints between inner regions and other
inner regions  similarly  normalization constraints on outer region pseudo marginals follow
from normalization constraints on the inner region pseudo marginals  so  a sufficient set of
constraints is
x
q  x  

q  x     q  x   with q  x    
x 

x

q  x      

  

x

introducing lagrange multipliers   x   and  for the corresponding constraints  we
obtain the lagrangian
 x x

xx
q  x  
q  x   log q  x  
 
c
l q     
q  x   log
  x  
x
 x





xxx
x
x
x
 
  x   q  x   
q  x    
   
q  x      b   
  x

x 

   



x

fiheskes

convex independent of the constraints
let us first consider the case that all overcounting numbers c are strictly positive  c  
    then  the lagrangian is not just convex over the set of constraints  but convex in
q independent of the constraints  minimization of the lagrangian with respect to these
pseudo marginals follows by setting its derivatives to zero  yielding
y
e  x   
 b   
q  x       x  e 


q  x  

  c  

  e

y

e  x   c   

 b   



where here and in the following it should be noted that q and q are functions of the
lagrange multipliers   substituting this solution back into the lagrangian  we obtain the
dual
x
xx
x x
l     l q        
 
q  x   
c
q  x    
 b   




x



x

now  consider optimizing l    with respect to the subset of the components corresponding
to the inner region   collected in         x    x    keeping all other   for
      fixed  because of the concavity of the dual l     we can find the maximum in the
direction  by setting the corresponding derivatives to zero  this yields
fi
l    fifi
  qnew  x    qnew  x       x  
  x   fi new
fi
x
l    fifi
 
 

qnew  x        
 b   
 fi new
x
where q new refers to the solution  b    and  b    with   x   replaced by new
  x   and
 by new
 
since
from
 b   

new

qnew  x  

e  x  
    x   q  x    
e  

the solution for new
  x   must obey
new
new
  x      log q  x       x     log q  x    

where we still have to solve for qnew  x    summing this expression over all     substituting  b     and solving for qnew  x   we get
log qnew  x    

x
 
 
 log q  x      x     
 new  c    
n    c
n    c 


now  we obtain exactly the updates in algorithm   if we define
  x     e  x   and   x     q  x  e  x    
   

fiefficient minimization of the kikuchi free energy

and properly normalize q  x    as in line    the normalization of q  x   in line    is then
in fact unnecessary  since by construction the updates ensure that q  x     q  x   with
z     
the bottom line is that with the particular ordering in algorithm   the joint update of
all messages for a particular subset  can be interpreted as doing coordinate wise gradient
ascent in the dual l     updating the lagrange multipliers  and   x   for a particular
 and all    at the same time  therefore algorithm   is guaranteed to converge to the
unique maximum in the case of all positive overcounting numbers c  
convex over the set of constraints
next  let us consider the more general case in which  some of  the overcounting numbers are
negative  but such that the kikuchi free energy is still convex over the set of constraints 
we consider the case in which all inner region overcounting numbers are negative    we
will show that  with sufficient damping of the updates  algorithm   is still guaranteed to
converge to the unique minimum of the kikuchi free energy over the set of constraints 
note that direct application of the above argumentation fails  because the solution  b   
for q  x   with negative c corresponds to a maximum rather than a minimum  consequently  the dual l    in  b    need not be concave  the updates in algorithm   that
follow by setting derivatives to zero can be interpreted as fixed point iterations  not as coordinate ascent in l     still  in practice they do seem to work just fine and indeed without
always increasing l     in the following we will explain why  we will argue that the updates of algorithm   do not correspond to coordinate ascent  but rather to something like
coordinate descent ascent on a convex concave saddle function  with sufficient damping 
such an algorithm will converge to the unique saddle point  which then corresponds to the
minimum of the kikuchi free energy over the set of constraints 
convexity over the set
p according to theorem      that there exists
p of constraints implies 
a matrix a such that  a    c   and  a     using q  x     q  x    we replace
the lagrangian  b    by

 xx
xx
x
q  x  
l q     
q  x   log
q  x   log q  x  

a
  x  
 x
x
 




xxx
x
x
x
x
 
 
  x   
q  x   
q  x    
   
q  x      b   
n 
x
x
x
 

 





 



now since  from lemma a   in appendix a 
x
x
q  x   log q  x   
q  x   log q  x  
x

x

is convex in  q  x    q  x     the lagrangian  b    is indeed convex in q independent of the
constraints  thus we could apply the same argumentation as above  find the minimum of
   our argumentation does not hold if some of the negative inner region entropy contributions have to be
compensated by positive inner region subset entropy contributions to prove convexity of the kikuchi free
energy  in that case  we might need a slightly different algorithm to guarantee convergence 

   

fiheskes

the convex lagrangian with respect to q  substitute the corresponding solution q    back
into the lagrangian to obtain the concave dual l     and maximize this dual with respect
to   the problem is that we do not have a closed form expression for the optimal q   
and thus also no closed form expression for the dual l     which makes this procedure
rather awkward 
instead  we distinguish between the outer region marginals  collected in qo   and the
inner region marginals  collected in qi   having rewritten the consistency constraint in terms
of outer region marginals alone  we only replace the constrained minimization with respect
to qo by unconstrained maximization with respect to corresponding lagrange multipliers
o   leaving the minimization with respect to qi under the normalization constraint as
is  this gives us a saddle point problem of the type minqi maxo   even without explicitly
writing out the equations  we can tell that maximization with respect to  for a particular
 and all    corresponds to finding  such that
qnew  x     qnew
  x  

    

then  minimization with respect to q given fixed qnew  x   immediately yields
x
a qnew  x    
qnew  x   


properly normalized to sum to    this is exactly what the updates for a particular inner
region  in algorithm   amount to  they yield the unique maximum with respect to 
and minimum with respect to q   while keeping all other    and q  for       fixed 
such a coordinate descent ascent procedure works fine if the saddle function is convex in the minimizing parameter and concave in the maximizing parameter  e g   seung 
richardson  lagarias    hopfield         the concavity in  is immediate  the convexity
in qi follows from the convexity of the lagrangian  b    in q    qo   qi    minimizing
an overall convex function over some of its parameters  here qo   yields a convex function
over its remaining parameters  qi   technically  convergence to the unique solution of the
saddle point problem can be proven through the construction of a lyapunov function that
decreases under infinitesimal updates of the parameters in the descent and ascent direction
to zero at the unique saddle point  seung et al          convergence can be guaranteed for
sufficiently damped updates  not the full ones in algorithm    empirically the full updates  that correspond to full maximization and minimization for one inner region  before
moving on the next one  work fine in most cases  but occasionally indeed require a little
damping  wainwright et al         successfully apply damping to a very similar algorithm
in an attempt to minimize a convexified bethe free energy 

appendix c  constructing a tight convex bound
in this appendix  we describe a procedure for constructing a tight convex bound fconvex
of the kikuchi free energy fkikuchi   it combines ideas from section     and      that is 
we first convexify the kikuchi free energy  bounding as little concave contributions from
negative inner regions as possible  next  in the terms that we have to bound anyways  we
try to incorporate as many convex contributions as we can  this leads to the following
procedure 
   

fiefficient minimization of the kikuchi free energy

 consider minus the entropy
s   


x

s  



o

x

c s  

x

c s

 



i 

i




and choose c  c for   i such that the first term in
 


 x
x

x
x
c s 
c s  
 c  c  s  
s   
s  
 
 

i 

i

i

is  just  convex 

 with a the corresponding allocation matrix of theorem      define the used resources
x
a  c    c  
c 
i

and rewrite
s   


x


s  





c s  

i


x


x

x

c s

i 

 c  c  s  

x

i 

i

by construction  the first term is still convex 





 c  c  s




 



 to guarantee convexity  we have to bound the entropy contributions s in the second
term for each   i   to make this bound tighter  we include as many of the convex
contributions s as we can  while still satisfying the conditions in theorem      call
the corresponding overcounting numbers c  c  c  c and put the remaining
c  c back into the first term 


x

x
x
c s
s   
c s  
s  
 

i 
i


x

x

 c  c  s  
 c  c  s  


i 

i

 choose fconvex to be the first term plus a linear bound of the second term 

to find c in the first step and similarly c in the third  we can use a linear program
similar to the one described in section     for checking the conditions of theorem      we
introduce slack variables  and replace condition   d  by
x
a    i  variable compensation   


   

fiheskes

similar in spirit to      furthermore  we add the inequality constraints    cp
   i
 no need to compensate for more than  c    and search for the maximum of   i 
 compensate as much as possible   in terms of the corresponding solution    we set c  
c    

references
aji  s     mceliece  r          the generalized distributive law and free energy minimization  in proceedings of the allerton conference on communication  control  and
computing 
besag  j          spatial interaction and the statistical analysis of lattice systems  journal
of the royal statistical society series b             
chiang  m     forney  g          statistical physics  convex optimization and the sum
product algorithm  tech  rep   stanford university 
darroch  j     ratcliff  d          generalized iterative scaling  annals of mathematical
statistics               
dechter  r   kask  k     mateescu  r          iterative join graph propagation  in darwiche  a     friedman  n   eds    proceedings uai       pp         
dempster  a   laird  n     rubin  d          maximum likelihood from incomplete data
via the em algorithm  journal of the royal statistical society b          
hall  p          on representatives of subsets  journal of the london mathematical society 
         
heckerman  d          a tractable inference algorithm for diagnosing multiple diseases  in
kanal  l   henrion  m   shachter  r     lemmer  j   eds    proceedings of the fifth
workshop on uncertainty in artificial intelligence  pp          amsterdam  elsevier 
heskes  t          stable fixed points of loopy belief propagation are minima of the bethe
free energy  in becker  s   thrun  s     obermayer  k   eds    advances in neural
information processing systems     pp          cambridge  mit press 
heskes  t          on the uniqueness of loopy belief propagation fixed points  neural
computation               
heskes  t   albers  k     kappen  b          approximate inference and constrained optimization  in uncertainty in artificial intelligence  proceedings of the nineteenth
conference  uai        pp          san francisco  ca  morgan kaufmann publishers 
heskes  t   zoeter  o     wiegerinck  w          approximate expectation maximization  in thrun  s   saul  l     scholkopf  b   eds    advances in neural information
processing systems     pp          cambridge  mit press 
ihler  a   fisher  j     willsky  a          loopy belief propagation  convergence and
effects of message errors  journal of machine learning research            
jaakkola  t     jordan  m          variational probabilistic inference and the qmr dt
network  journal of artificial intelligence research             
   

fiefficient minimization of the kikuchi free energy

jirousek  r     preucil  s          on the effective implementation of the iterative proportional fitting procedure  computational statistics and data analysis             
jordan  m   ghahramani  z   jaakkola  t     saul  l          an introduction to variational
methods for graphical models  in jordan  m   ed    learning in graphical models 
pp          kluwer academic publishers  dordrecht 
kikuchi  r          the theory of cooperative phenomena  physical review              
kschischang  f   frey  b     loeliger  h          factor graphs and the sum product algorithm  ieee transactions on information theory                 
lauritzen  s          graphical models  oxford university press  oxford 
luenberger  d          linear and nonlinear programming  addison wesley  reading 
massachusetts 
mceliece  r   mackay  d     cheng  j          turbo decoding as as an instance of pearls
belief propagation algorithm  ieee journal on selected areas in communication 
               
mceliece  r     yildirim  m          belief propagation on partially ordered sets  in
gilliam  d     rosenthal  j   eds    mathematical systems theory in biology  communications  computation  and finance  pp          springer  new york 
murphy  k          the bayes net toolbox for matlab  computing science and statistics 
           
murphy  k   weiss  y     jordan  m          loopy belief propagation for approximate
inference  an empirical study  in laskey  k     prade  h   eds    proceedings of
the fifteenth conference on uncertainty in articial intelligence  pp          san
francisco  ca  morgan kaufmann publishers 
neal  r     hinton  g          a view of the em algorithm that justifies incremental 
sparse  and other variants  in jordan  m   ed    learning in graphical models  pp 
        kluwer academic publishers  dordrecht 
pakzad  p     anantharam  v          belief propagation and statistical physics  in     
conference on information sciences and systems  princeton university 
pakzad  p     anantharam  v          estimation and marginalization using kikuchi approximation methods  neural computation               
pearl  j          probabilistic reasoning in intelligent systems  networks of plausible inference  morgan kaufmann  san francisco  ca 
pelizzola  a          cluster variation method in statistical physics and graphical models 
journal of physics a      r   r    
seung  s   richardson  t   lagarias  j     hopfield  j          minimax and hamiltonian
dynamics of excitatory inhibitory networks  in jordan  m   kearns  m     solla  s 
 eds    advances in neural information processing systems     pp          mit
press 
tatikonda  s     jordan  m          loopy belief propagation and gibbs measures  in darwiche  a     friedman  n   eds    uncertainty in artificial intelligence  proceedings
   

fiheskes

of the eighteenth conference  uai        pp          san francisco  ca  morgan
kaufmann publishers 
teh  y     welling  m          the unified propagation and scaling algorithm  in dietterich 
t   becker  s     ghahramani  z   eds    advances in neural information processing
systems     pp          cambridge  mit press 
wainwright  m   jaakkola  t     willsky  a       a   a new class of upper bounds on the log
partition function  in darwiche  a     friedman  n   eds    uncertainty in artificial
intelligence  proceedings of the eighteenth conference  uai        pp          san
francisco  ca  morgan kaufmann publishers 
wainwright  m   jaakkola  t     willsky  a       b   tree based reparameterization for
approximate estimation on loopy graphs  in dietterich  t   becker  s     ghahramani 
z   eds    advances in neural information processing systems     pp           
cambridge  mit press 
wainwright  m   jaakkola  t     willsky  a          tree reweighted belief propagation
algorithms and approximate ml estimation via pseudo moment matching  in bishop 
c     frey  b   eds    proceedings of the ninth international workshop on artificial
intelligence and statistics  society for artificial intelligence and statistics 
yedidia  j   freeman  w     weiss  y          generalized belief propagation  in leen 
t   dietterich  t     tresp  v   eds    advances in neural information processing
systems     pp          cambridge  mit press 
yedidia  j   freeman  w     weiss  y          constructing free energy approximations
and generalized belief propagation algorithms  ieee transactions on information
theory               
yuille  a          cccp algorithms to minimize the bethe and kikuchi free energies 
convergent alternatives to belief propagation  neural computation               

   

fi