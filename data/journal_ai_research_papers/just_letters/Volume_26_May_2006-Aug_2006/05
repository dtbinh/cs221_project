journal artificial intelligence research                 

submitted        published      

fast downward planning system
malte helmert

helmert   informatik   uni   freiburg   de

institut fur informatik
albert ludwigs universitat freiburg
georges kohler allee  gebaude    
      freiburg  germany

abstract
fast downward classical planning system based heuristic search  deal general deterministic planning problems encoded propositional fragment pddl     including
advanced features adl conditions effects derived predicates  axioms  
well known planners hsp ff  fast downward progression planner  searching
space world states planning task forward direction  however  unlike pddl planning systems  fast downward use propositional pddl representation planning
task directly  instead  input first translated alternative representation called multivalued planning tasks  makes many implicit constraints propositional planning
task explicit  exploiting alternative representation  fast downward uses hierarchical decompositions planning tasks computing heuristic function  called causal graph heuristic 
different traditional hsp like heuristics based ignoring negative interactions
operators 
article  give full account fast downwards approach solving multi valued
planning tasks  extend earlier discussion causal graph heuristic tasks involving
axioms conditional effects present novel techniques search control used
within fast downwards best first search algorithm  preferred operators transfer idea helpful actions local search global best first search  deferred evaluation heuristic functions
mitigates negative effect large branching factors search performance  multi heuristic
best first search combines several heuristic evaluation functions within single search algorithm
orthogonal way  describe efficient data structures fast state expansion  successor
generators axiom evaluators  present new non heuristic search algorithm called focused
iterative broadening search  utilizes information encoded causal graphs novel
way 
fast downward proven remarkably successful  classical  i  e   propositional 
non optimising  track  th international planning competition icaps       following
footsteps planners lpg  experiments show performs
well benchmarks earlier planning competitions provide insights
usefulness new search enhancements 

   introduction
consider typical transportation planning task  postal service must deliver number parcels
respective destinations using vehicle fleet cars trucks  let us assume car
serves locations one city  different cities connected via highways
served trucks  sake simplicity  let us assume travelling segment
road highway incurs cost  highly realistic assumption  purposes
exposition do  number parcels  posted arbitrary locations
c
    
ai access foundation  rights reserved 

fih elmert

p 

b

f

c 





e

c 

g

c

c 

p 

figure    transportation planning task  deliver parcel p   c g parcel p  f e 
using cars c    c    c  truck t  cars may use inner city roads  thin edges  
truck may use highway  thick edge  

arbitrary destinations  moreover  cities varying size  one several cars
within city  one several trucks connecting cities  cars never leave
city  fig    shows example task kind two cities  three cars single truck 
two parcels delivered  one  p     must moved two cities 
 p    stay within initial city 
astute reader familiar planning literature noticed
essentially describing l ogistics domain  standard benchmark classical planning systems 
extended roadmaps complete graphs   part of  propositional strips like encoding
task shown fig    
would human planners go solving tasks kind  likely  would use
hierarchical approach  p    clear parcel needs moved cities 
possible using truck  since example city access highway one
location  see must first load parcel car initial location  drop
first citys highway access location  load truck  drop citys highway
access location  load car city  finally drop destination 
commit high level plan delivering p   without worrying lower level aspects
path planning cars  obvious us good solution structure 
since parcel change location clearly defined ways  fig      figure
shows reasonable plans getting p   destination require loading car
initial city dropping target location  point ever loading
truck cars left city 
say committed  partially ordered  movements two parcels
interleaved  high level plan shown fig     need complete plan choose
linearization high level steps fill movements vehicle fleet them 
thus decomposed planning task number subproblems  parcel scheduling
problem  where  vehicles  parcel loaded unloaded  separated
path planning problem vehicle fleet  how move point x y  
   

fit fast ownward p lanning ystem

variables 
at p  a  at p  b  at p  c  at p  d  at p  e 
at p  a  at p  b  at p  c  at p  d  at p  e 
at c  a  at c  b  at c  c  at c  d 
at c  a  at c  b  at c  c  at c  d 
at c  e  at c  f  at c  g 
at t d  at t e 
in p  c   in p  c   in p  c   in p  t 
in p  c   in p  c   in p  c   in p  t
init 
at p  c  at p  f  at c  a  at c  b  at c  g 
goal 
at p  g  at p  e
operator drive c  a d 
pre  at c  a add  at c  d del  at c  a
operator drive c  b d 
pre  at c  b add  at c  d del  at c  b
operator drive c  c d 
pre  at c  c add  at c  d del  at c  c
   
operator load c  p  a 
pre  at c  a  at p  a add  in p  c  del 
operator load c  p  b 
pre  at c  b  at p  b add  in p  c  del 
operator load c  p  c 
pre  at c  c  at p  c add  in p  c  del 
   
operator unload c  p  a 
pre  at c  a  in p  c  add  at p  a del 
operator unload c  p  b 
pre  at c  b  in p  c  add  at p  b del 
operator unload c  p  c 
pre  at c  c  in p  c  add  at p  c del 
   

at p  f  at p  g 
at p  f  at p  g 

at t e

at p  a
at p  b
at p  c

in p  c 
in p  c 
in p  c 

figure    part typical propositional encoding transportation planning task  no actual
pddl syntax  

   

fih elmert

c 




b

c



e

f

c 

g

c 

figure    domain transition graph parcels p   p    indicates parcel change
state  example  arcs correspond actions
loading unloading parcel location truck t 

b
f







e

e

g
c

figure    domain transition graphs cars c   c   left   truck  centre   car c   right  
note graph corresponds part roadmap traversed
respective vehicle 

load
c  p  c

unload
c  p  d

load
t p  d

unload
t p  e

load
c  p  f

unload
c  p  e

load
c  p  e

figure    high level plan transportation planning task 
   

unload
c  p  g

fit fast ownward p lanning ystem

c 

c 

c 

p 

p 



figure    causal dependencies transportation planning task 
graph search problems  corresponding graphs shown fig    fig    
graphs kind formally introduced domain transition graphs section   
course graph search problems interact  limited ways  state
transitions parcels associated conditions regarding vehicle fleet  need
considered addition actual path planning fig     example  parcel change
state location inside car c   car c  location a  however  state transitions
vehicles associated conditions parts planning task  hence
moving vehicle one location another indeed easy finding path associated
domain transition graph  say parcels causal dependencies vehicles
operators change state parcels preconditions state
vehicles  indeed  causal dependencies task  since parcels depend
parcels vehicles depend anything except  fig      set causal
dependencies planning task visualized causal graph 
argue humans often solve planning tasks hierarchical fashion outlined preceding paragraphs  algorithmic approaches action planning usefully apply similar
ideas  indeed  show following section  first introduce domain transition graphs causal graphs  however  earlier work almost exclusively focused acyclic
causal graphs  good reason  causal graph planning task exhibits cycle  hierarchical decomposition possible  subproblems must solved achieve
operator precondition necessarily smaller original task  far aware 
first  helmert        present general planning algorithm focuses exploiting hierarchical information causal graphs  however  causal graph heuristic requires
acyclicity  general case  considers relaxed planning problem operator
preconditions ignored break causal cycles 
knowing cycles causal graphs undesirable  take closer look transportation
planning task  let us recall informal definition causal graphs  causal graph planning
task contains vertex state variable arcs variables occur preconditions
variables occur effects operator  far  may given impression
causal graph example task well behaved shape shown fig     unfortunately 
closer look strips encoding fig     see case  correct
causal graph  shown fig     looks messy  discrepancy intuitive actual
graph due fact informal account human style problem solving  made
use  non binary  state variables location car c   state parcel p   
strips level state variables correspond  binary  object location propositions parcel p  
   

fih elmert

figure    causal graph strips encoding transportation planning task 
location a  would much nicer given multi valued encoding planning
task explicitly contains variable location car c   similar properties  indeed 
nice looking acyclic graph fig    causal graph multi valued encoding shown
fig    
provided intuition underlying concepts  let us state design goal
fast downward planning system  develop algorithm efficiently solves general
propositional planning tasks exploiting hierarchical structure inherent causal graphs 
need overcome three major obstacles undertaking 
first  propositionally encoded planning tasks usually unstructured causal graphs 
however  intuitive dependencies often become visible encodings multi valued
state variables  exploit fact automated pddl planning system  devised
automatic algorithm translating  or reformulating  propositional tasks multi valued
ones  translation algorithm considered independently rest planner  fact  used part planning systems  van den briel  vossen   
kambhampati         keep article focused  discuss translation algorithm
here  referring earlier work central ideas  edelkamp   helmert        
instead  consider output  multi valued planning task  base formalism 
second  matter clever encoding is  planning tasks completely hierarchical nature  deal causal cycles  consider relaxations causal
dependencies ignored use solutions relaxed problem within heuristic search
algorithm 
third  even planning tasks solved hierarchically  finding solution difficult  indeed  still pspace complete   reason  heuristic function considers
fragment task time  namely subproblems induced single state variable
predecessors causal graph  even planning problem still np complete 
   

fit fast ownward p lanning ystem

variables 
p   p   at a  at b  at c  at d  at e  at f  at g 
in c   in c   in c   in t 
c   c   at a  at b  at c  at d 
c 
 at e  at f  at g 

 at d  at e 
init 
p    at c  p    at f
c    at a  c    at b  c    at g    at e
goal 
p    at g  p    at e
operator drive c  a d 
pre  c    at a eff  c    at d
operator drive c  b d 
pre  c    at b eff  c    at d
operator drive c  c d 
pre  c    at c eff  c    at d
   
operator load c  p  a 
pre  c    at a  p    at a eff  p    in c 
operator load c  p  b 
pre  c    at b  p    at b eff  p    in c 
operator load c  p  c 
pre  c    at c  p    at c eff  p    in c 
   
operator unload c  p  a 
pre  c    at a  p    in c  eff  p    at a
operator unload c  p  b 
pre  c    at b  p    in c  eff  p    at b
operator unload c  p  c 
pre  c    at c  p    in c  eff  p    at c
   
figure    part encoding transportation planning task multi valued state variables 

   

fih elmert

content incomplete solution algorithm within heuristic solver  solution
algorithm theoretical shortcomings never failed us practice 
introduced rationale approach  discuss related work next section 
followed overview general architecture fast downward planning system
section    planning system consists three components  translation  knowledge compilation 
search  translation component converts pddl    tasks multi valued planning tasks 
formally introduce section    knowledge compilation component discussed
section    search component section    conclude presentation experimental
results section   discussion section   

   related work
planning system based heuristic forward search  fast downward clearly related
heuristic planners hsp  bonet   geffner         hoffmann   nebel       
architectural level  however  section focus work related conceptual level 
i  e   work uses similar forms hierarchical decomposition causal graphs work uses
similar forms search domain transition graphs 
    causal graphs abstraction
term causal graph first appears literature work williams nayak        
general idea considerably older  approach hierarchically decomposing planning tasks
arguably old field ai planning itself  first surfaced newell simons
       work general problem solver 
still  took long time notions evolve modern form  sacerdotis       
abstrips algorithm introduced concept abstraction spaces strips like planning tasks 
abstraction space strips task state space abstracted task  obtained
removing preconditions operators original task belong given set
propositions  which abstracted away     solve planning task  abstrips first generates
plan abstracted task  refines plan inserting concrete plans abstract
plan steps bridge gap abstract states satisfying operator preconditions
ignored abstract level  idea easily generalized several levels abstraction forming abstraction hierarchy  abstract level top almost
preconditions ignored  successively introducing preconditions every layer final
layer hierarchy equals original planning task 
one problem approach planning general guarantee
abstract plans bear resemblance reasonable concrete plans  example  abstraction spaces
chosen badly  quite possible finding concrete plan satisfies precondition
first operator abstract plan difficult solving original goal concrete level 
shortcomings spawned large amount research properties abstraction hierarchies
generated automatically 
   later work authors  propositions abstracted away removed operator effects 
makes difference subtle cases require presence axioms  distinguish
two kinds abstraction here 

   

fit fast ownward p lanning ystem

tenenberg        gives one first formal accounts properties different kinds
abstraction  among contributions  defines so called upward solution property 
informally stated as  exists concrete solution  exists abstract
solution  rather surprisingly  abstractions considered time satisfied basic
property  without one would loathe call given state space abstraction another
state space 
limitation upward solution property states relationship concrete
abstract plan all  abstrips style hierarchical planning successful  abstract
plan must bear resemblance concrete one  otherwise little point trying
refine it  indeed  tenenberg introduces stronger versions upward solution property 
relevant fast downward knoblocks        work ordered monotonicity property 
abstraction space satisfies ordered monotonicity property if  roughly speaking  concrete
solution derived abstract solution leaving actions abstract plan
intact relevant concrete plan  clearly  important property abstripslike hierarchical planning 
knoblocks article causal graphs first surface  although introduce name
them   translated terminology  knoblock proves following relationship
useful abstractions causal graphs  causal graph contains path variable
abstracted away variable abstracted away  abstraction ordered
monotonicity property  particular  means acyclic causal graphs  possible devise
abstraction hierarchy one new variable introduced level 
besides theoretical contributions  knoblock presents planning system called alpine
computes abstraction hierarchy planning task causal graph exploits
within hierarchical refinement planner  although planning method different 
derivation abstraction hierarchy similar fast downwards method generating
hierarchical decompositions planning tasks  section      
itself  ordered monotonicity property sufficient guarantee good performance
hierarchical planning approach  guarantees every concrete solution obtained
natural way abstract solution  guarantee abstract solutions
refined concrete ones  guarantee provided downward refinement property 
introduced bacchus yang        
downward refinement property rarely guaranteed actual planning domains 
bacchus yang develop analytical model performance hierarchical planning situations given abstract plan refined certain probability p      based
analysis  present extension alpine called highpoint  selects abstraction hierarchy high refinement probability among satisfy ordered monotonicity
property  practice  feasible compute refinement probability  highpoint approximates value based notion k ary necessary connectivity 
    causal graphs unary strips operators
causal graphs first given name jonsson backstrom            b   call
dependency graphs  study fragment propositional strips negative conditions
interesting property plan existence decided polynomial time  minimal
solutions task exponentially long  polynomial planning algorithm exists 
   

fih elmert

present incremental planning algorithm polynomial delay  i  e   planning algorithm
decides within polynomial time whether given task solution  and  so  generates
solution step step  requiring polynomial time two subsequent steps   
fragment strips covered jonsson backstroms algorithm called  s
defined requirement causal graph task acyclic state variables
static  symmetrically reversible  splitting  static variables easy
guarantee never change value solution plan  variables detected
compiled away easily  symmetrically reversible variables operator
makes true corresponding operator identical preconditions makes
false  vice versa  words  variable symmetrically reversible iff domain
transition graph undirected  finally  variable v splitting iff removal causal graph
weakly disconnects positive successors  those variables appear effects operators
v precondition  negative successors  those variables appear effects
operators v precondition  
williams nayak        independently prove incremental  or  setting  reactive 
planning polynomial problem strips like setting causal graphs acyclic
operators reversible  operators reversible  according definition williams
nayak   variables symmetrically reversible  according definition jonsson
backstrom   actually special case previous result  however  williams nayaks
work applies general formalism propositional strips  approaches
directly comparable 
recently  domshlak brafman provide detailed account complexity finding plans propositional strips  with negation  formalism unary operators acyclic
graphs  domshlak   brafman        brafman   domshlak           among results 
prove restriction unary operators acyclic graphs reduce complexity
plan existence  problem pspace complete  unrestricted propositional strips
planning  bylander         show singly connected causal graphs  shortest plans
cannot exponentially long  problem still np complete  even restricted class
causal graphs  namely polytrees bounded indegree  present polynomial planning algorithm  generally  analysis relates complexity strips planning unary domains
number paths causal graph 
    multi valued planning tasks
exception williams nayaks paper  work discussed far exclusively deals
propositional planning problems  state variables assume values binary domain  observed introduction  question propositional vs  multi valued encodings
usually strong impact connectivity causal graph task  fact  apart
trivial ovie domain  none common planning benchmarks exhibits acyclic causal graph
   however  guarantee length generated solution polynomially related length
optimal solution  might exponentially longer  therefore  algorithm might spend exponential time tasks
solved polynomial time 
   according formal definition causal graphs section      operators several effects always induce
cycles causal graph  acyclic causal graph implies unary operators  researchers define causal graphs
differently  name properties explicitly here 

   

fit fast ownward p lanning ystem

considering propositional representation  contrast  multi valued encoding
introductory example acyclic causal graph 
due dominance pddl  and previously  strips  formalism  non binary state variables studied often classical planning literature  one important exceptions rule work sas   planning formalism  papers backstrom
nebel        jonsson backstrom      a  relevant fast downward 
sas  planning formalism basically equivalent multi valued planning tasks introduce
section   apart fact include derived variables  axioms  conditional
effects  backstrom nebel analyse complexity various subclasses sas   formalism discover three properties  unariness  post uniqueness single valuedness  together
allow optimal planning polynomial time  one three properties  unariness  related
acyclicity causal graphs  one  post uniqueness  implies particularly simple shape domain
transition graphs  namely  post unique tasks  domain transition graphs must simple cycles
trees  
backstrom nebel analyse domain transition graphs formally  indeed  term
introduced later article jonsson backstrom      a   refines earlier results
introducing five additional restrictions sas   tasks  related properties
domain transition graphs 
neither two articles discusses notion causal graphs  indeed  earlier work
aware includes causal graphs domain transition graphs central concepts
article domshlak dinitz        state transition support  sts  problem 
essentially equivalent sas  planning unary operators  context sts  domain
transition graphs called strategy graphs causal graphs called dependence graphs 
apart minor details  semantics two formalisms identical  domshlak dinitz
provide map complexity sts problem terms shape causal graph 
showing problem np complete worse almost non trivial cases  one interesting
result causal graph simple chain n nodes variables three valued 
length minimal plans already grow    n    contrast  propositional tasks
causal graph shape admit polynomial planning algorithms according result brafman
domshlak         causal graphs polytrees constant indegree bound
 namely  bound    
summarize conclude discussion related work  observe central concepts fast downward causal graph heuristic  causal graphs domain transition
graphs  firmly rooted previous work  however  fast downward first attempt marry
hierarchical problem decomposition use multi valued state variables within general planning framework  first attempt apply techniques similar knoblock       
bacchus yang        within heuristic search planner 
significance latter point underestimated  classical approaches
hierarchical problem decomposition  imperative abstraction satisfies ordered monotonicity property  important probability able refine abstract plan
concrete plan high  analysis bacchus yang shows  unfortunately  non trivial
abstraction hierarchies rarely ordered monotonic  even rarely guarantee high refinement probabilities  within heuristic approach  must haves turn nice to haves 
abstraction hierarchy ordered monotonic abstract plan considered heuristic
evaluator refinable  merely reduces quality heuristic estimate  rather caus   

fih elmert

translation





normalization
invariant synthesis
grounding
translation mpt

knowledge
compilation
domain transition
graphs
causal graph
successor generator
axiom evaluator

search






causal graph heuristic
heuristic
greedy best first search
multi heuristic best first search
focused iterative broadening search

figure    three phases fast downwards execution 
ing search fail  in worst case  spend long time trying salvage non refinable abstract
plans  in much better case  

   fast downward
describe overall architecture planner  fast downward classical planning
system based ideas heuristic forward search hierarchical problem decomposition 
deal full range propositional pddl     fox   long        edelkamp   hoffmann 
       i  e   addition strips planning  supports arbitrary formulae operator preconditions
goal conditions  deal conditional universally quantified effects derived
predicates  axioms  
name planner derives two sources  course  one sources hoffmanns successful  fast forward  planner  hoffmann   nebel         ff  fast
downward heuristic progression planner  i  e   computes plans heuristic search space
world states reachable initial situation  however  compared ff  fast downward uses
different heuristic evaluation function called causal graph heuristic  heuristic evaluator proceeds downward far tries solve planning tasks hierarchical fashion
outlined introduction  starting top level goals  algorithm recurses
causal graph remaining subproblems basic graph search tasks 
similar ff  planner shown excellent performance  original implementation
causal graph heuristic  plugged standard best first search algorithm  outperformed previous champions area  lpg  gerevini  saetti    serina         set strips
benchmarks first three international planning competitions  helmert         fast downward followed footsteps lpg winning propositional  non optimizing
track  th international planning competition icaps       referred ipc 
on  
mentioned introduction  fast downward solves planning task three phases  fig     
translation component responsible transforming pddl    input nonbinary form amenable hierarchical planning approaches  applies number normalizations compile away syntactic constructs disjunctions
directly supported causal graph heuristic performs grounding axioms operators  importantly  uses invariant synthesis methods find groups related propo   

fit fast ownward p lanning ystem

sitions encoded single multi valued variable  output translation
component multi valued planning task  defined following section 
knowledge compilation component generates four kinds data structures play
central role search  domain transition graphs encode how  conditions 
state variables change values  causal graph represents hierarchical dependencies different state variables  successor generator efficient data
structure determining set applicable operators given state  finally  axiom
evaluator efficient data structure computing values derived variables 
knowledge compilation component described section   
search component implements three different search algorithms actual planning 
two algorithms make use heuristic evaluation functions  one well known
greedy best first search algorithm  using causal graph heuristic  called multiheuristic best first search  variant greedy best first search tries combine several
heuristic evaluators orthogonal way  case fast downward  uses causal
graph heuristics  third search algorithm called focused iterative broadening
search  closely related ginsberg harveys        iterative broadening 
heuristic search algorithm sense use explicit heuristic evaluation
function  instead  uses information encoded causal graph estimate usefulness operators towards satisfying goals task  search component described
section   

   multi valued planning tasks
let us formally introduce problem planning multi valued state variables 
formalism based sas  planning model  backstrom   nebel        jonsson   backstrom 
    a   extends axioms conditional effects 
definition   multi valued planning tasks  mpts 
multi valued planning task  mpt  given   tuple   hv      s    a  oi following
components 
v finite set state variables  associated finite domain v   state variables partitioned fluents  affected operators  derived variables  computed
evaluating axioms   domains derived variables must contain undefined value  
partial variable assignment partial state v function subset v
s v  dv wherever s v  defined  partial state called extended state
defined variables v reduced state state defined fluents v 
context partial variable assignments  write v   variable value pairing
 v  d  v   d 
s  state v called initial state 
s  partial variable assignment v called goal 
finite set  mpt  axioms v  axioms triples form hcond  v  di 
cond partial variable assignment called condition body axiom  v derived
   

fih elmert

variable called affected variable  v called derived value v  pair
 v  d  called head axiom written v    d 
axiom set partitioned totally ordered set axiom layers   ak
within layer  affected variable may associated single
value axiom heads bodies  words  within layer  axioms
affected variable different derived values forbidden  variable appears
axiom head  may appear different value body  called
layering property 
finite set  mpt  operators v  operator hpre  effi consists partial
variable assignment pre v called precondition  finite set effects eff  effects
triples hcond  v  di  cond  possibly empty  partial variable assignment called
effect condition  v fluent called affected variable  v called new
value v 
axioms effects  use notation cond v    place hcond  v  di 
provide formal semantics mpt planning  first need formalize axioms 
definition   extended states defined state
let state mpt axioms a  layered   ak   extended state defined
s  written a s   result   following algorithm 
algorithm evaluate axioms a            ak   s  
variable
  v 
s v  v fluent variable
s   v    

v derived variable
            k  
exists axiom  cond v    d  cond s  s   v     d 
choose axiom cond v    d 
s   v    
words  axioms evaluated layer by layer fashion using fixed point computations 
similar semantics stratified logic programs  easy see layering
property definition   guarantees algorithm terminates produces deterministic
result  defined semantics axioms  define state space mpt 
definition   mpt state spaces
state space mpt   hv  s    s    a  oi  denoted s    directed graph  vertex
set set states v  contains arc  s      iff exists operator hpre  effi
that 
pre a s  
s   v    effects cond v    eff cond a s  
s   v    s v  fluents 
   

fit fast ownward p lanning ystem

finally  define mpt planning problem 
definition   mpt planning
mpt p lan e x following decision problem  given mpt initial state   goal
s    s   contain path s  state s  s  a s    
mpt p lanning following search problem  given mpt initial state   goal
s    compute path s   s  state s  s  a s     prove none exists 
mpt p lan e x problem easily shown pspace hard generalizes plan
existence problem propositional strips  known pspace complete  bylander 
       easy see addition multi valued domains  axioms conditional effects
increase theoretical complexity mpt planning beyond propositional strips  thus 
conclude formal introduction mpt planning stating mpt p lan e x pspacecomplete  turn practical side things following section 

   knowledge compilation
purpose knowledge compilation component set stage search algorithms
compiling critical information planning task number data structures efficient access  contexts  computations kind often called preprocessing  however 
preprocessing nondescript word mean basically anything  reason 
prefer term puts stronger emphasis role module  rephrase critical information planning task way directly useful search algorithms 
three building blocks fast downward  translation  knowledge compilation  search  
least time critical part  always requiring less time translation dominated search
trivial tasks 
knowledge compilation comprises three items  first foremost  compute domain
transition graph state variable  domain transition graph state variable encodes
circumstances variable change value  i  e   values domain
transitions values  operators axioms responsible transition  conditions state variables associated transition  domain
transition graphs described section      central concept computation
causal graph heuristic  described section     
second  compute causal graph planning task  domain transition graphs encode dependencies values given state variable  causal graph encodes dependencies
different state variables  example  given location planning task unlocked
means key carried agent  variable representing lock state
location dependent variable represents whether key carried 
dependency encoded arc causal graph  domain transition graphs  causal
graphs central concept computation causal graph heuristic  giving name 
causal graph heuristic requires causal graphs acyclic  reason  knowledge compilation component generates acyclic subgraph real causal graph cycles occur 
amounts relaxation planning task operator preconditions ignored 
addition usefulness causal graph heuristic  causal graphs key concept
focused iterative broadening search algorithm introduced section      discuss causal
graphs section     
   

fih elmert

third  compute two data structures useful forward searching algorithm
mpts  called successor generators axiom evaluators  successor generators compute set
applicable operators given world state  axiom evaluators compute values derived
variables given reduced state  designed job quickly possible 
especially important focused iterative broadening search algorithm  compute heuristic estimates thus requires basic operations expanding search node
implemented efficiently  data structures discussed section     
    domain transition graphs
domain transition graph state variable representation ways variable
change value  conditions must satisfied value changes allowed  domain transition graphs introduced jonsson backstrom      a  context
sas  planning  formalization domain transition graphs generalizes original definition
planning tasks involving axioms conditional effects 
definition   domain transition graphs
let   hv  s    s    a  oi multi valued planning task  let v v state variable  
domain transition graph v  symbols dtg v   labelled directed graph vertex
set dv   v fluent  dtg v  contains following arcs 
effect cond v    d  operator precondition pre pre cond
contains condition v   d  arc   labelled pre cond    v   d  
effect cond v    d  operator precondition pre pre cond
contain condition v   v   arc dv    d    d 
labelled pre cond 
v derived variable  dtg v  contains following arcs 
axiom cond v    d  cond contains condition v   d  arc
d  labelled cond    v   d  
axiom cond v    d  cond contain condition v  
dv   arc dv    d    d  labelled cond 
arcs domain transition graphs called transitions  labels referred
conditions transition 
domain transition graphs weighted  case transition associated
non negative integer weight  unless stated otherwise  assume transitions derived
operators weight   transitions derived axioms weight   
definition somewhat lengthy  informal content easy grasp  domain transition graph v contains transition   exists operator axiom
change value v d    transition labelled conditions state
variables must true transition shall applied  multiple transitions
values using different conditions allowed occur frequently 
already seen domain transition graphs introductory section  figs        although introduced informally show arc labels usually associated
   

fit fast ownward p lanning ystem

  open
      

      

      

      

      

      

r 

r           k   carried

closed

r           k   carried

r 

open

      

   

  

  

  
   
r 

  
   

r         

   

r         

r 

r 

r 

      

  
   

r 
r 

carried

r         

      

      

r         

  open

  open

   

   
   

  

  

  

      

r           k   carried
      

figure     domain transition graphs g rid task  top left  dtg r   robot   right  dtg k 
 key   bottom left  dtg d   door  

transitions  fig     shows examples simple task g rid domain  featuring     grid single initially locked location centre upper row  unlockable
single key  mpt encoding task  three state variables  variable r
dr      x  y    x                     encodes location robot  variable k
dk   dr  carried  encodes state key  variable    closed  open 
encodes state initially locked grid location 
operators mpt unary  i  e   single effect  leave aside axioms
moment  strong correspondence state space mpt
domain transition graphs  since vertices domain transition graphs correspond values state
variables  given state represented selecting one vertex domain transition graph  called
active vertex state variable  applying operator means changing active vertex
state variable performing transition corresponding domain transition graph 
whether transition allowed depends condition  checked
active vertices domain transition graphs 
let us use g rid example illustrate correspondence  consider initial state
robot location         key location         door locked  represent
placing pebbles appropriate vertices three domain transition graphs  want
move pebble domain transition graph key location         done
moving robot pebble vertex                         moving key pebble vertex
carried  moving robot pebble back vertex         moving door pebble open  moving
robot pebble vertex        finally moving key pebble vertex        
   

fih elmert

  open  r         
  open  r         

  open  r         

  closed


 



r         

 

r         

  open  r         

r         
r         

figure     domain transition graphs freezing variable g rid task  normal  left 
extended  right   note extended graph shows change state
freezing     freezing    

example shows plan execution viewed simultaneous traversal domain
transition graphs  cf  domshlak   dinitz         important notion fast downward
causal graph heuristic computes heuristic estimates solving subproblems
planning task looking paths domain transition graphs basically way described 
mentioned before  view mpt planning completely accurate unary tasks
without axioms  domain transition graphs indeed complete representation
state space  non unary operators  would need link certain transitions different domain
transition graphs belong operator  could executed together 
axioms  would need mark certain transitions mandatory  requiring taken
whenever possible   this intended rough analogy leaves details layered
axioms  
previous work  helmert         successfully applied view planning
strips tasks  extending notion plans conditional effects provides challenges domain transition graphs always consider planning operators one effect time 
case effect condition simply seen part operator precondition  however  axioms
provide challenge easily overlooked  want change value fluent
d    domain transition graph contains important information  find path  
try find associated conditions achieved  consider problem
derived state variable  let us assume unlocking location g rid example leads
drought  causing robot freeze enters horizontally adjacent location  could encode
new derived variable f  for freezing  domain f          defined axioms
  open  r          f        open  r          f       domain transition graph
dtg f   depicted fig      left  
problem domain transition graph tell us change
state variable f     general  mpts derived strips tasks derived
predicates occur negatively condition  domain transition graph contain sufficient
information changing value derived variable true false  derived variables
   

fit fast ownward p lanning ystem

never assume value due derivation value  negation failure semantics 
assume value default value derived  want reason
ways setting value derived variable   need make information explicit 
logical notation  whether derived variable assumes given value triggering
axiom given layer determined formula disjunctive normal form  one disjunct
axiom setting value  example  axioms   open  r          f     
  open  r          f      correspond dnf formula  d   open r            d  
open r            want know rules trigger  must negate formula 
leading cnf formula  d    open r            d    open r             able encode
information domain transition graph  need replace inequalities equalities
translate formula back dnf  since transformations increase formula size
dramatically  apply simplifications along way  removing duplicated dominated disjuncts 
result case dnf formula   closed r          r          r          r  
       
domain transition graph derived variable enriched contain possible
ways causing variable assume value called extended domain transition graph 
shown g rid example fig      right   since computing extended domain transition
graph costly always necessary  knowledge compilation component scans
conditions planning task  axioms  operator preconditions effect conditions  goal 
occurrences pairings type v   derived variables v  extended domain transition
graphs computed derived variables required 
note negative occurrences derived variables cascade  u  v w derived
variables domain       condition v   present operator precondition 
moreover v defined axiom u      w     v       v assumes value
whenever u w do  would require extended domain transition graphs u w well 
hand  multiple layers negation failure cancel out  derived
variable v occurs conditions form v   never positive form defined
axiom u     w   v       necessarily require extended domain transition
graphs u w 
general  whether need extended domain transition graphs derived variable
determined following rules 
v derived variable condition v      appears operator
precondition  effect condition goal  v used positively 
v derived variable condition v   appears operator precondition 
effect condition goal  v used negatively 
v derived variable condition v      appears body
axiom whose head used positively  negatively   v used positively  negatively  
v derived variable condition v   appears body axiom
whose head used positively  negatively   v used negatively  positively  
knowledge compilation component computes extended domain transition graphs derived variables used negatively  standard  domain transition graphs state
variables  normal domain transition graphs computed going set axioms
   

fih elmert

set operator effects following definition    reasonably straight forward  computation extended domain transition graphs outlined above  therefore  algorithmic
aspects topic require discussion 
    causal graphs
causal graphs introduced informally introduction  formal definition 
definition   causal graphs
let multi valued planning task variable set v  causal graph   symbols
cg    directed graph vertex set v containing arc  v  v     iff v    v   one
following conditions true 
domain transition graph v   transition condition v 
set affected variables effect list operator includes v v    
first case  say arc induced transition condition  second case say
induced co occurring effects 
course  arcs induced transition conditions arcs induced co occurring effects
mutually exclusive  causal graph arc generated reasons 
informally  causal graph contains arc source variable target variable changes
value target variable depend value source variable  arcs
included dependency form effect source variable  agrees
definition dependency graphs jonsson backstrom      b   although authors
distinguish two different ways arc graph introduced using
labelled arcs 
whether co occurring effects induce arcs causal graph depends intended semantics  arcs included  set causal graph ancestors anc v  variable
v precisely variables relevant goal change value v  plans
goal computed without considering variables outside anc v   eliminating variables outside anc v  planning task simplifying axioms operators accordingly 
call achievability definition causal graphs  causal graphs encode variables
important achieving given assignment state variable 
however  achievability definition  planner considers anc v  generating
action sequence achieves given valuation v may modify variables outside anc v   i  e  
generated plans side effects could destroy previously achieved goals otherwise
negative impact overall planning  therefore  prefer definition  call
separability definition causal graphs 
      acyclic c ausal g raphs
following separability definition causal graphs  solving subproblem variables anc v 
always possible without changing values outside anc v   leads us following
observation 
   

fit fast ownward p lanning ystem

observation   acyclic causal graphs strongly connected domain transition graphs
let mpt cg   acyclic  domain transition graphs strongly connected 
derived variables  trivially false conditions occur operators goals 
solution 
trivially false conditions  mean conditions kind  v   d  v          d   
note similarity observation   results williams nayak        planning domains unary operators  acyclic causal graphs reversible transitions  separability
definition causal graphs  acyclic causal graphs imply unariness operators operators
several effects introduce causal cycles  moreover  strong connectedness domain transition
graphs closely related williams nayaks reversibility property  although weaker
requirement 
truth observation easily seen inductively  planning task one state
variable domain transition graph strongly connected  state  of one variable 
transformed state applying graph search techniques  planning task
several state variables causal graph acyclic  pick sink causal graph  i  e  
variable v without outgoing arcs  check goal defined variable  not 
remove variable task  thus reducing problem one fewer state variables 
solved recursively  yes  search path    v  s   v  domain transition graph
v  guaranteed exist graph strongly connected  yields high level
plan setting v s   v  fleshed recursively inserting plans setting
variables predecessors v causal graph values required transitions
form high level plan  desired value v set  v eliminated
planning task remaining problem solved recursively 
algorithm shown fig      although backtrack free  require exponential
time execute generated plans exponentially long  unavoidable  even
mpts satisfy conditions observation    shortest plans exponentially long 
family planning tasks property given proof theorem     article
backstrom nebel        
method solving multi valued planning tasks essentially planning refinement 
begin constructing abstract skeleton plan  merely path domain transition
graph  lower level abstraction adding operators satisfy preconditions required
transitions taken path  strong connectedness domain transition graphs guarantees
every abstract plan actually refined concrete plan  precisely bacchus
yangs        downward refinement property  cf  section      
      g enerating



p runing c ausal g raphs

usefulness causal graphs planning refinement limited acyclic case  consider subset v   task variables contains causal graph descendants  general 
restrict task v   removing occurrences variables initial state  goal 
operators axioms  obtain abstraction original problem satisfies knoblocks
       ordered monotonicity property  section      
unfortunately  one major problem approach requirement include causal
graph descendants quite limiting  uncommon causal graph planning task
strongly connected  case technique allow us abstract away variables
   

fih elmert

algorithm solve easy mpt v  s    s    o  
s     
  goal empty  empty plan solution   
return hi 
else 
let v v variable occurring preconditions effect conditions o 
  variable always exists causal graph task acyclic   
v      v    v  
         affect v   
plan    hi
s   v  defined 
let t            tk path transitions dtg v     v  s   v  
  t            tk high level plan reaches goal v 
ignores preconditions variables   
 t            tk   
  recursively find plan achieves conditions t   
let cond condition operator associated t 
let s   state reached executing plan  restricted v    
extend plan solve easy mpt v     s     cond      
extend plan o 
  dealing v  recursively plan goals remaining variables   
let s   state reached executing plan  restricted v    
s      s  restricted v    
extend plan solve easy mpt v     s     s         
return plan
figure     planning algorithm mpts acyclic causal graph strongly connected domain
transition graphs 

   

fit fast ownward p lanning ystem

all  however  heuristic approach  free simplify planning task  particular 
ignoring operator preconditions purposes heuristic evaluation  make
arbitrary causal graph acyclic  clearly  aspects real task ignore  worse
expect heuristic approximate actual goal distance  considering this  aim ignore
little information possible  explain done 
knowledge compilation component begins causal graph processing generating
full causal graph  definition     one consequence separability definition causal graphs
state variables ancestors variables mentioned goal completely
irrelevant  therefore  computed graph  compute causal graph ancestors
variables goal  state variables found goal ancestors eliminated planning task causal graph  associated operators axioms removed   
afterwards  compute pruned causal graph  acyclic subgraph causal graph
vertex set  try fashion important causal dependencies retained
whenever possible  specifically  apply following algorithm 
first  compute strongly connected components causal graph  cycles occur
within strongly connected components  component dealt separately  second 
connected component  compute total order vertices  retaining
arcs  v  v     v v     v v     say v   higher level v  total order
computed following way 
   assign weight arc causal graph  weight arc n induced
n axioms operators  lower cumulated weight incoming arcs vertex 
fewer conditions ignored assigning low level vertex 
   pick vertex v minimal cumulated weight incoming arcs select
lowest level  i  e   set v v   vertices v   strongly connected component 
   since v dealt with  remove vertex incident arcs consideration
rest ordering algorithm 
   remaining problem solved iteratively applying technique order
vertices single vertex remains 
reader notice pruning choices within strongly connected component
performed greedy algorithm  could try find sets arcs minimal total weight
eliminating arcs results acyclic graph  however  np equivalent problem 
even case unweighted graphs  garey   johnson        problem gt   
generating pruned causal graph  prune domain transition graphs removing transition labels dtg v  conditions variables v   v v    
conditions ignored heuristic computation  finally  simplify domain transition
graphs removing dominated transitions    transitions two values
variable  condition proper subset condition     transition
easier apply t    remove t    similarly  several transitions identical
conditions  keep one them 
   simplification closely related knoblocks criterion problem specific ordered monotonicity property
 knoblock        

   

fih elmert

t 

t 

a 

p 

p 

a 

figure     causal graph l ogistics task  state variables ai encode locations
trucks airplanes  state variables p locations packages 

f 

p 

f 

f 

f 

f 

f 

l 

l 

l 

l 

c 

c 

c 

c 

p 

p 

p 

figure     causal graph ystery task  left  relaxed version task  right   state
variables encode fuel location  state variables l ci encode locations
remaining capacities trucks  state variables p encode locations packages 

      c ausal g raph e xamples
give impression types causal graphs typically found standard benchmarks
effects pruning  show examples increasing graph complexity 
first simplest example  fig     shows causal graph task l ogistics
domain  featuring two trucks  two airplanes two packages  seen  graph acyclic 
requires pruning causal graph heuristic  since l ogistics tasks feature strongly
connected domain transition graphs  even solved polynomial solve easy mpt
algorithm 
slightly complicated example  next figure  fig      shows task ys tery domain three locations  two trucks two packages  causal graph contains
number cycles  mostly local  pruning arcs vertices l fj   ignore
   

fit fast ownward p lanning ystem

r

r



l



k 

k 

l

k 

k 

figure     causal graph g rid task  left  relaxed version task  right   state
variable r encodes location robot  encodes status robot arm  empty
carrying key   l encodes status locked location  locked open   k  
k  encode locations two keys 

fact must move trucks certain locations want use fuel location 
using fuel useful thing do  big loss information  pruning arcs
vertices pi cj   ignore fact vehicles increase decrease current
capacity unloading loading packages  compared heuristics based ignoring delete effects  great loss information  since ignoring delete effects ystery domain
almost amounts ignoring capacity fuel constraints altogether  pruning arcs 
eliminate cycles causal graph  ystery domain considered fairly
well behaved 
worse case shown fig      shows example g rid domain
arbitrary number locations  single one locked  two keys  one
unlock locked location  eliminating cycles requires minor relaxations regarding
status robot arm  empty non empty   one major simplification  namely
elimination arc l r representing fact robot enter locked
location unlocked 
 nearly  worst case example  consider task b locksworld domain  no figure  
typical mpt encoding uses one state variable h encoding whether hand empty
two state variables per block task  i th block  encodes whether block
lying table  bi encodes block lying top it  clear held
arm  causal graph task  variable h ingoing arcs outgoing arcs
state variables  state variables b connected directions 
state variables ti slightly simpler connection structure  connected h
bi value i  relaxation problem eliminates cycles causal
graph loses large amount information  surprising epot domain 
includes b locksworld subproblem  one precursor fast downward fared
worst  helmert         still  pointed planners ignore delete effects
similar problems b locksworld like domains  comparison causal
graph heuristics article shows 
   

fih elmert

    successor generators axiom evaluators
addition good heuristic guidance  forward searching planning system needs efficient methods
generating successor states applied benchmark suite international
planning competitions  domains  causal graph heuristic popular methods
heuristic provide excellent goal estimates  yet still planning time consuming
long plans vast branching factors 
variant best first search implemented fast downward compute heuristic
estimate state generated  essentially  heuristic evaluations computed
closed nodes  computation deferred nodes search frontier  domains
strong heuristic guidance large branching factors  number nodes frontier
far dominate number nodes closed set  case point  consider problem instance
atellite      solving task  default configuration fast downward computes
heuristic estimates        world states adding             states frontier  clearly 
determining set applicable operators quickly critical importance scenario 
atellite tasks  almost           ground operators  try
avoid individually checking operator applicability  similarly  biggest psr tasks 
        axioms must evaluated state compute values derived
variables  computation must made efficient  purposes  fast downward uses two
data structures called successor generators axiom evaluators 
      uccessor g enerators
successor generators recursive data structures similar decision trees  internal nodes
associated conditions  likened decisions decision tree  leaves
associated operator lists likened set classified samples decision tree
leaf  formally defined follows 
definition   successor generators
successor generator mpt   hv      s    a  oi tree consisting selector nodes
generator nodes 
selector node internal node tree  associated variable v v called
selection variable  moreover   d v     children accessed via labelled edges  one edge labelled
v   value dv   one edge labelled    latter edge called dont care
edge selector 
generator node leaf node tree  associated set operators called
set generated operators 
operator must occur exactly one generator node  set edge labels
leading root node  excluding dont care edges  must equal precondition o 
given successor generator mpt state   compute set
applicable operators traversing successor generator follows  starting root 
selector node selection variable v  follow edge v   s v  dont care edge 
generator node  report generated operators applicable 
   

fit fast ownward p lanning ystem

algorithm evaluate axiom layer s    
axiom ai  
a counter     a cond 
variable v 
axiom ai condition v   s v  body 
a counter    a counter  
exists axiom ai a counter     yet considered 
let hv  di head axiom 
s v     d 
s v    
axiom ai condition v   body 
a counter    a counter  
figure     computing values derived variables given planning state 
build successor generator   apply top down algorithm considers task
variables arbitrary order v  v  vn   root node  choose v  selection variable classify set operators according preconditions respect v     operators
precondition v    represented child root accessed edge
corresponding label  operators without preconditions v   represented child
root accessed dont care edge  children root  choose v   selection
variable  grandchildren v    on 
one exception rule avoid creating unnecessary selection nodes  operator
certain branch tree condition v   vi considered selection variable
branch  construction branch ends variables considered 
stage generator node created operators associated branch 
      xiom e valuators
axiom evaluators simple data structure used efficiently implementing well known
marking algorithm propositional horn logic  dowling   gallier         extended modified
layered logic programs correspond axioms mpt  consist two parts 
firstly  indexing data structure maps given variable value pairing given axiom layer
set axioms given layer whose body pairing appears  secondly  set counters 
one axiom  counts number conditions axiom yet derived 
within fast downward  axioms evaluated two steps  first  derived variables set
default value   second  algorithm evaluate axiom layer  fig      executed axiom
layer sequence determine final values derived variables 
assume reader familiar enough marking algorithm require much
explanation  point test whether axiom ready trigger implemented means queue axioms put soon counter reaches    actual
implementation evaluate axiom layer within fast downward initializes axiom counters slightly
efficiently indicated pseudo code  however  minor technical detail 
turn remaining piece fast downwards architecture  search component 
   

fih elmert

   search
unlike translation knowledge compilation components  single
mode execution  search component fast downward perform work various alternative ways  three basic search algorithms choose from 
   greedy best first search  standard textbook algorithm  russell   norvig        
modified technique called deferred heuristic evaluation mitigate negative influence wide branching  extended algorithm deal preferred operators  similar ffs helpful actions  hoffmann   nebel         discuss greedy best first
search section      fast downward uses algorithm together causal graph
heuristic  discussed section     
   multi heuristic best first search  variation greedy best first search evaluates
search states using multiple heuristic estimators  maintaining separate open lists each 
variant greedy best first search  supports use preferred operators  multiheuristic best first search discussed section      fast downward uses algorithm
together causal graph heuristics  discussed sections         
   focused iterative broadening search  simple search algorithm use
heuristic estimators  instead reduces vast set search possibilities focusing
limited operator set derived causal graph  experimental algorithm 
future  hope develop basic idea algorithm robust method 
focused iterative broadening search discussed section     
two heuristic search algorithms  second choice must made regarding use
preferred operators  five options supported planner 
   use preferred operators 
   use helpful transitions causal graph heuristic preferred operators 
   use helpful actions heuristic preferred operators 
   use helpful transitions preferred operators  falling back helpful actions
helpful transitions current search state 
   use helpful transitions helpful actions preferred operators 
five options combined two heuristic search algorithms 
total eleven possible settings search component  ten using one
heuristic algorithms one using focused iterative broadening search 
addition basic settings  search component configured execute several
alternative configurations parallel making use internal scheduler  configurations
fast downward participated ipc  made use feature running one configuration
heuristic search algorithms parallel focused iterative broadening search  heuristic
search algorithm  configuration fast downward employed greedy best first search helpful
transitions  falling back helpful actions necessary  option      configuration fast diagonally downward employed multi heuristic best first search using helpful transitions helpful
actions preferred operators  option     
   

fit fast ownward p lanning ystem

avoid confusion complete fast downward planning system particular
configuration called fast downward  refer ipc  planner configurations fd
fdd rest paper  name planning system whole never abbreviated 
    causal graph heuristic
causal graph heuristic centrepiece fast downwards heuristic search engine  estimates cost reaching goal given search state solving number subproblems
planning task derived looking small windows  pruned  causal graph 
additional intuitions design heuristic discussion theoretical aspects 
refer article heuristic first introduced  helmert        
      c onceptual v iew



c ausal g raph h euristic

state variable v pair values d    dv   causal graph heuristic computes
heuristic estimate cost v  d  d    cost changing value v     assuming
state variables carry values current state   this simplification  cost
estimates computed state variables v values never required 
ignore fact discussing heuristic conceptual level   heuristic estimate
given state sum costs cost v  s v   s   v   variables v goal
condition s   v  defined 
conceptually  cost estimates computed one variable other  traversing  pruned 
causal graph bottom up fashion  bottom up  mean start variables
predecessors causal graphs  call order computation bottom up
consider variables change state accord low level  variables
whose state transitions require help variables complex transition semantics
thus considered high level  note figures depicting causal graphs  high level
variables typically displayed near bottom 
variables without predecessors causal graph  cost v  d  d    simply equals cost
shortest path d   pruned  domain transition graph dtg v   variables 
cost estimates computed graph search domain transition graph  however 
conditions transitions must taken account path planning  addition
counting number transitions required reach destination value  consider costs
achieving value changes variables necessary set transition conditions 
important point computing values cost v  d  d     completely consider
interactions state variable v predecessors causal graph  changing
value d  requires several steps steps associated condition
variable v     realize v   must assume values required conditions sequence 
example  v represents package transportation task must moved b
means vehicle located c  recognize vehicle must first move c
b order drop package b  different way hspor ff based heuristics work examples  however  consider interactions
immediate predecessors v causal graph  interactions occur via several graph layers
captured heuristic estimator 
essence  compute cost v  d  d    solving particular subproblem mpt  induced
variable v predecessors pruned causal graph  subproblem  assume
   

fih elmert

algorithm compute costs bottom up   s  
variable v   traversing pruned causal graph bottom up order 
let v   set immediate predecessors v pruned causal graph 
pair values  d  d    dv dv  
generate planning task v d d  following components 
variables  v    v  
initial state  v   v     s v     v   v    
goal  v   d   
axioms operators 
   corresponding transitions pruned dtg v 
   variables v   v   values e  e  dv    operator
precondition v     e  effect v     e  cost cost v  e  e    
  note variables v   v   considered previously 
cost values known   
set costv  d  d    cost plan solves v d d   
figure     compute costs bottom up algorithm  high level description causal graph
heuristic 

v initially set d  want v assume value     state variables carry
value current state  call planning problem local subproblem v     
local subproblem v leave target value   open 
formalization intuitive notions cost estimates generated  consider
pseudo code fig      reflect way heuristic values actually computed
within fast downward  algorithm figure would far expensive evaluate
search state  however  computes cost values fast downward does  provided
algorithm generating plans last line algorithm one one used
real cost estimator 
      c omputation



c ausal g raph h euristic

actual computation causal graph heuristic traverses causal graph top down direction starting goal variables  rather bottom up starting variables without causal
predecessors  fact  top down traversal causal graph reason fast downwards
name 
computing cost estimates top down traversal implies algorithm computing
plans local subproblems given variable  typically yet know costs changing
state causal predecessors  algorithm compute costs addresses evaluating
cost values dependent variables recursive invocations itself 
given variable value pairing v   d  always compute costs cost v  d  d    values
d  dv time  similar way dijkstras algorithm computes shortest path
single source single destination vertex  single source possible destination
vertices  computing costs values    much  expensive computing
   

fit fast ownward p lanning ystem

one values  cost values determined  cache re use
needed later parts computation heuristic value
current state 
fact  similarity shortest path problems superficial runs quite deeply 
ignore recursive calls computing cost values dependent variables  compute costs basically implementation dijkstras algorithm single source shortest path problem
domain transition graphs  difference regular algorithm lies fact
know cost using arc advance  transitions derived variables base cost
  transitions fluents base cost    addition base cost  must pay
cost achieving conditions associated transition  however  cost achieving
given condition v     e  depends current value e state variable time transition
taken  thus  compute real cost transition know values
dependent state variables relevant situation 
course  many different ways taking transitions domain transition graphs 
potentially leading different values dependent state variables  first introduced
causal graph heuristic  showed deciding plan existence local subproblems npcomplete  helmert         content approach lead complete
planning algorithm  long works well subproblems face practice 
approach chosen achieve value state variable v local subproblem
v quickly possible  following greedy policy  context dijkstra algorithm 
means start finding cheapest possible plan make transition
value d    found cheapest possible plan d    commit it  annotating
vertex d  domain transition graph local state obtained applying plan d 
current state  next step  look cheapest possible plan achieve another value     
either considering transitions start initial value d  considering transitions
continue plan d  moving neighbour d    process iterated vertices
domain transition graph reached progress possible 
implementation follows dijkstras algorithm  fig       implemented priority queue vector buckets maximal speed use cache avoid generating
costv  d  d    value twice state  addition this  use global cache shared
throughout whole planning process need compute values cost v  d  d    variables v ancestors pruned causal graph once   note cost v  d  d    depends
current values ancestors v  
apart technical considerations  fig     gives accurate account
fast downwards implementation causal graph heuristic  details  including
complexity considerations worked out example  refer original description
algorithm  helmert        
      tates

nfinite

h euristic value

noted fast downward uses incomplete planning algorithm determining solutions
local planning problems  therefore  states cost v  s v   s   v     even though
goal condition v   s   v  still reached  means cannot trust infinite values
returned causal graph heuristic  experience  states infinite heuristic evaluation
still possible reach goal rare  indeed treat states dead ends 
   

fih elmert

algorithm compute costs   s  v  d  
let v   set immediate predecessors v pruned causal graph  
let dtg pruned domain transition graph v 
costv  d  d      
costv  d  d       d  dv    d 
local state    restricted v  
unreached    dv
unreached contains value d  dv cost v  d  d       
choose value d  unreached minimizing cost v  d  d    
unreached    unreached    d   
transition dtg leading   d   unreached 
transition cost      v derived variable    v fluent
pair v     e  condition t 
e    local state d   v    
call compute costs   s  v     e  
transition cost    transition cost   cost v   e  e   
costv  d  d      transition cost   cost v  d  d     
costv  d  d        costv  d  d      transition cost
local state d      local state d 
pair v     e  condition t 
local state d    v        e 
figure     fast downwards implementation causal graph heuristic  compute costs algorithm computing estimates cost v  d  d    values d  dv state
mpt  

   

fit fast ownward p lanning ystem

turns states search frontier dead ends  cannot make progress
causal graph heuristic  case  use sound dead end detection routine verify
heuristic assessment  turns frontier states indeed dead ends  report
problem unsolvable  otherwise  search restarted heuristic  cf  section      
sound purposes dead end detection   
dead end detection routine originally developed strips like tasks  however 
extending full mpts easy  fact  changes core algorithm required  works
level domain transition graphs still sound applied tasks conditional
effects axioms  since central aspect fast downward  discuss here 
referring earlier work instead  helmert        
      h elpful ransitions
inspired hoffmanns successful use helpful actions within planner  hoffmann  
nebel         extended algorithm computing causal graph heuristic
addition heuristic estimate  generates set applicable operators considered useful
steering search towards goal 
compute helpful actions ff  hoffmanns algorithm generates plan relaxed planning task defined current search state considers operators helpful belong
relaxed plan applicable current state 
approach follows similar idea  computing heuristic estimate cost v  s v   s   v  
variable v goal condition defined  look domain transition graph
v trace path transitions leading s v     v  gave rise cost estimate 
particular  consider first transition path  starting s v   transition corresponds
applicable operator  consider operator helpful transition continue check
next goal  transition correspond applicable operator associated
conditions form v     e  currently satisfied  recursively look helpful transitions domain transition graph variable v     checking path
generated computation cost v   s v      e    
recursive process continues found helpful transitions  unlike case
ff  helpful actions found non goal states  might find helpful
transition all  may case transition correspond applicable operator
even though associated conditions  happen operator preconditions
represented pruned domain transition graph due cycles causal graph  even so 
found helpful transitions useful tool guiding best first search algorithms 
    heuristic
heuristic named hoffmanns planning algorithm name  context
originally introduced  hoffmann   nebel         based notion
relaxed planning tasks ignore negative interactions  context mpts  ignoring negative
interactions means assume state variable hold several values simultaneously 
operator effect axiom sets variable v value original task corresponds
   practice  never observed causal graph heuristic fail solvable task  therefore  fallback
mechanism used unsolvable tasks iconic  f ull adl domain recognized
dead end detection technique 

   

fih elmert

effect axiom adds value range values assumed v relaxed task 
condition v   original task corresponds condition requiring element
set values currently assumed v relaxed task 
easy see applying operator solvable relaxed planning task never render
unsolvable  lead operators applicable goals true 
significant effect all  reason  relaxed planning tasks solved efficiently  even
though optimal solutions still np hard compute  bylander         plan relaxation
planning task called relaxed plan task 
heuristic estimates goal distance world state generating relaxed plan
task reaching goal world state  number operators generated plan
used heuristic estimate  implementation heuristic necessarily
generate same  even equally long  relaxed plan ff  experiments  turn
problematic  implementations appear equally informative 
heuristic originally introduced adl domains  extending tasks involving derived predicates straight forward  one possible extension simply assume
derived predicate initially set default value treat axioms relaxed operators cost
   slightly complicated  accurate approach  derived variables initialized
actual value given world state  allowing relaxed planner achieve value
 or values  applying transitions extended domain transition graph derived
variable  followed second approach 
addition heuristic estimates  heuristic exploited restricting biasing
choice operators apply given world state s  set helpful actions consists
operators relaxed plan computed applicable state  mentioned
introduction section  fast downward configured treat helpful actions
preferred operators 
wealth work heuristic literature  discuss further 
thorough treatment  point references  hoffmann   nebel        hoffmann 
                  
    greedy best first search fast downward
fast downward uses greedy best first search closed list default search algorithm 
assume reader familiar algorithm refer literature details  russell  
norvig        
implementation greedy best first search differs textbook algorithm two ways 
first  treat helpful transitions computed causal graph heuristic helpful actions computed heuristic preferred operators  second  performs deferred heuristic evaluation
reduce influence large branching factors  turn describing two search
enhancements 
      p referred perators
make use helpful transitions computed causal graph heuristic helpful actions computed heuristic  variant greedy best first search supports use so called preferred operators  set preferred operators given state subset set applicable
operators state  operators considered preferred depends settings
   

fit fast ownward p lanning ystem

search component  discussed earlier  intuition behind preferred operators randomly
picked successor state likely closer goal generated preferred operator  case call preferred successor  preferred successors considered
non preferred ones average 
search algorithm implements preference maintaining two separate open lists  one
containing successors expanded states one containing preferred successors exclusively 
search algorithm alternates expanding regular successor preferred successor 
even iterations consider one open list  odd iterations other  matter
open list state taken from  successors placed first open list  preferred
successors additionally placed second open list   of course could limit first open
list contain non preferred successors  however  typically total number successors
vast number preferred successors tiny  therefore  cheaper add successors
first open list detect duplicates upon expansion scan list successors
determining element whether preferred  
since number preferred successors smaller total number successors 
means preferred successors typically expanded much earlier others  especially
important domains heuristic guidance weak lot time spent exploring plateaus 
faced plateaus  fast downwards open lists operate first in first out fashion   in
words  constant heuristic function  search algorithm behaves breadth first
search   preferred operators typically offer much better chances escaping plateaus since
lead significantly lower effective branching factors 
      eferred h euristic e valuation
upon expanding state s  textbook version greedy best first search computes heuristic
evaluation successor states sorts open list accordingly 
wasteful many successors heuristic evaluations costly  two conditions often
true heuristic search approaches planning 
second modification comes play  successor better heuristic
estimate generated early leads promising path towards goal  would
avoid generating successors  let us assume      successors     
  th successor generated  better heuristic estimate s  furthermore  let us
assume goal reached   path non increasing heuristic estimates 
would avoid computing heuristic values     later successors altogether 
deferred heuristic evaluation achieves computing heuristic estimates successors expanded state immediately  instead  successors placed open list
together heuristic estimate state s  heuristic estimates computed
expanded  time used sorting successors open
list  on  general  state sorted open list according heuristic evaluation
parent  initial state exception  fact  need put successor
state open list  since require representation want evaluate
heuristic estimate  instead  save memory storing reference parent state
operator transforming parent state successor state open list 
might clear approach lead significant savings time  since deferred
evaluation means information available later  potential savings become
   

fih elmert

apparent considering deferred heuristic evaluation together use preferred operators 
improving successor s  state reached preferred operator  likely
expanded  via second open list  long successors even siblings
s  situation described above  exists non increasing path   goal 
heuristic evaluations never computed successors s  fact  deferred heuristic
evaluation significantly improve search performance even preferred operators
used  especially tasks branching factors large heuristic estimate informative 
first glance  deferred heuristic evaluation might appear related another technique reducing effort expanding node within best first search algorithm  namely partial
expansion  yoshizumi  miura    ishida         however  algorithm designed reducing
space requirements best first search expense additional heuristic evaluations 
expanding node  partial expansion computes heuristic value successors 
stores open queue whose heuristic values fall certain relevance threshold 
later iterations  might turn threshold chosen low  case node
needs re expanded heuristic values successors re evaluated  general 
partial expansion never compute fewer heuristic estimates standard   usually
require less memory 
however  heuristic search approaches planning  and certainly fast downward   heuristic evaluations usually costly time memory storing open closed lists
limiting factor  thus willing trade memory time opposite way  deferred
heuristic evaluation normally leads node expansions higher space requirements
standard best first search heuristic values used guiding search less informative  they evaluate predecessor search node rather node itself   however  heuristic
computations required nodes actually removed open queue rather
nodes fringe  latter usually significantly numerous 
    multi heuristic best first search
alternative greedy best first search  fast downward supports extended algorithm called
multi heuristic best first search  algorithm differs greedy best first search use
multiple heuristic estimators  based observation different heuristic estimators different weaknesses  may case given heuristic sufficient directing search
towards goal except one part plan  gets stuck plateau  another heuristic
might similar characteristics  get stuck another part search space 
various ways combining heuristics proposed literature  typically adding
together taking maximum individual heuristic estimates  believe often
beneficial combine different heuristic estimates single numerical value  instead 
propose maintaining separate open list heuristic estimator  sorted according
respective heuristic  search algorithm alternates expanding state
open list  whenever state expanded  estimates calculated according heuristic 
successors put open list 
fast downward configured use multi heuristic best first search  computes estimates causal graph heuristic heuristic  maintaining two open lists  course 
approach combined use preferred operators  case  search algorithm
maintains four open lists  heuristic distinguishes normal preferred successors 
   

fit fast ownward p lanning ystem

algorithm reach one goal   v  d  cond  
               max threshold  
let set operators whose modification distance respect v
 
assign cost c operator modification distance c
respect v 
call uniform cost search algorithm closed list  using operator set  
find state satisfying  v   d  cond 
return plan uniform cost search succeeded 
figure     reach one goal procedure reaching state v   d  value max threshold
equal maximal modification distance operator respect v 

    focused iterative broadening search
focused iterative broadening search algorithm experimental piece fast downwards search arsenal  present form  algorithm unsuitable many planning domains 
especially containing comparatively different goals  yet think might contain
nucleus successful approach domain independent planning different
current methods  include completeness source inspiration 
algorithm intended first step towards developing search techniques emphasize
idea using heuristic criteria locally  limiting set operators apply  rather globally 
choosing states expand global set open states  made first experiments
direction observing large boost performance obtained using preferred
operators heuristic search  algorithm performed surprisingly well standard
benchmark domains  performing badly others 
name suggests  algorithm focuses search concentrating one goal time 
restricting attention operators supposedly important reaching goal 
definition   modification distances
let mpt  let operator   let v variable  
modification distance respect v defined minimum  variables
v   occur affected variables effect list o  distance v   v cg   
example  operators modify v directly modification distance   respect
v  operators modify variables occur preconditions operators modifying v
modification distance    on  assume order change value variable 
operators low modification distance respect variable useful 
fig     shows reach one goal procedure achieving single goal mpt  time
being  assume cond parameter always   procedure makes use assumption
high modification distance implies low usefulness two ways  first  operators high
modification distance respect goal variable considered higher associated
cost  hence applied less frequently  second  operators whose modification distance beyond
certain threshold forbidden completely  instead choosing threshold priori  algorithm
   

fih elmert

first tries find solution lowest possible threshold    increasing threshold  
whenever previous search failed  uniform cost search algorithm mentioned fig    
standard textbook method  russell   norvig        
although ignorant fact time algorithm conceived  core idea
reach one goal new  ginsberg harvey        present search technique called iterative
broadening  based idea repeatedly sequence uninformed searches
ever growing set operators  work demonstrates superiority iterative broadening standard depth bounded search empirically analytically reasonable
assumption choices made branching point equally important    original iterative broadening algorithm applies scenarios without knowledge problem domain 
chooses set operators may applied every search node randomly  rather
using heuristic information causal graph case  however  ginsberg harvey
already discuss potential incorporation heuristics operator selection  introduction operator costs  in form modification distances  new  fairly straightforward
extension heuristic information available 
focused iterative broadening search algorithm based reach one goal method 
idea achieve goals planning task one other  using reach one goal
algorithm core subroutine satisfying individual goals  since obvious good
order achieving goals would be  one invocation reach one goal started goal
parallel  one goal solver focuses  supposedly  relevant operators reaching
particular goal  hope number states considered goal reached small 
one one goal solvers reaches goal  resulting plan reported sub searches
stopped  overall search algorithm commits part plan  situation
first goal reached considered new initial state 
situation  try satisfy second goal  starting parallel invocations
reach one goal possible second goal  course  lead situation
search algorithm oscillates goals  first achieving goal a  abandoning favour goal
b  without sign making real progress  therefore  demand reach one goal achieves
second goal addition one reached first  setting cond argument accordingly 
two goals reached  sub searches stopped  sub searches third
goal started  on  goals reached 
sense  focusing technique similar beam search algorithm  lowerre        
performs fixed number concurrent searches avoid committing particular path
search space early  beam search uses heuristic function evaluate branches
search abandoned new branches spawned  focused iterativebroadening search appear use heuristic evaluations first glance  number satisfied
goals state used evaluation criterion essentially way  one important difference beam search use modification distances relative particular goal  means
different beams explore state space qualitatively different ways 
one final twist  motivate reach one goal needlessly wander away satisfied goals  forbid applying operators undo previously achieved goals cond 
old idea called goal protection  joslin   roach         well known protecting
   see original analysis precise definition equally important  ginsberg   harvey         ginsberg
harveys assumption certainly valid practice  find much convincing competing model
goal states uniformly distributed across search fringe 

   

fit fast ownward p lanning ystem

algorithm reach one goal   v  d  cond  
               max threshold  
let set operators whose modification distance respect v
affect state variable occurring cond 
assign cost c operator modification distance c
respect v 
call uniform cost search algorithm closed list  using operator set  
find state satisfying  v   d  cond 
return plan uniform cost search succeeded 
               max threshold  
let set operators whose modification distance respect v
 
assign cost c operator modification distance c
respect v 
call uniform cost search algorithm closed list  using operator set  
find state satisfying  v   d  cond 
return plan uniform cost search succeeded 
figure     reach one goal procedure reaching state v    corrected  
goals renders search algorithm incomplete  even state spaces operators reversible
local search approaches focused iterative broadening search would otherwise complete 
particular  search must fail planning tasks serializable  korf         therefore 
first solution attempt fails  algorithm restarted without goal protection  complete
procedure shown fig      concludes discussion fast downwards search component 

   experiments
evaluate performance fast downward  specifically differences various
configurations search component  performed number experiments set
benchmarks previous international planning competitions  purpose experiments compare fast downward state art pddl planning  contrast
performance different search algorithms fast downward  greedy best first search
without preferred operators  multi heuristic best first search without preferred operators 
focused iterative broadening search  
clearly state purpose experiments  let us point two areas worthy study
choose investigate here 
compare causal graph heuristic heuristics  hsp
heuristics  comparison would require evaluating different heuristics within otherwise identical planning systems  performed experiment  helmert 
      thus prefer dedicate section evaluation complete fast downward
planning system  rather heuristic function 
   

fih elmert

give final answer question fast downward performs well badly
domains analyse  observe bad performance  try give plausible
explanation this  conduct full blown study heuristic quality spirit
hoffmanns work h  heuristics  hoffmann         believe
much could learned investigation  major undertaking would go
beyond scope article 
aim section evaluate fast downward planner whole 
number algorithmic questions address  example  one might wonder  if
any  speed up obtained using successor generators simpler methods test
operator applicability whenever node expanded  another question concerns extent
deferred heuristic evaluation affects search performance  keep section reasonable
length  discuss either questions here  however  conducted experiments
addressing them  include results electronic appendix paper   
    benchmark set
benchmark set use consists propositional planning tasks fully automated
tracks first four international planning competitions hosted aips       aips       aips
     icaps       set benchmark domains shown fig      altogether  benchmark suite comprises      tasks   the numbers fig     add          atellite
instances introduced ipc  part benchmark set ipc  
count once  
distinguish three classes domains 
strips domains  domains feature derived predicates conditional effects 
conditions appearing goal operators conjunctions positive literals 
adl domains  domains make use conditional effects operator and or contain
general conditions simple conjunctions goals operators  however 
require axioms 
pddl    domains  domains use full range propositional pddl     including
features present adl domains axioms 
ipc   domains presented different formulations  meaning realworld task encoded several different ways  participants asked work one
formulation per domain  able choose preferred formulation given domain freely 
example  irport domain available strips formulation adl formulation 
however  organizers strictly follow rule considering different encodings
real world task different formulations  rather different domains proper  namely 
psr m iddle p romela domains  encodings without axioms available 
considered different domains grounds encodings without axioms
   see http   www jair org   short summary successor generators speed search two
orders magnitude extreme cases largest atellite tasks  little impact performance
time  deferred heuristic evaluation beneficial domains  speed ups one order
magnitude common  somewhat beneficial majority domains  speed ups     
rarely detrimental performance 

   

fit fast ownward p lanning ystem

competition

domain

class

number tasks

ipc   aips      

ssembly
g rid
g ripper
l ogistics
ovie
ystery
mp rime

adl
strips
strips
strips
strips
strips
strips

  
 
  
  
  
  
  

ipc   aips      

b locksworld
f reecell
l ogistics
iconic  strips
iconic  s imple adl
iconic  f ull adl
chedule

strips
strips
strips
strips
adl
adl
adl

  
  
  
   
   
   
   

ipc   aips      

epot
riverlog
f reecell
rovers
atellite
z enotravel

strips
strips
strips
strips
strips
strips

  
  
  
  
  
  

ipc   icaps      

irport
p romela  o pticalt elegraph
p romela  p hilosophers
p ipesworld  n otankage
p ipesworld  tankage
psr s mall
psr m iddle
psr l arge
atellite

strips
pddl   
pddl   
strips
strips
strips
pddl   
pddl   
strips

  
  
  
  
  
  
  
  
  

figure     planning domains first four international planning competitions 

   

fih elmert

much larger hence likely difficult solve  apply formulation vs  encoding view
strictly thus consider one psr m iddle domain one domain two
p romela variants  p romela  p hilosophers p romela  o pticalt elegraph 
ipc  benchmark set  tasks solvable except    ystery instances 
ipc  benchmark set  tasks solvable except    iconic  f ull adl instances 
ipc  benchmarks solvable  ipc   checked instances p ipesworld tankage domain  assume tasks solvable 
run heuristic search modes  fast downward proves unsolvability
unsolvable ystery iconic  f ull adl tasks using dead end detection routine described earlier article causal graph heuristic  helmert         cases
iconic  f ull adl domain exhaustively searching states finite heuristic 
course  unsolvable task proved unsolvable planner  report successfully
solved instance experimental results 
    experimental setup
discussed section    eleven possible configurations fast downwards search
component  however  equally reasonable  example  use ffs helpful
actions  would seem wasteful use heuristic estimate  since two calculated
together  therefore  greedy best first search setup  exclude configurations
helpful actions always computed  multi heuristic best first search setup  exclude
configurations one type preferred operators considered  other  since
would seem arbitrary choice  leaves us six different configurations
planner 
   g  use greedy best first search without preferred operators 
   g   p  use greedy best first search helpful transitions preferred operators 
   g   p    use greedy best first search helpful transitions preferred operators  use
helpful actions preferred operators states helpful transitions 
   m  use multi heuristic best first search without preferred operators 
     p  use multi heuristic best first search helpful transitions helpful actions
preferred operators 
   f  use focused iterative broadening search 
apply planner configurations      benchmark tasks  using
computer       ghz intel xeon cpu machine used ipc  set
memory limit   gb timeout     seconds 
compare fast downward state art  try solve benchmark
best performing planners literature  unfortunately  involves intricacies 
planners publicly available  others cover restricted subset pddl    
main experiment  thus partition benchmark domains three sets depending
planners available comparison 
   

fit fast ownward p lanning ystem

domain

task

configuration

f reecell  ipc  
g rid
mp rime
psr l arge
atellite  ipc  

probfreecell     
prob  
prob  
p   s    n   l  f  
p   hc pfile  

m p


g p
m p

preprocessing
    
     
     
     
      

search
      
      
      
      
      

figure     tasks could solved configuration fast downward search
timeout     seconds  total processing timeout     seconds 
column preprocessing shows total time translation knowledge compilation 

    translation knowledge compilation vs  search
course  results report fast downward include time spent three components
planner  translation  knowledge compilation  search  therefore  following presentation results  consider task solved total processing time     seconds 
however  investigated tasks solved timeout     seconds
search component alone  allowing components use arbitrary amount resources 
turns makes difference five cases  could solved
total time     seconds  fig       one five cases  atellite instance
exorbitant size  search take less time two phases combined  results show
search component time critical part fast downward practice  therefore 
report separate performance results individual components 
    strips domains ipc  
let us present results main experiment  abstain listing runtimes individual planning tasks due prohibitively large amount data  available electronic
appendix article   instead  report following information 
tables showing number tasks solved planner within     second timeout 
here  present individual results domain 
graphs showing number tasks solved given time planner  here 
present separate results domain  would require many graphs 
discuss plan lengths  observations regard similar made
original implementation causal graph heuristic  helmert        
fig     shows number unsolved tasks strips domains ipc   
figs        show number tasks solved planner within given time bound
      seconds  addition six configurations fast downward consideration 
table includes four columns 
heading any  include results hypothetical meta planner guesses
best six configuration fast downward input task executes fast downward
   http   www jair org 

   

fih elmert

domain

 tasks

g

b locksworld
epot
riverlog
f reecell  ipc  
f reecell  ipc  
g rid
g ripper
l ogistics  ipc  
l ogistics  ipc  
iconic  strips
ovie
ystery
mp rime
rovers
atellite  ipc  
z enotravel

  
  
  
  
  
 
  
  
  
   
  
  
  
  
  
  

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 

total

   

  

  

  

g p g p 

m p

f



cg



lpg

 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 

  
  
 
  
  
 
 
  
 
 
 
  
  
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 

 
 
 
  
  
 
 
 
 
 
 
  
 
 
 
 

  

  

   

  

  

  

   

figure     number unsolved tasks strips domains ipc   ipc   ipc  
psfrag replacements
fdd  fast downward 

          

fd  fast downward 
yahsp
macro ff

         

lpg td
cg

lpg

solved tasks

sgplan

         

 fast downward 
g   p  fast downward 
  p  fast downward 
g  fast downward 
g   p   fast downward 
 fast downward 
f  fast downward 

         

 s

  s

   s

   s
search time

   s

   s

   s

figure     number tasks solved vs  runtime strips domains ipc   ipc  ipc  
graph shows results various configurations fast downward 

   

fit fast ownward p lanning ystem

psfrag replacements
fdd  fast downward 

          

fd  fast downward 
yahsp
macro ff

         

lpg td

solved tasks

sgplan

         

g   p   fast downward 
 fast downward 
g   p  fast downward 
cg

lpg

         
g  fast downward 
  p  fast downward 
 fast downward 
f  fast downward 

 s

  s

   s

   s
search time

   s

   s

   s

figure     number tasks solved vs  runtime strips domains ipc   ipc  ipc  
graph shows results cg  lpg hypothetical planner
always chooses best configuration fast downward  result greedy
best first search helpful transitions repeated ease comparison fig     

   

fih elmert

setting  heading cg  report results first implementation
causal graph heuristic  helmert           finally  lpg refer well known planners
 hoffmann   nebel        gerevini et al         fully automated tracks ipc 
ipc   chosen comparison benchmark set showed best
performance far publicly available planners experimented with  lpg  uses
randomized search strategy  attempted solve task five times report median result 
results show excellent performance fast downward set benchmarks  compared cg  already shown solve tasks lpg benchmark set
 helmert         get another slight improvement half planner configurations  one
configurations  multi heuristic best first search using preferred operators  solves benchmarks
domains except epot f reecell  even importantly  number tasks
solved fast downward configurations small     note planning competitions typically allowed planner spend    minutes task  time constraints 
could allocate five minutes six configurations fast downward  getting results
least good reported planner  results might even better
cleverer allocation scheme 
even configuration using focused iterative broadening search performs comparatively well
benchmarks  although cannot compete planners  surprisingly 
version planner difficulties domains many dead ends  f reecell  ystery 
mp rime  goal ordering important  b locksworld  epot   fares comparatively badly domains large instances  namely l ogistics  ipc   atellite 
reader keep mind lpg excellent planning systems 
planners experimented with  including awarded prizes first three planning competitions  none solved benchmarks group focused iterative broadening
search 
one domain proves quite resistant fast downwards solution attempts configuration epot  already observed initial experiments causal graph heuristic
 helmert         believe one key problem fast downward  unlike ff 
use goal ordering techniques  important domain  fact domain
includes b locksworld like subproblem problematic  gives rise dense causal
graphs demonstrated section       
    adl domains ipc  
second  present results adl domains first three planning competitions 
much smaller group previous  including four domains  time  cannot consider
cg lpg  since neither cg publicly available version lpg supports adl domains 
therefore  compare exclusively  again  report number unsolved tasks
domain  fig      present graphs showing quickly tasks solved  figs         
results look good first group domains  results iconic
domains good  even improving ff  however  greedy best first search performs
badly ssembly domain  configurations perform badly chedule domain 
   apart missing support adl axioms  cg similar fast downward using greedy best first search
preferred operators  configuration g   translation knowledge compilation components essentially
identical  older search component mainly differs fast downward use deferred heuristic
evaluation 

   

fit fast ownward p lanning ystem

domain

 tasks

ssembly
iconic  s imple adl
iconic  f ull adl
chedule
total

  
   
   
   
   

g
  
 
 
   
   

g p g p 
  
 
 
  
   

  
 
 
  
   

 
 
 
   
   

m p

f





 
 
 
  
  

  
 
  
   
   

 
 
 
  
  

 
 
  
 
  

figure     number unsolved tasks adl domains ipc   ipc  ipc  

psfrag replacements
fdd  fast downward 

          

fd  fast downward 

         

yahsp
macro ff

         

lpg td
cg

lpg

solved tasks

sgplan

         
         

 fast downward 

         
  p  fast downward 
g   p   fast downward 
g   p  fast downward 
 fast downward 
g  fast downward 
f  fast downward 

         
         
 s

  s

   s

   s
search time

   s

   s

   s

figure     number tasks solved vs  runtime adl domains ipc   ipc  ipc  
graph shows results various configurations fast downward 

   

fih elmert

psfrag replacements
fdd  fast downward 

          

fd  fast downward 

         

yahsp
macro ff

         

lpg td
cg

lpg

g   p   fast downward 

solved tasks

sgplan

         
         
         

g   p  fast downward 
g  fast downward 

 fast downward 
f  fast downward 

         


 fast downward 
  p  fast downward 

         
 s

  s

   s

   s
search time

   s

   s

   s

figure     number tasks solved vs  runtime adl domains ipc   ipc  ipc  
graph shows results hypothetical planner always
chooses best configuration fast downward  result multi heuristic bestfirst search preferred operators repeated ease comparison fig     

   

fit fast ownward p lanning ystem

currently  good explanation ssembly behaviour  chedule domain  weak performance seems related missing goal ordering techniques 
many chedule tasks  several goals defined object satisfied
certain order  instance  objects cylindrical  polished painted 
three goals must satisfied precisely order  making object cylindrical reverts effects
polishing painting  polishing reverts effect painting  recognising constraints  heuristic search algorithm assumes close goal object already
polished painted cylindrical  loathe transform object cylindrical shape
would undo already achieved goals  rudimentary manual goal ordering 
ignoring painting goals goals satisfied  number tasks solved
multi heuristic best first search preferred operators drops       three failures
appear due remaining ordering problems regard cylindrical polished objects 
    domains ipc 
third finally  present results ipc  domains  here  compare ff 
benchmarks  perform well best planners competition  besides  several
ipc  competitors extensions hybrids using part bigger system  ffbased planning well represented even limit attention ipc  planners 
comparison  chose four successful competition participants besides fast downward 
namely lpg td  sgplan  macro ff yahsp  cf  results hoffmann   edelkamp        
similar previous two experiments  report number unsolved tasks domain
 fig      present graphs showing quickly tasks solved  figs         
fast downward competitive planners across domains  better others
some  p ipesworld domains ones planners noticeably better two competition versions fast downward  case yahsp
p ipesworld domain variants sgplan p ipesworld  n otankage   p ipesworld
domain hierarchical nature  might domain decomposition approach causal graph heuristic appropriate  results heuristic search
configurations p romela  o pticalt elegraph domain extremely bad require investigation 
interestingly  focused iterative broadening search performs well benchmarks suite  one reasons many tasks ipc  suite 
many individual goals easy serialize solved mostly independently    
comparing configuration g g   p   especially   p  observe using preferred operators useful benchmarks  even two previous
experiments 
final remark  observe implemented meta planner calling six
fast downward configurations round robin fashion  would obtain planning system
could solve    ipc  benchmarks within          minute timeout  almost
par top performer ipc   fast diagonally downward  solved    ipc 
benchmarks timeout  thus  benchmark set exploring different
planner configurations definitely pays off 
    devised experiment shows property artificially violated simple goal reformulation 
performance algorithm degrades quickly  see electronic appendix details 

   

fih elmert

domain

 tasks

irport
p ipesworld  n otankage
p ipesworld  tankage
p romela  o pticalt elegraph
p romela  p hilosophers
psr s mall
psr m iddle
psr l arge
atellite  ipc  
total

  
  
  
  
  
  
  
  
  
   

g
  
  
  
  
 
 
 
  
 
   

g p g p 

m p

f



  
  
  
  
 
 
 
  
 
   

  
 
  
  
 
 
 
  
 
   

 
  
  
  
  
 
  
  
  
   

 
 
  
  
 
 
 
  
 
  

  
  
  
  
 
 
 
  
 
   

  
  
  
  
  
 
 
  
 
   

domain

fd

fdd

lpg td

macro ff

sgplan

yahsp

irport
p ipesworld  n otankage
p ipesworld  tankage
p romela  o pticalt elegraph
p romela  p hilosophers
psr s mall
psr m iddle
psr l arge
atellite  ipc  
total

 
  
  
  
 
 
 
  
 
  

 
 
  
  
 
 
 
  
 
  

 
  
  
  
 
 
 
  
 
   

  
  
  
  
  
  
  
  
 
   

 
 
  
  
 
 
 
  
 
   

  
 
  
  
  
 
  
  
 
   

figure     number unsolved tasks ipc  domains  results various configurations
fast downward listed upper part  results competition participants
lower part  fd fdd denote versions fast downward participated ipc  names fast downward fast diagonally downward
 cf  section    

   

fit fast ownward p lanning ystem

psfrag replacements
fdd  fast downward 

          

fd  fast downward 

         

yahsp

         

macro ff
sgplan

cg

lpg

         
solved tasks

lpg td

 fast downward 

         
         
         
         
  p  fast downward 
g   p   fast downward 
g   p  fast downward 
 fast downward 
f  fast downward 
g  fast downward 

        
        
 s

  s

   s

   s
search time

   s

   s

   s

figure     number tasks solved vs  runtime ipc  domains  graph shows results
various configurations fast downward 
psfrag replacements
          
         
         

cg

lpg

g   p   fast downward 
g   p  fast downward 
g  fast downward 

solved tasks

         
         
         
         
         

 fast downward 
fdd  fast downward 
fd  fast downward 
sgplan
lpg td
yahsp
macro ff

        
        

  p  fast downward 
 fast downward 
f  fast downward 

 s

  s

   s

   s
search time

   s

   s

   s

figure     number tasks solved vs  runtime ipc  domains  graph shows results
hypothetical planner always chooses best configuration fast
downward  competition configurations fast downward best four
participants 

   

fih elmert

    conclusions experiment
interpret experimental results  first conclusion fast downward
clearly competitive state art  especially true configuration using
multi heuristic best first search preferred operators  m p   outperforms competing
planning systems set strips domains ipc   domains ipc  
problems chedule domain  would true remaining
group benchmarks  adl domains ipc   
regard second objective investigation  evaluating relative strengths
different planner configurations  m p configuration emerges clear cut winner    
   domains  configuration solves tasks  unlike configurations 
one domain  p romela  o pticalt elegraph  performs badly  conclude
multi heuristic best first search use preferred operators promising extensions
heuristic planners 
particularly true preferred operators  indeed  m p configuration  two
variants greedy best first search preferred operators show next best overall performance 
terms number domains among top performers terms
total number tasks solved  comparing g g p  ten domains variant
using preferred operators solves tasks one using them  opposite true five
domains  comparing m p  difference even striking  preferred operator
variant outperforming fifteen domains  worse two  in
solves one task less   convincing arguments use preferred operators 

   summary discussion
turn discussion  let us briefly summarize contributions article  motivating starting point  explained planning tasks often exhibit simpler structure expressed
multi valued state variables  rather traditional propositional representations 
introduced fast downward  planning system based idea converting tasks multivalued formalism exploiting causal information underlying encodings 
fast downward processes pddl planning tasks three stages  skipped first
stages  translation  automatically transforms pddl task equivalent multi valued
planning task nicer causal structure  explained inner workings second stage 
knowledge compilation  demonstrating depth kind knowledge planner extracts
problem representation  discussing causal graphs  domain transition graphs  successor generators axiom evaluators  discussion fast downwards search component 
introduced heuristic search algorithms  use technique deferred heuristic evaluation
reduce number states heuristic goal distance estimate must computed 
addition greedy best first search  fast downward employs multi heuristic best first search
algorithm usefully integrate information two heuristic estimators  namely causal graph
heuristic heuristic  heuristic search algorithms utilize preference information
operators  introduced fast downwards experimental focused iterative broadening
search algorithm  based idea pruning set operators consider
successor states likely lead towards specific goal 
thus tried give complete account fast downward planning systems approach
solving multi valued planning tasks  including motivation  architecture  algorithmic founda   

fit fast ownward p lanning ystem

tions  previous section  demonstrated empirical behaviour  showing good performance
across whole range propositional benchmarks previous planning competitions 
among novel algorithms search enhancements discussed article  two
aspects fast downward consider central importance would
emphasize  one use multi valued state variables pddl style planning 
believe multi valued representations much structured hence much amenable
automated reasoning purposes heuristic evaluation  problem decomposition 
aspects planning goal ordering extraction landmarks  central
idea use hierarchical decompositions within heuristic planning framework  hierarchical
approaches domain independent planning considerable potential  since work
knoblock        bacchus yang         little work published  fast downward  hope renew interest area  believe promising ground
advances automated planning 
future  several aspects fast downward would investigate
further  first  intend experiment search techniques along lines focused
iterative broadening search  emphasize heuristically evaluating operator usefulness rather
heuristically evaluating states 
second  would come efficient heuristic multi valued planning tasks
require pruning cycles causal graph  initial experiments direction
shown difficult achieve goal without losing performance fast downwards
heuristic estimator  perhaps better heuristic accuracy outweigh worse per state performance
many cases 
third  want investigate far performance planner could improved
encoding domains differently  cases  merging set state variables
closely interrelated single state variable whose domain product domains
original state variables might beneficial  also  want test hand tailored encodings lead
better performance automatically derived ones  so  large performance gap is 
fourth finally  would evaluate behaviour causal graph heuristic
specific planning domains empirically theoretically  following hoffmanns work
heuristic  hoffmann                     hopefully  give indication
expect good performance causal graph heuristic advisable look
approaches 

acknowledgements
author wishes thank silvia richter  member fast downward team
 th international planning competition  part implementing planner valuable
advice before  throughout  competition  deserves thanks helping
experiments  proof reading article  suggesting number improvements 
anonymous reviewers article handling editor  maria fox  made number
useful suggestions led significant improvements 
work partly supported german research council  dfg  within graduate
programme mathematical logic applications part transregional collaborative
research centre automatic verification analysis complex systems  sfb tr    avacs  
see www avacs org information 
   

fih elmert

references
bacchus  f     yang  q          downward refinement efficiency hierarchical problem
solving  artificial intelligence               
backstrom  c     nebel  b          complexity results sas   planning  computational intelligence                
bonet  b     geffner  h          planning heuristic search  artificial intelligence              
brafman  r  i     domshlak  c          structure complexity planning unary operators 
journal artificial intelligence research             
bylander  t          computational complexity propositional strips planning  artificial
intelligence                 
domshlak  c     brafman  r  i          structure complexity planning unary operators 
ghallab  m   hertzberg  j     traverso  p   eds    proceedings sixth international
conference artificial intelligence planning scheduling  aips        pp        aaai
press 
domshlak  c     dinitz  y          multi agent off line coordination  structure complexity 
cesta  a     borrajo  d   eds    pre proceedings sixth european conference
planning  ecp     pp          toledo  spain 
dowling  w  f     gallier  j  h          linear time algorithms testing satisfiability
propositional horn formulae  journal logic programming               
edelkamp  s     helmert  m          exhibiting knowledge planning problems minimize
state encoding length  fox  m     biundo  s   eds    recent advances ai planning 
 th european conference planning  ecp     vol       lecture notes artificial
intelligence  pp          new york  springer verlag 
edelkamp  s     hoffmann  j          pddl     language classical part  th
international planning competition  tech  rep       albert ludwigs universitat freiburg 
institut fur informatik 
fox  m     long  d          pddl     extension pddl expressing temporal planning
domains  journal artificial intelligence research            
garey  m  r     johnson  d  s          computers intractability guide theory
np completeness  freeman 
gerevini  a   saetti  a     serina  i          planning stochastic local search temporal
action graphs lpg  journal artificial intelligence research             
ginsberg  m  l     harvey  w  d          iterative broadening  artificial intelligence             
helmert  m          planning heuristic based causal graph analysis  zilberstein  s   koehler 
j     koenig  s   eds    proceedings fourteenth international conference automated
planning scheduling  icaps        pp          aaai press 
hoffmann  j          local search topology planning benchmarks  empirical analysis 
nebel  b   ed    proceedings   th international joint conference artificial intelligence  ijcai     pp          morgan kaufmann 
   

fit fast ownward p lanning ystem

hoffmann  j          local search topology planning benchmarks  theoretical analysis 
ghallab  m   hertzberg  j     traverso  p   eds    proceedings sixth international conference artificial intelligence planning scheduling  aips        pp         aaai
press 
hoffmann  j          ignoring delete lists works  local search topology planning benchmarks  journal artificial intelligence research             
hoffmann  j     edelkamp  s          deterministic part ipc    overview  journal
artificial intelligence research             
hoffmann  j     nebel  b          planning system  fast plan generation heuristic
search  journal artificial intelligence research             
jonsson  p     backstrom  c          incremental planning  ghallab  m     milani  a   eds   
new directions ai planning  ewsp     rd european workshop planning  vol    
frontiers artificial intelligence applications  pp        amsterdam  ios press 
jonsson  p     backstrom  c       a   state variable planning structural restrictions  algorithms complexity  artificial intelligence                  
jonsson  p     backstrom  c       b   tractable plan existence imply tractable plan generation  annals mathematics artificial intelligence                
joslin  d     roach  j          theoretical analysis conjunctive goal problems  artificial
intelligence                research note 
knoblock  c  a          automatically generating abstractions planning  artificial intelligence 
              
korf  r  e          planning search  quantitative approach  artificial intelligence        
     
lowerre  b  t          harpy speech recognition system  ph d  thesis  computer science
department  carnegie mellon university  pittsburgh  pennsylvania 
newell  a     simon  h  a          gps  program simulates human thought  feigenbaum 
e  a     feldman  j   eds    computers thought  pp          oldenbourg 
russell  s     norvig  p          artificial intelligence modern approach  prentice hall 
sacerdoti  e  d          planning hierarchy abstraction spaces  artificial intelligence    
       
tenenberg  j  d          abstraction planning  allen  j  f   kautz  h  a   pelavin  r  n  
  tenenberg  j  d   reasoning plans  chap     pp          morgan kaufmann  san
mateo 
van den briel  m   vossen  t     kambhampati  s          reviving integer programming approaches ai planning  branch and cut framework  biundo  s   myers  k     rajan 
k   eds    proceedings fifteenth international conference automated planning
scheduling  icaps        pp          aaai press 
williams  b  c     nayak  p  p          reactive planner model based executive  pollack 
m  e   ed    proceedings   th international joint conference artificial intelligence
 ijcai     pp            morgan kaufmann 
   

fih elmert

yoshizumi  t   miura  t     ishida  t          partial expansion large branching factor problems  kautz  h     porter  b   eds    proceedings seventeenth national
conference artificial intelligence  aaai        pp          aaai press 

   


