journal of artificial intelligence research                

submitted       published     

planning graph heuristics for belief space search
daniel bryce
subbarao kambhampati 

dan   bryce   asu   edu
rao   asu   edu

department of computer science and engineering
ira a  fulton school of engineering
arizona state university  brickyard suite    
    south mill avenue  tempe  az      

david e  smith

de   smith   email   arc   nasa   gov

nasa ames research center
intelligent systems division  ms      
moffett field  ca           

abstract
some recent works in conditional planning have proposed reachability heuristics to improve
planner scalability  but many lack a formal description of the properties of their distance estimates 
to place previous work in context and extend work on heuristics for conditional planning  we
provide a formal basis for distance estimates between belief states  we give a definition for the
distance between belief states that relies on aggregating underlying state distance measures  we
give several techniques to aggregate state distances and their associated properties  many existing
heuristics exhibit a subset of the properties  but in order to provide a standardized comparison we
present several generalizations of planning graph heuristics that are used in a single planner  we
compliment our belief state distance estimate framework by also investigating efficient planning
graph data structures that incorporate bdds to compute the most effective heuristics 
we developed two planners to serve as test beds for our investigation  the first  caltalt 
is a conformant regression planner that uses a  search  the second  p on d  is a conditional
progression planner that uses ao  search  we show the relative effectiveness of our heuristic
techniques within these planners  we also compare the performance of these planners with several
state of the art approaches in conditional planning 

   introduction
ever since cgp  smith   weld        and sgp  weld  anderson    smith        a series of planners have been developed for tackling conformant and conditional planning problems  including
gpt  bonet   geffner         c plan  castellini  giunchiglia    tacchella         pksplan  petrick   bacchus         frag plan  kurien  nayak    smith         mbp  bertoli  cimatti  roveri 
  traverso      b   kacmbp  bertoli   cimatti         cff  hoffmann   brafman         and
yka  rintanen      b   several of these planners are extensions of heuristic state space planners
that search in the space of belief states  where a belief state is a set of possible states   without
full observability  agents need belief states to capture state uncertainty arising from starting in an
uncertain state or by executing actions with uncertain effects in a known state  we focus on the
first type of uncertainty  where an agent starts in an uncertain state but has deterministic actions 
we seek strong plans  where the agent will reach the goal with certainty despite its partially known
state  many of the aforementioned planners find strong plans  and heuristic search planners are
c
    
ai access foundation  all rights reserved 

fib ryce   k ambhampati     s mith

currently among the best  yet a foundation for what constitutes a good distance based heuristic for
belief space has not been adequately investigated 
belief space heuristics  intuitively  it can be argued that the heuristic merit of a belief state depends
on at least two factorsthe size of the belief state  i e   the uncertainty in the current state   and the
distance of the individual states in the belief state from a destination belief state  the question of
course is how to compute these measures and which are most effective  many approaches estimate
belief state distances in terms of individual state to state distances between states in two belief
states  but either lack effective state to state distances or ways to aggregate the state distances  for
instance the mbp planner  bertoli et al       b  counts the number of states in the current belief
state  this amounts to assuming each state distance has unit cost  and planning for each state can be
done independently  the gpt planner  bonet   geffner        measures the state to state distances
exactly and takes the maximum distance  assuming the states of the belief state positively interact 
heuristic computation substrates  we characterize several approaches to estimating belief state
distance by describing them in terms of underlying state to state distances  the basis of our investigation is in adapting classical planning reachability heuristics to measure state distances and
developing state distance aggregation techniques to measure interaction between plans for states in
a belief state  we take three fundamental approaches to measure the distance between two belief
states  the first approach does not involve aggregating state distance measures  rather we use a
classical planning graph to compute a representative state distance  the second retains distinctions
between individual states in the belief state by using multiple planning graphs  akin to cgp  smith
  weld         to compute many state distance measures which are then aggregated  the third
employs a new planning graph generalization  called the labelled uncertainty graph  lu g   that
blends the first two to measure a single distance between two belief states  with each of these techniques we will discuss the types of heuristics that we can compute with special emphasis on relaxed
plans  we present several relaxed plan heuristics that differ in terms of how they employ state distance aggregation to make stronger assumptions about how states in a belief state can co achieve
the goal through action sequences that are independent  positively interact  or negatively interact 
our motivation for the first of the three planning graph techniques for measuring belief state
distances is to try a minimal extension to classical planning heuristics to see if they will work for us 
noticing that our use of classical planning heuristics ignores distinctions between states in a belief
state and may provide uninformed heuristics  we move to the second approach where we possibly
build exponentially many planning graphs to get a better heuristic  with the multiple planning
graphs we extract a heuristic from each graph and aggregate them to get the belief state distance
measure  if we assume the states of a belief state are independent  we can aggregate the measures
with a summation  or  if we assume they positively interact we can use a maximization  however 
as we will show  relaxed plans give us a unique opportunity to measure both positive interaction and
independence among the states by essentially taking the union of several relaxed plans  moreover 
mutexes play a role in measuring negative interactions between states  despite the utility of having
robust ways to aggregate state distances  we are still faced with the exponential blow up in the
number of planning graphs needed  thus  our third approach seeks to retain the ability to measure
the interaction of state distances but avoid computing multiple graphs and extracting heuristics
from each  the idea is to condense and symbolically represent multiple planning graphs in a single
planning graph  called a labelled uncertainty graph  lu g   loosely speaking  this single graph
unions the causal support information present in the multiple graphs and pushes the disjunction 
  

fip lanning g raph h euristics for b elief s pace s earch

describing sets of possible worlds  i e   initial literal layers   into labels  the planning graph
vertices are the same as those present in multiple graphs  but redundant representation is avoided 
for instance an action that was present in all of the multiple planning graphs would be present only
once in the lu g and labelled to indicate that it is applicable in a planning graph projection from
each possible world  we will describe how to extract heuristics from the lu g that make implicit
assumptions about state interaction without explicitly aggregating several state distances 
ideally  each of the planning graph techniques considers every state in a belief state to compute
heuristics  but as belief states grow in size this could become uninformed or costly  for example 
the single classical planning graph ignores distinctions between possible states where the heuristic
based on multiple graphs leads to the construction of a planning graph for each state  one way to
keep costs down is to base the heuristics on only a subset of the states in our belief state  we evaluate
the effect of such a sampling on the cost of our heuristics  with a single graph we sample a single
state and with multiple graphs and the lu g we sample some percent of the states  we evaluate
state sampling to show when it is appropriate  and find that it is dependent on how we compute
heuristics with the states 
standardized evaluation of heuristics  an issue in evaluating the effectiveness of heuristic techniques is the many architectural differences between planners that use the heuristics  it is quite hard
to pinpoint the global effect of the assumptions underlying their heuristics on performance  for
example  gpt is outperformed by mbpbut it is questionable as to whether the credit for this efficiency is attributable to the differences in heuristics  or differences in search engines  mbp uses a
bdd based search   our interest in this paper is to systematically evaluate a spectrum of approaches
for computing heuristics for belief space planning  thus we have implemented heuristics similar
to gpt and mbp and use them to compare against our new heuristics developed around the notion
of overlap  multiple world positive interaction and independence   we implemented the heuristics
within two planners  the conformant altalt planner  caltalt  and the partially observable nondeterministic planner  p on d   p on d does handle search with non deterministic actions  but
for the bulk of the paper we discuss deterministic actions  this more general action formulation  as
pointed out by smith and weld         can be translated into initial state uncertainty  alternatively 
in section     we discuss a more direct approach to reason with non deterministic actions in the
heuristics 
external evaluation  although our main interest in this paper is to evaluate the relative advantages of a spectrum of belief space planning heuristics in a normalized setting  we also compare
the performance of the best heuristics from this work to current state of the art conformant and
conditional planners  our empirical studies show that planning graph based heuristics provide effective guidance compared to cardinality heuristics as well as the reachability heuristic used by gpt
and cff  and our planners are competitive with bdd based planners such as mbp and yka  and
graphplan based ones such as cgp and sgp  we also notice that our planners gain scalability with
our heuristics and retain reasonable quality solutions  unlike several of the planners we compare
against 
the rest of this paper is organized as follows  we first present the caltalt and p on d planners
by describing their state and action representations as well as their search algorithms  to understand
search guidance in the planners  we then discuss appropriate properties of heuristic measures for
belief space planning  we follow with a description of the three planning graph substrates used to
compute heuristics  we carry out an empirical evaluation in the next three sections  by describing
  

fib ryce   k ambhampati     s mith

our test setup  presenting a standardized internal comparison  and finally comparing with several
other state of the art planners  we end with related research  discussion  prospects for future work 
and various concluding remarks 

   belief space planners
our planning formulation uses regression search to find strong conformant plans and progression
search to find strong conformant and conditional plans  a strong plan guarantees that after a finite
number of actions executed from any of the many possible initial states  all resulting states are goal
states  conformant plans are a special case where the plan has no conditional plan branches  as in
classical planning  conditional plans are a more general case where plans are structured as a graph
because they include conditional actions  i e  the actions have causative and observational effects  
in this presentation  we restrict conditional plans to dags  but there is no conceptual reason why
they cannot be general graphs  our plan quality metric is the maximum plan path length 
we formulate search in the space of belief states  a technique described by bonet and geffner
        the planning problem p is defined as the tuple d  bsi   bsg   where d is a domain
description  bsi is the initial belief state  and bsg is the goal belief state  consisting of all states
satisfying the goal   the domain d is a tuple f  a  where f is a set of fluents and a is a set of
actions 
logical formula representation  we make extensive use of logical formulas over f to represent
belief states  actions  and lu g labels  so we first explain a few conventions  we refer to every
fluent in f as either a positive literal or a negative literal  either of which is denoted by l  when
discussing the literal l  the opposite polarity literal is denoted l  thus if l   at location    then
l   at location    we reserve the symbols  and  to denote logical false and true  respectively 
throughout the paper we define the conjunction of an empty set equivalent to   and the disjunction
of an empty set as  
logical formulas are propositional sentences comprised of literals  disjunction  conjunction  and
negation  we refer to the set of models of a formula f as m f    we consider the disjunctive normal
    and the conjunctive normal form of f    f    the dnf is seen as
form of a logical formula f    f
a disjunction of constituents s each of which is a conjunction of literals  alternatively the cnf
is seen as a conjunction of clauses c each of which is a disjunction of literals   we find it useful
to think of dnf and cnf represented as sets  a disjunctive set of constituents or a conjunctive set
of clauses  we also refer to the complete representation  f   of a formula f as a dnf where every
constituent  or in this case state s  is a model of f  
belief state representation  a world state  s  is represented as a complete interpretation over
fluents  we also refer to states as possible worlds  a belief state bs is a set of states and is symbolically represented as a propositional formula over f   a state s is in the set of states represented by
a belief state bs if s  m bs   or equivalently s    bs 
for pedagogical purposes  we use the bomb and toilet with clogging and sensing problem 
btcs  as a running example for this paper   btcs is a problem that includes two packages  one of
   are readily related  specifically each constituent contains k of the  f   literals 
   it is easy to see that m f   and  f
corresponding to   f  k models 
   we are aware of the negative publicity associated with the b t problems and we do in fact handle more interesting
problems with difficult reachability and uncertainty  e g  logistics and rovers   but to simplify our discussion we
choose this small problem 

  

fip lanning g raph h euristics for b elief s pace s earch

which contains a bomb  and there is also a toilet in which we can dunk packages to defuse potential
bombs  the goal is to disarm the bomb and the only allowable actions are dunking a package in
the toilet  dunkp   dunkp    flushing the toilet after it becomes clogged from dunking  flush   and
using a metal detector to sense if a package contains the bomb  detectmetal   the fluents encoding
the problem denote that the bomb is armed  arm  or not  the bomb is in a package  inp   inp   or
not  and that the toilet is clogged  clog  or not  we also consider a conformant variation on btcs 
called btc  where there is no detectmetal action 
the belief state representation of the btcs initial condition  in clausal representation is 
 bsi     arm clog   inp   inp     inp  inp   
and in constituent representation is 

 bs
i      arm  clog  inp  inp     arm  clog inp   inp   
the goal of btcs has the clausal and constituent representation 

 bsg      bs
g     arm 
however  the goal has the complete representation 
 bsg      arm  clog  inp  inp     arm  clog inp   inp   
 arm clog  inp  inp     arm clog inp   inp   
 arm  clog inp  inp     arm  clog  inp   inp   
 arm clog inp  inp     arm clog  inp   inp   
the last four states  disjuncts  in the complete representation are unreachable  but consistent with
the goal description 
action representation  we represent actions as having both causative and observational effects 
all actions a are described by a tuple e  a    a    a  where e  a  is an execution precondition 
 a  is a set of causative effects  and  a  is a set of observations  the execution precondition 
e  a   is a conjunction of literals that must hold for the action to be executable  if an action is executable  we apply the set of causative effects to find successor states and then apply the observations
to partition the successor states into observational classes 
each causative effect j  a    a  is a conditional effect of the form j  a    j  a   where
the antecedent j  a  and consequent j  a  are both a conjunction of literals  we handle disjunction
in e  a  or a j  a  by replicating the respective action or effect with different conditions  so with out
loss of generality we assume conjunctive preconditions  however  we cannot split disjunction in the
effects  disjunction in an effect amounts to representing a set of non deterministic outcomes  hence
we do not allow disjunction in effects thereby restricting to deterministic effects  by convention
   a  is an unconditional effect  which is equivalent to a conditional effect where    a     
the only way to obtain observations is to execute an action with observations  each observation
formula oj  a    a  is a possible sensor reading  for example  an action a that observes the
truth values of two fluents p and q defines  a     p  q  p  q  p  q  p  q   this differs
slightly from the conventional description of observations in the conditional planning literature 
some works  e g   rintanen      b  describe an observation as a list of observable formulas  then
define possible sensor readings as all boolean combinations of the formulas  we directly define the
possible sensor readings  as illustrated by our example  we note that our convention is helpful in
problems where some boolean combinations of observable formulas will never be sensor readings 
the causative and sensory actions for the example btcs problem are 
  

fib ryce   k ambhampati     s mith

dunkp   e   clog          clog      inp    arm         
dunkp   e   clog          clog      inp    arm         
flush  e             clog          and
detectmetal  e              o    inp   o    inp   
    regression
we perform regression in the caltalt planner to find conformant plans by starting with the goal
belief state and regressing it non deterministically over all relevant actions  an action  without
observations  is relevant for regressing a belief state if  i  its unconditional effect is consistent with
every state in the belief state and  ii  at least one effect consequent contains a literal that is present in
a constituent of the belief state  the first part of relevance requires that every state in the successor
belief state is actually reachable from the predecessor belief state and the second ensures that the
action helps support the successor 
following pednault         regressing a belief state bs over an action a  with conditional
effects  involves finding the execution  causation  and preservation formulas  we define regression
in terms of clausal representation  but it can be generalized for arbitrary formulas  the regression
of a belief state is a conjunction of the regression of clauses in  bs   formally  the result bs  of
regressing the belief state bs over the action a is defined as  




bs    regress bs  a     a   




  a  l   ip  a  l  

c bs  lc

execution formula   a   is the execution precondition e  a   this is what must hold in bs  for
a to have been applicable 
causation formula   a  l   for a literal l w r t all effects i  a  of an action a is defined as the
weakest formula that must hold in the state before a such that l holds in bs  the intuitive meaning
is that l already held in bs    or the antecedent i  a  must have held in bs  to make l hold in bs 
formally  a  l  is defined as 

i  a 
 a  l    l 
i li  a 

preservation formula  ip  a  l   of a literal l w r t  all effects i  a  of action a is defined as the
formula that must be true before a such that l is not violated by any effect i  a   the intuitive
meaning is that the antecedent of every effect that is inconsistent with l could not have held in bs   
formally ip  a  l  is defined as 
ip  a  l   



i  a 

i li  a 

regression has also been formalized in the mbp planner  cimatti   roveri        as a symbolic
pre image computation of bdds  bryant         while our formulation is syntactically different 
both approaches compute the same result 
   note that bs  may not be in clausal form after regression  especially when an action has multiple conditional effects  

  

fip lanning g raph h euristics for b elief s pace s earch

bsg
flush

bs 
flush

bs 
flush

bs 

dunkp 

bs 

dunkp 

bs 
dunkp 

bs 

dunkp 

bs 
dunkp 

bs 

dunkp 

bs 

figure    illustration of the regression search path for a conformant plan in the bt c problem 
    caltalt
the caltalt planner uses the regression operator to generate children in an a  search  regression
terminates when search node expansion generates a belief state bs which is logically entailed by
the initial belief state bsi   the plan is the sequence of actions regressed from bsg to obtain the
belief state entailed by bsi  
for example  in the btc problem  figure    we have 
bs   regress bsg   dunkp     clog   arm  inp   
the first clause is the execution formula and the second clause is the causation formula for the
conditional effect of dunkp  and arm 
regressing bs  with flush gives 
bs    regress bs    flush     arm  inp   
for bs    the execution precondition of flush is   the causation formula is   clog     and
 arm  inp   comes by persistence of the causation formula 
finally  regressing bs  with dunkp  gives 
bs    regress bs    dunkp     clog   arm  inp   inp   
we terminate at bs  because bsi    bs    the plan is dunkp   flush  dunkp  
    progression
in progression we can handle both causative effects and observations  so in general  progressing the
action a over the belief state bs generates the set of successor belief states b  the set of belief
states b is empty when the action is not applicable to bs  bs 
   e  a   
progression of a belief state bs over an action a is best understood as the union of the result of
applying a to each model of bs but we in fact implement it as bdd images  as in the mbp planner
  

fib ryce   k ambhampati     s mith

 bertoli et al       b   since we compute progression in two steps  first finding a causative successor  and second partitioning the successor into observational classes  we explain the steps separately 
the causative successor bs  is found by progressing the belief state bs over the causative effects
of the action a  if the action is applicable  the causative successor is the disjunction of causative
progression  progressc   for each state in bs over a 



  bs 
   e  a 



bs   progressc  bs  a   
 sm bs  progressc  s  a    otherwise
the progression of an action a over a state s is the conjunction of every literal that persists  no
applicable effect consequent contains the negation of the literal  and every literal that is given as an
effect  an applicable effect consequent contains the literal  


s    progressc  s  a   

l ls and
j s  j  a  and
lj  a 



l
l j

s  j  a 
lj  a 

l
and

applying the observations of an action results in the set of successors b  the set is found  in
progresss   by individually taking the conjunction of each sensor reading oj  a  with the causative
successor bs    applying the observations  a  to a belief state bs  results in a set b of belief
states  defined as 

  bs   
 


 bs  
   a    
b   progresss  bs   a   



j

 bs  bs   o  a   bs     otherwise
the full progression is computed as 
b   progress bs  a    progresss  progressc  bs  a   a  
    p on d
we use top down ao  search  nilsson         in the p on d planner to generate conformant and
conditional plans  in the search graph  the nodes are belief states and the hyper edges are actions 
we need ao  because applying an action with observations to a belief state divides the belief state
into observational classes  we use hyper edges for actions because actions with observations have
several possible successor belief states  all of which must be included in a solution 
the ao  search consists of two repeated steps  expand the current partial solution  and then
revise the current partial solution  search ends when every leaf node of the current solution is a
belief state that satisfies the goal and no better solution exists  given our heuristic function   expansion involves following the current solution to an unexpanded leaf node and generating its children 
revision is a dynamic programming update at each node in the current solution that selects a best
hyper edge  action   the update assigns the action with minimum cost to start the best solution
rooted at the given node  the cost of a node is the cost of its best action plus the average cost of its
children  the nodes connected through the best action   when expanding a leaf node  the children
of all applied actions are given a heuristic value to indicate their estimated cost 
  

fip lanning g raph h euristics for b elief s pace s earch

the main differences between our formulation of ao  and that of nilsson        are that we
do not allow cycles in the search graph  we update the costs of nodes with an average rather than a
summation  and use a weighted estimate of future cost  the first difference is to ensure that plans
are strong  there are a finite number of steps to the goal   the second is to guide search toward plans
with lower average path cost  and the third is to bias our search to trust the heuristic function  we
define our plan quality metric  maximum plan path length  differently than the metric our search
minimizes for two reasons  first  it is easier to compare to other competing planners because they
measure the same plan quality metric  second  search tends to be more efficient using the average
instead of the maximum cost of an actions children  by using average instead of maximum  the
measured cost of a plan is lower  this means that we are likely to search a shallower search graph
to prove a solution is not the best solution 
conformant planning  using actions without observations  is a special case for ao  search 
which is similar to a  search  the hyper edges that represent actions are singletons  leading to a
single successor belief state  consider the btc problem  btcs without the detectmetal action 
with the future cost  heuristic value  set to zero for every search node  we show the search graph in
figure   for this conformant example as well as a conditional example  described shortly  we can
expand the initial belief state by progressing it over all applicable actions  we get 
b     bs       progress bsi   dunkp  
    inp  inp   clog arm    inp   inp   clog  arm  
and
b     bs       progress bsi   dunkp  
    inp  inp   clog  arm    inp   inp   clog arm   
since clog already holds in every state of the initial belief state  applying flush to bsi leads to
bsi creating a cycle  hence  a hyper edge for flush is not added to the search graph for bsi   we
assign a cost of zero to bs   and bs     update the internal nodes of our best solution  and add
dunkp  to the best solution rooted at bsi  whose cost is now one  
we expand the leaf nodes of our best solution  a single node bs     with all applicable actions 
the only applicable action is flush  so we get 
b     bs       progress bs     flush 
    inp  inp  clog arm    inp   inp  clog  arm   
we assign a cost of zero to bs   and update our best solution  we choose flush as the best action
for bs    whose cost is now one   and choose dunkp  as the best action for bsi  whose cost is
now one   dunkp  is chosen for bsi because its successor bs   has a cost of zero  as opposed to
bs   which now has a cost of one 
expanding the leaf node bs   with the only applicable action  flush  we get 
b     bs       progress bs     flush 
    inp   inp  clog arm    inp  inp  clog  arm   
we update bs    to have cost zero  and bs    to have a cost of one   and choose flush as the best
action for bs     the root node bsi has two children  each with cost one  so we arbitrarily choose
dunkp  as the best action 
we expand bs   with the relevant actions to get bsg with the dunkp  action  dunkp  creates
a cycle back to bs   so it is not added to the search graph  we now have a solution where all leaf
nodes are terminal  while it is only required that a terminal belief state contains a subset of the
  

fib ryce   k ambhampati     s mith

bsi
dunkp 

detect
metal

dunkp 

 inp 

inp 

b 

b 

bs  

b 

bs  

bs  

flush

flush

b 

b 

bs  

dunkp 

dunkp 
dunkp 

dunkp 

b 

bs  
dunkp 

bs  

b 

bs  

bs  

dunkp 

bsg

figure    illustration of progression search for a conformant plan  bold dashed edges  and a conditional plan  bold solid edges  in the btcs problem 

states in bsg   in this case the terminal belief state contains exactly the states in bsg   the cost of
the solution is three because  through revision  bs   has a cost of one  which sets bs   to a cost
of two  however  this means now that bsi has cost of three if its best action is dunkp   instead 
revision sets the best action for bsi to dunkp  because its cost is currently two 
we then expand bs   with dunkp  to find that its successor is bsg   dunkp  creates a cycle
back to bs   so it is not added to the search graph  we now have our second valid solution because
it contains no unexpanded leaf nodes  revision sets the cost of bs   to one  bs   to two  and
bsi to three  since all solutions starting at bsi have equal cost  meaning there are now cheaper
solutions   we can terminate with the plan dunkp   flush  dunkp   shown in bold with dashed lines
in figure   
as an example of search for a conditional plan in p on d  consider the btcs example whose
search graph is also shown in figure    expanding the initial belief state  we get 
b     bs       progress bsi   dunkp   
b     bs       progress bsi   dunkp   
and
b     bs     bs       progress bsi  detectmetal 
   inp  inp  clog  arm  inp   inp  clog  arm  
each of the leaf nodes is assigned a cost of zero  and dunkp  is chosen arbitrarily for the best
solution rooted at bsi because the cost of each solution is identical  the cost of including each
hyper edge is the average cost of its children plus its cost  so the cost of using detectmetal is        
         thus  our root bsi has a cost of one 
  

fip lanning g raph h euristics for b elief s pace s earch

as in the conformant problem we expand bs     giving its child a cost of zero and bs   a cost
of one  this changes our best solution at bsi to use dunkp   and we expand bs     giving its child
a cost of zero and it a cost of one  then we choose detectmetal to start the best solution at bsi
because it gives bsi a cost of one  where using either dunk action would give bsi a cost of two 
we expand the first child of detectmetal  bs     with dunkp  to get 
 inp  inp   clog arm  
which is a goal state  and dunkp  to get 
b     bs       progress bs    dunkp      inp  inp  clog  arm  
we then expand the second child  bs     with dunkp  to get 
 inp   inp   clog arm  
which is also a goal state and dunkp  to get 
b     bs       progress bs    dunkp      inp   inp  clog  arm  
while none of these new belief states are not equivalent to bsg   two of them entail bsg   so we
can treat them as terminal by connecting the hyper edges for these actions to bsg   we choose
dunkp  and dunkp  as best actions for bs   and bs   respectively and set the cost of each node
to one  this in turn sets the cost of using detectmetal for bsi to                  we terminate
here because this plan has cost equal to the other possible plans starting at bsi and all leaf nodes
satisfy the goal  the plan is shown in bold with solid lines in figure   

   belief state distance
in both the caltalt and p on d planners we need to guide search node expansion with heuristics
that estimate the plan distance dist bs  bs    between two belief states bs and bs    by convention  we assume bs precedes bs   i e   in progression bs is a search node and bs  is the goal
belief state  or in regression bs is the initial belief state and bs  is a search node   for simplicity 
we limit our discussion to progression planning  since a strong plan  executed in bs  ensures that
every state s  m bs  will transition to some state s   m bs     we define the plan distance
between bs and bs  as the number of actions needed to transition every state s  m bs  to a
state s   m bs     naturally  in a strong plan  the actions used to transition a state s   m bs 
may affect how we transition another state s   m bs   there is usually some degree of positive
or negative interaction between s  and s  that can be ignored or captured in estimating plan distance   in the following we explore how to perform such estimates by using several intuitions from
classical planning state distance heuristics 
we start with an example search scenario in figure    there are three belief states bs   containing states s   and s      bs   containing state s      and bs   containing states s   and s     
the goal belief state is bs    and the two progression search nodes are bs  and bs    we want to
expand the search node with the smallest distance to bs  by estimating dist bs    bs     denoted
by the bold  dashed line  and dist bs    bs     denoted by the bold  solid line  we will assume for
now that we have estimates of state distance measures dist s  s     denoted by the light dashed and
solid lines with numbers  the state distances can be represented as numbers or action sequences  in
our example  we will use the following action sequences for illustration 
   interaction between states captures the notion that actions performed to transition one state to the goal may interfere
 negatively interact  or aid with  positively interact  transitioning other states to goals states 

  

fib ryce   k ambhampati     s mith

bs 
s  

bs 

  
 

s  

s  

 
 

bs 

s  

 

s  

  

figure    conformant plan distance estimation in belief space
dist s     s         a    a      a      a    a     
dist s     s         a    a      a     
dist s     s         a    a      a    a    a      a    a      a     
in each sequence there may be several actions in each step  for instance  dist s     s     has a  and
a  in its first step  and there are a total of eight actions in the sequence  meaning the distance is
eight  notice that our example includes several state distance estimates  which can be found with
classical planning techniques  there are many ways that we can use similar ideas to estimate belief
state distance once we have addressed the issue of belief states containing several states 
selecting states for distance estimation  there exists a considerable body of literature on estimating the plan distance between states in classical planning  bonet   geffner        nguyen 
kambhampati    nigenda        hoffmann   nebel         and we would like to apply it to estimate the plan distance between two belief states  say bs  and bs    we identify four possible
options for using state distance estimates to compute the distance between belief states bs  and
bs   
 sample a state pair  we can sample a single state from bs  and a single state from bs   
whose plan distance is used for the belief state distance  for example  we might sample s  
from bs  and s   from bs    then define dist bs    bs      dist s     s     
 aggregate states  we can form aggregate states for bs  and bs  and measure their plan
distance  an aggregate state is the union of the literals needed to express a belief state formula 
  

fip lanning g raph h euristics for b elief s pace s earch

which we define as 
s bs   

ff

l

l ls s bs 

since it is possible to express a belief state formula with every literal  e g   using  q  q   p
to express the belief state where p is true   we assume a reasonably succinct representation 
such as a robdd  bryant         it is quite possible the aggregate states are inconsistent  but many classical planning techniques  such as planning graphs  do not require consistent states  for example  with aggregate states we would compute the belief state distance
dist bs    bs      dist s bs     s bs     
 choose a subset of states  we can choose a set of states  e g   by random sampling  from
bs  and a set of states from bs    and then compute state distances for all pairs of states
from the sets  upon computing all state distances  we can aggregate the state distances  as we
will describe shortly   for example  we might sample both s   and s   from bs  and s  
from bs    compute dist s     s     and dist s     s      and then aggregate the state distances
to define dist bs    bs    
 use all states  we can use all states in bs  and bs    and  similar to sampling a subset of
states  above   we can compute all distances for state pairs and aggregate the distances 
the former two options for computing belief state distance are reasonably straightforward  given
the existing work in classical planning  in the latter two options we compute multiple state distances 
with multiple state distances there are two details which require consideration in order to obtain a
belief state distance measure  in the following we treat belief states as if they contain all states
because they can be appropriately replaced with the subset of chosen states 
the first issue is that some of the state distances may not be needed  since each state in bs 
needs to reach a state in bs    we should consider the distance for each state in bs  to a state in
bs    however  we dont necessarily need the distance for every state in bs  to every state in
bs    we will explore assumptions about which state distances need to be computed in section     
the second issue  which arises after computing the state distances  is that we need to aggregate
the state distances into a belief state distance  we notice that the popular state distance estimates
used in classical planning typically measure aggregate costs of state features  literals   since we
are planning in belief space  we wish to estimate belief state distance with the aggregate cost of
belief state features  states   in section      we will examine several choices for aggregating state
distances and discuss how each captures different types of state interaction  in section      we
conclude with a summary of the choices we make in order to compute belief state distances 
    state distance assumptions
when we choose to compute multiple state distances between two belief states bs and bs   
whether by considering all states or sampling subsets  not all of the state distances are important 
for a given state in bs we do not need to know the distance to every state in bs  because each
state in bs need only transition to one state in bs    there are two assumptions that we can make
about the states reached in bs  which help us define two different belief state distance measures in
terms of aggregate state distances 
  

fib ryce   k ambhampati     s mith

 we can optimistically assume that each of the earlier states s  m bs  can reach the closest
of the later states s   m bs     with this assumption we compute distance as 
dist bs  bs      ffsm bs 

min

s  m bs   

dist s  s    

 we can assume that all of the earlier states s  m bs  reach the same later state s  
m bs     where the aggregate distance is minimum  with this assumption we compute distance as 
dist bs  bs     

min

s  m bs   

ffsm bs  dist s  s    

where ff represents an aggregation technique  several of which we will discuss shortly  
throughout the rest of the paper we use the first definition for belief state distance because it is
relatively robust and easy to compute  its only drawback is that it treats the earlier states in a more
independent fashion  but is flexible in allowing earlier states to transition to different later states 
the second definition measures more dependencies of the earlier states  but restricts them to reach
the same later state  while the second may sometimes be more accurate  it is misinformed in cases
where all earlier states cannot reach the same later state  i e   the measure would be infinite   we do
not pursue the second method because it may return distance measures that are infinite when they
are in fact finite 
as we will see in section    when we discuss computing these measures with planning graphs 
we can implicitly find for each state in bs the closest state in bs    so that we do not enumerate the
states s  in the minimization term of the first belief state distance  above   part of the reason we can
   rather than actual states 

do this is that we compute distance in terms of constituents s    bs
also  because we only consider constituents of bs    when we discuss sampling belief states to include in distance computation we only sample from bs  we can also avoid the explicit aggregation
ff by using the lu g  but describe several choices for ff to understand implicit assumptions made
by the heuristics computed on the lu g 
    state distance aggregation
the aggregation function ff plays an important role in how we measure the distance between belief
states  when we compute more than one state distance measure  either exhaustively or by sampling
a subset  as previously mentioned   we must combine the measures by some means  denoted ff 
there is a range of options for taking the state distances and aggregating them into a belief state
distance  we discuss several assumptions associated with potential measures 
 positive interaction of states  positive interaction assumes that the most difficult state in bs
requires actions that will help transition all other states in bs to some state in bs    in our
example  this means that we assume the actions used to transition s   to s   will help us
transition s   to s    assuming each state in bs  transitions to the closest state in bs    
inspecting the action sequences  we see they positively interact because both need actions a 
and a    we do not need to know the action sequences to assume positive interaction because
we define the aggregation ff as a maximization of numerical state distances 
dist bs  bs     

max

min

sm bs  s  m bs   

dist s  s    
  

fip lanning g raph h euristics for b elief s pace s earch

the belief state distances are dist bs    bs      max min         min            and
dist bs    bs      max min              in this case we prefer bs  to bs    if each
state distance is admissible and we do not sample from belief states  then assuming positive
interaction is also admissible 
 independence of states  independence assumes that each state in bs requires actions that are
different from all other states in bs in order to reach a state in bs    previously  we found
there was positive interaction in the action sequences to transition s   to s   and s   to s  
because they shared actions a  and a    there is also some independence in these sequences
because the first contains a    a    and a    where the second contains a    again  we do not need
to know the action sequences to assume independence because we define the aggregation ff
as a summation of numerical state distances 
fi
min dist s  s    
dist bs  bs     


sm bs  s m bs  

in our example  dist bs    bs      min          min            and dist bs    bs     
min             in this case we have no preference over bs  and bs   
we notice that using the cardinality of a belief state  m bs   to measure dist bs  bs    is
a special case of assuming state independence  where s  s  dist s  s         if we use cardinality to measure distance in our example  then we have dist bs    bs       m bs         
and dist bs    bs       m bs          with cardinality we prefer bs  over bs  because
we have better knowledge in bs   
 overlap of states  overlap assumes that there is both positive interaction and independence
between the actions used by states in bs to reach a state in bs    the intuition is that some
actions can often be used for multiple states in bs simultaneously and we should count these
actions only once  for example  when we computed dist bs    bs    by assuming positive
interaction  we noticed that the action sequences for dist s     s     and dist s     s     both
used a  and a    when we aggregate these sequences we would like to count a  and a  each
only once because they potentially overlap  however  truly combining the action sequences
for maximal overlap is a plan merging problem  kambhampati  ihrig    srivastava        
which can be as difficult as planning  since our ultimate intent is to compute heuristics 
we take a very simple approach to merging action sequences  we introduce a plan merging
operator  for ff that picks a step at which we align the sequences and then unions the aligned
steps  we use the size of the resulting action sequence to measure belief state distance 
dist bs  bs      sm bs 

min

s  m bs   

dist s  s    

depending on the type of search  we define  differently  we assume that sequences used in
progression search start at the same time and those used in regression end at the same time 
thus  in progression all sequences are aligned at the first step before we union steps  and in
regression all sequences are aligned at the last step before the union 
for example  in progression dist s     s      dist s     s         a    a      a      a    a     
  a    a      a         a    a    a      a    a      a    a     because we align the sequences at their
first steps  then union each step  notice that this resulting sequence has seven actions  giving
  

fib ryce   k ambhampati     s mith

dist bs    bs         whereas defining ff as maximum gave a distance of five and as summation gave a distance of eight  compared with overlap  positive interaction tends to under
estimate distance  and independence tends to over estimate distance  as we will see during our empirical evaluation  in section       accounting for overlap provides more accurate
distance measures for many conformant planning domains 
 negative interaction of states  negative interaction between states can appear in our example
if transitioning state s   to state s   makes it more difficult  or even impossible  to transition
state s   to state s     this could happen if performing action a  for s   conflicts with action
a  for s     we can say that bs  cannot reach bs  if all possible action sequences that start
in s   and s     respectively  and end in any s  m bs    negatively interact 
there are two ways negative interactions play a role in belief state distances  negative interactions can allow us to prove it is impossible for a belief state bs to reach a belief state
bs    meaning dist bs  bs        or they can potentially increase the distance by a finite
amount  we use only the first  more extreme  notion of negative interaction by computing
cross world mutexes  smith   weld        to prune belief states from the search  if we
cannot prune a belief state  then we use one of the aforementioned techniques to aggregate
state distances  as such  we do not provide a concrete definition for ff to measure negative
interaction 
while we do not explore ways to adjust the distance measure for negative interactions  we
mention some possibilities  like work in classical planning  nguyen et al          we can
penalize the distance measure dist bs    bs    to reflect additional cost associated with serializing conflicting actions  additionally in conditional planning  conflicting actions can be
conditioned on observations so that they do not execute in the same plan branch  a distance
measure that uses observations would reflect the added cost of obtaining observations  as
well as the change in cost associated with introducing plan branches  e g   measuring average
branch cost  
the above techniques for belief state distance estimation in terms of state distances provide the
basis for our use of multiple planning graphs  we will show in the empirical evaluation that these
measures affect planner performance very differently across standard conformant and conditional
planning domains  while it can be quite costly to compute several state distance measures  understanding how to aggregate state distances sets the foundation for techniques we develop in the
lu g  as we have already mentioned  the lu g conveniently allows us to implicitly aggregate state
distances to directly measure belief state distance 
    summary of methods for distance estimation
since we explore several methods for computing belief state distances on planning graphs  we provide a summary of the choices we must consider  listed in table    each column is headed with a
choice  containing possible options below  the order of the columns reflects the order in which we
consider the options 
in this section we have covered the first two columns which relate to selecting states from belief
states for distance computation  as well as aggregating multiple state distances into a belief state
distance  we test options for both of these choices in the empirical evaluation 
  

fip lanning g raph h euristics for b elief s pace s earch

state
selection
single
aggregate
subset
all

state distance
aggregation
  interaction
independence
overlap
  interaction

planning
graph
sg
mg
lu g

mutex
type
none
static
dynamic
induced

mutex
worlds
same
intersect
cross

heuristic
max
sum
level
relaxed plan

table    features for a belief state distance estimation 
in the next section we will also expand upon how to aggregate distance measures as well as
discuss the remaining columns of table    we will present each type of planning graph  the single
planning graph  sg   multiple planning graphs  m g   and the labelled uncertainty graph  lu g  
within each planning graph we will describe several types of mutex  including static  dynamic 
and induced mutexes  additionally  each type of mutex can be computed with respect to different
possible worlds  which means the mutex involves planning graph elements  e g   actions  when
they exist in the same world  i e   mutexes are only computed within the planning graph for a single
state   or across worlds  i e   mutexes are computed between planning graphs for different states 
by two methods  denoted intersect and cross   finally  we can compute many different heuristics
on the planning graphs to measure state distances  max  sum  level  and relaxed plan  we focus
our discussion on the planning graphs  same world mutexes  and relaxed plan heuristics in the next
section  cross world mutexes and the other heuristics are described in appendices 

   heuristics
this section discusses how we can use planning graph heuristics to measure belief state distances 
we cover several types of planning graphs and the extent to which they can be used to compute
various heuristics  we begin with a brief background on planning graphs 
planning graphs  planning graphs serve as the basis for our belief state distance estimation  planning graphs were initially introduced in graphplan  blum   furst        for representing an optimistic  compressed version of the state space progression tree  the compression lies in unioning
the literals from every state at subsequent steps from the initial state  the optimism relates to underestimating the number of steps it takes to support sets of literals  by tracking only a subset of the
infeasible tuples of literals   graphplan searches the compressed progression  or planning graph 
once it achieves the goal literals in a level with no two goal literals marked infeasible  the search
tries to find actions to support the top level goal literals  then find actions to support the chosen
actions and so on until reaching the first graph level  the basic idea behind using planning graphs
for search heuristics is that we can find the first level of a planning graph where a literal in a state
appears  the index of this level is a lower bound on the number of actions that are needed to achieve
a state with the literal  there are also techniques for estimating the number of actions required to
achieve sets of literals  the planning graphs serve as a way to estimate the reachability of state literals and discriminate between the goodness of different search states  this work generalizes such
literal estimations to belief space search by considering both graphplan and cgp style planning
graphs plus a new generalization of planning graphs  called the lu g 
planners such as cgp  smith   weld        and sgp  weld et al         adapt the graphplan
idea of compressing the search space with a planning graph by using multiple planning graphs  one
  

fib ryce   k ambhampati     s mith

overlap

n distances

hmg
rpu

hlug
rp

state distance aggregation

cff

independence

positive
interaction

none

h card
mbp
kacmbp
yka

hmg
s rp

gpt

hmg
m rp

h 
ng

 

hsg
rp
u
hsg
rp
sg

mg

lug

planning graph type

figure    taxonomy of heuristics with respect to planning graph type and state distance aggregation  blank entries indicate that the combination is meaningless or not possible 

for each possible world in the initial belief state  cgp and sgp search on these planning graphs 
similar to graphplan  to find conformant and conditional plans  the work in this paper seeks to
apply the idea of extracting search heuristics from planning graphs  previously used in state space
search  nguyen et al         hoffmann   nebel        bonet   geffner        to belief space
search 
planning graphs for belief space  this section proceeds by describing four classes of heuristics
to estimate belief state distance n g  sg  m g  and lu g  n g heuristics are techniques existing in
the literature that are not based on planning graphs  sg heuristics are techniques based on a single
classical planning graph  m g heuristics are techniques based on multiple planning graphs  similar
to those used in cgp  and lu g heuristics use a new labelled planning graph  the lu g combines
the advantages of sg and m g to reduce the representation size and maintain informedness  note
that we do not include observations in any of the planning graph structures as sgp  weld et al  
      would  however we do include this feature for future work  the conditional planning formulation directly uses the planning graph heuristics by ignoring observations  and our results show that
this still gives good performance 
in figure   we present a taxonomy of distance measures for belief space  the taxonomy also
includes related planners  whose distance measures will be characterized in this section  all of the
related planners are listed in the n g group  despite the fact that some actually use planning graphs 
because they do not clearly fall into one of our planning graph categories  the figure shows how
  

fip lanning g raph h euristics for b elief s pace s earch

different substrates  horizontal axis  can be used to compute belief state distance by aggregating
state to state distances under various assumptions  vertical axis   some of the combinations are
not considered because they do not make sense or are impossible  the reasons for these omissions
will be discussed in subsequent sections  while there are a wealth of different heuristics one can
compute using planning graphs  we concentrate on relaxed plans because they have proven to be the
most effective in classical planning and in our previous studies  bryce   kambhampati         we
provide additional descriptions of other heuristics like max  sum  and level in appendix a 
example  to illustrate the computation of each heuristic  we use an example derived from btc
called courteous btc  cbtc  where a courteous package dunker has to disarm the bomb and
leave the toilet unclogged  but some discourteous person has left the toilet clogged  the initial
belief state of cbtc in clausal representation is 
 bsi     arm  clog   inp   inp     inp  inp   
and the goal is 
 bsg     clog arm 
the optimal action sequences to reach bsg from bsi are 
flush  dunkp   flush  dunkp   flush 
and
flush  dunkp   flush  dunkp   flush 
thus the optimal heuristic estimate for the distance between bsi and bsg   in regression  is
h  bsg       because in either plan there are five actions 
we use planning graphs for both progression and regression search  in regression search the
heuristic estimates the cost of the current belief state w r t  the initial belief state and in progression
search the heuristic estimates the cost of the goal belief state w r t  the current belief state  thus 
in regression search the planning graph s  are built  projected  once from the possible worlds of
the initial belief state  but in progression search they need to be built at each search node  we
introduce a notation bsi to denote the belief state for which we find a heuristic measure  and bsp
to denote the belief state that is used to construct the initial layer of the planning graph s   in the
following subsections we describe computing heuristics for regression  but they are generalized for
progression by changing bsi and bsp appropriately 
in the previous section we discussed two important issues involved in heuristic computation 
sampling states to include in the computation and using mutexes to capture negative interactions in
the heuristics  we will not directly address these issues in this section  deferring them to discussion
in the respective empirical evaluation sections      and      the heuristics below are computed
once we have decided on a set of states to use  whether by sampling or not  also  as previously
mentioned  we only consider sampling states from the belief state bsp because we can implicitly
find closest states from bsi without sampling  we only explore computing mutexes on the planning
graphs in regression search  we use mutexes to determine the first level of the planning graph where
the goal belief state is reachable  via the level heuristic described in appendix a  and then extract a
relaxed plan starting at that level  if the level heuristic is  because there is no level where a belief
state is reachable  then we can prune the regressed belief state 
we proceed by describing the various substrates used for computing belief space distance estimates  within each we describe the prospects for various types of world aggregation  in addition to
our heuristics  we mention related work in the relevant areas 
  

fib ryce   k ambhampati     s mith

    non planning graph based heuristics  n g 
we group many heuristics and planners into the n g group because they are not using sg  m g 
or lu g planning graphs  just because we mention them in this group does not mean they are not
using planning graphs in some other form 
no aggregation  breadth first search uses a simple heuristic  h  where the heuristic value is set
to zero  we mention this heuristic so that we can gauge the effectiveness of our search substrates
relative to improvements gained through using heuristics 
positive interaction aggregation  the gpt planner  bonet   geffner        measures belief
state distance as the maximum of the minimum state to state distance of states in the source and
destination belief states  assuming optimistic reachability as mentioned in section    gpt measures
state distances exactly  in terms of the minimum number of transitions in the state space  taking
the maximum state to state distance is akin to assuming positive interaction of states in the current
belief state 
independence aggregation  the mbp planner  bertoli et al       b   kacmbp planner  bertoli
  cimatti         yka planner  rintanen      b   and our comparable hcard heuristic measure
belief state distance by assuming every state to state distance is one  and taking the summation of
the state distances  i e  counting the number of states in a belief state   this measure can be useful
in regression because goal belief states are partially specified and contain many states consistent
with a goal formula and many of the states consistent with the goal formula are not reachable from
the initial belief state  throughout regression  many of the unreachable states are removed from
predecessor belief states because they are inconsistent with the preconditions of a regressed action 
thus  belief states can reduce in size during regression and their cardinality may indicate they are
closer to the initial belief state  cardinality is also useful in progression because as belief states
become smaller  the agent has more knowledge and it can be easier to reach a goal state 
in cbtc  hcard  bsg       because bsg has four states consistent with its complete representation 
 bsg      inp  inp clog arm    inp   inp  clog arm  
 inp  inp  clog arm    inp   inp  clog arm  
notice  this may be uninformed for bsg because two of the states in  bsg   are not reachable 
like   inp   inp  clog arm   if there are n packages  then there would be  n  unreachable
states represented by  bsg    counting unreachable states may overestimate the distance estimate
because we do not need to plan for them  in general  in addition to the problem of counting unreachable states  cardinality does not accurately reflect distance measures  for instance  mbp reverts to
breadth first search in classical planning problems because state distance may be large or small but
it still assigns a value of one 
overlap aggregation  rintanen        describes n distances which generalize the belief state
distance measure in gpt to consider the maximum n tuple state distance  the measure involves 
for each n sized tuple of states in a belief state  finding the length of the actual plan to transition the
n tuple to the destination belief state  then the maximum n tuple distance is taken as the distance
measure 
for example  consider a belief state with four states  with an n equal to two  we would define
six belief states  one for each size two subset of the four states  for each of these belief states we
find a real plan  then take the maximum cost over these plans to measure the distance for the original
  

fip lanning g raph h euristics for b elief s pace s earch

l 

a 

e 

l 

a 

e 

l 

inp 

inp 

inp 

inp 

inp 

inp 

inp 

inp 

inp 

inp 

inp 

inp 
dunkp 

  dunkp  
  dunkp  

arm
dunkp 
arm

arm

  dunkp  
  dunkp  

clog

clog

clog
flush

  flush 

clog

arm

flush

  flush 

clog

figure    single planning graph for cbtc  with relaxed plan components in bold  mutexes omitted 

four state belief state  when n is one  we are computing the same measure as gpt  and when n is
equal to the size of the belief state we are directly solving the planning problem  while it is costly
to compute this measure for large values of n  it is very informed as it accounts for overlap and
negative interactions 
the cff planner  hoffmann   brafman        uses a version of a relaxed planning graph to
extract relaxed plans  the relaxed plans measure the cost of supporting a set of goal literals from all
states in a belief state  in addition to the traditional notion of a relaxed planning graph that ignores
mutexes  cff also ignores all but one antecedent literal in conditional effects to keep their relaxed
plan reasoning tractable  the cff relaxed plan does capture overlap but ignores some subgoals and
all mutexes  the way cff ensures the goal is supported in the relaxed problem is to encode the
relaxed planning graph as a satisfiability problem  if the encoding is satisfiable  the chosen number
of action assignments is the distance measure 
    single graph heuristics  sg 
the simplest approach for using planning graphs for belief space planning heuristics is to use a
classical planning graph  to form the initial literal layer from the projected belief state  we could
either sample a single state  denoted sg    or use an aggregate state  denoted sgu    for example 
in cbtc  see figure    assuming regression search with bsp   bsi   the initial level l  of the
planning graph for sg  might be 
  

fib ryce   k ambhampati     s mith

l     arm  clog  inp   inp  
and for sgu it is defined by the aggregate state s bsp   
l     arm  clog  inp   inp   inp   inp   
since these two versions of the single planning graph have identical semantics  aside from the initial
literal layer  we proceed by describing the sgu graph and point out differences with sg  where
they arise 
graph construction is identical to classical planning graphs  including mutex propagation  and
stops when two subsequent literal layers are identical  level off   we use the planning graph formalism used in ipp  koehler  nebel  hoffmann    dimopoulos        to allow for explicit representation of conditional effects  meaning there is a literal layer lk   an action layer ak   and an effect
layer ek in each level k  persistence for a literal l  denoted by lp   is represented as an action where
e  lp        lp     l  a literal is in lk if an effect from the previous effect layer ek  contains the
literal in its consequent  an action is in the action layer ak if every one of its execution precondition
literals is in lk   an effect is in the effect layer ek if its associated action is in the action layer ak and
every one of its antecedent literals is in lk   using conditional effects in the planning graph avoids
factoring an action with conditional effects into a possibly exponential number of non conditional
actions  but adds an extra planning graph layer per level  once our graph is built  we can extract
heuristics 
no aggregation  relaxed plans within a single planning graph are able to measure  under the
most optimistic assumptions  the distance between two belief states  the relaxed plan represents a
distance between a subset of the initial layer literals and the literals in a constituent of our belief
state  in the sgu   the literals from the initial layer that are used for support may not hold in a
single state of the projected belief state  unlike the sg    the classical relaxed plan heuristic hsg
rp
finds a set of  possibly interfering  actions to support the goal constituent  the relaxed plan rp is a
rp
rp
rp
rp
rp
subgraph of the planning graph  of the form  arp
    e    l         ab    eb    lb    each of the
layers contains a subset of the vertices in the corresponding layer of the planning graph 

more formally  we find the relaxed plan to support the constituent s   bs
i   that is reached
sg
earliest in the graph  as found by the hlevel  bsi   heuristic in appendix a   briefly  hsg
level  bsi  
returns the first level b where a constituent of bsi has all its literals in lb and none are marked
pair wise mutex  notice that this is how we incorporate negative interactions into our heuristics 
we start extraction at the level b  by defining lrp
as the literals in the constituent used in the level
b
rp
heuristic  for each literal l  lb   we select a supporting effect  ignoring mutexes  from eb 
rp   we prefer persistence of literals to effects in supporting literals  once a
to form the subset eb 
rp
supporting set of effects is found  we create arp
b  as all actions with an effect in eb    then the
rp
rp are added
needed preconditions for the actions and antecedents for chosen effects in ab  and eb 
to the list of literals to support from lrp
b    the algorithm repeats until we find the needed actions
from a    a relaxed plans value is the summation of the number of actions in each action layer  a
literal persistence  denoted by a subscript p  is treated as an action in the planning graph  but in a
   the single graph relaxed plan
relaxed plan we do not include it in the final computation of   arp
j
heuristic is computed as
hsg
rp  bsi  

 

b 

j  

  

  arp
 
j

fip lanning g raph h euristics for b elief s pace s earch

for the cbtc problem we find a relaxed plan from the sgu   as shown in figure   as the bold
edges and nodes  since arm and clog are non mutex at level two  we can use persistence to
rp we can use persistence for inp   and
support clog and dunkp  to support arm in lrp
    in l 
sg
flush for clog  thus  hrp  bsg       because the relaxed plan is 
   inp p   flush  
arp
 
e rp       inp p       flush   

   inp   clog  
lrp
 
   clogp   dunkp   
arp
 

e rp       clogp       dunkp    
   arm  clog  
lrp
 

the relaxed plan does not use both dunkp  and dunkp  to support arm  as a result arm is
not supported in all worlds  i e  it is not supported when the state where inp  holds is our initial
state   our initial literal layer threw away knowledge of inp  and inp  holding in different worlds 
and the relaxed plan extraction ignored the fact that arm needs to be supported in all worlds  even
with an sg  graph  we see similar behavior because we are reasoning with only a single world  a
single  unmodified classical planning graph cannot capture support from all possible worlds  hence
there is no explicit aggregation over distance measures for states  as a result  we do not mention
aggregating states to measure positive interaction  independence  or overlap 
    multiple graph heuristics  m g 
single graph heuristics are usually uninformed because the projected belief state bsp often corresponds to multiple possible states  the lack of accuracy is because single graphs are not able to
capture propagation of multiple world support information  consider the cbtc problem where the
projected belief state is bsi and we are using a single graph sgu   if dunkp  were the only action
we would say that arm and clog can be reached at a cost of two  but in fact the cost is infinite
 since there is no dunkp  to support arm from all possible worlds   and there is no strong plan 
to account for lack of support in all possible worlds and sharpen the heuristic estimate  a set of
multiple planning graphs  is considered  each    is a single graph  as previously discussed 
these multiple graphs are similar to the graphs used by cgp  smith   weld         but lack the
more general cross world mutexes  mutexes are only computed within each graph  i e  only sameworld mutexes are computed  we construct the initial layer l  of each graph  with a different state
s  m bsp    with multiple graphs  the heuristic value of a belief state is computed in terms of
all the graphs  unlike single graphs  we can compute different world aggregation measures with the
multiple planning graphs 
while we get a more informed heuristic by considering more of the states in m bsp    in
certain cases it can be costly to compute the full set of planning graphs and extract relaxed plans 
we will describe computing the full set of planning graphs  but will later evaluate  in section     
the effect of computing a smaller proportion of these  the single graph sg  is the extreme case of
computing fewer graphs 
to illustrate the use of multiple planning graphs  consider our example cbtc  we build two
graphs  figure    for the projected bsp   they have the respective initial literal layers 
l      arm  clog  inp   inp   and
l      arm  clog  inp   inp   

  

fib ryce   k ambhampati     s mith

l 

inp 

a 

e 

inp 

a 

l 

inp 

e 

inp 

inp 
dunkp 

 

  dunkp  
  dunkp  

arm
clog

  dunkp  

arm
flush

  flush 

dunkp 

clog

flush

 clog
inp 

inp 

inp 

inp 

l 

inp 

arm
arm

  dunkp  
  flush 

clog
 clog
inp 

dunkp 

  dunkp  
  dunkp  

 

inp 

arm
arm
clog

  dunkp  

arm
flush

  flush 

dunkp 

clog

flush

clog

  dunkp  
  flush 

arm
clog
clog

figure    multiple planning graphs for cbtc  with relaxed plan components bolded  mutexes
omitted 

in the graph for the first possible world  arm comes in only through dunkp  at level    in the
graph for the second world  arm comes in only through dunkp  at level    thus  the multiple
graphs show which actions in the different worlds contribute to support the same literal 
a single planning graph is sufficient if we do not aggregate state measures  so in the following we consider how to compute the achievement cost of a belief state with multiple graphs by
aggregating state distances 
positive interaction aggregation  similar to gpt  bonet   geffner         we can use the worstg
case world to represent the cost of the belief state bsi by using the hm
mrp heuristic  the difference
with gpt is that we compute a heuristic on planning graphs  where they compute plans in state
space  with this heuristic we account for the number of actions used in a given world  but assume
positive interaction across all possible worlds 
g
the hm
mrp heuristic is computed by finding a relaxed plan rp on each planning graph    
exactly as done on the single graph with hsg
rp   the difference is that unlike the single graph relaxed
plan sgu   but like sg    the initial levels of the planning graphs are states  so each relaxed plan
will reflect all the support needed in the world corresponding to   formally 


b  

rp
g

  aj   
hm
mrp  bsi     max


j  

where b is the level of  where a constituent of bsg was first reachable 
  

fip lanning g raph h euristics for b elief s pace s earch

notice that we are not computing all state distances between states in bsp and bsi   each
planning graph  corresponds to a state in bsp   and from each  we extract a single relaxed plan 
we do not need to enumerate all states in bsi and find a relaxed plan for each  we instead support a
set of literals from one constituent of bsi   this constituent is estimated to be the minimum distance
state in bsi because it is the first constituent reached in  
g
for cbtc  computing hm
mrp  bsg    figure    finds 
rp    
 
   inp p   flush  
arp
 

e rp        inp p       flush   
 
   inp   clog  
lrp
 
 
   clogp   dunkp   
arp
 

e rp        clogp       dunkp    

 
   arm  clog 
lrp
 

and rp    
 
   inp p   flush  
arp
 

e rp        inp p       flush   

 
   inp   clog  
lrp
 
 
   clogp   dunkp   
arp
 

e rp        clogp       dunkp    

 
   arm  clog  
lrp
 

each relaxed plan contains two actions and taking the maximum of the two relaxed plan values
g
gives hm
mrp  bsg        this aggregation ignores the fact that we must use different dunk actions
each possible world 
g
independence aggregation  we can use the hm
srp heuristic to assume independence among the
worlds in our belief state  we extract relaxed plans exactly as described in the previous heuristic
and simply use a summation rather than maximization of the relaxed plan costs  formally 


  
 b
rp
g

  aj   
hm
srp  bsi    


j  

where b is the level of  where a constituent of bsg was first reachable 
g
mg
for cbtc  if computing hm
srp  bsg    we find the same relaxed plans as in the hmrp  bsg  
heuristic  but sum their values to get           as our heuristic  this aggregation ignores the fact
that we can use the same flush action for both possible worlds 
state overlap aggregation  we notice that in the two previous heuristics we are either taking a
maximization and not accounting for some actions  or taking a summation and possibly accounting
g
for extra actions  we present the hm
rp u heuristic to balance the measure between positive interaction
and independence of worlds  examining the relaxed plans computed by the two previous heuristics
for the cbtc example  we see that the relaxed plans extracted from each graph have some overlap 
 
 
notice  that both arp
and arp
contain a flush action irrespective of which package the bomb is
 
 
 
 
contains dunkp   and arp
contains dunkp 
in  showing some positive interaction  also  arp
 
 
  

fib ryce   k ambhampati     s mith

 showing some independence  if we take the layer wise union of the two relaxed plans  we would
get a unioned relaxed plan 
rpu  
u
   inp p   flush  
arp
 

e rpu       inp p       inp p       flush   
u
lrp
   inp   inp   clog  
 
u
   clogp   dunkp   dunkp   
arp
 

e rpu       clogp       dunkp       dunkp    
u
lrp
   arm  clog  
 

this relaxed plans accounts for the actions that are the same between possible worlds and the
actions that differ  notice that flush appears only once in layer zero and the dunk actions both
appear in layer one 
in order to get the union of relaxed plans  we extract relaxed plans from each     as in the
two previous heuristics  then if we are computing heuristics for regression search  we start at the
last level  and repeat for each level  by taking the union of the sets of actions for each relaxed plan at
each level into another relaxed plan  the relaxed plans are end aligned  hence the unioning of levels
proceeds from the last layer of each relaxed plan to create the last layer of the rpu relaxed plan 
then the second to last layer for each relaxed plan is unioned and so on  in progression search  the
relaxed plans are start aligned to reflect that they all start at the same time  whereas in regression
we assume they all end at the same time  the summation of the number of actions of each action
level in the unioned relaxed plan is used as the heuristic value  formally 
g
hm
rp u  bsi    

b 


u
  arp
 
j

j  

where b is the greatest level b where a constituent of bsg was first reachable 
for cbtc  we just found rpu   so counting the number of actions gives us a heuristic value of
g  bs       
hm
g
rp u
    labelled uncertainty graph heuristics  lu g 
the multiple graph technique has the advantage of heuristics that can aggregate the costs of multiple
worlds  but the disadvantage of computing some redundant information in different graphs  c f 
g
figure    and using every graph to compute heuristics  c f hm
rp u    our next approach addresses
these limitations by condensing the multiple planning graphs to a single planning graph  called a
labelled uncertainty graph  lu g   the idea is to implicitly represent multiple planning graphs by
collapsing the graph connectivity into one planning graph  but use annotations  called labels     to
retain information about multiple worlds  while we could construct the lu g by generating each
of the multiple graphs and taking their union  instead we define a direct construction procedure 
we start in a manner similar to the unioned single planning graph  sgu   by constructing an initial
layer of all literals in our source belief state  the difference with the lu g is that we can prevent
loss of information about multiple worlds by keeping a label for each literal the records which
of the worlds is relevant  as we will discuss  we use a few simple techniques to propagate the
  

fip lanning g raph h euristics for b elief s pace s earch

labels through actions and effects and label subsequent literal layers  label propagation relies on
expressing labels as propositional formulas and using standard propositional logic operations  the
end product is a single planning graph with labels on all graph elements  labels indicate which of
the explicit multiple graphs  if we were to build them  contain each graph element 
we are trading planning graph structure space for label storage space  our choice of bdds to
represent labels helps lower the storage requirements on labels  the worst case complexity of the
lu g is equivalent to the m g representation  the lu gs complexity savings is not realized when
the projected possible worlds and the relevant actions for each are completely disjoint  however  this
does not often appear in practice  the space savings comes in two ways      redundant representation of actions and literals is avoided  and     labels that facilitate non redundant representation
are stored as bdds  a nice feature of the bdd package  brace  rudell    bryant        we use
is that it efficiently represents many individual bdds in a shared bdd that leverages common substructure  hence  in practice the lu g contains the same information as m g with much lower
construction and usage costs 
in this section we present construction of the lu g without mutexes  then describe how to
introduce mutexes  and finally discuss how to extract relaxed plans 
      l abel p ropagation
like the single graph and multiple graphs  the lu g is based on the ip p  koehler et al        
planning graph  we extend the single graph to capture multiple world causal support  as present in
multiple graphs  by adding labels to the elements of the action a  effect e  and literal l layers  we
denote the label of a literal l in level k as k  l   we can build the lu g for any belief state bsp  
and illustrate bsp   bsi for the cbtc example  a label is a formula describing a set of states  in
bsp   from which a graph element is  optimistically  reachable  we say a literal l is reachable from
a set of states  described by bs  after k levels  if bs    k  l   for instance  we can say that arm
is reachable after two levels if l  contains arm and bsi       arm   meaning that the models of
worlds where arm holds after two levels are a superset of the worlds in our current belief state 
the intuitive definition of the lu g is a planning graph skeleton  that represents causal relations 
over which we propagate labels to indicate specific possible world support  we show the skeleton
for cbtc in figure    constructing the graph skeleton largely follows traditional planning graph
semantics  and label propagation relies on a few simple rules  each initial layer literal is labelled 
to indicate the worlds of bsp in which it holds  as the conjunction of the literal with bsp   an
action is labelled  to indicate all worlds where its execution preconditions can be co achieved  as
the conjunction of the labels of its execution preconditions  an effect is labelled  to indicate all
worlds where its antecedent literals and its actions execution preconditions can be co achieved  as
the conjunction of the labels of its antecedent literals and the label of its associated action  finally 
literals are labelled  to indicate all worlds where they are given as an effect  as the disjunction over
all labels of effects in the previous level that affect the literal  in the following we describe label
propagation in more detail and work through the cbtc example 
initial literal layer  the lu g has an initial layer consisting of every literal with a non false   
label  in the initial layer the label    l  of each literal l is identical to lbsp   representing the states
of bsp in which l holds  the labels for the initial layer literals are propagated through actions and
effects to label the next literal layer  as we will describe shortly  we continue propagation until no
label of any literal changes between layers  a condition referred to as level off 
  

fib ryce   k ambhampati     s mith

l 

a 

e 

l 

a 

e 

l 

inp 

inp 

inp 

  inp 

  inp 

  inp 

inp 

inp 

inp 

  inp 

  inp 

dunkp 

  dunkp  
  dunkp  

dunkp 

  inp 
  arm

  dunkp  
  dunkp  

arm

arm

arm

clog

clog

clog

flush

  flush 

  clog

flush

  flush 

  clog

g
figure    the lu g skeleton for cbtc  with no mutexes  the relaxed plan for hlu
rp is shown in
bold 

the lu g for cbtc  shown in figure    without labels   using bsp  bsi has the initial literal
layer 
l     inp   inp   inp   inp   clog  arm 
   inp        inp      arm  clog  inp   inp   
   inp        inp      arm  clog  inp   inp   
   clog       arm    bsp
notice that inp  and inp  have labels indicating the respective initial states in which they hold 
and clog and arm have bsp as their label because they hold in all states in bsp  
action layer  once the previous literal layer lk is computed  we construct and label the action
layer ak   ak contains causative actions from the action set a  plus literal persistence  an action is
included in ak if its label is not false  i e  k  a  
    the label of an action at level k  is equivalent
to the extended label of its execution precondition 
k  a    k  e  a  
above  we introduce the notation for extended labels k  f   of a formula f to denote the worlds
of bsp that can reach f at level k  we say that any propositional formula f is reachable from bs
  

fip lanning g raph h euristics for b elief s pace s earch

after k levels if bsi    k  f    since we only have labels for literals  we substitute the labels of
literals for the literals in a formula to get the extended label of the formula  the extended label of a
propositional formula f at level k  is defined 
k  f  f      k  f    k  f    
k  f  f      k  f    k  f    

k   f  f       k  f  f    
k   f  f       k  f  f    
k      bsp  
k      
k  l    k  l 
the zeroth action layer for cbtc is 
a     flush  inp p   inp p   inp p   inp p   clogp   armp  
   flush    bsp  
   inp p        inp p      arm  clog  inp   inp   
   inp p        inp p      arm  clog  inp   inp   
   clogp        armp     bsp
each literal persistence has a label identical to the label of the corresponding literal from the
previous literal layer  the flush action has bsp as its label because it is always applicable 
effect layer  the effect layer ek depends both on the literal layer lk and action layer ak   ek
contains an effect j  a  if the effect has a non false label  i e  k  j  a   
    because both the
action and an effect must be applicable in the same world  the label of the effect at level k is the
conjunction of the label of the associated action with the extended label of the antecedent
k  j  a     k  a   k  j  a  
the zeroth effect layer for cbtc is 
e        flush      inp p       inp p       inp p   
   inp p       clogp       armp   
      flush     bsp
      inp p            inp p       arm  clog  inp   inp   
      inp p            inp p       arm  clog  inp   inp   
      clogp            armp      bsp
again  like the action layer  the unconditional effect of each literal persistence has a label identical to the corresponding literal in the previous literal layer  the unconditional effect of flush has
a label identical to the label of flush 
literal layer  the literal layer lk depends on the previous effect layer ek    and contains only
literals with non false labels  i e  k  l  
    an effect j  a   ek  contributes to the label of a
literal l when the effect consequent contains the literal l  the label of a literal is the disjunction of
the labels of each effect from the previous effect layer that gives the literal 

k   j  a  
k  l   
j  a  lj  a  
j  a ek 

  

fib ryce   k ambhampati     s mith

the first literal layer for cbtc is 
l     inp   inp   inp   inp   clog  clog  arm 
   inp        inp      arm  clog  inp   inp   
   inp        inp      arm  clog  inp   inp   
   clog       clog       arm    bsp
this literal layer is identical to the initial literal layer  except that clog goes from having a false
label  i e  not existing in the layer  to having the label bsp  
we continue to the level one action layer because l  does not indicate that bsg is reachable
from bsp  arm 
 l     action layer one is defined 
a     dunkp   dunkp   flush  inp p   inp p   inp p   inp p   clogp   armp   clogp  
   dunkp        dunkp        flush    bsp  
   inp p        inp p      arm  clog  inp   inp   
   inp p        inp p      arm  clog  inp   inp   
   clogp        armp        clogp     bsp
this action layer is similar to the level zero action layer  it adds both dunk actions because they
are now executable  we also add the persistence for clog  each dunk action gets a label identical
to its execution precondition label 
the level one effect layer is 
e        dunkp       dunkp       dunkp       dunkp       flush      inp p   
   inp p       inp p       inp p       clogp       armp       clogp   
      dunkp            dunkp            flush     bsp
      dunkp       arm  clog  inp   inp   
      dunkp       arm  clog  inp   inp   
      inp p            inp p       arm  clog  inp   inp   
      inp p            inp p       arm  clog  inp   inp   
      clogp            armp            clogp      bsp
the conditional effects of the dunk actions in cbtc  figure    have labels that indicate the
possible worlds in which they will give arm because their antecedents do not hold in all possible
worlds  for example  the conditional effect    dunkp   has the label found by taking the conjunction of the actions label bsp with the antecedent label    inp   to obtain  arm  clog  inp  
inp   
finally  the level two literal layer 
l     inp   inp   inp   inp   clog  clog  arm  arm 
   inp        inp      arm  clog  inp   inp   
   inp        inp      arm  clog  inp   inp   
   clog       clog       arm       arm    bsp
the labels of the literals for level   of cbtc indicate that arm is reachable from bsp because its label is entailed by bsp   the label of arm is found by taking the disjunction of
the labels of effects that give it  namely   arm  clog  inp   inp   from the conditional
  

fip lanning g raph h euristics for b elief s pace s earch

effect of dunkp  and  arm  clog  inp   inp   from the conditional effect of dunkp  
which reduces to bsp   construction could stop here because bsp entails the label of the goal
k  armclog   k  arm   k  clog    bsp  bsp   bsp   however  level off occurs at
the next level because there is no change in the labels of the literals 
when level off occurs at level three in our example  we can say that for any bs  where bs   
bsp   that a formula f is reachable in k steps if bs    k  f    if no such level k exists  then f is not
reachable from bs  if there is some level k  where f is reachable from bs  then the first such k is
a lower bound on the number of parallel plan steps needed to reach f from bs  this lower bound
is similar to the classical planning max heuristic  nguyen et al          we can provide a more
informed heuristic by extracting a relaxed plan to support f with respect to bs  described shortly 
      s ame  w orld l abelled m utexes
there are several types of mutexes that can be added to the lu g  to start with  we only concentrate
on those that can evolve in a single possible world because same world mutexes are more effective
as well as relatively easy to understand  we extend the mutex propagation that was used in the
multiple graphs so that the mutexes are on one planning graph  the savings of computing mutexes
on the lu g instead of multiple graphs is that we can reduce computation when a mutex exits in
several worlds  in appendix b we describe how to handle cross world mutexes  despite their lack of
effectiveness in the experiments we conducted  cross world mutexes extend the lu g to compute
the same set of mutexes found by cgp  smith   weld        
same world mutexes can be represented with a single label  k  x    x     between two elements
 actions  effect  or literals   the mutex holds between elements x  and x  in all worlds s where
s    k  x    x     if the elements are not mutex in any world  we can assume the label of a mutex
between them is false   we discuss how the labelled mutexes are discovered and propagated for
actions  effect relations  and literals 
by using mutexes  we can refine what it means for a formula f to be reachable from a set of
worlds bsp   we must ensure that for every state in bsp   there exists a state of f that is reachable 
a state s  of f is reachable from a state s of bsp when there are no two literals in s  that are
mutex in world s and bsp    k  s  
in each of the action  effect  and literal layers there are multiple ways for the same pair of
elements to become mutex  e g  interference or competing needs   thus  the mutex label for a pair
is the disjunction of all labelled mutexes found for the pair by some means 
action mutexes  the same world action mutexes at a level k are a set of labelled pairs of actions 
each pair is labelled with a formula that indicates the set of possible worlds where the actions are
mutex  the possible reasons for mutex actions are interference and competing needs 

 interference two actions a  a interfere if     the unconditional effect consequent    a  of
one is inconsistent with the execution precondition e  a   of the other  or     vice versa 
they additionally interfere if     both unconditional effect consequents    a  and    a   are
inconsistent  or     both execution preconditions e  a  and e  a   are inconsistent  the mutex
will exist in all possible world projections k  a  a     bsp   formally  a and a interfere if
  

fib ryce   k ambhampati     s mith

one of the following holds 
       a   e  a    
    e  a      a    
       a      a    
    e  a   e  a    
 competing needs two actions a  a have competing needs in a world when a pair of literals
from their execution preconditions are mutex in the world  the worlds where a and a are
mutex because of competing needs are described by 


k  a   k  a   

k  l  l  

lj  a  l j  a  

in the above formula we find all worlds where a pair of execution preconditions l  e  a   l 
e  a   are mutex and both actions are reachable 
effect mutexes  the effect mutexes are a set of labelled pairs of effects  each pair is labelled with
a formula that indicates the set of possible worlds where the effects are mutex  the possible reasons
for mutex effects are associated action mutexes  interference  competing needs  or induced effects 
 mutex actions two effects i  a    a   j  a     a   are mutex in all worlds where
their associated actions are mutex  k  a  a   
 interference like actions  two effects i  a   j  a   interfere if     the consequent i  a  of
one is inconsistent with the antecedent j  a   of the other  or     vice versa  they additionally interfere if     both effect consequents i  a  and j  a   are inconsistent  or     both
antecedents i  a  and j  a   are inconsistent  the mutex will exist in all possible world projections  so the label of the mutex is k  i  a   j  a      bsp   formally  i  a  and j  a  
interfere if one of the following holds 
    i  a   j  a    
    i  a   j  a    
    i  a   j  a    
    i  a   j  a    
 competing needs like actions  two effects have competing needs in a world when a pair of
literals from their antecedents are mutex in a world  the worlds where i  a  and j  a   have
a competing needs mutex are 
k  i  a    k  j  a    



k  l  l  

li  a  l j  a  

in the above formula we find all worlds where a pair of execution preconditions l  i  a   l 
j  a   are mutex and both actions are reachable 
  

fip lanning g raph h euristics for b elief s pace s earch

lk

lk p 
p

ek

ak

lk a 
a

h a 

lk h a  



lk p  q 
induced mutex in worlds 

lk j a  h a  lk i a  



lk j a   h a  

lk q 
q
lk a 
a

j a 

lk r 
r

lk j a  
i a  induces j a  in 
lk i a  lk j a  

i a  lk i a  

figure    effect i  a  induces effect j  a   j  a  is mutex with h  a    so i  a  is induced mutex
with h  a   

 induced an induced effect j  a  of an effect i  a  is an effect of the same action a that
may execute at the same time  an effect is induced by another in the possible worlds where
they are both reachable  for example  the conditional effect of an action always induces the
unconditional effect of the action 
induced mutexes  involving the inducing effect i  a   come about when an induced effect
j  a  is mutex with another effect h  a    see figure     the induced mutex is between
 a  the effect h  a   that is mutex with the induced effect j  a  and  b  the inducing effect
i  a   the label of the mutex is the conjunction of the label of the mutex k  j  a   h  a   
and the label of the induced effect j  a   for additional discussion of the methodology behind
induced mutexes we refer to smith and weld        

literal mutexes  the literal mutexes are a set of labelled pairs of literals  each pair is labelled with
a formula that indicates the set of possible worlds where the literals are mutex  the only reason for
mutex literals is inconsistent support 
 inconsistent support two literals have inconsistent support in a possible world at level k
when there are no two non mutex effects that support both literals in the world  the label of
the literal mutex at level k is a disjunction of all worlds where they have inconsistent support 
the worlds for an inconsistent support mutex between l and l are 
  

fib ryce   k ambhampati     s mith



s

s i  a  j  a  e

k   
where li  a  l j  a   
s  k   i  a  j  a   

the meaning of the above formula is that the two literals are mutex in all worlds s where all
pairs of effects that support the literals in s are mutex in s 
      lu g h euristics
the heuristics computed on the lu g can capture measures similar to the m g heuristics  but there
exists a new opportunity to make use of labels to improve heuristic computation efficiency  a single
planning graph is sufficient if there is no state aggregation being measured  so we do not mention
such measures for the lu g 
positive interaction aggregation  unlike m g heuristics  we do not compute positive interaction
based relaxed plans on the lu g  the m g approach to measure positive interaction across each
state in a belief state is to compute multiple relaxed plans and take their maximum value  to get the
same measure on the lu g we would still need to extract multiple relaxed plans  the situation we are
trying to avoid by using the lu g  while the graph construction overhead may be lowered by using
the lu g  the heuristic computation could take too long  hence  we do not compute relaxed plans
on the lu g to measure positive interaction alone  but we do compute relaxed plans that measure
overlap  which measures positive interaction  
independence aggregation  like positive interaction aggregation  we need a relaxed plan for every
state in the projected belief state to find the summation of the costs  hence  we do not compute
relaxed plans that assume independence 
g
state overlap aggregation  a relaxed plan extracted from the lu g to get the hlu
rp heuristic
m
g
m
g
resembles the unioned relaxed plan in the hrp u heuristic  recall that the hrp u heuristic extracts
a relaxed plan from each of the multiple planning graphs  one for each possible world  and unions
the set of actions chosen at each level in each of the relaxed plans  the lu g relaxed plan heuristic
is similar in that it counts actions that have positive interaction in multiple worlds only once and
accounts for independent actions that are used in subsets of the possible worlds  the advantage of
g
hlu
rp is that we find these actions with a single pass on one planning graph 
we are trading the cost of computing multiple relaxed plans for the cost of manipulating lu g
labels to determine what lines of causal support are used in what worlds  in the relaxed plan we
want to support the goal with every state in bsp   but in doing so we need to track which states in
bsp use which paths in the planning graph  a subgoal may have several different  and possibly
overlapping  paths from the worlds in bsp  
rp
rp
rp
rp
rp
rp
a lu g relaxed plan is a set of layers   arp
    e    l         ab    eb    lb    where ar
rp
rp
is a set of actions  er is a set of effects  and lr   is a set of clauses  the elements of the layers
are labelled to indicate the worlds of bsp where they are chosen for support  the relaxed plan is
g
extracted from the level b   hlu
level  bsi    i e   the first level where bsi is reachable  also described
in appendix a  
please note that we are extracting the relaxed plan for bsi in terms of clauses  and not literals  which is different than the sg and m g versions of relaxed plans  previously we found the

  

fip lanning g raph h euristics for b elief s pace s earch

constituent of bsi that was first reached on a planning graph and now we do not commit to any
one constituent  our rationale is that we were possibly using different constituents in each of the
multiple graphs  and in this condensed version of the multiple graphs we still want to be able to
support different constituents of the bsi in different worlds  we could also use the constituent representation of bsi in defining the layers of the relaxed plan  but choose the clausal representation
of bsi instead because we know that we have to support each clause  however with constituents
we know we only need to support one  but we dont need to know which one  
the relaxed plan  shown in bold in figure    for bsi to reach bsg in cbtc is listed as follows 
   inp p   inp p   flush  
arp
 
rp
   inp p      arm  clog  inp   inp   
rp
   inp p      arm  clog  inp   inp   
rp
   flush    bsp  
e rp       inp p       inp p       flush   
 
rp
     inp p       arm  clog  inp   inp   
 
rp
     inp p       arm  clog  inp   inp   
rp
      flush     bsp  
   inp   inp   clog  
lrp
 
rp
   inp      arm  clog  inp   inp   
rp
   inp      arm  clog  inp   inp   
rp
   clog    bsp  
   dunkp   dunkp   clogp   
arp
 
rp
   dunkp      arm  clog  inp   inp   
rp
   dunkp      arm  clog  inp   inp   
rp
   clogp     bsp  
e rp       dunkp       dunkp       clogp    
 
rp
     dunkp       arm  clog  inp   inp   
 
rp
     dunkp       arm  clog  inp   inp   
rp
      clogp      bsp  
   arm  clog  
lrp
 
rp
   arm    bsp  
rp
   clog    bsp
we start by forming lrp
with the clauses in  bsg    namely arm and clog  we label the
 
clauses with bsp because they need to be supported by all states in our belief state  next  we
support each clause in lrp
with the relevant effects from e  to form e rp   for clog we use
 
persistence because it supports clog in all worlds described by bsp  this is an example of positive
interaction of worlds   for arm the relevant effects are the respective   from each dunk action 
we choose both effects to support arm because we need to support arm in all worlds of bsp   and
each effect gives support in only one world  this is an example of independence of worlds   we then
with the appropriate label indicating
insert the actions associated with each chosen effect into arp
 
  

fib ryce   k ambhampati     s mith

the worlds where it was needed  which in general is fewer worlds than where it is reachable  i e 
rp with the execution preconditions of
it is always the case that rp
r       r      next we form l 
actions in arp
and antecedents of effects in e rp   which are clog  inp   and inp   labelled with
 
all worlds where an action or effect needed them  in the same fashion as level two  we support the
literals at level one  using persistence for inp  and inp   and flush for clog  we stop here  because
we have supported all clauses at level one 
for the general case  extraction starts at the level b where bsi is first reachable from bsp  
rp
rp
rp contains all clauses
the first relaxed plan layers we construct are arp
b    eb    lb   where lb
rp
c   bsi    labelled as k  c    bsp  
by choosing relevant effects from
for each level r     r  b  we support each clause in lrp
r
rp   an effect j  a  is relevant if it is reachable in some of the worlds where we
er  to form er 
need to support c  i e  r   j  a    rp
r  c  
   and the consequent gives a literal l  c  for
each clause  we have to choose enough supporting effects so that the chosen effect worlds are a
superset of the worlds we need to support the clause  formally 









rp
rp
j

 c 
  

 
 a  
clrp


r
r 
r
 j

  a  lj  a  

lc 
j  a er 

we think of supporting a clause in a set of worlds as a set cover problem where effects cover
subsets of worlds  our algorithm to cover the worlds of a clause with worlds of effects is a variant
of the well known greedy algorithm for set cover  cormen  leiserson    rivest         we first
choose all relevant persistence effects that can cover worlds  then choose action effects that cover
rp and labelled with the new
the most new worlds  each effect we choose for support is added to er 
rp
worlds it covered for c  once all clauses in lr are covered  we form the action layer arp
r  as all
rp   the actions in arp are labelled to indicate all worlds where
actions that have an effect in er 
r 
rp  
any of their effects were labelled in er 
we obtain the next subgoal layer  lrp
r    by adding literals from the execution preconditions of
rp
rp   each literal l  lrp is labelled to indicate all
actions in ar  and antecedents of effects in er 
r 
worlds where any action or effect requires l  we support the literals in lrp
r  in the same fashion
 
we
continue
to
support
literals
with
effects 
insert
actions 
and
insert action and effect
as lrp
r
rp
preconditions until we have supported all literals in l   
g
once we get a relaxed plan  the relaxed plan heuristic  hlu
rp  bsi    is the summation of the
number of actions in each action layer  formally 
g
hlu
rp  bsi  

 

b 


  arp
 
i

i  
g
thus in our cbtc example we have hlu
rp  bsg        notice that if we construct the lu g
without mutexes for cbtc we reach the goal after two layers  if we had included mutexes the
lu g  then it would reach the goal after three layers  the way we use mutexes will not change our
relaxed plan because we do not use mutexes to influence relaxed plan extraction  mutexes only help
to identify when a the belief state bsi is not reachable from bsp  

  

fip lanning g raph h euristics for b elief s pace s earch

problem

pddl parser
 ipc 
actions

belief
states

search engine
 hsp r  caltalt 
lao   pond 

heuristics

bdds
 cudd 

labels

 pond only 

planning
graph s 
 ipp 

figure    the implementations of caltalt and p on d rely on many existing technologies  the
search engine is guided by heuristics extracted from planning graphs 

   empirical evaluation  setup
this section presents our implementation of the caltalt and p on d planners and the domains we
use in the experiments  all tests were run in linux on an x   machine with a     ghz p  processor
and  gb ram with a timeout of    minutes  both caltalt and p on d used a heuristic weight
of five in the  respective  a  and ao  searches  we compare with the competing approaches  cgp 
sgp  gpt v      mbp v      kacmbp  yka  and cff  on several domains and problems  our
planners and all domain and problem files for all of the compared planners can be found in the
online appendix 
    implementation
the implementation of caltalt uses several off the shelf planning software packages  figure  
shows a diagram of the system architecture for caltalt and p on d  while caltalt extends the
name of altalt  it relies on a limited subset of the implementation  the components of caltalt
are the ipc parser for pddl      slightly extended to allow uncertain initial conditions   the hspr search engine  bonet   geffner         the ipp planning graph  koehler et al          and the
cudd bdd package  brace et al         to implement the lu g labels  the custom parts of the
implementation include the action representation  belief state representation  regression operator 
and the heuristic calculation 
the implementation of p on d is very similar to caltalt aside from the search engine  and
state and action representation  p on d also uses the ipp source code for planning graphs  p on d
uses modified lao   hansen   zilberstein        source code from eric hansen to perform ao 
  

fib ryce   k ambhampati     s mith

problem
rovers 
rovers 
rovers 
rovers 
rovers 
rovers 
logistics 
logistics 
logistics 
logistics 
logistics 
bt n 
btc n 
cubecenter n 
ring n 

initial
states
 
 
 
 
  
  
 
 
 
 
 
n
n
n 
n n

goal
literals
 
 
 
 
 
 
 
 
 
 
 
 
 
 
n

fluents
  
  
  
  
  
   
  
  
  
  
  
n  
n  
 n
 n

causative
actions
  
  
  
  
  
   
  
   
   
   
   
n
n  
 
 

observational
actions
      
      
      
      
      
      
      
      
      
      
      
   n 
   n 
 
 

optimal
parallel
     
     
      
      
     
     
     
     
     
     
     
     
 n      
  n     
 n  

optimal
serial
     
     
      
       
      
     
     
       
      
      
      
n  n   
 n    n   
  n     
 n  

table    features of test domains and problems   number of initial states  number of goal literals  number of fluents  number of causative actions  number of observational actions 
optimal number of parallel plan steps  optimal number of serial plan steps  data for conditional versions of domains is in braces  plan lengths for conditional plans are maximum
conditional branch length 

search  and cudd  brace et al         to represent belief states and actions  even with deterministic
actions it is possible to obtain cycles from actions with observations because we are planning in
belief space  p on d constructs the search graph as a directed acyclic graph by employing a cyclechecking algorithm  if adding a hyper edge to the search graph creates a cycle  then the hyper edge
cannot represent an action in a strong plan and is hence not added to the graph 
    domains
table   shows some of the relative features of the different problems we used to evaluate our approach  the table shows the number of initial states  goal literals  fluents  actions  and optimal
plan lengths  this can be used as a guide to gauge the difficulty of the problems  as well as our
performance 
conformant problems in addition to the standard domains used in conformant planningsuch
as bomb in the toilet  ring  and cube center  we also developed two new domains logistics and
rovers  we chose these new domains because they have more difficult subgoals  and have many
plans of varying length 
the ring domain involves a ring of n rooms where each room is connected to two adjacent
rooms  each room has a window which can be open  closed  or locked  the goal is to have every
window locked  initially  any state is possible  we could be in any room and each window could be
in any configuration  there are four actions  move right  move left  close the window in the current
  

fip lanning g raph h euristics for b elief s pace s earch

room  and lock the window in the current room  closing a window only works if the window is
open  and locking a window only works if the window is closed  a good conformant plan involves
moving in one direction closing and locking the window in each room 
the cube center domain involves a three dimensional grid  cube  where there are six actions 
it is possible to move in two directions along each dimension  each dimension consists of n possible
locations  moving in a direction along which there are no more grid points leaves one in the same
position  using this phenomena  it is possible to localize in each dimension by repeatedly moving
in the same direction  initially it is possible to be at any location in the cube and the goal is to reach
the center  a good conformant plan involves localizing in a corner and then moving to the center 
the rovers domain is a conformant adaptation of the analogous domain of the classical planning
track of the international planning competition  long   fox         the added uncertainty to
the initial state uses conditions that determine whether an image objective is visible from various
vantage points due to weather  and the availability of rock and soil samples  the goal is to upload an
image of an objective and some rock and soil sample data  thus a conformant plan requires visiting
all of the possible vantage points and taking a picture  plus visiting all possible locations of soil and
rock samples to draw samples 
the first five rovers problems have   waypoints  problems one through four have one through
four locations  respectively  at which a desired imaging objective is possibly visible  at least one will
work  but we dont know which one   problem   adds some rock and soil samples as part of the goal
and several waypoints where one of each can be obtained  again  we dont know which waypoint
will have the right sample   problem   adds two more waypoints  keeps the same goals as problem
  and changes the possible locations of the rock and soil samples  in all cases the waypoints are
connected in a tree structure  as opposed to completely connected 
the logistics domain is a conformant adaptation of the classical logistics domain where trucks
and airplanes move packages  the uncertainty is the initial locations of packages  thus  any actions
relating to the movement of packages have a conditional effect that is predicated on the package
actually being at a location  in the conformant version  the drivers and pilots cannot sense or communicate a packages actual whereabouts  the problems scale by adding packages and cities 
the logistics problems consist of one airplane  and cities with an airport  a post office  and a
truck  the airplane can travel between airports and the trucks can travel within cities  the first
problem has two cities and one package that could start at either post office  and the goal is to get
the package to the second citys airport  the second problem adds another package at the same
possible starting points and having the same destination  the third problem has three cities with
one package that could be at any post office and has to reach the third airport  the fourth problem
adds a second package to the third problem with the same starting and ending locations  the fifth
problem has three cities and three packages  each at one of two of the three post offices and having
to reach different airports 
conditional problems for conditional planning we consider domains from the literature  bombin the toilet with sensing bts  and bomb in the toilet with clogging and sensing btcs  we also
extend the conformant logistics and rovers to include sensory actions 
the rovers problem allows for the rover  when it is at a particular waypoint  to sense the availability of image  soil  or rock data at that location  the locations of the collectable data are expressed
as one of constraints  so the rover can deduce the locations of collectable data by failing to sense
the other possibilities 
  

fib ryce   k ambhampati     s mith

logistics has observations to determine if a package at a location exists  and the observation is
assumed to be made by a driver or pilot at the particular location  since there are several drivers and
a pilot  different agents make the observations  the information gained by the agents is assumed to
be automatically communicated to the others  as the planner is the agent that has all the knowledge  

   empirical evaluation  inter heuristic comparison
we start by comparing the heuristic approaches within our planners  in the next section  we continue
by describing how our planners  using the best heuristics  compare against other state of the art
approaches  in this section we intend to validate our claims that belief space heuristics that measure
overlap perform well across several domains  we further justify using the lu g over multiple
planning graphs and applying mutexes to improve heuristics in regression through pruning belief
states 
we compare many techniques within caltalt and p on d on our conformant planning domains  and in addition we test the heuristics in p on d on the conditional domains  our performance metrics include the total planning time and the number of search nodes expanded  additionally  when discussing mutexes we analyze planning graph construction time  we proceed by
showing how the heuristics perform in caltalt and then how various mutex computation schemes
for the lu g can affect performance  then we present how p on d performs with the different
heuristics in both conformant and conditional domains  explore the effect of sampling a proportion
of worlds to build sg    m g  and lu g graphs  and compare the heuristic estimates in p on d
to the optimal plan length to gauge heuristic accuracy  we finish with a summary of important
conclusions 
we only compute mutexes in the planning graphs for caltalt because the planning graph s  are
only built once in a search episode and mutexes help prune the inconsistent belief states encountered
in regression search  we abstain from computing mutexes in p on d because in progression we
build new planning graphs for each search node and we want to keep graph computation time low 
with the exception of our discussion on sampling worlds to construct the planning graphs  the
planning graphs are constructed deterministically  this means that the single graph is the unioned
single graph sgu   and the m g and lu g graphs are built for all possible worlds 
    caltalt
the results for caltalt in the conformant rovers  logistics  bt  and btc domains  in terms of
total time and number of expanded search nodes  are presented in table    we show the number of
expanded nodes because it gives an indication of how well a heuristic guides the planner  the total
time captures the amount of time computing the heuristic and searching  a high total time with a
high number of search nodes indicates a poor heuristic  and a high total time and low number of
search nodes indicates an expensive but informed heuristic 
we do not discuss the ring and cube center domains for caltalt because it cannot solve
even the smallest instances  due to implementation details the planner performs very poorly when
domains have actions with several conditional effects and hence does not scale  the trouble stems
   this problem may be interesting to investigate in a multi agent planning scenario  assuming no global communication
 e g  no radio dispatcher  

  

fip lanning g raph h euristics for b elief s pace s earch

problem
rovers  
 
 
 
 
 
logistics  
 
 
 
 
bt  
  
  
  
  
  
  
  
  
btc  
  
  
  
  
  
  
  

h 
      
       
to
      
to
    
       
to
    
        
to
 

hcard
        
to
      
to
    
     
      
       
       
        
        
        
        
    
      
       
       
        
        
         
          

hsg
rp
     
       
        
to
     
       
       
         
to
    
       
to
    
        
to
 

g
hm
mrp
     
      
        
        
to
     
        
        
to
    
       
to
    
        
to
 

g
hm
rp u
     
       
       
       
to
      
        
to
    
      
       
       
        
to
    
      
       
       
        
to
 

lu g f x 

hrp
       
       
        
        
to
      
        
        
         
to
    
     
      
       
       
        
        
        
         
    
       
        
         
to
 

table    results for caltalt for conformant rovers  logistics  bt  and btc  the data is total
time     expanded nodes  to indicates a time out     minutes  and   indicates no
attempt 

from a weak implementation for bringing general propositional formulas  obtained by regression
with several conditional effects  into cnf 
we describe the results from left to right in table    comparing the different planning graph
structures and relaxed plans computed on each planning graph  we start with the non planning
graph heuristics h  and hcard   as expected  h    breadth first search  does not perform well in a
large portion of the problems  shown by the large number of search nodes and inability to scale to
solve larger problems  we notice that with the hcard heuristic performance is very good in the bt
and btc problems  this confirms the results originally seen by bertoli  cimatti    roveri      a  
however  hcard does not perform as well in the rovers and logistics problems because the size of a
belief state  during planning  does not necessarily indicate that the belief state will be in a good plan 
part of the reason hcard works so well in some domains is that it measures knowledge  and plans
for these domains are largely based on increasing knowledge  the reason hcard performs poorly
on other domains is that finding causal support  which it does not measure  is more important than
knowledge for these domains 
  

fib ryce   k ambhampati     s mith

next  for a single planning graph  sgu    caltalt does reasonably well with the hsg
rp heuristic in
the rovers and logistics domains  but fails to scale very well on the bt and btc domains  rovers
and logistics have comparatively fewer initial worlds than the bt and btc problems  moreover
the deterministic plans  assuming each initial state is the real state  are somewhat similar for rovers
and logistics  but mostly independent for bt and btc  therefore  approximating a fully observable plan with the single graph relaxed plan is reasonable when plans for achieving the goal from
each world have high positive interaction  however  without high positive interaction the heuristic
degrades quickly when the number of initial worlds increases 
with multiple planning graphs  caltalt is able to perform better in the rovers domain  but takes
quite a bit of time in the logistics  bt  and btc domains  in rovers  capturing distance estimates
for individual worlds and aggregating them by some means tends to be better than aggregating
worlds and computing a single distance estimate  as in a single graph   in logistics  part of the
reason computing multiple graphs is so costly is that we are computing mutexes on each of the
planning graphs  in bt and btc  the total time increases quickly because the number of planning
graphs  and number of relaxed plans for every search node increase so much as problems get larger 
g
mg
comparing the two multiple graph heuristics  in caltalt namely hm
mrp and hrp u   we can
m
g
see the effect of our choices for state distance aggregation  the hmrp relaxed plan heuristic
aggregates state distances  as found on each planning graph  by taking the maximum distance  the
g
hm
rp u unions the relaxed plans from each graph  and counts the number of actions in the unioned
g
relaxed plan  as with the single graph relaxed plan  the hm
mrp relaxed plan essentially measures
one state to state distance  thus  performance suffers on the bt and btc domains  however  using
the unioned relaxed plan heuristic  we capture the independence among the multiple worlds so that
we scale up better in bt and btc  despite the usefulness of the unioned relaxed plan  it is costly to
compute and scalability is limited  so we turn to the lu g version of this same measure 
lu g f x 

with the lu g  we use the hrp
heuristic in caltalt  this heuristic uses a lu g with
g
full cross world mutexes  denoted by f x   as in the similar hm
rp u heuristic  measuring overlap is
important  and improving the speed of computing the heuristic tends to improve the scalability of
caltalt  while caltalt is slower in the rovers and btc domains when using the lu g  we note
that it is because of the added cost of computing cross world mutexes  we are able to improve the
speed by relaxing the mutexes  as we will describe shortly 
    mutexes
mutexes are used to help determine when a belief state is unreachable  mutexes improve the pruning
power of heuristics by accounting for negative interactions  the mutexes are only used to improve
our heuristics  so it is reasonable to compute only a subset of the mutexes  we would like to know
which mutexes are the most cost effective because the number of possible mutexes we can find is
quite large 
we can use several schemes to compute a subset of the mutexes  the schemes combine different
types of mutexes with types of cross world checking  the mutex types are  computing no mutexes
 nx   computing only static interference mutexes  stx   computing  stx  plus inconsistent support and competing needs mutexes  dynamic mutexes  dyx   and computing  dyx  plus induced
mutexes  full mutexes  fx   the cross world checking  see appendix b  reduction schemes are 
g
   we show hm
srp with p on d 

  

fiproblem
rovers  
 
 
 
 
 
logistics  
 
 
 
 
bt  
  
  
  
  
  
  
  
  
btc  
  
  
  
  
  
  
  

lu g n x 

hrp
          
         
           
to
        
             
to
      
       
         
          
           
            
            
            
              
      
       
         
          
           
            
             
             

lu g stx 

hrp
          
         
           
to
         
             
to
      
       
         
          
           
            
            
            
              
      
       
         
          
           
            
             
             

lu g dyx 

hrp
          
           
            
            
              
to
          
            
             
              
to
      
        
          
           
            
             
             
              
               
      
        
          
           
            
to
 

lu g f x 

hrp
          
           
            
            
to
         
            
            
              
to
      
        
          
           
            
             
             
              
               
      
          
            
              
to
 

lu g dyxsx 

hrp
          
           
            
            
             
              
         
           
            
            
             
      
        
          
           
            
             
             
              
               
      
        
          
           
            
             
              
to

lu g dyxix 

hrp
          
           
            
            
              
              
         
           
            
            
              
      
        
          
           
            
             
             
              
               
      
        
          
           
            
             
              
to

lu g f xsx 

hrp
          
           
            
            
             
              
         
           
            
            
             
      
        
          
           
            
             
             
              
               
      
        
          
           
            
             
              
to

lu g f xix 

hrp
          
           
            
            
              
              
         
           
            
            
              
      
        
          
           
            
             
             
              
               
      
         
            
              
               
to
 

p lanning g raph h euristics for b elief s pace s earch

g
table    results for caltalt using hlu
rp with mutex schemes  the data is graph construction
time  ms  all other time  ms    expanded nodes  to indicates a time out     minutes 
and   indicates no attempt 

  

fib ryce   k ambhampati     s mith

computing mutexes across same worlds  sx  and computing mutexes across pairs of worlds in the
intersection  conjunction  of element labels  ix  
table   shows that within caltalt  using the relaxed plan heuristic and changing the way we
compute mutexes on the lu g can drastically alter performance  often  the cross world mutexes
are so numerous that building the lu g takes too much time  to see if we could reduce graph
g
construction overhead without hindering performance  we evaluated hlu
rp when the lug is built
 a  considering all cross world relations  for the schemes  nx    stx    dyx   and  fx   and  b 
same world relations for the schemes  dyx sx  and  fx sx   and  c  cross world relations for all
possible worlds pairs in the intersection of elements labels  dyx ix  and  fx ix  
the results show that simpler problems like bt and btc do not benefit as much from advanced
computation of mutexes beyond static interference  however  for the rovers and logistics problems  advanced mutexes play a larger role  mainly  interference  competing needs  and inconsistent
support mutexes are important  the competing needs and inconsistent support mutexes seem to
have a large impact on the informedness of the guidance given by the lu g  as scalability improves
most here  induced mutexes dont improve search time much  and only add to graph computation
time  a possible reason induced mutexes dont help as much in these domains is that all the actions
have at most two effects  an unconditional and conditional effect  reducing cross world mutex
checking also helps quite a bit  it seems that only checking same world mutexes is sufficient to
solve large problems  interestingly  the m g graphs compute same world interference  competing
needs  and inconsistent support mutexes within each graph  equating to the same scenario as  dyxsx   however  the lug provides a much faster construction time  evidenced by the lu gs ability
to out scale m g 
    p on d
we show the total time and the number of expanded nodes for p on d solving the conformant
problems  including ring and cube center  in table    and for p on d solving the conditional
problems in table    as with caltalt we show the total time and number of expanded nodes for
g
each test  we also add the hm
srp heuristic  not implemented in caltalt  that takes the summation
of the values of relaxed plans extracted from multiple planning graphs  we do not compute mutexes
on any of the planning graphs used for heuristics in p on d mainly because we build planning
graphs for each search node  we proceed by first commenting on the performance of p on d  with
the different heuristics  in the conformant domains  then discuss the conditional domains 
in the conformant domains  p on d generally does better than caltalt  this may be attributed
in part to implementation level details  p on d makes use of an existing  highly optimized  bdd
package for belief state generation in progression  but as previously mentioned  caltalt relies on a
less optimized implementation for belief state generation in regression  as we will see in the next
section  regression planners that employ a more sophisticated implementation perform much better 
but could still benefit from our heuristics  aside from a few differences that we will mention  we see
similar trends in the performance of the various heuristics in both caltalt and p on d  namely 
the n g and sg heuristics have limited ability to help the planner scale  the m g heuristics help
the planner scale better but are costly  and the lu g provides the best scalability  the difference
between the m g and the lu g are especially pronounced in cube center and ring  where the size
of the initial belief state is quite large as the instances scale  interestingly in ring  breadth first
search and the single graph relaxed plan are able to scale due to reduced heuristic computation time
  

fip lanning g raph h euristics for b elief s pace s earch

problem
rovers  
 
 
 
 
 
logistics  
 
 
 
 
bt  
  
  
  
  
  
  
  
  
btc  
  
  
  
  
  
  
  
cubecenter  
 
 
 
  
  
ring  
 
 
 
 
 
 
 
  

h 
      
       
         
to
       
to
     
        
to
     
         
to
      
        
          
to
     
     
      
       
        
          
           
             
to

hcard
      
       
        
          
to
       
to
     
       
to
     
        
to
     
     
      
      
        
        
    
     
     
     
     
     
     
     
     

hsg
rp
     
      
        
          
to
      
to
     
         
to
     
         
to
     
         
           
            
to
     
     
       
        
          
           
            
to
 

g
hm
mrp
     
       
       
         
         
          
      
       
         
       
        
     
        
to
     
          
to
       
         
to
    
       
        
to
 

g
hm
srp
     
      
       
        
        
        
      
        
       
         
         
     
      
       
        
         
         
to
     
      
to
     
        
          
to
    
     
       
         
to
 

g
hm
rp u
     
      
       
       
        
        
     
       
       
         
          
     
      
       
        
         
         
to
     
      
       
        
         
          
to
       
        
           
to
    
      
        
to
 

g
hlu
rp
     
      
      
       
       
        
     
      
       
       
       
     
      
       
       
        
        
        
         
         
     
      
       
       
        
        
         
          
     
        
          
           
            
to
    
     
      
      
       
         
          
to
 

table    results for p on d for conformant rovers  logistics  bt  btc  cube center  and ring 
the data is total time  ms    expanded nodes  to indicates a time out and   indicates
no attempt 

and the low branching factor in search  the lu g is able to provide good search guidance  but tends
to take a long time computing heuristics in ring 
we are also now able to compare the choices for aggregating the distance measures from reg
laxed plans for multiple graphs  we see that taking the maximum of the relaxed plans  hm
mrp   in
assuming positive interaction among worlds is useful in logistics and rovers  but loses the independence of worlds in the bt and btc domains  however  taking the summation of the relaxed plan
  

fib ryce   k ambhampati     s mith

problem
rovers  
 
 
 
 
 
logistics  
 
 
 
 
bt  
  
  
  
  
  
  
  
  
btc  
  
  
  
  
  
  
  

h 
      
        
        
         
to
       
to
     
to
     
to
 

hcard
      
      
      
      
to
to
     
      
      
      
      
       
        
         
         
     
      
      
      
      
       
        
        

hsg
rp
     
      
        
        
to
      
to
     
           
to
     
            
to
 

g
hm
mrp
     
      
      
       
         
         
      
       
       
       
         
     
      
       
        
         
         
to
     
       
        
        
         
         
to
 

g
hm
srp
     
      
      
       
         
         
      
       
       
       
         
     
      
       
        
         
         
to
     
       
to
 

g
hm
rp u
     
      
      
       
         
         
      
       
       
       
         
     
       
       
        
         
to
     
       
        
        
         
to
 

g
hlu
rp
     
      
      
      
        
         
      
       
       
       
         
     
      
       
       
        
        
         
          
          
     
      
       
       
        
        
          
          

table    results for p on d for conditional rovers  logistics  bts  btcs  the data is total time
 ms    expanded nodes  to indicates a time out     minutes  and   indicates no
attempt 

g
values for different worlds  hm
srp is able to capture the independence in the bt domain  we notice
that the summation does not help p on d in the btc domain  this is because we overestimate the
heuristic value for some nodes by counting the flush action once for each world when it in fact
g
only needs to be done once  i e  we miss positive interaction   finally  using the hm
rp u heuristic
we do well in every domain  aside from the cost of computing multiple graph heuristics  because
we account for both positive interaction and independence by taking the overlap of relaxed plans 
again  with the lu g relaxed plan  analogous to the multiple graph unioned relaxed plan  p on d
scales well because we measure overlap and lower the cost of computing the heuristic significantly 

the main change we see in using p on d versus caltalt is that the direction of search is
different  so the hcard heuristic performs unlike before  in the bt and btc domains cardinality
does not work well in progression because the size of belief states does not change as we get closer
to the goal  it is impossible to ever know which package contains the bomb   however  in regression
we start with a belief state containing all states consistent with the goal and regressing actions limits
  

fip lanning g raph h euristics for b elief s pace s earch

our belief state to only those states that can reach the goal through those actions  thus in regression
the size of belief states decreases  but in progression remains constant 
the performance of p on d in the conditional domains exhibits similar trends to the conformant domains  with a few exceptions  like the conformant domains  the m g relaxed plans tend to
outperform the sg relaxed plan  but the lu g relaxed plan does best overall  unlike the conformant
g
domains  the hm
mrp performs much better in bts and btcs over bt and btc partly because
the conditional plans have a lower average cost  the hcard heuristic does better in bts and btcs
over bt and btc because the belief states actually decrease in size when they are partitioned by
sensory actions 
    sampling worlds
our evaluations to this point have considered the effectiveness of different heuristics  each computed with respect to all possible worlds of a belief state  while we would like to use as many of
the possible worlds as we can  we can reduce computation cost and hopefully still get reasonable
heuristics by considering a subset of the worlds  our scheme for considering subsets of worlds in
the heuristics is to sample a single world  sg     or sample a given percentage of the worlds and
build multiple graphs  or the lu g 
mg
lu g
with these sampling approaches  we use the hsg
rp   hrp u   and hrp relaxed plans  we build
the m g and lu g for                     and     of the worlds in each belief state  sampled
randomly  in figure     we show the total time taken  ms  to solve every problem in our test set
    problems over    domains   each unsolved problem contributed    minutes to the total time 
for comparison we show the previously mentioned heuristics  hsg
rp computed on a unioned single
u
graph sg   denoted as unioned compared to the sampled single graph sg  denoted as single 
g
lu g
and hm
rp u and hrp computed for all worlds denoted as       the total time for any heuristic
that samples worlds is averaged over ten runs 
there are two major points to see in figure     first  the hsg
rp heuristic is much more effective
 
u
when computed on sg versus sg   this is because the sg  is less optimistic  it builds a
planning graph for a real world state  as opposed to the union of literals in all possible world states 
as in sgu   respecting state boundaries and considering only a single state is better than ignoring
state boundaries to naively consider all possible states  however  as we have seen with the m g
and lu g heuristics  respecting state boundaries and considering several states can be much better 
bringing us to the second point 
we see very different performance when using more possible worlds to build multiple graphs
compared to the lu g  we are better off using fewer worlds if we have to build multiple graphs
because they can become very costly as the number of worlds increases  in contrast  performance
improves with more possible worlds when we use the lu g  using more possible worlds to compute
heuristics is a good idea  but it takes a more efficient substrate to exploit them 
    accuracy
the heuristics that account for overlap in the possible worlds should be more accurate than the
heuristics that make an assumption of full positive interaction or full independence  to check our
intuitions  we compare the heuristic estimates for the distance between the initial belief state and
the goal belief state for all the heuristics used in conformant problems solved by p on d  figure
   shows the ratio of the heuristic estimate for h bsi   to the optimal serial plan length h  bsi   in
  

fib ryce   k ambhampati     s mith

sg
mg
lug

  

  

  

  

 

 

 

 

 
unioned

single

   

   

   

   

   

    

figure     total time  hours  for p on d to solve all conformant and conditional problems when
sampling worlds to use in heuristic computation 

several problems  the points below the line  where the ratio is one  are under estimates  and those
above are over estimates  some of the problem instances are not shown because no optimal plan
length is known 
g
mg

we note that in all the domains the hlu
rp and hrp u heuristics are very close to h   confirming
m
g
m
g

our intuitions  interestingly  hsrp and hmrp are both close to h in rovers and logistics 
whereas the former is close in the bt and btc problems  and the latter is close in cubecenter
and ring  as expected  assuming independence  using summation  tends to over estimate  and
assuming positive interaction  using maximization  tends to under estimate  the hsg
rp heuristic
tends to under estimate  and in some cases  cubecenter and ring  gives a value of zero  because
there is an initial state that satisfies the goal   the hcard heuristic is only accurate in bt and btc 
under estimates in rovers and logistics  and over estimates in cube center and ring 

the accuracy of heuristics is in some cases disconnected from their run time performance  for
instance hcard highly overestimates in ring and cube center  but does well because the domains
g
mg
exhibit special structure and the heuristic is fast to compute  on the other hand  hlu
rp and hrp u
  

fip lanning g raph h euristics for b elief s pace s earch

     
    
   
  
 
   
    
     

 
 
 
 

 
   
 
 
 
 


 
 


 


 

 



 


 





        
 
 

 

  
 
   
   
 

 
 






 
 

  
  
      
     
 
  
 
 
  
 
        
 
 
 
 
 
  
  
 
  
  
  
  
  
  
 
  
  
  
 
hcard  
hsg
rp  
m
g
hmrp
 
m
g
hsrp 
g
hm
rp u 
g 
hlu
rp

rv  rv  l 

l  b  

b   bc  
bc   c 
problem

c   r 

r  

figure     ratio of heuristic estimates for distance between bsi and bsg to optimal plan length 
rv   rovers  l   logistics  b   bt  bc   btc  c   cube center  r   ring 

are very accurate in many domains  but suffer in ring and cube center because they can be costly
to compute 
    inter heuristic conclusions
our findings fall into two main categories  one  what are effective estimates for belief state distances
in terms of state to state distances  and two  how we can exploit planning graphs to support the
computation of these distance measures 
in comparing ways to aggregate state distance measures to compute belief state distances  we
found that measuring no interaction as in single graph heuristics tends to poorly guide planners 
measuring independence and positive interaction of worlds works well in specific domains  and
measuring overlap  i e  a combination of positive interaction and independence  tends to work well
in a large variety of instances  by studying the accuracy of our heuristics we found that in some
cases the most accurate were not the most effective  we did however find that the most accurate did
best over the most cases 
comparing graph structures that provide the basis for belief state distance measures  we found
that the heuristics extracted from the single graph fail to systematically account for the independence or positive interaction among different possible worlds  despite this lack in the distance
measure  single graphs can still identify some structure in domains like rovers and logistics  to
more accurately reflect belief state distances  multiple graphs reason about reachability for each
world independently  this accuracy comes at the cost of computing a lot of redundant m g structure and is limiting in instances with large belief states  we can reduce the cost of the m g structure
  

fib ryce   k ambhampati     s mith

planner
caltalt
p on d
mbp
kacmbp
cgp
sgp
gpt
yka
cff

search space
belief space
belief space
belief space
belief space
planning graph
planning graph
belief space
belief space
belief space

search direction
backward
forward
forward backward
forward
backward
backward
forward
backward
forward

conditional






heuristic
planning graph
planning graph
cardinality
cardinality
planning graph
planning graph
state space plans
cardinality
planning graph

implementation
c
c
c
c
lisp
lisp
c
c
c

table    comparison of planner features 
by sampling worlds used in its construction  however planners are able to exhibit better scalability
by considering more worlds through optimizing the representation of the redundant structure as in
the lu g  the improvement in scalability is attributed to lowering the cost of heuristic computation  but retaining measures of multiple state distances  the lu g makes a trade off of using an
exponential time algorithm for evaluation of labels instead of building an exponential number of
planning graphs  this trade off is justified by our experiments 

   empirical evaluation  inter planner comparison
we first compare caltalt and p on d with several planners on our conformant domains  then
compare p on d with the conditional planners on the conditional domains  our purpose in this
section is to identify the advantages of our techniques over the state of the art planners  we end the
section with a discussion of general conclusions drawn from the evaluation 
    conformant planning
although this work is aimed at giving a general comparison of heuristics for belief space planning 
we also present a comparison of the best heuristics within caltalt and p on d to some of the
other leading approaches to conformant planning  table   lists several features of the evaluated
planners  such as their search space  their search direction  whether they are conditional  the type of
heuristics  and the implementation language  note  since each approach uses a different planning
representation  bdds  graphplan  etc    not all of which even use heuristics  it is hard to get a
standardized comparison of heuristic effectiveness  furthermore  not all of the planners use pddllike input syntax  mbp  and kacmbp use ar encodings which may give them an advantage in
reducing the number of literals and actions  we gave the mbp planners the same grounded and
filtered action descriptions that we used in caltalt and p on d  we also tried  but do not report
results  giving the mbp planners the full set of ground actions without filtering irrelevant actions  it
appears that the mbp planners do not use any sort of action pre processing because performance was
much worse with the full grounded set of actions  nevertheless  table   compares mbp  kacmbp 
lu g dyxsx 
g
gpt  cgp  yka  and cff with hrp
in caltalt and hlu
rp in p on d with respect to
run time and plan length 
mbp  the mbp planner uses a cardinality heuristic that in many cases overestimates plan distances
 as per our implementation with hcard    mbp uses regression search for conformant plans  but
progression search for conditional plans  it is interesting to note that in the more difficult problem
  

fip lanning g raph h euristics for b elief s pace s earch

problem
rovers  
 
 
 
 
 
logistics  
 
 
 
 
bt  
  
  
  
  
  
  
  
  
btc  
  
  
  
  
  
  
  
cubecenter  
 
 
 
  
ring  
 
 
 
 
 
 

caltalt
lu g dyxsx 
hrp u
       
       
        
        
        
         
     
       
        
        
        
    
     
      
       
       
        
        
        
         
    
     
      
       
       
        
         
         
to
to
 

pond
g
hlu
rp
     
     
      
       
       
       
     
      
       
       
       
     
      
       
       
        
        
        
         
         
     
      
       
       
        
        
         
          
    
       
        
         
         
    
    
      
      
       
        
         

mbp

kacmbp

gpt

cgp

yka

cff

    
     
      
       
oom
      
    
      
      
       
oom
   
      
     
      
      
      
      
      
       
   
      
     
      
      
       
        
        
    
     
     
     
      
   
   
     
     
     
     
      

      
       
       
       
        
to
      
      
       
       
         
    
     
     
      
      
       
       
       
       
    
     
      
      
       
        
        
        
    
     
     
      
      
   
    
     
     
      
      
      

      
      
       
       
         
to
     
       
       
       
         
     
      
         
to
     
      
    
      
       
        
        
    
    
     
      
        
to
 

    
     
      
       
oom
    
     
     
      
to
    
     
      
       
       
       
       
        
to
   
        
       
to
to
 

      
       
       
       
       
        
      
      
        
        
         
   
    
     
     
      
      
      
      
       
    
     
      
       
       
       
         
         
   
    
     
     
      
   
   
     
     
      
      
      

    
    
     
     
     
     
    
     
     
     
     
   
     
       
       
        
        
         
         
         
    
     
       
        
         
         
to
     
        
to
      
to
 

lu g dyxsx 

g
table    results for caltalt using hrp
  p on d using hlu
rp   mbp  kacmbp  gpt 
cgp  yka  and cff for conformant rovers  logistics  bt  btc  cube center  and ring 
the data is total time     plan steps  to indicates a time out     minutes   oom
indicates out of memory   gb   and   indicates no attempt 

instances in the rovers and logistics domains mbp and kacmbp tend to generate much longer
plans than the other planners  mbp does outperform p on d in some cases but does not find
solutions in certain instances  like rovers     most likely because of its heuristic  we note that
kacmbp and mbp are quite fast on the cube center and ring domains  but have more trouble on
domains like rovers and logistics  this illustrates how a heuristic modeling knowledge as opposed
to reachability can do well in domains where the challenge is uncertainty not reachability 
  

fib ryce   k ambhampati     s mith

optimal planners  the optimal approaches  cgp and gpt  tend not to scale as well  despite their
good solutions  cgp has trouble constructing its planning graphs as the parallel conformant plan
depth increases  cgp spends quite a bit of time computing mutexes  which increases the planning
cost as plan lengths increase  cgp does much better on shallow and parallel domains like bt  where
it can find one step plans that dunk every package in parallel 
gpt performs progression search that is guided by a heuristic that measures the cost of fully
observable plans in state space  gpt finds optimal serial plans but is not as effective when the size
of the search space increases  gpt fails to scale with the search space because it becomes difficult
to even compute its heuristic  due to a larger state space as well  
yka  yka  like caltalt is a regression planner  but the search engine is very different and yka
uses a cardinality heuristic  yka performs well on all the domains because of its search engine
based on bdds  we notice a difference in progression and regression by comparing p on d to
yka  similar to trends found in the comparison between p on d and caltalt  additionally  it
seems yka has a stronger regression search engine than caltalt  p on d is able to do better than
yka in the rovers and logistics domains  but it is unclear whether that it is because of the search
direction or heuristics 
cff  conformant ff  a progression planner using a relaxed plan similar to the lu g relaxed plan 
does very well in the rovers and logistics domains because it uses the highly optimized ff search
engine as well as a cheap to compute relaxed plan heuristic  however  cff does not do as well in
the bt  btc  cube center  and ring problems because there are not as many literals that will be
entailed by a belief state  cff relies on implicitly representing belief states in terms of the literals
that are entailed by the belief state  the initial belief state  and the action history  when there are
very few literals that can be entailed by the belief state  reasoning about the belief state requires
inference about the action history  another possible reason cff suffers is our encodings  the
cube center and ring domains are naturally expressed with multi valued state features  and in our
transformation to binary state features we describe the values that must hold but also the values that
must not hold  this is difficult for cff because the conditional effect antecedents contain several
literals and its heuristic is restricted to considering only one such literal  it may be that cff is
choosing the wrong literal or simply not enough literals to get effective heuristics  however in bt
and btc where we used only one literal in effect antecedents cff still performs poorly 
    conditional planning
table   shows the results for testing the conditional versions of the domains on p on d  mbp  gpt 
sgp  and yka 
mbp  the p on d planner is very similar to mbp in that it uses progression search  p on d
uses an ao  search  whereas the mbp binary we used uses a depth first and or search  the depth
first search used by mbp contributes to highly sub optimal maximum length branches  as much
as an order of magnitude longer than p on d   for instance  the plans generated by mbp for
the rovers domain have the rover navigating back and forth between locations several times before
doing anything useful  this is not a situation beneficial for actual mission use  mbp tends to not scale
as well as p on d in all of the domains we tested  a possible reason for the performance of mbp
is that the logistics and rovers domains have sensory actions with execution preconditions  which
prevent branching early and finding deterministic plan segments for each branch  we experimented
  

fip lanning g raph h euristics for b elief s pace s earch

problem
rovers  
 
 
 
 
 
logistics  
 
 
 
 
bt  
  
  
  
  
  
  
  
  
btc  
  
  
  
  
  
  
  

pond
g
hlu
rp
     
     
     
      
       
        
     
       
      
       
        
     
      
       
       
        
        
        
         
         
     
      
       
       
        
        
         
         

mbp

gpt

sgp

yka

       
       
        
        
        
oom
     
         
       
oom
   
      
oom
    
      
oom
 

      
      
      
        
to
      
       
      
to
     
         
oom
     
         
to
 

    
     
to
      
to
   
    
     
      
       
       
       
        
to
    
to
 

      
      
      
        
to
      
to
to
   
     
     
      
      
      
       
       
       
   
      
       
        
        
         
         
        

g
table    results for p on d using hlu
rp   mbp  gpt  sgp  and yka for conditional rovers  logistics  bt  and btc  the data is total time     maximum possible steps in a execution 
to indicates a time out     minutes   oom indicates out of memory   gb   and  
indicates no attempt 

with mbp using sensory actions without execution preconditions and it was able to scale somewhat
better  but plan quality was much longer 
optimal planners  gpt and sgp generate better solutions but very slowly  gpt does better on
the rovers and logistics problems because they exhibit some positive interaction in the plans  but
sgp does well on bt because its planning graph search is well suited for shallow  yet broad  highly
parallel  problems 
yka  we see that yka fares similar to gpt in rovers and logistics  but has trouble scaling for
other reasons  we think that yka may be having trouble in regression because of sensory actions
since it was able to scale reasonably well in the conformant version of the domains  despite this 
yka proves to do very well in the bt and btc problems 
  

fib ryce   k ambhampati     s mith

    empirical evaluation conclusions
in our internal comparisons of heuristics within caltalt and p on d  as well as external comparisons with several state of the art conformant and conditional planners we have learned many
interesting lessons about heuristics for planning in belief space 
 distance based heuristics for belief space search help control conformant and conditional plan
length because  as opposed to cardinality  the heuristics model desirable plan quality metrics 
 planning graph heuristics for belief space search scale better than planning graph search and
admissible heuristic search techniques 
 of the planning graph heuristics presented  relaxed plans that take into account the overlap
of individual plans between states of the source and destination belief states are the most
accurate and tend to perform well across many domains 
 the lug is an effective planning graph for both regression and progression search heuristics 
 in regression search  planning graphs that maintain only same world mutexes provide the best
trade off between graph construction cost and heuristic informedness 
 sampling possible worlds to construct planning graphs does reduce computational cost  but
considering more worlds by exploiting planning graph structure common to possible worlds
 as in the lu g   can be more efficient and informed 
 the lug heuristics help our conditional planner  p on d  to scale up in conditional domains 
despite the fact that the heuristic computation does not model observation actions 

   related work   discussion
we discuss connections with several related works that involve heuristics and or conditional planning in the first half of this section  in the second part of the section we discuss how we can extend
our work to directly handle non deterministic outcomes of actions in heuristic computation 
    related work
much interest in conformant and conditional planning can be traced to cgp  smith   weld         a
conformant version of graphplan  blum   furst         and sgp  weld et al          the analogous
conditional version of graphplan  here the graph search is conducted on several planning graphs 
each constructed from one of the possible initial states  more recent work on c plan  castellini
et al         and frag plan  kurien et al         generalize the cgp approach by ordering the
searches in the different worlds such that the plan for the hardest to satisfy world is found first 
and is then extended to the other worlds  although caltalt and p on d utilize planning graphs
similar to cgp and frag plan it only uses them to compute reachability estimates  the search itself
is conducted in the space of belief states 
another strand of work models conformant and conditional planning as a search in the space
of belief states  this started with genesereth and nourbakhsh         who concentrated on formulating a set of admissible pruning conditions for controlling search  there were no heuristics for
choosing among unpruned nodes  gpt  bonet   geffner        extended this idea to consider a
  

fip lanning g raph h euristics for b elief s pace s earch

simple form of reachability heuristic  specifically  in computing the estimated cost of a belief state 
gpt assumes that the initial state is fully observable  the cost estimate itself is done in terms of
reachability  with dynamic programming rather than planning graphs   gpts reachability heuristic
g
is similar to our hm
mrp heuristic because they both estimate the cost of the farthest  maximum distance  state by looking at a deterministic relaxation of the problem  in comparison to gpt  caltalt
and p on d can be seen as using heuristics that do a better job of considering the cost of the belief
state across the various possible worlds 
another family of planners that search in belief states is the mbp family of plannersmbp
 bertoli et al       b   and kacmbp  bertoli   cimatti         in contrast to caltalt but similar to p on d  the mbp family of planners all represent belief states in terms of binary decision
diagrams  action application is modeled as modifications to the bdds  mbp supports both progression and regression in the space of belief states  while kacmbp is a pure progression planner 
before computing heuristic estimates  kacmbp pro actively reduces the uncertainty in the belief
state by preferring uncertainty reducing actions  the motivation for this approach is that applying
cardinality heuristics to belief states containing multiple states may not give accurate enough direction to the search  while reducing the uncertainty seems to be an effective idea  we note that  a 
not all domains may contain actions that reduce belief state uncertainty and  b  the need for uncertainty reduction may be reduced when we have heuristics that effectively reason about the multiple
worlds  viz   our multiple planning graph heuristics   nevertheless  it could be very fruitful to integrate knowledge goal ideas of kacmbp and the reachability heuristics of caltalt and p on d to
handle domains that contain both high uncertainty and costly goals 
in contrast to these domain independent approaches that only require models of the domain
physics  pksplan  petrick   bacchus        is a forward chaining knowledge based planner that
requires richer domain knowledge  the planner makes use of several knowledge bases  as opposed
to a single knowledge base taking the form of a belief state  the knowledge bases separate binary
and multi valued variables  and planning and execution time knowledge 
yka  rintanen      b  is a regression conditional planner using bdds that uses a cardinality heuristic  recently rintanen has also developed related reachability heuristics that consider
distances for groups of states  which do not rely on planning graphs  rintanen        
more recently  there has been closely related work on heuristics for constructing conformant
plans within the cff planner  hoffmann   brafman         the planner represents belief states
implicitly through a set of known facts  the action history  leading to the belief state   and the initial
belief state  cff builds a planning graph forward from the set of known literals to the goal literals
and backwards to the initial belief state  in the planning graph  conditional effects are restricted
to single literals in their antecedent to enable tractable   cnf reasoning  from this planning graph 
cff extracts a relaxed plan that represents supporting the goal belief state from all states in the
initial belief state  the biggest differences between the lu g and the cff technique are that the
lu g reasons only forward from the source belief state  assuming an explicit  albeit symbolic  belief
state   and the lu g does not restrict the number of literals in antecedents  as a result  the lu g
does not lose the causal information nor perform backward reasoning to the initial belief state 
our handling of uncertainty through labels and label propagation is reminiscent of and related to
de kleers assumption based truth maintenance system  atms   de kleer         where an atms
uses labels to identify the assumptions  contexts  where a particular statement holds  a traditional
truth maintenance system requires extensive backtracking and consistency enforcement to identify
other contexts  similarly  where we can reason about multiple possible worlds  contexts  with the
  

fib ryce   k ambhampati     s mith

lug simultaneously  the mg approach requires  not backtracking  but reproduction of planning
graphs for other possible worlds 
finally  caltalt and p on d are also related to  and an adaptation of the work on reachability
heuristics for classical planning  including altalt  nguyen et al          ff  hoffmann   nebel 
      and hsp r  bonet   geffner         caltalt is the conformant extension to altalt that uses
regression search  similar to hsp r  guided by planning graph heuristics  p on d is similar to ff
in that it uses progression search with planning graph heuristics 
    extension to non deterministic actions
while the scope of our presentation and evaluation is restricted to planning with initial state uncertainty and deterministic actions  some of the planning graph techniques can be extended to include
non deterministic actions of the type described by rintanen      a   non deterministic actions
have effects that are described in terms of a set of outcomes  for simplicity  we consider rintanens
conditionality normal form  where actions have a set of conditional effects  as before  and each
consequent is a mutually exclusive set of conjunctions  outcomes   one outcome of the effect will
result randomly  we outline the generalization of our single  multiple  and labelled planning graphs
to reason with non deterministic actions 
single planning graphs  single planning graphs  that are built from approximate belief states or
a sampled state  do not lend themselves to a straight forward extension  a single graph ignores
uncertainty in a belief state by unioning its literals or sampling a state to form the initial planning
graph layer  continuing with the single graph assumptions about uncertainty  it makes sense to treat
non deterministic actions as deterministic  similar to how we approximate a belief state as a set of
literals to form the initial literal layer or sample a state  we can assume that a non deterministic effect
adds all literals appearing in the effect or samples an outcome as if the action were deterministic
 i e  gives a set of literals   single graph relaxed plan heuristics thus remain unchanged 
multiple planning graphs  multiple planning graphs are very much like conformant graphplan
 smith   weld         we can generalize splitting the non determinism in the current belief state
into multiple initial literal layers to splitting the outcomes of non deterministic effects into multiple
literal layers  the idea is to root a set of new planning graphs at each level  where each has an
initial literal layer containing literals supported by an interpretation of the previous effect layer  by
interpretations of the effect layer we mean every possible set of joint effect outcomes  a set of effect
outcomes is possible if no two outcomes are outcomes of the same effect  relaxed plan extraction
still involves finding a relaxed plan in each planning graph  however  since each planning graph is
split many times  in a tree like structure  a relaxed plan is extracted from each path of the tree 
we note that this technique is not likely to scale because of the exponential growth in redundant
planning graph structure over time  further  in our experiments cgp has enough trouble with initial
state uncertainty  we expect that we should be able to do much better with the lu g 
labelled uncertainty graph  with multiple planning graphs we are forced to capture non
determinism through splitting the planning graphs not only in the initial literal layer  but also each
literal layer that follows at least one non deterministic effect  we saw in the lu g that labels can
capture the non determinism that drove us to split the initial literal layer in multiple graphs  as
such  these labels took on a syntactic form that describes subsets of the states in our source belief
state  in order to generalize labels to capture non determinism resulting from uncertain effects  we
  

fip lanning g raph h euristics for b elief s pace s earch

need to extend their syntactic form  our objective is to have a label represent which sources of
uncertainty  arising from the source belief state or effects  causally support the labelled item  we
also introduce a graph layer ok to represent outcomes and how they connect effects and literals 
it might seem natural to describe the labels for outcomes in terms of their affected literals  but
this can lead to trouble  the problem is that the literals in effect outcomes are describing states at a
different time than the literals in the projected belief state  further  an outcome that appears in two
levels of the graph is describing a random event at different times  using state literals to describe
all labels will lead to confusion as to which random events  state uncertainty and effect outcomes at
distinct steps  causally support a labelled item  a pathological example is when we have an effect
whose set of outcomes matches one to one with the states in the source belief state  in such a case 
by using labels defined in terms of state literals we cannot distinguish which random event  the state
uncertainty or the effect uncertainty  is described by the label 
we have two choices for describing effect outcomes in labels  in both choices we introduce a
new set of label variables to describe how a literal layer is split  these new variables will be used
to describe effect outcomes in labels and will not be confused with variables describing initial state
uncertainty  in the first case  these variables will have a one to one matching with our original set
of literals  but can be thought of as time stamped literals  the number of variables we add to the
label function is on the order of  f per level  the number of fluent literals  assuming boolean
fluents   the second option is to describe outcomes in labels with a new set of fluents  where each
interpretation over the fluents is matched to a particular outcome  in this case  we add on the order
of log  ok   variables  where ok is the k th outcome layer  it would actually be lower if many of
the outcomes were from deterministic effects because there is no need to describe them in labels 
the former approach is likely to introduce fewer variables when there are a lot of non deterministic
effects and they affect quite a few of the same literals  the latter will introduce fewer variables
when there are relatively few non deterministic effects whose outcomes are fairly independent 
with the generalized labelling  we can still say that an item is reachable from the source belief
state when its label is entailed by the source belief state  this is because even though we are adding
variables to labels  we are implicitly adding the fluents to the source belief state  for example  say
we add a fluent v to describe two outcomes of an effect  one outcome is labelled v  the other v 
we can express the source belief state bsp that is projected by the lu g with the new fluent as
bsp   v  v    bsp   an item labelled as bsp  v will not be entailed by the projected belief
state  i e  is unreachable  because only one outcome causally supports it  if both outcomes support
the item  then it will be reachable 
given our notion of reachability  we can determine the level from which to extract a relaxed
plan  the relaxed plan procedure does not change much in terms of its semantics other than having
the extra graph layer for outcomes  we still have to ensure that literals are causally supported in all
worlds they are labelled with in a relaxed plan  whether or not the worlds are from the initial state
uncertainty or supporting non deterministic effects 

   conclusion
with the intent of establishing a basis for belief state distance estimates  we have 
 discussed how heuristic measures can aggregate state distance measures to capture positive
interaction  negative interaction  independence  and overlap 
  

fib ryce   k ambhampati     s mith

 shown how to compute such heuristic measures on planning graphs and provided empirical
comparisons of these measures 
 found that exploiting planning graph structure to reduce the cost of considering more possible
states of a belief state is preferable to sampling a subset of the states for the heuristics 
 shown that a labelled uncertainty graph can capture the same support information as multiple
graphs  and reduces the cost of heuristic computation 
 shown that the labelled uncertainty graph is very useful for conformant planning and  without
considering observational actions and knowledge  can perform well in conditional planning 
our intent in this work was to provide a formal basis for measuring the distance between belief
states in terms of underlying state distances  we investigated several ways to aggregate the state
distances to reflect various assumptions about the interaction of state to state trajectories  the best
of these measures turned out to measure both positive interaction and independence  what we call
overlap  we saw that planners using this notion of overlap tend to do well across a large variety of
domains and tend to have more accurate heuristics 
weve also shown that planning with a labelled uncertainty planning graph lu g  a condensed
version of the multiple graphs is useful for encoding conformant reachability information  our main
innovation is the idea of labels  labels are attached to all literals  actions  effect relations  and
mutexes to indicate the set of worlds in which those respective elements hold  our experimental
results show that the lu g can outperform the multiple graph approach  in comparison to other
approaches  weve also been able to demonstrate the utility of structured reachability heuristics in
controlling plan length and boosting scalability for both conformant and conditional planning 
we intend to investigate three additions to this work  the first  is to incorporate sensing and
knowledge into the heuristics  we already have some promising results without using these features
in the planning graphs  but hope that they will help the approaches scale even better on conditional
problems  the second addition will be to consider heuristics for stochastic planning problems  the
major challenges here are to associate probabilities with labels to indicate the likelihood of each
possible world and integrate reasoning about probabilistic action effects 
lastly  we have recently extended the lu g within the framework of state agnostic planning
graphs  cushing   bryce         and hope to improve the technique  a state agnostic planning
graph is essentially a multiple source planning graph  where by analogy a conventional planning
graph has a single source  planning graphs are already multiple destination  so in our generalization
the state agnostic planning graph allows us to compute the distance measure between any pair of
states or belief states  the lu g seeks to avoid redundancy across the multiple planning graphs
built for states in the same belief state  we extended this notion to avoid redundancy in planning
graphs built for every belief state  we have shown that the state agnostic lu g  slu g  which is
built once per search episode  as opposed to a lu g at each node  can reduce heuristic computation
cost without sacrificing informedness 
acknowledgments we would like to thank minh b  do  romeo sanchez  terry zimmermam 
satish kumar thittamaranahalli  and will cushing for helpful discussions and feedback  jussi rintanen for help with the yka planner  and piergiorgio bertoli for help with the mbp planner  this
work was supported in part by nasa grants ncc       and nag        the nsf grant iis         the      nasa riacs ssrp  the arcs foundation  and an ibm faculty award 
  

fip lanning g raph h euristics for b elief s pace s earch

appendix a  additional heuristics
for completeness  we present some additional heuristics adapted from classical planning to reason
about belief state distances in each type of planning graph  many of these heuristics appeared in our
previous work  bryce   kambhampati         we show how to compute the max  sum  and level
heuristics on the single graph sg  multiple graphs m g  and the labelled uncertainty graph lu g 
while these heuristics tend to be less effective than the relaxed plan heuristics  we provide them as
reference  as with section    we describe the heuristics in terms of regression search 
a   single planning graph heuristics  sg 
like  the relaxed plan for the single unmodified planning graph  we cannot aggregate state distances
because all notion of separate states is lost in forming the initial literal layer  thus we only compute
heuristics that do not aggregate state distances 
no state aggregation 
 max in classical planning  the maximum cost literal is used to get a max heuristic  but we use
formulas to describe our belief states  so we take the maximum cost clause as the cost of the
belief state to find the max heuristic hsg
max   the maximum cost clause of the belief state  with
respect to a single planning graph  is 
hsg
max  bsi    

max

c bsi  

cost c 

where the cost of a clause is 
cost c    min min k
lc k llk

here we find the cheapest literal as the cost of each clause to find the maximum cost clause 
this is an underestimate of the closest state to our current belief state 
 sum like the classical planning sum heuristic  we can take the sum hsg
sum of the costs of the
clauses in our belief state to estimate our belief state distance

cost c 
hsg
sum  bsi    
c bsi  

this heuristic takes the summation of costs of literals in the closest estimated state in the
belief state  and is inadmissible because there may be a single action that will support every
clause  and we could count it once for each clause 
 level when we have mutexes on the planning graph  we can compute a level heuristic hsg
level
 without mutexes the level heuristic is equivalent to the max heuristic   the level heuristic
maintains the admissibility of the max heuristic but improves the lower bound by considering
what level of the planning graph all literals in a constituent are non pairwise mutex  the

level heuristic is computed by taking the minimum among the s   bs
i    of the first level
 lev s   in the planning graph where literals of s are present with none of them marked
pairwise mutex  formally 
hsg
level  bsi    

  

min

s bsi  

lev s 

fib ryce   k ambhampati     s mith

a   multiple planning graph heuristics  m g 
similar to the various relaxed plan heuristics for the multiple graphs  we can compute a max  sum 
or level heuristic on each of the multiple planning graphs and aggregate them with a maximum
or summation to respectively measure positive interaction or independence  the reason we cannot
aggregate the individual graph heuristics to measure overlap is that they are numbers  not sets of
actions  measuring overlap involves taking the union of heuristics from each graph and the union
of numbers is not meaningful like the union of action sets from relaxed plans  like before  there is
no reason to use multiple graphs if there is no state distance aggregation 
positive interaction aggregation 
g
 max the max heuristic hm
mmax is computed with multiple planning graphs to measure posm
g
itive interaction in the hmmax heuristic  this heuristic computes the maximum cost clause
in  bsi   for each graph     similar to how hsg
mmax  bsi   is computed  and takes the
maximum  formally 
g

hm
mmax  bsi     max  hmax  bsi   


g
the hm
mmax heuristic considers the minimum cost  relevant literals of a belief state  those that
are reachable given a possible world for each graph   to get state measures  the maximum
is taken because the estimate accounts for the worst  i e   the plan needed in the most difficult
world to achieve the subgoals  

 sum the sum heuristic that measures positive interaction for multiple planning graphs is
g
hm
msum   it computes the summation of the cost of the clauses in  bsi   for each graph
   and takes the maximum  formally 
g

hm
msum  bsi     max  hsum  bsi   


the heuristic considers the minimum cost  relevant literals of a belief state  those that are
reachable given the possible worlds represented for each graph   to get state measures  as
g
with hm
mmax   the maximum is taken to estimate for the most costly world 

g
mg
mg
 level similar to hm
mmax and hmsum   the hmlevel heuristic is found by first finding hlevel
for each graph    to get a state distance measure  and then taking the maximum across

the graphs  hlevel  bsi   is computed by taking the minimum among the s   bs
i    of the

first level lev  s  in the planning graph  where literals of s are present with none of them
marked mutex  formally 

hlevel  bsi    

min

s bsi  

lev   s 

and

g
hm
mlevel  bsi     max hlevel  bsi   


note that this heuristic is admissible  by the same reasoning as in classical planning  the first
level where all the subgoals are present and non mutex is an underestimate of the true cost of
a state  this holds for each of the graphs  taking the maximum accounts for the most difficult
  

fip lanning g raph h euristics for b elief s pace s earch

world in which to achieve a constituent of bsi and is thus a provable underestimate of h  
g
gpts max heuristic  bonet   geffner        is similar to hm
mlevel   but is computed with
dynamic programming in state space rather than planning graphs 
independence aggregation  all heuristics mentioned for positive interaction aggregation can
be augmented to take the summation of costs found on the individual planning graphs rather than
g
mg
mg
the maximum  we denote them as  hm
smax   hssum   and hslevel   none of these heuristics are
admissible because the same action may be used in all worlds  but we count its cost for every world
by using summation 
a   labelled uncertainty graph  lu g 
the max  sum  and level heuristics for the lu g are similar to the analogous multiple graph heuristics  the main difference with these heuristics for the lu g is that it is much easier to compute
positive interaction measures than independence measures  the reason positive interaction is easier
to compute is that we find the cost of a clause for all states in our belief state at once  rather than on
each of multiple planning graphs  like before  we do not consider heuristics that do not aggregate
state distances 
positive interaction aggregation 
g
 max the max heuristic hlu
mmax for the lu g finds the maximum clause cost across clauses
of the current belief state bsi   the cost of a clause is the first level it becomes reachable 
formally 


g
hlu
mmax  bsi  

 

max

c bsi  


min

k bsp   k  c 

k

g
 sum the sum heuristic hlu
msum for the lu g sums the individual levels where each clause
in  bsi   is first reachable  formally 

 
g
min
hlu
 bs
 
 
k
i
msum

c bsi  

k bsp   k  c 

g
 level the level heuristic hlu
mlevel is the index of the first level where bsi is reachable 
formally 
g
hlu
mlevel  bsi    

min

k bsp   k  bsi  

i

independence aggregation  all heuristics mentioned for positive interaction aggregation can be
augmented to take the summation of costs for each state in our belief state  this may be inefficient
due to the fact that we lose the benefit of having a lu g by evaluating a heuristic for each state of
our bsp   rather than all states at once as in the positive interaction aggregation  in such a case we
are doing work similar to the multiple graph heuristic extraction  aside from the improved graph
construction time  the positive interaction aggregation is able to implicitly calculate the maximum
over all worlds for most of the heuristics  whereas for the sum heuristic we need to explicitly find a
g
lu g
lu g
cost for each world  we denote the sum heuristics as  hlu
smax   hssum   and hslevel  
  

fib ryce   k ambhampati     s mith

appendix b  cross world mutexes
mutexes can develop not only in the same possible world but also between two possible worlds 
as described by smith and weld         cross world mutexes are useful to capture negative interactions in belief state distance measures  mentioned in section     the representation of crossworld mutexes requires another generalization for the labelling of mutexes  same world mutexes
require keeping only one label for the mutex to signify all same possible worlds for which the mutex holds  the extended representation keeps a pair of labels  one for each element in the mutex 
if x in possible world s is mutex with x in possible world s    we denote the mutex as the pair
 k  x    s  k  x     s    
we can compute cross world mutexes between several worlds of elements x and x   for example  if k  x    s  s  s  and k  x     s  s    then to check for all cross world mutexes we need
to consider mutexes for the world pairs  s    s      s    s      s    s      s    s      s    s     and  s    s    
we can also check for mutexes in the intersection of the element labels k  x   k  x     s   s   
meaning the only cross world pairs we check for mutexes are  s    s      s    s      s    s     and
 s    s    
we can say that a formula f is reachable from our projected belief state bsp   when considering
cross world mutexes  if for every pair of states in bsp   f is reachable  for a pair of states s and
s    f is reachable if s  s     k  f   and for every pair of constituents s   s  f such that
s    k  s   and s     k  s    there are no two literals in either s or s that are same world
mutex when s   s    and there is not a mutex between literals in s and s   across the respective
worlds s and s  when s 
  s    there is a mutex between a pair literals l and l   respectively from
s and s if there is a mutex  k  l   k  l    such that s    k  l  and s     k  l   
the computation of cross world mutexes requires changes to some of the mutex formulas  as
outlined next  the major change is to check  instead of all the single possible worlds s  all pairs of
possible worlds s and s  for mutexes 
action mutexes  the action mutexes can now hold for actions that are executable in different
possible worlds 
 interference interference mutexes do not change for cross world mutexes  except that there
is a pair of labels where  k  a    bsp   k  a     bsp    instead of a single label 
 competing needs competing needs change mutexes for cross world mutexes because two
actions a and a   in worlds s and s  respectively  could be competing  formally  a crossworld competing needs mutex   k  a    s  k  a     s    exists between a and a in worlds s
and s  if 
le  a  l e  a    k  l    s  k  l     s   
effect mutexes  the effect mutexes can now hold for effects that occur in different possible worlds 
 interference effect interference mutexes do not change for cross world mutexes  except that
there is a pair of labels where  k  i  a     bsp   k  j  a      bsp    instead of a single
label 
  

fip lanning g raph h euristics for b elief s pace s earch

lk

lk p 
p


ek

ak

lk a 
a

h a 

lk h a  



 lk p   lk q  
induced mutex across worlds 


 lk j a  lk i a    lk h a   





 lk j a    lk h a   

lk q 
q
lk a 
a

j a 

lk r 
r

lk j a  
i a  induces j a  in 
lk i a  lk j a  

i a  lk i a  

figure     example of a cross world induced effect mutex 
 competing needs effect competing needs mutexes change for cross world mutexes because
two effects i  a  and j  a    in worlds s and s  respectively  could be competing  formally 
a cross world competing needs mutex  k  i  a     s  k  j  a      s    exists between i  a 
and j  a   in worlds s and s  if 
li  a  l j  a    k  l    s  k  l     s   
 induced induced mutexes change slightly for cross world mutexes  the worlds where one
effect induces another  remains the same  but the mutex changes slightly 
if j  a  in k  j  a   is mutex with h  a   in k  h  a     and i  a  induces effect j  a 
in the possible worlds described by k  i  a    k  j  a    then there is an induced mutex
between i  a  in k  j  a    k  i  a   and h  a   in k  h  a     see figure     

literal mutexes  the literal mutexes can now hold for literals that are supported in different possible worlds 
 inconsistent support changes for cross world mutexes  a mutex  k  l    s  k  l     s   
holds for l in s and l in s  if i  a   j  a    ek  where l  i  a   l  j  a    there is a
mutex k   i  a     s  k   j  a      s    

  

fib ryce   k ambhampati     s mith

references
bertoli  p     cimatti  a          improving heuristics for planning as search in belief space  in
proceedings of aips   
bertoli  p   cimatti  a     roveri  m       a   heuristic search   symbolic model checking  
efficient conformant planning  in proceedings of ijcai   
bertoli  p   cimatti  a   roveri  m     traverso  p       b   planning in nondeterministic domains
under partial observability via symbolic model checking  in proceedings of ijcai   
blum  a     furst  m          fast planning through planning graph analysis  in proceedings of
ijcai   
bonet  b     geffner  h          planning as heuristic search  new results  in proceedings of
ecp   
bonet  b     geffner  h          planning with incomplete information as heuristic search in belief
space  in proceedings of aips   
brace  k   rudell  r     bryant  r          efficient implementation of a bdd package  in proceedings of the   th acm ieee design automation conference 
bryant  r          graph based algorithms for boolean function manipulation  ieee transactions
on computers  c               
bryce  d     kambhampati  s          heuristic guidance measures for conformant planning  in
proceedings of icaps   
castellini  c   giunchiglia  e     tacchella  a          improvements to sat based conformant
planning  in proceedings of ecp   
cimatti  a     roveri  m          conformant planning via symbolic model checking  journal of
artificial intelligence research             
cormen  t  h   leiserson  c  e     rivest  r  l          introduction to algorithms  mcgraw hill 
cushing  w     bryce  d          state agnostic planning graphs  in proceedings of aaai   
de kleer  j          an assumption based tms  artificial intelligence                
genesereth  m  r     nourbakhsh  i  r          time saving tips for problem solving with incomplete information  in proceedings of aaai   
hansen  e     zilberstein  s          lao  a heuristic search algorithm that finds solutions with
loops  artificial intelligence                
hoffmann  j     brafman  r          conformant planning via heuristic forward search  a new
approach  in proceedings of icaps   
hoffmann  j     nebel  b          the ff planning system  fast plan generation through heuristic
search  journal of artificial intelligence research             
kambhampati  s   ihrig  l     srivastava  b          a candidate set based analysis of subgoal
interactions in conjunctive goal planning  in proceedings of aips   
koehler  j   nebel  b   hoffmann  j     dimopoulos  y          extending planning graphs to an
adl subset  in proceedings of ecp   
  

fip lanning g raph h euristics for b elief s pace s earch

kurien  j   nayak  p     smith  d          fragment based conformant planning  in proceedings of
aips   
long  d     fox  m          the  rd international planning competition  results and analysis 
journal of artificial intelligence research          
nguyen  x   kambhampati  s     nigenda  r          planning graph as the basis for deriving
heuristics for plan synthesis by state space and csp search  artificial intelligence           
      
nilsson  n          principles of artificial intelligence  morgan kaufmann 
pednault  e  p  d          synthesizing plans that contain actions with context dependent effects 
computational intelligence            
petrick  r     bacchus  f          a knowledge based approach to planning with incomplete information and sensing  in proceedings of aips   
rintanen  j       a   expressive equivalence of formalisms for planning with sensing  in proceedings of icaps   
rintanen  j       b   product representation of belief spaces in planning under partial observability 
in proceedings of ijcai   
rintanen  j          distance estimates for planning in the discrete belief space  in proceedings of
aaai   
smith  d     weld  d          conformant graphplan  in proceedings of aaai   
weld  d   anderson  c     smith  d          extending graphplan to handle uncertainty and sensing
actions  in proceedings of aaai   

  

fi