journal artificial intelligence research                  

submitted        published      

convexity arguments efficient minimization
bethe kikuchi free energies
tom heskes

t heskes science ru nl

iris  faculty science  radboud university nijmegen
toernooiveld         ed  nijmegen  netherlands

abstract
loopy generalized belief propagation popular algorithms approximate inference markov random fields bayesian networks  fixed points algorithms
shown correspond extrema bethe kikuchi free energy 
approximations exact helmholtz free energy  however  belief propagation always converge  motivates approaches explicitly minimize
kikuchi bethe free energy  cccp ups 
describe class algorithms solves typically non convex constrained
minimization problem sequence convex constrained minimizations upper
bounds kikuchi free energy  intuitively one would expect tighter bounds lead
faster algorithms  indeed convincingly demonstrated simulations  several
ideas applied obtain tight convex bounds yield dramatic speed ups cccp 

   introduction
pearls belief propagation  pearl        popular algorithm inference bayesian
networks  known exact special cases  e g   tree structured  singly connected 
networks gaussian discrete nodes  networks containing cycles 
so called loopy belief propagation empirically often leads good performance  approximate
marginals close exact marginals   murphy  weiss    jordan        mceliece  mackay 
  cheng         notion fixed points loopy belief propagation correspond
extrema so called bethe free energy  yedidia  freeman    weiss        important
step theoretical understanding success 
kikuchi free energy  kikuchi        generalization bethe free energy
lead better approximations exact helmholtz free energy  fixed points
loopy belief propagation correspond extrema bethe free energy  fixed points
algorithm called generalized belief propagation  yedidia et al         correspond
extrema kikuchi free energy 
problem loopy generalized belief propagation always
converge stable fixed point  new algorithms  yuille        teh   welling       
derived therefore explicitly minimize bethe kikuchi free energy 
describe section    minimization kikuchi free energy corresponds usually nonconvex constrained minimization problem  non convex constrained minimization problems
known rather difficult solve  section   first derive sufficient
conditions kikuchi free energy convex  over set constraints   section  
derive class converging double loop algorithms  inner loop
corresponds constrained minimization convex bound kikuchi free energy 
c
    
ai access foundation  rights reserved 

fiheskes

outer loop step recalculation bound  based intuition
tightest bound yields fastest algorithm  come several ideas construct
tight bounds  see yuilles        cccp algorithm corresponds special
case rather loose bound discuss relationship ups algorithm teh
welling        section      simulations section   illustrate use tight
convex bounds several inference problems  implications issues discussed
section    technical details treated appendices 

   kikuchi approximation
exact inference graphical models often intractable  section introduce
kikuchi approximation particular example variational approach towards approximate inference 
    graphical models
undirected graph g    v  e  consists set nodes vertices v               n  
joined set edges e  place node variable xi takes values
finite discrete alphabet  vector containing variables denoted x  x            xn   
let subset v   call region  clique fully connected subset v   c
set cliques  potential  referred compatibility kernel function   x  
strictly positive function depends variables part clique
  define probability distribution probability mass function
pexact  x 

 
 x    
z

   

c

z normalizing constant  often called partition function  hammersleyclifford theorem  besag        guarantees us underlying probability process
markov respect graph and  vice versa  distribution markov random field g strictly positive expressed form  process
moralization  directed graphical model  bayesian network  transformed
corresponding undirected model  consequently  probability distribution corresponding
bayesian network written form      lauritzen        
computing partition function z  well computing marginals subsets variables  principle requires summation exponential number states  circumvent
exponential summation two kinds approaches  sampling techniques
variational methods  sampling  one draws samples exact probability distribution  variational methods try find approximation exact probability
distribution 
    variational methods
variational methods often derived approximation so called free energy
x
xx
p x   log  x    
p x  log p x  e p  s p   
   
f  p   
c x

x

   

fiefficient minimization kikuchi free energy

first term  e p   referred energy  second term s p  entropy 
functional minimization f  p  respect functions p x  constraint
p x  properly normalized yields pexact  x   furthermore  partition function z
follows
log z   f  pexact    
stick exact free energy      really gain anything  entropy
part s p  still consists sum exponentially many terms  variational methods
based tractable approximation free energy  roughly divided two
classes  mean field kikuchi approximations  mean field approach one
confines minimization free energy restricted class  tractable  probability
distributions instead considering class p probability distributions 
log z   f  pexact     min f  p  min f  p   
pp

pt

crux choose class entropy s p  becomes tractable p  
note however restriction typically affects energy term e p   jordan 
ghahramani  jaakkola    saul        jaakkola   jordan        
kikuchi approximation free energy     leaves energy term
approximates entropy s p  combination marginal entropies 
x
x
s p   
p x  log p x 
c  p 
r

x

 

x

c

r

x

p x   log p x    

   

x

r denotes collection so called regions  parameters c called moebius
overcounting numbers 
      partially ordered sets
following pakzad anantharam               use language partially ordered
sets posets  specifically  collection r regions viewed poset
ordering defined respect inclusion operator   region includes
region   written   variables part   use denote
strict inclusion  i e       say covers r  written  
exists r   visualize poset
so called hasse diagram region graph  see examples below   given particular poset
r  hasse diagram gr directed acyclic graph  whose vertices elements r 
whose edges corresponds cover relationships  is  edge
iff  
    cluster variation method
kikuchis        original cluster variation method  cvm   collections regions
overcounting numbers constructed follows  start defining collection
outer regions  minimal choice original set cliques c  choose
   

fiheskes

combine cliques construct larger ones  similar process triangulation  lauritzen 
       convenience  redefine potentials correspondingly  i e  
precisely one potential  x   per outer region  see example below  
given outer regions  construct new regions taking intersections
outer regions  intersections intersections  on  intersections
made  refer regions constructed way inner regions  combined
collection i  collection regions r     union outer
inner regions  r   i 
overcounting moebius numbers original cvm follow moebius
formula
x
   
c    
c  


definition c     outer regions o 
bethe free energy considered special case kikuchi free energy 
bethe free energy intersectionspof intersections  i e   one level
inner regions c     n n o    equals number outer regions
covering inner region  
      alternatives
several alternatives original cvm  weaker constraints and or constraints
choice regions overcounting numbers  proposed recently  yedidia 
freeman  weiss        present overview  particular choice inner regions
subsets overcounting numbers junction graphs  aji   mceliece        join
graphs  dechter  kask    mateescu        leads entropy approximation
overcounting numbers inner regions negative  resulting algorithms
similar junction tree algorithm  applied graph loops 
entropy approximation follows original cluster variation method takes
account entropy contributions level outer regions consistent manner
and  theoretical grounds  seems reason deviate  pakzad
  anantharam         paper  therefore focus original cluster variation
method  analysis holds much generally poset region graph 
    constrained minimization
kikuchi approximation free energy depends marginals p x  
r  replace minimization exact free energy complete
distribution p x  minimization kikuchi free energy
xx
x x
fkikuchi  q   
q  x   log  x    
c
q  x   log q  x  
   
x

r

   

x

fiefficient minimization kikuchi free energy

pseudo marginals q  q   r  consistency normalization constraints
q  x     r x
x

q  x       r

 positive 

  a 

 normalized 

  b 

 consistent 

  c 

x

x

q  x     q  x     r 

x  

referring class pseudo marginals satisfying constraints q 
approximation
log z min fkikuchi  q   
qq

furthermore  hope pseudo marginals q  x   corresponding minimum accurate approximations exact marginals pexact  x    kikuchi free
energy corresponding marginals exact hasse diagram turns singlyconnected  pakzad   anantharam        
    illustration
illustration main concepts  consider probability model   variables
 nodes  pairwise interactions nodes visualized figure   a  
obvious shorthand notation  exact distribution form
 
 
pexact  x   
ij  xi   xj                        
z
z
 i j 

note potentials originally defined single nodes always incorporated
definition two node potentials  region graph corresponding minimal
choice outer regions  i e   equivalent potential subsets  given figure   b  
outer regions pairs nodes  inner regions subsets single nodes 
fact  case region graph equivalent so called factor graph  kschischang 
frey    loeliger        kikuchi approximation free energy boils
bethe approximation 
xx
qij  xi   xj   log ij  xi   xj  
fkikuchi  q   
 i j  xi  xj

 

xx

qij  xi   xj   log qij  xi   xj    

 i j  xi  xj

x
x
   ni  
qi  xi   log qi  xi    


xi

ni     number outer regions containing inner region i 
cluster variation method allows us choose larger outer regions  example 
consisting triples  i  j  k   redefine factorization potentials
pexact  x   

 
ijk  xi   xj   xk                      
z
 i j k 

   

fiheskes

 
x 

x 

ee
ee yyy
eyey
yy eee

e
yy

 

 

 

 

 

                   
    
    
   ii
ii
ii
u
u
u
u
ii
ii
u
   iii
uu
uu
   iii iiii iuiuiuiu
uu
u
  

ii uu ii uu

iuiu
iu
  iiii

uuuii
uu
 
 
 
 

x 

x 

  

 a  markov random field 

  

  

  

 b  hasse diagram bethe approximation 

 

 

 

 

       i        i        i        

ii   
iu
iu

ii
uuii
uuii
uuu iii uuu iii
ii    


ii  


u
u





u
u
ii   

u
u


ii
ii
uuu
ii  
uu





u

uu


uu

                   
    
    
   ii
ii
ii
u
u
u
u



u
u
ii
ii uu    uu   
ii
         
  
  
u
   iiii iiii uuiuiuii
uu
ii
ii uuu
ii uu
  



ui

ii
uuuii
uu
 
 
 
 
 

 

 

 

 c  region graph kikuchi approximation 
figure    region graphs bethe kikuchi approximations  lines nodes
markov random field  a  indicate edges  region graphs  b   c  
outer regions drawn highest level  lines indicate covering
relationship  lower regions covered higher regions  oblique
numbers overcounting numbers follow moebius formula 
bethe approximation  b  corresponds minimal approximation
outer regions equivalent cliques graph  pairs nodes 
particular kikuchi approximation  c  follows taking outer regions
node triples 

   

fiefficient minimization kikuchi free energy

example  distribute symmetrically 
 

                 

 

                 

 

                 

 

                   
 assign first outer region 
            
         
      
       
corresponding region graph given figure   c   first level inner regions
pairs nodes second level inner regions single nodes  overcounting numbers       respectively  kikuchi approximation entropy boils

x
x
x
skikuchi  q   
sijk
sij  
si  
 i j k 

 i j 



intuitive reasoning behind approximation follows  sum threenode entropies overcounts two node interactions  each combination  i  j  appears twice
rather once   therefore discounted once  single node
interactions much discounted  overcounting number    times   appearances  compared   appearances overcounting number   three node entropies  
yielding overcounting number                   
    generalized loopy belief propagation
summarize  finding kikuchi approximation partition function z boils
minimization kikuchi free energy respect set pseudo marginals
linear constraints them  introducing lagrange multipliers constraints 
shown fixed points popular algorithm called loopy belief propagation correspond extrema bethe free energy and  generally  fixed points generalized
belief propagation extrema kikuchi free energy  yedidia et al          however 
algorithms guaranteed converge minimum practice get stuck
example limit cycles  explains search convergent alternatives directly
minimize kikuchi free energy  topic rest paper 

   convexity kikuchi free energy
section derive sufficient conditions kikuchi free energy convex
set consistency constraints      relevant kikuchi free
energy indeed convex constraint set  must unique minimum
minimization problem relatively straightforward  furthermore  argument
   

fiheskes

use deriving conditions play important role construction efficient
minimization algorithms later on 
    sufficient conditions
consider kikuchi free energy     function pseudo marginals q 
reasoning convexity  disregard energy term linear q 
entropy terms give either convex concave contribution  depending whether
corresponding overcounting numbers positive negative  respectively  ignoring
constraints      free energy     convex concave contributions vanish 
i e   c     r  
however  really care subspace induced constraints      therefore introduce notion convexity set constraints  call free energy
convex set constraints    
f  q        q    f  q          f  q         q   q  q  
note that  since constraints linear  q  q  satisfy constraints     
q        q    following  talk convexity kikuchi free
energy  conditioning constraint set implicitly assumed 
one way proceed make use  consistency  constraints express kikuchi
free energy terms outer region pseudo marginals study convexity 
approach along lines  particular  replace inner region pseudomarginals correspond concave contributions outer region pseudo marginals 
pseudo marginals corresponding convex contributions concern  fact  may
able use convex contributions well compensate concave
contributions 
make reasoning precise  define positive regions  or perhaps better 
nonnegative  r    r    r  c    i  negative regions r  
r   r  c        idea  formulated following theorem 
kikuchi free energy convex compensate concave contributions
negative regions r convex contributions positive regions r   
theorem      kikuchi free energy convex set constraints    
exists allocation matrix positive regions r  negative regions
r satisfying
    

  used compensate  

  a 

 
x
c

 positivity 

  b 

 sufficient amount resources 

  c 

 sufficient compensation 

  d 

r 



x

 c  

r



   

fiefficient minimization kikuchi free energy

proof first all  note worry energy terms
linear q  words  prove theorem restrict showing
minus entropy


x
x
s q   
c  q  
 c  s  q  
r 

r

convex set constraints 
intermediate step  let us consider combination convex entropy contribution
positive region r  concave entropy contribution negative inner region
r   subset  
x
x
 q   s  q   q    
q  x   log q  x  
q  x   log q  x  
x

 

x

q  x   log q  x  

 

x

q  x   log q  x  

x

x

x

x

x



q  x  

x

x 



q  x   x   log q  x   x    

used standard definitions
x
q  x  
q  x   q  x   x  
q  x  
 
q  x  
x
 

first step  applied constraint q  x     q  x   extended summation
x second term summation x   second step basically turned
difference two entropies  a weighted sum of  conditional entropies 
difference   depends q   is  lemma a   appendix a  convex
q   words  concave contribution fully compensated convex
contribution   yielding overall convex term relevant set constraints 
resulting operation matter resource allocation  concave contribution  c  s find convex contributions compensate it  let denote
amount resources take positive region r  compensate
negative region r   obviously  positive region compensate negative regions
contains      subset   explains condition   a  
now  shorthand notation little bit rewriting


x
x
 c  s
c
s q   
r 

 

x

r 

 

x

r 



c



c

r

x

 



x



x











x x

r 

   

x

r





x

 



 s  

x



x

r






 c  

x





 c    

fiheskes

p
convexity first term guaranteed
p c     c   second term
    b   third term  c       d  

    checking conditions

checking conditions theorem     cast form linear programming
problem  example follows  define auxiliary variable replacing condition   c 

x
   
   c   r  variable compensation 


solve linear programming problem attempts maximize single variable constraints implied four conditions  interpretation
try use available resources compensate much concave contributions
can  find solution   conditions satisfied  kikuchi free energy
convex set constraints unique minimum  optimal turns
smaller    matrix satisfying constraints convexity
kikuchi free energy guaranteed theorem     
instead solving linear program  often get away simpler checks 
example  guess particular check whether conditions     hold  obvious
choice
x
c
  n
  

n
r  


satisfies condition   c  substituted   d  yields condition
x

c  

r   

c
 
n


r  

   

similarly  choice
 

x
 c  
 

n

 

n 

r  
 

satisfies condition   d  yields condition
x

r  

c
  c   r 
n 


    

substituted   c            holds  theorem     guarantees convexity
kikuchi free energy 
two conditions sufficient  necessary theorem     apply 
necessary condition
x
x
c  
    
c  
r

r 

easily derived summing condition   d  r substituting condition   c   condition      fails  cannot use theorem     prove convexity
kikuchi free energy 

   

fiefficient minimization kikuchi free energy

would conjecture conditions theorem     sufficient 
necessary convexity kikuchi free energy  pursue
here  irrelevant current purposes  furthermore  may
relevant practice either  since convexity sufficient necessary condition unique minimum  tatikonda jordan         heskes         ihler 
fisher  willsky        give conditions convergence loopy belief propagation
uniqueness minimum corresponding bethe free energy  conditions
depend graphical structure   strength the  kernels  x   
    related work
chiang forney        present similar ideas  convex entropy terms compensating
concave terms set constraints  derive conditions convexity bethe
free energy pairwise potentials  resulting conditions formulated terms
single node marginals  may difficult validate practice generalize
kikuchi case 
closely related theorem     following theorem pakzad anantharam
             
theorem       pakzad   anantharam              kikuchi free energy     convex
set consistency constraints imposed collection regions r  and hence
constrained minimization problem unique solution  overcounting numbers c
c satisfy 
x
x
r 
c  
c    
    
r s 
s 



words  subset r  sum overcounting numbers elements
ancestors r must nonnegative 
fact  using halls        matching theorem  shown conditions    
theorem     equivalent conditions      theorem      latter
direct require solution linear program 
theorem     theorem     used show bethe free energy
graphs single loop convex set constraints  heskes        mceliece  
yildirim        pakzad   anantharam              
    minimization convex kikuchi free energy
kikuchi free energy convex  guaranteed unique minimum 
minimum relatively easy find message passing algorithm similar
standard  loopy  belief propagation 
basic idea follows  focus case overcounting numbers
positive  case negative overcounting numbers involved worked
appendix b  furthermore  rest paper ignore positivity
constraints   a   easy check satisfied solutions obtain 
introduce lagrange multipliers  x   consistency constraints well

   

fiheskes

normalization constraints construct lagrangian


xx
x
l q      fkikuchi  q   
q  x  
 x   q  x  
 


 

x




x  

x

 

x
x



q  x    

    

minimization kikuchi free energy appropriate consistency normalization constraints is  terms lagrangian  equivalent
min fkikuchi  q    min max l q     
q

qq



minimization q unconstrained  standard results constrained
optimization  e g   luenberger        tell us
min max l q    max min l q     
q





q

equality convex problems linear equality constraints  is  convex
problems allowed interchange maximum minimum q 
furthermore  optimal q    corresponding minimum lagrangian     
function unique  since l q    convex q   substitution solution
yields so called dual
l    min l q      l q        

    

q

dual concave unique maximum 
many algorithms used find maximum dual       particular
one  derived appendix b  given algorithm    slightly differs presented
yedidia et al         yuille        sending messages  messages directly related
lagrange multipliers  inner regions outer regions  i e   never
inner regions subsets inner regions  price one pay update
line   depends overcounting number c   bethe free energy  c     n  
obtain standard  loopy  belief propagation update rules  particular ordering
algorithm    running inner regions updating messages inner
region neighboring outer regions  guarantees dual      increases
iteration    local partition functions z z lines      chosen
normalize pseudo marginals q  x   q  x    normalization strictly
necessary  helps prevent numerical instability  algorithm   initialized
setting messages  x       skipping lines     first iteration 
   positive overcounting numbers c   argumentation negative overcounting numbers
complicated may require damping updates achieve convergence  see appendix b details 

   

fiefficient minimization kikuchi free energy

algorithm   message passing algorithm constrained minimization kikuchi free
energy 
  

converged

  



  
  

o 
x
q  x    
q  x  
x 

  

 x    

q  x  
 x  

  

end

  

q  x    

  

o 
q  x  
 x    
 x  

 
q  x    
 x  
 x  
z
i 

 
n  c
 
 x  
z o 


  
   



   

end

   

end

   

end

   double loop algorithms guaranteed convergence
even kikuchi free energy convex  still run algorithm  
hope converges fixed point  fixed point must correspond
extremum kikuchi free energy appropriate constraints  yedidia et al  
       even better  empirically general kikuchi free energy provably
bethe free energy  heskes         extremum fact minimum  however  practice
single loop  algorithm always converge resort double loop
algorithms guarantee convergence minimum kikuchi free energy 
    general procedure
introduce class double loop algorithms based following theorem 
   note single loop refers message passing algorithm nothing
notion single loop graphical model 

   

fiheskes

theorem      given function fconvex  q  q   properties
fconvex  q  q   fkikuchi  q 

q q q

fconvex  q  q    fkikuchi  q 

fconvex  q  q   fifi
fkikuchi  q 
 
q
q
q  q

fconvex  q  q   convex q q

 bound 

   a 

qq

 touching 

   b 

q q

 convex 

   c 

algorithm
qn     argmin fconvex  q  qn    

    

qq

qn pseudo marginals iteration n  guaranteed converge local minimum
kikuchi free energy fkikuchi  q  appropriate constraints 
proof immediate kikuchi free energy decreases iteration 
fkikuchi  qn     fconvex  qn     qn   fconvex  qn   qn     fkikuchi  qn    
first inequality follows condition    a   upper bound  second
definition algorithm  gradient property    b  ensures algorithm
stationary points gradient fkikuchi zero  construction qn q
n 
see figure   illustration algorithm proof  fact  convexity
fconvex used establish proof  but  argued section     
algorithmic point view constrained minimization convex functional much simpler
constrained minimization non convex functional  general idea  replacing
minimization complex functional consecutive minimization easier
handle upper bound functional  forms basis popular algorithms
em algorithm  dempster  laird    rubin        neal   hinton        iterative
scaling iterative proportional fitting  darroch   ratcliff        jirousek   preucil        
intuitively  tighter bound  faster algorithm 
    bounding concave terms
first step  lay main ideas  build convex bound removing concave
entropy contributions   so  make use linear bound
x
x

q  x   log q  x  
    
q  x   log q  x    
x

x

directly follows
 

kl q   q  

 

x
x

 

q  x  
q  x   log
q  x  

   

 

fiefficient minimization kikuchi free energy

   
   

   

figure    illustration proposed algorithm corresponding convergence proof 
iteration n  fconvex  q  qn    dashed line  convex bound non convex
fkikuchi  q   solid line   touch qn   point      fconvex  qn   qn    
fkikuchi  qn   
minimum  point      fconvex  qn     qn  
fconvex  qn   qn    corresponding kikuchi free energy  point      obeys
fkikuchi  qn     fconvex  qn     qn   bounding property 

kl kullback leibler divergence  choice fconvex reads

x
xx
x
q  x  
   

fconvex  q  q    
q  x   log
q  x   log q  x  
c
 
 x  
x
x
i 


x
x
x
x
 c    
q  x         
 c  

q  x   log q  x    




x

x

easy check functional properties    a     c   last term
added fulfill property    b   next make crucial observation that  using
   
constraints     fixed q   rewrite fconvex normal form     

x x
xx
q  x  
   
fconvex
 q  q    
q  x   log
 
c
q  x   log q  x     c q        

 x
 


x
x


c q  evaluates zero q q   implicitly depends q  
c defined

x  c  
 

log q  x   c
 
    
log  x   log  x    
c i 
n
 



is  always incorporate terms linear q energy term
redefinition potentials  chosen distribute terms equally
n neighboring outer regions  choices possible well 
   

fiheskes

term c q       evaluates zero q q thus irrelevant
optimization inner loop  consists terms last one     
   
serve make bound fconvex satisfy    b   construction bounds below 
ignore terms  affect algorithm way   
   
fconvex convex normal form  use algorithm  
solve constrained problem       resulting double loop algorithm described
two lines 
outer loop  recompute      q   qn  
inner loop  run algorithm   c c  yielding qn    
inner loop  initialize messages converged values previous
inner loop 
    bounding convex terms
section show many cases make algorithm better
simpler  idea bound concave  convex entropy
contributions inner regions  is  enforce c   set


xx
q  x  
   

fconvex  q  q    
q  x   log
 
    
 x  
x

log  x   log  x  

x c
log q  x    
n

    



   

let us first explain algorithm based fconvex simpler one based
      reference inner regions disappeared  fact  constraints
care outer regions pseudo marginals agree
intersections  consequently  inner loop  algorithm     run
inner regions direct intersections outer regions  is 
exist outer regions x   x x   similar arguments
used algorithm based      well  neglecting negative inner regions
correspond direct intersections outer regions  practice  however 
negative inner regions direct intersections outer regions  whereas many positive
inner regions arise next level  intersections intersections  see instance
example figure    six negative inner regions direct intersections outer
regions  contrast four positive inner regions 
   
      applied positive inner regions  clear fconvex  q  q  
   
   
   
fconvex  q  q    bound  fconvex tighter bound fconvex expect
   
algorithm based fconvex perform better  remains shown
   
conditions fkikuchi  q  fconvex  q  q    following theorem comes in 
   
fconvex  

   alternatively  could relax condition    b  statement gradients fconvex fkikuchi
equal subspace orthogonal constraints  milder condition  c q 
well last term      longer needed 

   

fiefficient minimization kikuchi free energy

theorem      functional fconvex      convex bound kikuchi free energy     exists allocation matrix negative inner regions
positive inner regions i  satisfying
    

  used compensate  

   a 

 
x
 c  

 positivity 

   b 

 sufficient amount resources 

   c 

 sufficient compensation 

   d 





x

c

i 



proof surprisingly  proof follows line reasoning proof theorem      first consider combination concave entropy contribution
     convex entropy contribution i     
x
x

q  x   log q  x    
q  x   log q  x  
x

x



x

q  x   log q  x    

x

x

q  x   log q  x    

    

x

follows

q  x   x  
 
q  x   q  x   x  
q  x   x  
x



x
q  x  
q  x   q  x  
 
q  x  
log
 
 x  
q
 x
 
q
 x
 
q






x
x







recognize term braces kullback leibler divergence two
probability distributions 
   
show difference fconvex fkikuchi nonnegative 
able compensate concave contributions c i  convex contributions   without exceeding available amount resources
 c    shorthand notation 
 
 
x
q  x  
k
 
q  x   log
q  x  
x


decomposition
x
x
x
   
fconvex
fkikuchi  
c k  
c k
 c  k


 

x





 c  

x





k  



x x

i 

 k k    



x

i 

   




x





c k    

fiheskes

      
 

 

 

 

 

    

     

     

     

    

 

 

 

   
 

    

    

    

   

   

   

   

   

   

   

   

   

   

                           

 

 

 

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 a  outer regions 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 b  region graph 
figure    smallest example showing conditions theorem     need always
hold region graph overcounting numbers constructed cluster
variation method   a  visualization outer regions  black means
variable       part outer region       
 b  region graph overcounting numbers boldface  positive overcounting numbers third level outweigh negative overcounting numbers second level 

inequality follows since terms guaranteed nonnegative
conditions      satisfied 
above  conditions theorem     checked linear program 
generated many different sets overcounting numbers resulting moebius formula      started wondering whether conditions      perhaps automatically satisfied  however  exhaustively checking possible outer region combinations given fixed
number variables  come counterexample  smallest counterexample
violates conditions theorem      illustrated figure   
even if  counterexample  positive inner regions compensated
negative inner regions  pay get rid many possible  finding optimal
assignment may complex problem  heuristics easy find  see appendix c  
    pulling tree
   

previous section tightened convex bound fconvex kikuchi free energy
fkikuchi bounding convex contributions positive regions well  another way
get tighter bound bound part concave contributions negative

   

fiefficient minimization kikuchi free energy

inner regions  first illustrate considering bethe free energy  i e  
non overlapping negative inner regions  nodes  c     n  
bethe free energy convex singly connected structures  inspired teh
welling         choose set nodes ibound remaining nodes ifree
become singly connected take


xx
x
x
q  x  
   

fconvex  q  q    
q  x   log
 
   n  
q  x   log q  x  
 x  
x
x
ifree
x
x
 
   n  
    
q  x   log q  x    
ibound

x

is  bound entropy terms corresponding bounded nodes ibound
simply keep entropy terms correspond free nodes ifree   construction
fconvex satisfies conditions       furthermore  rewritten normal form    
definitions

x   n
 
ibound

log  x   log  x  
 
log q  x   c
 

n
n
ifree

 
bound



note resulting inner loop algorithm completely equivalent running standard belief propagation tree free nodes  send messages
bounded nodes ibound well enforce constraints q  x     q  x  
   
rather pulling single tree  pull convex combination
trees  is  suppose several bounds  result pulling
particular tree corresponding set overcounting numbers ci  
convex combination
x
x
c  
wi ci wi  
wi    




corresponds convex bound  generally  combine ideas
previous section choosing c resulting bound convex 
procedure given appendix c  basically  first try shield much
concave entropy contributions convex entropy contributions can  next 
tighten bound incorporating convex contributions linear bounds
concave contributions manage shield first step  steps
cast form easy solve linear programming problem 
    related work
   

double loop algorithm described section     based fconvex closely related
yuilles        cccp  concave convex procedure  algorithm  although originally formulated completely different way  cccp applied minimization kikuchi free
energy understood particular case general procedure outlined
theorem      specifically  based bounding concave contributions
x
x
x
 c  
q  x   log q  x  
q  x   log q  x     c     
q  x   log q  x         
x

x

x

   

fiheskes

compared       is  bounding concave entropy contributions  part concave terms taken convex side  reason
cccp algorithm requires functional convex  independent
constraints involved    procedure  hand  makes use fact
functional convex set constraints  allows us use
tighter bounds  yielding efficient sometimes simpler algorithms  less important note  inner loop algorithm particular message passing scheme applied
yuille        somewhat different 
   
double loop algorithm based fconvex      inspired teh wellings
       ups  unified propagation scaling  algorithm  difference
bound entropy contributions nodes tree  ups nodes  and thus
entropy contributions  clamped values resulting previous inner loop 
is  inner loop ups algorithm corresponds minimizing


xx
x
x
q  x  
ups

fconvex  q  q    
q  x   log
 
   n  
q  x   log q  x  
 x  
x
x
ifree
x
x

   n  
q  x   log q  x    
iclamped

x

constraints
q  x     q  x   ifree     yet q  x     q  x   iclamped    
boils iterative scaling algorithm  relatively easy solve 
outer loop iteration  different choice made ifree iclamped   ups
algorithm understood coordinate descent guaranteed converge
local minimum bethe free energy  under appropriate conditions choices made
   
ifree iclamped    inner loop results fconvex allows changes
marginals q  x   ibound   i e   flexible make larger steps  loosely
   
ups   furthermore  approach
speaking  fconvex tighter bound fconvex
choose different subdivisions bounded free nodes
within inner loop 
wainwright  jaakkola  willsky      b      a  present similar ideas  exploiting
convexity bethe free energy tree structures  wainwright et al       b  use
tree structure obtain efficient implementation loopy belief propagation  without
however guaranteeing convergence  wainwright et al       a  show particular convex
combinations convex bethe free energies lead convex bounds exact helmholtz
free energy      bounds  overcounting numbers inner regions still follow
moebius relation      overcounting numbers outer regions smaller
equal    constrained minimization bound similar constrained
   
minimization fconvex algorithm used wainwright  jaakkola  willsky       
indeed closely related algorithm   
   procedure described yuille        often even moves part convex terms concave side 
makes  implicit  bound even worse corresponding algorithm slower  following
stick favorable interpretation cccp algorithm based implicit
bound      

   

fiefficient minimization kikuchi free energy

   simulations
intuitively  would expect algorithms based tightest bound converge
fastest terms outer loop iterations  however  larger steps outer loop 
might need inner loop iterations achieve convergence inner loop 
following simulations designed check this 
    general set up
simulations compare four different algorithms  based different
bound 
convex tightest bound kikuchi free energy convex  based
ideas described section     appendix c 
negative zero bound obtained setting negative overcounting numbers
zero  explained section     
zero bound described section     follows setting overcounting
numbers  negative positive  zero  models considered below 
overcounting numbers satisfy conditions theorem      i e   setting zero
indeed yields bound kikuchi free energy  note zero
equivalent negative zero bethe free energy 
cccp  rather favorable interpretation the  bound implicit yuilles        cccp
algorithm  explained section     
algorithm   applied inner loop algorithms  difference
setting overcounting numbers c implied bound 
inner loop runs preset convergence criterion met  specifically  end inner loop
inner region marginals change less       criterion algorithms
happened converge  probably would case looser criteria 
example  yuille        reports two inner loop iterations sufficient obtain
convergence 
simulations report kullback leibler  kl  divergence exact
approximate marginals  either summed nodes subset nodes  plots
different error functions look much same  kikuchi bethe free energy
somewhat less illustrative  close minimum  marginals
thus kl divergence still change considerably  visualize kl divergence
function outer loop iterations function floating point operations 
count necessary operations involved inner loop outer loop updates  i e  
involved convergence checks  computing kl divergence  on  
comparing number inner loop iterations used different algorithms meet
convergence criterion  scale outer loop iterations relative outer loop iterations
convex algorithm  is  number outer loop iterations used
algorithm reach particular level accuracy  consider corresponding number
outer loop iterations used convex algorithm reach level 

   

fiheskes

 a 

 b 
just convex
negative to zero
cccp
kldivergence

kldivergence

just convex
negative to zero
cccp
 

  

 

 

  

 

  

  
 

  

  
  
  
outerloop iterations

   

 

 

 
flops

 

 
 

x   

figure    bethe approximation     boltzmann grid  kullback leibler divergence
exact approximate single node marginals function outerloop iterations  a  floating point operations  b  three different algorithms 

done simulations quite number different problems problem instances  involving markov random fields bayesian networks  results shown
exemplary meant illustrate general findings summarize
below 
    bethe free energy boltzmann grid
first set simulations concerns minimization bethe free energy boltzmann grid     nodes pairwise interactions form


tj
ti
    
ij  xi   xj     exp wij   xi     xj        xi        xj   
ni
nj
ni number neighbors node i  i e     corner node    nodes
boundary    nodes middle  weights wij biases ti drawn
random normal distribution mean zero standard deviation     
bethe approximation outer regions pairs neighboring nodes 
figure   shows summed kl divergence exact approximate single node
marginals function number outer loop iterations  a  function
number floating point operations  b  convex  negative zero 
cccp algorithms  seen that  expected  convex algorithms converges
faster negative zero algorithm  converges faster cccp algorithm  speed up terms outer loop iterations translates almost equivalent
speed up terms flops  indeed  seen figure   a   number inner loop
iterations required convex algorithm slightly higher
two algorithms 
curves figure   a  mapped onto rough linear scaling
number outer loop iterations  suggested straight lines
   

fiefficient minimization kikuchi free energy

 

outerloop iterations

  

 b 
number innerloop iterations

 a 
just convex
negative to zero
cccp

 

  

 

  
 
  

 
 
 
 
 

 

just convex
negative to zero
cccp

  
outerloop iterations

  
  
  
  
outerloop iterations  scaled 

figure    bethe approximation     boltzmann grid   a  outer loop iterations
convex algorithm versus corresponding outer loop iterations
two algorithms   b  number inner loop iterations needed meet
convergence criterion function outer loop iterations  scaled according
 a  

figure   a   slope lines relate          by definition       
convex  negative zero cccp  respectively  see convergence rates
table     following argumentation shows striking correspondence
numbers respective bounds 
negative overcounting numbers
p
bethe free energy fkikuchi
p add c        respective convex
bounds fconvex   sums c               translate
fraction negative overcounting mass bounded  i e  
p
p
c
c
p
 
c

obtain  respectively          by definition         is  appears
almost linear relationship tightness bound  here expressed fraction
concave entropy contributions bounded linearly  speed convergence 
noticed almost linear relationship simulations involving
bethe free energy  no positive overcounting numbers  
    kikuchi free energy boltzmann grid

second set simulations    boltzmann grid  outer regions
chosen squares four neighboring nodes  potentials form     
weights biases drawn normal distribution standard deviation       
respectively  note size weights much larger previous set
simulations  make problem still bit challenge kikuchi approximation 
weights  bethe approximation badly  summed kullback leibler
   

fiheskes

 a 

 b 

 

 

  
just convex
negative to zero
all to zero
cccp

 

  

kldivergence

kldivergence

  

 

  

just convex
negative to zero
all to zero
cccp

 

  

 

  

 

   
   
   
outerloop iterations

   

 

 

  
flops

  
 

x   

figure    kikuchi approximation     boltzmann grid  kullback leibler divergence
exact approximate single node marginals function outerloop iterations  a  floating point operations  b  four different algorithms 

divergence larger      bethe kikuchi algorithm  singleloop algorithm convergence problems  bethe approximation typically gets
stuck limit cycle kikuchi approximation tends diverge  total
         outer regions               negative inner regions  all node pairs
correspond intersections outer regions           positive inner regions
 all single nodes correspond intersections node pairs  
figure   shows kl divergence approximate exact single node marginals
four different algorithms terms outer loop iterations  a  floating point
operations  b   seen ordering  a  expected  tighter
bound  faster algorithm  terms floating point operations  convex
zero algorithm get much closer together 
part explanation given figure    convex algorithm requires considerably inner loop iterations meet convergence criterion 
effect zero algorithm inner loop runs     negative
inner regions instead     positive negative inner regions  makes
inner loop iteration zero requires factor     less floating point operations
inner loop iteration three algorithms 
difficult find quantitative relationship tightness
bounds  asymptotic  convergence rates  one complications
negative  positive overcounting numbers play role  case 
algorithms still seem converge linearly  faster convergence rates tighter bounds 
convergence rates  expressed time scale corresponding exponential decay
 kl t  kl   exp t     outer loop iterations   summarized
table   

   

fiefficient minimization kikuchi free energy

 

outerloop iterations

  

 b 
number innerloop iterations

 a 
just convex
negative to zero
all to zero
cccp

 

  

 

  

 

  
 
  

  
  
  
  
 
 

 

  
outerloop iterations

just convex
negative to zero
all to zero
cccp

 

  
  
  
  
outerloop iterations  scaled 

figure    kikuchi approximation     boltzmann grid   a  outer loop iterations
convex algorithm versus corresponding outer loop iterations
three algorithms   b  number inner loop iterations needed meet
convergence criterion function outer loop iterations  scaled according
 a  

figure    graphical structure qmr like network 
    qmr network
third set simulations concerns qmr like  quick medical reference  bayesian
network  heckerman        jaakkola   jordan         bipartite graph layer
disease nodes layer findings  particular network used simulations
generated bayes net toolbox  murphy         contains    finding nodes 
   observed  positive      hidden disease nodes  see figure    diseases
bernoulli probability distributions prior drawn random        
findings noisy or conditional probability distributions without leakage  diseases
findings linked randomly probability      absence leakage  large amount
findings  strong connectivity make relatively difficult inference problem 
outer regions take subsets implied conditional probability distribution  i e  
outer region consists disease findings linked it  figure   gives
corresponding region graph 

   

fiheskes

                                
                                                                   
 

 

 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 
 

figure    region graph resulting qmr like network 

 a 
just convex
negative to zero
all to zero
cccp

  

  

 

  

 

   
   
   
outerloop iterations

just convex
negative to zero
all to zero
cccp

 

kldivergence

 

kldivergence

 b 

   

 

  

 

 

 

 
flops

 

  
 

x   

figure     kikuchi approximation qmr like network  kullback leibler divergence
exact approximate single node marginals function outerloop iterations  a  floating point operations  b  four different algorithms 

   

fiefficient minimization kikuchi free energy

 b 
number innerloop iterations

outerloop iterations

 a 
just convex
negative to zero
all to zero
cccp

 

  

 

  

 

  
 
  

  

  
  
  
  
 
 

 

  
outerloop iterations

just convex
negative to zero
all to zero
cccp

  

 
  
  
outerloop iterations  scaled 

  

figure     kikuchi approximation qmr like network   a  outer loop iterations
convex algorithm versus corresponding outer loop iterations
three algorithms   b  number inner loop iterations needed meet
convergence criterion function outer loop iterations  scaled according
 a  

original
convex
negative zero
zero
cccp

    
    
 
 
  

bethe
 

 
 
   
      
      
      

kikuchi
 

       
   
 
  
    
  
 
 
  
          

   
   
 
 
  

qmr
 

  
  
 
  
  
 
  
      

table    summary asymptotic convergence   time constant  time outerloop iterations  exponential decay  sums negative positive overcounting numbers original kikuchi bethe free energy convex bounds
used different algorithms 

results found figure        comparable
kikuchi approximation boltzmann grid  single loop algorithm fails
converge  convex algorithm converges much faster three algorithms  requires inner loop iterations less efficient zero algorithm  makes latter preferable terms floating point operations  however 
relatively straightforward speed up convex algorithm  first  probably
need many inner loop iterations outer loop converge properly 
secondly  bound part entropy contribution  efficient choice
would many zero overcounting numbers possible 

   

fiheskes

    general findings
summarize points illustrated
encountered many simulations well 
tighter  convex  bound used inner loop  faster convergence
terms outer loop iterations 
number outer loop iterations needed meet prespecified convergence criterion tends decrease looser bound  never nearly enough compensate
slower convergence outer loop 
fact  observed strong dependency number inner loop
iterations tightness bound bound convex problem
hard sense single loop algorithm would fail converge 
terms floating point operations  looser bound sets overcounting numbers
inner loop zero  beat tighter bound negative overcounting numbers 
slower convergence terms outer loop iterations compensated
efficient inner loop 
pelizzola        tests several convergent algorithms kikuchi approximations problems statistical physics reports similar findings  study  convex algorithm  described first time heskes  albers  kappen         clearly outperforms competitors 

   discussion
article based perspective interested minima kikuchi
free energy appropriate constraints  finding minimum becomes possibly non convex constrained minimization problem  here  well studies 
approach solve non convex problem sequential constrained minimization convex bounds kikuchi free energy  presumption tighter
bounds yield faster algorithms  worked several ideas construct tight convex
bounds  simulation results article well obtained pelizzola       
clearly validate presumption show speed ups significant 
heskes  zoeter  wiegerinck        apply bounds  approximate  parameter
learning directed graphical models 
double loop algorithms considered article based convex bounds
kikuchi free energy  principle  necessary  concern
inner loop algorithm converges might well case tighter bounds  one
practical solution simply choose  tight  bound kikuchi free  check whether
inner loop algorithm converge  restart looser bound not  alternatively 
construct tighter bounds making use conditions guaranteed convergence
belief propagation derived tatikonda jordan         heskes        
ihler et al         bethe approximation 
suggested non convergence single loop generalized loopy belief propagation indication kikuchi bethe approximation inaccurate 
   

fiefficient minimization kikuchi free energy

results section         show need always case  apparently 
exist middle range problems kikuchi free energy easy minimize  yield decent approximations  problems algorithms
described article useful 

acknowledgments
author would thank wim wiegerinck  onno zoeter  kees albers  bert kappen fruitful discussions anonymous reviewers constructive comments 
work supported part dutch technology foundation stw 

appendix a  convexity difference two entropies
appendix treats two lemmas convexity difference two entropies 
first one used proof theorem      similar lemma used mceliece
yildirim        
lemma a    difference two entropies
x
x
q  x   log q  x  
q  x   log q  x  
 q  
x

x

 

x
x

convex q  



q  x  

x

x 



q  x   x   log q  x   x  

proof take step backwards write

 q    

x
x





q  x  
 
q  x   log
x

q  x  

x 

taking derivatives  best interpret table q   specifying value q  x  
possible realization x   vector x playing role index  taking second
derivatives  obtain
hx  x  q  

   q  
 
 
 
 
ix  x

q  x  q  x  
q  x   q  x   x  x

ix x   elements x x equal zero otherwise 

   

fiheskes

next would show matrix positive semi definite  i e  
tables q  interpreted vectors indices x  
 

x

q x  hx  x  q  q x    

x  x

x


x q    x   x  
x

 

 

q  x    x  
x x


 

x q x  q x  


q  x  
q  x   x  x

x  x



q x    x  q x    x  

x q    x  

x

x   x 



q  x  


i 
hp



x x q    x    x  
x  q x    x  
 
p
 

q  x    x  

x  q  x    x  
x x





 

cauchys inequality 

x

a k

k

x

b k

k

 

x
k

ak bk

  

 

follows term braces indeed semi positive q
realization x  
see this  make substitutions x  k  q x    x    q  x    x   ak  
q
q  x    x   bk find
       

x
k

a k

p
 
k ak bk  
p
  
 
k bk
 

following related lemma used appendix b 

lemma a    difference two entropies
x
x
 q   q  
q  x   log q  x  
q  x   log q  x  
x

x

convex  q   q   
proof hessian matrix components
hx  x



   q  
 
 
ix  x

q  x  q  x  
q  x  

hx  x



   q  
 

 


q  x  q  x  
q  x   x  x

hx  x



q  x  
   q  
 

   

q  x  q  x  
q  x   x  x

   

fiefficient minimization kikuchi free energy

convexity requires q    q  x    q  x    
q  x   q  x  

 
 

x q   x  

 

hx  x
hx  x

hx  x
hx  x

x q  x  q  x  

q  x  


x
q  x   q  x    

 
q  x  
 
q  x   q  x  
x
x

q  x  



x

 

 

q  x  
q  x  



x q  x  q   x  
q   x  

x



appendix b  minimizing convex kikuchi free energy
appendix  derive algorithm   minimizing convex kikuchi free energy
appropriate linear constraints  simplify notation  use convention runs
outer regions  inner regions 
first  note principle necessary explicitly take account
constraints      since constraints implied others  obviously  constraint
two inner region marginals 
q  x     q  x    
implied corresponding constraints inner region marginals outer
region subsuming inner regions 
q  x     q  x   q  x     q  x    
is  take account constraints inner regions
inner regions  similarly  normalization constraints outer region pseudo marginals follow
normalization constraints inner region pseudo marginals  so  sufficient set
constraints
x
q  x  

q  x     q  x   q  x    
x 

x

q  x      

 

x

introducing lagrange multipliers  x   corresponding constraints 
obtain lagrangian
x x

xx
q  x  
q  x   log q  x  
 
c
l q     
q  x   log
 x  
x
x





xxx
x
x
x
 
 x   q  x  
q  x    
 
q  x      b   
x

x 

   



x

fiheskes

convex independent constraints
let us first consider case overcounting numbers c strictly positive  c  
    then  lagrangian convex set constraints  convex
q independent constraints  minimization lagrangian respect
pseudo marginals follows setting derivatives zero  yielding

e  x  
 b   
q  x      x  e 


q  x  

 c  

  e



e  x   c  

 b   



following noted q q functions
lagrange multipliers   substituting solution back lagrangian  obtain
dual
x
xx
x x
l    l q        

q  x  
c
q  x    
 b   




x



x

now  consider optimizing l    respect subset components corresponding
inner region   collected      x    x    keeping
   fixed  concavity dual l     find maximum
direction setting corresponding derivatives zero  yields

l    fifi
  qnew  x   qnew  x       x  
 x   fi new

x
l    fifi
 
 

qnew  x        
 b   
fi new
x
q new refers solution  b     b     x   replaced new
 x  
new
 
since

 b   

new

qnew  x  

e  x  
   x   q  x    
e

solution new
 x   must obey
new
new
 x     log q  x      x     log q  x    

still solve qnew  x    summing expression   substituting  b     solving qnew  x   get
log qnew  x    

x
 
 
 log q  x    x     
 new c    
n   c
n   c


now  obtain exactly updates algorithm   define
 x     e  x    x     q  x  e  x    
   

fiefficient minimization kikuchi free energy

properly normalize q  x    line    normalization q  x   line   
fact unnecessary  since construction updates ensure q  x     q  x  
z     
bottom line particular ordering algorithm   joint update
messages particular subset interpreted coordinate wise gradient
ascent dual l     updating lagrange multipliers  x   particular
time  therefore algorithm   guaranteed converge
unique maximum case positive overcounting numbers c  
convex set constraints
next  let us consider general case  some of  overcounting numbers
negative  kikuchi free energy still convex set constraints 
consider case inner region overcounting numbers negative   
show that  sufficient damping updates  algorithm   still guaranteed
converge unique minimum kikuchi free energy set constraints 
note direct application argumentation fails  solution  b   
q  x   negative c corresponds maximum rather minimum  consequently  dual l     b    need concave  updates algorithm  
follow setting derivatives zero interpreted fixed point iterations  coordinate ascent l     still  practice seem work fine indeed without
always increasing l     following explain why  argue updates algorithm   correspond coordinate ascent  rather something
coordinate descent ascent convex concave saddle function  sufficient damping 
algorithm converge unique saddle point  corresponds
minimum kikuchi free energy set constraints 
convexity set
p according theorem      exists
p constraints implies 
matrix    c      using q  x     q  x    replace
lagrangian  b   

xx
xx
x
q  x  
l q     
q  x   log
q  x   log q  x  


 x  
x
x





xxx
x
x
x
x
 
 
 x  
q  x  
q  x    
 
q  x      b   
n
x
x
x








 



since  lemma a   appendix a 
x
x
q  x   log q  x  
q  x   log q  x  
x

x

convex  q  x    q  x     lagrangian  b    indeed convex q independent
constraints  thus could apply argumentation above  find minimum
   argumentation hold negative inner region entropy contributions
compensated positive inner region subset entropy contributions prove convexity kikuchi free
energy  case  might need slightly different algorithm guarantee convergence 

   

fiheskes

convex lagrangian respect q  substitute corresponding solution q    back
lagrangian obtain concave dual l     maximize dual respect
  problem closed form expression optimal q   
thus closed form expression dual l     makes procedure
rather awkward 
instead  distinguish outer region marginals  collected qo  
inner region marginals  collected qi   rewritten consistency constraint terms
outer region marginals alone  replace constrained minimization respect
qo unconstrained maximization respect corresponding lagrange multipliers
  leaving minimization respect qi normalization constraint
is  gives us saddle point problem type minqi maxo   even without explicitly
writing equations  tell maximization respect particular
corresponds finding
qnew  x     qnew
 x  

   

then  minimization respect q given fixed qnew  x   immediately yields
x
qnew  x    
qnew  x  


properly normalized sum    exactly updates particular inner
region algorithm   amount to  yield unique maximum respect
minimum respect q   keeping q    fixed 
coordinate descent ascent procedure works fine saddle function convex minimizing parameter concave maximizing parameter  e g   seung 
richardson  lagarias    hopfield         concavity immediate  convexity
qi follows convexity lagrangian  b    q    qo   qi    minimizing
overall convex function parameters  qo   yields convex function
remaining parameters  qi   technically  convergence unique solution
saddle point problem proven construction lyapunov function
decreases infinitesimal updates parameters descent ascent direction
zero unique saddle point  seung et al          convergence guaranteed
sufficiently damped updates  full ones algorithm    empirically full updates  correspond full maximization minimization one inner region
moving next one  work fine cases  occasionally indeed require little
damping  wainwright et al         successfully apply damping similar algorithm
attempt minimize convexified bethe free energy 

appendix c  constructing tight convex bound
appendix  describe procedure constructing tight convex bound fconvex
kikuchi free energy fkikuchi   combines ideas section          is 
first convexify kikuchi free energy  bounding little concave contributions
negative inner regions possible  next  terms bound anyways 
try incorporate many convex contributions can  leads following
procedure 
   

fiefficient minimization kikuchi free energy

consider minus entropy
 


x

 





x

c  

x

c

 



i 






choose c c first term



x
x

x
x
c
c  
 c c  s  
 
 



i 





 just  convex 

corresponding allocation matrix theorem      define used resources
x
 c   c  
c


rewrite
 


x


 





c  




x


x

x

c

i 

 c c  s  

x

i 



construction  first term still convex 





 c c  s




 



guarantee convexity  bound entropy contributions second
term   make bound tighter  include many convex
contributions can  still satisfying conditions theorem      call
corresponding overcounting numbers c c c c put remaining
c c back first term 


x

x
x
c
 
c  
 


i 



x

x

 c c  s  
 c c  s  


i 



choose fconvex first term plus linear bound second term 

find c first step similarly c third  use linear program
similar one described section     checking conditions theorem     
introduce slack variables replace condition   d 
x
   variable compensation   


   

fiheskes

similar spirit      furthermore  add inequality constraints  cp
 
 no need compensate  c    search maximum
 compensate much possible   terms corresponding solution   set c  
c  

references
aji  s     mceliece  r          generalized distributive law free energy minimization  proceedings allerton conference communication  control 
computing 
besag  j          spatial interaction statistical analysis lattice systems  journal
royal statistical society series b             
chiang  m     forney  g          statistical physics  convex optimization sum
product algorithm  tech  rep   stanford university 
darroch  j     ratcliff  d          generalized iterative scaling  annals mathematical
statistics               
dechter  r   kask  k     mateescu  r          iterative join graph propagation  darwiche  a     friedman  n   eds    proceedings uai       pp         
dempster  a   laird  n     rubin  d          maximum likelihood incomplete data
via em algorithm  journal royal statistical society b          
hall  p          representatives subsets  journal london mathematical society 
         
heckerman  d          tractable inference algorithm diagnosing multiple diseases 
kanal  l   henrion  m   shachter  r     lemmer  j   eds    proceedings fifth
workshop uncertainty artificial intelligence  pp          amsterdam  elsevier 
heskes  t          stable fixed points loopy belief propagation minima bethe
free energy  becker  s   thrun  s     obermayer  k   eds    advances neural
information processing systems     pp          cambridge  mit press 
heskes  t          uniqueness loopy belief propagation fixed points  neural
computation               
heskes  t   albers  k     kappen  b          approximate inference constrained optimization  uncertainty artificial intelligence  proceedings nineteenth
conference  uai        pp          san francisco  ca  morgan kaufmann publishers 
heskes  t   zoeter  o     wiegerinck  w          approximate expectation maximization  thrun  s   saul  l     scholkopf  b   eds    advances neural information
processing systems     pp          cambridge  mit press 
ihler  a   fisher  j     willsky  a          loopy belief propagation  convergence
effects message errors  journal machine learning research            
jaakkola  t     jordan  m          variational probabilistic inference qmr dt
network  journal artificial intelligence research             
   

fiefficient minimization kikuchi free energy

jirousek  r     preucil  s          effective implementation iterative proportional fitting procedure  computational statistics data analysis             
jordan  m   ghahramani  z   jaakkola  t     saul  l          introduction variational
methods graphical models  jordan  m   ed    learning graphical models 
pp          kluwer academic publishers  dordrecht 
kikuchi  r          theory cooperative phenomena  physical review              
kschischang  f   frey  b     loeliger  h          factor graphs sum product algorithm  ieee transactions information theory                 
lauritzen  s          graphical models  oxford university press  oxford 
luenberger  d          linear nonlinear programming  addison wesley  reading 
massachusetts 
mceliece  r   mackay  d     cheng  j          turbo decoding instance pearls
belief propagation algorithm  ieee journal selected areas communication 
               
mceliece  r     yildirim  m          belief propagation partially ordered sets 
gilliam  d     rosenthal  j   eds    mathematical systems theory biology  communications  computation  finance  pp          springer  new york 
murphy  k          bayes net toolbox matlab  computing science statistics 
           
murphy  k   weiss  y     jordan  m          loopy belief propagation approximate
inference  empirical study  laskey  k     prade  h   eds    proceedings
fifteenth conference uncertainty articial intelligence  pp          san
francisco  ca  morgan kaufmann publishers 
neal  r     hinton  g          view em algorithm justifies incremental 
sparse  variants  jordan  m   ed    learning graphical models  pp 
        kluwer academic publishers  dordrecht 
pakzad  p     anantharam  v          belief propagation statistical physics      
conference information sciences systems  princeton university 
pakzad  p     anantharam  v          estimation marginalization using kikuchi approximation methods  neural computation               
pearl  j          probabilistic reasoning intelligent systems  networks plausible inference  morgan kaufmann  san francisco  ca 
pelizzola  a          cluster variation method statistical physics graphical models 
journal physics a      r   r    
seung  s   richardson  t   lagarias  j     hopfield  j          minimax hamiltonian
dynamics excitatory inhibitory networks  jordan  m   kearns  m     solla  s 
 eds    advances neural information processing systems     pp          mit
press 
tatikonda  s     jordan  m          loopy belief propagation gibbs measures  darwiche  a     friedman  n   eds    uncertainty artificial intelligence  proceedings
   

fiheskes

eighteenth conference  uai        pp          san francisco  ca  morgan
kaufmann publishers 
teh  y     welling  m          unified propagation scaling algorithm  dietterich 
t   becker  s     ghahramani  z   eds    advances neural information processing
systems     pp          cambridge  mit press 
wainwright  m   jaakkola  t     willsky  a       a   new class upper bounds log
partition function  darwiche  a     friedman  n   eds    uncertainty artificial
intelligence  proceedings eighteenth conference  uai        pp          san
francisco  ca  morgan kaufmann publishers 
wainwright  m   jaakkola  t     willsky  a       b   tree based reparameterization
approximate estimation loopy graphs  dietterich  t   becker  s     ghahramani 
z   eds    advances neural information processing systems     pp           
cambridge  mit press 
wainwright  m   jaakkola  t     willsky  a          tree reweighted belief propagation
algorithms approximate ml estimation via pseudo moment matching  bishop 
c     frey  b   eds    proceedings ninth international workshop artificial
intelligence statistics  society artificial intelligence statistics 
yedidia  j   freeman  w     weiss  y          generalized belief propagation  leen 
t   dietterich  t     tresp  v   eds    advances neural information processing
systems     pp          cambridge  mit press 
yedidia  j   freeman  w     weiss  y          constructing free energy approximations
generalized belief propagation algorithms  ieee transactions information
theory               
yuille  a          cccp algorithms minimize bethe kikuchi free energies 
convergent alternatives belief propagation  neural computation               

   


