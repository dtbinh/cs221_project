journal of artificial intelligence research                  

submitted        published      

finding consensus bayesian network structures
jose m  pena

jose m pena liu se

adit
department of computer and information science
linkoping university
se       linkoping
sweden

abstract
suppose that multiple experts  or learning algorithms  provide us with alternative
bayesian network  bn  structures over a domain  and that we are interested in combining
them into a single consensus bn structure  specifically  we are interested in that the
consensus bn structure only represents independences all the given bn structures agree
upon and that it has as few parameters associated as possible  in this paper  we prove
that there may exist several non equivalent consensus bn structures and that finding one
of them is np hard  thus  we decide to resort to heuristics to find an approximated
consensus bn structure  in this paper  we consider the heuristic proposed by matzkevich
and abramson  which builds upon two algorithms  called methods a and b  for efficiently
deriving the minimal directed independence map of a bn structure relative to a given node
ordering  methods a and b are claimed to be correct although no proof is provided  a
proof is just sketched   in this paper  we show that methods a and b are not correct and
propose a correction of them 

   introduction
bayesian networks  bns  are a popular graphical formalism for representing probability distributions  a bn consists of structure and parameters  the structure  a directed and acyclic
graph  dag   induces a set of independencies that the represented probability distribution
satisfies  the parameters specify the conditional probability distribution of each node given
its parents in the structure  the bn represents the probability distribution that results
from the product of these conditional probability distributions  typically  a single expert
 or learning algorithm  is consulted to construct a bn of the domain at hand  therefore 
there is a risk that the so constructed bn is not as accurate as it could be if  for instance 
the expert has a bias or overlooks certain details  one way to minimize this risk consists
in obtaining multiple bns of the domain from multiple experts and  then  combining them
into a single consensus bn  this approach has received significant attention in the literature  matzkevich   abramson            b  maynard reid ii   chajewska        nielsen
  parsons        pennock   wellman        richardson   domingos        del sagrado
  moral         the most relevant of these references is probably the work of pennock
and wellman         because it shows that even if the experts agree on the bn structure 
no method for combining the experts bns produces a consensus bn that respects some
reasonable assumptions and whose structure is the agreed bn structure  unfortunately 
this problem is often overlooked  to avoid it  we propose to combine the experts bns
c
    
ai access foundation  all rights reserved 

fipena

in two steps  first  finding the consensus bn structure and  then  finding the consensus
parameters for the consensus bn structure  this paper focuses only on the first step  we
briefly discuss the second step in section     specifically  we assume that multiple experts
provide us with alternative dag models of a domain  and we are interested in combining
them into a single consensus dag  specifically  we are interested in that the consensus
dag only represents independences all the given dags agree upon and as many of them
as possible  in other words  the consensus dag is the dag that represents the most independences among all the minimal directed independence  mdi  maps of the intersection
of the independence models induced by the given dags   to our knowledge  whether the
consensus dag can or cannot be found efficiently is still an open problem  see the work of
matzkevich and abramson            b  for more information  in this paper  we redefine
the consensus dag as the dag that has the fewest parameters associated among all the
mdi maps of the intersection of the independence models induced by the given dags  this
definition is in line with that of finding a dag to represent a probability distribution p 
the desired dag is typically defined as the mdi map of p that has the fewest parameters
associated rather than as the mdi map of p that represents the most independences  see 
for instance  the work of chickering et al          the number of parameters associated
with a dag is a measure of the complexity of the dag  since it is the number of parameters
required to specify all the probability distributions that can be represented by the dag 
in this paper  we prove that there may exist several non equivalent consensus dags
and that finding one of them is np hard  thus  we decide to resort to heuristics to find
an approximated consensus dag  in this paper  we consider the following heuristic due to
matzkevich and abramson            b   see also the work of matzkevich and abramson
     a  for related information  first  let  denote any ordering of the nodes in the given
dags  which we denote here as g            gm   then  find the mdi map gi of each gi relative
to   finally  let the approximated consensus dag be the dag whose arcs are exactly
the union of the arcs in g            gm
   it should be mentioned that our formulation of the
heuristic differs from that by matzkevich and abramson            b  in the following two
points  first  the heuristic was introduced under the original definition of consensus dag 
we justify later that the heuristic also makes sense under our definition of consensus dag 
second   was originally required to be consistent with one of the given dags  we remove
this requirement  all in all  a key step in the heuristic is finding the mdi map gi of each
gi   since this task is not trivial  matzkevich and abramson      b  present two algorithms 
called methods a and b  for efficiently deriving gi from gi   methods a and b are claimed
to be correct although no proof is provided  a proof is just sketched   in this paper  we
show that methods a and b are not correct and propose a correction of them 
as said  we are not the first to study the problem of finding the consensus dag  in addition to the works discussed above by matzkevich and abramson            b  and pennock
and wellman         some other works devoted to this problem are those by maynard reid
ii and chajewska         nielsen and parsons         richardson and domingos        
   it is worth mentioning that the term consensus dag has a different meaning in computational biology
 jackson et al          there  the consensus dag of a given set of dags g            gm is defined as the
dag that contains the most of the arcs in g            gm   therefore  the difficulty lies in keeping as many
arcs as possible without creating cycles  note that  unlike in the present work  a dag is not interpreted
as inducing an independence model by jackson et al 

   

fifinding consensus bayesian network structures

del sagrado and moral         we elaborate below on the differences between these works
and ours  maynard reid ii and chajewska        propose to adapt existing score based algorithms for learning dags from data to the case where the learning data is replaced by the
bns provided by some experts  their approach suffers the problem pointed out by pennock
and wellman         because it consists essentially in learning a consensus dag from a
combination of the given bns  a somehow related approach is proposed by richardson and
domingos         specifically  they propose a bayesian approach to learning dags from
data  where the prior probability distribution over dags is constructed from the dags
provided by some experts  since their approach requires data and does not combine the
given dags into a single dag  it addresses a problem rather different from the one in this
paper  moreover  the construction of the prior probability distribution over dags ignores
the fact that some given dags may be different but equivalent  that is  unlike in the
present work  a dag is not interpreted as inducing an independence model  a work that
is relatively close to ours is that by del sagrado and moral         specifically  they show
how to construct a mdi map of the intersection and union of the independence models
induced by the dags provided by some experts  however  there are three main differences
between their work and ours  first  unlike us  they do not assume that the given dags
are defined over the same set of nodes  second  unlike us  they assume that there exists a
node ordering that is consistent with all the given dags  third  their goal is to find a mdi
map whereas ours is to find the mdi map that has the fewest parameters associated among
all the mdi maps  i e  the consensus dag  finally  nielsen and parsons        develop a
general framework to construct the consensus dag gradually  their framework is general
in the sense that it is not tailored to any particular definition of consensus dag  instead  it
relies upon a score to be defined by the user and that each expert will use to score different
extensions to the current partial consensus dag  the individual scores are then combined
to choose the extension to perform  unfortunately  we do not see how this framework could
be applied to our definition of consensus dag 
it is worth recalling that this paper deals with the combination of probability distributions expressed as bns  those readers interested in the combination of probability distributions expressed in non graphical numerical forms are referred to  for instance  the work
of genest and zidek         note also that we are interested in the combination before any
data is observed  those readers interested in the combination after some data has been
observed and each expert has updated her beliefs accordingly are referred to  for instance 
the work of ng and abramson         finally  note also that we aim at combining the given
dags into a dag  the consensus dag  those readers interested in finding not a dag but
graphical features  e g  arcs or paths  all or a significant number of experts agree upon may
want to consult the works of friedman and koller         hartemink et al          pena et
al          since these works deal with a similar problem 
the rest of the paper is organized as follows  we start by reviewing some preliminary
concepts in section    we analyze the complexity of finding the consensus dag in section
   we discuss the heuristic for finding an approximated consensus dag in more detail in
section    we introduce methods a and b in section   and show that they are not correct 
we correct them in section    we analyze the complexity of the corrected methods a and
b in section   and show that they are more efficient than any other approach we can think
of to solve the same problem  we close with some discussion in section   
   

fipena

   preliminaries
in this section  we review some concepts used in this paper  all the dags  probability
distributions and independence models in this paper are defined over v  unless otherwise
stated  if a  b is in a dag g  then we say that a and b are adjacent in g  moreover 
we say that a is a parent of b and b a child of a in g  we denote the parents of b in g
by p ag  b   a node is called a sink node in g if it has no children in g  a route between
two nodes a and b in g is a sequence of nodes starting with a and ending with b such
that every two consecutive nodes in the sequence are adjacent in g  note that the nodes in
a route are not necessarily distinct  the length of a route is the number of  not necessarily
distinct  arcs in the route  we treat all the nodes in g as routes of length zero  a route
between a and b is called descending from a to b if all the arcs in the route are directed
towards b  if there is a descending route from a to b  then b is called a descendant of a 
note that a is a descendant of itself  since we allow routes of length zero  given a subset
x  v  a node a  x is called maximal in g if a is not descendant of any node in x    a 
in g  given a route  between a and b in g and a route   between b and c in g     
denotes the route between a and c in g resulting from appending   to  
p
q
the number of parameters associated with a dag g is bv   ap ag  b  ra   rb     
where ra and rb are the numbers of states of the random variables corresponding to the
node a and b  an arc a  b in g is said to be covered if p ag  a    p ag  b     a   by
covering an arc a  b in g we mean adding to g the smallest set of arcs so that a  b
becomes covered  we say that a node c is a collider in a route in a dag if there exist two
nodes a and b such that a  c  b is a subroute of the route  note that a and b may
coincide  let x  y and z denote three disjoint subsets of v  a route in a dag is said to
be z active when  i  every collider node in the route is in z  and  ii  every non collider node
in the route is outside z  when there is no route in a dag g between a node in x and a
node in y that is z active  we say that x is separated from y given z in g and denote it
as x  g y z  we denote by x   g y z that x  g y z does not hold  this definition of
separation is equivalent to other more common definitions  studeny        section      
let x  y  z and w denote four disjoint subsets of v  let us abbreviate x  y as
xy  an independence model m is a set of statements of the form x  m y z  meaning
that x is independent of y given z  given a subset u  v  we denote by  m  u all the
statements in m such that x  y  z  u  given two independence models m and n   we
denote by m  n that if x  m y z then x  n y z  we say that m is a graphoid if
it satisfies the following properties  symmetry x  m y z  y  m x z  decomposition
x  m yw z  x  m y z  weak union x  m yw z  x  m y zw  contraction
x  m y zw  x  m w z  x  m yw z  and intersection x  m y zw  x  m
w zy  x  m yw z  the independence model induced by a probability distribution p 
denoted as i p   is the set of probabilistic independences in p  the independence model
induced by a dag g  denoted as i g   is the set of separation statements x  g y z  it is
known that i g  is a graphoid  studeny   bouckaert        lemma       moreover  i g 
satisfies the composition property x  g y z  x  g w z  x  g yw z  chickering  
meek        proposition     two dags g and h are called equivalent if i g    i h  
a dag g is a directed independence map of an independence model m if i g   m  
moreover  g is a minimal directed independence  mdi  map of m if removing any arc
   

fifinding consensus bayesian network structures

from g makes it cease to be a directed independence map of m   we say that g and an
ordering of its nodes are consistent when  for every arc a  b in g  a precedes b in
the node ordering  we say that a dag g is a mdi map of an independence model m
relative to a node ordering  if g is a mdi map of m and g is consistent with   if m
is a graphoid  then g is unique  pearl        thms    and     specifically  for each node
a  p ag  a  is the smallest subset x of the predecessors of a in   p re  a   such that
a  m p re  a    x x 

   finding a consensus dag is np hard
recall that we have defined the consensus dag of a given set of dags g            gm as the
i
dag that has the fewest parameters associated among all the mdi maps of m
i   i g    a
sensible way to start the quest for the consensus dag is by investigating whether there can
exist several non equivalent consensus dags  the following theorem answers this question 
theorem    there exists a set of dags that has two non equivalent consensus dags 
proof  consider the following two dags over four random variables with the same number
of states each 
i

k



j

i





l

k



j

l

any of the following two non equivalent dags is the consensus dag of the two dags
above 
i

k


 


i

k

j

l


 


j

l

a natural follow up question to investigate is whether a consensus dag can be found
efficiently  unfortunately  finding a consensus dag is np hard  as we prove below  specifically  we prove that the following decision problem is np hard 
consensus
 instance  a set of dags g            gm over v  and a positive integer d 
i
 question  does there exist a dag g over v such that i g   m
i   i g   and the
number of parameters associated with g is not greater than d  

proving that consensus is np hard implies that finding the consensus dag is also
np hard  because if there existed an efficient algorithm for finding the consensus dag  then
we could use it to solve consensus efficiently  our proof makes use of the following two
   

fipena

decision problems 
feedback arc set
 instance  a directed graph g    v  a  and a positive integer k 
 question  does there exist a subset b  a such that  b   k and b has at least
one arc from every directed cycle in g  
learn
 instance  a probability distribution p over v  and a positive integer d 
 question  does there exist a dag g over v such that i g   i p  and the number
of parameters associated with g is not greater than d  
feedback arc set is np complete  garey   johnson         feedback arc
set remains np complete for directed graphs in which the total degree of each vertex is at
most three  gavril         this degree bounded feedback arc set problem is used
by chickering et al         to prove that learn is np hard  in their proof  chickering
et al         use the following polynomial reduction of any instance of the degree bounded
feedback arc set into an instance of learn 
 let the instance of the degree bounded feedback arc set consist of the directed
graph f    vf   af   and the positive integer k 
 let l denote a dag whose nodes and arcs are determined from f as follows  for
every arc vif  vjf in af   create the following nodes and arcs in l 

vif   



aij    

bij    

cij    

hij

   

 

 

dij    

eij    

fij    



gij



vjf   

   

the number in parenthesis besides each node is the number of states of the corresponding random variable  let hl denote all the nodes hij in l  and let vl denote
the rest of the nodes in l 
 specify a  join  probability distribution p hl   vl   such that i p hl   vl      i l  
 let the instance of learn consist of the  marginal  probability distribution p vl  
and the positive integer d  where d is computed from f and k as shown in the work
of chickering et al         equation    
we now describe how the instance of learn resulting from the reduction above can
be further reduced into an instance of consensus in polynomial time 
 let c   denote the dag over vl that has all and only the arcs in l whose both
endpoints are in vl  
   

fifinding consensus bayesian network structures

 let c   denote the dag over vl that only has the arcs bij  cij  fij for all i and
j 
 let c   denote the dag over vl that only has the arcs cij  fij  eij for all i and
j 
 let the instance of consensus consist of the dags c     c   and c     and the positive
integer d 
theorem    consensus is np hard 
proof  we start by proving that there is a polynomial reduction of any instance f of the
degree bounded feedback arc set into an instance c of consensus  first  reduce
f into an instance l of learn as shown in the work of chickering et al         and  then 
reduce l into c as shown above 
we now prove that there is a solution to f iff there is a solution to c  chickering et
al         thms    and    prove that there is a solution to f iff there is a solution to l 
therefore  it only remains to prove that there is a solution to l iff there is a solution to
c  note that the parameter d of l and the parameter d of c are the same   let l and
p hl   vl   denote the dag and the probability distribution constructed in the reduction
of f into l  recall that i p hl   vl      i l   moreover 
 let l  denote the dag over  hl   vl   that has all and only the arcs in l whose both
endpoints are in vl  
 let l  denote the dag over  hl   vl   that only has the arcs bij  cij  hij  fij
for all i and j 
 let l  denote the dag over  hl   vl   that only has the arcs cij  hij  fij  eij
for all i and j 
note that any separation statement that holds in l also holds in l    l  and l    then 
i p hl   vl      i l    i   i li   and  thus  i p vl       i   i li   vl    i    i li   vl  
let c     c   and c   denote the dags constructed in the reduction of l into c  note that
 i li   vl   i c i   for all i  then  i p vl      i   i c i   and  thus  if there is a solution to
l then there is a solution to c  we now prove the opposite  the proof is essentially the
same as that in the work of chickering et al         thm      let us define the  vi   vj  
edge component of a dag g over vl as the subgraph of g that has all and only the arcs
in g whose both endpoints are in  vi   aij   bij   cij   dij   eij   fij   gij   vj    given a solution
c to c  we create another solution c   to c as follows 
 initialize c   to c    
 for every  vi   vj   edge component of c  if there is no directed path in c from vi to
vj   then add to c   the arcs eij  cij  fij  
 for every  vi   vj   edge component of c  if there is a directed path in c from vi to vj  
then add to c   the arcs bij  fij  cij  
   

fipena

note that c   is acyclic because c is acyclic  moreover  i c       i   i c i   because
i c      i c i   for all i  in order to be able to conclude that c   is a solution to c  it only
remains to prove that the number of parameters associated with c   is not greater than
d  specifically  we prove below that c   does not have more parameters associated than c 
which has less than d parameters associated because it is a solution to c 
as seen before  i c      i c      likewise  i c   i c     because c is a solution to c 
thus  there exists a sequence s  resp  s     of covered arc reversals and arc additions that
transforms c   into c  resp  c      chickering        thm      note that a covered arc
reversal does not modify the number of parameters associated with a dag  whereas an arc
addition increases it  chickering        thm      thus  s and s   monotonically increase
the number of parameters associated with c   as they transform it  recall that c   consists
of a series of edge components of the form

vif   



aij    

bij    

cij    

dij    

eij    

fij    



gij



vjf   

   

the number in parenthesis besides each node is the number of states of the corresponding
random variable  let us study how the sequences s and s   modify each edge component
of c     s   simply adds the arcs bij  fij  cij or the arcs eij  cij  fij   note that
adding the first pair of arcs results in an increase of    parameters  whereas adding the
second pair of arcs results in an increase of    parameters  unlike s     s may reverse some
arc in the edge component  if that is the case  then s must cover the arc first  which implies
an increase of at least    parameters  covering fij  vj by adding eij  vj implies an
increase of exactly    parameters  whereas any other arc covering implies a larger increase  
then  s implies a larger increase in the number of parameters than s     on the other hand 
if s does not reverse any arc in the edge component  then s simply adds the arcs that are
in c but not in c     note that either cij  fij or cij  fij is in c  because otherwise
cij  c fij  z for some z  vl which contradicts the fact that c is a solution to c since
cij   c   fij  z  if cij  fij is in c  then either bij  fij or bij  fij is in c because
otherwise bij  c fij  z for some z  vl such that cij  z  which contradicts the fact that
c is a solution to c since bij   c   fij  z  as bij  fij would create a cycle in c  bij  fij
is in c  therefore  s adds the arcs bij  fij  cij and  by construction of c     s   also
adds them  thus  s implies an increase of at least as many parameters as s     on the other
hand  if cij  fij is in c  then either cij  eij or cij  eij is in c because otherwise
cij  c eij  z for some z  vl such that fij  z  which contradicts the fact that c is a
solution to c since cij   c   eij  z  as cij  eij would create a cycle in c  cij  eij is in
c  therefore  s adds the arcs eij  cij  fij and  by construction of c     s   adds either
the arcs eij  cij  fij or the arcs bij  fij  cij   in any case  s implies an increase
of at least as many parameters as s     consequently  c   does not have more parameters
associated than c 
finally  note that i p vl     i c     by chickering et al         lemma     thus  if
there is a solution to c then there is a solution to l 
   

fifinding consensus bayesian network structures

it is worth noting that our proof above contains two restrictions  first  the number of
dags to consensuate is three  second  the number of states of each random variable in
vl is not arbitrary but prescribed  the first restriction is easy to relax  our proof can be
extended to consensuate more than three dags by simply letting c i be a dag over vl
with no arcs for all i      however  it is an open question whether consensus remains
np hard when the number of dags to consensuate is two and or the number of states of
each random variable in vl is arbitrary 
the following theorem strengthens the previous one 
theorem    consensus is np complete 
proof  by theorem    all that remains to prove is that consensus is in np  i e  that
we can verify in polynomial time if a given dag g is a solution to a given instance of
consensus 
let  denote any node ordering that is consistent with g  the causal list of g relative
to  is the set of separation statements a  g p re  a    p ag  a  p ag  a  for all node a 
it is known that i g  coincides with the closure with respect to the graphoid properties of
i
the causal list of g relative to   pearl        corollary     therefore  i g   m
i   i g   iff
i
a  gi p re  a    p ag  a  p ag  a  for all    i  m  because m
i   i g   is a graphoid  del
sagrado   moral        corollary     let n  a and ai denote  respectively  the number of
nodes in g  the number of arcs in g  and the number of arcs in gi   let b   max im ai  
checking a separation statement in gi takes o ai   time  geiger et al         p        then 
i
checking whether i g   m
i   i g   takes o mnb  time  finally  note that computing the
number of parameters associated with g takes o a  

   finding an approximated consensus dag
since finding a consensus dag of some given dags is np hard  we decide to resort to
heuristics to find an approximated consensus dag  this does not mean that we discard
the existence of fast super polynomial algorithms  it simply means that we do not pursue
that possibility in this paper  specifically  in this paper we consider the following heuristic
due to matzkevich and abramson            b   see also the work of matzkevich and
abramson      a  for related information  first  let  denote any ordering of the nodes
in the given dags  which we denote here as g            gm   then  find the mdi map gi of
each gi relative to   finally  let the approximated consensus dag be the dag whose
arcs are exactly the union of the arcs in g            gm
   the following theorem justifies taking
the union of the arcs  specifically  it proves that the dag returned by the heuristic is the
consensus dag if this was required to be consistent with  
theorem    the dag h returned by the heuristic above is the dag that has the fewest
i
parameters associated among all the mdi maps of m
i   i g   relative to  
i
proof  we start by proving that h is a mdi map of m
i   i g    first  we show that
i
m
i
i
i h   m
i   i g    it suffices to note that i h   i   i g   because each g is a subm
i
m
i
i
i
graph of h  and that i   i g    i   i g   because i g    i g   for all i  now 

   

fipena

assume to the contrary that the dag h   resulting from removing an arc a  b from h
i
i
satisfies that i h      m
i   i g    by construction of h  a  b is in g for some i  say
i   j  note that b  h   p re  b    p ah    b  p ah    b   which implies b  gj p re  b   
m
m
  m
i   p agi  b      a    i   p agi  b      a  because p ah    b     i   p agi  b      a 
i
and i h      m
i   i g    note also that b  gj p re  b    p agj  b  p agj  b   which implies b  gj p re  b    p agj  b  p agj  b  because i gj    i gj    therefore  b  gj


p re  b     p agj  b     a   p agj  b     a  by intersection  however  this contradicts the


i
fact that gj is the mdi map of gj relative to   then  h is a mdi map of m
i   i g  
relative to  
i
finally  note that m
i   i g   is a graphoid  del sagrado   moral        corollary    
i
consequently  h is the only mdi map of m
i   i g   relative to  

a key step in the heuristic above is  of course  choosing a good node ordering   unfortunately  the fact that consensus is np hard implies that it is also np hard to find the
best node ordering   i e  the node ordering that makes the heuristic to return the mdi
i
map of m
i   i g   that has the fewest parameters associated  to see it  note that if there
existed an efficient algorithm for finding the best node ordering  then theorem   would
imply that we could solve consensus efficiently by running the heuristic with the best
node ordering 
in the last sentence  we have implicitly assumed that the heuristic is efficient  which
implies that we have implicitly assumed that we can efficiently find the mdi map gi of
each gi   the rest of this paper shows that this assumption is correct 

   methods a and b are not correct
matzkevich and abramson      b  do not only propose the heuristic discussed in the previous section  but they also present two algorithms  called methods a and b  for efficiently
deriving the mdi map g of a dag g relative to a node ordering   the algorithms work
iteratively by covering and reversing an arc in g until the resulting dag is consistent with
  it is obvious that such a way of working produces a directed independence map of g 
however  in order to arrive at g   the arc to cover and reverse in each iteration must be
carefully chosen  the pseudocode of methods a and b can be seen in figure    method
a starts by calling construct  to derive a node ordering  that is consistent with g and
as close to  as possible  line     by  being as close to  as possible  we mean that the
number of arcs methods a and b will later cover and reverse is kept at a minimum  because
methods a and b will use  to choose the arc to cover and reverse in each iteration  in
particular  method a finds the leftmost node in  that should be interchanged with its left
neighbor  line    and it repeatedly interchanges this node with its left neighbor  lines    
and       each of these interchanges is preceded by covering and reversing the corresponding arc in g  line     method b is essentially identical to method a  the only differences
between them are that the word right is replaced by the word left and vice versa in
lines      and that the arcs point in opposite directions in line    note that methods a and
b do not reverse an arc more than once 
   

fifinding consensus bayesian network structures

construct  g   
   given a dag g and a node ordering   the algorithm returns a node ordering  that
is consistent with g and as close to  as possible   
 
 
 
    
 
 
 
 
 
 
  
  

 
g    g
let a denote a sink node in g 
let a denote the rightmost node in  that is a sink node in g    
add a as the leftmost node in 
let b denote the right neighbor of a in 
if b     and a 
  p ag  b  and a is to the right of b in  then
interchange a and b in 
go to line  
remove a and all its incoming arcs from g 
if g      then go to line  
return 
method a g   
   given a dag g and a node ordering   the algorithm returns g   

 
 
 
 
 
 
 
 
 

 construct  g   
let y denote the leftmost node in  whose left neighbor in  is to its right in 
let z denote the left neighbor of y in 
if z is to the right of y in  then
if z  y is in g then cover and reverse z  y in g
interchange y and z in 
go to line  
if      then go to line  
return g
method b g   
   given a dag g and a node ordering   the algorithm returns g   

 
 
 
 
 
 
 
 
 

 construct  g   
let y denote the leftmost node in  whose right neighbor in  is to its left in 
let z denote the right neighbor of y in 
if z is to the left of y in  then
if y  z is in g then cover and reverse y  z in g
interchange y and z in 
go to line  
if      then go to line  
return g

figure    construct   and methods a and b  our correction of construct  consists in  i 
replacing line   with the line in comments under it  and  ii  removing lines     
   

fipena

figure    a counterexample to the correctness of methods a and b 
methods a and b are claimed to be correct in the work of matzkevich and abramson
     b  thm    and corollary    although no proof is provided  a proof is just sketched  
the following counterexample shows that methods a and b are actually not correct  let g
be the dag in the left hand side of figure    let     m  i  k  j  l   then  we can make
use of the characterization introduced in section   to see that g is the dag in the center
of figure    however  methods a and b return the dag in the right hand side of figure
   to see it  we follow the execution of methods a and b step by step  first  methods a
and b construct  by calling construct   which runs as follows 
   initially      and g    g 
   select the sink node m in g    then      m    remove m and its incoming arcs from
g   
   select the sink node l in g    then      l  m    no interchange in  is performed
because l  p ag  m    remove l and its incoming arcs from g   
   select the sink node k in g    then      k  l  m    no interchange in  is performed
because k is to the left of l in   remove k and its incoming arcs from g   
   select the sink node j in g    then      j  k  l  m    no interchange in  is performed
because j  p ag  k  
   select the sink node i in g    then      i  j  k  l  m    no interchange in  is
performed because i is to the left of j in  
when construct  ends  methods a and b continue as follows 
   

fifinding consensus bayesian network structures

   initially      i  j  k  l  m   
   add the arc i  j and reverse the arc j  k in g  interchange j and k in  
then      i  k  j  l  m   
   add the arc j  m and reverse the arc l  m in g  interchange l and m in  
then      i  k  j  m  l  
    add the arcs i  m and k  m   and reverse the arc j  m in g  interchange j
and m in   then      i  k  m  j  l  
    reverse the arc k  m in g  interchange k and m in   then      i  m  k  j  l  
    reverse the arc i  m in g  interchange i and m in   then      m  i  k  j  l   
 
as a matter of fact  one can see as early as in step   above that methods a and b will
fail  one can see that i and m are not separated in the dag resulting from step    which
implies that i and m will not be separated in the dag returned by methods a and b 
because covering and reversing arcs never introduces new separation statements  however 
i and m are separated in g  
note that we constructed  by selecting first m   then l  then k  then j  and finally i 
however  we could have selected first k  then i  then m   then l  and finally j  which would
have resulted in     j  l  m  i  k   with this   methods a and b return g   therefore  it
makes a difference which sink node is selected in line   of construct   however  construct
 overlooks this detail  we propose correcting construct  by  i  replacing line   by let a
denote the rightmost node in  that is a sink node in g    and  ii  removing lines     since
they will never be executed  hereinafter  we assume that any call to construct  is a call
to the corrected version thereof  the rest of this paper is devoted to prove that methods a
and b now do return g  

   the corrected methods a and b are correct
before proving that methods a and b are correct  we introduce some auxiliary lemmas 
their proof can be found in appendix a  let us call percolating y right to left in  to
iterating through lines     in method a while possible  let us modify method a by replacing
line   by let y denote the leftmost node in  that has not been considered before and
by adding the check z     to line    the pseudocode of the resulting algorithm  which we
call method a   can be seen in figure    method a  percolates right to left in  one by
one all the nodes in the order in which they appear in  
lemma    method a g    and method a  g    return the same dag 
lemma    method a  g    and method b g    return the same dag 
let us call percolating y left to right in  to iterating through lines     in method b
while possible  let us modify method b by replacing line   by let y denote the rightmost
node in  that has not been considered before and by adding the check z     to line   
the pseudocode of the resulting algorithm  which we call method b   can be seen in figure
   

fipena

method a  g   
   given a dag g and a node ordering   the algorithm returns g   
 
 
 
 
 
 
 
 
 

 construct  g   
let y denote the leftmost node in  that has not been considered before
let z denote the left neighbor of y in 
if z     and z is to the right of y in  then
if z  y is in g then cover and reverse z  y in g
interchange y and z in 
go to line  
if      then go to line  
return g
method b  g   
   given a dag g and a node ordering   the algorithm returns g   

 
 
 
 
 
 
 
 
 

 construct  g   
let y denote the rightmost node in  that has not been considered before
let z denote the right neighbor of y in 
if z     and z is to the left of y in  then
if y  z is in g then cover and reverse y  z in g
interchange y and z in 
go to line  
if      then go to line  
return g

figure    methods a  and b  
   method b  percolates left to right in  one by one all the nodes in the reverse order in
which they appear in  
lemma    method b g    and method b  g    return the same dag 
we are now ready to prove the main result of this paper 
theorem    let g denote the mdi map of a dag g relative to a node ordering   then 
method a g    and method b g    return g  
proof  by lemmas      it suffices to prove that method b  g    returns g   it is evident
that method b  transforms  into  and  thus  that it halts at some point  therefore 
method b  performs a finite sequence of n modifications  arc additions and covered arc
reversals  to g  let gi denote the dag resulting from the first i modifications to g  and
let g    g  specifically  method b  constructs gi   from gi by either  i  reversing the
covered arc y  z  or  ii  adding the arc x  z for some x  p agi  y     p agi  z   or
 iii  adding the arc x  y for some x  p agi  z    p agi  y    note that i gi      i gi  
for all    i   n and  thus  that i gn    i g    
   

fifinding consensus bayesian network structures

we start by proving that gi is a dag that is consistent with  for all    i  n  since
this is true for g  due to line    it suffices to prove that if gi is a dag that is consistent
with  then so is gi   for all    i   n  we consider the following four cases 
case   method b  constructs gi   from gi by reversing the covered arc y  z  then 
gi   is a dag because reversing a covered arc does not create any cycle  chickering 
      lemma     moreover  note that y and z are interchanged in  immediately
after the covered arc reversal  thus  gi   is consistent with  
case   method b  constructs gi   from gi by adding the arc x  z for some x 
p agi  y     p agi  z   note that x is to the left of y and y to the left of z in  
because gi is consistent with   then  x is to the left of z in  and  thus  gi   is a
dag that is consistent with  
case   method b  constructs gi   from gi by adding the arc x  y for some x 
p agi  z    p agi  y    note that x is to the left of z in  because gi is consistent with
  and y is the left neighbor of z in   recall line     then  x is to the left of y in
 and  thus  gi   is a dag that is consistent with  
case   note that  may get modified before method b  constructs gi   from gi   specifically  this happens when method b  executes lines     but there is no arc between
y and z in gi   however  the fact that gi is consistent with  before y and z are
interchanged in  and the fact that y and z are neighbors in   recall line    imply
that gi is consistent with  after y and z have been interchanged 
since method b  transforms  into   it follows from the result proven above that gn
is a dag that is consistent with   in order to prove the theorem  i e  that gn   g   all
that remains to prove is that i g    i gn    to see it  note that gn   g follows from
i g    i gn    i gn    i g     the fact that gn is a dag that is consistent with   and
the fact that g is the unique mdi map of g  relative to   recall that g is guaranteed
to be unique because i g    is a graphoid 
the rest of the proof is devoted to prove that i g    i gn    specifically  we prove
that if i g    i gi   then i g    i gi     for all    i   n  note that this implies
that i g    i gn   because i g    i g    by definition of mdi map  first  we prove it
when method b  constructs gi   from gi by reversing the covered arc y  z  that the
arc reversed is covered implies that i gi       i gi    chickering        lemma     thus 
i g    i gi     because i g    i gi   
now  we prove that if i g    i gi   then i g    i gi     for all    i   n when
method b  constructs gi   from gi by adding an arc  specifically  we prove that if there
is an s active route  s  v  ab
i   between two nodes a and b in gi     then there is an
s active route between a and b in g   we prove this result by induction on the number of
occurrences of the added arc in ab
i     we assume without loss of generality that the added
ab
arc occurs in i   as few or fewer times than in any other s active route between a and b
 
in gi     we call this the minimality property of ab
i     if the number of occurrences of the
   it is not difficult to show that the number of occurrences of the added arc in ab
i   is then at most two
 see case     for some intuition   however  the proof of the theorem is simpler if we ignore this fact 

   

fipena

figure    different cases in the proof of theorem    only the relevant subgraphs of gi   and
g are depicted  an undirected edge between two nodes denotes that the nodes
are adjacent  a curved edge between two nodes denotes an s active route between
the two nodes  if the curved edge is directed  then the route is descending  a
grey node denotes a node that is in s 

ab
added arc in ab
i   is zero  then i   is an s active route between a and b in gi too and 
thus  there is an s active route between a and b in g since i g    i gi    assume as
induction hypothesis that the result holds for up to k occurrences of the added arc in ab
i    
we now prove it for k     occurrences  we consider the following two cases  each case is
illustrated in figure   

case   method b  constructs gi   from gi by adding the arc x  z for some x 
 
ab
ax
zb
p agi  y   p agi  z   note that x  z occurs in ab
i     let i     i   x  zi    
ax
ab
note that x 
  s and i   is s active in gi   because  otherwise  i   would not be
   note that maybe a   x and or b   z 

   

fifinding consensus bayesian network structures

s active in gi     then  there is an s active route ax
between a and x in g by the

zb
induction hypothesis  moreover  y  s because  otherwise  ax
i    x  y  z  i  
would be an s active route between a and b in gi   that would violate the minimality
property of ab
i     note that y  z is in g because  i  y and z are adjacent in
g since i g    i gi    and  ii  z is to the left of y in   recall line     note
also that x  y is in g   to see it  note that x and y are adjacent in g since
i g    i gi    recall that method b  percolates left to right in  one by one all
the nodes in the reverse order in which they appear in   method b  is currently
percolating y and  thus  the nodes to the right of y in  are to the right of y in 
too  if x  y were in g then x would be to the right of y in  and  thus  x would
be to the right of y in   however  this would contradict the fact that x is to the
left of y in   which follows from the fact that gi is consistent with   thus  x  y
is in g   we now consider two cases 
case     assume that z 
  s  then  zb
i   is s active in gi   because  otherwise 
ab
i   would not be s active in gi     then  there is an s active route zb
 between
z and b in g by the induction hypothesis  then  ax

x

y

z  zb

 is
an s active route between a and b in g  
wb  
case     assume that z  s  then  zb
  s and
i     z  w  i     note that w 
w
b
ab
i   is s active in gi   because  otherwise  i   would not be s active in gi    
b between w and b in g by the induction
then  there is an s active route w


hypothesis  note that w and z are adjacent in g since i g    i gi    this
and the fact proven above that y  z is in g imply that y and w are adjacent
in g because  otherwise  y   gi w  u but y  g w  u for some u  v such
that z  u  which would contradict that i g    i gi    in fact  y  w is in
g   to see it  recall that the nodes to the right of y in  are to the right of y in
 too  if y  w were in g then w would be to the right of y in  and  thus 
w would be to the right of y in  too  however  this would contradict the fact
that w is to the left of y in   which follows from the fact that w is to the left of
z in  because gi is consistent with   and the fact that y is the left neighbor of
wb
z in   recall line     thus  y  w is in g   then  ax
  x  y  w  
is an s active route between a and b in g  

case   method b  constructs gi   from gi by adding the arc x  y for some x 
 
ab
ax
yb
p agi  z  p agi  y    note that x  y occurs in ab
i     let i     i   x  y i    
ax
ab
note that x 
  s and i   is s active in gi   because  otherwise  i   would not be
s active in gi     then  there is an s active route ax
between a and x in g by the

induction hypothesis  note that y  z is in g because  i  y and z are adjacent in
g since i g    i gi    and  ii  z is to the left of y in   recall line     note also
that x and z are adjacent in g since i g    i gi    this and the fact that y  z
is in g imply that x and y are adjacent in g because  otherwise  x   gi y  u
but x  g y  u for some u  v such that z  u  which would contradict that
wb
   note that maybe w   b  note also that w    x because  otherwise  ax
i    x  y  x  i   would
be an s active route between a and b in gi   that would violate the minimality property of ab
i    
   note that maybe a   x and or b   y  

   

fipena

i g    i gi    in fact  x  y is in g   to see it  recall that method b  percolates
left to right in  one by one all the nodes in the reverse order in which they appear
in   method b  is currently percolating y and  thus  the nodes to the right of y
in  are to the right of y in  too  if x  y were in g then x would be to the
right of y in  and  thus  x would be to the right of y in  too  however  this would
contradict the fact that x is to the left of y in   which follows from the fact that
x is to the left of z in  because gi is consistent with   and the fact that y is the
left neighbor of z in   recall line     thus  x  y is in g   we now consider three
cases 
b   y  x  xb   note that xb is s active
case     assume that y  s and yi  
i  
i  
ab
in gi   because  otherwise  i   would not be s active in gi     then  there
is an s active route xb
between x and b in g by the induction hypothesis 

ax
then    x  y  x  xb
is an s active route between a and b in g  

b   y  w  w b    note that w 
case     assume that y  s and yi  
  s and
i  
w
b
i   is s active in gi   because  otherwise  ab
would
not
be
s active
in gi    
i  
b between w and b in g by the induction
then  there is an s active route w


hypothesis  note also that y  w is in g   to see it  note that y and w
are adjacent in g since i g    i gi    recall that the nodes to the right of
y in  are to the right of y in  too  if y  w were in g then w would
be to the right of y in  and  thus  w would be to the right of y in  too 
however  this would contradict the fact that w is to the left of y in   which
follows from the fact that gi is consistent with   thus  y  w is in g   then 
w b is an s active route between a and b in g  
ax

  x  y  w  

case     assume that y 
  s  the proof of this case is based on that of step   in the
work of chickering        lemma      let d denote the node that is maximal
in g from the set of descendants of y in gi   note that d is guaranteed to be
unique by chickering        lemma      because i g    i gi    note also that
d    y   because z is a descendant of y in gi and  as shown above  y  z is in
g   we now show that d is a descendant of z in gi   we consider three cases 
case       assume that d   z  then  d is a descendant of z in gi  
case       assume that d    z and d was a descendant of z in g    recall
that method b  percolates left to right in  one by one all the nodes in the
reverse order in which they appear in   method b  is currently percolating
y and  thus  it has not yet percolated z because z is to the left of y in 
 recall line     therefore  none of the descendants of z in g   among which
is d  is to the left of z in   this and the fact that  is consistent with gi
imply that z is a node that is maximal in gi from the set of descendants of
z in g    actually  z is the only such node by chickering        lemma     
because i gi    i g     then  the descendants of z in g  are descendants
of z in gi too  thus  d is a descendant of z in gi  
   note that maybe w   b  note also that w    x  because the case where w   x is covered by case
    

   

fifinding consensus bayesian network structures

case       assume that d    z and d was not a descendant of z in g    as
shown in case        the descendants of z in g  are descendants of z in
gi too  therefore  none of the descendants of z in g  was to the left of d
in  because  otherwise  some descendant of z and thus of y in gi would
be to the left of d in   which would contradict the definition of d  this
and the fact that d was not a descendant of z in g  imply that d was still
in g  when z became a sink node of g  in construct   recall figure    
therefore  construct  added d to  after having added z  recall lines      
because d is to the left of z in  by definition of d   for the same reason 
method b  has not interchanged d and z in   recall line     thus  d is
currently still to the left of z in   which implies that d is to the left of y
in   because y is the left neighbor of z in   recall line     however  this
contradicts the fact that gi is consistent with   because d is a descendant
of y in gi   thus  this case never occurs 
b is
we continue with the proof of case      note that y 
  s implies that yi  
s active in gi   because  otherwise  ab
i   would not be s active in gi     note
also that no descendant of z in gi is in s because  otherwise  there would be
xy  y b
an s active route xy
between x and y in gi and  thus  ax
i
i    i
i  
would be an s active route between a and b in gi   that would violate the
minimality property of ab
  s because  as shown above 
i     this implies that d 
d is a descendant of z in gi   it also implies that there is an s active descending
zd is an s active route
route zd
from z to d in gi   then  ax
i
i    x  z  i
zd is an s active route
between a and d in gi     likewise  by
i    y  z  i
by
between b and d in gi     where i   denotes the route resulting from reversing
b   therefore  there are s active routes ad and bd between a and d and
yi  


between b and d in g by the induction hypothesis 
consider the subroute of ab
i   that starts with the arc x  y and continues in
the direction of this arc until it reaches a node e such that e   b or e  s 
note that e is a descendant of y in gi and  thus  e is a descendant of d in g
by definition of d  let de
denote the descending route from d to e in g  

assume without loss of generality that g has no descending route from d to
b or to a node in s that is shorter than de
   this implies that if e   b then
de
de is an
 is s active in g because  as shown above  d 
  s  thus  ad
  
s active route between a and b in g   on the other hand  if e  s then e    d
de  ed  db is an s active route between
because d 
  s  thus  ad
  


ed
a and b in g   where  and db
denote
the
routes resulting from reversing

bd  
de
and




finally  we show how the correctness of method b  leads to an alternative proof of the
so called meeks conjecture         given two dags g and h such that i h   i g  
meeks conjecture states that we can transform g into h by a sequence of arc additions
and covered arc reversals such that after each operation in the sequence g is a dag and
   note that this statement is true thanks to our correction of construct  

   

fipena

method g h g  h 
   given two dags g and h such that i h   i g   the algorithm transforms
g into h by a sequence of arc additions and covered arc reversals such that
after each operation in the sequence g is a dag and i h   i g    
 
 
 

let  denote a node ordering that is consistent with h
g method b  g   
add to g the arcs that are in h but not in g

figure    method g h 
i h   i g   the importance of meeks conjecture lies in that it allows to develop efficient
and asymptotically correct algorithms for learning bns from data under mild assumptions
 chickering        chickering   meek        meek        nielsen et al          meeks
conjecture was proven to be true in the work of chickering        thm     by developing
an algorithm that constructs a valid sequence of arc additions and covered arc reversals 
we propose an alternative algorithm to construct such a sequence  the pseudocode of our
algorithm  called method g h  can be seen in figure    the following corollary proves that
method g h is correct 
corollary    given two dags g and h such that i h   i g   method g h g  h 
transforms g into h by a sequence of arc additions and covered arc reversals such that
after each operation in the sequence g is a dag and i h   i g  
proof  note from method g hs line   that  denotes a node ordering that is consistent
with h  let g denote the mdi map of g relative to   recall that g is guaranteed to be
unique because i g  is a graphoid  note that i h   i g  implies that g is a subgraph
of h  to see it  note that i h   i g  implies that we can obtain a mdi map of g relative
to  by just removing arcs from h  however  g is the only mdi map of g relative to  
then  it follows from the proof of theorem   that method g hs line   transforms
g into g by a sequence of arc additions and covered arc reversals  and that after each
operation in the sequence g is a dag and i g    i g   thus  after each operation in
the sequence i h   i g  because i h   i g   since  as shown above  g is a subgraph
of h  moreover  method g hs line   transforms g from g to h by a sequence of arc
additions  of course  after each arc addition g is a dag and i h   i g  because g is
a subgraph of h 

   the corrected methods a and b are efficient
in this section  we show that methods a and b are more efficient than any other solution
to the same problem we can think of  let n and a denote  respectively  the number of
nodes and arcs in g  moreover  let us assume hereinafter that a dag is implemented as an
   

fifinding consensus bayesian network structures

adjacency matrix  whereas a node ordering is implemented as an array with an entry per
node indicating the position of the node in the ordering  since i g  is a graphoid  the first
solution we can think of consists in applying the following characterization of g   for each
node a  p ag  a  is the smallest subset x  p re  a  such that a  g p re  a    x x  this
solution implies evaluating for each node a all the o  n   subsets of p re  a   evaluating a
subset implies checking a separation statement in g  which takes o a  time  geiger et al  
      p        therefore  the overall runtime of this solution is o an n   
since i g  satisfies the composition property in addition to the graphoid properties 
a more efficient solution consists in running the incremental association markov boundary
 iamb  algorithm  pena et al         thm     for each node a to find p ag  a   the iamb
algorithm first sets p ag  a     and  then  proceeds with the following two steps  the
first step consists in iterating through the following line until p ag  a  does not change 
take any node b  p re  a    p ag  a  such that a   g b p ag  a  and add it to p ag  a  
the second step consists in iterating through the following line until p ag  a  does not
change  take any node b  p ag  a  that has not been considered before and such that
a  g b p ag  a   b   and remove it from p ag  a   the first step of the iamb algorithm
can add o n  nodes to p ag  a   each addition implies evaluating o n  candidates for
the addition  since p re  a  has o n  nodes  evaluating a candidate implies checking a
separation statement in g  which takes o a  time  geiger et al         p        then  the
first step of the iamb algorithm runs in o an    time  similarly  the second step of the
iamb algorithm runs in o an  time  therefore  the iamb algorithm runs in o an    time 
since the iamb algorithm has to be run once for each of the n nodes  the overall runtime
of this solution is o an    
we now analyze the efficiency of methods a and b  to be more exact  we analyze
methods a  and b   recall figure    rather than the original methods a and b  recall
figure     because the former are more efficient than the latter  methods a  and b  run
in o n    time  first  note that construct  runs in o n    time  the algorithm iterates n
times through lines      and  in each of these iterations  it iterates o n  times through lines
     moreover  line   takes o n    time  line   takes o    time  and line   takes o n  time 
now  note that methods a  and b  iterate n times through lines     and  in each of these
iterations  they iterate o n  times through lines      moreover  line   takes o    time 
and line   takes o n  time because covering an arc implies updating the adjacency matrix
accordingly  consequently  methods a and b are more efficient than any other solution to
the same problem we can think of 
finally  we analyze the complexity of method g h  method g h runs in o n    time 
 can be constructed in o n    time by calling construct  h    where  is any node
ordering  running method b  takes o n    time  and adding to g the arcs that are in h
but not in g can be done in o n    time  recall that method g h is an alternative to
the algorithm in the work of chickering         unfortunately  no implementation details
are provided in the work of chickering and  thus  a comparison with the runtime of the
algorithm there is not possible  however  we believe that our algorithm is more efficient 
   

fipena

   discussion
in this paper  we have studied the problem of combining several given dags into a consensus
dag that only represents independences all the given dags agree upon and that has as few
parameters associated as possible  although our definition of consensus dag is reasonable 
we would like to leave out the number of parameters associated and focus solely on the
independencies represented by the consensus dag  in other words  we would like to define
the consensus dag as the dag that only represents independences all the given dags
agree upon and as many of them as possible  we are currently investigating whether both
definitions are equivalent  in this paper  we have proven that there may exist several nonequivalent consensus dags  in principle  any of them is equally good  if we were able
to conclude that one represents more independencies than the rest  then we would prefer
that one  in this paper  we have proven that finding a consensus dag is np hard  this
made us resort to heuristics to find an approximated consensus dag  this does not mean
that we discard the existence of fast super polynomial algorithms for the general case  or
polynomial algorithms for constrained cases such as when the given dags have bounded
in degree  this is a question that we are currently investigating  in this paper  we have
considered the heuristic originally proposed by matzkevich and abramson            b  
this heuristic takes as input a node ordering  and we have shown that finding the best
node ordering for the heuristic is np hard  we are currently investigating the application
of meta heuristics in the space of node orderings to find a good node ordering for the
heuristic  our preliminary experiments indicate that this approach is highly beneficial  and
that the best node ordering almost never coincides with any of the node orderings that are
consistent with some of the given dags 
as said in section    we aim at combining the bns provided by multiple experts  or
learning algorithms  into a single consensus bn that is more robust than the individual
bns  in this paper  we have proposed to combine the experts bns in two steps to avoid
the problems discussed by pennock and wellman         first  finding a consensus bn
structure and  then  finding some consensus parameters for the consensus bn structure 
this paper has focused only on the first step  we are currently working on the second
step along the following lines  let  g                  gm   m   denote the bns provided by the
experts  the first element in each pair denotes the bn structure whereas the second denotes
the bn parameters  let p            pm denote the probability distributions represented by the
bns provided by the experts  then  we call p    f  p            pm   the consensus probability
distribution  where f is any combination function  e g  the weighted arithmetic or geometric
mean  let g denote a consensus bn structure obtained from g            gm as described
in this paper  we propose to obtain a consensus bn by parameterizing g such that
p  a p ag  a     p   a p ag  a   for all a  v  where p is the probability distribution
represented by the consensus bn  the motivation is that such a parameterization minimizes
the kullback leibler divergence between p and p   koller   friedman        thm       
some hints about how to speed up the computation of this parameterization by performing
inference in the experts bns can be found in the work of pennock and wellman       
properties   and    and section     alternatively  one could first sample p  and  then 
parameterize g such that p  a p ag  a     p   a p ag  a   for all a  v  where p  is
the empirical probability distribution obtained from the sample  again  the motivation is
   

fifinding consensus bayesian network structures

that such a parameterization minimizes the kullback leibler divergence between p and p 
 koller   friedman        thm        and  of course  p   p  if the sample is sufficiently
large  note that we use p  to parameterize g but not to construct g which  as discussed
in section    allows us to avoid the problems discussed by pennock and wellman        
finally  note that the present work combines the dags g            gm although there is
no guarantee that each gi is a mdi map of i pi    i e  gi may have superfluous arcs 
therefore  one may want to check if gi contains superfluous arcs and remove them before
the combination takes place  in general  several mdi maps of i pi   may exist  and they
may differ in the number of parameters associated with them  it would be interesting to
study how the number of parameters associated with the mdi map of i pi   chosen affects
the number of parameters associated with the consensus dag obtained by the method
proposed in this paper 

acknowledgments
we thank the anonymous referees and the editor for their thorough review of this manuscript 
we thank dr  jens d  nielsen and dag sonntag for proof reading this manuscript  this
work is funded by the center for industrial information technology  ceniit  and a socalled career contract at linkoping university 

appendix a  proofs of lemmas    
lemma    method a g    and method a  g    return the same dag 

proof  it is evident that methods a and a  transform  into  and  thus  that they halt
at some point  we now prove that they return the same dag  we prove this result by
induction on the number of times that method a executes line   before halting  it is
evident that the result holds if the number of executions is one  because methods a and a 
share line    assume as induction hypothesis that the result holds for up to k   executions 
we now prove it for k executions  let y and z denote the nodes involved in the first of
the k executions  since the induction hypothesis applies for the remaining k    executions 
the run of method a can be summarized as

if z  y is in g then cover and reverse z  y in g
interchange y and z in 
for i     to n do
percolate right to left in  the leftmost node in  that has not been percolated before

where n is the number of nodes in g  now  assume that y is percolated when i   j  note
that the first j    percolations only involve nodes to the left of y in   thus  the run
above is equivalent to
   

fipena

for i     to j    do
percolate right to left in  the leftmost node in  that has not been percolated before
if z  y is in g then cover and reverse z  y in g
interchange y and z in 
percolate y right to left in 
percolate z right to left in 
for i   j     to n do
percolate right to left in  the leftmost node in  that has not been percolated before 
now  let w denote the nodes to the left of z in  before the first of the k executions of
line    note that the fact that y and z are the nodes involved in the first execution implies
that the nodes in w are also to the left of z in   note also that  when z is percolated
in the latter run above  the nodes to the left of z in  are exactly w   y    since all the
nodes in w   y   are also to the left of z in   the percolation of z in the latter run above
does not perform any arc covering and reversal or node interchange  thus  the latter run
above is equivalent to
for i     to j    do
percolate right to left in  the leftmost node in  that has not been percolated before
percolate z right to left in 
percolate y right to left in 
for i   j     to n do
percolate right to left in  the leftmost node in  that has not been percolated before
which is exactly the run of method a   consequently  methods a and a  return the same
dag 

lemma    method a  g    and method b g    return the same dag 
proof  we can prove the lemma in much the same way as lemma    we simply need to
replace y by z and vice versa in the proof of lemma   

lemma    method b g    and method b  g    return the same dag 
proof  it is evident that methods b and b  transform  into  and  thus  that they halt
at some point  we now prove that they return the same dag  we prove this result by
induction on the number of times that method b executes line   before halting  it is
evident that the result holds if the number of executions is one  because methods b and b 
share line    assume as induction hypothesis that the result holds for up to k   executions 
we now prove it for k executions  let y and z denote the nodes involved in the first of
the k executions  since the induction hypothesis applies for the remaining k    executions 
the run of method b can be summarized as
   

fifinding consensus bayesian network structures

if y  z is in g then cover and reverse y  z in g
interchange y and z in 
for i     to n do
percolate left to right in  the rightmost node in  that has not been percolated before
where n is the number of nodes in g  now  assume that y is the j th rightmost node in
  note that  for all    i   j  the i th rightmost node wi in  is to the right of y in 
when wi is percolated in the run above  to see it  assume to the contrary that wi is to
the left of y in   this implies that wi is also to the left of z in   because y and z are
neighbors in   however  this is a contradiction because wi would have been selected in
line   instead of y for the first execution of line    thus  the first j    percolations in the
run above only involve nodes to the right of z in   then  the run above is equivalent to
for i     to j    do
percolate left to right in  the rightmost node in  that has not been percolated before
if y  z is in g then cover and reverse y  z in g
interchange y and z in 
for i   j to n do
percolate left to right in  the rightmost node in  that has not been percolated before
which is exactly the run of method b  

references
chickering  d  m  a transformational characterization of equivalent bayesian network
structures  in proceedings of the eleventh conference on uncertainty in artificial intelligence              
chickering  d  m  optimal structure identification with greedy search  journal of machine
learning research                  
chickering  d  m    meek  c  finding optimal bayesian networks  in proceedings of the
eighteenth conference on uncertainty in artificial intelligence               
chickering  d  m   heckerman  d    meek  c  large sample learning of bayesian networks
is np hard  journal of machine learning research                    
friedman  n    koller  d  being bayesian about network structure  a bayesian approach
to structure discovery in bayesian networks  machine learning                 
gavril  f  some np complete problems on graphs  in proceedings of the eleventh conference on information sciences and systems              
garey  m    johnson  d  computers and intractability  a guide to the theory of npcompleteness  w  h  freeman       
   

fipena

geiger  d   verma  t    pearl  j  identifying independence in bayesian networks  networks 
                 
genest  c    zidek  j  v  combining probability distributions  a critique and an annotated bibliography  statistical science                  
hartemink  a  j   gifford  d  k   jaakkola  t  s    young  r  a  combining location
and expression data for principled discovery of genetic regulatory network models  in
pacific symposium on biocomputing                  
jackson  b  n   aluru  s    schnable  p  s  consensus genetic maps  a graph theoretic approach  in proceedings of the      ieee computational systems bioinformatics
conference              
koller  d    friedman  n  probabilistic graphical models  principles and techniques  mit
press       
matzkevich  i    abramson  b  the topological fusion of bayes nets  in proceedings of
the eight conference conference on uncertainty in artificial intelligence                
matzkevich  i    abramson  b  some complexity considerations in the combination of
belief networks  in proceedings of the ninth conference conference on uncertainty in
artificial intelligence               a 
matzkevich  i    abramson  b  deriving a minimal i map of a belief network relative to
a target ordering of its nodes  in proceedings of the ninth conference conference on
uncertainty in artificial intelligence               b 
maynard reid ii  p    chajewska  u  agregating learned probabilistic beliefs  in proceedings of the seventeenth conference in uncertainty in artificial intelligence          
     
meek  c  graphical models  selecting causal and statistical models  phd thesis  carnegie
mellon unversity       
ng  k  c    abramson  b  probabilistic multi knowledge base systems  journal of applied
intelligence                  
nielsen  j  d   kocka  t    pena  j  m  on local optima in learning bayesian networks 
in proceedings of the nineteenth conference on uncertainty in artificial intelligence 
              
nielsen  s  h    parsons  s  an application of formal argumentation  fusing bayesian
networks in multi agent systems  artificial intelligence                   
pearl  j  probabilistic reasoning in intelligent systems  networks of plausible inference 
morgan kaufmann       
pennock  d  m    wellman  m  p  graphical representations of consensus belief  in proceedings of the fifteenth conference on uncertainty in artificial intelligence          
     
   

fifinding consensus bayesian network structures

pena  j  m   nilsson  r   bjorkegren  j    tegner  j  towards scalable and data efficient
learning of markov boundaries  international journal of approximate reasoning                  
pena  j  m   kocka  t    nielsen  j  d  featuring multiple local optima to assist the user
in the interpretation of induced bayesian network models  in proceedings of the tenth
international conference on information processing and management of uncertainty in
knowledge based systems                  
richardson  m    domingos  p  learning with knowledge from multiple experts  in proceedings of the twentieth international conference on machine learning                
del sagrado  j    moral  s  qualitative combination of bayesian networks  international
journal of intelligent systems                   
studeny  m  bayesian networks from the point of view of chain graphs  in proceedings of
the fourteenth conference conference on uncertainty in artificial intelligence          
     
studeny  m    bouckaert  r  r  on chain graph models for description of conditional
independence structures  the annals of statistics                     

   

fi