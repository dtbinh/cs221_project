journal artificial intelligence research                  

submitted        published      

combining evaluation metrics via unanimous
improvement ratio application clustering tasks
enrique amigo
julio gonzalo

enrique lsi uned es
julio lsi uned es

uned nlp   ir group  juan del rosal   
madrid        spain

javier artiles

javier artiles qc cuny edu

blender lab  queens college  cuny  
      kissena blvd  ny        usa

felisa verdejo

felisa lsi uned es

uned nlp   ir group  juan del rosal   
madrid        spain

abstract
many artificial intelligence tasks cannot evaluated single quality criterion
sort weighted combination needed provide system rankings  problem
weighted combination measures slight changes relative weights may produce
substantial changes system rankings  paper introduces unanimous improvement ratio  uir   measure complements standard metric combination criteria
 such van rijsbergens f measure  indicates robust measured differences
changes relative weights individual metrics  uir meant elucidate
whether perceived difference two systems artifact individual metrics
weighted 
besides discussing theoretical foundations uir  paper presents empirical
results confirm validity usefulness metric text clustering problem  tradeoff precision recall based metrics results
particularly sensitive weighting scheme used combine them  remarkably 
experiments show uir used predictor well differences
systems measured given test bed hold different test bed 

   introduction
many artificial intelligence tasks cannot evaluated single quality criterion 
sort weighted combination needed provide system rankings  many problems 
instance  require considering precision  p  recall  r  compare systems
performance  perhaps common combining function f measure  van rijsbergen         includes parameter sets relative weight metrics 
       metrics relative weight f computes harmonic mean 
problem weighted combination measures relative weights established
intuitively given task  time slight change relative weights may
produce substantial changes system rankings  reason behavior
overall improvement f often derives improvement one individual
c
    
ai access foundation  rights reserved 

fiamigo  gonzalo  artiles   verdejo

metrics expense decrement other  instance  system improves
system b precision loss recall  f may say better b viceversa 
depending relative weight precision recall  i e  value  
situation common one might expect  table   shows evaluation results
different tasks extracted acl       su et al         conference proceedings 
p r combined using f measure  paper considered
three evaluation results  one maximizes f  presented best result
paper  baseline  alternative method considered  note
cases  top ranked system improves baseline according f measure 
cost decreasing one metrics  instance  case paper word
alignment  average r grows              p decreases             
paper sentiment analysis  p increases four points r decreases five points 
reasonable assume contrastive system indeed improving baseline 
evaluation results alternative approach controversial  cases 
alternative approach improves best system according one metric  improved according other  therefore  depending relative metric weighting 
alternative approach could considered better worse best scored system 
conclusion parameter crucial comparing real systems 
practice  however  authors set        equal weights precision recall 
standard  agnostic choice requires justification  thus  without notion
much perceived difference systems depends relative weights
metrics  interpretation results f combination scheme
misleading 
goal is  therefore  find way estimating extent perceived difference
using metric combination scheme f robust changes relative
weights assigned individual metric 
paper propose novel measure  unanimity improvement ratio  uir  
relies simple observation  system improves system b according
individual metrics  the improvement unanimous   better b weighting
scheme  given test collection n test cases  test cases improvements
unanimous  robust perceived difference  average difference f
combination scheme  be 
words  well statistical significance tests provide information
robustness evaluation across test cases  is perceived difference two systems
artifact set test cases used test collection     uir meant provide
information robustness evaluation across variations relative metric
weightings  is perceived difference two systems artifact relative metric
weighting chosen evaluation metric    
experiments clustering test collections show uir contributes analysis
evaluation results two ways 
allows detect system improvements biased metric weighting
scheme  cases  experimenters carefully justify particular choice
relative weights check whether results swapped vicinity 
   

ficombining evaluation metrics via unanimous improvement ratio

systems
precision recall
f
task  word alignment  huang      
baseline
bm
     
           
max  f
link select
     
           
alternative

     
           
task  opinion question answering  li et al       
baseline
system  
    
    
    
max  f
ophit
    
    
    
alternative
oppagerank
    
    
  
task  sentiment analysis  kim et al      
baseline
baseline
    
    
    
max  f
vs lsa dtp
    
    
  
alternative
vs pmi
    
    
    
task  lexical reference rule extraction  shnarch et al      
baseline
expansion
  
  
  
max  f
wordnet wiki
  
  
  
alternative rules   dice filter
  
  
  
table    three way system comparisons taken acl      conference proceedings  su et al        

increases substantially consistency evaluation results across datasets  result
supported high unanimous improvement ratio much likely hold
different test collection  is  perhaps  relevant practical application
uir  predictor much result replicable across test collections 
although work presented paper applies research areas 
focus clustering task one relevant examples clustering
tasks specially sensitive metric relative weightings  research goals are 
   investigate empirically whether clustering evaluation biased precision
recall relative weights f  use one recent test collections
focused text clustering problem  artiles  gonzalo    sekine        
   introduce measure quantifies robustness evaluation results across
metric combining criteria  leads us propose uir measure  derived
conjoint measurement theory  luce   tukey        
   analyze empirically uir f measure complement other 
   illustrate application uir comparing systems context shared
task  measure uir serves predictor consistency evaluation
results across different test collections 

   

fiamigo  gonzalo  artiles   verdejo

figure    evaluation results semantic labeling conll     

   combining functions evaluation metrics
section briefly review different metrics combination criteria  present
rationale behind metric weighting approach well effects systems ranking 
    f measure
frequent way combining two evaluation metrics f measure  van rijsbergen         originally proposed evaluation information retrieval systems
 ir   use expanded many tasks  given two metrics p r  e g 
precision recall  purity inverse purity  etc    van rijsbergens f measure combines
single measure efficiency follows 
f  r  p    

  p   

 
        r   

f assumes value set particular evaluation scenario  parameter
represents relative weight metrics  cases value crucial 
particular  metrics correlated  instance  figure   shows precision
recall levels obtained conll      shared task evaluating semantic role labeling
systems  carreras   marquez         except one system  every substantial improvement
precision involves increase recall  case  relative metric weighting
substantially modify system ranking 
cases metrics completely correlated  decreasing marginal effectiveness property  van rijsbergen        ensures certain robustness across values  f
satisfies property  states large decrease one metric cannot compensated large increase metric  therefore  systems low precision
recall obtain low f values value  discussed detail section      however  show section      cases decreasing marginal
   

ficombining evaluation metrics via unanimous improvement ratio

effectiveness property prevent f measure overly sensitive small
changes value 

figure    example two systems evaluated break even point

    precision recall break even point
another way combining metrics consists evaluating system point one
metric equals  tao li   zhu         method applicable system
represented trade off metrics  instance  precision recall curve 
method relies idea increasing metrics implies necessarily overall
quality increase  instance  assumes obtaining     precision recall
point     better obtaining     precision recall point     
actually  break even point assumes relevance metrics  considers
precision recall point system distributes efforts equitably
metrics  indeed  could change relative relevance metrics computing
break even point 
figure   illustrates idea  continuous curve represents trade off
precision recall system s   straight diagonal represents points
metrics return score  quality system corresponds therefore
intersection diagonal precision recall curve  hand 
discontinuous curve represents another system s  achieves increase precision
low recall levels cost decreasing precision high recall levels  according
break even points  second system superior first one 
however  could give relevance recall identifying point recall doubles
precision  case  would obtain intersection points q   q   shown
figure  reverses quality order systems  conclusion  break even
point assumes arbitrary relative relevance combined metrics 
    area precision recall curve
approaches average scores every potential parameterization metric combining function  instance  mean average precision  map  oriented ir systems 
   

fiamigo  gonzalo  artiles   verdejo

computes average precision across number recall levels  another example
receiver operating characteristic  roc  function used evaluate binary classifiers
 cormack   lynam         roc computes probability positive sample receives
confidence score higher negative sample  independently threshold used
classify samples  functions related area auc exists
precision recall curve  cormack   lynam        
map roc low high recall regions relative relevance
computing area  again  could change measures order assign different
weights high low recall levels  indeed  weng   poon        weighted area
curve proposed  something similar would happen average f across different
values 
note measures applied certain kinds problem  binary
classification document retrieval  system output seen ranking 
different cutoff points ranking give different precision recall values 
directly applicable  particular  clustering problem focus work
here 

   combining metrics clustering tasks
section present metric combination experiments specific clustering task 
results corroborate importance quantifying robustness systems across different
weighting schemes 
    clustering task
clustering  grouping similar items  applications wide range artificial intelligence
problems  particular  context textual information access  clustering algorithms
employed information retrieval  clustering text documents according content
similarity   document summarization  grouping pieces text order detect redundant
information   topic tracking  opinion mining  e g  grouping opinions specific topic  
etc 
scenarios  clustering distributions produced systems usually evaluated
according similarity manually produced gold standard  extrinsic evaluation  
wide set metrics measure similarity  amigo  gonzalo  artiles   
verdejo         rely two quality dimensions   i  extent items
cluster belong group gold standard   ii 
extent items different clusters belong different groups gold standard 
wide set extrinsic metrics proposed  entropy class entropy  steinbach 
karypis    kumar        ghosh         purity inverse purity  zhao   karypis        
precision recall bcubed metrics  bagga   baldwin         metrics based counting
pairs  halkidi  batistakis    vazirgiannis        meila         etc  

   see work amigo et al         detailed overview 

   

ficombining evaluation metrics via unanimous improvement ratio

    dataset
weps  web people search  campaigns focused task disambiguating person
names web search results  input systems ranked list web pages retrieved
web search engine using person name query  e g  john smith  
challenge correctly estimate number different people sharing name
search results group documents referring individual  every person
name  weps datasets provide around     web pages top search results  using
quoted person name query  order provide different ambiguity scenarios  person
names sampled us census  wikipedia  listings program committee
members computer science conferences 
systems evaluated comparing output gold standard  manual grouping
documents produced two human judges two rounds  first annotated corpus
independently discussed disagreements together   note single
document assigned one cluster  amazon search results list 
instance  may refer books written different authors name  weps
task is  therefore  overlapping clustering problem  general case clustering
items restricted belong one single cluster  weps datasets
official evaluation metrics reflect fact 
experiments focused evaluation results obtained weps  
 artiles  gonzalo    sekine        weps    artiles et al         evaluation campaigns 
weps   corpus includes data web   test bed  mann        
used trial purposes follows similar annotation guidelines  although number
document per ambiguous name variable  refer corpora weps  a
 trial   weps  b weps      
    thresholds stopping criteria
clustering task involves three main aspects determine systems output quality 
first one method used measuring similarity documents  second
clustering algorithm  k neighbors  hierarchical agglomerative clustering  etc   
third aspect considered usually consists couple related variables fixed 
similarity threshold two pages considered related stopping
criterion determines clustering process stops and  consequently  number
clusters produced system 
figure   shows purity inverse purity values change different clustering
stopping points  one systems evaluated weps  b corpus     purity focuses
frequency common category cluster  amigo et al         
c set clusters evaluated  l set categories  reference distribution 
   weps datasets selected experiments  i  address relevant well defined
clustering task   ii  use widespread  weps datasets used hundreds experiments
since first weps evaluation        iii  runs submitted participants weps   weps  
available us  essential experiment different evaluation measures  weps datasets
freely available http   nlp uned es weps 
   system based bag words  tf idf word weighting  stopword removal  cosine distance
hierarchical agglomerative clustering algorithm 

   

fiamigo  gonzalo  artiles   verdejo

n number clustered items  purity computed taking weighted average
maximal precision values 
purity  

x  ci  


n

maxj precision ci   lj  

precision cluster ci given category lj defined as 
 ci lj  
precision ci   lj    
 ci  


purity penalizes noise cluster  reward grouping items
category together  simply make one cluster per item  reach trivially
maximum purity value  inverse purity focuses cluster maximum recall
category  inverse purity defined as 
inverse purity  

x  li  


n

maxj precision li   cj  

inverse purity rewards grouping items together  penalize mixing items
different categories  reach maximum value inverse purity making single
cluster items 
change stopping point implies increase purity cost decrease
inverse purity  viceversa  therefore  possible value f rewards different stopping
points  phenomenon produces high dependency clustering evaluation results
metric combining function 

figure    example trade off purity inverse purity optimizing
grouping threshold

   

ficombining evaluation metrics via unanimous improvement ratio

    robustness across values
determining appropriate value given scenario trivial  instance 
users point view weps task  easier discard irrelevant documents
good cluster  because precision perfect high recall 
check additional relevant documents clusters  because precision high
recall not   therefore  seems inverse purity priority purity 
i e   value      point view company providing
web people search service  however  situation quite different  priority
high precision  mixing profiles of  say  criminal doctor may result
company sued  perspective  receive high value 
weps campaign decided agnostic set neutral       value 
table   shows resulting system ranking weps  b according f set    
     ranking includes two baseline systems  b  consists grouping document
separate cluster  b    consists grouping documents one single cluster 
b  maximizes purity  b    maximizes inverse purity 
b  b    may obtain high low f measure depending value 
table shows        b  outperforms b    considerable number systems 
reason result that  weps  b test set  many singleton clusters
 people referred one web page   means default strategy
making one cluster per document achieve maximal purity 
acceptable inverse purity         however  fixed      b  goes bottom
ranking outperformed systems  including baseline b     
note outperforming trivial baseline system b  crucial optimize
systems  given optimization cycle could otherwise lead baseline approach
b    drawback b  informative  the output depend
input  and  crucially  sensitive variations   words  performance
robust changes metric combination criterion  remarkably  top scoring
system  s    best values  primary motivation article
quantify robustness across values order complement information given
traditional system ranking 
    robustness across test beds
average size clusters gold standard may change one test bed
another  affects purity inverse purity trade off  clustering system
may obtain different balance metrics different corpora  may
produce contradictory evaluation results comparing systems across different corpora 
even value 
instance  weps  b test bed  artiles et al          b  substantially outperforms
b          vs       using f        weps   data set  artiles et al          however 
b    outperforms b        versus        reason singletons less common
weps    words  comparison b    b  depends value
particular distribution reference cluster sizes test bed 
point system improvements robust across values  which
case b  b      affected phenomenon  therefore  estimating
   

fiamigo  gonzalo  artiles   verdejo

f    
ranked systems f result
s 
    
s 
    
s 
    
s 
    
s 
    
s 
    
s 
    
b 
    
s 
    
s 
    
s  
    
s  
    
s  
    
s  
    
s  
    
s  
    
b   
   
s  
   

f   
ranked systems
s 
s 
s 
s 
s 
s 
s  
s 
s  
s  
s  
s 
s  
s 
s  
b   
s  
b 

f result
    
    
    
    
    
    
    
    
    
    
    
    
    
    
   
    
    
    

table    weps  b system ranking according f     vs f     using purity inverse
purity

robustness system improvements changes prevent reaching contradictory
results different test beds  indeed  evidence presented section   

   proposal
primary motivation article quantify robustness across values
order complement information given traditional system rankings  end
introduce section unanimous improvement ratio 
    unanimous improvements
problem combining evaluation metrics closely related theory conjoint
measurement  see section     detailed discussion   van rijsbergen        argued
possible determine empirically metric combining function
adequate context information retrieval evaluation  however  starting
measurement theory principles  van rijsbergen described set properties metric
combining function satisfy  set includes independence axiom  also called
single cancellation   monotonicity property derives  monotonicity
property states quality system surpasses equals another one according
metrics necessarily equal better other  words  one system
   

ficombining evaluation metrics via unanimous improvement ratio

better dependence whatsoever relative importance
metric set 
define combination procedure metrics  unanimous improvement 
based property 
qx  a  qx  b  x x qx  a  qx  b 
qx  a  quality according set metrics x 
relationship dependence metrics scaled weighted 
degree correlation metric set  equality      derived directly  
unanimous equality implies systems obtain score metrics 
qx  a    qx  b   qx  a  qx  b    qx  b  qx  a  

strict unanimous improvement implies one system improves strictly
least one metric  improved according metric 
qx  a    qx  b   qx  a  qx  b    qx  a    qx  b  
 qx  a  qx  b    qx  b  qx  a  

non comparability k derived here  occurs metrics favor one
system metrics favor other  refer cases metric biased
improvements 
qx  a k qx  b   qx  a  qx  b    qx  b  qx  a  

theoretical properties unanimous improvement described depth
section      important property unanimous improvement
relational structure depend relative metric weightings  satisfying
independence  monotonicity  axiom  words  claim that  system improvement according metric combining function depend whatsoever metric
weightings quality decrease according individual metric 
theoretical justification assertion developed section       
    unanimous improvement ratio
according unanimous improvement  unique observable test case
three valued function  unanimous improvement  equality biased improvement   need 
however  way quantitatively comparing systems 
given two systems  b  unanimous improvement relationship set
test cases   samples improves b  qx  a  qx  b    samples b improves  qx  b  qx  a   samples biased improvements  qx  a k qx  b   
refer sets ta b   tb tak b   respectively  unanimous improvement ratio  uir  defined according three formal restrictions 
   

fiamigo  gonzalo  artiles   verdejo

test cases
 
 
 
 
 
 
 
 
 
  

precision
system system b
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

recall
system system b
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

b
yes
yes
yes
yes
yes
yes





b
yes
yes




yes
yes



table    example experiment input compute uir
   uir a  b  decrease number biased improvements  tak b   
boundary condition samples biased improvements  tak b     
uir a  b    
   improves b much b improves  ta b   tb   uir a  b      
   given fixed number biased improvements  tak b    uir a  b  proportional
ta b inversely proportional tb  
given restrictions  propose following uir definition 
uirx t  a  b   

 ta b    tb  
 
 t  

 t  qx  a  qx  b    t  qx  b  qx  a  
 t  
alternatively formulated as 
uirx t  a  b    p a b  p b a 
probabilities estimated frequentist manner 
uir range        symmetric  uirx t  a  b    uirx t  b  a  
illustration uir computed  consider experiment outcome table    systems
b compared terms precision recall    test cases  test case   
instance  unanimous improvement b  better terms precision
            recall              table  uir value is 
uirx t  a  b   

 ta b    tb  
  
 
        uirx t  b  a 
 t  
  

uir two formal limitations  first  transitive  see section       therefore 
possible define linear system ranking based uir  is  however 
   

ficombining evaluation metrics via unanimous improvement ratio

necessary  uir meant provide ranking  complement ranking provided
f measure  or metric combining function   indicating robust results
changes   section     illustrates uir integrated insights provided
system ranking 
second limitation uir consider improvement ranges  therefore 
less sensitive f measure  empirical results  however  show uir
sensitive enough discriminate robust improvements versus metric biased improvements 
section   make empirical comparison non parametric definition uir
parametric version  results make non parametric definition preferable 

   theoretical foundations
section discuss theoretical foundations unanimous improvement ratio
framework conjoint measurement theory  proceed describe
formal properties uir implications point view evaluation
methodology  readers interested solely practical implications using uir may
proceed directly section   
    conjoint measurement theory
problem combining evaluation metrics closely related conjoint measurement theory  independently discovered economist debreu       
mathematical psychologist r  duncan luce statistician john tukey  luce   tukey 
       theory measurement defines necessary conditions state homomorphism empirical relational structure  e g  john bigger bill 
numeric relational structure  johns height      meters bills height      meters  
case conjoint measurement theory  relational structure factored
two  or more  ordered substructures  e g  height weight  
context  numerical structures given evaluation metric scores  e g 
purity inverse purity   however  empirical quality ordering
clustering systems  different human assessors could assign relevance purity
inverse purity viceversa  nevertheless  conjoint measurement theory provide
mechanisms state kind numerical structures produce homomorphism
assuming empirical structure satisfies certain axioms  van rijsbergen        used
idea analyze problem combining evaluation metrics  axioms shape
additive conjoint structure   r  p   quality system according two evaluation
metrics r p   axioms are 
connectedness  systems comparable other  formally   r  p  
 r    p      r    p      r  p   
transitivity   r  p    r    p      r    p      r     p      implies  r  p    r     p      
axioms transitivity connectedness shape weak order 
thomsen condition   r    p     r    p     r    p     r    p    imply  r    p   
 r    p     where indicates equal effectiveness  
   

fiamigo  gonzalo  artiles   verdejo

independence  two components contribute effects independently effectiveness  formally   r    p    r    p   implies  r    p      r    p     p    
 r  p     r  p    implies  r    p     r    p    r    property implies
monotonicity  narens   luce        states improvement metrics necessarily produces improvement according metric combining function 
restricted solvability  property     concerned continuity
component  makes precise intuitively would expect considering
existence intermediate levels  formally  whenever  r    p      r  p    r    p    
exists r  r    p        r  p   
essential components  variation one leaving constant gives variation effectiveness  exists r  r  p case
 r  p      r    p    exists p   p   r case
 r  p      r  p     
archimedean property  merely ensures intervals component
comparable 
f measure proposed van rijsbergen        arithmetic mean p r
satisfy axioms  according restrictions  indeed  unlimited set acceptable combining functions evaluation metrics defined  f relational structure 
however  satisfies another property satisfied functions
arithmetic mean  property decreasing marginal effectiveness  basic idea
increasing one unit one metric decreasing one unit metric
improve overall quality  i e  first metric weight combining function   imply great loss one metric compensated great
increase other  defined as 
r  p      n       p   n  r n     r  p   
according this  high values metrics required obtain high overall
improvement  makes measures observing property   f   robust
arbitrary metric weightings 
    formal properties unanimous improvement
unanimous improvement x trivially satisfies desirable properties proposed van rijsbergen        metric combining functions  transitivity  independence 
thomsen condition  restricted solvability  essential components decreasing marginal
effectiveness  exception connectedness property    given non comparability k  biased improvements  see section      derived unanimous improvement  possible find system pairs neither qx  a  qx  b  qx  b  qx  a 
hold  therefore  connectedness satisfied 
formally  limitation unanimous improvement represent
weak order  cannot satisfy transitivity connectedness simultaneously  let
us elaborate issue 
   sake simplicity  consider combination two metrics  r  p   

   

ficombining evaluation metrics via unanimous improvement ratio

systems

b
c

metric x 
   
   
    

metric x 
   
   
    

table    counter sample transitivity unanimous improvement
could satisfy connectedness considering biased improvements represent
equivalent system pairs       case  transitivity would satisfied  see 
instance  table    according table 
qx  b k qx  a  qx  c k qx  b 
therefore  considering k represents equivalence  have 
qx  b  qx  a  qx  c  qx  b 

qx  c  qx  a 
summary  choose satisfy transitivity connectedness  both 
unanimous improvement derive weak order 
      uniqueness unanimous improvement
unanimous improvement interesting property contradict
evaluation result given f measure  regardless value used f 
qx  a  qx  b  f  a  f  b 
due fact f measure  for value  satisfies monotonicity
axiom  unanimous improvement grounded  property essential
purpose checking robustness system improvements across values 
crucially  unanimous improvement function satisfies property 
precisely  unanimous improvement relational structure that  satisfying
monotonicity  contradict additive conjoint structure  see section      
order prove assertion  need define concept compatibility
additive conjoint structure  let add additive conjoint structure let r
relational structure  say r compatible conjoint structure
if 
ha  b  add i  qx  a  r qx  b    qx  a  add qx  b  
words  r holds  additive conjoint holds  want prove
unanimous improvement relation satisfies property  therefore 
prove r monotonic compatible relational structure 
necessarily matches unanimous improvement definition 
   

fiamigo  gonzalo  artiles   verdejo

r monotonic compatible    qx  a  r qx  b  xi  a  xi  b xi x 
split in 
    r monotonic compatible    qx  a  r qx  b  xi  a  xi  b xi x 
    r monotonic compatible    qx  a  r qx  b  xi  a  xi  b xi x 
proving     immediate  since rightmost component corresponds monotonicity property definition  let us prove     reductio ad absurdum  assuming
exists relational structure that 
 o monotonic compatible   qx  a  qx  b    xi x xi  a    xi  b  
case  could define additive conjoint structure combined measure
q x  a      x   a    i xi  a    n xn  a  big enough q x  a    q x  b  
q  additive conjoint structure would contradict   therefore  would compatible
 contradiction   conclusion  predicate     true unanimous improvement x
monotonic compatible relational structure 
interesting corollary derived analysis  unanimous improvement compatible relational structure  formally conclude
measurement system improvements without dependence metric weighting schemes
derive weak order  i e  one satisfies transitivity connectedness  
corollary practical implications  possible establish system ranking
independent metric weighting schemes 
natural way proceed is  therefore  use unanimous improvement addition
standard f measure  for suitable value  provides additional information
robustness system improvements across values 

   f versus uir  empirical study
section perform number empirical studies weps corpora order
find uir behaves practice  first  focus number empirical results
show uir rewards robustness across values  information complementary information provided f  second  examine extent f
uir correlated 
    uir  rewarding robustness
figure   shows three examples system comparisons weps  b corpus using metrics
purity inverse purity  curve represents f value obtained one system
according different values  system s   black curves  compared s    s 
s    grey curves  three graphs  cases similar quality increase
according f       uir  however  ranges            depending robust
difference changes   highest difference uir  s  s    system
pair  rightmost graph   systems swap f values value 
   

ficombining evaluation metrics via unanimous improvement ratio

    f      
 uir 

improvements

    system pairs 
    
    

cases
     system pairs 
    
    

table    uir f     increase f increases values

figure    f measure vs  uir  rewarding robustness
smallest uir value  s  s     s  better s   values
     worse larger  comparison illustrates uir captures  similar
increments f  ones less dependent relative weighting scheme
precision recall 
let us consider two system combinations weps  b corpus  dividing
two sets   i  system pairs f increases values  i e  purity
inverse purity increases    ii  pairs relative systems performance swaps
value  i e  f increases values decreases rest 
one would expect average increase f larger system pairs
one beats every value  surprisingly  true  table   shows
average increments uir f     sets  uir behaves expected  average
value substantially larger set different lead contradictory results
      vs         average relative increase f       however  similar
sets       vs        
conclusion certain f     improvement range say anything
whether purity inverse purity simultaneously improved not 
words  matter large measured improvement f is  still extremely
dependent weighting individual metrics measurement 
conclusion corroborated considering independently metrics  purity inverse purity   according statistical significance improvements
independent metrics  distinguish three cases 
   opposite significant improvements  one metrics  purity inverse purity 
increases decreases  changes statistically significant 
   

fiamigo  gonzalo  artiles   verdejo

    f      
 uir 

significant
concordant
improvements
   pairs
    
    

significant
opposite
improvements
   pairs
    
    

non
significant
improvements
   pairs
    
     

table    uir f     increases vs  statistical significance tests
   concordant significant improvements  metrics improve significantly least
one improves significantly decrease significantly 
   non significant improvements  statistically significant differences
systems metric 
use wilcoxon test p        detect statistical significance  table  
shows average uir     f       values three cases  remarkably 
f     average increase even larger opposite improvements set       
concordant improvements set         according results  would seem
f     rewards individual metric improvements obtained cost  smaller 
decreases metric  uir  hand  sharply different behavior 
strongly rewarding concordant improvements set       versus       
results confirm uir provides essential information experimental
outcome two system comparisons  provided main evaluation metric
f  
    correlation f uir
fact uir f offer different information outcome experiment
imply uir f orthogonal  fact  correlation
values 
figure   represents f     differences uir values possible system pair
weps   test bed  general trends  i  high uir values imply positive difference
f  ii  high   f       values imply anything uir values   iii  low uir seem
imply anything   f       values  overall  figure suggest triangle relationship 
gives pearson correlation      
      reflecting improvement ranges
consistent difference two systems values  uir rewards
larger improvement ranges  let us illustrate behavior considering three sample system
pairs taken weps   test bed 
figure   represents f      values three system pairs  cases  one system
improves values  however  uir assigns higher values larger improvements f  larger distance black grey curves   reason
   

ficombining evaluation metrics via unanimous improvement ratio

figure      f       vs uir

figure    f vs  uir  reflecting improvement ranges
larger average improvement test cases makes less likely cases individual test
cases  which ones uir considers  contradict average result 
another interesting finding that  metrics improved  metric
weakest improvement determines behavior uir  figure   illustrates
relationship ten system pairs largest improvement  pearson correlation
graph       words  individual metrics improve  uir sensitive
weakest improvement 
      analysis boundary cases
order better understanding relationship uir f 
examine detail two cases system improvements uir f produce drastically
different results  two cases marked b figure   
point marked case figure corresponds comparison systems
s  s     exists substantial  and statistically significant  difference
systems according f       however  uir low value  i e   improvement
robust changes according uir 
   

fiamigo  gonzalo  artiles   verdejo

figure    correlation uir weakest single metric improvement 

figure    purity inverse purity per test case  systems s  s   
visual explanation results seen figure    shows purity
inverse purity results systems s    s   every test case  test cases  s 
important advantage purity cost slight consistent loss inverse
purity  given f     compares purity inverse purity ranges  states
exists important statistically significant improvement s   s    however 
slight consistent decrease inverse purity affects uir  decreases
test cases improvements f metric biased  k notation  
case b  see figure    opposite example  small difference systems
s  s   according f       differences purity inverse purity
small  s   however  gives small consistent improvements purity inverse
purity  all test cases right vertical line figure   unanimous
improvements  therefore  uir considers exists robust overall improvement
case 
   

ficombining evaluation metrics via unanimous improvement ratio

figure    purity inverse purity per test case  systems s    s 
again  cases show uir gives additional valuable information comparative behavior systems 
    significance threshold uir
mentioned earlier uir parallelism statistical significance tests 
typically used information retrieval estimate probability p observed
difference two systems obtained chance  i e   difference artifact
test collection rather true difference systems  computing
statistical significance  useful establish threshold allows binary decision 
instance  result often said statistically significant p         significant
otherwise  choosing level significance arbitrary  nevertheless helps reporting
summarizing significance tests  stricter thresholds increase confidence test 
run increased risk failing detect significant result 
situation applies uir  would establish uir threshold
decides whether observed difference reasonably robust changes   set
threshold  could restrictive decide  instance  improvement
significantly robust uir       condition  however  hard would
never satisfied practice  therefore uir test would informative 
hand  set permissive threshold satisfied system
pairs and  again  informative  question whether exists
threshold uir values obtaining uir threshold guarantees
improvement robust  and  time  strong satisfied practice 
given set two system combinations uir surpasses certain candidate
threshold  think desirable features 
   must able differentiate two types improvements  robust vs  nonrobust   words  one two types usually empty almost empty 
threshold informative 
   

fiamigo  gonzalo  artiles   verdejo

   robust set contain high ratio two system combinations
average f increases values  f  a    f  b   
   robust set contain high ratio significant concordant improvements
low ratio significant opposite improvements  see section      
   robust set contain low ratio cases f contradicts uir  the dots
figure   region   f            

figure     improvement detected across uir thresholds
figure    shows conditions met every threshold range          
uir threshold      accepts around     system pairs  low      ratio
significant opposite improvements high       ratio significant concordant improvements  threshold  half robust cases f increases values 
cases       f     increases  seems  therefore  uir      reasonable
threshold  least clustering task  note  however  rough rule thumb
revised adjusted dealing clustering tasks weps 
    uir system rankings
results presented far focused pairwise system comparisons  according
nature uir  turn question use uir component
analysis results evaluation campaign 
order answer question applied uir results weps  
evaluation campaign  artiles et al          campaign  best runs system
ranked according bcubed precision recall metrics  combined f      
addition participant systems  three baseline approaches included ranking 
   

ficombining evaluation metrics via unanimous improvement ratio

documents one cluster  b       document one cluster  b    union
 bcomb     
table   shows results applying uir weps   participant systems   robust
improvements represented third column  improved systems   every system 
displays set systems improves uir       fourth column
reference system  defined follows  given system a  reference system
one improves maximal uir 
sref  a    argmaxs  uir s  a  
words  sref  a  represents system replaced order
robustly improve results across different values  finally  last column  uir
reference system  displays uir system reference  uir sref   si    
note uir adds new insights evaluation process  let us highlight two
interesting facts 
although three top scoring systems  s   s   s   similar performance
terms f                    s  consistently best system according uir 
reference    systems  s   s   s   s   s    s    s    s   
s   baseline b     contrast  s  reference s  only  s  reference
s   only  therefore  f uir together strongly point towards s  best
system  f alone able discern set three top scoring systems 
although non informative baseline b     all documents one cluster  better
five systems according f  improvement robust according uir 
note uir signal near baseline behaviors participant systems low
value  receive large f depending nature test collection 
average cluster large small  systems tend cluster everything
nothing artificially rewarded  is  opinion  substantial improvement
using f alone 

   uir predictor stability results across test collections
common issue evaluating systems deal natural language results
different test collections often contradictory  particular case text clustering 
factor contributes problem average size clusters vary across
different test beds  variability modifies optimal balance precision
recall  system tends favor precision  creating small clusters  may good
results dataset small average cluster size worse results test collection
larger average cluster size 
therefore  apply f combine single metrics  reach contradictory
results different test beds  uir depend metric weighting criteria 
hypothesis high uir value ensures robustness evaluation results across test beds 
   see work artiles et al         extended explanation 

   

fiamigo  gonzalo  artiles   verdejo

system

f   

s 
s 
s 
s 
s 
s 
s 
s 
s 
s  
s  
s  
b   
s  

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

bcomb
s  
s  
s  
b 
s  

improved systems
 uir        
s  s  s  s  s  s    s   b 
s  s  s  s  s    s   b 
s  s  s  s  s    s   b 
s   s    s  
s    s  
s  s  s   s    s   b 
s   s    s  
s    s  
s  s   s   s  
s    s  
s    s  
s   s  
bcomb
s   s  
s  
s  
 

reference
system
s 
s 
s 
s 
s 
s 
s 
s 
b   
s 
s 
s 
s 
s 

uir
reference system
    
    
    
    
    
    
    
   
    
   
    
    
    
    

table    weps   results bcubed precision recall  f uir measures
words  given particular test bed  high uir value good predictor
observed difference two systems still hold test beds 
following experiment designed verify hypothesis  implemented
four different systems weps problem  based agglomerative clustering algorithm  hac  used best systems weps    system employs
certain cluster linkage technique  complete link single link  certain feature extraction criterion  word bigrams unigrams   system experimented   
stopping criteria  therefore  used   x  system variants overall  evaluated
systems weps  a  weps  b weps   corpora   
first observation that  given system pairs  f     gives consistent results
three test beds     cases  system pairs  best system
different depending test collection  robust evaluation criterion predict 
given single test collection  whether results still hold collections 
consider two alternative ways predicting observed difference  system
better system b  one test bed still hold three test beds 
first using f  a  f  b   larger value reference test bed 
likely f  a  f  b  still positive different test collection 
   weps  a originally used training first weps campaign  weps  b used testing 

   

ficombining evaluation metrics via unanimous improvement ratio

second using u ir a  b  instead f  larger uir is  likely
f  a  f  b  positive different test bed 
summary  want compare f uir predictors robust result
change test collection  tested it 
   select reference corpus weps  a  weps  b weps   test beds 
cref  weps  a weps  b weps   
   system pair reference corpus  compute improvement one
system respect according f uir  take system pairs
one improves certain threshold t  uirc  s    s   
uir results systems s  s  test bed c  fc  s  results f
system test bed c 
su ir t  c      s    s    uirc  s    s      t 
sf t  c     s    s    fc  s    fc  s       t  
every threshold t  su ir t sf t represent set robust improvements
predicted uir f  respectively 
   then  consider system pairs one improves according f
three test collections simultaneously 
   s    s   fc  s      fc  s   c 
gold standard compared predictions su ir t sf t  
   every threshold t  compute precision recall uir f predictions
 su ir t  c  sf t  c   versus actual set robust results across collections
 t   
p recision su ir t  c    

 su ir t  c   
 su ir t  

p recision sf t  c    

 sf t  c   
 sf t  c  

recall su ir t  c    

recall sf t  c    

 su ir t  c   
 t  

 sf t  c   
 t  

trace precision recall curve predictors f  uir
compare results  figures            show precision recall values f  triangles 
uir  rhombi   figure displays results one reference test beds  weps a weps  b weps     
altogether  figures show uir much effective f predictor 
note f suffers sudden drop performance low recall levels  suggests
   curve parametric uir refers alternative definition uir explained section  

   

fiamigo  gonzalo  artiles   verdejo

figure     predictive power uir f weps  a

figure     predictive power uir f weps  b

   

ficombining evaluation metrics via unanimous improvement ratio

figure     predictive power uir f weps  
big improvements f tend due peculiarities test collection rather
real superiority one system versus other 
is  opinion  remarkable result  differences uir better indicators
reliability measured difference f amount measured difference 
therefore  uir useful know stable results changes  
changes test collection  i e   indicator reliable perceived difference
is 
note explicitly tested dependency  and reliability  uir results
number test cases reference collection  however  working
collection less    test cases unlikely  practical terms usability uir
granted test collections  least respect number test cases 

   parametric versus non parametric uir
according analysis  see section       given two measures p r  relational
structure pairs hpi   ri depend weighting criteria unanimous
improvement 
b pa pb ra rb
comparing systems  uir measure counts unanimous improvement results
across test cases 
uirx t  a  b   

 ta b    tb  
 t  

alternatively  formulation expressed terms probabilities 
   

fiamigo  gonzalo  artiles   verdejo

uirx t  a  b    prob a b  prob b a 
probabilities estimated frequentist manner 
said  main drawback unanimous improvement threevalued function consider metric ranges  uir inherits drawback 
consequence  uir less sensitive combining schemes f measure 
order solve drawback  could estimate uir parametrically  however  results
section seem indicate best option 
one way estimating p rob a b  p rob b a  consists assuming
metric differences  p  r  two systems across test cases follow normal bivariate
distribution  estimate distribution case samples provided
test bed  estimating density function p rob p  r   estimate p rob a
b  as   
p rob a b    p rob p   r     

z p    r  

p rob p  r  dp dr
p    r  

expression used compute uirx t  a  b    prob a b  prob b a  
leads parametric version uir 
order compare effectiveness parametric uir versus original uir 
repeated experiment described section    adding uirparam precision recall
curves figures            squares figures represent results
parametric version uir  note behavior lies somewhere f nonparametric uir  low levels recall  behaves original uir  intermediate
levels  general worse original definition better f 
recall high end  overlaps results f  probably due fact
parametric uir estimation considers ranges  becomes sensitive unreliability
high improvements f 

   conclusions
work addressed practical problem strong dependency  and usually
degree arbitrariness  relative weights assigned metrics applying metric
combination criteria  f  
based theory measurement  established relevant theoretical results  fundamental one monotonic relational structure
contradict additive conjoint structure  unique relationship
transitive  implies possible establish ranking  a complete ordering  systems without assuming arbitrary relative metric weighting  transitive
relationship  however  necessary ensure robustness specific pairwise system
comparisons 
based theoretical analysis  introduced unanimous improvement ratio  uir   estimates robustness measured system improvements across potential
metric combining schemes  uir measure complementary metric combination
   computation employed matlab tool

   

ficombining evaluation metrics via unanimous improvement ratio

scheme works similarly statistical relevance test  indicating perceived difference two systems reliable biased particular weighting scheme used
evaluate overall performance systems 
empirical results text clustering task  particularly sensitive
problem  confirm uir indeed useful analysis tool pairwise system comparisons   i  similar increments f  uir captures ones less dependent
relative weighting scheme precision recall   ii  unlike f  uir rewards system
improvements corroborated statistical significance tests single measure   iii  practice  high uir tends imply large f increase  large increase
f imply high uir  words  large increase f completely
biased weighting scheme  therefore uir essential information add f 
looking results evaluation campaign  uir proved useful  i  discern
best system among set systems similar performance according f  
 ii  penalize trivial baseline strategies systems baseline like behavior 
perhaps relevant result side effect proposed measure defined 
uir good estimator robust result changes test collection 
words  given measured increase f test collection  high uir value makes
likely increase observed test collections  remarkably  uir
estimates cross collection robustness f increases much better absolute value
f increase 
limitation present study tested uir text clustering
problem  usefulness clustering problems already makes uir useful analysis
tool  potential goes well beyond particular problem  natural language problems and  general  many problems artificial intelligence evaluated terms
many individual measures trivial combine  uir powerful tool
many scenarios 
uir evaluation package available download http   nlp uned es 

acknowledgments
research partially supported spanish government  grant holopedia 
tin           c    regional government madrid research network
ma vicmr  s     tic       

references
amigo  e   gonzalo  j   artiles  j     verdejo  f          comparison extrinsic clustering
evaluation metrics based formal constraints  information retrieval                 
artiles  j   gonzalo  j     sekine  s          weps   evaluation campaign  overview
web people search clustering task  proceedings  nd web people search
evaluation workshop  weps       
artiles  j   gonzalo  j     sekine  s          semeval      weps evaluation  establishing benchmark web people search task  proceedings  th
international workshop semantic evaluations  semeval     pp       stroudsburg  pa  usa  association computational linguistics 
   

fiamigo  gonzalo  artiles   verdejo

bagga  a     baldwin  b          entity based cross document coreferencing using
vector space model  proceedings   th annual meeting association
computational linguistics   th international conference computational
linguistics  coling acl     pp       
carreras  x     marquez  l          introduction conll      shared task  semantic
role labeling  ng  h  t     riloff  e   eds    hlt naacl      workshop  eighth
conference computational natural language learning  conll        pp      
boston  massachusetts  usa  association computational linguistics 
cormack  g  v     lynam  t  r          trec      spam track overview  proceedings
fourteenth text retrieval conference  trec       
debreu  g          topological methods cardinal utility theory  mathematical methods
social sciences  stanford university press               
ghosh  j          scalable clustering methods data mining  ye  n   ed    handbook
data mining  lawrence erlbaum 
halkidi  m   batistakis  y     vazirgiannis  m          clustering validation techniques 
journal intelligent information systems                   
luce  r     tukey  j          simultaneous conjoint measurement  new scale type
fundamental measurement  journal mathematical psychology        
mann  g  s          multi document statistical fact extraction fusion  ph d  thesis 
johns hopkins university 
meila  m          comparing clusterings  proceedings colt    
narens  l     luce  r  d          measurement  theory numerical assignments  psychological bulletin     
steinbach  m   karypis  g     kumar  v          comparison document clustering
techniques  kdd workshop text mining      
su  k  y   su  j   wiebe  j     li  h   eds            proceedings joint conference
  th annual meeting acl  th international joint conference
natural language processing afnlp  association computational linguistics  suntec  singapore 
tao li  c  z     zhu  s          empirical studies multilabel classification  proceedings   th ieee international conference tools artificial intelligence
 ictai       
van rijsbergen  c  j          foundation evaluation  journal documentation         
       
weng  c  g     poon  j          new evaluation measure imbalanced datasets 
roddick  j  f   li  j   christen  p     kennedy  p  j   eds    seventh australasian
data mining conference  ausdm        vol     crpit  pp       glenelg  south
australia  acs 
zhao  y     karypis  g          criterion functions document clustering  experiments
analysis  technical report tr       department computer science  university minnesota  minneapolis  mn 
   


