journal artificial intelligence research                  

submitted        published      

finding consensus bayesian network structures
jose m  pena

jose m pena liu se

adit
department computer information science
linkoping university
se       linkoping
sweden

abstract
suppose multiple experts  or learning algorithms  provide us alternative
bayesian network  bn  structures domain  interested combining
single consensus bn structure  specifically  interested
consensus bn structure represents independences given bn structures agree
upon parameters associated possible  paper  prove
may exist several non equivalent consensus bn structures finding one
np hard  thus  decide resort heuristics find approximated
consensus bn structure  paper  consider heuristic proposed matzkevich
abramson  builds upon two algorithms  called methods b  efficiently
deriving minimal directed independence map bn structure relative given node
ordering  methods b claimed correct although proof provided  a
proof sketched   paper  show methods b correct
propose correction them 

   introduction
bayesian networks  bns  popular graphical formalism representing probability distributions  bn consists structure parameters  structure  directed acyclic
graph  dag   induces set independencies represented probability distribution
satisfies  parameters specify conditional probability distribution node given
parents structure  bn represents probability distribution results
product conditional probability distributions  typically  single expert
 or learning algorithm  consulted construct bn domain hand  therefore 
risk so constructed bn accurate could if  instance 
expert bias overlooks certain details  one way minimize risk consists
obtaining multiple bns domain multiple experts and  then  combining
single consensus bn  approach received significant attention literature  matzkevich   abramson            b  maynard reid ii   chajewska        nielsen
  parsons        pennock   wellman        richardson   domingos        del sagrado
  moral         relevant references probably work pennock
wellman         shows even experts agree bn structure 
method combining experts bns produces consensus bn respects
reasonable assumptions whose structure agreed bn structure  unfortunately 
problem often overlooked  avoid it  propose combine experts bns
c
    
ai access foundation  rights reserved 

fipena

two steps  first  finding consensus bn structure and  then  finding consensus
parameters consensus bn structure  paper focuses first step  we
briefly discuss second step section     specifically  assume multiple experts
provide us alternative dag models domain  interested combining
single consensus dag  specifically  interested consensus
dag represents independences given dags agree upon many
possible  words  consensus dag dag represents independences among minimal directed independence  mdi  maps intersection
independence models induced given dags   knowledge  whether
consensus dag cannot found efficiently still open problem  see work
matzkevich abramson            b  information  paper  redefine
consensus dag dag fewest parameters associated among
mdi maps intersection independence models induced given dags 
definition line finding dag represent probability distribution p 
desired dag typically defined mdi map p fewest parameters
associated rather mdi map p represents independences  see 
instance  work chickering et al          number parameters associated
dag measure complexity dag  since number parameters
required specify probability distributions represented dag 
paper  prove may exist several non equivalent consensus dags
finding one np hard  thus  decide resort heuristics find
approximated consensus dag  paper  consider following heuristic due
matzkevich abramson            b   see work matzkevich abramson
     a  related information  first  let denote ordering nodes given
dags  denote g            gm   then  find mdi map gi gi relative
  finally  let approximated consensus dag dag whose arcs exactly
union arcs g            gm
  mentioned formulation
heuristic differs matzkevich abramson            b  following two
points  first  heuristic introduced original definition consensus dag 
justify later heuristic makes sense definition consensus dag 
second  originally required consistent one given dags  remove
requirement  all  key step heuristic finding mdi map gi
gi   since task trivial  matzkevich abramson      b  present two algorithms 
called methods b  efficiently deriving gi gi   methods b claimed
correct although proof provided  a proof sketched   paper 
show methods b correct propose correction them 
said  first study problem finding consensus dag  addition works discussed matzkevich abramson            b  pennock
wellman         works devoted problem maynard reid
ii chajewska         nielsen parsons         richardson domingos        
   worth mentioning term consensus dag different meaning computational biology
 jackson et al          there  consensus dag given set dags g            gm defined
dag contains arcs g            gm   therefore  difficulty lies keeping many
arcs possible without creating cycles  note that  unlike present work  dag interpreted
inducing independence model jackson et al 

   

fifinding consensus bayesian network structures

del sagrado moral         elaborate differences works
ours  maynard reid ii chajewska        propose adapt existing score based algorithms learning dags data case learning data replaced
bns provided experts  approach suffers problem pointed pennock
wellman         consists essentially learning consensus dag
combination given bns  somehow related approach proposed richardson
domingos         specifically  propose bayesian approach learning dags
data  prior probability distribution dags constructed dags
provided experts  since approach requires data combine
given dags single dag  addresses problem rather different one
paper  moreover  construction prior probability distribution dags ignores
fact given dags may different equivalent  is  unlike
present work  dag interpreted inducing independence model  work
relatively close del sagrado moral         specifically  show
construct mdi map intersection union independence models
induced dags provided experts  however  three main differences
work ours  first  unlike us  assume given dags
defined set nodes  second  unlike us  assume exists
node ordering consistent given dags  third  goal find mdi
map whereas find mdi map fewest parameters associated among
mdi maps  i e  consensus dag  finally  nielsen parsons        develop
general framework construct consensus dag gradually  framework general
sense tailored particular definition consensus dag  instead 
relies upon score defined user expert use score different
extensions current partial consensus dag  individual scores combined
choose extension perform  unfortunately  see framework could
applied definition consensus dag 
worth recalling paper deals combination probability distributions expressed bns  readers interested combination probability distributions expressed non graphical numerical forms referred to  instance  work
genest zidek         note interested combination
data observed  readers interested combination data
observed expert updated beliefs accordingly referred to  instance 
work ng abramson         finally  note aim combining given
dags dag  consensus dag  readers interested finding dag
graphical features  e g  arcs paths  significant number experts agree upon may
want consult works friedman koller         hartemink et al          pena et
al          since works deal similar problem 
rest paper organized follows  start reviewing preliminary
concepts section    analyze complexity finding consensus dag section
   discuss heuristic finding approximated consensus dag detail
section    introduce methods b section   show correct 
correct section    analyze complexity corrected methods
b section   show efficient approach think
solve problem  close discussion section   
   

fipena

   preliminaries
section  review concepts used paper  dags  probability
distributions independence models paper defined v  unless otherwise
stated  b dag g  say b adjacent g  moreover 
say parent b b child g  denote parents b g
p ag  b   node called sink node g children g  route
two nodes b g sequence nodes starting ending b
every two consecutive nodes sequence adjacent g  note nodes
route necessarily distinct  length route number  not necessarily
distinct  arcs route  treat nodes g routes length zero  route
b called descending b arcs route directed
towards b  descending route b  b called descendant a 
note descendant itself  since allow routes length zero  given subset
x v  node x called maximal g descendant node x    a 
g  given route b g route   b c g   
denotes route c g resulting appending    
p
q
number parameters associated dag g bv   ap ag  b  ra   rb    
ra rb numbers states random variables corresponding
node b  arc b g said covered p ag  a    p ag  b     a  
covering arc b g mean adding g smallest set arcs b
becomes covered  say node c collider route dag exist two
nodes b c b subroute route  note b may
coincide  let x  z denote three disjoint subsets v  route dag said
z active  i  every collider node route z   ii  every non collider node
route outside z  route dag g node x
node z active  say x separated given z g denote
x g y z  denote x   g y z x g y z hold  definition
separation equivalent common definitions  studeny        section      
let x  y  z w denote four disjoint subsets v  let us abbreviate x
xy  independence model set statements form x y z  meaning
x independent given z  given subset u v  denote  m  u
statements x  y  z u  given two independence models n  
denote n x y z x n y z  say graphoid
satisfies following properties  symmetry x y z x z  decomposition
x yw z x y z  weak union x yw z x y zw  contraction
x y zw x w z x yw z  intersection x y zw x
w zy x yw z  independence model induced probability distribution p 
denoted i p   set probabilistic independences p  independence model
induced dag g  denoted i g   set separation statements x g y z 
known i g  graphoid  studeny   bouckaert        lemma       moreover  i g 
satisfies composition property x g y z x g w z x g yw z  chickering  
meek        proposition     two dags g h called equivalent i g    i h  
dag g directed independence map independence model i g   
moreover  g minimal directed independence  mdi  map removing arc
   

fifinding consensus bayesian network structures

g makes cease directed independence map   say g
ordering nodes consistent when  every arc b g  precedes b
node ordering  say dag g mdi map independence model
relative node ordering g mdi map g consistent  
graphoid  g unique  pearl        thms        specifically  node
a  p ag  a  smallest subset x predecessors   p  a  
p  a    x x 

   finding consensus dag np hard
recall defined consensus dag given set dags g            gm

dag fewest parameters associated among mdi maps
i   i g   
sensible way start quest consensus dag investigating whether
exist several non equivalent consensus dags  following theorem answers question 
theorem    exists set dags two non equivalent consensus dags 
proof  consider following two dags four random variables number
states each 


k



j







l

k



j

l

following two non equivalent dags consensus dag two dags
above 


k


 




k

j

l


 


j

l

natural follow up question investigate whether consensus dag found
efficiently  unfortunately  finding consensus dag np hard  prove below  specifically  prove following decision problem np hard 
consensus
instance  set dags g            gm v  positive integer d 

question  exist dag g v i g 
i   i g  
number parameters associated g greater  

proving consensus np hard implies finding consensus dag
np hard  existed efficient algorithm finding consensus dag 
could use solve consensus efficiently  proof makes use following two
   

fipena

decision problems 
feedback arc set
instance  directed graph g    v  a  positive integer k 
question  exist subset b  b  k b least
one arc every directed cycle g  
learn
instance  probability distribution p v  positive integer d 
question  exist dag g v i g  i p  number
parameters associated g greater  
feedback arc set np complete  garey   johnson         feedback arc
set remains np complete directed graphs total degree vertex
three  gavril         degree bounded feedback arc set problem used
chickering et al         prove learn np hard  proof  chickering
et al         use following polynomial reduction instance degree bounded
feedback arc set instance learn 
let instance degree bounded feedback arc set consist directed
graph f    vf   af   positive integer k 
let l denote dag whose nodes arcs determined f follows 
every arc vif vjf af   create following nodes arcs l 

vif   



aij    

bij    

cij    

hij

   

 

 

dij    

eij    

fij    



gij



vjf   

   

number parenthesis besides node number states corresponding random variable  let hl denote nodes hij l  let vl denote
rest nodes l 
specify  join  probability distribution p hl   vl   i p hl   vl      i l  
let instance learn consist  marginal  probability distribution p vl  
positive integer d  computed f k shown work
chickering et al         equation    
describe instance learn resulting reduction
reduced instance consensus polynomial time 
let c   denote dag vl arcs l whose
endpoints vl  
   

fifinding consensus bayesian network structures

let c   denote dag vl arcs bij cij fij
j 
let c   denote dag vl arcs cij fij eij
j 
let instance consensus consist dags c     c   c     positive
integer d 
theorem    consensus np hard 
proof  start proving polynomial reduction instance f
degree bounded feedback arc set instance c consensus  first  reduce
f instance l learn shown work chickering et al         and  then 
reduce l c shown above 
prove solution f iff solution c  chickering et
al         thms       prove solution f iff solution l 
therefore  remains prove solution l iff solution
c  note parameter l parameter c same   let l
p hl   vl   denote dag probability distribution constructed reduction
f l  recall i p hl   vl      i l   moreover 
let l  denote dag  hl   vl   arcs l whose
endpoints vl  
let l  denote dag  hl   vl   arcs bij cij hij fij
j 
let l  denote dag  hl   vl   arcs cij hij fij eij
j 
note separation statement holds l holds l    l  l    then 
i p hl   vl      i l   i   i li   and  thus  i p vl      i   i li   vl    i    i li   vl  
let c     c   c   denote dags constructed reduction l c  note
 i li   vl   i c   i  then  i p vl     i   i c   and  thus  solution
l solution c  prove opposite  proof essentially
work chickering et al         thm      let us define  vi   vj  
edge component dag g vl subgraph g arcs
g whose endpoints  vi   aij   bij   cij   dij   eij   fij   gij   vj    given solution
c c  create another solution c   c follows 
initialize c   c    
every  vi   vj   edge component c  directed path c vi
vj   add c   arcs eij cij fij  
every  vi   vj   edge component c  directed path c vi vj  
add c   arcs bij fij cij  
   

fipena

note c   acyclic c acyclic  moreover  i c      i   i c  
i c     i c   i  order able conclude c   solution c 
remains prove number parameters associated c   greater
d  specifically  prove c   parameters associated c 
less parameters associated solution c 
seen before  i c     i c      likewise  i c  i c     c solution c 
thus  exists sequence  resp      covered arc reversals arc additions
transforms c   c  resp  c      chickering        thm      note covered arc
reversal modify number parameters associated dag  whereas arc
addition increases  chickering        thm      thus    monotonically increase
number parameters associated c   transform it  recall c   consists
series edge components form

vif   



aij    

bij    

cij    

dij    

eij    

fij    



gij



vjf   

   

number parenthesis besides node number states corresponding
random variable  let us study sequences   modify edge component
c       simply adds arcs bij fij cij arcs eij cij fij   note
adding first pair arcs results increase    parameters  whereas adding
second pair arcs results increase    parameters  unlike     may reverse
arc edge component  case  must cover arc first  implies
increase least    parameters  covering fij vj adding eij vj implies
increase exactly    parameters  whereas arc covering implies larger increase  
then  implies larger increase number parameters     hand 
reverse arc edge component  simply adds arcs
c c     note either cij fij cij fij c  otherwise
cij c fij  z z vl contradicts fact c solution c since
cij   c   fij  z  cij fij c  either bij fij bij fij c
otherwise bij c fij  z z vl cij z  contradicts fact
c solution c since bij   c   fij  z  bij fij would create cycle c  bij fij
c  therefore  adds arcs bij fij cij and  construction c      
adds them  thus  implies increase least many parameters    
hand  cij fij c  either cij eij cij eij c otherwise
cij c eij  z z vl fij z  contradicts fact c
solution c since cij   c   eij  z  cij eij would create cycle c  cij eij
c  therefore  adds arcs eij cij fij and  construction c       adds either
arcs eij cij fij arcs bij fij cij   case  implies increase
least many parameters     consequently  c   parameters
associated c 
finally  note i p vl    i c     chickering et al         lemma     thus 
solution c solution l 
   

fifinding consensus bayesian network structures

worth noting proof contains two restrictions  first  number
dags consensuate three  second  number states random variable
vl arbitrary prescribed  first restriction easy relax  proof
extended consensuate three dags simply letting c dag vl
arcs      however  open question whether consensus remains
np hard number dags consensuate two and or number states
random variable vl arbitrary 
following theorem strengthens previous one 
theorem    consensus np complete 
proof  theorem    remains prove consensus np  i e 
verify polynomial time given dag g solution given instance
consensus 
let denote node ordering consistent g  causal list g relative
set separation statements g p  a    p ag  a  p ag  a  node a 
known i g  coincides closure respect graphoid properties

causal list g relative  pearl        corollary     therefore  i g 
i   i g   iff

gi p  a    p ag  a  p ag  a    m 
i   i g   graphoid  del
sagrado   moral        corollary     let n  ai denote  respectively  number
nodes g  number arcs g  number arcs gi   let b   max im ai  
checking separation statement gi takes o ai   time  geiger et al         p        then 

checking whether i g 
i   i g   takes o mnb  time  finally  note computing
number parameters associated g takes o a  

   finding approximated consensus dag
since finding consensus dag given dags np hard  decide resort
heuristics find approximated consensus dag  mean discard
existence fast super polynomial algorithms  simply means pursue
possibility paper  specifically  paper consider following heuristic
due matzkevich abramson            b   see work matzkevich
abramson      a  related information  first  let denote ordering nodes
given dags  denote g            gm   then  find mdi map gi
gi relative   finally  let approximated consensus dag dag whose
arcs exactly union arcs g            gm
  following theorem justifies taking
union arcs  specifically  proves dag returned heuristic
consensus dag required consistent  
theorem    dag h returned heuristic dag fewest

parameters associated among mdi maps
i   i g   relative  

proof  start proving h mdi map
i   i g    first  show




i h 
i   i g    suffices note i h  i   i g   g subm





graph h  i   i g   i   i g   i g   i g   i  now 

   

fipena

assume contrary dag h   resulting removing arc b h


satisfies i h    
i   i g    construction h  b g i  say
  j  note b h   p  b    p ah    b  p ah    b   implies b gj p  b   


  m
i   p agi  b      a    i   p agi  b      a  p ah    b     i   p agi  b      a 

i h    
i   i g    note b gj p  b    p agj  b  p agj  b   implies b gj p  b    p agj  b  p agj  b  i gj   i gj    therefore  b gj


p  b     p agj  b     a   p agj  b     a  intersection  however  contradicts



fact gj mdi map gj relative   then  h mdi map
i   i g  
relative  

finally  note
i   i g   graphoid  del sagrado   moral        corollary    

consequently  h mdi map
i   i g   relative  

key step heuristic is  course  choosing good node ordering   unfortunately  fact consensus np hard implies np hard find
best node ordering   i e  node ordering makes heuristic return mdi

map
i   i g   fewest parameters associated  see it  note
existed efficient algorithm finding best node ordering  theorem   would
imply could solve consensus efficiently running heuristic best
node ordering 
last sentence  implicitly assumed heuristic efficient 
implies implicitly assumed efficiently find mdi map gi
gi   rest paper shows assumption correct 

   methods b correct
matzkevich abramson      b  propose heuristic discussed previous section  present two algorithms  called methods b  efficiently
deriving mdi map g dag g relative node ordering   algorithms work
iteratively covering reversing arc g resulting dag consistent
  obvious way working produces directed independence map g 
however  order arrive g   arc cover reverse iteration must
carefully chosen  pseudocode methods b seen figure    method
starts calling construct derive node ordering consistent g
close possible  line     close possible  mean
number arcs methods b later cover reverse kept minimum 
methods b use choose arc cover reverse iteration 
particular  method finds leftmost node interchanged left
neighbor  line    repeatedly interchanges node left neighbor  lines    
      interchanges preceded covering reversing corresponding arc g  line     method b essentially identical method a  differences
word right replaced word left vice versa
lines      arcs point opposite directions line    note methods
b reverse arc once 
   

fifinding consensus bayesian network structures

construct  g   
   given dag g node ordering   algorithm returns node ordering
consistent g close possible   
 
 
 
    
 
 
 
 
 
 
  
  

 
g    g
let denote sink node g 
let denote rightmost node sink node g    
add leftmost node
let b denote right neighbor
b   
  p ag  b  right b
interchange b
go line  
remove incoming arcs g 
g     go line  
return
method a g   
   given dag g node ordering   algorithm returns g   

 
 
 
 
 
 
 
 
 

 construct  g   
let denote leftmost node whose left neighbor right
let z denote left neighbor
z right
z g cover reverse z g
interchange z
go line  
   go line  
return g
method b g   
   given dag g node ordering   algorithm returns g   

 
 
 
 
 
 
 
 
 

 construct  g   
let denote leftmost node whose right neighbor left
let z denote right neighbor
z left
z g cover reverse z g
interchange z
go line  
   go line  
return g

figure    construct   methods b  correction construct consists  i 
replacing line   line comments it   ii  removing lines     
   

fipena

figure    counterexample correctness methods b 
methods b claimed correct work matzkevich abramson
     b  thm    corollary    although proof provided  a proof sketched  
following counterexample shows methods b actually correct  let g
dag left hand side figure    let    m  i  k  j  l   then  make
use characterization introduced section   see g dag center
figure    however  methods b return dag right hand side figure
   see it  follow execution methods b step step  first  methods
b construct calling construct   runs follows 
   initially    g    g 
   select sink node g    then     m    remove incoming arcs
g   
   select sink node l g    then     l     interchange performed
l p ag  m    remove l incoming arcs g   
   select sink node k g    then     k  l     interchange performed
k left l   remove k incoming arcs g   
   select sink node j g    then     j  k  l     interchange performed
j p ag  k  
   select sink node g    then     i  j  k  l     interchange
performed left j  
construct ends  methods b continue follows 
   

fifinding consensus bayesian network structures

   initially     i  j  k  l    
   add arc j reverse arc j k g  interchange j k  
then     i  k  j  l    
   add arc j reverse arc l g  interchange l  
then     i  k  j  m  l  
    add arcs k   reverse arc j g  interchange j
  then     i  k  m  j  l  
    reverse arc k g  interchange k   then     i  m  k  j  l  
    reverse arc g  interchange   then     m  i  k  j  l   
 
matter fact  one see early step   methods b
fail  one see separated dag resulting step   
implies separated dag returned methods b 
covering reversing arcs never introduces new separation statements  however 
separated g  
note constructed selecting first   l  k  j  finally i 
however  could selected first k  i    l  finally j  would
resulted    j  l  m  i  k     methods b return g   therefore 
makes difference sink node selected line   construct   however  construct
overlooks detail  propose correcting construct  i  replacing line   let
denote rightmost node sink node g     ii  removing lines     since
never executed  hereinafter  assume call construct call
corrected version thereof  rest paper devoted prove methods
b return g  

   corrected methods b correct
proving methods b correct  introduce auxiliary lemmas 
proof found appendix a  let us call percolating right to left
iterating lines     method possible  let us modify method replacing
line   let denote leftmost node considered
adding check z    line    pseudocode resulting algorithm 
call method a   seen figure    method a  percolates right to left one
one nodes order appear  
lemma    method a g    method a  g    return dag 
lemma    method a  g    method b g    return dag 
let us call percolating left to right iterating lines     method b
possible  let us modify method b replacing line   let denote rightmost
node considered adding check z    line   
pseudocode resulting algorithm  call method b   seen figure
   

fipena

method a  g   
   given dag g node ordering   algorithm returns g   
 
 
 
 
 
 
 
 
 

 construct  g   
let denote leftmost node considered
let z denote left neighbor
z    z right
z g cover reverse z g
interchange z
go line  
   go line  
return g
method b  g   
   given dag g node ordering   algorithm returns g   

 
 
 
 
 
 
 
 
 

 construct  g   
let denote rightmost node considered
let z denote right neighbor
z    z left
z g cover reverse z g
interchange z
go line  
   go line  
return g

figure    methods a  b  
   method b  percolates left to right one one nodes reverse order
appear  
lemma    method b g    method b  g    return dag 
ready prove main result paper 
theorem    let g denote mdi map dag g relative node ordering   then 
method a g    method b g    return g  
proof  lemmas      suffices prove method b  g    returns g   evident
method b  transforms and  thus  halts point  therefore 
method b  performs finite sequence n modifications  arc additions covered arc
reversals  g  let gi denote dag resulting first modifications g 
let g    g  specifically  method b  constructs gi   gi either  i  reversing
covered arc z   ii  adding arc x z x p agi  y     p agi  z  
 iii  adding arc x x p agi  z    p agi  y    note i gi     i gi  
    n and  thus  i gn   i g    
   

fifinding consensus bayesian network structures

start proving gi dag consistent   n  since
true g  due line    suffices prove gi dag consistent
gi       n  consider following four cases 
case   method b  constructs gi   gi reversing covered arc z  then 
gi   dag reversing covered arc create cycle  chickering 
      lemma     moreover  note z interchanged immediately
covered arc reversal  thus  gi   consistent  
case   method b  constructs gi   gi adding arc x z x
p agi  y     p agi  z   note x left left z  
gi consistent   then  x left z and  thus  gi  
dag consistent  
case   method b  constructs gi   gi adding arc x x
p agi  z    p agi  y    note x left z gi consistent
  left neighbor z  recall line     then  x left
and  thus  gi   dag consistent  
case   note may get modified method b  constructs gi   gi   specifically  happens method b  executes lines     arc
z gi   however  fact gi consistent z
interchanged fact z neighbors  recall line    imply
gi consistent z interchanged 
since method b  transforms   follows result proven gn
dag consistent   order prove theorem  i e  gn   g  
remains prove i g   i gn    see it  note gn   g follows
i g   i gn    i gn   i g     fact gn dag consistent  
fact g unique mdi map g  relative   recall g guaranteed
unique i g    graphoid 
rest proof devoted prove i g   i gn    specifically  prove
i g   i gi   i g   i gi         n  note implies
i g   i gn   i g   i g    definition mdi map  first  prove
method b  constructs gi   gi reversing covered arc z 
arc reversed covered implies i gi       i gi    chickering        lemma     thus 
i g   i gi     i g   i gi   
now  prove i g   i gi   i g   i gi         n
method b  constructs gi   gi adding arc  specifically  prove
s active route  s v  ab
i   two nodes b gi    
s active route b g   prove result induction number
occurrences added arc ab
i     assume without loss generality added
ab
arc occurs i   fewer times s active route b
 
gi     call minimality property ab
i     number occurrences
   difficult show number occurrences added arc ab
i   two
 see case     intuition   however  proof theorem simpler ignore fact 

   

fipena

figure    different cases proof theorem    relevant subgraphs gi  
g depicted  undirected edge two nodes denotes nodes
adjacent  curved edge two nodes denotes s active route
two nodes  curved edge directed  route descending 
grey node denotes node s 

ab
added arc ab
i   zero  i   s active route b gi and 
thus  s active route b g since i g   i gi    assume
induction hypothesis result holds k occurrences added arc ab
i    
prove k     occurrences  consider following two cases  case
illustrated figure   

case   method b  constructs gi   gi adding arc x z x
 
ab
ax
zb
p agi  y   p agi  z   note x z occurs ab
i     let i     i   x zi    
ax
ab
note x
  i   s active gi   because  otherwise  i   would
   note maybe   x and or b   z 

   

fifinding consensus bayesian network structures

s active gi     then  s active route ax
x g

zb
induction hypothesis  moreover  because  otherwise  ax
i   x z i  
would s active route b gi   would violate minimality
property ab
i     note z g  i  z adjacent
g since i g   i gi     ii  z left  recall line     note
x g   see it  note x adjacent g since
i g   i gi    recall method b  percolates left to right one one
nodes reverse order appear   method b  currently
percolating and  thus  nodes right right
too  x g x would right and  thus  x would
right   however  would contradict fact x
left   follows fact gi consistent   thus  x
g   consider two cases 
case     assume z
  s  then  zb
i   s active gi   because  otherwise 
ab
i   would s active gi     then  s active route zb

z b g induction hypothesis  then  ax

x



z zb


s active route b g  
wb  
case     assume z s  then  zb
 
i     z w i     note w
w
b
ab
i   s active gi   because  otherwise  i   would s active gi    
b w b g induction
then  s active route w


hypothesis  note w z adjacent g since i g   i gi   
fact proven z g imply w adjacent
g because  otherwise    gi w  u g w  u u v
z u  would contradict i g   i gi    fact  w
g   see it  recall nodes right right
too  w g w would right and  thus 
w would right too  however  would contradict fact
w left   follows fact w left
z gi consistent   fact left neighbor
wb
z  recall line     thus  w g   then  ax
x w
s active route b g  

case   method b  constructs gi   gi adding arc x x
 
ab
ax
yb
p agi  z  p agi  y    note x occurs ab
i     let i     i   x i    
ax
ab
note x
  i   s active gi   because  otherwise  i   would
s active gi     then  s active route ax
x g

induction hypothesis  note z g  i  z adjacent
g since i g   i gi     ii  z left  recall line     note
x z adjacent g since i g   i gi    fact z
g imply x adjacent g because  otherwise  x   gi  u
x g  u u v z u  would contradict
wb
   note maybe w   b  note w    x because  otherwise  ax
i   x x i   would
s active route b gi   would violate minimality property ab
i    
   note maybe   x and or b    

   

fipena

i g   i gi    fact  x g   see it  recall method b  percolates
left to right one one nodes reverse order appear
  method b  currently percolating and  thus  nodes right
right too  x g x would
right and  thus  x would right too  however  would
contradict fact x left   follows fact
x left z gi consistent   fact
left neighbor z  recall line     thus  x g   consider three
cases 
b   x xb   note xb s active
case     assume yi  
i  
i  
ab
gi   because  otherwise  i   would s active gi     then 
s active route xb
x b g induction hypothesis 

ax
then  x x xb
s active route b g  

b   w w b    note w
case     assume yi  
 
i  
w
b
i   s active gi   because  otherwise  ab
would


s active
gi    
i  
b w b g induction
then  s active route w


hypothesis  note w g   see it  note w
adjacent g since i g   i gi    recall nodes right
right too  w g w would
right and  thus  w would right too 
however  would contradict fact w left  
follows fact gi consistent   thus  w g   then 
w b s active route b g  
ax

x w

case     assume
  s  proof case based step  
work chickering        lemma      let denote node maximal
g set descendants gi   note guaranteed
unique chickering        lemma      i g   i gi    note
     z descendant gi and  shown above  z
g   show descendant z gi   consider three cases 
case       assume   z  then  descendant z gi  
case       assume    z descendant z g    recall
method b  percolates left to right one one nodes
reverse order appear   method b  currently percolating
and  thus  yet percolated z z left
 recall line     therefore  none descendants z g   among
d  left z   fact consistent gi
imply z node maximal gi set descendants
z g    actually  z node chickering        lemma     
i gi   i g     then  descendants z g  descendants
z gi too  thus  descendant z gi  
   note maybe w   b  note w    x  case w   x covered case
    

   

fifinding consensus bayesian network structures

case       assume    z descendant z g   
shown case        descendants z g  descendants z
gi too  therefore  none descendants z g  left
because  otherwise  descendant z thus gi would
left   would contradict definition d 
fact descendant z g  imply still
g  z became sink node g  construct  recall figure    
therefore  construct added added z  recall lines      
left z definition d   reason 
method b  interchanged z  recall line     thus 
currently still left z   implies left
  left neighbor z  recall line     however 
contradicts fact gi consistent   descendant
gi   thus  case never occurs 
b
continue proof case      note
  implies yi  
s active gi   because  otherwise  ab
i   would s active gi     note
descendant z gi because  otherwise  would
xy b
s active route xy
x gi and  thus  ax

i  
i  
would s active route b gi   would violate
minimality property ab
  because  shown above 
i     implies
descendant z gi   implies s active descending
zd s active route
route zd
z gi   then  ax

i   x z
zd s active route
gi     likewise 
i   z

b gi     i   denotes route resulting reversing
b   therefore  s active routes ad bd
yi  


b g induction hypothesis 
consider subroute ab
i   starts arc x continues
direction arc reaches node e e   b e s 
note e descendant gi and  thus  e descendant g
definition d  let de
denote descending route e g  

assume without loss generality g descending route
b node shorter de
  implies e   b
de
de
s active g because  shown above 
  s  thus  ad

s active route b g   hand  e e   
de ed db s active route

  s  thus  ad



ed
b g   db
denote

routes resulting reversing

bd  
de





finally  show correctness method b  leads alternative proof
so called meeks conjecture         given two dags g h i h  i g  
meeks conjecture states transform g h sequence arc additions
covered arc reversals operation sequence g dag
   note statement true thanks correction construct  

   

fipena

method g h g  h 
   given two dags g h i h  i g   algorithm transforms
g h sequence arc additions covered arc reversals
operation sequence g dag i h  i g    
 
 
 

let denote node ordering consistent h
g method b  g   
add g arcs h g

figure    method g h 
i h  i g   importance meeks conjecture lies allows develop efficient
asymptotically correct algorithms learning bns data mild assumptions
 chickering        chickering   meek        meek        nielsen et al          meeks
conjecture proven true work chickering        thm     developing
algorithm constructs valid sequence arc additions covered arc reversals 
propose alternative algorithm construct sequence  pseudocode
algorithm  called method g h  seen figure    following corollary proves
method g h correct 
corollary    given two dags g h i h  i g   method g h g  h 
transforms g h sequence arc additions covered arc reversals
operation sequence g dag i h  i g  
proof  note method g hs line   denotes node ordering consistent
h  let g denote mdi map g relative   recall g guaranteed
unique i g  graphoid  note i h  i g  implies g subgraph
h  see it  note i h  i g  implies obtain mdi map g relative
removing arcs h  however  g mdi map g relative  
then  follows proof theorem   method g hs line   transforms
g g sequence arc additions covered arc reversals 
operation sequence g dag i g   i g   thus  operation
sequence i h  i g  i h  i g   since  shown above  g subgraph
h  moreover  method g hs line   transforms g g h sequence arc
additions  course  arc addition g dag i h  i g  g
subgraph h 

   corrected methods b efficient
section  show methods b efficient solution
problem think of  let n denote  respectively  number
nodes arcs g  moreover  let us assume hereinafter dag implemented
   

fifinding consensus bayesian network structures

adjacency matrix  whereas node ordering implemented array entry per
node indicating position node ordering  since i g  graphoid  first
solution think consists applying following characterization g  
node a  p ag  a  smallest subset x p  a  g p  a    x x 
solution implies evaluating node o  n   subsets p  a   evaluating
subset implies checking separation statement g  takes o a  time  geiger et al  
      p        therefore  overall runtime solution o an n   
since i g  satisfies composition property addition graphoid properties 
efficient solution consists running incremental association markov boundary
 iamb  algorithm  pena et al         thm     node find p ag  a   iamb
algorithm first sets p ag  a    and  then  proceeds following two steps 
first step consists iterating following line p ag  a  change 
take node b p  a    p ag  a    g b p ag  a  add p ag  a  
second step consists iterating following line p ag  a 
change  take node b p ag  a  considered
g b p ag  a   b   remove p ag  a   first step iamb algorithm
add o n  nodes p ag  a   addition implies evaluating o n  candidates
addition  since p  a  o n  nodes  evaluating candidate implies checking
separation statement g  takes o a  time  geiger et al         p        then 
first step iamb algorithm runs o an    time  similarly  second step
iamb algorithm runs o an  time  therefore  iamb algorithm runs o an    time 
since iamb algorithm run n nodes  overall runtime
solution o an    
analyze efficiency methods b  exact  analyze
methods a  b   recall figure    rather original methods b  recall
figure     former efficient latter  methods a  b  run
o n    time  first  note construct runs o n    time  algorithm iterates n
times lines      and  iterations  iterates o n  times lines
     moreover  line   takes o n    time  line   takes o    time  line   takes o n  time 
now  note methods a  b  iterate n times lines     and 
iterations  iterate o n  times lines      moreover  line   takes o    time 
line   takes o n  time covering arc implies updating adjacency matrix
accordingly  consequently  methods b efficient solution
problem think of 
finally  analyze complexity method g h  method g h runs o n    time 
constructed o n    time calling construct  h    node
ordering  running method b  takes o n    time  adding g arcs h
g done o n    time  recall method g h alternative
algorithm work chickering         unfortunately  implementation details
provided work chickering and  thus  comparison runtime
algorithm possible  however  believe algorithm efficient 
   

fipena

   discussion
paper  studied problem combining several given dags consensus
dag represents independences given dags agree upon
parameters associated possible  although definition consensus dag reasonable 
would leave number parameters associated focus solely
independencies represented consensus dag  words  would define
consensus dag dag represents independences given dags
agree upon many possible  currently investigating whether
definitions equivalent  paper  proven may exist several nonequivalent consensus dags  principle  equally good  able
conclude one represents independencies rest  would prefer
one  paper  proven finding consensus dag np hard 
made us resort heuristics find approximated consensus dag  mean
discard existence fast super polynomial algorithms general case 
polynomial algorithms constrained cases given dags bounded
in degree  question currently investigating  paper 
considered heuristic originally proposed matzkevich abramson            b  
heuristic takes input node ordering  shown finding best
node ordering heuristic np hard  currently investigating application
meta heuristics space node orderings find good node ordering
heuristic  preliminary experiments indicate approach highly beneficial 
best node ordering almost never coincides node orderings
consistent given dags 
said section    aim combining bns provided multiple experts  or
learning algorithms  single consensus bn robust individual
bns  paper  proposed combine experts bns two steps avoid
problems discussed pennock wellman         first  finding consensus bn
structure and  then  finding consensus parameters consensus bn structure 
paper focused first step  currently working second
step along following lines  let  g                  gm     denote bns provided
experts  first element pair denotes bn structure whereas second denotes
bn parameters  let p            pm denote probability distributions represented
bns provided experts  then  call p    f  p            pm   consensus probability
distribution  f combination function  e g  weighted arithmetic geometric
mean  let g denote consensus bn structure obtained g            gm described
paper  propose obtain consensus bn parameterizing g
p  a p ag  a     p   a p ag  a   v  p probability distribution
represented consensus bn  motivation parameterization minimizes
kullback leibler divergence p p   koller   friedman        thm       
hints speed computation parameterization performing
inference experts bns found work pennock wellman       
properties      section     alternatively  one could first sample p  and  then 
parameterize g p  a p ag  a     p   a p ag  a   v  p 
empirical probability distribution obtained sample  again  motivation
   

fifinding consensus bayesian network structures

parameterization minimizes kullback leibler divergence p p 
 koller   friedman        thm        and  course  p  p  sample sufficiently
large  note use p  parameterize g construct g which  discussed
section    allows us avoid problems discussed pennock wellman        
finally  note present work combines dags g            gm although
guarantee gi mdi map i pi    i e  gi may superfluous arcs 
therefore  one may want check gi contains superfluous arcs remove
combination takes place  general  several mdi maps i pi   may exist 
may differ number parameters associated them  would interesting
study number parameters associated mdi map i pi   chosen affects
number parameters associated consensus dag obtained method
proposed paper 

acknowledgments
thank anonymous referees editor thorough review manuscript 
thank dr  jens d  nielsen dag sonntag proof reading manuscript 
work funded center industrial information technology  ceniit  socalled career contract linkoping university 

appendix a  proofs lemmas    
lemma    method a g    method a  g    return dag 

proof  evident methods a  transform and  thus  halt
point  prove return dag  prove result
induction number times method executes line   halting 
evident result holds number executions one  methods a 
share line    assume induction hypothesis result holds k   executions 
prove k executions  let z denote nodes involved first
k executions  since induction hypothesis applies remaining k   executions 
run method summarized

z g cover reverse z g
interchange z
    n
percolate right to left leftmost node percolated

n number nodes g  now  assume percolated   j  note
first j   percolations involve nodes left   thus  run
equivalent
   

fipena

    j  
percolate right to left leftmost node percolated
z g cover reverse z g
interchange z
percolate right to left
percolate z right to left
  j     n
percolate right to left leftmost node percolated before 
now  let w denote nodes left z first k executions
line    note fact z nodes involved first execution implies
nodes w left z   note that  z percolated
latter run above  nodes left z exactly w  y    since
nodes w  y   left z   percolation z latter run
perform arc covering reversal node interchange  thus  latter run
equivalent
    j  
percolate right to left leftmost node percolated
percolate z right to left
percolate right to left
  j     n
percolate right to left leftmost node percolated
exactly run method a   consequently  methods a  return
dag 

lemma    method a  g    method b g    return dag 
proof  prove lemma much way lemma    simply need
replace z vice versa proof lemma   

lemma    method b g    method b  g    return dag 
proof  evident methods b b  transform and  thus  halt
point  prove return dag  prove result
induction number times method b executes line   halting 
evident result holds number executions one  methods b b 
share line    assume induction hypothesis result holds k   executions 
prove k executions  let z denote nodes involved first
k executions  since induction hypothesis applies remaining k   executions 
run method b summarized
   

fifinding consensus bayesian network structures

z g cover reverse z g
interchange z
    n
percolate left to right rightmost node percolated
n number nodes g  now  assume j th rightmost node
  note that      j  i th rightmost node wi right
wi percolated run above  see it  assume contrary wi
left   implies wi left z   z
neighbors   however  contradiction wi would selected
line   instead first execution line    thus  first j   percolations
run involve nodes right z   then  run equivalent
    j  
percolate left to right rightmost node percolated
z g cover reverse z g
interchange z
  j n
percolate left to right rightmost node percolated
exactly run method b  

references
chickering  d  m  transformational characterization equivalent bayesian network
structures  proceedings eleventh conference uncertainty artificial intelligence              
chickering  d  m  optimal structure identification greedy search  journal machine
learning research                  
chickering  d  m    meek  c  finding optimal bayesian networks  proceedings
eighteenth conference uncertainty artificial intelligence               
chickering  d  m   heckerman  d    meek  c  large sample learning bayesian networks
np hard  journal machine learning research                    
friedman  n    koller  d  bayesian network structure  bayesian approach
structure discovery bayesian networks  machine learning                 
gavril  f  np complete problems graphs  proceedings eleventh conference information sciences systems              
garey  m    johnson  d  computers intractability  guide theory npcompleteness  w  h  freeman       
   

fipena

geiger  d   verma  t    pearl  j  identifying independence bayesian networks  networks 
                 
genest  c    zidek  j  v  combining probability distributions  critique annotated bibliography  statistical science                  
hartemink  a  j   gifford  d  k   jaakkola  t  s    young  r  a  combining location
expression data principled discovery genetic regulatory network models 
pacific symposium biocomputing                  
jackson  b  n   aluru  s    schnable  p  s  consensus genetic maps  graph theoretic approach  proceedings      ieee computational systems bioinformatics
conference              
koller  d    friedman  n  probabilistic graphical models  principles techniques  mit
press       
matzkevich  i    abramson  b  topological fusion bayes nets  proceedings
eight conference conference uncertainty artificial intelligence                
matzkevich  i    abramson  b  complexity considerations combination
belief networks  proceedings ninth conference conference uncertainty
artificial intelligence               a 
matzkevich  i    abramson  b  deriving minimal i map belief network relative
target ordering nodes  proceedings ninth conference conference
uncertainty artificial intelligence               b 
maynard reid ii  p    chajewska  u  agregating learned probabilistic beliefs  proceedings seventeenth conference uncertainty artificial intelligence          
     
meek  c  graphical models  selecting causal statistical models  phd thesis  carnegie
mellon unversity       
ng  k  c    abramson  b  probabilistic multi knowledge base systems  journal applied
intelligence                  
nielsen  j  d   kocka  t    pena  j  m  local optima learning bayesian networks 
proceedings nineteenth conference uncertainty artificial intelligence 
              
nielsen  s  h    parsons  s  application formal argumentation  fusing bayesian
networks multi agent systems  artificial intelligence                   
pearl  j  probabilistic reasoning intelligent systems  networks plausible inference 
morgan kaufmann       
pennock  d  m    wellman  m  p  graphical representations consensus belief  proceedings fifteenth conference uncertainty artificial intelligence          
     
   

fifinding consensus bayesian network structures

pena  j  m   nilsson  r   bjorkegren  j    tegner  j  towards scalable data efficient
learning markov boundaries  international journal approximate reasoning                  
pena  j  m   kocka  t    nielsen  j  d  featuring multiple local optima assist user
interpretation induced bayesian network models  proceedings tenth
international conference information processing management uncertainty
knowledge based systems                  
richardson  m    domingos  p  learning knowledge multiple experts  proceedings twentieth international conference machine learning                
del sagrado  j    moral  s  qualitative combination bayesian networks  international
journal intelligent systems                   
studeny  m  bayesian networks point view chain graphs  proceedings
fourteenth conference conference uncertainty artificial intelligence          
     
studeny  m    bouckaert  r  r  chain graph models description conditional
independence structures  annals statistics                     

   


