journal of artificial intelligence research                  

submitted        published      

binary encodings of non binary constraint satisfaction
problems  algorithms and experimental results
nikolaos samaras

samaras uom gr

department of applied informatics
university of macedonia  greece

kostas stergiou

konsterg aegean gr

department of information and communication systems engineering
university of the aegean  greece

abstract
a non binary constraint satisfaction problem  csp  can be solved directly using extended versions of binary techniques  alternatively  the non binary problem can be translated into an equivalent binary one  in this case  it is generally accepted that the translated
problem can be solved by applying well established techniques for binary csps  in this
paper we evaluate the applicability of the latter approach  we demonstrate that the use of
standard techniques for binary csps in the encodings of non binary problems is problematic
and results in models that are very rarely competitive with the non binary representation 
to overcome this  we propose specialized arc consistency and search algorithms for binary encodings  and we evaluate them theoretically and empirically  we consider three
binary representations  the hidden variable encoding  the dual encoding  and the double
encoding  theoretical and empirical results show that  for certain classes of non binary
constraints  binary encodings are a competitive option  and in many cases  a better one
than the non binary representation 

   introduction
constraint satisfaction problems  csps  appear in many real life applications such as
scheduling  resource allocation  timetabling  vehicle routing  frequency allocation  etc  most
csps can be naturally and eciently modelled using non binary  or n ary  constraints that
may involve an arbitrary number of variables  it is well known that any non binary csp
can be converted into an equivalent binary one  the most well known translations are the
dual encoding  dechter   pearl        and the hidden variable encoding  rossi  petrie   
dhar         the ability to translate any non binary csp into binary has been often used
in the past as a justication for restricting attention to binary csps  implicitly  the assumption had been that when faced with a non binary csp we can simply convert it into a
binary one  and then apply well known generic techniques for solving the binary equivalent 
in this paper we will show that this assumption is awed because generic techniques for
binary csps are not suitable for binary encodings of non binary problems 
in the past few years  there have been theoretical and empirical studies on the eciency
of binary encodings and comparisons between binary encodings and the non binary representation  bacchus   van beek        stergiou   walsh        mamoulis   stergiou       
smith        bacchus  chen  van beek    walsh         theoretical results have showed
c
    
ai access foundation  all rights reserved 

fisamaras   stergiou

that converting non binary csps into binary equivalents is a potentially ecient way to
solve certain classes of non binary problems  however  in the  limited  empirical studies
there are very few cases where this appears to be true  with conways game of life  smith 
      being the most notable exception  there are various reasons for this  in many cases 
the extensive space requirements of the binary encodings make them infeasible  also  in
many non binary problems we can utilize ecient specialized propagators for certain constraints  such as the algorithm developed by regin        for the all dierent constraint 
converting such constraints into binary is clearly impractical  another reason  which has
been overlooked  is that most  if not all  experimental studies use well known generic local
consistency and search algorithms in the encodings  in this way they fail to exploit the
structure of the constraints in the encodings  ending up with inecient algorithms  to
make the binary encodings a realistic choice of modelling and solving non binary csps  we
need algorithms that can utilize their structural properties  finally  it is important to point
out that the use of a binary encoding does not necessarily mean that we have to convert
all the non binary constraints in a problem into binary  as it is commonly perceived  if we
are selective in the constraints we encode  based on properties such as arity and tightness 
then we can get ecient hybrid models 
to address these issues  we show that the use of specialized arc consistency and search
algorithms for binary encodings of non binary csps can lead to ecient models  we consider three encodings  the dual  the hidden variable  and the double encoding  the latter 
which is basically the conjunction of the other two encodings  has received little attention
but may well turn out to be the most signicant in practice  the aim of this study is
twofold  first  to present ecient algorithms for the binary encodings and analyze them
theoretically and experimentally  second  and more importantly  to investigate if and when
the use of such algorithms can help solve non binary problems eciently  towards these
aims  we make the following contributions 
 we describe a simple algorithm that enforces arc consistency on the hidden variable
encoding of an arbitrary non binary csp with o ekdk   time complexity  where e
is the number of constraints  k the maximum arity of the constraints  and d the
maximum domain size  this gives an o d  improvement compared to the asymptotic
complexity of a generic arc consistency algorithm  the improved complexity is now
the same as the complexity of an optimal generalized arc consistency algorithm in
the non binary representation of the problem  we also identify a property of the arc
consistency algorithm for the hidden variable encoding that can make it run faster 
on arc inconsistent problems  than the generalized arc consistency algorithm 
 we then consider search algorithms that maintain local consistencies during search
in the hidden variable encoding  we show that  like maintaining arc consistency 
all the generalizations of forward checking to non binary csps can be emulated by
corresponding forward checking algorithms that run in the hidden variable encoding
and only instantiate original variables  i e  the variables of the initial non binary
problem   we show that each such algorithm and its corresponding algorithm for nonbinary constraints have the following relationships     they visit the same number of
search tree nodes  and    the asymptotic cost of each of them is within a polynomial
bound of the other 
   

fibinary encodings of non binary csps  algorithms   experimental results

 we describe a specialized algorithm for the dual encoding that achieves arc consistency
with o e  dk   worst case time complexity  this is signicantly lower than the o e  d k  
complexity of a generic arc consistency algorithm  the improvement in the complexity
bound stems from the observation that constraints in the dual encoding have a specic
structure  namely they are piecewise functional  van hentenryck  deville    teng 
       apart from applying arc consistency in the dual encoding of a non binary
csp  this algorithm can also be used as a specialized ltering algorithm for certain
classes of non binary constraints 
 we adapt various search algorithms to run in the double encoding and compare them
theoretically to similar algorithms for the hidden variable encoding and the non binary
representation  search algorithms that operate in the double encoding can exploit the
advantages of both the hidden variable and the dual encoding  for example  we show
that  under certain conditions  the asymptotic cost of the maintaining arc consistency
algorithm in the double encoding can only be polynomially worse than the asymptotic
cost of the corresponding algorithm in the non binary representation  and the hidden
variable encoding   while it can be exponentially better 
 finally  we make an extensive empirical study on various domains  we consider
random problems as well as structured ones  like crossword puzzle generation  conguration  and frequency assignment  this study consists of two parts  in the rst
part  we give experimental results that demonstrate the advantages of the specialized
algorithms for binary encodings compared to generic algorithms  for example  the
specialized arc consistency algorithm for the dual encoding can be orders of magnitude faster than a generic arc consistency algorithm  in the second part we show that
the use of binary encodings can oer signicant benets when solving certain classes
of non binary csps  for example  solving the dual encoding of some conguration
problems can be orders of magnitudes more ecient than solving the non binary
representation  also  empirical results from frequency assignment   like problems
demonstrate that a binary encoding can be benecial even for non binary constraints
that are intentionally specied 

this paper is structured as follows  in section   we give the necessary denitions and
background  in section   we describe a specialized arc consistency algorithm for the hidden
variable encoding  we also demonstrate that all the extensions of forward checking to
non binary csps can be emulated by binary forward checking algorithms that run in the
hidden variable encoding  in section   we explain how the complexity of arc consistency
in the dual encoding can be improved and describe a specialized arc consistency algorithm 
section   discusses algorithms for the double encoding  in section   we present experimental
results on random and structured problems that demonstrate the usefulness of the proposed
algorithms  we also draw some conclusions regarding the applicability of the encodings 
based on theoretical and experimental results  section   discusses related work  finally  in
section   we conclude 
   

fisamaras   stergiou

   background
in this section we give some necessary denitions on csps  and describe the hidden variable 
dual  and double encodings of non binary csps 
    basic definitions
a constraint satisfaction problem  csp   p   is dened as a tuple  x  d  c   where 
 x    x            xn   is a nite set of n variables 
 d    din  x             din  xn    is a set of initial domains  for each variable xi  x 
din  xi   is the initial nite domain of its possible values  csp algorithms remove
values from the domains of variables through value assignments and propagation  for
any variable xi   we denote by d xi   the current domain of xi that at any time consists
of values that have not been removed from din  xi    we assume that for every xi  x 
a total ordering  d can be dened on din  xi   
 c    c            ce   is a set of e constraints  each constraint ci
a pair  vars ci    rel ci     where    vars ci      xj            xjk   is
of x called the constraint scheme     rel ci   is a subset of the
din  xj   x       xdin  xjk   that species the allowed combinations of
ables in vars ci   

 c is dened as
an ordered subset
cartesian product
values for the vari 

the size of vars ci   is called the arity of the constraint ci   constraints of arity   are called
binary  constraints of arity greater than   are called non binary  or n ary   each tuple
  rel ci   is an ordered list of values  a            ak   such that aj  din  xj   j              k  a
tuple     a            ak   is valid if  aj   j             k  aj  d xj    that is  a tuple is valid if
all the values in the tuple are present in the domains of the corresponding variables  the
process which veries whether a given tuple is allowed by a constraint ci or not is called a
consistency check  a constraint can be either dened extensionally by the set of allowed  or
disallowed  tuples or intensionally by a predicate or arithmetic function  a binary csp can
be represented by a graph  called constraint graph  where nodes correspond to variables
and edges correspond to constraints  a non binary csp can be represented by a constraint
hyper graph where the constraints correspond to hyper edges connecting two or more nodes 
the assignment of value a to variable xi will be denoted by  xi   a   any tuple   
 a            ak   can be viewed as a set of value to variable assignments   x    a              xk   ak    
the set of variables over which a tuple  is dened will be denoted by vars     for any
subset vars of vars       vars   denotes the sub tuple of  that includes only assignments to
the variables in vars   any two tuples  and   of rel ci   can be ordered by the lexicographic
ordering  lex   in this ordering    lex   i there a exists a subset  x            xj   of ci such
that   x            xj        x            xj   and   xj      lex    xj      an assignment  is consistent 
if for all constraints ci   where vars ci    vars       vars ci     rel ci    a solution to a csp
 x  d  c  is a consistent assignment to all variables in x  if there exists a solution for a
given csp  we say that the csp is soluble  otherwise  it is insoluble 
a basic way of solving csps is by using backtracking search  this can be seen as a
traversal of a search tree which comprises of the possible assignments of values to variables 
   

fibinary encodings of non binary csps  algorithms   experimental results

each level of the tree corresponds to a variable  a node in the search tree corresponds to
a tuple  i e  an assignment of values to variables   the root of the tree corresponds to
the empty tuple  the rst level nodes correspond to   tuples  an assignment of a value to
one variable   the second level nodes correspond to   tuples  assignment of values to two
variables generated by extending the rst level   tuples  etc  at each stage of the search
tree traversal  the variables that have been already assigned are called past variables  the
most recently assigned variable is called current variable  the variables that have not been
assigned yet are called future variables 
in the rest of this paper we will use the notation n for the number of variables in a
csp  e for the number of constraints in the problem  d for the maximum domain size of the
variables  and k for the maximum arity of the constraints 
      arc consistency
an important concept in csps is the concept of local consistency  local consistencies are
properties that can be applied in a csp  using  typically  polynomial algorithms  to remove
inconsistent values either prior to or during search  arc consistency is the most commonly
used local consistency property in the existing constraint programming engines  we now
give a denition of arc consistency 
definition     a value a  d xj   is consistent with a constraint ci   where xj  vars ci   if
  rel ci   such that   xj     a and  is valid  in this case we say that  is a support of a in
ci   a constraint ci is arc consistent  ac  i for each variable xj  vars ci     a  d xj   
there exists a support for a in ci   a csp  x  d  c  is arc consistent i there is no empty
domain in d and all the constraints in c are arc consistent 
arc consistency can be enforced on a csp by removing all the unsupported values from
the domains of variables  by enforcing arc consistency  or some local consistency property
a in general  on a csp p   we mean applying an algorithm that yields a new csp that is
arc consistent  or has the property a  and has the same set of solutions as p   the above
denition of arc consistency applies to constraints of any arity  to distinguish between
the binary and non binary cases  we will use the term arc consistency  ac  to refer to the
property of arc consistency for binary constraints only  for non binary constraints we will
use the term generalized arc consistency  gac  
the usefulness of ac processing was recognized early  and as a result  various ac
algorithms for binary constraints have been proposed in the literature  e g  ac   in mackworth        ac   in mohr   henderson        ac   in van hentenryck et al         ac  
in bessiere et al         ac      in bessiere   regin        ac    in zhang   yap        
some of them have been extended to the non binary case  e g  gac   in mohr   masini 
      gac schema in bessiere   regin      a  gac      in bessiere   regin        
ac can be enforced on a binary csp with o ed    optimal worst case time complexity  the
worst case complexity of enforcing gac on a non binary csp is o ekdk    bessiere   regin 
    a  
in this paper we use algorithms ac      and gac      for theoretical and empirical
comparisons with specialized algorithms for the encodings  this is not restrictive  in the
sense that any generic ac  and gac  algorithm can be used instead 
   

fisamaras   stergiou

following debruyne   bessiere         we call a local consistency property a stronger
than b i for any problem enforcing a deletes at least the same values as b  and strictly
stronger i it is stronger and there is at least one problem where a deletes more values than
b  we call a equivalent to b i they delete the same values for all problems  similarly  we
call a search algorithm a stronger than a search algorithm b i for every problem a visits
at most the same search tree nodes as b  and strictly stronger i it is stronger and there
is at least one problem where a visits less nodes than b  a is equivalent to b i they visit
the same nodes for all problems 
following bacchus et al          the asymptotic cost  or just cost hereafter  of a search
algorithm a is determined by the worst case number of nodes that the algorithm has to
visit to solve the csp  and the worst case time complexity of the algorithm at each node   
as in the paper by bacchus et al          we use this measure to set asymptotic bounds
in the relative performance of various algorithms  for example  if two algorithms a and
b always visit the same nodes and a enforces a property at each node with exponentially
higher complexity than the property enforced by b  then we say that algorithm a can have
an exponentially greater cost than algorithm b 
      functional and piecewise functional constraints
the specialized ac algorithms for the hidden variable and the dual encoding that we will
describe in sections   and   exploit structural properties of the encodings  as we will
explain in detail later  the binary constraints in the hidden variable encoding are one way
functional  while the binary constraints in the dual encoding are piecewise functional  we
now dene these concepts 
definition     a binary constraint c  where vars c     xi   xj    is functional with respect
to d xi   and d xj   i for all a  d xi    resp  b  d xj    there exists at most one value
b  d xj    resp  a  d xi    such that b is a support of a in c  resp  a is a support of b  
an example of a functional constraint is xi   xj   a binary constraint is one way functional
if the functionality property holds with respect to only one of the variables involved in the
constraint 
informally  a piecewise functional constraint over variables xi   xj is a constraint where
the domains of xi and xj can be partitioned into groups such that each group of d xi   is
supported by at most one group of d xj    and vice versa  to give a formal denition  we
rst dene the concept of a piecewise decomposition 
definition      van hentenryck et al         let c be a binary constraint with vars c   
 xi   xj    the partitions s    s            sm   of d xi   and s     s            sm   of d xj   are a
piecewise decomposition of d xi   and d xj   with respect to c i for all sl  s sl  s    the
following property holds  either for all a  sl   b  sl    a  b   rel c   or for all a  sl   b  sl  
 a  b  
  rel c  
   in the paper by bacchus et al         the cost of applying a variable ordering heuristic at each node is
also taken into account  when we theoretically compare search algorithms in this paper we assume that
they use the same variable ordering  so we do not take this cost into account 

   

fibinary encodings of non binary csps  algorithms   experimental results

definition      van hentenryck et al         a binary constraint c  where vars c   
 xi   xj    is piecewise functional with respect to d xi   and d xj   i there exists a piecewise
decomposition s    s            sm   of d xi   and s     s            sm   of d xj   with respect to
c such that for all sl  s  resp  sl  s     there exists at most one sl  s   resp  sl  s  
such that for all a  sl   b  sl  a  b   rel c  
example of piecewise functional constraints are the modulo  x  mod x    a  and integer
division  x  div x    a  constraints 
    binary encodings
there are two well known methods for transforming a non binary csp into a binary one 
the dual graph encoding and the hidden variable encoding  both encode the non binary
constraints to variables that have as domains the valid tuples of the constraints  that is  by
building a binary encoding of a non binary constraint we store the extensional representation
of the constraint  the set of allowed tuples   a third method is the double encoding which
combines the other two 
      dual encoding
the dual encoding  originally called dual graph encoding  was inspired by work in relational
databases  in the dual encoding  de   dechter   pearl        the variables are swapped
with constraints and vice versa  each constraint c of the original non binary csp is represented by a variable which we call a dual variable and denote by vc   we refer to the variables
of the original non binary csp as original variables  the domain of each dual variable vc
consists of the set of allowed tuples in the original constraint c  binary constraints between
two dual variables vc and vc exist i vars c   vars c       that is  i the constraints c
and c share one or more original variables  if common vars is the set of original variables
common to c and c then a tuple   d vc   is supported in the constraint between vc and
vc i there exists a tuple    d vc   such that   common vars       common vars  

v c 

v c 

               

               

       

       

               

               

       

               
v c 

v c 

figure    dual encoding of a non binary csp 
   

fisamaras   stergiou

consider the following example with six variables with     domains  and four constraints 
c    x    x    x       c    x   x    x       c    x    x   x      and c    x    x  
x       the de represents this problem with   dual variables  one for each constraint 
the domains of these dual variables are the tuples that satisfy the respective constraint 
for example  the dual variable vc  associated with the third constraint has the domain
                                             as these are the tuples of values for  x    x    x    which
satisfy x    x   x      as a second example  the dual variable vc  associated with the
last constraint has the domain                                    between vc  and vc  there is a
compatibility constraint to ensure that the two original variables in common  x  and x   
have the same values  this constraint allows only those pairs of tuples which agree on the
second and third elements  i e            for vc  and           for vc    or           for vc  and
          for vc     the de of the problem is shown in figure   
in the rest of this paper  we will sometimes denote by cvi the non binary constraint
that is encoded by dual variable vi   for an original variable xj  vars cvi    pos xj   cvi   will
denote the position of xj in cvi   for instance  given a constraint cvi on variables x    x    x   
pos x    cvi       
      hidden variable encoding
the hidden variable encoding  hve  was inspired by the work of philosopher peirce        
according to rossi et al          peirce rst showed that binary relations have the same
expressive power as non binary relations 
in the hve  rossi et al          the set of variables consists of all the original variables
of the non binary csp plus the set of dual variables  as in the dual encoding  each dual
variable vc corresponds to a constraint c of the original problem  the domain of each dual
variable consists of the tuples that satisfy the original constraint  for every dual variable
vc   there is a binary constraint between vc and each of the original variables xi such that
xi  vars c   a tuple   d vc   is supported in the constraint between vc and xi i there
exists a value a  d xi   such that   xi     a 
consider the previous example with six variables with     domains  and four constraints 
c    x    x    x       c    x   x    x       c    x    x   x      and c    x    x   x      
in the hve there are  in addition to the original six variables  four dual variables  as in
the de  the domains of these variables are the tuples that satisfy the respective constraint 
there are now compatibility constraints between a dual variable vc and the original variables
contained in constraint c  for example  there are constraints between vc  and x    between
vc  and x  and between vc  and x    as these are the variables involved in constraint c    the
compatibility constraint between cv  and x  is the relation that is true i the rst element
in the tuple assigned to cv  equals the value of x    the hve is shown in figure   
      double encoding
the double encoding  stergiou   walsh        combines the hidden variable and the dual
encoding  as in the hve  the set of variables in the double encoding consists of all the
variables of the original non binary csp plus the dual variables  for every dual variable
vc   there is a binary constraint between vc and each of the original variables xi involved in
the corresponding non binary constraint c  as in the de  there are also binary constraints
   

fibinary encodings of non binary csps  algorithms   experimental results

v c 

v c 

               

               

       

       

x     

x     

x     

x     

               

x 

  

x 

  

               

       

               
v c 

v c 

figure    hidden variable encoding of a non binary csp 
between two dual variables vc and vc if the non binary constraints c and c share one or
more original variables 

   algorithms for the hidden variable encoding
in this section we discuss specialized algorithms for the hve  we rst describe a simple
ac algorithm for the hve that has the same worst case time complexity as an optimal
gac algorithm for the non binary representation  in appendix a  we also show that for
any arc consistent csp the proposed ac algorithm performs exactly the same number of
consistency checks as the corresponding gac algorithm  for arc inconsistent problems we
show that the ac algorithm for the hve can detect the inconsistency earlier and thus
perform fewer consistency checks than the gac algorithm 
we also consider search algorithms for the hve that maintain local consistencies during
search  we show that  like maintaining arc consistency  the generalizations of forward
checking to non binary csps can be emulated by corresponding binary forward checking
algorithms in the hve that only instantiate original variables 
    arc consistency
it has been proved that ac in the hve is equivalent to gac in the non binary problem
 stergiou   walsh         since the hve is a binary csp  one obvious way to apply ac
is by using a generic ac algorithm  however  this results in redundant processing and an
asymptotic time complexity worse than o ekdk    to be precise  in the hve of a problem
with kary constraints we have ek binary constraints between dual and original variables 
on such a constraint  ac can be enforced with o ddk   worst case time complexity  for the
whole problem the complexity is o ekdk     
instead  we will now describe a simple ac algorithm that operates in the hve and
achieves the same worst case time complexity as an optimal gac algorithm applied in the
non binary representation  we can achieve this by slightly modifying the gac algorithm
   

fisamaras   stergiou

of bessiere and regin         gac        in figure   we sketch the ac algorithm for the
hve  which we call hac  hidden ac  
function hac
  
q
  
for each dual variable vj
  
for each variable xi where xi  vars cvj  
  
if revise xi   vj     t ru e
  
if d xi   is empty return inconsistency
  
put in q each dual variable vl such that xi  vars cvl  
  
return p ropagation
function p ropagation
  
while q is not empty
  
pop dual variable vj from q
   
for each unassigned variable xi where xi  vars cvj  
   
if revise xi   vj     t ru e
   
if d xi   is empty return inconsistency
   
put in q each dual variable vl such that xi  vars cvl  
    return consistency
function revise xi   vj  
    deletion  false
   
for each value a  d xi  
   
if currentsupportxi a vj is not valid
   
if     d vj     lex currentsupportxi a vj     xi     a and  is valid
   
currentsupportxi a vj  
   
else
   
remove a from d xi  
   
for each vl such that xi  vars cvl  
   
remove from d vl   each tuple   such that    xi     a
   
if d vl   is empty return inconsistency
   
deletion  true
    return deletion
figure    hac  an ac algorithm for the hidden variable encoding 
the hac algorithm uses a stack  or queue  of dual variables to propagate value deletions  and works as follows  in an initialization phase it iterates over each dual variable
vj  line     for every original variable xi constrained with vj the algorithm revises the
constraint between vj and xi   this is done by calling function revise  line     during each
revision  for each value a of d xi   we look for a tuple in the domain of vj that supports
it  as in ac       we store currentsupportxi a vj   the most recent tuple we have found in
d vj   that supports value a of variable xi     if this tuple has not been deleted from d vj  
   we assume  without loss of generality  that the algorithm looks for supports by checking the tuples in
lexicographic order 

   

fibinary encodings of non binary csps  algorithms   experimental results

then we know that a is supported  otherwise  we look for a new supporting tuple starting
from the tuple immediately after currentsupportxi  a vj   if no such tuple is found then a is
removed from d xi    line      in that case  all tuples that include that value are removed
from the domains of the dual variables that are constrained with xi  lines        if these
dual variables are not already in the stack they are added to it    then  dual variables are
removed from the stack sequentially  for each dual variable vj that is removed from the
stack  the algorithm revises the constraint between vj and each original variable xi constrained with vj   the algorithm terminates if all the values in a domain are deleted  in
which case the problem is not arc consistent  or if the stack becomes empty  in which case
the problem is arc consistent 
the main dierence between hac and gac      is that gac      does not include
lines       that is  even if the non binary constraints are given in extension  gac     does not remove tuples that become invalid from the lists of allowed tuples  as a
result  the two algorithms check for the validity of a tuple  in lines    and     in dierent
ways  later on in this section we will explain this in detail  apart from this dierence 
which is important because it aects their run times  the two algorithms are essentially the
same  we can move from hac to gac      by removing lines      and substituting any
references to dual variables by references to the corresponding constraints  for example 
currentsupportxi a vj corresponds to currentsupportxi a cvj in gac       i e  the last tuple
in constraint cvj that supports value a of variable xi   note that in such an implementation
of gac       propagation is constraint based  that is  the algorithm utilizes a stack of
constraints to perform the propagation of value deletions 
      complexities
we now give a upper bound on the number of consistency checks performed by hac in the
worst case  function revise xi   vj   can be called at most kd times for each dual variable
vj   once for every deletion of a value from the domain of xi   where xi is one of the k original
variables constrained with vj   in each call to revise xi   vj   the algorithm performs at most
d checks  one for each value a  d xi    to see if currentsupportxi a vj is valid  line      if
currentsupportxi a vj is not valid  hac tries to nd a new supporting tuple for a in d vj   
to check if a tuple  that contains the assignment  xi   a  supports a we need to check if 
is valid  if a tuple is not valid then one of its values has been removed from the domain
of the corresponding variable  this means that the tuple has also been removed from the
domain of the dual variable  therefore  checking the validity of a tuple can be done in
constant time by looking in the domain of the dual variable  the algorithm only needs
to check for support the dk    at maximum  tuples that contain the assignment  xi   a  
since hac stores currentsupportxi a vj   at each call of revise xi   vj   and for each value
a  d xi    it only checks tuples that have not been checked before  in other words  we can
check each of the dk  tuples at most once for each value of xi   so overall  in the worst
case  we have dk  checks plus the d checks to test the validity of the current support  for
kd values the upper bound in checks performed by hac to make one dual variable ac is
   note that dual variables that are already in the stack are never added to it  in this sense  the stack is
implemented as a set 

   

fisamaras   stergiou

o kd d   dk     o kdk    for e dual variables the worst case complexity bound is o ekdk   
which is the same as the complexity of gac in the non binary representation 
the asymptotic space complexity of the hac algorithm is dominated by the o edk  
space needed to store the domains of the dual variables  the algorithm also requires o nde 
space to store the current supports  since the space required grows exponentially with the
arity of the constraints  it is reasonable to assume that the hve  and the other binary
encodings  cannot be practical for constraints of large arity  unless the constraints are very
tight 
as mentioned  a consistency check in the non binary representation is done in a dierent
way than in the hve  assume that gac      looks for a support for value ai  d xi   in
constraint c  where vars c     x            xk   and xi  vars c   a tuple     a            ak  
supports ai if   xi     ai and  is valid  to check if  is valid  gac      has to check if
values a            ak  except ai   are still in the domains of variables x            xk   therefore  in
the worst case  a consistency check by gac      involves k    operations  in contrast 
hac checks for the validity of a tuple in constant time by looking in the domain of the
corresponding dual variable to see if the tuple is still there  however  this means that the
algorithm has to update the  usually  large domains of the dual variables after a value
deletion from an original variable  this aects the run times of the algorithms in dierent
problems settings 
in appendix a we show that hac does not only have the same complexity  but it also
performs exactly the same number of consistency checks as gac      in arc consistent
problems  we also show that in arc inconsistent problems there can be a dierence in the
number of checks in favor of the hve 
    search algorithms
search algorithms that maintain local consistencies are widely used for csp solving  some of
them have been extended to the non binary case  for example  maintaining arc consistency
 mac  and forward checking  fc   it has been shown that the non binary version of mac
 mgac  applied in a non binary csp is equivalent to mac applied in the hve of the
csp when only original variables are instantiated and the same variable orderings are used
 stergiou   walsh         we show that  like mgac  non binary extensions of fc can be
emulated by equivalent algorithms that run in the hve 
fc  haralick   elliot        was rst generalized to handle non binary constraints by
van hentenryck         according to the denition of van hentenryck         forward
checking is performed after the k   variables of an k ary constraint have been assigned and
the remaining variable is unassigned  this algorithm is called nfc  in the paper by bessiere 
meseguer  freuder    larrosa        where more  and stronger  generalizations of fc to
non binary constraints were introduced  these generalizations dier between them in the
extent of look ahead they perform after each variable instantiation  algorithm nfc  applies
one pass of gac on each constraint or constraint projection involving the current variable
and exactly one future variable    algorithm nfc  applies gac on the set of constraints
involving the current variable and at least one future variable  in one pass  algorithm nfc 
applies gac to the set of constraints involving the current variable and at least one future
   one pass means that each constraint is processed only once 

   

fibinary encodings of non binary csps  algorithms   experimental results

variable  algorithm nfc  applies gac on the set of constraints involving at least one
past variable and at least one future variable  in one pass  algorithm nfc   which is the
strongest version  applies gac to the set of constraints involving at least one past variable
and at least one future variable  all the generalizations reduce to simple fc when applied
to binary constraints 
we will show that the various versions of nfc are equivalent  in terms of visited nodes 
to binary versions of fc that run in the hve of the problem  this holds under the
assumption that the binary algorithms only assign original variables and they use the same
variable and value ordering heuristics  static or dynamic  as their non binary counterparts 
note that if such an algorithm nds a consistent assignment for all original variables  and
these assignments are propagated to the dual variables  then all the domains of the dual
variables will be reduced to singletons  that is  the domain of each dual variable vc will
only contain the single tuple that is consistent with the assignments of the original variables
constrained with vc   therefore  the algorithm can proceed to assign the dual variables in a
backtrack free manner 
the equivalence between nfc  and a version of fc for the hve  called fc   bacchus
  van beek         has been proved by bessiere et al          fc  is a specialized forward
checking algorithm for the hve  it operates like standard binary fc except that when the
domain of a dual variable is pruned  fc  removes from adjacent original variables any
value which is no longer supported 
algorithms nfc  nfc  also have equivalent algorithms that operate in the hve  we
call these algorithms hfc hfc   for example  hfc  will enforce ac on the set of dual
variables  and original variables connected to them  such that each dual variable is connected
to at least one past original variable and at least one future original variable  note that
nfc  has no natural equivalent algorithm in the hve  if we emulate it in the hve we will
get an inecient and awkward algorithm  in the following  hfc  will refer to the standard
binary fc algorithm and hfc  will refer to fc  

proposition     in any non binary csp  under a xed variable and value ordering  algorithm nfci  i              is equivalent to algorithm hfci that operates in the hidden variable
encoding of the problem 
proof  we prove this for nfc   the strongest among the generalized fc algorithms 
the proof for the other versions is similar  we only need to prove that at each node of
the search tree algorithms nfc  and hfc  will delete exactly the same values from the
domains of original variables  assume that at some node  after instantiating the current
variable  nfc  deletes value a from a future variable xi   then there exists some constraint
c including xi and at least one past variable  and value a of xi has no supporting tuple in c 
in the hve  when hfc  tries to make vc  the dual variable corresponding to c  ac it will
remove all tuples that assign a to xi   hence  hfc  will delete a from the domain of xi   now
in the opposite case  if hfc  deletes value a from an original variable xi it means that all
tuples including that assignment will be removed from the domains of dual variables that
include xi and at least one past variable  in the non binary representation of the problem 
the assignment of a to xi will not have any supporting tuples in constraints that involve xi
and at least one past variable  therefore  nfc  will delete a from the domain of xi    
   

fisamaras   stergiou

algorithms nfc nfc  are not only equivalent in node visits with the corresponding algorithms hfc hfc   but they also have the same asymptotic cost  this holds under the
condition that the non binary algorithms use gac       or some other optimal algorithm 
to enforce gac  and the hve versions use algorithm hac 
proposition     in any non binary csp  under a xed variable and value ordering  algorithm nfci  i              has the same asymptotic cost as algorithm hfci that operates in
the hidden variable encoding of the problem 
proof  in section     we showed that we can enforce ac on the hve of a non binary
csp with the same worst case complexity as gac in the non binary representation of the
problem  since algorithm nfci enforces gac on the same part of the problem on which
algorithm hfci enforces ac  and they visit the same nodes of the search tree  it follows
that the two algorithm have the same asymptotic cost   
in the paper by bessiere et al          a detailed discussion on the complexities of algorithms nfc nfc  is made  the worst case complexity of nfc  and nfc  in one node is
o  cc f   k    dk     where  cc f   is the number of constraints involving the current variable and at least one future variable  this is also the complexity of hfc  and hfc   the
worst case complexity of nfc  and nfc  in one node is o  cp f   k    dk     where  cp f  
is the number of constraints involving at least one past variable and at least one future
variable  this is also the complexity of hfc  and hfc  
assuming that nodes algi   is the set of search tree nodes visited by search algorithm
algi then the following holds 
corollary     given the hidden variable encoding of a csp with xed variable and value
ordering schemes  the following relations hold 
   nodes hfc   nodes hfc  
   nodes hfc   nodes hfc  
   nodes hfc   nodes hfc   nodes hfc  
   nodes hfc   nodes hfc   nodes hfc  
   nodes mac  nodes hfc  
proof  the proof of   is straightforward  see the paper by bacchus   van beek        
proof of     is a straightforward consequence of proposition     and corollary   from the
paper by bessiere et al         where the hierarchy of algorithms nfc  nfc  in node visits
is given  it is easy to see that   holds since hfc  applies ac in only a part of the csp 
while mac applies it in the whole problem  therefore  mac will prune at least as many
values as hfc  at any given node of the search tree  since the same variable and value
ordering heuristics are used  this means that mac will visit at most the same number of
nodes as hfc    
note that in the paper by bacchus   van beek        experimental results show differences between fc in the hve and fc in the non binary representation  however  the
   

fibinary encodings of non binary csps  algorithms   experimental results

algorithms compared there were fc  and nfc   which are not equivalent  also  it has
been proved that hfc  can have an exponentially greater cost than nfc   and vice versa
 bacchus et al          however  these algorithms are not equivalent  as proved in proposition      the result of bacchus et al         does not hold when comparing equivalent
algorithms 
so far we have showed that solving a non binary csp directly is in many ways equivalent
to solving it using the hve  assuming that only original variables are instantiated  a
natural question is whether there are any search techniques which are inapplicable in the
non binary case  but can be applied in the encoding  the answer is the ability of a search
algorithm that operates on the encoding to instantiate dual variables  in the equivalent
non binary representation this would imply instantiating values of more than one variables
simultaneously  to implement such an algorithm we would have to modify standard search
algorithms and heuristics or devise new ones  on the other hand  in the hve an algorithm
that instantiates dual variables can be easily implemented 

   algorithms for the dual encoding
in this section we turn our attention to the de and describe a specialized ac algorithm
with signicantly lower complexity than a generic algorithm 
    arc consistency
we know that ac in the de is strictly stronger than gac in the non binary representation
and ac in the hve  stergiou   walsh         since the de is a binary csp  one obvious
way to apply ac is using a generic ac algorithm  the domain size of a dual variable
corresponding to a kary constraint is dk in the worst case  therefore  if we apply an
optimal ac algorithm then we can enforce ac on one dual constraint with o d k   worstcase complexity  in the de of a csp with e constraints of maximum arity k there are
at most e e       binary constraints  when all pairs of dual variables share one or more
original variables   therefore  we can enforce ac in the de of the csp with o e  d k   worstcase complexity  this is signicantly more expensive compared to the o ekdk   complexity
bound of gac in the non binary representation and ac in the hve  because of the very
high complexity bound  ac processing in the de is considered to be impractical  except
perhaps for very tight constraints 
however  we will now show that ac can be applied in the de much more eciently  to
be precise we can enforce ac on the de of a non binary csp with o e  dk   worst case time
complexity  the improvement in the asymptotic complexity can be achieved by exploiting
the structure of the de  namely  the fact that the constraints in the de are piecewise
functional 
consider a binary constraint between dual variables vi and vj   we can create a piecewise
decomposition of the tuples in the domain of either dual variable into groups such that all
tuples in a group are supported by the same group of tuples in the other variable  if the
non binary constraints corresponding to the two dual variables share f original variables
x            xf of domain size d  then we can partition the tuples of vi and vj into df groups 
each tuple in a group s includes the same sub tuple of the form  a            af    where a  
d x             af  d xf    each tuple  in s will be supported by all tuples in a group s of
   

fisamaras   stergiou

the other variable  where each tuple in s also includes the sub tuple  a            af   the tuples
belonging to s will be the only supports of tuple  since any other tuple does not contain
the sub tuple  a            af    in other words  a group of tuples s in variable vi will only be
supported by a corresponding group s in variable vj where the tuples in both groups have
the same values for the original variables that are common to the two encoded non binary
constraints  therefore  the constraints in the de are piecewise functional 
example     assume that we have two dual variables v  and v    v  encodes constraint
 x    x    x     and v  encodes constraint  x    x    x     where the original variables
x            x  have the domain            we can partition the tuples in each dual variable
into   groups  the rst group will include tuples of the form          the second will include tuples of the form          and the third will include tuples of the form          a
star    means that the corresponding original variable can take any value  each group is
supported only by the corresponding group in the other variable  note that the tuples of a
variable vi are partitioned in dierent groups according to each constraint that involves vi  
for instance  if there is another dual variable v  encoding constraint  x    x    x    then the
partition of tuples in d v    according to the constraint between v  and v  is into groups of
the form                           
van hentenryck  deville   teng        have shown that ac can be achieved in a
set of binary piecewise functional constraints with o ed  worst case time complexity  an
improvement of o d  compared to the o ed    complexity of arbitrary binary constraints
 van hentenryck et al          since we showed that the constraints in the de are piecewise
functional  the result of van hentenryck et al         means that we can improve on the
o e  d k   complexity of ac in the de 
in figure   we sketch an ac   like ac algorithm specically designed for the de 
which we call pw ac  piecewise arc consistency   as we will show  this algorithm has
a worst case time complexity of o e  dk    the same complexity bound can be achieved
by the ac   algorithm of van hentenryck et al          in its specialization to piecewise
functional constraints  with the necessary adaptations to operate in the de  as do most
ac algorithms  pw ac uses a stack  or queue  to propagate deletions from the domains
of variables  this stack processes groups of piecewise decompositions  instead of variables
or constraints as is usual in ac algorithms  we use the following notation 
 s vi   vj      s   vi   vj            sm  vi   vj    denotes the piecewise decomposition of d vi  
with respect to the constraint between vi and vj   each sl  vi   vj    l              m  is a
group of the partition 
 sup sl  vi   vj    denotes the group of s vj   vi   that can support group sl  vi   vj   of
s vi   vj    as discussed  this group is unique 
 counter sl  vi   vj    holds the number of valid tuples that belong to group sl  vi   vj   of
decomposition s vi   vj    that is  at any time the value of counter sl  vi   vj    gives the
current cardinality of the group 
 groupof  s vi   vj       is a function that returns the group of s vi   vj   where tuple 
belongs  to implement this function  for each constraint between dual variables vi
   

fibinary encodings of non binary csps  algorithms   experimental results

function p w  ac
  
q
  
initialize all group counters to  
  
for each variable vi
  
for each variable vj constrained with vi
  
for each tuple   d vi  
  
counter groupof  s vi   vj         counter groupof  s vi   vj           
  
for each variable vi
  
for each variable vj constrained with vi
  
for each group sl  vi   vj  
   
if counter sl  vi   vj       
   
put sl  vi   vj   in q
    return p ropagation
function p ropagation
    while q is not empty
   
pop group sl  vi   vj   from q
   

   
  revise vi   vj   sl  vi   vj   
   
if d vj   is empty return inconsistency
   
for each group sl  vj   vk   in  put sl  vj   vk   in q
    return consistency
function revise vi   vj   sl  vi   vj   
    for each tuple   d vj   where   sup sl  vi   vj   
   
remove  from d vj  
   
for each group sl  vj   vk   that includes 
   
counter sl  vj   vk     counter sl  vj   vk      
   
if counter sl  vj   vk       
   
add sl  vj   vk   to 
    return 
figure    pw ac  an ac algorithm for the dual encoding 

and vj we store the original variables shared by the non binary constraints cvi and
cvj   also  for each such original variable xl we store pos xl   cvi   and pos xl   cvj    in
this way the groupof function takes constant time 
 the set  contains the groups that have their counter reduced to   after a call to
function revise  that is  groups such that all tuples belonging to them have been
deleted 
the algorithm works as follows  in an initialization phase  for each group we count
the number of tuples it contains  lines      then  for each variable vi we iterate over the
   

fisamaras   stergiou

variables vj that are constrained with vi   for each group sl  vi   vj   of s vi   vj    we check if
sl  vi   vj   is empty or not  line      if it is empty  it is added to the stack for propagation 
in the next phase  function p ropagation is called to delete unsupported tuples and
propagate the deletions  line      once the previous phase has nished  the stack will
contain a number of groups with   cardinality  for each such group sl  vi   vj   we must
remove all tuples belonging to group sup sl  vi   vj    since they have lost their support  this
is done by successively removing a group sl  vi   vj   from the stack and calling function
revise  since group sup sl  vi   vj    has lost its support  each tuple   d xj   that belongs
to sup sl  vi   vj    is deleted  lines        apart from sup sl  vi   vj     tuple  may also belong
to other groups that d vj   is partitioned in with respect to constraints between vj and other
variables  since  is deleted  the counters of these groups must be updated  i e  reduced
by one   this is done in lines       in the implementation we use function groupof
to access the relevant groups  if the counter of such a group becomes   then the group is
added to the stack for propagation  lines      and      the process stops when either the
stack or the domain of a variable becomes empty  in the former case  the de is ac  while
in the latter it is not 
the following example illustrates the advantage of algorithm pw ac over both a generic
ac algorithm employed in the de  and ac in the hve  or gac in the non binary representation  
example     consider three constraints c    c    c  as part of a csp  where vars c     
 x    x    x     vars c       x    x    x     vars c       x    x    x     assume that at some point
the domains of the variables in the de of the problem are as shown in figure    disregarding
the original variables depicted with dashed lines   assume that we try to enforce ac in the

x  x  x  

x  x  x  

vc 

     
     
     
     
     

vc 

     
     
     
     
     
     
     

x 

x  x  x  

   
     
     

vc 

   
x 

figure    dual encoding of a non binary csp 
de using algorithm ac         the algorithm will discover that the rst tuple in d vc   
has no support in d vc     there is no tuple with x      and x       and will delete it 
because of this deletion  the rst two tuples in d vc    lose their support in d vc    and
ac      must therefore look for new supports  for each of the two tuples of d vc    the
algorithm will check all the   remaining tuples in d vc    before discovering that there is
no support  as a result the two tuples will be deleted  algorithm pw ac  on the other
hand  will set the counter of the group where the rst tuple of d vc    belongs  according
to partition s vc    vc     to   once it deletes the tuple  this will result in a call to function
   note that we can construct similar examples for any generic ac algorithm 

   

fibinary encodings of non binary csps  algorithms   experimental results

revise and an automatic deletion of the rst two tuples of d vc     saving a total of     
checks 
now consider the hve of the problem  applying ac on the hve will have no eect
because values   and   of x  and x  are both supported in d vc    and d vc     therefore
there is no propagation through these variables  and as a result the two tuples of d vc    will
not be deleted  similarly  there will be no propagation if we apply gac in the non binary
representation of the problem 
note that the theoretical results regarding the de presented in the rest of the paper
hold if the ac   algorithm of van hentenryck et al         was adapted and used the de
instead of pw ac  the two algorithms have some similarities  e g  they both use a function
to access the group of a decomposition that a certain tuple belongs to  though implemented
dierently   but their basic operation is dierent  the algorithm of van hentenryck et al 
        being an instantiation of ac    handles a queue of triples  vi   vj   a  to implement
constraint propagation  where vi and vj are two variables involved in a constraint and
a is a value that has been removed from d vj    pw ac utilizes a queue of piecewise
decompositions  also the data structures used by the algorithms are dierent  pw ac
checks and updates counters to perform the propagation which  as we explain below  requires
space exponential in the number of common variables in the non binary constraints  the
algorithm of van hentenryck et al         utilizes a more complicated data structure which
requires space exponential in the arity of the non binary constraints  it has to be noted 
however  that pw ac is specically designed for the de  that is  its operation  data
structures  and the way it checks for consistency are based on the fact that the domains of
the dual variables consist of the tuples of the original constraints extensionally stored  on
the other hand  the algorithm of van hentenryck et al         is generic  in the sense that
it can be adapted to operate on any piecewise functional constraint 
      complexities
the pw ac algorithm consists of two phases  in the initialization phase we set up the group
counters  and in the main phase we delete unsupported tuples and propagate the deletions 
we now analyze the time complexity of pw ac  note that in our complexity analysis we
measure operations  such as incrementing or decrementing a counter  since pw ac does
not perform consistency checks in the usual sense 
proposition     the worst case time complexity of algorithm pw ac is o e  dk   
proof  we assume that for any constraint in the dual encoding  the non binary constraints corresponding to the two dual variables vi and vj share at most f original variables
x            xf of domain size d  this means that each piecewise decomposition consists of at
most df groups  obviously  f is equal to k     where k is the maximum arity of the
constraints  in the initialization phase of lines    we iterate over all constraints  and for
each constraint between variables vi and vj   we iterate over all the tuples in d vi    this
is done with o e  dk   asymptotic time complexity  then  all empty groups are inserted in
q  lines       this requires e  df operations in the worst case  after the initialization 
function p ropagation is called  a group is inserted to q  and later removed  only when
it becomes empty  this means that the while loop of p ropagation is executed at most
   

fisamaras   stergiou

df times for each constraint  and at most e  df times in total  this is also the maximum
number of times function revise is called  once in every iteration of the loop   the cost
of function revise is computed as follows  assuming revise is called for a group sl  vi   vj   
we iterate over the  at most  dkf tuples of group sup sl  vi   vj     line      in each iteration
we remove a tuple   line     and we update the counters of the groups where  belongs
 lines        there are at most e such groups  in case vj is constrained with all other dual
variables   therefore  each iteration costs o e   and as a result  each call to revise costs
o edkf    since revise is called at most e  df times  the complexity of pw ac  including
the initialization step  is o e  dk   e  df   e  df edkf   o e  dk     
note that pw ac can be easily used incrementally during search  in this case  the
initialization phase will only be executed once  the asymptotic space complexity of pwac  and any ac algorithm on a binary encoding  is dominated by the o edk   space need
to store the allowed tuples of the non binary constraints  algorithm pw ac also requires
o e  df   space to store the counters for all the groups  o e  df   space for the stack  and
o f e    space for the fast implementation of function groupof  

   algorithms for the double encoding
the double encoding has rarely been used in experiments with binary encodings  although
it combines features of the hve and the de  and therefore may exploit the advantages of
both worlds  to be precise  the double encoding oers the following interesting potential 
search algorithms can deploy dynamic variable ordering heuristics to assign values to the
original variables  while constraint propagation can be implemented through the constraints
between dual variables to achieve higher pruning  in this section we rst briey discuss how
ac can be applied in the double encoding  we then show how various search algorithms
can be adapted to operate in the double encoding 
    arc consistency
ac can be enforced on the double encoding using algorithm pw ac with the addition
that each time a value a of an original variable xi loses all its supports in an adjacent dual
variable  it is deleted from d xi    alternatively  we can use any generic ac algorithm  such
as ac       note that an ac algorithm applied in the double encoding can enforce various
levels of consistency depending on which constraints it uses for propagation between dual
variables  that is  propagation can be either done directly through the constraints between
dual variables  or indirectly through the constraints between dual and original variables 
for example  if we only use the constraints between dual and original variables then we get
the same level of consistency as ac in the hve  if propagation between dual variables is
performed using the constraints of the de then we get the same level of consistency as ac
in the de  for the dual variables  and we also prune the domains of the original variables 
in between  we have the option to use dierent constraints for propagation in dierent parts
of the problem  as the next example shows  ac in the double encoding can achieve a very
high level of consistency compared to the non binary representation  in sections     and    
we will show that this can have a profound eect in practice 
   

fibinary encodings of non binary csps  algorithms   experimental results

example     consider the problem of figure    applying ac through the constraint
between the two dual variables will determine that the problem is insoluble  however  the
problem in its non binary representation is not only gac  but also singleton  generalized 
arc consistent  sgac   which is a very high level of consistency  a csp is sgac if after
applying gac in the problem induced by any instantiation of a single variable  there is no
domain wipeout  debruyne   bessiere        prosser  stergiou    walsh        

x 
x  x  x  x  

 
x 

   

 
x 

x  x  x  x  

x 
vc 

          
          
          
          

   

          
          
          
          

vc 

   
x 

figure    double encoding of a problem that is not ac in the double encoding but is sgac
in the non binary representation 

    search algorithms
various search algorithms for the double encoding can be dened  depending on the variables
that are instantiated and the constraints that are used for propagation  here we will restrict
ourselves to algorithms that only instantiate original variables and perform propagation
using the constraints between dual variables  intuitively this is the most interesting class
of algorithms because they combine nice features from the non binary representation and
the hve  small domain sizes   and from the de  strong propagation  
we rst show that the fc versions for the hve discussed in section     can be adapted
to yield algorithms that run on the double encoding  we call these algorithms dfc dfc  
each algorithm dfci  i                 instantiates only original variables and enforces ac on
exactly the same set of variables of the double encoding as the corresponding algorithm hfci
does in the hve  for example  dfc  will enforce ac on the set of dual variables  and original
variables connected to them  such that each dual variable is connected to at least one past
original variable and at least one future original variable  the dierence between algorithm
dfci  i                 and hfci is that the former can exploit the constraints between dual
variables to enforce a higher level of consistency than the latter  not surprisingly  this
results in stronger algorithms 
proposition     in any non binary csp  under a xed variable and value ordering  algorithm dfci  i                is strictly stronger than the respective algorithm hfci 
proof  it is easy to see that if a value is pruned by hfci in the hve then it is also
pruned by dfci in the double encoding  this is a straightforward consequence of the
fact that    the double encoding subsumes the hve  and    algorithms dfci and hfci
enforce ac on the same set of variables  algorithm dfci is strictly stronger than hfci
   

fisamaras   stergiou

because  by exploiting the constraints between dual variables  it can prune more values than
hfci  consider  for instance  a problem with two constraints c  and c    where vars c     
 x    x    x    x    and vars c       x    x    x    x     all variables xi   i                 have domains
        the allowed tuples of the constraints are rel c                                                
and rel c                                                  if x  is given value   in the hve then
algorithms hfc hfc  will prune tuples              and              from the domains of dual
variables vc  and vc  respectively  no other pruning will be performed  in the double
encoding  the same variable assignment  by any of the algorithms dfc dfc   will cause
the domain wipe out of the two dual variables   
corollary     in any non binary csp  under a xed variable and value ordering  algorithm
dfci  i             is strictly stronger than the respective algorithm nfci  i            
proof  straightforward consequence of propositions     and       
it is easy to see that algorithm hfc   i e  simple binary fc  is equivalent to dfc   the
same holds for algorithms hfc  and dfc   as with the various versions of fc  the mac
algorithm can be adapted to run in the the double encoding so that only original variables
are instantiated  and propagation is implemented through the constraints between dual
variables  it is easy to see that this algorithm is strictly stronger than the corresponding
algorithm for the hve  the proof is similar to the proof of proposition       more interestingly  we show that this mac algorithm for the double encoding can  at most  have a
polynomially greater cost than the corresponding mac algorithm for the hve  while  on
the other hand  it can be exponentially better 
proposition     in any non binary csp  under a xed variable and value ordering  the
mac algorithm for the hidden variable encoding that only instantiates original variables
can have exponentially greater cost than the corresponding mac algorithm for the double
encoding 
proof  to prove this  we can use example    from the paper by bacchus et al         
in this example we have a csp with  n     variables  x            x n     each with domain
            n   and  n     constraints 
c     x    x  mod       x    x  mod   
c     x    x  mod       x    x  mod   
   
c n    x n    x n mod       x n     x n   mod   
c n      x n     x n   mod       x    x  mod   
assume that the variables are assigned in lexicographic order in the double encoding  if x 
and x  are assigned values such that  x    x  mod        then enforcing ac will prune any
tuples from d vc    such that  x    x  mod         this in turn will prune from d vc    any
tuples such that  x    x  mod         continuing this way  ac propagation will prune from
d vc n     any values such that  x    x  mod         when these deletions are propagated
to vc    d vc    will become empty  in a similar way  enforcing ac after assignments to
   

fibinary encodings of non binary csps  algorithms   experimental results

x  and x    such that  x    x  mod         leaves d vc    empty  therefore  the csp is
insoluble  mac in the double encoding needs to instantiate two variables to discover this 
and visit o n    nodes  on the other hand  as explained by bacchus et al          mac in
the hve needs to visit o nlog n    nodes to conclude that the problem is insoluble  finally 
note that  for each node  the asymptotic costs of mac in the double encoding  using pwac  and mac in the hve are polynomially related  therefore  mac in the hve can be
exponentially worse than mac in the double encoding   
a corollary of proposition     is that mac in the double encoding can have have exponentially smaller cost than mgac in the non binary representation 
proposition     in any non binary csp  under a xed variable and value ordering  the
mac algorithm for the double encoding that only instantiates original variables can have
at most polynomially greater cost than the corresponding mac algorithm for the hidden
variable encoding 
proof  to prove this we need to show two things     the number of node visits made by
mac in the double encoding is at most by a polynomial factor greater than the number of
node visits made by mac in the hve     at each node  the worst case cost of mac in the
double encoding is at most by a polynomial factor greater than the worst case cost of ac
in the hve  the former is true since mac in the double encoding is strictly stronger than
mac in the hve  the latter can be established by considering the worst case complexities
of the algorithms at each node  mac in the hve costs o ekdk   at each node  while mac
in the double encoding can use pw ac to enforce ac  which costs o e  dk    therefore 
there is only a polynomial dierence   
in a similar way  we can prove that the relationship of proposition     holds between each
algorithm dfci  i             and the corresponding algorithm hfci  a corollary of proposition     is that mac in the double encoding can have at most polynomially greater cost
than mgac in the non binary representation  it is important to note that proposition    
holds only if algorithm pw ac is used to enforce ac in the double encoding  if we use a
generic algorithm  like ac       then we can get exponential dierences in favor of mac
in the hve  finally  regarding the relationship in node visits among the algorithms for the
double encoding  we have the following 
proposition     given the double encoding of a csp with xed variable and value ordering schemes  the following relations hold 
   nodes dfc   nodes dfc  
   nodes dfc   nodes dfc  
   nodes dfc   nodes dfc   nodes dfc  
   nodes dfc   nodes dfc   nodes dfc  
   nodes dmac  nodes dfc  
proof  the proof is very simple and it is based on comparing the size of the subsets of
the problem where each algorithm enforces ac   
   

fisamaras   stergiou

   experimental results
in this section we make an empirical study of algorithms for binary encodings  the empirical
study is organized in two parts 
 in the rst part  subsections     and      we evaluate the improvements oered by
specialized algorithms compared to generic ones  at the same time we compare the
eciency of algorithms that run in the binary encodings to their non binary counterparts  this comparison can give us a better understanding of when encoding a
non binary problem into a binary one pays o  and which encoding is preferable  for
this empirical investigation we use randomly generated problems  random problems
with added structure  and benchmark crossword puzzle generation problems  random
problems allow us to relate the performance of the algorithms to certain parameters 
such as tightness  constraint graph density  and domain size  crossword puzzles are
standard benchmarks for comparing binary to non binary constraint models  and allow us to to evaluate the performance of the algorithms on problems that include
constraints of high arity 
 in the second part  subsection        we investigate the usefulness of binary encodings
in more realistic problem settings  for this study we use problems from the domains
of conguration and frequency assignment and we compare the performance of mac
algorithms that run in the encodings to an mgac algorithm in the non binary representation 
all algorithms were implemented in c  all experiments were run on a pc with a     
ghz pentium   processor and   gb ram  in all experiments  all algorithms use the
dom deg heuristic  bessiere   regin      b  for dynamic variable ordering and lexicographic value ordering 
      random problems
random instances were generated using the extended model b as it is described by bessiere
et al          to summarize this generation method  a random non binary csp is dened
by the following ve input parameters 
n   number of variables
d   uniform domain size
k   uniform arity of the constraints
p   density     percentage of the generated graph  i e  the ratio between existing constraints
and the number of possible sets of k variables
q   uniform looseness     percentage of the constraints  i e  the ratio between allowed
tuples and the dk total tuples of a constraint
the constraints and the allowed tuples were generated following a uniform distribution  we
made sure that the generated graphs were connected  in the following  a class of non binary
   

fibinary encodings of non binary csps  algorithms   experimental results

csps will be denoted by a tuple of the form   n  d  k  p  q    we use a star    for the case
where one of the parameters is varied  for example  the tuple                     stands
for the class of problems with    variables  domain size     arity    graph density      and
varying constraint looseness 
      crossword puzzles
crossword puzzle generation problems have been used for the evaluation of algorithms and
heuristics for csps  ginsberg  frank  halpin    torrance        beacham  chen  sillito   
van beek        and binary encodings of non binary problems  bacchus   van beek       
stergiou   walsh         in crossword puzzle generation we try to construct puzzles for a
given number of words and a given grid which has to be lled in with words  this problem
can be represented as either a non binary or a binary csp in a straightforward way  in
the non binary representation there is a variable for each letter to be lled in and a nonbinary constraint for each set of k variables that form a word in the puzzle  the domain
of each variable consists of the low case letters of the english alphabet giving a domain
size of     the allowed tuples of such a constraint are all the words with k letters in the
dictionary used  these are very few compared to the   k possible combinations of letters 
which means that the constraints are very tight  in the de there is a variable for each word
of length k in the puzzle and the possible values of such a variable are all the words with k
letters in the dictionary  this gives variables with large domains  up to      values for the
unix dictionary that we used in the experiments   there are binary constraints between
variables that intersect  i e  they have a common letter   in the hve there are all the
original variables as well a set of dual variables  one for each non binary constraint 
    hidden variable encoding
in our rst empirical study we investigated the performance of two mac algorithms that
operate in the hve  and compared them to mgac       their counterpart in the nonbinary representation  the two mac algorithms for the hve are mhac       which
stands for mac in the hve that only instantiates original variables  and mhac      f ull
which is a mac algorithm that may instantiate any variable  dual or original  according to
the heuristic choice  as stated by their names  all three algorithms use ac       gac      
to enforce ac  although we also run experiments with the various versions of fc  we do not
include any results since these algorithms are inecient on hard problems  especially on hard
crossword puzzles   however  the qualitative comparison between fc based algorithms for
the hve and the non binary representation is similar to the comparison regarding macbased algorithms 
      random problems
table   shows the performance  measured in cpu time  of the algorithms on ve classes of
randomly generated csps  all classes are from the hard phase transition region  classes   
      and   are sparse  while   is more dense  we do not include results on mhac      f ull
because experiments showed that this algorithm has very similar behavior to mhac      
the reason is that  because of the nature of the constraints  the dom deg heuristic almost
   

fisamaras   stergiou

always selects original variables for instantiation  in the rare cases where the heuristic
selected dual variables  this resulted in a large increase in cpu time 
class
mgac      mhac     
                          
    
    
                          
    
    
                        
     
     
                            
     
     
                       
    
    
table    comparison of algorithms mgac      and mhac      on random classes of
problems  classes   and   taken from the paper by bessiere et al          we give
the average run times  in seconds  for     instances at each class  the winning
time for each instance is given in bold  we follow this in the rest of the paper 

from table   we can see that mhac      performs better than mgac      on the
sparse problems  in general  for all the   ary classes we tried with density less than       
the relative run time performance of mhac      compared to mgac      ranged from
being equal to being around     times faster  in the very sparse class    which includes
problems with   ary constraints  mhac      is considerably more ecient than mgac      this is due to the fact that for sparse problems with relatively large domain sizes
the hard region is located at low constraint looseness  i e  small domains for dual variables 
where only a few operations are required for the revision of dual variables  another factor
contributing to the dominance of the binary algorithm in class   is the larger arity of the
constraints  the non binary algorithm requires more operations to check the validity of
tuples when the tuples are of large arity  as explained in section     
when the density of the graph increases  class     the overhead of revising the domains
of dual variables and restoring them after failed instantiations slows down mhac       and
as a result it is outperformed by mgac       for denser classes than the ones reported 
the phase transition region is at a point where more than half of the tuples are allowed  and
in such cases the non binary algorithm performs even better 
      crossword puzzles
table   demonstrates the performance of search algorithms on various crossword puzzles 
we used benchmark puzzles from the papers by ginsberg et al         and beacham et al 
        four puzzles                              could not be solved by any of the algorithms
within   hours of cpu time  also  two puzzles        and        were arc inconsistent  in
both cases gac discovered the inconsistency slower than ac in hve  around     time
dierence in       and      in        because the latter method discovered early the domain
wipe out of a dual variable 
in the rest of the puzzles we can observe that mhac      performs better than mgac     on the hard instances  for the hard insoluble puzzles mhac      is up to   times
faster than mgac       this is mainly due to the large arity of the constraints in these
   

fibinary encodings of non binary csps  algorithms   experimental results

puzzle
     
      
     
     
     
  
   
   
     

n
  
  
  
   
   
  
  
  
  

e mgac      mhac      mhac      f ull
   
    
    

   
     
     
     
   
     
     
  m
   
     
     

   


    
  
    
    
    
  
  m
 m
  m
  
 m
 m
 m
   
     
     
     

table    comparison  in cpu time  between algorithms for the hve and algorithms for the
non binary representation of crossword puzzles  n is the number of words and e
is the number of blanks  all times are in seconds except those followed by m
 minutes   a dash    is placed wherever the algorithm did not manage to nd
a solution within   hours of cpu time  problems marked by     are insoluble  we
only include problems that were reasonably hard for at least one algorithm and at
the same time were solvable within   hours by at least one algorithm 

classes    another interesting observation is that there can be signicant dierences between
the performance of methods that may instantiate dual variables and those which instantiate
only original ones  in many cases mac      f ull managed to nd a  dierent  solution
than mhac      and mgac      earlier  on the other hand  mac      f ull was subject
to thrashing in some instances where other methods terminate  the fact that in all insoluble
puzzles mac      f ull did not do better than mhac      shows that its performance is
largely dependent on the variable ordering scheme  in many cases mac      f ull visited
less nodes than mhac       however  this was not reected to similar time performance
dierence because when a dual variable is instantiated mac      f ull does more work
than when an original one is instantiated  it has to instantiate automatically each original
variable xi constrained with the dual variable and propagate these changes to other dual
variables containing xi  
    dual and double encodings
in this empirical study we investigated the performance of algorithms for the de and double
encoding  we tried to answer the following three questions     how ecient are specialized
algorithms compared to generic algorithms     does the use of a specialized algorithm
make the de an eective option for solving non binary csps     can we take advantage
of the theoretical properties of the double encoding in practice  to answer these questions 
we run experiments with random and structured problems to evaluate the benets oered
by the specialized algorithm pw ac when maintaining ac during search  we compared
   puzzles         correspond to square grids with no blank squares 

   

fisamaras   stergiou

the performance of two mac algorithms  one that uses ac      to enforce ac  mac       and another that uses pw ac to enforce ac  mac pw ac   we also compared
these algorithms to an algorithm that maintains gac in the non binary representation
using gac       mgac        and to mac algorithms that maintain ac in the double
encoding using pw ac  algorithm mac pw acd  and ac       algorithm mac     d  
      random problems
we rst give some indicative results of a comparison between the various algorithms using
random problems  figure   compares the time that is required to enforce ac in the de
and gac in the non binary representation  while figures      compare algorithms that
maintain these consistencies 
figure   shows the average cpu times  in msecs  that pw ac and ac      take to
enforce ac in the de of     random csps with    variables with domain size     ternary
constraints  and     graph density     constraints   we also include the average time gac     takes to enforce gac on the non binary representation of the generated instances  the
looseness of the constraints is varied starting from a point where all instances are not gac
up until gac and ac in the de do not delete any values  there is signicant dierence in
the performance of pw ac compared to ac      which constantly rises as the looseness of
the constraints becomes higher  this is expected  since as the number of allowed tuples in a
constraint grows  ac      takes more and more time to nd supports  gac      is faster
than pw ac  up to one order of magnitude  when the looseness in low  but the dierence
becomes smaller as the looseness grows 
figure   shows cpu times for a relatively sparse class of problems with    variables and
   ternary constraints  p       figure   shows cpu times and node visits for a denser class
with    variables and     ternary constraints  p       along the x axis we vary the domain
size of the variables  all data points show average cpu times  in secs  over     instances
taken from the hard phase transition region 
we can make the following observations     mac pw ac and mac pw acd are signicantly faster  one order of magnitude  than mac      and mac     d  respectively  in
both classes of problems     for both these classes  the non binary representation is preferable to the de  mgac      is two orders of magnitude faster in the denser class   in the
sparser class  mac in the double encoding  i e  algorithm mac pw acd  is competitive
with mgac      for small domain sizes  and considerably faster for larger domain sizes 
the eect of the domain size in the relative performance of the algorithms is mainly due to
a run time advantage of pw ac compared to gac       and not to the higher consistency
level achieved in the double encoding    the run time advantage of pw ac can be explained
considering that  as the domain size increases  gac      has to check an increasing number
of tuples for supports  an operation more costly than the counter updates of pw ac  in the
denser class mgac      is constantly faster than all the other algorithms for all domain
sizes  this is not surprising considering the o e  dk   and o ekdk   complexities of pw ac
and gac       i e  factor e becomes more signicant  
in figure    we compare algorithms mgac      and mac pw acd  the faster among
the algorithms for the encodings  in a class of problems with    variables and      ary
   this was verified by looking at the node visits of the two algorithms 

   

fibinary encodings of non binary csps  algorithms   experimental results

     

     
cpu time  secs 

    
cpu time  msecs 

      

ac     
pw ac
gac     

   

  

 

    
   
  
 

   

   
 

     

    

     
q

    

     

    

 

      

  

  

  

  

figure                     csps 
      

mac     
mac ac    d
mac pw ac
mac pw acd
mgac     

mgac     
mac pw acd

     
cpu time  secs 

     

 

d

figure                         csps 

cpu time  secs 

mac     
mac     d
mac pw ac
mgac     
mac pw acd

    
   
  

    

   

  

 
   

 
 

 

  
d

  

  

 

 

  

  

  

  

d

figure                     csps 

figure                      csps 

constraints  the other algorithms for the encodings were not competitive in this class of
problems  we can see that mgac      is more ecient for small domain sizes  while for
larger domain sizes mac pw acd can be up to one order of magnitude faster  however 
for denser classes of problems these results are reversed 
from our experiments with random problems we conjecture that the double encoding
should be the preferred model for sparse problems  provided that an ecient algorithm like
pw ac is used for propagation  for csps with medium and high density the non binary
representation is preferable to the encodings 
random problems with added structure in the experiments with ternary csps
we did not detect an advantage of the de compared to the non binary representation
 and consequently the hve   mac in the de is rarely better than mgac       only in
some cases of very tight constraints and large domain sizes   despite the use of pw ac
for propagation  also  while mac pw acd is competitive and often faster than mgac     in sparse random problems  this result is reversed as the density increases  a basic
reason for these results is that in randomly generated problems  especially ones with ternary
constraints  we get many pairs of non binary constraints that share at most one original
variable  it is known  see bacchus et al        for example  that for any such pair of
constraints  the ltering achieved by ac in the de is the same as the ltering achieved
by gac in the non binary representation  and ac in the hve   therefore  ac in the de
looses much of its ltering power 
   

fisamaras   stergiou

to validate this conjecture  we experimented with a generation model where structure is
added to purely random problems  to be precise  we experimented with problems where a
clique of variables is embedded in a randomly generated instance  for ternary problems any
two constraints in the clique may share one or two variables  this is decided at random  for
  ary problems any two constraints in the clique may share one  or two  or three variables 
again  this is decided at random  table   compares the performance of various mac
algorithms on                    and                    problems of this type  for the second
class we only include results for mac pw acd  which is by far the best algorithm for such
problems  and mgac      
arity clique size mgac      mac      mac pw ac mac     d mac pw acd
 
 
      
        
       
       
       
 
  
      
        
       
       
      
 
  
       
       
      
      
     
 
  
       
      
     
      
    
 
 
     
      
 
  
      
     
 
  
       
      
table    average cpu times of mac algorithms for the de and the double encoding and
mgac for the non binary representation of random problems with embedded
cliques  all times are in seconds  each number gives the average of    instances
from around the phase transition region 
as we can see  the comparative results of the algorithms vary according to the size of
the embedded clique  when there is no clique embedded  clique size    mgac      is
faster than the algorithms for the binary encodings  as the clique size grows  the binary
encodings  and especially the double  become more ecient  the double encoding is more
eective than the de for all clique sizes  for a large clique that covers all variables  mac
in the double encoding is many orders of magnitude faster than mgac       this huge
dierence is caused by the presence of many constraints that share more than one variable in
the non binary representation  in such cases ltering through the constraints between dual
variables is very strong  however  much of this advantage is lost when generic algorithms
are used in the encodings  similar results occur in denser problems when this generation
model is used 
      crossword puzzles
table   compares the cpu times of the two mac algorithms in the de and mgac in the
non binary representation using various benchmark crossword puzzles  we do not include
results for mac in the double encoding since this particular representation of crossword
puzzle generation problems is impractical  the reason for this is that for each pair of dual
variables involved in a constraint  the two variables have at most one original variable in
common  i e  the letter on which the two words intersect   as explained previously  this
   

fibinary encodings of non binary csps  algorithms   experimental results

degrades the ltering achieved by the constraints between dual variables  such constraints
in the double encoding are redundant since the same ltering can be achieved through the
constraints between dual and original variables 

puzzle
     
      
     
     
     
     
     
     
     
     
     
  
   
   
   
     

n
  
  
  
  
   
   
   
   
   
   
   
  
  
  
  
  

e mgac      mac      mac pw ac
   
    
      
     
   
     
      
      
   
     


   
    


   
    


   
     

       
   

     
    
   
    
     
     
   
      
      
     
   


    
   


    
  
    
     
    
  
  m

  m
  
 m

 m
  


      
   
     
      
     

table    comparison  in cpu time  between mac algorithms for the de and mgac for the
non binary representation of crossword puzzles  all times are in seconds except
those followed by m  minutes   the cpu limit was   hours  problems marked by
    are insoluble  we only include problems that were reasonably hard for either
mgac      or mac pw ac and at the same time were solvable within   hours
by at least one algorithm 

from the data in table   we can clearly see that mac pw ac is signicantly faster
than mac      on all instances  the speedup oered by the use of pw ac makes mac
in the de competitive with mgac in many cases where using a generic algorithm in the
de results in a clear advantage in favor of mgac  also  in some instances  e g  puzzles
                      the use of pw ac makes mac in the de considerably faster than
mgac  however  there are still some instances where mgac  and consequently mhac 
nds a solution  or proves insolubility  fast  while mac in the de thrashes  and vice versa 
note  that only   of the    very hard      puzzles that we tried were solved by any
algorithm within the time limit of two hours  mac pw ac managed to solve these  
instances relatively fast  while the other two algorithms solved only   of them within the
cpu limit 
   

fisamaras   stergiou

    experiments with realistic problems
in the next sections we present experimental results from conguration and frequency assignment problems  the aim of these experiments was to investigate the usefulness of binary
encodings in realistic structured domains  we focus on the dual and double encodings which
are the most promising binary encodings because of the strong propagation they can oer 
      configuration
conguration is an area where csp technology has been particularly eective  a conguration problem can be viewed as trying to specify a product dened by a set of attributes 
where attribute values can only be combined in predened ways  such problems can be
modelled as csps  where variables correspond to attributes  the domains of the variables
correspond to the possible values of the attributes  and constraints specify the predened
ways in which values can be combined  in many conguration problems the constraints
are expressed extensionally through lists of allowed  or disallowed  combinations of values  alternatively  constraints are expressed as rules which can easily be transformed into
an extensional representation  consider the following example adapted from the paper by
subbarayan  jensen  hadzic  andersen  hulgaard   moller        
example     the conguration of a t shirt requires that we specify the size  small 
medium  or large   the print  men in black   mib or save the whales   stw   and the
color  black  white  or red   there are the following constraints     if the small size is chosen
then the stw print cannot be selected     if the mib print is chosen then the black color has
to be chosen as well  and if the stw print is chosen then the black color cannot be selected 
this conguration problem can be modelled as a csp with three variables  x    x    x    representing size  print  and color respectively  the domains of the variables are d x     
 small  medium  large   d x       m ib  st w    and d x       black  white  red   the
rst constraint is a binary constraint between variables x  and x  with the following allowed
tuples     small  m ib      medium  m ib      medium  st w      large  m ib     
large  st w     the second constraint is a binary constraint between variables x  and x 
with the following allowed tuples     m ib  black      st w  white      st w  red    
in practice  many solvers for conguration problems are able to interact with the user
so that  apart from meeting the given specications  the users choices of values for certain
attributes are also satised  in this study we use conguration instances to compare the
non binary representation to binary encodings on structured realistic problems  although
it would be interesting to investigate the applicability of binary encodings in an interactive
congurator  such work is outside the scope of this paper 
we run experiments on ve problems taken from clib  a library of benchmark conguration problems  clib         the rst thing we noticed after encoding the ve problems
as binary and non binary csps is that they are trivially solvable by all algorithms without
backtracking  a closer look at the structure of clibss problems revealed the reason  their
constraint graphs consist of various unconnected components  each component consists of
very few or  in some cases  a single variable  as a result  the problems are split into independent subproblems that are trivially solved by all algorithms  in order to obtain dicult
instances for benchmarking  we made the graphs connected by adding some randomness 
   

fibinary encodings of non binary csps  algorithms   experimental results

each of the ve problems was extended by adding to it   variables and      constraints
so that the graph became connected    table   shows the total number of variables and
constraints in the modied problems  the added constraints were of arity       or    chosen
at random  and the variables on which they were posted were selected at random  making
sure that the resulting graph was connected  the looseness of each added constraint was
also set at random  and nally  the allowed tuples of each constraint were chosen at random
according to its looseness 

problem n

e arity dom

machine
fx
fs
esvs
bike

  
  
  
  
  

  
  
  
  
  

 
 
 
 
 

 
  
  
  
  

mgac     
mac pw ac mac pw acd
nodes   time
nodes   time
nodes   time
              
          
           
             
         
         
              
         
          
                
           
             
                                              

table    comparison of algorithms on conguration problems  arity and dom are the
maximum constraint arity and maximum domain size in the problem  run times
are given in seconds 

table   gives the average run times and node visits for algorithms mgac      in the
non binary representation  mac pw ac in the de  and mac pw acd in the double
encoding  for each of the ve benchmarks we repeatedly generated instances using the
model described above  each generated instance was solved by all three algorithms and
was stored if the instance was hard for at least one algorithm  otherwise  it was discarded 
an instance was considered hard if at least one algorithm took more than one second to
solve it  table   reports averages over the rst    hard instances generated from each
benchmark  that is  we run     hard instances in total  note that in the binary encodings
all constraints of the original problem  even binary ones  were encoded as dual variables 
the experimental results of table   show a very signicant advantage in favor of the
binary encodings compared to the non binary representation  both in node visits and run
times  the de is clearly the most ecient model  mac pw ac in the de can be up
to three orders of magnitude faster than mgac      in the non binary representation 
there was not a single instance among the     instances where mgac      was faster
than mac pw ac  the double encoding is also much more ecient than the non binary
representation  the main factor contributing to the performance of the encodings is the
strong propagation that is achieved through the constraints between dual variables  which
is reected on the numbers of node visits  there is a number of reasons  related to the
structure of these conguration problems  that can justify the strong performance of the
encodings 
   experiments showed that these are the minimum additions that need to be made in order to get hard
problems without altering the structure of the problems too much 

   

fisamaras   stergiou

 the constraint graphs are very sparse  this is typical of conguration problems since 
usually  an attribute of the product specication has dependencies with only a few of
the other attributes 
 the constraints of high arity are very tight  moreover  each value of the variables with
large domain sizes has very few  typically one  supporting tuple in the constraints such
variables participate 
 there are intersecting non binary constraints with more than one original variable in
common  as explained  and demonstrated empirically in section      this can have a
signicant impact on the propagation power of ac in the dual and double encodings 
note that the prole of conguration problems  as analyzed above  agrees with the conjectures we made based on results from random problems  that is  the dual and double
encodings are suitable for sparse problems with tight constraints  where intersecting constraints may share more than one variable 
      frequency assignment
frequency assignment is an important problem in the radiocommunication industry  in
such a problem there is a radio communications network in a given region consisting of a
set of transmitters  each transmitter has a position in the region  a frequency spectrum 
a certain power  and a directional distribution  the aim is to assign values to some or all
of the properties of the transmitters so that certain criteria are satised  there are various
types of frequency assignment problems  in this study we consider a version of the radio
link frequency assignment problem  rlfa   in such a problem we are given a set of links
 l            ln    each consisting of a transmitter and a receiver  each link must be assigned a
frequency from a given set f   at the same time the total interference at the receivers must
be reduced below an acceptable level using as few frequencies as possible  these problems
are typically optimization problems but for the purposes of this study we treat them as
satisfaction problems 
a rlfa problem can be modelled as a csp where each transmitter corresponds to
a variable  the domain of each variable consists of the frequencies that can be assigned
to the corresponding transmitter  the interferences between transmitters are modelled as
binary constraints of the form  xi  xj     s  where xi and xj are variables and s    is
a required frequency separation  such a constraint restricts the frequencies that the two
transmitters can simultaneously be assigned  and in that way the interference between them
is minimized  this is under the realistic assumption that the closer two frequencies are the
greater is the interference between them  this binary model has been used extensively to
represent rlfa problems  and numerous solution methods  csp based or other  have been
proposed  also  rlfa has been widely used as a benchmark to test new algorithms for
binary constraints  mainly ac algorithms  
it has been argued that the standard binary model of frequency assignment problems
fails to capture some important aspects of real problems  such as multiple interferences 
resulting in non optimal frequency assignments  jeavons  dunkin    bater        watkins 
hurley    smith        bater        hodge  hurley    smith         as a consequence 
there have been some eorts to introduce more expressive methods that utilize non binary
   

fibinary encodings of non binary csps  algorithms   experimental results

constraints in frequency assignment  e g  bater        hodge et al          there are many
types of non binary constraints that can be considered  the following ones have received
attention 
co channel constraints   e g   the frequencies assigned to n transmitters are not all equal 
adjacent channel constraints   e g   the frequencies assigned to n transmitters are at
least one frequency apart 
separation constraints   e g   the frequencies assigned to n transmitters are at least s
frequencies apart 
obviously  separation constraints generalize the adjacent channel constraints  the rst
two types of constraints are typically very loose while the third can be tight  separation
constraints are used in densely constrained areas  representing conurbations in a region 
where there is large number of links closely situated  in such cases  large separations in
the frequencies of the transmitters must be imposed  resulting in tight constraints  we
also consider a richer type of separation constraints  the frequencies assigned to a set of n
transmitters are at least s frequencies apart and n transmitters among them are at least
s    s  frequencies apart from all the others  note that some of the non binary constraints
can be equivalently decomposed into a clique of binary constraints  without introducing
dual variables  resulting however in weaker propagation  an example is adjacent channel
constraints  others cannot be equivalently expressed as a set of binary constraints unless
a binary encoding is used  for example  co channel constraints  as noted by hodge et al 
        only non binary constraints of low arity can be utilized in practice  it has been
shown that in many cases such constraints are sucient to achieve very low interferences 
constraints of higher arity may oer improvements in the quality of solutions  but they tend
to slow down the solution process to an extend that solving large real problems becomes
infeasible 
in the empirical study presented here we are interested in comparing models of rlfatype problems with non binary constraints to the corresponding binary encodings and not
in devising new ecient methods for solving rlfa problems  since the available rlfa
benchmarks follow the standard binary approach  to test the algorithms we generated nonbinary problems by placing variables  corresponding to links  on a grid following the typical
rlfa structure  that is  the problems consist of several groups of closely situated variables
plus a few constraints that connect these groups  for example  such structures are depicted
in figure     this corresponds to the constraint graph of a binary rlfa problem which
typically consists of a set of cliques  or near cliques  of binary constraints and a small number
of constraints connecting the various cliques  e g  the benchmarks of cabon  de givry 
lobjois  schiex    warners         from the binary encodings we only considered the
double since dual variables can have very large domains  which makes the de inecient 
indicative results of the experiments we run are depicted in table    in these experiments
we posted only low arity  i e    ary to   ary  separation constraints  as shown in figure    
and compared the performance of algorithm mgac      on the non binary model of the
problems to the performance of mac pw acd on the double encoding of the problems  we
tried two implementations of mgac       one that utilizes specialized propagators for the
   

fisamaras   stergiou

a  prob 

b  prob 

c  prob 

figure     examples of rlfa problems with non binary separation constraints 

separation constraints  written as functions   and another that operates on the extensional
representation of the constraints  the rst implementation was generally faster  so all the
results of mgac      presented below refer to the intentional implementation  the double
encoding was built by translating the separation constraints into lists of allowed tuples in
a preprocessing step 

problem
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 

 easiest 
 median 
 hardest 
 easiest 
 median 
 hardest 
 easiest 
 median 
 hardest 
 easiest 
 median 
 hardest 
 easiest 
 median 
 hardest 

n
  
  
  
  
  
  
  
  
  
  
  
  
   
   
   

e arity
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

mgac     
mac pw acd
nodes   time
nodes   time
          
         
                   
         


             
               
               
               
                                      
           
        
            
            
             
        
         
         

         


          
        
              
         

           

table    comparison of algorithms on rlfa problems with separation constraints  arity
is the maximum constraint arity  run times are given in seconds  a dash    is
placed wherever the algorithm did not nish its run within    hours of cpu time 

   

fibinary encodings of non binary csps  algorithms   experimental results

table   reports results from a total of    instances created using ve dierent constraint
graph topologies  all variables have domains of    or    values  the number of allowed
tuples for the constraints varied from around    for very tight constraints to several thousands for looser ones  according to the frequency separation imposed by parameters s and
s of the separation constraints  these parameters were set at random for each constraint 
making sure that very loose constraints were not generated  for example  for a   ary basic
separation constraint on variables with domain size     s was at least    giving      allowed
tuples  and at most    giving     allowed tuples  
prob   prob   and prob  refer to problems having the topologies shown in figure    
prob  consists of three groups of variables  similar to the ones of prob   arranged in a
chain like structure  finally  instances of prob  consist of randomly generated groups of
variables  each one having      variables and       ary to   ary constraints  these groups
are interconnected according to their topological distance  i e  constraints are posted on
variables of nearby groups   all instances of prob  prob  have xed topology  for each
topology a set of instances was created by changing the type of the constraints  for example 
two instances having the topology of prob  may dier in the type of separation constraints
 basic or richer  they include  also  the frequency separations s and s imposed by a
constraint may dier  instances of prob  may also dier in their constraint graph topology 
we report node visits and run times of the easiest  median  and hardest instance for each
topology  with respect to the performance of mgac    the hardest instances were the same
for both the encoding and the non binary representation  except for prob    while the easiest
and median instances were sometimes dierent 
in table   we can see that there can be very substantial dierences in favor of the
double encoding  many instances were solvable in the double encoding with no or very
little backtracking while mgac      thrashed  this is mainly due to the large number
of interleaved constraints sharing more than one variable  which boosts propagation in the
double encoding  the performance of the algorithms seems to be heavily dependent on the
topology of the problems  for example  on instances of prob  the non binary representation
was much more ecient than the double encoding  it seems that in this particular class of
problems heuristic choices were misled by the propagation achieved in the double encoding 
we have not been able to come up with a satisfactory explanation as to why this occurred
in this particular topology 
finally  to investigate the eect that the presence of loose constraints of higher arity
has  we run experiments where   ary adjacent channel constraints were posted between
variables further apart in the graph  in addition to the separation constraints  in this
case using the double encoding to model all the constraints in the problems was infeasible
due to the spatial requirements  for example  trying to generate the allowed tuples of a
single   ary adjacent channel constraint consumed all the memory of the system  therefore 
we compared algorithm mgac      on the non binary model to a mac algorithm that
runs on a hybrid model where the tight separation constraints are modelled using the
double encoding and the loose adjacent channel constraints are kept in the intentional nonbinary representation  table   reports results from a total of    instances created using the
   to create the instances we varied the type of the constraints and the values of parameters s and s until
non trivial problems were generated  we consider as trivial problems that are arc inconsistent or solvable
with no backtracking 

   

fisamaras   stergiou

problem
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 
prob 

 easiest 
 median 
 hardest 
 easiest 
 median 
 hardest 
 easiest 
 median 
 hardest 

n
  
  
  
  
  
  
   
   
   

e arity
  
  
  
  
  
  
  
  
  

 
 
 
 
 
 
 
 
 

mgac     
mac hybrid
nodes   time
nodes   time
           
          
              
           


            
             
                



          
         
               
          

               

table    comparison of algorithms on rlfa problems with separation and adjacentchannel constraints  mac hybrid corresponds to a mac algorithm that runs
on the hybrid model 

graph topologies of prob   prob  and prob  with the addition of four   ary adjacent channel
constraints in each instance  the hybrid model is more ecient on instances of prob  and
prob  because of the strong propagation achieved through the binary encoding of the tight
constraints  the non binary model is better on instances of prob  where it seems that
propagation through the binary encoding results in bad heuristic choices 
    discussion
in this section we summarize the results of our experimental studies and draw some conclusions regarding the applicability of the encodings  based on our theoretical and experimental
analysis 
hidden variable encoding as theoretical results suggested  and empirical results conrmed  solving problems in the hve using algorithms that only instantiate original variables
is essentially analogous to solving the non binary representation directly  all the commonly
used algorithms for non binary problems can be applied  with adjustments  to the hve  and
vice versa  when such algorithms are used  the hve oers some  moderate  computational
savings compared to the non binary representation  especially in sparse problems  these
savings are due to the ability of the ac algorithm in the hve to detect inconsistencies earlier than the corresponding gac algorithm in the non binary representation  therefore  we
conjecture that the hve is applicable in sparse non binary problems where the constraints
are extensionally specied  in other cases  the hve is either less ecient in run times
than the non binary representation  e g  dense problems   or building the hve adds space
overheads that are not justied by the marginal gains in search eort  additionally  there
is not enough empirical evidence to suggest that the essential dierence between search
algorithms for the hve and the non binary representation  i e  the ability of the former
to branch on dual variables  can make the hve signicantly more ecient in some class
   

fibinary encodings of non binary csps  algorithms   experimental results

of problems  this  coupled with the fact that any benets gained by instantiating dual
variables can be maximized if the double encoding is used instead of the hve  limits the
applicability of such algorithms 
dual and double encodings the de and the double encoding have the advantage
of strong ltering through the constraints between dual variables  we showed that this
advantage can be exploited by a low cost specialized algorithm  such as pw ac  to make
the de competitive and often signicantly better than the non binary representation in
several sparse csps  such as crossword puzzle generation and conguration problems  for
dense csps  the de does not pay o because either the spatial requirements make its use
infeasible  or if this is not the case  the advantages oered are outweighed by the overhead
of updating the domains of dual variables  the same holds for csps containing constraints
of large arity unless they are very tight  as in crossword puzzles  
algorithms for the double encoding demonstrate especially promising performance 
when many non binary constraints that share more than one variable are present in a
problem then mac in the double encoding can exploit the benets of both the variable
ordering heuristic  borrowed from the non binary representation  and the stronger ltering 
borrowed from the de  to outperform the other representations  this was demonstrated in
problems with such structure  random and also frequency assignment   like   this is also
the case in the still life problem  which explains the success of the double encoding     in
addition  the double encoding oers the interesting potential of hybrid models where certain
constraints are encoded into binary and others are kept in the non binary representation
based on certain properties of the constraints  to be precise we can benet by encoding
constraints that are either naturally specied in extension  or have relatively low arity and
are tight  this was demonstrated in various domains  most notably  in the frequency assignment problems where the double encoding  or a hybrid one  payed o in most cases 
although the constraints in such problems are naturally dened intentionally 

   related work
although  the de was proposed in       dechter   pearl        and the hve in       rossi
et al          the rst substantial eort towards evaluating their eciency was carried out
in       bacchus   van beek         in that work  bacchus and van beek compared theoretically and empirically the fc algorithm in the two encodings against fc for non binary
csps  also  they introduced fc   a specialized algorithm for the hve  the algorithms
compared by bacchus and van beek were the simplest versions of fc  hfc  and hfc   i e 
fc   for the hve  and nfc  for the non binary representation  we extend that work by
studying various recent and more advanced versions of fc 
following bacchus and van beek         stergiou and walsh made a theoretical and
empirical study of ac in the encodings  stergiou   walsh         it was proved that ac
in the hve is equivalent to gac in the non binary representation  while ac in the de is
stronger  in the small experimental study included in the paper by stergiou   walsh        
mac for the hve  de  and double encoding was compared to mgac in the non binary
    although the title of smiths paper        refers to the de  the model of the still life problem used is
based on the double encoding 

   

fisamaras   stergiou

representation of some crossword puzzles and golomb rulers problems  results showed an
advantage for the non binary representation and the hve  but it is important to note that
all the mac algorithms used generic inecient algorithms to enforce ac 
smith  stergiou   walsh        performed a more extensive experimental comparison
of mac in the hve and the double encoding  and mgac in a non binary model of the
golomb rulers problem  however  again the mac algorithms in the encodings used a generic
algorithm to enforce ac  as a result they were outperformed by mgac in the non binary
model 
beacham et al         compared the performances of dierent models  heuristics  and
algorithms for csps using crossword puzzle generation problems as benchmarks  among
the models that were compared was the hve  the de and the non binary representation 
once again  the algorithms that were applied in the encodings were generic algorithms 
for example  two of the implemented algorithms for the de were mac that uses ac   for
propagation and mac that uses ac    both these algorithms suer from the very high complexity of ac propagation  as demonstrated  the use of algorithm pw ac for propagation
can signicantly enhance the performance of mac in crossword puzzle problems 
bacchus et al         presented an extensive theoretical study of the de and the hve 
among other results  polynomial bounds were placed on the relative performance of fc
and mac in the two encodings and the non binary representation  or it was shown that no
polynomial bound exists  for example  it was shown that fc in the hve  i e  hfc  in the
terminology we use  is never more than a polynomial factor worse than fc in the de  but
fc in the de can be exponentially worse than fc in the hve  also  fc in the non binary
representation  i e  nfc  in the terminology we use  can be exponentially worse than fc in
the hve  and vice versa  we add to these results by analyzing the performance of various
more advanced algorithms for the hve and the double encoding 
smith modelled the problem of nding a maximum density stable pattern still life
in conways game of life using mac in the double encoding with remarkable success 
compared to other constraint programming and integer programming approaches  smith 
       the mac algorithm was implemented using the table constraint of ilog solver 
this constraint implements the generic ac algorithm of bessiere   regin      a   which is
very expensive when used in the de because of its high time complexity  we believe that
the results presented by smith can be further improved if mac pw ac is used instead 

   conclusion
in this paper we studied three binary translations of non binary csps  the hidden variable
encoding  the dual encoding  and the double encoding  we showed that the common perception that standard algorithms for binary csps can be used in the encodings of non binary
csps suers from aws  namely  standard algorithms do not exploit the structure of the encodings  and end up being inecient  to address this problem  we proposed specialized arc
consistency and search algorithms for the encodings  and we evaluated them theoretically
and empirically  we showed how arc consistency can be enforced on the hidden variable
encoding of a non binary csp with the same worst case time complexity as generalized arc
consistency on the non binary representation  we showed that the structure of constraints
in the dual encoding can be exploited to achieve a much lower time complexity than a
   

fibinary encodings of non binary csps  algorithms   experimental results

generic algorithm  empirical results demonstrated that the use of a specialized algorithm
makes the dual encoding signicantly more ecient  we showed that generalized search
algorithms for non binary csps can be relatively easily adjusted to operate in the hidden
variable encoding  we also showed how various algorithms for the double encoding can be
designed  these algorithms can exploit the properties of the double encoding  strong ltering and branching on original variables  to achieve very good results in certain problems 
empirical results in random and structured problems showed that  for certain classes of
non binary constraints  using binary encodings is a competitive option  and in many cases 
a better one than solving the non binary representation 

acknowledgements
we would like to thank panagiotis karagiannis  nikos mamoulis  and toby walsh for their
help in various stages of this work  we would also like to thank the anonymous reviewers
of an earlier version of this paper for their very useful comments and suggestions 

appendix a
as explained  the main dierence between the ac algorithm for the hve and the corresponding gac algorithm is the fact that the ac algorithm has to update the domains of
the dual variables as well as the original ones  this incurs a time overhead  but as we will
show  deleting values from dual variables can help propagation discover domain wipe outs
in arc inconsistent problems faster 
proposition     let p be a non binary csp  assume that after generalized arc consistency is applied in p   there is no domain wipeout in the resulting problem  enforcing arc
consistency in the hidden variable encoding of p using hac requires the same number of
consistency checks as enforcing generalized arc consistency in p using gac       assuming the two algorithms follow the same ordering of variables and values when looking for
supports and propagating deletions 
proof  first  consider that if no domain wipeout in any variable  original or dual  occurs
then the two algorithms will add constraints  dual variables  to the stack and remove
them for revision in exactly the same order  therefore  we only need to show that if a
value is deleted from a variable during the revision of a constraint or nds a new support
in the constraint then these operations will require the same number of checks in both
representations  assume that in the non binary version of the algorithm value a is deleted
from the domain of variable xi because it has no support in constraint c  if  t   is the
number of allowed tuples in c then determining the lack of support will require  t   
currentsupportxi a c checks  one for each of the tuples in c that have not been checked yet 
if the value is not deleted but nds a new support    with    currentsupportxi a c   then
  currentsupportxi a c checks will be performed  in the hve  xi will be processed in the
same order as in the non binary version and we will require  t    currentsupportxi a vc or
  currentsupportxi a vc checks depending on the case  obviously  currentsupportxi  a c
is the same as currentsupportxi  a vc since a tuple in c corresponds to a value in vc   and
therefore  the same number of checks will be performed in both representations   
   

fisamaras   stergiou

proposition     let p be a non binary csp  assume that the application of generalized
arc consistency in p results in a domain wipeout  algorithm hac applied in the hidden
variable encoding of p discovers the domain wipeout with at most the same number of
consistency checks as algorithm gac      in the non binary representation  assuming the
two algorithms follow the same ordering of variables and values when looking for supports
and propagating deletions 
proof  in any csp  arc inconsistency in detected when the domain of a variable is wiped
out while applying ac  in the hve of a non binary csp  arc inconsistency is detected when
the domain of an original variable is wiped out or  crucially  when the domain of a dual
variable is wiped out  the second possibility can make an ac algorithm that operates in
the hve more ecient than the corresponding gac algorithm  to prove this consider
an arc inconsistent non binary problem  assume that the domain of original variable xi
is wiped out during the processing of constraint c which is encoded as a dual variable vc
in the hve  until the point where function revise is called with xi and c as arguments 
there is no inconsistency and according to proposition     the gac algorithm and the
ac algorithm on the hve will perform the same number of consistency checks  assume
that there are j values left in d xi   before the call to revise  in function revise we will
unsuccessfully look for a support for each of the j values  if  t   is the number of allowed
tuples in c then  for each value a  d xi    this will require  t    currentsupportxi a c checks
for the gac algorithm and  t    currentsupportxi  a vc checks for the ac algorithm  since
 t    currentsupportxi  a c    t    currentsupportxi a vc   the two algorithms will perform
the same number of consistency checks to detect the domain wipeout 
the following example demonstrates that hac may discover the inconsistency with less
checks  consider a problem with variables x    x    x    x  which have domains                
                and         respectively  there are two constraints  c  and c    with vars c     
 x    x    x    and vars c       x    x    x    respectively  value   of x  is supported in c  by
tuples that include the assignment  x        value   of x  is supported in c  by tuples that
include the assignment  x        constraint c  allows only tuples that include the assignment
 x        values              of x  are supported in c  by tuples that include  x       and by tuples
that include  x        now assume that variable x  is instantiated to    which means that
the deletion of   from d x    must be propagated  in the hve  we will rst delete all
tuples that include the value  x       from dual variables vc  and vc    then  we will add dual
variables vc  and vc  to the stack  remove them  and revise all original variables connected
to them  assuming that vc  is removed rst  value   of x  will have no support in vc  so
it will be deleted  as a result  we will delete all tuples from dual variable vc  that include
the pair  x        this means that the domain of vc  will be wiped out  in the non binary
representation  we will proceed in a similar way and perform the same number of checks
until   is deleted from x    after that deletion the algorithm will look for supports in c  for
value   of x  and all values of x    this will involve checks that are avoided in the hve 
the inconsistency will be discovered later when we process constraint c  and nd out that
value   of x  has no support in c  resulting in the domain wipeout of x     

   

fibinary encodings of non binary csps  algorithms   experimental results

references
bacchus  f   chen  x   van beek  p     walsh  t          binary vs  non binary csps 
artificial intelligence           
bacchus  f     van beek  p          on the conversion between non binary and binary
constraint satisfaction problems  in proceedings of aaai    pp         
bater  j          non binary  higher order  modelling and solution techniques for frequency assignment in mobile communications networks  ph d  thesis  university of
london 
beacham  a   chen  x   sillito  j     van beek  p          constraint programming lessons
learned from crossword puzzles  in proceedings of the   th canadian conference in
ai 
bessiere  c   freuder  e     regin  j          using inference to reduce arc consistency
computation  in proceedings of ijcai    pp         
bessiere  c   meseguer  p   freuder  e     larrosa  j          on forward checking for
non binary constraint satisfaction  artificial intelligence              
bessiere  c     regin  j       a   arc consistency for general constraint networks  preliminary results  in proceedings of ijcai    pp         
bessiere  c     regin  j       b   mac and combined heuristics  two reasons to forsake
fc  and cbj   on hard problems  in proceedings of cp    pp       
bessiere  c     regin  j          rening the basic constraint propagation algorithm  in
proceedings of ijcai      pp         
cabon  b   de givry  s   lobjois  l   schiex  t     warners  j          radio link frequency
assignment  constraints          
clib         conguration benchmarks library  http   www itu dk doi vecos clib   
maintained by vecos group  it university of copenhagen 
debruyne  r     bessiere  c          domain filtering consistencies  journal of artificial
intelligence research             
dechter  r     pearl  j          tree clustering for constraint networks  artificial intelligence             
ginsberg  m   frank  m   halpin  m     torrance  m          search lessons learned from
crossword puzzles  in proceedings of aaai     pp         
haralick  r     elliot  g          increasing tree search eciency for constraint satisfaction problems  artificial intelligence             
hodge  l   hurley  s     smith  d          higher order constraint techniques for the
frequency assignment problem  tech  rep   university of cardi 
jeavons  p   dunkin  n     bater  j          why higher order constraints are necessary
to model frequency assignment problems  in ecai   workshop on non binary
constraints 
mackworth  a          consistency in networks of relations  artificial intelligence        
   

fisamaras   stergiou

mamoulis  n     stergiou  k          solving non binary csps using the hidden variable
encoding  in proceedings of cp       pp         
mohr  r     henderson  t          arc and path consistency revisited  artificial intelligence             
mohr  r     masini  g          good old discrete relaxation  in proceedings of ecai    
pp         
peirce  c         collected papers vol  iii  cited in f  rossi  c  petrie  and v  dhar      
prosser  p   stergiou  k     walsh  t          singleton consistencies  in proceedings of
cp       pp         
regin  j          a filtering algorithm for constraints of dierence in csps  in proceedings
of aaai     pp         
rossi  f   petrie  c     dhar  v          on the equivalence of constraint satisfaction
problems  in proceedings of ecai     pp         
smith  b          a dual graph translation of a problem in life  in proceedings of
cp     pp         
smith  b   stergiou  k     walsh  t          using auxiliary variables and implied constraints to model non binary problems  in proceedings of aaai      pp         
stergiou  k     walsh  t          encodings of non binary constraint satisfaction problems  in proceedings of aaai    pp         
subbarayan  s   jensen  r   hadzic  t   andersen  h   hulgaard  h     moller  j         
comparing two implementations of a complete and backtrack free interactive congurator  in proceedings of the cp    workshop on csp techniques with immediate
application  pp        
van hentenryck  p   ed            constraint satisfaction in logic programming  mit
press 
van hentenryck  p   deville  y     teng  c          a generic arc consistency algorithm
and its specializations  artificial intelligence             
watkins  w   hurley  s     smith  d          area coverage frequency assignment  evaluation of models for area coverage  tech  rep   university of glamorgan  also presented
in informs    
zhang  y     yap  r          making ac   an optimal algorithm  in proceedings of
ijcai      pp         

   

fi