journal of artificial intelligence research                 

submitted        published      

engineering note
mgpt  a probabilistic planner based on heuristic search
blai bonet

bonet ldc usb ve

departamento de computacion
universidad simon bolvar  venezuela

hector geffner

hector geffner upf edu

icrea   universitat pompeu fabra
paseo de circunvalacion    barcelona        spain

abstract
we describe the version of the gpt planner used in the probabilistic track of the  th
international planning competition  ipc     this version  called mgpt  solves markov
decision processes specified in the ppddl language by extracting and using different classes
of lower bounds along with various heuristic search algorithms  the lower bounds are
extracted from deterministic relaxations where the alternative probabilistic effects of an
action are mapped into different  independent  deterministic actions  the heuristic search
algorithms use these lower bounds for focusing the updates and delivering a consistent
value function over all states reachable from the initial state and the greedy policy 

   introduction
mgpt is a planner based on heuristic search for solving markov decision processes  mdps 
specified in the high level planning language ppddl  mgpt captures a fragment of the
functionality of the gpt system that handles non determinism and incomplete information 
in both qualitative and probabilistic forms  including pomdps and conformant planning
 bonet   geffner        
mgpt supports several algorithms and admissible heuristic functions  lower bounds 
that when combined generate a wide range of solvers  the main algorithms are lrtdp and
hdp  both are heuristic search algorithms for solving mdps that make use of lower bounds
for computing a consistent value function v   a function with bellman residuals bounded
by a user provided parameter  over all states reachable from a given initial state s  and
the greedy policy based on v  bonet   geffner      b      a  
the lower bounds are derived by solving relaxations of the input problem  since the algorithms for solving the relaxations are also based on heuristic search  we have implemented
stackable software components that are created in sequence for computing complex heuristic functions from simpler ones 

   algorithms
we divide the algorithms into two groups  those that deliver consistent value functions with
respect to a user provided parameter   and those that select actions in real time  the first

c
    
ai access foundation  all rights reserved 

fibonet   geffner

class of algorithms compute an  consistent value function v for all states reachable from
the initial state s    and the greedy policy v based on v  
in the following subsection  we give definitions of admissible and consistent value functions  and greedy  partial and proper policies  then  we present the algorithms implemented
by mgpt 
    consistent value functions  and greedy  partial and proper policies
a value function v is admissible if it is non overestimating  i e  if the value v  s  at each
state s is a lower bound on the optimal expected cost of starting at s  v is  consistent at
state s if its bellman residual at s 
fi

fi
x
fi
fi
def
 
  fi
fi
r s    fiv  s   min c s  a   
p r s  s  a v  s   fi  
   
aa s 

s  s

is less than or equal to   here  a s  denotes the actions that are applicable at s  c s  a  is
the cost of applying action a in s  and p r   is the probabilistic transition function  if v is
  consistent at s  then we say that v is consistent at s 
a state s is reachable from the initial state s  and policy  if there exists a trajectory
s    s            sn such that sn   s and p  sk    sk    sk        for all    k   n  in other words 
if the state s can be reached with positive probability from s  in zero or more steps using
the policy  
it is known that the greedy policy v based on the value function v   defined as


x
def
 
 
v  s    argmin c s  a   
p r s  s  a v  s    
   
aa s 

s  s

is optimal when v is  consistent over all states for a sufficiently small   yet  since our goal
is to find an optimal policy with respect to the initial state s  and the states reachable from
it  it is sufficient for v to be admissible and  consistent over the states that are reachable
from s  and v  
a partial policy  is a policy that doesnt need to be defined for all states  it is closed
with respect to a state s if  is defined over s and all states reachable from s and   it is
proper with respect to s if a goal state can be reached from every state reachable from s
and   and finally it is proper if it is proper with respect to all states 
    algorithms that compute  consistent value functions
for the first group of algorithms  mgpt implements value iteration  vi   labeled realtime dynamic programming  lrtdp   and heuristic dynamic programming  hdp  
value iteration  bertsekas        is applied over the states that can be reached from
the given initial state and the available operators  and yields an  consistent value function
over all of them   mgpts vi serves as a bottom line reference for comparison with the
other algorithms 
   on undiscounted problems like those in probabilistic planning  some conditions are neeeded in order for
vi to finish with an  consistent value function  bertsekas        

   

fimgpt  a probabilistic planner based on heuristic search

labeled real time dynamic programming  bonet   geffner      b  is a heuristicsearch algorithm that implements a labeling scheme on top of the rtdp algorithm  barto 
bradtke    singh        to improve its convergence  lrtdp works by performing simulated
trials that start at the initial state and end at solved states  selecting actions according
to the greedy policy v and successor states according to their corresponding transition
probabilities  initially  v is the input heuristic function  and the only solved states are the
goal states  then  each time an action is picked at state s  the value of s is updated by
making it consistent with the value of its successors  at the end of each trial  a labeling
procedure is called that checks whether new states can be labeled as solved  a state is solved
if its value and the value of all its descendents are  consistent  the algorithm ends when
the initial state is labeled solved  at that point all states reachable from the initial state
s  and the greedy policy v are  consistent  the labeling mechanism also guarantees that
v is a proper partial policy with respect to s   
heuristic dynamic programming  bonet   geffner      a  is the second heuristic search
algorithm supported in mgpt for solving mdps  hdp performs systematic depth first
searches over the set of states reachable from the initial state s  and the greedy policy
v looking for  inconsistent states and updating their values  on top of this search 
a labeling scheme based on tarjans strongly connected components procedure  tarjan 
       identifies the states that are solved and that do not need to be revisited  the initial
value function is given by a heuristic function  and the algorithm ends when the initial state
is solved  as with lrtdp  the labeling mechanism guarantees that v is proper with respect
to s   
    algorithms for real time action selection
the second class of algorithms do not attempt to solve the given mdp  they rather select
actions in real time after a limited amount of processing without offering any guarantees
on the quality of the resulting policies  algorithms in this group include an extension of
the action selection for planning algorithm  asp   bonet  loerincs    geffner        for
probabilistic domains  which is basically an rtdp algorithm with lookahead  asp  like rtdp 
performs value function updates over states and so cannot get trapped into a loop  thus 
although the policy delivered by asp is suboptimal  it is a proper policy  i e  a policy that
is guaranteed to reach a goal state 

   heuristics
all these algorithms assume that the initial value function is given by a heuristic function
that provides good cost estimates  and in particular  lrtdp and hdp expect this heuristic
to be admissible  as described by pearl         informative admissible heuristics can be
obtained by solving suitable relaxations of the input problem  two such relaxations are
supported in mgpt  the min min relaxation  and the strips relaxation  the first defines a
 deterministic  shortest path problem in the original state space  the second is used to define
 deterministic  shortest path problems in atom space   thus  while the first is solved in
   atoms refer to the propositional symbols used in the representation language  ppddl in our case  to
define the problem  the number of atoms is polynomial in the size of the input  while the size of the
state space is  in general  exponential in the number of atoms 

   

fibonet   geffner

time polynomial in the number of states  the shortest path problems defined by the second
are solved in time polynomial in the number of atoms  both methods yield lower bounds on
the expected cost to the goal from a given state  yet the bounds produced by the min min
relaxation are stronger than those produced by the strips relaxation 
    min min state relaxation
the idea behind the min min relaxation is to transform the input probabilistic problem 
described by its bellman equations


x
def

 
  
v  s    min c s  a   
p r s  s  a v  s    
   
aa s 

s  s

into a deterministic shortest path problem with bellman equations of the form 

vmin
 s   

def


min c s  a    min  vmin
 s      p  s   s  a        

   

aa s 

at the level of the representation language  the min min relaxation is built by transforming each probabilistic operator of the form 
o   h     p                pn   n   i  

   

where  is the precondition of o and each i is the ith probabilistic effect  with probability
pi    into a set of independent and deterministic operators of the form 
oi   h   i i  

   i  n 

   

thus  in the min min relaxation one can actually choose the most convenient non deterministic effect of an operator  and hence  the cost of the relaxation is a lower bound on the
expected cost of the original probabilistic problem 
the min min relaxation is a deterministic problem that can be solved by means of
standard path finding algorithms  for example  it can be solved with dijkstras algorithm 
a   ida   or a deterministic version of lrtdp  i e  a labeled lrta algorithm  korf         
mgpt provides two methods for computing the min min heuristic from this relaxation 
min min ida   which uses ida   and min min lrtdp  which uses lrtdp  both versions
are lazy in the sense that the heuristic values of states are computed as needed when the
planner requires them 
    strips relaxation
the strips relaxation in turn converts the deterministic problem obtained from the min min
relaxation into a strips problem  and then obtains lower bounds for the original mdp by
computing lower bounds for the resulting strips problem using the methods developed in
classical planning  e g   bonet   geffner        haslum   geffner        hoffmann   nebel 
      edelkamp        nguyen   kambhampati         these methods run in polynomial
time in the number of atoms yet  unlike the min min relaxation  require casting the minmin relaxation into strips format  a conversion that  like the conversion of adl into strips
 gazen   knoblock         may require exponential time and space  see below  
   

fimgpt  a probabilistic planner based on heuristic search

in mgpt  the strips relaxation is obtained directly from the original problem  by first
transforming the probabilistic operator into the form 
o   h prec    p     add    del             pn    addn   deln     i  

   

where prec  addi   deli are conjunctions of literals that represents the precondition  the ith
add list  and the ith delete list of operator o respectively  and pi are probabilities that sum
to    in order to take the operators into form      all disjunctive preconditions  conditional
effects  and quantifiers are removed as described by gazen and knoblock        
once all operators have the form      the strips relaxation is generated by splitting the
operators into n independent strips operators of the form 
oi   h prec  addi   deli i  

   i  n 

   

the following heuristics are implemented in mgpt upon the strips relaxation  the
first two are lower bounds on the optimal cost of the strips relaxation and hence on the
optimal  expected  cost of the original mdp  the third one is not necessarily a lower bound
on either cost 
 the hm heuristics  h m   haslum   geffner        are heuristics that recursively
approximate the cost of achieving a set of atoms c from the initial state by the cost
of achieving the most costly subset of size m in c  they are computed by a shortestpath algorithm over a graph with nodes standing for sets of at most m atoms  and
result in values hm  s  that estimate the cost of reaching a goal state from s  we use
the option h m k in mgpt to refer to the hm heuristic with m   k 
 pattern database heuristics  patterndb   edelkamp        compute optimal costs of
relaxations of the strips problem defined by some of the multi valued variables that
are implicit in the problem  e g  the location of a block in the blocksworld domain is
an implicit multi valued variable whose possible values are either the table or the top
of any other block   this heuristic is also precomputed only once  at the beginning 
and provides a lower bound on the cost of an arbitrary state to the goal  a pattern
database is computed by projecting the strips problem with respect to a set of atoms a
 those that define the multi valued variables  and then solving the resulting problem
optimally with dijkstras algorithm  multiple pattern databases can be combined
either by taking max or sum  in the latter case  the pattern database is referred to
as additive   we use additive pattern databases as defined by haslum  bonet  and
geffner        where some constraints of the original problem are preserved into the
projection  something that often results in stronger heuristics  patterndb k refers to
a pattern database heuristic defined by k multi valued variables 
 the ff  ff  heuristic implements the heuristic function used in the ff planner  hoffmann   nebel         it is computed by building the so called relaxed planning graph
and finding a plan in it  the heuristic is then the number of operators in such a plan 
   some conditions are required for adding two pattern databases such that the result remains admissible 
a sufficient condition is that a  b    if the sets a and b are those used to build the projections
respectively 

   

fibonet   geffner

the relaxed planning graph is the version of the graph constructed by graphplan
 blum   furst        when delete lists are ignored  it can be shown that computing
the ff heuristic can be done in polynomial time in the size of the input problem
 hoffmann   nebel         this heuristic however is informative but non admissible 
as it is shown below  these heuristics can be plugged directly into the planning algorithm
or they can be used to compute more informative heuristics  for example  the patterndb
heuristic can be used within ida  to solve the min min relaxation  which gives a stronger
heuristic than the patterndb heuristic  thus  mgpt implements algorithms and heuristics
as stackable software components so that an element in the stack is used to solve the elements
above it 

   implementation
this section gives some details on the implementation of mgpt together with examples on
its use  the mgpt system is implemented in c   upon a preliminary parser offered by
the organizers of ipc   
    hash tables
perhaps the most important component of modern search based planners is the internal
representation of states and hash tables  since mgpt uses different search algorithms and
hash tables to solve a given instance  e g  when more informative heuristics are computed
from less informative ones   good internal representations and hash table implementation
are critical for good performance 
after grounding all atoms and operators  a state is represented by the ordered list of
the atoms that hold true in the state  a state s can appear associated with different
data in multiple hash tables simultaneously  thus  instead of having multiples copies of
s  mgpt implements a system wide state hash table that stores the representation of the
states referenced in all hash tables so that entries in such tables simply contain a reference
into the state hash table  in this way  the planner saves time and space 
another issue that has large impact on performance is the average number of collisions
in each hash table  two points are relevant for keeping the number of collisions low 
the hashing function and the size of the hash table  for the former  we have seen that
cryptographic hashing functions like md  behave very well even though they are slower
than more traditional choices  for the latter  mgpt uses hash tables whose size is equal
to a large prime number  cormen  leiserson    rivest        
    algorithms and heuristics
each algorithm in mgpt is implemented as a subclass of the abstract algorithm class
whose members are a reference to a problem and  in some cases  a reference to a hash table
and a parameter   similarly  each heuristic in mgpt is implemented as a subclass of the
abstract heuristic class whose members are a reference to a problem and a function that
maps states to non negative values  simple heuristics like the constant zero function are
straightforward  others like min min lrtdp are implemented by a class whose members are 
in addition to above  references to a hash table and to an lrtdp algorithm 
   

fimgpt  a probabilistic planner based on heuristic search

    examples
the main parameters on a call to mgpt are  a  algorithm  that specifies the algorithm
to use   h  heuristic  that specifies the heuristic function  and  e  epsilon  that
specifies the threshold  for the consistency check  a typical call looks like 
mgpt  a lrtdp  h h m    e       domain   problem 
which instructs mgpt to use the lrtdp algorithm with the h m   heuristic and         
over the domain and problem files specified 
the h m   heuristic is admissible but very weak  the following example shows how to
compute the min min lrtdp heuristic using h m   as the base heuristic 
mgpt  a lrtdp  h  h m   min min lrtdp   e       domain   problem 
the pipe symbol is used to instruct the planner how heuristics are to be computed using
other heuristics 
another possibility is to use mgpt as a reactive planner in which decisions are taken
on line with respect to a heuristic function that is improved over time  for example 
mgpt  a asp  h ff  domain   problem 
uses the asp algorithm with the ff heuristic  while
mgpt  a asp  h  zero min min ida    domain   problem 
uses the asp algorithm with the min min ida  heuristic computed from the constant zero
heuristic  other combinations of algorithms and heuristics are possible  mgpt also accepts
parameters to control initial hash size  a weight on the heuristic function  values for dead end
states  verbosity level  lookahead settings for asp  etc 

   the competition
the competition suite consisted of   probabilistic domains named blocksworld  explodingblocksworld  boxworld  fileworld  tireworld  towers of hanoise  and zeno  blocksworld and
exploding blocksworld are variations of the standard blocksworld domain for classical planning  boxworld is a logistics like transportation domain  fileworld is a file folder domain
where the uncertainty is only present at the initial situation where the destination of each
file is set  tireworld and towers of hanoise are variations of the classical tireworld domain
and towers of hanoi  zeno is a traveling domain with a fuel resource 
some of the domains come in two variations  a goal oriented version where the goal is to
be achieved with certainty while minimizing expected costs  and a reward oriented version
that involves rewards  the mgpt planner handles the first type of tasks only 
in the competition we used the lrtdp algorithm with the patterndb   heuristic  a
parameter           and a weight w     for the heuristic function  in some cases  when
the patterndb   heuristic was too poor  the planner switched automatically to the asp
algorithm with the ff heuristic 

   

fibonet   geffner

problem name
blocksworld  
blocksworld  
blocksworld   
blocksworld   
blocksworld   
blocksworld   
exploding bw
boxworld c  b  
boxworld c   b  
boxworld c   b  
fileworld     
towers of hanoise
tireworld g
tireworld r
zeno

runs
  
  
  
  



  


  

  
  
  

failed
 
 
 
 



 


 

  
 
 

successful
  
  
  
  



  


  

  
  
  

time
  
  
   
     



     


     

  
  
   

reward
     
     
     
     



     


    

     
 
   

table    results for the mgpt planner over the competition problems  the table shows
problem name  number of runs  number of failed and successful runs  see text  
and time and reward averages  a dash means that mgpt was not able to solve
the problem  times are in milliseconds 

    results
the competition was held through a client server model  each planner was evaluated in
each problem over a number of runs under supervision of the server  the planner initiated
the session by connecting to the server and then interacted with it by exchanging messages 
each run consisted of actions sent by the planner whose effects were transmitted back from
the server to the planner  thus  the current state of the problem was maintained both by
the planner and the server 
table   shows the results for mgpt over the competition problems  for each problem 
   runs were executed  the table shows the number of runs  the number of failed runs
 i e  those that finished without reaching a goal state   the number of successful runs  i e 
those that finished at goal states   and the time and reward averages per run   for the
blocksworld  the problem blocksworld xx means a problem with xx blocks  for boxworld 
the problem boxworld cxx byy means a problem with xx cities and yy boxes 
as it can be seen from the table  mgpt did not solve exploding bw  the larger instances
of blocksworld and boxworld  and it also failed on approximately half of the instances in
tireworld g  the difficulties encountered by mgpt in solving these problems often had
not so much to do with the probabilities involved  but with the domains  and in particular 
with the encodings  the basic algorithms used by mgpt try to solve the problems by
   the competition format was reward based while our presentation here is cost based  it is straightforward
to go from one format to the other 

   

fimgpt  a probabilistic planner based on heuristic search

computing a value function with  residuals over the relevant states  those reachable from
the initial state by an optimal policy   for this  mgpt computes an admissible heuristic
function by solving either the min min relaxation  the strips relaxation  or both  a problem
faced by this approach is that in many instances neither of these relaxations could be
solved  here  we give a detailed explanation of the problems encountered by mgpt over
the different domains  it is worth noting that many of these difficulties would surface in
any strips planner as well  even if the probabilities are ignored 
 blocksworld and exploding blocksworld  the operator encodings have preconditions
containing universally quantified negative literals  as the result of not using a clear
predicate  for example 
  action pick up block from
 parameters   top   block  bottom 
 precondition  and  not     top  bottom  
 forall   b   block   not  holding  b   
 on top of  top  bottom 
 forall   b   block   not  on top of  b  top    
 effect  and  decrease  reward    
 probabilistic
      and  holding  top   not  on top of  top  bottom   
      when  not     bottom table  
 and  not  on top of  top  bottom  
 on top of  top table     
 

this complex encoding is not standard in planning and makes our atom based heuristics almost useless  mgpt could solve the instances with          and    blocks but
not those with    and    blocks  for exploding blocksworld  mgpt was unable to
solve it as the parser is incomplete and does not parse some complex constructs 
 boxworld  the encoding contains a drive truck operator that moves the truck to
its intended destination with probability     and to one of three wrong destinations
with probability       each  the encoding specifies the unintended effects by means
of nested conditional effects of the form
  action drive truck
 parameters   t   truck  src   city  dst   city 
 precondition  and  truck at city  t  src   can drive  src  dst  
 effect  and  not  truck at city  t  src  
 probabilistic
     forall   c    city 
 when  wrong drive   src  c  
 forall   c    city 
 when  wrong drive   src  c  
 forall   c    city 
 when  wrong drive   src  c  
 probabilistic
     truck at city  t  c  
     truck at city  t  c  
     truck at city  t  c         
     truck at city  t  dst   
 
   

fibonet   geffner

our strips relaxation  like any planner that converts adl style operators into strips 
suffers an exponential blow up in this domain  with    cities  there are more than
a thousand operators for each grounded adl operator  this set included problems
with       and    cities 
 fileworld  in this domain  there are    files that need to be filed into one of   different
folders  the exact destination determined probabilistically  the optimal policy for this
problem  and any proper policy  must prescribe an action for more than     states  all
of them relevant  the consequence is a problem with millions of relevant states that
need to be stored into the hash table if the task is to compute a proper policy  the
patterndb   heuristic for this problem is not informative  as revealed by an analysis
of the values stored in the pattern database  and thus mgpt switched automatically
to the asp algorithm with the ff heuristic 
 towers of hanoise  as in the blocksworld domain  the encoding is complex with operators that have disjunctions and universally quantified negative literals in the preconditions  and complex conditional effects  yet the problem that prevented mgpt from
solving any problem in this domain is a bug in the code that implements conditional
effects which did not surface in the other domains 
 tireworld  there are two versions  a goal based version called tireworld g and a
reward based version called tireworld r  the domain contains multiple dead ends
at locations where the car gets a flat tire and no spare tire is available  some of the
dead ends are unavoidable  i e  there is no proper policy for this problem  all trials for
the reward based version end successfully since there is no requirement to reach a goal
position  rather the objective is to maximize the accumulated reward  mgpt treated
both versions as goal based problems as it does not deal directly with reward based
problems 

   conclusions
the mgpt planner entered into the probabilistic planning competition combines heuristicsearch algorithms with methods for obtaining lower bounds from deterministic relaxations 
the results obtained at the competition were mixed with some of the difficulties having to do
with the selection of domains and encodings which do not match the capabilities of mgpt 
mgpt tries to compute proper solutions using heuristics derived from the strips relaxations 
as we have described  some of the domains could not be solved due to the number of relevant
states  and others due to the complexity of the strips relaxations themselves 
for the definition of good benchmarks for mdp solvers  it is crucial to define what
constitutes a solution and what is the bottom line for assessing performance  in classical
planning  for example  the solutions are plans and the bottom line is given by blind search
algorithms  progress in the field can then be measured by the distance to this bottom line 
in the probabilistic setting  this is more difficult as it is not always clear what it means to
solve a problem  this  however  needs to be defined in some way  otherwise performance
comparisons are not meaningful  indeed  in the classical setting  one no longer compares
optimal with non optimal planners since both types of planners are very different  one
provides guarantees that apply to all solutions  while the other provides guarantees that

   

fimgpt  a probabilistic planner based on heuristic search

apply to one solution only  in the probabilistic setting this is even more subtle as there are
different types of guarantees  for example  if we restrict ourselves to the class of mdps
that constitute the simplest generalization of the classical setting  the task of reaching
the goal with certainty while minimizing the expected number of steps from a given initial
state s   there are methods that yield solutions  policies  that ensure that the goal will be
reached with certainty in a finite number of steps  not necessarily optimal   and methods
with no such guarantees  both types of methods are necessary in practice  yet it is crucial
to make a distinction among them and to identify useful benchmarks in each class  for
methods that yield optimal policies  or at least policies with finite expected costs  standard
dynamic programming methods like value iteration provide a useful bottom line reference
for assessing performance  in any case  we believe that useful benchmarks need to be defined
taking into account the types of tasks that the various algorithms aim to solve  and the
types of guarantees  if any  that they provide in their solutions 
gpt and mgpt are available for download at http   www ldc usb ve bonet 
acknowledgements
mgpt was built upon a parser developed by john asmuth from rutgers university and
hakan younes from carnegie mellon university  we also thank david e  smith for comments that helped us to improve this note 

references
barto  a   bradtke  s     singh  s          learning to act using real time dynamic programming  artificial intelligence            
bertsekas  d          dynamic programming and optimal control     vols   athena scientific 
blum  a     furst  m          fast planning through planning graph analysis  artificial
intelligence             
bonet  b     geffner  h          planning with incomplete information as heuristic search
in belief space  in chien  s   kambhampati  s     knoblock  c   eds    proc   th
international conf  on artificial intelligence planning and scheduling  pp       
breckenridge  co  aaai press 
bonet  b     geffner  h          planning as heuristic search  artificial intelligence        
        
bonet  b     geffner  h       a   faster heuristic search algorithms for planning with
uncertainty and full feedback  in gottlob  g   ed    proc    th international joint
conf  on artificial intelligence  pp            acapulco  mexico  morgan kaufmann 
bonet  b     geffner  h       b   labeled rtdp  improving the convergence of real time
dynamic programming  in giunchiglia  e   muscettola  n     nau  d   eds    proc 
  th international conf  on automated planning and scheduling  pp        trento 
italy  aaai press 

   

fibonet   geffner

bonet  b   loerincs  g     geffner  h          a robust and fast action selection mechanism
for planning  in kuipers  b     webber  b   eds    proc    th national conf  on
artificial intelligence  pp          providence  ri  aaai press   mit press 
cormen  t   leiserson  c     rivest  r          introduction to algorithms  mit press 
edelkamp  s          planning with pattern databases  in cesta  a   ed    proc   th
european conf  on planning  pp        toledo  spain  springer  lncs 
gazen  b     knoblock  c          combining the expressiveness of ucpop with the
efficiency of graphplan  in steel  s     alami  r   eds    proc   th european conf 
on planning  pp          toulouse  france  springer  lncs 
haslum  p   bonet  b     geffner  h          new admissible heuristics for domainindependent planning  in veloso  m     kambhampati  s   eds    proc     national
conf  on artificial intelligence  pp            pittsburgh  pa  aaai press   mit
press 
haslum  p     geffner  h          admissible heuristic for optimal planning  in chien  s  
kambhampati  s     knoblock  c   eds    proc   th international conf  on artificial
intelligence planning and scheduling  pp          breckenridge  co  aaai press 
hoffmann  j     nebel  b          the ff planning system  fast plan generation through
heuristic search  journal of artificial intelligence research             
korf  r          real time heuristic search  artificial intelligence                  
nguyen  x     kambhampati  s          extracting effective and admissible state space
heuristics from the planning graph  in kautz  h     porter  b   eds    proc    th
national conf  on artificial intelligence  pp          austin  tx  aaai press  
mit press 
pearl  j          heuristics  morgan kaufmann 
tarjan  r  e          depth first search and linear graph algorithms  siam journal on
computing                

   

fi