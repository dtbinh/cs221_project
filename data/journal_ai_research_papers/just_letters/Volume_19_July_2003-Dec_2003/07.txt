journal of artificial intelligence research                  

submitted        published      

an architectural approach to
ensuring consistency in hierarchical execution
robert e  wray

wrayre acm org

soar technology  inc        green court  suite    
ann arbor  mi       usa

john e  laird

laird umich edu

the university of michigan       beal avenue
ann arbor  mi       usa

abstract
hierarchical task decomposition is a method used in many agent systems to organize
agent knowledge  this work shows how the combination of a hierarchy and persistent
assertions of knowledge can lead to difficulty in maintaining logical consistency in asserted
knowledge  we explore the problematic consequences of persistent assumptions in the
reasoning process and introduce novel potential solutions  having implemented one of
the possible solutions  dynamic hierarchical justification  its effectiveness is demonstrated
with an empirical analysis 

   introduction
the process of executing a task by dividing it into a series of hierarchically organized subtasks is called hierarchical task decomposition  hierarchical task decomposition has been
used in a large number of agent systems  including the adaptive intelligent systems architecture  hayes roth         atlantis  gat      a   cypress  wilkins et al         
the entropy reduction engine  bresina  drummond    kedar         the procedural reasoning system  georgeff   lansky         raps  firby         soar  laird  newell   
rosenbloom        laird   rosenbloom         and theo  mitchell        mitchell et al  
       and is a cornerstone in belief desire intention based agent implementations  rao  
georgeff        wooldridge         hierarchical task decomposition helps both an agents
knowledge developer and the agent itself manage environmental complexity  for example 
an agent may consider high level tasks such as find a power source or fly to miami
independent of low level subtasks such as go east    meters or turn to heading     
the low level tasks can be chosen dynamically based on the currently active high level
tasks and the current situation  thus the high level task is progressively decomposed into
smaller subtasks  this division of labor simplifies the design of agents  thus reducing their
cost  additional advantages of hierarchical task decomposition include knowledge sharing
 a low level subtask can be invoked for many different high level procedures   modularity
 the decomposition helps insulate subtasks from interaction with other knowledge  and the
naturalness of this representation  simon        
without careful design  it can be difficult to ensure consistent reasoning in agents employing hierarchical task decompositions  by consistency  we mean that reasoning does
not lead to a set of assertions that contains a contradiction  ensuring consistency becomes
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fiwray   laird

much more difficult to solve  and thus more costly  as the complexity of an agents
knowledge grows  although this problem can be solved through careful design of agent
knowledge  such an approach requires an understanding of all possible interactions in the
hierarchy  thus  the correctness of this solution depends on the skill and vigilance of the
knowledge engineer  our bias is to seek solutions in which the operation of an agents primitive memories and processes are structured to ensure inconsistencies do not arise  thus 
we will prefer architectural solutions to knowledge based ones  architectural solutions can
guarantee consistency for all tasks and domains  reducing brittleness due to omissions in
task knowledge  further  while developing an architectural solution may be costly  it should
be less costly than repeatedly developing knowledge based solutions for different domains 
the following sections describe the inconsistency problem and introduce a space of
solutions to the problem  including two novel solutions  through both theoretical and
empirical analysis  one of the new solutions  dynamic hierarchical justification  is shown
to provide an efficient architectural solution to the problem of ensuring reasoning consistency
in hierarchical execution 

   maintaining reasoning consistency in hierarchical agents
this section describes the inconsistency problem in greater detail  we review methods
for ensuring consistency in non hierarchical systems and discuss the limitations of these
approaches in hierarchical systems 
    consistency in non hierarchical systems
truth maintenance systems  tmss  are often used to maintain consistency in non hierarchical systems  doyle        mcdermott        forbus   dekleer         an inference engine
uses domain knowledge to create two different kinds of assertions of knowledge in an agents
knowledge base  assumptions and entailments  the inference engine enables assumptions
that it has decided to treat as being true  without requiring that the assertion be justified  agents often treat environmental percepts as assumptions or unquestioned beliefs
 shoham         entailments are justified assertions  a data structure  the justification 
captures the reasons for asserting the entailment  when the reasons no longer hold  the
entailment is no longer justified   the tms retracts it from the set of asserted beliefs  thus 
a tms automatically manages the assertion and retraction of entailments as an agents
situation changes  ensuring all entailments are consistent with the external environment
and the enabled assumptions 
careful construction of the domain knowledge is required to ensure that no enabled
assumptions are contradictory  for example  if some assumption is inconsistent with the
current input  then the agent must have domain knowledge that recognizes the situation and
removes the assumption  thus  when an agent utilizes a tms  the problem of maintaining
consistency in reasoning is largely one of managing assumptions through the agents domain
knowledge 
assumptions often reflect hypothetical reasoning about the world  hence assumptions   however  assumptions can be used to represent any persistent feature  although
researchers have explored structuring the external environment to provide persistent memory  agre   horswill         internal  persistent memory is usually necessary in agent
   

fiensuring consistency in hierarchical execution

assumptions
entailments
assumptions
entailments
assumptions

inference
engine

entailments
assumptions

tms

entailments
assumptions
entailments
assumptions
entailments
assumptions
entailments

memory
hierarchy maintenance

figure    a hierarchical agent 
domains  for example  persistence is required for hypothetical reasoning  nonmonotonic
revisions of assertions  such as when counting   and remembering 
    truth maintenance in hierarchical agents
the tms agent framework introduced above can be extended to hierarchical agent architectures  in such an agent  the inference engine and tms are more or less identical to those of
a non hierarchical agent  when the agent initiates a new subtask via dynamic hierarchical
task decomposition  it also creates a new database that will contain assumptions and entailments specific to the subtask  further decomposition can result in a stack of subtasks  each
containing entailments and assumptions specific to the subtask  as shown in figure    we
consider the creation and deletion of these distinct databases of assertions the sine qua non
of a hierarchical architecture  the architecture decomposes the task not only by identifying
relevant subtasks  but also by dynamically organizing its memory according to the current
decomposition 
a new system component  hierarchy maintenance  is responsible for creating and
destroying the subtask databases when subtasks begin and terminate  when a subtask is
achieved  or determined to be no longer worth pursuing   hierarchy maintenance responds
by immediately removing all the assertions associated with the subtask  this function is of
central importance in hierarchical architectures because it allows the agent to automatically
retract all assertions associated with a terminated subtask  requiring no agent knowledge
to clean up or remove individual assertions associated with the terminated subtask  the
hierarchy maintenance component can efficiently remove the assertions because they are
 conceptually  located in a distinct unit  the subtask database 
   

fiwray   laird

subtask 

a  
e  

a  

a  
a  

a  

subtask 
e  
e  
e  
e  
e  
e  
e  
a  
e  a   a  
a  
a  

e  

e  

 a    a    e    e   
psfrag replacements

subtask 

a  

e  

a  
a  

e  

e  

 a    a    e   

hierarchy maintenance

figure    an example of hierarchy maintenance  assumptions  a  and entailments  e 
are asserted within subtasks 

an agents hierarchy maintenance function can be employed to help maintain consistency  illustrated notionally in figure    the agent architecture identifies assertions at each
of the higher levels in the hierarchy that led to a new subtask  these assertions together
form a subtask support set  in figure    assertions a      a     e     and e   form the support
set for subtask  while a     a     e   support subtask    these support sets  in effect  form
justifications for subtasks in the hierarchy  when an assertion in a support set is removed
 e g   a      the agent responds by removing the subtask  subtask      while not all hierarchical architectures use architectural processes to create and destroy subtask databases  this
example illustrates how an architectural hierarchical maintenance function can be realized
via a process similar to that of justification in truth maintenance 
within a specific subtask  reason maintenance can go on as before  however  the hierarchical structure adds a complication to the maintenance of logical consistency  assumptions
at some level in the hierarchy can be dependent on entailments and assumptions in higher
levels of the hierarchy   this dependence relationship is suggested in figure   by the curved
lines extending from one subtask to the one below it  higher levels of the hierarchy form a
context for reasoning in the local subtask 
for execution agents embedded in dynamic domains  the hierarchical context may
change at almost any time  the changing context is not problematic for entailments  the
   assumptions in a lower level subtask are always at least indirectly dependent on the higher level assertions  this observation will be exploited in section     

   

fiensuring consistency in hierarchical execution

tms can readily determine dependent context changes and retract affected entailments 
however  changes in higher levels of the hierarchy  such as those deriving from inputs 
may also invalidate the assumptions of lower levels  without any additional architectural
mechanisms  domain knowledge is required to ensure consistency among assumptions and
the hierarchical context as in non hierarchical systems  the domain knowledge for ensuring consistency in the assumptions is complicated by the necessity of spanning multiple
 possibly many  subtasks  we refer to such knowledge as across level consistency knowledge  as described in further detail below  identifying and creating across level consistency
knowledge is a tedious  costly  and often incomplete process  across level knowledge must
explicitly consider the interactions between different subtasks  in different levels of the hierarchy   rather than focus solely on the local subtask  compromising the benefit of the
hierarchical decomposition 
before continuing  we note that hierarchical architectures should be contrasted with
hierarchical task network  htn  planners  sacerdoti        erol  hendler    nau       
and execution oriented systems that use htn representations  such as decaf  graham
  decker        and retsina  sycara  decker  pannu  williamson    zeng         a
planning problem for an htn planner is represented by an initial task network that can
consist of primitive and non primitive tasks  the planner uses operators to find a plan
to solve the tasks  methods allow the planner to match non primitive tasks with other
task networks that describe how to accomplish the task  thus  methods enable hierarchical
decomposition of the planning problem into a family of connected task networks 
the main difference between htn systems and hierarchical architectures is that the
planner represents its plan in a single global state  that is  while methods represent decomposition steps  the hierarchical structure of an evolving plan is represented in a blackboardlike database that does not also reflect the structure of the decomposition  the following
sections discuss problems and especially solutions that depend on the hierarchical organization of asserted knowledge during execution  in addition to a hierarchical task decomposition encoded as an agents task knowledge  thus  the following will not be generally
applicable to htn based execution systems  however  htn systems need to address the
inconsistency problem  section       examines the consequences of global state with respect
to inconsistency arising from persistence in a hierarchy 
    failing to respond to relevant changes in hierarchical context
as mentioned in the introduction  when an agent fails to respond to a relevant change
in its hierarchical context and leaves a now inconsistent assumption enabled  the resulting
behavior can become irrational  that is  not consistent with its knowledge  this section
explores how such irrational behavior can arise with several illustrative examples 
      the blocks world
we use a variant of the blocks world to illustrate the inconsistency problem in a domain
familiar to most readers  this domain is an execution domain rather than a planning
domain  which we call the dynamic blocks world to reflect this difference from the static
blocks world used in planning  we assume the agent has knowledge to build an ordered
   

fiwray   laird

goal     on       on       on table 
agent memory
put on table   
put on table   
put down   

agent memory
put on table   
put on table   
put down   

agent memory
put on table   
put on table   
put down   

empty
space

empty
space

empty
space

 
 
 

 
 
 

actual world state

 

 
 

time

 

 
 
 

ent
l ev  
a
n
r
exte ks over
c
kno

actual world state

time

 
   

   

actual world state

figure    failing to respond to relevant changes in hierarchical context in the dynamic
blocks world 

tower    on   on    without resorting to planning and uses hierarchical task decomposition
to determine what actions to take as it builds the tower 
in figure    the agent is placing block   on the table  in order to reach block   and
begin the goal tower  the put down subtask finds an empty location on the table  the
agent places the empty assertion in the memory associated with the put down subtask  in
the figure  the space immediately to the left of the gripper was chosen  whether or not a
space is empty may not be directly observable but may need to be inferred from a number
of other facts in the domain and stored as an assumption in memory  assume the empty
assertion is an assumption  now  assume block   is suddenly placed underneath block   
the result is an inconsistency between the assumption  the location is a good place to put
block    and the hierarchical context  the location is no longer a good place to put the
block on the table  
if the agent fails to recognize that block   has moved  it will attempt to put block  
into the same location occupied by block    this behavior is irrational  or not consistent
with the agents goals and knowledge  assuming the agent has knowledge that indicates
that blocks should not be placed in positions already occupied by other blocks   the inconsistency arises because the agent has failed to recognize its previously derived assumption
 empty  is no longer true in the current situation 
although this example may appear contrived  this specific situation arose in an experimental system developed to explore architecture and learning issues  of course  it is possible
in such a simple domain to reformulate the task such that the problem does not occur  this
reformulation of the task via changes to or additions of knowledge is exactly the solution
we wish to avoid  that is  we desire that the architecture guarantee consistency between
the hierarchical context and local assumptions such that the architecture provides a priori
constraints  guidance  in the knowledge development process and increased robustness in
execution  via consistency   the conclusion returns to this example to describe how an
   

fiensuring consistency in hierarchical execution

patrol
intercept
attack defensive 
achieveproximity
turntoheading

figure    decomposition of behavior into subtasks 
architectural solution to the inconsistency problem solves this particular problem  without
requiring any reformulation of the agents task knowledge 
      tacair soar
tacair soar agents pilot virtual military aircraft in a complex  real time computer simulation of tactical combat  tambe et al         jones et al          the tacair soar domain is
only indirectly accessible  each agent uses simulated aircraft sensor models and can perceive
only what a pilot in a real aircraft would sense   nondeterministic  from the point of view
of the agent  the behavior of other agents cannot be strictly predicted or anticipated   nonepisodic  the decisions an agent makes early in the simulation can impact later options and
capabilities   dynamic  the world changes in real time while the agent is reasoning   and
continuous  individual inputs have continuous values   domains with these characteristics
are the most difficult ones in which to create and apply agents  russell   norvig        
the domain knowledge of tacair soar agents is organized into over     subtasks  during
execution  the resulting hierarchical task decomposition sometimes reaches depths of greater
than    subtasks  each agent can have one of several different mission roles  among them
flying a patrol mission  and acting as a partner or wing to some other agents lead 
consider a pair of planes on patrol  which have been given specific instructions for
engaging enemy aircraft  when enemy aircraft enter the patrol area  the lead agent decides
to intercept the aircraft  the lead then decomposes the intercept into a series of situationdependent subtasks  which themselves may be further decomposed  for example  figure  
shows that the complex task of intercepting an enemy aircraft has been decomposed into a
decision to turn the agents aircraft to a specific heading  the agent turns to this heading
in order to get close enough to the enemy agent  via achieve proximity  to launch an
attack 
assume three different kinds of attack can be chosen for an intercept  the first tactic
 scare  is to engage and attempt to scare away enemy planes without using deadly force 
this tactic is selected when the rules of engagement specify that deadly force should not be
used  regardless of the number of aircraft in the area  one of the remaining two tactics will
be chosen when deadly force is allowed  offensive attack is appropriate when friendly
patrol
intercept
count  enemy 

patrol
intercept
count friendly 

patrol
intercept
attack defensive 
achieveproximity
turntoheading

figure    trace of behavior leading to intercept tactic in tacair soar 
   

fiwray   laird

figure    inconsistency due to persistence 

planes outnumber or equal enemy planes  defensive attack is used when enemy planes
outnumber friendly planes 
choosing between offensive and defensive attack requires counting the current aircraft
in the area  figure   shows the evolution of an executing example decomposition  the
agent must count relevant enemy and friendly planes  determining a planes side and
its relevance to the count often requires remembering and is sufficiently complex that entailment of the count is not possible  for instance  non combatant aircraft should not be
counted  requiring some reasoning about the type of each aircraft  if the agent determines
that enemy planes outnumber friendly ones  the agent selects defensive attack  leading
to further decomposition 
what happens if an enemy plane flees  thus reducing the actual count of relevant enemy planes by one  the count maintained by the agent is now invalid  standard tms
mechanisms are insufficient because the count was asserted as an assumption  if the actual
number of enemy and friendly planes is now equal  then the agent should switch its tactic to offensive attack  continuing the defensive attack is not consistent with the agents
knowledge  additionally  other friendly agents participating in the attack may base their
behavior on the expectation that the agent is pursuing an offensive attack  thus the agent
needs to recognize the inconsistency and remove the current count 
figure   presents a conceptual illustration of the problem  assumptions are represented
as squares  entailments as circles  the horizontal line represents a hierarchical relationship
between the assertions  i e   assumptions and entailments  in the hierarchical context  above
the line  and assertions in a local subtask  below the line   the arrowed lines represent
dependence in the creation of an assertion  as in the previous examples  some reasoning
in the subtask may require persistence  leading to the creation of an assumption such as
assumption    however  the persistent assertion may still depend on other assertions  this
work focuses on the dependent assertions in the higher level context  such as a  b  c  d 
and e  in the figure 
suppose the world changes so that e  is retracted from memory and e  is asserted 
assumption   remains in memory  if e   would not also lead to    e g   it could lead to some
new assumption    as shown   then   is no longer justified and may not be consistent with
the higher level context  whether or not this potential inconsistency among the assertions
leads to inconsistent behavior depends on the use of assumption   in later reasoning 
   

fiensuring consistency in hierarchical execution

   solutions
our goal is to develop architectural solutions that allow an agent to support persistent
assumptions and simultaneously avoid inconsistencies across the hierarchical context that
can lead to irrational behavior  before introducing two new architectural solutions  however 
we examine knowledge based approaches and their consequences in order to provide further
rationale for the architectural approach 
    knowledge based solutions
inconsistency can be avoided in hierarchical agents by creating domain knowledge that
recognizes potential inconsistencies and responds by removing assumptions  many planning and agent systems use explicit domain knowledge to represent knowledge about the
interactions among assertions in the world  for example  the entropy reduction engine
 ere   bresina et al         is one agent system that relies on this knowledge based assumption consistency  kbac   ere requires domain constraints  or knowledge that describes
the physics of the task domain  domain constraints identify impossible conditions  for
instance  a domain constraint would indicate that a robot cannot occupy two different
physical locations simultaneously 
in ere  domain constraints are specifically used to maintain consistency in the current
world model state during execution  bresina et al         pp        however  many other
architectures use kbac as well  perhaps in conjunction with other methods   kbac
knowledge can be viewed simply as domain knowledge that must be added to the system
to achieve consistent behavior 
kbac will always be necessary to maintain consistency among the assumptions within
a level of the hierarchy  however  in order to guarantee consistency for assumptions distributed throughout the hierarchy  all possible interactions leading to inconsistency must
be identified throughout the hierarchy  this knowledge engineering problem can add significant cost to agent development  a knowledge designer must not only specify the conditions
under which an assumption is asserted but also all the conditions under which it must be
removed  in the tacair soar interception example  when the enemy plane flees  the agent
requires knowledge that disables all assumptions that depend upon the number of enemy
airplanes  similarly  in the dynamic blocks world  the agent must have knowledge that
recognizes any situation  in any subtask  that should cause the disabling of empty  in both
cases  this kbac knowledge crosses levels of the hierarchy  a complete kbac solution
requires that an agents knowledge capture all potential dependencies between assumptions
in a local subtask and any higher levels in the hierarchy 
although it will be possible to encode complete across level consistency knowledge for
simple domains  experience in tacair soar and other complex agent systems has convinced
us that kbac requires significant investments of time and energy  further  because it is
often not possible to enumerate all conditions under which an assumption must be removed 
agents are also brittle  failing in difficult to understand  difficult to duplicate ways 
the insufficiency of knowledge based solutions led us to consider architectural solutions
to the problem  architectural solutions eliminate the need for domain knowledge encoded
only to address inconsistency between the hierarchical context and assumptions within a
subtask  thus  the cost of developing individual agents should be reduced  in addition to
   

fiwray   laird

their generality  by definition  architectural solutions are also complete  and thus able to
guarantee consistency between the hierarchical context and assumptions within a subtask 
at all times  for any agent task  such completeness should improve the robustness of agent
systems  especially in situations not explicitly anticipated by their designers 
    assumption justification
one potential architectural solution to the inconsistency problem is to justify each assumption in the hierarchy with respect to assertions in higher levels of the hierarchy  assumption
justification is an extension of the truth maintenance approaches to consistency outlined
previously  each assumption in the hierarchy is treated as if it were an entailment with
respect to dependent assertions higher in the hierarchy  a new data structure  the assumption justification  is created that captures the reasons in the hierarchical context for
a particular assumption  locally  an assumption is treated exactly like an assumption in a
non hierarchical system  however  when the assumption justification is no longer supported
 indicating a change in the dependent hierarchical context   the architecture retracts the
assumption 
refer again to figure    when the agent asserts a      the architecture builds an assumption justification for the assumption that includes a    and a     if the agent retracts
a     the assumption justification for a    is no longer supported and the architecture also
retracts a     the architecture ensures reasoning consistency across hierarchy levels because
an assumption persists no longer than the context assertions that led to its creation 
assumption justification solves the inconsistency problem because all dependencies in
the hierarchical context are captured in the justification  within the subtask  domain knowledge is still required to ensure consistency among the enabled assumptions in the subtask 
however  no across level consistency knowledge is needed  assumption justification still
supports local nonmonotonic and hypothetical reasoning  thus  assumption justification
appears to meet functional evaluation criteria  however  in order to assess its impact on
performance  some implementation details must be considered 
      implementing assumption justification
creating assumption justifications requires computing context dependencies for each assumption  similar to the computation of justifications for entailments    figure   outlines
a procedure for computing the assumption justification data structure  this procedure is
invoked when any assertion is created  this procedure creates assumption justifications for
every assertion in a local subtask  that is  for entailments as well as assumptions  this approach allows the architecture to cache context dependencies for each local assertion  the
advantage of this caching is that the architecture can simply concatenate the assumption
justifications of the local assertions contributing directly to the creation of the assumption
   the assumption justification procedure  as presented  requires that the inference engine record a justification for every assertion during the course of processing  in soar  the architecture in which assumption
justification was implemented  these calculations are available from its production rule matcher for both
assumptions and entailments  however  justification calculations for assumptions may not be supported
in other architectures  requiring modifications to the underlying inference engine  laird and rosenbloom
       and the soar users manual  laird  congdon    coulter        describe the specific mechanisms
of justification creation in soar 

   

fiensuring consistency in hierarchical execution

proc create new assertion       
an assumption justification is computed when each new assertion a is
created  thus  assumption justifications are computed for both
assumptions and entailments 
   
ajust  create justif ication       
justifications can be created via well known  textbook algorithms
 e g   forbus   dekleer        russell   norvig       
aaj  make assumption justif ication f or assertion a 
   
end
proc make assumption justif ication f or assertion assertion a 
aj  nil
for each assertion j in ajust   the justification of a

 
if  level j  closer to the root than level a  
aj  append j  aj   add j to the assumption justification 

 
else
 j and a at the same level 
aj  concatenate jaj   aj   add assumption justification of j to
assumption justification of a 
return aj  a list of assertions comprising the assumption justification of a
end
proc level assertion a 
return the subtask level associated with assertion a
figure    a procedure for building assumption justifications 
 in 
    we chose this caching option for computing assumption justifications over an ondemand implementation that would  when an assumption was created  recursively follow
local dependencies until all context dependencies were determined  the advantage of the
caching implementation is that the context dependencies for any assertion must be computed only once  even when a local assertion contributes to the creation of multiple local
assumptions 
the procedure that creates an assumption justification loops over the assertions in the
justification of a new assertion a  the assertions in the justification can be either context or
local assertions  context assertions  in 
   are added to the assumption justification directly 
however  local assertions should not be added to the assumption justification because the
assumption justification should include only context dependencies  for example  the architecture can retract a local assertion for reasons other than a change in the hierarchical
context  e g   a non monotonic reasoning step or a change in enabled assumptions in the
subtask  and in these cases  the agent should not necessarily retract dependent assumptions 
because assumption justifications for all local assertions in the justification have already
been computed  i e   they are cached  as described above   the assumption justification of a
   

fiwray   laird

a b c d e

a b c d e

psfrag replacements

 a 

  

 b 

 

figure    technical problems with assumption justification  in  a   an assumption replaces
another assumption nonmonotonically  in  b   multiple assumption justifications
for the same assumption must be supported 

local assertion j can simply be added to the assumption justification of a  as in 
   for an
on demand implementation  the procedure here would recur through local assertions  until
all context dependencies for local assertions contributing to a had been identified 
the worst case computational complexity of this algorithm is polynomial in the number
of assertions in the subtask  the addition of a higher level assertion can be done in constanttime  a single pointer reference   however  
  must uniquely add context assertions from the
assumption justification of the local assertion  there are at most  n     local assumption
justifications whenever the nth assertion is created  thus  the concatenation needs to be
performed no more than  n   times for any call to the assumption justification procedure 
this limit provides an upper bound of o n  on the complexity of the assumption justification
procedure  the worst case cost of building an individual assumption justification is linear in
the number of assertions  n  in the level  however  the architecture executes the assumption
justification procedure for every assertion in the level  thus  the worst case cost for building
all the justifications in a particular level is o               n  or o n     
non monotonic changes complicate the implementation  the architecture must disable
a replaced assumption  rather than delete it  because the initial assumption may need to
be restored  for example  in figure    a   assume that the assertion of e leads to both
the assertion of   in the local subtask and the retraction of    i e     is a revision of     if
the agent retracts e  assumption justification will retract    as desired  but it must also
re enable    thus  assumption   must remain available in memory  although disabled 
figure    b  illustrates a second problem  an assumption can have multiple assumption justifications  these justifications can change as reasoning progresses  assumption  
initially depends on assertions a  b  and c in higher levels  now assume that later in
the processing  the agent removes a  which normally would result in the retraction of   
however  in the meantime  the context has changed such that   is now also justified by  c 
d  e   now when the agent removes a  the architecture should not immediately retract  
but must determine if   is justified from other sources 
an implementation of assumption justification in soar was completed by members of
the soar research group at the university of michigan  experiments using air soar  a flight
simulator domain  pearson et al          showed that the overhead of maintaining all prior
assumptions in a level produced a significant negative impact on agent performance  in
this domain  assumption justification incurred significant computational cost  requiring at
   

fiensuring consistency in hierarchical execution

least      more time than the original air soar agent  further  the number of assumption
justifications maintained within a level continued to grow during execution  for the reasons
explained above  some subtasks required minutes to execute as the aircraft performed a
maneuver  leading to large  and problematic  increases in the amount of memory required 
thus  assumption justification failed to meet efficiency requirements on both theoretical
and empirical grounds  although the limitations of assumption justification might be improved by developing solutions to its technical problems  we abandoned further exploration
of this approach after such strongly discouraging results 
    dynamic hierarchical justification
figure   introduced the notion of a support set for subtasks  both the procedural reasoning
system  prs   georgeff   lansky        and soar  laird et al         use architectural
mechanisms to retract complete levels of a subtask hierarchy when the support set no longer
holds  in this section  we consider a solution that leverages the hierarchy maintenance
function to ensure consistency between assumptions and the higher level context 
a significant disadvantage of the support set in existing systems is that it is fixed  in
soar  the support set is computed for the initiation of the subtask but is not updated to
reflect reasoning that occurs within the subtask  for example  in figure    suppose that
assumption a   depends on assumptions a   and a    represented by the dashed  arrowed
lines   the support set does not include a      this assertion may not have even been present
when subtask  was created  when a local assumption depends on an assertion not in the
support set  then a change in that assertion will not directly lead to the retraction of the
assumption  or the subtask   thus  approaches using such fixed hierarchical justification
 fhj  still require knowledge based solutions for consistency  fhj is discussed further in
section       
we propose a novel solution  dynamic hierarchical justification  dhj   that is similar
to fixed hierarchical justification  but dynamically updates the support set as reasoning
progresses  assumption justifications for individual assumptions are unnecessary  however 
one consequence of this simplification is that a subtask  and all assertions within it  will
be retracted when the dependent context changes  refer to figure    when a dhj agent
asserts a   in figure    the architecture updates the support set for subtask   to include a    
assumption a   is already a member of the support set and need not be added again  when
any member of the support set for subtask   changes  the architecture retracts the entire
subtask  thus dynamic hierarchical justification enforces reasoning consistency across the
hierarchy because a subtask persists only as long as all dependent context assertions 
      implementing dynamic hierarchical justification
figure   outlines the procedure for computing the support set in dhj  as in assumption
justification  the architecture can directly add context assertions to the support set 
  
when the architecture computes the dependencies for a local assertion 
   the assertion
is marked as having been inspected 
   inspected assertions can simply be ignored in the
future 
   because the architecture has already added the assertions dependencies to the
support set  the architecture will also ignore dependent  local assumptions 
  because
the dependencies of those assumptions will have already been added to the support set 
   

fiwray   laird

proc create new assertion       
whenever a new assumption is asserted  the support set is updated
to include any additional context dependencies 
   
ajust  create justif ication       
if a is an assumption
s is the subtask in which a is asserted
ssupport set  append ssupport set   add dependencies to support set a  
   
end
proc add dependencies to support set assertion a 
for each assertion j in ajust   the justification of a

 
if  level j  closer to the root than level a  
append j  s   append context dependency to support set 

 


 

 

elseif  level j  same as level a  and
j is not an assumption and
j has not previously been inspected  
s  append s  add dependencies to support set j  
 compute support set dependencies for j and add to s 
jinspected  true
 js context dependencies have now been added to the support set 

return s  the list of new dependencies in the support set
end
proc level assertion a 
return the subtask level associated with assertion a
figure    a procedure for dynamic hierarchical justification 
because dhj needs to inspect any local assertion only once  context dependencies are
computed on demand  rather than cached as in assumption justification  condition 
  will
be true whenever there is a local entailment whose context dependencies have not yet been
computed  these dependencies are determined by calling add dependencies to support set
recursively  recursive instantiations of add dependencies to support set each receive a local
assertion in the justification of an uninspected entailment  j  and return a list comprising
the context dependencies of j  the return value is then appended to the support set s in
the prior instantiation of add dependencies to support set 
the recursive call to add dependencies to support set at 
  is the only non constant time
operation in the procedure  it must be made only once for any assertion j i and thus the
worst case complexity to compute the dependencies is linear in the number of assertions in
the level  as in assumption justification  however  dhj requires only a single inspection of
any individual assertion  rather than repeated inspections for each new assumption as in as   

fiensuring consistency in hierarchical execution

sumption justification  thus the architecture needs to call add dependencies to support set at most n times for any subtask consisting of n assertions  and the worst case cost of
updating the support set in a level remains o n   this reduction in complexity potentially makes dynamic hierarchical justification a more efficient solution than assumption
justification  especially as the number of local assertions increases 
additionally  the two technical problems outlined for assumption justification do not
impact dhj  dhj never needs to restore a previous assumption  when a dependency
changes  the architecture retracts the entire level  thus  dhj can immediately delete
replaced assumptions from memory  dhj collects all dependencies for assumptions  so
there is no need to switch from one justification to another  in figure    b   dependencies
a  b  c  d  and e are all added to the support set  these simplifications can make the
support set overly specific but reduce the memory and computation overhead required by
dynamic hierarchical justification 
dhj retractions will sometimes be followed by the regeneration of the subtask and
the re assertion of reasoning that was retracted  for example  if the enemy plane fled as
described in the tacair soar scenario  dhj would retract the entire level associated with
the counting subtask  the count would then need to be re started from the beginning 
section       examines potential problems introduced by interruption and regeneration 
the cost incurred through the regeneration of previously derived assertions is the primary
drawback of dynamic hierarchical justification 
    implications of dynamic hierarchical justification
dynamic hierarchical justification solves the specific problem of maintaining reasoning
consistency in a hierarchy  guaranteeing consistency and utilizing an efficient algorithm 
the heuristic dhj employs assumes that assumptions are so closely associated with their
subtasks that retracting subtasks is nearly equivalent to retracting individual assumptions 
this section explores the implications of this heuristic  focusing on task decompositions  the
impact on the agents ability to use persistent assumptions  and the feasibility of interrupting
an agent  with a subtask retraction  in the midst of reasoning 
      the influence of the task decomposition
an agents reasoning can be viewed as knowledge search  newell         from this perspective  the inconsistency problem is failure to backtrack in knowledge search  the world
changes  leading to changes in the agent hierarchy  the agent must retract some of the
knowledge it has previously asserted  so it should backtrack to a knowledge state consistent
with the world state   each solution can be described in terms of the way its achieves  or
avoids  backtracking in the knowledge search  for instance  kbac leads to knowledge based
backtracking  in which the kbac knowledge tells the agent how to correct its assumptions
given the current situation 
   obviously  this world state will usually be different than the agents initial state and it is often impossible
to return to a prior state in an execution system  we use backtrack in this section to refer to the
retraction of asserted execution knowledge such that any remaining asserted knowledge is consistent with
the currently perceived world state 

   

fiwray   laird

a b c d e f g h

 a 

 

a b c d e
 b 

 

 

 

figure     examples of  a  disjoint dependencies and  b  intersecting assumption dependencies 

assumption justification is a form of dependency directed backtracking  stallman  
sussman         in dependency directed backtracking  regardless of the chronological order
in which an architecture makes assertions  the architecture can identify and retract those
assertions that contributed to failure in a search and retain all other assertions  in assumption justification  the architecture retracts only those assumptions that are directly affected
by a change in the context  assumptions created later in the processing  not dependent
on the change  are unaffected  consider the examples in figure     in  a   assumptions
  and   each depend upon disjoint sets of assertions  with assumption justification  removal of any assertion in  s assumption justification will result in the retraction of      is
unchanged  even if the architecture asserted   after   
dynamic hierarchical justification is similar to backjumping  gaschnig         backjumping heuristically determines the state to which a current search should backtrack or
backjump  the heuristics used by backjumping are based on syntactic features of the
problem  for instance  in constraint satisfaction problems  the backjumping algorithm
identifies which variable assignments are related to other variable assignments via the constraints specified in the problem definition  when a violation is discovered  the algorithm
backtracks to the most recent  related variable  dechter         intervening variable assignments are discarded  in dhj  when an assertion in the hierarchy changes  the system
backjumps in its knowledge search to the highest subtask in the hierarchy not dependent
on the change  in figure     a  all dependent assertions are collected in the support set for
the subtask  if any of the higher level assertions change  the entire subtask is removed 
when using dhj  as in backjumping  some previous knowledge search may need to
be repeated after backtracking  assume the removal of the subtask in figure     a  was
due to a change in a  if a similar subtask is reinitiated  assumption   may need to be
regenerated  this regeneration is unnecessary because   did not need to be retracted
to avoid inconsistency  under dynamic hierarchical justification  the agent retracts all
reasoning in the dependent subtask  and all lower levels in the hierarchy   assertions not
dependent on the change in the context can also be removed  thus  like backjumping  dhj
uses a syntactic feature of reasoning  decomposition into subtasks  to choose a backtracking
point and this backtracking is not always as conservative as possible 
although the subtask decomposition is a syntactic feature of the knowledge search  it
is a strongly principled one  reflecting a semantic analysis of the task by a knowledge designer  hierarchical task decomposition is based on the premise that tasks can be broken
down into discrete units that have little interaction with other units  they are nearly decom   

fiensuring consistency in hierarchical execution

posable  simon         thus  the goal of a hierarchical decomposition is to separate mostly
independent subtasks from one another  a consequence of this separation is that dependencies in higher levels will be limited as much as possible  interaction between subtasks should
be minimized  and the dependencies among the assertions in any particular subtask will be
shared  otherwise  the subtask could be subdivided into two or more independent subtasks  
of course  it is often possible to decompose a given task in many different ways  in most
cases the domain imposes minimal constraint and the knowledge engineer has significant
latitude in crafting the task decomposition 
in the situation illustrated in figure      b  would be a more complete decomposition
of a task by the knowledge engineer than  a   assuming the two alternatives represent a
decomposition of the same task  in  b   the number of dependent assertions does not necessarily grow as a function of the number of assumptions in the local level  while in  a  it
does  further  in  a   two independent assumptions are being pursued  these assumptions
could potentially be inferred in separate subtasks in an alternate decomposition  in  b  
on the other hand  the assumptions in the subtask are closely tied together in terms of
their dependencies and thus better asserted within the same subtask  because the dependencies of assumptions   and   have considerable overlap in  b   assumption justification
pays a high overhead cost to track individual assumptions because  most  everything in
the local subtask would be removed simultaneously if assertions b  c  or d changed  because dhj incurs no such overhead  dhj is a better choice when the intersection between
assumption dependencies is high  task knowledge structured more like the situation in
 b   rather than  a  would lead to few unnecessary retractions  because  b  appears to
better reflect well decomposed tasks  dynamic hierarchical justification will constrain the
knowledge development process and improve the resulting decompositions  consequently 
nearly decomposed tasks should allow dhj to avoid most unnecessary regenerations while
avoiding the processing overhead of assumption justification 
      limiting persistence under dhj
dhj limits persistence in subtasks  resulting in assumptions that are not as persistent as
assumptions in typical truth maintenance systems  this section explores the consequences
of these limitations to determine if dhj architectures   can still provide the persistence
necessary for agent execution  section      
dhj will retract a subtask when a potential inconsistency could impact hypothetical and
recursive reasoning like counting  consider the aircraft classification and counting example 
perhaps an aircrafts altitude contributes to a hypothetical classification of the aircraft
 e g   particular altitude and speed combinations might suggest a reconnaissance aircraft  
the agent would create assumptions locally that depend on this aircrafts altitude  if the
altitude  or an altitude boundary  changes  then the assumption should be retracted  this
retraction is required to avoid inconsistency  if the contacts altitude no longer suggests that
it is a reconnaissance aircraft  then the assumption that depended on that assertion should
be removed  dhj captures these dependencies and performs the retraction  the agent now
   for clarity  and because assumption justification has already been eliminated as a candidate solution 
the following discussion focuses exclusively on dhj  however  assumption justification limits persistence
similarly 

   

fiwray   laird

has the opportunity to reconsider the classification of the aircraft  or pursue other tasks if
the classification is no longer important 
dhj will also retract a subtask if an assumption was created in the local subtask for
the purpose of remembering some input  or elaboration of input   for example  if an agent
needed to remember a particular aircrafts altitude at a particular point in time  then that
assumption cannot be stored in a local subtask  dhj limits persistence in such a way that
remembering within a local subtask is generally impossible 
in order to remember previous situations  assumptions can be asserted in the root task 
any assumption asserted in this level will never be retracted because there are no higher level
dependencies  assuming percepts are associated with the top level and not a higher input
level  as in theo  mitchell et al          the primary drawback of this requirement for
remembering is that remembered items are no longer local to the subtask that created them 
requiring additional domain knowledge to manage remembered assumptions  however 
remembering already requires domain knowledge  it is not possible to remember an assertion
regardless of its dependencies and also be able to retract it architecturally 
these examples show that dynamic hierarchical justification still allows all forms of
persistence  but trades capturing dependencies for nonmonotonic assumptions in local subtasks with remembering assumptions in the root task  where no dependencies are captured 
because dhj forces remembered items into the root task  it also suggests that a fundamental aspect of this root task should be managing these remembered assumptions  we view
this requirement as a positive consequence of dhj  because it forces knowledge engineers
to better recognize the reasons for creating an assumption  e g   remembering vs  a hypothetical  and circumscribes remembering so that we can now develop or adopt functional
or temporal theories to manage assumptions created for remembering  e g   allen       
altmann   gray        
      recovery from interruption with dhj
dynamic hierarchical justification makes an agent more reactive to its environment  ensuring that relevant changes in the environment lead to the retraction of any dependent
subtasks  dhj imposes an automatic interruption of the agent for a subtask retraction 
without evaluating the state of the system first  although automatic interruption increases
the reactivity of the system  it can lead to difficulties if there is no way to override it 
in this section we examine two cases where uncontrolled interruption can cause problems 
the problems arise because dhj biases the system to be reactive  that is  to respond automatically to changes in the environment without deliberation  however  in both cases 
additional agent knowledge can overcome that bias and make the system more deliberate
and avoid uncontrolled interruption 
the first problem arises when there is a sequence of actions that must be completed
without interruption in order for a subgoal to be achieved  if the processing is interrupted 
then it is possible  because of the dynamics of the world  that the task cannot be resumed 
for example  imagine an aircraft nearing the point where it can launch a missile at a target 
when the task is interrupted and then resumed  the aircrafts position may have changed
enough  relative to the target  that additional steering commands are necessary before the
   

fiensuring consistency in hierarchical execution

missile can be launched  in this case  it may be preferable not to interrupt the original
launch sequence once it has begun 
consider two possible approaches to achieving this capability with dynamic hierarchical
justification architectures  the first is to move the processing to the root task  because
the root task is not interrupted  the processing will not be interrupted  however  this
approach greatly restricts how a task can be hierarchically decomposed and thus should be
considered only as a last resort  the second approach is to add new reasoning for the task
that freezes the external situation with respect to additional reasoning in the subtask 
the new processing initiates the execution of the subtask and creates persistent structures
in the root task  these persistent structures represent a deliberate commitment to not
being interrupted  the remaining processing in the subtask accesses only these structures
in the execution of the task  thus  because they are persistent  even if there are changes
to the surrounding situation that would have interrupted the subtask  its processing is
now insensitive to those changes and interruption is prevented  this approach also requires
additional reasoning to recognize completion of the uninterruptible behavior and remove the
persistent structures built by the initial subtask  this reasoning reflects a deliberate act 
signaling that the commitment no longer holds  in the abstract  together these additions
provide a mechanism for overcoming automatic interruption  the disadvantage of this
approach is that  as part of the system design  those subgoals that cannot be interrupted
must be identified beforehand  for those subtasks  additional agent knowledge must be
implemented to create and remove encapsulations of any dynamic data 
a more critical problem for dhj is the wesson oil problem  when someone is cooking
dinner and a higher priority activity suddenly occurs  a hurt child   the cook should turn off
the stove  a cleanup procedure  before leaving for the hospital  gat      b   this problem
occurs when there is a change in the hierarchical context at a level far from the terminal
level of the hierarchy  in this situation  similar tasks may not be resumed or initiated
following the interruption  the agent must therefore recognize whether cleanup of the
external and or internal states is necessary  and  if so  perform that cleanup  even with
dhj  the agent can still behave appropriately if it has the right knowledge  in particular 
the agent must be able to recognize partially completed tasks  like cooking dinner  and be
able to select cleanup actions specific to the task state  like turning off a stove burner  
because dhj requires all remembered assumptions to be asserted in the root level of the
hierarchy  this recognition task has internal state available  it need not try to reconstruct
that state from the external environment alone  however  it does require some analysis
of the task domain s  by a knowledge engineer so that any interruptible activity requiring
cleanup include triggering assertions for cleanup in the root task 
this work was prompted by a desire for architectural solutions to inconsistency  yet
maintaining consistency efficiently can lead to interruptions  which  under dhj  requires
knowledge based solutions to problems arising from automatic interruption    however  most
of the requirements imposed by dhj are positive consequences  subtask retractions and
observed recovery in the development process help define what must be remembered in the
root task for cleanup  which is significantly different than the laborious process of debugging
   dynamic hierarchical justification could also be used as a trigger for meta level deliberation rather than
immediate subtask retraction  it would then possibly provide an architectural solution to the question
of when to deliberate about potential inconsistency for intention reconsideration  see section      

   

fiwray   laird

agent programs that are failing due to inconsistency  in theory  dynamic hierarchical
justification imposes requirements for handling interruptions that do pose serious questions
about its overall utility  in practice  we have not found addressing these questions to be a
problem in a variety of recent agent implementations using the soar dhj architecture  e g  
laird        wray et al         

   empirical evaluation of dynamic hierarchical justification
architectural mechanisms like dhj must be efficient  we have demonstrated that the
algorithm itself is efficient  but the question of its impact on the overall behavior generation
capability of an agent remains an open question due to interruption and regeneration  given
the complexity of both agent based systems and the domains in which they are applied 
analytical evaluations must be extremely narrow in scope  and even then require specialized
techniques  wooldridge         this section instead pursues an empirical evaluation of
dynamic hierarchical justification  focusing on efficiency and responsiveness in two domains
at extremes in the continua of agent domain characteristics  because the architectural
solution to inconsistency was motivated by the cost  and incompleteness  of knowledgebased solutions  knowledge development costs will also be estimated 
    methodological issues
dynamic hierarchical justification is a general solution  applicable in a wide range of agent
tasks  in order to evaluate such a solution  a number of methodological issues must be
addressed  the following describes three important issues and the choices made for this
evaluation 
      relative vs  absolute evaluation
what constitutes good or poor cost and performance evaluations  in general  an
absolute evaluation of performance and cost is difficult because the task itself  in addition
to the agents knowledge and architecture  determines overall cost and performance results 
we circumvent this problem by making relative comparisons between agents using the
original  fixed hierarchical justification soar architecture  fhj agents  and new agents
 dhj agents   the fhj agents provide cost and performance benchmarks  obviating the
need for absolute evaluations 
      addressing multiple degrees of freedom in agent design
even when architecture and task are fixed  many different functional agents can be developed  how can one know if comparative results are valid and general if the experimenter
has control over both benchmarks and new agents 
dhj agents will be compared to agents previously implemented by others  such systems
will provide good performance targets  because they were optimized for performance  and
will minimize bias  because they were developed independently 
fhj systems were used as fixed benchmarks  and were not modified  dhj agents use the
identical task decompositions employed by the fhj agents and the same initial knowledge
base  we observed opportunities to improve performance in the dhj agents by modifying
   

fiensuring consistency in hierarchical execution

either the task decomposition or re designing significant portions of the agent knowledge
base  however  agent knowledge was modified only when necessary for correct behavior  in
order to ensure that dhj agents remained tightly constrained by their fhj counterparts 
thus limiting bias in the evaluation 
      the choice of representative tasks
this evaluation will be limited to execution agents in the dynamic blocks world and in
a reduced knowledge version of tacair soar  micro tacair soar   the choice of only a
few tasks or domains is a considerable drawback of benchmarks  hanks  pollack    cohen         although these choices were motivated primarily by the availability of domains
with pre existing fhj agents  the two domains do represent opposite extremes for many
domain characteristics  micro tacair soar  like tacair soar  is inaccessible  nondeterministic  dynamic  and continuous  while the dynamic blocks world simulator used in the
experiments is accessible  deterministic  static and discrete  the primary motivation for
using the dynamic blocks world  which is less representative of typical agent tasks than
micro tacair soar  is to assess the cost of employing dhj in a domain where a priori it
appears it would not be useful  although section   suggests dhj can prove useful even
in relatively static domains   thus  the dynamic blocks world will provide a baseline for
the actual cost of deploying the algorithm  even though little benefit is expected from its
deployment in this domain 
    evaluation hypotheses
although specific expectations will differ in different domains  differences in the dimensions
of knowledge cost and performance can be anticipated when comparing dhj agents to
baseline agents  the following discusses the expectations and the metric s  used for each
dimension 
      knowledge engineering cost
knowledge engineering effort in dhj agents should decrease in comparison to previously
developed agents  knowledge in soar is represented with production rules  each production
represents a single  independent knowledge unit  we assume the addition of more productions represents an increase in cost and measure knowledge cost by counting the number of
productions in each type of agent  the number of productions  of course  provides only a
coarse metric of cost because the complexity of individual productions varies significantly 
however  the productions that will be removed in dhj agents are often the most difficult
ones to create  therefore  the difference in number of productions is probably a conservative
metric for knowledge cost in dhj 
      performance  efficiency and responsiveness
in general  overall performance should change little in dhj agents  as compared to fhj
counterparts  although dynamic hierarchical justification does add a new architectural
mechanism  the algorithm itself is efficient and should not contribute to significant differences in performance  further  less domain knowledge will need to be asserted because all
   

fiwray   laird

across level consistency knowledge is now incorporated in the architecture  thus  if applying across level kbac knowledge represented a significant expense in the overall cost of
executing a task  dhj agents might perform better than fhj agents 
there are two specific exceptions to this expectation  first  in domains where consistency knowledge is  mostly  unnecessary for task performance  fhj agents may perform
better than dhj agents  for example  the dynamic blocks world requires little consistency knowledge but the dhj architecture will still update the support set  even though
few inconsistency causing context changes should arise 
second  if regeneration is problematic  overall performance will suffer  in dhj  whenever
the dependent context changes  a subtask will be retracted  if the change does not lead
to a different choice of subtask  the subtask will be necessarily regenerated  thus  under
dhj  some subtask regeneration will occur  and  if regeneration is significant  performance
degradation will result 
cpu execution time provides a simple  single dimension of gross performance  the cpu
time reported for individual experiments reflects the time the agent spends reasoning and
initiating actions rather than the time it takes to execute those actions in the environment 
decisions  in soar  subtasks correspond to the selection of operators and subgoals for
implementing operators  the selection of an operator is called a decision  when soar
selects an operator  it tries to apply the operator  soar reaches an impasse when it cannot
apply a newly selected operator  these non primitive operators lead to the generation of
a subgoal in the subsequent decision  for example  soar selects the put down operator
in one decision and creates a subgoal to implement put down in the subsequent decision 
together  these two steps constitute the notion of a subtask in soar 
the number of decisions can thus be used as an indication of the number of subtasks
undertaken for a task  in fhj  a subtask was generally never interrupted until it terminated
 either successfully or unsuccessfully   in dhj  subtasks will be interrupted whenever a
dependent change occurs  thus  decisions should increase in dhj agents because subtasks
will be interrupted and re started  further  if decisions increase substantially  suggesting
significant regeneration   overall performance will degrade 
production firings  a production rule fires when its conditions match and its result is
applied to the current situation  production firings should decrease in dhj for two reasons 
first  any across level consistency knowledge that was previously used in fhj agents will no
longer be necessary  or represented   therefore  this knowledge will not be accessed  second 
any reasoning that occurred after inconsistency arose in fhj agents will be interrupted and
eliminated  however  production firings will increase if significant regeneration is necessary 
    empirical evaluation in the blocks world
agents in this dynamic blocks world domain have execution knowledge to transform any
initial configuration of three blocks into an ordered tower using a simulated gripper arm 
the table in this simulation has a width of nine blocks  the agents task goal is always to
build the   on   on   tower  each agent built a tower from each of the resulting     unique 
non goal  initial configurations of blocks  table   summarizes the results of these tasks  as
expected  total knowledge decreased  overall performance improved  decisions increased 
as expected  but the number of rule firings increased as well  which was not anticipated 
   

fiensuring consistency in hierarchical execution

rules
decision avg 
avg  rule firings
avg  cpu time  ms 

fhj
x
s d 
   

    
    
           
           

dhj
x
s d 
   

     
    
           
           

table    summary of knowledge and performance data from the blocks world  the agents
performed the tower building task for each of     configurations  task order was
randomly determined 

      knowledge differences
total knowledge decreased about    in the dhj agent  this small reduction is consistent
with expectation  the aggregate comparison is misleading because knowledge was both
added     productions  and deleted      
removing consistency knowledge  in soar  the subtask operator and subgoal are
terminated separately  soar monitors impasse causing assertions to determine if a subgoal
 such as the subtask goal  should be removed via fhj  however  the removal of a subtask
operator requires knowledge  the original  fhj architecture treats the initiation of an
operator as a persistent assumption and requires knowledge to recognize when a selected
operator should be interrupted or terminated  this knowledge can be categorized as consistency knowledge because it determines the time at which a subtask should be terminated 
even when the initiating conditions for the subtask no longer hold 
in dhj  only the effects of operators are persistent  all other assertions are entailments
of the situation  thus  the initiation of a subtask is now treated as an entailment and
a subtask remains selected only as long as the initiation conditions for the subtask hold 
this change removes the need for knowledge to terminate the subtask  when the subtask
initiation conditions are no longer true  the subtask is automatically retracted  thus 
termination knowledge was removed for all subtask operators 
filling gaps in domain knowledge  the persistence of subtasks in the original architecture allows fhj agents to ignore large parts of the state space in their domain knowledge 
for example  the knowledge that initiates stack and put on table subtasks assumes that
the gripper is currently not holding a block  as these tasks are executed  the gripper  of
course  does grasp individual blocks  the conditions for initiating stack or put on table
when holding a block were ignored in the original domain knowledge 
the dhj agent now requires knowledge to determine which subtasks it should choose
when holding blocks  because subtasks can be interrupted while the agent still holds a block 
   productions were necessary  primarily for the stack and put on table operators  it is
important to note that this knowledge is necessary domain knowledge  fhj agents could
not solve any problem in which they began a task holding a block because they lacked
domain knowledge for these states  these additions are thus a positive consequence of
dhj  the architectures enforcement of consistency revealed gaps in domain knowledge 
   

fiwray   laird

      performance differences
somewhat surprisingly  overall performance of the dhj agents  measured in cpu time  improves slightly in comparison to the fhj agents  even though both decisions and production
firings increase  each of the soar specific performance metrics are considered individually
below  and then the overall performance improvement is considered 
decisions  fhj agents  on average  made considerably fewer decisions than dhj agents 
the difference was consistent across every task  these additional decisions result from the
removal and subsequent regeneration of subtasks  for example  when the agent picks up a
block in pursuit of a stack task  the selection of the stack task must be regenerated  the
knowledge in the dhj agents could be modified to avoid testing specific configurations of
blocks and thus avoid many of these regenerations 
production firings  the number of production firings also increased in the blocks world 
the increase in production firings can be attributed to the knowledge added to the system
and the regeneration of subtasks that made the additions necessary  the relative increase in
number of production firings       was much smaller than the increase in decisions       
the smaller difference can be attributed to the productions that were removed  and thus
did not fire  
cpu time  generally  when production firings increase in soar  an increase in cpu
time is expected  however  cpu time in dhj decreased slightly in comparison to fhj
even though production firings increased  to explain this result  some additional aspects of
soars processing must be considered 
the match cost of a production is not constant but grows linearly with the number of
tokens  partial instantiations of the production  tambe         each token indicates what
conditions in the production have matched and the variable bindings for those conditions 
thus  each token represents a node in a search over the agents memory for matching
instantiation s  of the production  the more specific a productions conditions are  the more
constrained the search through memory  and thus it costs less to generate the instantiation 
the new productions added to the dhj blocks world agent were more specific to
the agents memory  i e   its external and internal state  than the productions removed 
further  simply having fewer total productions also can reduce the amount of total search
in memory   an informal inspection of the match time and tokens for several fhj and
dhj runs showed that the number of tokens decreased in dhj by         this reduction
in token activity is the primary source of improvement in dynamic blocks world dhj
agent cpu time  this improvement  of course  is not a general result and provides no
guarantee that in some other task or domain the cost of matching will not increase rather
than decrease 

   the rete algorithm  forgy        shares condition elements across different productions  thus  the
removal of productions only decreases the total search if removed productions contain condition elements
not appearing in the remaining productions  we did not perform an exhaustive analysis of the condition
elements to determine if the removed productions reduce the number of unique condition elements in
the rete network 

   

fiensuring consistency in hierarchical execution

    empirical evaluation in tacair soar
converting tacair soar to the dhj architecture would be very expensive  requiring many
months of effort  dhj agents were instead developed for a research and instruction version
of tacair soar  micro tacair soar  tas   tas agents use the tacair soar simulation
environment  modsaf  and interface but have knowledge to fly only a few missions  resulting in an order of magnitude decrease in the number of productions in the agents  however 
tas uses the same tactics and doctrine for its missions as tacair soar 
in tas  a team of two agents  lead and wing  fly the patrol mission described
previously  they engage any hostile aircraft that are headed toward them and are within
a specific range  the lead agents primary role is to fly the patrol route and intercept
enemy planes  the wings responsibility is to fly in formation with the lead  because the
total knowledge is significantly reduced  converting tas dhj agents should be relatively
inexpensive  however  the results should be representative of tacair soar because tas
retains the complexity and dynamics of tacair soar 
the patrol mission has no clearly defined task termination condition like the dynamic
blocks world  to address this problem  each agent in the simulation executes for ten
minutes of simulator time  during this time  each agent has the opportunity to take off 
fly in formation with its partner on patrol  intercept one enemy agent  and return to patrol
after the intercept  in an actual tacair soar scenario  these activities would normally be
separated by much larger time scales  however  an agent spends much of its time on a
patrol mission simply monitoring the situation  waiting   rather than taking new actions 
ten minutes of simulated time proved to be brief enough that overall behavior was not
dominated by wait states  while also providing time for a natural flow of events 
when running for a fixed period of time  an increase in the number of decisions can be
attributed to regeneration or simply an improvement in decision cycle time  we avoid this
potential confusion by running the simulator with a constant cycle time  in this mode  each
simulator update represents    milliseconds of simulated time  because each agent now
runs for a fixed period of time with fixed updates  each fhj and dhj agent will execute
the same number of decisions  any problems due to regeneration will be apparent in the
number of rule firings and degradation in responsiveness  additionally  the general results
do not change significantly if the scenarios are executed with the real time mode normally
used for tacair soar agents  the fixed cycle simply eliminates some variability 
although the patrol scenario was designed to minimize variation from run to run  the
tas simulator is inherently stochastic and the specific actions taken by an agent and the
time course of those actions varies when the same task is repeated  to control for this variation  each scenario was run for the lead and wing agents approximately    times  logging
and data collection significantly impacted cpu time and other performance statistics  in
order to control for this effect  we actually ran each scenario    times  randomly choosing
one agent  lead or wing  to perform logging functions  and discarding its performance measures   the other agent performed no logging functions  data from logging agents was used
to create figure    the performance measures of the no logging agents were recorded at
the conclusion of each scenario and are summarized in table   
   

fiwray   laird

lead agent
rules
number of runs  n 
decisions
outputs
rule firings
cpu time  msec 

fhj
   
  
x s d 
    
   
          
        
        

x
    
     
    
    

dhj
   
  
s d 
   
    
    
   

wing agent
fhj
dhj
   
   
  
  
x s d 
x s d 
    
   
    
   
         
        
         
        
         
        

table    summary of tas run data 
      improving task decompositions
tacair soar dhj agents required extensive knowledge revision  such revision was not
unexpected  for instance  unlike the dynamic blocks world  tas agents remember many
percepts  such as the last known location of an enemy aircraft  as previously described 
assertions for remembering must now be located in the root level of the hierarchy  thus
requiring some knowledge revision  however  other problems were discovered  in some
cases  fhj agents took advantage of inconsistency in asserted knowledge  in other words  the
fhj agent not only allowed inconsistency in the assertions but actually depended on those
inconsistencies to apply new knowledge  there were two major categories of this knowledge 
within level consistency knowledge recognized specific inconsistencies  e g   retraction of
the proposal for the subtask  as a trigger for actions such as clean up of the subtask
state  complex subtasks allowed the non interruptible execution of a complex procedure
regardless of the continuing acceptability of the subtask  in both cases  agent knowledge
was modified to remove any dependence on inconsistency  appendix a provides further
explanation of the original knowledge and subsequent changes  section       summarizes
the changes quantitatively 
      results
table   lists average data for the fhj and dhj lead and wing agents for the patrol intercept
scenario after the modifications to the dhj agents knowledge base were completed  the
results in this domain are consistent with expectations  total knowledge decreases  rule
firings decrease and performance improves  substantially so for the dhj wing agent  the
following sections explore each of these results in greater detail 
      knowledge differences
table   quantifies the changes to the soar production rules described above    modifications include deletions  additions and changes  a rule was considered changed only if
its conditions changed slightly  but it made the same type of computation for the same
subtask  for example  most of the changed within level consistency knowledge now refers
   the dhj agent data was generated with a knowledge base that included some changes to accommodate
learning  wray        and these changes are included in the table for completeness  the presence of
these rules in the knowledge base has negligible impact on the performance data reported here 

   

fiacross level
consistency

remembering

within level
consistency

complex
subtasks

learning

miscellaneous

ensuring consistency in hierarchical execution

  
 

  
  

 
 

  
  

 
 

 
 

 

  

 

 

  

 

fhj agent 
deletions 
additions 
dhj agent 
additional changes 

totals
   
     
  
   
  

table    quantitative summary of changes to production rules in the fhj agent knowledge
base for dhj agents 

to an entailed structure rather than one created as an assumption  but that structure is
located in the same subtask  this somewhat restrictive definition of a change inflates the
addition and deletion accounting  in many cases a production was deleted and then immediately added to a different subtask  for example  the productions that manipulate
motor commands were all moved from local subtasks to the highest subtask  almost all
the additions and deletions in the remembering category can be attributed to this move 
which required no synthesis of new production knowledge 
total knowledge required for the dhj agents decreased  this approximately    reduction was achieved by making some type of modification to about     of the fhj agent
rules  and may seem a modest gain  given the conversion cost  however  this cost is an
artifact of the chosen methodology  had the dhj agents been constructed in this domain
without previously existing fhj agents  at least a    decrease in the total knowledge would
be expected  this result thus suggests a reduction in the cost of the agent design  the
high conversion cost does suggest that converting a much larger system  like tacair soar 
would probably be very costly  on the other hand  the modifications were made evident by
identifiable regenerations in the architecture  thus  the     total changes made to the fhj
knowledge base were much easier to make than constructing a similar number of rules 
      performance differences
as the performance results in table   show  dhj agents improved in performance relative to
their fhj peers  however  the improvements of the lead and wing agents was substantially
different  differences in the tasks of lead and wing pilots led to the differences in relative
improvements 
lead and wing agents  the lead and wing agent share the same knowledge base but
perform different tasks in the tas scenario    these differences lead to differences in their
   the agents share the same knowledge base because they can dynamically swap roles during execution 
for instance  if the lead exhausts its long range missiles  it will order the wing to take over the lead role 
and then take the role of wing itself 

   

fiwray   laird

    

dhj lead
dhj wing
fhj lead
fhj wing

cumulative outputs

    

    

   
intercept

launch missile

patrol turns

resume patrol
 
 

   

   

   

   

   

   

time  sec 

figure     cumulative outputs over the course of one ten minute scenario for dhj  black 
and fhj  gray  agents  cumulative outputs for lead agents are represented with
solid lines  wing agents with dashed lines 

absolute performance  recall that the leads primary responsibility is to fly the patrol route
and intercept enemy aircraft  on the other hand  the wings primary mission role is to follow
the lead  these different tasks require different responses in the agents 
an agents overall reasoning activity is often correlated with its output activity  that
is  the commands it sends to the external environment to take action in it  figure   
summarizes the output activity of two pairs of lead and wing agents  fhj   dhj  over the
course of a ten minute scenario  the output activity of both leads is mostly concentrated
at a few places over the course of the scenario  take off  intercept  launch missile 
and when resuming patrol following the intercept   the wings most concentrated output
activity occurs when the leads turn to a new leg of the patrol and the wings must follow
the lead through a     degree turn  in the remainder of this section  we focus only on dhj
agents to contrast lead and wing agent behavior  the discussion of the performance metrics
will examine differences between fhj and dhj leads and wings 
the lead actually spends most of the scenario waiting  with short bursts of reasoning
and output activity occurring at tactically important junctures in the scenario  on patrol 
the lead flies straight and makes a decision to turn when it reaches the end of a patrol
leg  the lead monitors the environment and searches for enemy planes  this search is
   

fiensuring consistency in hierarchical execution

 mostly  passive  the agents radar notifies the agent if any new entities have been detected 
after detecting and classifying an enemy plane as a potential threat  the lead commits to an
intercept  the lead immediately makes a number of course  speed  and altitude adjustments 
based on the tactical situation  these actions are evident in the figure by the pulse labeled
intercept  the lead spends most of the time in the intercept closing the distance between
the aircraft to get within weapon range  again having to maneuver very little and thus
requiring few actions in the environment  thus the relatively flat slope following intercept  
when the agent reaches missile range of the enemy plane  the lead executes a number of
actions very quickly  the lead steers the plane into a launch window for the missile  pushes
the fire button  waits for the missile to clear  and then determines a course to maintain
radar contact as the missile flies to its target  at launch missile   once the intercept has
been completed  the lead resumes its patrol task  again  it issues a large number of output
commands in a short period of time  these examples show that the leads reasoning focuses
primarily on reacting to discrete changes in the tactical situation  patrol leg ended  enemy
in range  etc   and the behavior generally requires little continuous adjustment 
the execution of the wings follow leader task  on the other hand  requires reaction to
continuous change in the leads position in order to maintain formation  position corrections
require observing the leads position  recognizing an undesired separation in the formation 
and then responding by adjusting speed  course  altitude  etc  because the wing is following
the lead throughout the scenario  it is executing this position maintenance knowledge almost
constantly  when the lead is flying straight and level  as on a patrol leg  the wings task does
not require the generation of many outputs  in figure     these periods of little activity
are evident in the periodic flat segments in the wings cumulative outputs  when the lead
begins a maneuver  e g   a turn   the wing must maintain the formation throughout the
maneuver  during a turn the wing generates many motor commands as it follows the lead 
because the turn takes a few seconds to complete  the outputs increase gradually over the
course of the turn  as can be seen in the figure  thus  the wing periodically encounters
a dynamic situation that requires significant reasoning and motor responses  further  the
response to this change is not discrete  as in the lead  but occurs continuously over the
course of the leads maneuver 
these differences in the tasks for the two agents account for the relatively large absolute
differences in the performance metrics between the lead and wing agents  because the wings
are adjusting their positions relative to the leads  they issue many more output commands
than the leads  which requires many more inferences to determine what those commands
should be 
decisions  the differences between decisions in the lead and wing is due to an artifact of
the data collection  the lead agents ran for an extra second after the wings halted in order
to initiate data collection 
production firings  in both the lead and wing agents  production firings decrease  however  the wings production firings decrease by      while in the lead  the decrease is only
     one reason for the large improvement in the dhj wing is due to the elimination of
some redundant output commands in the fhj agents  the fhj wing sometimes issues the
same motor command more than once  the reason for this duplication is that a specific motor command is computed locally  and is thus not available to other subtasks  in some cases 
two subtasks may issue the same motor command  when the command is stored locally  a
   

fiwray   laird

command may be issued again because the agent cannot recognize that the command has
already been issued by another subtask  because motor commands are remembered in the
top subtask by dhj agents  they can be inspected by all subtasks  the dhj wing thus
never issues a redundant motor command  the large relative decrease in outputs in the
wing agent from fhj to dhj  figure     can be attributed to this improvement  production firings decrease with the decrease in output activity because most reasoning activity
in the wing concerns reacting to the leads maneuvers 
in contrast to the wing  the leads average number of outputs actually increases  regeneration is the source of these additional outputs  in a few situations  a dhj agents
subtask for adjusting heading  speed or altitude can get updated repeatedly in a highly
dynamic situation  e g   a hard turn   the fhj agent uses subtask knowledge to decide if
the current output command needs to be updated  however  in dhj  the subtask may be
retracted due to dependence on a changing value  e g   current heading   when the subtask is regenerated following a retraction  the lead may generate a slightly different motor
command  for example  the lead might decide to turn to heading      instead of       
this decision causes the generation of a new output command that would not have been
re issued in fhj agents and accounts for the small increase in outputs  it also suggests
that without the self imposed constraint of the methodology  the knowledge base could be
further modified to avoid this regeneration and further decrease production firings 
although the large magnitude of the improvement in the wing is primarily due to remembering motor commands  both agents also needed less consistency knowledge and thus
accessed less knowledge while performing the same task  the agents perform the same tasks
using less knowledge 
cpu time  cpu time decreases in both the dhj lead and wing agents  the improvement
in the lead       is about half the improvement in the wing        these differences are due
primarily to the decrease in production firings  there are fewer production firings and thus
fewer instantiations to generate  leading to improvements in cpu time  match time also
improved  contributing to the overall performance improvement    the larger improvements
in cpu time as compared to production firings improvements      vs      in the lead 
    vs      in the wing  might be attributable to decreases in both the number of rule
firings and match time  again  these results offer no guarantee that match time will always
decrease with dhj  it is important to note  however  in two very different domains dhj
reduces total knowledge and further constrains the remaining knowledge  the architecture
then leveraged these small differences for improved overall performance 
      differences in responsiveness
because cpu time decreases in the dhj agents  responsiveness should generally improve 
however  because some agent knowledge has been split into several different subtasks  some
actions may not be initiated as quickly as would be initiated by the fhj agent  in this
section  we explore differences in responsiveness in one of these situations 
   as in the dynamic blocks world  these trends are based on a few observations of the data  rather than
a significant analysis  in particular  in tas  data for the number of tokens generated was not collected 
the results reported here are consistent with the expectation that the token activity falls in dhj agents 
as compared to fhj agents 

   

fiensuring consistency in hierarchical execution

fhj
dhj

avg  in range time
 sec 
       
       

avg  launch time
 sec 
       
       

reaction time
 sec 
    
    

n
  
  

table    a comparison of average reaction times for launching a missile in tas 
when an enemy plane comes in range  the agent executes a series of actions  leading to
the firing of a missile  reaction time is the difference between the time at which an enemy
agent comes in range and the time when the agent actually pushes the fire button to launch
a missile  this reaction time is one measure of the agents responsiveness  as table   shows 
the fhj agent is able to launch the missile in just over a quarter of a second  however 
the dhj agent is about three and a half times slower than the fhj agent in launching the
missile  taking almost a full second  on average 
split subtasks  regeneration  and subtask selection all contribute to the increase in
reaction time  splitting a subtask with n steps  which may have all been executed in a
single decision previously  may now take n decisions in the dhj agent  only a few actions
are necessary for launching a missile so one would expect an increase of  at most  a few
hundred milliseconds for this change  however  by dividing subtasks into separate steps 
the sequential series of actions can be interrupted  in particular  a number of regenerations
occur under the launch missile subtask as the agent prepares to fire the missile in a highly
dynamic situation  the agent sometimes chooses to undertake a similar action because the
situation has changed enough that a slightly different action might be necessary  as described
above  the result is that the dhj agents are taking more accurate aim than the fhj agents 
as they are responding more quickly to the dynamics of the environment  this aiming 
however takes more time  although the increase in time is not tactically significant  i e  
enemy planes were not escaping that were previously hit by fhj agents  
some additional re engineering of the knowledge would improve the reaction time  e g  
as described in section         however  decreases in responsiveness will be difficult to avoid 
in general  dynamic hierarchical justification requires that subtasks with different dependencies be initiated and terminated separately  or risk unnecessary regeneration  however 
by splitting complex tasks into separate subtasks  individual actions are delayed both because the subtasks are now separate procedures  and because the selection for a particular
subtask in the series can be postponed when additional subtask choices are available 
    summary of empirical evaluations
figure    summarizes results from the dynamic blocks world and tas  in both domains 
dhj agents require fewer total productions  suggesting a decrease in knowledge cost  performance is roughly the same in the dynamic blocks world and for the lead agents in tas 
the dhj wing agents show a much greater improvement in overall performance  which is due
both to dhj and to changes in knowledge  these results suggest that dynamic hierarchical
justification can be expected to reduce engineering effort and not degrade performance in
a variety of domains  simple and complex  however  response time in some situations may
decrease 
   

fiwray   laird

   
   

productions

   
   
   
fhj lead
fhj wing
fhj dbw

   

dhj lead
dhj wing
dhj dbw

 
 

 

 

 

 

  

  

  

  

  

cpu time  sec 

figure     mean cpu time vs  knowledge in productions for fhj  black  and dhj  gray 
agents in the dynamic blocks world and tas  the graph includes the actual
distribution of cpu time for each agent as well as the mean for each agent 
means for the dynamic blocks world agents are illustrated with squares  tas
lead agents with triangles  and tas wing agents with diamonds 

   discussion
solutions other than kbac and the new solutions introduced here can be developed for
the inconsistency problem  wray         we briefly introduce a few additional solutions 
and also consider the relationship of dynamic hierarchical justification to intention reconsideration in belief desire intention agents and belief revision 
    other solutions to inconsistency across the hierarchy
in this section  we review other existing architectural solutions to the problem of inconsistency arising from persistence in a hierarchy of assertions 
      limiting persistence
one obvious approach to eliminating inconsistency arising from persistence is to disallow
persistent assumptions altogether  this approach was adopted in theo  mitchell et al  
       all reasoning in theo is entailed from sensors  only perceptual inputs are unjustified 
theo cannot reason non monotonically about any particular world state  only the world can
change non monotonically  thus  theo cannot generally remember previous inputs 
   

fiensuring consistency in hierarchical execution

another possible limitation would be to restrict all assumptions to a single memory
 global state   or  equivalently  allow assumptions only in the root level of the hierarchy
in a hierarchical architecture  this solution ensures that the hierarchical context is always
consistent  all assertions within an associated subtask are entailments  and also allows
persistence  because htn execution systems such as retsina and decaf  mentioned
previously  have only a global state  they obviously do not suffer from inconsistency over
a hierarchy  however  the interactions between persistent assertions and new information
derived from sensors will be a problem in systems with global state 
retsina has recently adopted rationale based monitoring  veloso  pollack    cox 
      to identify environmental changes that could impact a currently executing task network  paolucci et al          rationale based monitoring uses the structure of plan knowledge  in this case  plan operators  including task networks  to alleviate inconsistency  monitors for relevant world features are created dynamically as planning progresses by identifying
pre conditions in operators and instantiating them via a straightforward taxonomy of monitor types  e g   a monitor for quantified conditions   the collection of monitors form a plan
rationale  reasons that support a planners decisions  veloso et al          plan rationales
are thus similar to the justifications used in truth maintenance  monitors are activated
when a pre condition element in the world changes  they then inform the planner of the
change  and the planner can then deliberate about whether the change should impact the
plan under construction and  if so  consider appropriate repairs 
rationale based monitoring is similar to dynamic hierarchical justification  especially
because they both leverage the structures of their  different  underlying task representations to provide consistency  however  there are two important differences  first  because
dhj identifies the specific subtask impacted by a change  it does not require deliberation
to determine the impact of the change  immediate return to a consistent knowledge state
is possible  when a monitor is activated in rationale based monitoring  the planner must
first determine where and how the plan is affected  which can require deliberation  second 
because monitors trigger deliberation  rather than automatically retracting reasoning  an
agent using rationale based monitoring can determine if the plan should be repaired and
how  dhj  as implemented  does not offer this flexibility  retraction is automatic  automatic retraction assumes the cost of retrieving  or regenerating  pre existing plan knowledge
is less costly than deliberation to determine if how the plan can be revised  because plan
modification can be as expensive as plan generation  nebel   koehler         this assumption is reasonable  however  invoking a deliberate revision process could circumvent
potential problems arising from recovery from interruption  section        
      fixed hierarchical justification
as mentioned previously  both the pre dhj version of soar and the procedural reasoning
system  prs   georgeff   lansky        use fixed hierarchical justification to retract
complete levels of the hierarchy when the support set no longer holds  in prs  the support
set consists of a set of context elements that must hold during the execution of the subtask 
these elements are defined by a knowledge engineer  fixed hierarchical justification offers a
complete solution to the inconsistency problem if context references within the reasoning in
a subtask are limited to the support set  this approach guarantees consistency  however 
   

fiwray   laird

it requires that the knowledge designer identify all potentially relevant features used in
reasoning within the subtask  additionally  the resulting system may be overly sensitive
to the features in the support set if those features only rarely impact reasoning  leading to
unnecessary regeneration 
fixed hierarchical justification requires less explicit consistency knowledge than knowledgebased solutions  however  kbac knowledge is still required if access to the whole task hierarchy is possible  thus  an agents ability to make subtask specific reactions to unexpected
changes in the environment is limited by the knowledge designers ability to anticipate and
explicitly encode the consequences of those changes 
    intention reconsideration
in the belief desire intention  bdi  model of agency  an intention represents a commitment
to achieving a goal  rao   georgeff        wooldridge         an intention is thus similar
to the instantiation of a subtask in a hierarchical architecture 
dynamic hierarchical justification can be viewed as a partial implementation of intention reconsideration  schut   wooldridge               intention reconsideration is the
process of determining when an agent should abandon its intentions  due to goal achievement  recognition of failure  or recognition that the intention itself is no longer desired  
dynamic hierarchical justification is only a partial implementation of intention reconsideration because it is only able to capture syntactic features of the problem solving  i e  
the identification of dependencies via the support set  to determine when to reconsider an
intention  situations that require deliberation to determine that an intention should be
abandoned are not captured in dhj    schut   wooldridge        describe an initial attempt to allow the run time determination of reconsideration policies  an optimal policy
would maximize the likelihood that deliberate intention reconsideration actually leads to
abandoning an intention  i e   the agent reconsiders when reconsideration is necessary   in
contrast  dynamic hierarchical justification offers a low cost  always available  domain general process for abandoning intentions  but cannot automatically identify reconsiderations
requiring semantic analysis of the problem state 
in bdi models  agents can choose to execute their current action plans with or without
reconsidering their current intentions first  kinny and georgeff        showed that  in more
static domains  bold agents that never reconsider their intentions perform more effectively
than cautious agents that always reconsider before executing a plan step  the opposite
is true in highly dynamic domains  cautious agents out perform bold ones  both soar
and prs can be described as being cautious via fixed hierarchical justification  that is 
at each plan step  the architectures determine if elements in the support set remain asserted
before executing the step  fhj approaches are  in effect  more bold than they appear 
because they do not reconsider intentions when assertions have changed in the dependent
context  but not in the support set  dynamic hierarchical justification provides more
cautious agents  because it ensures that the agents reconsideration function takes into
account all context dependencies for subtask reasoning  from the perspective of intention
    dhj does not preclude deliberate reconsideration  however  soar  as the testbed for the exploration of
dhj  does not provide an architectural solution for deliberate reconsideration  thus  these situations
will be addressed through knowledge and the deliberative processes of the architecture 

   

fiensuring consistency in hierarchical execution

reconsideration  the problems introduced by more dynamic domains prompted us to explore
more cautious solutions 
the results of the empirical analysis were somewhat consistent with those of kinny  
georgeff  the cautious dhj agents performed better than less cautious fhj agents in
the highly dynamic tacair soar domain  in the dynamic blocks world  the performance
differences were more equivocal  in comparison to fhj the number of new intentions
increased with dynamic hierarchical justification  measured as soar decisions   while
there was a slight overall performance improvement with dhj  it was due to improvements
in the match time of productions  a soar specific measure that likely will not generalize
to other systems  these results suggest that dhj is possibly overly cautious in static
domains  however  because dynamic hierarchical justification did not present a significant
performance cost and unexpectedly played a constructive role in agent execution even in
the static domain  dhj seems warranted in both static and dynamic domains 
    belief revision
belief revision refers to the process of changing beliefs to accommodate newly acquired
information  the inconsistency problem is an example of the need for revision in asserted
beliefs  some change in the hierarchical context  deriving ultimately from perceived changes
in the world  leads to a situation in which a currently asserted assumption would not  necessarily  be regenerated if it were re derived  theories of belief revision identify functions
that can be used to update a belief set so that it remains consistent 
the best known theory of belief revision is the agm theory  alchourron  gardenfors 
  makinson        gardenfors               agm is a coherence theory  meaning that
changes to beliefs are determined based on mutual coherence with one another  this approach contrasts with the foundations approach  in which justifications  reasons  determine
when how to revise a belief set  obviously  dynamic hierarchical justification is an extension to the foundations approach to belief revision  however  as the foundations and
coherence approaches can be reconciled  doyle         in this section we explore the repercussions of dynamic hierarchical justification in the context of the agm theory of belief
revision 
in agm theory  when a new sentence is presented to a database of sentences representing
the current knowledge state  an agent is faced with the task of revising its knowledge base
via one of three processes  expansion  adding sentences to the knowledge base   contraction
 removing sentences from the knowledge base  and revision  a combination of expansions
and contractions   agm theory emphasizes making minimal changes to a knowledge base
and epistemic entrenchment  a notion of the usefulness of a sentence within the database 
agm theory prefers that sentences with high epistemic entrenchment  relative to other
sentences  are retained during revision 
comparing dynamic hierarchical justification to assumption justification suggests that
it is sometimes cheaper to remove a subtask  and all asserted beliefs associated with that
subtask  than it is to compute the minimal revision with assumption justification  in
the context of belief revision  this result is not surprising  since it has been shown that
computing a minimal revision to a knowledge base can be computationally harder than
deduction  eiter   gottlob         this theoretical result has led to applications that
   

fiwray   laird

compute belief updates via incremental derivations of a belief state  rather than via belief
revision  kurien   nayak        
the power of the heuristic approach used by dhj over the analytic solution follows from
the characteristics outlined in section        the hierarchical structure and organization of
the agent assertions and the efficiency of the underlying reasoning system to regenerate any
unnecessarily removed assertions  assumptions  persistent beliefs  are associated with particular subtasks in hierarchical architectures  a change in perception  an epistemic input 
leads to a revision  rather than determining the minimal revision  dhj uses a heuristic
that  in this context  says that persistent beliefs in a subtask have similar epistemic entrenchment to the subtask intention itself  in some cases  this heuristic will be incorrect 
leading to regeneration  but  when correct  it provides a much simpler mechanism for revision  gardenfors        anticipates such conclusions  suggesting that systems possessing
additional internal structure  as compared to the the relatively unstructured belief sets of
agm theory  may provide additional constraints for orderings of epistemic entrenchment 

   conclusion
the empirical results from both the dynamic blocks world and tas domains were consistent with expectations  knowledge engineering cost decreased and overall performance in
dhj was roughly the same  or slightly improved  in comparison to independently developed
fhj benchmarks  development cost decreases because the designer is freed from the task
of creating across level consistency knowledge  one drawback of dhj is that responsiveness
can degrade when regeneration occurs 
dhj has been incorporated into the currently released version of soar  soar    for over
  years and the experience of users further confirms that development cost decreases  it
is partly true that developers need a deeper understanding of the architecture to realize
this benefit  however  dhj removes the need for the encoding of across level consistency
knowledge  which has proven difficult to understand and encode in many systems  dhj also
makes understanding the role of assumptions in soar systems more straightforward  by imposing design and development constraints  for instance  the knowledge designer must now
think about why  when  and where persistence should be used in the agent  once the knowledge designer determines the functional role of some persistent assumption  dhj guides the
development of the knowledge necessary for that assumption  for a nonmonotonic or hypothetical assumption  no knowledge must be created that looks outside the subtask in
order to ensure consistency  i e   no across level knowledge is necessary   assumptions for
remembering must be asserted in the root level of the hierarchy  and knowledge must be
created to manage the remembered assumption  functions of the root task now include
monitoring  updating  and removing remembered assumptions  we are developing domaingeneral methods for managing these remembered assumptions to further reduce cost   thus 
while dhj does increase the complexity of the architecture  it makes design decisions more
explicit and manageable than previous kbac approaches 
regeneration  seemingly one of the drawbacks of dhj  also contributes to decreased
knowledge development costs  regeneration serves as a debugging tool  allowing immediate
localization of problem areas in the domain knowledge  and its specific decomposition  
this debugging aid contrasts with previous knowledge development in which inconsistency
   

fiensuring consistency in hierarchical execution

often became evident only in irrational behavior  making it often difficult to determine the
actual source of a problem  thus  in addition to reducing total knowledge necessary for
some task  dynamic hierarchical justification might also reduce the cost per knowledge
unit when creating agent knowledge by localizing problems via regeneration  however  if
it is the case that some domain cannot be decomposed into nearly decomposable subunits 
regeneration could be debilitating 
another positive consequence of dhj is that an agent may behave more robustly in novel
situations not anticipated by the knowledge engineer  for example  as a simple experiment 
the fhj and dhj dynamic blocks world agents were placed in the situation described in
figure    the fhj agent fails when the block moves because it lacks knowledge to recognize
moving blocks  the knowledge designer assumed a static domain  with the same knowledge 
however  the dhj agent responds to this situation gracefully  in the specific situation
in figure    the dhj agent immediately retracts the put on table    subtask  because
block   is on the table  and thus the selection of that subtask is no longer consistent with
the current situation  the agent then chooses stack      and decomposes this subtask
into actions to put block   on block    if a new block  e g   block    is placed in the
empty space below block    the architecture responds by retracting the subtask goal for
put down     i e   the subtask that contains the empty assumption   it then begins to search
for empty spaces in order to continue its attempt to put block   on the table  because the
architecture  rather than agent knowledge  ensures consistency across the hierarchy  dhj
agents should be less brittle in situations not explicitly anticipated in agent design 
dhj also provides a solution to the problem of learning rules with non contemporaneous
constraints  wray  laird    jones         non contemporaneous constraints arise when
temporally distinct assertions  e g   red light  green light  are collected in a single learned
rule via knowledge compilation  a rule with non contemporaneous constraints will not lead
to inappropriate behavior but rather will never apply  this problem makes it difficult to
use straightforward explanation based learning approaches to operationalize agent execution
knowledge  non contemporaneous constraints arise when the architecture creates persistent
assumptions that can become inconsistent with the hierarchical context  wray et al         
because dhj never allows such inconsistency  it solves the non contemporaneous problem 
for instance  agents in both the dynamic blocks world and tas were able to learn
unproblematically in the new architecture  with no little knowledge re design  wray       
provides additional details and an empirical assessment of the learning 
dynamic hierarchical justification operates at a higher level of granularity than assumption justification or knowledge based solution methods  trading fine grained consistency for lower computational cost  this higher level of abstraction does introduce additional cost in execution  in particular  necessary regeneration led to some redundancy in
knowledge search in both the dynamic blocks world and tas agents  although overall efficiency improved  some of the improvement was due to improvements in the average
match cost of productions  which cannot be guaranteed in all domains or in other architectures  further  dynamic hierarchical justification requires that complex subtasks be
split into distinct subtasks  this requirement improves the knowledge decomposition and
reduces regeneration in performance but can reduce responsiveness  however  with the
straightforward compilation of reasoning in subtasks that dhj enables  the reduction in
responsiveness can be overcome with learning  wray        
   

fiwray   laird

although the implementation and evaluation of dhj was limited to soar  we attempted
to reduce the specificity of the results to soar in two ways  first  we identified the problems that across level consistency knowledge introduces in knowledge based approaches  it
is expensive to develop  degrades the modularity and simplicity of the hierarchical representation  and is only as robust as the knowledge designers imagination  when agents are
developed in sufficiently complex domains  the expense of creating this knowledge will grow
prohibitive  this cost may lead additional researchers to consider architectural assurances
of consistency  second  dynamic hierarchical justification gains its power via the structure
of hierarchically decomposed tasks  although specific implementations may differ for other
agent architectures  the heuristic simplifications employed by dhj should transfer to any
architecture utilizing a hierarchical organization of memory for task decomposition  dynamic hierarchical justification is an efficient  architectural solution that ensures reasoning
consistency across the hierarchy in agents employing hierarchical task decompositions  this
solution allows agents to act more reliably in complex  dynamic environments while more
fully realizing low cost agent development via hierarchical task decomposition 

acknowledgments
this work would not have been possible without those who contributed directly to the
development and evaluation of dynamic hierarchical justification  scott huffman  john
laird and mark portelli implemented assumption justification in soar  ron chong implemented a precursor to dhj  randy jones  john laird  and frank koss developed tacairsoar  sayan bhattacharyya  randy jones  doug pearson  peter wiemer hastings  and
other members of the soar group at the university of michigan contributed to the development of the dynamic blocks world simulator  the anonymous reviewers provided valuable 
constructive comments on earlier versions of the manuscript  this work was supported in
part by a university of michigan rackham graduate school pre doctoral fellowship  contract n         k      from the advanced systems technology office of darpa and
nrl  and contract n    i    c      from the advanced systems technology office of
darpa and the naval command and ocean surveillance center  rdt e division  portions of this work were presented at the    th national conference on artificial intelligence
in madison  wisconsin 

appendix a  improving task decompositions
this appendix describes in detail the changes that were made to the tas agent knowledge
for dhj 
remembering  figure   showed an agent computing a new heading as a subtask of the
achieve proximity subtask  this calculation usually depends upon the current heading 
when the agent generates the command to turn  the heading changes soon thereafter  in
this situation  the dhj agent must remember that it has already made a decision to turn
to a new heading by placing the assumption that reflects the new heading in the top level 
if it places the assumption in the local level  then the new current heading will trigger the
removal of turn to heading and then regeneration of the subtask  if the agent determines
that it still needs to turn to some new heading  
   

fiensuring consistency in hierarchical execution

in the fhj agents  all output commands  such as turn to some specific heading  were
asserted as assumptions in the local subtask  the dhj agents knowledge was changed to
issue output commands directly to the output interface  which  in soar  is always part of
the highest subtask in the hierarchy   no unnecessary regeneration now occurs because
the agent remembers all motor commands and generates a new one only when a different
output is necessary  this change  of course  requires consistency knowledge because the
motor commands are unjustified and thus must be explicitly removed  as is true for any
remembered knowledge with dhj 
within level consistency knowledge  dynamic hierarchical justification  like all solutions to the across level consistency problem  still requires consistency knowledge within
an individual subtask  some of this knowledge in the fhj agents is used to remove intermediate results in the execution of a subtask  this clean up knowledge allows the agent
to remove local assertions that contributed to some terminating subtask and thus avoid the
 mis use of these assertions in later reasoning 
as an example  consider the achieve proximity subtask  this subtask is used in
a number of different situations when an agent needs to get closer to another agent  if
the wing strays too far from the lead  it may invoke achieve proximity to get back into
formation with the lead  the lead uses achieve proximity to get close enough to an enemy
aircraft to launch a missile  the subtask requires many local computations as the agent
reasons about what heading it should take to get closer to another aircraft  the specific
computation depends on what information is available about the other aircraft  when the
wing is pursuing the lead  it may know the leads heading and thus calculate a collision
course to maximize the rate of convergence  sometimes the other agents heading is not
available  in this case  the agent simply moves toward the current location of the other agent 
these local computations are stored in the local subtask  when achieve proximity is
terminated in the fhj agent  the agent removes the local structure  removing the structure
is important both because it interrupts entailment of the local structure  e g   calculation of
the current collision course  and guarantees that if the agent decides to achieve proximity
with a different aircraft  supporting data structures are properly initialized  this knowledge
thus maintains consistency in the local subtask by removing the local structure when the
achieve proximity subtask is no longer selected 
the fhj agent could recognize when it was going to remove a subtask  the termination
conditions in fhj agents acted as a signal to the within level consistency knowledge  the
knowledge that removes the local structure for achieve proximity can be summarized as 
if the achieve proximity operator is selected  but its initiation conditions no longer hold 
then remove the local achieve proximity data structure  thus  the fhj agent uses a
recognition of an inconsistency in the assertions to trigger the activation of this within level
consistency knowledge 
when the subtasks initiating conditions are no longer supported in the dhj agents  the
selected subtask is removed immediately  thus  the dhj agent never has the opportunity
to apply the fhj agents within level consistency knowledge  the failure to utilize this
knowledge led to a number of problems  including more regenerations than expected 
to solve this problem  the local subtask data structure was created as an entailment of
the initiation conditions of the subtask itself  when the subtask initiation conditions no
longer held  both the subtask selection and the local structure are immediately removed by
   

fiwray   laird

the architecture  requiring no additional knowledge  thus  this change obviated the need
for some within level consistency knowledge  however  the local data structure may need
to be regenerated if a subtask is temporarily displaced  for instance  the fhj within level
consistency knowledge could determine under what conditions the local structure should be
removed  the dhj solution has lost that flexibility 
subtasks with complex actions  fhj agents can execute a number of actions in rapid
succession  regardless of any inconsistency in the local assertions  a single subtask operator
can be initiated in a situation representing the conditions under which to apply the first
action in a sequence  and terminated when the last step in the sequence has applied  if
some intermediate step invalidates the initiation conditions  the subtask still executes the
actions 
consider the process of launching a missile  an actual missile launch requires only
the push of a button  assuming that previous steps such as selecting the target and an
appropriate missile have been accomplished beforehand  after pushing the fire button  the
pilot must fly straight and level for a few seconds while the missile rockets ignite and launch
the missile into flight  once the missile has cleared the aircraft  the agent supports the
missile by keeping radar contact with the target  in fhj agents  the push fire button
subtask includes both the act of pushing the fire button and counting while the missile clears
the aircraft  these tasks have different and mutually exclusive dependencies  the initiation
condition for push fire button requires that no missile is already launched  however  the
subsequent counting requires monitoring the newly launched missile 
dhj agents using the fhj knowledge base always remove the push fire button subtask as soon as the missile is perceived to be in the air  interrupting the complete procedure 
regeneration of the push fire button subtask occurs because the agent never waits for the
missile to clear and thus never realizes that the missile just launched needs to be supported 
the dhj agent unsuccessfully fires all available missiles at the enemy plane 
pushing the fire button and waiting for the missile to clear are independent tasks
which happen to arise in serial order in the domain  we enforced this independence by
creating a new subtask  wait for missile to clear  which depends only on having a
newly launched missile in the air  the dhj agent now pushes the fire button  selects
wait for missile to clear to count a few seconds before taking any other action  and
then supports the missile if it clears successfully 
this solution reduces regeneration and improves behavior quality but it does have a
non trivial cost  whenever a subtask is split  the effects of subtask actions no longer occur
in rapid succession within a decision  instead  the effect of the first subtask occurs in one
decision  the effect of the second subtask in the second decision  etc  thus  this solution
can compromise responsiveness 

references
agre  p  e     horswill  i          lifeworld analysis  journal of artificial intelligence
research            
alchourron  c  e   gardenfors  p     makinson  d          on the logic of theory change 
partial meet contraction and revision functions  journal of symbolic logic         
       
   

fiensuring consistency in hierarchical execution

allen  j  f          time and time again  international journal of intelligent systems 
              
altmann  e  m     gray  w  d          forgetting to remember  the functional relationship
of decay and interference  psychological science           
bresina  j   drummond  m     kedar  s          reactive  integrated systems pose new
problems for machine learning  in minton  s   ed    machine learning methods for
planning  pp          morgan kaufmann  san francisco  ca 
dechter  r          enhancement schemes for constraint processing  backjumping  learning
and cutset decomposition  artificial intelligence             
doyle  j          a truth maintenance system  artificial intelligence             
doyle  j          reason maintenance and belief revision  in gardenfors  p   ed    belief
revision  pp        cambridge university press  cambridge  uk 
eiter  t     gottlob  g          on the complexity of propositional knowledge base revision 
updates  and counterfactuals  artificial intelligence             
erol  k   hendler  j     nau  d  s          htn planning  complexity and expressivity  in
proceedings of the   th national conference on artificial intelligence  pp           
firby  r  j          an investigation into reactive planning in complex domains  in proceedings of the  th national conference on artificial intelligence  pp         
forbus  k  d     dekleer  j          building problem solvers  mit press  cambridge 
ma 
forgy  c  l          on the efficient implementation of production systems  ph d  thesis 
computer science department  carnegie mellon university 
gardenfors  p          knowledge in flux  modeling the dynamics of epistemic states 
mit press  cambridge  ma 
gardenfors  p          belief revision  in pettorossi  a   ed    meta programming in logic 
springer verlag  berlin  germany 
gaschnig  j          performance measurement and analysis of certain search algorithms 
tech  rep  cmu cs         computer science department  carnegie mellon university  pittsburgh  pennsylvania 
gat  e       a   integrating planning and reacting in a heterogeneous asynchronous architecture for mobile robots  sigart bulletin          
gat  e       b   reliable  goal directed control of autonomous mobile robots  ph d 
thesis  virginia polytechnic institute and state university  blacksburg  va 
georgeff  m     lansky  a  l          reactive reasoning and planning  in proceedings of
the  th national conference on artificial intelligence  pp         
graham  j     decker  k          towards a distributed  environment centered agent framework  in wooldridge  m     lesperance  y   eds    lecture notes in artificial intelligence  agent theories  architectures  and languages vi  atal      springer verlag 
berlin 
   

fiwray   laird

hanks  s   pollack  m     cohen  p  r          benchmarks  test beds  controlled experimentation and the design of agent architectures  ai magazine           
hayes roth  b          an architecture for adaptive intelligent systems  in workshop on
innovative approaches to planning  scheduling and control  pp         
jones  r  m   laird  j  e   neilsen  p  e   coulter  k  j   kenny  p     koss  f  v         
automated intelligent pilots for combat flight simulation  ai magazine               
kinny  d     georgeff  m          commitment and effectiveness of situated agents  in
proceedings of the   th international joint conference on artificial intelligence  pp 
     
kurien  j     nayak  p  p          back to the future for consistency based trajectory
tracking  in proceedings of the   th national conference on artificial intelligence 
pp         
laird  j  e          it knows what you are going to do  adding anticipation to a quakebot 
in proceedings of the  th international conference on autonomous agents  pp     
    
laird  j  e   congdon  c  b     coulter  k  j          soar users manual version     
manual  department of electrical engineering and computer science  university of
michigan  http   ai eecs umiuch edu soar docs html 
laird  j  e   newell  a     rosenbloom  p  s          soar  an architecture for general
intelligence  artificial intelligence          
laird  j  e     rosenbloom  p  s          integrating execution  planning  and learning
in soar for external environments  in proceedings of the   th national conference on
artificial intelligence  pp           
laird  j  e     rosenbloom  p  s          the evolution of the soar cognitive architecture 
in steier  d     mitchell  t   eds    mind matters  contributions to cognitive and
computer science in honor of allen newell  lawrence erlbaum associates  hillsdale 
nj 
mcdermott  d          a general framework for reason maintenance  artificial intelligence 
           
mitchell  t  m   allen  j   chalasani  p   cheng  j   etzioni  o   ringuette  m     schlimmer 
j  c          theo  a framework for self improving systems  in vanlehn  k   ed   
architectures for intelligence  chap      pp          lawrence erlbaum associates 
hillsdale  nj 
mitchell  t  m          becoming increasingly reactive  in proceedings of the   th national
conference on artificial intelligence  pp           
nebel  b     koehler  j          plan reuse versus plan generation  a theoretical and
empirical analysis  artificial intelligence             
newell  a          unified theories of cognition  harvard university press  cambridge 
ma 
   

fiensuring consistency in hierarchical execution

paolucci  m   shehory  o   sycara  k  p   kalp  d     pannu  a          a planning component for retsina agents  in wooldridge  m     lesperance  y   eds    lecture notes
in artificial intelligence  agent theories  architectures  and languages vi  atal     pp          berlin  springer verlag 
pearson  d  j   huffman  s  b   willis  m  b   laird  j  e     jones  r  m          a
symbolic solution to intelligent real time control  robotics and autonomous systems 
           
rao  a  s     georgeff  m  p          modeling rational agents within a bdi architecture 
in proceedings of the  nd international conference on principles of knowledge representation and reasoning  pp         
russell  s     norvig  p          artificial intelligence  a modern approach  prentice hall 
upper saddle river  nj 
sacerdoti  e  d          the nonlinear nature of plans  in proceedings of the   th international joint conference on artificial intelligence  pp         
schut  m     wooldridge  m          intention reconsideration in complex environments  in
proceedings of the  th international conference on autonomous agents  pp         
schut  m     wooldridge  m          principles of intention reconsideration  in proceedings
of the  th international conference on autonomous agents  pp         
shoham  y          agent oriented programming  artificial intelligence               
simon  h  a          the sciences of the artificial  mit press  cambridge  ma 
stallman  r  m     sussman  g  j          forward reasoning and dependency directed
backtracking in a system for computer aided circuit analysis  artificial intelligence 
              
sycara  k   decker  k   pannu  a   williamson  m     zeng  d          distributed intelligent agents  ieee expert               
tambe  m          eliminating combinatorics from production match  ph d  thesis 
carnegie mellon university   also published as technical report cmu cs        
computer science department  carnegie mellon university   
tambe  m   johnson  w  l   jones  r  m   koss  f   laird  j  e   rosenbloom  p  s    
schwamb  k          intelligent agents for interactive simulation environments  ai
magazine               
veloso  m  m   pollack  m  e     cox  m  t          rationale based monitoring for planning in dynamic environments  in proceedings of the   th international conference on
artificial intelligence planning systems  pp         
wilkins  d  e   myers  k  l   lowrance  j  d     wesley  l  p          planning and reacting
in uncertain and dynamic environments  journal of experimental and theoretical
artificial intelligence                
wooldridge  m          reasoning about rational agents  mit press  cambridge  ma 
wray  r  e          ensuring reasoning consistency in hierarchical architectures  ph d 
thesis  university of michigan  also published as university of michigan technical
report cse tr        
   

fiwray   laird

wray  r  e     laird  j          maintaining consistency in hierarchical reasoning  in
proceedings of the   th national conference on artificial intelligence  pp         
wray  r  e   laird  j     jones  r  m          compilation of non contemporaneous constraints  in proceedings of the   th national conference on artificial intelligence  pp 
       
wray  r  e   laird  j  e   nuxoll  a     jones  r  m          intelligent opponents for virtual
reality trainers  in proceedings of the interservice industry training  simulation and
education conference  i itsec       

   

fi