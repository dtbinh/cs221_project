journal artificial intelligence research                  

submitted       published      

efficient solution algorithms factored mdps
carlos guestrin

guestrin cs stanford edu

computer science dept   stanford university

daphne koller

koller cs stanford edu

computer science dept   stanford university

ronald parr

parr cs duke edu

computer science dept   duke university

shobha venkataraman

shobha cs cmu edu

computer science dept   carnegie mellon university

abstract
paper addresses problem planning uncertainty large markov decision
processes  mdps   factored mdps represent complex state space using state variables
transition model using dynamic bayesian network  representation often allows
exponential reduction representation size structured mdps  complexity exact
solution algorithms mdps grow exponentially representation size  paper 
present two approximate solution algorithms exploit structure factored mdps 
use approximate value function represented linear combination basis functions 
basis function involves small subset domain variables  key contribution
paper shows basic operations algorithms performed efficiently
closed form  exploiting additive context specific structure factored mdp 
central element algorithms novel linear program decomposition technique  analogous
variable elimination bayesian networks  reduces exponentially large lp provably
equivalent  polynomial sized one  one algorithm uses approximate linear programming 
second approximate dynamic programming  dynamic programming algorithm novel
uses approximation based max norm  technique directly minimizes terms
appear error bounds approximate mdp algorithms  provide experimental results
problems      states  demonstrating promising indication scalability
approach  compare algorithm existing state of the art approach  showing 
problems  exponential gains computation time 

   introduction
last years  markov decision processes  mdps  used basic
semantics optimal planning decision theoretic agents stochastic environments 
mdp framework  system modeled via set states evolve stochastically 
main problem representation that  virtually real life domain 
state space quite large  however  many large mdps significant internal structure 
modeled compactly structure exploited representation 
factored mdps  boutilier  dearden    goldszmidt        one approach representing large  structured mdps compactly  framework  state implicitly described
assignment set state variables  dynamic bayesian network  dbn   dean
  kanazawa        allow compact representation transition model 
exploiting fact transition variable often depends small number
c
    
ai access foundation morgan kaufmann publishers  rights reserved 

figuestrin  koller  parr   venkataraman

variables  furthermore  momentary rewards often decomposed
sum rewards related individual variables small clusters variables 
two main types structure simultaneously exploited factored
mdps  additive context specific structure  additive structure captures fact
typical large scale systems often decomposed combination locally interacting components  example  consider management large factory many
production cells  course  long run  cell positioned early production line
generates faulty parts  whole factory may affected  however  quality
parts cell generates depends directly state cell quality
parts receives neighboring cells  additive structure present
reward function  example  cost running factory depends  among things 
sum costs maintaining local cell 
context specific structure encodes different type locality influence  although
part large system may  general  influenced state every part
system  given point time small number parts may influence directly 
factory example  cell responsible anodization may receive parts directly
cell factory  however  work order cylindrical part may restrict
dependency cells lathe  thus  context producing cylindrical
parts  quality anodized parts depends directly state cells
lathe 
even large mdp represented compactly  example  using factored
representation  solving exactly may still intractable  typical exact mdp solution algorithms require manipulation value function  whose representation linear
number states  exponential number state variables  one approach
approximate solution using approximate value function compact representation  common choice use linear value functions approximation value
functions linear combination potentially non linear basis functions  bellman 
kalaba    kotkin        sutton        tsitsiklis   van roy      b   work builds
ideas koller parr               using factored  linear  value functions 
basis function restricted small subset domain variables 
paper presents two new algorithms computing linear value function approximations factored mdps  one uses approximate dynamic programming another
uses approximate linear programming  algorithms based use factored linear value functions  highly expressive function approximation method 
representation allows algorithms take advantage additive context specific
structure  order produce high quality approximate solutions efficiently  capability exploit types structure distinguishes algorithms differ earlier
approaches  boutilier et al          exploit context specific structure  provide
detailed discussion differences section    
show that  factored mdp factored value functions  various critical operations planning algorithms implemented closed form without necessarily
enumerating entire state space  particular  new algorithms build upon
novel linear programming decomposition technique  technique reduces structured lps
exponentially many constraints equivalent  polynomially sized ones  decomposition follows procedure analogous variable elimination applies additively
   

fiefficient solution algorithms factored mdps

structured value functions  bertele   brioschi        value functions exploit context specific structure  zhang   poole         using basic operations 
planning algorithms implemented efficiently  even though size state space
grows exponentially number variables 
first method based approximate linear programming algorithm  schweitzer
  seidmann         algorithm generates linear  approximate value function
solving single linear program  unfortunately  number constraints lp proposed
schweitzer seidmann grows exponentially number variables  using lp
decomposition technique  exploit structure factored mdps represent exactly
optimization problem exponentially fewer constraints 
terms approximate dynamic programming  paper makes twofold contribution 
first  provide new approach approximately solving mdps using linear value
function  previous approaches linear function approximation typically utilized
least squares  l   norm  approximation value function  least squares approximations
incompatible convergence analyses mdps  based max norm 
provide first mdp solution algorithms value iteration policy iteration
use linear max norm projection approximate value function  thereby directly
optimizing quantity appears provided error bounds  second  show
exploit structure problem apply technique factored mdps 
leveraging lp decomposition technique 
although approximate dynamic programming currently possesses stronger theoretical
guarantees  experimental results suggest approximate linear programming
good alternative  whereas former tends generate better policies set
basis functions  due simplicity computational advantages approximate linear
programming  add basis functions  obtaining better policy still requiring
less computation approximate dynamic programming approach 
finally  present experimental results comparing approach work boutilier
et al          illustrating tradeoffs two methods  particular 
problems significant context specific structure value function  approach
faster due efficient handling value function representation  however 
cases significant context specific structure problem  rather
value function  algorithm requires exponentially large value function
representation  classes problems  demonstrate using value function exploits additive context specific structure  algorithm obtain
polynomial time near optimal approximation true value function 
paper starts presentation factored mdps approximate solution algorithms mdps  section    describe basic operations used algorithms 
including lp decomposition technique  section    present first two
algorithms  approximate linear programming algorithm factored mdps  second
algorithm  approximate policy iteration max norm projection  presented section   
section   describes approach efficiently computing bounds policy quality based
bellman error  section   shows extend methods deal context specific
structure  paper concludes empirical evaluation section   discussion
related work section    
   

figuestrin  koller  parr   venkataraman

paper greatly expanded version work published guestrin
et al       a   work presented guestrin et al       b        

   factored markov decision processes
markov decision process  mdp  mathematical framework sequential decision
problems stochastic domains  thus provides underlying semantics task
planning uncertainty  begin concise overview mdp framework 
describe representation factored mdps 
    markov decision processes
briefly review mdp framework  referring reader books bertsekas
tsitsiklis        puterman        in depth review  markov decision process
 mdp  defined   tuple  x  a  r  p   where  x finite set  x    n states 
finite set actions  r reward function r   x   r  r x  a  represents
reward obtained agent state x taking action a  p markovian
transition model p  x    x  a  represents probability going state x state
x  action a  assume rewards bounded  is  exists rmax
rmax  r x  a     x  a 
example     consider problem optimizing behavior system administrator
 sysadmin  maintaining network computers  network  machine
connected subset machines  various possible network topologies
defined manner  see figure   examples   one simple network  might
connect machines ring  machine connected machines         in
example  assume addition subtraction performed modulo m  
machine associated binary random variable xi   representing whether
working failed  every time step  sysadmin receives certain amount
money  reward  working machine  job sysadmin decide
machine reboot  thus      possible actions time step  reboot one
machines nothing  only one machine rebooted per time step   machine
rebooted  working high probability next time step  every machine
small probability failing time step  however  neighboring machine fails 
probability increases dramatically  failure probabilities define transition model
p  x    x  a   x particular assignment describing machines working
failed current time step  sysadmins choice machine reboot x 
resulting state next time step 
assume mdp infinite horizon future rewards discounted
exponentially discount factor         stationary policy mdp
mapping   x   a   x  action agent takes state x  computer
network problem  possible configuration working failing machines  policy
would tell sysadmin machine reboot  policy associated value
function v rn   v  x  discounted cumulative value agent gets
starts state x follows policy   precisely  value v state x
   

fiefficient solution algorithms factored mdps

server

server

star

bidirectional ring

ring star

server

  legs

ring rings

figure    network topologies tested  status machine influence status
parent network 

policy given by 
v  x    e

 
x





 t 

 t 

r x    x

t  


 

   
  x   x  


x t  random variable representing state system steps 
running example  value function represents much money sysadmin expects
collect starts acting according network state x  value function
fixed policy fixed point set linear equations define value
state terms value possible successor states  formally  define 
definition     dp operator    stationary policy is 
v x    r x   x    

x

p  x    x   x  v x    

x 

value function policy   v   fixed point operator  v   v  
optimal value function v describes optimal value agent achieve
starting state  v defined set non linear equations  case 
value state must maximal expected value achievable policy starting
state  precisely  define 
definition     bellman operator    is 
v x    max r x  a   


x

p  x    x  a v x     

x 

optimal value function v fixed point   v   v  
value function v  define policy obtained acting greedily relative
v  words  state  agent takes action maximizes one step
   

figuestrin  koller  parr   venkataraman

utility  assuming v represents long term utility achieved next state 
precisely  define 
greedy v  x    arg max r x  a   


x

p  x    x  a v x     

   

x 

greedy policy relative optimal value function v optimal policy  
greedy v   
    factored mdps
factored mdps representation language allows us exploit problem structure
represent exponentially large mdps compactly  idea representing large
mdp using factored model first proposed boutilier et al         
factored mdp  set states described via set random variables x  
 x            xn    xi takes values finite domain dom xi    state x
defines value xi dom xi   variable xi   general  use upper case letters
 e g   x  denote random variables  lower case  e g   x  denote values 
use boldface denote vectors variables  e g   x  values  x   instantiation
dom y  subset variables z y  use y z  denote value
variables z instantiation y 
factored mdp  define state transition model using dynamic bayesian
network  dbn   dean   kanazawa         let xi denote variable xi current
time xi    variable next step  transition graph dbn
two layer directed acyclic graph g whose nodes  x            xn   x             xn     denote
parents xi  graph parents  xi     simplicity exposition  assume
parents  xi    x  thus  arcs dbn variables consecutive
time slices   this assumption used expository purposes only  intra time slice arcs
handled small modification presented section       node xi  associated
conditional probability distribution  cpd  p  xi    parents  xi      transition
probability p  x    x  defined be 
p  x    x   



p  x i   ui    



ui value x variables parents  xi    
example     consider instance sysadmin problem four computers  labelled
m            m    unidirectional ring topology shown figure   a   first task
modeling problem factored mdp define state space x  machine
associated binary random variable xi   representing whether working
failed  thus  state space represented four random variables   x    x    x    x    
next task define transition model  represented dbn  parents
next time step variables xi  depend network topology  specifically  probability
machine fail next time step depends whether working current
time step status direct neighbors  parents topology  network
current time step  shown figure   b   parents xi  example xi
xi    cpd xi  xi   false  xi    false high probability 
   

fiefficient solution algorithms factored mdps

x 

x 
r

x 

m 

r

m 

m 

m 

 a 

 

x 
r

x 
r

 

 

p  xi      xi   xi    a  
h
 

h

 

x 

x 
h

 

x 
h

 

 b 

action reboot 
machine machine

 

xi 
xi
xi 
xi
xi 
xi
xi 
xi

 f
 f
 f
 t
 t
 f
 t
 t






 

      

 

     

 

      

 

    

 c 

figure    factored mdp example  network topology  a  obtain factored
mdp representation  b  cpds described  c  

is  failures tend persist  xi   true  xi  noisy parents  in
unidirectional ring topology xi  one parent xi     is  failure
neighbors independently cause machine fail 
described represent factored markovian transition dynamics arising
mdp dbn  directly addressed representation actions 
generally  define transition dynamics mdp defining separate dbn
model   hga   pa action a 
example     system administrator example  action ai rebooting
one machines  default action nothing  transition model
described corresponds nothing action  transition model ai
different transition model variable xi    xi    true
probability one  regardless status neighboring machines  figure   c  shows
actual cpd p  xi    w orking   xi   xi    a   one entry assignment
state variables xi xi    action a 
fully specify mdp  need provide compact representation reward
function  assume reward function factored additively set localized
reward functions  depends small set variables  example 
might reward function associated machine i  depends xi  
is  sysadmin paid per machine basis  every time step  receives money
machine working  formalize concept localized functions 
definition     function f scope scope f     c x f   dom c    r 
f scope z  use f  z  shorthand f  y  part
instantiation z corresponds variables y 
   

figuestrin  koller  parr   venkataraman

characterize concept local rewards  let r a           rra set
functions  scope ria restricted variable cluster uai  x            xn   
p
reward taking action state x defined ra  x    ri   ria  uai   r 
example  reward function ri associated machine i  depends
xi   depend action choice  local rewards represented
diamonds figure   b   usual notation influence diagrams  howard  
matheson        

   approximate solution algorithms
several algorithms compute optimal policy mdp  three
commonly used value iteration  policy iteration  linear programming  key component three algorithms computation value functions  defined section     
recall value function defines value state x state space 
explicit representation value function vector values different states 
solution algorithms implemented series simple algebraic steps  thus 
case  three implemented efficiently 
unfortunately  case factored mdps  state space exponential number
variables domain  sysadmin problem  example  state x system
assignment describing machines working failed  is  state x
assignment random variable xi   thus  number states exponential
number machines network   x    n    m    hence  even representing
explicit value function problems ten machines infeasible  one
might tempted believe factored transition dynamics rewards would result
factored value function  thereby represented compactly  unfortunately  even
trivial factored mdps  guarantee structure model preserved
value function  koller   parr        
section  discuss use approximate value function  admits
compact representation  describe approximate versions exact algorithms 
use approximate value functions  description section somewhat abstract 
specify basic operations required algorithms performed
explicitly  later sections  elaborate issues  describe algorithms
detail  brevity  choose focus policy iteration linear programming 
techniques easily extend value iteration 
    linear value functions
popular choice approximating value functions using linear regression  first
proposed bellman et al          here  define space allowable value functions
v h rn via set basis functions 
definition     linear value function set basis functions h    h            hk  
p
function v written v x    kj   wj hj  x  coefficients w  
 w            wk     
define h linear subspace rn spanned basis functions h 
useful define n k matrix h whose columns k basis functions viewed
   

fiefficient solution algorithms factored mdps

vectors  compact notation  approximate value function represented
hw 
expressive power linear representation equivalent  example 
single layer neural network features corresponding basis functions defining
h  features defined  must optimize coefficients w order obtain
good approximation true value function  view approach separating
problem defining reasonable space features induced space h 
problem searching within space  former problem typically purview
domain experts  latter focus analysis algorithmic design  clearly 
feature selection important issue essentially areas learning approximation 
offer simple methods selecting good features mdps section    
goal address large important topic paper 
chosen linear value function representation set basis functions 
problem becomes one finding values weights w hw yield
good approximation true value function  paper  consider two
approaches  approximate dynamic programming using policy iteration approximate
linear programming  section  present two approaches  section   
show exploit problem structure transform approaches practical
algorithms deal exponentially large state spaces 
    policy iteration
      exact algorithm
exact policy iteration algorithm iterates policies  producing improved policy
iteration  starting initial policy       iteration consists two phases 
value determination computes  policy  t    value function v t    finding
fixed point equation t t  v t    v t    is  unique solution set linear
equations 
x
p  x    x   t   x  v t   x     x 
v t   x    r x   t   x    
x 

policy improvement step defines next policy
 t      greedy v t    
shown process converges optimal policy  bertsekas   tsitsiklis 
       furthermore  practice  convergence optimal policy often quick 
      approximate policy iteration
steps policy iteration algorithm require manipulation value functions
policies  often cannot represented explicitly large mdps  define
version policy iteration algorithm uses approximate value functions  use
following basic idea  restrict algorithm using value functions within
provided h  whenever algorithm takes step results value function v
outside space  project result back space finding value function
within space closest v  precisely 
   

figuestrin  koller  parr   venkataraman

definition     projection operator mapping   rn h  said
projection w r t  norm kk v   hw w arg minw khw vk 
is  v linear combination basis functions  closest v respect
chosen norm 
approximate policy iteration algorithm performs policy improvement step exactly  value determination step  value function value acting according
current policy  t  approximated linear combination basis functions 
consider problem value determination policy  t    point 
useful introduce notation  although rewards function state
action choice  policy fixed  rewards become function state
only  denote r t    r t   x    r x   t   x    similarly  transition
model  p t   x    x    p  x    x   t   x    rewrite value determination step
terms matrices vectors  view v t  r t  n  vectors  p t 
n n matrix  equations 
v t    r t    p t  v t   
system linear equations one equation state 
solved exactly relatively small n   goal provide approximate solution  within
h  precisely  want find 
w t    arg min khw  r t    p t  hw k  
w







  arg min  h p t  h  w t  r t   
w

thus  approximate policy iteration alternates two steps 
w t    arg min khw  r t    p t  hw k  
w

 t      greedy hw t    

   
   

      max norm projection
approach along lines described used various papers  several
recent theoretical algorithmic results  schweitzer   seidmann        tsitsiklis   van
roy      b  van roy        koller   parr               however  approaches suffer
problem might call norm incompatibility  computing projection 
utilize standard euclidean projection operator respect l  norm
weighted l  norm   hand  convergence error analyses mdp
algorithms utilize max norm  l    incompatibility made difficult provide
error guarantees 
tie projection operator closely error bounds use
projection operator l norm  problem minimizing l norm
studied optimization literature problem finding chebyshev solution 
   weighted l  norm projections stable meaningful error bounds weights correspond
stationary distribution fixed policy evaluation  value determination   van roy        
stable combined   averagers  gordon        stable non expansive
l   require mixture weights determined priori  thus  not  general 
minimize l error 
   chebyshev norm referred max  supremum l norms minimax solution 

   

fiefficient solution algorithms factored mdps

overdetermined linear system equations  cheney         problem defined
finding w that 
w arg min kcw bk  
   
w

use algorithm due stiefel         solves problem linear programming 
variables  w            wk    
minimize   
p
   
subject to  kj   cij wj bi
pk
bi j   cij wj         n 



p


constraints linear program imply kj   cij wj bi i 
equivalently  kcw bk   objective lp minimize   thus 
solution  w     linear program  w solution equation     l
projection error 
use l projection context approximate policy iteration
obvious way  implementing projection operation equation      use
l projection  as equation       c    h p t  h  b   r t   
minimization solved using linear program     
key point lp k     variables  however   n constraints 
makes impractical large state spaces  sysadmin problem  example 
number constraints lp exponential number machines network
 a total    m constraints machines   section    show that  factored mdps
linear value functions   n constraints represented efficiently  leading
tractable algorithm 
      error analysis
motivated use max norm projection within approximate policy iteration
algorithm via compatibility standard error analysis techniques mdp algorithms 
provide careful analysis impact l error introduced projection step  analysis provides motivation use projection step directly
minimizes quantity  acknowledge  however  main impact analysis
motivational  practice  cannot provide priori guarantees l projection
outperform methods 
goal analyze approximate policy iteration terms amount error
introduced step projection operation  error zero 
performing exact value determination  error accrue  error small 
get approximation accurate  result follows analysis below 
precisely  define projection error error resulting approximate
value determination step 








 t    hw t  r t    p t  hw t   


note that  using max norm projection  finding set weights w t 
exactly minimizes one step projection error  t    is  choosing best
   

figuestrin  koller  parr   venkataraman

possible weights respect error measure  furthermore  exactly error
measure going appear bounds theorem  thus  make
bounds step tight possible 
first show projection error accrued step bounded 
lemma     value determination error bounded  exists constant p rmax
p  t  iterations algorithm 
proof  see appendix a   
due contraction property bellman operator  overall accumulated error
decaying average projection error incurred throughout iterations 
definition     discounted value determination error iteration defined as 
 t  
   
 t   
      

 t 

 

lemma     implies accumulated error remains bounded approximate policy
 t 
    
iteration  p  
  bound loss incurred acting according
policy generated approximate policy iteration algorithm  opposed
optimal policy 
theorem     approximate policy iteration algorithm  let  t  policy generated
iteration t  furthermore  let v t  actual value acting according policy 
loss incurred using policy  t  opposed optimal policy value v
bounded by 
 t 
 



kv v t  k kv v    k  
 
   
     
proof  see appendix a   
words  equation     shows difference approximation iteration
optimal value function bounded sum two terms  first term
present standard policy iteration goes zero exponentially fast  second
discounted accumulated projection error and  lemma     shows  bounded  second
term minimized choosing w t  one minimizes 





hw t  r t    p t  hw t 



 

exactly computation performed max norm projection  therefore 
theorem motivates use max norm projections minimize error term appears
bound 
bounds provided far may seem fairly trivial  provided
strong priori bound  t    fortunately  several factors make bounds interesting despite lack priori guarantees  approximate policy iteration converges 
b policy
occurred experiments  obtain much tighter bound 
convergence  then 



v v  b
 
b

    
b one step max norm projection error associated estimating value
b   since max norm projection operation provides b

  easily obtain
   

fiefficient solution algorithms factored mdps

posteriori bound part policy iteration procedure  details provided
section   
one could rewrite bound theorem     terms worst case projection error p   worst projection error cycle policies  approximate policy iteration
gets stuck cycle  formulations would closer analysis bertsekas
tsitsiklis        proposition      p       however  consider case policies
 or policies final cycle  low projection error  policies
cannot approximated well using projection operation  large
one step projection error  worst case bound would loose  would
dictated error difficult policy approximate  hand  using
discounted accumulated error formulation  errors introduced policies hard
approximate decay rapidly  thus  error bound represents average case
analysis  decaying average projection errors policies encountered successive iterations algorithm  convergent case  bound computed
easily part policy iteration procedure max norm projection used 
practical benefit posteriori bounds give meaningful feedback
impact choice value function approximation architecture 
explicitly addressing difficult general problem feature selection paper 
error bounds motivate algorithms aim minimize error given approximation
architecture provide feedback could useful future efforts automatically
discover improve approximation architectures 
    approximate linear programming
      exact algorithm
linear programming provides alternative method solving mdps  formulates
problem finding value function linear program  lp   lp variables
v            vn   vi represents v xi    value starting ith state system 
lp given by 
variables  v            vn  
p
minimize 
xi  xi   vi  
p
subject to  vi  r xi   a    j p  xj   xi   a vj   xi x  a 

   

state relevance weights positive  note that  exact case  solution
obtained positive weight vector  interesting note steps
simplex algorithm correspond policy changes single states  steps policy
iteration involve policy changes multiple states  practice  policy iteration tends
faster linear programming approach  puterman        
      approximate linear program
approximate formulation lp approach  first proposed schweitzer seidmann         restricts space allowable value functions linear space spanned
basis functions  approximate formulation  variables w            wk  
weights basis functions  lp given by 
   

figuestrin  koller  parr   venkataraman

variables  w            wk  
p
p
minimize 
 x  wi hi  x   
px
p
p
 
 
subject to 
wi hi  x   r x  a   
x  p  x   x  a 
wi hi  x    x x  a 
   
words  formulation takes lp     substitutes explicit state
p
value function linear value function representation wi hi  x   or  compact
notation  v replaced hw  linear program guaranteed feasible constant
function function constant value states included set
basis functions 
approximate linear programming formulation  choice state relevance weights 
  becomes important  intuitively  constraints lp binding  is 
constraints tighter states others  state x  relevance
weight  x  indicates relative importance tight constraint  therefore  unlike
exact case  solution obtained may differ different choices positive weight vector
  furthermore  is  general  guarantee quality greedy policy
generated approximation hw  however  recent work de farias van
roy      a  provides analysis error relative best possible approximation subspace  guidance selecting improve quality
approximation  particular  analysis shows lp provides best
approximation hw optimal value function v weighted l  sense subject
constraint hw hw   weights l  norm state relevance
weights  
transformation exact approximate problem formulation effect reducing number free variables lp k  one basis function
coefficient   number constraints remains n  a   sysadmin problem 
example  number constraints lp      m       m   number
machines network  thus  process generating constraints solving
lp still seems unmanageable machines  next section  discuss
use structure factored mdp provide compact representation
efficient solution lp 

   factored value functions
linear value function approach  algorithms described section    apply
choice basis functions  context factored mdps  koller parr        suggest
particular type basis function  particularly compatible structure
factored mdp  suggest that  although value function typically structured 
many cases might close structured  is  might wellapproximated using linear combination functions refers small
number variables  precisely  define 
definition     factored  linear  value function linear function basis set
h            hk   scope hi restricted subset variables ci  
value functions type long history area multi attribute utility theory  keeney   raiffa         example  might basis function hi
   

fiefficient solution algorithms factored mdps

machine  indicating whether working not  basis function scope restricted
xi   represented diamonds next time step figure   b  
factored value functions provide key performing efficient computations
exponential sized state spaces factored mdps  main insight restricted scope functions  including basis functions  allow certain basic operations
implemented efficiently  remainder section  show structure
factored mdps exploited perform two crucial operations efficiently  one step
lookahead  backprojection   representation exponentially many constraints
lps  then  use basic building blocks formulate efficient approximation algorithms factored mdps  presented self contained section 
approximate linear programming factored mdps section    approximate policy
iteration max norm projection section   
    one step lookahead
key step algorithms computation one step lookahead value
action a  necessary  example  computing greedy policy
equation      lets consider computation q function  qa  x   represents
expected value agent obtains taking action current time step receiving
long term value v thereafter  q function computed by 
qa  x    r x  a   

x

p  x    x  a v x  

   

x 

is  qa  x  given current reward plus discounted expected future value 
using notation  express greedy policy as  greedy v  x    maxa qa  x  
recall estimating long term value policy using set basis
p
functions  v x    wi hi  x   thus  rewrite equation     as 
qa  x    r x  a   

x

p  x    x  a 

x

x 

wi hi  x  

    



p

size state space exponential  computing expectation x  p  x   
p
x  a  wi hi  x  seems infeasible  fortunately  discussed koller parr        
expectation operation  backprojection  performed efficiently transition
model value function factored appropriately  linearity value
function permits linear decomposition  summand expectation
viewed independent value function updated manner similar value
iteration procedure used boutilier et al          recap construction briefly 
first defining 
ga  x   

x
x 

p  x    x  a 

x

wi hi  x     



x


wi

x

p  x    x  a hi  x    

x 

thus  compute expectation basis function separately 
gia  x   

x

p  x    x  a hi  x    

x 

   

figuestrin  koller  parr   venkataraman

p

weight wi obtain total expectation ga  x    wi gia  x  
intermediate function gia called backprojection basis function hi
transition model pa   denote gia   pa hi   note that  factored mdps 
transition model pa factored  represented dbn  basis functions hi
scope restricted small set variables  two important properties allow us
compute backprojections efficiently 
show restricted scope function h  such basis functions 
backprojected transition model p represented dbn  
h scope restricted y  goal compute g   p h  define backprojected scope set parents y  transition graph g  
 y      yi  y  parents  yi     intra time slice arcs included  parents  xi   
 x            xn   x             xn     change algorithm definition backprojected scope   definition includes direct parents    
variables  x            xn   ancestors    
 y       xj   exist directed path xj xi  y    
thus  backprojected scope may become larger  functions still factored 
show that  h scope restricted y  backprojection g
scope restricted parents y    i e    y     furthermore  backprojection
computed enumerating settings variables  y     rather settings
variables x 
g x     p h  x  
 

x

p  x    x h x    

x 

 

x

p  x    x h y    

x 

 

x
y 

 

x

x

p  y    x h y   

p  u    x  

u   x  y   

p  y    z h y    

y 

  g z  
p

z value  y    x term u   x  y    p  u    x     
sum probability distribution complete domain  therefore  see  p h 
function whose scope restricted  y     note cost computation depends
linearly  dom   y       depends  the scope h  complexity
process dynamics  backprojection procedure summarized figure   
returning example  consider basis function hi indicator variable xi  
takes value   ith machine working   otherwise  hi scope restricted
xi    thus  backprojection gi scope restricted parents  xi      xi       xi    xi   
    representing exponentially many constraints
seen section    approximation algorithms require solution linear programs  lp     approximate policy iteration  lp     approximate
   

fiefficient solution algorithms factored mdps

backproja  h 

basis function h scope c 

define scope backprojection   c      xi  c  parentsa  xi    
 
assignment
p
q  c      

g  y    c  c  i x   c  pa  c  xi     y h c    


return g  

figure    backprojection basis function h 
linear programming algorithm  lps common characteristics 
small number free variables  for k basis functions k     free variables approximate policy iteration k approximate linear programming   number
constraints still exponential number state variables  however  factored mdps 
lp constraints another useful property  functionals constraints
restricted scope  key observation allows us represent constraints
compactly 
first  observe constraints linear programs form 


x

wi ci  x  b x   x 

    



w            wk free variables lp x ranges states 
general form represents type constraint max norm projection lp    
approximate linear programming formulation      
first insight construction replace entire set constraints
equation      one equivalent non linear constraint 
max
x

x

wi ci  x  b x  

    



second insight new non linear constraint implemented set
linear constraints using construction follows structure variable elimination
cost networks  insight allows us exploit structure factored mdps represent
constraint compactly 
tackle problem representing constraint equation      two steps 
first  computing maximum assignment fixed set weights  then  representing
non linear constraint small set linear constraints  using construction call
factored lp 
      maximizing state space
key computation algorithms represent non linear constraint form
equation      efficiently small set linear constraints  presenting construction  lets first consider simpler problem  given fixed weights wi   would
p
compute maximization    maxx wi ci  x  b x   is  state x 
p

   complementary constraints      b x  wi ci  x   formulated using analogous
construction one present section changing sign ci  x  b x   approximate
linear programming constraints     formulated form  show section   

   

figuestrin  koller  parr   venkataraman

p

difference wi ci  x  b x  maximal  however  cannot explicitly enumerate exponential number states compute difference  fortunately 
structure factored mdps allows us compute maximum efficiently 
case factored mdps  state space set vectors x assignments state variables x    x            xn    view cw b functions
state variables  hence difference  thus  define function
p
f w  x            xn   f w  x    wi ci  x  b x   note executed
representation shift  viewing f w function variables x  parameterized w  recall size state space exponential number
variables  hence  goal section compute maxx f w  x  without explicitly
considering exponentially many states  solution use fact f w
p
factored representation  precisely  cw form wi ci  zi    zi
subset x  example  might c   x    x    takes value   states
x    true x    false   otherwise  similarly  vector b case sum
p
restricted scope functions  thus  express f w sum j fjw  zj    fjw may
may depend w  future  sometimes drop superscript w
clear context 
p
using compact notation  goal simply compute maxx wi ci  x 
b x    maxx f w  x   is  find state x f w maximized  recall
p
w
fw  
j   fj  zj    maximize function  f   without enumerating every state
using non serial dynamic programming  bertele   brioschi         idea virtually
identical variable elimination bayesian network  review construction here 
central component solution lp 
goal compute
x
max
fj  x zj    
x       xn

j

main idea that  rather summing functions maximization 
maximize variables one time  maximizing xl   summands
involving xl participate maximization 
example     assume
f   f   x    x      f   x    x      f   x    x      f   x    x    
therefore wish compute 
max

x   x   x   x 

f   x    x      f   x    x      f   x    x      f   x    x    

first compute maximum x    functions f  f  irrelevant 
push out  get
max f   x    x      f   x    x      max f   x    x      f   x    x     

x   x   x 

x 

result internal maximization depends values x    x    thus  introduce new function e   x    x    whose value point x    x  value internal
max expression  problem reduces computing
max f   x    x      f   x    x      e   x    x    

x   x   x 

   

fiefficient solution algorithms factored mdps

variableelimination  f  o 
  f    f            fm   set functions maximized 
  o stores elimination order 

    number variables 
  select next variable eliminated 

let l   o i   
  select relevant functions 

let e            el functions f whose scope contains xl  
  maximize current variable xl  

define new function e   maxxl
l
j   scope ej    xl   

pl

j   ej

  note scope e   

  update set functions 

update set functions f   f  e     e            el   
  now  functions empty scope
p sum maximum value f      fm  

return maximum value

ei f

ei  

figure    variable elimination procedure computing maximum value f      fm  
restricted scope function 

one fewer variable  next  eliminate another variable  say x    resulting
expression reducing to 
max f   x    x      e   x    x    
x   x 



e   x    x      max f   x    x      e   x    x     
x 

finally  define
e    max f   x    x      e   x    x    
x   x 

result point number  desired maximum x            x   
naive approach enumerating states requires    arithmetic operations variables
binary  using variable elimination need perform    operations 
general variable elimination algorithm described figure    inputs
algorithm functions maximized f    f            fm   elimination
ordering variables  o i  returns ith variable eliminated 
example above  variable xl eliminated  select relevant functions
e            el   whose scope contains xl   functions removed set f
p
introduce new function e   maxxl l
j   ej   point  scope functions
f longer depends xl   is  xl eliminated  procedure repeated
variables eliminated  remaining functions f thus empty
scope  desired maximum therefore given sum remaining functions 
computational cost algorithm linear number new function
values introduced elimination process  precisely  consider computation
new function e whose scope z  compute function  need compute  dom z  
different values  cost algorithm linear overall number values 
introduced throughout execution  shown dechter         cost exponential
   

figuestrin  koller  parr   venkataraman

induced width cost network  undirected graph defined variables
x            xn   edge xl xm appear together one original
functions fj   complexity algorithm is  course  dependent variable
elimination order problem structure  computing optimal elimination order
np hard problem  arnborg  corneil    proskurowski        elimination orders
yielding low induced tree width exist problems  issues
confronted successfully large variety practical problems bayesian network
community  benefited large variety good heuristics
developed variable elimination ordering problem  bertele   brioschi        kjaerulff 
      reed        becker   geiger        
      factored lp
section  present centerpiece planning algorithms  new  general
approach compactly representing exponentially large sets lp constraints problems
factored structure functions constraints decomposed
sum restricted scope functions  consider original problem representing
non linear constraint equation      compactly  recall wish represent
p
non linear constraint maxx wi ci  x  b x   equivalently  maxx f w  x  
without generating one constraint state equation       new  key insight
non linear constraint implemented using construction follows
structure variable elimination cost networks 
consider function e used within f  including original s   let z scope 
assignment z z  introduce variable uez   whose value represents ez  
linear program  initial functions fiw   include constraint ufzi   fiw  z  
fiw linear w  constraint linear lp variables  now  consider new function
e introduced f eliminating variable xl   let e            el functions extracted
f  let z scope resulting e  introduce set constraints 
uez



l
x
ej
j  

u z xl   zj  

xl  

    

let en last function generated elimination  recall scope empty 
hence  single variable uen   introduce additional constraint uen  
complete algorithm  presented figure    divided three parts  first 
generate equality constraints functions depend weights wi  basis functions  
second part  add equality constraints functions depend
weights  target functions   equality constraints let us abstract away differences
two types functions manage unified fashion third
part algorithm  third part follows procedure similar variable elimination
described figure    however  unlike standard variable elimination would inp
troduce new function e  e   maxxl l
j   ej   factored lp procedure
introduce new lp variables uez   enforce definition e maximum xl
pl
j   ej   introduce new lp constraints equation      
example     understand construction  consider simple example above 
assume want express fact maxx f w  x   first introduce set
   

fiefficient solution algorithms factored mdps

factoredlp  c  b o 
   c    c            ck   set basis functions 
   b    b            bm   set target functions 
  o stores elimination order 
p
p
  return  polynomial  set constraints equivalent wi ci  x    j bj  x   x  
  data structure constraints factored lp 

let       
  data structure intermediate functions generated variable elimination 

let f       
  generate equality constraint abstract away basis functions 

ci c 
let z   scope ci   
assignment z z  create new lp variable ufzi add
constraint  
ufzi   wi ci  z  
store new function use variable elimination step  f   f  fi   
  generate equality constraint abstract away target functions 

bj b 
let z   scope bj   
f
assignment z z  create new lp variable uzj add
constraint  
f
uzj   bj  z  
store new function fj use variable elimination step  f   f  fj   
  now  f contains functions involved lp  constraints become 
p
e  x   x   represent compactly using variable elimination procedure 
e f


    number variables 

  select next variable eliminated 

let l   o i   
  select relevant functions 

let e            el functions f whose scope contains xl   let
zj   scope ej   
  introduce linear constraints maximum current variable xl  

define new function e scope z   l
j   zj  xl   represent
pl
maxxl j   ej  
add constraints enforce maximum  assignment z z 
uez

l
x

e

j
u z x
l   zj  

xl  

j  

  update set functions 

update set functions f   f  e     e            el   
  now  variables eliminated functions empty scope 

add last constraint  


x

ei  

ei f

return  

figure    factored lp algorithm compact representation exponential set
p
p
constraints wi ci  x    j bj  x   x 
   

figuestrin  koller  parr   venkataraman

variables ufx    x  every instantiation values x    x  variables x    x    thus 
x  x  binary  four variables  introduce constraint
defining value ufx    x  appropriately  example  f  above  uft t     
uft f    w    similar variables constraints fj value z
zj   note constraints simple equality constraint involving numerical
constants perhaps weight variables w 
next  introduce variables intermediate expressions generated variable elimination  example  eliminating x    introduce set lp variables
uex    x    them  set constraints
uex    x  ufx    x    ufx    x 
one value x  x    similar set constraint uex    x  terms
ufx    x  uex    x    note constraint simple linear inequality 
prove factored lp construction represents constraint
non linear constraint equation      
theorem     constraints generated factored lp construction equivalent
non linear constraint equation       is  assignment    w  satisfies
factored lp constraints satisfies constraint equation      
proof  see appendix a   
p
returning original formulation  j fjw cw b original
set constraints  hence new set constraints equivalent original set 
p
maxx wi ci  x  b x  equation       turn equivalent exponential
p
set constraints wi ci  x  b x   x equation       thus  represent
exponential set constraints new set constraints lp variables  size
new set  variable elimination  exponential induced width cost
network  rather total number variables 
section  presented new  general approach compactly representing exponentially large sets lp constraints problems factored structure  remainder
paper  exploit construction design efficient planning algorithms factored
mdps 
      factored max norm projection
use procedure representing exponential number constraints
equation      compactly compute efficient max norm projections  equation     
w arg min kcw bk  
w

max norm projection computed linear program      two sets
p
p
constraints lp  kj   cij wj bi   bi kj   cij wj   i 
sets instance constraints equation       addressed
previous section  thus  k basis functions c restricted scope
function target function b sum restricted scope functions 
use factored lp technique represent constraints max norm projection lp
compactly  correctness algorithm corollary theorem     
   

fiefficient solution algorithms factored mdps

corollary     solution     w   linear program minimizes subject
constraints factoredlp c  b o  factoredlp c  b o   elimination
order satisfies 
w arg min kcw bk  
w



  min kcw bk  
w

original max norm projection lp k     variables two constraints
state x  thus  number constraints exponential number state variables 
hand  new factored max norm projection lp variables 
exponentially fewer constraints  number variables constraints new factored
lp exponential number state variables largest factor cost
network  rather exponential total number state variables  show
section    exponential gain allows us compute max norm projections efficiently
solving large factored mdps 

   approximate linear programming
begin simplest approximate mdp solution algorithms  based
approximate linear programming formulation section      using basic operations
described section    formulate algorithm simple efficient 
    algorithm
discussed section      approximate linear program formulation based linear
programming approach solving mdps presented section      however  approximate version  restrict space value functions linear space defined
basis functions  precisely  approximate lp formulation  variables
w            wk weights basis functions  lp given by 
variables  w            wk  
p
p
minimize 
 x  wi hi  x   
x
p
p
p
 
 
subject to 
wi hi  x   r x  a   
x  p  x   x  a 
wi hi  x    x x  a 
    
words  formulation takes lp     substitutes explicit state value
p
function linear value function representation wi hi  x   transformation
exact approximate problem formulation effect reducing number
free variables lp k  one basis function coefficient   number
constraints remains  x   a   sysadmin problem  example  number
constraints lp       m       m   number machines
network  however  using algorithm representing exponentially large constraint sets
compactly able compute solution approximate linear programming
algorithm closed form exponentially smaller lp  section     
p
p
first  consider objective function x  x  wi hi  x  lp       naively
representing objective function requires summation exponentially large state
space  however  rewrite objective obtain compact representation 
first reorder terms 
   

figuestrin  koller  parr   venkataraman

factoredalp  p   r    h  o   
  p factored transition model 
  r set factored reward functions 
   discount factor 
  h set basis functions h    h            hk   
  o stores elimination order 
   state relevance weights 
  return basis function weights w computed approximate linear programming 
  cache backprojections basis functions 

basis function hi h  action a 
let gia   backproja  hi   
  compute factored state relevance weights 

basis function hi   compute factored state relevance weights
equation       
  generate approximate linear programming constraints

let      
action a 
   ra   o  
let   factoredlp  g a h            gka hkp

p

  so far  constraints guarantee r x  a    x  p  x    x  a  wi hi  x   
p
w hi  x   satisfy approximate linear programming solution      must add

final constraint 

let          
  we obtain solution weights solving lp 

let w solution linear program  minimize
constraints  
return w 

p


wi   subject

figure    factored approximate linear programming algorithm 

   

fiefficient solution algorithms factored mdps

x

 x 

x

x

wi hi  x   

x



x

wi

 x  hi  x  

x



now  consider state relevance weights  x  distribution states   x     
p
x  x       backprojections  write 
 

x

x

 x  hi  x   

x

 ci   hi  ci   

    

ci ci

 ci   represents marginal state relevance weights domain
dom ci   basis function hi   example  use uniform state relevance weights
 
experiments  x     x 
marginals become  ci      c i     thus 
p
rewrite objective function wi   basis weight computed shown
equation       state relevance weights represented marginals  cost
computing depends exponentially size scope ci only  rather
exponentially number state variables  hand  state relevance
weights represented arbitrary distributions  need obtain marginals
ci s  may efficient computation  thus  greatest efficiency achieved
using compact representation  bayesian network  state relevance weights 
second  note right side constraints lp      correspond qa
functions 
x
x
qa  x    ra  x   
p  x    x  a 
wi hi  x    
x 



using efficient backprojection operation factored mdps described section    
rewrite qa functions as 
qa  x    ra  x   

x

wi gia  x  



gia


backprojection basis function hi transition model pa  
discussed  hi scope restricted ci   gia restricted scope function  c i   
precompute backprojections gia basis relevance weights  
approximate linear programming lp      written as 
variables  w            wk  
p
minimize 
w  
pi
p


subject to 
w
hi  x   r  x   
wi gi  x   x x  a 

    

finally  rewrite lp use constraints form one equation      
variables  w            wk  
p
minimize 
wi  
p
subject to    maxx  ra  x    wi  gia  x  hi  x    a 

    

use factored lp construction section     represent non linear
constraints compactly  basically  one set factored lp constraints action
a  specifically  write non linear constraint form equation      expressing functions c as  ci  x    hi  x gia  x   ci  x  restricted
   

figuestrin  koller  parr   venkataraman

scope function  is  hi  x  scope restricted ci   gia  x  scope restricted
 c i    means ci  x  scope restricted ci  c i    next  target
function b becomes reward function ra  x  which  assumption  factored  finally 
constraint equation       free variable  hand  lp     
maximum right hand side must less zero  final condition
achieved adding constraint      thus  algorithm generates set factored
lp constraints  one action  total number constraints variables
new lp linear number actions  a  exponential induced width
cost network  rather total number variables  complete factored
approximate linear programming algorithm outlined figure   
    example
present complete example operations required approximate lp algorithm solve factored mdp shown figure   a   presentation follows four steps 
problem representation  basis function selection  backprojections lp construction 
problem representation  first  must fully specify factored mdp model
problem  structure dbn shown figure   b   structure maintained
action choices  next  must define transition probabilities action 
  actions problem  nothing  reboot one   machines
network  cpds actions shown figure   c   finally  must define
reward function  decompose global reward sum   local reward functions 
one machine  reward machine working  specifically 
ri  xi   true      ri  xi   false       breaking symmetry setting r   x    true   
   use discount factor       
simple example  use five simple basis functions 
basis function selection 
first  include constant function h       next  add indicators machine
take value   machine working  hi  xi   true      hi  xi   false      
backprojections 
first algorithmic step computing backprojection
basis functions  defined section      backprojection constant basis
simple 
g a  

x

pa  x    x h   

x 

 

x

pa  x    x     

x 

    
next  must backproject indicator basis functions hi  
gia  

x
x 

 

pa  x    x hi  x i    

x



pa  x j   xj    xj  hi  x i    

x    x    x    x   j

   

fiefficient solution algorithms factored mdps

 

x
x i

 

x

x

pa  x i   xi    xi  hi  x i  



pa  x j   xj    xj    

x   x   xi     j  i

pa  x i   xi    xi  hi  x i    

x i

  pa  xi    true   xi    xi       pa  xi    false   xi    xi      
  pa  xi    true   xi    xi    
thus  gia restricted scope function  xi    xi    use cpds figure   c  specify gia  
reboot  

 xi    xi    

reboot   

 xi    xi    

gi

gi

xi   true xi   false
xi    true
 
 
 
xi    false
 
 
xi    true
xi    false

xi   true xi   false
   
    
 
   
    

lp construction 
illustrate factored lps constructed algorithms 
define constraints approximate linear programming approach presented above 
first  define functions cai   gia hi   shown equation       example 
functions ca            constant basis  indicator bases 
reboot  

 xi    xi    

reboot   

 xi    xi    

ci

ci

xi   true xi   false
xi    true
   
   
 
xi    false
   
   
xi    true
xi    false

xi   true xi   false
    
     
 
    
     

using definition cai   approximate linear programming constraints given by 
  max
x

x

ri  

x



wj caj    

    

j

present lp construction one   actions  reboot      analogous constructions
made actions 
first set constraints  abstract away difference rewards basis
functions introducing lp variables u equality constraints  begin reward
functions 
r 
 
ur
x        ux       

r 
 
ur
x        ux       

r 
 
ur
x        ux       

r 
 
ur
x        ux       

represent equality constraints caj functions reboot     action  note
appropriate basis function weight equation      appears constraints 

   

figuestrin  koller  parr   venkataraman

uc        w   
ucx    x        w   
ucx    x        w   
ucx    x        w   
ucx    x        w   
c
c
c
ux    x         w    ux    x         w    ux    x          w    ucx    x          w   
ucx    x         w    ucx    x         w    ucx    x          w    ucx    x          w   
ucx    x         w    ucx    x         w    ucx    x          w    ucx    x          w   
using new lp variables  lp constraint equation      reboot     action
becomes 
 

max

x   x   x   x 

 
 
x
x
c
c 

ur
 
u
 
uxjj   xj  
xi
i  

j  

ready variable elimination process  illustrate elimination
variable x   
 

max

x   x   x 

 
 
h

x
x
c
ri
c 
c 
c 
 
uxi   u  
uxjj   xj   max ur
x    ux   x    ux   x   
i  

x 

j  

h



c 
c 
 
represent term maxx  ur
x    ux   x    ux   x  set linear constraints 
one assignment x  x    using new lp variables uex    x  represent
maximum 

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

uex    x 

c 
c 
 
ur
x    ux   x    ux   x   

eliminated variable x  global non linear constraint becomes 
 

 
 
x
x
c
c 

ur
 
u
 
uxjj   xj   uex    x   
xi
x   x   x 

max

j  

i  

next  eliminate variable x    new lp constraints variables form 
c 
e 
 
uex    x  ur
x    ux   x    ux   x    x    x    x   

thus  removing x  global non linear constraint 
 
x
c 
e 
c 

ur
xi   u   ux   x    ux   x   
x   x 

  max

i  

   

fiefficient solution algorithms factored mdps

      

number lp constraints

      

  explicit constraints  
 n      n

explicit lp
factored lp
      

      

     

  factored constraints  
  n     n    
 
 

 

 

 
 
  
number machines ring

  

  

  

figure    number constraints lp generated explicit state representation
versus factored lp construction solution ring problem
basis functions single variables approximate linear programming
solution algorithm 

eliminate x    generating linear constraints 
c 
e 
 
uex   ur
x    ux   x    ux   x    x    x   

now  global non linear constraint involves x   
e 
c 
 
  max ur
x    u   ux   
x 

x  last variable eliminated  scope new lp variable empty
linear constraints given by 
e 
 
u e  u r
x    ux    x   

state variables eliminated  turning global non linear constraint
simple linear constraint 
  uc    ue   
completes lp description approximate linear programming solution
problem figure   
small example four state variables  factored lp technique generates
total    equality constraints      inequality constraints     lp variables 
explicit state representation equation     generates    inequality constraints
  lp variables  however  problem size increases  number constraints
lp variables factored lp approach grow o n     explicit state approach
grows exponentially  o n n    scaling effect illustrated figure   

   approximate policy iteration max norm projection
factored approximate linear programming approach described previous section
elegant easy implement  however  cannot  general  provide strong
   

figuestrin  koller  parr   venkataraman

guarantees error achieves  alternative use approximate policy
iteration described section      offer certain bounds error  however 
shall see  algorithm significantly complicated  requires place
additional restrictions factored mdp 
particular  approximate policy iteration requires representation policy
iteration  order obtain compact policy representation  must make additional
assumption  action affects small number state variables  first state
assumption formally  then  show obtain compact representation greedy
policy respect factored value function  assumption  finally  describe
factored approximate policy iteration algorithm using max norm projections 
    default action model
section      presented factored mdp model  action associated
factored transition model represented dbn factored reward
function  however  different actions often similar transition dynamics  differing effect small set variables  particular  many cases variable
default evolution model  changes action affects directly  boutilier
et al         
type structure turns useful compactly representing policies  property important approximate policy iteration algorithm  thus  section
paper  restrict attention factored mdps defined using default transition model   hgd   pd  koller   parr         action a  define effects a  x 
variables next state whose local probability model different   i e  
variables xi  pa  xi    parentsa  xi        pd  xi    parentsd  xi     
example     system administrator example  action ai rebooting
one machines  default action nothing  transition model
described corresponds nothing action  default transition
model  transition model ai different transition model
variable xi    xi    true probability one  regardless status
neighboring machines  thus  example  effects ai     xi   
transition dynamics  define notion default reward model 
p
case  set reward functions ri   ri  ui   associated default action
d  addition  action reward function ra  ua    here  extra reward
action scope restricted rewards a    uai  x            xn    thus  total reward
p
associated action given ra   ri   ri   note ra factored
linear combination smaller terms even compact representation 
build additional assumption define complete algorithm 
recall approximate policy iteration algorithm iterates two steps  policy
improvement approximate value determination  discuss steps 
    computing greedy policies
policy improvement step computes greedy policy relative value function v  t    
 t    greedy v  t     
   

fiefficient solution algorithms factored mdps

recall value function estimates linear form hw  described
section      greedy policy type value function given by 
greedy hw  x    arg max qa  x  


p

qa represented by  qa  x    r x  a    wi gia  x  
attempt represent policy naively  faced problem
exponentially large state spaces  fortunately  shown koller parr        
greedy policy relative factored value function form decision list 
precisely  policy written form ht    a  i  ht    a  i          htl   al i  ti
assignment values small subset ti variables  ai action 
greedy action take state x action aj corresponding first event tj
list x consistent  completeness  review construction
decision list policy 
critical assumption allows us represent policy compact decision list
default action assumption described section      assumption  qa
functions written as 


qa  x    r  x   

r
x

ri  x   

i  

x

wi gia  x  



ra scope restricted ua   q function default action just 
p
p
qd  x    ri   ri  x    wi gid  x  
set linear q functions implicitly describes policy  
immediately obvious q functions result compactly expressible policy 
important insight components weighted combination
identical  gia equal gid i  intuitively  component gia corresponding
backprojection basis function hi  ci   different action influences
one variables ci   formally  assume effects a  ci     case 
variables ci transition model   thus 
gia  x    gid  x   words  ith component qa function irrelevant
deciding whether action better default action d  define
components actually relevant  let ia set indices effects a  ci     
indices basis functions whose backprojection differs pa pd  
example dbn figure    actions basis functions involve single variables 
iai   i 
let us consider impact taking action default action d 
define impact difference value as 
 x    qa  x  qd  x  
  ra  x   

x

h



wi gia  x  gid  x   

    

iia

analysis shows  x  function whose scope restricted




ta   ua iia  c i    
   

    

figuestrin  koller  parr   venkataraman

decisionlistpolicy  qa  
  qa set q functions  one action 
  return decision list policy  
  initialize decision list 

let      
  compute bonus functions 

action a  default action d 
compute bonus taking action a 
 x    qa  x  qd  x  
equation       note scope restricted ta  
equation      
  add states positive bonuses  unsorted  decision list 

assignment ta  
 t       add branch decision list 
   ht  a   t i  
  add default action  unsorted  decision list 

let    h  d   i  
  sort decision list obtain final policy 

sort decision list decreasing order element ht  a  i 
return  

figure    method computing decision list policy factored representation
qa functions 

example dbn  ta     x    x    
intuitively  situation baseline value function qd  x 
defines value state x  action changes baseline adding
subtracting amount state  point amount depends ta  
states variables ta take values 
define greedy policy relative q functions  action a  define
set conditionals ht  a  i  assignment values variables ta  
 t   now  sort conditionals actions order decreasing  
ht    a      i  ht    a      i          htl   al   l i 
consider optimal action state x  would get largest possible bonus
default value  x consistent t    clearly take action a   
gives us bonus     not  try get     thus  check x
consistent t    so  take a    using procedure  compute decisionlist policy associated linear estimate value function  complete algorithm
computing decision list policy summarized figure   
p
note number conditionals list  dom ta     ta   turn  depends
set basis function clusters intersect effects a  thus  size
policy depends natural way interaction structure
   

fiefficient solution algorithms factored mdps

process description structure basis functions  problems actions
modify large number variables  policy representation could become unwieldy 
approximate linear programming approach section   appropriate cases 
require explicit representation policy 
    value determination
approximate value determination step algorithm computes 
w t    arg min khw  r t    p t  hw k  
w

rearranging expression  get 
w t    arg min k h p t  h  w r t  k  
w

equation instance optimization equation      p t  factored 
conclude c    h p t  h  matrix whose columns correspond restrictedscope functions  specifically 
 t 

ci  x    hi  x  gi  x  
 t 

gi backprojection basis function hi transition model p t   
described section      target b   r t  corresponds reward function 
moment assumed factored  thus  apply factored lp
section       estimate value policy  t   
unfortunately  transition model p t  factored  decision list representation policy  t  will  general  induce transition model p t  cannot
represented compact dbn  nonetheless  still generate compact lp exploiting decision list structure policy  basic idea introduce cost networks
corresponding branch decision list  ensuring  additionally  states
consistent branch considered cost network maximization  specifically 
factored lp construction branch hti   ai i  ith cost network
considers subset states consistent ith branch decision list 
let si set states x ti first event decision list x
consistent  is  state x si   x consistent ti   consistent
tj j   i 
recall that  equation       lp construction defines set constraints
p
imply wi ci  x  b x  state x  instead  separate set
constraints states subset si   state si   know action ai
taken  hence  apply construction using pai transition model
factored assumption place non factored p t    similarly  reward function
p
becomes rai  x    ri   ri  x  subset states 
issue guarantee cost network constraints derived transition model applied states si   specifically  must guarantee
applied states consistent ti   states consistent
tj j   i  guarantee first condition  simply instantiate variables ti
take values specified ti   is  cost network considers variables
   

figuestrin  koller  parr   venkataraman

factoredapi  p   r    h  o    tmax  
  p factored transition model 
  r set factored reward functions 
   discount factor 
  h set basis functions h    h            hk   
  o stores elimination order 
   bellman error precision 
  tmax maximum number iterations 
  return basis function weights w computed approximate policy iteration 
  initialize weights

let w        
  cache backprojections basis functions 

basis function hi h  action a 
let gia   backproja  hi   
  main approximate policy iteration loop 

let     
repeat
  policy improvement part loop 
  compute decision list policy iteration weights 

let  t    decisionlistpolicy ra  

p



 t 

wi gia   

  value determination part loop 
  initialize constraints max norm projection lp 

let             
  initialize indicators 

let      
  for every branch decision list policy  generate relevant set constraints 
update indicators constraint state space future branches 

branch htj   aj decision list policy  t   
  instantiate variables tj assignment given tj  




instantiate set functions  h  g  j           hk gk j  
partial state assignment tj store c 
instantiate target functions raj partial state assignment tj store b 
instantiate indicator functions partial state assignment tj store    
  generate factored lp constraints current decision list branch 

let       factoredlp c  b       o  
let   factoredlp c  b       o  
  update indicator functions 

let ij  x      x   tj   update indicators   ij  
  we obtain new set weights solving lp  corresponds
max norm projection 

let w t    solution linear program  minimize   subject
constraints        
let       
bellmanerr hw t    tmax w t     w t   
return w t   

figure    factored approximate policy iteration max norm projection algorithm 

   

fiefficient solution algorithms factored mdps

 x            xn  ti   computes maximum states consistent ti   ti  
guarantee second condition  ensure impose constraints
states associated previous decisions  achieved adding indicators ij
previous decision tj   weight   specifically  ij function takes value
states consistent tj zero assignments tj   constraints
ith branch form 
r x  ai    

x

wl  gl  x  ai   h x    

x

  x   tj   

x  ti   

    

j i

l

x  ti   defines assignments x consistent ti   introduction
indicators causes constraints associated ti trivially satisfied states sj
j   i  note indicators restricted scope function tj
handled fashion terms factored lp  thus  decision
list size l  factored lp contains constraints  l cost networks  complete
approximate policy iteration max norm projection algorithm outlined figure   
    comparisons
instructive compare max norm policy iteration algorithm l   projection
policy iteration algorithm koller parr        terms computational costs per
iteration implementation complexity  computing l  projection requires  among
things  series dot product operations basis functions backprojected
basis functions hhi gj i  expressions easy compute p refers transition
model particular action a  however  policy represented decision list 
result policy improvement step  step becomes much complicated 
particular  every branch decision list  every pair basis functions j 
assignment variables scope hi   scope gja    requires solution
counting problem  p  complete general  although koller parr show
computation performed using bayesian network  bn  inference  algorithm
still requires bn inference one assignments branch decision
list  makes algorithm difficult implement efficiently practice 
max norm projection  hand  relies solving linear program every
iteration  size linear program depends cost networks generated 
discuss  two cost networks needed point decision list  complexity
cost networks approximately one bn inferences
counting problem l  projection  overall  branch decision
list  total two inferences  opposed one assignment
scope hi   scope gja   every pair basis functions j  thus  max norm policy
iteration algorithm substantially less complex computationally approach based
l   projection  furthermore  use linear programming allows us rely existing
lp packages  such cplex   highly optimized 
interesting compare approximate policy iteration algorithm approximate linear programming algorithm presented section    approximate
linear programming algorithm  never need compute decision list policy 
policy always represented implicitly qa functions  thus  algorithm
   

figuestrin  koller  parr   venkataraman

require explicit computation manipulation greedy policy  difference two
important consequences  one computational terms generality 
first  compute consider decision lists makes approximate linear
programming faster easier implement  algorithm  generate single lp
one cost network action never need compute decision list policy 
hand  iteration  approximate policy iteration needs generate two lps
every branch decision list size l  usually significantly longer  a  
total  l cost networks  terms representation  require policies
compact  thus  need make default action assumption  therefore 
approximate linear programming algorithm deal general class problems 
action independent dbn transition model  hand 
described section      approximate policy iteration stronger guarantees terms
error bounds  differences highlighted experimental results
presented section   

   computing bounds policy quality
presented two algorithms computing approximate solutions factored mdps 
b w
b
algorithms generate linear value functions denoted hw 
resulting basis function weights  practice  agent define behavior
b one issue remains
b   greedy hw  
acting according greedy policy

b compares true optimal policy   is  actual value vb
policy
policy
b compares v  

section    showed priori bounds quality policy  another
possible procedure compute posteriori bound  is  given resulting weights
b compute bound loss acting according greedy policy
b rather
w 
optimal policy  achieved using bellman error analysis williams
baird        
bellman error defined bellmanerr v    kt v vk   given greedy
b   greedy v   analysis provides bound 
policy


v v  bellmanerr v   
b

 

    

b evaluate quality resulting
thus  use bellman error bellmanerr hw 
greedy policy 
note computing bellman error involves maximization state space 
thus  complexity computation grows exponentially number state
variables  koller parr        suggested structure factored mdp
exploited compute bellman error efficiently  here  show error bound
computed set cost networks using similar construction one maxb represented
norm projection algorithms  technique used
decision list depend algorithm used determine policy  thus 
apply technique solutions determined approximate linear programming
action descriptions permit decision list representation policy 
b bellman error given by 
set weights w 
   

fiefficient solution algorithms factored mdps

b
factoredbellmanerr  p   r    h  o  w 
  p factored transition model 
  r set factored reward functions 
   discount factor 
  h set basis functions h    h            hk   
  o stores elimination order 
  w
b weights linear value function 
  return bellman error value function hw 
b
  cache backprojections basis functions 

basis function hi h  action a 
let gia   backproja  hi   
  compute decision list policy value function
hw 
b

b   decisionlistpolicy ra   p w
let
bi gi   
  initialize indicators 

let      
  initialize bellman error 

let     
  for every branch decision list policy  generate relevant cost networks  solve
variable elimination  update indicators constraint state space future branches 

b
branch htj   aj decision list policy  

  instantiate variables tj assignment given tj  




instantiate set functions  w
b   h  g  j            w
bk  hk gk j   
partial state assignment tj store c 
instantiate target functions raj partial state assignment
tj store b 
instantiate indicator functions partial state assignment
tj store    
  use variable elimination solve first cost network  update bellman error  error
branch larger 

let   max    variableelimination c b       o   
  use variable elimination solve second cost network  update bellman error  error
branch larger 

let   max    variableelimination c   b       o   
  update indicator functions 

let ij  x      x   tj   update indicators   ij  
return  
b
figure     algorithm computing bellman error factored value function hw 

   

figuestrin  koller  parr   venkataraman

b
b hwk
b  
bellmanerr hw 
  kt hw


  max

p

p

p

maxx wi hi  x  rb  x  x  pb  x    x  j wj hj  x     
p
p
p
maxx rb  x    x  pb  x    x  j wj hj  x    wi hi  x 

 

rewards rb transition model pb factored appropriately 
compute one two maximizations  maxx   using variable elimination cost
b decision list policy
network described section        however 
induce factored transition model  fortunately  approximate policy iteration
algorithm section    exploit structure decision list perform
maximization efficiently  particular  approximate policy iteration  generate
two cost networks branch decision list  guarantee maximization
performed states branch relevant  include type
indicator functions  force irrelevant states value   thus guaranteeing point decision list policy obtain corresponding state
maximum error  state overall largest bellman error maximum
ones generated point decision list policy  complete factored
algorithm computing bellman error outlined figure    
one last interesting note concerns approximate policy iteration algorithm maxnorm projection section    experiments  algorithm converged 
w t    w t    iterations  convergence occurs  objective function
 t    linear program last iteration equal bellman error final
policy 
lemma     approximate policy iteration max norm projection converges 
w t    w t    iteration t  max norm projection error  t    last
b   hw t   
iteration equal bellman error final value function estimate hw
b    t     
bellmanerr hw 

proof  see appendix a   
thus  bound loss acting according final policy  t    substituting
 t   

bellman error bound 
corollary     approximate policy iteration max norm projection converges
b associated greedy policy
b  
iterations final value function estimate hw
b
b instead optimal policy
greedy hw  
loss acting according
bounded by 
 t   


v v  
 
b

 

b 
vb actual value policy

therefore  approximate policy iteration converges obtain bound
quality resulting policy without needing compute bellman error explicitly 
   

 

fiefficient solution algorithms factored mdps

   exploiting context specific structure
thus far  presented suite algorithms exploit additive structure
reward basis functions sparse connectivity dbn representing transition
model  however  exists another important type structure
exploited efficient decision making  context specific independence  csi   example 
consider agent responsible building maintaining house  painting task
completed plumbing electrical wiring installed 
probability painting done    contexts plumbing electricity
done  independently agents action  representation used far
paper would use table represent type function  table exponentially
large number variables scope function  ignores context specific
structure inherent problem definition 
boutilier et al   boutilier et al         dearden   boutilier        boutilier  dean   
hanks        boutilier et al         developed set algorithms exploit csi
transition reward models perform efficient  approximate  planning  although
approach often successful problems value function contains sufficient
context specific structure  approach able exploit additive structure
often present real world problems 
section  extend factored mdp model include context specific structure 
present simple  yet effective extension algorithms exploit csi
additive structure obtain efficient approximations factored mdps  first extend
factored mdp representation include context specific structure show
basic operations section   required algorithms performed efficiently
new representation 
    factored mdps context specific additive structure
several representations context specific functions  common
decision trees  boutilier et al          algebraic decision diagrams  adds   hoey  st aubin 
hu    boutilier         rules  zhang   poole         choose use rules
basic representation  two main reasons  first  rule based representation allows
fairly simple algorithm variable elimination  key operation framework 
second  rules required mutually exclusive exhaustive  requirement
restrictive want exploit additive independence  functions
represented linear combination set non mutually exclusive functions 
begin describing rule based representation  along lines zhang
pooles presentation         probabilistic transition model  particular  cpds
dbn model  roughly speaking  rule corresponds set cpd entries
associated particular probability value  entries
value referred consistent contexts 
definition     let c  x  x    c dom c   say c consistent
b dom b   b  x  x     c b assignment variables
c b 
probability consistent contexts represented probability rules 
   

figuestrin  koller  parr   venkataraman

electrical

electrical

done

done

done

done

plumbing

p painting     

plumbing

p painting     
done

done

done

painting

p painting     

done

done

p painting     

p painting        

p painting     

 a 

done
p painting       

 b 

    helectrical    i
    helectrical plumbing    i
    helectrical plumbing painting    i
    helectrical plumbing painting      i
 d 

    helectrical    i
    helectrical plumbing    i
    helectrical plumbing       i
 c 

figure     example cpds variable painting   true represented decision trees 
 a  action paint   b  action paint  cpds
represented probability rules shown  c   d   respectively 

definition     probability rule   hc   pi function    x  x             
context c dom c  c  x  x    p          x  x      p  x  x   
consistent c equal   otherwise 
case  convenient require rules mutually exclusive exhaustive  cpd entry uniquely defined association single rule 
definition     rule based conditional probability distribution  rule cpd  pa function pa     xi    x            composed set probability rules                    whose
contexts mutually exclusive exhaustive  define 
pa  x i   x    j  x  x    
j unique rule pa cj consistent  x i   x   require that 
x 
x
pa  x i   x      
x i

define parentsa  xi    union contexts rules pa  xi    x  
example cpd represented set probability rules shown figure    
rules used represent additive functions  reward basis functions 
represent context specific value dependencies using value rules 
   

fiefficient solution algorithms factored mdps

definition     value rule   hc   vi function   x   r  x    v
x consistent c   otherwise 
note value rule hc   vi scope c 
important note value rules required mutually exclusive
exhaustive  value rule represents  weighted  indicator function  takes
value v states consistent context c    states  given state 
values zero rules consistent state simply added together 
example     construction example  might set rules 
    hplumbing   done      i 
    helectricity   done      i 
    hpainting   done      i 
    haction   plumb     i 
  
 
which  summed together  define reward function r                    
general  reward function ra represented rule based function 
definition     rule based function f   x   r composed set rules              n  
p
f  x    ni    x  
manner  one basis functions hj represented rule based
function 
notion rule based function related tree structure functions used
boutilier et al          substantially general  tree structure value functions  rules corresponding different leaves mutually exclusive exhaustive 
thus  total number different values represented tree equal number
leaves  or rules   rule based function representation  rules mutually
exclusive  values added form overall function value different settings
variables  different rules added different settings  and  fact  k rules 
one easily generate  k different possible values  demonstrated section    thus 
rule based functions provide compact representation much richer class
value functions 
using rule based representation  exploit csi additive independence
representation factored mdp basis functions  show basic
operations section   adapted exploit rule based representation 
    adding  multiplying maximizing consistent rules
table based algorithms  relied standard sum product operators applied
tables  order exploit csi using rule based representation  must redefine
standard operations  particular  algorithms need add multiply rules
ascribe values overlapping sets states 
start defining operations rules context 
   

figuestrin  koller  parr   venkataraman

definition     let     hc   v      hc   v  two rules context c  define
rule product       hc   v  v  i  rule sum         hc   v    v  i 
note definition restricted rules context  address
issue moment  first  introduce additional operation maximizes
variable set rules  otherwise share common context 
definition     let variable dom y      y            yk    let    
           k  rule form   hc   yi   vi i  rule based function
f         k   define rule maximization maxy f   hc   maxi vi  
operation  maximized scope function f  
three operations described applied sets rules
satisfy stringent conditions  make set rules amenable application
operations  might need refine rules  therefore define
following operation 
definition     let   hc   vi rule  variable  define rule split
split     variable follows  scope c   split          
otherwise 
split        hc   yi   vi   yi dom y     
thus  split rule variable scope context  
generate new set rules  one assignment domain  
general  purpose rule splitting extend context c one rule coincide
context c  another consistent rule     naively  might take variables
scope c    scope c  split recursively one them  however  process
creates unnecessarily many rules  variable scope c    scope c  split
  one  dom y    new rules generated remain consistent    
one assignment one c    thus  consistent rule
needs split further  define recursive splitting procedure achieves
parsimonious representation 
definition      let   hc   vi rule  b context b dom b  
define recursive rule split split   b  context b follows 
       c consistent b  else 
       scope b  scope c   else 
    split i   b    split       variable scope b  scope c   

definition  variable scope b  scope c  leads generation k  
 dom y    rules step split  however  one k rules used
next recursive step one consistent b  therefore  size
p
split set simply     scope b scope c    dom y        size independent
order variables split within operation 
   

fiefficient solution algorithms factored mdps

note one rules split   b  consistent b  one context
c b  thus  want add two consistent rules     hc    v      hc    v  i 
need replace rules set 
split     c    split     c    
simply replace resulting rules hc  c    v  hc  c    v  sum
hc  c    v    v  i  multiplication performed analogous manner 
example      consider adding following set consistent rules 
    ha b    i 
    ha c    i 
rules  context c    b  context c    c d 
rules     consistent  therefore  must split perform addition
operation 


ha b c    i 
ha b c    i 
split     c     

ha b c    i 
likewise 

 

split    

c     

ha b c    i 
ha b c    i 

result adding rules    
ha b c    i 
ha b c    i 
ha b c    i 
ha b c    i 

    rule based one step lookahead
using compact rule based representation  able compute one step lookahead
plan efficiently models significant context specific additive independence 
section     table based case  rule based qa function represented
sum reward function discounted expected value next state 
due linear approximation value function  expectation term is  turn 
represented linear combination backprojections basis functions 
exploit csi  representing rewards basis functions rule based functions 
represent qa rule based function  sufficient us show represent
backprojection gj basis function hj rule based function 
p  h  
hj rule based
function 
written hj  x    j  x  

e
 h  
 h  
 h  
j form ci j   vi j   rule restricted scope function  thus 
simplify backprojection as 
   

figuestrin  koller  parr   venkataraman

rulebackproja     

given hc   vi  c dom c  

let g      
select set p relevant probability rules 
p    j p  xi    parents xi       xi  c c consistent cj   
remove x  assignments context rules p 
   multiply consistent rules 
two consistent rules     hc    p      hc    p  i 
c    c    replace two rules hc    p  p  i 
else replace two rules set  split     c    split     c    
   generate value rules 
rule p 
update backprojection g   g  hci   pi vi  
return g 

figure     rule based backprojection 
gja  x   

x

pa  x    x hj  x     

x 

 

x

pa  x    x 

x 

 

xx


 

x  hj  



 x    


 hj  

 

pa  x   x i

 x    

x 

x  hj  

vi

 hj  

pa  ci

  x  


 h  

 h  

term vi j pa  ci j   x  written rule function  denote back h  
projection operation rulebackproja  i j   
backprojection procedure  described figure     follows three steps  first 
relevant rules selected  cpds variables appear context  
select rules consistent context  rules play role
backprojection computation  second  multiply consistent probability rules
form local set mutually exclusive rules  procedure analogous addition
procedure described section      represented probabilities
affect mutually exclusive set  simply represent backprojection
product probabilities value   is  backprojection
rule based function one rule one mutually exclusive probability rules
  context new value rule   value product
probability value  
example      example  consider backprojection simple rule 
  h painting   done      i 
cpd figure    c  paint action 
rulebackprojpaint     

x

ppaint  x    x  x    

x 

   

fiefficient solution algorithms factored mdps

x

 

ppaint  painting    x  painting    

painting 

     

 


 painting   done  x   

i  

note product simple rules equivalent decision tree cpd shown
figure    a   hence  product equal   contexts  example  electricity
done time t  product non zero one context  context associated
rule     thus  express result backprojection operation rule based
function single rule 
rulebackprojpaint      hplumbing electrical     i 
similarly  backprojection action paint represented
single rule 
rulebackprojpaint      hplumbing electrical painting     i 
using algorithm  write backprojection rule based basis function hj as 
gja  x   

x

 hj  

rulebackproja  i

  

    



gja sum rule based functions  therefore rule based function 
simplicity notation  use gja   rulebackproja  hj   refer definition backprop
jection  using notation  write qa  x    ra  x    j wj gja  x  
rule based function 
    rule based maximization state space
second key operation required extend planning algorithms exploit csi
modify variable elimination algorithm section       handle rule based representation  section        showed maximization linear combination
table based functions restricted scope performed efficiently using non serial
dynamic programming  bertele   brioschi         variable elimination  exploit structure rules  use algorithm similar variable elimination bayesian network
context specific independence  zhang   poole        
intuitively  algorithm operates selecting value rules relevant variable
maximized current iteration  then  local maximization performed
subset rules  generating new set rules without current variable 
procedure repeated recursively variables eliminated 
precisely  algorithm eliminates variables one one  elimination process performs maximization step variables domain  suppose
eliminating xi   whose collected value rules lead rule function f   f involves
additional variables set b  f scope b  xi    need compute
maximum value xi choice b dom b   use maxout  f  xi   denote procedure takes rule function f  b  xi   returns rule function g b 
   

figuestrin  koller  parr   venkataraman

maxout  f  b 
let g      
add completing rules f   hb   bi    i               k 
   summing consistent rules 
two consistent rules     hc    v      hc    v  i 
c    c    replace two rules hc    v    v  i 
else replace two rules set  split     c    split     c    
   maximizing variable b 
repeat f empty 
rules hc b   bi   vi i  bi dom b   
remove rules f add rule hc   maxi vi g 
else select two rules    hci b   bi   vi j   hcj b   bj   vj
ci consistent cj   identical  replace
split i   cj   split j   ci    
return g 

figure     maximizing variable b rule function f  
that  g b    maxxi f  b  xi    procedure extension variable elimination
algorithm zhang poole  zhang   poole        
rule based variable elimination algorithm maintains set f value rules  initially
containing set rules maximized  algorithm repeats following steps
variable xi variables eliminated 
   collect rules depend xi    hc   vi f   xi c 
remove rules f 
   perform local maximization step xi   gi   maxout  fi   xi   
   add rules gi f  now  xi eliminated 
cost algorithm polynomial number new rules generated
maximization operation maxout  fi   xi    number rules never larger many
cases exponentially smaller complexity bounds table based maximization
section        which  turn  exponential induced width cost network
graph  dechter         however  computational costs involved managing sets rules
usually imply computational advantage rule based approach tablebased one significant problems possess fair amount context specific
structure 
remainder section  present algorithm computing local
maximization maxout  fi   xi    next section  show ideas applied
extending algorithm section       exploit csi lp representation
planning factored mdps 
procedure  presented figure     divided two parts  first  consistent
rules added together described section      then  variable b maximized 
maximization performed generating set rules  one assignment b  whose
contexts assignment variables except b  definition     
set substituted single rule without b assignment context value
equal maximum values rules original set  note that  simplify
   

fiefficient solution algorithms factored mdps

algorithm  initially need add set value rules   value  guarantee
rule function f complete  i e   least one rule consistent every
context  
correctness procedure follows directly correctness rule based
variable elimination procedure described zhang poole  merely replacing summations product max  products products sums  conclude
section small example illustrate algorithm 
example      suppose maximizing following set rules 
 
 
 
 

  ha    i 
  ha b    i 
  ha b c    i 
  ha b    i 

add completing rules  get 
    ha    i 
    ha    i 
first part algorithm  need add consistent rules  add      which
remains unchanged   combine             split   context
    get following inconsistent set rules 
 
 
 
 
 

  ha b    i 
  ha b c    i 
  ha b    i 
 from adding   consistent rule split     b  
  ha b    i 
 from split     b  
  ha b c    i 
 from split     b c   

note several rules value   generated  shown
added rules consistent contexts  move second stage  repeat loop 
maxout  remove         maximize them  give 
     hb    i 
select rules     split   c    split empty set
changed  
     ha b c    i 
     ha b c    i 
maximizing rules        get 
     hb c    i 
left      maximized counterpart   gives
     hb c    i 
notice that  throughout maximization  split variable c b ci  
giving us   distinct rules final result  possible table based
representation  since functions would   variables a b c  therefore
must   entries 
   

figuestrin  koller  parr   venkataraman

    rule based factored lp
section        showed lps used algorithms exponentially many
p
constraints form  wi ci  x  b x   x  substituted single 
p
equivalent  non linear constraint  maxx wi ci  x  b x   showed that  using
variable elimination  represent non linear constraint equivalent set
linear constraints construction called factored lp  number constraints
factored lp linear size largest table generated variable elimination
procedure  table based algorithm exploit additive independence 
extend algorithm section       exploit additive context specific structure 
using rule based variable elimination described previous section 
suppose wish enforce general constraint   maxy f w  y   f w  y   
p w
j fj  y  fj rule  table based version  superscript w means
fj might depend w  specifically  fj comes basis function hi   multiplied
weight wi   fj rule reward function  not 
rule based factored linear program  generate lp variables associated
contexts  call lp rules  lp rule form hc   ui  associated
context c variable u linear program  begin transforming original
rules fjw lp rules follows  rule fj form hcj   vj comes basis
function hi   introduce lp rule ej   hcj   uj equality constraint uj   wi vj  
fj form comes reward function  introduce lp rule
form  equality constraint becomes uj   vj  
p
now  lp rules need represent constraint    maxy j ej  y  
represent constraint  follow algorithm similar variable elimination procedure section      main difference occurs maxout  f  b  operation
figure     instead generating new value rules  generate new lp rules  associated
new variables new constraints  simplest case occurs computing split
adding two lp rules  example  add two value rules original algorithm 
instead perform following operation associated lp rules  lp rules
hc   ui hc   uj i  replace new rule hc   uk i  associated new lp
variable uk context c  whose value ui   uj   enforce value constraint 
simply add additional constraint lp  uk   ui   uj   similar procedure
followed computing split 
interesting constraints generated perform maximization 
rule based variable elimination algorithm figure     maximization occurs
replace set rules 
hc b   bi   vi i  bi dom b  
new rule





c   max vi  


following process lp rule summation above  maximizing
ei   hc b   bi   ui i  bi dom b  
generate new lp variable uk associated rule ek   hc   uk i  however 
cannot add nonlinear constraint uk   maxi ui   add set equivalent linear
   

fiefficient solution algorithms factored mdps

constraints
uk ui   i 
therefore  using simple operations  exploit structure rule functions
p
represent nonlinear constraint en maxy j ej  y   en last lp
rule generate  final constraint un   implies representing exactly
constraints equation       without enumerate every state 
correctness rule based factored lp construction corollary theorem    
correctness rule based variable elimination algorithm  zhang   poole 
       
corollary      constraints generated rule based factored lp construction
equivalent non linear constraint equation       is  assignment    w 
satisfies rule based factored lp constraints satisfies constraint
equation      
number variables constraints rule based factored lp linear
number rules generated variable elimination process  turn  number rules
larger  often exponentially smaller  number entries table based
approach 
illustrate generation lp constraints described  present small
example 
example      let e    e    e    e  set lp rules depend variable
b maximized  here  rule ei associated lp variable ui  
e 
e 
e 
e 

  ha b   u  i 
  ha b c   u  i 
  ha b   u  i 
  ha b c   u  i 

set  note rules e  e  consistent  combine generate
following rules 
e    ha b c   u  i 
e    ha b c   u  i 
constraint u    u    u    similarly  e  e  may combined  resulting in 
e    ha b c   u  i 
constraint u    u    u    now  following three inconsistent rules
maximization 
e    ha b   u  i 
e    ha b c   u  i 
e    ha b c   u  i 
following maximization procedure  since pair rules eliminated right away 
split e  e  generate following rules 
e    ha b c   u  i 
e    ha b c   u  i 
e    ha b c   u  i 
   

figuestrin  koller  parr   venkataraman

maximize b e  e    resulting following rule constraints
respectively 
e     ha c   u  i 
u  u   
u  u   
likewise  maximizing b e  e    get 
e     ha c   u  i 
u  u   
u  u   
completes elimination variable b rule based factored lp 
presented algorithm exploiting additive context specific structure lp construction steps planning algorithms  rule based factored lp
approach applied directly approximate linear programming approximate policy iteration algorithms  presented sections     
additional modification required concerns manipulation decision
list policies presented section      although approximate linear programming
require explicit policy representation  or default action model   approximate policy iteration require us represent policy  fortunately  major modifications
required rule based case  particular  conditionals hti   ai   decision
list policies already context specific rules  thus  policy representation algorithm
section     applied directly new rule based representation  therefore 
complete framework exploiting additive context specific structure
efficient planning factored mdps 

   experimental results
factored representation value function appropriate certain types
systems  systems involve many variables  strong interactions
variables fairly sparse  decoupling influence variables
induce unacceptable loss accuracy  argued herbert simon       
architecture complexity  many complex systems nearly decomposable 
hierarchical structure  subsystems interacting weakly themselves 
evaluate algorithm  selected problems believe exhibit type structure 
section  perform various experiments intended explore performance
algorithms  first  compare factored approximate linear programming  lp 
approximate policy iteration  pi  algorithms  compare l   projection
algorithm koller parr         second evaluation compares table based implementation rule based implementation exploit csi  finally  present
comparisons approach algorithms boutilier et al         
    approximate lp approximate pi
order compare approximate lp approximate pi algorithms  tested
sysadmin problem described detail section      problem relates system
   

fiefficient solution algorithms factored mdps

administrator maintain network computers  experimented various
network architectures  shown figure    machines fail randomly  faulty machine
increases probability neighboring machines fail  every time step 
sysadmin go one machine reboot it  causing working next time
step high probability  recall state space problem grows exponentially
number machines network  is  problem machines  m states 
machine receives reward   working  except ring  one machine
receives reward    introduce asymmetry   zero reward given faulty
machines  discount factor         optimal strategy rebooting machines
depend upon topology  discount factor  status machines
network  machine machine j faulty  benefit rebooting must
weighed expected discounted impact delaying rebooting j js successors 
topologies rings  policy may function status every single
machine network 
basis functions used included independent indicators machine  value
  working zero otherwise  i e   one restricted scope function single
variable   constant basis  whose value   states  selected straightforward
variable elimination orders  star three legs topologies  first eliminated
variables corresponding computers legs  center computer  server 
eliminated last  ring  started arbitrary computer followed ring
order  ring star  ring machines eliminated first center one 
finally  ring rings topology  eliminated computers outer rings
first ones inner ring 
implemented factored policy iteration linear programming algorithms
matlab  using cplex lp solver  experiments performed sun ultrasparcii      mhz    mb ram  evaluate complexity approximate policy
iteration max norm projection algorithm  tests performed increasing
number states  is  increasing number machines network  figure    shows
running time increasing problem sizes  various architectures  simplest one
star  backprojection basis function scope restricted two
variables largest factor cost network scope restricted two variables 
difficult one bidirectional ring  factors contain five variables 
note number states growing exponentially  indicated log scale
figure      running times increase logarithmically number states 
polynomially number variables  illustrate behavior figure    d  
fit  rd order polynomial running times unidirectional ring  note
size problem description grows quadratically number variables  adding
machine network adds possible action fixing machine 
problem 
computation
cost factored algorithm empirically grows approximately


 n  a        problem n variables  opposed exponential complexity
poly   n    a   explicit algorithm 
evaluation  measured error approximate value function relative
true optimal value function v   note possible compute v small
problems  case  able go    machines  comparison 
evaluated error approximate value function produced l   projection
   

figuestrin  koller  parr   venkataraman

   

   

ring
  legs

   

ring rings

   
total time  minutes 

total time  minutes 

   

star

   

ring star
   

   

   

 

 
 e   

 e   

 e   

 e     e     e   
number states

 e   

 

 e   

   

     
       
number states

 a 
    

   

    

fitting polynomial 

   

time          x           x   
       x          

 

ring 

total time  minutes 

total time  minutes 

 e   

 b 

   

   

         

unidirectional
bidirectional

   
   

 

 

quality fit  r        
   

   

   

   
 
 e   

 e   

 e   

 e   

 e   

 e   

 e   

 e   

 
 

number state

 c 

  

  
  
  
number variables  x 

  

  

 d 

figure      a  c  running times policy iteration max norm projection variants
sysadmin problem   d  fitting polynomial running time
ring topology 

algorithm koller parr         discussed section      l  projections
factored mdps koller parr difficult time consuming  hence 
able compare two algorithms smaller problems  equivalent l   projection
implemented using explicit state space formulation  results algorithms
presented figure    a   showing relative error approximate solutions
true value function increasing problem sizes  results indicate that  larger
problems  max norm formulation generates better approximation true optimal
value function v l   projection  here  used two types basis functions 
single variable functions  pairwise basis functions  pairwise basis functions
contain indicators neighboring pairs machines  i e   functions two variables  
expected  use pairwise basis functions resulted better approximations 
   

fiefficient solution algorithms factored mdps

   

max norm  single basis
l   single basis

   

bellman error   rmax

max norm  pair basis
l   pair basis

relative error 

   

   

 
 

 

 

 

 

 

 

  

number variables

   

   

ring
  legs

   

 
 e   

star

 e   

 e   

 e   

 e   

 e   

 e   

 e   

numbe r sta tes

 a 

 b 

figure      a  relative error optimal value function v comparison l  projection
ring   b  large models  measuring bellman error convergence 

small problems  compare actual value policy generated
algorithm value optimal policy  here  value policy generated
algorithm much closer value optimal policy error implied
difference approximate value function v   example  star
architecture one server   clients  approximation single variable
basis functions relative error      policy generated value
optimal policy  case  true policy generated l 
projection  unidirectional ring   machines pairwise basis  relative
error approximation v      resulting policy
   loss optimal policy  problem  l  approximation value
function error      true policy loss     words  methods induce
policies lower errors errors approximate value function  at least
small problems   however  algorithm continues outperform l  algorithm 
even respect actual policy loss 
large models  longer compute correct value function  cannot
evaluate results computing kv hwk   fortunately  discussed section   
bellman error used provide bound approximation error
computed efficiently exploiting problem specific structure  figure    b  shows
bellman error increases slowly number states 
valuable look actual decision list policies generated experiments 
first  noted lists tended short  length final decision list policy
grew approximately linearly number machines  furthermore  policy
often fairly intuitive  ring star architecture  example  decision list
says  server faulty  fix server  else  another machine faulty  fix it 
thus far  presented scaling results running times approximation error
approximate pi approach  compare algorithm simpler approximate
   

figuestrin  koller  parr   venkataraman

   

   

pi single basis
pi single basis

   

lp single basis

   

lp pair basis

   

lp triple basis

discounted reward final policy
 averaged    trials     steps 

total running time  minutes 

   

   
  
  
  
  
 
 

 

  

  

  

  

  

  

numbe r machine

lp single basis
lp pair basis

   

lp triple basis

   

   

 
 

  

  

  

  

numbe r machine

 a 

 b 

figure     approximate lp versus approximate pi sysadmin problem ring
topology   a  running time   b  estimated value policy 

lp approach section    shown figure    a   approximate lp algorithm
factored mdps significantly faster approximate pi algorithm  fact  approximate pi single variable basis functions variables costly computationally
lp approach using basis functions consecutive triples variables  shown
figure    b   singleton basis functions  approximate pi policy obtains slightly better
performance problem sizes  however  increase number basis functions
approximate lp formulation  value resulting policy much better  thus 
problem  factored approximate linear programming formulation allows us use
basis functions obtain resulting policy higher value  still maintaining
faster running time  results  along simpler implementation  suggest
practice one may first try apply approximate linear programming algorithm
deciding move elaborate approximate policy iteration approach 
    comparing table based rule based implementations
next evaluation compares table based representation  exploits additive
independence  rule based representation presented section    exploit
additive context specific independence  experiments  implemented
factored approximate linear programming algorithm table based rule based
representations c    using cplex lp solver  experiments performed
sun ultrasparc ii      mhz  gb ram 
evaluate compare algorithms  utilized complex extension
sysadmin problem  problem  dubbed process sysadmin problem  contains three
state variables machine network  loadi   statusi selectori   computer runs processes receives rewards processes terminate  processes
represented loadi variable  takes values  idle  loaded  success  
computer receives reward assignment loadi success  statusi variable 
   

fitotal running time  minutes 

efficient solution algorithms factored mdps

   
table based  single  basis
rule based  single  basis

   

table based  pair basis
   

rule based  pair basis

  
 
 e   

 e   

 e   

 e   

 e   

 e   

 e   

number states

total running time  minutes 

 a 
   
   

table based  single  basis
rule based  single  basis

   

table based  pair basis
   
rule based  pair basis
  
 
 e     e     e     e     e     e     e     e   
number states

 b 

total running time  minutes 

   
 
 x   

 x   

   e     x         e     x     
        
 
r        

   

table based  single  basis
rule based  single  basis

   
   

 

 

        x         x  
      x         
r          

   
   
 
 

 

  
number machines

  

  

 c 
figure     running time process sysadmin problem various topologies   a  star 
 b  ring   c  reverse star  with fit function  

   

figuestrin  koller  parr   venkataraman

cplex time   total time

 
   
table based  single  basis
   
rule based  single  basis
   
   
 
 

 

  

  

  

number machines

figure     fraction total running time spent cplex process sysadmin problem ring topology 

representing status machine i  takes values  good  faulty  dead   value
faulty  processes smaller probability terminating value dead 
running process lost loadi becomes idle  status machine become faulty eventually dead random  however  machine receives packet
dead machine  probability statusi becomes faulty dead increases 
selectori variable represents communication selecting one neighbors
uniformly random every time step  sysadmin select one computer
reboot every time step  computer rebooted  status becomes good
probability    running process lost  i e   loadi variable becomes idle 
thus  problem  sysadmin must balance several conflicting goals  rebooting
machine kills processes  rebooting machine may cause cascading faults network 
furthermore  sysadmin choose one machine reboot  imposes additional tradeoff selecting one  potentially many  faulty dead machines
network reboot 
experimented two types basis functions  single  includes indicators
joint assignments loadi   statusi selectori   pair which  addition 
includes set indicators statusi   statusj   selectori   j  neighbor j
machine network  discount factor         variable elimination
order eliminated loadi variables first  followed patterns
simple sysadmin problem  eliminating first statusi selectori machine
eliminated 
figure    compares running times table based implementation ones
rule based representation three topologies  star  ring  reverse star 
reverse star topology reverses direction influences star  rather
central machine influencing machines topology  machines influence
central one  three topologies demonstrate three different levels csi 
   

fiefficient solution algorithms factored mdps

star topology  factors generated variable elimination small  thus  although
running times polynomial number state variables methods  tablebased representation significantly faster rule based one  due overhead
managing rules  ring topology illustrates intermediate behavior  single 
basis functions induce relatively small variable elimination factors  thus table based
approach faster  however  pair basis factors larger rule based
approach starts demonstrate faster running times larger problems  finally  reverse star topology represents worst case scenario table based approach  here 
scope backprojection basis function central machine involve
computers network  machines potentially influence central one
next time step  thus  size factors table based variable elimination approach exponential number machines network  illustrated
exponential growth figure    c   rule based approach exploit csi
problem  example  status central machine status  depends machine
j value selector j  i e   selector    j  exploiting csi  solve
problem polynomial time number state variables  seen second curve
figure    c  
instructive compare portion total running time spent cplex
table based compared rule based approach  figure    illustrates
comparison  note amount time spent cplex significantly higher
table based approach  two reasons difference  first  due csi  lps
generated rule based approach smaller table based ones  second  rulebased variable elimination complex table based one  due overhead
introduced rule management  interestingly  proportion cplex time increases
problem size increases  indicating asymptotic complexity lp solution
higher variable elimination  thus suggesting that  larger problems  additional
large scale lp optimization procedures  constraint generation  may helpful 
    comparison apricodd
closely related work line research began work
boutilier et al          particular  approximate apricodd algorithm hoey et
al          uses analytic decision diagrams  adds  represent value function
strong alternative approach solving factored mdps  discussed detail section     apricodd algorithm successfully exploit context specific structure
value function  representing set mutually exclusive exhaustive branches
add  hand  approach exploit additive context specific
structure problem  using linear combination non mutually exclusive rules 
better understand difference  evaluated rule based approximate linear
programming algorithm apricodd two problems  linear expon  designed
boutilier et al         illustrate respectively best case worst case behavior
algorithm  experiments  used web distributed version apricodd  hoey  st aubin  hu    boutilier         running locally linux pentium iii
   mhz  gb ram 
   

figuestrin  koller  parr   venkataraman

   

rule based

  
  

 

 

        x         x         x         
 

r         

  

apricodd
 

        x         x
        

  

apricodd

   
time  in seconds 

time  in seconds 

  

x

 

x

   e                             
r          

   
   

rule based
       x         x   
      x        
r     

   

 

r         

 

 

 

 

  
  
  
  
number variables

  

 

  

 

  

  

number variables

 a 

 b 

figure     comparing apricodd rule based approximate linear programming  a 
linear  b  expon problems 

two problems involve n binary variables x            xn n deterministic actions
a              reward   variables xk true    otherwise  problem
discounted factor         difference linear expon
problems transition probabilities  linear problem  action ak sets
variable xk true makes succeeding variables  xi   k  false  state space
linear problem seen binary number  optimal policy set repeatedly
largest bit  xk variable  preceding bits set true  using add  optimal
value function problem represented linear space  n   leaves  boutilier
et al          best case apricodd  algorithm compute value
function quite efficiently  figure    a  compares running time apricodd
one algorithms indicator basis functions pairs consecutive variables 
note algorithms obtain policy polynomial time number
variables  however  structured problems  efficient implementation add
package used apricodd makes faster problem 
hand  expon problem illustrates worst case apricodd 
problem  action ak sets variable xk true  preceding variables  xi   k 
true  makes preceding variables false  state space seen binary number 
optimal policy goes binary numbers sequence  repeatedly setting
largest bit  xk variable  preceding bits set true  due discounting 
n
optimal value function assigns value   j  jth binary number 
value function contains exponentially many different values  using add  optimal
value function problem requires exponential number leaves  boutilier et al  
       illustrated exponential running time figure    b   however 
value function approximated compactly factored linear value
function using n     basis functions  indicator variable xk constant
base  shown figure    b   using representation  factored approximate linear
programming algorithm computes value function polynomial time  furthermore 
   

fiefficient solution algorithms factored mdps

  

  

running time  minutes 

discounted value policy
 avg     runs     steps 

rule based lp

  

apricodd
  
  
  
  
 

rule based lp

  

apricodd
  
  
  
 
 

 

 

 
 
 
number machines

  

  

 

 

 
 
 
number machines

 a 

  

  

  

 b 

  

  

  

rule based lp

rule based lp

  

discounted value policy
 avg     runs     steps 

running time  minutes 

  

apricodd

  
  
  
  
  
  

  

apricodd

  
  
  
 

 
 

 
 

 

 
 
 
number machines

  

  

 c 

 

 

 
 
 
number machines

 d 

figure     comparing apricodd rule based approximate linear programming single  basis functions process sysadmin problem ring topology
 a  running time  b  value resulting policy  star topology
 c  running time  d  value resulting policy 

policy obtained approach optimal problem  thus  problem 
ability exploit additive independence allows efficient polynomial time solution 
compared apricodd rule based approximate linear programming
algorithm process sysadmin problem  problem significant additive structure reward function factorization transition model  although type
structure exploited directly apricodd  add approximation steps performed
algorithm can  principle  allow apricodd find approximate solutions problem  spent significant amount time attempting find best set parameters
apricodd problems   settled sift method variable reordering
round approximation method size  maximum add size  criteria 
   grateful jesse hoey robert st aubin assistance selecting parameters 

   

figuestrin  koller  parr   venkataraman

allow value function representation scale problem size  set maximum
add size           n network n machines   we experimented variety
different growth rates maximum add size  here  parameters 
selected choice gave best results apricodd   compared apricodd
parameters rule based approximate linear programming algorithm
single  basis functions pentium iii    mhz  gb ram  results
summarized figure    
small problems  up    machines   performance two algorithms
fairly similar terms running time quality policies generated 
however  problem size grows  running time apricodd increases rapidly 
becomes significantly higher algorithm   furthermore  problem size
increases  quality policies generated apricodd deteriorates  difference
policy quality caused different value function representation used two
algorithms  adds used apricodd represent k different values k leaves  thus 
forced agglomerate many different states represent using single value 
smaller problems  agglomeration still represent good policies  unfortunately 
problem size increases state space grows exponentially  apricodds policy
representation becomes inadequate  quality policies decreases 
hand  linear value functions represent exponentially many values k basis
functions  allows approach scale significantly larger problems 

    related work
closely related work line research began work
boutilier et al          address comparison separately below  begin
section broader background references 
     approximate mdp solutions
field mdps  popularly known  formalized bellman       
    s  importance value function approximation recognized early stage
bellman         early     s mdp framework recognized ai
researchers formal framework could used address problem planning
uncertainty  dean  kaelbling  kirman    nicholson        
within ai community  value function approximation developed concomitantly
notion value function representations markov chains  suttons seminal paper
temporal difference learning         addressed use value functions prediction
planning  assumed general representation value function noted
connection general function approximators neural networks  however 
stability combination directly addressed time 
several important developments gave ai community deeper insight relationship function approximation dynamic programming  tsitsiklis van
roy      a  and  independently  gordon        popularized analysis approximate
mdp methods via contraction properties dynamic programming operator
function approximator  tsitsiklis van roy      b  later established general convergence result linear value function approximators d    bertsekas
   

fiefficient solution algorithms factored mdps

tsitsiklis        unified large body work approximate dynamic programming
name neuro dynamic programming  providing many novel general error
analyses 
approximate linear programming mdps using linear value function approximation
introduced schweitzer seidmann         although approach somewhat
deprecated fairly recently due lack compelling error analyses lack
effective method handling large number constraints  recent work de farias
van roy      a      b  started address concerns new error bounds
constraint sampling methods  approach  rather sampling constraints  utilizes
structure model value function represent constraints compactly 
     factored approaches
tatman shachter        considered additive decomposition value nodes influence diagrams  number approaches factoring general mdps explored
literature  techniques exploiting reward functions decompose additively
studied meuleau et al          singh cohn        
use factored representations dynamic bayesian networks pioneered
boutilier et al         developed steadily recent years  methods rely
use context specific structures decision trees analytic decision diagrams
 adds   hoey et al         represent transition dynamics dbn
value function  algorithms use dynamic programming partition state space 
representing partition using tree like structure branches state variables
assigns values leaves  tree grown dynamically part dynamic programming process algorithm creates new leaves needed  leaf split
application dp operator two states associated leaf turn
different values backprojected value function  process interpreted
form model minimization  dean   givan        
number leaves tree used represent value function determines computational complexity algorithm  limits number distinct values
assigned states  since leaves represent partitioning state space  every state
maps exactly one leaf  however  recognized early on  trivial mdps
require exponentially large value functions  observation led line approximation
algorithms aimed limiting tree size  boutilier   dearden        and  later  limiting
add size  st aubin  hoey    boutilier         kim dean        explored
techniques discovering tree structured value functions factored mdps 
methods permit good approximate solutions large mdps  complexity still
determined number leaves representation number distinct values
assigned states still limited well 
tadepalli ok        first apply linear value function approximation
factored mdps  linear value function approximation potentially expressive
approximation method assign unique values every state mdp without
requiring storage space exponential number state variables  expressive
power tree k leaves captured linear function approximator k basis
functions basis function hi indicator function tests state belongs
   

figuestrin  koller  parr   venkataraman

partition leaf i  thus  set value functions represented
tree k leaves subset set value functions represented
value function k basis functions  experimental results section     highlight
difference showing example problem requires exponentially many leaves
value function  approximated well using linear value function 
main advantage tree based value functions structure determined
dynamically solution mdp  principle  value function representation derived automatically model description  approach requires less insight
user  problems value function well approximated relatively small number values  approach provides excellent solution problem 
method linear value function approximation aims address believe
common case  large range distinct values required achieve good
approximation 
finally  note schuurmans patrascu         based earlier work
max norm projection using cost networks linear programs  independently developed
alternative approach approximate linear programming using cost network 
method embeds cost network inside single linear program  contrast  method
based constraint generation approach  using cost network detect constraint
violations  constraint violations found  new constraint added  repeatedly
generating attempting solve lps feasible solution found  interestingly 
approach schuurmans patrascu uses multiple calls variable elimination
order speed lp solution step  successful time spent
solving lp significantly larger time required variable elimination 
suggested section      lp solution time larger table based approach  thus 
schuurmans patrascus constraint generation method probably successful
table based problems rule based ones 

    conclusions
paper  presented new algorithms approximate linear programming approximate dynamic programming  value policy iteration  factored mdps 
algorithms leverage novel lp decomposition technique  analogous variable elimination cost networks  reduces exponentially large lp provably
equivalent  polynomial sized one 
approximate dynamic programming algorithms motivated error analyses
showing importance minimizing l error  algorithms efficient
substantially easier implement previous algorithms based l   projection 
experimental results suggest perform better practice 
approximate linear programming algorithm factored mdps simpler  easier
implement general dynamic programming approaches  unlike policy
iteration algorithm  rely default action assumption  states
actions affect small number state variables  although algorithm
theoretical guarantees max norm projection approaches  empirically seems
favorable option  experiments suggest approximate policy iteration tends
generate better policies set basis functions  however  due computa   

fiefficient solution algorithms factored mdps

tional advantages  add basis functions approximate linear programming
algorithm  obtaining better policy still maintaining much faster running time
approximate policy iteration 
unlike previous approaches  algorithms exploit additive contextspecific structure factored mdp model  typical real world systems possess
types structure  thus  feature algorithms increase applicability factored mdps practical problems  demonstrated exploiting
context specific independence  using rule based representation instead standard
table based one  yield exponential improvements computational time problem significant amounts csi  however  overhead managing sets rules make
less well suited simpler problems  compared approach work
boutilier et al          exploits context specific structure  problems
significant context specific structure value function  approach faster due
efficient handling add representation  however  problems
significant context specific structure problem representation  rather value
function  require exponentially large adds  problems  demonstrated using linear value function algorithm obtain polynomial time
near optimal approximation true value function 
success algorithm depends ability capture important
structure value function using linear  factored approximation  ability  turn 
depends choice basis functions properties domain 
algorithms currently require designer specify factored basis functions 
limitation compared algorithms boutilier et al          fully automated 
however  experiments suggest simple rules quite successful designing basis  first  ensure reward function representable basis 
simple basis that  addition  contained separate set indicators variable often
quite well  add indicators pairs variables  simply  choose
according dbn transition model  indicator added variables
xi one variables parents xi    thus representing one step influences 
procedure extended  adding basis functions represent influences
required  thus  structure dbn gives us indications choose basis
functions  sources prior knowledge included specifying
basis 
nonetheless  general algorithm choosing good factored basis functions still
exist  however  potential approaches  first  problems csi  one
could apply algorithms boutilier et al  iterations generate partial treestructured solutions  indicators defined variables backprojection leaves
could  turn  used generate basis set problems  second  bellman
error computation  performed efficiently shown section   
provide bound quality policy  actual state error
largest  knowledge used create mechanism incrementally increase
basis set  adding new basis functions tackle states high bellman error 
many possible extensions work  already pursued extensions collaborative multiagent systems  multiple agents act simultaneously
maximize global reward  guestrin et al       b   factored pomdps 
   

figuestrin  koller  parr   venkataraman

full state observed directly  indirectly observation variables  guestrin 
koller    parr      c   however  settings remain explored 
particular  hope address problem learning factored mdp planning
competitive multiagent system 
additionally  paper tackled problems induced width cost
network sufficiently low possess sufficient context specific structure allow
exact solution factored lps  unfortunately  practical problems may
prohibitively large induced width  plan leverage ideas loopy belief propagation algorithms approximate inference bayesian networks  pearl        yedidia 
freeman    weiss        address issue 
believe methods described herein significantly extend efficiency 
applicability general usability factored models value functions control
practical dynamic systems 

acknowledgements
grateful craig boutilier  dirk ormoneit uri lerner many useful
discussions  anonymous reviewers detailed thorough comments 
would thank jesse hoey  robert st aubin  alan hu  craig boutilier
distributing algorithm useful assistance using apricodd
selecting parameters  work supported dod muri program  administered office naval research grant n                 air force contract
f                darpas task program  sloan foundation  first
author supported siebel scholarship 

appendix a  proofs
a   proof lemma    
exists setting weights zero setting yields bounded maxnorm projection error p policy  p rmax    max norm projection operator
chooses set weights minimizes projection error  t  policy  t    thus 
projection error  t  must least low one given zero weights p
 which bounded   thus  error remains bounded iterations 
a   proof theorem    
first  need bound approximation v t   




v t  hw t 












t t  hw t  hw t 




  v t  t t  hw t 








 t 
 t 
t t  hw hw   v t  hw t 






   triangle inequality  

   t t  contraction  

moving second term right hand side dividing     obtain 




v t  hw t 






 
 t 


 
t t  hw t  hw t   

 
 
   

    

fiefficient solution algorithms factored mdps

next part proof  adapt lemma bertsekas tsitsiklis        lemma
     p      fit framework  manipulation  lemma reformulated as 
kv v t    k kv v t  k  


 


v t  hw t   

 

    

proof concluded substituting equation      equation      and  finally  induction t 
a   proof theorem    
first  note equality constraints represent simple change variable  thus 
rewrite equation      terms new lp variables ufzii as 
max

x

x

ufzii  

    



assignment weights w implies assignment ufzii   stage 
lp variables 
remains show factored lp construction equivalent constraint
equation       system n variables  x            xn    assume  without loss
generality  variables eliminated starting xn x    prove
equivalence induction number variables 
base case n      functions ci  x  b x  equation     
empty scope  case  equation      written as 


x

uei  

    



case  transformation done constraint  equivalence immediate 
now  assume result holds systems i  variables prove equivalence
system variables  system  maximization decomposed
two terms  one factors depend xi   irrelevant
maximization xi   another term factors depend xi   using
decomposition  write equation      as 




max

x ej

x       xi

uzj  

j

max

x       xi 




x

x

uezll   max
xi

l   xi  zl

e
uzjj  

    

j   xi zj

point define new lp variables uez corresponding second term
right hand side constraint  new lp variables must satisfy following
constraint 
uez max
xi

x ej
j  

   

u z xi   zj    

    

figuestrin  koller  parr   venkataraman

new non linear constraint represented factored lp construction
set equivalent linear constraints 
uez

x ej
j  

u z xi   zj     z  xi  

    

equivalence non linear constraint equation      set linear constraints equation      shown considering binding constraints  new
lp variable created uez    xi   new constraints created  one value xi xi  
assignment lp variables right hand side constraint equap
ej
tion       one  xi   constraints relevant  is  one  j   u z x
  zj  
maximal  corresponds maximum xi   again  value z
one assignment xi achieves maximum   and only  constraints
corresponding maximizing assignments could binding  thus  equation     
equation      equivalent 
substituting new lp variables uez equation       get 


max

x       xi 

x

uezll   uez  

l   xi  zl

depend xi anymore  thus  equivalent system i  variables 
concluding induction step proof 
a   proof lemma    
first note iteration     objective function  t    max norm projection
lp given by 








 t      hw t    r t      p t    hw t     


however  convergence value function estimates equal iterations 
w t      w t   
that 








 t      hw t  r t      p t    hw t   


operator notation  term equivalent to 






 t      hw t  t t    hw t   


note that   t      greedy hw t    definition  thus  that 
t t    hw t    hw t   
finally  substituting previous expression  obtain result 






 t      hw t  hw t   


   

fiefficient solution algorithms factored mdps

references
arnborg  s   corneil  d  g     proskurowski  a          complexity finding embeddings
k tree  siam journal algebraic discrete methods                 
becker  a     geiger  d          sufficiently fast algorithm finding close optimal
clique trees  artificial intelligence                 
bellman  r   kalaba  r     kotkin  b          polynomial approximation new computational technique dynamic programming  math  comp                  
bellman  r  e          dynamic programming  princeton university press  princeton  new
jersey 
bertele  u     brioschi  f          nonserial dynamic programming  academic press  new
york 
bertsekas  d     tsitsiklis  j          neuro dynamic programming  athena scientific 
belmont  massachusetts 
boutilier  c   dean  t     hanks  s          decision theoretic planning  structural assumptions computational leverage  journal artificial intelligence research       
   
boutilier  c     dearden  r          approximating value trees structured dynamic
programming  proc  icml  pp       
boutilier  c   dearden  r     goldszmidt  m          exploiting structure policy construction  proc  ijcai  pp           
boutilier  c   dearden  r     goldszmidt  m          stochastic dynamic programming
factored representations  artificial intelligence                   
cheney  e  w          approximation theory   nd edition   chelsea publishing co   new
york  ny 
de farias  d     van roy  b       a   linear programming approach approximate
dynamic programming  submitted operations research 
de farias  d     van roy  b       b   constraint sampling linear programming approach approximate dynamic programming  appear mathematics
operations research 
dean  t   kaelbling  l  p   kirman  j     nicholson  a          planning deadlines
stochastic domains  proceedings eleventh national conference artificial
intelligence  aaai      pp          washington  d c  aaai press 
dean  t     kanazawa  k          model reasoning persistence causation 
computational intelligence                
dean  t     givan  r          model minimization markov decision processes 
proceedings fourteenth national conference artificial intelligence  aaai     pp          providence  rhode island  oregon  aaai press 
dearden  r     boutilier  c          abstraction approximate decision theoretic planning  artificial intelligence                 
   

figuestrin  koller  parr   venkataraman

dechter  r          bucket elimination  unifying framework reasoning  artificial
intelligence                 
gordon  g          stable function approximation dynamic programming  proceedings
twelfth international conference machine learning  pp          tahoe
city  ca  morgan kaufmann 
guestrin  c  e   koller  d     parr  r       a   max norm projections factored mdps 
proceedings seventeenth international joint conference artificial intelligence  ijcai      pp           seattle  washington  morgan kaufmann 
guestrin  c  e   koller  d     parr  r       b   multiagent planning factored mdps 
  th neural information processing systems  nips      pp            vancouver 
canada 
guestrin  c  e   koller  d     parr  r       c   solving factored pomdps linear value
functions  seventeenth international joint conference artificial intelligence
 ijcai     workshop planning uncertainty incomplete information 
pp         seattle  washington 
guestrin  c  e   venkataraman  s     koller  d          context specific multiagent coordination planning factored mdps  eighteenth national conference
artificial intelligence  aaai        pp          edmonton  canada 
hoey  j   st aubin  r   hu  a     boutilier  c          spudd  stochastic planning using decision diagrams  proceedings fifteenth conference uncertainty
artificial intelligence  uai      pp          stockholm  sweden  morgan kaufmann 
hoey  j   st aubin  r   hu  a     boutilier  c          stochastic planning using decision
diagrams c implementation  http   www cs ubc ca spider staubin spudd  
howard  r  a     matheson  j  e          influence diagrams  howard  r  a     matheson  j  e   eds    readings principles applications decision analysis 
pp          strategic decisions group  menlo park  california 
keeney  r  l     raiffa  h          decisions multiple objectives  preferences
value tradeoffs  wiley  new york 
kim  k  e     dean  t          solving factored mdps using non homogeneous partitioning  proceedings seventeenth international joint conference artificial
intelligence  ijcai      pp           seattle  washington  morgan kaufmann 
kjaerulff  u          triangulation graphs algorithms giving small total state space 
tech  rep  tr r        department mathematics computer science  strandvejen  aalborg  denmark 
koller  d     parr  r          computing factored value functions policies structured
mdps  proceedings sixteenth international joint conference artificial
intelligence  ijcai      pp             morgan kaufmann 
koller  d     parr  r          policy iteration factored mdps  proceedings
sixteenth conference uncertainty artificial intelligence  uai      pp     
     stanford  california  morgan kaufmann 
   

fiefficient solution algorithms factored mdps

meuleau  n   hauskrecht  m   kim  k   peshkin  l   kaelbling  l   dean  t     boutilier  c 
        solving large weakly coupled markov decision processes  proceedings
  th national conference artificial intelligence  pp          madison  wi 
pearl  j          probabilistic reasoning intelligent systems  networks plausible inference  morgan kaufmann  san mateo  california 
puterman  m  l          markov decision processes  discrete stochastic dynamic programming  wiley  new york 
reed  b          finding approximate separators computing tree width quickly 
  th annual symposium theory computing  pp          acm 
schuurmans  d     patrascu  r          direct value approximation factored mdps 
advances neural information processing systems  nips      pp           
vancouver  canada 
schweitzer  p     seidmann  a          generalized polynomial approximations markovian decision processes  journal mathematical analysis applications          
    
simon  h  a          sciences artificial  second edition   mit press  cambridge 
massachusetts 
singh  s     cohn  d          dynamically merge markov decision processes 
jordan  m  i   kearns  m  j     solla  s  a   eds    advances neural information
processing systems  vol      mit press 
st aubin  r   hoey  j     boutilier  c          apricodd  approximate policy construction using decision diagrams  advances neural information processing systems
    proceedings      conference  pp            denver  colorado  mit press 
stiefel  e          note jordan elimination  linear programming tchebycheff approximation  numerische mathematik          
sutton  r  s          learning predict methods temporal differences  machine
learning         
tadepalli  p     ok  d          scaling average reward reinforcmeent learning approximating domain models value function  proceedings thirteenth
international conference machine learning  bari  italy  morgan kaufmann 
tatman  j  a     shachter  r  d          dynamic programming influence diagrams 
ieee transactions systems  man cybernetics                 
tsitsiklis  j  n     van roy  b       a   feature based methods large scale dynamic
programming  machine learning           
tsitsiklis  j  n     van roy  b       b   analysis temporal difference learning
function approximation  technical report lids p       laboratory information
decision systems  massachusetts institute technology 
van roy  b          learning value function approximation complex decision
processes  ph d  thesis  massachusetts institute technology 
   

figuestrin  koller  parr   venkataraman

williams  r  j     baird  l  c  i          tight performance bounds greedy policies based
imperfect value functions  tech  rep   college computer science  northeastern
university  boston  massachusetts 
yedidia  j   freeman  w     weiss  y          generalized belief propagation  advances
neural information processing systems     proceedings      conference 
pp          denver  colorado  mit press 
zhang  n     poole  d          role context specific independence probabilistic
reasoning  proceedings sixteenth international joint conference artificial
intelligence  ijcai      pp            morgan kaufmann 

   


