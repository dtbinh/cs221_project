journal of artificial intelligence research                 

submitted        published      

location based reasoning about complex multi agent behavior
adam sadilek
henry kautz

sadilek   cs   rochester   edu
kautz   cs   rochester   edu

department of computer science  university of rochester
rochester  ny        usa

abstract
recent research has shown that surprisingly rich models of human activity can be learned from
gps  positional  data  however  most effort to date has concentrated on modeling single individuals or statistical properties of groups of people  moreover  prior work focused solely on modeling
actual successful executions  and not failed or attempted executions  of the activities of interest 
we  in contrast  take on the task of understanding human interactions  attempted interactions  and
intentions from noisy sensor data in a fully relational multi agent setting  we use a real world
game of capture the flag to illustrate our approach in a well defined domain that involves many
distinct cooperative and competitive joint activities  we model the domain using markov logic  a
statistical relational language  and learn a theory that jointly denoises the data and infers occurrences of high level activities  such as a player capturing an enemy  our unified model combines
constraints imposed by the geometry of the game area  the motion model of the players  and by
the rules and dynamics of the game in a probabilistically and logically sound fashion  we show
that while it may be impossible to directly detect a multi agent activity due to sensor noise or malfunction  the occurrence of the activity can still be inferred by considering both its impact on the
future behaviors of the people involved as well as the events that could have preceded it  further 
we show that given a model of successfully performed multi agent activities  along with a set of
examples of failed attempts at the same activities  our system automatically learns an augmented
model that is capable of recognizing success and failure  as well as goals of peoples actions with
high accuracy  we compare our approach with other alternatives and show that our unified model 
which takes into account not only relationships among individual players  but also relationships
among activities over the entire length of a game  although more computationally costly  is significantly more accurate  finally  we demonstrate that explicitly modeling unsuccessful attempts
boosts performance on other important recognition tasks 

   introduction
our society is founded on the interplay of human relationships and interactions  since every person is tightly embedded in our social structure  the vast majority of human behavior can be fully
understood only in the context of the actions of others  thus  not surprisingly  more and more evidence shows that when we want to model behavior of a person  the single best predictor is often the
behavior of people in her social network  for instance  behavioral patterns of people taking taxis 
rating movies  choosing a cell phone provider  or sharing music are best explained and predicted by
the habits of related people  rather than by all the single person attributes such as age  race  or
education  bell  koren    volinsky        pentland        
in contrast to these observations  most research effort on activity recognition to date has concentrated on modeling single individuals  bui        liao  fox    kautz               or statistical
properties of aggregate groups of individuals  abowd  atkeson  hong  long  kooper    pinkerton 
      horvitz  apacible  sarin    liao         or combinations of both  eagle   pentland        
c
    
ai access foundation  all rights reserved 

fis adilek   k autz

notable exceptions to this isolated individuals approach includes the work of kamar and horvitz
       and gupta  srinivasan  shi  and davis         where simple relationships among people are
just starting to be explicitly considered and leveraged  for instance  eagle and pentland       
elegantly model the location of individuals from multi modal sensory data  but their approach is
oblivious to the explicit effects of ones friends  relatives  etc  on ones behavior  the isolated individuals approximations are often made for the sake of tractability and representational convenience 
while considering individuals independently of each other is sufficient for some constrained tasks 
in many interesting domains it discards a wealth of important information or results in an inefficient and unnatural data representation  on the other hand  decomposing a domain into a set of
entities  representing for instance people  objects in their environment  or activities  that are linked
by various relationships  e g   is a  has a  is involved in  is a natural and clear way of representing
data 
to address the shortcomings of nonrelational behavior modeling  we introduce the capture the
flag domain  described below   and argue for a statistical relational approach to learning models
of multi agent behavior from raw gps data  the ctf dataset is on one hand quite complex and
recorded by real world sensors  but at the same time it is well defined  as per the rules of the game  
thereby allowing for an unambiguous evaluation of the results 
being able to recognize peoples activities and reason about their behavior is a necessary precondition for having intelligent and helpful machines that are aware of what is going on in the
human machine as well as human human relationships  there are many exciting practical applications of activity recognition that have the potential to fundamentally change peoples lives  for
example  cognitive assistants that help people and teams be more productive  or provide support to
 groups of  disabled individuals  or efficiently summarize a long complex event to a busy person
without leaving out essential information  other important applications include intelligent navigation  security  physical as well as digital   human computer interaction  and crowdsourcing  all
these applications and a myriad of others build on top of multi agent activity recognition and therefore require it as a necessary stepping stone  furthermore  as a consequence of the anthropocentrism
of our technology  modeling human behavior playsperhaps surprisinglya significant role even
in applications that do not directly involve people  e g   unmanned space probes  
furthermore  reasoning about human intentions is an essential element of activity recognition 
since if we can recognize what a person  or a group of people  wants to do  we can proactively
try to help them  orin adversarial situationshinder them   intent is notoriously problematic to
quantify  e g   baldwin   baird         but we show that in the capture the flag domain  the notion
is naturally captured in the process of learning the structure of failed activities  we all know perhaps
too well that a successful action is often precededand unfortunately sometimes also followedby
multiple failed attempts  therefore  reasoning about attempts typically entails high practical utility 
but not just for their relatively high frequency  consider  for example  a task of real time analysis
of a security video system  there  detecting that a person or a group of people  again  relations 
intend to steal something is much more important and useful than recognizing that a theft has taken
 or even is taking  place  because then it is certainly too late to entirely prevent the incident  and it
may also be too late or harder to merely stop it  we believe that recognition of attempts in peoples
activities is a severely underrepresented topic in artificial intelligence that needs to be explored more
since it opens a new realm of interesting possibilities 
before we delve into the details of our approach in sections   and    we briefly introduce
the ctf dataset  section     highlight the main contributions of our work  section     and review
  

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

background material  section     we discuss related work  conclude  and outline future work in
sections      and   respectively 
this paper incorporates and extends our previous work  sadilek   kautz      a      b  

   capture the flag domain
imagine two teamsseven players eachplaying capture the flag  ctf  on a university campus 
where each player carries a consumer grade global positioning system  gps  that logs its location
 plus noise  every second  see figure     the primary goal is to enter the opponents flag area 
players can be captured only while on enemy territory by being tagged by the enemy  upon being
captured  they must remain in place until freed  tagged by a teammate  or the game ends  the
games involve many competitive and cooperative activities  but here we focus on  both successful
and attempted  capturing and freeing  visualization of the games is available from the first authors
website 
we collected four games of ctf on a portion of the university of rochester campus  about
   acres  with columbus v     gps loggers  one per player  with   gb memory card each that
were set to a sampling rate of   hz  the durations of the games ranged approximately from   to   
minutes 
our work is not primarily motivated by the problem of annotating strategy games  although
there are obvious applications of our results to sports and combat situations  we are  more generally  exploring relational learning and inference methods for recognizing multi agent activities
from location data  we accept the fact that the gps data at our disposal is inherently unreliable and
ambiguous for any one individual  we therefore focus on methods that jointly and simultaneously
localize and recognize the high level activities of groups of individuals 
although the ctf domain doesnt capture all the intricacies of life  it contains many complex  interesting  and yet well defined  multi agent  activities  moreover  it is based on extensive
real world gps data  total of         data points   thus most of the problems that we are addressing here clearly have direct analogs in everyday life situations that ubiquitous computing needs to
addressimagine people going about their daily lives in a city instead of ctf players  and their
own smart phones instead of gps loggers 
one of the main challenges we have to overcome if we are to successfully model ctf is the
severe noise present in the data  accuracy of the gps data varies from   to more than    meters  in
open areas  readings are typically off by   meters  but the discrepancy is much higher in locations
with tall buildings  which are present within the game area  or other obstructions  compare the
scale of the error with the granularity of the activities we concern ourselves with  both capturing
and freeing involves players that are within reaching distance  less than   meter  apart  therefore 
the signal to noise ratio in this domain is daunting 
the error has a systematic component as well as a significant stochastic component  errors
between devices are poorly correlated  because subtle differences between players  such as the angle
at which the device sits in the players pocket  can dramatically affect accuracy  moreover  since
we consider multi agent scenarios  the errors in individual players readings can add up  thereby
creating a large discrepancy between the reality and the recorded dataset  because players can
move freely through open areas  we cannot reduce the data error by assuming that the players move
along road or walkways  as is done in much work on gps based activity recognition  e g   liao
et al          finally  traditional techniques for denoising gps data  such as kalman filtering  are

  

fis adilek   k autz

figure    a snapshot of a game of capture the flag that shows most of the game area  players are
represented by pins with letters  in our version of ctf  the two flags are stationary
and are shown as white circles near the top and the bottom of the figure  the horizontal road in the middle of the image is the territory boundary  the data is shown prior
to any denoising or corrections for map errors  videos of the games are available at
http   www cs rochester edu u sadilek 
  

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

of little help  due to the low data rate    sample per second  relative to the small amount of time
required for a player to completely change her speed or direction 
if we are to reliably recognize events that happen in these games in the presence of such severe
noise  we need to consider not only each player  but also the relationships among them and their
actions over extended periods of time  possibly the whole length of the game   consider a concrete
task of inferring the individual and joint activities and intentions of the ctf players from their gps
traces  for example  suppose the gps data shows player a running toward a stationary teammate
b  then moving away  what occurred  possibly player a has just freed player b  but gps error
has hidden the fact that player a actually reached b  another possibility is that player a had the
intention of freeing player b  but was scared off by an opponent at the last second  yet another possibility is that no freeing occurred nor was even intended  because player b had not been previously
captured 
understanding a game thus consists of inferring a complex set of interactions among the various
players as well as the players intentions  the conclusions drawn about what occurs at one point in
time affect and are affected by inferences about past and future events  in the example just given 
recognizing that player b is moving in the future reinforces the conclusion that player a is freeing
player b  while failing to recognize a past event of player b being captured decreases confidence in
that conclusion  the game of ctf also illustrates that understanding a situation is as much or more
about recognizing attempts and intentions as about recognizing successfully executed actions  for
example  in course of a    minute game  only a handful of capture or freeing events occur  however 
there are dozens of cases where one player unsuccessfully tries to capture an opponent or to free a
teammate  a description of a game that was restricted to what actually occurred would be only a
pale reflection of the original 

figure    three snapshots of a game situation where both successful and failed capturing occur 
this example also illustrates the need for an approach that exploits both the relational
and the far reaching temporal structure of our domain   see text for explanation  

as a concrete example  consider a real game situation illustrated in figure    there we see three
snapshots of a game projected over a map of the campus before any modification of the gps data 
the game time is shown on each snapshot  players d  f  and g are allies and are currently on their
home territory near their flag  whereas players l and m are their enemies  in the first snapshot 
players l and m head for the opponents flag but thenin the second framethey are intercepted
by g  at this point it is unclear what is happening because of the substantial error in the gps data

  

fis adilek   k autz

the three players appear to be very close to each other  but in actuality they could have been    or
more meters apart  however  once we see the third snapshot  note that tens of seconds have passed 
we realize that player g actually captured only player m and didnt capture l since g is evidently
still chasing l  the fact that player m remains stationary coupled with the fact that neither d nor f
attempt to capture him suggests that m has indeed been captured  we show that it is possible to infer
occurrences of capturing events even for complex situations like these whereas limited approaches
largely fail  however  we need to be able to recognize not just individual events  we also need
to discover new activities  identify their respective goals  and distinguish between events based on
whether their outcomes are favorable or negative  for instance  in the second frame  player g tries
to capture both l and m  although he succeeded in the former case  he failed in the latter 
many different kinds of cooperative and competitive multi agent activities occur in the games 
the lowest level joint activities are based on location and movement  and include approaching and
being at the same location  note  that noise in the gps data often makes it difficult or impossible
to directly detect these simple activities  at the next level come competitive multi agent activities
including capturing and attacking  cooperative activities include freeing  and there are activities 
such as chasing and guarding  that may belong to either category or to both categories  there
are also more abstract tactical activities  such as making a sacrifice  and overall strategies  such as
playing defensively  in this paper  we concentrate on activities at the first two levels 

   our contributions
the main contributions of this paper are as follows  we first present a novel method that simultaneously denoises positional data and learns a model of multi agent activities that occur there  we
subsequently evaluate the model on the ctf dataset and show that it achieves high accuracy in
recognizing complex game events 
however  creating a model by manually writing down new rules or editing existing axioms is
laborious and prone to introduction of errors or unnecessarily complex theories  thus  we would
like to automate this process by learning  or inducing  new axioms from training data  for people 
it is much easier to provide or validate concrete examples than to directly modify a model  this
leads us to our second contribution  we show how to automatically augment a preexisting model of
 joint  activities so that it is capable of not only recognizing successful actions  but also identifies
failed attempts at the same types of activities  this line of work also demonstrates that explicitly
modeling attempted interactions in a unified way improves overall model performance 
as our third contribution  we demonstrate that the difference  discussed below  between the
newly learned definitions of a failed activity and the original definition of the corresponding successful activity directly corresponds to the goal of the given activity  for instance  as per the rules
of the capture the flag game  a captured player cannot move until freed  when our system induces
the definition of failed capture  the new theory does not contain such a constraint on the movement
of the almost captured player  thereby allowing him to move freely 

   background
the cores of our models described below are implemented in markov logic  ml   a statisticalrelational language  in this section  we provide a brief overview of ml  which extends finite firstorder logic  fol  to a probabilistic setting  for a more detailed  and excellent  treatment of fol 

  

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

ml  and inductive logic programming see the work of shoenfield         domingos  kok  lowd 
poon  richardson  and singla         and de raedt and kersting         respectively 
in order to compare the markov logic based models to alternative approaches  we consider a
dynamic bayesian network  dbn  model in the experiments below as one of our baselines  we
therefore review relevant aspects of dbns in this section as well 
    markov logic
given the inherent uncertainty involved in reasoning about real world activities as observed through
noisy sensor readings  we looked for a methodology that would provide an elegant combination of
probabilistic reasoning with the expressive  relatively natural  and compact but unfortunately strictly
true or false formulas of first order logic  and that is exactly what markov logic provides and thus
allows us to elegantly model complex finite relational non i i d  domains  a markov logic network
 mln  consists of a set of constants c and of a set of pairs hfi   wi i such that each fol formula
fi has a weight wi  r associated with it  optionally  each weight can be further scaled by a
real valued function of a subset of the variables that appear in the corresponding formula  markov
logic networks that contain such functions are called hybrid mlns  wang   domingos        
a mln can be viewed as a template for a markov network  mn  as follows  the mn contains
one node for each possible ground atom of mln  the value of the node is   if the corresponding
atom is false and   otherwise  two nodes are connected by an edge if the corresponding atoms
appear in the same formula  thus  the mn has a distinct clique corresponding to each grounding of
g
each formula  by fi j we denote the j th grounding of formula fi   the mn has a feature value fi j
gj
for each fi such that
 
g
  if fi j is true
fi j  
  otherwise
each weight wi intuitively represents the relative importance of satisfying  or violating  if the
weight is negative  the corresponding formula fi   more formally  the weight scales the difference
in log probability between a world that satisfies n groundings of the corresponding formula and one
that results in m true groundings of the formula  all else being equal  cf  equation     thus the
problem of satisfiability is relaxed in mlns  we no longer search for a satisfying truth assignment
as in traditional fol  instead  we are looking for a truth assignment that maximizes the sum of the
weights of all satisfied formulas 
the weights can be either specified by the knowledge base engineer or  as in our approach 
learned from training data  that is  we provide the learning algorithm with labeled capture instances and pairs of raw and corresponding denoised trajectories along with labeled instances of
game events and it finds an optimal set of weights that maximize the likelihood of the training
data  weight learning can be done in either generative or discriminative fashion  generative training maximizes the joint probability of observed  evidence  as well as hidden  query  predicates 
whereas discriminative learning directly maximizes the conditional likelihood of the hidden predicates given the observed predicates  since prior work demonstrated that markov network models
learned discriminatively consistently outperform their generatively trained counterparts  singla  
domingos         we focus on discriminative learning in our activity recognition domain 
once the knowledge base with weights has been specified  we can ask questions about the state
of hidden atoms given the state of the observed atoms  let x be a vector of random variables
 one random variable for each possible ground atom in the mn  and let  be the set of all possible
  

fis adilek   k autz

instantiations of x  then  each x   represents a possible world  if  x    pr x   x      
holds  the probability distribution over these worlds is defined by
 
x

 
pr x   x    exp
wi ni x i 
   
z
i

where ni  x i    is the number of true groundings of i th formula with wi as its weight in a world x
and
 
x
x

z 
exp
wi ni x i 
   
x

i

equation   can be viewed as assigning a score to each possible world and dividing each score
by the sum of all scores over all possible worlds  the constant z  in order to normalize 
maximum a posteriori  map  inference in markov logic given the state of the observed atoms
reduces to finding a truth assignment for the hidden atoms such that the weighed sum of satisfied
clauses is maximal  even though this problem is in general  p complete  we achieve reasonable
run times by applying cutting plane map inference  cpi   riedel         cpi can be thought of as
a meta solver that incrementally grounds a markov logic network  at each step creating a markov
network that is subsequently solved by any applicable methodsuch as maxwalksat or via a
reduction to an integer linear program  cpi refines the current solution by searching for additional
groundings that could contribute to the objective function 
up to this point  we have focused on first order markov logic  in first order ml  each variable
ranges over objects present the domain  e g   apples  players  or cars   on the other hand  in finite
second order markov logic  we variabilize not only objects but also predicates  relations  themselves  kok   domingos         our ctf model contains a predicate variable for each type of activity  for example  we have one variable capturetype whose domain is  capturing  failedcapturing 
and analogously for freeing events  when grounding the second order ml  we ground all predicate
variables as well as object variables  there has also been preliminary work on generalizing ml to
be well defined over infinite domains  which would indeed give it the full power of fol  singla  
domingos        
implementations of markov logic include alchemy  and thebeast    our experiments used a
modified version of thebeast 
    dynamic bayesian networks
a bayesian network  bn  is a directed probabilistic graphical model  jordan         nodes in the
graph represent random variables and edges represent conditional dependencies  cf  figure     for
a bn with n nodes  the joint probability distribution is given by
pr x            xn    

n
y
i  

   http   alchemy cs washington edu 
   http   code google com p thebeast 

  


pr xi  pa xi    

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

where pa xi   denotes the parents of node xi   in a typical setting  a subset of the random variables
is observed  we know their actual values   while the others are hidden and their values need to be
inferred 
a dynamic bayesian network  dbn  is a bn that models sequential data  a dbn is composed
of slicesin our case each slice represents a one second time interval  in order to specify a dbn 
we either write down or learn intra  and inter slice conditional probability distributions  cpds  
the intra slice cpds typically constitute the observation model while the inter slice cpds model
transitions between hidden states  for an extensive treatment of dbns  see the work of murphy
       
there are a number of parameter learning and inference techniques for dbns  to match the
markov logic based framework  in the experiments with the dbn model presented below  we focus
on a supervised learning scenario  where the hidden labels are known at training time and therefore
a maximum likelihood estimate can be calculated directly 
we find a set of parameters  discrete probability distributions   that maximize the log likelihood
of the training data  this is achieved by optimizing the following objective function 

    argmax log pr x  t   y  t     

   



where x  t and y  t represent the sequence of observed and hidden values  respectively  between
times   and t  and   is the set of optimal model parameters  in our implementation  we represent
probabilities and likelihoods with their log counterparts to avoid arithmetic underflow 
at testing time  we are interested in the most likely explanation of the observed data  that is  we
want to calculate the most likely assignment of states to all the hidden nodes  i e   viterbi decoding
of the dbn  given by

 
   
y  t
  argmax log pr y  t  x  t    
y  t

where pr y  t  x  t   is the conditional probability of a sequence of hidden states y  t given a concrete
sequence of observations x  t between times   and t  we calculate the viterbi decoding efficiently
using dynamic programming  jordan        

   methodology
in this section  we describe the three major components of our approach  in short  we first manually
construct a model of captures and freeings in ctf and optimize its parameters in a supervised
learning framework  section       this constitutes our seed theory that is used for denoising raw
location data and recognition of successful multi agent activities  we then show  in section     
how to automatically extend the seed theory by inducing the structure and learning the importance
of failed captures and freeings as well as the relationships to their successful counterparts  finally  in
section      we use the augmented theory to recognize this richer set of multi agent activitiesboth
successful and failed attemptsand extract the goals of the activities 
specifically  we investigate the following four research questions 
q   can we reliably recognize complex multi agent activities in the ctf dataset even in the presence of severe noise 
q   can models of attempted activities be automatically learned by leveraging existing models of
successfully performed actions 
  

fis adilek   k autz

q   does modeling both success and failure allow us to infer the respective goals of the activities 
q   does modeling failed attempts of activities improve the performance on recognizing the activities themselves 
we now elaborate on each of the three components of our system in turn  and subsequently
discuss  in light of the experimental results and lessons learned  our answers to the above research
questions 
    recognition of successful activities
in this section  we present our unified framework for intelligent relational denoising of the raw gps
data while simultaneously labeling instances of a player being captured by an enemy or freed by an
ally  both the denoising and the labeling are cast as a learning and inference problem in markov
logic  by denoising  we mean modifying the raw gps trajectories of the players such that the final
trajectories satisfy constraints imposed by the geometry of the game area  the motion model of the
players  as well as by the rules and the dynamics of the game  in this paper  we refer to this trajectory
modification as snapping since we tile the game area with   by   meter cells and snap each raw
gps reading to an appropriate cell  by creating cells only in unobstructed space  we ensure the final
trajectory is consistent with the map of the area 
we begin by modeling the domain via a markov logic theory  where we write the logical formulas that express the structure of the model by hand  and learn an optimal set of weights on the
formulas from training data in a supervised discriminative fashion  details on the experimental setup are in section     in the following two subsections  we will show how to augment this seed
markov logic theory to recognize a richer set of events and extract the goals of players multi agent
activities 
in order to perform data denoising and recognition of successful capturing and freeing  we
model the game as weighted formulas in markov logic  some of the formulas are hard  in the
sense that we are only interested in solutions that satisfy all of them  hard formulas capture basic
physical constraints  e g   a player is only at one location at a time  and inviolable rules of the game
 e g   a captured player must stand still until freed or the game ends    the rest of the formulas
are soft  meaning there is a finite weight associated with each one  some of the soft constraints
correspond to a traditional low level data filter  expressing preferences for smooth trajectories that
are close to the raw gps readings  other soft constraints capture high level constraints concerning
when individual and multi agent activities are likely to occur  for example  a soft constraint states
that if a player encounters an enemy on the enemys territory  the player is likely to be captured 
the exact weights on the soft constraints are learned from labeled data  as described below 
we distinguish two types of atoms in our models  observed  e g   gps p                      
and hidden  e g   freeing p    p         the observed predicates in the ctf domain are  gps  enemies  adjacent  onhometer  and onenemyter   whereas capturing  freeing  iscaptured  isfree 
sameplace  and snap are hidden  additionally  the set of hidden predicates is expanded by the structure learning algorithm described below  see table   for predicate semantics   in the training phase 
   cheating did not occur in our ctf games  but in principle could be accommodated by making the rules highlyweighted soft constraints rather than hard constraints 
   while the noise in the gps data introduces some ambiguity to the last two observed predicates  we can still reliably
generate them since the road that marks the boundary between territories constitutes a neutral zone 

  

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

hard rules 
h   each raw gps reading is snapped to exactly one cell 
h  

 a  when player a frees player b  then both involved players must be snapped to a common cell at
that time 
 b  a player can only be freed by a free ally 
 c  a player can be freed only when he or she is currently captured 
 d  immediately after a freeing event  the freed player transitions to a free state 
 e  a player can only be freed while on enemy territory 

h  

 a  when player a captures player b  then both involved players must be snapped to a common cell
at that time 
 b  a player can only be captured by a free enemy 
 c  a player can be captured only if he or she is currently free 
 d  immediately after a capture event  the captured player transitions to a captured state 
 e  a player can be captured only when standing on enemy territory 

h   all players are free at the beginning of the game 
h   at any given time  a player is either captured or free but not both 
h   a player transitions from a captured state to a free state only via a freeing event 
h   a player transitions from a free state to a captured state only via a capture event 
h   if a player is captured then he or she must remain in the same location 

soft rules 
s   minimize the distance between the raw gps reading and the snapped to cell 
s   minimize projection variance  i e   two consecutive snappings should be generally correlated 
s   maximize smoothness  both in terms of space and time  of the final player trajectories 
s   if players a and b are enemies  a is on enemy territory and b is not  b is not captured already  and they
are close to each other  then a probably captures b 
s   if players a and b are allies  both are on enemy territory  b is currently captured and a is not  and they
are close to each other  then a probably frees b 
s   capture events are generally rare  i e   there are typically only a few captures within a game 
s   freeing events are also generally rare 

figure    descriptions of the hard and soft rules for capture the flag 
our learning algorithm has access to the known truth assignment to all atoms  in the testing phase 
it can still access the state of the observed atoms  but it has to infer the assignment to the hidden
atoms 
figure   gives an english description of our hard and soft rules for the low level movement
and player interactions within capture the flag  corresponding formulas in the language of ml are
shown in figures   and   
  

fis adilek   k autz

predicate
capturing a  b  t 
enemies a  b 
adjacent c    c   
failedcapturing a  b  t 
failedfreeing a  b  t 
freeing a  b  t 
iscaptured a  t 
isfailedcaptured a  t 

type
hidden
observed
observed
hidden
hidden
hidden
hidden
hidden

isfailedfree a  t 

hidden

isfree a  t 

hidden

onenemyter a  t 
onhometer a  t 
sameplace a  b  t 

observed
observed
hidden

snap a  c  t 

hidden

meaning
player a is capturing b at time t 
players a and b are enemies 
cells c  and c  are mutually adjacent  or c    c   
player a is unsuccessfully capturing b at time t 
player a is unsuccessfully freeing b at time t 
player a is freeing b at time t 
player a is in captured state at time t 
at time t  player a is in a state that follows
an unsuccessful attempt at capturing a 
a in this state has the same capabilities as when free 
at time t  player a is in a state that follows
an unsuccessful attempt at freeing a 
a in this state has the same capabilities as when captured 
player a is in free state at time t
 isfree a  t    iscaptured a  t   
player a in on enemy territory at time t 
player a in on home territory at time t 
players a and b are either snapped to a common cell
or to two adjacent cells at time t 
player a is snapped to cell c at time t 

table    summary of the logical predicates our models use  predicate names containing the word
failed are introduced by the markov logic theory augmentation method described in
section       

we compare our unified approach with four alternative models  the first two models  baseline
and baseline with states  are purely deterministic and they separate the denoising of the gps data
and the labeling of game events  we implemented both of them in perl  they do not involve any
training phase  the third alternative model is a dynamic bayesian network shown in figure   
finally  we have two models cast in markov logic  the two step ml model and the unified ml
model itself  the unified model handles the denoising and labeling in a joint fashion  whereas the
two step approach first performs snapping given the geometric constraints and subsequently labels
instances of capturing and freeing  the latter three models are evaluated using four fold crossvalidation where in order to test on a given game  we first train a model on the other three games 
all of our models can access the following observed data  raw gps position of each player at
any time and indication whether they are on enemy or home territory  location of each   by   meter
cell  cell adjacency  and list of pairs of players that are enemies  we tested all five models on the
same observed data  the following describes each model in more detail 
 baseline model  b 
this model has two separate stages  first we snap each reading to the nearest cell and afterward we label the instances of player a capturing player b  the labeling rule is simple 
  

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

we loop over the whole discretized  via snapping  data set and output capturing a  b  t  every
time we encounter a pair of players a and b such that they were snapped  in the first step  to
either the same cell or to two mutually adjacent cells at time t  they are enemies  and a is on
its home territory while b is not  freeing recognition is not considered in this simple model
since we need to have a notion of persisting player states  captured or free  in order to model
freeing in a meaningful way 
 baseline model with states  b s 
this second model builds on top of the previous one by introducing a notion that players have states  if player a captures player b at time t  b enters a captured state  in logic 
iscaptured b  t        then b remains in captured state until he moves  is snapped to a different cell at a later time  or the game ends  as per rules of ctf  a player who is in captured
state cannot be captured again 
thus  this model works just like the previous one except whenever it is about to label a
capturing event  it checks the states of the involved players and outputs capturing a  b  t  only
if both a and b are not in captured state 
freeing recognition is implemented in an analogous way to capturing recognition  namely 
every time a captured player b is about to transition to a free state  we check if b has a
free teammate a nearby  again  within the adjacent cells   if that is the case  we output
freeing a  b  t  
 dynamic bayesian network model  dbn 
the dynamic bayesian network model can be viewed as a probabilistic generalization of the
above baseline model with states  the structure of the dbn model for one player is shown
in figure    in each time slice  we have one hidden node and four observed nodes  all of
which represent binary random variables  we want to infer the most likely state s for each
player at any given time t over the course of a game  the state is either free or captured and
is hidden at testing time  there are four observed random variables per time step that model
players motion  m    presence or absence of at least one enemy  en   and ally  an   player
nearby  and finally players location on either home or enemy territory  et    each player is
modeled by a separate dbn  therefore  there are fourteen instantiated dbns for each game 
but within any one game  all the dbns share the same set of parameters 
note that the dbn model does not perform any gps trajectory denoising itself  to make a fair
comparison with the markov logic models  we use the denoising component of the markov
logic theory using only constraints h  and s s   in figure     this produces a denoised
discretization of the data that is subsequently fed into the dbn model  the random variables
within the dbn that capture the notion of player movement and players being nearby one
another is defined on the occupancy grid of the game area  just like in the two deterministic
baseline models  namely  a player is said to be moving between time t and t     when he
or she is snapped to two different nonadjacent cells at those times  similarly  two players are
nearby if they are snapped either to the same cell or to two adjacent cells 
 two step ml model   sml 
in the two step approach  we have two separate theories in markov logic  the first theory
is used to perform a preliminary snapping of each of the player trajectories individually us  

fis adilek   k autz

ett

   

ent

ant

ett  

ent  

st

st  

mt

mt  

ant  

   

figure    two consecutive time slices of our dynamic bayesian network for modeling the state
of an individual player p from observations  shaded nodes represent observed random
variables  unfilled denote hidden variables  all random variables are binary   ett    
when p is on enemy territory at time t  ent     when there is an enemy nearby at time
t  ant     when there is an ally nearby at time t  and finally mt     if p has moved
between time t    and t  the value of hidden state st is   if p is captured at time t and
  when p is free  

ing constraints h  and s s   in figure     this theory is identical to the one used in the
discretization step in the dbn model above 
the second theory then takes this preliminary denoising as a list of observed atoms in the
form preliminarysnap a  c  t   meaning player a is snapped to cell c at time t  and uses the
remaining constraints to label instances of capturing and freeing  while considering cell adjacency in the same manner as the previous three models  the two step model constitutes a
decomposition of the unified model  see below  and overall contains virtually the same formulas  except  sml operates with an observed preliminarysnap predicate  whereas the unified
model contains a hidden snap predicate instead  thus we omit elaborating on it further here 
 unified ml model  uml 
in the unified approach  we express all the hard constraints h h  and soft constraints s 
s   figure    in markov logic as a single theory that jointly denoises the data and labels game
events  selected interesting formulas are shown in figure  their labels correspond to the
listing in figure    note that formulas s s  contain real valued functions d    d    and d 
respectively  d  returns the distance between agent a and cell c at time t  similarly  d  returns
the dissimilarity of the two consecutive snapping vectors  given agent as position at time t
and t     and the location of the centers of two cells c  and c    finally  since people prefer to
move in straight lines  function d  quantifies the lack of smoothness of any three consecutive
segments of the trajectory  since wp   ws   and wt are all assigned negative values during
training  formulas s s  effectively softly enforce the corresponding geometric constraints 
   the initial point of each snapping  projection  vector is a raw gps reading and the terminal point is the center of the
cell we snap that reading to 

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

the presence of functions d  through d  renders formulas s s  hybrid formulas  this means
that at inference time  the instantiated logical part of each formula evaluates to either    true 
or    false   which is in turn multiplied by the product of the corresponding function value
and the formula weight 
we will see how we train  test  and evaluate these four models  and how they perform on the
multi agent activity recognition task in section    next  we turn to our supervised learning method
for augmenting the unified ml model in order to recognize both successful and failed attempts at
multi agent activities 
hard formulas 
a  t c   snap a  c  t 
 

 h  
 

 

a  c  c   t    snap a  c  t   c    c    snap a  c   t 
a    a    t   freeing a    a    t   sameplace a    a    t   isfree a    t 

 h  

enemies a    a     iscaptured a    t   isfree a    t     

onenemyter a    t   onenemyter a    t 

a    a    t   capturing a    a    t   sameplace a    a    t   isfree a    t 

 h  

enemies a    a     isfree a    t   iscaptured a    t     

onhometer a    t   onenemyter a    t 

a    a    t   sameplace a    a    t   c    c    snap a    c    t   snap a    c    t   adjacent c    c   



a  t    t       isfree a  t 

 h  

a  t   iscaptured a  t   isfree a  t 

 h  

a  t    isfree a  t   iscaptured a  t            a    capturing a    a  t  

 h  

a  t    iscaptured a  t   isfree a  t            a    freeing a    a  t  

 h  

a  t  c    iscaptured a  t   iscaptured a  t       snap a  c  t    snap a  c  t     

 h  

figure    our hard formulas in markov logic  see corresponding rules in figure   for an english
description and table   for explanation of the predicates  in our implementation  the
actual rules are written in the syntax used by thebeast  a markov logic toolkit     
denotes unique existential quantification   designates exclusive or  

    learning models of failed attempts
in the work described above  we manually designed the structure of a markov logic network that
models the capture the flag domain and allows us to jointly denoise the raw gps data and recognize
   

fis adilek   k autz

soft formulas 


a  c  t   snap a  c  t   d   a  c  t   wp

 s  



a c    c    t   snap a  c    t   snap a  c    t       d   a  c    c    t   ws

 s  



a c    c    c    t   snap a  c    t   snap a  c    t       snap a  c    t       d   a  c    c    c    t   wt
a    a    t     enemies a    a     onhometer a    t 

 s  
 s  

onenemyter a    t   isfree a    t 
sameplace a    a    t    capturing a    a    t    wc
a    a    t     enemies a    a     onenemyter a    t 

 s  

onenemyter a    t   sameplace a    a    t   isfree a    t 
 iscaptured a    t    freeing a    a    t    wf


a  c  t   capturing a  c  t   wcb

 s  

a  c  t    freeing a  c  t    wf b

 s  

figure    soft formulas in markov logic  see corresponding rules in figure   for an english description  each soft formula
is written

 as a traditional quantified finite first order logic
formula  e g   a  c  t   snap a  c  t     followed by an optional function  e g   d   a  c  t   
followed by the weight of the formula  e g   wp    this syntax denotes that at inference
time  the instantiated logical part of each formula evaluates to either    true  or    false  
which is then effectively multiplied by the product of corresponding function value and
formula weight 

instances of actual capturing and freeing  now we show how to automaticallyin a supervised
learning settingextend this theory to encompass and correctly label not only successful actions 
but also failed attempts at those interactions  that is  given the raw gps data that represent the
ctf games  we want our new model to label instances where player a captures  or frees  player
b as successful captures  successful frees  and instances where player a almost captures  or frees 
player b as failed captures  failed frees   for example  by failed capturing we mean an instance of
players interactions whereup to a pointit appeared that a is capturing b  but when we carefully
consider the events that  potentially  preceded it as well as the impacts of the supposed capture
on the future unfolding of the game  we conclude that it is a false alarm and no capture actually
occurred  in other words  the conditions for a capture were right  but later on  there was a pivotal
moment that foiled the capturing agents attempt 
for both activities  capturing and freeing   our model jointly finds an optimal separation between success and failure  note that since we cast our model in second order markov logic  we
do not learn  e g   an isolated rule that separates successful freeing from a failed attempt at freeing 
rathersince capturing and freeing events  both actual and failed  are related and thus labeling
an activity as  say  successful capturing has far reaching impact on our past  present  and future
   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

labelingwe learn the separations in a joint and unified way  namely  both the structure  logical
form  and importance  weight  of each formula in our theory is considered with all its consequences
and influence on other axioms in the theory  our system thus finds an optimal balance between success and failure in capturing and freeing activities with respect to the training data 
      t he t heory augmentation a lgorithm
in what follows  we will describe our markov logic theory augmentation algorithm  algorithm    
for clarity  we will explain how it works in concrete context of the ml models of capture the flag
we discussed in previous sections  however  the underlying assumption that successful actions are
in many ways similar to their failed counterparts  and that minorbut crucialdeviations cause the
failure to occur  often hold beyond capture the flag  therefore  the same algorithm is applicable to
other domains with different activities  as long as they are modeled in markov logic 
algorithm     extend a ml theory to model successful as well as failed activities 
input  a  set of activities
ms   ml theory that models successful instances of activities in a
s  set of examples of successful activities
f   set of examples of failed activities
output  ms f   augmented ml model with learned weights that models both successful and
attempted activities in a
i  intended goals of the activities
  
  
  
  
  
  
  

m s  lifttosecondorderml ms   a 
m s  instantiate m s   a 
i  findincompatibleformulas f   m s  
ms f  m s  i
ms f  learnweights s  f   ms f  
ms f  removezeroweightedformulas ms f  
return ms f   i

at a high level  the augmentation algorithm belongs to the family of structure learning methods  starting with a seed model of successful actions  it searches for new formulas that can be
added to the seed theory in order to jointly model both successfully and unsuccessfully carried out
actions  the declarative language biasessentially rules for exploring the hypothesis space of candidate structuresis defined implicitly by the notion that for any given activity  the structure of
unsuccessful attempts is similar to the successful attempts  therefore  the augmentation algoritm
goes through an inflation stage  where formulas in the seed theory are generalized  followed by
a refinement stage  where superfluous and incompatible formulas in the inflated model are pruned
away  the refinement step also optimizes the weights within the newly induced theory  we will
now discuss this process in more detail 
the input of our theory augmentation algorithm consists of an initial first order ml theory ms
that models successful capturing and freeing  such as the unified ml model defined in section    
that contains formulas shown in figures   and     a set of activities of interest a  and a set of
examples of successful  s  as well as failed  f   captures and frees  ms does not need to have
weights for its soft formulas specified  in case they are missing  we will learn them from scratch in

   

fis adilek   k autz

the final steps of the augmentation algorithm  if the weights are specified  the final weight learning
step for ms f can leverage them to estimate the initial weight values  a can be specified as a
set of predicate names  e g    capturing  freeing   each example in sets s and f describes a game
segment and constitutes a truth assignment to the appropriate literals instantiated from ms   table  
shows two toy examples of sets s and f for three time steps  since the goal is to learn a model
of failed  and successful  attempts in a supervised way  the example game segment in f contain
activities labeled with predicates failedcapturing   and failedfreeing   
if ms contains hybrid formulas  such our formulas s s  in figure     the appropriate function
definitions are provided as part of s and f as well  each definition consists of implicit mapping
from input arguments to function values  for instance  function d  in formula s  quantifies the l 
distance
between the agent a and cell c at time t in the projected mercator space  d   a  c  t   
p
 a gpsxt  c gpsx      a gpsyt  c gpsy     
our system goes through the following process in order to induce a new theory ms f that
augments ms with a definition of failed attempts for each activity already defined in ms  
first we lift ms to second order markov logic by variabilizing all predicates that correspond
to the activities of interest  step   of algorithm     this yields a lifted theory m s   more concretely  in order to apply this technique in our domain  we introduce new predicate variables capturetype  whose domain is  capturing  failedcapturing    freetype  over  freeing  failedfreeing   
and statetype  over  iscaptured  isfailedcaptured  isfree  isfailedfree    for instance  variabilizing a first order ml formula freeing a  b  t   enemies a  b  yields a second order ml formula
freetype a  b  t   enemies a  b   note that freetype is now a variable   instantiating back to
first order yields two formulas  freeing a  b  t   enemies a  b  and failedfreeing a  b  t  
enemies a  b  
as far as agents behavior is concerned  in the ctf domain  iscaptured is equivalent to isfailedfree  and isfree is equivalent to isfailedcaptured  as we will soon see  the theory augmentation
process learns these equivalence classes and other relationships between states from training examples by expanding and subsequently refining formula h  in figure    while we could work with
only the iscaptured predicate and its negation to represent agents states  we feel that having explicit failure states makes our discussion clearer  furthermore  future work will need to address
hierarchies of activities  including their failures  in that context  a representation of explicit failure
states may not only be convenient  but may be necessary 
next  we instantiate all predicate variables in m s to produce a new first order ml theory m s
that contains the original theory ms in its entirety plus new formulas that correspond to failed captures and frees  step     since events that are  e g   near captures appear similar to actual successful
captures  our hypothesis is that we do not need to drastically modify the original successful formulas in order to model the failed activities as well  in practice  the above process of lifting and
instantiating indeed results in a good seed theory  while we could emulate the lifting and grounding
steps with a scheme of copying formulas and renaming predicates in the duplicates appropriately 
we cast our approach in principled second order markov logic  which ties our work more closely to
previous research and results in a more extensible framework  specifically  second order markov
logic has been successfully used in deep transfer learning  davis   domingos        and predicate invention  kok   domingos         therefore  an interesting direction of future work is to
combine our theory augmentation and refinement with transfer and inductive learningoperating
in second order mlto jointly induce models of failed attempts of different activities in different
domains  while starting with a single model of only successful activities in the source domain 
   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

set s  successful capture
enemies p    p   
enemies p    p   
onenemyter p      
onenemyter p      
capturing p    p      
isfree p      
isfree p      
isfree p      
isfree p      
isfree p      
iscaptured p      
snap p    c     
snap p    c      
snap p    c      
snap p    c     
snap p    c      
snap p    c      
sameplace p    p      
sameplace p    p      
sameplace p    p      
sameplace p    p      

set f  failed capture
enemies p    p   
enemies p    p   
onenemyter p      
onenemyter p      
onenemyter p      
failedcapturing p    p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
snap p    c      
snap p    c      
snap p    c     
snap p    c     
snap p    c      
snap p    c     
sameplace p    p      
sameplace p    p      

table    two examples of a logical representation of successful  s  as well as failed  f   capture
events that are input to algorithm    the closed world assumption is applied  therefore
all atoms not listed are assumed to be false  for clarity  we omit listing the adjacent  
predicate 

typical structure learning and inductive logic programming techniques start with an initial  perhaps empty  theory and iteratively grow and refine it in order to find a form that fits the training data
well  in order to avoid searching the generally huge space of hypotheses  a declarative bias is either
specified by hand or mined from the data  the declarative bias then restricts the set of possible refinements of the formulas that the search algorithm can apply  common restrictions include limiting
formula length  and adding a new predicate to a formula only when it shares at least one variable
with some predicate already present in the formula  on the other hand  in our approach  we first
generate our seed theory by instantiating all the activity related predicate variables  to put it into
   

fis adilek   k autz

context of structure learning  we expand the input model in order to generate a large seed theory 
and then apply bottom up  data driven  learning to prune the seed theory  whereby the training data
guides our search for formulas to remove as well as for an optimal set of weights on the remaining
formulas  we conjecture that any failed attempt at an activity always violates at least one constraint
that holds for successful executions of the activity  the experiments below support this conjecture 
the pruning is done in steps   and   of algorithm    the function findincompatibleformulas f  
m s   returns a set of hard formulas in m s that are incompatible with the set of examples of failed
interactions f   we say that a formula c is compatible with respect to a set of examples f if f
logically entails c  f    c   conversely  if f does not entail c  we say that c is incompatible w r t 
f   we explain how to find incompatible formulas in the next section 
in step   of algorithm    we simply remove all incompatible formulas  i  from the theory  at
this point  we have our ms f model  where hard formulas are guaranteed logically consistent with
the examples of failed activities  because we removed the incompatible hard formulas   as well as
with the successful activities  because they were logically consistent to start with   however  the
soft formulas in ms f are missing properly updated weights  in markov logic  the weight of each
hard formula is simply set to     therefore  we run markov logic weight learning using thebeast
package  step    
recall that thebeast implements the cutting plane meta solving scheme for inference in markov
logic  where the ground ml network is reduced to an integer linear program that is subsequently
solved by the lpsolve ilp solver  we chose this approach as opposed to  e g   maxwalksat that
may find a solution that is merely locally optimal  since the resulting run times are still relatively
short  under an hour even for training and testing even the most complex model   weights are
learned discriminatively  where we directly model the posterior conditional probability of the hidden predicates given the observed predicates  we set thebeast to optimize the weights of the soft
formulas via supervised on line learning using margin infused relaxed algorithm  mira  for weight
updates while the loss function is computed from the number of false positives and false negatives
over the hidden atoms  note that if any of the soft formulas are truly irrelevant with respect to the
training examples  they are not picked out by the findincompatibleformulas   function  but their
weights are set to zero  or very close to zero  in the weight learning step  line   in algorithm    
these zero weighted formulas are subsequently removed in the following step  note that the weight
learning process does not need to experience a cold start  as an initial setting of weights can be
inherited from the input theory ms  
finally  we return the learned theory ms f   whose formulas are optimally weighted with respect to all training examples  in the experiments and results section below  we will use ms f to
recognize both successful and failed activities  algorithm   also returns the incompatible hard formulas i  we will see how i is used to extract the intended goal of the activities in the section     
but first  let us discuss step   of algorithm   in more detail 
      c onsistency c heck   f inding i ncompatible f ormulas
now we turn to our method for finding incompatible formulas  summarized in algorithm     since
our method leverages satisfiability testing to determine consistency between candidate theories
and possible worlds  examples    algorithm   can be viewed as an instance of learning from
interpretationsa learning setting in the inductive logic programming literature  de raedt        
   this is often referred to as the covers relation in inductive logic programming 

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

algorithm    findincompatibleformulas   find formulas in a ml theory that are logically inconsistent with examples of execution of failed activities 
input  f   a set of examples of failed activities
t   unrefined ml theory of successful and failed activities
output  smallest set of formulas that appear in t and are unsatisfiable in the worlds in f
  
  
  
  
  
  
  
  
  
   
   
   
   

o  extractobjects f  
thard  t   tsoft
integer n   
boolean result  false
while result    false do
t c  thard
remove a new n tuple of formulas from t c
if for the current n  all n tuples have been tested then
nn  
end if
result  testsat f   t c   o 
end while
return thard   t c

as input  we take a set of examples of failed activities f and a seed theory t  e g   produced
in step   of algorithm     the output is the smallest set of hard formulas that appear in t and
are logically inconsistent with f   the algorithm first extracts the set of all objects o that appear
in f  step   in algorithm     while keeping track of the type of each object  for example  suppose there are only two example worlds in f shown in table    then extractobjects f   returns
 p    p    p    p    c    c          
example  
snap p    c      
snap p    c      
failedcapturing p    p      

example  
snap p    c      
snap p    c      
failedfreeing p    p      

table    two simple examples of a logical representation a failed capture event 

in step    we limit ourselves to only hard formulas when testing compatibility  we do so since
we can prove incompatibility only for hard formulas  soft constraints can be violated many times
in the data and yet we may not want to eliminate them  instead  we want to merely adjust their
weights  which is exactly what we do in our approach  therefore  thard contains only hard formulas
that appear in t   next  on lines   through     we check if the entire unmodified thard is compatible
 since for n      we do not remove any formulas   if it is compatible  we return an empty set
indicating that all the hard formulas in the original seed theory t are compatible with the examples 
if we detect incompatibility  we will need to remove some  and perhaps even all  hard formulas in
order to arrive at a logically consistent theory  therefore  we incrementally start removing n tuples
of formulas  that is  in the subsequent  thard   iterations of the while loop  we determine if we can
   

fis adilek   k autz

restore consistency by removing any one of the hard formulas in thard   if we can  we return the
set thard   fi   where fi is the identified and removed incompatible formula  if consistency cannot
be restored by removing a single formula  we in turn begin considering pairs of formulas  n      
triples  n       etc  until we find a pruned theory t c that is consistent with all examples 
in general  we do need to consider n tuples of formulas  rather than testing each formula in
isolation  this is due to disjunctive formulas in conjunction with an possibly incomplete truth
assignment in the training data  consider the following theory in propositional logic 
f    a  b
f    b  c
data  a  c
 following the closed world assumption  the negated atom c would actually not appear in the training data  but we explicitly include it in this example for clarity   while f  and f  are each individually consistent with the data  f   f  is inconsistent with the data  more complicated examples
can be constructed  where every group of k formulas is inconsistent with the data  even though the
individual formulas are  in a special case where the truth values of all atoms in the training examples are known  the formulas can be tested for consistency individually  which reduces the original
exponential number of iterations algorithm   executes  in the worst case  to a linear complexity 
an interesting direction for future work is to explore applications of logical methods to lower the
computational cost for the general case of partially observed data 
we also note that some hard formulas model physical constraints or inviolable rules of capture
the flag  and therefore hold universally  appropriately  these formulas are not eliminated by algorithm    as an example  consider formula h  in figure    which asserts that each player occupies
exactly one cell at any given time  this formula is satisfied in games that include both successful and failed activities  on the other hand  consider formula h  in the same figure  it contains a
captured player to the cell he was captured in  following the captured players cannot move rule
of ctf   while this holds for successful capturing events  it does not necessarily hold for failed
attempts at capturing  therefore  when rule h  is expanded via second order ml  only some of the
derived formulas are going to be consistent with the observations 
specifically  the candidate formula in equation   will be pruned away  as it is inconsistent with
the training examples  i e   players that were only nearly captured continue to be free to move about 
however  the remaining three variants of formula h  will not be pruned away  equation   will
always evaluate to true  since if someone attempts to re capture an already captured player a  a does
indeed remain stationary  similarly  equation   is also consistent with all the example ctf games
because if there is a failed attempt at capture immediately followed by a successful capture  the
captured player does remain in place from time t onward  finally  equation   is compatible as well 
since it is the original formula h  that is consistent with the observations 

a  t  c   isfailedcaptured a  t   isfailedcaptured a  t       snap a  c  t   snap a  c  t     
   

a  t  c   iscaptured a  t   isfailedcaptured a  t       snap a  c  t   snap a  c  t         

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior


a  t  c   isfailedcaptured a  t   iscaptured a  t       snap a  c  t   snap a  c  t         


a  t  c   iscaptured a  t   iscaptured a  t       snap a  c  t   snap a  c  t     

   

the function testsat    line    in algorithm    checks whether a given candidate theory t c is
compatible with the examples f by the following process  first  we ground t c using the objects in
o  thereby creating a ground theory g  for example  if t c    p x   q x   and o    b  w   
the grounding would be g    p b   q b   p w    q w     then we check if g  fhidden is
satisfiable using the minisat solver  where fhidden is simply the set of hidden atoms that appear in
f   intuitively  this corresponds to testing whether we can plug in the worlds in f into t c while
satisfying all the hard constraints  though satisfiability is an np complete problem  in practice
testsat   completes within tenths of a second even for the largest problems in our ctf domain 
for instance  suppose fhidden    p b   q b    then we test satisfiability of the formula

 

p b   q b   p w    q w    p b   q b  
in this case we cannot satisfy it since we are forced to set p b  to true and q b  to false  which
renders the first clauseand therefore the whole formulafalse 
an alternative approach to pruning formulas via satisfiability testing  as we have just described 
would be to treat both types of formulas  hard and soft  in the inflated theory m s as strictly soft
formulas and learning a weight for each formula from examples of both successful and failed game
events  however  this introduces several complications that negatively impact the systems performance as well as model clarity  first  the number of formulas in the inflated theory can be
exponentially larger than in the seed theory  while the instantiation of the second order ml representation can be quantified to limit this expansion  we still have worst case exponential blow up 
by treating all formulas as soft ones  we now need to potentially learn many more weights  this is
especially problematic for activities that occur rarely  as we may not have enough training data to
properly learn those weights  eliminating the hard candidate formulas by proving them inconsistent
dramatically reduces the number of parameters we have to model  while satisfiability testing is
np complete  weight learning in markov logic entails running inference multiple times  which is
itself a  p complete problem 
the second reason for distinguishing between soft and hard formulas is the resulting clarity and
elegance of the final learned model ms f   even in situations when we have enough training data
to properly learn a large number of weights  we run into overfitting problems  where neither the
structure nor the parameters of the model represent the domain in a natural way  our experiments
have shown that if we skip the pruning stage  steps   and   in algorithm     the models recognition
performance does not differ from that of a pruned model in a significant way  p value of       
however  we end up with a large number of soft formulas with a mixture of positive and negative
weights that the learning algorithm carefully tuned and balanced to fit the training data  they
however bear little relationship to the concepts in the underlying domain  not only does this make
it very hard for a human expert to analyze the model  but it makes it even harder to modify the
model 
   

fis adilek   k autz

for these reasons  softening all hard formulas is  in general  infeasible  an interesting direction
of future work will be to identify a small amount of key inconsistent hard formulas to soften  while
eliminating the rest of the inconsistent hard formulas  this however entails searching in a large
space of candidate subsets of softened formulas  where each iteration requires expensive re learning
of all weights 
note that algorithm   terminates as soon as it finds a compatible theory that requires the smallest
number of formula removals  we also experimented with an active learning component to our
system  where we modify algorithms   and   such that they present several possible refinements
of the theory to the user who then selects the one that looks best  the proposed modifications are
shown both at the ml theory level with modified sections  formulas  highlighted as well as at the
data level where the program shows the inferred consequences of those modifications  for each
candidate modification  the corresponding consequences are displayed as a collection of animations
where each animation shows what the results of activity recognition would be if we committed to
that particular candidate theory  note that even people who do not have background in ml can
interact with such a system since the visualization is easy to understand  interestingly  in the case
of captures and frees  the least modified theory that the off line version of the algorithm finds is
also the best one and therefore there is no need to query the user  one can view this as a differential
variant of occams razor  however  for different activities or other domains  the active learning
approach may be worth revisiting and we leave its exploration for future work 
finally  general structure learning techniques from statistical relational ai and from inductive
logic programming are not applicable as a substitute for our theory augmentation algorithm for
several reasons  the main reason is that  for efficiency reasons  existing techniques in the literature
typically operate over a very restricted set of formula templates  that is  they consider only horn
clauses  or only formulas without an existential quantifier  or only formulas with at most k literals or
with at most l variables  and so on  this set of restrictions is part of the language bias of any given
approach  while in principle  structure learning is possible without a language bias  one often has
to carefully define one for the sake of tractability  see the section   for details   in our approach 
the language bias is defined implicitly as discussed in section       
    extracting the goal from success and failure
recall that applying the theory augmentation process  algorithm    on the ctf seed theory of
successful interactions  shown in figures   and    induces a new set of formulas that capture the
structure of failed activities and ties them together with the existing formulas in the seed theory 
the logically inconsistent formulas i that algorithm   returns are ones that are not satisfiable in
the worlds with failed activities  at the same time  variants of those formulas were consistent with
the examples of successful actions occurring in the games  therefore  i represents the difference
between a theory that models only successful activities and the augmented theory of both successful
and failed actions  that has been derived from it  intuitively  the difference between success and
failure can be viewed as the intended purpose of any given activity a rational agent executes  and
consequently as the goal the agent has in mind when he engages in that particular activity  in the
next section  we will explore the goals extracted from the ctf domain in this fashion 
this concludes discussion of our models and methodology  and now we turn to experimental
evaluation of the framework presented above 

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

   experiments and results
we evaluate our approach along the three major directions outlined in section    methodology  
while focusing on answering the four research questions formulated ibidem  the structure of this
section closely follows that of the methodology section 
in a nutshell  we are first interested in how our markov logic models perform on the standard
multi agent activity recognition tasklabeling successful activitiesand how their performance
compares to the alternative models  second  we examine the augmented model that captures both
successful and failed attempts at activities  this is the model ms f induced by algorithm    which
also lets us extract the intended goal of the activities in question  third  we compare the performance
of ms f on the task of jointly recognizing all four activities with that of an alternative model 
finally  we investigate to what extent the reasoning about failed attempts does help in recognition
of successfully executed activities 
all experiments are performed on our capture the flag dataset consisting of four separate games 
the dataset is summarized in table    where for each game we list the number of raw gps readings
and the number of instances of each activity of interest  we evaluate the models via four fold crossvalidation  always training on three games  if training is required for a model  and testing against the
fourth  for each experimental condition below  we report precision  recall  and f  scores attained
by each respective model over the four cross validation runs  we have purposefully chosen to
split the data so that each cross validation fold directly corresponds to a separate game of ctf for
conceptual convenience and clarity  as we discussed above  the events occurring in the games often
have far reaching consequences  for example  most captured players are never freed by their allies 
therefore  a capture at the beginning of a game typically profoundly influences the entire rest of the
game  for this reason  splitting the games randomly or even manually would introduce unnecessary
complications  as most of the segments would have dependencies on other segments  by enforcing
that each fold exactly corresponds with a different game  we make each fold self contained 
to quantify the statistical significance of the pair wise differences between models  we use a
generalized probabilistic interpretation of f  score  goutte   gaussier         namely  we express
f  scores in terms of gamma variates derived from models true positives  false positives  and false
negatives          h        cf   goutte   gaussier         this approach makes it possible to
compare our results to future work that may apply alternative models on similar  but not identical 
datasets  a future comparison may  for instance  include additional games or introduce random
splits of the data  we note that standard statistical significance tests cannot be applied in those situations  all p values reported are one sided  as we are interested if models performance significantly
improves as their level of sophistication increases 
    recognition of successful activities
recall that for both our two step   sml  and unified  uml  markov logic models  we specify the
markov logic formulas by hand and optimize the weights of the soft formulas via supervised online learning  we run a modified version of thebeast software package to perform weight learning
and map inference  thebeast implements the cutting plane meta solving scheme for inference in
markov logic  where the ground ml network is reduced to an integer linear program that is subsequently solved by the lpsolve ilp solver  we chose this approach as opposed to  e g   maxwalksat
that can get stuck at a local optimum  since the resulting run times are still relatively short  under
an hour even for training and testing even the most complex model  
   

fis adilek   k autz

game  
game  
game  
game  
total

 gps
      
      
     
      
      

 ac
 
 
 
 
  

 fc
  
  
  
 
  

 af
 
 
 
 
 

 ff
 
 
 
 
 

table    ctf dataset overview   gps is the total number of raw gps readings   ac and  fc is the
number actual  successful  and failed captures respectively  and analogously for freeings
  af and  ff  

at weight learning time  we use the margin infused relaxed algorithm  mira  for weight updates while the loss function is computed from the number of false positives and false negatives
over the hidden atoms  as described in the methodology section  the discretization step for the
dynamic bayesian network model  dbn  is implemented in markov logic and is also executed in
this fashion  the dbn model is trained via maximum likelihood as described in section      the
two deterministic baselines  b and b s  do not require any training phase 
at inference time  we are interested in the most likely explanation of the data  in markov logic 
maximum a posteriori inference reduces to finding a complete truth assignment that satisfies all the
hard constraints while maximizing the sum of the weights of the satisfied soft formulas  at testing
time  thebeast markov logic solver finds the most likely truth assignment to the hidden atoms as
described above  and in this section we are specifically interested in the values of the capturing and
freeing atoms 
in dbns  the most likely explanation of the observations is equivalent to viterbi decoding  the
dbn model assigns either free or captured state to each player for every time step  we then label
all transitions from free to captured state as capturing and all transitions from captured to free as
freeing  note that the dbn model is capable of determining which player is being freed or captured 
but it does not model which player does the freeing or capturing  in our evaluation  we give it the
benefit of the doubt and assume it always outputs the correct actor 
for all models  inference is done simultaneously over an entire game  on average  about   
minutes worth of data   note that we do not restrict inference to a  small  sliding time window  as
the experiments described below show  many events in this domain can only be definitely recognized
long after they occur  for example  gps noise may make it impossible to determine whether a player
has been captured at the moment of encounter with an enemy  but as the player thereafter remains
in place for a long time  the possibility of his capture becomes certain 
figures   and   summarize the performance of our models of successful capturing and freeing
in terms of precision  recall  and f  score calculated over the four cross validation runs  for clarity 
we present the results in two separate plots  but each model was jointly labeling both capturing and
freeing activities  we do not consider the baseline model for freeing recognition as that activity
makes little sense without having a notion of player state  captured or free  
we see that the unified approach yields the best results for both activities  let us focus on
capturing first  figure     overall  the unified model labels    out of    captures correctlythere

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

capturing  recogni on  
      

      
      

      

      

      

      
      

      

      
      

      

precision  

      
      
      

recall  

      
      
             

             

b  

b s  

f   

dbn  

 sml  

uml  

figure    comparison of performance of the five models on capturing recognition while doing joint
inference over both capturing and freeing events  see table   for statistical significance
analysis of the pairwise differences between models   b   baseline model  b s   baseline
model with states   sml   two step markov logic model  uml   unified markov logic
model 

are only two false negatives  in fact  these two capture events are missed by all the models because
they involve two enemies that appear unusually far apart  about    meters  in the raw data  even the
unified approach fails on this instance since the cost of adjusting the players trajectoriesthereby
losing score due to violation of the geometry based constraintsis not compensated for by the
potential gain from labeling an additional capture 
note that even the two step approach recognizes    out of    captures  as compared to the
unified model  it misses one additional instance in which the involved players  being moderately
far apart  are snapped to mutually nonadjacent cells  on the other hand  the unified model does not
fail in this situation because it is not limited by prior nonrelational snapping to a few nearby cells 
however  the difference between their performance on our dataset is not statistically significant even
at the      level  p value of       
both deterministic baseline models  b and b s  perform very poorly  although they yield a
respectable recall  they produce an overwhelming amount of false positives  this shows that even
relatively comprehensive pattern matching does not work at all in this domain  interestingly  the
performance of the dbn model leaves much to be desired as well  especially in terms of precision 
while the dbn model is significantly better than both baselines  p value less than             it
also achieves significantly worse performance than both the markov logic models  p value less than
        see table    
table   summarizes p values of pairwise differences between models of actual  i e   successful 
capturing  while the difference between the markov logic based models   sml and uml  are not

   

fis adilek   k autz

freeing  recogni on  
      

      

      

      

      
      

      
      

      
      

      
      
      

      

      

precision  

      

recall  

      

f   

      
b s  

dbn  

  sml  

uml  

figure    comparison of performance of our three models on freeing recognition while doing joint
inference over both capturing and freeing events  see table   for statistical significance
analysis of the pairwise differences between models   b s   baseline model with states 
 sml   two step markov logic model  uml   unified markov logic model 

b
b s
dbn
 sml

b s
      
 

dbn
        
        
 

 sml
        
        
      
 

uml
        
        
        
      

table    summary of statistical significance  one sided p values  of the pairwise differences between f  scores for models of actual capturing   b   baseline model  b s   baseline
model with states  dbn   dynamic bayesian network model   sml   two step markov
logic model  uml   unified markov logic model 

statistically significant  p value of        pairwise differences in f  scores between all other models
are significant at the      level  and most often even at much lower p values 
though the unified model still outperforms its alternatives in the case of freeing recognition as
well  its performance is further from ideal as compared to the capture recognition case  figure    
it correctly identifies only   out of   freeing events in the games  but does not produce any false
positives  this is partly due to the dependency of freeing on capturing  a failure of a model to
recognize a capture precludes its recognition of a future freeing  another reason is the extreme
sparseness of the freeing events  there are only five of them in         datapoints   finally  in some

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

b s
dbn
 sml

dbn
      
 

 sml
      
      
 

uml
      
      
      

table    summary of statistical significance  one sided p values  of the pairwise differences between f  scores for models of actual freeing   b s   baseline model with states  dbn  
dynamic bayesian network model   sml   two step markov logic model  uml   unified
markov logic model 

instances players barely move after they had been freed  this may occur for a number of reasons
ranging from already occupying a strategic spot to simply being tired  such freeing instances are
very challenging for any automated system  and even people familiar with the game to recognize
 several situations would have been extremely hard to disambiguate if we didnt have access to our
notes about data collection  
the two step ml model does a slightly worse job than the unified model on freeing recognition 
it correctly identifies only   out of   freeings for the same reasons as in the capturing recognition
case  similarly to models of actual captures  the difference between the unified and two step freeing
models is not statistically significant  p value of       
table   summarizes p values of pairwise differences between models of actual  i e   successful  freeing  here we see that only the difference between b s and uml models is statistically
significant  p value of        whereas the differences between the rest of the model pairs are not
statistically significant  since there are only five instances of successful freeing  the  sml model
does not perform significantly better than the b s model at the      significance level  p value of
       however  the uml model achieves better recognition results than even the dbn model with
high confidence  p value less than        therefore  we see that although the  sml model strictly
dominates the non markov logic models when evaluated on capturing recognition  we need the full
power of the unified ml model to strictly outperform the nonrelational alternatives for freeing  this
suggests that as we move to more complex and more interdependent activities  relational and unified
modeling approaches will be winning by larger and larger margins 
even though the statistical significance tests suggest that  sml is likely to give similar results to
uml  it is important to note that  sml  by design  precludes recognition of the activities in question
in certain situations  namely  as our experiments demonstrate  when the players are snapped to cells
that are too far apart  the two step model does not even consider those instances as candidates for
labeling  and inevitably fails at recognizing them  therefore  one needs to look beyond the p values
obtained when comparing the fully unified models to various alternatives 
as expected from the experiments with capturing recognition  both deterministic baseline models perform very poorly on freeing recognition as well  not only do they produce an overwhelming
amount of false positives  they also fail to recognize most of the freeing events 
thus  we see that the models cast in markov logic perform significantly better than both of the
deterministic baseline models  and also better than the probabilistic  but nonrelational  dbn model 
we note that the dbn model has the potential to be quite powerful and similar dbns have been
applied with great success in previous work on activity recognition from location data  eagle  
   

fis adilek   k autz

pentland        liao  patterson  fox    kautz         it also has many similarities with the twostep ml model  they both share the same denoising and discretization step  and they both operate
on the same observed data  the key difference is that the dbn model considers players individually 
whereas the two step ml model performs joint reasoning 
looking at the actual ctf game data  we see several concrete examples of how this hurts dbns
labeling accuracy  for instance  consider a situation where two allies had been captured near each
other  performing inference about individual players in isolation allows the dbn model to infer that
the two players effectively free each other  even though in reality they are both captured and cannot
do so  this occurs because the dbn model is oblivious to the explicit states of ones teammates as
well as opponents  since capturing and freeing are interdependent  the obliviousness of the dbn
model to the state of the actors negatively impacts its recognition performance for both activities 
the example we just gave illustrates one type of freeing false positives  the hallucinated freeings
create opportunities that often lead to false positives of captures  creating a vicious cycle  false
negatives of freeing  capturing  events often occur for players who the model incorrectly believes
have already been freed  captured  at a prior time 
since the markov logic based models are significantly betterwith a high level of confidence
than the alternatives that are not fully relational  the experiments above validate our hypothesis that
we need to exploit the rich relational and temporal structure of the domain in a probabilistic way
and at the same time affirmatively answer research question q   can we reliably recognize complex
multi agent activities in the ctf dataset even in the presence of severe noise    namely  we show
that although relatively powerful probabilistic models are not sufficient to achieve high labeling
accuracy  we can gain significant improvements by formulating the recognition problem as learning
and inference in markov logic networks 
now we turn to the evaluation of our method of learning models of both success and failure in
peoples activities 
    learned formulas and intentions
applying the theory augmentation process  algorithm    on the ctf seed theory  shown in figures   and    induces a new set of formulas that capture the structure of failed activities and ties
them together with the existing formulas in the theory  we call this model ms f   figure   shows
examples of new weighted formulas modeling failed freeing and capturing attempts that appear in
ms f  
first  note that our system correctly carries over the basic preconditions of each activity  contrast
formulas s  with s   and s  with s   in figures   and   respectively   this allows it to reliably
recognize both successful and failed actions instead of  e g   merely labeling all events that at some
point in time appear to resemble a capture as near capture  this re use of preconditions directly
follows from the language bias of the theory augmentation algorithm 
turning our attention to the learned hard formulas  we observe that the system correctly induced
equivalence classes of the states  and also derived their mutual exclusion relationships  h      it
furthermore tied the new failure states to their corresponding instantaneous interactions  h   and
h     
finally  the algorithm correctly discovers that the rule if a player is captured then he or she
must remain in the same location  h   figure    is the key distinction between a successful and
failed capture  since players who were not actually captured can still move   therefore  it introduces

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

an appropriate rule for the failed captures  h     figure    explicitly stating that failed capturing does
not confine the near captured player to remain in stationary  an analogous process yields a fitting
separation between failed and successful freeings  namely  our model learns that an unsuccessfully
freed player remains stationary  this learned difference between success and failure in players
actions directly corresponds to the goal of the activity and consequently the intent of rational actors  this difference is what our system outputs as the intended goal of capturing activity  and
analogously for freeing  
these experimental results provide an evidence for a resounding yes to both q   can models
of attempted activities be automatically learned by leveraging existing models of successfully performed actions   and q   does modeling both success and failure allow us to infer the respective
goals of the activities   within the ctf domain 
we note that instead of applying our automated theory augmentation method  a person could 
in principle  manually formulate a markov logic theory of successful as well as failed activities
by observing the games  after all  this is how we designed the initial seed model of successful
events  however  this process is extremely time consuming  as one tends to omit encoding facts
that to us  humans  seem self evident but need to be explicitly articulated for the machine  e g   a
single person cannot be at ten different places at once  or that a player is either free or captured but
not both   it is also surprisingly easy to introduce errors in the theory  that are difficult to debug 
mostly because of the complex weight learning techniques involved  therefore  we believe that the
theory augmentation method is a significant step forward in enhancing models capabilities while
requiring small amounts of human effort  as the complexity of domains and their models increases 
this advantage will gain larger and larger importance 
    recognition of both successful and failed activities
we now compare the performance of our model ms f to an alternative  baseline  method that
labels all four activities in the following way  similarly to the baseline with states model for successful interactions defined in section      there are two separate stages  first we snap each gps
reading to the nearest cell by applying only the geometric constraints  h  and s s   of our theory  and afterward we label the instances of our activities  the following labeling rule is applied 
we loop over the whole discretized  via snapping  data set and look for instances where a pair of
players a and b were snapped  in the first step  to either the same cell or to two adjacent cells at
time t  they are enemies  b is not captured already  and a is on its home territory while b is not 
if b moves  is snapped to a different cell at a later time  without having an ally nearby  we output
failedcapturing a b t   otherwise we output capturing a b t   the labeling rule for freeing is defined analogously and all four events are tied together  we also tested a variant of the dbn model
introduced in section     that has two additional hidden state values for node st   isfailedfree and
isfailedcaptured  however  the difference in the results obtained with this model was not statistically significant  p value of        and therefore we focus on the conceptually more straightforward
baseline model described above 
model ms f is evaluated using four fold cross validation  always training on three games and
testing against the fourth   figure    compares both models in terms of precision  recall  and f 
score  note that all four activities are modeled jointly in both models  the f  score of the augmented
model is significantly better than that of the baseline for all four target activities  p value less than
           

   

fis adilek   k autz

a    a    t     enemies a    a     onhometer a    t 

 s    

onenemyter a    t   sameplace a    a    t   isfree a    t 
 isfree a    t    failedcapturing a    a    t          
a    a    t     enemies a    a     onenemyter a    t 

 s    

onenemyter a    t   sameplace a    a    t   isfree a    t 
 iscaptured a    t    failedfreeing a    a    t         
a    a    t    failedcapturing a    a    t            

 s    

a    a    t    failedfreeing a    a    t           

 s    

a  t   isfailedcaptured a  t   isfree a  t 

 h    

a  t   iscaptured a  t   isfailedfree a  t 
a  t   isfailedcaptured a  t   isfree a  t 
a  t   iscaptured a  t   isfailedfree a  t 
a  t    isfree a  t   isfailedcaptured a  t            a    failedcapturing a    a  t  
a  t    iscaptured a  t   isfailedfree a  t            a    failedfreeing a    a  t  

 h    
 h    

a  t  c    isfailedcaptured a  t   isfailedcaptured a  t       snap a  c  t    snap a  c  t     
 h    

figure    example formulas  learned by algorithm    that model unsuccessful capturing and freeing events  the crucial intent recognition formula  h     is highlighted in bold  formulas
eliminated by algorithm   are preceded by the  symbol  and are not included in the
induced model ms f   the identity iscaptured a  t    isfree a  t  is applied throughout refining to show the formulas in a more intuitive fashion  for concreteness sake  the
values of the learned weights here come from one cross validation run  and are similar in
other runs  

we see that the baseline model has  in general  a respectable recall but it produces a large
number of false positives for all activities  the false positives stem from the fact that the algorithm
is greedy in that it typically labels a situation where several players appear close to each other
for certain period of time as a sequence of many captures and subsequent frees even though none
of them actually occurred  model ms f gives significantly better results because it takes full
advantage of the structure of the game in a probabilistic fashion  it has a similar over labeling
tendency only in the case of failed captures  where a single capture attempt is often labeled as
several consecutive attempts  while this hurts the precision score  it is not a significant deficiency 

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

      

baseline  

ac        

      

fc        

      

      
      

af       

      

      
      

ff       
augmented  ml  model  

      

      

f   

      

      

recall  
      
      
      

ac        
      

fc        

      

af       

      

ff       

      

   

     

     

     

     

     

     

     

     

precision  

      

      
      
      
      

     

   

figure     performance of the baseline and augmented  ms f   models on joint recognition of
successful and failed capturing and freeing  the f  score of the augmented model is
significantly better than that of the baseline for all four target activities  p value less
than             ac   actual  successful  capturing  fc   failed capturing  af  
actual freeing  ff   failed freeing 

as in practice  having a small number of short game segments labeled as possible near captures is
useful as well 
we also note that even though the original model  uml  did not contain any information on
failed capturing nor failed freeing  the performance of ms f is respectable even for those two
newly introduced activities  we only provided examples of game situations where those attempts
occur and the system augmented itself and subsequently labeled all four activities  thus  we see
that we can indeed extend preexisting models in an automated fashion so that the unified model is
capable of recognizing not only individual activities  but also both success and failure in peoples
behavior 
    the effect of modeling failed attempts on recognition of successful activities
to address research question q   does modeling failed attempts of activities improve the performance on recognizing the activities themselves    we want to see how much does the recognition
of attempted activities help in modeling the successful actions  the latter being the standard activity

   

fis adilek   k autz

capturing  

f   

      

recall  

      

precision  

       

      

f   
freeing  

       

      

recall  

       

      

       

precision  

      

   

     

     

     

     

without  modeling  failure  

     

     

     

     

     

   

with  modeling  failure  

figure     considering unsuccessfully attempted activities strictly improves performance on standard activity recognition  blue bars show scores obtained with the unified markov logic
model that considers only successful activities  ms    the red bars indicate the additive improvement provided by the augmented model that considers both successful and
failed activities  ms f   the output of algorithm     each model labels its target activities jointly  we separate capturing and freeing in the plot for clarity  precision has value
of   for both models  f  scores obtained when explicitly modeling failed attempts are
not statistically different from f  scores obtained without modeling attempts at a high
confidence level  p value of        however  these results still show the importance of
reasoning about peoples attempts when recognizing their activities  see text for details 

recognition problem   toward that end  we compare the markov logic model ms that jointly labels
only successful capturing and freeing with model ms f that jointly labels both successful and
failed attempts at both capturing and freeing  see section       for a detailed description of the two
models   however  we evaluate them in terms of precision  recall  and f  score only on successful
interactions  not all four types of activities 
figure    summarizes the results  we see that when evaluated on actual capturing  ms f
performs better than ms   and similarly for freeing  however  the difference in f  scores between
a model that captures both attempted and successful activities  ms f   and a model of only successful activities  ms   is not statistically significant  p value of        this is partly because ms
already produces very solid results  leaving little room for improvement  additionally  the ctf
dataset contains relatively few events of interest  in terms of labeling performance at testing time 
the difference between the two models is more than      ms and ms f recognize  respectively 
   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

   and    out of    successful activities correctly   thus  we believe the trends shown in figure   
are promising and modeling attempted actions does improve recognition performance on both capturing and freeing  but evaluation on a dataset with a larger number of events is needed to show the
difference to be statistically significant at a higher confidence level  however  this does not mean
that recognizing attempts is unimportant  as we show above  our induced augmented model does
recognize failed  as well as successful  activities in the complex ctf domain with high accuracy 
and we argue this to be a significant contribution 
finally  the comparison of ms and ms f shows that applying our learning algorithm that augments a model with more recognition capabilities does not hurt model labeling performance  the
fact that binary classification problems are typically easier to solve than their multi class counterparts has been well reported on in machine learning literature  allwein  schapire    singer        
therefore  introducing new activities into a model  especially in an automated way  is likely to degrade its performance  contrary to this intuition  our experiments show that ms f is no worse than
ms on successful activity recognition  i e   their intersection  with high confidence  even though
ms f is clearly richer and more useful 

   related work
in the world of single agent location based reasoning  the work of bui        presents and evaluates a system for probabilistic plan recognition cast as an abstract hidden markov memory model 
subsequently  the work of liao et al         implements a system for denoising raw gps traces and
simultaneously inferring individuals mode of transportation  car  bus  etc   and their goal destination  they cast the problem as learning and inference in a dynamic bayesian network and achieve
encouraging results  in a follow up work  liao et al         introduce a framework for locationbased activity recognition  which is implemented as efficient learning and inference in a relational
markov network 
the work of ashbrook and starner        focuses on inferring significant locations from raw
gps logs via clustering  the transition probabilities between important places are subsequently
used for a number of user modeling tasks  including location prediction  the work of eagle and
pentland        explores harnessing data collected on regular smart phones for modeling human
behavior  specifically  they infer individuals general location from nearby cell towers and bluetooth devices at various times of day  applying a hidden markov model  hmm   they show that
predicting if a person is at home  at work  or someplace else can be achieved with more than     accuracy  similarly  the work of eagle and pentland        extracts significant patterns and signatures
in peoples movement by applying eigenanalysis to smart phone logs 
the work of hu  pan  zheng  liu  and yang        concentrates on recognition of interleaving
and overlapping activities  they show that publicly available academic datasets contain a significant
number of instances of such activities  and formulate a conditional random field  crf  model that
is capable of detecting them with high  more than      accuracy  however  they focus solely on
single agent household activities 
peoples conversation has been the primary focus of multi agent modeling effort  barbuceanu
  fox         in the fields of multi agent activity recognition and studies of human behavior  researchers have either modeled conversation explicitly  e g   busetta  serafini  singh    zini        
or have leveraged peoples communication implicitly via call and location logs from mobile phones 
this data has been successfully used to infer social networks  user mobility patterns  model socially

   

fis adilek   k autz

significant locations and their dynamics  and others  eagle   pentland        eagle  pentland 
  lazer         this is arguably an excellent stepping stone for full fledged multi agent activity
recognition since location is  at times  practically synonymous with ones activity  e g   being at a
store often implies shopping   tang  lin  hong  siewiorek    sadeh         and our social networks
have tremendous influence on our behavior  pentland        
additionally  a number of researchers in machine vision have worked on the problem of recognizing events in videos of sporting events  such as impressive recent work on learning models of
baseball plays  gupta et al          most work in that area has focused on recognizing individual
actions  e g   catching and throwing   and the state of the art is just beginning to consider relational
actions  e g   the ball is thrown from player a to player b   the computational challenges of dealing
with video data make it necessary to limit the time windows of a few seconds  by contrast  we
demonstrate in this work that many events in the capture the flag data can only be disambiguated
by considering arbitrarily long temporal sequences  in general  however  both our work and that
in machine vision rely upon similar probabilistic models  and there is already some evidence that
statistical relational techniques similar to markov logic can be used for activity recognition from
video  biswas  thrun    fujimura        tran   davis        
looking beyond activity recognition  recent work on relational spacial reasoning includes an
attempt to locateusing spacial abductioncaches of weapons in iraq based on information about
attacks in that area  shakarian  subrahmanian    spaino         additionally  the work of abowd
et al         presents a location  and context aware system  cyberguide  that helps people explore
and fully experience foreign locations  other researchers explore an intelligent and nonintrusive
navigation system that takes advantage of predictions of traffic conditions along with a model of
users knowledge and competence  horvitz et al          finally  the work of kamar and horvitz
       explore automatic generation of synergistic plans regarding sharing vehicles across multiple
commuters 
an interesting line of work in cognitive science focuses on intent and goal recognition in a probabilistic framework  baker  tenenbaum    saxe               specifically  they cast goal inference
as inverse planning problem in markov decision processes  where bayesian inversion is used to estimate the posterior distribution over possible goals  recent extensions of this work begin to consider
simulated multi agent domains  baker  goodman    tenenbaum        ullman  baker  macindoe 
evans  goodman    tenenbaum        baker  saxe    tenenbaum         comparison of the
computational models against human judgement in synthetic domains shows a strong correlation
between peoples predicted and actual behavior  however  the computational challenges involved in
dealing with the underlying partially observable markov decision processes are prohibitive in more
complex domains with large state spaces  such as ours 
the focus of our work is on a different aspect of reasoning about peoples goals  rather than
inferring a distribution over possible  a priori known goals  we automatically induce the goals of
complex multi agent activities themselves 
other researchers have concentrated on modeling behavior of people and general agents as reinforcement learning problems in both single agent and multi agent settings  the work of ma       
proposes a system for household activity recognition cast as a single agent markov decision process
problem that is subsequently solved using a probabilistic model checker  wilson and colleagues address the problem of learning agents roles in a multi agent domain derived from a real time strategy
computer game  wilson  fern  ray    tadepalli        wilson  fern    tadepalli         experiments in this synthetic domain show strongly encouraging results  while we do not perform role
   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

learning ourselves  we anticipate that the work of wilson et al  is going to play an important role
in learning hierarchies of peoples activities  in our capture the flag domain  one can imagine automatically identifying a particular player as  for example  a defender and subsequently leveraging
this information to model his or her behavior in a more personalized way 
the work of hong        concentrates on recognizing the goal of an agent in the course of her
activities in a deterministic  but relational setting  interesting work on goal recognition has been
also applied to computer aided monitoring of complex multi agent systems  where relationships
between agents are leveraged to compensate for noise and sparse data  kaminka  tambe  pynadath 
  tambe         by contrast  in our work we focus on learning the respective goals of a given set
of multi agent activities in a probabilistic setting  the knowledge is in turn leveraged to achieve a
stronger robustness of the other recognition tasks  similarly to the approach of hong  our system
does not need a supplied plan library either 
our work also touches on anomaly detection since our system reasons about the failed attempts
of the players  anomaly detection concerns itself with revealing segments of the data that in some
way violate our expectations  for an excellent survey of the subject  we refer the reader to the
results of chandola  banerjee  and kumar         in the realm of anomaly detection within peoples
activities  the work of moore and essa        addresses the problem of error detection and recovery
card games that involve two players recorded on video  their system models the domain with a
stochastic context free grammar and achieves excellent results 
we note that recognizing a failed attempt at an activity is more fine grained a problem than
anomaly detection  the failed event is not just anomalous in general   rather  it is the specific
distinction between success and failure in human activities that we are interested in  and the distinction lies in the fact that an unsuccessful attempt does not yield a certain desired state whereas
a successful action does  this desired state is exactly what our approach extracts for each activity
in question  to our knowledge  there exists no prior work on explicit modeling and recognition of
attempted activities or on learning the intended purpose of an activity in a multi agent setting 
one of the components of our contribution focuses on joint learning and inference across multiple tasks  capturing  freeing  and their respective attempted counterparts   this is in contrast with
the traditional pipeline learning architecture  where a system is decomposed into a series of modules and each module performs partial computation and passes the result on to the next stage  the
main benefits of this set up are reduced computational complexity and often higher modularity 
however  since each stage is myopic  it may not take full advantage of dependencies and broader
patterns within the data  additionally  even though errors introduced by each module may be small 
they can accumulate beyond tolerable levels as data passes through the pipeline 
an extensive body of work has shown that joint reasoning improves model performance in a
number of natural language processing and data mining tasks including information extraction  i e  
text segmentation coupled with entity resolution   poon   domingos         co reference resolution  poon   domingos         information extraction coupled with co reference resolution  wellner  mccallum  peng    hay         temporal relation identification  yoshikawa  riedel  asahara 
  matsumoto        ling   weld         and record de duplication  domingos        culotta
  mccallum         similarly to our work  some of the above models are cast in markov logic 
however  prior work uses sampling techniques to perform learning and inference  whereas we apply
   a situation where a player in ctf moves through the campus at a speed of     mph and on her way passes an enemy
player is certainly anomalous  and probably caused by gps sensor noise   but we do not want to say that it is a failed
attempt at capturing 

   

fis adilek   k autz

a reduction to integer linear programming  interestingly  the work in denis and baldridge       
jointly addresses the problems of anaphoricity and co reference via a manual formulation of an
integer linear program 
joint activity modeling has also been shown to yield better recognition accuracy  as compared to
pipeline baselines as well as baselines that make strong inter activity independence assumptions 
the work of wu  lian  and hsu        performs joint learning and inference over concurrent singleagent activities using a factorial conditional random field model  similarly  the work of helaoui 
niepert  and stuckenschmidt        models interleaved activities in markov logic  they distinguish
between foreground and background activities and infer a time window in which each activity takes
place from rfid sensory data  by contrast  we focus on joint reasoning about multi agent activities
and attempts in a fully relationaland arguably significantly more noisysetting 
the work of manfredotti  hamilton  and zilles        propose a hierarchical activity recognition
system formulated as learning and inference in relational dynamic bayesian networks  their model
jointly leverages observed interactions with individual objects in the domain and the relationships
between objects  since their method outperforms a hidden markov model by a significant margin  it
contributes additional experimental evidence that a relational decomposition of a domain improves
model quality 
the work of landwehr  gutmann  thon  philipose  and de raedt        casts single agent
activity recognition as a relational transformation learning problem  building on transformationbased tagging from natural language processing  their system induces a set of transformation rules
that are then used to infer activities from sensory data  since the transformation rules are applied
adaptively  at each step  the system leverages not only observed data  but also currently assigned
labels  inferred activities   however  the transformation rules are learned in a greedy fashion and
experiments show that the model does not perform significantly better than a simple hmm  on
the other hand  their representation is quite general  intuitive  and extensible  as we will see  our
markov logic model has a similar level of representational convenience while performing global
instead of greedyoptimization in a significantly more complex domain 
the denoising component of our model can be formulated as a tracking problem  prior work
proposed a relational dynamic bayesian network model for multi agent tracking  manfredotti  
messina         their evaluation shows that considering relationships between tracked entities
significantly improves model performance  as compared to a nonrelational particle filter baseline 
by contrast  our work explores joint tracking and activity recognition  however  each gps reading
is annotated with the identity of the corresponding agent  the work of manfredotti and messina
suggests that our model can be generalized  such that the associations between gps and agent
identities are inferred and need not be observed 
our markov logic theory can be viewed as a template for a conditional random field  lafferty 
       an undirected graphical model that captures the conditional probability of hidden labels
given observations  rather than the joint probability of both labels and observations  as one would
typically do in a directed graphical model  in the relational world  directed formalisms include
relational bayesian networks  jaeger        and their dynamic counterparts  manfredotti        
probabilistic relational models  koller        friedman  getoor  koller    pfeffer         bayesian
logic programs  kersting   de raedt         and first order conditional influence language  natarajan  tadepalli  altendorf  dietterich  fern    restificar         conditional random fields have been
extensively applied to activity recognition  and their superior labeling performance over generative
models has been demonstrated in a number of both single agent and multi agent domains  liao
   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

et al         limketkai  fox    liao        vail        vail   veloso        hu et al         
since mlns are often solved as propositionalized crfs  and the directed alternatives can be compiled into a bayesian network  it can be expected that discriminative relational models generally
outperform their generative counterparts on labeling tasks  however  more work needs to be done
to answer this question in its entirety 
since markov logic is based on  and in fact subsumes  finite first order logic  we immediately
gain access to a number of techniques developed in the rich field of traditional logic  current markov
logic solvers take advantage of the underlying logical structure to perform more powerful optimizations  such as alchemys lifted inference in belief propagation and mc sat  poon   domingos 
       additionally  domain pruning  where one uses hard constraints to infer reduced domains for
predicates  has been shown to lead to significant speed ups  papai  singla    kautz        
we also leverage this relationship between markov and first order logic when inducing an augmented model  furthermore  presence of dependency cycles introduces additional problems in
directed graphical  relational  models  thus  the fact that  in markov logic  knowledge can be
expressed as weighted first order formulas combined with the above factors make it a powerful
framework best suited for the multi agent reasoning tasks considered in this work 
traditional hidden markov models operate over an alphabet of unstructured  i e   flat  symbols  this makes relational reasoning difficult  as one has to either propositionalize the domain 
thereby incurring combinatorial increase in the number of symbols and model parameters  or ignore
the relational structure and sacrifice information  logical hidden markov models  lhmms  have
been proposed to address this problem  kersting  de raedt    raiko         lhmms are a generalization of standard hmms that compactly represents probability distributions over sequences of
logical atoms rather than flat symbols  lhmms have been proven strictly more powerful than their
propositional counterparts  hmms   by applying techniques from logic based reasoning  such as
unification  while leveraging the logical structure component of the model  kersting et al  show that
lhmms often require fewer parameters and achieve higher accuracy than hmms 
lhmms have been recently applied to activity recognition  in the context of intelligent user interfaces  the work of shen        designs and evaluates a lhmm model for recognition of peoples
activities and workflows carried out on a desktop computer  other researchers proposed a hierarchical extension of lhmms along with an efficient particle filter based inference technique  and
apply it to activity recognition problems in synthetic domains  natarajan  bui  tadepalli  kersting 
  wong         both lines of work show that lhmms can be learned and applied efficiently  and
perform better than plain hmms 
however  lhmms are a generative model and therefore are not ideal for pure labeling and
recognition tasks  where we typically do not want to make strong independence assumptions about
the observations  nor do we want to explicitly model dependencies in the input space  tildecrfa
relational extension of traditional conditional random fieldshas been introduced to address this
issue  gutmann   kersting         tildecrf allows discriminative learning and inference in crfs
that encode sequences of logical atoms  as opposed to sequences of unstructured symbols  tildecrf
specifically focuses on efficient learning of models of sequential data via boosting  and is subsumed
by markov logic  which can produce both discriminative and generative models  we cast our model
in the latter framework to make it more general  extensible  and interpretable 
prism  a probabilistic extension of prolog  has been shown to subsume a wide variety of generative models  including bayesian networks  probabilistic context free grammars  hmms  along
with their logical extension   sato   kameya               however  since the focus of prism is
   

fis adilek   k autz

on representational elegance and generality  rather than scalability  the sheer size of the state space
and complexity of our ctf domain precludes its application here 
finally  our markov logic theory augmentation process is related to structure learning  transfer learning  and inductive logic programming  in fact  algorithm   implements a special case of
structure learning  where we search for a target theory that explains the training data well  while our
declarative bias forces the target theory to differ from the source theory only as much as necessary 
again  with the intuition that failed attempts are similar to their failed counterparts  a number of
researchers have focused on structure learning specifically in markov logic networks  this includes
early work on top down structure learning  where clauses in the knowledge base are greedily modified by adding  flipping  and deleting logical literals  kok   domingos         this search is guided
by the likelihood of the training data under the current model  the work of mihalkova and mooney
       exploit patterns in the ground markov logic networks to introduce a bottom up declarative
bias that makes their algorithm less susceptible to finding only local optima  as compared to alternative greedy methods  similarly  the work of kok and domingos        introduce a bottom up
declarative bias based on lifted hypergraph representation of the relational database  this bias then
guides search for clauses that fit the data  since the hypergraph is lifted  relational path finding
tractable  interesting work on predicate invention applies relational clustering technique formulated
in second order markov logic to discover new predicates from relational databases  kok   domingos         the above systems are capable of modeling relatively rich family of logical formulas 
other approaches perform discriminative structure learning and achieve excellent results  but focus
on a restricted set of types of formulas  e g   horn clauses   huynh   mooney        biba  ferilli   
esposito         the work of davis and domingos        successfully uses second order markov
logic in deep transfer learning  they lift the model of the source domain to second order ml and
identify high level structural patterns  these subsequently serve as declarative bias for structure
learning in the target domain 
by its very nature  the inductive logic programming discipline has extensively studied structure
learning in deterministic  as well as probabilistic settings  e g   muggleton        de raedt       
de raedt  frasconi  kersting    muggleton         in fact  our theory augmentation algorithm can
be viewed as an efficient markov logic based version of theory refinement  a well established ilp
technique that aims to improve the quality of a theory in terms of simplicity  fit to newly acquired
data  efficiency or other factors  wrobel        
our approach differs from all this work in three main points  first  our declarative bias is defined
implicitly by the seed theory of successful activities  therefore  our theory augmentation algorithm
is not limited to any hard wired set of formula types it can consider  rather  the search space is
defined at run time by extracting motifs from the seed theory  the second distinction lies in computational tractability and exactness of the results  by distinguishing between soft and hard formulas 
we are able to search through candidate formulas in a systematic  rather than greedy manner  consequently  our final learned model requires fewer parameters  which is especially important when
the amount of training data is relatively small  additionally  our weight learning does not experience cold starts  as we leverage the seed theory  the final difference is that  to our knowledge  we
are the first to explore structure learning in the context of interplay of success and failure  and their
relationship to the intended goals of peoples actions 

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

   conclusions
this paper took on the task of understanding the game of capture the flag from gps data as an
exemplar of the general problem of inferring human interactions and intentions from sensor data 
we have presented a novel methodologycast in markov logicfor effectively combining data
denoising with higher level relational reasoning about a complex multi agent domain  specifically 
we have demonstrated that given raw and noisy data  we can automatically and reliably detect
and recognize both successful and failed interactions in adversarial as well as cooperative settings 
additionally  we have shown that success  failure  and the goal of an activity are intimately tied
together and having a model for successful events allows us to naturally learn models of the other
two important aspects of life  specifically  we have demonstrated that the intentions of rational
agents are automatically discovered in the process of resolving inconsistencies between a theory that
models successful instances of a set of activities and examples of failed attempts at those activities 
we have formulated four research questions and designed experiments within the ctf domain
that empirically answer them  compared to alternative approaches to solving the multi agent activity recognition problem  our augmented markov logic model  which takes into account not only
relationships among individual players  but also relationships among activities over the entire length
of a game  although computationally more costly  is significantly more accurate on real world data 
furthermore  we have illustrated that explicitly modeling unsuccessful attempts boosts performance
on other important recognition tasks 

   future work
multi agent activity recognition is especially interesting in the context of current unprecedented
growth of on line social networksin terms of their size  popularity  and their impact on our offline lives  in this paper  we show that location information alone allows for rich models of peoples
interactions  but in the case of on line social networks  we additionally have access to the content
of users posts and both the explicit and the implicit network interactions  for instance  our recent
study shows that  interestingly  about     of twitter status updates reveal their authors location
 sadilek  kautz    bigham         these data sources are now available to machines in massive
volumes and at ever increasing real time streaming rate  we note that a substantial fraction of posts
on services such as facebook and twitter talk about everyday activities of the users  naaman  boase 
  lai         and this information channel has become available to the research community only
very recently  thus  if we are able to reason about human behavior and interactions in an automated
way  we can tap the colossal amounts of knowledge that isat presentdistributed across the whole
population 
we are currently extending our model to handle not only explicit gps traces  but also be able to
infer the location of people who do not broadcast their gps coordinates  the basic idea is  again  to
leverage the structure of relationships among people  the vast majority of us participate in on line
social networks and typically some of our friends there do publish their location  we thus view
the gps enabled people as noisy location sensors and use the network interactions and dynamics
to estimate the location of the rest of the users  at present  we are testing this approach on public
tweets 

   

fis adilek   k autz

acknowledgments
we thank anonymous reviewers for their constructive feedback  we further thank sebastian riedel
for his help with thebeast  and to radka sadlkova and wendy beatty for their helpful comments 
this work was supported by aro grant  w   nf            darpa sbir contract  w  p q   c       and a gift from kodak 

references
abowd  g  d   atkeson  c  g   hong  j   long  s   kooper  r     pinkerton  m          cyberguide 
a mobile context aware tour guide  wirel  netw                
allwein  e   schapire  r     singer  y          reducing multiclass to binary  a unifying approach
for margin classifiers  the journal of machine learning research            
ashbrook  d     starner  t          using gps to learn significant locations and predict movement
across multiple users  personal ubiquitous comput             
baker  c   tenenbaum  j     saxe  r          bayesian models of human action understanding 
advances in neural information processing systems         
baker  c   goodman  n     tenenbaum  j          theory based social goal inference  in proceedings of the thirtieth annual conference of the cognitive science society  pp           
baker  c   saxe  r     tenenbaum  j          bayesian theory of mind  modeling joint belief desire
attribution  in proceedings of the thirty second annual conference of the cognitive science
society 
baker  c   tenenbaum  j     saxe  r          goal inference as inverse planning  in proceedings
of the   th annual meeting of the cognitive science society 
baldwin  d  a     baird  j  a          discerning intentions in dynamic human action  trends in
cognitive sciences                 
barbuceanu  m     fox  m          cool  a language for describing coordination in multi
agent systems  in proceedings of the first international conference on multi agent systems
 icmas      pp       
bell  r   koren  y     volinsky  c          modeling relationships at multiple scales to improve
accuracy of large recommender systems  in kdd  pp         new york  ny  usa  acm 
biba  m   ferilli  s     esposito  f          discriminative structure learning of markov logic
networks   pp        springer 
biswas  r   thrun  s     fujimura  k          recognizing activities with multiple cues  in workshop on human motion  pp         
bui  h  h          a general model for online probabilistic plan recognition  in eighteenth international joint conference on artificial intelligence  ijcai       
busetta  p   serafini  l   singh  d     zini  f          extending multi agent cooperation by overhearing  in cooperative information systems  pp        springer 
chandola  v   banerjee  a     kumar  v          anomaly detection  a survey  acm comput 
surv                 
   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

culotta  a     mccallum  a          joint deduplication of multiple record types in relational data 
in proceedings of the   th acm international conference on information and knowledge
management  pp          acm 
davis  j     domingos  p          deep transfer via second order markov logic  in proceedings of
the   th annual international conference on machine learning  pp          acm 
de raedt  l          logical and relational learning  springer verlag new york inc 
de raedt  l   frasconi  p   kersting  k     muggleton  s   eds            probabilistic inductive
logic programming   theory and applications  vol       of lecture notes in computer
science  springer 
de raedt  l     kersting  k          probabilistic inductive logic programming   de raedt et al  
       pp      
denis  p     baldridge  j          joint determination of anaphoricity and coreference resolution
using integer programming  in proceedings of naacl hlt  pp         
domingos  p          multi relational record linkage  in in proceedings of the kdd      workshop
on multi relational data mining 
domingos  p   kok  s   lowd  d   poon  h   richardson  m     singla  p          markov logic 
 de raedt et al          pp        
eagle  n     pentland  a          reality mining  sensing complex social systems  personal and
ubiquitous computing                
eagle  n     pentland  a          eigenbehaviors  identifying structure in routine  behavioral
ecology and sociobiology                  
eagle  n   pentland  a     lazer  d          inferring social network structure using mobile phone
data  in proceedings of the national academy of sciences 
friedman  n   getoor  l   koller  d     pfeffer  a          learning probabilistic relational models 
in international joint conference on artificial intelligence  vol      pp           
goutte  c     gaussier  e          a probabilistic interpretation of precision  recall and f score 
with implication for evaluation   pp          springer 
gupta  a   srinivasan  p   shi  j     davis  l  s          understanding videos  constructing plots 
learning a visually grounded storyline model from annotated videos  in cvpr 
gutmann  b     kersting  k          tildecrf  conditional random fields for logical sequences  in
machine learning  ecml       pp          springer 
helaoui  r   niepert  m     stuckenschmidt  h          a statistical relational activity recognition
framework for ambient assisted living systems  in ambient intelligence and future trendsinternational symposium on ambient intelligence  isami        pp          springer 
hong  j          goal recognition through goal graph analysis  journal of artificial intelligence
research          
horvitz  e   apacible  j   sarin  r     liao  l          prediction  expectation  and surprise  methods  designs  and study of a deployed traffic forecasting service  in twenty first conference
on uncertainty in artificial intelligence 

   

fis adilek   k autz

hu  d   pan  s   zheng  v   liu  n     yang  q          real world activity recognition with multiple
goals  in ubicomp  vol     pp       
huynh  t     mooney  r          discriminative structure and parameter learning for markov
logic networks  in proceedings of the   th international conference on machine learning 
pp          acm 
jaeger  m          relational bayesian networks  in proceedings of the   th conference on uncertainty in artificial intelligence  pp         
jordan  m          learning in graphical models  kluwer academic publishers 
kamar  e     horvitz  e          collaboration and shared plans in the open world  studies of
ridesharing  in ijcai 
kaminka  g  a   tambe  d  v  p  m   pynadath  d  v     tambe  m          monitoring teams
by overhearing  a multi agent plan recognition approach  journal of artificial intelligence
research           
kersting  k     de raedt  l          bayesian logic programs  in proceedings of the work inprogress track at the   th international conference on inductive logic programming 
kersting  k   de raedt  l     raiko  t          logical hidden markov models  journal of artificial
intelligence research                
kok  s     domingos  p          learning the structure of markov logic networks  in proceedings
of the   nd international conference on machine learning  pp          acm 
kok  s     domingos  p          statistical predicate invention  in proceedings of the   th international conference on machine learning  pp          acm 
kok  s     domingos  p          learning markov logic network structure via hypergraph lifting  in
proceedings of the   th annual international conference on machine learning  pp         
acm 
kok  s     domingos  p          statistical predicate invention  in icml     proceedings of
the   th international conference on machine learning  pp          new york  ny  usa 
acm 
koller  d          probabilistic relational models  in inductive logic programming  pp      
springer 
lafferty  j          conditional random fields  probabilistic models for segmenting and labeling
sequence data  in international conference on machine learning  icml   pp         
morgan kaufmann 
landwehr  n   gutmann  b   thon  i   philipose  m     de raedt  l          relational
transformation based tagging for human activity recognition  in proceedings of the  th international workshop on multi relational data mining  mrdm     pp       
liao  l   patterson  d   fox  d     kautz  h          learning and inferring transportation routines 
artificial intelligence                   
liao  l   fox  d     kautz  h          learning and inferring transportation routines  in proceedings of the nineteenth national conference on artificial intelligence 

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

liao  l   fox  d     kautz  h          location based activity recognition using relational markov
networks  in ijcai 
limketkai  b   fox  d     liao  l          crf filters  discriminative particle filters for sequential
state estimation  in robotics and automation       ieee international conference on  pp 
         
ling  x     weld  d          temporal information extraction  in proceedings of the twenty fifth
national conference on artificial intelligence 
ma  z          modelling with prism of intelligent system  msc  thesis  linacre college  university of oxford 
manfredotti  c          modeling and inference with relational dynamic bayesian networks  in
advances in artificial intelligence  pp          springer 
manfredotti  c     messina  e          relational dynamic bayesian networks to improve multitarget tracking  in advanced concepts for intelligent vision systems  pp          springer 
manfredotti  c   hamilton  h     zilles  s          learning rdbns for activity recognition  in
neural information processing systems 
mihalkova  l     mooney  r          bottom up learning of markov logic network structure  in
proceedings of the   th international conference on machine learning  pp          acm 
moore  d     essa  i          recognizing multitasked activities using stochastic context free grammar  in in proceedings of aaai conference 
muggleton  s          learning structure and parameters of stochastic logic programs  in proceedings of the   th international conference on inductive logic programming  pp         
springer verlag 
murphy  k  p          dynamic bayesian networks  representation  inference and learning  ph d 
thesis  university of california  berkeley 
naaman  m   boase  j     lai  c  h          is it really about me   message content in social
awareness streams  in cscw     proceedings of the      acm conference on computer
supported cooperative work  pp          new york  ny  usa  acm 
natarajan  s   tadepalli  p   altendorf  e   dietterich  t   fern  a     restificar  a          learning
first order probabilistic models with combining rules  in proceedings of the   nd international conference on machine learning  pp          acm 
natarajan  s   bui  h  h   tadepalli  p   kersting  k     wong  w          logical hierarchical
hidden markov models for modeling user activities  in in proc  of ilp    
papai  t   singla  p     kautz  h          constraint propagation for efficient inference in markov
logic  in seventeenth international conference on principles and practice of constraint
programming 
pentland  a  s          honest signals  how they shape our world  the mit press 
poon  h     domingos  p          sound and efficient inference with probabilistic and deterministic
dependencies  in proceedings of the national conference on artificial intelligence  vol     
p       menlo park  ca  cambridge  ma  london  aaai press  mit press       

   

fis adilek   k autz

poon  h     domingos  p          joint inference in information extraction  in proceedings of the
  nd national conference on artificial intelligence volume    pp          aaai press 
poon  h     domingos  p          joint unsupervised coreference resolution with markov logic  in
proceedings of the conference on empirical methods in natural language processing  pp 
        association for computational linguistics 
riedel  s          improving the accuracy and efficiency of map inference for markov logic  in
proceedings of the proceedings of the twenty fourth conference annual conference on uncertainty in artificial intelligence  uai      pp          corvallis  oregon  auai press 
sadilek  a     kautz  h       a   modeling and reasoning about success  failure  and intent of
multi agent activities  in mobile context awareness workshop  twelfth acm international
conference on ubiquitous computing 
sadilek  a     kautz  h       b   recognizing multi agent activities from gps data  in twentyfourth aaai conference on artificial intelligence 
sadilek  a   kautz  h     bigham  j  p          finding your friends and following them to where
you are  in fifth acm international conference on web search and data mining  wsdm  
sato  t     kameya  y          parameter learning of logic programs for symbolic statistical modeling  in journal of artificial intelligence research 
sato  t     kameya  y          new advances in logic based probabilistic modeling by prism  in
probabilistic inductive logic programming  pp          springer 
shakarian  p   subrahmanian  v     spaino  m  l          scare  a case study with baghdad 
in proceedings of the third international conference on computational cultural dynamics 
aaai 
shen  j          activity recognition in desktop environments  ph d  thesis  oregon state university 
shoenfield  j  r          mathematical logic  addison wesley 
singla  p     domingos  p          discriminative training of markov logic networks  in proceedings of the national conference on artificial intelligence  vol      p       menlo park  ca 
cambridge  ma  london  aaai press  mit press       
singla  p     domingos  p          markov logic in infinite domains  in uai    
tang  k   lin  j   hong  j   siewiorek  d     sadeh  n          rethinking location sharing  exploring the implications of social driven vs  purpose driven location sharing  in proceedings of
the   th acm international conference on ubiquitous computing  pp        acm 
tran  s     davis  l          visual event modeling and recognition using markov logic networks 
in proceedings of the   th european conference on computer vision 
ullman  t   baker  c   macindoe  o   evans  o   goodman  n     tenenbaum  j          help
or hinder  bayesian models of social goal inference  in advances in neural information
processing systems  nips   vol     
vail  d          conditional random fields for activity recognition  ph d  thesis  carnegie mellon
university 

   

fil ocation  based r easoning about c omplex m ulti  agent b ehavior

vail  d     veloso  m          feature selection for activity recognition in multi robot domains  in
proceedings of aaai  vol       
wang  j     domingos  p          hybrid markov logic networks  in proceedings of the   rd
national conference on artificial intelligence   volume    pp            aaai press 
wellner  b   mccallum  a   peng  f     hay  m          an integrated  conditional model of information extraction and coreference with application to citation matching  in proceedings of
the   th conference on uncertainty in artificial intelligence  pp          auai press 
wilson  a   fern  a   ray  s     tadepalli  p          learning and transferring roles in multi agent
mdps  in proceedings of aaai 
wilson  a   fern  a     tadepalli  p          bayesian role discovery for multi agent reinforcement learning  in proceedings of the  th international conference on autonomous agents
and multiagent systems  volume   volume    pp            international foundation for
autonomous agents and multiagent systems 
wrobel  s          first order theory refinement  in advances in inductive logic programming  pp 
      ios press  amsterdam 
wu  t   lian  c     hsu  j          joint recognition of multiple concurrent activities using factorial
conditional random fields  in proc    nd conf  on artificial intelligence  aaai       
yoshikawa  k   riedel  s   asahara  m     matsumoto  y          jointly identifying temporal relations with markov logic  in proceedings of the joint conference of the   th annual meeting
of the acl and the  th international joint conference on natural language processing of
the afnlp  volume   volume    pp          association for computational linguistics 

   

fi