journal of artificial intelligence research                 

submitted        published      

computing all pairs shortest paths
by leveraging low treewidth
leon planken
mathijs de weerdt

l r planken tudelft nl
m m deweerdt tudelft nl

faculty of eemcs  delft university of technology 
delft  the netherlands

roman van der krogt

roman  c ucc ie

cork constraint computation centre 
university college cork  cork  ireland

abstract
we present two new and efficient algorithms for computing all pairs shortest paths  the
algorithms operate on directed graphs with real  possibly negative  weights  they make use
of directed path consistency along a vertex ordering d  both algorithms run in o n  wd
time  where wd is the graph width induced by this vertex ordering  for graphs of constant
treewidth  this yields o n  time  which is optimal  on chordal graphs  the algorithms
run in o  nm  time  in addition  we present
a variant that exploits graph separators to

arrive at a run time of o nwd    n  sd on general graphs  where sd  wd is the size of
the largest minimal separator induced by the vertex ordering d  we show empirically that
on both constructed and realistic benchmarks  in many cases the algorithms outperform
floydwarshalls as well as johnsons
algorithm  which
represent the current state of the


art with a run time of o n  and o nm   n  log n   respectively  our algorithms can be
used for spatial and temporal reasoning  such as for the simple temporal problem  which
underlines their relevance to the planning and scheduling community 

   introduction
finding shortest paths is an important and fundamental problem in communication and
transportation networks  circuit design  bioinformatics  internet node traffic  social networking  and graph analysis in generale g  for computing betweenness  girvan   newman       and is a sub problem of many combinatorial problems  such as those that can
be represented as a network flow problem  in particular  in the context of planning and
scheduling  finding shortest paths is important to solve a set of binary linear constraints
on events  i e  the simple temporal problem  stp  dechter  meiri    pearl         the
stp in turn appears as a sub problem to the np hard temporal constraint satisfaction
problem  tcsp  dechter et al         and disjunctive temporal problem  dtp  stergiou
  koubarakis         which are powerful enough to model e g  job shop scheduling problems  the shortest path computations in these applications can account for a significant
part of the total run time of a solver  thus  it is hardly surprising that these topics have received substantial interest in the planning and scheduling community  satish kumar       
bresina  jonsson  morris    rajan        rossi  venable    yorke smith        shah  
williams        conrad  shah    williams        
c
    
ai access foundation  all rights reserved 

fiplanken  de weerdt    van der krogt

instances of the stp  called simple temporal networks  stns   have a natural representation as directed graphs with real edge weights  recently  there has been specific interest
in stns stemming from hierarchical task networks  htns  castillo  fernandez olivares 
  gonzalez        bui   yorke smith         these graphs have the sibling restricted
property  each task  represented by a pair of vertices  is connected only to its sibling tasks 
its parent or its children  in these graphs the number of children of a task is restricted by a
constant branching factor  and therefore the resulting stns also have a tree like structure 
the canonical way of solving an stp instance  dechter et al         is by computing
all pairs shortest paths  apsp  on its stn  thus achieving full path consistency  for
graphs with n vertices and m edges  this can be done in o n  time with the floydwarshall
algorithm  floyd         based on warshalls        formulation of efficiently computing the
transitive closure of boolean matrices  however  the state of the art for computing apsp
on sparse graphs is an algorithm based on the technique originally proposed by johnson
        which does some preprocessing to allow n runs of dijkstras        algorithm  using
a fibonacci heap  fredman   tarjan         the algorithm runs in o n  log n   nm time 
in the remainder of this paper  we refer to this algorithm as johnson 
in this paper we present two new algorithms for apsp with real edge weights  in section     one algorithm  dubbed chleqapsp  is based on a point to point shortest path
algorithm by chleq         the other  named snowball  is similar to planken  de weerdt 
and van der krogts        algorithm for enforcing partial  instead of full  path consistency  p  c   these new algorithms advance the state of the art in computing apsp  in
graphs of constant treewidth  such as sibling restricted stns based on htns with
a con
 
stant branching factor  the run time
 of both algorithms is bounded by o n   which is
optimal since the output is  n    in addition to these stns  examples of such graphs
of constant treewidth are outerplanar graphs  graphs of bounded bandwidth  graphs of
bounded cutwidth  and series parallel graphs  bodlaender        
when chleqapsp and snowball are applied to chordal graphs  they have a run time of
o  nm   which is a strict improvement
over the state of the art  chaudhuri   zaroliagis 

      with a run time of o nmwd    wd is defined below   chordal graphs are an important
subset of general sparse graphs  interval graphs  trees  k trees and split graphs are all special
cases of chordal graphs  golumbic         moreover  any graph can be made chordal using
a so called triangulation algorithm  such an algorithm operates by eliminating vertices one
by one  connecting the neighbours of each eliminated vertex and thereby inducing cliques
in the graph 
the induced width wd of the vertex ordering d is defined to be equal to the cardinality
of the largest such set of neighbours encountered  the upper
 bound of the run time of
both proposed algorithms on these general graphs  o n  wd   depends on this induced
width  finding a vertex ordering of minimum induced width  however  is an np hard
problem  arnborg  corneil    proskurowski         this minimum induced width is the
tree likeness property of the graph mentioned above  i e  the treewidth  denoted w   in
contrast  the induced width is not a direct measure of the input  graph   so the bound of
o n  wd is not quite proper  still  it is better than the bound on johnson if wd  o  log n   
   we prefer to write x  o  f  n   instead of the more common x   o  f  n    formally  the right hand
side represents the set of all functions that grow strictly slower than f  n   and the traditional equality
in fact only works in one direction  see also graham  knuth    patashnik        section      

   

ficomputing apsp by leveraging low treewidth


to see this  note that the bound on johnson is never better than o n  log n   regardless of
the value of m 
in this paper  we also present a variant of snowball that exploits graph separators and
attains an upper bound on the run time of o nwd    n  sd   this upper bound is even
better than the one for the two other new algorithms  since sd  wd is the size of the largest
minimal separator induced by the vertex ordering d  while theoretical bounds on the run
time usually give a good indication of the performance of algorithms  we see especially for
this last variant that they do not always predict which algorithm is best in which settings 
in section    therefore  we experimentally establish the computational efficiency of the
proposed algorithms on a wide range of graphs  varying from random scale free networks
and parts of the road network of new york city  to stns generated from htns and job shop
scheduling problems 
below  we first give a more detailed introduction of the required concepts  such as
induced width  chordal graphs and triangulation  after which we present the new algorithms
and their analysis 

   preliminaries
in this section  we briefly introduce the algorithm that enforces directed path consistency  dpc  and how to find a vertex ordering required for this algorithm  we then
present our algorithms for all pairs shortest paths  all of which require enforcing dpc  or
a stronger property  as a first step  in our treatment  we assume the weights on the edges
in the graph are real and possibly negative 
    directed path consistency
dechter et al         presented dpc  included here as algorithm    as a way check whether
an stp instance is consistent   this is equivalent to checking that the graph does not
contain a negative cycle  a closed path with negative total weight   the algorithm takes as
input a weighted directed graph g   hv  ei and a vertex ordering d  which is a bijection
between v and the natural numbers             n   in this paper  we simply represent the ith
vertex in such an ordering as the natural number i  the  possibly negative  weight on the
arc from i to j is represented as wij  r  our shorthand for the existence of an arc
between these vertices  in either direction  is  i  j   e  finally  we denote by gk the graph
induced on vertices             k   likewise  for a set of vertices v    v   gv   denotes the graph
induced on v     so  in particular  gv   gn   g 
in iteration k  the algorithm adds edges  in line    between all pairs of lower numbered
neighbours i  j of k  thus triangulating the graph  moreover  in lines   and    it updates
the edge between i and j with the weight of the paths i  k  j and j  k  i  if shorter 
consequently  for i   j  a defining property of dpc is that it ensures that wij is no higher
than the total weight of any path from i to j that consists only of vertices outside gj  except
for i and j themselves   this implies in particular that after running dpc  w   and w  
are labelled by the shortest paths between vertices   and   
   note that other algorithmssuch as bellmanfordcan be used for this purpose as well  and usually
perform better in practice 

   

fiplanken  de weerdt    van der krogt

algorithm    dpc  dechter et al        
input  weighted directed graph g   hv  ei  vertex ordering d   v              n 
output  dpc version of g  or inconsistent if g contains a negative cycle

  

for k  n to   do
forall i   j   k such that  i  k     j  k   e do
wij  min  wij   wik   wkj  
wji  min  wji   wjk   wki  
e  e    i  j  
if wij   wji     then
return inconsistent
end
end
end

  

return g   hv  ei

 
 
 
 
 
 
 
 
 

the run time of dpc depends on a measure wd called the induced width relative to
the ordering d of the vertices  dechter et al         define this induced width of a vertex
ordering d procedurally to be exactly the highest number of neighbours j of k with j   k
encountered during the dpc algorithm  this includes neighbours in the original graph  i e 
 j  k   e  as well as vertices that became neighbours through edges added during an
earlier iteration of the algorithm  however  the definition can be based on just the original
graph and the vertex ordering  by making use of the following result 
proposition    suppose that g   hv  ei is an undirected graph and d   v              n 
 where d is a bijection  is a vertex ordering  suppose further that we are given n sets of
edges ek  for    k  n  defined as follows 

 
ek     j  k   v   j   k  path from k to j in g j  k k       n 
then  ek  is exactly the set of edges visited during iteration k of dpc 
proof  note that by definition  each set ek  is a superset of the original edges between
vertex k and its lower numbered neighbours  we use this fact to prove the equivalence by
induction 
the equivalence holds for the first iteration k   n  because en  is exactly the set of
original edges between vertex n and its lower numbered neighbours  and there are no earlier
iterations during which dpc may have added other edges  j  k  with j   k  now  assuming
that the equivalence holds for all sets e   with     k  we show that it also holds for ek    for
this inductive case  we prove both inclusion relations separately 
   to reach a contradiction  assume that there exists some edge  j  k    ek    with j   k 
which is visited by dpc during iteration k  because ek  includes the original edges between
k and lower numbered neighbours  this must be a new edge added during some earlier
iteration     k  so there must exist edges  j        k      e     by the induction hypothesis 
j and k are therefore connected in the induced subgraph g j k            n    but then they
   

ficomputing apsp by leveraging low treewidth

must also be connected in the larger subgraph g j  k k      n  and thus by definition be
included in ek    a contradiction 
   assume  again for reaching a contradiction  that there exists some edge  j  k   ek 
not part of e during iteration k of dpc and therefore not visited by the algorithm  clearly 
 j  k  cannot have been one of the original edges  by definition of ek  there must therefore
exist a path with at least one intermediate vertex from j to k in the induced subgraph
g j  k k      n    let   be the lowest numbered vertex other than j and k on this path 
we have that     k   j  then  by the induction hypothesis  there must exist edges
 j        k      e     both of which were visited by dpc during iteration    once more  we
reach a contradiction  since dpc must have added  j  k  to e during iteration     k 
we now formally define the induced width as follows  and conclude with proposition  
that this is equivalent to the original procedural definition 
definition    given an undirected graph g   hv  ei  a vertex ordering d  and n sets of
edges ek  as in proposition    the induced width wd of g  relative to d  is the following
measure 
fi fi
wd   max fiek  fi
kv

it follows that the run time of dpc is not a property of the graph per se  rather  it is
dependent on both the graphand the vertex ordering used  with a careful implementation 
dpcs time bound is o nwd  if this ordering is known beforehand 
the edges added by dpc are called fill edges and make the graph chordal  sometimes
also called triangulated   indeed  dpc differs from a triangulation procedure only by its
manipulation of the arc weights  in a chordal graph  every cycle of length four or more has
an edge joining two vertices that are not adjacent in the cycle  by definition    the number
of edges in such a chordal graph  denoted by mc  m  is o  nwd    we now give the formal
definitions of these concepts 

 
definition    given a graph g   hv  ei and a set v     v             v k  v of vertices that
form a cycle in g  a chord
  of this cycle is an edge between non adjacent vertices in this
cycle  i e  an edge v i   v j  e with     j  i   k     a graph g   hv  ei is called chordal
if all cycles of size larger than   have a chord 
definition    given a graph g   hv  ei  a triangulation t of g  with t  e     is a
set of edges such that g    hv  e  t i is chordal  these edges are called fill edges  t is
a minimal triangulation of g if there exists no proper subset t    t such that t   is a
triangulation of g 
    finding a vertex ordering
in principle  dpc can use any vertex ordering to make the graph both chordal and directionally path consistent  however  since the vertex ordering defines the induced width  it
directly influences the run time and the number of edges mc in the resulting graph  as mentioned in the introduction  finding an ordering d with minimum induced width wd   w  
and even just determining the treewidth w   is an np hard problem in general  still  the
class of constant treewidth graphs can be recognised  and optimally triangulated  in o  n 
   

fiplanken  de weerdt    van der krogt

time  bodlaender         if g is already chordal  we can find a perfect ordering  resulting in no fill edges  in o  m  time  using e g  maximal cardinality search  mcs  tarjan  
yannakakis         this perfect ordering is also called a simplicial ordering  because every vertex k together with its lower numbered neighbours in the ordering induces a clique
 simplex  in the subgraph gk   this implies the following  known  result  relating induced
width and treewidth to the size of the largest clique in g 
proposition    if a graph g is chordal  the size of its largest clique is exactly w      if a
non chordal graph g is triangulated along a vertex ordering d  yielding a chordal graph g   
the size of the largest clique in g  is exactly wd      the treewidth of g  equals wd and is
an upper bound for the treewidth of the original graph g  w  wd  
for general graphs  various heuristics exist that often produce good results  we mention
here the minimum degree heuristic  rose         which in each iteration chooses a vertex
of lowest degree  since the ordering produced by this heuristic is not fully known before
dpc starts but depends on the fill edges added  an adjacency list based implementation will
require another o  log n  factor in dpcs time bound  however  for our purposes in this
article  we can afford
the comfort of maintaining an adjacency matrix  which yields bounds

of o n    nwd  time and o n  space 

   all pairs shortest paths
even though  to the best of our knowledge  a dpc based apsp algorithm has not yet
been proposed  algorithms for computing single source shortest paths  sssp  based on dpc
can be obtained from known results in a relatively straightforward manner  chleq       
proposed a point to point shortest path algorithm that with a trivial adaptation computes
sssp  planken  de weerdt  and yorke smith        implicitly also compute sssp as part
of their ippc algorithm  these algorithms run in o  mc   time and thus can
 simply be run
 
once for each vertex to yield an apsp algorithm with o  nmc    o n wd time complexity 
below  we first show how to adapt chleqs algorithm to compute apsp  then  we present
a new  efficient algorithm named snowball that relates to planken et al s        p  c 
    chleqs approach
chleqs        point to point shortest path algorithm was simply called minpath and computes the shortest path between two arbitrary vertices s  t  v in a directionally pathconsistent graph g  it is reproduced here as algorithm   and can be seen to run in o  mc  
time because each edge is considered at most twice  the shortest distance from the source
vertex s is maintained in an array d  the algorithm iterates downward from s to   and then
upward from   to t  updating the distance array when a shorter path is found 
since the sink vertex t is only used as a bound for the second loop  it is clear that d
actually contains shortest distances between all pairs  s  t    with t   t  therefore  we can
easily adapt this algorithm to compute sssp within the same o  mc   time bound by setting
t   n and returning the entire array d instead of just d t   we call the result chleqapsp 
included as algorithm    which calls this sssp algorithm  referred to as minpaths  n times
to compute all pairs shortest paths in o  nmc    o nwd  time 
   

ficomputing apsp by leveraging low treewidth

algorithm    minpath  chleq       
input  weighted directed dpc graph g   hv  ei 
 arbitrary  source vertex s and destination vertex t
output  distance from s to t  or inconsistent if g contains a negative cycle

  

i  v   d i   
d s    
for k  s to   do
forall j   k such that  j  k   e do
d j   min  d j   d k    wkj  
end
end
for k    to t do
forall j   k such that  j  k   e do
d j   min  d j   d k    wkj  
end
end

  

return d t 

 
 
 
 
 
 
 
 
 
  
  

algorithm    chleqapsp
input  weighted directed graph g   hv  ei  vertex ordering d   v              n 
output  distance matrix d  or inconsistent if g contains a negative cycle
 
 

g  dpc g  d 
return inconsistent if dpc did

 

for i    to n do
d i     minpaths g  i 
end

 

return d

 
 

   

fiplanken  de weerdt    van der krogt

algorithm    snowball
input  weighted directed graph g   hv  ei  vertex ordering d   v              n 
output  distance matrix d  or inconsistent if g contains a negative cycle
 
 

g  dpc g  d 
return inconsistent if dpc did

  

i  j  v   d i  j   
i  v   d i  i    
for k    to n do
forall j   k such that  j  k   e do
forall i              k     do
d i  k   min  d i  k   d i  j    wjk  
d k  i   min  d k  i   wkj   d j  i  
end
end
end

  

return d

 
 
 
 
 
 
 
  
  

    the snowball algorithm
in this section  we present an algorithm that computes apsp  or full path consistency  
dubbed snowball and included as algorithm    that has the same asymptotic worst case time
bounds as chleqapsp but requires strictly less computational work 
like chleqapsp  this algorithm first ensures that the input graph is directionally pathconsistent  the idea behind the algorithm is then that we grow  during the execution of
the outermost loop  a clique             k  of computed  shortest  distances  one vertex at a
time  starting with the trivial clique consisting of just vertex    while dpc performed a
backward sweep along d  snowball iterates in the other direction  when adding vertex k
to the clique  the two inner loops ensure that we compute the distances between k and all
vertices i   k  this works because we know by dpc that for any such pair  i  k   there
must exist a shortest path from i to k of the form i      j  k  and vice versa   such
that  j  k   e with j   k is an edge of the chordal graph  this means that the algorithm
only needs to look down at vertices i  j   k  and it follows inductively that d i  j  and
d j  i  are guaranteed to be correct from an earlier iteration 
the name of our algorithm derives from its snowball effect  the clique of computed
distances grows quadratically during the course of its operation  a small example of the
operation of snowball is given in figure    originally  the graph contained a shortest path
         dashed edges have been added by dpc  and the path      is now also
a shortest path  in particular  w   holds the correct value  this snapshot is taken for
k      the shaded vertices    have already been visited and shortest distances d i  j  have
been computed for all i  j     then  during the iteration k      for j     and i      the
algorithm sets the correct weight of d       by taking the sum w     d       
theorem
    algorithm     snowball  correctly computes all pairs shortest paths in o  nmc   
o n  wd time 
   

ficomputing apsp by leveraging low treewidth

 
 
 
 
 
 
 

figure    snapshot  k      of a graph during the operation of snowball 

proof  the proof is by induction  after enforcing dpc  w   and w   are labelled by the
shortest distances between vertices   and    for k     and i   j      the algorithm then
sets d       and d       to the correct values 
now  assume that d i  j  is set correctly for all vertices i  j   k  let    i   v  
v       v    v    k be a shortest path from i to k  and further let hmax  
arg maxh             vh     by dpc  if     hmax      there exists a path of the same
weight where a shortcut vhmax    vhmax    is taken  this argument can be repeated to
conclude that there must exist a shortest path    from i to k that lies completely in gk and 
except for the last arc  in gk    thus  by the induction hypothesis and the observation that
the algorithm considers all arcs from the subgraph gk  to k  d i  k  is set to the correct
value  an analogous argument holds for d k  i  
with regard to the algorithms time complexity  note that the two outermost loops
together result in each of the mc edges in the chordal graph being visited exactly once  the
inner loop always has fewer than n iterations  yielding a run time of o  nmc   time  from
 the
 
observation above that mc  nwd   we can also state a looser time bound of o n wd  
we now briefly discuss the consequences for two special cases  graphs of constant
treewidth and chordal graphs  for chordal graphs  which can be recognised in o  m  time 
we can just substitute m for mc in the run time complexity  further  as described above 
a perfect ordering exists and can be found in o  m  time  this gives the total run time
complexity of o  nm   likewise  we stated above that for a given constant   it can be
determined in o  n  time whether a graph has treewidth w    and if so  a vertex ordering d with wd   w can be found within the same time bound  then  omitting the
constant factor wd   the algorithm runs in o n  time  this also follows from the algorithms pseudocode by noting that every vertex k has a constant number  at most w   of
neighbours j   k 
we note here the similarity between snowball and the p  c algorithm  planken et al  
       presented below  like snowball  p  c operates by enforcing dpc  followed
by a single

backward sweep along the vertex ordering  p  c then computes  in o nwd  time  shortest
   

fiplanken  de weerdt    van der krogt

algorithm    p   c  planken et al        
input  weighted directed graph g   hv  ei  vertex ordering d   v              n 
output  ppc version of g  or inconsistent if g contains a negative cycle
 
 

g  dpc g  d 
return inconsistent if dpc did

 

for k    to n do
forall i  j   k such that  i  k     j  k   e do
wik  min  wik   wij   wjk  
wkj  min  wkj   wki   wij  
end
end

 

return g

 
 
 
 
 

paths only for the arcs present in the chordal graph  this similarity and a property of chordal
graphs in fact prompt us to present a version of snowball with improved time complexity 
    improving run time complexity using separators

in this section  we present an improvement of snowball for an o nwd    n  sd run time 
where sd is the size of the largest minimal separator in the chordal graph obtained by
triangulation along d 
definition    given a connected graph g   hv  ei  a separator is a set v    v such that
gv  v   is no longer connected  a separator v   is minimal if no proper subset of v   is a
separator 
this bound is better because  as seen below  it always holds that sd  wd   the improvement hinges on a property of chordal graphs called partial path consistency  ppc  
in a partially path consistent graph  each arc is labelled by the length of the shortest path
between its endpoints   p  c  presented as algorithm    depends on dpc and computes ppc
in o nwd  time  which is the current state of the art  then  we use a clique tree of the
ppc graph to compute the shortest path between all vertices  figure   shows an example
of a chordal graph and its associated clique tree  such a clique tree has the following useful
properties  heggernes        section      
property    every chordal graph g   hv  ei has an associated clique tree t   hc  si 
which can be constructed in linear time o  mc   
property    each clique tree node c  c is associated with a subset vc  v and induces a
maximal clique in g  conversely  every maximal clique in g has an associated clique tree
node c  c 
property    t is coherent  for each vertex v  v   the clique tree nodes whose associated
cliques contain v induce a subtree of t  
   full path consistency  fpc  is achieved if an arc exists for all pairs of vertices u  v  v  

   

ficomputing apsp by leveraging low treewidth

 a  chordal graph

 b  clique tree

figure    a chordal graph and its clique tree  each shaded shape represents a maximal
clique of the graph  containing the vertices at its corners 
property    if two clique tree nodes ci   cj  c are connected by an edge  ci   cj    s 
vci  vcj is a minimal separator in g  conversely  for each minimal separator v   in g 
there is a clique tree edge  ci   cj    s such that v     vci  vcj  
property
   all vertices appear in at least one clique associated with a node in t   so 
s
v
 
v
 
cc c
since we have by proposition   on page     that the size of the largest clique in a chordal
graph is exactly wd      it follows from properties   and   that sd  wd  

now  the idea behind snowballseparators is to first compute ppc in o nwd  time using
p  c  and then traverse the clique tree  ppc ensures that shortest paths within each clique
have been computed  then  when traversing the clique tree from an arbitrary root node
out  we grow a set vvisited of vertices in cliques whose nodes have already been traversed 
for each clique node c  c visited during the traversal  shortest paths between vertices in
the clique vc and vertices in vvisited must run through the separator vsep between c and cs
parent  if sd is the size of the largest minimal separator in g  for each
 pair of vertices it
 
suffices to consider at most sd alternative routesfor a total of o n sd routes  yielding the
stated overall time complexity of o nwd    n  sd   we formally present the algorithm based
on this idea as algorithm   with its associated recursive procedure processcliquetreenode
 on the following page  
note that because we visit a nodes parent before visiting the node itself  it always
holds that vcparent  vvisited   further note that  for simplicity of presentation  we assume
the graph to be connected  if not  we can simply find all connected components in linear
time and construct a clique tree for each of them 
the improved algorithm has an edge over the original algorithm when separators are
small while the treewidth is not  htn based sibling restricted stns  which are described
as part of our experimental validation in section         for instance  have many separators

of size    if every task has as many as o   n  subtasks and every task with its subtasks

induces a clique  we have
wd  o   n  and sd      implying that snowballseparators still

 
has an optimal o n time complexity for these instances  
before we proceed to prove that the algorithm is correct and meets the stated run time
bounds  we introduce the following definition 
   however  since in general not every task and its subtasks form a clique  this low value of sd will usually
not be attained in practice 

   

fiplanken  de weerdt    van der krogt

algorithm    snowballseparators
input  weighted directed graph g   hv  ei  vertex ordering d   v              n 
output  distance matrix d  or inconsistent if g contains a negative cycle
 
 
 
 
 
 
 
 
 
  

g  p  c g  d 
return inconsistent if p  c did
i  j  v   d i  j   
i  v   d i  i    
  i  j   e   d i  j   wij
  i  j   e   d j  i   wji
build a clique tree t   hc  si of g
select an arbitrary root node croot  c of t
 d  vvisited    processcliquetreenode croot   nil  d   
return d

procedure processcliquetreenode c  cparent   d  vvisited  
input  current clique tree node c  cs parent cparent   distance matrix d  set of
visited vertices vvisited
output  updated matrix d and set vvisited

  

if cparent    nil then
vnew  vc   vcparent
vsep  vc  vcparent
vother  vvisited   vc
forall  i  j  k   vnew  vsep  vother do
d i  k   min  d i  k   d i  j    d j  k  
d k  i   min  d k  i   d k  j    d j  i  
end
end
vvisited  vvisited  vc
forall children c  of c do
 d  vvisited    processcliquetreenode c    c  d  vvisited  
end

  

return  d  vvisited  

 
 
 
 
 
 
 
 
 
  
  
  

   

   recursive call

ficomputing apsp by leveraging low treewidth

definition    we define a distance matrix d as valid for a set u of vertices  and  d  u  
as a valid pair  if for all pairs of vertices  i  j   u  u   d i  j  holds the shortest distance
in g from i to j 
we split the correctness proof of the algorithm into three parts  lemmas   and  
culminate in theorem    the first step is to show that if processcliquetreenode is called
with a valid pair  d  u   and some clique node c  the procedure extends the validity to
u  vc  
lemma    consider a call to procedure processcliquetreenode with  as arguments  a clique
node c  cs parent cparent   a distance matrix d  and the set of visited vertices vvisited   if d
is valid for vvisited upon calling  then d becomes valid for vc  vvisited after running lines
   of processcliquetreenode 
proof  first  note that by property    vc induces a clique in g  therefore  edges exist
between each pair  i  k  of vertices in vc   and since the graph is ppc  wik is labelled with
the shortest distance between i and k  due to lines   and   of the main algorithm  d also
contains these shortest distances  so d is valid for vc  
now  it remains to be shown that for each pair of vertices  i  k   vc  vvisited the
shortest distances d i  k  and d k  i  are set correctly  we show here the case for d i  k  
the other case is analogous 
the desired result follows trivially if cparent   nil  since the procedure is then called with
vvisited     otherwise  let vnew   vc   vcparent   vsep   vc  vcparent and vother   vvisited   vc
as set by the procedure in lines     if either i or k lies in vsep   the correctness of d i  k s
value was already proven  so we only need to consider pairs of vertices  i  k   vnew  vother  
for any such pair  i  k   vsep is a separator between i and k by property    so any
shortest path from i to k is necessarily a concatenation of shortest paths from i to j  and
from j  to k  for some j   vsep   since it follows from the definitions of vnew   vsep and vother
that for all  i  j   vnew  vsep and  j  k   vsep  vother   d i  j  and d j  k  are correctly
set  by the validity of d for vc and vvisited   respectively   the loop on lines    yields the
desired result 
our next step is to prove that through the recursive calls  validity is in fact extended
to the entire subtree rooted at c 
lemma    consider again a call to procedure processcliquetreenode with  as arguments  a
clique node c  cs parent vcparent   a distance matrix d  and the set of visited vertices vvisited  
 
if d is valid for vvisited upon calling  then the returned  updated pair  d    vvisited
  is also
valid 
proof  first  note that by lemma    d is valid for vvisited after the update in line    
assume that the clique tree has a depth of d  the proof is by reverse induction over the
depth of the clique tree node  if c is a clique tree node at depth d  i e  a leaf   the loop in
lines      is a no op  so we immediately obtain the desired result 
now assume that the lemma holds for all nodes at depth k and let c be a clique tree
node at depth k     for the first call  if any  made for a child node c  during the loop in
lines       this lemma can then be applied  as a consequence  the returned and updated
   

fiplanken  de weerdt    van der krogt

pair is again valid  this argument can be repeated until the loop ends and the procedure
returns a valid pair 
with these results at our disposal  we can state and prove the main theorem of this
section 
theorem    algorithm
    snowballseparators  correctly computes all pairs shortest paths

in o nwd    n  sd time 
proof  note that vvisited    for the call to processcliquetreenode in line   of snowball
separators  therefore  the pair  d  vvisited   is trivially valid  by lemma    this call thus
returns a valid updated pair  d  vvisited    since processcliquetreenode has recursively tras
versed the entire clique tree  vvisited contains the union cc vc of all cliques in the clique
tree t   hc  si  which by property   equals the set of all vertices in g  therefore  d
contains the correct shortest paths between all pairs of vertices in the graph 
as for the
 time complexity  note that the initialisations in lines   and   can be carried
 
out in o n time  whereas those in lines   and   require o  mc   time  by property    the
clique tree can be built in linear time o  mc    since the clique tree contains
at most n nodes 

processcliquetreenode is called o  n  times  line   requires o wd  time  to implement
lines    and    of processcliquetreenode  we represent the characteristic function for
vvisited as an array of size n  using vvisited instead of vcparent everywhere  we then we simply
iterate over all o  wd   members of vc to perform the required computations 
now  only the complexity of the loop in lines    remains to be shown  note that
 vsep    sd by definition  and  vother     n always  further using the observation that each of
the n vertices in the graph appears in vnew for exactly one invocation of processcliquetree
node  after
 which it becomes a staunch member of vvisited    we obtain a total time bound of
 
o n sd for the loop over all invocations 
while the recursive description above is perhaps easier to grasp and satisfies the claimed
time bounds  we found that efficiency benefited in practice from an iterative implementation 
it also turns out that a good heuristic is to first visit child nodes connected to the already
visited subtree by a large separator  postponing the processing of children connected by a
small separator  because the set of visited vertices is then still small  in this way  the sum of
terms  vsep  vvisited   is kept low  in our implementation  we therefore used a priority queue
of clique nodes ordered by their separator sizes  future research must point out whether it
is feasible to determine an optimal traversal of the clique tree within the given time bounds 
having presented our new algorithms and proven their correctness and formal complexity  we now move on to an empirical evaluation of their performance 

   experiments
we evaluate the two algorithms together with efficient implementations of floydwarshall
and johnson with a fibonacci heap  across six different benchmark sets  
   for johnson we used the corrected fibonacci heap implementation by fiedler         since the widely
used pseudocode of cormen  leiserson  rivest  and stein        contains mistakes 
   available at
http   dx doi org         uuid      c   c fb    f      cca    edccf

   

ficomputing apsp by leveraging low treewidth

table    properties of the benchmark sets
type
chordal
 figure  
 figure  
scale free
 figure  
 figure  
new york
diamonds
job shop
htn

 cases

n

m

wd

sd

   
   

     
        

             
             

     
   

     
   

   
   
   
   
   
   

     
        
        
        
       
      

           
          
        
        
         
        

     
      
   
 
    
    

     
      
   
 
    
    

the properties of the test cases are summarised in table    this table lists the number
of test cases  the range of the number of vertices n  edges m  the induced width wd produced
by the minimum degree heuristic  as well as the size of the largest minimal separators sd
in the graphs  more details on the different sets can be found below  but one thing that
stands out immediately is that sd is often equal to or only marginally smaller than wd  
however  the median size of the minimum separator is less than    for all instances except
the constructed chordal graphs 
all algorithms were implemented in java and went through an intensive profiling phase  
the experiments were run using java      openjdk       b    in server mode  on intel
xeon e     cpus running    bit linux  the java processes were allowed a maximum
heap size of   gb  and used the default stack size  we report the measured cpu times 
including the time that was spent running the triangulation heuristic for chleqapsp and
snowball  the reported run times are averaged over    runs for each unique problem instance 
moreover  we generated    unique instances for each parameter setting  obtained by using
different random seeds  thus  each reported statistic represents an average over     runs 
unless otherwise indicated  finally  each graph instance was ensured to contain no cycles
of negative weight 
    triangulation
as discussed in section      finding an optimal vertex ordering  with minimum induced
width  is np hard  but several efficient triangulation heuristics for this problem exist  we
ran our experiments with six different heuristics  the minimum fill and minimum degree
heuristics  static variants of both  taking into account only the original graph   an ordering
produced by running maximum cardinality search  mcs  on the original graph  and a
random ordering  all of these  except minimum fill  have time complexities within the bound
on the run time of chleqapsp and snowball  we found that the minimum degree heuristic
gave on average induced widths less than      higher than those found by minimum fill 
   our implementations are available in binary form at
http   dx doi org         uuid    a   e   c    ee  d    c  d  b    

   

fiplanken  de weerdt    van der krogt

table    the summed induced width  triangulation  and total run time of snowball over all
experiments on general  non chordal  graphs show that the minimum degree heuristic is the
best choice 
heuristic
min fill
min degree
mcs
static min fill
static min degree
random

p

wd
       
       
       
       
       
       

triangulation  s 
         
   
     
     
     
     

snowball  s 

     
     
     
     
     
     

total  s 
         
     
     
     
     
     

but with drastically lower run time  the exorbitant time consumption of the minimum
fill heuristic can be partially explained by the fact that we used the libtw package  to
compute this ordering  whose implementation can probably be improved  however  it is
also known from the literature that the theoretical bound on the minimum fill heuristic
is worse than that of minimum degree  kjrulff         all other heuristics are not only
slower than minimum degree  but also yield an induced width at least     higher  resulting
in a longer total triangulation time and a longer total run time of snowball  see the summary
of the results over all benchmarks given in table     again  this confirms kjrulffs earlier
work  in the experimental results included below we therefore only show the results based
on the minimum degree heuristic 
    chordal graphs
to evaluate the performance of the new algorithms on chordal graphs  we construct chordal
graphs of a fixed size of       vertices with a treewidth ranging from    up to just less
than the number of vertices  thus yielding a nearly complete graph at the high end  the
results of this experiment are depicted in figure    in this  and other figures  the error
bars represent the standard deviations in the measured run time for the instances of that
size  for graphs up to an induced width of about three quarters of the number of vertices 
snowball significantly outperforms floydwarshall  which yields the expected horizontal line  
and overall the run time of both new algorithms is well below that of johnson across the
entire range  figure   shows the run times on chordal graphs of a constant treewidth and
with increasing number of vertices  here  the two new algorithms outperform johnson by
nearly an order of magnitude  a factor     for snowball around n          and even more so
regarding floydwarshall  confirming the expectations based on the theoretical upper bounds 
    general graphs

for general  non chordal graphs  we expect from the theoretical analysis that the o nwd  time chleqapsp and snowball algorithms are faster than johnson with its o nm   n  log n
   available from http   treewidth com  

   

ficomputing apsp by leveraging low treewidth

      

time to solve  ms  log scale 

f w
johnson
chleq
snowball

     

    

   
   

    
induced width  log scale 

figure    run times on generated chordal graphs with a fixed number of      vertices and
varying treewidth 

 e   

f w
johnson
chleq
snowball

time to solve  ms  log scale 

      

     

    

   
   

    
number of vertices  log scale 

    

figure    run times on generated chordal graphs of a fixed treewidth of     

   

fiplanken  de weerdt    van der krogt

      
f w
johnson
chleq
snowball

time to solve  ms  log scale 

     

    

   

  
   

   

   

   

   
induced width

   

   

   

   

figure    run times on the scale free benchmarks for graphs of       vertices and varying
induced width 
time bound when wd is low  and that johnson is faster on sparse graphs  where m is low 
of a large induced width wd   the main question is at which induced width this changeover
occurs  regarding floydwarshall with its o n  bound  we expect that for larger n it is
always outperformed by the other algorithms 
      scale free graphs
scale free networks are networks whose degree distribution follows a power law  that is 
for large values of k  the fraction p  k  of vertices in the network having k connections to
other vertices tends to p  k   ck    for some constant c and parameter   in other words 
few vertices have many connections while many vertices have only a few connections  such
a property can be found in many real world graphs  such as in social networks and in
the internet  our instances were randomly generated with albert and barabasis       
preferential attachment method  where in each iteration a new vertex is added to the graph 
which is then attached to a number of existing vertices  the higher the degree of an existing
vertex  the more likely it is that it will be connected to the newly added vertex  to see at
which induced width johnson is faster  we compare the run times on such generated graphs
with       vertices  by varying the number of attachments for each new vertex from  
to n    we obtain graphs with an induced width ranging from    to      in these graphs 
the induced width is already quite large for small attachment values  for example  for a
value of     the induced width is already over     
the results of this experiment can be found in figure    here we see that up to an
induced width of about      attachment value     snowball is the most efficient  for higher
induced widths  johnson becomes the most efficient  for wd around      even floydwarshall
becomes faster than snowball  a consistent observation but from a different angle can be
made from figure    where the induced width is between     and      the number of edges
   

ficomputing apsp by leveraging low treewidth

time to solve  ms  log scale 

     

f w
johnson
chleq
snowball

    

   

   

   

   

   
   
number of vertices

   

   

    

figure    run times on the scale free benchmarks for graphs of induced widths     to    
and varying vertex count 
is between       and       and the number of vertices is varied from     to        here we
see that for small graphs up to     vertices  johnson is the fastest  then snowball overtakes
it  and around     vertices chleqapsp is also faster than johnson  this holds for all results
up to a sparse graph of       vertices  
around the mark of     vertices  the results show a decrease in the run time for both
snowball and chleqapsp  this is an artifact of the  preferential attachment  benchmark
generator  since we cannot generate scale free graphs with a specific induced width  we
modify the attachment value instead  as it turns out  for graphs of this size only one
attachment value yields an induced width within the desired range  for the graph of size
     this width is at the high end of the interval  whereas for the graph of size     it is near
the low end  this explains the reduced run time for the larger graph 
for these scale free networks  we conclude that snowball is the fastest of the four algorithms when the induced width is not too large  at most one third of the number of vertices
in our benchmark set   however  we also observe that the structure of scale free networks is
such that they have a particularly high induced width for relatively sparse graphs  exactly
because a few vertices have most of the connections  therefore  snowball is most efficient
only for relatively small attachment values 
      selections from new york road network
more interesting than the artificially constructed graphs are graphs based on real networks 
for which shortest path calculations are relevant  the first of this series is based on the road
network of new york city  which we obtained from the dimacs challenge website   this
network is very large  with         vertices and         edges  so we decided to compute
   http   www dis uniroma  it  challenge  

   

fiplanken  de weerdt    van der krogt

figure    coordinates for the vertices in the new york city input graph  and examples of
the extent of subgraphs with respectively            and      vertices 

 e   
f w
johnson
chleq
snowball

time to solve  ms  log scale 

 e   

      

     

    

   

  
   

    
number of vertices  log scale 

figure    run times on the new york benchmarks for subgraphs of varying vertex count 

   

ficomputing apsp by leveraging low treewidth

shortest paths for  induced  subgraphs of varying sizes  these were obtained by running
a simple breadth first search from a random starting location until the desired number of
vertices had been visited  the extent of the subnetworks thus obtained is illustrated for
three different sizes in figure    the results of all algorithms on these subgraphs can be
found in figure    here we observe the same ranking of the algorithms as on the chordal
graphs of a fixed treewidth and for diamonds  floydwarshall is slowest with its  n 
run time  then each of johnson  chleqapsp  and snowball is significantly faster than its
predecessor  this can be explained by considering the induced width of these graphs  even
for the largest graphs the induced width is around     which is considerably smaller than
the number of vertices 
      stns from diamonds
this benchmark set is based on problem instances in difference logic proposed by strichman 
seshia  and bryant        and also appearing in the smt lib  ranise   tinelli         where
the constraint graph for each instance takes the form of a circular chain of diamonds  each
such diamond consists of two parallel paths of equal length starting from a single vertex and
ending in another single vertex  from the latter vertex  two paths start again  to converge
on a third vertex  this pattern is repeated for each diamond in the chain  the final vertex
is then connected to the very first one  the sizes of each diamond and the total number of
diamonds are varied between benchmarks 
problems in this class are actually instances of the np complete disjunctive temporal
problem  dtp   constraints take the form of a disjunction of inequalities  from each dtp
instance  we obtain a stp instance  i e  a graph  by randomly selecting one inequality from
each such disjunction  this stp is most probably inconsistent  so its constraint graph
contains a negative cycle  we remedy this by modifying the weights on the constraint edges 
the idea behind this procedure is that the structure of the graph still conforms to the type
of networks that one might encounter when solving the corresponding dtp instance  and
that the run time of the algorithms mostly depends on this structure  moreover  to reduce
the influence of the randomized extraction procedure  we repeat it for    different seeds 
for our benchmark set  we considered problem instances which had the size of the
diamonds fixed at   and their number varying  the most interesting property of this set
is that the graphs generated from it are very sparse  we ran experiments on     graphs 
ranging in size from     to      vertices  all with an induced width of    this induced width
is clearly extremely small  which translates into chleqapsp and snowball being considerably
faster than johnson and floydwarshall  as evidenced by figure   
      stns from job shop scheduling
we generated each of the     graphs in our job shop set from an instance of a real jobshop problem  these instances were of the type available in smt lib  ranise   tinelli 
       but of a larger range than included in that benchmark collection  to obtain these
graphs from the job shop instances  we again used the extraction procedure described in
the previous section  the most striking observation that can be taken from figure    is
that the difference between johnson and the two new algorithms is not quite as pronounced 
though snowball is consistently the fastest of the three by a small margin  the fact that this
   

fiplanken  de weerdt    van der krogt

      
f w
johnson
chleq
snowball

time to solve  ms  log scale 

     

    

   

  

 
   

    
number of vertices  log scale 

figure    run times on the diamonds benchmarks for graphs of varying vertex count 

     

f w
johnson
chleq
snowball

time to solve  ms  log scale 

    

   

  

 
   
number of vertices  log scale 

    

figure     run times on the job shop benchmarks for graphs of varying vertex count 

   

ficomputing apsp by leveraging low treewidth

margin is so small is most likely due to the structure of these graphs  which is also reflected
in their relatively high induced width  note also that the run times for floydwarshall are
better for graphs of up to     vertices  while for larger graphs the other algorithms are
significantly faster 
      stns from htns
finally  we consider a benchmark set whose instances imitate so called sibling restricted
stns originating from hierarchical task networks  this set is therefore particularly interesting from a planning point of view  in these graphs  constraints may occur only between
parent tasks and their children  and between sibling tasks  bui   yorke smith         we
consider an extension that includes landmark variables  castillo  fernandez olivares   
gonzalez        that mimic synchronisation between tasks in different parts of the network  and thereby cause some deviation from the tree like htn structure  we generate
htns using the following parameters   i  the number of tasks in the initial htn tree  fixed
at      note that tasks have a start and end point    ii  the branching factor  determining
the number of children for each task  between   and      iii  the depth of the htn tree
 between   and      iv  the ratio of landmark time points to the number of tasks in the
htn  varying from   to     with a step size of       and  v  the probability of constraints
between siblings  varying from   to     with a step size of      
these settings result in graphs of between     and     vertices  with induced widths
varying between   and      though the induced width seems high in light of our claim
above that it is constant  we verified that wd     branching factor    landmarks    
for all instances  filling in the maximal values of   and     respectively  we find an upper
bound wd       well above the actual maximum encountered 
figure    shows the results of these experiments as a function of the induced widths of
the graphs  we can see that only for the larger induced widths  johnson and chleqapsp
come close  these large induced widths are only found for high landmark ratios of      the
results indicate that for the majority of stns stemming from htns  snowball is significantly
more efficient than johnson 
    snowballseparators
in section     we presented a version of snowball that has an improved worst case run time
over vanilla snowball by taking advantage of the separators in the graph  in this section 
we discuss the results of our experiments comparing these two variants  first  we turn our
attention to the benchmark problems on regular graphs  our results are summarised in
figure     as one can see  snowballseparators actually performs strictly worse on these sets
in terms of run time performance when compared to the original snowball 
however  as can be seen in table    the largest minimal separator is often equal to
or only marginally smaller than the induced width  even though there may be only few
separators this large  and many may be substantially smaller  as noted above  for most
instances the median separator size is below      this prompts us to run experiments on
instances where separator sizes are artificially kept small  indeed  we found that there are
cases where snowballseparators shows an improvement over vanilla snowball when comparing
the number of update operations performedi e  lines   and   of snowball and lines   and  
   

fiplanken  de weerdt    van der krogt

f w
johnson
chleq
snowball

time to solve  ms  log scale 

    

   

  
 

  

  

  
induced width

  

   

   

figure     run times on the htn benchmarks for graphs from     to     vertices and
varying induced width  each point is the average of instances with an induced width within
a range   k   k       for some k  this results in between   and    instances per data point 

      
snowball
snowball sep

time to solve  ms  log scale 

     

chordal

    
scale free

ny
diamonds

   
htn

  
job shop

 
   

    
number of vertices  log scale 

figure     run times of the snowball algorithms on the benchmark problem sets listed in
table   

   

ficomputing apsp by leveraging low treewidth

      

number of updates  x      log scale 

snowball
snowball sep
dpc
p c

     

    

   
  

   

   

   

   
   
induced width

   

   

   

figure     number of distance matrix updates on chordal instances with     vertices 
largest minimal separator size   and varying treewidth  each point represents between  
and    instances 
in processcliquetreenode  along with lines   and   of dpc and lines   and   of p  c  one
such case is presented in figure     this describes the results on a collection of chordal
graphs of     vertices  in which the largest minimal separator is fixed at size    and the
treewidth is varied between    and      the figure also includes the results of dpc and p  c 
as these are the respective subroutines of snowball and snowballseparators  for these graphs 
snowballseparators performs strictly fewer update operations than snowball on all instances 
although the difference becomes smaller as the induced width increases  while the number of
updates shows a distinct improvement over snowball  the run times of the snowballseparators
algorithms do not show the same improvement  instead  as can be seen from figure     the
run times of snowball are strictly better than those of snowballseparators on all instances 
snowball can now even be seen to outperform p  c which has a better theoretical bound  the
reason is that the adjacency matrix data structure as used by snowball is very fast  while
the adjacency list used by p  c  though staying within the theoretical bound  inflicts a larger
constant factor on the run time 
from these experiments  we can conclude that on graphs of these sizes  the additional
bookkeeping required by snowballseparators outweighs the potential improvement in the
number of distance matrix updates 
    a proper upper bound on the run time
on general graphs  the run time of the proposed algorithms depends on the induced width wd
of the ordering produced by the triangulation heuristic  this induced width is not a direct
measure of the input  graph   so the given upper bound on the run time is not quite proper 
to arrive at a proper bound  in this section we aim to relate the run time to the treewidth 
denoted w   which is a property of the input  however  determining the treewidth  an
   

fiplanken  de weerdt    van der krogt

     

time to solve  ms  log scale 

snowball
snowball sep
dpc
p c

    

   

  
  

   

   

   

   
induced width

   

   

   

   

figure     run times on chordal instances with     vertices  largest minimal separator
size   and varying treewidth  each point represents between   and    instances 

np hard problem  is an intractable task for the benchmark problems we used  we therefore

compare the measured induced width wd  w   an upper bound on the treewidth  to a lower
bound x  w     we are unaware of any guarantee on the quality relative to the treewidth
of either the minimum degree triangulation heuristic or the lower bound we used  however 
we can calculate the ratio wd  x to get an upper bound on the ratio wd  w   from this
measure we can then obtain an upper bound on the run time expressed in the treewidth 
at least for the benchmark problems in this paper 
the results of these computations can be found in figure     where we plot these ratios
for the new york  htn  scale free and job shop benchmarks as a function of the lower
bound x  using a least squares approach  we then fitted functions wd  x    cxk  showing
up as a straight line in this log log plot  to the plotted data points  for functions found
by fitting  we get k       for new york  k       for htn  and k        for job shop  all
with small multiplicative constants         c         as one can see from the plotted data
points for the scale free instances  they are not amenable to such a fit and we therefore omit
it from the figure 
the decreasing trend for the job shop data indicates that the quality of the triangulation
 i e  of the upper bound represented by the induced width  gradually increases  the lower
and upper bound are always less than a factor   apart  indeed  if we plot a line representing
a function wd   x     x  yielding a horizontal line in this figure   we find that it describes a
comfortable upper bound on the data points for this benchmark set 
the htn data prompts us to plot a function wd    x       x      with an exponent slightly
higher than the one we found from the least squares fit  and further tweaked slightly by a
    the lower bound was computed with the libtw package  see http   treewidth com   we used the
mmd   least c heuristic 

   

firelative induced width  vs  lower bound 

computing apsp by leveraging low treewidth

new york
htn
scale free
job shop
 x
 
  x   

 

 

 

 
  

   
lower bound on treewidth

figure     an upper bound on the induced width relative to the treewidth can be determined experimentally by comparing it to a lower bound on the treewidth 
multiplicative coefficient to bring it into view  this function as plotted represents an ample
upper bound for the htn benchmarks  as well as the job shop ones  
the fit for the data points for the new york benchmark is not good and the trend of
the points themselves is not very clear  because the lower bound only spans an interval
from   to    therefore  we cannot give an upper bound for this set of benchmarks with any
acceptable level of confidence 
however  the scale free data points we plotted  which could not be fitted with a function
yielding a straight line  do mostly follow a clear curving trend  a hypothesis for this
behaviour is that the quality of the upper and lower bound deteriorates mostly for the middle
sizes of the benchmarks  smaller and larger scale free graphs are easier to triangulate well   
to give an upper bound  we could plot any line on the outer hull of these data points  e g 
the horizontal line represented by wd  x     x would work  the most pessimistic assumption
would be to choose a function with the highest slope  and we find that the upper bound
wd    x       x      found for the htn benchmarks  also works here 
from this discussion 
 we may conclude that for
 all benchmarks we ran except for new
snowball
york  wd  x  is o x    which in turn is o w       the run time of the algorithms

and chleqapsp on these instances can therefore be bounded by o n  w      
to conclude this section  we remark that an alternative to a triangulation heuristic
would be to use an approximation algorithm with a bound on the induced width that can
be theoretically determined  for example  bouchitte  kratsch  muller  and todinca       
give a o  log w   approximation of the treewidth w   using such an approximation
would

give an upper bound on the run time of snowball of o n  w log w   however  the run
    this mirrors earlier observations by the authors 

   

fiplanken  de weerdt    van der krogt


time of obtaining this approximate induced width is o n  log  nw   log w and has a high
constant as well  so their work isfor nowmainly of theoretical value 

   related work
for dense  directed
graphs with real weights  the state of the art apsp algorithms run in

 
o n   logn time  chan        han         these represent a serious improvement over
the o n  bound on floydwarshall but do not profit from the fact that in most graphs that
occur in practice  the number of edges m is significantly lower than n   
this profit is exactly what algorithms for sparse graphs aim to achieve  recently  an
improvement was published over the o nm   n  log n algorithm based on johnsons       
and fredman and tarjans
       work  an algorithm for sparse directed graphs running

in o nm   n  log log n time  pettie         in theory  this algorithm is thus faster than
johnson  in worst cases  for large graphs  when m  o  n log n     however  currently no
implementation exists  as confirmed through
personal communication with pettie  june

       the upper bound of o n  wd on the run time of snowball is smaller than this
established upper bound when the induced width is small  i e  when wd  o  log log n   
and  of course  for chordal graphs and graphs of constant treewidth 
we are familiar with one earlier work to compute shortest paths by leveraging low
treewidth  chaudhuri and zaroliagis        present
an algorithm for answering  point to

o wd   
point  shortest path queries with o wd  n log n preprocessing time and query time

a direct extension of their results to apsp would imply a run time of o n  wd  on general
graphs ando nmwd  on chordal graphs  our result of computing apsp on general graphs
in o n  wd and in o  nm  on chordal graphs is thus a strict improvement 
a large part of the state of the art in point to point shortest paths is focused on road
networks  with positive edge weights   these studies have a strong focus on heuristics  ranging from goal directed search and bi directional search to using or creating some hierarchical
structure  see for example  geisberger  sanders  schultes    delling        bauer  delling 
sanders  schieferdecker  schultes    wagner         one of these hierarchical heuristics has
some similarities to the idea of using chordal graphs  this heuristic is called contraction 
the idea there is to distinguish important  core  vertices  which may be possible end points 
from vertices that are never used as a start or end point  these latter vertices are then
removed  bypassed  one by one  connecting their neighbours directly 
other restrictions on the input graphs for which shortest paths are computed can also
be assumed  and sometimes lead to algorithms with tighter bounds 
for example  for

unweighted chordal graphs  apsp lengths can be determined in o n  time  balachandhran
  rangan        han  sekharan    sridhar        if all pairs at distance two are known 
see  dragan        for an overview and unification of such approaches  considering only
planar graphs  recent work shows that apsp be found in o n  log  n  klein  mozes 
  
 
weimann         which is an improvement over johnson in cases where m   n log n  
in the context of planning and scheduling  a number of similar apsp problems need
to be computed sequentially  potentially allowing for a more efficient approach using dynamic algorithms  even and gazit        provide a method where addition of a single edge
can require o n  steps  and deletion o n   m on average  thorup        and deme    we explain our use of the notation x  o  f  n   in footnote   on page     

   

ficomputing apsp by leveraging low treewidth

trescu and italiano       
 later give an alternative approach with an amortized run time of
o n   log n   log  n m
 
  especially in the context of planning and scheduling  it is not esn
sential that the shortest paths between all time points be maintained  often  it is sufficient
when the shortest paths of a selection of pairs are maintained  above  we already mentioned
the p  c algorithm by planken et al         for the single shot case  planken et al        
describe an algorithm that incrementally maintains the property of partial path consistency
on chordal graphs in time linear in the number of edges 

   conclusions and future work
in this paper we give three algorithms for computing all pairs shortest paths  with a run
time bounded by  i  o n  for graphs of constant treewidth  matching earlier results that
also required o n   chaudhuri   zaroliagis        
  ii  o  nm  on chordal graphs  improving over the earlier o nmwd    and  iii  o n  wd on general
 graphs  showing again an
 
 
improvement over previously known tightest bound of o n wd   in these bounds  wd is the
induced width of the ordering used  experimentally we have determined this to be bounded
by the treewidth to the power     for most of our benchmarks 
these contributions are obtained by applying directed path consistency combined with
known graph theoretic techniques  such as a vertex elimination and tree decomposition  to
computing shortest paths  this supports the general idea that such techniques may help
in solving graphically representable combinatorial problems  but the main contribution of
this article is more narrow  focusing on improving the state of the art for this single  but
important problem of computing apsp 
from the results of our extensive experiments we can make recommendations as to
which algorithm is best suited for which type of problems  only for very small instances 
floydwarshall should be used  this is probably mostly thanks to its simplicity  yielding a
very straightforward implementation with low overhead  snowball can exploit the fact that
a perfect elimination ordering can be efficiently found for chordal graphs  which makes it
the most efficient algorithm for this class of graphs  from all our experiments on different
types of general graphs  we conclude that snowball consistently outperforms johnson  and
floydwarshall   except when the induced width is very high  our experiments also show
that snowball always outperforms both chleqapsp and snowballseparators  although the
latter has a better bound on its run time  surprisingly its actual performance is worse than
snowball on all instances of our benchmark sets  this holds even for those instances for
which snowballseparators performs significantly fewer updates  thus  we conclude that the
additional bookkeeping required by snowballseparators does not pay off 
regarding these experiments  it must be noted that  although we did the utmost to
obtain a fair comparison  a constant factor in the measurements depends in a significant
way on the exact implementation details  e g  whether a lookup table or a heap is used  
as is also put forward in earlier work on experimentally comparing shortest path algorithms  mondou  crainic    nguyen        cherkassky  goldberg    radzik         in our
own implementation a higher constant factor for the snowball algorithms may be caused by
adhering to the object oriented paradigm  i e  inheriting from the dpc and p  c superclasses 
and choosing to reuse code rather than inlining method calls  nonetheless  we are confident
that the general trends we identified hold independently of such details 
   

fiplanken  de weerdt    van der krogt

note that strictly speaking  the algorithms introduced in this paper compute all pairs
shortest distances  if one wants to actually trace shortest paths  the algorithms can be
extended to keep track of the midpoint whenever the distance matrix is updated  just like
one does for floydwarshall  then  for any pair of vertices  the actual shortest path in the
graph can be traced in o  n  time 
in our current implementation of snowballseparators  we used a priority queue to decide
heuristically which clique tree node to visit next  giving precedence to nodes connected by
a large separator to the part of the clique tree already visited  as noted before  we defer
answering the question whether an optimal ordering can be found efficiently to future work 
we remark that using the minimum degree heuristic for triangulation provides snowball with
a natural edge  delaying the processing of vertices where the number of iterations of the
middle loop is small until k grows large 
cherkassky and goldberg        compared several innovative algorithms for singlesource shortest paths that gave better efficiency than the standard bellmanford algorithm
in practice  while having the same worst case bound of o  nm  on the run time  in future
work  we will investigate if any of these clever improvements can also be exploited in snowball 
snowballseparators can be improved further in a way that does not influence the theoretical complexity but may yield better performance in practice  iterating over vother can be
seen as a reverse traversal of the part of the clique tree visited before  starting at cs parent 
then  instead of always using the separator between the current clique node  containing k 
and its parent for all previously visited vertices in vother   we can keep track of the smallest
separator encountered during this backwards traversal for no extra asymptotic cost  since
it was shown in table   that the largest minimal separator is often hardly smaller than the
induced width  it might well pay off to search for smaller separators  we plan to implement
this improvement in the near future 
another possible improvement is suggested by the following observation on dpc  a
variant of dpc can be proposed where edge directionality is taken into account  during
iteration k  only those neighbours i  j   k are considered for which there is a directed path
i  k  j  resulting in the addition of the arc i  j  this set of added arcs would often be
much smaller than twice the number of edges added by the standard dpc algorithm  and
while the graph produced by the directed variant would not be chordal  the correctness of
snowball would not be impacted 
furthermore  we would like to also experimentally compare our algorithms to the recent
algorithms by pettie        and the algorithms for graphs of constant treewidth by chaudhuri and zaroliagis        in future work  in addition  we are interested in more efficient
triangulation heuristics  or triangulation heuristics with a guaranteed quality  to be able
to give a guaranteed theoretical bound on general graphs  another direction  especially
interesting in the context of planning and scheduling  is to use the ideas presented here to
design a faster algorithm for dynamic all pairs shortest paths  maintaining shortest paths
under edge deletions  or relaxations  and additions  or tightenings  

acknowledgments
roman van der krogt is supported by science foundation ireland under grant number
   rfp cms     
   

ficomputing apsp by leveraging low treewidth

we offer our sincere gratitude to our reviewers for their comments  which helped us
improve the clarity of the article and strengthen our empirical results 
this article is based on a conference paper with the same title  which has received an
honourable mention for best student paper at the international conference on automated
planning and scheduling  planken  de weerdt    van der krogt        

appendix a  johnsons heap
in the experiments in this paper  we presented the results for johnson
 using a fibonacci
 
heap  because only then the theoretical bound of o nm   n log n time is attained  in
practice  using a binary heap for a theoretical bound of o  nm log n  time turns out to be
more efficient on some occasions  as we show by the results in this section 
figure    shows the run times of johnson with a binary heap and with a fibonacci
heap on all of the benchmark sets listed in table    on the diamonds  htn  and new
york benchmarks the binary heap is a few percent faster than the fibonacci heap  but the
slope of the lines in this doubly logarithmic scale is the same  so we can conclude that
the average case run time has similar asymptotic behavior  however  for larger job shop
problems  a binary heap is a factor   slower than a fibonacci heap  and on our chordal
graph benchmark problems even a factor     our benchmark problems on scale free graphs
with a fixed number of vertices help explaining this difference 
in figure     the run time of both variants of johnson can be found for scale free graphs
with       vertices  with the number of edges varying from about       to almost        
here  we see that only for the sparsest scale free graphs with about        edges  the binary
heap is slightly faster  but when more edges are considered  using the fibonacci heap
significantly outperforms using the binary heap  in particular  the run time of the fibonacci
heap implementation increases only slowly with the number of edges  while the run time of
the binary heap increases much more significantly  this can be explained by the fact that
when running dijkstras algorithm as a subroutine in johnson  each update of a  candidate 
shortest path can be done in amortized constant time with a fibonacci heap  while in a
binary heap this has a worst case cost of o  log n  time per update  the number of updates
is bounded by m for each run of dijkstras algorithm  yielding a bound of o  nm  updates
for johnson  for the binary heap this o  nm log n  bound accounts for a significant part of
the run time  while with a fibonacci heap other operations  such as extracting the minimum
element from the heap  have a bigger relative contribution to the run time 
based on the results over all benchmark sets  we conclude that although johnson with a
binary heap can help reducing the actual run time in sparse graphs  johnson with a fibonacci
heap is overall the better choice if m can be large 

   

fiplanken  de weerdt    van der krogt

 e   
binary
fibonacci

time to solve  ms  log scale 

 e   

chordal

      

     

ny

    

diamonds
scale free

   

htn
job shop

  

  

   
number of vertices  log scale 

    

figure     run times of johnson with a binary heap and with a fibonacci heap on the
benchmark problem sets listed in table   

 e   
binary
fibonacci

time to solve  ms  log scale 

 e   

      

     

    

   

  

    

    

    
     
number of edges  log scale 

     

     

figure     run times of johnson with a binary heap and with a fibonacci heap on scale free
graphs with       vertices and increasing number of edges 

   

ficomputing apsp by leveraging low treewidth

references
albert  r     barabasi  a  l          statistical mechanics of complex networks  reviews
of modern physics               
arnborg  s   corneil  d  g     proskurowski  a          complexity of finding embeddings
in a k  tree  siam journal on algebraic and discrete methods                
balachandhran  v     rangan  c  p          all pairs shortest length on strongly chordal
graphs  discrete applied mathematics                   
bauer  r   delling  d   sanders  p   schieferdecker  d   schultes  d     wagner  d         
combining hierarchical and goal directed speed up techniques for dijkstras algorithm  in experimental algorithms  wea        vol       of lncs  pp         
springer 
bodlaender  h  l          classes of graphs with bounded tree width  tech  rep  ruu cs       utrecht university 
bodlaender  h  l          a linear time algorithm for finding tree decompositions of
small treewidth  siam journal on computing                   
bouchitte  v   kratsch  d   muller  h     todinca  i          on treewidth approximations 
discrete applied mathematics                    
bresina  j  l   jonsson  a  k   morris  p  h     rajan  k          activity planning for
the mars exploration rovers  in proc  of the   th int  conf  on automated planning
and scheduling  pp       
bui  h  h     yorke smith  n          efficient variable elimination for semi structured
simple temporal networks with continuous domains  knowledge engineering review                 
castillo  l   fernandez olivares  j     gonzalez  a          a temporal constraint network
based temporal planner  in proc  of the   st workshop of the uk planning and
scheduling special interest group  pp         delft  the netherlands 
castillo  l   fernandez olivares  j     gonzalez  a          efficiently handling temporal
knowledge in an htn planner  in proc  of the   th int  conf  on automated planning
and scheduling  pp       

chan  t          all pairs shortest paths with real weights in o n    log n time  in
algorithms and datastructures  lncs  pp          springer 
chaudhuri  s     zaroliagis  c  d          shortest paths in digraphs of small treewidth 
part i  sequential algorithms  algorithmica                 
cherkassky  b  v   goldberg  a  v     radzik  t          shortest paths algorithms  theory
and experimental evaluation  mathematical programming                 
cherkassky  b  v     goldberg  a  v          negative cycle detection algorithms  mathematical programming             
chleq  n          efficient algorithms for networks of quantitative temporal constraints 
in proc  of the  st int  workshop on constraint based reasoning  pp       
   

fiplanken  de weerdt    van der krogt

conrad  p  r   shah  j  a     williams  b  c          flexible execution of plans with
choice  in proc  of the   th int  conf  on automated planning and scheduling 
cormen  t  h   leiserson  c  e   rivest  r  l     stein  c          introduction to algorithms   nd edition  mit press 
dechter  r   meiri  i     pearl  j          temporal constraint networks  artificial intelligence                
demetrescu  c     italiano  g  f          fully dynamic all pairs shortest paths with
real edge weights  journal of computer and system sciences                 
dijkstra  e  w          a note on two problems in connexion with graphs   numerische
mathematik            
dragan  f  f          estimating all pairs shortest paths in restricted graph families  a
unified approach  journal of algorithms              
even  s     gazit  h          updating distances in dynamic graphs  methods of operations research             
fiedler  n          analysis of java implementations of fibonacci heap  http   tinyurl 
com fibo heap 
floyd  r  w          algorithm     shortest path  communications of the acm        
    
fredman  m     tarjan  r  e          fibonacci heaps and their uses in improved network
optimization algorithms  journal of the acm                 
geisberger  r   sanders  p   schultes  d     delling  d          contraction hierarchies 
faster and simpler hierarchical routing in road networks  in proc  of the int  workshop
on experimental algorithms  pp          springer 
girvan  m     newman  m  e  j          community structure in social and biological
networks  proc  of the national academy of sciences of the usa                    
golumbic  m          algorithmic graph theory and perfect graphs  elsevier 
graham  r  l   knuth  d  e     patashnik  o          concrete mathematics  a foundation
for computer science   st edition   addison wesley 
han  k   sekharan  c  n     sridhar  r          unified all pairs shortest path algorithms
in the chordal hierarchy  discrete applied mathematics               

han  y          a note of an o n    log n  time algorithm for all pairs shortest paths 
information processing letters                  
heggernes  p          minimal triangulations of graphs  a survey  discrete mathematics 
                 minimal separation and minimal triangulation 
johnson  d  b          efficient algorithms for shortest paths in sparse networks  journal
of the acm              
kjrulff  u          triangulation of graphs   algorithms giving small total state space 
tech  rep   aalborg university 
   

ficomputing apsp by leveraging low treewidth

klein  p  n   mozes  s     weimann  o          shortestpaths in directed planar graphs
with negative lengths  a linear space o n log  n  time algorithm  acm transactions on algorithms             
mondou  j  f   crainic  t  g     nguyen  s          shortest path algorithms  a computational study with the c programming language  computers   operations research 
               
pettie  s          a new approach to all pairs shortest paths on real weighted graphs 
theoretical computer science                
planken  l  r   de weerdt  m  m     van der krogt  r  p  j          p  c  a new algorithm
for the simple temporal problem  in proc  of the   th int  conf  on automated
planning and scheduling  pp         
planken  l  r   de weerdt  m  m     van der krogt  r  p  j          computing allpairs shortest paths by leveraging low treewidth  in proc  of the   st int  conf  on
automated planning and scheduling  pp         
planken  l  r   de weerdt  m  m     yorke smith  n          incrementally solving stns
by enforcing partial path consistency  in proc  of the   th int  conf  on automated
planning and scheduling  pp         
ranise  s     tinelli  c          the smt lib format  an initial proposal  in proc  of
pragmatics of decision procedures in automated reasoning 
rose  d  j          a graph theoretic study of the numerical solution of sparse positive
definite systems of linear equations  in read  r   ed    graph theory and computing 
pp          academic press 
rossi  f   venable  k  b     yorke smith  n          uncertainty in soft temporal constraint problems  a general framework and controllability algorithms for the fuzzy
case  journal of ai research             
satish kumar  t  k          on the tractability of restricted disjunctive temporal problems  in proc  of the   th int  conf  on automated planning and scheduling  pp 
       
shah  j  a     williams  b  c          fast dynamic scheduling of disjunctive temporal
constraint networks through incremental compilation  in proc  of the   th int  conf 
on automated planning and scheduling  pp         
stergiou  k     koubarakis  m          backtracking algorithms for disjunctions of temporal
constraints  artificial intelligence                 
strichman  o   seshia  s  a     bryant  r  e          deciding separation formulas with
sat  in proc  of the   th int  conf  on computer aided verification  vol       of
lncs  pp          springer 
tarjan  r  e     yannakakis  m          simple linear time algorithms to test chordality
of graphs  test acyclicity of hypergraphs  and selectively reduce acyclic hypergraphs  siam journal on computing                 
   

fiplanken  de weerdt    van der krogt

thorup  m          fully dynamic all pairs shortest paths  faster and allowing negative
cycles  in algorithm theory  vol       of lncs  pp          springer 
warshall  s          a theorem on boolean matrices  journal of the acm              

   

fi