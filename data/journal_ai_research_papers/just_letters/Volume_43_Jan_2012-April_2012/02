journal artificial intelligence research                 

submitted        published      

location based reasoning complex multi agent behavior
adam sadilek
henry kautz

sadilek   cs   rochester   edu
kautz   cs   rochester   edu

department computer science  university rochester
rochester  ny        usa

abstract
recent research shown surprisingly rich models human activity learned
gps  positional  data  however  effort date concentrated modeling single individuals statistical properties groups people  moreover  prior work focused solely modeling
actual successful executions  and failed attempted executions  activities interest 
we  contrast  take task understanding human interactions  attempted interactions 
intentions noisy sensor data fully relational multi agent setting  use real world
game capture flag illustrate approach well defined domain involves many
distinct cooperative competitive joint activities  model domain using markov logic 
statistical relational language  learn theory jointly denoises data infers occurrences high level activities  player capturing enemy  unified model combines
constraints imposed geometry game area  motion model players 
rules dynamics game probabilistically logically sound fashion  show
may impossible directly detect multi agent activity due sensor noise malfunction  occurrence activity still inferred considering impact
future behaviors people involved well events could preceded it  further 
show given model successfully performed multi agent activities  along set
examples failed attempts activities  system automatically learns augmented
model capable recognizing success failure  well goals peoples actions
high accuracy  compare approach alternatives show unified model 
takes account relationships among individual players  relationships
among activities entire length game  although computationally costly  significantly accurate  finally  demonstrate explicitly modeling unsuccessful attempts
boosts performance important recognition tasks 

   introduction
society founded interplay human relationships interactions  since every person tightly embedded social structure  vast majority human behavior fully
understood context actions others  thus  surprisingly  evidence shows want model behavior person  single best predictor often
behavior people social network  instance  behavioral patterns people taking taxis 
rating movies  choosing cell phone provider  sharing music best explained predicted
habits related people  rather single person attributes age  race 
education  bell  koren    volinsky        pentland        
contrast observations  research effort activity recognition date concentrated modeling single individuals  bui        liao  fox    kautz               statistical
properties aggregate groups individuals  abowd  atkeson  hong  long  kooper    pinkerton 
      horvitz  apacible  sarin    liao         combinations  eagle   pentland        
c
    
ai access foundation  rights reserved 

fis adilek   k autz

notable exceptions isolated individuals approach includes work kamar horvitz
       gupta  srinivasan  shi  davis         simple relationships among people
starting explicitly considered leveraged  instance  eagle pentland       
elegantly model location individuals multi modal sensory data  approach
oblivious explicit effects ones friends  relatives  etc  ones behavior  isolated individuals approximations often made sake tractability representational convenience 
considering individuals independently sufficient constrained tasks 
many interesting domains discards wealth important information results inefficient unnatural data representation  hand  decomposing domain set
entities  representing instance people  objects environment  activities  linked
various relationships  e g   is a  has a  is involved in  natural clear way representing
data 
address shortcomings nonrelational behavior modeling  introduce capture
flag domain  described below   argue statistical relational approach learning models
multi agent behavior raw gps data  ctf dataset one hand quite complex
recorded real world sensors  time well defined  as per rules game  
thereby allowing unambiguous evaluation results 
able recognize peoples activities reason behavior necessary precondition intelligent helpful machines aware going
human machine well human human relationships  many exciting practical applications activity recognition potential fundamentally change peoples lives 
example  cognitive assistants help people teams productive  provide support
 groups of  disabled individuals  efficiently summarize long complex event busy person
without leaving essential information  important applications include intelligent navigation  security  physical well digital   human computer interaction  crowdsourcing 
applications myriad others build top multi agent activity recognition therefore require necessary stepping stone  furthermore  consequence anthropocentrism
technology  modeling human behavior playsperhaps surprisinglya significant role even
applications directly involve people  e g   unmanned space probes  
furthermore  reasoning human intentions essential element activity recognition 
since recognize person  or group people  wants do  proactively
try help  orin adversarial situationshinder them   intent notoriously problematic
quantify  e g   baldwin   baird         show capture flag domain  notion
naturally captured process learning structure failed activities  know perhaps
well successful action often precededand unfortunately sometimes followedby
multiple failed attempts  therefore  reasoning attempts typically entails high practical utility 
relatively high frequency  consider  example  task real time analysis
security video system  there  detecting person group people  again  relations 
intend steal something much important useful recognizing theft taken
 or even taking  place  certainly late entirely prevent incident 
may late harder merely stop it  believe recognition attempts peoples
activities severely underrepresented topic artificial intelligence needs explored
since opens new realm interesting possibilities 
delve details approach sections      briefly introduce
ctf dataset  section     highlight main contributions work  section     review
  

fil ocation  based r easoning c omplex ulti  agent b ehavior

background material  section     discuss related work  conclude  outline future work
sections        respectively 
paper incorporates extends previous work  sadilek   kautz      a      b  

   capture flag domain
imagine two teamsseven players eachplaying capture flag  ctf  university campus 
player carries consumer grade global positioning system  gps  logs location
 plus noise  every second  see figure     primary goal enter opponents flag area 
players captured enemy territory tagged enemy  upon
captured  must remain place freed  tagged teammate  game ends 
games involve many competitive cooperative activities  focus  both successful
attempted  capturing freeing  visualization games available first authors
website 
collected four games ctf portion university rochester campus  about
   acres  columbus v     gps loggers  one per player    gb memory card
set sampling rate   hz  durations games ranged approximately     
minutes 
work primarily motivated problem annotating strategy games  although
obvious applications results sports combat situations  are  generally  exploring relational learning inference methods recognizing multi agent activities
location data  accept fact gps data disposal inherently unreliable
ambiguous one individual  therefore focus methods jointly simultaneously
localize recognize high level activities groups individuals 
although ctf domain doesnt capture intricacies life  contains many complex  interesting  yet well defined  multi agent  activities  moreover  based extensive
real world gps data  total         data points   thus problems addressing clearly direct analogs everyday life situations ubiquitous computing needs
addressimagine people going daily lives city instead ctf players 
smart phones instead gps loggers 
one main challenges overcome successfully model ctf
severe noise present data  accuracy gps data varies      meters 
open areas  readings typically   meters  discrepancy much higher locations
tall buildings  which present within game area  obstructions  compare
scale error granularity activities concern with  capturing
freeing involves players within reaching distance  less   meter  apart  therefore 
signal noise ratio domain daunting 
error systematic component well significant stochastic component  errors
devices poorly correlated  subtle differences players  angle
device sits players pocket  dramatically affect accuracy  moreover  since
consider multi agent scenarios  errors individual players readings add up  thereby
creating large discrepancy reality recorded dataset  players
move freely open areas  cannot reduce data error assuming players move
along road walkways  done much work gps based activity recognition  e g   liao
et al          finally  traditional techniques denoising gps data  kalman filtering 

  

fis adilek   k autz

figure    snapshot game capture flag shows game area  players
represented pins letters  version ctf  two flags stationary
shown white circles near top bottom figure  horizontal road middle image territory boundary  data shown prior
denoising corrections map errors  videos games available
http   www cs rochester edu u sadilek 
  

fil ocation  based r easoning c omplex ulti  agent b ehavior

little help  due low data rate    sample per second  relative small amount time
required player completely change speed direction 
reliably recognize events happen games presence severe
noise  need consider player  relationships among
actions extended periods time  possibly whole length game   consider concrete
task inferring individual joint activities intentions ctf players gps
traces  example  suppose gps data shows player running toward stationary teammate
b  moving away  occurred  possibly player freed player b  gps error
hidden fact player actually reached b  another possibility player
intention freeing player b  scared opponent last second  yet another possibility freeing occurred even intended  player b previously
captured 
understanding game thus consists inferring complex set interactions among various
players well players intentions  conclusions drawn occurs one point
time affect affected inferences past future events  example given 
recognizing player b moving future reinforces conclusion player freeing
player b  failing recognize past event player b captured decreases confidence
conclusion  game ctf illustrates understanding situation much
recognizing attempts intentions recognizing successfully executed actions 
example  course    minute game  handful capture freeing events occur  however 
dozens cases one player unsuccessfully tries capture opponent free
teammate  description game restricted actually occurred would
pale reflection original 

figure    three snapshots game situation successful failed capturing occur 
example illustrates need approach exploits relational
far reaching temporal structure domain   see text explanation  

concrete example  consider real game situation illustrated figure    see three
snapshots game projected map campus modification gps data 
game time shown snapshot  players d  f  g allies currently
home territory near flag  whereas players l enemies  first snapshot 
players l head opponents flag thenin second framethey intercepted
g  point unclear happening substantial error gps data

  

fis adilek   k autz

three players appear close other  actuality could   
meters apart  however  see third snapshot  note tens seconds passed 
realize player g actually captured player didnt capture l since g evidently
still chasing l  fact player remains stationary coupled fact neither f
attempt capture suggests indeed captured  show possible infer
occurrences capturing events even complex situations whereas limited approaches
largely fail  however  need able recognize individual events  need
discover new activities  identify respective goals  distinguish events based
whether outcomes favorable negative  instance  second frame  player g tries
capture l m  although succeeded former case  failed latter 
many different kinds cooperative competitive multi agent activities occur games 
lowest level joint activities based location movement  include approaching
location  note  noise gps data often makes difficult impossible
directly detect simple activities  next level come competitive multi agent activities
including capturing attacking  cooperative activities include freeing  activities 
chasing guarding  may belong either category categories 
abstract tactical activities  making sacrifice  overall strategies 
playing defensively  paper  concentrate activities first two levels 

   contributions
main contributions paper follows  first present novel method simultaneously denoises positional data learns model multi agent activities occur there 
subsequently evaluate model ctf dataset show achieves high accuracy
recognizing complex game events 
however  creating model manually writing new rules editing existing axioms
laborious prone introduction errors unnecessarily complex theories  thus  would
automate process learning  or inducing  new axioms training data  people 
much easier provide validate concrete examples directly modify model 
leads us second contribution  show automatically augment preexisting model
 joint  activities capable recognizing successful actions  identifies
failed attempts types activities  line work demonstrates explicitly
modeling attempted interactions unified way improves overall model performance 
third contribution  demonstrate difference  discussed below 
newly learned definitions failed activity original definition corresponding successful activity directly corresponds goal given activity  instance  per rules
capture flag game  captured player cannot move freed  system induces
definition failed capture  new theory contain constraint movement
almost captured player  thereby allowing move freely 

   background
cores models described implemented markov logic  ml   statisticalrelational language  section  provide brief overview ml  extends finite firstorder logic  fol  probabilistic setting  detailed  and excellent  treatment fol 

  

fil ocation  based r easoning c omplex ulti  agent b ehavior

ml  inductive logic programming see work shoenfield         domingos  kok  lowd 
poon  richardson  singla         de raedt kersting         respectively 
order compare markov logic based models alternative approaches  consider
dynamic bayesian network  dbn  model experiments one baselines 
therefore review relevant aspects dbns section well 
    markov logic
given inherent uncertainty involved reasoning real world activities observed
noisy sensor readings  looked methodology would provide elegant combination
probabilistic reasoning expressive  relatively natural  compact unfortunately strictly
true false formulas first order logic  exactly markov logic provides thus
allows us elegantly model complex finite relational non i i d  domains  markov logic network
 mln  consists set constants c set pairs hfi   wi fol formula
weight wi r associated it  optionally  weight scaled
real valued function subset variables appear corresponding formula  markov
logic networks contain functions called hybrid mlns  wang   domingos        
mln viewed template markov network  mn  follows  mn contains
one node possible ground atom mln  value node   corresponding
atom false   otherwise  two nodes connected edge corresponding atoms
appear formula  thus  mn distinct clique corresponding grounding
g
formula  j denote j th grounding formula   mn feature value fi j
gj

 
g
  j true
fi j  
  otherwise
weight wi intuitively represents relative importance satisfying  or violating 
weight negative  corresponding formula   formally  weight scales difference
log probability world satisfies n groundings corresponding formula one
results true groundings formula  else equal  cf  equation     thus
problem satisfiability relaxed mlns  longer search satisfying truth assignment
traditional fol  instead  looking truth assignment maximizes sum
weights satisfied formulas 
weights either specified knowledge base engineer or  approach 
learned training data  is  provide learning algorithm labeled capture instances pairs raw corresponding denoised trajectories along labeled instances
game events finds optimal set weights maximize likelihood training
data  weight learning done either generative discriminative fashion  generative training maximizes joint probability observed  evidence  well hidden  query  predicates 
whereas discriminative learning directly maximizes conditional likelihood hidden predicates given observed predicates  since prior work demonstrated markov network models
learned discriminatively consistently outperform generatively trained counterparts  singla  
domingos         focus discriminative learning activity recognition domain 
knowledge base weights specified  ask questions state
hidden atoms given state observed atoms  let x vector random variables
 one random variable possible ground atom mn  let set possible
  

fis adilek   k autz

instantiations x  then  x represents possible world   x   pr x   x      
holds  probability distribution worlds defined
 
x

 
pr x   x    exp
wi ni x i 
   
z


ni  x i    number true groundings i th formula wi weight world x

 
x
x

z 
exp
wi ni x i 
   
x



equation   viewed assigning score possible world dividing score
sum scores possible worlds  the constant z  order normalize 
maximum posteriori  map  inference markov logic given state observed atoms
reduces finding truth assignment hidden atoms weighed sum satisfied
clauses maximal  even though problem general  p complete  achieve reasonable
run times applying cutting plane map inference  cpi   riedel         cpi thought
meta solver incrementally grounds markov logic network  step creating markov
network subsequently solved applicable methodsuch maxwalksat via
reduction integer linear program  cpi refines current solution searching additional
groundings could contribute objective function 
point  focused first order markov logic  first order ml  variable
ranges objects present domain  e g   apples  players  cars   hand  finite
second order markov logic  variabilize objects predicates  relations   kok   domingos         ctf model contains predicate variable type activity  example  one variable capturetype whose domain  capturing  failedcapturing 
analogously freeing events  grounding second order ml  ground predicate
variables well object variables  preliminary work generalizing ml
well defined infinite domains  would indeed give full power fol  singla  
domingos        
implementations markov logic include alchemy  thebeast    experiments used
modified version thebeast 
    dynamic bayesian networks
bayesian network  bn  directed probabilistic graphical model  jordan         nodes
graph represent random variables edges represent conditional dependencies  cf  figure    
bn n nodes  joint probability distribution given
pr x            xn    

n

i  

   http   alchemy cs washington edu 
   http   code google com p thebeast 

  


pr xi  pa xi    

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

pa xi   denotes parents node xi   typical setting  subset random variables
observed  we know actual values   others hidden values need
inferred 
dynamic bayesian network  dbn  bn models sequential data  dbn composed
slicesin case slice represents one second time interval  order specify dbn 
either write learn intra  inter slice conditional probability distributions  cpds  
intra slice cpds typically constitute observation model inter slice cpds model
transitions hidden states  extensive treatment dbns  see work murphy
       
number parameter learning inference techniques dbns  match
markov logic based framework  experiments dbn model presented below  focus
supervised learning scenario  hidden labels known training time therefore
maximum likelihood estimate calculated directly 
find set parameters  discrete probability distributions  maximize log likelihood
training data  achieved optimizing following objective function 

    argmax log pr x  t   y  t     

   



x  t y  t represent sequence observed hidden values  respectively 
times   t    set optimal model parameters  implementation  represent
probabilities likelihoods log counterparts avoid arithmetic underflow 
testing time  interested likely explanation observed data  is 
want calculate likely assignment states hidden nodes  i e   viterbi decoding
dbn  given

 
   
y  t
  argmax log pr y  t  x  t    
y  t

pr y  t  x  t   conditional probability sequence hidden states y  t given concrete
sequence observations x  t times   t  calculate viterbi decoding efficiently
using dynamic programming  jordan        

   methodology
section  describe three major components approach  short  first manually
construct model captures freeings ctf optimize parameters supervised
learning framework  section       constitutes seed theory used denoising raw
location data recognition successful multi agent activities  show  section     
automatically extend seed theory inducing structure learning importance
failed captures freeings well relationships successful counterparts  finally 
section      use augmented theory recognize richer set multi agent activitiesboth
successful failed attemptsand extract goals activities 
specifically  investigate following four research questions 
q   reliably recognize complex multi agent activities ctf dataset even presence severe noise 
q   models attempted activities automatically learned leveraging existing models
successfully performed actions 
  

fis adilek   k autz

q   modeling success failure allow us infer respective goals activities 
q   modeling failed attempts activities improve performance recognizing activities themselves 
elaborate three components system turn  subsequently
discuss  light experimental results lessons learned  answers research
questions 
    recognition successful activities
section  present unified framework intelligent relational denoising raw gps
data simultaneously labeling instances player captured enemy freed
ally  denoising labeling cast learning inference problem markov
logic  denoising  mean modifying raw gps trajectories players final
trajectories satisfy constraints imposed geometry game area  motion model
players  well rules dynamics game  paper  refer trajectory
modification snapping since tile game area     meter cells snap raw
gps reading appropriate cell  creating cells unobstructed space  ensure final
trajectory consistent map area 
begin modeling domain via markov logic theory  write logical formulas express structure model hand  learn optimal set weights
formulas training data supervised discriminative fashion  details experimental setup section     following two subsections  show augment seed
markov logic theory recognize richer set events extract goals players multi agent
activities 
order perform data denoising recognition successful capturing freeing 
model game weighted formulas markov logic  formulas hard 
sense interested solutions satisfy them  hard formulas capture basic
physical constraints  e g   player one location time  inviolable rules game
 e g   captured player must stand still freed game ends    rest formulas
soft  meaning finite weight associated one  soft constraints
correspond traditional low level data filter  expressing preferences smooth trajectories
close raw gps readings  soft constraints capture high level constraints concerning
individual multi agent activities likely occur  example  soft constraint states
player encounters enemy enemys territory  player likely captured 
exact weights soft constraints learned labeled data  described below 
distinguish two types atoms models  observed  e g   gps p                      
hidden  e g   freeing p    p         observed predicates ctf domain are  gps  enemies  adjacent  onhometer  onenemyter   whereas capturing  freeing  iscaptured  isfree 
sameplace  snap hidden  additionally  set hidden predicates expanded structure learning algorithm described  see table   predicate semantics   training phase 
   cheating occur ctf games  principle could accommodated making rules highlyweighted soft constraints rather hard constraints 
   noise gps data introduces ambiguity last two observed predicates  still reliably
generate since road marks boundary territories constitutes neutral zone 

  

fil ocation  based r easoning c omplex ulti  agent b ehavior

hard rules 
h   raw gps reading snapped exactly one cell 
h  

 a  player frees player b  involved players must snapped common cell
time 
 b  player freed free ally 
 c  player freed currently captured 
 d  immediately freeing event  freed player transitions free state 
 e  player freed enemy territory 

h  

 a  player captures player b  involved players must snapped common cell
time 
 b  player captured free enemy 
 c  player captured currently free 
 d  immediately capture event  captured player transitions captured state 
 e  player captured standing enemy territory 

h   players free beginning game 
h   given time  player either captured free both 
h   player transitions captured state free state via freeing event 
h   player transitions free state captured state via capture event 
h   player captured must remain location 

soft rules 
s   minimize distance raw gps reading snapped to cell 
s   minimize projection variance  i e   two consecutive snappings generally correlated 
s   maximize smoothness  both terms space time  final player trajectories 
s   players b enemies  enemy territory b not  b captured already 
close other  probably captures b 
s   players b allies  enemy territory  b currently captured not 
close other  probably frees b 
s   capture events generally rare  i e   typically captures within game 
s   freeing events generally rare 

figure    descriptions hard soft rules capture flag 
learning algorithm access known truth assignment atoms  testing phase 
still access state observed atoms  infer assignment hidden
atoms 
figure   gives english description hard soft rules low level movement
player interactions within capture flag  corresponding formulas language ml
shown figures     
  

fis adilek   k autz

predicate
capturing a  b  t 
enemies a  b 
adjacent c    c   
failedcapturing a  b  t 
failedfreeing a  b  t 
freeing a  b  t 
iscaptured a  t 
isfailedcaptured a  t 

type
hidden
observed
observed
hidden
hidden
hidden
hidden
hidden

isfailedfree a  t 

hidden

isfree a  t 

hidden

onenemyter a  t 
onhometer a  t 
sameplace a  b  t 

observed
observed
hidden

snap a  c  t 

hidden

meaning
player capturing b time t 
players b enemies 
cells c  c  mutually adjacent  c    c   
player unsuccessfully capturing b time t 
player unsuccessfully freeing b time t 
player freeing b time t 
player captured state time t 
time t  player state follows
unsuccessful attempt capturing a 
state capabilities free 
time t  player state follows
unsuccessful attempt freeing a 
state capabilities captured 
player free state time
 isfree a  t  iscaptured a  t   
player enemy territory time t 
player home territory time t 
players b either snapped common cell
two adjacent cells time t 
player snapped cell c time t 

table    summary logical predicates models use  predicate names containing word
failed introduced markov logic theory augmentation method described
section       

compare unified approach four alternative models  first two models  baseline
baseline states  purely deterministic separate denoising gps data
labeling game events  implemented perl  involve
training phase  third alternative model dynamic bayesian network shown figure   
finally  two models cast markov logic  two step ml model unified ml
model itself  unified model handles denoising labeling joint fashion  whereas
two step approach first performs snapping given geometric constraints subsequently labels
instances capturing freeing  latter three models evaluated using four fold crossvalidation order test given game  first train model three games 
models access following observed data  raw gps position player
time indication whether enemy home territory  location     meter
cell  cell adjacency  list pairs players enemies  tested five models
observed data  following describes model detail 
baseline model  b 
model two separate stages  first snap reading nearest cell afterward label instances player capturing player b  labeling rule simple 
  

fil ocation  based r easoning c omplex ulti  agent b ehavior

loop whole discretized  via snapping  data set output capturing a  b  t  every
time encounter pair players b snapped  in first step 
either cell two mutually adjacent cells time t  enemies 
home territory b not  freeing recognition considered simple model
since need notion persisting player states  captured free  order model
freeing meaningful way 
baseline model states  b s 
second model builds top previous one introducing notion players states  player captures player b time t  b enters captured state  in logic 
iscaptured b         b remains captured state moves  is snapped different cell later time  game ends  per rules ctf  player captured
state cannot captured again 
thus  model works previous one except whenever label
capturing event  checks states involved players outputs capturing a  b  t 
b captured state 
freeing recognition implemented analogous way capturing recognition  namely 
every time captured player b transition free state  check b
free teammate nearby  again  within adjacent cells   case  output
freeing a  b  t  
dynamic bayesian network model  dbn 
dynamic bayesian network model viewed probabilistic generalization
baseline model states  structure dbn model one player shown
figure    time slice  one hidden node four observed nodes 
represent binary random variables  want infer likely state
player given time course game  state either free captured
hidden testing time  four observed random variables per time step model
players motion  m    presence absence least one enemy  en   ally  an   player
nearby  finally players location either home enemy territory  et    player
modeled separate dbn  therefore  fourteen instantiated dbns game 
within one game  dbns share set parameters 
note dbn model perform gps trajectory denoising itself  make fair
comparison markov logic models  use denoising component markov
logic theory using constraints h  s s   in figure     produces denoised
discretization data subsequently fed dbn model  random variables
within dbn capture notion player movement players nearby one
another defined occupancy grid game area  two deterministic
baseline models  namely  player said moving time    
snapped two different nonadjacent cells times  similarly  two players
nearby snapped either cell two adjacent cells 
two step ml model   sml 
two step approach  two separate theories markov logic  first theory
used perform preliminary snapping player trajectories individually us  

fis adilek   k autz

ett

   

ent

ant

ett  

ent  

st

st  

mt

mt  

ant  

   

figure    two consecutive time slices dynamic bayesian network modeling state
individual player p observations  shaded nodes represent observed random
variables  unfilled denote hidden variables  random variables binary   ett    
p enemy territory time t  ent     enemy nearby time
t  ant     ally nearby time t  finally mt     p moved
time   t  value hidden state st   p captured time
  p free  

ing constraints h  s s   in figure     theory identical one used
discretization step dbn model above 
second theory takes preliminary denoising list observed atoms
form preliminarysnap a  c  t   meaning player snapped cell c time t  uses
remaining constraints label instances capturing freeing  considering cell adjacency manner previous three models  two step model constitutes
decomposition unified model  see below  overall contains virtually formulas  except  sml operates observed preliminarysnap predicate  whereas unified
model contains hidden snap predicate instead  thus omit elaborating here 
unified ml model  uml 
unified approach  express hard constraints h h  soft constraints s 
s   figure    markov logic single theory jointly denoises data labels game
events  selected interesting formulas shown figure  their labels correspond
listing figure    note formulas s s  contain real valued functions d    d    d 
respectively  d  returns distance agent cell c time t  similarly  d  returns
dissimilarity two consecutive snapping vectors  given agent position time
    location centers two cells c  c    finally  since people prefer
move straight lines  function d  quantifies lack smoothness three consecutive
segments trajectory  since wp   ws   wt assigned negative values
training  formulas s s  effectively softly enforce corresponding geometric constraints 
   initial point snapping  projection  vector raw gps reading terminal point center
cell snap reading to 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

presence functions d  d  renders formulas s s  hybrid formulas  means
inference time  instantiated logical part formula evaluates either    true 
   false   turn multiplied product corresponding function value
formula weight 
see train  test  evaluate four models  perform
multi agent activity recognition task section    next  turn supervised learning method
augmenting unified ml model order recognize successful failed attempts
multi agent activities 
hard formulas 
a  c   snap a  c  t 
 

 h  
 

 

a  c  c      snap a  c  t  c    c   snap a  c   t 
a    a      freeing a    a    t  sameplace a    a    t  isfree a    t 

 h  

enemies a    a    iscaptured a    t  isfree a        

onenemyter a    t  onenemyter a    t 

a    a      capturing a    a    t  sameplace a    a    t  isfree a    t 

 h  

enemies a    a    isfree a    t  iscaptured a        

onhometer a    t  onenemyter a    t 

a    a      sameplace a    a    t  c    c    snap a    c    t  snap a    c    t  adjacent c    c   



a     t      isfree a  t 

 h  

a    iscaptured a  t  isfree a  t 

 h  

a     isfree a  t  iscaptured a            a    capturing a    a  t  

 h  

a     iscaptured a  t  isfree a            a    freeing a    a  t  

 h  

a  t  c    iscaptured a  t  iscaptured a       snap a  c  t   snap a  c      

 h  

figure    hard formulas markov logic  see corresponding rules figure   english
description table   explanation predicates  implementation 
actual rules written syntax used thebeast  markov logic toolkit     
denotes unique existential quantification  designates exclusive or  

    learning models failed attempts
work described above  manually designed structure markov logic network
models capture flag domain allows us jointly denoise raw gps data recognize
   

fis adilek   k autz

soft formulas 


a  c    snap a  c  t  d   a  c  t  wp

 s  



a c    c      snap a  c    t  snap a  c         d   a  c    c    t  ws

 s  



a c    c    c      snap a  c    t  snap a  c         snap a  c         d   a  c    c    c    t  wt
a    a        enemies a    a    onhometer a    t 

 s  
 s  

onenemyter a    t  isfree a    t 
sameplace a    a    t   capturing a    a    t   wc
a    a        enemies a    a    onenemyter a    t 

 s  

onenemyter a    t  sameplace a    a    t  isfree a    t 
iscaptured a    t   freeing a    a    t   wf


a  c    capturing a  c  t  wcb

 s  

a  c     freeing a  c  t   wf b

 s  

figure    soft formulas markov logic  see corresponding rules figure   english description  soft formula
written

traditional quantified finite first order logic
formula  e g   a  c    snap a  c  t     followed optional function  e g   d   a  c  t   
followed weight formula  e g   wp    syntax denotes inference
time  instantiated logical part formula evaluates either    true     false  
effectively multiplied product corresponding function value
formula weight 

instances actual capturing freeing  show automaticallyin supervised
learning settingextend theory encompass correctly label successful actions 
failed attempts interactions  is  given raw gps data represent
ctf games  want new model label instances player captures  or frees  player
b successful captures  successful frees  instances player almost captures  or frees 
player b failed captures  failed frees   example  failed capturing mean instance
players interactions whereup pointit appeared capturing b  carefully
consider events  potentially  preceded well impacts supposed capture
future unfolding game  conclude false alarm capture actually
occurred  words  conditions capture right  later on  pivotal
moment foiled capturing agents attempt 
activities  capturing freeing   model jointly finds optimal separation success failure  note since cast model second order markov logic 
learn  e g   isolated rule separates successful freeing failed attempt freeing 
rathersince capturing freeing events  both actual failed  related thus labeling
activity as  say  successful capturing far reaching impact past  present  future
   

fil ocation  based r easoning c omplex ulti  agent b ehavior

labelingwe learn separations joint unified way  namely  structure  logical
form  importance  weight  formula theory considered consequences
influence axioms theory  system thus finds optimal balance success failure capturing freeing activities respect training data 
      heory augmentation lgorithm
follows  describe markov logic theory augmentation algorithm  algorithm    
clarity  explain works concrete context ml models capture flag
discussed previous sections  however  underlying assumption successful actions
many ways similar failed counterparts  minorbut crucialdeviations cause
failure occur  often hold beyond capture flag  therefore  algorithm applicable
domains different activities  long modeled markov logic 
algorithm     extend ml theory model successful well failed activities 
input  a  set activities
ms   ml theory models successful instances activities
s  set examples successful activities
f   set examples failed activities
output  ms f   augmented ml model learned weights models successful
attempted activities
i  intended goals activities
  
  
  
  
  
  
  

m s lifttosecondorderml ms   a 
m s instantiate m s   a 
findincompatibleformulas f   m s  
ms f m s  i
ms f learnweights s  f   ms f  
ms f removezeroweightedformulas ms f  
return ms f  

high level  augmentation algorithm belongs family structure learning methods  starting seed model successful actions  searches new formulas
added seed theory order jointly model successfully unsuccessfully carried
actions  declarative language biasessentially rules exploring hypothesis space candidate structuresis defined implicitly notion given activity  structure
unsuccessful attempts similar successful attempts  therefore  augmentation algoritm
goes inflation stage  formulas seed theory generalized  followed
refinement stage  superfluous incompatible formulas inflated model pruned
away  refinement step optimizes weights within newly induced theory 
discuss process detail 
input theory augmentation algorithm consists initial first order ml theory ms
models successful capturing freeing  such unified ml model defined section    
contains formulas shown figures       set activities interest a  set
examples successful  s  well failed  f   captures frees  ms need
weights soft formulas specified  case missing  learn scratch

   

fis adilek   k autz

final steps augmentation algorithm  weights specified  final weight learning
step ms f leverage estimate initial weight values  specified
set predicate names  e g    capturing  freeing   example sets f describes game
segment constitutes truth assignment appropriate literals instantiated ms   table  
shows two toy examples sets f three time steps  since goal learn model
failed  and successful  attempts supervised way  example game segment f contain
activities labeled predicates failedcapturing   failedfreeing   
ms contains hybrid formulas  such formulas s s  figure     appropriate function
definitions provided part f well  definition consists implicit mapping
input arguments function values  instance  function d  formula s  quantifies l 
distance
agent cell c time projected mercator space  d   a  c  t   
p
 a gpsxt c gpsx      a gpsyt c gpsy     
system goes following process order induce new theory ms f
augments ms definition failed attempts activity already defined ms  
first lift ms second order markov logic variabilizing predicates correspond
activities interest  step   algorithm     yields lifted theory m s   concretely  order apply technique domain  introduce new predicate variables capturetype  whose domain  capturing  failedcapturing    freetype  over  freeing  failedfreeing   
statetype  over  iscaptured  isfailedcaptured  isfree  isfailedfree    instance  variabilizing first order ml formula freeing a  b  t  enemies a  b  yields second order ml formula
freetype a  b  t  enemies a  b   note freetype variable   instantiating back
first order yields two formulas  freeing a  b  t  enemies a  b  failedfreeing a  b  t 
enemies a  b  
far agents behavior concerned  ctf domain  iscaptured equivalent isfailedfree  isfree equivalent isfailedcaptured  soon see  theory augmentation
process learns equivalence classes relationships states training examples expanding subsequently refining formula h  figure    could work
iscaptured predicate negation represent agents states  feel explicit failure states makes discussion clearer  furthermore  future work need address
hierarchies activities  including failures  context  representation explicit failure
states may convenient  may necessary 
next  instantiate predicate variables m s produce new first order ml theory m s
contains original theory ms entirety plus new formulas correspond failed captures frees  step     since events are  e g   near captures appear similar actual successful
captures  hypothesis need drastically modify original successful formulas order model failed activities well  practice  process lifting
instantiating indeed results good seed theory  could emulate lifting grounding
steps scheme copying formulas renaming predicates duplicates appropriately 
cast approach principled second order markov logic  ties work closely
previous research results extensible framework  specifically  second order markov
logic successfully used deep transfer learning  davis   domingos        predicate invention  kok   domingos         therefore  interesting direction future work
combine theory augmentation refinement transfer inductive learningoperating
second order mlto jointly induce models failed attempts different activities different
domains  starting single model successful activities source domain 
   

fil ocation  based r easoning c omplex ulti  agent b ehavior

set s  successful capture
enemies p    p   
enemies p    p   
onenemyter p      
onenemyter p      
capturing p    p      
isfree p      
isfree p      
isfree p      
isfree p      
isfree p      
iscaptured p      
snap p    c     
snap p    c      
snap p    c      
snap p    c     
snap p    c      
snap p    c      
sameplace p    p      
sameplace p    p      
sameplace p    p      
sameplace p    p      

set f  failed capture
enemies p    p   
enemies p    p   
onenemyter p      
onenemyter p      
onenemyter p      
failedcapturing p    p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
isfree p      
isfailedcaptured p      
snap p    c      
snap p    c      
snap p    c     
snap p    c     
snap p    c      
snap p    c     
sameplace p    p      
sameplace p    p      

table    two examples logical representation successful  s  well failed  f   capture
events input algorithm    closed world assumption applied  therefore
atoms listed assumed false  clarity  omit listing adjacent  
predicate 

typical structure learning inductive logic programming techniques start initial  perhaps empty  theory iteratively grow refine order find form fits training data
well  order avoid searching generally huge space hypotheses  declarative bias either
specified hand mined data  declarative bias restricts set possible refinements formulas search algorithm apply  common restrictions include limiting
formula length  adding new predicate formula shares least one variable
predicate already present formula  hand  approach  first
generate seed theory instantiating activity related predicate variables  put
   

fis adilek   k autz

context structure learning  expand input model order generate large seed theory 
apply bottom up  data driven  learning prune seed theory  whereby training data
guides search formulas remove well optimal set weights remaining
formulas  conjecture failed attempt activity always violates least one constraint
holds successful executions activity  experiments support conjecture 
pruning done steps     algorithm    function findincompatibleformulas f  
m s   returns set hard formulas m s incompatible set examples failed
interactions f   say formula c compatible respect set examples f f
logically entails c  f    c   conversely  f entail c  say c incompatible w r t 
f   explain find incompatible formulas next section 
step   algorithm    simply remove incompatible formulas  i  theory 
point  ms f model  hard formulas guaranteed logically consistent
examples failed activities  because removed incompatible hard formulas   well
successful activities  because logically consistent start with   however 
soft formulas ms f missing properly updated weights  in markov logic  weight
hard formula simply set     therefore  run markov logic weight learning using thebeast
package  step    
recall thebeast implements cutting plane meta solving scheme inference markov
logic  ground ml network reduced integer linear program subsequently
solved lpsolve ilp solver  chose approach opposed to  e g   maxwalksat
may find solution merely locally optimal  since resulting run times still relatively
short  under hour even training testing even complex model   weights
learned discriminatively  directly model posterior conditional probability hidden predicates given observed predicates  set thebeast optimize weights soft
formulas via supervised on line learning using margin infused relaxed algorithm  mira  weight
updates loss function computed number false positives false negatives
hidden atoms  note soft formulas truly irrelevant respect
training examples  picked findincompatibleformulas   function 
weights set zero  or close zero  weight learning step  line   algorithm    
zero weighted formulas subsequently removed following step  note weight
learning process need experience cold start  initial setting weights
inherited input theory ms  
finally  return learned theory ms f   whose formulas optimally weighted respect training examples  experiments results section below  use ms f
recognize successful failed activities  algorithm   returns incompatible hard formulas i  see used extract intended goal activities section     
first  let us discuss step   algorithm   detail 
      c onsistency c heck   f inding ncompatible f ormulas
turn method finding incompatible formulas  summarized algorithm     since
method leverages satisfiability testing determine consistency candidate theories
possible worlds  examples    algorithm   viewed instance learning
interpretationsa learning setting inductive logic programming literature  de raedt        
   often referred covers relation inductive logic programming 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

algorithm    findincompatibleformulas   find formulas ml theory logically inconsistent examples execution failed activities 
input  f   set examples failed activities
  unrefined ml theory successful failed activities
output  smallest set formulas appear unsatisfiable worlds f
  
  
  
  
  
  
  
  
  
   
   
   
   

extractobjects f  
thard   tsoft
integer n  
boolean result false
result    false
c thard
remove new n tuple formulas c
current n  n tuples tested
nn  
end
result testsat f   c   o 
end
return thard   c

input  take set examples failed activities f seed theory  e g   produced
step   algorithm     output smallest set hard formulas appear
logically inconsistent f   algorithm first extracts set objects appear
f  step   algorithm     keeping track type object  example  suppose two example worlds f shown table    extractobjects f   returns
 p    p    p    p    c    c          
example  
snap p    c      
snap p    c      
failedcapturing p    p      

example  
snap p    c      
snap p    c      
failedfreeing p    p      

table    two simple examples logical representation failed capture event 

step    limit hard formulas testing compatibility  since
prove incompatibility hard formulas  soft constraints violated many times
data yet may want eliminate them  instead  want merely adjust
weights  exactly approach  therefore  thard contains hard formulas
appear   next  lines       check entire unmodified thard compatible
 since n      remove formulas   compatible  return empty set
indicating hard formulas original seed theory compatible examples 
detect incompatibility  need remove some  perhaps even all  hard formulas
order arrive logically consistent theory  therefore  incrementally start removing n tuples
formulas  is  subsequent  thard   iterations loop  determine
   

fis adilek   k autz

restore consistency removing one hard formulas thard   can  return
set thard     identified removed incompatible formula  consistency cannot
restored removing single formula  turn begin considering pairs formulas  n      
triples  n       etc  find pruned theory c consistent examples 
general  need consider n tuples formulas  rather testing formula
isolation  due disjunctive formulas conjunction possibly incomplete truth
assignment training data  consider following theory propositional logic 
f    b
f    b c
data  c
 following closed world assumption  negated atom c would actually appear training data  explicitly include example clarity   f  f  individually consistent data  f  f  inconsistent data  complicated examples
constructed  every group k formulas inconsistent data  even though
individual formulas are  special case truth values atoms training examples known  formulas tested consistency individually  reduces original
exponential number iterations algorithm   executes  worst case  linear complexity 
interesting direction future work explore applications logical methods lower
computational cost general case partially observed data 
note hard formulas model physical constraints inviolable rules capture
flag  therefore hold universally  appropriately  formulas eliminated algorithm    example  consider formula h  figure    asserts player occupies
exactly one cell given time  formula satisfied games include successful failed activities  hand  consider formula h  figure  contains
captured player cell captured  following captured players cannot move rule
ctf   holds successful capturing events  necessarily hold failed
attempts capturing  therefore  rule h  expanded via second order ml 
derived formulas going consistent observations 
specifically  candidate formula equation   pruned away  inconsistent
training examples  i e   players nearly captured continue free move about 
however  remaining three variants formula h  pruned away  equation  
always evaluate true  since someone attempts re capture already captured player a 
indeed remain stationary  similarly  equation   consistent example ctf games
failed attempt capture immediately followed successful capture 
captured player remain place time onward  finally  equation   compatible well 
since original formula h  consistent observations 

a  t  c   isfailedcaptured a  t  isfailedcaptured a       snap a  c  t  snap a  c      
   

a  t  c   iscaptured a  t  isfailedcaptured a       snap a  c  t  snap a  c          

   

fil ocation  based r easoning c omplex ulti  agent b ehavior


a  t  c   isfailedcaptured a  t  iscaptured a       snap a  c  t  snap a  c          


a  t  c   iscaptured a  t  iscaptured a       snap a  c  t  snap a  c      

   

function testsat    line    algorithm    checks whether given candidate theory c
compatible examples f following process  first  ground c using objects
o  thereby creating ground theory g  example  c    p x  q x      b  w   
grounding would g    p b  q b   p w   q w     check g fhidden
satisfiable using minisat solver  fhidden simply set hidden atoms appear
f   intuitively  corresponds testing whether plug worlds f c
satisfying hard constraints  though satisfiability np complete problem  practice
testsat   completes within tenths second even largest problems ctf domain 
instance  suppose fhidden    p b   q b    test satisfiability formula



p b  q b  p w   q w   p b  q b  
case cannot satisfy since forced set p b  true q b  false 
renders first clauseand therefore whole formulafalse 
alternative approach pruning formulas via satisfiability testing  described 
would treat types formulas  hard soft  inflated theory m s strictly soft
formulas learning weight formula examples successful failed game
events  however  introduces several complications negatively impact systems performance well model clarity  first  number formulas inflated theory
exponentially larger seed theory  instantiation second order ml representation quantified limit expansion  still worst case exponential blow up 
treating formulas soft ones  need potentially learn many weights 
especially problematic activities occur rarely  may enough training data
properly learn weights  eliminating hard candidate formulas proving inconsistent
dramatically reduces number parameters model  satisfiability testing
np complete  weight learning markov logic entails running inference multiple times 
 p complete problem 
second reason distinguishing soft hard formulas resulting clarity
elegance final learned model ms f   even situations enough training data
properly learn large number weights  run overfitting problems  neither
structure parameters model represent domain natural way  experiments
shown skip pruning stage  steps     algorithm     models recognition
performance differ pruned model significant way  p value       
however  end large number soft formulas mixture positive negative
weights learning algorithm carefully tuned balanced fit training data 
however bear little relationship concepts underlying domain  make
hard human expert analyze model  makes even harder modify
model 
   

fis adilek   k autz

reasons  softening hard formulas is  general  infeasible  interesting direction
future work identify small amount key inconsistent hard formulas soften 
eliminating rest inconsistent hard formulas  however entails searching large
space candidate subsets softened formulas  iteration requires expensive re learning
weights 
note algorithm   terminates soon finds compatible theory requires smallest
number formula removals  experimented active learning component
system  modify algorithms     present several possible refinements
theory user selects one looks best  proposed modifications
shown ml theory level modified sections  formulas  highlighted well
data level program shows inferred consequences modifications 
candidate modification  corresponding consequences displayed collection animations
animation shows results activity recognition would committed
particular candidate theory  note even people background ml
interact system since visualization easy understand  interestingly  case
captures frees  least modified theory off line version algorithm finds
best one therefore need query user  one view differential
variant occams razor  however  different activities domains  active learning
approach may worth revisiting leave exploration future work 
finally  general structure learning techniques statistical relational ai inductive
logic programming applicable substitute theory augmentation algorithm
several reasons  main reason that  efficiency reasons  existing techniques literature
typically operate restricted set formula templates  is  consider horn
clauses  formulas without existential quantifier  formulas k literals
l variables  on  set restrictions part language bias given
approach  principle  structure learning possible without language bias  one often
carefully define one sake tractability  see section   details   approach 
language bias defined implicitly discussed section       
    extracting goal success failure
recall applying theory augmentation process  algorithm    ctf seed theory
successful interactions  shown figures      induces new set formulas capture
structure failed activities ties together existing formulas seed theory 
logically inconsistent formulas algorithm   returns ones satisfiable
worlds failed activities  time  variants formulas consistent
examples successful actions occurring games  therefore  represents difference
theory models successful activities augmented theory successful
failed actions  derived it  intuitively  difference success
failure viewed intended purpose given activity rational agent executes 
consequently goal agent mind engages particular activity 
next section  explore goals extracted ctf domain fashion 
concludes discussion models methodology  turn experimental
evaluation framework presented above 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

   experiments results
evaluate approach along three major directions outlined section    methodology  
focusing answering four research questions formulated ibidem  structure
section closely follows methodology section 
nutshell  first interested markov logic models perform standard
multi agent activity recognition tasklabeling successful activitiesand performance
compares alternative models  second  examine augmented model captures
successful failed attempts activities  model ms f induced algorithm   
lets us extract intended goal activities question  third  compare performance
ms f task jointly recognizing four activities alternative model 
finally  investigate extent reasoning failed attempts help recognition
successfully executed activities 
experiments performed capture flag dataset consisting four separate games 
dataset summarized table    game list number raw gps readings
number instances activity interest  evaluate models via four fold crossvalidation  always training three games  if training required model  testing
fourth  experimental condition below  report precision  recall  f  scores attained
respective model four cross validation runs  purposefully chosen
split data cross validation fold directly corresponds separate game ctf
conceptual convenience clarity  discussed above  events occurring games often
far reaching consequences  example  captured players never freed allies 
therefore  capture beginning game typically profoundly influences entire rest
game  reason  splitting games randomly even manually would introduce unnecessary
complications  segments would dependencies segments  enforcing
fold exactly corresponds different game  make fold self contained 
quantify statistical significance pair wise differences models  use
generalized probabilistic interpretation f  score  goutte   gaussier         namely  express
f  scores terms gamma variates derived models true positives  false positives  false
negatives          h        cf   goutte   gaussier         approach makes possible
compare results future work may apply alternative models similar  identical 
datasets  future comparison may  instance  include additional games introduce random
splits data  note standard statistical significance tests cannot applied situations  p values reported one sided  interested models performance significantly
improves level sophistication increases 
    recognition successful activities
recall two step   sml  unified  uml  markov logic models  specify
markov logic formulas hand optimize weights soft formulas via supervised online learning  run modified version thebeast software package perform weight learning
map inference  thebeast implements cutting plane meta solving scheme inference
markov logic  ground ml network reduced integer linear program subsequently solved lpsolve ilp solver  chose approach opposed to  e g   maxwalksat
get stuck local optimum  since resulting run times still relatively short  under
hour even training testing even complex model  
   

fis adilek   k autz

game  
game  
game  
game  
total

 gps
      
      
     
      
      

 ac
 
 
 
 
  

 fc
  
  
  
 
  

 af
 
 
 
 
 

 ff
 
 
 
 
 

table    ctf dataset overview   gps total number raw gps readings   ac  fc
number actual  successful  failed captures respectively  analogously freeings
  af  ff  

weight learning time  use margin infused relaxed algorithm  mira  weight updates loss function computed number false positives false negatives
hidden atoms  described methodology section  discretization step
dynamic bayesian network model  dbn  implemented markov logic executed
fashion  dbn model trained via maximum likelihood described section     
two deterministic baselines  b b s  require training phase 
inference time  interested likely explanation data  markov logic 
maximum posteriori inference reduces finding complete truth assignment satisfies
hard constraints maximizing sum weights satisfied soft formulas  testing
time  thebeast markov logic solver finds likely truth assignment hidden atoms
described above  section specifically interested values capturing
freeing atoms 
dbns  likely explanation observations equivalent viterbi decoding 
dbn model assigns either free captured state player every time step  label
transitions free captured state capturing transitions captured free
freeing  note dbn model capable determining player freed captured 
model player freeing capturing  evaluation  give
benefit doubt assume always outputs correct actor 
models  inference done simultaneously entire game  on average    
minutes worth data   note restrict inference  small  sliding time window 
experiments described show  many events domain definitely recognized
long occur  example  gps noise may make impossible determine whether player
captured moment encounter enemy  player thereafter remains
place long time  possibility capture becomes certain 
figures     summarize performance models successful capturing freeing
terms precision  recall  f  score calculated four cross validation runs  clarity 
present results two separate plots  model jointly labeling capturing
freeing activities  consider baseline model freeing recognition activity
makes little sense without notion player state  captured free  
see unified approach yields best results activities  let us focus
capturing first  figure     overall  unified model labels       captures correctlythere

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

capturing recogni on
    

    
    

    

    

    

    
    

    

    
    

    

precision

    
    
    

recall

    
    
         

         

b

b s

f 

dbn

 sml

uml

figure    comparison performance five models capturing recognition joint
inference capturing freeing events  see table   statistical significance
analysis pairwise differences models   b   baseline model  b s   baseline
model states   sml   two step markov logic model  uml   unified markov logic
model 

two false negatives  fact  two capture events missed models
involve two enemies appear unusually far apart  about    meters  raw data  even
unified approach fails instance since cost adjusting players trajectoriesthereby
losing score due violation geometry based constraintsis compensated
potential gain labeling additional capture 
note even two step approach recognizes       captures  compared
unified model  misses one additional instance involved players  moderately
far apart  snapped mutually nonadjacent cells  hand  unified model
fail situation limited prior nonrelational snapping nearby cells 
however  difference performance dataset statistically significant even
     level  p value       
deterministic baseline models  b b s  perform poorly  although yield
respectable recall  produce overwhelming amount false positives  shows even
relatively comprehensive pattern matching work domain  interestingly 
performance dbn model leaves much desired well  especially terms precision 
dbn model significantly better baselines  p value less           
achieves significantly worse performance markov logic models  p value less
        see table    
table   summarizes p values pairwise differences models actual  i e   successful 
capturing  difference markov logic based models   sml uml 

   

fis adilek   k autz

freeing recogni on
    

    

    

    

    
    

    
    

    
    

    
    
    

    

    

precision

    

recall

    

f 

    
b s

dbn

  sml

uml

figure    comparison performance three models freeing recognition joint
inference capturing freeing events  see table   statistical significance
analysis pairwise differences models   b s   baseline model states 
 sml   two step markov logic model  uml   unified markov logic model 

b
b s
dbn
 sml

b s
      
 

dbn
       
       
 

 sml
       
       
      
 

uml
       
       
       
      

table    summary statistical significance  one sided p values  pairwise differences f  scores models actual capturing   b   baseline model  b s   baseline
model states  dbn   dynamic bayesian network model   sml   two step markov
logic model  uml   unified markov logic model 

statistically significant  p value        pairwise differences f  scores models
significant      level  often even much lower p values 
though unified model still outperforms alternatives case freeing recognition
well  performance ideal compared capture recognition case  figure    
correctly identifies     freeing events games  produce false
positives  partly due dependency freeing capturing  failure model
recognize capture precludes recognition future freeing  another reason extreme
sparseness freeing events  there five         datapoints   finally 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

b s
dbn
 sml

dbn
      
 

 sml
      
      
 

uml
      
      
      

table    summary statistical significance  one sided p values  pairwise differences f  scores models actual freeing   b s   baseline model states  dbn  
dynamic bayesian network model   sml   two step markov logic model  uml   unified
markov logic model 

instances players barely move freed  may occur number reasons
ranging already occupying strategic spot simply tired  freeing instances
challenging automated system  even people familiar game recognize
 several situations would extremely hard disambiguate didnt access
notes data collection  
two step ml model slightly worse job unified model freeing recognition 
correctly identifies     freeings reasons capturing recognition
case  similarly models actual captures  difference unified two step freeing
models statistically significant  p value       
table   summarizes p values pairwise differences models actual  i e   successful  freeing  see difference b s uml models statistically
significant  p value        whereas differences rest model pairs
statistically significant  since five instances successful freeing   sml model
perform significantly better b s model      significance level  p value
       however  uml model achieves better recognition results even dbn model
high confidence  p value less        therefore  see although  sml model strictly
dominates non markov logic models evaluated capturing recognition  need full
power unified ml model strictly outperform nonrelational alternatives freeing 
suggests move complex interdependent activities  relational unified
modeling approaches winning larger larger margins 
even though statistical significance tests suggest  sml likely give similar results
uml  important note  sml  design  precludes recognition activities question
certain situations  namely  experiments demonstrate  players snapped cells
far apart  two step model even consider instances candidates
labeling  inevitably fails recognizing them  therefore  one needs look beyond p values
obtained comparing fully unified models various alternatives 
expected experiments capturing recognition  deterministic baseline models perform poorly freeing recognition well  produce overwhelming
amount false positives  fail recognize freeing events 
thus  see models cast markov logic perform significantly better
deterministic baseline models  better probabilistic  nonrelational  dbn model 
note dbn model potential quite powerful similar dbns
applied great success previous work activity recognition location data  eagle  
   

fis adilek   k autz

pentland        liao  patterson  fox    kautz         many similarities twostep ml model  share denoising discretization step  operate
observed data  key difference dbn model considers players individually 
whereas two step ml model performs joint reasoning 
looking actual ctf game data  see several concrete examples hurts dbns
labeling accuracy  instance  consider situation two allies captured near
other  performing inference individual players isolation allows dbn model infer
two players effectively free other  even though reality captured cannot
so  occurs dbn model oblivious explicit states ones teammates
well opponents  since capturing freeing interdependent  obliviousness dbn
model state actors negatively impacts recognition performance activities 
example gave illustrates one type freeing false positives  hallucinated freeings
create opportunities often lead false positives captures  creating vicious cycle  false
negatives freeing  capturing  events often occur players model incorrectly believes
already freed  captured  prior time 
since markov logic based models significantly betterwith high level confidence
alternatives fully relational  experiments validate hypothesis
need exploit rich relational temporal structure domain probabilistic way
time affirmatively answer research question q   can reliably recognize complex
multi agent activities ctf dataset even presence severe noise    namely  show
although relatively powerful probabilistic models sufficient achieve high labeling
accuracy  gain significant improvements formulating recognition problem learning
inference markov logic networks 
turn evaluation method learning models success failure
peoples activities 
    learned formulas intentions
applying theory augmentation process  algorithm    ctf seed theory  shown figures      induces new set formulas capture structure failed activities ties
together existing formulas theory  call model ms f   figure   shows
examples new weighted formulas modeling failed freeing capturing attempts appear
ms f  
first  note system correctly carries basic preconditions activity  contrast
formulas s  s   s  s   figures     respectively   allows reliably
recognize successful failed actions instead of  e g   merely labeling events
point time appear resemble capture near capture  re use preconditions directly
follows language bias theory augmentation algorithm 
turning attention learned hard formulas  observe system correctly induced
equivalence classes states  derived mutual exclusion relationships  h     
furthermore tied new failure states corresponding instantaneous interactions  h  
h     
finally  algorithm correctly discovers rule player captured
must remain location  h   figure    key distinction successful
failed capture  since players actually captured still move   therefore  introduces

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

appropriate rule failed captures  h     figure    explicitly stating failed capturing
confine near captured player remain stationary  analogous process yields fitting
separation failed successful freeings  namely  model learns unsuccessfully
freed player remains stationary  learned difference success failure players
actions directly corresponds goal activity consequently intent rational actors  difference system outputs intended goal capturing activity  and
analogously freeing  
experimental results provide evidence resounding yes q   can models
attempted activities automatically learned leveraging existing models successfully performed actions   q   does modeling success failure allow us infer respective
goals activities   within ctf domain 
note instead applying automated theory augmentation method  person could 
principle  manually formulate markov logic theory successful well failed activities
observing games  all  designed initial seed model successful
events  however  process extremely time consuming  one tends omit encoding facts
us  humans  seem self evident need explicitly articulated machine  e g  
single person cannot ten different places once  player either free captured
both   surprisingly easy introduce errors theory  difficult debug 
mostly complex weight learning techniques involved  therefore  believe
theory augmentation method significant step forward enhancing models capabilities
requiring small amounts human effort  complexity domains models increases 
advantage gain larger larger importance 
    recognition successful failed activities
compare performance model ms f alternative  baseline  method
labels four activities following way  similarly baseline states model successful interactions defined section      two separate stages  first snap gps
reading nearest cell applying geometric constraints  h  s s   theory  afterward label instances activities  following labeling rule applied 
loop whole discretized  via snapping  data set look instances pair
players b snapped  in first step  either cell two adjacent cells
time t  enemies  b captured already  home territory b not 
b moves  is snapped different cell later time  without ally nearby  output
failedcapturing a b t   otherwise output capturing a b t   labeling rule freeing defined analogously four events tied together  tested variant dbn model
introduced section     two additional hidden state values node st   isfailedfree
isfailedcaptured  however  difference results obtained model statistically significant  p value        therefore focus conceptually straightforward
baseline model described above 
model ms f evaluated using four fold cross validation  always training three games
testing fourth   figure    compares models terms precision  recall  f 
score  note four activities modeled jointly models  f  score augmented
model significantly better baseline four target activities  p value less
          

   

fis adilek   k autz

a    a        enemies a    a    onhometer a    t 

 s    

onenemyter a    t  sameplace a    a    t  isfree a    t 
isfree a    t   failedcapturing a    a    t         
a    a        enemies a    a    onenemyter a    t 

 s    

onenemyter a    t  sameplace a    a    t  isfree a    t 
iscaptured a    t   failedfreeing a    a    t        
a    a       failedcapturing a    a    t           

 s    

a    a       failedfreeing a    a    t          

 s    

a    isfailedcaptured a  t  isfree a  t 

 h    

a    iscaptured a  t  isfailedfree a  t 
a    isfailedcaptured a  t  isfree a  t 
a    iscaptured a  t  isfailedfree a  t 
a     isfree a  t  isfailedcaptured a            a    failedcapturing a    a  t  
a     iscaptured a  t  isfailedfree a            a    failedfreeing a    a  t  

 h    
 h    

a  t  c    isfailedcaptured a  t  isfailedcaptured a       snap a  c  t   snap a  c      
 h    

figure    example formulas  learned algorithm    model unsuccessful capturing freeing events  crucial intent recognition formula  h     highlighted bold  formulas
eliminated algorithm   preceded symbol  included
induced model ms f   identity iscaptured a  t    isfree a  t  applied throughout refining show formulas intuitive fashion  concreteness sake 
values learned weights come one cross validation run  and similar
runs  

see baseline model has  general  respectable recall produces large
number false positives activities  false positives stem fact algorithm
greedy typically labels situation several players appear close
certain period time sequence many captures subsequent frees even though none
actually occurred  model ms f gives significantly better results takes full
advantage structure game probabilistic fashion  similar labeling
tendency case failed captures  single capture attempt often labeled
several consecutive attempts  hurts precision score  significant deficiency 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

    

baseline

ac     

    

fc     

    

    
    

af    

    

    
    

   
augmented ml model

    

    

f 

    

    

recall
    
    
    

ac     
    

fc     

    

af    

    

   

    

 

   

   

   

   

   

   

   

   

precision

    

    
    
    
    

   

 

figure     performance baseline augmented  ms f   models joint recognition
successful failed capturing freeing  f  score augmented model
significantly better baseline four target activities  p value less
           ac   actual  successful  capturing  fc   failed capturing  af  
actual freeing    failed freeing 

practice  small number short game segments labeled possible near captures
useful well 
note even though original model  uml  contain information
failed capturing failed freeing  performance ms f respectable even two
newly introduced activities  provided examples game situations attempts
occur system augmented subsequently labeled four activities  thus  see
indeed extend preexisting models automated fashion unified model
capable recognizing individual activities  success failure peoples
behavior 
    effect modeling failed attempts recognition successful activities
address research question q   does modeling failed attempts activities improve performance recognizing activities themselves    want see much recognition
attempted activities help modeling successful actions  the latter standard activity

   

fis adilek   k autz

capturing

f 

    

recall

    

precision

     

    

f 
freeing

     

    

recall

     

    

     

precision

    

 

   

   

   

   

without modeling failure

   

   

   

   

   

 

modeling failure

figure     considering unsuccessfully attempted activities strictly improves performance standard activity recognition  blue bars show scores obtained unified markov logic
model considers successful activities  ms    red bars indicate additive improvement provided augmented model considers successful
failed activities  ms f   output algorithm     model labels target activities jointly  separate capturing freeing plot clarity  precision value
  models  f  scores obtained explicitly modeling failed attempts
statistically different f  scores obtained without modeling attempts high
confidence level  p value        however  results still show importance
reasoning peoples attempts recognizing activities  see text details 

recognition problem   toward end  compare markov logic model ms jointly labels
successful capturing freeing model ms f jointly labels successful
failed attempts capturing freeing  see section       detailed description two
models   however  evaluate terms precision  recall  f  score successful
interactions  four types activities 
figure    summarizes results  see evaluated actual capturing  ms f
performs better ms   similarly freeing  however  difference f  scores
model captures attempted successful activities  ms f   model successful activities  ms   statistically significant  p value        partly ms
already produces solid results  leaving little room improvement  additionally  ctf
dataset contains relatively events interest  terms labeling performance testing time 
difference two models      ms ms f recognize  respectively 
   

fil ocation  based r easoning c omplex ulti  agent b ehavior

         successful activities correctly   thus  believe trends shown figure   
promising modeling attempted actions improve recognition performance capturing freeing  evaluation dataset larger number events needed show
difference statistically significant higher confidence level  however  mean
recognizing attempts unimportant  show above  induced augmented model
recognize failed  as well successful  activities complex ctf domain high accuracy 
argue significant contribution 
finally  comparison ms ms f shows applying learning algorithm augments model recognition capabilities hurt model labeling performance 
fact binary classification problems typically easier solve multi class counterparts well reported machine learning literature  allwein  schapire    singer        
therefore  introducing new activities model  especially automated way  likely degrade performance  contrary intuition  experiments show ms f worse
ms successful activity recognition  i e   intersection  high confidence  even though
ms f clearly richer useful 

   related work
world single agent location based reasoning  work bui        presents evaluates system probabilistic plan recognition cast abstract hidden markov memory model 
subsequently  work liao et al         implements system denoising raw gps traces
simultaneously inferring individuals mode transportation  car  bus  etc   goal destination  cast problem learning inference dynamic bayesian network achieve
encouraging results  follow up work  liao et al         introduce framework locationbased activity recognition  implemented efficient learning inference relational
markov network 
work ashbrook starner        focuses inferring significant locations raw
gps logs via clustering  transition probabilities important places subsequently
used number user modeling tasks  including location prediction  work eagle
pentland        explores harnessing data collected regular smart phones modeling human
behavior  specifically  infer individuals general location nearby cell towers bluetooth devices various times day  applying hidden markov model  hmm   show
predicting person home  work  someplace else achieved     accuracy  similarly  work eagle pentland        extracts significant patterns signatures
peoples movement applying eigenanalysis smart phone logs 
work hu  pan  zheng  liu  yang        concentrates recognition interleaving
overlapping activities  show publicly available academic datasets contain significant
number instances activities  formulate conditional random field  crf  model
capable detecting high  more      accuracy  however  focus solely
single agent household activities 
peoples conversation primary focus multi agent modeling effort  barbuceanu
  fox         fields multi agent activity recognition studies human behavior  researchers either modeled conversation explicitly  e g   busetta  serafini  singh    zini        
leveraged peoples communication implicitly via call location logs mobile phones 
data successfully used infer social networks  user mobility patterns  model socially

   

fis adilek   k autz

significant locations dynamics  others  eagle   pentland        eagle  pentland 
  lazer         arguably excellent stepping stone full fledged multi agent activity
recognition since location is  times  practically synonymous ones activity  e g  
store often implies shopping   tang  lin  hong  siewiorek    sadeh         social networks
tremendous influence behavior  pentland        
additionally  number researchers machine vision worked problem recognizing events videos sporting events  impressive recent work learning models
baseball plays  gupta et al          work area focused recognizing individual
actions  e g   catching throwing   state art beginning consider relational
actions  e g   ball thrown player player b   computational challenges dealing
video data make necessary limit time windows seconds  contrast 
demonstrate work many events capture flag data disambiguated
considering arbitrarily long temporal sequences  general  however  work
machine vision rely upon similar probabilistic models  already evidence
statistical relational techniques similar markov logic used activity recognition
video  biswas  thrun    fujimura        tran   davis        
looking beyond activity recognition  recent work relational spacial reasoning includes
attempt locateusing spacial abductioncaches weapons iraq based information
attacks area  shakarian  subrahmanian    spaino         additionally  work abowd
et al         presents location  context aware system  cyberguide  helps people explore
fully experience foreign locations  researchers explore intelligent nonintrusive
navigation system takes advantage predictions traffic conditions along model
users knowledge competence  horvitz et al          finally  work kamar horvitz
       explore automatic generation synergistic plans regarding sharing vehicles across multiple
commuters 
interesting line work cognitive science focuses intent goal recognition probabilistic framework  baker  tenenbaum    saxe               specifically  cast goal inference
inverse planning problem markov decision processes  bayesian inversion used estimate posterior distribution possible goals  recent extensions work begin consider
simulated multi agent domains  baker  goodman    tenenbaum        ullman  baker  macindoe 
evans  goodman    tenenbaum        baker  saxe    tenenbaum         comparison
computational models human judgement synthetic domains shows strong correlation
peoples predicted actual behavior  however  computational challenges involved
dealing underlying partially observable markov decision processes prohibitive
complex domains large state spaces  ours 
focus work different aspect reasoning peoples goals  rather
inferring distribution possible  priori known goals  automatically induce goals
complex multi agent activities themselves 
researchers concentrated modeling behavior people general agents reinforcement learning problems single agent multi agent settings  work       
proposes system household activity recognition cast single agent markov decision process
problem subsequently solved using probabilistic model checker  wilson colleagues address problem learning agents roles multi agent domain derived real time strategy
computer game  wilson  fern  ray    tadepalli        wilson  fern    tadepalli         experiments synthetic domain show strongly encouraging results  perform role
   

fil ocation  based r easoning c omplex ulti  agent b ehavior

learning ourselves  anticipate work wilson et al  going play important role
learning hierarchies peoples activities  capture flag domain  one imagine automatically identifying particular player as  example  defender subsequently leveraging
information model behavior personalized way 
work hong        concentrates recognizing goal agent course
activities deterministic  relational setting  interesting work goal recognition
applied computer aided monitoring complex multi agent systems  relationships
agents leveraged compensate noise sparse data  kaminka  tambe  pynadath 
  tambe         contrast  work focus learning respective goals given set
multi agent activities probabilistic setting  knowledge turn leveraged achieve
stronger robustness recognition tasks  similarly approach hong  system
need supplied plan library either 
work touches anomaly detection since system reasons failed attempts
players  anomaly detection concerns revealing segments data
way violate expectations  excellent survey subject  refer reader
results chandola  banerjee  kumar         realm anomaly detection within peoples
activities  work moore essa        addresses problem error detection recovery
card games involve two players recorded video  system models domain
stochastic context free grammar achieves excellent results 
note recognizing failed attempt activity fine grained problem
anomaly detection  failed event anomalous general   rather  specific
distinction success failure human activities interested in  distinction lies fact unsuccessful attempt yield certain desired state whereas
successful action does  desired state exactly approach extracts activity
question  knowledge  exists prior work explicit modeling recognition
attempted activities learning intended purpose activity multi agent setting 
one components contribution focuses joint learning inference across multiple tasks  capturing  freeing  respective attempted counterparts   contrast
traditional pipeline learning architecture  system decomposed series modules module performs partial computation passes result next stage 
main benefits set up reduced computational complexity often higher modularity 
however  since stage myopic  may take full advantage dependencies broader
patterns within data  additionally  even though errors introduced module may small 
accumulate beyond tolerable levels data passes pipeline 
extensive body work shown joint reasoning improves model performance
number natural language processing data mining tasks including information extraction  i e  
text segmentation coupled entity resolution   poon   domingos         co reference resolution  poon   domingos         information extraction coupled co reference resolution  wellner  mccallum  peng    hay         temporal relation identification  yoshikawa  riedel  asahara 
  matsumoto        ling   weld         record de duplication  domingos        culotta
  mccallum         similarly work  models cast markov logic 
however  prior work uses sampling techniques perform learning inference  whereas apply
   situation player ctf moves campus speed     mph way passes enemy
player certainly anomalous  and probably caused gps sensor noise   want say failed
attempt capturing 

   

fis adilek   k autz

reduction integer linear programming  interestingly  work denis baldridge       
jointly addresses problems anaphoricity co reference via manual formulation
integer linear program 
joint activity modeling shown yield better recognition accuracy  compared
pipeline baselines well baselines make strong inter activity independence assumptions 
work wu  lian  hsu        performs joint learning inference concurrent singleagent activities using factorial conditional random field model  similarly  work helaoui 
niepert  stuckenschmidt        models interleaved activities markov logic  distinguish
foreground background activities infer time window activity takes
place rfid sensory data  contrast  focus joint reasoning multi agent activities
attempts fully relationaland arguably significantly noisysetting 
work manfredotti  hamilton  zilles        propose hierarchical activity recognition
system formulated learning inference relational dynamic bayesian networks  model
jointly leverages observed interactions individual objects domain relationships
objects  since method outperforms hidden markov model significant margin 
contributes additional experimental evidence relational decomposition domain improves
model quality 
work landwehr  gutmann  thon  philipose  de raedt        casts single agent
activity recognition relational transformation learning problem  building transformationbased tagging natural language processing  system induces set transformation rules
used infer activities sensory data  since transformation rules applied
adaptively  step  system leverages observed data  currently assigned
labels  inferred activities   however  transformation rules learned greedy fashion
experiments show model perform significantly better simple hmm 
hand  representation quite general  intuitive  extensible  see 
markov logic model similar level representational convenience performing global
instead greedyoptimization significantly complex domain 
denoising component model formulated tracking problem  prior work
proposed relational dynamic bayesian network model multi agent tracking  manfredotti  
messina         evaluation shows considering relationships tracked entities
significantly improves model performance  compared nonrelational particle filter baseline 
contrast  work explores joint tracking activity recognition  however  gps reading
annotated identity corresponding agent  work manfredotti messina
suggests model generalized  associations gps agent
identities inferred need observed 
markov logic theory viewed template conditional random field  lafferty 
       undirected graphical model captures conditional probability hidden labels
given observations  rather joint probability labels observations  one would
typically directed graphical model  relational world  directed formalisms include
relational bayesian networks  jaeger        dynamic counterparts  manfredotti        
probabilistic relational models  koller        friedman  getoor  koller    pfeffer         bayesian
logic programs  kersting   de raedt         first order conditional influence language  natarajan  tadepalli  altendorf  dietterich  fern    restificar         conditional random fields
extensively applied activity recognition  superior labeling performance generative
models demonstrated number single agent multi agent domains  liao
   

fil ocation  based r easoning c omplex ulti  agent b ehavior

et al         limketkai  fox    liao        vail        vail   veloso        hu et al         
since mlns often solved propositionalized crfs  directed alternatives compiled bayesian network  expected discriminative relational models generally
outperform generative counterparts labeling tasks  however  work needs done
answer question entirety 
since markov logic based on  fact subsumes  finite first order logic  immediately
gain access number techniques developed rich field traditional logic  current markov
logic solvers take advantage underlying logical structure perform powerful optimizations  alchemys lifted inference belief propagation mc sat  poon   domingos 
       additionally  domain pruning  one uses hard constraints infer reduced domains
predicates  shown lead significant speed ups  papai  singla    kautz        
leverage relationship markov first order logic inducing augmented model  furthermore  presence dependency cycles introduces additional problems
directed graphical  relational  models  thus  fact that  markov logic  knowledge
expressed weighted first order formulas combined factors make powerful
framework best suited multi agent reasoning tasks considered work 
traditional hidden markov models operate alphabet unstructured  i e   flat  symbols  makes relational reasoning difficult  one either propositionalize domain 
thereby incurring combinatorial increase number symbols model parameters  ignore
relational structure sacrifice information  logical hidden markov models  lhmms 
proposed address problem  kersting  de raedt    raiko         lhmms generalization standard hmms compactly represents probability distributions sequences
logical atoms rather flat symbols  lhmms proven strictly powerful
propositional counterparts  hmms   applying techniques logic based reasoning 
unification  leveraging logical structure component model  kersting et al  show
lhmms often require fewer parameters achieve higher accuracy hmms 
lhmms recently applied activity recognition  context intelligent user interfaces  work shen        designs evaluates lhmm model recognition peoples
activities workflows carried desktop computer  researchers proposed hierarchical extension lhmms along efficient particle filter based inference technique 
apply activity recognition problems synthetic domains  natarajan  bui  tadepalli  kersting 
  wong         lines work show lhmms learned applied efficiently 
perform better plain hmms 
however  lhmms generative model therefore ideal pure labeling
recognition tasks  typically want make strong independence assumptions
observations  want explicitly model dependencies input space  tildecrfa
relational extension traditional conditional random fieldshas introduced address
issue  gutmann   kersting         tildecrf allows discriminative learning inference crfs
encode sequences logical atoms  opposed sequences unstructured symbols  tildecrf
specifically focuses efficient learning models sequential data via boosting  subsumed
markov logic  produce discriminative generative models  cast model
latter framework make general  extensible  interpretable 
prism  probabilistic extension prolog  shown subsume wide variety generative models  including bayesian networks  probabilistic context free grammars  hmms  along
logical extension   sato   kameya               however  since focus prism
   

fis adilek   k autz

representational elegance generality  rather scalability  sheer size state space
complexity ctf domain precludes application here 
finally  markov logic theory augmentation process related structure learning  transfer learning  inductive logic programming  fact  algorithm   implements special case
structure learning  search target theory explains training data well 
declarative bias forces target theory differ source theory much necessary 
again  intuition failed attempts similar failed counterparts  number
researchers focused structure learning specifically markov logic networks  includes
early work top down structure learning  clauses knowledge base greedily modified adding  flipping  deleting logical literals  kok   domingos         search guided
likelihood training data current model  work mihalkova mooney
       exploit patterns ground markov logic networks introduce bottom up declarative
bias makes algorithm less susceptible finding local optima  compared alternative greedy methods  similarly  work kok domingos        introduce bottom up
declarative bias based lifted hypergraph representation relational database  bias
guides search clauses fit data  since hypergraph lifted  relational path finding
tractable  interesting work predicate invention applies relational clustering technique formulated
second order markov logic discover new predicates relational databases  kok   domingos         systems capable modeling relatively rich family logical formulas 
approaches perform discriminative structure learning achieve excellent results  focus
restricted set types formulas  e g   horn clauses   huynh   mooney        biba  ferilli   
esposito         work davis domingos        successfully uses second order markov
logic deep transfer learning  lift model source domain second order ml
identify high level structural patterns  subsequently serve declarative bias structure
learning target domain 
nature  inductive logic programming discipline extensively studied structure
learning deterministic  well probabilistic settings  e g   muggleton        de raedt       
de raedt  frasconi  kersting    muggleton         fact  theory augmentation algorithm
viewed efficient markov logic based version theory refinement  well established ilp
technique aims improve quality theory terms simplicity  fit newly acquired
data  efficiency factors  wrobel        
approach differs work three main points  first  declarative bias defined
implicitly seed theory successful activities  therefore  theory augmentation algorithm
limited hard wired set formula types consider  rather  search space
defined run time extracting motifs seed theory  second distinction lies computational tractability exactness results  distinguishing soft hard formulas 
able search candidate formulas systematic  rather greedy manner  consequently  final learned model requires fewer parameters  especially important
amount training data relatively small  additionally  weight learning experience cold starts  leverage seed theory  final difference that  knowledge 
first explore structure learning context interplay success failure 
relationship intended goals peoples actions 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

   conclusions
paper took task understanding game capture flag gps data
exemplar general problem inferring human interactions intentions sensor data 
presented novel methodologycast markov logicfor effectively combining data
denoising higher level relational reasoning complex multi agent domain  specifically 
demonstrated given raw noisy data  automatically reliably detect
recognize successful failed interactions adversarial well cooperative settings 
additionally  shown success  failure  goal activity intimately tied
together model successful events allows us naturally learn models
two important aspects life  specifically  demonstrated intentions rational
agents automatically discovered process resolving inconsistencies theory
models successful instances set activities examples failed attempts activities 
formulated four research questions designed experiments within ctf domain
empirically answer them  compared alternative approaches solving multi agent activity recognition problem  augmented markov logic model  takes account
relationships among individual players  relationships among activities entire length
game  although computationally costly  significantly accurate real world data 
furthermore  illustrated explicitly modeling unsuccessful attempts boosts performance
important recognition tasks 

   future work
multi agent activity recognition especially interesting context current unprecedented
growth on line social networksin terms size  popularity  impact offline lives  paper  show location information alone allows rich models peoples
interactions  case on line social networks  additionally access content
users posts explicit implicit network interactions  instance  recent
study shows that  interestingly      twitter status updates reveal authors location
 sadilek  kautz    bigham         data sources available machines massive
volumes ever increasing real time streaming rate  note substantial fraction posts
services facebook twitter talk everyday activities users  naaman  boase 
  lai         information channel become available research community
recently  thus  able reason human behavior interactions automated
way  tap colossal amounts knowledge isat presentdistributed across whole
population 
currently extending model handle explicit gps traces  able
infer location people broadcast gps coordinates  basic idea is  again 
leverage structure relationships among people  vast majority us participate on line
social networks typically friends publish location  thus view
gps enabled people noisy location sensors use network interactions dynamics
estimate location rest users  present  testing approach public
tweets 

   

fis adilek   k autz

acknowledgments
thank anonymous reviewers constructive feedback  thank sebastian riedel
help thebeast  radka sadlkova wendy beatty helpful comments 
work supported aro grant  w   nf            darpa sbir contract  w  p q   c       gift kodak 

references
abowd  g  d   atkeson  c  g   hong  j   long  s   kooper  r     pinkerton  m          cyberguide 
mobile context aware tour guide  wirel  netw                
allwein  e   schapire  r     singer  y          reducing multiclass binary  unifying approach
margin classifiers  journal machine learning research            
ashbrook  d     starner  t          using gps learn significant locations predict movement
across multiple users  personal ubiquitous comput             
baker  c   tenenbaum  j     saxe  r          bayesian models human action understanding 
advances neural information processing systems         
baker  c   goodman  n     tenenbaum  j          theory based social goal inference  proceedings thirtieth annual conference cognitive science society  pp           
baker  c   saxe  r     tenenbaum  j          bayesian theory mind  modeling joint belief desire
attribution  proceedings thirty second annual conference cognitive science
society 
baker  c   tenenbaum  j     saxe  r          goal inference inverse planning  proceedings
  th annual meeting cognitive science society 
baldwin  d  a     baird  j  a          discerning intentions dynamic human action  trends
cognitive sciences                
barbuceanu  m     fox  m          cool  language describing coordination multi
agent systems  proceedings first international conference multi agent systems
 icmas      pp       
bell  r   koren  y     volinsky  c          modeling relationships multiple scales improve
accuracy large recommender systems  kdd  pp         new york  ny  usa  acm 
biba  m   ferilli  s     esposito  f          discriminative structure learning markov logic
networks   pp        springer 
biswas  r   thrun  s     fujimura  k          recognizing activities multiple cues  workshop human motion  pp         
bui  h  h          general model online probabilistic plan recognition  eighteenth international joint conference artificial intelligence  ijcai       
busetta  p   serafini  l   singh  d     zini  f          extending multi agent cooperation overhearing  cooperative information systems  pp        springer 
chandola  v   banerjee  a     kumar  v          anomaly detection  survey  acm comput 
surv                 
   

fil ocation  based r easoning c omplex ulti  agent b ehavior

culotta  a     mccallum  a          joint deduplication multiple record types relational data 
proceedings   th acm international conference information knowledge
management  pp          acm 
davis  j     domingos  p          deep transfer via second order markov logic  proceedings
  th annual international conference machine learning  pp          acm 
de raedt  l          logical relational learning  springer verlag new york inc 
de raedt  l   frasconi  p   kersting  k     muggleton  s   eds            probabilistic inductive
logic programming   theory applications  vol       lecture notes computer
science  springer 
de raedt  l     kersting  k          probabilistic inductive logic programming   de raedt et al  
       pp      
denis  p     baldridge  j          joint determination anaphoricity coreference resolution
using integer programming  proceedings naacl hlt  pp         
domingos  p          multi relational record linkage  proceedings kdd      workshop
multi relational data mining 
domingos  p   kok  s   lowd  d   poon  h   richardson  m     singla  p          markov logic 
 de raedt et al          pp        
eagle  n     pentland  a          reality mining  sensing complex social systems  personal
ubiquitous computing                
eagle  n     pentland  a          eigenbehaviors  identifying structure routine  behavioral
ecology sociobiology                  
eagle  n   pentland  a     lazer  d          inferring social network structure using mobile phone
data  proceedings national academy sciences 
friedman  n   getoor  l   koller  d     pfeffer  a          learning probabilistic relational models 
international joint conference artificial intelligence  vol      pp           
goutte  c     gaussier  e          probabilistic interpretation precision  recall f score 
implication evaluation   pp          springer 
gupta  a   srinivasan  p   shi  j     davis  l  s          understanding videos  constructing plots 
learning visually grounded storyline model annotated videos  cvpr 
gutmann  b     kersting  k          tildecrf  conditional random fields logical sequences 
machine learning  ecml       pp          springer 
helaoui  r   niepert  m     stuckenschmidt  h          statistical relational activity recognition
framework ambient assisted living systems  ambient intelligence future trendsinternational symposium ambient intelligence  isami        pp          springer 
hong  j          goal recognition goal graph analysis  journal artificial intelligence
research          
horvitz  e   apacible  j   sarin  r     liao  l          prediction  expectation  surprise  methods  designs  study deployed traffic forecasting service  twenty first conference
uncertainty artificial intelligence 

   

fis adilek   k autz

hu  d   pan  s   zheng  v   liu  n     yang  q          real world activity recognition multiple
goals  ubicomp  vol     pp       
huynh  t     mooney  r          discriminative structure parameter learning markov
logic networks  proceedings   th international conference machine learning 
pp          acm 
jaeger  m          relational bayesian networks  proceedings   th conference uncertainty artificial intelligence  pp         
jordan  m          learning graphical models  kluwer academic publishers 
kamar  e     horvitz  e          collaboration shared plans open world  studies
ridesharing  ijcai 
kaminka  g  a   tambe  d  v  p  m   pynadath  d  v     tambe  m          monitoring teams
overhearing  multi agent plan recognition approach  journal artificial intelligence
research           
kersting  k     de raedt  l          bayesian logic programs  proceedings work inprogress track   th international conference inductive logic programming 
kersting  k   de raedt  l     raiko  t          logical hidden markov models  journal artificial
intelligence research                
kok  s     domingos  p          learning structure markov logic networks  proceedings
  nd international conference machine learning  pp          acm 
kok  s     domingos  p          statistical predicate invention  proceedings   th international conference machine learning  pp          acm 
kok  s     domingos  p          learning markov logic network structure via hypergraph lifting 
proceedings   th annual international conference machine learning  pp         
acm 
kok  s     domingos  p          statistical predicate invention  icml     proceedings
  th international conference machine learning  pp          new york  ny  usa 
acm 
koller  d          probabilistic relational models  inductive logic programming  pp      
springer 
lafferty  j          conditional random fields  probabilistic models segmenting labeling
sequence data  international conference machine learning  icml   pp         
morgan kaufmann 
landwehr  n   gutmann  b   thon  i   philipose  m     de raedt  l          relational
transformation based tagging human activity recognition  proceedings  th international workshop multi relational data mining  mrdm     pp       
liao  l   patterson  d   fox  d     kautz  h          learning inferring transportation routines 
artificial intelligence                   
liao  l   fox  d     kautz  h          learning inferring transportation routines  proceedings nineteenth national conference artificial intelligence 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

liao  l   fox  d     kautz  h          location based activity recognition using relational markov
networks  ijcai 
limketkai  b   fox  d     liao  l          crf filters  discriminative particle filters sequential
state estimation  robotics automation       ieee international conference on  pp 
         
ling  x     weld  d          temporal information extraction  proceedings twenty fifth
national conference artificial intelligence 
ma  z          modelling prism intelligent system  msc  thesis  linacre college  university oxford 
manfredotti  c          modeling inference relational dynamic bayesian networks 
advances artificial intelligence  pp          springer 
manfredotti  c     messina  e          relational dynamic bayesian networks improve multitarget tracking  advanced concepts intelligent vision systems  pp          springer 
manfredotti  c   hamilton  h     zilles  s          learning rdbns activity recognition 
neural information processing systems 
mihalkova  l     mooney  r          bottom up learning markov logic network structure 
proceedings   th international conference machine learning  pp          acm 
moore  d     essa  i          recognizing multitasked activities using stochastic context free grammar  proceedings aaai conference 
muggleton  s          learning structure parameters stochastic logic programs  proceedings   th international conference inductive logic programming  pp         
springer verlag 
murphy  k  p          dynamic bayesian networks  representation  inference learning  ph d 
thesis  university california  berkeley 
naaman  m   boase  j     lai  c  h          really me   message content social
awareness streams  cscw     proceedings      acm conference computer
supported cooperative work  pp          new york  ny  usa  acm 
natarajan  s   tadepalli  p   altendorf  e   dietterich  t   fern  a     restificar  a          learning
first order probabilistic models combining rules  proceedings   nd international conference machine learning  pp          acm 
natarajan  s   bui  h  h   tadepalli  p   kersting  k     wong  w          logical hierarchical
hidden markov models modeling user activities  proc  ilp    
papai  t   singla  p     kautz  h          constraint propagation efficient inference markov
logic  seventeenth international conference principles practice constraint
programming 
pentland  a  s          honest signals  shape world  mit press 
poon  h     domingos  p          sound efficient inference probabilistic deterministic
dependencies  proceedings national conference artificial intelligence  vol     
p       menlo park  ca  cambridge  ma  london  aaai press  mit press       

   

fis adilek   k autz

poon  h     domingos  p          joint inference information extraction  proceedings
  nd national conference artificial intelligence volume    pp          aaai press 
poon  h     domingos  p          joint unsupervised coreference resolution markov logic 
proceedings conference empirical methods natural language processing  pp 
        association computational linguistics 
riedel  s          improving accuracy efficiency map inference markov logic 
proceedings proceedings twenty fourth conference annual conference uncertainty artificial intelligence  uai      pp          corvallis  oregon  auai press 
sadilek  a     kautz  h       a   modeling reasoning success  failure  intent
multi agent activities  mobile context awareness workshop  twelfth acm international
conference ubiquitous computing 
sadilek  a     kautz  h       b   recognizing multi agent activities gps data  twentyfourth aaai conference artificial intelligence 
sadilek  a   kautz  h     bigham  j  p          finding friends following
are  fifth acm international conference web search data mining  wsdm  
sato  t     kameya  y          parameter learning logic programs symbolic statistical modeling  journal artificial intelligence research 
sato  t     kameya  y          new advances logic based probabilistic modeling prism 
probabilistic inductive logic programming  pp          springer 
shakarian  p   subrahmanian  v     spaino  m  l          scare  case study baghdad 
proceedings third international conference computational cultural dynamics 
aaai 
shen  j          activity recognition desktop environments  ph d  thesis  oregon state university 
shoenfield  j  r          mathematical logic  addison wesley 
singla  p     domingos  p          discriminative training markov logic networks  proceedings national conference artificial intelligence  vol      p       menlo park  ca 
cambridge  ma  london  aaai press  mit press       
singla  p     domingos  p          markov logic infinite domains  uai    
tang  k   lin  j   hong  j   siewiorek  d     sadeh  n          rethinking location sharing  exploring implications social driven vs  purpose driven location sharing  proceedings
  th acm international conference ubiquitous computing  pp        acm 
tran  s     davis  l          visual event modeling recognition using markov logic networks 
proceedings   th european conference computer vision 
ullman  t   baker  c   macindoe  o   evans  o   goodman  n     tenenbaum  j          help
hinder  bayesian models social goal inference  advances neural information
processing systems  nips   vol     
vail  d          conditional random fields activity recognition  ph d  thesis  carnegie mellon
university 

   

fil ocation  based r easoning c omplex ulti  agent b ehavior

vail  d     veloso  m          feature selection activity recognition multi robot domains 
proceedings aaai  vol       
wang  j     domingos  p          hybrid markov logic networks  proceedings   rd
national conference artificial intelligence   volume    pp            aaai press 
wellner  b   mccallum  a   peng  f     hay  m          integrated  conditional model information extraction coreference application citation matching  proceedings
  th conference uncertainty artificial intelligence  pp          auai press 
wilson  a   fern  a   ray  s     tadepalli  p          learning transferring roles multi agent
mdps  proceedings aaai 
wilson  a   fern  a     tadepalli  p          bayesian role discovery multi agent reinforcement learning  proceedings  th international conference autonomous agents
multiagent systems  volume   volume    pp            international foundation
autonomous agents multiagent systems 
wrobel  s          first order theory refinement  advances inductive logic programming  pp 
      ios press  amsterdam 
wu  t   lian  c     hsu  j          joint recognition multiple concurrent activities using factorial
conditional random fields  proc    nd conf  artificial intelligence  aaai       
yoshikawa  k   riedel  s   asahara  m     matsumoto  y          jointly identifying temporal relations markov logic  proceedings joint conference   th annual meeting
acl  th international joint conference natural language processing
afnlp  volume   volume    pp          association computational linguistics 

   


