journal of artificial intelligence research               

submitted        published      

learning and reasoning with action related places
for robust mobile manipulation
freek stulp

stulp clmc usc edu

computational learning and motor control lab
university of southern california
     s  mcclintock avenue  los angeles  ca        usa

andreas fedrizzi
lorenz mosenlechner
michael beetz

fedrizza cs tum edu
moesenle cs tum edu
beetz cs tum edu

intelligent autonomous systems group
technische universitat munchen
boltzmannstrae    d       garching bei munchen  germany

abstract
we propose the concept of action related place  arplace  as a powerful and flexible representation of task related place in the context of mobile manipulation  arplace
represents robot base locations not as a single position  but rather as a collection of positions  each with an associated probability that the manipulation action will succeed when
located there  arplaces are generated using a predictive model that is acquired through
experience based learning  and take into account the uncertainty the robot has about its
own location and the location of the object to be manipulated 
when executing the task  rather than choosing one specific goal position based only
on the initial knowledge about the task context  the robot instantiates an arplace  and
bases its decisions on this arplace  which is updated as new information about the
task becomes available  to show the advantages of this least commitment approach  we
present a transformational planner that reasons about arplaces in order to optimize
symbolic plans  our empirical evaluation demonstrates that using arplaces leads to
more robust and efficient mobile manipulation in the face of state estimation uncertainty
on our simulated robot 

   introduction
recent advances in the design of robot hardware and software are enabling robots to solve
increasingly complex everyday tasks  when performing such tasks  a robot must continually decide on its course of action  where a decision is a commitment to a plan or an
action parameterization based on evidence and the expected costs and benefits associated
with the outcome   resulaj  kiani  wolpert    shadlen         this definition highlights
the complexity of decision making  it involves choosing the appropriate action and action
parameterization  such that costs are minimized and benefits are maximized  the robot
must therefore be able to predict which costs and benefits will arise when executing an
action  furthermore  due to stochasticity and hidden state  the exact outcome of an action
is not known in advance  the robot must therefore reason about expected outcomes  and be
able to predict the probability of different outcomes for a given action and action paramec
    
ai access foundation  all rights reserved 

fistulp  fedrizzi  mosenlechner    beetz

terization  finally  a robot commits to decisions based on the current observable evidence 
represented in its belief state  so if the evidence changes  the rationale for committing to
a decision may no longer be valid  the robot therefore needs methods to efficiently reconsider decisions as the belief state changes during action execution  and possibly commit to
another plan if necessary 
mobile manipulation is a good case in point  even the most basic mobile manipulation
tasks  such as picking up an object from a table  require complex decision making  to pick
up an object the robot must decide where to stand in order to pick up the object  which
hand s  to use  how to reach for it  which grasp type to apply  where to grasp  how much
grasp force to apply  how to lift the object  how much force to apply to lift it  where to
hold the object  and how to hold it  such decision problems are complex as they depend on
the specific task context  which consists of many task relevant parameters  furthermore 
these decisions must be continually updated and verified  as the task context  or the robots
knowledge about the context  often changes during task execution 
consequently  tasks of such complexity require not only robust hardware and low level
controllers  but also a least commitment approach to making decisions  abstract planning
capabilities  probabilistic representations  and principled ways of updating beliefs during
task execution  in this article  we demonstrate how implementing these core ai topics
contributes to the robustness and flexibility of our mobile manipulation platform 
the task relevant decision we consider in this article is to which base position the robot
should navigate to in order to perform a manipulation action  this decision alone presents
several challenges  such as    successfully executing the reaching and manipulation action
critically depends on the position of the base     due to imperfect state estimation  there is
uncertainty in the position of the robot and the target object  as these positions are not
known exactly  but are fundamental to successfully grasping the object  it is not possible to
determine a single best base position for manipulation     the complete knowledge required
to determine an appropriate base position is often not available initially  but rather acquired
on line during task execution 
our solution idea to address these challenges is the concept of action related places
 arplace   a powerful and flexible representation of task related place in the context of
mobile manipulation  arplace is represented as a probability mapping  which specifies the
expected probability that the target object will be successfully grasped  given the positions
of the target object and the robot

arplace     p  success fkrob   hf obj   obj i   k
k  

   

here  the estimated position of the target object is represented as a multi variate gaussian
distribution with mean f obj and covariance matrix obj     the discrete set of robot positions
 fkrob  k
k   should be thought of as possible base positions the robot considers for grasping 
i e  potential positions to navigate to  typically  this set of positions is arranged in a grid 
as in the exemplary arplace depicted in figure   
   the feature vectors f rob and f obj contain the poses of the robot and the object relative to the tables
edge  details will be given in section      positions without uncertainty are denoted f   and estimated
positions with uncertainty as hf   i 

 

filearning and reasoning with action related places for robust mobile manipulation

figure    arplace  the probability of successful manipulation  given the current estiobj
rob k
  obj
mated object position hfcur
cur i  the set of potential robot positions  fk  k  
are arranged in a grid along the x and y axis  whereby each position leads to
obj
  obj
a different probability of successful grasping p  success fkrob   hfcur
cur i   the
black isolines represent grasp success probability levels of     and     

arplace has three important properties     it models base places not as a single
position f rob   but rather as a set of positions  fkrob  k
k     each with a different expectation
of the success of the manipulation action     it depends upon the estimated target object
position  so updating f obj or obj during task execution thus leads to different probabilities
in arplace     using a probabilistic representation that takes into account uncertainty in
the target object position leads to more robust grasping 
    example scenario
in figure    we present an example scenario that demonstrates how these properties
of arplace address the challenges stated above  and supports decision making during
mobile manipulation  the images in the top row show the current situation of the robot
from an outside view  while the images in the lower visualize the robots internal arplace
representation  the arplace is visualized with the colors red  white and green  which
represent low  medium and high grasp success probabilities respectively  grasp success
probability levels of     and     are depicted as isolines  as in figure   
in this scenario the robots task is to clean the table  in scene   the robot enters the
kitchen and its vision system detects a cup  because the robot is far away from the cup 
the uncertainty arising from the vision based pose estimation of the cup is high  indicated
by the large circle around the cup in the lower left image  as the exact position of the cup
is not known  it is not possible to determine a single best base position for grasping the
cup  the arplace representation takes this uncertainty into account by modeling the
base position as a probability mapping 
 

fistulp  fedrizzi  mosenlechner    beetz

scene  

scene  

scene  

scene  

figure    example scenario 
in scene   the arplace distribution has low probabilities overall  with a maximum
probability of grasp success of only       note that although the initial uncertainty in the
cups position precludes the robot from determining a specific base position from which to
reliably grasp the cup  the robot does know the general area to which it should navigate 
during navigation  the robot is able to determine the position of the cup more accurately 
as depicted in scene    as new sensor data comes in  the robot refines the arplace and
therefore the arplace in scene   has much higher probabilities overall  with a maximum
of      
in scene   the robot has detected a second cup  because grasping both cups at once
from a single position is much more efficient than approaching two locations  the robot
merges the two arplaces for each cup into one arplace representing the probability
of successfully grasping both cups from a single position    in scene   further measurements
helped to reduce pose estimation uncertainties of both cups  the maximum grasp success
probability in the arplace now reaches       sufficient for the robot to commit itself to
a goal position and attempt to grasp both cups at once 
this scenario illustrates that real world tasks can often not be planned from start to
finish  as the initial knowledge is often not complete or accurate enough to determine
an optimal goal position  so rather than committing to a particular base position early
based only on the robots initial knowledge about the task context  a robot instantiates
an arplace for a particular task context  and bases its decisions on this arplace 
having the place concept instantiation represented explicitly during the course of action
enables the robot to reconsider and reevaluate these decisions on line whenever new
information about the task context comes in  for instance  the decision to grasp both
cups from one position in scene   would not have been possible if the robot would have
committed itself to a plan given its initial knowledge when only one cup was detected  even
if the environment is completely observable  dynamic properties can make a pre planned
optimal position suboptimal or unaccessible  a least commitment implementation  where
   section       explains how arplaces are merged to compute an arplace for joint tasks 

 

filearning and reasoning with action related places for robust mobile manipulation

decisions are delayed until they must be taken is more flexible  and leads to more robust
and efficient mobile manipulation  this will be demonstrated in the empirical evaluation 
    contributions  system overview and outline
the system overview for learning  computing  and reasoning with arplaces is depicted
in figure    it also serves as an outline for the rest of this article 

figure    system overview  numbers refer to sections in this article  green ovals represent
algorithms and procedures  and blue rectangles the models that result from them 
procedures and models are briefly described in the contributions in this section 
more detail is given throughout the article  yellow rectangles cluster conceptually
related procedures  and also delineate the different sections of this article 

the main contributions of this article are 
representing arplace  section    we propose arplace as a flexible representation
of place for least commitment decision making in mobile manipulation 
model learning  section    to generate an arplace  the robot must be able to
predict the outcome of an action for a given action parameterization  we propose
a generic  off line learning approach to acquiring a compact prediction model in two
steps     learn to predict whether an action will succeed for a given task parameterization  this is a supervised classification problem which we implement with support
vector machines  sonnenburg  raetsch  schaefer    schoelkopf            generalize
over several task parameterizations by generalizing over the learned svm classifiers 
 

fistulp  fedrizzi  mosenlechner    beetz

which we implement with point distribution models  cootes  taylor  cooper    graham         the resulting success prediction model enables the robot to predict
whether a manipulation action for a given object position will succeed from a given
base position    
generating arplace section    we demonstrate how arplaces are generated online  and take object position uncertainty into account through a monte carlo simulation  furthermore  the arplace is conditioned on robot position uncertainty  which
is thus also taken into account 
reasoning with arplace section    we show how arplace is integrated in a symbolic transformational planner  to automate decision making with arplaces  in
particular  we consider a scenario that shows how arplaces can be merged for joint
manipulation tasks 
empirical evaluation  section    we demonstrate how reasoning with arplaces
leads to more robust and efficient behavior on a simulated mobile manipulation platform 
before turning to these contributions  we first compare our approach to related work in
section   

   related work
most state of the art mobile manipulation platforms use sampling based motion planners
to solve manipulation problems  lavalle         some of the advantages of using symbolic
planning in general  and with arplaces in particular  are     abstraction  representing and planning with abstract symbolic actions reduces the complexity of the planning
problem  although computational power is ever increasing  it is still intractable to solve
extended tasks  such as preparing a meal  beetz et al          with state space search alone 
   least commitment  friedman and weld        show that setting open conditions to
abstract actions and later refining this choice to a particular concrete action can lead to exponential savings  note that this principle has also be used to reduce the number of collision
checks for building probabilistic roadmaps  bohlin   kavraki            modular replanning  in symbolic planning  causal links between the actions are explicitly represented  that
the robot navigates to the table in order to perform a grasping motion is not represented in
a plan generated by a sampling based motion planner  therefore  during execution  motion
planners cannot reconsider the appropriate base position as a decision in its own right  but
must rather inefficiently replan the entire trajectory if the belief state changes     reflection  the explicit symbolic representation of causality also allows a robot to reason about
and reflect its own plans and monitor their execution  for instance to report reasons for
   by using experience based learning  our approach can be applied to a variety of robots and environments 
once a model has been learned however  it is obviously specific to the environment in which the experience
was generated  for instance  if only one table height is considered during data collection  the learned
prediction model will be specific to that table height  if different table heights are used during experience
collection  and the table height is included as a task relevant parameter  the model should be able to
generalize over table heights as well  we refer to section     for a full discussion 

 

filearning and reasoning with action related places for robust mobile manipulation

plan failure  i could not find the cup  or i could not determine the position of the cup
with sufficient accuracy to robustly perform the grasp  or an obstacle was blocking my
path   it is not obvious how to achieve such introspection with motion planning methods 
also  in contrast to sampling based motion planning  an arplace itself does not generate trajectories or motion itself  but is rather a representation that supports decisions  such
as the decision where the robot should move to in order to manipulate  this goal position
can then be given to a motion planner in order to find a trajectory that gets the robot to
the goal position  in our system for instance  the navigation trajectory is determined by
a wavefront planner  also  an arplace is not a reinforcement learning policy  sutton
  barto         a policy maps states to actions  whereas an arplace maps  uncertain 
states to expected probabilities of successfully executing a certain action  arplaces are
thus models of actions  and not executable actions in their own right  this distinction will
become most apparent in section    in which arplaces are used by a transformational
planner to detect and repair performance flaws in symbolic plans 
from this perspective  most similar to our work are asymov  cambon  gravot   
alami        and rl tops  ryan         in that they use symbolic planners to generate
sequences of motion plans reinforcement learning policies respectively  the specific contributions of this article are to enable the robot to learn grounded  probabilistic models of
actions to support symbolic decision making  as well as using more flexible transformational
planners that reason with these models  our focus is thus more on grounding and improving
the representations that enable symbolic planning  rather than the underlying actions that
generate trajectories and or the actual motion 
okada  kojima  sagawa  ichino  sato  and inaba        also develop representations for
place to enable symbolic planning  and they denote a good base placement for grasping a
spot  different spots are hand coded for different tasks  such as manipulating a faucet 
a cupboard  and a trashcan  these symbolic representations of place are then used by a
lisp based motion planner to perform tool manipulation behavior  arplace extends the
concept of a spot by learning it autonomously  grounding it in observed behavior  and
providing a probabilistic representation of place  berenson  choset  and kuffner       
address the issue of finding optimal start and goal configurations for manipulating objects
in pick and place operations  they explicitly take the placement of the mobile base into
account  as they are interested in the optimal start and goal configurations  instead of
a probabilistic representation  this approach does not enable least commitment planning 
diankov  ratliff  ferguson  srinivasa  and kuffner        use a model of the reachable
workspace of the robot arm to decide where the robot may stand to grasp an object and to
focus the search  however  uncertainties in the robots base position or the objects position
are not considered  and thus cannot be compensated for  more recent work by berenson 
srinivasa  and kuffner        addresses these issues  but still relies on an accurate model
of the environment  and at a high computational cost  on the other hand  arplace is a
compact representation that is computed with negligible computational load  allowing for
continuous updating 
recently  similar methods to the ones presented in this article have been used to determine successful grasps  rather than base positions for grasping  for instance  detry et al 
       determine a probability density function that represents the graspability of specific
objects  this function is learned from samples of successful robot grasps  which are biased
 

fistulp  fedrizzi  mosenlechner    beetz

by observed human grasps  however  this approach does not take examples of failed grasps
into account  as we shall see in section    the distance between a failed and a successful
grasp can be quite small  and can only be determined by taking failed grasps into account 
our classification boundaries in section     are similar to workspace goal regions  except
that our boundaries refer to base positions  whereas workspace goal regions refer to grasp
positions  berenson  srinivasa  ferguson  romea    kuffner         also  we generalize over
these boundaries with a point distribution model  and use it to generate a probabilistic
concept of successful grasp positions 
kuipers  beeson  modayil  and provost        present a bootstrapping approach that
enables robots to develop high level ontologies from low level sensor data including distinctive states  places  objects  and actions  these high level states are used to choose
trajectory following control laws to move from one distinctive state to another  our approach is exactly the other way around  given the manipulation and navigation skills of the
robot  which are far too high dimensional to learn with trajectory following control laws  
learn places from which these skills  e g  grasping  can be executed successfully  our focus
is on action and affordance  not recognition and localization  for us  place means a cluster
of locations from which i can execute my  grasping  skill successfully  whereas for kuipers
et al  it refers to a location that is perceptually distinct from others  and can therefore be
well recognized  furthermore  their work has not yet considered the physical manipulation
of objects  and how this relates to place 
learning success models can be considered as probabilistic pre condition learning  most
research in this field until now far focussed on learning symbolic predicates from symbolic
examples  clement  durfee    barrett        chang   amir        amir   chang        
these approaches have not been applied to robots  because the representations that are
learned are not able to encapsulate the complex conditions that arise from robot dynamics
and action parameterization  in robotics  the focus in pre condition learning is therefore
rather on grounding pre conditions in robot experience  a more realistic domain is considered by zettlemoyer  pasula  and kaelbling         where a simulated gripper stacks objects
in a blocks world  here  the focus is on predicting possible outcomes of the actions in a completely observable  unambiguous description of the current state  our emphasis is rather on
taking state estimation uncertainty into account  dexter learns sequences of manipulation
skills such as searching and then grasping an object  hart  ou  sweeney    grupen        
declarative knowledge such as the length of its arm is learned from experience  learning
success models has also been done in the context of robotic soccer  for instance learning the
success rate of passing  buck   riedmiller         or approaching the ball  stulp   beetz 
       our system extends these approaches by explicitly representing the regions in which
successful instances were observed  and computing a generalized success model for these
regions 
an interesting line of research that shares some paradigms with arplaces  such as
learning the relation between objects and actions or building prediction models  are objectaction complexes  oacs   geib  mourao  petrick  pugeault  steedman  kruger  and
worgotter        and pastor  hoffmann  asfour  and schaal        present oacs that
can be used to integrate high level artificial intelligence planning technology and continuous low level robot control  the work stresses that  for a cognitive agent  objects and
actions are inseparably intertwined and should therefore be paired in a single interface  by
 

filearning and reasoning with action related places for robust mobile manipulation

physically interacting with the world and applying machine learning techniques  oacs allow
the acquisition of high level action representations from low level control representations 
oacs are meant to generalize the principle of affordances  gibson        

   learning a generalized success model for arplace
in this section  we describe the implementation of the off line phase depicted in figure    in
which a generalized success model  gsm  is learned  the goal is to acquire the function g
p  success f rob   f obj  

 

g f rob   f obj           

   

which predicts the chance of a successful manipulation action  given the relative positions
of the robot and the object  which are stored in the feature vectors f rob and f obj respectively 
note that during the off line learning phase  these are known positions  uncertainty in
positions is taken into account in the on line phase  as described in section   
performing mobile manipulation is a complex task that involves many hardware and
software modules  an overview of these modules in our platform is described in appendix a 
this overview demonstrates the large number of modules required to implement a mobile
manipulation platform  many of these modules themselves are the results of years if not
decades of research and development within companies  research groups  and open source
projects  the global behavior of the robot  e g  whether it can grasp a cup from a certain
base position  depends on all of these modules  and the interactions between them  in some
cases  analytic models of certain modules are available  such as a capability map for the
arms workspace  section       however  there is no general way of composing such models
to acquire a global model of the systems behavior during task execution  therefore  we
rather learn this model from observed experience 
however  the component that computes arplaces requires exactly such a global model
to predict under which circumstances a manipulation action will fail or succeed  as attempting a theoretical analysis to model all foreseeable events and uncertainties about the world
is at best tedious and error prone  and at worst infeasible  we therefore use experience based
learning to acquire global models of the behavior  by doing so  the model is grounded in
the observation of actual robot behavior 
the off line learning phase consists of three steps     repeatedly execute the action
sequence and observe the result for n different target object positions     learn n support
vector machines classifiers for n specific cup positions    generalize over these n classifiers
with a point distribution model 
    data acquisition
the robot acquires experience by executing the following action sequence     navigate to
a specified base position at the table     reach for the cup     close the gripper     lift
the cup  stulp  fedrizzi    beetz      a   in this action sequence  the task context is
determined by the following parameters    the pose to which the robot navigates to       the
   note that the navigation planner is parameterized such that the robot is always directly facing the table 
this is not a limitation of the planner  but rather a constraint that is added to make the behavior of

 

fistulp  fedrizzi  mosenlechner    beetz

pose of the target object on the table  after execution  the robot logs whether the object was
successfully grasped or not  to efficiently acquire sufficient data  we perform the training
experiments in the gazebo simulator  gerkey  vaughan    howard         the robot is
modeled accurately  and thus the simulator provides training data that is also valid for the
real robot  examples of a failed and successful grasp are depicted in figure   

figure    two experiment runs with different samples for the robot position  the navigatereach grasp sequence in the upper row succeeds  but fails in the lower sequence 

the vector field controller we use to perform the reaching movement has proven to be
robust in a wide range of the robots workspace  beetz et al          it also has a very
low computational load  is easy to debug  and can quickly be adapted to novel objects 
a disadvantage is that it occasionally gets stuck in local minima  after which the motion
must be restarted  our probabilistic motion planner for the arm does not suffer from local
minima  but plan generation fails at the border of the workspace  even though the vector
field controller is able to grasp there  every planner and controller has its advantages and
disadvantages  and there will always be sources of failure in the real world  especially for
complex embodied agents  this article aims at modelling those failures through experiencebased learning  and basing decisions on these models 
the feature space in which the data is collected is depicted in figure    this coordinate
system is relative to the tables edge  and the position of the cup on the table  this
will enable us to apply the model that is learned from the data to different tables at
different locations in the kitchen  in contrast to our previous work  stulp  fedrizzi   
beetz      b   from now on  we will refer to f obj    xobj  obj   as the observable taskrelevant parameters  which the robot observes but cannot influence directly  here xobj
is the distance of the object to the table edge  and  obj is the angle between the object
orientation and the normal that goes through the table edge and the object  as depicted in
the physical robot more predictable  this makes the robot more safe  which is required to operate the
robot in human environments  cf  figure      in principle  the methods in this paper could take this
orientation into account 

  

filearning and reasoning with action related places for robust mobile manipulation

figure    f rob    xrob y rob   are the controllable action parameters  because the robot can
use its navigation system to change them 

figure    relative feature space used in the rest of this paper 
the robot gathers data for    target object poses  as depicted in figure    the target
object poses are listed in the matrix fobj   for a given target object position  we determine
a rectangular area which is our generous estimation of the upper bound from which the
robot can grasp the object  this rectangle is the same for all    object poses  within
this rectangle a uniform grid of almost     positions  which are stored in the matrix frob  
is defined  figure   depicts the results of data gathering for these positions  here  the
markers represent the position of the robot base at the table  there are three types of
markers  which represent the following classes 
      theoretically unreachable  light round markers 
the cup cannot be grasped from many of the positions in the bounding rectangle simply
because the arm is not long enough  more formally  for these base positions  the kinematics
of the arm are such that no inverse kinematic solution exists for having the end effector
at the position required to grasp the target object  we exploit analytic models of arm
kinematics to filter out base positions in the bounding rectangle from which the cup is theoretically unreachable  the analytic model we use is a capability map  which is a compiled
representation of the robots kinematic workspace  zacharias  borst    hirzinger        
capability maps are usually used to answer the question  given the position of my base 
which positions can i reach with my end effector  in this article  we use the capability map
to answer the inverse question  given the position of the target object  and therefore the
desired position of my end effector   from which base positions can i reach this end effector
position  in figure    the answer to this question is visualized for a specific target object
position  the depicted area is a theoretical kinematic upper bound on the base positions
from which the robot can reach the target 
for each example base position in the bounding box  we use the capability map to
determine if the target object is theoretically reachable  if not  the corresponding base
position is labeled as a failure without executing the navigate reach grasp action sequence 
this saves time when gathering data  another obvious theoretical bound we implemented
was that the robots distance to the table should be at least as big as the robots radius 
otherwise the robot would bump into the table  again  we labeled such base positions as
failures without executing them in order to save time 
  

fistulp  fedrizzi  mosenlechner    beetz

figure    results of data acquisition for    target object poses  listed in the matrix fobj  
markers correspond to the center of the robot base  green squares and red
circles represent successful and failed grasps respectively  bright circles were not
executed as a successful grasp is deemed theoretically impossible by capability
maps  the dark green hulls are the classification boundaries  section      

      practically unreachable  red filled round markers 
the capability map only considers the theoretical reachability of a position  given the kinematics of the robots arm  it does not take self collisions into account  or the constraints
imposed by our vector field controller for reaching  or the specific hardware of our gripper 
and the way the gripper interacts with the target object  red markers in figure   represent
base positions that the capability map deems possible  but that lead to a failure while performing the reaching motion  some causes for failure are     bumping into the table due to
imprecision in the navigation routine    bumping into the cup before grasping it     closing
the gripper without the cup handle being in it     the cup slipping from the gripper    the
vector field controller getting caught in a local minimum 
one aim of this article is to demonstrate how such practical problems  that arise from
the interaction of many hard  and software modules  are properly addressed by experiencebased learning  our approach is to use analytic models when they are available  but use
experience based learning when necessary  by interacting with the world  the robot observes
  

filearning and reasoning with action related places for robust mobile manipulation

figure    inverse capability map for the right arm for a specific object position 
its global behavior  and learns the difference between what is possible in theory and what
works in practice 
      reachable  green square markers 
these are base positions from which the robot was able to successfully grasp the cup  the
task execution is deemed successful when the cup is more than   cm above the table when
the action sequence is completed  because this can only be the case if the robot is holding
it  we prefer such an empirical measure over for instance a force closure measure  as the
latter requires accurate models of the object  which we do not always have  furthermore 
it has been argued on theoretical grounds  zheng   qian         as well as demonstrated
empirically  morales  chinellato  fagg    del pobil         that force closure grasps may
not always lead to successful grasps in practice  of course  force closure may just as well
be used as a measure of successful grasping  the methods described in this article do not
depend upon this design choice 
the data acquisition yields a set of discrete robot and object positions  associated with
the resulting outcome of the manipulation action  being a success or a failure 
obj n
p  success  f rob  m
 j       bi j   with bi j        
i      f

   

in this article  the number of sampled object positions n              i e  the number
of graphs in figure     and the number of sampled robot positions m                 i e 
the number of data points per graph in figure    
in the remainder of this section  we first generalize over the m discrete robot positions
by training support vector machines  section       and then generalize over the n cup
positions with point distribution models  section     
    generalization over robot positions
in this step  we generalize over the discrete robot positions  and acquire a compact boolean
classifier that efficiently predicts whether manipulation will succeed 
  

fistulp  fedrizzi  mosenlechner    beetz

p  success f rob    f obj  n
j    

 

gj     n  f rob           

   

this generalization is implemented as follows  a separate classifier gi     n is learned for
each of the n      object poses  i e  one classifier for each of the    data sets depicted in
figure    to acquire these prediction models  we compute a classification boundary around
the successful samples with support vector machines  svm   using the implementation
by sonnenburg et al          with a gaussian kernel with      and cost parameter c      
as successful grasps are rarer  we weight them twice as much as failed grasp attempts 
figure   depicts the resulting classification boundaries for different configurations of taskrelevant parameters as dark green boundaries  manipulation is predicted to succeed if the
robots base position lies within a boundary for a given target object pose  fobj   the
accuracy of these learned classifiers is listed in section     
    generalization over object positions
in the next step  we generalize over the discrete object positions 
p  success f rob   f obj  

 

g f rob   f obj           

   

we do so by determining a low dimensional set of parameters that allows us to interpolate
between the individual classification boundaries that the support vector machines generate  this is done with a point distribution model  pdm   which is an established method
for modelling variations in medical images and faces  cootes et al         wimmer  stulp 
pietzsch    radig         the result is one compact model that incorporates the individual boundaries  and is able to interpolate to make predictions for target object poses not
observed during training 
as input a pdm requires n points that are distributed over a contour  how these
landmarks are distributed is described in appendix b  given the landmarks on the classification boundaries  we compute a pdm  although pdms are most well known for their
use in computer vision  cootes et al         wimmer et al          we use the notation
by roduit  martinoli  and jacot         who focus on robotic applications  first  the   
boundaries of     d points are merged into one   x   matrix h  where the columns are the
concatenation of the xrob and y rob coordinates of the    landmarks along the classification boundary  each column thus represents one boundary  the next step is to compute
p  which is the matrix of eigenvectors of the covariance matrix of h  p represents the
principal modes of variation  given h and p  we can decompose each boundary h      in
the set into the mean boundary and a linear combination of the columns of p as follows
hk   h   p  bk   here  bk is the so called deformation mode of the k th boundary  this
is the point distribution model  to get an intuition for what the pdm represents  the
first three deformation modes are depicted in figure    where the values of the first  second
and third deformation modes  columns         of b  are varied between their maximal and
minimal value  whilst the other deformation modes are set to   
the eigenvalues of the covariance matrix of h indicate that the first   components already contain     of the deformation energy  for reasons of compactness and to achieve
  

filearning and reasoning with action related places for robust mobile manipulation

figure    the first   deformation modes of the point distribution model  in b  

better generalization  we use only the first   deformation modes  without losing much accuracy 

 fjobj   gj  f rob     inboundary f rob   hj   n
j  
 fjobj   gj  f rob     inboundary f rob   h   p  bj   n
j  
g f

rob

 f

obj

    inboundary f

rob

  h   p  b f

obj

  

n support vector machines

   

point distribution model

   

regression between

fjobj

and bj

   

the pdm has several advantages     instead of having to store n      classification
boundaries hj with each     d points to capture the variation in classification hulls due to
different target object positions  we only store n      deformation modes with   degrees of
freedom each  this greatly reduces the dimensionality     the   degrees of freedom in b can
be used to interpolate in a principled way between the computed classification boundaries
hj   to generate boundaries for object positions that were not observed during learning     a
simple regression between the two degrees of freedom of the pdm b and the position f obj is
feasible  so that the object position can be related directly to the shape of the classification
boundary  this regression is explained in the next section 
    relation to task relevant parameters
in this step  we acquire a function b  that computes the appropriate deformation modes b
for a given object position f obj   to do so  we compute a regression between the matrix of
deformation modes of the specific object positions b  and the    object positions themselves
in fobj   as depicted in figure    we found that a simple second order polynomial regression
model suffices to compute the regression  as it yields high coefficients of determination of
r         and r         for the first and second deformation modes respectively  the
coefficients of the polynomial model are stored in two  x  upper triangular matrices w 
and w    such that b    diag  t     w    fobj   t   diag  t     w    t   t  
the generalized success model now consists of    h  the mean of the classification
boundaries computed with the svm     p  the principal modes of variation of these clas  

fistulp  fedrizzi  mosenlechner    beetz

sification boundaries     w      the mapping from task relevant parameters to deformation
modes 
let us now summarize how the generalized success model is used to predict successful
manipulation behavior 
   the generalized success model takes the  observed  relative position of the object on
obj
obj
the table fcur
   xobj
cur cur   as input  figure    
   the appropriate deformation values for the given object position are computed with
obj
obj
obj
bcur   b fcur
      q  w   qt q  w   qt    where q    fcur
      xobj
cur cur   
 section      
   the boundary is computed with hcur   h   p  bcur  section      
   if the relative robot base center f rob    xrob y rob   is within boundary hcur   the
model predicts that the robot will be able to successfully grasp the object at position
obj
obj
   xobj
fcur
cur cur   
note that these steps only involve simple multiplications and additions of small matrices 
and thus can be performed very efficiently    the reason for this efficiency lies in the fact that
we directly relate task relevant parameters  such as the position of the cup on the table  to
predictions about the global behavior of the robot  such as whether the manipulation action
will succeed or not  the on line efficiency is made possible by experience based learning 
where the wealth of information in the observation of global behavior is compiled into a
compact model off line  this approach adheres to the proposed strategy of learning taskrelevant features that map to actions  instead of attempting to reconstruct a detailed model
of the world with which to plan actions  kemp  edsinger    torres jara        
in summary  from observed behavior outcomes  we have learned the mapping in equation    which we repeat in equation     which maps continuous robot and target object
positions to a boolean prediction about the success of an action 
p  success f rob   f obj     g f rob   f obj           

   

this mapping can be used to predict if the current base position of the robot will lead to
successful manipulation  but also to determine appropriate base positions to navigate to 
equation   assumes that the true values of the robot and target object positions are
known to the robot  in section    we discuss how uncertainties in the estimates of these
positions is taken into account during task execution 
    generality of generalized success model
before explaining how the generalized success model is used to generate arplaces online during task execution in section    we discuss some of the generalization properties
and limitations of the generalized success model  to do so  we must distinguish between
   as an indication  with the model that is described in this paper all four steps take    ms on a    ghz
machine in our matlab implementation 

  

filearning and reasoning with action related places for robust mobile manipulation

the general applicability of our approach to different robots  objects and domains  and the
specificity of the model to these factors once it has been learned  this essentially holds for
any data driven approach  the model can in principle be learned for any data  independent
of the robot system that generates these data  but once learned  will be specific to the
data generated by that robot system  and thus specific to the robot system itself  for all
practical purposes  we assume that the domain and robot hardware remain fixed  so learning
a domain  and robot specific model is not a grave limitation 
      generalization over object poses
the learned model generalizes over different object poses  as the relative object pose on the
table f obj    xobj  obj   is part of the feature space with which the generalized success
model is parameterized  see step    in calling a gsm in section       the generalized
actually refers to this capability of generalizing over success models for specific object poses 
      grasp specific arplaces
by being specific to the object  a lot of data would be required to learn an arplace for
each object the robot should manipulate  in practice however  we found that only a few
grasps suffice to grasp most everyday objects in kitchen environments with the real robot
platform  maldonado  klank    beetz         in particular  this approach required only
  grasps  one from the top and one from the side  to achieve    successful grasps out of
   attempts with    everyday kitchen objects  therefore  we propose to use grasp specific
arplaces  rather than object specific arplaces  we have learned generalized success
models for both grasps  which are depicted in figure   

figure    the two point distribution models for the side and top grasp  examples of
objects that can be manipulated with these grasps are depicted 

the two deformation modes for the point distribution model depicted in figure  
already contain     of the deformation energy  which is even more than for the side grasps 
this is because the success of the side grasp is relatively independent of the orientation of
the object  as the robot does not need to reach around the object  this also leads to more
symmetric classification boundaries for the top grasp  as can be seen in figure   
in summary  only two generalized success models must be learned for two different
grasps  as these two grasps suffice to grasp the    everyday kitchen objects that were tested
  

fistulp  fedrizzi  mosenlechner    beetz

with the real robot by maldonado et al          in the rest of this article  we will focus on
the side grasp  arplaces for top grasps are presented by fedrizzi        

   computing action related places
in the previous section  we demonstrated how the generalized success model is learned
from observed experience for a variety of task parameterizations  the resulting function
maps known robot and object positions to a prediction whether the action execution will
succeed or feel 
in this section  we describe how arplaces for manipulation are computed on line
for specific task contexts  as depicted in figure    this module takes the generalized
success model and the estimated robot pose and target object pose as input  and returns
an arplace such as depicted in figure   
    taking object position uncertainty into account
in equation    the prediction whether a manipulation action succeeds or fails is based on
known robot and target object positions  however  during task execution  the robot only
has estimates of these positions  with varying levels of uncertainty  these uncertainties
must be taken into account when predicting the outcome  as a manipulation action that
is predicted to succeed might well fail if the target object is not at the position where the
robot expects it to be  given the generalized success model in equation    the goal of this
section is therefore to compute the mapping

generalized success model

p  succ f

rob

 f

obj

arplace  with object uncertainty 

            monte carlo    p  succ fkrob   hf obj   obj i   k
k           
    

which takes estimates of the target object position  and returns a continuous probability
value  rather than a discrete        probability value as in equation    in our belief state 
the uncertainties in object positions are modelled as a gaussian distribution with mean f obj
and covariance matrix obj  
on the robot platform described in appendix a  f obj and obj are obtained from a
vision based object localization module  klank  zia    beetz         typical values along
 
 
 
the diagonal of the  x  covariance matrix are  x x
        y y
        z z
       
 
 
 
yaw yaw        pitch pitch         roll roll         the uncertainties in position are specified
in meters and the angular uncertainties are specified in radians  the estimation of the object
position is quite accurate  but our vision system has problems to detect the handle  which is
important for estimating the orientation  yaw  of the cup  due to the constraints enforced
by our assumption that the cup is standing upright on the table  the uncertainty in z  pitch
and roll is set to    the remaining  x  covariance matrix is mapped to the relative feature
space  which yields obj  
at the end of section      we demonstrated how a classification boundary hnew is reobj
obj
constructed  given known task relevant parameters fnew
    xobj
new new    because of the
obj
uncertainty in fnew   it does not suffice to compute only one classification boundary given
  

filearning and reasoning with action related places for robust mobile manipulation

the most probable position of the cup as the arplace from which to grasp  this might
lead to a failure if the cup is not at the position where it was expected  therefore  we use
a monte carlo simulation to generate a whole set of classification boundaries  this is done
by taking     samples from the gaussian distribution of the object position  given its mean
position and associated covariance matrix  this yields a matrix of task relevant parameters
obj  obj    the corresponding classification boundaries are computed
fobj
s
s
s            x
for the samples with hs   h   p  b fsobj    from equation    in figure    a      out of
the     boundaries are depicted  these were
the task relevant
parameters
 h
   generated with
i
 obj obj
   obj obj
 
x

    
 
 
 
f obj     xobj obj                 and obj    x x
 
 
      

 obj xobj

 obj  obj

 a  sampled classification boundaries  b  discretized relative sum  c  final distribution  after condi hs         
of the boundaries 
tioning on the robot pose uncertainty 

figure     monte carlo simulation of classification boundaries to compute arplace 
as described in appendix c  y is   by definition  as fgsm is defined relative to the
cups position along the tables edge  that is why the uncertainty in y  described by
    leads to an uncertainty in the origin of f
y y
gsm   therefore  when sampling from the
task relevant parameters  we also sample values of y  and translate fgsm accordingly  uncertainty in y does not influence the shape of the classification boundary through the pdm 
it simply translates the classification boundary along the tables edge  this sampling of
y has actually already been done in figure    a   where yobj yobj         so in fact 
  

 obj obj
   obj obj
   obj obj


x
x
x
y
x

       
 
 
 
 
obj





 
  
 
      
 
y obj xobj
y obj y obj
y obj  obj
 

 obj xobj

 

 obj y obj

 

 

 obj  obj

 

     

after having computed the sampled classification boundaries  we then generate a discrete
grid of       cm cells  which represent the discrete robot positions  fkrob  k
k   in equation   
for each cell  the number of classification boundaries that classify each cell as a success is
counted  we are thus computing a histogram of predicted successful grasps  dividing the
result by the overall number of boundaries yields the probability that grasping the cup will
succeed from this position  the corresponding distribution  which takes the uncertainty of
the cup position into account  is depicted in figure    b  
it is interesting to note the steep decline on the right side of the distribution near the
table  where the probability of a successful grasp drops from     to     in about  cm  this
is intuitive  as the table is located on the right side  and the robot bumps into the table
when moving to the sampled initial position  leading to an unsuccessful navigate reach  

fistulp  fedrizzi  mosenlechner    beetz

grasp sequence  therefore  none of the    boundaries contain the area that is close to the
table  and the variation in p on the right side of the pdm is low  variations in b do not
have a large effect on this boundary  as can be seen in figure    b   when summing over
the sampled boundaries  this leads to a steep decline in success probability 
note that an arplace is not a normalized probability distribution  which sums to    
but rather a probability mapping  in which each element  discrete grid cell  is a probability
distribution itself  thus the sum of probabilities in each grid cell is    i e  p  succ   
p  succ      
    taking robot position uncertainty into account
the robot not only has uncertainty about the position of the target object  but also about its
own position  this uncertainty must also be taken into account in arplace  for instance 
although any position near to the left of the steep incline in figure    b  is predicted to
be successful  they might still fail if the robot is actually more to the right than expected 
therefore  we condition the probabilities in figure    b  on the robot actually being at a
 rob   y
 rob      and acquire the
certain grid cell  xrob   y rob   given its position estimate  x
final arplace mapping as 
arplace prob  mapping  figure    c  
p  success hf rob   rob i  hf obj   obj i   
p  success f rob   hf obj   obj i 

p  f rob  hf rob   rob i 
    

prob  mapping equation     figure    b  

prob  distribution robot uncertainty  gaussian  

in this equation  hf rob   rob i can be interpreted in two ways  first of all  it can represent
the actual estimate of the robots position at the current time  in this case  p  success         
predicts the probability of success when manipulation from the current position  however 
it can also be interpreted as possible goal positions the robot could navigate to in order to
rob   rob i  as we do throughout this paper  in doing so  we
perform the navigation  i e  hfgoal
goal
rob
make the assumption that the future position uncertainty rob
goal at the goal position fgoal is
rob   we believe this is a fair assumption because 
the same as it is currently  i e  rob
goal   
   it is more realistic than assuming rob
goal         as the robot approaches the navigation
rob
goal  it is continually updating    and thus p  success           once it has reached the
rob  
goal  rob
goal will be equivalent to 
    refining arplace on line
in summary  arplaces are computed on line with a learned generalized success model 
given the task relevant parameters of the current task context  which includes uncertainties
   since the navigation planner is parameterized such that the robot always faces the table  cf  section      
we have ignored the orientation of the robot in computing the gsm  note that we therefore also ignore
the uncertainty in this parameter here  and arplaces do not take it into account  we expect that the
improved robustness  evaluated in section      could be further improved by taking  the uncertainty  in
this parameter into account 

  

filearning and reasoning with action related places for robust mobile manipulation

in the poses of the robot and target object  this yields a probability mapping that maps
robot base positions to the probability that grasping the target object will succeed 
learning the generalized success model is a costly step which involves extensive data
collection  and thus is performed off line  once learned  this model is very compact  and
is used to efficiently compute arplaces on line  therefore  arplaces can be updated
as the execution of the task progresses  and can incorporate new knowledge about taskrelevant parameters or changes in the environment  figure    depicts how the arplace
probability mapping is affected as new knowledge about task relevant parameters comes
in  the first row demonstrates how more accurate knowledge about the target objects
position  lower uncertainty  e g  lower xobj xobj   leads to a more focussed arplace
with higher overall probabilities  and a higher mode  the second and third row depict
similar effects when estimates of the target objects position and orientation change  this
figure serves two purposes  it gives the reader a visual intuition of the effects of several taskrelevant parameters on the shape of the arplace  and it demonstrates how the robots
internal arplace representation might change as new  more accurate  information about
the target object pose comes in 
decreasing uncertainty in cup position perpendicular to table edge
xobj  

    

xobj  

    

 obj  

    

    

    

    

decreasing distance of cup to table edge
    

    

    

changing orientation of cup on table
    

    

    

figure     these images demonstrate how varying certain task relevant parameters affects
the shape of the arplace distribution 
the decision whether a certain probability of success suffices to execute the manipulation
action critically depends on the domain and task  failing to grasp a full glass of wine has
   as an indication  it takes on average    ms on a    ghz machine in our matlab implementation to
perform the steps in section     and     

  

fistulp  fedrizzi  mosenlechner    beetz

more grave consequences than failing to grasp a tennis ball  in general  arplace provides
a representation which enables high level planners to make rational decisions about such
scenarios  but does not specify how such decisions should be made  or what the minimal
success probability should be in order to perform the task  in section   we present the use
of arplace in a concrete scenario 
    generality of arplaces
in section      we discussed the generality of learning the generalized success model  and
the specificity of the model with respect to the robot and its skills  once the model has
been learned off line  in this section  we demonstrate the generality and flexibility of the
arplace representation  which is generated on line using the generalized success model 
we also present various ways in which arplaces can be extended  and lay the groundwork for section    which explains how arplaces are used in the context of a high level
transformational planner 
      merging arplaces for multiple actions
arplaces for multiple actions can be composed by intersecting them  assume we have
computed arplaces for two different actions  a  and a     if the success probabilities of
the arplaces is independent  we can compute the arplace for executing both actions
in parallel by multiplying the probabilities of the arplaces for action a  and a   
in the first two graphs of figure    for instance  the arplaces for grasping a cup with
the left and right gripper are depicted  with a piecewise multiplication of the probabilities 
we acquire the merged arplace  depicted in the right graph  the robot can use this
merged arplace to determine with which probability it can use the left and right gripper
to grasp both cups from one base position  fedrizzi  moesenlechner  stulp    beetz        
another similar application is merging the arplaces for two cup positions  grasped with
the same gripper  this arplace represents the probability of being able to grasp a
cup from one position  and placing it on the other position  without moving the base  such
compositions would be impossible if the robot commits itself to specific positions in advance 

figure     left distribution  grasp cup with left gripper  center distribution  grasp cup
with right gripper  right distribution  element wise product of the other two
distributions   grasp both cups with left right gripper from one base position 

  

filearning and reasoning with action related places for robust mobile manipulation

as navigating to only one position to grasp two cups is much more efficient than navigating to two positions  we have implemented this decision as a transformation rule in the
reactive planning language  mcdermott         which is described in detail in section   
      different supporting planes
defining the feature space of the generalized success model relative to the tables edge
allows the robot to compute arplaces for more general table shapes than the one presented so far  this is done by determining an arplace for each of the straight edges of a
table  and computing the union of these individual arplaces  an example is depicted in
figure    

figure     an arplace for a more complex table shape 

      different uncertainty distributions
in this article  the uncertainty in the position of the robot and target objects is modelled
by a multi variate gaussian distribution  this is not because our approach expects such
a distribution  but because this is how our state estimation systems represent uncertainty 
in section      we described how specific target object positions are sampled from this
distribution in a monte carlo simulation  in general  our method applies to any distribution
from which such a sampling can be done  these distributions need not be gaussian  and
might well be multi modal or even non parametric  for a particle filter for instance  each
particle could directly be used as a sample to compute the classification boundaries as in
figure    a  
      applicability to other domains
we demonstrate the generality of arplaces by briefly showing how an arplace is able
to represent a task relevant place for a very different task and domain  approaching the ball
in robotic soccer  this task frequently fails because the robot bumps into the ball before
achieving the desired position at the ball  in figure    a   examples of a successful  s 
and failed  f  attempt are depicted  here  the robot should approach the ball from the
top  our goal is to acquire an arplace that maps the robots position on the field to the
predicted probability that it will successfully approach the ball 
  

fistulp  fedrizzi  mosenlechner    beetz

the procedure for learning an arplace is equivalent to that in the mobile manipulation
domain     gather data and log successful and failed episodes  figure    a       learn classification boundaries and a generalized success model from these data     generate arplaces
for specific task contexts  figure    b    this example demonstrates that the arplace
approach is not limited to mobile manipulation  but generalizes to other actions and domains 

 a  successful and failed
attempts at approaching
the ball 
data taken
from  stulp   beetz 
      

 b  the robots arplace for approaching the ball  green
plateau  high probability that the robot will succeed at approaching the ball at the orientation indicated by the thick
black arrow 

figure     an arplace for the robot soccer domain 
note the two bumps to the left and right of the ball  it is not intuitively clear why the
robot should succeed in approaching the ball from these locations  but not the surrounding
ones  we assume that it depends on the particular morphology of the robot  and the
controller used to approach the ball  both are described by stulp and beetz         one
of the main advantages of using an approach based on learning is that our assumptions
and intuitions do not play a role in acquiring the model  whatever the reason may be 
these successful approaches are obvious in the observed data  figure    a    and hence the
arplace represents them 
      using more general cost functions
in this article  the probability of success is considered the only utility relevant to determining
an appropriate base position  but in principle  arplace is able to represent any kind of
utility or cost  an example of which is given in figure     here  the task of the robot is to
collect one of the two cups on the table  the probabilistic arplaces for the two cups are
depicted in the left graph  given these parameters  the chance of success is      for both of
the cups  so there is no reason to prefer fetching one over the other  however  cup b is much
closer to the robot  and therefore it would be more efficient to collect cup b  this preference
can be expressed with an arplace  first  we compute the distance of the robot to each
  

filearning and reasoning with action related places for robust mobile manipulation

of the grid cells of the probabilistic arplace  as depicted in the center graph  finally 
we merge the probability p and distance d into one cost u  with u       p      d     
this expresses that it takes on average   seconds to reposition the robot for another grasp
attempt in case of a failure  and that the average navigation speed is    m s  this cost
thus expresses the expected time the overall task will take 
as depicted in figure     the mode of the arplace of the cup that is closer to the
robot is now higher  reflecting the fact that we prefer the robot to fetch cups that are closer 
for an in depth discussion of utility based arplaces  and how they affect the behavior of
the robot  we refer to fedrizzi        
probability  p

distance  d

cost  u       p      d    

figure     example of a more general cost based arplace  right   including both the
probability of success  left  and distance to the robot  center   by including the
distance as part of the cost  the mode of the cost based arplace for the closer
cup is higher than for the more distant cup 

   transformational planning with arplace
so far  we have described how arplaces are generated on line by using the learned generalized success model  the ability to predict the  probability of an  outcome of an action
makes arplaces a powerful tool when combined with a high level planning system  in
this section  we demonstrate how arplace is used in the context of a symbolic transformational planner  reasoning about arplace enables the planner to generate more robust
and efficient plans  and demonstrates the flexibility of the least commitment arplace
representation 
in particular  we consider the task of retrieving two cups from a table  one action
sequence that solves this task is  plan a  navigate to a location near cup   pick up cup 
with the left gripper  navigate to a location near cup   pick up cup  with the right gripper 
as depicted in figure     however  if the cups are sufficiently close to each other  as in
figure     right   it is much more efficient to replace the plan above with plan b  navigate
to a location both near cup  and cup   pick up cup  with the left gripper  pick up cup 
with the right gripper  as it saves an entire navigation action 
   this cost is chosen for its simplicity  to illustrate the generality of the arplace representation  more
realistic  complex cost functions can be used 

  

fistulp  fedrizzi  mosenlechner    beetz

figure     improving performance through transformational planning with  merged 
arplace  plan a  navigate to two separate poses for grasping each object 
using arplaces for both objects  plan b  navigate to one pose for grasping
both objects  using the merged arplace 

deciding whether to use two base locations  plan a  or one  plan b  is difficult to solve
in a control program without sacrificing generality  to keep our solution general  we do not
want to write two separate control programs for both options  and choose between them
with an if then else statement  that would mean we have to provide control programs and
choice points for every option a robot has  the space of choices is prohibitively large in
everyday tasks to allow such an approach  instead  we use a transformational planner that
takes our general program  plan a  and  if appropriate  applies generic transformation rules
that change the program locally  to yield plan b   our transformational planner consists
of the following components 
plan projection  a projection mechanism for predicting the outcome of a plan  arplace
is a compact representation of such a projection mechanism  as it is able to predict
the probability of success of an action  given its parameters 
flaw detection  a mechanism for detecting behavior flaws within the predicted plan outcome  flaws are not only errors that hinder the robot from completing the task  but
they may also be performance flaws  such as suboptimal efficiency  using two navigation actions to approach to cups that are close to each other  plan a  is flawed  in
that it is much more efficient to navigate to one position that is close to both cups 
plan transformation  a mechanism to fix the detected flaws by applying transformation
rules to the plan code  for the problem we consider  a local transformation rule is
applied to plan a to yield the more efficient plan b 
in the next sections  we will describe each of these mechanisms in more detail  and
explain how they are implemented to exploit the arplace representation  note that in
this article  we use our transformational planner to exemplify how arplace can be used
in the context of a larger planning system  for more information on our transformational
planning framework  and further examples of behavior flaws and transformation rules  we
refer to the work of mosenlechner and beetz        
  

filearning and reasoning with action related places for robust mobile manipulation

    plan design
to detect flaws and apply transformation rules for their repair  the transformational planner
must be able to reason about the intention of code parts  infer if a goal has been achieved or
not  and deduce what the reason for a possible failure was  to do so  our control programs
are written in rpl  mcdermott         which provides functionality for annotating code
parts to indicate their purpose and make them transparent to the transformational planner 
for the purpose of this article  the most important rpl instructions for semantic annotation
in the context of pick and place tasks are achieve  perceive and at location  a formal
definition of the semantics of these instructions is given by mosenlechner and beetz        
here we describe them informally 
 achieve  expression   if the achieve statement executes successfully  the logical expression which is passed as its argument is asserted as being true  for instance  after a successful
execution of  achieve  entity picked up  cup    the object referenced by the variable  cup
must be in the robots gripper   
 perceive  object   before manipulating objects  the robot must find the objects and
instantiate them in its belief state  after successful execution  the statement  perceive  cup 
asserts that the object referenced by  cup has been found  and a reference to its internal
representation is returned 
 at location  location  expression   manipulation implies the execution of actions at
specific locations  therefore  it must be assured that pick up actions are only executed
when the robot is at a specific location   at location  location      asserts that code within
its context is either executed at the specified location or fails  please note that transformations which affect the location where actions are performed directly modify the  location
parameter of such at location expressions  therefore  at location is the most important
declarative plan expression for optimizing arplaces  to specify locations for at location 
we use so called designators  symbolic descriptions of entities such as locations  objects and
actions  for instance  a designator for the location where to stand for picking up a cup
can be specified as follows   a location  to pick up   the object  type cup     this symbolic
description is then resolved by reasoning mechanisms such as arplaces and prolog and an
actual pose is generated when it is needed  in general  an infinite number of poses provide a
valid solution for such a pose  arplace gives us a way to evaluate their utility and select
the best pose 
the declarative expressions explained above can be combined to form a tree  every
achieve statement can contain several further achieve  perceive and at location statements
as sub plans  an example plan tree is sketched in figure     in this tree  the goal  achieve
 entity at location  object  location   first perceives the object  then picks it up by achieving
entity picked up  which executes the pick up action within an at location block  and puts
the object down by achieving entity put down  which also contains an at location block 
as we shall see in section      behavior flaws are repaired by applying transformation rules
that replace sub trees within the plan tree by new code 

   please note the lisp syntax  where variables are prefixed with a     for example  cup  and predicates
and functions are pure symbols 

  

fistulp  fedrizzi  mosenlechner    beetz

 entity at location  o  l 

 perceive  o 

 achieve  entity put down  o  l  

 achieve  entity picked up  o 
  
 
  
 

    at location  obj l 
 

 at location  obj l 
  
 
  
 

  
 

  
 

figure     an example plan tree created by executing a pick up plan
    plan projection
a central component of a transformational planner is plan projection  which simulates the
behavior of the robot that arises when executing a plan  in our approach  plan projection generates a temporally ordered set of events based on the plan code presented in the
previous section  we use the same gazebo based mechanism for projection that has been
used for generating the training data for learning arplaces  in particular  we use information about collisions  perception events and the locations of objects and the robot 
while executing the plan in simulation  we generate an extensive execution trace that is
then used in our reasoning engine that infers behavior flaws that are then fixed by transformation rules  mosenlechner   beetz         the execution trace contains low level data
representing the position of all objects and the robot  as well as collisions between objects 
the visibility of objects for the robot  and information to reconstruct the state of program
throughout its execution 
arplaces are a very efficient way of performing plan projection  as they predict the
probability of a successful outcome without requiring on line generation of execution traces 
the reason that execution trace sampling is not required on line  is because the task has
already been executed frequently off line during data acquisition  cf  section       the
results of these task executions have been compiled into the arplaces by learning a
gsm  which yields a compact representation of the experience acquired  therefore  this
experience must not be generated anew during plan generation 
    behavior flaws and reasoning about plan execution
plan projection simulates the robot behavior when executing a plan  the second component of a transformational planner is a reasoning engine that finds pre defined flaws in
the projected robot behavior  examples of such flaws are collisions  e g  caused by underparameterized goal locations  or blocked goals  e g  when a chair is standing at a location
the robot wants to navigate to  the examples above are behavior flaws that lead to critical
errors in plan execution  i e  the plan fails   but we also consider behavior that is inefficient
to be flawed  i e  the plan succeeds  but is unnecessarily inefficient   the task we consider
in this paper is an example of such a performance flaw  as performing two navigation actions where only one is required is highly inefficient  behavior flaws are specified using a
  

filearning and reasoning with action related places for robust mobile manipulation

prolog like reasoning engine that is implemented in common lisp  mosenlechner   beetz 
      
the execution trace generated by plan projection is transparently integrated into the
reasoning engine  i e  the execution trace is queried using prolog predicates  the information recorded in the execution trace is valuable information in order to find behavior flaws 
additional information that is used to find behavior flaws is a set of facts that model the semantics of declarative expressions such as achieve or at location and concepts of the world 
for instance that objects are placed on supporting planes  table  cup board        to find
behavior flaws  their prolog specifications are matched against the logical representation of
the execution trace and if solutions are found  the corresponding flaw is present in the plan
and can be fixed 
for instance  the code to match two locations to perform actions that can be merged to
one arplace looks as follows 
listing    flaw definition to match two different pick up tasks 
 
 
 
 
 

  and
  t a s k g o a l   t a s k     a c h i e v e   e n t i t y p i c k e d up   o b j e c t     
  t a s k g o a l   t a s k     a c h i e v e   e n t i t y p i c k e d up   o b j e c t        t h n o t
      t a s k     t a s k       o p t i m i z e d a c t i o n l o c a t i o n   o b j e c t  
  o b j e c t     o p t i m i z e d l o c a t i o n    

the code above first matches two different pick up tasks  the predicate optimizedaction location holds for  optimized location being an arplace from which the two objects
can be picked up  to bind this variable  the predicate is implemented to calculate such an
arplace 
another example for such a flaw definition is failed navigation  i e  if the robot is not
standing at the location it was supposed to drive to 

listing    flaw definition to find locations that were not reached by the robot although it
was told to reach them 
 
 
 
 
 

  and
  t a s k g o a l   t a s k   a c h i e v e   l o c robot   g o a l l o c      
  t a s k s t a t u s   t a s k done   t  
  h o l d s   l o c robot   r o b o t l o c     a t   t    
  not       g o a l l o c   r o b o t l o c      

the code above first matches the code that is navigating the robot to the location  goalloc  then it infers the actual location of the robot when the navigation task terminated
and binds it to the variable  robot loc and finally asserts that the two locations are not
equal  if this prolog expression can be proven against an execution trace  we have found a
flaw indicating an unachieved goal location 
    plan transformations and transformation rules
after a behavior flaw has been detected  the last step of a planner iteration is the application
of a transformation rule to fix the behavior flaw  transformation rules are applied to parts
of the plan tree and cause substantial changes in its structure and the corresponding robot
behavior 
  

fistulp  fedrizzi  mosenlechner    beetz

a transformation rule consists of three parts  the input schema is matched against the
plan part that has to be transformed and binds all required code parts to variables in order
to reassemble them in the output part  the transformation part performs transformations
on the matched parts  and the output plan describes how the new code of the respective
plan part has to be reassembled 
input schema
transformation
output plan
besides the integration of arplace into the robot control program through at location
statements  arplace is also integrated into the reasoning engine of our transformational
planner  using two locations for grasping is considered a performance flaw if one location
would suffice  informally  we investigate the execution trace for the occurrence of two different pick up actions  where one is executed at location l    and the other one is executed
at location l    then we request a location l  to perform both actions and the corresponding success probability  l  is computed by merging the arplace as in figure    
if the probability of success of the merged arplace is sufficiently high  we apply a plan
transformation  and replace locations l  and l  with location l   
the transformation rule for optimizing arplaces is shown in listing    please note
that all variables that have been bound while matching the flaw definition are still bound
and can be used in the transformation rule 
listing    transformation rule for fixing the flaw 
 
 
 
 
 
 
 
 
 
  
  

  d e f t r r u l e f i x unoptimized l o c a t i o n s
  i n p u t schema
    and   t a s k g o a l   l o c a t i o n t a s k  
  atl o c a t i o n     l o c a t i o n        code    
  subt a s k   l o c a t i o n t a s k     t a s k    
  and   t a s k g o a l   l o c a t i o n t a s k  
  atl o c a t i o n     l o c a t i o n        code    
  subt a s k   l o c a t i o n t a s k     t a s k     
  outputp l a n
    atl o c a t i o n     o p t i m i z e d l o c a t i o n       code   
  atl o c a t i o n     o p t i m i z e d l o c a t i o n       code     

the input schema of the code above consists of two similar patterns  each matching the
at location sub plan of the pick up goals matched in the flaw  the planner replaces the
matching code parts by the corresponding entries of the output plan  in our transformation
rule  the location that has been passed to at location is replaced by the optimized location
that has been calculated in the flaw definition 
our behavior flaw is defined to match two different pick up executions  then an
arplace query is performed to find out the probability for successfully grasping both
objects from one location  if the probability is sufficiently high          the prolog query
succeeds  i e  the flaw is detected only if a sufficiently good location for grasping both
objects can be found  note that sufficiently high depends very much on the scenario
context  in robotic soccer it can be beneficial to choose fast and risky moves  whereas
in safe human robot interaction  certainty of successful execution is more important than
mere speed  this article focusses on principled ways of integrating such thresholds in a
transformational planner  and relating them to grounded models of the robots behavior 
  

filearning and reasoning with action related places for robust mobile manipulation

what these thresholds should be  and how they are determined  depends on the application
domain and the users 

   empirical evaluation
in this section we    determine how many samples are needed to learn an accurate svm
classifier     compare the robustness of our default strategy for determining base positions
with a strategy that uses arplaces     compare the efficiency of plans with and without
fixing performance flaws with our transformational planner     present preliminary results
on the physical robot platform 
    classification accuracy and training set size
figure    depicts the accuracy of the svm classifier for predicting which base positions will
lead to successful grasps for one particular cup position  evaluated on a separate test set
with     samples  without using the capability map to filter out kinematically impossible
base positions  the graph levels off after about     examples     by filtering out theoretically
impossible base positions with the capability map  the classifier achieves the same accuracy
within     examples  stulp et al         

figure     accuracy dependent on training set size for one cup position 
the effect is more dramatic for the entire dataset containing the data for    different cup
positions  by applying the capability map  the number of trials that need to be executed
reduces from       all markers in figure    to      only red green filled markers in figure    
as the capability map only reduces unsuccessful attempts  it has no influence on the final
classification accuracy  which is     
    this graph applies to another dataset described by stulp  fedrizzi  zacharias  tenorth  bandouch  and
beetz         which is very similar to the one used in the rest of this article 

  

fistulp  fedrizzi  mosenlechner    beetz

    results from the simulated robot
we now compare the robustness of navigation based on probabilistic arplaces with a
strategy based on deterministic navigation goals  in this evaluation  the position to which
the robot navigates is the position for which arplace returns the highest probability
that grasping the target object will succeed  we compare this strategy to our previous
hand coded implementation fixed  which always navigates to a location that has the same
relative offset to the target object  whilst at the same time taking care not to bump into
the table 
in these experiments  we vary the position of the cup  xobj   obj    as well as the
uncertainties the robot has about its own position and the position of the cup  by varying
the diagonal elements of the covariance matrices associated with the position of the robot
 xrob xrob  yrob yrob   and the cup  xobj xobj  obj obj    for each combination of
these variables  the robot performs the navigate reach grasp lift sequence  the result is
recorded  just as during data acquisition for learning the generalized success model  to
simulate the uncertainty  we sample a specific perceived robot and cup position from the
distribution defined by their means and covariance matrices  the result of the action is
determined by the true simulated state of the world  but the robot bases its decisions on
the perceived samples 
the results of this evaluation are summarized in the three bar plots in figure     which
depict the success ratios of the arplace based and fixed strategies  each ratio is the
number of successful executions  divided by the number of examples  which is      the pvalue above each pair of bars is computed with a   test between them  which tests whether
the number of successful and failed attempts is sampled from the same distribution for
arplace and fixed 
the first graph depicts the success ratios for increasing uncertainty about the object
position  i e  xobj xobj                                  for fixed robot position uncertainty xrob         in all cases  the arplace strategy significantly outperforms the
fixed strategy  furthermore  the performance of arplace is much more robust towards
increasing object position uncertainty  as arplace takes this explicitly into account 
the same trend can be seen when increasing the uncertainty in the robot position  i e 
xrob xrob   yrob yrob                                  for fixed object position uncertainty
xobj         however  when xrob xrob       the difference between arplace and
fixed is no longer significant 
finally  the last graph depicts the success ratios when increasing both robot and object
uncertainty  again  arplace significantly outperforms fixed when            if the
robot is quite uncertain about its own and the objects position            grasp success
probabilities drop below     for both strategies 
summarizing  arplace is more robust towards state estimation uncertainties than our
previous default strategy  the effect is more pronounced for object positions than robot
positions 
    transformational planning with merged arplaces
we evaluated the merging of arplaces for joint grasping  and the application of transformation rules with our rpl planner  as discussed in section        two cups are placed on
  

filearning and reasoning with action related places for robust mobile manipulation

figure     success ratios of the arplace and fixed approaches when changing object
and or robot pose uncertainties 

the table  where the distance between them is varied between    and   cm  with increments
of  cm  our evaluation shows that grasping two cups from separate base positions requires
on average    seconds  independent of the relative distance of the cups to each other  by
applying transformation rules  the default plan is optimized to    seconds  which is a significant  t test  p          and substantial performance gain of      fedrizzi et al         
above   cm  two cups cannot be grasped from one position  and plan transformation is not
applied 
    integration of arplace in the physical robot system
at a day of open house  our b   mobile manipulation platform continually performed an
application scenario  where it locates  grasps  and lifts a cup from the table and moves it to
the kitchen oven  figure    shows two images taken during the demonstration  the robot
performed this scenario    times in approximately   hours  which has convinced us that the
robot hardware and software are robust enough to be deployed amongst the general public 
after the open day  we ran the same experiment  but this time we determined the goal
location for navigating to the table as being the mode of the arplace that was computed
before executing the navigation action  since the main focus of this experiment was on our
error recovery system described by beetz et al          the improved robot performance we
observed cannot quantitatively be attributed to the use of arplace or the error recovery
system  however  a major qualitative improvement we certainly can attribute to using
arplace was that the cup can now be grasped from a much larger area on the table 
without arplaces  the cup always had to be placed on the same position on the table to
enable successful grasping 

   conclusion
in this article  we present a system that enables robots to learn action related places
from observed experience  and reason with these places to generate robust  flexible  least  

fistulp  fedrizzi  mosenlechner    beetz

   robot navigates to table

   robot reaches for cup

figure     a reach and grasp trajectory performed during a public demonstration   note
that the operator is holding a camera  not a remote control  

commitment plans for mobile manipulation  arplace is modeled as a probability distribution that maps locations to the predicted outcome of an action 
we believe our system has several advantages  first of all  the learned model is very
compact  with only    deformation  parameters  which are directly related to task relevant
parameters  querying the model on line is therefore very efficient  this is an advantage
of compiling experience into compact models  rather than running a novel search for each
situation 
on the other hand  as the model is acquired through experience based learning  the
model is grounded in observed experience  and takes into account the robot hardware  its
control programs  and interactions with the environment  it can be applied to any mobile
manipulation platform  independent of the manipulators  navigation base  or the algorithms
that run on them 
the output of this model is a set of positions with associated success probabilities 
instead of one specific position  rather than constraining itself to a specific position prematurely  the robot can efficiently update arplace as new sensor data comes in  this enables
least commitment planning  the arplace representation also enables the optimization of
secondary criteria  such as execution duration  or determining the best position for grasping two objects simultaneously  in previous work  we proposed subgoal refinement  stulp
  beetz        for optimizing such secondary criteria with respect to subgoals 
finally  by using arplaces to determine appropriate base positions  difficult positions
for grasping are avoided  which leads to more robust behavior in the face of state estimation
uncertainty  as demonstrated in our empirical evaluation 
we are currently extending our approach in several directions  we are in the process of
including arplace in a more general utility based framework  in which the probability of
success is only one of the aspects of the task that needs to be optimized  new utilities  such
  

filearning and reasoning with action related places for robust mobile manipulation

as execution duration or power consumption  are easily included in this framework  which
enables the robot to trade off efficiency and robustness on line during task execution 
we are also applying our approach to more complex scenarios and different domains  for
instance  we are learning higher dimensional arplace concepts  which take more aspects
of the scenario into account  i e  different object sizes and objects that require different
types of grasps  instead of mapping specific objects to places  we will map object and grasp
properties to deformation modes  we are also investigating extensions and other machine
learning algorithms that will enable our methods to generalize over this larger space  objects
which require very different grasps  such as using two hands to manipulate them  will require
more sophisticated methods for acquiring and reasoning about place  generalization of our
place concept with respect to situations and task contexts is a research challenge which we
have on our mid term research agenda 

acknowledgments
we are grateful to pierre roduit for providing us with the matlab code described by roduit
et al          we also thank ingo kresse  alexis maldonado  and federico ruiz for assistance
with the robotic platform  and the robot system overview  we are grateful to franziska
zacharias for providing a capability map  zacharias et al         for our robot  we thank
dominik jain and franziska meier for fruitful discussions on section     
this work was partly funded by the dfg project actar  action awareness in autonomous robots  and the cotesys cluster of excellence  cognition for technical systems  http   www cotesys org   part of the excellence initiative of the german research
foundation  dfg   freek stulp was also supported by a post doctoral research fellowship
 stu          from the dfg  as well as by the japanese society for the promotion of
science  pe        freek stulps contributions to this work were made at the intelligent
autonomous systems group  technische universitat munchen  munich  germany   the
computational neuroscience laboratories  advanced telecommunications research institute international  kyoto  japan   and the computational learning and motor control lab
 university of southern california  los angeles  usa  

appendix a  robot platform
the action sequence we consider in this article is     navigate to a specified base position
near the table     reach for the object     close the gripper     lift the object  we now
sequentially describe the various hard  and software components involved in executing these
actions  an overview of these components and the data communicated between them is
depicted in figure    
the main hardware component is a b  r mobile robot from real world interfaces
 rwi   with a frontal     degrees sick lms     laser range scanner  before task execution 
the robot acquires a map of the  kitchen  environment using pmap for map building  to
navigate to the specified base position  the robot uses an adaptive monte carlo localization
algorithm for localization  and the amcl wavefront planner for global path planning 
for these three software modules  map building  localization and planning   we use the
implementations from the player project  gerkey et al         
  

fistulp  fedrizzi  mosenlechner    beetz

figure     overview of mobile manipulation hardware and software modules 

when the robot is close to the table  it detects and tracks the target object using the
approach proposed by klank et al          the stereo vision hardware consists of two
high dynamic range cameras that are mounted on a ptu    pan tilt unit from directed
perception and have a resolution of     x     pixels 
for manipulation  the robot is equipped with two   dof powercube lightweight arms
from amtec robotics  to control the arms and reach for the target cup  we use the kinematics and dynamics library  orocos kdl   smits    and a vector field approach  within
this vector field  the handle of the cup is an attractor  but the cup itself  the table and all
other obstacles are repellors  details about the position and shape of these attractors and
repellors are given by beetz et al          on line at every control cycle  the task space velocity at the end effector is computed given the attractors and repellors  and this velocity is
mapped to joint space velocities using a damped least squares inverse kinematics algorithm 
after reaching the desired end effector pose  the   dof slide gripper closes 
high level decision making  monitoring and error recovery is done by the planning module written in the reactive planning language  mcdermott         it requests arplaces
from the module described in this article  reasons about them  and performs navigation and
manipulation requests based on them 
communication between all modules described above is done over a middleware layer
consisting of player  gerkey et al         and yarp  metta  fitzpatrick    natale        
this overview is a simplification of the actual system  for instance  the role of rfid tags
and the belief state have been omitted  for a complete and more detailed description of
the mobile manipulation platform  we refer to the work of beetz et al         section      
  

filearning and reasoning with action related places for robust mobile manipulation

appendix b  landmark distribution for the point distribution model
a point distribution model  pdm  takes a set of m landmarks on n contours as an input 
represented as a m  n matrix h  and returns the matrices h  mean of the contours   p
 deformation modes   and b  deformation mode weighting per contour   which the original
contours can be reconstructed 
in our application of pdms  we are free to choose the locations of the landmarks  therefore  the goal of the procedure described here is to determine landmark locations that leads
to a compact pdm that accurately reconstructs the original contours  i e  the classification
boundaries  we do so by explicitly optimizing two measures     model compactness  the
amount of energy e stored in the first d degrees of freedom of the pdm  with    e    
   reconstruction accuracy  the mean distance l between the landmarks on the original
contours and reconstructed contours  these measures are combined in the cost function
    e l    expressing that we want low error and high energy for a given number of degrees
of freedom d 
given the number of landmarks m and the number of degrees of freedom d  we explicitly
optimize this cost function through search  we do so by varying the position of each
landmark  one landmark at a time  and greedily selecting the position that leads to the
lowest cost  this optimization is first done for d      and the number of degrees of freedom
d is incremented until the optimization leads to an energy that lies above      this ensures
that the number of degrees of freedom d and the distance l between the landmarks remains
low  whilst the energy e is high  therefore  the resulting pdm model will be compact yet
accurate 
this optimization step is by far the most computationally intensive step in the off line
learning phase  we are currently investigating the use of alignment methods from computer
vision  huang  paragios    metaxas         to replace our iterative optimization approach 

appendix c  from robot coordinate systems to the relative feature
space
our robot uses a variety of coordinate systems  the goal is to compute the matrix gsm to  
which describes the objects position relative to the feature space of the generalized success
model  gsm to can then be used to reconstruct classification boundaries for successfully
grasping the object  as described in section      we now present the required coordinate
systems  and how they are transformed to yield the generalized success model required
feature space that is depicted in figure   
the coordinate frames that are involved in the transformation are depicted in figure    
the world frame fw   the table frame ft that is centered in the middle top of the table  the
robot frame fr that is centered in the robots base center at the floor  the camera frame
fc that is centered in the cameras sensor chip  the frame of the pan tilt unit where the
camera is mounted fp t   and the relative feature space fgsm  
to acquire the position of the target object o relative to fgsm   we compute gsm to as
follows 
gsm

to    w tgsm    
  

w

to

    

fistulp  fedrizzi  mosenlechner    beetz

figure     relevant coordinate frames

the global position of the object
w

to  

w

wt
o

tr 

is computed as follows 
r

tp t 

pt

tc 

c

to

    

here  w tr is the location of the robots base frame relative to the world frame  the
robot uses an amcl particle filter for estimating its position  r tp t is the pose of the pan
tilt unit relative to the robots base frame  the transformation matrix r tp t is constant
and was specified by manually measuring the distances and angular offsets from the b  
robot base to the pan tilt unit  because of careful measurement  we assume maximum
errors of  mm for the distance measurements along the x   y   and z axis  and   for the
yaw angle measurement  p t tc is the pose of the cameras sensor relative to the pan tilt
unit  p t tc changes according to the current pan and tilt angles  but can be read from the
pan tilt units driver with high accuracy  c to is the position of the target object relative
to the camera frame  it is estimated by the vision based object localization module that is
described by klank et al         
in order to compute w tgsm we need to know the global position of the object w to  
which we already computed above  and the global position of the table w tt   currently 
we get the world coordinates of the tables position from a map  but it is also possible to
estimate its position with the vision based object localization module  we then compute
the normal from the object to the table edge that is closest to the robot  as can be seen in
figure    the origin of fgsm and therefore w tgsm is where the table edge and the object
normal intersect 
the most critical parts in the computations above are the angular estimations of the
robots localization and vision system  first  their estimation uncertainty is rather big 
second  an error in the localization angle has a significant impact on the estimated object
pose  as follows from equation    
the pose of the cup in frame fgsm is a  d vector  x  y  z  yaw  pitch  roll   however 
since we assume the cup is standing upright on the table  we set z to the tables height 
and roll and pitch to     since the origin of fgsm is perpendicular to the tables edge
that passes through y  y is also   by definition  the remaining parameters x and yaw then
correspond to the features xobj and  obj respectively 
  

filearning and reasoning with action related places for robust mobile manipulation

references
amir  e     chang  a          learning partially observable deterministic action models 
journal of artificial intelligence research  jair              
beetz  m   stulp  f   esden tempski  p   fedrizzi  a   klank  u   kresse  i   maldonado 
a     ruiz  f          generality and legibility in mobile manipulation  autonomous
robots journal  special issue on mobile manipulation                
beetz  m   stulp  f   radig  b   bandouch  j   blodow  n   dolha  m   fedrizzi  a   jain 
d   klank  u   kresse  i   maldonado  a   marton  z   mosenlechner  l   ruiz  f  
rusu  r  b     tenorth  m          the assistive kitchen  a demonstration scenario
for cognitive technical systems  in ieee   th international symposium on robot and
human interactive communication  ro man   muenchen  germany  invited paper 
berenson  d   choset  h     kuffner  j          an optimization approach to planning
for mobile manipulation  in proceedings of the ieee international conference on
robotics and automation  icra        pp           
berenson  d   srinivasa  s   ferguson  d   romea  a  c     kuffner  j       a   manipulation planning with workspace goal regions  in proceedings of the ieee international
conference on robotics and automation  icra   pp           
berenson  d   srinivasa  s  s     kuffner  j  j       b   addressing pose uncertainty in
manipulation planning using task space regions  in proceedings of the ieee rsj
international conference on intelligent robots and systems  iros  pp           
bohlin  r     kavraki  l  e          path planning using lazy prm  in ieee international
conference robototics and automation  pp         
buck  s     riedmiller  m          learning situation dependent success rates of actions in a
robocup scenario  in pacific rim international conference on artificial intelligence 
p      
cambon  s   gravot  f     alami  r          a robot task planner that merges symbolic and
geometric reasoning   in proceedings of the   th european conference on artificial
intelligence  ecai   pp         
chang  a     amir  e          goal achievement in partially known  partially observable domains  in international conference on automated planning and scheduling
 icaps   pp         
clement  b  j   durfee  e  h     barrett  a  c          abstract reasoning for planning
and coordination  journal of artificial intelligence research             
cootes  t  f   taylor  c  j   cooper  d     graham  j          active shape models   their
training and application  computer vision and image understanding               
detry  r   baseski  e   popovic  m   touati  y   krueger  n   kroemer  o   peters  j    
piater  j          learning object specific grasp affordance densities  in proceedings
of the international conference on development and learning  icdl   pp     
diankov  r   ratliff  n   ferguson  d   srinivasa  s     kuffner  j          bispace planning 
concurrent multi space exploration  in proc  int  conf  on robotics  science and
systems 
  

fistulp  fedrizzi  mosenlechner    beetz

fedrizzi  a          action related places for mobile manipulation  ph d  thesis  technische
universiat munchen 
fedrizzi  a   moesenlechner  l   stulp  f     beetz  m          transformational planning for mobile manipulation based on action related places  in proceedings of the
international conference on advanced robotics  icar    pp     
friedman  m     weld  d  s          least commitment action selection  in proceedings
 rd international conference on a i  planning systems  pp        aaai press 
geib  c   mourao  k   petrick  r   pugeault  m   steedman  m   kruger  n     worgotter 
f          object action complexes as an interface for planning and robot control  in
proceedings of the      ieee ras international conference on humanoid robots 
genova 
gerkey  b   vaughan  r  t     howard  a          the player stage project  tools for
multi robot and distributed sensor systems  in proceedings of the   th international
conference on advanced robotics  icar   pp         
gibson  j  j          the theory of affordances  john wiley   sons 
hart  s   ou  s   sweeney  j     grupen  r          a framework for learning declarative
structure  in rss    workshop  manipulation for human environments 
huang  x   paragios  n     metaxas  d  n          shape registration in implicit spaces
using information theory and free form deformations  ieee trans  pattern analysis
and machine intelligence  tpami                
kemp  c   edsinger  a     torres jara  e          challenges for robot manipulation in
human environments  ieee robotics and automation magazine               
klank  u   zia  m  z     beetz  m           d model selection from an internet database
for robotic vision  in international conference on robotics and automation  icra  
pp           
kuipers  b   beeson  p   modayil  j     provost  j          bootstrap learning of foundational representations  connection science             
lavalle  s  m          planning algorithms  chap  chapter    sampling based motion
planning  cambridge university press 
maldonado  a   klank  u     beetz  m          robotic grasping of unmodeled objects
using time of flight range data and finger torque information  in      ieee rsj
international conference on intelligent robots and systems  iros   pp           
taipei  taiwan 
mcdermott  d          a reactive plan language  research report yaleu dcs rr     yale university 
metta  g   fitzpatrick  p     natale  l          yarp  yet another robot platform  international journal of advanced robotics systems  special issue on software development
and integration in robotics              
morales  a   chinellato  e   fagg  a  h     del pobil  a  p          using experience for
assessing grasp reliability  international journal of humanoid robotics                
  

filearning and reasoning with action related places for robust mobile manipulation

mosenlechner  l     beetz  m          using physics  and sensor based simulation for
high fidelity temporal projection of realistic robot behavior  in   th international
conference on automated planning and scheduling  icaps    
okada  k   kojima  m   sagawa  y   ichino  t   sato  k     inaba  m          vision
based behavior verification system of humanoid robot for daily environment tasks 
in proceedings of the  th ieee ras international conference on humanoid robots
 humanoids   pp      
pastor  p   hoffmann  h   asfour  t     schaal  s          learning and generalization
of motor skills by learning from demonstration  in proceedings of the international
conference on robotics and automation  icra   pp           
resulaj  a   kiani  r   wolpert  d  m     shadlen  m  n          changes of mind in
decision making  nature                     
roduit  p   martinoli  a     jacot  j          a quantitative method for comparing trajectories of mobile robots using point distribution models  in proceedings of the ieee rsj
international conference on intelligent robots and systems  iros   pp           
ryan  m  r  k          using abstract models of behaviours to automatically generate reinforcement learning hierarchies  in proceedings of the   th international conference
on machine learning  sydney  australia  pp         
smits  r  kdl  kinematics and dynamics library  http   www orocos org kdl 
sonnenburg  s   raetsch  g   schaefer  c     schoelkopf  b          large scale multiple
kernel learning  journal of machine learning research              
stulp  f     beetz  m          refining the execution of abstract actions with learned action
models  journal of artificial intelligence research  jair      
stulp  f   fedrizzi  a     beetz  m       a   action related place based mobile manipulation  in proceedings of the international conference on intelligent robots and systems
 iros   pp           
stulp  f   fedrizzi  a     beetz  m       b   learning and performing place based mobile
manipulation  in proceedings of the  th international conference on development and
learning  icdl    pp     
stulp  f   fedrizzi  a   zacharias  f   tenorth  m   bandouch  j     beetz  m       c  
combining analysis  imitation  and experience based learning to acquire a concept of
reachability  in  th ieee ras international conference on humanoid robots  pp 
       
sutton  r     barto  a          reinforcement learning  an introduction  mit press 
wimmer  m   stulp  f   pietzsch  s     radig  b          learning local objective functions
for robust face model fitting  ieee transactions on pattern analysis and machine
intelligence  pami                    
zacharias  f   borst  c     hirzinger  g          capturing robot workspace structure  representing robot capabilities  in proceedings of the ieee rsj international conference
on intelligent robots and systems  iros   pp           
  

fistulp  fedrizzi  mosenlechner    beetz

zettlemoyer  l  s   pasula  h  m     kaelbling  l  p          learning planning rules in noisy
stochastic worlds  in proceedings of the twentieth national conference on artificial
intelligence  aaai   pp         
zheng  y     qian  w  h          coping with the grasping uncertainties in force closure
analysis  international journal robotics research                 

  

fi