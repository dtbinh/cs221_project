journal of artificial intelligence research                  

submitted       published     

asynchronous partial overlay  a new algorithm for solving
distributed constraint satisfaction problems
roger mailler

mailler ai sri com

sri international
    ravenswood dr
menlo park  ca       usa

victor r  lesser

lesser cs umass edu

university of massachusetts  department of computer science
    governors drive
amherst  ma       usa

abstract
distributed constraint satisfaction  dcsp  has long been considered an important
problem in multi agent systems research  this is because many real world problems can
be represented as constraint satisfaction and these problems often present themselves in a
distributed form  in this article  we present a new complete  distributed algorithm called
asynchronous partial overlay  apo  for solving dcsps that is based on a cooperative mediation process  the primary ideas behind this algorithm are that agents  when acting as a
mediator  centralize small  relevant portions of the dcsp  that these centralized subproblems overlap  and that agents increase the size of their subproblems along critical paths
within the dcsp as the problem solving unfolds  we present empirical evidence that shows
that apo outperforms other known  complete dcsp techniques 

   introduction
the distributed constraint satisfaction problem has become a very useful representation
that is used to describe a number of problems in multi agent systems including distributed
resource allocation  conry  kuwabara  lesser    meyer        and distributed scheduling
 sycara  roth  sadeh    fox         some researchers in cooperative multi agent systems
have focused on developing methods for solving these problems that are based on one key assumption  particularly  the agents involved in the problem solving process are autonomous 
this means that the agents are only willing to exchange information that is directly relevant
to the shared problem and retain the ability to refuse a solution when it obviously conflicts
with some internal goal 
these researchers believe that the focus on agent autonomy precludes the use of centralization because it forces the agents to reveal all of their internal constraints and goals which
may  for reasons of privacy or pure computational complexity  be impossible to achieve 
several algorithms have been developed with the explicit purpose of allowing the agents
to retain their autonomy even when they are involved in a shared problem which exhibits
interdependencies  probably the best known algorithms that fit this description can be
found in the work of yokoo et al  in the form of distributed breakout  dba   yokoo  
hirayama         asynchronous backtracking  abt   yokoo  durfee  ishida    kuwabara 
       and asynchronous weak commitment  awc   yokoo   hirayama        
c
    
ai access foundation  all rights reserved 

fimailler   lesser

unfortunately  a common drawback to each of these algorithms is that in an effort to
provide the agents which complete privacy  these algorithms prevent the agents from
making informed decisions about the global effects of changing their local allocation  schedule  value  etc  for example  in awc  agents have to try a value and wait for another agent
to tell them that it will not work through a nogood message  because of this  agents never
learn true reason why another agent or set of agents is unable to accept the value  they only
learn that their value in combination with other values doesnt work 
in addition  these techniques suffer because they have complete distribution of the control  in other words  each agent makes decisions based on its incomplete and often inaccurate
view of the world  the result is that this leads to unnecessary thrashing in the problem
solving because the agents are trying to adapt to the behavior of the other agents  who in
turn are trying to adapt to them  pathologically  this behavior can be counter productive to
convergence of the protocol fernandez  bejar  krishnamachari  gomes    selman        
this iterative trial and error approach to discovering the implicit and implied constraints
within the problem causes the agents to pass an exponential number of messages and actually reveals a great deal of information about the agents constraints and domain values
 yokoo  suzuki    hirayama         in fact  in order to be complete  agents using awc
have to be willing to reveal all of their shared constraints and domain values  the key thing
to note about this statement is that awc still allows the agents to retain their autonomy
even if they are forced to reveal information about the variables and constraints that form
the global constraint network 
in this paper  we present a cooperative mediation based dcsp protocol  called asynchronous partial overlay  apo   cooperative mediation represents a new methodology
that lies somewhere between centralized and distributed problem solving because it uses
dynamically constructed  partial centralization  this allows cooperative mediation based
algorithms  like apo  to utilize the speed of current state of the art centralized solvers
while taking advantage of opportunities for parallelism by dynamically identifying relevant
problem structure 
apo works by having agents asynchronously take the role of mediator  when an agent
acts as a mediator  it computes a solution to a portion of the overall problem and recommends value changes to the agents involved in the mediation session  if  as a result of its
recommendations  it causes conflicts for agents outside of the session  it links with them
preventing itself from repeating the mistake in future sessions 
like awc  apo provides the agents with a great deal of autonomy by allowing anyone
of them to take over as the mediator when they notice an undesirable state in the current
solution to the shared problem  further adding to their autonomy  agents can also ignore
recommendations for changing their local solution made by other agents  in a similar
way to awc  apo is both sound and complete when the agents are willing to reveal the
domains and constraints of their shared variables and allows the agents to obscure the
states  domains  and constraints of their strictly local variables 
in the rest of this article  we present a formalization of the dcsp problem  section
    in section    we describe the underlying assumptions and motivation for this work 
we then present the apo algorithm  section      and give an example of the protocols
execution on a simple   coloring problem  section       we go on to give the proofs for
the soundness and completeness of the algorithm  section       in section    we present
   

fiasynchronous partial overlay  a new algorithm for dcsp

the results of extensive testing that compares apo with awc within the distributed graph
coloring domain and the complete compatibility version of the sensordcsp domain  bejar 
krishnamachari  gomes    selman        across a variety of metrics including number of
cycles  messages  bytes transmitted  and serial runtime  in each of these cases  we will show
that apo significantly outperforms awc  yokoo        hirayama   yokoo         section
  summarizes the article and discusses some future research directions 

   distributed constraint satisfaction
a constraint satisfaction problem  csp  consists of the following 

 a set of n variables v    x            xn   

 discrete  finite domains for each of the variables d    d            dn   

 a set of constraints r    r            rm   where each ri  di            dij   is a predicate on
the cartesian product di       dij that returns true iff the value assignments of
the variables satisfies the constraint 

the problem is to find an assignment a    d            dn  di  di   such that each of the
constraints in r is satisfied  csp has been shown to be np complete  making some form
of search a necessity 
in the distributed case  dcsp  using variable based decomposition  each agent is assigned one or more variables along with the constraints on their variables  the goal of each
agent  from a local perspective  is to ensure that each of the constraints on its variables
is satisfied  clearly  each agents goal is not independent of the goals of the other agents
in the system  in fact  in all but the simplest cases  the goals of the agents are strongly
interrelated  for example  in order for one agent to satisfy its local constraints  another
agent  potentially not directly related through a constraint  may have to change the value
of its variable 
in this article  for the sake of clarity  we restrict ourselves to the case where each agent
is assigned a single variable and is given knowledge of the constraints on that variable 
since each agent is assigned a single variable  we will refer to the agent by the name of
the variable it manages  also  we restrict ourselves to considering only binary constraints
which are of the form ri  di    di     since apo uses centralization as its core  it is easy to
see that the algorithm would work if both of these restrictions are removed  this point will
be discussed as part of the algorithm description in section       
throughout this article  we use the term constraint graph to refer to the graph formed by
representing the variables as nodes and the constraints as edges  also  a variables neighbors
are the variables with which it shares constraints 
   

fimailler   lesser

   assumptions and motivation
    assumptions
the following are the assumptions made about the environments and agents for which this
protocol was designed 
   agents are situated  autonomous  computing entities  as such  they are capable of
sensing their environment  making local decisions based on some model of intentionality  and acting out their decisions  agents are rationally and resource bounded 
as a result  agents must communicate to gain information about each others state 
intentions  decisions  etc 
   agents within the multi agent system share one or more joint goals  in this paper 
this goal is boolean in nature stemming from the dcsp formulation 
   because this work focuses on cooperative problem solving  the agents are cooperative 
this does not necessarily imply they will share all of their state  intentions  etc  with
other agents  but are  to some degree  willing to exchange information to solve joint
goals  it also does not imply that they will change their intentions  state  or decisions
based on the demands of another agent  agents still maintain their autonomy and
the ability to refuse or revise the decisions of other agents based on their local state 
intentions  decisions  etc 
   each agent has the capability of computing solutions to the joint goal based on their
potentially limited rationality  this follows naturally from the ability of agents to
make their own decisions  i e   every agent is capable of computing a solution to its
own portion of the joint goal based on its own desires 
    motivation for mediation based problem solving
the websters dictionary defines the act of mediating as follows 
mediate     to act as an intermediary  especially to work with opposing sides
in order to resolve  as a dispute  or bring about  as a settlement      to bring
about  influence  or transmit by acting as an intermediate or controlling agent
or mechanism   merriam webster       
by its very definition  mediation implies some degree of centralizing a shared problem in
order for a group of individuals to derive a conflict free solution  clearly in situations where
the participants are willing  cooperative   mediation is a powerful paradigm for solving
disputes  its rather strange  considering this  that very little has been done on looking at
mediation as a cooperative method for solving dcsps 
probably  the earliest mediation based approach for solving conflicts amongst agents in
an airspace management application cammarata  mcarthur    steeb         this work
investigates using various conflict resolution strategies to deconflict airspace in a distributed
air traffic control system  the author proposes a method for solving disputes where the
involved agents elect a leader to solve the problem  once elected  the leader becomes
   

fiasynchronous partial overlay  a new algorithm for dcsp

s 

s 

     

     

figure    a simple distributed problem with two variables 
responsible for recognizing the dispute  devising a plan to correct it  and acting out the
plan  various election schemes are tested  but unfortunately  the leader only has authority
to modify its own actions in order to resolve the conflicts  this obviously leads to situations
where the plan is suboptimal 
in  hayden  carrick    yang         the authors describe mediation as one of a number possible coordination mechanisms  in this work  the mediator acts as a intermediary
between agents and can also act to coordinate their behavior  as an intermediary  the mediator routes messages  provides directory services  etc  this provides for a loose coupling
of the agents  since they only need to know the mediator  the mediator can also act to
coordinate the agents behavior if they have tight interdependencies 
most of the research work on mediation based problem solving involved settling disputes
between competitive or semi competitive agents  probably one of the best examples of
using mediation in this manner can be found in the persuader system sycara        
persuader was designed to settle conflicts between adversarial parties that are involved
in a labor dispute  persuader uses case based reasoning to suggest concessions in order
to converge on a satisfactory solution  another example of using mediation in this way
can be found in in a system called designer fabricator interpreter  dfi   werkman        
in dfi  mediation is used to resolve conflicts as one of a series of problem solving steps 
whenever the first step fails  in this case iterative negotiation  a mediator agent steps in and
tries to convince the agents to relax their constraints  if this fails  the mediator mandates
a final solution 
there may be several reasons why mediation has not been more deeply explored as
a cooperative problem solving method  first  researchers have focused strongly on using
distributed computing as a way of exploiting concurrency to distribute the computation
needed to solve hard problems  rao   kumar         because of this  even partially
and or temporarily centralizing sections of the problem can be viewed as contradictory
to the central goal  second  researchers have often claimed that part of the power of the
distributed methods lies in the ability of the techniques to solve problems that are naturally
distributed  for example  supply chain problems generally have no central monitoring
authority  again  directly sharing the reasons why a particular choice is made in the form of
a constraint can seem to contradict the use of distributed methods  lastly  researchers often
claim that for reasons of privacy or security the problem should be solved in a distributed
fashion  clearly  sharing information to solve a problem compromises an agents ability to
be private and or violates its security in some manner 
although  parallelism  natural distribution  security  and privacy  may all seem like good
justifications for entirely distributed problem solving  in actuality  whenever a problem has
interdependencies between distributed problem solvers  some degree of centralization and
information sharing must take place in order to derive a conflict free solution 
   

fimailler   lesser

consider  as a simple example  the problem in figure    in this figure  two problem
solvers  each with one variable  share the common goal of having a different value from one
another  each of the agents has only two allowable values          now  in order to solve
this problem  each agent must individually decide that they have a different value from the
other agent  to do this  at the very least  one agent must transmit its value to the other  by
doing this  it removes half of its privacy  by revealing one of its possible values   eliminates
security  because the other agent could make him send other values by telling him that this
value is no good   and partially centralizes the problem solving  agent s  has to compute
solutions based on the solution s  presented and decide if the problem is solved and agent
s  just relies on s  to solve it   in even this simple example  achieving totally distributed
problem solving is impossible 
in fact  if you look at the details of any of the current approaches to solving dcsps 
you will observe a significant amount of centralization occurring  most of these approaches
perform this centralization incrementally as the problem solving unfolds in an attempt to
restrict the amount of internal information being shared  unfortunately  on problems that
have interdependencies among the problem solvers  revealing an agents information  such
as the potential values of their variables  is unavoidable  in fact  solutions that are derived
when one or more agents conceals all of the information regarding a shared constraint or
variable are based on incomplete information and therefore may not always be sound 
it follows then  that since you cannot avoid some amount of centralization  mediation
is a natural method for solving problems that contain interdependencies among distributed
problem solvers 

   asynchronous partial overlay
as a cooperative mediation based protocol  the key ideas behind the creation of the apo
algorithm are
 using mediation  agents can solve subproblems of the dcsp using internal search 
 these local subproblems can and should overlap to allow for more rapid convergence
of the problem solving 
 agents should  over time  increase the size of the subproblem they work on along
critical paths within the csp  this increases the overlap with other agents and ensures
the completeness of the search 
    the algorithm
figures             and   present the basic apo algorithm  the algorithm works by constructing a good list and maintaining a structure called the agent view  the agent view
holds the names  values  domains  and constraints of variables to which an agent is linked 
the good list holds the names of the variables that are known to be connected to the owner
by a path in the constraint graph 
as the problem solving unfolds  each agent tries to solve the subproblem it has centralized within its good list or determine that it is unsolvable which indicates the entire global
problem is over constrained  to do this  agents take the role of the mediator and attempt
   

fiasynchronous partial overlay  a new algorithm for dcsp

procedure initialize
di  random d  di  
pi  sizeof  neighbors      
mi  true 
mediate  false 
add xi to the good list 
send  init   xi   pi   di   mi   di   ci    to neighbors 
initlist  neighbors 
end initialize 
when received  init   xj   pj   dj   mj   dj   cj    do
add  xj   pj   dj   mj   dj   cj   to agent view 
if xj is a neighbor of some xk  good list do
add xj to the good list 
  good list
add all xl  agent view  xl 
that can now be connected to the good list 
pi  sizeof  good list  
end if 
if xj 
  initlist do
send  init   xi   pi   di   mi   di   ci    to xj  
else
remove xj from initlist 
check agent view 
end do 
figure    the apo procedures for initialization and linking 

to change the values of the variables within the mediation session to achieve a satisfied
subsystem  when this cannot be achieved without causing a violation for agents outside of
the session  the mediator links with those agents assuming that they are somehow related to
the mediators variable  this process continues until one of the agents finds an unsatisfiable
subsystem  or all of the conflicts have been removed 
in order to facilitate the problem solving process  each agent has a dynamic priority
that is based on the size of their good list  if two agents have the same sized good list then
the tie is broken using the lexicographical ordering of their names   priorities are used by
the agents to decide who mediates a session when a conflicts arises  priority ordering is
important for two reasons  first  priorities ensure that the agent with the most knowledge
gets to make the decisions  this improves the efficiency of the algorithm by decreasing
the effects of myopic decision making  second  priorities improve the effectiveness of the
mediation process because lower priority agents expect higher priority agents to mediate 
this improves the likelihood that lower priority agents will be available when a mediation
request is sent 
   

fimailler   lesser

when received  ok    xj   pj   dj   mj    do
update agent view with  xj   pj   dj   mj   
check agent view 
end do 
procedure check agent view
if initlist     or mediate   false do
return 
m i  hasconf lict xi   
if m i and j  pj   pi  mj     true 
if  d i  di    d i  agent view does not conflict 
and di conflicts exclusively with lower priority neighbors
di  d i  
send  ok    xi   pi   di   mi    to all xj  agent view 
else
do mediate 
else if mi    m i
mi  m i  
send  ok    xi   pi   di   mi    to all xj  agent view 
end if 
end check agent view 

figure    the procedures for doing local resolution  updating the agent view and the
good list 

      initialization  figure   
on startup  the agents are provided with the value  they pick it randomly if one isnt
assigned  and the constraints on their variable  initialization proceeds by having each of
the agents send out an init message to its neighbors  this initialization message includes
the variables name  xi    priority  pi    current value di    the agents desire to mediate  mi   
domain  di    and constraints  ci    the array initlist records the names of the agents that
initialization messages have been sent to  the reason for which will become immediately
apparent 
when an agent receives an initialization message  either during the initialization or
through a later link request   it records the information in its agent view and adds the
variable to the good list if it can  a variable is only added to the good list if it is a
neighbor of another variable already in the good list  this ensures that the graph created
by the variables in the good list always remains connected  which focuses the agents internal
problem solving on variables which it knows it has an interdependency with  the initlist
is then checked to see if this message is a link request or a response to a link request  if an
agent is in the initlist  it means that this message is a response  so the agent removes the
   

fiasynchronous partial overlay  a new algorithm for dcsp

procedure mediate
pref erences   
counter    
for each xj  good list do
send  evaluate    xi   pi    to xj  
counter    
end do 
mediate  true 
end mediate 
when receive  wait    xj   pj    do
update agent view with  xj   pj   
counter     
if counter      do choose solution 
end do 
when receive  evaluate    xj   pj   labeled dj    do
record  xj   labeled dj   in preferences 
update agent view with  xj   pj   
counter     
if counter      do choose solution 
end do 
figure    the procedures for mediating an apo session 
name from the initlist and does nothing further  if the agent is not in the initlist then it
means this is a request  so a response init is generated and sent 
it is important to note that the agents contained in the good list are a subset of the
agents contained in the agent view  this is done to maintain the integrity of the good list
and allow links to be bidirectional  to understand this point  consider the case when a
single agent has repeatedly mediated and has extended its local subproblem down a long
path in the constraint graph  as it does so  it links with agents that may have a very limited
view and therefore are unaware of their indirect connection to the mediator  in order for
the link to be bidirectional  the receiver of the link request has to store the name of the
requester in its agent view  but cannot add them to their good list until a path can be
identified  as can be seen in section      the bi directionality of links is important to ensure
the protocols soundness 
      checking the agent view  figure   
after all of the initialization messages are received  the agents execute the check agent view
procedure  at the end of figure     in this procedure  the current agent view  which contains
the assigned  known variable values  is checked to identify conflicts between the variable
owned by the agent and its neighbors  if  during this check  called hasconflict in the
   

fimailler   lesser

procedure choose solution
select a solution s using a branch and bound search that 
   satisfies the constraints between agents in the good list
   minimizes the violations for agents outside of the session
if s that satisfies the constraints do
broadcast no solution 
for each xj  agent view do
if xj  pref erences do
if d j  s violates an xk and xk 
  agent view do
send  init   xi   pi   di   mi   di   ci    to xk  
add xk to initlist 
end if 
send  accept    d j   xi   pi   di   mi    to xj  
update agent view for xj
else
send  ok    xi   pi   di   mi    to xj  
end if 
end do 
mediate  false 
check agent view 
end choose solution 
figure    the procedure for choosing a solution during an apo mediation 
figure   an agent finds a conflict with one or more of its neighbors and has not been told by
a higher priority agent that they want to mediate  it assumes the role of the mediator 
an agent can tell when a higher priority agent wants to mediate because of the m i flag
mentioned in the previous section  whenever an agent checks its agent view it recomputes
the value of this flag based on whether or not it has existing conflicts with its neighbors 
when this flag is set to true it indicates that the agent wishes to mediate if it is given
the opportunity  this mechanism acts like a two phase commit protocol  commonly seen in
database systems  and ensures that the protocol is live lock and dead lock free 
when an agent becomes the mediator  it first attempts to rectify the conflict s  with
its neighbors by changing its own variable  this simple  but effective technique prevents
mediation sessions from occurring unnecessarily  which stabilizes the system and saves messages and time  if the mediator finds a value that removes the conflict  it makes the change
and sends out an ok  message to the agents in its agent view  if it cannot find a nonconflicting value  it starts a mediation session  an ok  message is similar to an init
message  in that it contains information about the priority  current value  etc  of a variable 
      mediation  figures       and   
the most complex and certainly most interesting part of the protocol is the mediation  as
was previously mentioned in this section  an agent decides to mediate if it is in conflict
   

fiasynchronous partial overlay  a new algorithm for dcsp

when received  evaluate    xj   pj    do
mj  true 
if mediate    true or k  pk   pj  mk     true  do
send  wait    xi   pi    
else
mediate  true 
label each d  di with the names of the agents
that would be violated by setting di  d 
send  evaluate    xi   pi   labeled di    
end if 
end do 
when received  accept    d  xj   pj   dj   mj    do
di  d 
mediate  false 
send  ok    xi   pi   di   mi    to all xj in agent view 
update agent view with  xj   pj   dj   mj   
check agent view 
end do 
figure    procedures for receiving an apo session 

with one of its neighbors and is not expecting a session request from a higher priority
agent  the mediation starts with the mediator sending out evaluate  messages to each
of the agents in its good list  the purpose of this message is two fold  first  it informs
the receiving agent that a mediation is about to begin and tries to obtain a lock from that
agent  this lock  referred to as mediate in the figures  prevents the agent from engaging
in two sessions simultaneously or from doing a local value change during the course of a
session  the second purpose of the message is to obtain information from the agent about
the effects of making them change their local value  this is a key point  by obtaining this
information  the mediator gains information about variables and constraints outside of its
local view without having to directly and immediately link with those agents  this allows
the mediator to understand the greater impact of its decision and is also used to determine
how to extend its view once it makes its final decision 
when an agent receives a mediation request  it responds with either a wait  or
evaluate  message  the wait message indicates to the requester that the agent is
currently involved in a session or is expecting a request from an agent of higher priority
than the requester  which in fact could be itself  if the agent is available  it labels each of
its domain elements with the names of the agents that it would be in conflict with if it were
asked to take that value  this information is returned in the evaluate  message 
the size of the evaluate  message is strongly related to the number of variables and the
size of the agents domain  in cases where either of these are extremely large  a number of
techniques can be used to reduce the overall size of this message  some example techniques
   

fimailler   lesser

include standard message compression  limiting the domain elements that are returned to be
only ones that actually create conflict or simply sending relevant value variable pairs so the
mediator can actually do the labeling  this fact means that the largest evaluate  message
ever actually needed is polynomial in the number of agents  o v     in this implementation 
for graph coloring  the largest possible evaluate  message is o  d i      v    
it should be noted that the agents do not need to return all of the names when they
have privacy or security reasons  this effects the completeness of the algorithm  because
the completeness relies on one or more of the agents eventually centralizing the entire
problem in the worst case  as was mentioned in section      whenever an agent attempts to
completely hide information about a shared variable or constraint in a distributed problem 
the completeness is necessarily effected 
when the mediator has received either a wait  or evaluate  message from the agents
that it sent a request to  it chooses a solution  the mediator determines that it has received
all of the responses by using the counter variable which is set to the size of the good list
when the evaluate  messages are first sent  as the mediator receives either a wait  or
evaluate  message  it decrements this counter  when it reaches    all of the agents have
replied 
agents that sent a wait  message are dropped from the mediation while for agents
that sent an evaluate  message their labeled domains specified in the message are recorded
and used in the search process  the mediator then uses the current values along with the
labeled domains it has received in the evaluate  messages to conduct a centralized search 
currently  solutions are generated using a branch and bound search  freuder   wallace 
      where all of the constraints in the good list must be satisfied and the number of outside
conflicts are minimized  this is very similar to the the min conflict heuristic  minton 
johnston  philips    laird         notice that although this search takes all of the variables
and constraints in its good list into consideration  the solution it generates may not adhere
to the variable values of the agents that were dropped from the session  these variables are
actually considered outside of the session and the impact of not being able to change their
values is calculated as part of the min conflict heuristic  this causes the search to consider
the current values of dropped variables as weak constraints on the final solution 
in addition  the domain for each of the variables in the good list is ordered such that
the variables current value is its first element  this causes the search to use the current
value assignments as the first path in the search tree and has the tendency to minimize the
changes being made to the current assignments  these heuristics  when combined together 
form a lock and key mechanism that simultaneously exploits the work that was previously
done by other mediators and acts to minimize the number of changes in those assignments 
as will be presented in section    these simple feed forward mechanisms  combined with the
limited centralization needed to solve problems  account for considerable improvements in
the algorithms runtime performance 
if no satisfying assignments are found during this search  the mediator announces that
the problem is unsatisfiable and the algorithm terminates  once the solution is chosen 
accept  messages are sent to the agents in the session  who  in turn  adopt the proposed
answer 
the mediator also sends ok messages to the agents that are in its agent view  but for
whatever reason were not in the session  this simply keeps those agents agent views up   

fiasynchronous partial overlay  a new algorithm for dcsp

to date  which is important for determining if a solution has been reached  lastly  using the
information provided to it in the evaluate  messages  the mediator sends init messages
to any agent that is outside of its agent view  but it caused conflict for by choosing a
solution  this linking step extends the mediators view along paths that are likely to be
critical to solving the problem or identifying an over constrained condition  this step also
ensures the completeness of the protocol 
although termination detection is not explicitly part of the apo protocol  a technique
similar to  wellman   walsh        could easily be added to detect quiescence amongst
the agents 
      multiple variables and n ary constraints
removing the restrictions presented in section   is a fairly straightforward process  because
apo uses linking as part of the problem solving process  working with n ary constraints
simply involves linking with the n agents within the constraint during initialization and
when a post mediation linking needs to occur  priorities in this scheme are identical to
those used for binary constraints 
removing the single agent per variable restriction is also not very difficult and in fact is
one of the strengths of this approach  by using a spanning tree algorithm on initialization 
the agents can quickly identify the interdependencies between their internal variables which
they can then use to create separate good lists for each of the disconnected components
of their internal constraint graph  in essence  on startup  the agents would treat each
of these decomposed problems as a separate problem  using a separate m i flag  priority 
good list  etc  as the problem solving unfolds  and the agent discovers connections between
the internal variables  through external constraints   these decomposed problems could be
merged together and utilize a single structure for all of this information 
this technique has the advantages of being able to ensure consistency between dependent internal variables before attempting to mediate  because of the local checking before
mediation   but allows the agent to handle independent variables as separate problems 
using a situation aware technique such as this one has been shown to yield the best results
in previous work mammen   lesser         in addition  this technique allows the agents
to hide variables that are strictly internal  by doing pre computation on the decomposed
problems  the agents can construct constraints which encapsulate each of the subproblems
as n ary constraints where n is the number of variables that have external links  these derived constraints can then be sent as part of the init message whenever the agent receives
a link request for one of its external variables 
    an example
consider the   coloring problem presented in figure    in this problem  there are   agents 
each with a variable and    edges or constraints between them  because this is a   coloring
problem  each variable can only be assigned one of the three available colors  black  red 
or blue   the goal is to find an assignment of colors to the variables such that no two
variables  connected by an edge  have the same color 
in this example  four constraints are in violation   nd  nd     nd  nd     nd  nd   
and  nd  nd    following the algorithm  upon startup each agent adds itself to its
   

fimailler   lesser

figure    an example of a   coloring problem with   nodes and    edges 
good list and sends an init message to its neighbors  upon receiving these messages 
the agents add each of their neighbors to their good list because they are able to identify a
shared constraint with themselves 
once the startup has been completed  each of the agents checks its agent view  all of
the agents  except nd   find that they have conflicts  nd   priority    waits for nd  to
mediate  priority     nd  and nd   both priority    wait for nd   priority    tie with
nd  broken using lexicographical ordering   nd   having an equal number of agents in
its good list  but a lower lexicographical order  waits for nd  to start a mediation  nd  
knowing it is highest priority amongst its neighbors  first checks to see if it can resolve
its conflict by changing its value  which in this case  it cannot  nd  starts a session that
involves nd   nd   nd   and nd   it sends each of them an evaluate  message  nd 
being highest priority amongst its neighbors  and unable to resolve its conflict locally  also
starts a session by sending evaluate  messages to nd   nd   nd   and nd  
when each of the agents in the mediation receives the evaluate  message  they first
check to see if they are expecting a mediation from a higher priority agent  in this case 
nd   nd   and nd  are expecting from nd  so tell nd  to wait  then they label their
domain elements with the names of the variables that they would be in conflict with as
a result of adopting that value  this information is sent in an evaluate  message  the
following are the labeled domains for the agents that are sent to nd  
 nd    black causes no conflicts  red conflicts with nd  and nd   blue conflicts with
nd  and nd 
 nd    black causes no conflicts  red conflicts with nd  and nd   blue conflicts with
nd 
 nd    black conflicts with nd   red conflicts with nd   blue conflicts with nd 
 nd    black conflicts with nd   red conflicts with nd   blue conflicts with nd 

   

fiasynchronous partial overlay  a new algorithm for dcsp

figure    the state of the sample problem after nd  leads the first mediation 
the following are the responses sent to nd  
 nd    wait 
 nd    black causes no conflicts  red conflicts with nd   blue causes no conflicts
 nd    wait 
 nd    wait 
once all of the responses are received  the mediators  nd  and nd   conduct a branch
and bound searches that attempt to find a satisfying assignment to their subproblems and
minimizes the amount of conflict that would be created outside of the mediation  if either
of them cannot find at least one satisfying assignment  it broadcasts that a solution cannot
be found 
in this example  nd   with the limited information that it has  computes a satisfying
solution that changes its own color and to remain consistent would have also changed the
colors of nd  and nd   since it was told by nd  and nd  to wait  it changes its color 
sends an accept   message to nd  and ok  messages to nd   nd  and nd   having
more information  nd  finds a solution that it thinks will solve its subproblem without
creating outside conflicts  it changes its own color to red  nd  to blue  and nd  to black
leaving the problem in the state shown in figure   
nd   nd   nd   nd  and nd  inform the agents in their agent view of their new
values  then check for conflicts  this time  nd   nd   and nd  notice that their values are
in conflict  nd   having the highest priority  becomes the mediator and mediates a session
with nd   nd   nd   and nd   following the protocol  nd  sends out the evaluate 
messages and the receiving agents label and respond  the following are the labeled domains
that are returned 
 nd    black conflicts with nd   red conflicts with nd  and nd   blue conflicts with
nd 
   

fimailler   lesser

figure    the final solution after nd  leads the second mediation 
 nd    black conflicts with nd   red causes no conflicts  blue causes no conflicts
 nd    black conflicts with nd   red conflicts with nd   blue conflicts with nd 
 nd    black conflicts with nd  and nd   red conflicts with nd   blue causes no
conflicts
nd   after receiving these messages  conducts its search and finds a solution that solves
its subproblem  it chooses to change its color to red  nd   nd   nd   nd   and nd 
check their agent view and find no conflicts  since  at this point  none of the agents have
any conflict  the problem is solved  see figure    
    soundness and completeness
in this section we will show that the apo algorithm is both sound and complete  for these
proofs  it is assumed that all communications are reliable  meaning that if a message is sent
from xi to xj that xj will receive the message in a finite amount of time  we also assume
that if xi sends message m  and then sends message m  to xj   that m  will be received
before m    lastly  we assume that the centralized solver used by the algorithm is sound and
complete  before we prove the soundness and completeness  it helps to have a few principal
lemmas established 
lemma   links are bidirectional  i e  if xi has xj in its agent view then eventually xj
will have xi in its agent view 
proof 
assume that xi has xj in its agent view and that xi is not in the agent view of xj   in
order for xi to have xj in its agent view  xi must have received an init message at some
point from xj   there are two cases 
case    xj is in the initlist of xi   in this case  xi must have sent xj an init message
first  meaning that xj received an init message and therefore has xi in its agent view  a
contradiction 
   

fiasynchronous partial overlay  a new algorithm for dcsp

case    xj is not in the initlist of xi   in this case  when xi receives the init message
from xj   it responds with an init message  that means that if the reliable communication
assumption holds  eventually xj will receive xi s init message and add xi to its agent view 
also a contradiction 
lemma   if agent xi is linked to xj and xj changes its value  then xi will eventually be
informed of this change and update its agent view 
proof 
assume that xi has a value in its agent view for xj that is incorrect  this would mean
that at some point xj altered its value without informing xi   there are two cases 
case    xj did not know it needed to send xi an update  i e  xi was not in xj s
agent view  contradicts lemma   
case    xj did not inform all of the agents in its agent view when it changes its value 
it is clear from the code that this cannot happen  agents only change their values in the
check agent view  choose solution  and accept  procedures  in each of these cases  it informs
all of the agents within its agent view by either sending an ok  or through the accept 
message that a change to its value has occurred  a contradiction 
lemma   if xi is in conflict with one or more of its neighbors  does not expect a mediation
from another higher priority agent in its agent view  and is currently not in a session  then
it will act as mediator 
proof 
directly from the procedure check agent view 
lemma   if xi mediates a session that has a solution  then each of the constraints between
the agents involved in the mediation will be satisfied 
proof 
assume that there are two agents xj and xk  either of them could be xi    that were
mediated over by xi and after the mediation there is a conflict between xj and xk   there
are two ways this could have happened 
case    one or both of the agents must have a value that xi did not assign to it as
part of the mediation 
assume that xj and or xk has a value that xi did not assign  we know that since xi
mediated a session including xj and xk   that xi did not receive a wait  message from
either of xj or xk   this means that they could not have been mediating  this also means
that they must have set their mediate flags to true when xi sent them the evaluate 
message  since the only times an agent can change its value is when its mediate flag is
false  it is mediating  or has been told to by a mediator  xj and or xk could only have
changed their values is if xi told them to  which contradicts the assumption 
case    xi assigned them a value that caused them to be in conflict with one another 
lets assume that xi assigned them conflicting values  this means that xi chose a
solution that did not take into account the constraints between xj and xk   but  we know
that xi only chooses satisfying solutions that include all of the constraints between all of
the agents in the good list  this leads to a contradiction 
   

fimailler   lesser

this lemma is important because it says that once a mediator has successfully concluded
its session  the only conflicts that can exist are on constraints that were outside of the
mediation  this can be viewed as the mediator pushing the constraint violations outside
of its view  in addition  because mediators get information about who the violations are
being pushed to and establish links with those agents  over time  they gain more context 
this is a very important point when considering the completeness of the algorithm 
theorem   the apo algorithm is sound  i e  it reaches a stable state only if it has either
found an answer or no solution exists 
proof 
in order to be sound  the agents can only stop when they have reached an answer  the
only condition in which they would stop without having found an answer is if one or more
of the agents is expecting a mediation request from a higher priority agent that does not
send it  in other words  the protocol has deadlocked 
lets say we have   agents  xi   xj   and xk with pi   pj  pk   pj  i could be equal to k 
and xk has a conflict with xj   there are two cases in which xj would not mediate a session
that included xi   when xi was expecting it to 
case    xi has mj   true in its agent view when the actual value should be false 
assume that xi has mj   true in its agent view when the true value of mj   false 
this would mean that at some point xj changed the value of mj to false without informing
xi   there is only one place that xj changes the value of mj   this is in the check agent view
procedure  see figure     note that in this procedure  whenever the flag changes value from
true to false  the agent sends an ok message to all the agents in its agent view  since
by lemma   we know that xi is in the agent view of xj   xi must have received the message
saying that mj   false  contradicting the assumption 
case    xj believes that xi should be mediating when xi does not believe it should be 
i e  xj thinks that mi   true and pi   pj  
by the previous case  we know that if xj believes that mi   true that this must be the
case  we only need to show that pi   pj   lets say that p i is the priority that xj believes
xi has and assume that xj believes that p i   pj when  in fact pi   pj   this means that at
some point xi sent a message to xj informing it that its current priority was p i   since we
know that priorities only increase over time  the good list only gets larger   we know that
p i  pi  xj always has the correct value or underestimates the priority of xi    since pj   pi
and pi  p i then pj   p i which contradicts the assumption 
this is also an important point when considering how the algorithm behaves  this proof
says that agents always either know or underestimate the true value of their neighbors
priorities  because of this  the agents will attempt to mediate when in fact sometimes 
they shouldnt  the side effect of this attempt  however  is that the correct priorities are
exchanged so the same mistake doesnt get repeated  the other important thing to mention
is the case were the priority values become equal  in this case  the tie is broken by using
the alphabetical order of names of the agents  this ensures that there is always a way to
break ties 
definition   oscillation is a condition that occurs when a subset v    v of the agents are
infinitely cycling through their allowable values without reaching a solution  in other words 
the agents are live locked
   

fiasynchronous partial overlay  a new algorithm for dcsp

by this definition  in order to be considered part of an oscillation  an agent within the
subset must be changing its value  if its stable  its not oscillating  and it must be connected
to the other members of the subset by a constraint  otherwise  it is not actually a part of
the oscillation  
theorem   the apo algorithm is complete  i e  if a solution exists  the algorithm will
find it  if a solution does not exist  it it will report that fact 
proof 
a solution does not exist whenever the problem is over constrained  if the problem
is over constrained  the algorithm will eventually produce a good list where the variables
within it and their associated constraints lead to no solution  since a subset of the variables
is unsatisfiable  the entire problem is unsatisfiable  therefore  no solution is possible  the
algorithm terminates with failure if and only if this condition is reached 
since we have now shown in theorem   that whenever the algorithm reaches a stable
state  the problem is solved and that when it finds a subset of the variables that is unsatisfiable it terminates  we only need to show that it reaches one of these two states in finite
time  the only way for the agents to not reach a stable state is when one or more of the
agents in the system is in an oscillation 
there are two cases to consider  the easy case is when a single agent is oscillating
  v          and the other case is when more than one agent is oscillating   v          
case    there is an agent xi that is caught in an infinite loop and all other agents are
stable 
lets assume that xi is in an infinite processing loop  that means that no matter what
it changes its value to  it is in conflict with one of its neighbors  because if it changed its
value to something that doesnt conflict with its neighbors  it would have a solution and
stop  if it changes its value to be in conflict with some xj that is higher priority than it 
then xj will mediate with xi   contradicting the assumption that all other agents are stable 
if xi changes its value to be in conflict with a lower priority agent  then by lemma    it will
act as mediator with its neighbors  since it was assumed that each of the other agents is
in a stable state  then all of the agents in xi s good list will participate in the session and
by lemma    agent xi will have all of its conflicts removed  this means that xi will be in a
stable state contradicting the assumption that it was in an infinite loop 
case    two or more agents are in an oscillation 
lets say we have a set of agents v    v that are in an oscillation  now consider an
agent xi that is within v     we know that the only conditions in which xi changes its value
is when it can do so and solve all of its conflicts  a contradiction because x i wouldnt be
considered part of the oscillation   as the mediator  or as the receiver of a mediation from
some other agent in v     the interesting case is when an agent acts as the mediator 
consider the case when xi is the mediator and call the set of agents that it is mediating
over vi   we know according to definition   that after the mediation  that at least one
conflict must be created or remain otherwise the oscillation would stop and the problem
would be solved  in fact  we know that each of the remaining conflicts must contain an
agent from the set v    vi by lemma    we also know that for each violated constraint that
has a member from vi   that xi will link with any agent that is part of those constraints and
   

fimailler   lesser

not a member of vi   the next time xi mediates  the set vi will include these members and
the number of agents in the set v    vi is reduced  in fact  whenever xi mediates the set
v    vi will be reduced  assuming it is not told to wait  by one or more agents  in this
case  it takes longer to reduce this set  but the proof still holds   eventually  after o  v      
mediations  some xi within v   must have vi   v    every agent within the set must have
mediated  v     times in order for this to happen   when this agent mediates it will push the
violations outside of the set v   or it will solve the subproblem by lemma    either of these
conditions contradicts the oscillation assumption  therefore  the algorithm is complete 
qed
it should be fairly clear that  in domains that are exponential  the algorithms worsecase runtime is exponential  the space complexity of the algorithm is  however  polynomial 
because the agents only retain the names  priorities  values  and constraints of other agents 

   evaluation
a great deal of testing and evaluation has been conducted on the apo algorithm  almost
exclusively  these test are done comparing the apo algorithm with the currently fastest
known  complete algorithm for solving dcsps called the asynchronous weak commitment
 awc  protocol  in this section we will describe the awc protocol  section       then will
describe the distributed   coloring domain and present results from extensive testing done
in this domain  section       this testing compares these two algorithms across a variety
of metrics  including the cycle time  number of messages  and serial runtime 
next  we will describe the tracking domain  section      and present results from testing
in this domain as well  for this domain  we modified the core search algorithm of apo to
take advantage of the polynomial complexity of this problem  this variant called  apoflow  will also be described 
    the asynchronous weak commitment  awc  protocol
the awc protocol  yokoo        was one of the first algorithms used for solving dcsps 
like the apo algorithm  awc is based on variable decomposition  also  like apo  awc
assigns each agent a priority value that dynamically changes  awc  however  uses the
weak commitment heuristic  yokoo        to assign these priorities values which is where
it gets its name 
upon startup  each of the agents selects a value for its variable and sends ok  messages
to its neighbors  agents it shares a constraint with   this message includes the variables
value and priority  they all start at    
when an agent receives an ok  message  it updates its agent view and checks its
nogood list for violated nogoods  each nogood is composed of a set of nogood pairs which
describe the combination of agents and values that lead to an unsatisfiable condition  initially  the only nogoods in an agents nogood list are the constraints on its variable 
when checking its nogood list  agents only check for violations of higher priority nogoods  the priority of a nogood is defined as the priority of the lowest priority variable in
the nogood  if this value is greater than the priority of the agents variable  the nogood is
higher priority  based on the results from this check  one of three things can happen 
   

fiasynchronous partial overlay  a new algorithm for dcsp

   if no higher priority nogoods are violated  the agent does nothing 
   if there are higher priority nogoods that are violated and this can be repaired by
simply changing the agents variable value  then the agent changes its value and sends
out ok  messages to the agents in its agent view  if there are multiple possible
satisfying values  then the agent chooses the one that minimizes the number of violated
lower priority nogoods 
   if there are violated higher priority nogoods and this cannot be repaired by changing
the value of its variable  the agent generates a new nogood  if this nogood is the
same as a previously generated nogood  it does nothing  otherwise  it then sends this
new nogood to every agent that has a variable contained in the nogood and raises the
priority value of its variable  finally  it changes its variable value to one that causes
the least amount of conflict and sends out ok  messages 
upon receiving a nogood message from another agent  the agent adds the nogood to
its nogood list and rechecks for nogood violations  if the new nogood includes the names
of agents that are not in its agent view it links to them  this linking step is essential to
the completeness of the search yokoo et al          but causes the agents to communicate
nogoods and ok  messages to agents that are not their direct neighbors in the constraint
graph  the overall effect is an increase in messages and a reduction in the amount of
privacy being provided to the agents because they communicate potential domain values
and information about their constraints through the exchange of ok  and nogood messages
with a larger number of agents 
one of the more recent advances to the awc protocol has been the addition of resolventbased nogood learning  hirayama   yokoo        which is an adaptation of classical nogood
learning methods  ginsberg        cha   iwana        frost   dechter        
the resolvent method is used whenever an agent finds that it needs to generate a new
nogood  agents only generate new nogoods when each of their domain values are in violation
with at least one higher priority nogood already in their nogood list  the resolvent method
works by selecting one of these higher priority nogoods for each of the domain values and
aggregating them together into a new nogood  this is almost identical to a resolvent in
propositional logic which is why it is referred to as resolvent based learning  the awc
protocol used for all of our testing incorporates resolvent based nogood learning 
    distributed graph coloring
following directly from the definition for a csp  a graph coloring problem  also known as
a k colorability problem  consists of the following 
 a set of n variables v    x            xn   
 a set of possible colors for each of the variables d    d            dn   where each di is
has exactly k allowable colors 
 a set of constraints r    r            rm   where each ri  di   dj   is predicate which implements the not equals relationship  this predicate returns true iff the value assigned
to xi differs from the value assigned to xj  
   

fimailler   lesser

   

apo
awc

cycles

  

  

  

  

 
  

  

  

  

  

  

  

  

  

   

variables

figure     comparison of the number of cycles needed to solve satisfiable  low density  coloring problems of various sizes by awc and apo 

the problem is to find an assignment a    d            dn  di  di   such that each of the
constraints in r is satisfied  like the general csp  graph coloring has been shown to be
np complete for all values of k     
to test the apo algorithm  we implemented the awc and apo algorithms and conducted experiments in the distributed   coloring domain  the distributed   coloring problem is a   coloring problem with n variables and m binary constraints where each agent is
given a single variable  we conducted   sets of graph coloring based experiments to compare
the algorithms computation and communication costs 
      satisfiable graphs
in the first set of experiments  we created solvable graph instances with m      n  lowdensity   m      n  medium density   and m      n  high density  according to the method
presented in  minton et al          generating graphs in this way involves partitioning the
variables into k equal sized groups  edges are then added by selecting two of the groups at
random and adding an edge between a random member of each group  this method ensures
that the resulting graphs are satisfiable  but also tests a very limited and very likely easier
subset of the possible graphs  these tests were done because they are traditionally used by
other researchers in dcsps 
these particular values for m were chosen because they represent the three major regions
within the phase transition for   colorability  culberson   gent         a phase transition
in a csp is defined based on an order parameter  in this case the average node degree
d  the transition occurs at the point where random graphs created with that order value
yield half satisfiable and half unsatisfiable instances  values of the order parameter that are
   

fiasynchronous partial overlay  a new algorithm for dcsp

   

apo
awc

cycles

   

   

  

 
  

  

  

  

  

  

  

  

  

   

variables

figure     comparison of the number of cycles needed to solve satisfiable  medium density
  coloring problems of various sizes by awc and apo 

lower than the transition point  more than     of the instance are satisfiable  are referred
to being to the left of the transition  the opposite is true of values to the right 
phase transitions are important because that are strongly correlated with the overall difficulty of finding a solution to the graph  cheeseman  kanefsky    taylor        monasson 
zecchina  kirkpatrick  selman    troyansky        culberson   gent         within the
phase transition  randomly created instances are typically difficult to solve  interestingly 
problems to the right and left of the phase transitions tend to be much easier 
in   colorability  the value d       is to the left of the phase transition  in this region 
randomly created graphs are very likely to be satisfiable and are usually easy to find solve 
at d        which is in the middle of the phase transition the graph has about a     chance
of being satisfiable and is usually hard to solve  for m      n  right of the phase transition 
graphs are more than likely to be unsatisfiable and  again  are also easier to solve 
a number of papers  yokoo   hirayama              hirayama   yokoo        have
reported that m      n is within the critical phase transition for   colorability  this seems
to have been caused by a misinterpretation of previous work in this area cheeseman et al  
       although cheeseman  kanefsky  and taylor reported that m      n was within the
critical region for   colorability  they were using reduced graphs for their analysis 
a reduced graph is one in which the trivially colorable nodes and non relevant edges
have been removed  for example  one can easily remove any node with just two edges in
a   coloring problem because it can always be trivially colored  additionally  nodes that
possess a unique domain element from their neighbors can also be easily removed 
in later work  culberson and gent identified the critical region as being approximately
d       and therefore was included in our tests culberson   gent         one should note 
however  that because phase transitions are typically done on completely random graphs
   

fimailler   lesser

d

   

   

   

nodes
  
  
  
  
  
  
overall
  
  
  
  
  
  
overall
  
  
  
  
  
  
overall

apo
mean
     
     
     
     
     
     

apo
stdev
    
     
     
     
     
     

awc
mean
     
     
     
     
     
     

awc
stdev
     
     
     
     
      
     

     
     
     
     
      
      

    
     
     
     
     
      

     
     
      
      
      
      

     
     
     
      
      
     

     
     
     
     
     
     

    
     
     
     
     
     

     
     
     
     
      
      

     
     
     
     
     
     

p aw c  ap o 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    comparison of the number of cycles needed to solve satisfiable   coloring problems
of various sizes and densities by awc and apo 

   

fiasynchronous partial overlay  a new algorithm for dcsp

apo

   

awc
   

cycles

   
  
  
  
  
 
  

  

  

  

  

  

  

  

  

   

variables

figure     comparison of the number of cycles needed to solve satisfiable  high density
  coloring problems of various sizes by awc and apo 

and by its very definition involves both satisfiable and unsatisfiable instances  it is very
hard to apply the phase tranisition results to graphs created using the technique described
at the beginning of the section because it only generates satisfiable instances  a detailed
phase transition analysis has not been done on this graph generation technique and in fact 
we believe that these graphs tend to be easier than randomly created satisfiable ones of the
same size and order 
to evaluate the relative strengths and weakness of each of the approaches  we measured
the number of cycles and the number of messages used during the course of solving each
of the problems  during a cycle  incoming messages are delivered  the agent is allowed
to process the information  and any messages that were created during the processing are
added to the outgoing queue to be delivered at the beginning of the next cycle  the actual
execution time given to one agent during a cycle varies according to the amount of work
needed to process all of the incoming messages  the random seeds used to create each
graph instance and variable instantiation were saved and used by each of the algorithms for
fairness 
for this comparison between awc and apo  we randomly generated    graphs of size
n                          and m      n     n     n and for each instance generated    initial
variable assignments  therefore  for each combination of n and m  we ran     trials making
a total of      trials  the results from this experiment can be seen in figures    through   
and table    we should mention that the results of the testing on awc obtained from these
experiments agree with previous results  hirayama   yokoo        verifying the correctness
of our implementation 
at first glance  figure    appears to indicate that for satisfiable low density graph instances  awc and apo perform almost identically in terms of cycles to completion  look   

fimailler   lesser

apo

awc

nodes
  
  
  
  
  
  
  
  
  
  
  
  

  links
mean
     
     
     
    
    
    
     
     
     
     
     
     

  links
stdev
    
    
    
    
    
    
     
    
    
    
    
    

  central
mean
     
     
     
     
     
     
     
     
     
     
     
     

  central
stdev
    
    
    
    
    
    
     
     
     
     
     
     

table    link statistics for satisfiable  low density problems 

apo

awc

nodes
  
  
  
  
  
  
  
  
  
  
  
  

  links
mean
     
     
     
     
     
     
     
     
     
     
     
     

  links
stdev
    
    
    
    
    
    
     
     
     
     
     
     

  central
mean
     
     
     
     
     
     
     
     
     
     
     
     

  central
stdev
    
    
     
     
     
     
    
     
     
     
     
     

table    link statistics for satisfiable  medium density problems 

   

fiasynchronous partial overlay  a new algorithm for dcsp

apo

awc

nodes
  
  
  
  
  
  
  
  
  
  
  
  

  links
mean
     
     
     
     
     
     
     
     
     
     
     
     

  links
stdev
    
    
    
    
    
    
     
     
     
     
     
     

  central
mean
     
     
     
     
     
     
     
     
     
     
     
     

  central
stdev
    
    
     
     
     
     
    
    
     
     
    
     

table    link statistics for satisfiable  high density problems 
ing at the associated table  table     however  reveals that overall  the pairwise t test
indicates that with     confidence  apo outperforms awc on these graphs 
as the density  or average degree  of the graph increases  the difference becomes more
apparent  figures    and    show that apo begins to scale much more efficiently than
awc  this can be attributed to the ability of apo to rapidly identify strong interdependencies between variables and to derive solutions to them using a centralized search of the
partial subproblem 
tables   through    partially verify this statement  as you can see  on average  less than
    of the possible number of links  n   n      are used by apo in solving problems   
links column   in addition  the maximum amount of centralization    central column 
occuring within any single agent  i e  the number of agents in its agent view  remains fairly
low  the highest degree of centralization occurs for small  high density graphs  intuitively 
this makes a lot of sense because in these graphs  a single node is likely to have a high
degree from the very start  combine this fact with the dynamic priority ordering and the
result is large amounts of central problem solving 
the most profound differences in the algorithms can be seen in figures         and    and
table    apo uses at least an order of magnitude less messages than awc  table   shows
that these message savings lead to large savings in the number of bytes being transmitted as
well  even though apo uses about twice as many bytes per message as awc  the messages
were not optimized at all   the total amount of information be passed around is significantly
less in almost every case 
again  looking at the linking structure that awc produces gives some insights into why
it uses some many more messages than apo  because agents communicate with all of the
agents they are linked to whenever their value changes  and a large number of changes can
occur in single cycle  awc can have a tremendous amount of thrashing behavior  apo 
on the other hand  avoids this problem because the process of mediating implicitly creates
   

fimailler   lesser

d

   

   

   

nodes
  
  
  
  
  
  
overall
  
  
  
  
  
  
overall
  
  
  
  
  
  
overall

apo
mean
      
       
       
       
       
       

apo
stdev
      
      
       
       
       
       

awc
mean
      
       
       
        
        
        

awc
stdev
      
       
       
        
        
        

      
       
       
       
        
        

      
      
       
       
        
        

       
       
        
        
         
         

      
       
        
        
         
         

      
       
       
       
       
        

      
      
       
       
       
        

       
       
        
        
         
         

       
       
        
        
        
         

p aw c  ap o 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    comparison of the number of messages needed to solve satisfiable   coloring problems of various sizes and densities by awc and apo 

   

fiasynchronous partial overlay  a new algorithm for dcsp

d

   

   

   

nodes
  
  
  
  
  
  
overall
  
  
  
  
  
  
overall
  
  
  
  
  
  
overall

apo
mean
        
        
        
        
         
         

apo
stdev
       
        
        
        
        
         

awc
mean
        
        
        
         
         
         

awc
stdev
        
        
         
         
         
         

        
        
        
         
         
         

       
        
        
         
         
         

        
        
         
          
          
          

        
         
         
          
          
          

        
        
         
         
         
         

       
        
        
        
         
         

        
         
         
         
          
          

        
         
         
         
          
          

p aw c  ap o 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table    comparison of the number of bytes transmitted by apo and awc for satisfiable
graph instances of various sizes and density 

   

fimailler   lesser

     

apo
awc

     

messages

     
     
     
     
    
 
  

  

  

  

  

  

  

  

  

   

variables

figure     comparison of the number of messages needed to solve satisfiable  low density
  coloring problems of various sizes by awc and apo 

      

apo
awc

messages

      

      

      

     

 
  

  

  

  

  

  

  

  

  

   

variables

figure     comparison of the number of messages needed to solve satisfiable  mediumdensity   coloring problems of various sizes by awc and apo 

regions of stability in the problem landscape while the mediator decides on a solution  in
addition  because apo uses partial centralization to solve problems  it avoids having to use
a large number of messages to discover implied constraints through trial and error 
   

fiasynchronous partial overlay  a new algorithm for dcsp

      

apo
awc

messages

      

      

     

 
  

  

  

  

  

  

  

  

  

   

variables

figure     comparison of the number of messages needed to solve satisfiable  high density
  coloring problems of various sizes by awc and apo 

  satisfiable

 
   
   
   
   
 
   

 

   

   

   

   

density

figure     phase transition curve for the    node randomly generated graphs used in testing 

as we will see in the next two experiments  the high degree of centralization caused
by its unfocused linking degrades awcs performance even more when solving randomly
generated  possibly unsatisfiable  graph instances 
   

fimailler   lesser

   

apo

   

awc

cycles

   
   
   
   
   
   
 
   

 

   

   

   

   

density

figure     number of cycles needed to solve completely random    variable problems of
various density using awc and apo 

density
   
   
   
   
   
   
   
overall

apo
mean
     
     
      
      
     
     
     

apo
stdev
     
     
      
      
     
     
     

  apo
solved
   
   
   
   
   
   
   

awc
mean
     
      
      
      
      
      
      

awc
stdev
     
      
      
      
      
      
      

  awc
solved
   
  
  
  
  
  
  

p aw c  ap o 
    
    
    
    
    
    
    
    

table    number of cycles needed to solve completely random    variable problems of
various density using awc and apo 

   

fiasynchronous partial overlay  a new algorithm for dcsp

   e   

apo
awc

   e   

messages

 e   
      
      
      
      
 
   

 

   

   

   

   

density

figure     number of messages needed to solve completely random    variable problems of
various density using awc and apo 

      random graphs
in the second set of experiments  we generated completely random    node graphs with
average degrees from d       to      this series was conducted to test the completeness of
the algorithms  verify the correctness of their implementations  and to study the effects of
the phase transition on their performance  for each value of d  we generated     random
graphs each with a single set of initial values  graphs were generate by randomly choosing
two nodes and connecting them  if the edge already existed  another pair was chosen  the
phase transition curve for these instances can be seen in figure    
in total       graphs were generated and tested  due to time constraints  we stopped
the execution of awc once      cycles had completed  apo never reached        the
results of these experiments are shown in figures    and    and tables   and   
on these graphs  apo significantly outperforms awc on all but the simplest problems
 see figure      these results can most directly be attributed to awcs poor performance
on unsatisfiable problem instances  fernandez et al          in fact  in the region of the
phase transition  awc was unable to complete     of the graphs within the      cycles 
in addition  to solve these problems  awc uses at least an order of magnitude more
messages that apo  these results can be seen in figure     by looking at table    it is easy
to see why this occurs  awc has a very high degree of linking and centralization  in fact 
on d       graphs  awc reaches an average of     centralization and     of complete
inter agent linking 
to contrast this  apo has very loose linking throughout the entire phase transition and
centralizes on average around     of the entire problem  these results are very encouraging and reinforce the idea that partial overlays and extending along critical paths yields
improvements in the convergence on solutions 
   

fimailler   lesser

density
   
   
   
   
   
   
   
overall

apo
mean
       
       
        
        
       
       
       

apo
stdev
       
       
        
        
       
       
       

awc
mean
        
         
         
         
          
          
          

awc
stdev
        
         
         
         
         
         
         

p aw c  ap o 
    
    
    
    
    
    
    
    

table    number of messages needed to solve completely random    variable problems of
various density using awc and apo 

apo

awc

density
   
   
   
   
   
   
   
   
   
   
   
   
   
   

  links
mean
    
     
     
     
     
     
     
     
     
     
     
     
     
     

  links
stdev
    
    
    
    
    
    
    
    
     
     
     
     
     
    

  central
mean
     
     
     
     
     
     
     
     
     
     
     
     
     
     

  central
stdev
    
     
     
     
     
     
     
     
     
     
    
    
    
    

table    link statistics for    node random problems 
      runtime tests
in the third set of experiments  we directly compared the serial runtime performance of
awc against apo  serial runtime is measured using the following formula 

serialtime  

cycles
x

x

i   aagents

   

time a  i 

fiseconds

asynchronous partial overlay  a new algorithm for dcsp

     
     
    
    
    
    
    
   
   
   
   
  
  
  
  

apo
awc
backtracking

  

  

  

  

  

  

nodes

seconds

figure     comparison of the number of seconds needed to solve random  low density  coloring problems of various sizes by awc  apo  and centralized backtracking 

     
     
     
     
    
    
    
    
   
   
   
   
  
  
  
  

apo
awc
backtracking

  

  

  

  

  

  

nodes

figure     comparison of the number of seconds needed to solve random  medium density
  coloring problems of various sizes by awc  apo  and centralized backtracking 

   

fiseconds

mailler   lesser

    
    
    
    
   
   
   
   
   
  
  
  
  

apo
awc
backtracking

  

  

  

  

  

  

nodes

figure     comparison of the number of seconds needed to solve random  high density  coloring problems of various sizes by awc  apo  and centralized backtracking 

d
   

   

   

nodes
  
  
  
  
  
  
  
  
  
  
  
  

apo
mean
    
    
    
    
    
    
    
     
    
    
    
    

apo
stdev
    
    
    
    
    
    
    
     
    
    
    
    

awc
mean
    
     
      
      
    
      
       
        
    
     
      
       

awc
stdev
    
     
       
       
    
      
       
        
    
     
      
       

bt
mean
    
    
      
        
    
    
      
        
    
    
     
       

bt
stdev
    
    
      
        
    
    
      
         
    
    
     
       

table     comparison of the number of seconds needed to solve random   coloring problems
of various sizes and densities using awc  apo  and centralized backtracking 

   

fiasynchronous partial overlay  a new algorithm for dcsp

which is just the total accumulated runtime needed to solve the problem when only one
agent is allowed to process at a time 
for these experiments  we again generated random graphs  this time varying the size
and the density of the graph  we generated    graphs for the values of n                  and
the densities of d                  for a total of     test cases  to show that the performance
difference in apo and awc was not caused by the speed of the central solver  we ran a
centralized backtracking algorithm on the same graph instances  although  apo uses the
branch and bound algorithm  the backtracking algorithm used in this test provides a best
case lower bound on the runtime of apos internal solver 
each of the programs used in this test was run on an identical    ghz pentium   with
    mbytes of ram  these machines where entirely dedicated to the tests so there was a
minimal amount of interference by competing processes  in addition  no computational cost
was assigned to message passing because the simulator passes messages between cycles  the
algorithms were  however  penalized for the amount of time they took to process messages 
although we realize that the specific implementation of an algorithm can greatly effect its
runtime performance  every possible effort was made to optimize the awc implementation
used for these experiments in an effort to be fair 
the results of this test series can be seen in figures         and     you should note
that the scale used for these graphs is logarithmic  from looking at these results  two
things should become apparent  obviously  the first is that apo outperforms awc in
every case  second  apo actually outperforms its own centralized solver on graphs larger
than    nodes  this indicates two things  first  the solver that is currently in apo is
very poor and second that apos runtime performance is not a direct result of the speed of
centralized solver that it is using  in fact  these tests show that the improved performance
of apo over awc is caused by apos ability to take advantage of the problems structure 
if we were to replace the centralized solver used in these tests with a state of the art
solver  we would expect two things  the first is that we would expect the serial runtime of
the apo algorithm to decrease simply from the speedup caused by the centralized solver 
the second  and more importantly  is that the centralized solver would always outperform
apo  this is because current csp solvers take advantage of problem structure unlike the
solver used in these tests  we are in no way making a claim that apo improves any
centralized solver  we are simply stating that apo outperforms awc for reasons other
than the speed of its current internal solver 
    tracking domain
to test apos adaptability to various centralized solvers  we created an implementation
of the complete compatibility version of the sensordcsp formulation  bejar et al        
krishnamachari  bejar    wicker        fernandez et al          in this domain  there
are a number of sensors and a number of targets randomly placed within an environment 
because of range restrictions  only sensors that are within some distance dist can see a
target  the goal is to find an assignment of sensors to targets such that each target has
three sensors tracking it 
following directly from the definition for a csp  a sensordcsp problem consists of the
following 
   

fimailler   lesser

figure     an example of a tracking problem  there are    targets  labeled with their
name  and     sensors  black dots   lines connecting sensors and targets indicate that the sensor is assigned to tracking the target 

   

fiasynchronous partial overlay  a new algorithm for dcsp

 a set of n targets t    t            tn   
 a set of possible sensors that can see each of the targets d    d             dn   
 a set of constraints r    r            rm   where each ri  ai   aj   is predicate which implements the not intersects relationship  this predicate returns true iff the sensors
assigned to ti does not have any elements in common with the sensors assigned to tj  
the problem is to find an assignment a    a            an   such that each of the constraints
in r is satisfied and each ai is a set of  dci   sensors from di where c   min  di        this
indicates that each target requires   sensors  if enough are available  or all of the sensors  if
there are less than   
since  in this implementation  each of the sensors is compatible with one another  the
overall complexity of the problem is polynomial  using a reduction to feasible flow in a
bipartite graph krishnamachari         because of this  the centralized solver used by
the apo agents was changed to a modified version of the ford fulkerson maximum flow
algorithm  ford   fulkerson        cormen  leiserson    rivest         which has been
proven to run in polynomial time 
an example of the tracking problem can be seen in figure     in this example  there
are     sensors  black dots  placed in an ordered pattern in the environment  there are
   targets  labeled with their names  which are randomly placed at startup  the lines
connecting sensors to targets indicate that the sensor is assigned to the target  note that
this instance of the problem is satisfiable 
      modifying apo for the tracking domain
because the tracking domain is so closely related to the general csp formulation  very few
changes were made to either awc or apo for these tests  we did  however  decide to test
the adaptability of apo to a new centralized problem solver  to do this  we changed the
centralized problem solver to the ford fulkerson max flow algorithm in figure     fordfulkerson works by repeatedly finding paths with remaining capacity through the residual
flow network and augmenting the flows along those paths  the algorithm terminates when
no additional paths can be found  a detailed explanation of the algorithm as well as a proof
of its optimality can be found in  cormen et al         
like mapping bipartite graphs into max flow  the sensordcsp problem is also easily
mapped into max flow  in figures    and    you can see the mapping of a simple sensor
allocation problem into a max flow problem  notice that the capacity of the flow between
the sensors and targets is    this ensures that a sensor cannot be used by more than a
single target  also  notice that the capacity of the targets to t is    in fact  this value is to
min  di       
to use this algorithm within apo  the mediator simply translates the problem into
a network flow graph g using the following rules whenever it runs the choose solution
procedure in figure   
   add the nodes s and t to g 
   for each ti  t add a node ti and an edge  ti   t  with capacity min  di       to g 
   

fimailler   lesser

ford fulkerson  g  s  t 
for each edge  u  v   e g  do
f  u  v     
f  v  u     
end do 
while there exists a path p from s to t
in the residual network gf do
cf  p   min cf  u  v     u  v   p  
for each edge  u  v   p do
f  u  v   f  u  v    cf  p  
f  v  u   f  u  v  
end do 
end do 
end ford fulkerson 
figure     the ford fulkerson maximum flow algorithm 

s 

s 

t 

s 

s 
t 
s 

s 

figure     a simple sensor to target allocation problem 
   for each unique sensor si in the domains of ti  t   add a node si   an edge  s  si  
with capacity    and an edge  si   ti   with capacity   to g 

   

fiasynchronous partial overlay  a new algorithm for dcsp

s 
 

 
s 

 
 

s 

 
 
 

t 

 

s

t
 

 
 

s 
 
s 

 
 

t 

 
s 

figure     the flow network for the simple target allocation problem in figure    
it then executes the ford fulkerson algorithm  once the algorithm finishes  the mediator
checks the residual capacity of the edges between the targets and t  if any of these edges has
residual flow  then the problem is unsatisfiable  otherwise  the assignment can be derived
by finding all of the  si   ti   edges that have a flow of   
one of the nicest characteristics of the ford fulkerson algorithm is that it works regardless of the order that the paths in the residual network are chosen  in our implementation 
we used a breadth first search which  in addition to identifying paths in the residual network  minimized the cost of the path  cost in this sense refers to the amount of external
conflict that is created by having a sensor assigned to a target  this modification maintains
the min conflict heuristic which is an integral part of extending the mediators local view 
      results
to test apo and awc in this domain  we ran a test series which used a    f t     f t
environment with     sensors placed in an ordered grid based pattern  we chose to place
the sensors in an ordered fashion to reduce the variance obtained within the results  we ran
a test series which varied the sensor to target ratio from      to           to    targets  in
increments of     which is across the spectrum from mostly satisfiable to mostly unsatisfiable
instances  see figure      we then conducted     trial runs with a random target placement
for each of these values to get a good statistical sampling 
in total       test cases were used  for comparison  we measured the number of messages
and cycles that were taken by the algorithms to find a solution  the random seeds used to
place the targets were saved  so apo and awc were both tested using identical problem
   

fimailler   lesser

   
   

  satisfiable

   
   
   
   
   
   
   
 
  

  

  

  

  

  

  

  

  

targets

figure     phase transition curve for the     sensor environment used for testing 

apo
awc

cycles

  

  

  

 

 
  

  

  

  

  

  

  

  

  

targets

figure     number of cycles needed to solve random target configurations in a field of    
sensors using awc and apo 

instances  the correctness of the algorithms was verified by cross checking the solutions
 satisfiable unsatisfiable  obtained during these tests  which matched identically 
as can be seen in figure    and    and tables    and     apo outperforms awc on all
but the simplest cases  part of the reason for this is the minimum   cycles it takes apo to
finish a mediation session  in problems that have very sparsely connected interdependencies 
this cost tends to dominate  all in all  as the t tests indicate  apo is significantly better
than awc in terms of both cycles to completion and number of messages used for problems
in this domain 
   

fiasynchronous partial overlay  a new algorithm for dcsp

targets
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
overall

apo
mean
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

apo
stdev
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     
     
     
    
    
    
    
    
    
    
    

awc
mean
    
    
    
    
    
     
     
    
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
    

awc
stdev
    
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     

p aw c  ap o 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table     number of cycles needed to solve random target configurations in a field of    
sensors using awc and apo 

   

fimailler   lesser

targets
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
overall

apo
mean
     
     
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

apo
stdev
     
     
     
     
     
     
      
     
      
      
      
      
      
      
      
      
      
      
      
      
      
     
      
      
      
     
      

awc
mean
     
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
       
       
       
       
       
       
       
       

awc
stdev
      
      
      
      
      
      
      
      
      
      
      
      
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       

p aw c  ap o 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table     number of messages needed to solve random target configurations targets in a
field of     sensors using awc and apo 

   

fiasynchronous partial overlay  a new algorithm for dcsp

apo

messages

    

awc

    

    

   

 
  

  

  

  

  

  

  

  

  

targets

figure     number of messages needed to solve random target configurations targets in a
field of     sensors using awc and apo 

   conclusions and future directions
in this article  we presented a new complete  distributed constraint satisfaction protocol
called asynchronous partial overlay  apo   like awc  apo allows the agents to retain
their autonomy because they can obscure or completely hide internal variables and constraints  in addition  agents can refuse solutions posed by a mediator  instead taking over
as the mediator if for some reason they are unhappy with a proposed solution  we also
presented an example of its execution on a simple problem  section      and proved the
soundness and completeness of the algorithm  section       through extensive empirical
testing on        graph instances from the graph coloring and tracking domain  we also
showed that apo significantly outperforms the currently best known distributed constraint
satisfaction algorithm  awc  yokoo         these tests have shown that apo is better
than awc in terms of cycles to completion  message usage  and runtime performance  we
have also shown that the runtime characteristics can not be directly attributed to the speed
of the centralized solver 
apos performance enhancements can be attributed to a number of things  first 
apo exhibits a hill climbing nature early in the search which becomes more focused and
controlled as time goes on  like other hill climbing techniques this often leads to a satisfiable
solution early in the search  second  by using partial overlaying of the information that the
agents use in decision making  apo exploits the work that has been previously done by
other mediators  this forms a lock and key mechanism which promotes solution stability 
lastly  and most importantly  because apo uses dynamic  partial centralization  the agents
work on smaller  highly relevant portions of the overall problem  by identifying these areas
of decomposability  the search space can be greatly reduced which  in some cases  improves
the efficiency of the centralized search algorithm 
there are a vast number of improvements planned for apo in the future  probably the
most important is to improve the centralized solver that it uses  in this article  an inefficient
solver was chosen to show the strengths of the distributed portions of apo  we expect
   

fimailler   lesser

that additional improvements in the algorithms runtime performance can be obtained by
using a faster centralized search engine  in addition  modern solvers often use methods
like graph reductions  unit propagation and backbone guided search  it is conceivable that
information gained from the centralized search engine could be used to prune the domains
from the variables for consistency reasons and variables from the centralized subproblem
for relevance reasons  we expect this will further focus the efforts of the agents additionally
reducing the search time and communications usage of the algorithm 
along with these improvements is the selective use of memory for recording nogoods 
unlike awc which uses the nogoods to ensure a complete search  apos completeness relies
on one of the agents centralizing the entire problem in the worst case  because of this key
difference  apo can be improved by simply remembering a small  powerful subset of the
nogoods that it discovers from mediation session to session  this would allow the algorithm
to improve future search by exploiting work that it had done previously 
what should be clear is that apo  and the cooperative mediation methodology as a
whole  opens up new areas for future exploration and new questions to be answered in
distributed problem solving  we believe that this work shows a great deal of promise for
addressing a vast number of problems and represents a bridge between centralized and
distributed problem solving techniques 

acknowledgments
special thanks to bryan horling for his design and implementation of the farm simulation
environment in which the experiment were run and to shlomo zilberstein  bart selman 
neil immerman  and jose vidal for making numerous suggestions during the development
of this work  lastly  the authors would like to thank the jair reviewers for their helpful
feedback and suggestions and carlos ansotegui and jean charles regin for their lengthy
discussion during the final revision to this article 
the effort represented in this paper has been sponsored by the defense advanced research projects agency  darpa  and air force research laboratory  air force materiel
command  usaf  under agreement number f                 the views and conclusions
contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements  either expressed or implied  of the defense
advanced research projects agency  darpa   air force research laboratory  or the u s 
government  the u s  government is authorized to reproduce and distribute reprints for
governmental purposes notwithstanding any copyright annotation thereon 

references
bejar  r   krishnamachari  b   gomes  c     selman  b          distributed constraint
satisfaction in a wireless sensor tracking system  in workshop on distributed constraint reasoning  international joint conference on artificial intelligence  seattle 
washington 
cammarata  s   mcarthur  d     steeb  r          strategies of cooperation in distributed
problem solving  in proceedings of the  th international joint conference on artificial
   

fiasynchronous partial overlay  a new algorithm for dcsp

intelligence  ijcai      vol     pp         
cha  b     iwana  k          adding new clauses for faster local search  in proceedings of
the thirteenth national conference on artificial intelligence  aaai   pp         
cheeseman  p   kanefsky  b     taylor  w          where the really hard problems are 
in proceedings of the   th international joint conference on artificial intelligence
 ijcai      pp         
conry  s  e   kuwabara  k   lesser  v  r     meyer  r  a          multistage negotiation
for distributed constraint satisfaction  ieee transactions on systems  man  and
cybernetics         
cormen  t  h   leiserson  c  e     rivest  r  l          introduction to algorithms 
mcgraw hill 
culberson  j     gent  i          frozen development in graph coloring  theoretical computer science                   
fernandez  c   bejar  r   krishnamachari  b   gomes  c     selman  b          distributed
sensor networks  a multiagent perspective  chap  communication and computation
in distributed csp algorithms  pp          kluwer academic publishers 
ford  l  r     fulkerson  d          flows in networks  princeton university press 
freuder  e  c     wallace  r  j          partial constraint satisfaction  artificial intelligence                
frost  d     dechter  r          dead end driven learning  in proceedings of the twelfth
natioanl conference on artificial intelligence  pp         
ginsberg  m  l          dynamic backtracking  journal of artificial intelligence research 
        
hayden  s   carrick  c     yang  q          architectural design patterns for multi agent
coordination  in proceedings of the international conference on agent systems  seattle  wa 
hirayama  k     yokoo  m          the effect of nogood learning in distributed constraint
satisfaction  in the   th international conference on distributed computing systems
 icdcs   pp         
krishnamachari  b   bejar  r     wicker  s          distributed problem solving and the
boundaries of self configuration in multi hop wireless networks  in hawaii international conference on system sciences  hicss     
krishnamachari  b          phase transitions  structure  and compleixty in wireless networks  ph d  thesis  cornell university  ithaca  ny 
mammen  d  l     lesser  v  r          problem structure and subproblem sharing in
multi agent systems  third international conference on multi agent systems     
    
merriam webster  ed            the merriam webster dictionary  home and office edition   springfield  il 
   

fimailler   lesser

minton  s   johnston  m  d   philips  a  b     laird  p          minimizing conflicts  a
heuristic repair method for constraint satisfaction and scheduling problems  artificial
intelligence                   
monasson  r   zecchina  r   kirkpatrick  s   selman  b     troyansky  l          determining computational complexity from characteristic phase transitions  nature      
       
rao  v  n     kumar  v          on the efficiency of parallel backtracking  ieee transactions on parallel and distributed systems                
sycara  k   roth  s   sadeh  n     fox  m          distributed constrained heuristic search 
ieee transactions on systems  man  and cybernetics                   
sycara  k          resolving goal conflicts via negotiation  in proceedings of the seventh
national conference on artificial intelligence  pp         
wellman  m     walsh  w          distributed quiescence detection in multiagent negotiation  in in aaai    workshop on negotiation  settling conflicts and identifying
opportunities 
werkman  k  j          knowledge based model of negotiation using shared perspectives  in
proceedings of the   th international workshop on distributed artificial intelligence 
bandera  tx 
yokoo  m          weak commitment search for solving constraint satisfaction problems 
in proceedings of the   th national conference on artificial intelligence  aaai     
vol     pp          seattle  wa  usa  aaai press       
yokoo  m          asynchronous weak commitment search for solving distributed constraint
satisfaction problems   in proceedings of the first international conference on principles and practice of constraint programming  cp      lecture notes in computer
science      pp         springer verlag 
yokoo  m   durfee  e  h   ishida  t     kuwabara  k          distributed constraint satisfaction for formalizing distributed problem solving  in international conference on
distributed computing systems  pp         
yokoo  m     hirayama  k          distributed breakout algorithm for solving distributed
constraint satisfaction problems   in international conference on multi agent systems
 icmas  
yokoo  m     hirayama  k          algorithms for distributed constraint satisfaction  a
review  autonomous agents and multi agent systems                
yokoo  m   suzuki  k     hirayama  k          secure distributed constraint satisfaction  reaching agreement without revealing private information  in proceeding of the
eighth international conference on principles and practice of constraint programming  cp  

   

fi