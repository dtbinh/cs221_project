journal of artificial intelligence research                  

submitted        published     

a continuation method for nash equilibria in structured
games
ben blum

bblum cs berkeley edu

university of california  berkeley
department of electrical engineering and computer science
berkeley  ca      

christian r  shelton

cshelton cs ucr edu

university of california  riverside
department of computer science and engineering
riverside  ca      

daphne koller

koller cs stanford edu

stanford university
department of computer science
stanford  ca      

abstract
structured game representations have recently attracted interest as models for multiagent artificial intelligence scenarios  with rational behavior most commonly characterized
by nash equilibria  this paper presents efficient  exact algorithms for computing nash equilibria in structured game representations  including both graphical games and multi agent
influence diagrams  maids   the algorithms are derived from a continuation method for
normal form and extensive form games due to govindan and wilson  they follow a trajectory through a space of perturbed games and their equilibria  exploiting game structure
through fast computation of the jacobian of the payoff function  they are theoretically
guaranteed to find at least one equilibrium of the game  and may find more  our approach
provides the first efficient algorithm for computing exact equilibria in graphical games with
arbitrary topology  and the first algorithm to exploit fine grained structural properties of
maids  experimental results are presented demonstrating the effectiveness of the algorithms and comparing them to predecessors  the running time of the graphical game
algorithm is similar to  and often better than  the running time of previous approximate
algorithms  the algorithm for maids can effectively solve games that are much larger
than those solvable by previous methods 

   introduction
in attempting to reason about interactions between multiple agents  the artificial intelligence
community has recently developed an interest in game theory  a tool from economics  game
theory is a very general mathematical formalism for the representation of complex multiagent scenarios  called games  in which agents choose actions and then receive payoffs that
depend on the outcome of the game  a number of new game representations have been
introduced in the past few years that exploit structure to represent games more efficiently 
these representations are inspired by graphical models for probabilistic reasoning from the
artificial intelligence literature  and include graphical games  kearns  littman    singh 
c
    
ai access foundation  all rights reserved 

fiblum  shelton    koller

       multi agent influence diagrams  maids   koller   milch         g nets  la mura 
       and action graph games  bhat   leyton brown        
our goal is to describe rational behavior in a game  in game theory  a description of the
behavior of all agents in the game is referred to as a strategy profile  a joint assignment of
strategies to each agent  the most basic criterion to look for in a strategy profile is that it be
optimal for each agent  taken individually  no agent should be able to improve its utility by
changing its strategy  the fundamental game theoretic notion of a nash equilibrium  nash 
      satisfies this criterion precisely  a nash equilibrium is a strategy profile in which
no agent can improve its payoff by deviating unilaterally  changing its strategy while all
other agents hold theirs fixed  there are other types of game theoretic solutions  but the
nash equilibrium is the most fundamental and is often agreed to be a minimum solution
requirement 
computing equilibria can be difficult for several reasons  first  game representations
themselves can grow quite large  however  many of the games that we would be interested
in solving do not require the full generality of description that leads to large representation
size  the structured game representations introduced in ai exploit structural properties
of games to represent them more compactly  typically  this structure involves locality of
interaction  agents are only concerned with the behavior of a subset of other agents 
one would hope that more compact representations might lead to more efficient computation of equilibria than would be possible with standard game theoretic solution algorithms
 such as those described by mckelvey   mclennan         unfortunately  even with compact representations  games are quite hard to solve  we present a result showing that finding
nash equilibria beyond a single trivial one is np hard in the types of structured games that
we consider 
in this paper  we describe a set of algorithms for computing equilibria in structured
games that perform quite well  empirically  our algorithms are in the family of continuation
methods  they begin with a solution of a trivial perturbed game  then track this solution as
the perturbation is incrementally undone  following a trajectory through a space of equilibria
of perturbed games until an equilibrium of the original game is found  our algorithms are
based on the recent work of govindan and wilson                     gw hereafter  
which applies to standard game representations  normal form and extensive form   the
algorithms of gw are of great interest to the computational game theory community in
their own right  nudelman et al         have tested them against other leading algorithms
and found them  in certain cases  to be the most effective available  however  as with
all other algorithms for unstructured games  they are infeasible for very large games  we
show how game structure can be exploited to perform the key computational step of the
algorithms of gw  and also give an alternative presentation of their work 
our methods address both graphical games and maids  several recent papers have
presented methods for finding equilibria in graphical games  many of the proposed algorithms  kearns et al         littman  kearns    singh        vickrey   koller        ortiz
  kearns        have focused on finding approximate equilibria  in which each agent may
in fact have a small incentive to deviate  these sorts of algorithms can be problematic 
approximations must be crude for reasonable running times  and there is no guarantee of
an exact equilibrium in the neighborhood of an approximate one  algorithms that find
exact equilibria have been restricted to a narrow class of games  kearns et al          we
   

fia continuation method for nash equilibria in structured games

present the first efficient algorithm for finding exact equilibria in graphical games of arbitrary structure  we present experimental results showing that the running time of our
algorithm is similar to  and often better than  the running time of previous approximate
algorithms  moreover  our algorithm is capable of using approximate algorithms as starting
points for finding exact equilibria 
the literature for maids is more limited  the algorithm of koller and milch       
only takes advantage of certain coarse grained structure in maids  and otherwise falls
back on generating and solving standard extensive form games  methods for related types
of structured games  la mura        are also limited to coarse grained structure  and
are currently unimplemented  approximate approaches for maids  vickrey        come
without implementation details or timing results  we provide the first exact algorithm that
can take advantage of the fine grained structure of maids  we present experimental results
demonstrating that our algorithm can solve maids that are significantly outside the scope
of previous methods 
    outline and guide to background material
our results require background in several distinct areas  including game theory  continuation
methods  representations of graphical games  and representation and inference for bayesian
networks  clearly  it is outside the scope of this paper to provide a detailed review of all of
these topics  we have attempted to provide  for each of these topics  sufficient background
to allow our results to be understood 
we begin with an overview of game theory in section    describing strategy representations and payoffs in both normal form games  single move games  and extensive form
games  games with multiple moves through time   all concepts utilized in this paper will
be presented in this section  but a more thorough treatment is available in the standard
text by fudenberg and tirole         in section   we introduce the two structured game
representations addressed in this paper  graphical games  derived from normal form games 
and maids  derived from extensive form games   in section   we give a result on the complexity of computing equilibria in both graphical games and maids  with the proof deferred
to appendix b  we next outline continuation methods  the general scheme our algorithms
use to compute equilibria  in section    continuation methods form a broad computational
framework  and our presentation is therefore necessarily limited in scope  watson       
provides a more thorough grounding  in section   we describe the particulars of applying
continuation methods to normal form games and to extensive form games  the presentation
is new  but the methods are exactly those of gw 
in section    we present our main contribution  exploiting structure to perform the
algorithms of gw efficiently on both graphical games and maids  we show how bayesian
network inference in maids can be used to perform the key computational step of the gw
algorithm efficiently  taking advantage of finer grained structure than previously possible 
our algorithm utilizes  as a subroutine  the clique tree inference algorithm for bayesian
networks  although we do not present the clique tree method in full  we describe the
properties of the method that allow it to be used within our algorithm  we also provide
enough detail to allow an implementation of our algorithm using a standard clique tree
package as a black box  for a more comprehensive introduction to inference in bayesian
   

fiblum  shelton    koller

networks  we refer the reader to the reference by cowell  dawid  lauritzen  and spiegelhalter
        in section    we present running time results for a variety of graphical games and
maids  we conclude in section   

   game theory
we begin by briefly reviewing concepts from game theory used in this paper  referring to
the text by fudenberg and tirole        for a good introduction  we use the notation
employed by gw  those readers more familiar with game theory may wish to skip directly
to the table of notation in appendix a 
a game defines an interaction between a set n    n    n            n n     of agents  each agent
n  n has a set n of available strategies  where a strategy determines the agents behavior
in the game  the precise definition of the set n depends on the
q game representation  as
we discuss below  a strategy profile     n    n            n n      nn n defines a strategy
n  n for each agent n  n   given a strategy profile   the game defines an expected
payoff gn    for each agent n  n   we use n to refer to the set of all strategy profiles
of agents in n    n   agents other than n  and n  n to refer to one such profile  we
generalize this notation to n n  for the set of strategy profiles of all but two agents  if 
is a strategy profile  and n   n is a strategy for agent n  then  n    n   is a new strategy
profile in which n deviates from  to play n    and all other agents act according to  
a solution to a game is a prescription of a strategy profile for the agents  in this paper 
we use nash equilibria as our solution concept  strategy profiles in which no agent can
profit by deviating unilaterally  if an agent knew that the others were playing according
to an equilibrium profile  and would not change their behavior   it would have no incentive
to deviate  using the notation we have outlined here  we can define a nash equilibrium
to be a strategy profile  such that  for all n  n and all other strategies n   n  
gn  n   n    gn  n    n   
we can also define a notion of an approximate equilibrium  in which each agents incentive to deviate is small  an  equilibrium is a strategy profile  such that no agent
can improve its expected payoff by more than  by unilaterally deviating from   in other
words  for all n  n and all other strategies n   n   gn  n    n    gn  n   n     
unfortunately  finding an  equilibrium is not necessarily a step toward finding an exact
equilibrium  the fact that  is an  equilibrium does not guarantee the existence of an exact
equilibrium in the neighborhood of  
    normal form games
a normal form game defines a simultaneous move multi agent scenario  each agent independently selects an action and then receives a payoff that depends on the actions selected
by all of the agents  more precisely  let g be a normal form game with a set n of agents 
each agent n  n hasq
a discrete action set an and a payoff array gn with entries for every
action profile in a   nn an  that is  for joint actions a    an    an            an n     of all
agents  we use an to refer to the joint actions of agents in n    n  
   

fia continuation method for nash equilibria in structured games

      strategy representation
if agents are restricted to choosing actions deterministically  an equilibrium is not guaranteed to exist  if  however  agents are allowed to independently randomize over actions  then
the seminal result of game theory  nash        guarantees the existence of a mixed strategy
equilibrium  a mixed strategy n is a probability distribution over an  
the strategy set n is therefore defined to be the probability simplex of all mixed
strategies  the support of a mixed strategy is the set of actions in an that have non zero
probability  a strategy n for agent n is said to be a pure strategy if it has only a single
action in its support  pure strategies correspond
exactly to the deterministic actions in
q
an   the set  of mixed strategy profiles is nn n   a product of simplices  a mixed
strategy for a single agent can be represented as a vector of probabilities  one for each
action  for notational simplicity later on  we can concatenate allpthese vectors and regard
a mixed strategy profile    as a single m vector  where m   nn  an    the vector is
indexed by actions in nn an   so for an action a  an   a is the probability that agent
n plays action a   note that  for notational convenience  every action is associated with a
particular agent  different agents cannot take the same action  
      payoffs
a mixed strategy profile induces a joint distribution over action profiles  and we can compute
an expectation of payoffs with respect to this distribution  we let gn    represent the
expected payoff to agent n when all agents behave according to the strategy profile   we
can calculate this value by
x
y
gn     
gn  a 
 ak  
   
aa

kn

in the most general case  a fully mixed strategy profile  in which every    this sum includes
every entry in the game array gn   which is exponentially large in the number of agents 
    extensive form games
an extensive form game is represented by a tree  the game proceeds sequentially from
the root  each non leaf node in the tree corresponds to a choice either of an agent or of
nature  outgoing branches represent possible actions to be taken at the node  for each
of natures choice nodes  the game definition includes a probability distribution over the
outgoing branches  these are points in the game at which something happens randomly in
the world at large   each leaf z  z of the tree is an outcome  and is associated with a
vector of payoffs g z   where gn  z  denotes the payoff to agent n at leaf z  the choices of
the agents and of nature dictate which path of the tree is followed 
the choice nodes belonging to each agent are partitioned into information sets  each
information set is a set of states among which the agent cannot distinguish  thus  an agents
strategy must dictate the same behavior at all nodes in the same information set  the set
of agent ns information sets is denoted in   and the set of actions available at information
set i  in is denoted a i   we define an agent history hn  y  for a node y in the tree and
an agent n to be a sequence containing pairs  i  a  of the information sets belonging to n
traversed in the path from the root to y  excluding the information set in which y itself is
   

fiblum  shelton    koller

   

a 

   

   

b 

b 

   

a  a 

      

   

a 

   

b 

   

   

   

   

a  a 

      

      

   

b 

   

   

a  a 

      

      

   

a  a 

      

      

      

figure    a simple   agent extensive form game 
contained   and the action selected by n at each one  since actions are unique to information
sets  the same action cant be taken at two different information sets   we can also omit
the information sets and represent a history as an ordered tuple of actions only  two nodes
have the same agent n history if the paths used to reach them are indistinguishable to n 
although the paths may differ in other ways  such as natures decisions or the decisions of
other agents  we make the common assumption of perfect recall   an agent does not forget
information known nor choices made at its previous decisions  more precisely  if two nodes
y  y   are in the same information set for agent n  then hn  y    hn  y     
example    in the game tree shown in figure    there are two agents  alice and bob  alice
first chooses between actions a  and a    bob next chooses b  or b    and then alice chooses
between two of the set  a     a             a      which pair depends on bobs choice   information
sets are indicated by nodes connected with dashed lines  bob is unaware of alices actions 
so both of his nodes are in the same information set  alice is aware at the bottom level of
both her initial action and bobs action  so each of her nodes is in a distinct information set 
edges have been labeled with the probability that the agent whose action it is will follow it 
note that actions taken at nodes in the same information set must have the same probability
distribution associated with them  there are eight possible outcomes of the game  each
labeled with a pair of payoffs to alice and bob  respectively 

      strategy representation
unlike the case of normal form games  there are several quite different choices of strategy
representation for extensive form games  one convenient formulation is in terms of behavior
strategies  a behavior profile b assigns to each information set i a distribution over the
   

fia continuation method for nash equilibria in structured games

actions a  a i   the probability that agent n takes action a at information set i  in is
then written b a i   if y is a node in i  then we can also write b a y  as an abbreviation for
b a i  
our methods primarily employ a variant of the sequence form representation  koller  
megiddo        von stengel        romanovskii         which is built upon the behavior
strategy representation  in sequence form  a strategy n for an agent n is represented
as a realization plan  a vector of real values  each value  or realization probability  in the
realization plan corresponds to a distinct history  or sequence  hn  y  that agent n has  over
all nodes y in the game tree  some of these sequences may only be partial records of ns
behavior in the game  proper prefixes of larger sequences  the strategy representation
employed by gw  and by ourselves  is equivalent to the sequence form representation
restricted to terminal sequences  those which are agent n histories of at least one leaf node 
we shall henceforth refer to this modified strategy representation simply as sequence form 
for the sake of simplicity 
for agent n  then  we consider a realization plan n to be a vector of the realization
probabilities of terminal sequences  for an outcome z   hn  z    abbreviated n  z   is the
probability that agent ns choices allow the realization of outcome z 
q in other words 
the product of agent ns behavior probabilities along the history hn  z    i a hn  z  b a i  
several different outcomes may be associated with the same terminal sequence  so that
agent n may have fewer realization probabilities than there are leaves in the tree  the set
of realization plans for agent n is therefore a subset of ir n   where  n   the number of distinct
terminal sequences for agent n  is at most the number of leaves in the tree 
example    in the example above  alice has eight terminal sequences  one for each of
a     a             a   from her four information sets at the bottom level  the history for one such
last action is  a    a      the realization probability  a    a     is equal to b a   b a    a    b     
                 bob has only two last actions  whose realization probabilities are exactly his
behavior probabilities 
when all realization probabilities are non zero  realization plans and behavior strategies
are in one to one correspondence   when some probabilities are zero  many possible behavior strategy profiles might correspond to the same realization plan  as described by koller
  megiddo        this does not affect the work presented here   from
q a behavior strategy
profile b  we can easily calculate the realization probability n  z     i a hn  z  b a i   to
understand the reverse transformation  note that we can also map behavior strategies to
full realization plans defined on non terminal sequences
 as they were originally defined
q
by koller   megiddo        by defining n  h     i a h b a i   intuitively  n  h  is the
probability that agent ns choices allow the realization of partial sequence h  using this
observation  we can compute a behavior strategy from an extended realization plan  if  partial  sequence  h  a  extends sequence h by one action  namely action a at information set
i belonging to agent n  then we can compute b a i    nn h a 
 h    the extended realization
probabilities can be computed from the terminal realization probabilities by a recursive
procedure starting at the leaves of the tree and working upward  atpinformation set i with
agent n history h  determined uniquely by perfect recall   n  h    aa i  n  h  a  
as several different information sets can have the same agent n history h  n  h  can
be computed in multiple ways  in order for a  terminal  realization plan to be valid  it
   

fiblum  shelton    koller

must satisfy the constraint that all choices of information sets with agent n history h must
give rise to the same value of n  h   more formally  for each partial sequence h  we have
the
p constraints that for
p all pairs of information sets i  and i  with hn  i      hn  i      h 

 h 
a 
 
aa i    n
aa i    n  h  a   in the game tree of example    consider alices
realization probability a  a     it can be expressed as either a  a    a       a  a    a      
                    or a  a    a       a  a    a                            so these two sums must
be the same 
by recursively defining each realization probability as a sum of realization probabilities for longer sequences  all constraints can be expressed in terms of terminal realization
probabilities  in fact  the constraints are linear in these probabilities  there are several
further constraints  all probabilities must be nonnegative  and  for each agent n  n        
where   the empty sequence  is the agent n history of the first information set that agent n
encounters  this latter constraint simply enforces that probabilities sum to one  together 
these linear constraints define a convex polytope  of legal terminal realization plans 
      payoffs
if all agents play according to     the payoff to agent n in an extensive form game is
x
y
gn     
gn  z 
k  z   
   
zz

kn

where here we have augmented n to include nature for notational convenience  this is
simply an expected sum of the payoffs over all leaves  for each agent
q k  k  z  is the
product of the probabilities controlled by n along the path to z  thus  kn k  z  is the
multiplication of all probabilities along the path to z  which is precisely the probability of
z occurring  importantly  this expression has a similar multi linear form to the payoff in a
normal form game  using realization plans rather than mixed strategies 
extensive form games can be expressed  inefficiently  as normal form games  so they
too are guaranteed to have an equilibrium in mixed strategies  in an extensive form game
satisfying perfect recall  any mixed strategy profile can be represented by a payoff equivalent
behavior profile  and hence by a realization plan  kuhn        

   structured game representations
the artificial intelligence community has recently introduced structured representations
that exploit independence relations in games in order to represent them compactly  our
methods address two of these representations  graphical games  kearns et al          a
structured class of normal form games  and maids  koller   milch         a structured
class of extensive form games 
    graphical games
the size of the payoff arrays required to describe a normal form game grows exponentially
with the number of agents  in order to avoid this blow up  kearns et al         introduced
the framework of graphical games  a more structured representation inspired by probabilistic graphical models  graphical games capture local structure in multi agent interactions 
   

fia continuation method for nash equilibria in structured games

allowing a compact representation for scenarios in which each agents payoff is only affected
by a small subset of other agents  examples of interactions where this structure occurs include agents that interact along organization hierarchies and agents that interact according
to geographic proximity 
a graphical game is similar in definition to a normal form game  but the representation
is augmented by the inclusion of an interaction graph with a node for each agent  the
original definition assumed an undirected graph  but easily generalizes to directed graphs 
an edge from agent n  to agent n in the graph indicates that agent ns payoffs depend on
the action of agent n    more precisely  we define famn to be the set of agents consisting
of n itself and its parents in the graph  agent ns payoff function gn is an array indexed
only by the actions of the agents in famn   thus  the description of the game is exponential
in the in degree of the graph and not in the total number of agents  in this case  we use
fn and afn to refer to strategy profiles and action profiles  respectively  of the agents in
famn    n  
example    suppose  l landowners along a road running north to south are deciding
whether to build a factory  a residential neighborhood  or a shopping mall on their plots 
the plots are laid out along the road in a   by l grid  half of the agents are on the east side
 e            el   and half are on the west side  w            wl    each agents payoff depends only
on what it builds and what its neighbors to the north  south  and across the road build  for
example  no agent wants to build a residential neighborhood next to a factory  each agents
payoff matrix is indexed by the actions of at most four agents  fewer at the ends of the road 
and has    entries  as opposed to the full   l entries required in the equivalent normal form
game   this example is due to vickrey   koller        
    multi agent influence diagrams
the description length of extensive form games can also grow exponentially with the number of agents  in many situations  this large tree can be represented more compactly 
multi agent influence diagrams  maids   koller   milch        allow a structured representation of games involving time and information by extending influence diagrams  howard
  matheson        to the multi agent case 
maids and influence diagrams derive much of their syntax and semantics from the
bayesian network framework  a maid compactly represents a certain type of extensiveform game in much the same way that a bayesian network compactly represents a joint
probability distribution  for a thorough treatment of bayesian networks  we refer the
reader to the reference by cowell et al         
      maid representation
like a bayesian network  a maid defines a directed acyclic graph whose nodes correspond
to random variables  these random variables are partitioned into sets  a set x of chance
variables whose values are chosen by nature  represented in the graph by ovals  for each
agent n  a set dn of decision variables whose values are chosen by agent n  represented
by rectangles  and for each agent n  a set un of utility variables  represented by diamonds 
chance and decision variables have  as their domains  finite sets of possible actions  we
refer to the domain of a random variable v by dom v    for each chance or decision variable
   

fiblum  shelton    koller

v   the graph defines a parent set pav of those variables on whose values the choice at v
can depend  utility variables have finite sets of real payoff values for their domains  and
are not permitted to have children in the graph  they represent components of an agents
payoffs  and not game state 
the game definition supplies each chance variable x with a conditional probability
distribution  cpd  p  x pax    conditioned on the values of the parent variables of x 
the semantics for a chance variable are identical to the semantics of a random variable in
a bayesian network  the cpd specifies the probability that an action in dom x  will be
selected by nature  given the actions taken at xs parents  the game definition also supplies
a utility function for each utility node u   the utility function maps each instantiation
pa  dom pau   deterministically to a real value u  pa   for notational and algorithmic
convenience  we can regard this utility function as a cpd p  u  pau   in which  for each
pa  dom pau    the value u  pa  has probability   in p  u  pa  and all other values have
probability    the domain of u is simply the finite set of possible utility values   at the
end of the game  agent ns total payoff is the sum of the utility received from each uni  un
 here i is an index variable   note that each component uni of agent ns payoff depends only
on a subset of the variables in the maid  the idea is to compactly decompose as payoff
into additive pieces 
      strategy representation
the counterpart of a cpd for a decision node is a decision rule  a decision rule for
a decision variable dni  dn is a function  specified by n  mapping each instantiation
pa  dom padni   to a probability distribution over the possible actions in dom dni    a
decision rule is identical in form to a conditional probability distribution  and we can refer
to it using the notation p  dni  padni    as with the semantics for a chance node  the decision
rule specifies the probability that agent n will take any particular action in dom dni    having
seen the actions taken at dni s parents  an assignment of decision rules to all dni  dn
comprises a strategy for agent n  once agent n chooses a strategy  ns behavior at dni
depends only on the actions taken at dni s parents  padni can therefore be regarded as the
set of nodes whose values are visible to n when it makes its choice at dni   agent ns choice
of strategy may well take other nodes into account  but during actual game play  all nodes
except those in padni are invisible to n 
example    the extensive form game considered in example   can be represented by the
maid shown in figure   a   alice and bob each have an initial decision to make without
any information about previous actions  then alice has another decision to make in which
she is aware of bobs action and her own  alice and bob each have only one utility node
 the two are condensed into a single node in the graph  for the sake of brevity   whose payoff
structure is wholly general  dependent on every action in the game  and thus whose possible
values are exactly the values from the payoff vectors in the extensive form game 
example    figure   b  shows a more complicated maid of a somewhat more realistic
scenario  here  three landowners along a road are deciding whether to build a store or a
house  their payoff depends only on what happens adjacent to them along the road  their
decision proceeds in two stages  the planning stage and the building stage  the second
   

fia continuation method for nash equilibria in structured games

a
p 

p 

b

p 

e 

e 

c 

a

c 

b 

ab

c 

b 

r 

l 

 a 

b 

r 

l 

 b 

figure     a  a simple maid equivalent to the extensive form game in figure     b  a
two stage road game with three agents 

landowner  for instance  has the two decision variables p  and b    he receives a certain
penalty from the utility node c  if he builds the opposite of what he had planned to build 
but after planning  he learns something about what his neighbor to the left has planned 
the chance node e  represents noisy espionage  it transmits the action taken at p    after
learning the value of e    it may be in the second landowners interests to deviate from
his plan  even if it means incurring the penalty  it is in his interest to start a trend that
distinguishes him from previous builders but which subsequent builders will follow  the utility
node l  rewards him for building the opposite of what was built at b    and the utility node
r  rewards him if the third landowner builds the same thing he does at b   
note that this maid exhibits perfect recall  because the choice made at a planning stage
is visible to the agent when it makes its next choice at the building stage 
      payoffs
under a particular strategy profile   that is  a tuple of strategies for all players  all
decision nodes have cpds specified  since chance and utility nodes are endowed with cpds
already  the maid therefore induces a fully specified bayesian network b with variables
v   x  d  u and the same directed graph as the maid  by the chain rule for bayesian
networks qb induces a joint probability distribution p over all the variables in v by
p  v    v v p  v  pav    with cpds for chance and utility variables given by the maid
definition and cpds for decision variables given by   for a game g represented as a
maid  the expected payoff that agent n receives under  is the expectation of ns utility
node values with respect to this distribution 
x
gn     
ep  uni  
uni un

 

x

x

uni un udom uni  

   

u  p  u  

fiblum  shelton    koller

we show in section   that this and other related expectations can be calculated efficiently
using bayesian network inference algorithms  giving a substantial performance increase over
the calculation of payoffs in the extensive form game 
      extensive form strategy representations in maids
a maid provides a compact definition of an extensive form game  we note that  although
this correspondence between maids and extensive form games provides some intuition
about maids  the details of the mapping are not relevant to the remainder of the discussion 
we therefore briefly review this construction  referring to the work of koller and milch
       for details 
the game tree associated with a maid is a full  balanced tree  with each path corresponding to a complete assignment of the chance and decision nodes in the network  each
node in the tree corresponds either to a chance node or to a decision node of one of the
players  with an outgoing branch for each possible action at that node  all nodes at the
same depth in the tree correspond to the same maid node  we assume that the nodes
along a path in the tree are ordered consistently with the ordering implied by the directed
edges in the maid  so that if a maid node x is a parent of a maid node y   the tree
branches on x before it branches on y   the information sets for tree nodes associated
with a decision node dni correspond to assignments to the parents padni   all tree nodes
corresponding to dni with the same assignment to padni are in a single information set 
we note that  by construction  the assignment to padni was determined earlier in the tree 
and so the partition to information sets is well defined  for example  the simple maid in
figure   a  expands into the much larger game tree that we saw earlier in figure   
translating in the opposite direction  from extensive form games to maids  is not
always as natural  if the game tree is unbalanced  then we cannot simply reverse the above
process  however  with care  it is possible to construct a maid that is no larger than a
given extensive form game  and that may be exponentially smaller in the number of agents 
the details are fairly technical  and we omit them here in the interest of brevity 
despite the fact that a maid will typically be much more compact than the equivalent
extensive form game  the strategy representations of the two turn out to be equivalent and
of equal size  a decision rule for a decision variable dni assigns a distribution over actions to
each joint assignment to padni   just as a behavior strategy assigns a distribution over actions
to an information set in an extensive form game  as discussed above  each assignment to
the parents of dni is an information set  a strategy profile for a maid  a set of decision
rules for every decision variable  is therefore equivalent to a set of behavior strategies for
every information set  which is simply a behavior profile 
if we make the assumption of perfect recall  then  since maid strategies are simply
behavior strategies  we can represent them in sequence form  perfect recall requires that
no agent forget anything that it has learned over the course of the game  in the maid
formalism  the perfect recall assumption is equivalent to the following constraint  if agent
n has two decision nodes dni and dnj   with the second occurring after the first  then all
parents of dni  the information n is aware of in making decision dni   and dni itself must be
parents of dnj   this implies that agent ns final decision node dnd has  as parents  all of ns
previous decision nodes and their parents  then a joint assignment to dnd  padnd precisely
   

fia continuation method for nash equilibria in structured games

determines agent ns sequence of information sets and actions leading to an outcome of the
game  the agent n history of the outcome 
the realization probability for a particular sequence is computed by multiplying all
behavior strategy probabilities for actions in that sequence  in maids  a sequence corresponds to a joint assignment to dnd  padnd   and the behavior strategy probabilities for
this sequence are entries consistent with this assignment in the decision rules for agent n 
we can therefore derive all of agent ns realization probabilities at once by multiplying
together  as conditional probability distributions  the decision rules of each of agent ns decision nodes in the sequence  when multiplying conditional probability distributions  only
those entries whose assignments are consistent with each other are multiplied  conversely 
given a realization plan  we can derive the behavior strategies and hence the decision rules
according to the method outlined for extensive form games 
in the simple maid example in figure   a   the terminal sequences are the same as
in the equivalent extensive form game  in the road example in figure   b   agent   has  
terminal sequences  one for each joint assignment to his final decision node  b    and its
parents  e  and p     their associated realization probabilities are given by multiplying the
decision rules at p  and at b   

   computational complexity
when developing algorithms to compute equilibria efficiently  the question naturally arises
of how well one can expect these algorithms to perform  the complexity of computing
nash equilibria has been studied for some time  gilboa and zemel        first showed
that it is np hard to find more than one nash equilibrium in a normal form game  and
conitzer and sandholm        recently utilized a simpler reduction to arrive at this result
and several others in the same vein  other recent hardness results pertain to restricted
subclasses of normal form games  e g   chu   halpern        codenotti   stefankovic 
       however  these results apply only to   agent normal form games  while it is true
that proving a certain subclass of a class of problems to be np hard also proves the entire
class to be np hard  because np hardness is a measure of worst case complexity   such a
proof might tell us very little about the complexity of problems outside the subclass  this
issue is particularly apparent in the problem of computing equilibria  because games can
grow along two distinct axes  the number of agents  and the number of actions per agent 
the hardness results of conitzer and sandholm        apply only as the number of actions
per agent increases  because   agent normal form games are  fully connected  graphical
games  these results apply to graphical games 
however  we are more interested in the hardness of graphical games as the number
of agents increases  rather than the number of actions per agent  it is graphical games
with large numbers of agents that capture the most structure  these are the games for
which the graphical game representation was designed  in order to prove results about the
asymptotic hardness of computing equilibria along this more interesting  in this setting 
axis of representation size  we require a different reduction  our proof  like a number of
previous hardness proofs for games  e g   chu   halpern        conitzer   sandholm       
codenotti   stefankovic         reduces  sat to equilibrium computation  however  in
these previous proofs  variables in  sat instances are mapped to actions  or sets of actions 
   

fiblum  shelton    koller

in a game with only   players  whereas in our reduction they are mapped to agents  although
differing in approach  our reduction is very much in the spirit of the reduction appearing in
the work of conitzer and sandholm         and many of the corollaries of their main result
also follow from ours  in a form adapted to graphical games  
theorem    for any constant d     and k     the problem of deciding whether a
graphical game with a family size at most d and at most k actions per player has more than
one nash equilibrium is np hard 
proof  deferred to appendix b 
in our reduction  all games that have more than one equilibria have at least one pure
strategy equilibrium  this immediately gives us
corollary    it is np hard to determine whether a graphical game has more than one nash
equilibrium in discretized strategies with even the coarsest possible granularity 
finally  because graphical games can be represented as  trivial  maids  in which each
agent has only a single parentless decision node and a single utility node  and each agents
utility node has  as parents  the decision nodes of the graphical game family of that agent 
we obtain the following corollary 
corollary    it is np hard to determine whether a maid with constant family size at least
  has more than one nash equilibrium 

   continuation methods
continuation methods form the basis of our algorithms for solving each of these structured game representations  we begin with a high level overview of continuation methods 
referring the reader to the work of watson        for a more detailed discussion 
continuation methods work by solving a simpler perturbed problem and then tracing
the solution as the magnitude of the perturbation decreases  converging to a solution for
the original problem  more precisely  let  be a scalar parameterizing a continuum of
perturbed problems  when       the perturbed problem is the original one  when      
the perturbed problem is one for which the solution is known  let w represent the vector
of real values of the solution  for any perturbed problem defined by   we characterize
solutions by the equation f  w         where f is a real valued vector function of the same
dimension as w  so that   is a vector of zeros   the function f is such that w is a solution
to the problem perturbed by  if and only if f  w        
the continuation method traces solutions along the level set of solution pairs  w   
satisfying f  w         specifically  if we have a solution pair  w     we would like to trace
that solution to a nearby solution  differential changes to w and  must cancel out so that
f remains equal to   
if  w    changes in the direction of a unit vector u  then f will change
in the direction


f  u  where f is the jacobian of f  which can also be written w f  f    we
want to find a direction u such that f remains unchanged  i e   equal to    thus  we need
to solve the matrix equation
 

 dw
 w f  f
   
   
d
   

fia continuation method for nash equilibria in structured games

equivalently  changes dw and d along the path must obey w f dw    f d  rather
than inverting the matrix w f in solving this equation  we use the adjoint adj w f    which
is still defined when w f has a null space of rank    the adjoint is the matrix of cofactors 
the element at  i  j  is    i j times the determinant of the sub matrix in which row i and
column j have been removed  when the inverse is defined  adj w f     det w f   w f     
in practice  we therefore set dw   adj w f     f and d   det w f    if the jacobian
 w f  f   has a null space of rank   everywhere  the curve is uniquely defined 
the function f should be constructed so that the curve starting at      is guaranteed
to cross       at which point the corresponding value of w is a solution to the original
problem  a continuation method begins at the known solution for        the null space of
the jacobian f at a current solution  w    defines a direction  along which the solution
is moved by a small amount  the jacobian is then recalculated and the process repeats 
tracing the curve until       the cost of each step in this computation is at least cubic in
the size of w  due to the required matrix operations  however  the jacobian itself may in
general be much more difficult to compute  watson        provides some simple examples
of continuation methods 

   continuation methods for games
we now review the work of gw on applying the continuation method to the task of finding equilibria in games  they provide continuation methods for both normal form and
extensive form games  these algorithms form the basis for our extension to structured
games  described in the next section  the continuation methods perturb the game by giving agents fixed bonuses  scaled by   for each of their actions  independently of whatever
else happens in the game  if the bonuses are large enough  and unique   they dominate the
original game structure  and the agents need not consider their opponents actions  there
is thus a unique pure strategy equilibrium easily determined by the bonuses at       the
continuation method can then be used to follow a path in the space of  and equilibrium
profiles for the resulting perturbed game  decreasing  until it is zero  at this point  the
corresponding strategy profile is an equilibrium of the original game 
    continuation method for normal form games
we now make this intuition more precise  beginning with normal form games 
      perturbations
a perturbation vector b is a vector of m values chosen at random  one for each action in the
game  the bonus ba is given to the agent n owning action a for playing a  independently of
whatever else happens in the game  applying this perturbation to a target game g gives
us a new game  which we denote g  b  in which  for each a  an   and for any t  an  
 g  b n  a  t    gn  a  t    ba   if b is made sufficiently large  then g  b has a unique
equilibrium  in which each agent plays the pure strategy a for which ba is maximal 
   

fiblum  shelton    koller

      characterization of equilibria
in order to apply equation      we need to characterize the equilibria of perturbed games as
the zeros of a function f   using a structure theorem of kohlberg and mertens         gw
show that the continuation method path deriving from their equilibrium characterization
leads to convergence for all perturbation vectors except those in a set of measure zero  we
present only the equilibrium characterization here  proofs of the characterization and of the
methods convergence are given by govindan and wilson        
we first define an auxiliary vector function v g     indexed by actions  of the payoffs to
each agent for deviating from  to play a single action  we call v g the deviation function 
the element vag    corresponding to a single action a  owned by an agent n  is the payoff
to agent n when it deviates from the mixed strategy profile  by playing the pure strategy
for action a 
x
y
   
vag     
gn  a  t 
tk  
tan

kn   n 

it can also be viewed as the component of agent ns payoff that it derives from action a 
under the strategy profile   since bonuses are given to actions independently of   the
effect of bonuses on v g is independent of   vag measures the payoff for deviating and
playing a  and bonuses are given for precisely this deviation  so v gb      v g      b 
we also utilize the retraction operator r   irm   defined by gul  pearce  and stachetti         which maps an arbitrary m vector w to the point in the space  of mixed
strategies which is nearest to w in euclidean distance  given this operator  the equilibrium
characterization is as follows 
lemma     gul et al         if  is a strategy profile of g  then    r v g        iff 
is an equilibrium 
although we omit the proof  we will give some intuition for why this result is true 
suppose  is a fully mixed equilibrium  that is  every action has non zero probability  for
a single agent n  vag    must be the same for all actions a  an   because n should not have
any incentive to deviate and play a single one of them  let vn be the vector of entries in
v g    corresponding to actions of n  and let n be defined similarly  vn is a scalar multiple
of    the all ones vector  and the simplex n of ns mixed strategies is defined by  t x     
so vn is orthogonal to n   v g    is therefore orthogonal to   so retracting    v g    onto
 gives precisely   in the reverse direction  if  is a fully mixed strategy profile satisfying
   r v g         then v g    must be orthogonal to the polytope of mixed strategies 
then  for each agent  every pure strategy has the same payoff  therefore   is in fact an
equilibrium  a little more care must be taken when dealing with actions not in the support 
we refer to gul et al         for the details 
according to lemma    we can define an equilibrium as a solution to the equation
   r    v g      on the other hand  if    r w  for some w  irm   we have the
equivalent condition that w   r w    v g  r w     is an equilibrium iff this condition
is satisfied  as can easily be verified  we can therefore search for a point w  irm which
satisfies this equality  in which case r w  is guaranteed to be an equilibrium 
the form of our continuation equation is then

f  w      w  r w   v g  r  w     b  
   
   

fia continuation method for nash equilibria in structured games

we have that v g   b is the deviation function for the perturbed game g  b  so f  w   
is zero if and only if r w  is an equilibrium of g  b  at      the game is unperturbed 
so f  w         iff r w  is an equilibrium of g 
      computation
the expensive step in the continuation method is the calculation of the jacobian w f  
required for the computation that maintains the constraint of equation      here  we have
that w f   i   i   v g  r  where i is the m  m identity matrix  the hard part is
the calculation of v g   for pure strategies a  an and a   an    for n     n  the value
at location  a  a    in v g    is equal to the expected payoff to agent n when it plays the
pure strategy a  agent n  plays the pure strategy a    and all other agents act according to
the strategy profile  
y
 x
gn  a  t 
tk
a 
tan
kn   n 
x
y
 
 
gn  a  a   t 
 tk  

g
va a
      

tan n 

   

kn   n n   

g        
if both a  an and a   an   va a
 

computing equation
    requires a large number of multiplications  the sum is over the
q
space an n    kn   n n    ai   which is exponentially large in the number of agents 
    continuation method for extensive form games
the same method applies to extensive form games  using the sequence form strategy representation 
      perturbations
as with normal form games  the game is perturbed by the bonus vector b  agent n owning
sequence h is paid an additional bonus bh for playing h  independently of whatever else
happens in the game  applying this perturbation gives us a new game g  b in which  for
each z  z   g  b n  z    gn  z    bhn  z   
if the bonuses are large enough and unique  gw show that once again the perturbed
game has a unique pure strategy equilibrium  one in which all realization probabilities are
  or     however  calculating it is not as simple as in the case of normal form games 
behavior strategies must be calculated from the leaves upward by a recursive procedure  in
which at each step the agent who owns the node in question chooses the action that results
in the sequence with the largest bonus  since all actions below it have been recursively
determined  each action at the node in question determines an outcome  the realization
plans can be derived from this behavior profile by the method outlined in section       
   

fiblum  shelton    koller

      characterization of equilibria
once more  we first define a vector function capturing the benefit of deviating from a given
strategy profile  indexed by sequences 
x
y
k  z  
   
vhg     
gn  z 
zzh

kn   n 

where zh is the set of leaves that are consistent with the sequence h  the interpretation of
v g is not as natural as in the case of normal form games  as it is not possible for an agent
to play one sequence to the exclusion of all others  its possible actions will be partially
determined by the actions of other agents  in this case  vhg    can be regarded as the
portion of its payoff that agent n receives for playing sequence h  unscaled by agent ns own
probability of playing that sequence  as with normal form games  the vector of bonuses is
added directly to v g   so v gb   v g   b 
the retraction operator r for realization plans is defined in the same way as for normalform strategies  it takes a general vector and projects it onto the nearest point in the valid
region of realization plans  the constraints defining this space are linear  as discussed in
section         we can therefore express them as a constraint matrix c with c     for
all valid profiles   in addition  all probabilities must be greater than or equal to zero  to
calculate w  we must find a  minimizing  w  t  w    the  squared  euclidean distance
between w and   subject to c     and      this is a quadratic program  qp   which
can be solved efficiently using standard methods  the jacobian of the retraction is easily
computable from the set of active constraints 
the equilibrium characterization for realization plans is now surprisingly similar to
that of mixed strategies in normal form games  gw show that  as before  equilibria are
characterized by    r    v g      where now r is the retraction for sequence form and
v g is the deviation function  the continuation equation f takes exactly the same form as
well 
      computation
the key property of the reduced sequence form strategy representation is that the deviation function is a multi linear function of the extensive form parameters  as shown in
equation      the elements of the jacobian v g thus also have the same general structure  in particular  the element corresponding to sequence h for agent n and sequence h 
for agent n  is
y
 x
gn  z 
k  z 
h 
zzh
kn   n 
x
y
 
gn  z 
k  z 

g
vh h
      

zzh h 

   

kn   n n   

where zh h  is the set of leaves that are consistent with the sequences h  for agent n  and
h   for agent n     zh h  is the empty set  and hence v g      if h and h  are incompatible 
equation     is precisely analogous to equation     for normal form games  we have a sum
over outcomes of the utility of the outcome multiplied by the strategy probabilities for all
   

fia continuation method for nash equilibria in structured games


 
 


 

figure    an abstract diagram of the path  the horizontal axis represents  and the vertical
axis represents the space of strategy profiles  actually multidimensional   the
algorithm starts on the right at      and follows the dynamical system until
     at point    where it has found an equilibrium of the original game  it can
continue to trace the path and find the equilibria labeled   and   

other agents  note that this sum is over the leaves of the tree  which may be exponentially
numerous in the number of agents 
one additional subtlety  which must be addressed by any method for equilibrium computation in extensive form games  relates to zero probability actions  such actions induce
a probability of zero for entire trajectories in the tree  possibly leading to equilibria based
on unrealizable threats  additionally  for information sets that occur with zero probability 
agents can behave arbitrarily without disturbing the equilibrium criterion  resulting in a continuum of equilibria and a possible bifurcation in the continuation path  this prevents our
methods from converging  we therefore constrain all realization probabilities to be greater
than or equal to  for some small       this is  in fact  a requirement for gws equilibrium
characterization to hold  the algorithm thus looks for an  perfect equilibrium  fudenberg
  tirole         a strategy profile  in which each component is constrained by s    and
each agents strategy is a best response among those satisfying the constraint  note that
this is entirely different from an  equilibrium  an  perfect equilibrium always exists  as
long as  is not so large as to make the set of legal strategies empty  an  perfect equilibrium can be interpreted as an equilibrium in a perturbed game in which agents have a small
probability of choosing an unintended action  a limit of  perfect equilibria as  approaches
  is a perfect equilibrium  fudenberg   tirole         a refinement of the basic notion of
a nash equilibrium  as  approaches    the equilibria found by gws algorithm therefore
converge to an exact perfect equilibrium  by continuity of the variation in the continuation
method path  then for  small enough  there is a perfect equilibrium in the vicinity of the
found  perfect equilibrium  which can easily be found with local search 
   

fiblum  shelton    koller

    path properties
in the case of normal form games  gw show  using the structure theorem of kohlberg and
mertens         that the path of the algorithm is a one manifold without boundary with
probability one over all choices for b  they provide an analogous structure theorem that
guarantees the same property for extensive form games  figure   a  shows an abstract
representation of the path followed by the continuation method  gw show that the path
must cross the      hyperplane at least once  yielding an equilibrium  in fact  the path
may cross multiple times  yielding many equilibria in a single run  as the path must
eventually continue to the     side  it will find an odd number of equilibria when run
to completion 
in both normal form and extensive form games  the path is piece wise polynomial  with
each piece corresponding to a different support set of the strategy profile  these pieces are
called support cells  the path is not smooth at cell boundaries due to discontinuities in the
jacobian of the retraction operator  and hence in w f   when the support changes  care
must be taken to step up to these boundaries exactly when following the path  at this point 
the jacobian for the new support can be calculated and the path can be traced into the
new support cell 
in the case of two agents  the path is piece wise linear and  rather than taking steps  the
algorithm can jump from corner to corner along the path  when this algorithm is applied to
a two agent game and a particular bonus vector is used  in which only a single entry is nonzero   the steps from support cell to support cell that the algorithm takes are identical to
the pivots of the lemke howson algorithm  lemke   howson        for two agent generalsum games  and the two algorithms find precisely the same set of solutions  govindan  
wilson         thus  the continuation method is a strict generalization of the lemkehowson algorithm that allows different perturbation rays and games of more than two
agents 
this process is described in more detail in the pseudo code for the algorithm  presented
in figure   
    computational issues
guarantees of convergence apply only as long as we stay on the path defined by the dynamical system of the continuation method  however  for computational purposes  discrete
steps must be taken  as a result  error inevitably accumulates as the path is traced  so that
f becomes slightly non zero  gw use several simple techniques to combat this problem 
we adopt their techniques  and introduce one of our own  we employ an adaptive step
size  taking smaller steps when error accumulates quickly and larger ones when it does not 
when f is nearly linear  as it is  for example  when very few actions are in the support of
the current strategy profile   this technique speeds computation significantly 
gw use two different techniques to remove error once it has accumulated  suppose we
are at a point  w    and we wish to minimize the magnitude of f  w      w  v g  r w    
b r w   there are two values we might change  w  or b  we can change the first without
affecting the guarantee of convergence  so every few steps we run a local newton method
search for a w minimizing  f  w      if this search does not decrease error sufficiently  then
we perform what gw call a wobble  we change the perturbation vector  wobble the
   

fia continuation method for nash equilibria in structured games

continuation path  to make the current solution consistent  if we set b    w  v g  r w   
r w     the equilibrium characterization equation is immediately satisfied  changing the
perturbation vector invalidates any theoretical guarantees of convergence  however  it is
nonetheless an attractive option because it immediately reduces error to zero  both the
local newton method and the wobbles are described in more detail by govindan and
wilson        
these techniques can potentially send the algorithm into a cycle  and in practice they
occasionally do  however  they are necessary for keeping the algorithm on the path  if the
algorithm cycles  random restarts and a decrease in step size can improve convergence  more
sophisticated path following algorithms might also be used  and in general could improve
the success rate and execution time of the algorithm 
    iterated polymatrix approximation
because perturbed games may themselves have a large number of equilibria  and the path
may wind back and forth through any number of them  the continuation algorithm can
take a while to trace its way back to a solution to the original game  we can speed up the
algorithm using an initialization procedure based on the iterated polymatrix approximation
 ipa  algorithm of gw  a polymatrix game is a normal form game in which the payoffs to
an agent n are equal to the sum of the payoffs from a set of two agent games  each involving
n and another agent  because polymatrix games are a linear combination of two agent
normal form games  they reduce to a linear complementarity problem and can be solved
quickly using the lemke howson algorithm  lemke   howson        
for each agent n  n in a polymatrix game  the payoff array is a matrix b n indexed
n
by the actions of agent n and of each other agent  for actions a  an and a   an    ba a
 
 
 
 
is the payoff n receives for playing a in its game with agent n   when n plays a   agent
ns
the payoffs it receives from its games with each other agent 
p total
ppayoff is the sum of
n
n    n
aan  a  an  a a  ba a    given a normal form game g and a strategy profile   we
can construct the polymatrix game p whose payoff function has the same jacobian at 
as gs by setting
g
n
   
ba a
    va a      
the game p is a linearization of g around   its jacobian is the same everywhere  gw
show that  is an equilibrium of g if and only if it is an equilibrium of p   this follows
from the equation v g      v g        n        which holds for all   to see why it
holds  consider the single element indexed by a  an  
x
x
x
y
 v g      a  
 a 
gn  a  a    t 
 tk
n  n   n  a  an 

 

x

x

n  n   n 

tan

kn   n n   

tan n 

gn  a  t 

y

tk

kn   n 

g

    n      v   a  
the equilibrium characterization equation can therefore be written

   r    v g        n        
   

fiblum  shelton    koller

g and p have the same value of v at   and thus the same equilibrium characterization
function  then  satisfies one if and only if it satisfies the other 
we define the mapping p      such that p   is an equilibrium for p  specifically 
the first equilibrium found by the lemke howson algorithm   if p       then  is an
equilibrium of g  the ipa procedure of govindan and wilson        aims to find such a
fixed point  it begins with a randomly chosen strategy profile   and then calculates p  
by running the lemke howson algorithm  it adjusts  toward p   using an approximate
derivative estimate of p built up over the past two iterations  if  and p   are sufficiently
close  it terminates with an approximate equilibrium 
ipa is not guaranteed to converge  however  in practice  it quickly moves near a
good solution  it is possible at this point to calculate a perturbed game close to the
original game  essentially  one that differs from it by the same amount that gs polymatrix
approximation differs from g  for which the found approximate equilibrium is in fact an
exact equilibrium  the continuation method can then be run from this starting point to
find an exact equilibrium of the original game  the continuation method is not guaranteed
to converge from this starting point  however  in practice we have always found it to
converge  as long as ipa is configured to search for high quality equilibrium approximations 
although there are no theoretical results on the required quality  ipa can refine the starting
point further if the continuation method fails  our results show that the ipa quick start
substantially reduces the overall running time of our algorithm 
we can in fact use any other approximate algorithm as a quick start for ours  also
without any guarantees of convergence  given an approximate equilibrium   the inverse
image of  under r is defined by a set of linear constraints  if we let w    v g       
then we can use standard qp methods to retract w to the nearest point w  satisfying these
constraints  and let b    w   w  then    r w      r v g         b   so we are on a
continuation method path  alternatively  we can choose b by wobbling  in which case we
set b     w  v g  r w    r w    

   exploiting structure
our algorithms continuation method foundation is the same for each game representation 
but the calculation of v g in step   b i of the pseudo code in figure   is different for each
and consumes most of the time  both in normal form and  in the worst case  in extensiveform games  it requires exponential time in the number of agents  however  as we show in
this section  when using a structured representation such as a graphical game or a maid 
we can effectively exploit the structure of the game to drastically reduce the computational
time required 
    graphical games
since a graphical game is also a normal form game  the definition of the deviation function
v g in equation     is the same  vag    is the payoff to agent n for deviating from  to
play a deterministically  however  due to the structure of the graphical game  the choice
of strategy for an agent outside the family of n does not affect agent n  s payoff  this
observation allows us to compute this payoff locally 
   

fia continuation method for nash equilibria in structured games

for an input game g 
   set       choose initial b and  either by a quick start procedure  e g   ipa  or by randomizing  set
w   v g      b    
   while  is greater than some  negative  threshold  i e   there is still a good chance of picking up
another equilibrium  
 a  initialize for the current support cell  set the steps counter to the number of steps we will take
in crossing the cell  depending on the current amount of error  if f is linear or nearly linear  if 
for example  the strategy profile is nearly pure  or there are only   agents   set steps     so we
will cross the entire cell 
 b  while steps    
i  compute v g    
ii  set w f  w      i   v g      i r w   we already know  f   b   set dw  
adj w f    b and d   det w f    these satisfy equation     
iii  set  equal to the distance wed have to go in the direction of dw to reach the next support
boundary  we will scale dw and d by  steps 
iv  if  will change signs in the course of the step  record an equilibrium at the point where
it is   
v  set w    w   dw  steps  and        d  steps  
vi  if sufficient error has accumulated  use the local newton method to find a w minimizing
 f  w      if this does not reduce error enough  increase steps  thereby decreasing step
size  if we have already increased steps  perform a wobble and reassign b 
vii  set steps    steps    

figure    pseudo code for the cont algorithm 
      the jacobian for graphical games
we begin with the definition of v g for normal form games  modified slightly to account
for the local payoff arrays   recall that afn is the set of action profiles of agents in famn
other than n  and let afamn be the set of action profiles of agents not in famn   then
we can divide a sum over full action profiles between these two sets  switching from the
normal form version of gn to the graphical game version of gn   as follows 
x
y
vag     
gn  a  t 
 tk
tan

 

x
uafn

kn   n 

gn  a  u 

y

uk

x

y

v j  

    

kfamn   n  vafamn jn  famn

note that the latter sum and product simply sum out a probability distribution  and hence
are always equal to   due to the constraints on   they can thus be eliminated without
changing the value v g takes on valid strategy profiles  however  their partial derivatives
with respect to strategies of agents not in famn are non zero  so they enter into the computation of v g  
suppose we wish to compute a row in the jacobian matrix corresponding to action a of
agent n  we must compute the entries for each action a  of each agent n   n   in the trivial
g      since  does not appear anywhere in the expression
case where n    n then va a
 
a
for vag     we next compute the entries for each action a  of each other agent n   famn  
   

fiblum  shelton    koller

in this case 
g
va a
      

x
y

gn  a  u 
a 
f

 

gn  a  u 

uafn

 

x


a 

y

y

v j

    

uk   

kfamn   n 

y

gn  a  a    t 

tafn n 

x

vafamn jn  famn

kfamn   n 

uan

x

uk

kfamn

if n   famn  

 tk  

    

  n n   

we next compute the entry for a single action a  of an agent n  
  famn   the derivative in
equation      takes a different form in this case  the variable in question is in the second
summation  not the first  so that we have
x
y
x
y

g
va a
v j
gn  a  u 
uk
      
a 
f
 

x

gn  a  u 

 

x

y

uk

gn  a  u 

uafn

y

x

vafamn

kfamn   n 

uafn

vafamn jn  famn

kfamn   n 

uan

uk    


a 

y

v j

jn  famn

if n    famn  

    

kfamn   n 

notice that this calculation does not depend on a    therefore  it is the same for each action
of each other agent not in famn   we need not compute any more elements of the row  we
can copy this value into all other columns of actions belonging to agents not in famn  
      computational complexity
due to graphical game structure  the computation of v g    takes time exponential only
in the maximal family size of the game  and hence takes time polynomial in the number
of agents if the family size is constant  in particular  our methods lead to the following
theorem about the complexity of the continuation method for graphical games 
theorem     the time complexity of computing the jacobian of the deviation function
v g    for a graphical game is o f df  n     d   n       where f is the maximal family size
and d is the maximal number of actions per agent 
proof  consider a single row in the jacobian  corresponding to a single action a owned by
a single agent n  there are at most d f     entries in the row for actions owned by other
g
members of famn   for one such action a    the computation of the jacobian element va a
 
f
 
according to equation      takes time o d    the total cost for all such entries is therefore
o  f    df      there are then at most d  n    f   entries for actions owned by non familyg for each such a  is the same  it can be calculated once in time
members  the value of va a
 
f
 
o d    then copied across the row in time d  n    f    all in all  the computational cost
for the row is o f df     d n     there are at most d n   rows  so the total computational
cost is o  n  f df   d   n      
   

fia continuation method for nash equilibria in structured games

p 

p 

p 

b 

b 

b 

a
b
a
 a 

 b 

figure    the strategic relevance graphs for the maids in  a  figure   a  and  b  figure   b  

each iteration of the algorithm calculates v g    once  we have therefore proved that a
single iteration takes time polynomial in  n   if f is constant  in fact  matrix operations make
the complexity cubic in  n     however  as for normal form games  there are no theoretical
results about how many steps of the continuation method are required for convergence 
    maids
for graphical games  the exploitation of structure was straightforward  we now turn to
the more difficult problem of exploiting structure in maids  we take advantage of two
distinct sets of structural properties  the first  a coarse grained structural measure known
as strategic relevance  koller   milch         has been used in previous computational
methods  after decomposing a maid according to strategic relevance relations  we can
exploit finer grained structure by using the extensive form continuation method of gw
to solve each components equivalent extensive form game  in the next two sections  we
describe these two kinds of structure 
      strategic relevance
intuitively  a decision node dni is strategically relevant to another decision node dnj   if agent
n    in order to optimize its decision rule at dnj     needs to know agent ns decision rule at
dni   the relevance relation induces a directed graph known as the relevance graph  in which
only decision nodes appear and an edge from node dnj   to node dni is present iff dni is
strategically relevant to dnj     in the event that the relevance graph is acyclic  the decision
rules can be optimized sequentially in any reverse topological order  when all the children
of a node dni have had their decision rules set  the decision rule at dni can be optimized
without regard for any other nodes 
when cycles exist in the relevance graph  however  further steps must be taken  within
a strongly connected component  scc   a set of nodes for which a directed path between any
two nodes exists in the relevance graph  decision rules cannot be optimized sequentially
in any linear ordering of the nodes in the scc  some node must be optimized before one
   

fiblum  shelton    koller

of its children  which is impossible  koller and milch        show that a maid can be
decomposed into sccs  which can then be solved individually 
for example  the relevance graph for the maid in figure   a   shown in figure   a  
has one scc consisting of a and b  and another consisting of a    in this maid  we would
first optimize the decision rule at a    as the optimal decision rule at a  does not rely on the
decision rules at a and b  when she makes her decision at a    alice already knows the
actions taken at a and b  so she does not need to know the decision rules that led to them 
then we would turn a  into a chance node with cpd specified by the optimized decision
rule and optimize the decision rules at a  and b  the relevance graph for figure   b  
shown in figure   b   forms a single strongly connected component 
the computational method of koller and milch        stops at strategic relevance 
each scc is converted into an equivalent extensive form game and solved using standard
methods  our algorithm can be viewed as an augmentation of their method  after a maid
has been decomposed into sccs  we can solve each of these sccs using our methods  taking
advantage of finer grained maid structure within them to find equilibria more efficiently 
the maids on which we test our algorithms  including the road maid in figure  b  all
have strongly connected relevance graphs  so they cannot be decomposed  see figure  b
and figure     
      the jacobian for maids
a maid is equivalent to an extensive form game  so its deviation function v g is the same
one defined in equation      now  however  we can compute the payoffs that make up the
jacobian v g more efficiently  consider a payoff gn  z  to agent n for outcome z  the
outcome z is simply an assignment x to all of the variables in the maid  the realization
probability n  z  is the product
q of the probabilities for the decisions of agent n in the
assignment x  so the product kn k  z  of all realization probabilities is simply the joint
probabilitypof the assignment 
the expected payoff agent n will receive under the strategy
q
profile   zz gn  z  kn k  z   is therefore an expectation of gn  z   the expectation
is with respect to the distribution p defined by the bayesian network b whose structure
is the same as the maid  with decision node cpds determined by  
the entries of v g are not strictly expected payoffs  however  equation     can be
rewritten as
q
x gn  z 
kn k  z 
g
vh h      
 
    
n  z n   z 
zzh h 

the expectation is of the quantity gn  z   n  z n   z    the payoff gn  z  is the sum of agent
ns utility nodes  due to linearity of expectation  we can perform the computation separately
for each of agent ns utility nodes  and then simply add up the separate contributions 
we can therefore restrict our attention to computing the contribution of a single utility
node un for each agent n  furthermore  the value of n  z  depends only on the values
of the set of nodes d n consisting of ns decision nodes and their parents  thus  instead
of computing the probabilities for all assignments to all variables  we need only compute
the marginal joint distribution over un   d n   and d n    from this distribution  we can
compute the contribution of un to the expectation in equation      for every pair of terminal
sequences belonging to agents n and n   
   

fia continuation method for nash equilibria in structured games

p 

p 

p 

e 

e 

c 

c 

b 

c 

b 

r 

l 

p  e 
b  b 

e  p 
b  b 

p  e 
b  b 

e  p 
b  b 

b 

r 

l 

 a 

 b 

figure     a  a two stage road maid with three agents is shown divided into cliques  each
of the four cliques is surrounded by a dashed line  and has three decision nodes
and a chance node   b  the resultant clique tree 

      using bayesian network inference
our analysis above reduces the required computations significantly  rather than computing
a separate expectation for every pair of sequences h  h    as might at first have seemed
necessary  we need only compute one marginal joint distribution over the variables in  un  
d n  d n  for every pair of agents n  n    this marginal joint distribution is the one defined
by the bayesian network b   naively  this computation requires that we execute bayesian
network inference  n    times  once for each ordered pair of agents n  n    in fact  we can
exploit the structure of the maid to perform this computation much more efficiently  the
basis for our method is the standard clique tree algorithm of lauritzen and spiegelhalter
        the clique tree algorithm is fairly complex  and a detailed presentation is outside
the scope of this paper  we choose to treat the algorithm as a black box  describing
only those of its properties that are relevant to understanding how it is used within our
computation  we note that these details suffice to allow our method to be implemented
using one of the many off the shelf implementations of the clique tree algorithm  a reader
wishing to understand the clique tree algorithm or its derivation in more detail is referred
to the reference by cowell et al         for a complete description 
a clique tree for a bayesian network b is a data structure defined over an undirected
tree with a set of nodes c  each node ci  c corresponds to some subset of the variables
in b  typically called a clique  the clique tree satisfies certain important properties  it
must be family preserving  for each node x in b  there exists a clique ci  c such that
 x  pax    ci   it also satisfies a separation requirement  if c  lies on the unique path
from c  to c    then  in the joint distribution defined by b  the variables in c  must be
conditionally independent of those in c  given those in c   
the division of the   agent road maid into cliques is shown in figure       a   this
maid has   cliques  notice that every family is contained in a clique  including the families
of chance nodes and utility nodes   the clique tree for this maid is shown in figure       b  
   

fiblum  shelton    koller

each clique maintains a data structure called a potential  a table with an entry for each
joint assignment to the variables in the clique  a table of this sort is more generally called
a factor  inference algorithms typically use two basic operations on factors  factor product 
and factor marginalization  if f and g are two factors over the  possibly overlapping  sets
of variables x and y   respectively  then we can define the product fg to be a new factor
over x  y   the entry in fg for a particular assignment to the variables in x  y is the
product of the entries in f and g corresponding to the restriction of the assignment to x
and y   respectively  this notion of multiplication corresponds to the way that conditional
probability distributions are multiplied  we can also marginalize  or sum  a variable x out
of a factor f over x in the same way in which
pwe would sum a variable out of a joint
probability distribution  the result is a factor xp
f over the variables in x  x   the
entry for a particular assignment to the variables in x f is equal to the sum of all entries
in f compatible with that assignment  one for each value of x 
because a factor has an entry for every joint assignment to its variables  the size of
the potential for ci is exponential in  ci    the clique tree inference algorithm proceeds by
passing messages  themselves factors  from one clique to another in the tree  the messages
are used to update the potential in the receiving clique by factor multiplication  after a
process in which messages have been sent in both directions over each edge in the tree  the
tree is said to be calibrated   at this point  the potential of every clique ci contains precisely
the joint distribution over the variables in ci according to b  for details  we refer to the
reference by cowell et al         
we can use the clique tree algorithm to perform inference over b   consider the final
decision node for agent n  due to the perfect recall assumption  all of ns previous decisions
and all of their parents are also parents of this decision node  the family preservation
property therefore implies that d n is fully contained in some clique  it also implies that
the family of each utility node is contained in a clique  the expectation of equation     
thus requires the computation of the joint distribution over three cliques in the tree  the one
containing paun   the one containing d n   and the one containing d n    we need to compute
this joint distribution for every pair of agents n  n   
the first key insight is that we can reduce this problem to one of computing the joint marginal distribution for all pairs of cliques in the tree  assume we have computed pb  ci   cj  
for every pair of cliques ci   cj   now  consider any triple of cliques ci   cj   ck   there are two
cases  either one of these cliques is on the path between the other two  or not  in the first
case  assume without loss of generality that cj is on the path from ci to ck   in this case  by
the separation requirement  we have that pb  ci   cj   ck     pb  ci   cj  pb  cj   ck   pb  cj   
in the second case  there exists a unique clique c  that lies on the path between any pair
of these cliques  again  by the separation property  c  renders these cliques conditionally
independent  so we can compute
pb  ci   cj   ck    

x pb  ci   c   pb  cj   c   pb  ck   c   
pb  c    

c

 

    

thus  we have reduced the problem to one of computing the marginals over all pairs of
cliques in a calibrated clique tree  we can use dynamic programming to execute this process
efficiently  we construct a table that contains pb  ci   cj   for each pair of cliques ci   cj   we
construct the table in order of length of the path from ci to cj   the base case is when ci and
   

fia continuation method for nash equilibria in structured games

cj are adjacent in the tree  in this case  we have that pb  ci   cj     pb  ci  pb  cj   pb  ci 
cj    the probability expressions in the numerator are simply the clique potentials in
the calibrated tree  the denominator can be obtained by marginalizing either of the two
cliques  in fact  this expression is computed as a byproduct of the calibration process  so
the marginalization is not required  for cliques ci and cj that are not adjacent  we let ck
be the node adjacent to cj on the path from ci to cj   the clique ck is one step closer
to ci   so  by construction  we have already computed p  ci   ck    we can now apply the
separation property again 

pb  ci   cj    

x pb  ci   ck  pb  ck   cj  
pb  ck  

ck

 

    

      computational complexity
theorem     the computation of v g    can be performed in time o    d    u n  d    
where   is the number of cliques in the clique tree for g  d is the size of the largest clique
 the number of entries in its potential    n   is the number of agents  and u is the total
number of utility nodes in the game 
proof  the cost of calibrating the clique tree for b is o  d   the cost of computing
equation      for a single pair of cliques is o d     as we must compute a factor over the
variables in three cliques before summing out  we must perform this computation o     
times  once for each pair of cliques  for a total cost of o    d     we now compute marginal
joint probabilities over triples of cliques pauni   d n   d n  for every utility node uni and every
agent n  other than n  there are u  n       such triples  computing a factor over the
variables in three cliques may first require computing a factor over the variables in four
cliques  at a cost of o d     given this factor  computing the expected value of the utility
node takes time o d     which does not affect the asymptotic running time  the total cost for
computing all the marginal joint probabilities and expected utilities is therefore o u n  d    
and the total cost for computing v g    is o    d    u n  d    

with this method  we have shown that a single iteration in the continuation method
can be accomplished in time exponential in the induced width of the graph  the number
of variables in the largest clique in the clique tree  the induced width of the optimal clique
tree  the one with the smallest maximal clique  is called the treewidth of the network 
although finding the optimal clique tree is  itself  an np hard problem  good heuristic
algorithms are known  cowell et al          in games where interactions between the agents
are highly structured  the road maid  for example   the size of the largest clique can be a
constant even as the number of agents grows  in this case  the complexity of computing the
jacobian grows only quadratically in the number of cliques  and hence also in the number
of agents  note that the matrix adjoint operation takes time cubic in m  which is at least
 n    so a single step along the path actually has cubic computational cost 
   

fiblum  shelton    koller

    

   
cont
ipa cont
vk

    
    

   

    

   
seconds

seconds

cont
ipa cont
vk

   

    
   

   
   

   

   

   

  

   
 
 

  

  
  
  of agents

  

 

   

  

  

 a 

  

  
  
  of agents

  

  

  

 b 

 

 

x   

    
cumulative

 

     

terminating run

     

 

     
seconds iteration

  of iterations

cont
cubic fit

 
 

     
     
     
     

 

     
 
     
 

  

  

  
  of agents

 
 

  

 c 

  

  
  
  of agents

  

 d 

figure    results for   by l road game with rock paper scissors payoffs   a  running time 
results for road game with random payoffs   b  running time   c  number of
iterations of cont   d  average time per iteration of cont 

   results
we performed run time tests of our algorithms on a wide variety of both graphical games
and maids  tests were performed on an intel xeon processor running at   ghz with  
gb of ram  although the memory was never taxed during our calculations 
    graphical games
for graphical games  we compared two versions of our algorithm  cont  the simple continuation method  and ipa cont  the continuation method with ipa initialization  we tested
the hybrid equilibrium refinement algorithm of vickrey and koller         vk hereafter 
   

fia continuation method for nash equilibria in structured games

 

   

 
cont
ipa cont
vk

   

cumulative

   

terminating run

 
   
  of iterations

   
seconds

x   

   

   

 
   
 
   
 

   

   
 

 

  

  

  

  
  
  of agents

  

  

 

  

 

  

  

 a 

  
  
  of agents

  

  

  

 b 
 

   

 

x   

cont

cumulative

ipa cont

 

   

terminating run

vk

  of iterations

seconds

 
   

   

 

 
  

 

 

 

  

  

  
  of agents

  

  

  

 

 c 

  

  

  
  of agents

  

 d 

figure    results for ring game with random payoffs   a  running time   b  number of
iterations of cont  results for l by l grid game with random payoffs   c  running
time   d  number of iterations of cont 

for comparison  with the same parameters that they used  the vk algorithm only returns
 equilibria  no exact methods exist which are comparable to our own 
our algorithms were run on two classes of games defined by vickrey and koller       
and two additional classes  the road game of example    denoting a situation in which
agents must build land plots along a road  is played on a   by l grid  each agent has three
actions  and its payoffs depend only on the actions of its  grid  neighbors  following vk 
we ran our algorithm on road games with additive rock paper scissors payoffs  each agents
payoffs are a sum of payoffs from independent rock paper scissors games with each of its
neighbors  this game is  in fact  a polymatrix game  and hence is very easy to solve using our
methods  in order to test our algorithms on more typical examples  we experimented with
   

fiblum  shelton    koller

road games in which the entries of the payoff matrix for each agent were chosen uniformly
at random from         we also experimented with a ring graph with three actions per
agent and random payoffs  finally  in order to test games with increasing treewidth  we
experimented with grid games with random payoffs  these are defined in the same manner
as the road games  except that the game graph is an l by l grid 
for each class of games  we chose a set of game sizes to run on  for each  we selected
 randomly in cases where the payoffs were random  a set of    test games to solve  we
then solved each game using cont  ipa cont  and vk  for cont  we started with a different
random perturbation vector each time and recorded the time and number of iterations
necessary to reach the first equilibrium  for ipa cont  we started with a different initial
strategy profile for ipa each time and recorded the total time for both ipa and cont to reach
the first equilibrium 
all equilibria found by our algorithm had error at most        essentially machine
precision  the hybrid refinement algorithm of vk found  equilibria with average error of
about     for road games with rock paper scissors payoffs       for road games and grid
games with random payoffs  and      for ring games with random payoffs  although the
equilibria had error as high as      for road games and     for ring games 
for smaller games  the algorithms always converged to an equilibrium  in some larger
games  cont or ipa detected that they had entered a cycle and terminated without finding
an equilibrium  by maintaining a hash table of support cells they have passed through
already  both cont and ipa are able to detect when they have entered a support cell for the
second time  although this is not a sure sign that they have entered a cycle  it is a strong
indicator  when potential cycles were detected  the algorithms were restarted with new
random initialization values  note that cycles in the execution of cont can never arise if
the algorithm does not stray from the path dictated by the theory of gw  so that random
restarts reflect a failure to follow the path accurately 
when an equilibrium was eventually found  the cumulative time for all the random
restarts was recorded  the error bars in the running time graphs show the variance due to
the number of random restarts required  the choices of initialization values  and  for random
games  the choice of game 
random restarts were required in     of the games we tested  on average      restarts
were necessary for these games  note that this figure is skewed by the larger games  which
occasionally required many restarts  the largest games sometimes required   or   restarts 
in a few large graphical games     random road games and   random ring games   ipa did
not converge after    restarts  in these cases we did not record results for ipa cont  cont
always found an equilibrium within    restarts  our results are shown in figures   a b c d 
and figures   a b c  
for random roads  we also plotted the number of iterations and time per iteration
for cont in figures   c d   the number of iterations varies based both on the game and
perturbation vector chosen  however  the time per iteration is almost exactly cubic  as
predicted  we note that  when ipa was used as a quick start  cont invariably converged
immediately  within a second   all of the time was spent in the ipa algorithm 
in the road games  our methods are more efficient for smaller games  but then become more costly  due to the polymatrix nature of the rock paper scissors road games 
the ipa cont algorithm solves them immediately with the lemke howson algorithm  and
   

fia continuation method for nash equilibria in structured games

is therefore significantly less expensive than vk  in the random ring games  our algorithms
are more efficient than vk for smaller games  up to      agents   with ipa cont performing considerably better than cont  however  as with road games  the running time of
our algorithms grows more rapidly than that of vk  so that for larger games  they become
impractical  nevertheless  our algorithms performed well in games with up to    agents
and   actions per agent  which were previously intractable for exact algorithms  for the
l by l grid games  our algorithm performed much better than the vk algorithm  see figures   c d    with and without ipa quick start  this reflects the fact that the running time
complexity of our algorithms does not depend on the treewidth of the graph 

  of equilibria

  
  
  
  
 
  
  

  

 
  

 
 

  of players

 
 
  of runs

figure    the number of unique equilibria found as a function of the size of the game and
the number of runs of the algorithm  averaged over ten random ring games 

we also examined the number of equilibria found by the ipa cont algorithm  we ran
ipa cont on the ring graphical game for differing numbers of agents  for each number of
agents  we fixed    random games  ran the algorithm    times on each game  and recorded
the cumulative number of unique equilibria found  the average number of equilibria found
over the    games for each number of agents is plotted in figure    for small games  with
presumably a small number of equilibria   the number of equilibria found quickly saturated 
for large games  there was an almost linear increase in the number of equilibria found by
each subsequent random restart  implying that each run of the algorithm produced a new
set of solutions 
    maids
the previous computational method for maids  koller   milch        stopped at strategic
relevance  each scc was converted into an equivalent extensive form game and solved using
standard methods  our algorithm takes advantage of further structure once a game has already been decomposed according to strategic relevance  all of our test cases were therefore
selected to have relevance graphs consisting of a single strongly connected component 
   

fiblum  shelton    koller

a

na

b

ab

nb

c

bc
 a 

a

b

c

 b 

figure      a  the chain game and  b  its strategic relevance graph for the case of three
agents  a  b  and c  

in order to ascertain how much difference our enhancements made  we compared the
results for our maid algorithm  maid cont  to those achieved by converting the game to
extensive form and running both ef cont  the extensive form version of cont as specified by
gw  and gambit  mckelvey  mclennan    turocy         a standard game theory software
package  the time required for conversion to extensive form is not included in our results 
we ran our algorithms on two classes of games  with varying sizes  the first  to which
we refer as the chain game  alternates between decision and chance nodes  see figure     
each decision node belongs to a different agent  each agent has two utility nodes  each
connected to its own decision node and to a neighbors  except for the end agents  who have
one utility node for their single neighbor   there are three actions at each decision node 
all probability tables and payoff matrices are chosen at uniformly at random  the second
class is the two stage road building game from example    shown in figure   b   in this
class  we chose payoffs carefully  by hand  to ensure non trivial mixed strategy equilibria 
we ran on chain games of all sizes between   and     and road games of all sizes between
  and    for each size  we randomly selected    perturbation vectors and    games  all
   road games were the same  since payoffs were set by hand  and all    chain games had
payoffs randomly assigned   we then tested the algorithms on these games  initialized with
these perturbation vectors  and averaged across test cases  the timing results appear in
figures    a b   the error bars reflect variance due to the choice of game  in the chain
games   the choice of perturbation vector  and the number of random restarts required 
in some cases  as with the graphical game tests  maid cont failed to find an equilibrium  terminating early because it detected that it had entered a cycle  in these cases 
it was restarted with a new perturbation vector until it successfully terminated  when
an equilibrium was eventually found  the cumulative time for all the random restarts was
recorded  over the course of our test runs  only two chain games required a random restart 
both were of size    our algorithms failed more frequently on road games  the spike for
road games of size   reflects the fact that the games of this size required  on average     
   

fia continuation method for nash equilibria in structured games

   

   
cont
ef cont
gambit

   

   

   

cont
ef cont
gambit

   

   

   
seconds

seconds

   
   

   
   

  
   

  

   

  

   

  
 
 

 

 

 

  

  
  
  of agents

  

  

  

 
 

  

 

 

 

 a 

 
  of agents

 

 

 

 

 

 

 b 

    

   
cont
cubic fit

   

    

   
   
seconds iteration

  of iterations

   
   
   
   

    
   
    

   
   
   
    

   
 
 

 

 

 

 
  of agents

 

 

 
 

 

 c 

 

 

 

 
  of agents

 d 

figure     results for maids   a  running times for the chain maid  results for two stage
road maid   b  running time   c  number of iterations   d  time per iteration 

random restarts before an equilibrium was found  strangely  maid cont was much more
successful on the road game of size    succeeding without random restarts in all but two
cases 
we tested gambit and ef cont only on smaller games  because the time and memory
requirements for testing on larger ones were beyond our means  our results show that  while
ef cont is a faster algorithm than gambit for extensive form games  it is inadequate for the
larger maids that we were able to solve with maid cont  this is not at all surprising  a
road game of size   has    decision or chance nodes  so the equivalent extensive form game
tree has         million outcome nodes  for maids of this size  the bayesian network
inference techniques that we have used become necessary 
   

fiblum  shelton    koller

for all maids  realization probabilities were constrained to be at least      i e   we
found  perfect equilibria with           the accuracy of these equilibria was within       
or machine precision 
as with graphical games  we recorded the number of iterations until convergence as well
as the time per iteration for maid cont  the results appear in figures    c d   the time
per iteration is fit well by a cubic curve  in accordance with our theoretical predictions  the
variance is primarily due to the execution of the retraction operator  whose running time
depends on the number of strategies in the support 

   discussion and conclusions
we have described here two adaptations of the continuation method algorithms of gw 
for the purpose of accelerated execution on structured games  our results show that these
algorithms represent significant advances in the state of the art of equilibrium computation
for both graphical games and maids 
    related work on graphical games
in the last few years  several papers have addressed the issue of finding equilibria in structured games  for graphical games  the exact algorithms proposed so far apply only to games
where the interaction structure is an undirected tree  and where each agent has only two
possible actions  kearns et al         provide an exponential time algorithm to compute
all exact equilibria in such a game  and littman et al         provide a polynomial time
algorithm to compute a single exact equilibrium  for this very limited set of games  these
algorithms may be preferable to our own  since they come with running time guarantees 
however  it is yet to be tested whether these algorithms are  in fact  more efficient in practice  moreover  our methods are applicable to fully general games  and our results indicate
that they perform well 
more effort has been focused on the computation of  equilibria in general graphical
games  a number of algorithms have recently been proposed for this task  most of these
use a discretized space of mixed strategies  probabilities must be selected from a grid
in the simplex  which can be made arbitrarily fine  for computational reasons  however 
this grid must typically be quite coarse  as the number of grid points to consider grows
exponentially with the number of actions per agent  most of these methods  implicitly or
explicitly  define an equilibrium as a set of constraints over the discretized strategy space 
and then use some constraint solving method  kearns et al         use a tree propagation
algorithm  kls   vickrey and koller        use standard csp variable elimination methods
 vk    and ortiz and kearns        use arc consistency constraint propagation followed
by search  ok   vickrey and koller        also propose a gradient ascent algorithm  vk   
and provide a hybrid refinement method that can  with further computation  reduce the
equilibrium error 
as with the exact methods  the kls algorithm is restricted to tree structured games 
and comes without experimental running time results  although it is guaranteed to run in
polynomial time   kearns et al         give a suggestion for working on a non tree graph
by constructing the junction tree and passing messages therein  however  the necessary
computations are not clear and potentially very expensive 
   

fia continuation method for nash equilibria in structured games

the vk  algorithm is applicable to graphical games of arbitrary topology  with any
number of actions per agent  it takes time exponential in the treewidth of the graph  if
the treewidth is constant  then it scales linearly with the number of agents  however  our
results show that it very quickly becomes infeasible if the treewidth expands  as in the grid
game  
both of these methods come with complexity guarantees  which depend on the treewidth
of the graph  the others  ok and vk   as well as our algorithm  are insensitive to treewidth
 a single iteration takes time polynomial in the size of the game representation  and
hence exponential only in the maximum degree of the graph   however  they all require an
unknown number of iterations to converge  corollary   shows that  in general  computation
of equilibria with discretized strategies in games with fixed degree is hard  thus  the lack
of complexity guarantees for these methods is not surprising 
nonetheless  experimental results for ok seem promising  they indicate that  on
average  relatively few iterations are required for convergence  results indicate that ok
is capable of solving grid games of at least     agents  although in these cases  was as
large as      not much better than in a random fully mixed strategy profile   however  no
running time results are provided 
vk  also exhibits strong experimental results  vickrey and koller        have successfully found  equilibria in games of up to     agents  with errors of up to    of the maximal
payoff 
the main drawback to these algorithms is that they only compute  equilibria  an equilibrium may be sufficient for certain applications  if the utility functions are themselves
approximate  an agent certainly might be satisfied with an  best response  and if we make
the assumption that it is slightly costly for agents to change their minds  each agent might
need an incentive greater than  to deviate  however   equilibria do bring their own set
of problems  the primary one is that there is no guarantee of an exact equilibrium in the
neighborhood of an  equilibrium  this can make it very difficult to find  equilibria with
small values of   attempts to refine a given  equilibrium may fail  the lack of a nearby
nash equilibrium also implies a certain instability  if some agent is unsatisfied with the
 equilibrium  play may deviate quite far from it  finally   equilibria are more numerous
than nash equilibria  uncountably so  in general   this exacerbates the difficulty an agent
faces in choosing which equilibrium to play 
the algorithms for computing  equilibria are frequently faster than our own  especially
when the approximations are crude or the games have more than    or so agents  however 
the exact equilibria found by our algorithms are more satisfying solutions  and our results
show that the performance of our algorithm is comparable to that of approximate methods
in most cases  surprisingly  for many games  running time results show that ours is the
fastest available  particularly in the case of games with large treewidth  such as the grid
game in our test cases  furthermore  since we can use any approximate equilibrium as a
starting point for our algorithm  advances in approximate methods complement our own
method  the hybrid algorithm of vickrey and koller        turns out to be unsuited
to this purpose  as it tends not to remove any pure strategies from the support  but it
is interesting to see whether other methods  including those listed above  might be more
effective  it remains to be seen how small  must be for our methods to reliably refine an
approximate equilibrium 
   

fiblum  shelton    koller

    related work on maids
koller and milch         km  define a notion of dependence between agents decisions
 s relevance   and provide an algorithm that can decompose and solve maids based on
this fairly coarse independence structure  our algorithm is able to exploit finer grained
structure  resolving an open problem left by km  in general  our method will not automatically exploit the same structure obtained by decomposing the game into its relevance
components  and so our methods are best regarded as a complement to those of km  after decomposition according to s relevance  our algorithm can be applied to find equilibria
efficiently in the decomposed problems  running time results indicate that our methods
are significantly faster than previous standard algorithms for extensive form games  this is
unsurprising  since the game representation of our test cases is exponentially larger in the
number of players when converted to extensive form 
vickrey        proposes an approximate hill climbing algorithm for maids that takes
advantage of the same sort of fine grained structure that we do  bayesian network inference
is employed to calculate expected utility as one component of the score function for a single
iteration  a constraint satisfaction approach is also proposed  however  these proposals
were never implemented  so it is hard to determine what quality equilibria they would find
or how quickly they would find them 
la mura        proposes a continuation method for finding one or all equilibria in
a g net  a representation that is very similar to maids  this proposal only exploits a
very limited set of structural properties  a strict subset of those exploited by km   this
proposal was also never implemented  and several issues regarding non converging paths
seem unresolved 
our algorithm is therefore the first to be able to exploit the finer grained structure of
a maid  moreover  our algorithm  applied in conjunction with the decomposition method
of km  is able to take advantage of the full known independence structure in a maid  a
potential drawback is the requirement that strategies be  perturbed  however  decreasing
 incurs no additional computational cost  although there are limits imposed by machine
precision  perfect equilibria  a highly desirable refinement of nash equilibria  defined to
be the limit of a sequence of  perturbed equilibria as  goes to zero  can therefore be
computed effectively by our algorithm with little or no additional computational cost  in
this sense  our use of perturbed strategies is advantageous  we have not implemented a
local search algorithm to find an exact perfect equilibrium in the neighborhood of a found
 perturbed equilibrium  although it should be straightforward to do so 
    conclusion and further work
we have presented two related algorithms for computing exact equilibria in structured
games  our algorithms are based on the methods of gw  but perform the key computational
steps in their methods much more efficiently by exploiting game structure  our approach
yields the first exact algorithm to take advantage of structure in general graphical games
and the first algorithm to take full advantage of the independence structure of a maid 
these algorithms are capable of computing exact equilibria in games with large numbers of
agents  which were previously intractable for exact methods 
   

fia continuation method for nash equilibria in structured games

our algorithms come without theoretical running time bounds  but we have noticed certain interesting trends  in both the graphical game and the maid version of our algorithm 
each iteration executes in time polynomial in the number of agents  so we have examined the
number of iterations required for convergence  our adaptive step size technique decreases
the number of random restarts required to find an equilibrium  but increases the number
of iterations required to cross a support cell in larger games  when adaptive step size is
disabled  we have noticed that the number of iterations required  averaged across games
with random payoffs  seems to grow approximately linearly  intuitively  it makes sense that
the number of iterations should be at least linear  starting from a pure strategy profile  a
linear number of actions  in the number of agents  must enter the support in order for us
to reach a general strategy profile  each support boundary requires at least one iteration of
our algorithm  it is somewhat surprising  however  that the number of iterations required
does not grow more quickly  it is an interesting open problem to analyze the number of
iterations required for convergence 
in very large games  the tendency of our algorithm to cycle increases  this phenomenon
can be attributed  partially  to the cumulative effect of wobbling  after a great number
of wobbles  it is possible that the path has been altered sufficiently that it does not pass
through an equilibrium  we have noticed that some games seem intrinsically harder than
others  requiring many random restarts before convergence  for very large games  the
overall running time of our algorithm is therefore quite unpredictable 
our algorithms might be improved in a number of ways  most importantly  the continuation method would profit greatly from more sophisticated path following methods  in
a number of cases  cont or maid cont failed to find an equilibrium because it strayed too
far from the path  better path following techniques might greatly increase the reliability
of our algorithms  particularly if they obviated the need for wobbles  which negate gws
theoretical guarantee of the convergence of the continuation method 
there are also a number of theoretical questions about the algorithms of gw that
remain unresolved  nothing is known about the worst case or average case running time
of ipa  and no theoretical bounds exist on the number of iterations required by cont  it is
interesting to speculate on how the choice of perturbation ray might affect the execution
of the algorithm  can the algorithm be directed toward particular equilibria of interest
either by a careful selection of the perturbation ray or by some change in the continuation
method  is there a way of selecting perturbation rays such that all equilibria will be found 
is there a way of selecting the perturbation ray so as to speed up the execution time 
several improvements might be made to maid cont  we have not adapted ipa for use in
maids  but it should be possible to do so  making use of the generalized lemke algorithm
of koller  megiddo  and von stengel        to solve intermediate linearized maids  the
computation of v g might also be accelerated using a variant of the all pairs clique tree
algorithm that only computes the potentials for pairs of sepsets  sets of variables shared
by adjacent cliques  rather than pairs of cliques 
our work suggests several interesting avenues for further research  in fact  after the
initial publication of these results  blum  shelton    koller         at least one further
application of our techniques has already been developed  bhat and leyton brown       
have shown that an adaptation of cont can be used to efficiently solve a new class of structured games called action graph games  a generalization of local effect games as presented
   

fiblum  shelton    koller

in leyton brown   tennenholtz         we believe that these games  and other structured
representations  show great promise as enablers of new applications for game theory  they
have several advantages over their unstructured counterparts  they are well suited to games
with a large number of agents  they are determined by fewer parameters  making it feasible
for human researchers to fully specify them in a meaningful way  and their built in structure
makes them a more intuitive medium in which to frame structured  real world scenarios 
however  to avoid the computational intractability of the general problem  each new class
of structured games requires a new algorithm for equilibrium computation  we hypothesize
that cont and ipa are an excellent starting point for addressing this need 

acknowledgments  this work was supported by onr muri grant n                
and by air force contract f                under darpas task program  special
thanks to robert wilson  for kindly taking the time to guide us through the details of his
work with srihari govindan  and to david vickrey  for aiding us in testing our algorithms
alongside his  we also thank the anonymous referees for their helpful comments 
   

fia continuation method for nash equilibria in structured games

appendix a  table of notation
notation for all games
n
set of agents
n
strategy for agent n
n
strategy space for agent n

strategy profile

space of strategy profiles
n
strategy profile  restricted to agents other than n
n
space of strategy profiles for all agents other than n
 n   n   strategy profile in which agent n plays strategy n and all other agents act
according to n
gn   
expected payoff to agent n under strategy profile 
g
v   
vector deviation function
r
retraction operator mapping points to closest valid strategy profile
f
continuation method objective function

scale factor for perturbation in continuation method
w
free variable in continuation method
notation for normal form games
an
action for agent n
an
set of available actions for agent n
a
action profile
a
set of action profiles
an
action profile a restricted to agents other than n
an
space of action profiles for agents other than n
notation for extensive form games
z
leaf node in game tree  outcome 
z
set of outcomes
i
information set
in
set of information sets for agent n
a i 
set of actions available at information set i
hn  y 
sequence  history  for agent n determined by node y
zh
set of outcomes consistent with sequence  history  h
b a i 
probability under behavior profile b that agent n will choose action a at i
n  z 
realization probability of outcome z for agent n
notation for graphical games
famn
set of agent n and agent ns parents
f
n
strategy profiles of agents in famn other than n
f
an
space of action profiles of agents in famn other than n
notation for maids
dni
decision node with index i belonging to agent n
uni
utility node with index i belonging to agent n
pax
parents of node x
dom s  joint domain of variables in set s
   

fiblum  shelton    koller

c 

c 

a

c 

a
b

a
b

c

b
c

c

figure     reduction of the  sat instance  a  b  c    a  b  c    a  b  c  to a
graphical game 

appendix b  proof of theorem  
proof  the proof is by reduction from  sat  for a given  sat instance  we construct a
graphical game whose equilibria encode satisfying assignments to all the variables 
let c    c    c            cm   be the clauses of the  sat instance in question  and let v  
 v    v    v    v            vn   vn   be the set of literals  if a variable appears in only one clause  it
can immediately be assigned so as to satisfy that clause  therefore  we assume that variables
appear in at least two clauses 
we now construct the  undirected  graphical game  for each clause  ci   we create an
agent ci connected to ci  and ci    except c  and cm   which only have one clause
neighbor   we also create agents vi  for each literal   in ci  there are at most     if  for
example  ci is the clause  v   v     it has agents viv  and viv    we connect each of these
to ci   for every variable v  we group all agents viv and vjv and connect them in a line 
the same way we connected clauses to each other  the order is unimportant 
clause agents now have at most   neighbors  two clauses on either side of them and three
literals  and literal agents have at most   neighbors  two literals on either side of them and
one clause   this completely specifies the game topology  as an example  figure    shows
the graphical game corresponding to the  sat problem  abc  abc  abc  
now we define the actions and payoff structure  each agent can be interpreted as a
boolean variable  and has two actions  true and false  which correspond to the boolean
values true and false  intuitively  if a clause ci plays true  it is satisfied  if an agent
viv plays true  where v is a non negated variable  then v is assigned to be true  if vjv
plays true  then v is assigned to be false 
the payoff matrix for a clause agent ci is designed to ensure that if one clause is
unsatisfied  the entire  sat instance is marked as unsatisfied  it can best be expressed in
pseudo code  as follows 
if any of ci
s clause neighbors play false then
  for playing false
payoff is
  for playing true
else if at least one of ci s literals plays true  ci is satisfied  then
   

fia continuation method for nash equilibria in structured games


payoff is

 
 

for playing false
for playing true

else
 ci is unsatisfied 

  for playing false
payoff is
  for playing true
end if
the payoff matrix for a literal agent vi  is designed to encourage agreement with the
other literals along the line for the variable v    associated with    it can be described in
pseudo code as follows 
if the parent
 clause ci plays false then
  for playing consistently with a false assignment to v   
payoff is
  for playing the opposite
else if vi  sliteral neighbors all play consistently with a single assignment to v    then
  for playing consistently with neighbors
payoff is
  for playing the opposite
else

  for playing consistently with a false assignment to v   
payoff is
  for playing the opposite
end if
if the formula does have a satisfying assignment  then there is a pure equilibrium in
which each literal is consistent with the assignment and all clauses play true  in fact  all
agents receive higher payoffs in this case than in any other equilibrium  so that satisfying
assignments correspond to equilibria with maximum social welfare 
if the parent clauses all play false  then clearly at equilibrium all non negated literals
must play false and all negated literals must play true  this is the trivial equilibrium  it
remains to show that the trivial equilibrium is the only equilibrium for unsatisfiable formulas  i e  that any non trivial equilibrium can be used to construct a satisfying assignment 
we first prove two simple claims 
claim       in any nash equilibrium  either all clauses play true with probability one or
all clauses play false with probability one 
proof  in no case is it advantageous for a clause to choose true over false  and if a neighbor
clause takes the action false  it is in fact disadvantageous to do so  thus  if any clause has a
non zero probability of playing false at an equilibrium  its neighbors  and consequently all
other clauses  must play false with probability one  therefore  the only possible equilibria
have all clauses playing false or all clauses playing true 
it follows immediately from this claim that every non trivial equilibrium has all clauses
playing true with probability one 
claim       in any non trivial nash equilibrium  in a line of literals for the same variable
v  all those literals that play pure strategies must choose them consistently with a single
assignment to v 
   

fiblum  shelton    koller

proof  since the equilibrium is non trivial  all clauses play true  suppose that one of the
literals  v     employs the pure strategy corresponding to a false assignment to v  it suffices
to show that in fact all literals in the line must have pure strategies corresponding to a false
 
 
assignment to v  consider a neighbor v   of v     either v   s neighbors  one of which is
v     both play consistently with a false assignment to v  in which case v   must also play
consistently with a false assignment to v  or its neighbors play inconsistently  in which case
 
the else clause of v   s payoff matrix applies and v   must  again  play consistently with a
false assignment to v  we may proceed all the way through the line in this manner  all
literals in the line must therefore have pure strategies consistent with a false assignment to
v  so there can be no contradicting literals 

suppose we have a non trivial equilibrium  then by claim       all clauses must play
true with probability    if all of the literals have pure strategies  it is clear that the
equilibrium corresponds to a satisfying assignment  the literals must all be consistent with
an assignment by claim       and the clauses must all be satisfied  some subtleties arise
when we consider mixed strategy equilibria 
note first that in each clause  the payoff for choosing true is the same as for choosing false in the case of a satisfying assignment to its literals  and is less in the case of an
unsatisfying assignment  therefore  if there is any unsatisfying assignment with non zero
probability  the clause must play false 
consider a single clause ci   assumed to be choosing true at equilibrium  the mixed
strategies of ci s literals induce a distribution over their joint
because ci plays true 
w actions 
 
each joint action with non zero probability must satisfy   vi   if a literal vi  has a mixed
strategy  consider what will happen if we change its strategy to either one of the possible
pure strategies  true or false   some of the joint actions with non zero probability will
be
but the ones that remain will be a subset of the originals  so will still satisfy
w removed 
    essentially  the value of   does not affect the satisfiability of c   so it can be assigned
v
i
  i
arbitrarily 
thus  if each literal in a line for a certain variable has a mixed strategy  we can assign
the variable to be either true or false  and give each literal in the line the corresponding
pure strategy  without making any of the clauses connected to these literals unsatisfied  in
fact  we can do this if all literals in a line that have pure strategies are consistent with each
other  if there are indeed literals with pure strategies  we assign the variable according to
them  and by claim       this will always be the case 

we observe briefly that this constructed graphical game has only a finite number of
equilibria  even if peculiarities in the  sat instance give rise to equilibria with mixed
strategies  if all clauses play false  then there is only one equilibrium  if all clauses play true 
then we can remove them from the graph and trim the payoff matrices of the literals
accordingly  each line of literals is in this case a generic graphical game  with a finite set
of equilibria  the equilibria of the original game must be a subset of the direct product of
these finite sets 
   

fia continuation method for nash equilibria in structured games

references
bhat  n  a  r     leyton brown  k          computing nash equilibria of action graph
games  in proceedings of the twentieth international conference on uncertainty in
artificial intelligence 
blum  b   shelton  c     koller  d          a continuation method for nash equilibria in
structured games  in proceedings of the eighteenth international joint conference on
artificial intelligence  pp         
chu  f     halpern  j          on the np completeness of finding an optimal strategy in
games with common payoff  international journal of game theory            
codenotti  b     stefankovic  d          on the computational complexity of nash equilibria
for       bimatrix games  information processing letters             
conitzer  v     sandholm  t          complexity results about nash equilibria  in proceedings of the eighteenth international joint conference on artificial intelligence 
pp         
cowell  r  g   dawid  a  p   lauritzen  s  l     spiegelhalter  d  j          probabilistic
networks and expert systems  springer verlag 
fudenberg  d     tirole  j          game theory  the mit press 
gilboa  i     zemel  e          nash and correlated equilibria  some complexity considerations  games and economic behavior          
govindan  s     wilson  r          structure theorems for game trees  proceedings of the
national academy of sciences                    
govindan  s     wilson  r          a global newton method to compute nash equilibria 
journal of economic theory            
govindan  s     wilson  r          computing nash equilibria by iterated polymatrix
approximation  journal of economic dynamics and control               
gul  f   pearce  d     stachetti  e          a bound on the proportion of pure strategy
equilibria in generic games  mathematics of operations research             
howard  r  a     matheson  j  e          influence diagrams  in howard  r  a     matheson  j  e   eds    readings on the principles and applications of decision analysis 
vol     pp          strategic decision group  article dated      
kearns  m   littman  m  l     singh  s          graphical models for game theory  in
proceedings of the seventeenth international conference on uncertainty in artificial
intelligence  pp         
kohlberg  e     mertens  j  f          on the strategic stability of equilibria  econometrica 
                 
koller  d     megiddo  n          the complexity of two person zero sum games in extensive
form  games and economic bahavior            
koller  d   megiddo  n     von stengel  b          efficient computation of equilibria for
extensive two person games  games and economic behavior             
   

fiblum  shelton    koller

koller  d     milch  b          multi agent influence diagrams for representing and solving
games  in proceedings of the seventeenth international joint conference on artificial
intelligence  pp           
kuhn  h  w          extensive games and the problem of information  in contributions to
the theory of games ii  eds  h  w  kuhn and a  w  tucker  vol      pp         
princeton university press  princeton  nj 
la mura  p          game networks  in proceedings of the sixteenth international conference on uncertainty in artificial intelligence  pp         
lauritzen  s  l     spiegelhalter  d  j          local computations with probabilities on
graphical structures and their application to expert systems  journal of the royal
statistical society  b                
lemke  c  e     howson  jr   j  t          equilibrium points in bimatrix games  journal
of the society of applied mathematics                 
leyton brown  k     tennenholtz  m          local effect games  in proceedings of the
eighteenth international joint conference on artificial intelligence  pp         
littman  m  l   kearns  m     singh  s          an efficient exact algorithm for singly
connected graphical games  in advances in neural information processing systems
    vol     pp         
mckelvey  r  d     mclennan  a          computation of equilibria in finite games  in
handbook of computational economics  vol     pp         elsevier science 
mckelvey  r  d   mclennan  a  m     turocy  t  l          gambit  software tools for
game theory  version           http   econweb tamu edu gambit 
nash  j          non cooperative games  the annals of mathematics                 
nudelman  e   wortman  j   shoham  y     leyton brown  k          run the gamut 
a comprehensive approach to evaluating game theoretic algorithms  in third international conference on autonomous agents and multi agent systems 
ortiz  l  e     kearns  m          nash propagation for loopy graphical games  in advances
in neural information processing systems     vol     pp         
romanovskii  i          reduction of a game with complete memory to a matrix game 
doklady akademii nauk  sssr             english translation  soviet mathematics
   pages         
vickrey  d          multiagent algorithms for solving structured games  undergraduate
honors thesis  stanford university 
vickrey  d     koller  d          multi agent algorithms for solving graphical games  in
proceedings of the eighteenth national conference on artificial intelligence  aaai  
pp         
von stengel  b          efficient computation of behavior strategies  games and economic
behavior             
watson  l  t          theory of globally convergent probability one homotopies for nonlinear programming  siam journal on optimization                 

   

fi