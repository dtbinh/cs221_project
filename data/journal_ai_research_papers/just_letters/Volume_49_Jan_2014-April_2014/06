journal artificial intelligence research                  

submitted        published      

large scale optimization evaluation functions
minimax search
kunihito hoki

hoki cs uec ac jp

department communication engineering informatics
university electro communications

tomoyuki kaneko

kaneko acm org

department graphics computer sciences
university tokyo

abstract
paper presents new method  minimax tree optimization  mmto   learn
heuristic evaluation function practical alpha beta search program  evaluation
function may linear non linear combination weighted features  weights
parameters optimized  control search results move decisions agree game records human experts  well modeled objective function
minimized designed  moreover  numerical iterative method used find local
minima objective function  forty million parameters adjusted
using small number hyper parameters  method applied shogi  major
variant chess evaluation function must handle larger state space
chess  experimental results show large scale optimization evaluation
function improves playing strength shogi programs  new method performs
significantly better methods  implementation new method shogi
program bonanza made substantial contributions programs first place finish
     world computer shogi championship  additionally  present preliminary evidence
broader applicability method two player games chess 

   introduction
heuristic search powerful method artificial intelligence        chess playing
computer deep blue defeated world chess champion garry kasparov  campbell  hoane 
  hsu         computer decided moves making large number searches
minimax game tree using heuristic evaluation functions  framework
artificial intelligence  heuristic evaluation functions  well search methods 
crucial making strong computer players  thus  researchers working various games
made substantial efforts quest create effective evaluation functions using machine learning techniques  furnkranz         however  fully automated learning
heuristic evaluation functions remains challenging goal chess variants  example  developers reported majority features weights deep blue
created tuned hand  campbell et al          said recent top level chess
programs tune parameters automatically  although yet find
publication describing methods use  moreover  reinforcement learning
applied chess  baxter  tridgell    weaver        veness  silver  uther    blair        
c
    
ai access foundation  rights reserved 

fihoki   kaneko

however  best authors knowledge  evaluation functions learned
methods reported literature still weaker best hand crafted functions
terms chess playing strength 
paper  revisit idea behind earlier research learning chess evaluation
functions  marsland        hsu  anantharaman  campbell    nowatzyk        tesauro 
      reformulate task optimization problem using alternative learning
method  called minimax tree optimization  mmto   objective optimize
full set parameters evaluation function search results match
desired move decisions  e g   recorded moves grandmaster games  evaluation
functions learned iteration two procedures      shallow heuristic search
training positions using current parameters     parameter update guided
approximation gradient objective function  achieve scalability stability 
introduce new combination optimization techniques  simplified loss function  gridadjacent update  equality constraint  l   regularization  one resulting merits
mmto ensure existence local minimum within convenient range
parameters 
study demonstrates performance mmto shogi  variant chess
evaluation functions need handle wider variety features positions western
chess  implementation mmto shogi program bonanza  described section     
made substantial contribution programs first place finish      world computer shogi championship  rules shogi  well survey approaches artificial
intelligence  described literature  iida  sakuta    rollason         basic techniques  minimax search guided heuristic evaluation functions  effective
shogi chess  however  drop rule allows player reuse captured pieces
significantly changes properties      number legal moves  well average
game length  greater chess      endgame databases available     
material balance less important chess  especially endgame  thus 
performance shogi program dependent quality evaluation function 
experiments  first show full set parameters evaluation
functions optimized respect rate agreement training set 
that  examine performance various learned evaluation functions terms
rates agreement test positions win rates references  scalability
demonstrated forty million parameters  far many tune
hand  features used piece values extended versions piece square tables
commonly used learn evaluation functions chess  tesauro        baxter et al  
      veness et al          briefly examine performance mmto chess
catch glimpse applicability mmto games 
rest paper organized follows  next section reviews related research 
third section presents mmto method  fourth section shows experimental
results  forty million parameters adjusted better performance  compares
performance method existing methods  last section presents
concluding remarks  paper incorporates extends previous work  hoki  
kaneko        kaneko   hoki        
   

filarge scale optimization evaluation functions minimax search

   related work
section reviews related research learning evaluation functions  first  describe
supervised learning methods use desired moves  second  discuss learning
methods  including regression reinforcement learning  third  briefly discuss difficulty supervised learning terms numerical optimization  although machine learning
components besides evaluation functions game programs would interesting
research topic  bjornsson   marsland        tsuruoka  yokoyama    chikayama       
coulom        silver   tesauro         review focuses research
done learning evaluation functions 
    learning desired moves chess
grandmaster games popular source information learning chess  let us say
set positions p desired moves position p  typically 
positions moves sampled grandmaster games  chess program
evaluation function e p  w    p game position feature weight vector w
contains parameters adjusted 
let us assume evaluation function e p  w   partially differentiable respect
wi i  here  wi i th component w  
p example  function could
linear combination weighted features  i e   e p  w     wi  p    p  i th
feature value position p  aim learning find better weight vector w
strengthening play program  hypothesis behind kind learning
computer play agrees desired moves  better plays 
let us begin simple intuitive goal  make results one ply search agree
desired moves  simplicity  let us assume maximizing player moves first
root position p  one ply search  move highest evaluation value
selected  thus  w adjusted desired move highest evaluation
moves  goal formally written mathematical minimization problem
objective function 
p
w   
jh
 w

x x

h  e p m  w   e p dp   w     

   

pp mm p

here  p m position move position p  dp desired move position p  m p
set legal moves p excluding dp   h x  heaviside step function  i e  
h x  equals   x      otherwise  objective function counts number
moves evaluation value greater equal desired move 
better w found minimizing eq       although several studies attempted
machine learning basis framework  nitsche        van der meulen       
anantharaman         numerical procedures complicated  adjustment
large scale vector w seemed present practical difficulties 
marsland        presented notable extension wherein continuous function used
conventional optimization techniques exploited  here  continuous function
difference substituted non continuous step function eq       interesting
   

fihoki   kaneko

modified function
w   
j p  w

x x

 max     e p m  w   e p dp   w       

   

pp mm p

meaning function value different eq       i e   function
count number moves evaluation value greater equal
w   helps reduce function
desired move  however  gradient vector w j p  w
value numerically  marsland introduced inequality constraints order keep
evaluation right range  however  literature provide experimental
results practical chess programs 
second notable extension proposed early development chess machines
deep thought  nowatzyk        hsu et al          here  positions compared
p m  rather wp m   is  one leaves principal variations  pvs   possibly
several plies p m  extension carries least square fitting evaluation
w   does  instead  biases
values  therefore  max function j p  w
p dp
value e w   w   used least square fitting  evaluation value
p  d
p  m
desired move dp   e w p   w   lower another move m  e w
  w   
third notable extension comparison training proposed tesauro        
tesauro modified objective function
x x
p  d
p
p  m
w   
jct
 w
tct  e w p   w   e w
  w    
pp mm p

tct  x      r x        

   

standard sigmoid function  r heuristic rescaling factor positive
differences  i e   r x    x x    r x    cx constant c     otherwise  note
r x  still continuous function  important property modified objective
function value derivative zero limit difference x goes
positive infinity  respectively one zero limit difference
x goes negative infinity  therefore  tct  x  eq      continuous approximation
h x  eq       note property explicitly stated tesauro 
notably distinct work  number feature weights adjusted
method less two hundred  tesauro mentioned application small bit
integers  used adjust weights deep blue  however  neither
clarified procedure mentioned whether weights automatically adjusted
experiment 
table   summarizes related work  existing methods possesses least
one three important properties optimization  i e   continuity  minimax searches 
assured local minimum  however  none three properties  also 
existing methods  nowatzyk        hsu et al         tesauro        try
decrease functions iteration much possible  revisit issues
section      hand  method  mmto  scalability high dimensional
learning  moreover  empirically show decrease objective function value
leads increase playing strength  existing methods shown
property 
   

filarge scale optimization evaluation functions minimax search

method
 nitsche       
 marsland       
 van der meulen       
 hsu et al        
 anantharaman       
comparison training
mmto

continuity

search

assured local minimum












yes


yes

yes
yes
yes
yes



yes
yes

yes


yes

table    summary learning methods using desired moves training positions
adjust feature weights evaluation functions  first column name
method piece literature  second column describes continuity
objective functions respect feature weights  yes means
continuity depends kind search method used  third column indicates
whether objective functions use minimax searches depths   
instead comparisons legal moves root position  fourth column
shows whether hyper parameters objective functions assure local
minimum found 

    methods learning evaluation functions
many researchers utilized information sources desired moves 
example  studies othello dating     s compare desired moves
moves  fawcett         however  practical famous machine learning
method yielded strong programs based regression desired value
using     million features  buro               othello  different evaluation functions
used game stages determined basis number discs play  thus 
desired values training positions obtained complete endgame search
well heuristic search evaluation functions learned later game stages 
method successfully applied card games  buro  long  furtak    sturtevant 
       chess variants  best authors knowledge  learning based
regression win loss labeled data yielded decent evaluation functions chess
variants  except using desired moves  buros method properties
similar listed table    objective function continuity well assured
local minimum  method scalable  gomboc  buro  marsland        proposed
learn game records annotated human experts  however  feature weights
adjusted experiments small part full evaluation functions 
reinforcement learning  sutton   barto         especially temporal difference learning 
famous success backgammon  tesauro         considered promising
way avoid difficulty finding desired values regression  approach
applied chess shown improve strength programs  baxter
et al         levinson   weber        veness et al          knightcap program
achieved rating        points free internet chess server  fics   
   free internet chess server  http   www freechess org  last access      

   

fihoki   kaneko

easy
 a 

single minimum

dicult
 b 

 c 

 d 

smooth non dieren able

 e 

narrow trough non con nuous

figure    example illustrating difficulties facing minimization procedure 
       points highest peak internet chess club  icc   baxter et al         
another program achieved        points highest peak icc  veness et al         
however  strong human players ratings        points icc 
difference means programs reached top level chess programs 
is  evaluation functions tuned reinforcement learning yet reached level
best handcrafted evaluation functions chess  moreover  number feature
weights adjusted order thousands  checkers  evaluation functions
trained temporal difference learning reportedly comparable best handcrafted
efforts  schaeffer  hlynka    jussila         reported player stronger
expert human checker players created using neural networks trained
evolutionary strategy  chellapilla   fogel         here  features beyond piece
differentials given neural network priori 
many machine learning techniques  baxter et al         veness et al        
applied shogi  however  despite efforts many programmers researchers  adjustment full weight vector evaluation function remains challenging goal 
studies published far adjusted piece values small part feature
weights evaluation functions  beal   smith        ugajin   kotani        
    learning numerical optimization
learning methods reviewed section     objective functions decrease 
learning process extended numerical optimization using functions 
performance numerical optimization sensitive surface objective function 
figure   shows properties particular sorts functions difficulties regarding
numerical minimization  easiest one among convex function  a   local
minimum exists  global minimum  function  b  multiple local minima  however  still thought easy problem  various minimization algorithms
using gradients hessian matrices effective it  would desirable design
learning method using  say  linear logistic regression  uses one two types
objective function  buro        
contrast  non differentiable functions  c   e  often difficult
minimize differentiable ones  quadratic model  hessian
approximation conjugated gradient method  bertsekas   bertsekas        
always appropriate functions  function  d  difficult target 
important local minimum hidden inside deep narrow trough  quite difficult
find using numerical iteration methods  difficult example minimization
   

filarge scale optimization evaluation functions minimax search

non continuous function  e   even primitive iterative methods gradient decent
capable finding minimum  extreme case would function
analytical formula gradient unavailable  case  learning method would
able use partial derivatives  minima would obtained using
derivative free methods  e g   sampling methods  bjornsson   marsland        coulom 
      
theorems appendix show minimax value continuous always
partially differentiable  thus  existing methods incorporate minimax search
 hsu et al         tesauro        mmto listed table   type  c   moreover 
certain forward pruning techniques may cause discontinuities  therefore  even learning
methods type  e   overcome difficulty  mmto well modeled objective
function updates feature weights careful manner 

   minimax tree optimization
minimax tree optimization  mmto  extension comparison training reach
first intuitive goal embodied eq       purpose extension overcome
practical difficulties stabilize mathematical optimization procedure largescale feature weight vector w   given set training positions p desired move dp
position p  mmto optimizes weight vector w minimax search
w better agrees desired moves 
weight vector w improved iteration sub procedures  see figure    
iteration t  first step consists tree searches identify one leaves
pvs w  t  legal moves training positions p  pv leaf w  t  depends
feature weights w  t  evaluation function  new pv obtained
w  t  updated  we discuss issue section       second step calculation
approximate partial derivatives  depends pv weight vector 
last step update weight vector  numerical stability  difference
w  t      w  t   must kept small distorted drastic changes
 w
partial derivatives  section     shows grid adjacent update ensures this 
    objective function minimized
objective function
p
w     j p  w     jc  w
w     jr  w
w   
jmmto
 w

   

first term j p  w   right side main part  terms jc
jr constraint regularization terms  respectively  defined section     
first term
x x
j p  w    
 s p dp   w   s p m  w     
   
pp mm p

s p  w   minimax value identified tree search position p   x 
       exp ax    horizontally mirrored sigmoid function  slope  x 
controlled constant parameter      large limit   x  becomes heaviside
   

fihoki   kaneko





wp  t 

   perform game tree search identify pv leaves
child positions
p m position p training set p  w  t  weight vector
t th iteration w     initial guess 
   calculate partial derivative approximation well modeled objective
p  m
w
function defined section     using w
 t   t   objective
function employs differentiable approximation h x   see section      
well constraint regularization term  see section      



   obtain new weight vector w  t    w  t  using grid adjacent update
guided partial derivatives computed step    see section       go
back step    terminate optimization objective function
value converges  see section    



figure    minimax tree optimization  iteration searches update using partial
derivatives

step function h x   thus  main differences first intuitive objective function
p  w
w   eq      use  x  smooth approximation h x  use
jh
w  
search result s p  w   instead raw evaluation e p  w    difference j p  w
p
w
w
eq      jct  w   eq      j p    simpler closer first intuitive one
w   jr  w
w   eq     
eq       moreover  none existing studies incorporate jc  w
minimax value s p  w   equals raw evaluation value e wp   w    e p  w  
evaluation position p wp one pv leaves identified tree search rooted
p weight vector w   cases  derivatives s p  w   equal derivatives
e wp   w    reasons  pv leaves identified step   figure   
    constraint regularization terms
computer programs chess variants  evaluation values typically represented
integers  signed    bit integers especially preferred corresponding transposition tables memory efficient  thus  restrict range absolute
value evaluation function e p  w    moreover  search results change
w constant factor      restriction
one uses scaled weight vector w
stabilizes numerical optimization procedure value uncertain 
w       g w
w     eq      
restriction  introduce constraint term jc  w
 
w       equality constraint    lagrange multiplier 
subset w   g w
w    see
addition constraint term  introduce regularization term jr  w
w        w
w            
last term eq        use l   regularization jr  w
constant variable  w    subset w   l   regularization widely used deal highdimensional parameters  whereas l   regularization used avoid over fitting  tibshirani 
      

w 

   

filarge scale optimization evaluation functions minimax search

p  w
w   exists
constraint regularization terms ensure local minimum jmmto
finite range w   hand  depending p distribution dp  
p  w
w   eq       jct
w   eq      
property always true j p  w   itself  j p  w
constraint l   regularization terms similar functionalities  i e   restrict
range absolute value evaluation function e p  w    however  distinctions important practice l   regularization makes weight vector w    sparse
whereas constraint term not  thus  regularization term suitable minor
features rarely seen  whereas constraint term suitable major features
appear often training set  moreover  terms useful controlling
strength restriction  major feature values usually change often
minor feature values  magnitudes partial derivatives respect major feature
weights usually greater respect minor feature weights  adjust
strength l   regularization term weaker constraint term 
example  experiments used constraint term piece values
feature values  i e   number pieces owned black white  change single games
shogi  many weights penalized l   regularization  weight
w     w      
controlled either constraint l   regularization term  i e   w    w
partial derivatives respect major minor feature weights differed several
orders magnitude  difficult stabilize optimization procedure means
single hyper parameter    

    partial derivative approximation
iteration  feature weights updated basis partial derivatives
p  w
w   defined eq       partial derivative  exists 
objective function jmmto
p



w   
w   
w   
jmmto  w
j p  w    
jc  w
jr  w
wi
wi
wi
wi

   


w   right side treated intuitive manner  sgn wi   
last term w
jr  w

  
wi w     otherwise  function sgn x    x        x        x     

w     wi
jc  w
  w     case wi w  
partial derivative constraint term w

discussed section     
partial derivative j p  w   always exist  minimax value
s p  w   always differentiable  instead  use approximation 


j p  w    
wi


x x
 s p dp   w   s p m  w   
wi
 

   



x x
p  d
e w p   w   e wp m   w  
wi
 

   

pp mmp

pp mmp

 

x x

p d

   e w p   w   e wp m   w   

pp mm p


p  d p
e w   w   e wp m   w    
wi

   x    ddx  x   approximation eq      eq      makes computation
tractable  identify pv leaves step   figure    stated appendix a 
   

fihoki   kaneko

minimax value s p  w   found search continuous  therefore  function
j p  w   continuous  moreover  approximate value equivalent partial
derivative unique pv exists position  appendix discusses con
ditions w
s p  w   exists  note found errors caused

approximation sufficiently small shogi application  kaneko   hoki        
previous studies  baxter et al         tesauro        use approximation well 
    grid adjacent update
numerical stability  grid adjacent update step    see figure    used get
w  t      w  t   consider simple n dimensional grid distance two
adjacent points h  suppose h integer  e g   h      grid adjacent update 
feature vector w  t  always one points grid  i th component
wi  t      adjacent wi  t  
wi  t        wi  t  h sgn 

p  w
w  t  
jmmto
  
wi

thus   wi  t   wi  t      wi     h   i  update decrease objective
p  w
p  w
w   w
w w jmmto
w     errors approximation  see
function jmmto
eq       negligible  moreover  h must small enough update
p
p
change pv  i e   w
 t    w  t    majority positions p searched step   
although mmto focuses optimization weight vectors represented integers 
noted gradient descent update suitable even one uses floatingpoint feature weights  preliminary experiments indicate partial derivatives
j p  w   respect major minor feature weights differ seven orders
w proportional gradient vector may
magnitude  thus  update vector w
appropriate updating minor feature weights small step  thus  step
size component weight vector fixed grid adjacent update 
might able controlled ways  see  e g   duchi  hazan    singer        
    combination techniques practical issues
mmto combination above described techniques  subsection discusses
practical issues combination alternatives  relate external constraints
learning  e g   many weeks wait results   depend properties domain mmto applied 
      lagrange multiplier grid adjacent update
numerical stability  mmto explores restricted parameter space constraint
w        this  lagrange multiplier   jc  w
w   set
satisfied  i e   jc  w
w 
j p w
 
median partial derivatives   wi   wi w   order maintain constraint
w         iteration  result  wi  h n feature weights  h n feature
g w
weights    one feature weight  number feature weights w    n     
w   constant iterations 
hand    regularization term jr  w
   

filarge scale optimization evaluation functions minimax search

      search depth
game tree searches step   figure   time consuming step mmto 
tesauro        shown use quiescence search yields better evaluation
functions  thus  expected deeper searches mmto yield better evaluation
functions  hand  must handle large amount training positions 
search time tends grow exponentially increase search depth  therefore 
experiments use   ply standard search together quiescence search  here 
quiescence search called every frontier node standard search  observed
evaluation functions learned shallow searches still effective playing games
deep searches  see section       similar results reported tesauro 
      reuse pv efficiency learning
step   figure   time consuming part  worth considering omitting
assuming wp  t    wp  t   certain frequency  experiments  steps    
repeated    times without running step    counted number iterations
run step    is  iteration ran single step      pairs steps     
number    would domain dependent set small enough update
change pv positions 
      pruning trees
pruning techniques dramatically reduce number searched nodes hence speed
learning  fortunately  pruning introduce discontinuities objective
function  hand  pruning methods  including futility pruning  schaeffer 
       may introduce discontinuities  see appendix a     therefore  robustness
whole learning procedure examined pruning techniques used 
far authors experience goes  objective function futility pruning seems
continuous  see section      
      convergence performance measurement
termination criteria usually difficult determine iterative computations 
case learning shogi evaluation function  convergence objective function
mmto seems significant criteria  rate agreement test set
elo rating learned evaluation function converge converges  note
rate agreement measured separate test set training set
order detect overfitting  see section      
      duplication positions alternative moves
game records usually duplications positions desired moves opening
phase  although ideal distributions positions desired moves unknown 
decided remove duplications training test sets simplicity 
is  use pair hposition  movei iteration  duplications
detected zobrist hashing         note two different moves may
suggested position training test sets  objective function
   

fihoki   kaneko

becomes smaller tree search rooted position matches one moves 
result  conflicting goals move better move b vice versa
independently augmented objective function cancel
moves played position  experience  adaptation seems work
reasonably well shogi  best solution may depend target game 

   experiments
evaluated effectiveness mmto experiments number feature
weights evaluation function varied thirteen forty million 
found mmto works better comparison training intuitive modifications
terms rate agreement  speed convergence  game playing strength 
w   regularization term jr  w
w   help inalso observed constraint term jc  w
crease performance evaluation functions terms rate agreement
test set  see numerical convergence  investigated surfaces objective
function mmto limited number feature weights experimentally found
mmto finds local minima reasonable range feature weights  finally  carried
preliminary experiments chess well experiments data quality dependence 
    setup  evaluation functions  features  game records
experiments described section used bonanza  whose source code
available online  hoki   muramatsu         performance bonanza major tournaments discussed section      bonanza uses techniques mmto  pvs  pearl 
      marsland   campbell        reinefeld         capture search frontier nodes
quiescence search  transposition tables  zobrist        russell   norvig         static exchange evaluation  reul         killer history heuristics  akl   newborn        schaeffer         null move pruning  adelson velskiy  arlazarov    donskoy        heinz        
futility pruning  schaeffer        heinz         late move reductions  romstad        
uses opening book database randomly chose opening lines
self play experiments  game records training test sets exclusively
chosen games played famous tournaments            game records
total          games played professional players using standard
time controls  i e   one ten hours side byoyomi period  once time
   abbreviated tournament name  number games used  date range games are  juni 
                 kisei                  ryuo                  osho                  oui       
          ouza                  nhk cup                  ginga                  kio       
          shinjino                  zen nihon proshogi                  hayazashi shogi senshuken 
               judan                 meisho                 joryu meijin                 meijin 
               all star kachinuki                 rating senshuken                 asahi open 
               heisei saikyo                 teno                 joryu osho                
kurashiki touka                 nihon series                   dan league                 ladiesopen                 joryu oui                 shoureikai                 gakusei osho           
      hayazashi shinei                 gakusei ouza                 asahi amashogi                
wakajishi                 kudan                 gakusei meijin                 shogi renmei cup 
               tatsujin                 kinsho cup                 amateur meijin                
kashima cup                 grand champion                 saikyosya kettei                 miscellaneous                 

   

filarge scale optimization evaluation functions minimax search

evaluation function
  
x



e
 p  fia  p  wia
i  
x
b
b
b
eb
fkj
 p  fkj
 p  wkj
ec
ed

k j
x

   l
k k
x

dimension
  
       

c
c
c
fkk
  l  p  fkk   l  p  wkk   l

           




fkjj    p  fkjj
   p  wkjj  

            

k jj  

table    dimensions evaluation functions  evaluation function linear combination weighted features  ea evaluates material balance  others
evaluate variety positional scores using extended piece square tables 

expired  player move within sixty seconds   tournaments employed rapid
time controls    seconds per move top level amateur players participants 
table   shows four basic evaluation functions  ea material balance
others positional scores  experiments used sum functions  i e  
ea   eab   ea   eb   eabc   eab   ec   eabcd   eabc   ed   evaluation functions
anti symmetric respect exchange black white  e p  w     e p  w    here 
p complete reversal black white sides position p  is  black plays
white white plays black    reversal  pieces owned black white
p regarded white black pieces p  respectively  also  evaluation functions
symmetric respect right and left mirroring position  e p  w     e p  w    p
mirror image p along file e 
function ea  p  w   used evaluate material balance     types
pieces shogi  iida et al          feature fia  p  represents number i th
type owned black position p  wia relative value i th type piece 
partial derivative evaluation function respect wia ea  p  w   wia  
fia  p  fia  p  
function eb  p  w b   linear combination weighted two piece square features 
natural extensions one piece square features employed recent
machine learning studies chess evaluations  baxter et al         tesauro        veness
et al          two piece square features used evaluate conditions
b  p  indicator function returns one
king another piece  feature fkj
conditions k j exist position p  otherwise  returns zero  condition
k represents location black king  there    squares   j represents
type  owner  black white   location piece         different
conditions j minor conditions merged  thus  total number
kingpiece conditions                      mirror symmetric conditions
merged 
   following shogi notation  black white refer players plays first second  respectively 

   

fihoki   kaneko

similarly  functions ec  p  w c   ed  p  w   used evaluate kingking
c  p 
piece features kingpiecepiece features  respectively  indicator function fkk
 l
represents location two kings  k  k     condition  type location 
 p  represents location black king k
black piece l  indicator function fkjj
 
conditions two black white pieces  j  j     
game tree searches required identify pv leaf positions mmto obtain
best moves measure rate agreement  purposes  nominal depth  
search used together quiescence search  normalize objective function
values  objective function values divided total number move pairs  z p  
p
 
pp  mp    constraint function set


w   
g w

  
x

 
wia

       

   

i  

also  accordance magnitude constraint  horizontally mirrored
sigmoid function  x           exp ax   set         x  would vary signifiw               w
wb   
cantly x changed hundred  regularization term jr  w
c

w      w
w     intuitive explanation penalty strength absolute value
 w
wi increased     improves relationship evaluation
values desired move another legal move  sums eb   ec   ed computed
using    bit integers  divided    order fit evaluation value
   bit integer  step h grid adjacent update set smallest integer value   
    learning piece values
first  feature weights w   w evaluation function ea adjusted mmto
comparison training  starting initial value wia       i  tesauro
       used floating point feature weights conventional gradient descent method 
is  weight vector w updated
p
w   
w  t    w  t  rw jct
 w

    

r constant training rate hand tuned      components w used tree
search rounded nearest integer values  rescaling factor r eq      set
p  d
       accordance range difference   e w p   w   e wp m   w      
        experiment    piece values adjusted w         
game records used compose training set p  set         desired moves
z p               move pairs removing duplications handicapped games 
one problem observed comparison training slow learning  shown figure    phase iterative procedure  from iteration       mainly adjusting
pawn value  partial differential value eq      pawns largest
phase  good pawn value found  phase ii  from iteration        
mainly adjusting promoted rook promoted bishop values  values
highest second highest reasonable game play  long period time taken
w   eq      scales poorly  general problem
phase ii indicates jctp  w
gradient descent methods multiple degrees freedom  nocedal   wright        
   

filarge scale optimization evaluation functions minimax search

pro rook

    

phase ii

phase

phase iii
pro bishop

piece weight

    
gold
bishop
rook
pro pawn
pro knight
silver
pro silver
pro lance
knight
lance

    

    

   

pawn
 

 

 

 

     

 

 

     

  

 

 

     

   

    

iteration

figure    results comparison training piece weights shogi  horizontal axis
plots number iterations logarithmic scale 

cope it  learning rate r cannot greater     accordance largest
partial derivative experiments 
second problem convergence  phase iii  after iteration      figure   
piece values keep increasing without changing ratio piece values  even though
relative ratios piece values room improvement  problem inherent
objective function comparison training  eq      explicit term
avoid it  extreme case training data satisfy inequality condition
p  d
e w p   w   e wp m   w   moves position p  piece values diverge infinity
w   minimized  fact  found training data
value jctp  w
experiment satisfied condition     pairs best another legal move 
moreover  extreme case  training satisfy inequality
condition move position p eq       piece values shrink zero 
mmto deals problems making grid adjacent updates keeping
w    weighted vector w converged
magnitudes constant constraint term jc  w
   iterations  see figure     value promoted rook    
pawn      note number iterations counted number step    s
throughout experiments 
    scalability learning practical evaluation functions
learning piece values  adjusted weight vectors positional scores 
time  large number training records used cope high dimensional weight
vectors  main training set p             desired moves z p                
   

fihoki   kaneko

pro rook
pro bishop
rook
bishop
gold
pro knight
silver
pro pawn
pro lance
pro silver
knight
lance
pawn

piece weight

   

   

   

   
 

 

 

 

       

 

  
iteration

 

 

       

   

figure    results mmto piece weights 
move pairs removing duplications handicap games         game records 
test set          desired moves removing duplications handicap games
another        game records  feature weights eab adjusted mmto
comparison training intuitive modifications  initial feature weights
w      w b      used three methods  w     optimized mmto
 w
previous experiment  w b          that  show scalability  feature weights
eabc eabcd optimized mmto order  adjust feature weights
eabc   optimized feature weights eab used initial feature weights w    
w b        used w c      similarly  eabcd   optimized feature weights
eabc used initial feature weights w      w b      w c        used
w     
comparison training eabc eabcd tested learning eab yielded
small improvements  rate r eq       hand tuned        example
intuitive modifications stabilize iterative procedure  constant step update
tested learning eab   case  training rate r   t  substituted r

p
w  t    
r   t    rc   w  t  jct
 w
constant step modification conservatively updated w using constant step rc
hand tuned         value r rc best five trials  another
intuitive modification reuse pv  explained section      pvs
used    times rate r eq             rescaling factor r eq     
set         value satisfactory previous experiment shown
figure    although three methods different  iterations consumed almost
amount time  time consuming step experiments
game tree search identify pv leaf positions 
rate agreement test set shown figure    here  agreement means
legal move obtained highest value tree search desired move 
   

filarge scale optimization evaluation functions minimax search

 

b  c  h 
b  c  b 

  

   
d  b  f 
   

b  c  b 
d  f  c 

   

positional weight

agreement    

  

  

abcd

mmto  e
 
abc
mmto  e  
ab
mmto  e  
ab
ct  e   reuse pv 
ab
ct  e   constant step 
ab
ct  e  

  

  

 

 

 

 

       

 

  

 

 

       

b  c  a 
d  f  b 

   

b  b  c 
    

b  c  a 

    

    
b  d  c 

 

   

iteration

 

  

   
   
iteration

   

figure     left panel  improvement rate agreement test set mmto
comparison training  ct    right panel  improvement feature weights
positional features ed   feature weight b  c  b  indicates black king
b  two gold generals c  b   similarly  feature weights b  c  h  
b  c  b   b  c  a   b  b  c   b  c  a   b  d  c  indicate two gold generals
king b   feature weight d  b  f  indicates black king d 
opponents two gold generals b  f   similarly  feature weights
d  f  b  d  f  c  indicate opponents two gold generals king
d   here  value divided     

rate calculated excluding positions one legal move  positions
easy checkmate sequence identified shallow depth
search  tied values counted  either 
performances mmto  comparison training  variations compared
case learning eab   see figure agreement rates comparison
training constant step modification unstable substantially lower
mmto  see reuse of pv modification increases stability
reduces step length            reduces computation time learning
almost    times reduces number time consuming pv updates 
mmto full evaluation function eabcd highest rate        largescale optimization weight vector wd increased level agreement     iterations 
   

fihoki   kaneko

without constraint
constraint

pawn value

   
   
   
 

 

       

 

  
iteration

       

 

   

figure    effect constraint term mmto  eab   
computation took week using intel x     workstation  agreement ratio
test set converged     iterations  however  feature weights converge 
w   eq      improves stability mmto
figure   shows constraint jc  w
response pawn value changes eab learning  see value keeps
w   turned converges     iterations
increasing jc  w
constraint turned on  one feature weights overflowed comparison training
eabc   another reason results eabc shown comparison
w   little effect learning eab  
training  regularization term jr  w
improvement agreement rates mmto mainly due use constraint
w   grid adjacent updates 
jc  w
w   important optimizing larger weight vectors  figthe regularization term jr  w
w   eq      improves weight vector enlarged evaluation
ure   shows jr  w
function eabcd   without regularization term  objective function value rate
agreement training set increase number iterations  however 
linear increment absolute value weight vectors  distorts
rate agreement test set    th iteration      th iteration 
     components w zero  hand        components
w zero regularization term  results indicate mmto without
regularization suffers overfitting training set large scale weight vector
used  similar effect regularization occurs mmto used eabc
learning  though effect smaller eabcd  
    improvements strength
analyze relationship agreement rate strength  programs learned mmto comparison training  figure    play games
reference shogi program many times  reference program version gps shogi
released       kaneko         open source program finalist past
world computer shogi championships  completely different evaluation function
majority parameters hand tuned  version gps shogi
serves reference program popular game server shogi programs    matches
follows  reference program        nodes move  vs  four learned programs 
   http   wdoor c u tokyo ac jp shogi   last access        in japanese  

   

fiobjective function

large scale optimization evaluation functions minimax search

    
    
    
    
    

agreement    

  

l  regularization
without l  regularization

  
  

training set

  

test set

  



  

b

           

  

c

  
  
  

  

 

 

 

 

     

 

  

 

     

 

   

iteration

figure    effect regularization term mmto  eabcd   
reference program       nodes move  vs  two learned programs evaluation
function ea eab   reference program        nodes move  vs  two learned
programs evaluation functions eabc eabcd       games played
match  weight vectors obtained                                                  
iterations tested learning configuration  thus  total                   
games played  learned programs searched       nodes per move  programs
ran single thread searched similar numbers nodes second 
measured playing strength terms elo rating  popular way
represent relative strength two player games  winning probability two
players estimated          d        difference ratings 
example  rating player higher player b      winning
percentage player      here  ratings determined using maximum
likelihood estimation games 
figure   shows elo rating player  see mmto eab significantly outperformed comparison training initial feature weights 
mmto used eab   winning percentage reference     k move  stably increased               elo points                elo points   contrast  comparison
   

fielo rating

hoki   kaneko

    
    
    
    
    
    
    
    
    
    
    

mmto  abcd 
mmto  abc 
mmto  ab 
comparison training  ab 
reference     k 
reference     k 
reference     k 

 

  
iteration

   

figure    improvements strength  elo rating  achieved mmto comparison training 

opponent
player  
player  

depth  
     
     

depth  
     
     

depth  
     
     

depth  
     
     

depth  
     
     

depth  
     
     

depth  
     
     

table    winning percentages program learned game tree search various
depths  opponent player   program search depth reduced
   opponent player   program uses weight vector
learning 

training               elo points  games  results shown figs   
  indicate mmto outperforms comparison training 
large number features contributed playing strength programs
learned mmto  although eabc showed small improvement terms agreement
rate elo rating  eabcd consistently yielded significant improvements two criteria  thus  concluded mmto scales well forty million features  note
computational cost eabcd reasonably small practical game play 
number features appear position        less even total
number features forty million  also  summations table   maintained incremental manner program makes unmakes move  sort
feature design similar famous othello program  buro         result 
bonanza using eabcd searched       nodes sec intel xeon x       
threads  speed slower many chess programs  average
strong shogi programs  addition  found bonanza using eabcd trained
mmto played better comparable top shogi programs actual
tournaments  details discussed section     
two additional fixed depth self play experiments conducted see evaluation
functions trained using shallow searches  depth   quiescence search  effective
deep searches  table   shows winning percentages learned program various
   

filarge scale optimization evaluation functions minimax search

search depths game play  learned program eabcd evaluation function yielded
    th iteration  figure     winning percentages program
 player    search depth reduced   around      thus  see
deeper learned program searched  stronger program was  tesauro       
reported similar results using comparison training  addition  winning percentage
    program  player    searched depth used eabc
    th iteration  thus  use eabcd trained     iterations effective
even program searched deeper  here  winning percentages computed
thousand games  seventy six games less ending draws exceeding     moves
counted   fifty megabytes memory assigned transposition table
program  uncertainties indicated   estimated conducting two sided test
significance level    one thousand games 
    numerical stability convergence
investigated continuity partial differentiability objective function
convergence feature weights empirical manner  forward pruning techniques game tree searches speed mmto practical applications  methods
always maintain continuous search values  shown appendix a    moreover 
objective function contains large number search values  means difficult
estimate properties theoretical manner 
make empirical investigation manageable  used smallest evaluation
function ea deals thirteen shogi piece values  moreover  reduced number
game records         game records         desired moves z p              
move pairs removing duplications handicapped games 
      surface objective function
investigated function surface main part objective function j p  w  
mmto eq      generating contour maps millions sampling vectors w  
note contour line  isovalue surface  curve along functions take
value  contour lines certain properties  gradient function
perpendicular lines  magnitude gradient large two lines
close together  addition  closed loop contour line indicates location local
minimum maximum 
two thirteen piece values weight vector w sampled order draw
contour maps two dimensional functions interval   piece value 
remaining eleven pieces assigned reasonable values       pawn        lance      
 knight        silver general        gold general        bishop        rook        promoted
pawn        promoted lance        promoted knight        promoted silver        promoted
w   ignored w
bishop        promoted rook   constraint term jc  w
w   turned piece values 
could freely changed regularization term jr  w
nominal depth   search  together quiescence search  used 
analyzed two pairs  hgold  bishopi  hpawn  promoted lancei  figure   shows
enlargement contour map j p  wgold   wbishop    contour interval        
map computed ranges             bishop           
   

fihoki   kaneko

    bishop pro bishop

    bishop dragon
    gold bishop

    bishop rook

    bishop silver

gold general weight

    gold pro bishop

    gold rook
   
   

x x

   
   
   

objective function

    gold pro rook

   

     

    gold silver
   

       

           
bishop weight

   

   

     
     

   

       
   

   

       

     
                   
bishop weight

                   
gold general weight

figure     upper panel  enlarged contour map j p  wgold   wbishop    dashed lines
indicate critical boundaries two dimensional function
partially differentiable  two minima indicated x   bottom panel 
cross sections contour map  left one shows intersection
map line wgold        shows wbishop       

gold general  note function simply increases interesting
structures outside enlarged map  figure    shows enlargement contour
map j p  wpawn   wpro lance    contour interval         map computed
ranges           pawn            promoted lance 
see maps local minima within reasonable ranges
sudden changes function values  although function depends large
number empirical search values  s p  w    approximately continuous amenable
optimization basis gradients approximated mmto 
hand  maps illustrate three difficulties  first difficulty clear
edges contour lines  indicate function partially differentiable
points edges  dashed lines maps critical boundaries
profit loss ratio material exchanges inverts itself  example  silver usually
   

filarge scale optimization evaluation functions minimax search

    pro lance lance     pro lance knight     pro lance silver
    pawn silver

pawn weight

   
    pawn knight
   

    pawn lance
    lance promotion pawn

   
x

   

   

   

   

x

   

   

   

objective function

promoted lance weight
      
      
           
      
          
      
      
                       
promoted lance weight

    
    
    
    
    

           
   

                   
pawn weight

figure      upper panel  enlarged contour map j p  wpawn   wpro lance    dashed
lines indicate critical boundaries two dimensional function
partially differentiable  two minima indicated x   bottom panel 
cross sections contour map  left one shows intersection
map line wpawn        shows wpro lance       

less valuable bishop  capturing silver becomes profitable capturing
bishop bishop value smaller      boundary labeled bishop silver
figure    discussed appendix a  function always partially differentiable
critical boundaries  multiple moves share best value  note
boundaries theory  e g   bishop promoted knight boundary  whether
boundary visible depends training set evaluation features  addition 
boundaries become winding curves non linear evaluation function used instead
linear weighted sum 
second difficulty  scaling problem  illustrated figure     map 
see scales two piece values differ two orders magnitude 
is  pawn value variation five hundred changes function value       whereas
promoted lance value variation five hundred changes function value        
difference scaling  surface along promoted lance almost flat 
property explains pawn value optimized earlier pieces
comparison training  shown figure    property ill scaling disadvantageous
comes optimizing promoted lance value using naive gradient decent method 
   

fihoki   kaneko

methods based second order partial derivatives approximations hessian matrix
resolve problem  however  behave poorly non partially differentiable points
many boundaries  two difficulties point grid adjacent update mmto
effective 
third difficulty multiple local minima two maps 
means results mmto depend initial values chance ending
local rather global minimum  investigate problem next
subsection       
      empirical convergence local minima properties
previous subsection  examined two dimensional cross sections function
j p  w    subsection  loosen restriction two thirteen dimensions 
sufficiently large express piece values shogi  aim experiment
catch glimpse global map numerical convergences arbitrary initial
guesses values pieces 
purpose  monte carlo sampling initial guess  w      carried
enumerate local minima analyze optimized vectors  ran     mmto
randomized initial values  here  uniformly distributed integer range           
assigned vector component  resulting vector scaled satisfy
w       
equality condition g w
figure    shows cosine similarity objective function value hundred    
runs  here  cosine similarity weight vector measured relative best vector
whose objective function smallest among     vectors     iterations 
majority runs  see function values weight vectors converged
numerically    iterations  here  regard iteration procedure converged
function values similarities oscillate show neither steady increase
decrease    th     th iteration  although convergence almost assured
mmto thirteen piece values  would difficult achieve feature weights
optimized  example  figure   shows convergence twothousand iterations using eabcd       iterations took week intel
x     workstation  could afford investigate convergence eabcd
current hardware  however      iterations nonetheless achieved significant improvement
strength  shown figure   
see trials mmto ended multiple local minima 
although multiplicity minima generally undesirable optimization 
other  favorable properties  first property run mmto changed
weight vector components sufficient amount  is  cosine similarity
    optimized vectors localized range             random
initial vectors widely spread  see top panel figure      second property
weak correlation cosine similarities initial optimized
vectors  means starting better initial vector terms cosine similarity
beneficial  see top panel figure      however  starting better initial
vector terms objective function value beneficial  see middle panel
figure      third distribution local minima formed structures  see
   

filarge scale optimization evaluation functions minimax search

    
    
    
    
    

similarity

cosine similarity weight vector

    

    
    

    
    
    

objective function

    

objective function

    

     
     

    
     
     
iteration

    

 

 

 

 

        

  
iteration

 

 

 

        

   

figure     hundred runs mmto weight vector w consisting thirteen piece
values  initial vectors set using pseudo random numbers  inset
enlargement showing appearance numerical convergences 
top panel shows cosine similarities relative best weight vector 
bottom panel shows values objective function 

bottom panel figure      is  lower local minimum is  similar
becomes best vector  moreover  number local minima decreases weight
vector gets farther away best 
investigated dependence performance nominal search depth
step     shown figure    similar results terms convergence distribution
local minima obtained using deeper search nominal depth   
mmto depth   consumes time mmto depth    number
   

fiinitial objective function

cosine similarity initial vector

hoki   kaneko

   
   
   
   
   
    

corr       

    

    

    
corr        

optimized objective function

     
     
     
     
     
corr        
    

    

    

    

cosine similarity optimized vector

figure     scatter plots     trials thirteen dimensional weight vectors  vector
expresses thirteen piece values  cosine similarity vector measured
relative best vector  initial vector consists uniform pseudo random
numbers  optimized one     th vector mmto iterations
starting initial one  inset shows correlation coefficient
scatter plot 

random initial vectors reduced     number iterations reduced
sixty sake speed  majority runs  function values weight
vectors converged    iterations  figure    shows strength  elo rating  objective   

filarge scale optimization evaluation functions minimax search

   
depth    corr         
depth    corr         

elo rating

  
 
   
    
    
     

     

     

     

     

     

     

objective function

figure     scatter plots thirteen dimensional weight vectors      vectors indicated
crosses learned nominal depth   search step        
vectors indicated squares learned depth   search 

function value    runs depth    squares      runs depth    crosses  
here  elo ratings identified using maximum likelihood estimation         
random pairing games        nodes move   elo rating depth     
average depth      average  also  correlation coefficient
elo rating objective function value depth        depth
        moreover  compared performance two best vectors gave
smallest objective function values  here  computed winning probability
best results depth      player allowed use one second move 
one core intel xeon x     fifty megabytes memory assigned
transposition table  excluding two drawn games two games exceeding thousand
moves  obtained       winning rate program using best results
depth    results indicate mmto better depth   depth   
    performance mmto tournament conditions
mmto invented developer bonanza made one best programs
shogi  moreover  ideas behind earlier versions mmto published japanese
 hoki        adopted many developers dramatically changed shogi
programs 
one authors started developing bonanza       published program files
web       published source codes web       hoki         paper
gives detailed descriptions evaluation function learning  whereas literature  hoki
  muramatsu        gives detailed descriptions game tree pruning bonanza 
addition learning method mmto  bonanza uses evaluation function eabcd
shown table    earlier versions      used subset eabcd modified
   

fihoki   kaneko

 
 
 
 
 

     may
bonanza
yss
kcc shogi
tacos
gekisashi

     may
yss
tanase shogi
gekisashi
bonanza
bingo shogi

     may
gekisashi
tanase shogi
bonanza
yss
bingo shogi

     may
gps shogi
otsuki shogi
monju
kcc shogi
bonanza

 
 
 
 
 

     may
gekisashi
shueso
gps shogi
bonkras
bonanza feliz

     may
bonkras
bonanza
shueso
gekisashi
ponanza

     may
gps shogi
puella
tsutsukana
ponanza
shueso

     may
bonanza
ponanza
gps shogi
gekisashi
ninedayfever

table    program names results recent world computer shogi championship 
mmto  earlier version variant mmto  learning method
influenced mmto used 

l  regularization  hoki         subsequent versions fully evaluate eabcd learned l regularization 
table   shows results world computer shogi championships  since      
performance bonanza examined several computer shogi tournaments 
participant connects server program plays shogi time control
   minutes side  bonanza received first prize twice  second prize once  third
prize once  moreover  players entitled bonanza feliz monju used evaluation functions obtained mmto  thus  claim bonanza uses mmto 
plays better comparable top programs shogi  including commercial ones  method clearly plays level handcrafted shogi programs  moreover 
descriptions learning shogi evaluation functions earlier version mmto
published hoki        japanese quickly recognized significant advances  fact  shogi program conventional handcrafted evaluation functions
broken top five last five years tournaments  one interesting case
results gps shogi  kaneko         winner           tournaments 
source codes available online  tanaka kaneko                   
program uses handcrafted evaluation function      used variant mmto
results dramatically improved  variants mmto used program differ
accordance content policy program  example  tanase shogi 
runner up program       used learning method based mmto handcrafted
evaluation functions  bonkras  ponanza  puella   ninedayfever used variants mmto  excellent results make clear mmto outperforms conventional
programs use handcrafted evaluation functions played extremely well recent
shogi tournaments 
   

filarge scale optimization evaluation functions minimax search

noted versions bonanza add small amount randomness
grid adjacent updates  however  omitted discussion using randomness
paper clear whether added randomness improved quality
evaluation function not  source codes various versions bonanza available
online  hoki        source code mmto two files  learn  c learn  c 
    preliminary experiments chess
far  discussed performance mmto shogi  expect mmto
would effective two player perfect information games provided certain
conditions met      sufficient number game records available      minimax
searches guided heuristic evaluations effective      analytic partial derivatives
evaluation function respect variables available  example  mmto
would yield interesting results applied game solved
means  e g   van den herik  uiterwijk    van rijswijck         also  would yield
interesting results game go monte carlo tree searches effective
minimax searches guided heuristic evaluation function  kocsis   szepesvari       
gelly   silver        browne  powley  whitehouse  lucas  cowling  rohlfshagen  tavener 
perez  samothrakis    colton        gelly  kocsis  schoenauer sebag  silver  szepesvari   
teytaud         moreover  simpler learning method  e g   regression method othello 
buro        would preferable mmto  sufficiently effective 
conducted preliminary experiments chess catch glimpse applicability
mmto games  note already evaluation functions chess
outplay grandmasters  whereas none shogi  thus  might difficult
improve well crafted chess evaluation functions  experiment  chose opensource program  crafty  fair implementation chess program  hyatt        
original evaluation function tightly tuned simple multivariable
function  thus  sake simplicity  modify way except add
new linear combination weighted two pieces square features  features used
evaluate conditions king another piece  eb section     
mirror symmetric property described section     applied features
pawn exists eighth rank counted  results  total number added
weights w b          chess position possesses thirty fewer two piecessquare features  additional computational time due modification became
almost negligible help pawn hash table lazy evaluation technique
come original 
training test sets composed using game records free internet
chess server  fics   games played using standard time control server
two players ratings        more  training set p             desired
moves z p                move pairs removing duplications         game
records  whereas test set p          desired moves z p               move pairs
removing duplications        game records 
figure    shows rate agreement test set number correct answers
chess problems iteration  here  sigmoid function set         
w b           w
w b   
equality constraint used  regularization term jr  w
   

fihoki   kaneko

agreement    

    

    

    

    
    

agreement
number correct answers

    
 

 

 

 

 

     

 

 

 

 

 

  

 

    

     

   

number correct answers

    

iteration

figure     improvement rate agreement test set  solid line  number
correct answers        problems  dashed line  chess  two piece square
weights w b adjusted using mmto 

rating
win

        
     

        
     

        
     

        
     

    
     

table    dependence strength  winning percentages  learned programs
quality  ratings players  training set  uncertainty indicated  
estimated conducting two sided test significance level          
games 

total        chess problems encyclopedia chess middlegames  the second
section     problems   win chess      problems   winning chess sacrifices
        problems  used  krogius  livsic  parma    taimanov        reinfeld       
       learned program searched       nodes per problem eight megabytes
memory assigned transposition table  see agreement rate well
number correct answers tends improve number iterations grows  though
differences moderate  means mmto found room improvement
well implemented chess program  results indicate mmto useful way
learn heuristic evaluation functions chess  especially one design evaluation
features suitable learning 
    data quality dependence
assess importance quality game records  conducted additional experiments using game records players various levels experience shogi  here 
eabcd learned using results eabc figure   initial value  results
summarized table    training set composed records        
rapid time control     seconds per move  games played amateurs popular internet
shogi site  shogi club       first line table shows ratings amateur
players  second line shows winning percentages learned evaluation function
   shogi club     http   www shogidojo com  last access       

   

filarge scale optimization evaluation functions minimax search

evaluation function trained grandmaster game records  here  evaluation function learned     iterations  winning percentages computed
averaging results thousand games  about    drawn games games exceeding
    moves counted   player allowed use one second one core
intel xeon x     move  fifty megabytes memory assigned
transposition table  table   shows significance quality training set  use
game records stronger players made program stronger 

   conclusion
presented method  minimax tree optimization  mmto   uses game records
adjust full set feature weights evaluation function two player game 
learning mmto designed search results match desired moves 
e g   recorded moves grandmaster games  mmto consists two procedures     
shallow heuristic search training positions using current feature weights
    update guided approximation gradient objective function 
new combination simple smooth approximation step function grid adjacent
updates standard techniques  i e   gradient guided optimization  constraints  regularization  contributed scalability stability mmto led showing
substantial improvements existing methods 
performance mmto demonstrated experiments shogi  variant chess
larger number legal moves  mmto clearly outperformed existing methods 
addition  experimental results rate agreement playing strength indicate
mmto adjust forty million parameters  possible future work would automated
adjustment step length theoretical convergence analysis 

acknowledgments
grateful dr  masakazu muramatsu support work 

appendix a  notes continuity partial differentiability
minimax value
saw section     objective function mmto piecewise smooth surface 
appendix  theoretically discuss continuity partial differentiability
w   respect w rn   w vector parameters
minimax value vp  w
evaluation function e p  w   p position  continuity minimax value
ensures continuity main part objective function mmto defined eq      
partial differentiability analysis gives conditions approximation inside
mmto described section     valid  first analyze single minimax tree  assuming
tree known fixed  then  extend discussion game tree search
methods possibly explore different trees different w  
definition    evaluation function e      p  rn     r function  p set
positions target game  r set real numbers  rn n  dimensional
   

fihoki   kaneko

euclidean space  evaluation function e p  w   continuous respect parameters w position p p w rn   moreover  evaluation function
e p  w   partially differentiable respect component w w rn  
continuity partial differentiability evaluation function feasible assumptions  note evaluation based ordinary piece square table
properties  recent machine learning evaluation functions  baxter et al  
      veness et al         buro        
definition    theoretical game graph g finite  directed acyclic  connected graph
representing possible transitions states target game  node  resp  edge 
represents position  resp  move   set nodes g corresponds p  v  g    p 
minimax graph finite connected sub graph g  convention  use term
minimax tree minimax graph even tree  denote set minimax
trees g t  node called maximizing  resp  minimizing  node corresponding
position maximizing  resp  minimizing  player move  destination edge
maximizing  resp  minimizing  node source edge minimizing
 resp  maximizing  node  clearly assume node n single position p 
denote evaluation function e n  w   
let lr t set leaf nodes entire sub tree tr tr rooted node r 
omit tree use lr obvious  denote set immediate successors
 or children  node n tree cn t cn   note cn   n leaf 
standard notation  node  or vertex  graph denoted n v  t    however 
appendix  omit v     write n obvious 
w   value associated node n minimax
definition    minimax value vn t  w
tree defined recursively tree structure static evaluation function
e n  w    follows 

n leaf 
e n  w  
w   n non leaf maximizing node 
w   
maxccn t vc  w
vn t  w
    

w
minccn t vc  w   n non leaf minimizing node 
w   obvious  two minimax values b
omit tree use vn  w
maximizing  resp  minimizing  node  say better b   b  resp  b   a  
a   continuity minimax value
continuity minimax value follows continuity evaluation function 
w   continuous respect w minimax
theorem    minimax value vn t  w
w     vn t  w
w      equivalently 
tree w rn   is  limw w
w   vn t  w
w w       logically implies
w   rn      exists      w
 
w   vn t  w
w       
 vn t  w
following assertion ordinary properties basic functions max
min common sense analysis  rather difficult  however  find suitable
reference containing it  therefore give proof useful subsequent
discussion 
   

filarge scale optimization evaluation functions minimax search

x        fk  x
x  continuous function
proposition    let k natural number f   x
x   continuous function rn   similarly  mini  fi  x
x  
rn   r  then  maxi  fi  x
n
continuous function r  
x  continuous  x   rn      exists
proof   x
x x      implies  fi  x
x   x
x         hence  choose   mini  
     x
 
 
x x     implies  fi  x
x   x
x                   k  is 
 x
x       x
x     x
x       
 x

             k 

note ai   bi              k obviously implies maxi ai   maxi bi   thus 
inequalities obtain
x      max  x
x    max  x
x       
max  x






is 

x  max  x
x        
  max  x




x   proof similar mini  x
x  
implies continuity maxi  x
let r root given tree   now  prove theorem   basis
mathematical induction leaf nodes lr t root r  is  leaf node
n lr t   minimax value continuous continuity evaluation
w     e n  w    internal node n  assume continuity holds
function  vn t  w
child c cn t   induction hypothesis proposition   ensure continuity
w   
vn t  w
a   stability principal variations
subsection  showed continuity minimax values continuity
min max functions  here  show best moves principal variations
stable changes leaves small enough  analyze stability order
discuss partial differentiability 
 
w    hereafter called best children  denotes set
 w
definition    symbol cn t
children node n tree minimax value n 
 
w      c cn t  vc  w
w     vn  w
w    
 w
cn t
 

w    here    b denotes
w    is  cn t   cn t
 w
 w
denote rest children cn t
set difference  i e    e e e
  b  

child considered best choice parent node minimax value
child parent node  two children share value 
w   contains one child  otherwise  number nodes cn   w
w   greater
cn   w
one 
definition    let r root tree t  principal variation  abbreviated pv
w   tree sub tree obtained closure best children
short   w
root 
w      r  
   w
 

w      c cn t
w     n i   w
w        
 w
 w
w   
 w


 

w   
 w

i  

   

fihoki   kaneko

n   

 
 
n    n    n   

 

n    n    n   

figure     example minimax tree  graph  transposition n 
 
 

w     cn t
w   cn t
w     n  w
w    also  denote leaves
note cn t
 w
 w
 w



w   l  w
w    is   w
w   lr t  
 w

example    figure    shows small minimax tree two best children root n   
maximizing minimizing nodes denoted boxes circles  respectively  here 
cn      n    n    cn      n     principal variation tree  n    n    n    n    
lemma    internal node n tree w   rn   exists
w   w       n   set best
positive number n w   satisfying  w
 
 
children node n w subset one w  
 
 
w      w   s t   w
w   w       n  
w     cn t
 w
 w
cn t

w     empty  assertion trivial 
proof  child values same  i e   cn  w
otherwise  let   minimum absolute difference best value
w     vc  w
w           continuity minimax
values  i e       minccn  w
w      vn  w
w   w       n  
values ensures existence n w   satisfying  w
 
 
 
 
w   vc  w
w            vn  w
w   vn  w
w            definition
maxccn  vc  w

 
w   satisfies
n triangle inequalities  c cn t  w
w     vn  w
w     
   vc  w
w     vc  w
w         vc  w
w     vn  w
w     
 vc  w
w     vc  w
w         vc  w
w     vn  w
w         vn  w
w     vn  w
w     
 vc  w


w     vn  w
w             
   vc  w
 
 
 
 
w   vn  w
w         
   vc  w
w     vn  w
w                 namely  vc  w
w        vn  w
w      implies definition
thus   vc  w
 
w     
 irrespective whether n max min node  c   cn t
 w
definition     tree stability tree minimum value n among
nodes n   n positive number satisfying lemma    note minimum
value     exists finite 
example     reference figure     suppose leaf value changes     
w     vn  w
w          internal node n heights      
then  proven  vn  w
  order  obvious n    n    n    proven n    n  n   
finally n    see neither n  n  become new best node result
change 
   

filarge scale optimization evaluation functions minimax search


p

vn


u
 





w  
vn  w

w  
 w
j

w  
vc  w
 c cn   
  h
w      c
vc  w
  cn   
q



w     maximizing node n  w   changes along i th comfigure     sketch vn  w
 
w     n equals vc  w
w     one old best
ponent wi   h w     here  vn  w
 
 
w   
children c cn  w

a   partial differentiability
show partial differentiability  well partial derivative  minimax
value node tree depends principal variations  denote right
left partial derivatives function rn   r point x  
f  
x    
 x
x 


f  x             x i   h          x n   f  x             x n  
 
h  
h

    

f  
x    
 x
x


f  x             x i   h          x n   f  x             x n  
 
h 
h

    

lim
lim

let us pay attention single parameter xi changes h limit opf
 
erations  hereafter  parameters held constant often omitted x
   x   
x one dimensional parameter interest  use symbol
analogy partial derivative order forget parameters
omitted 
w   tree
theorem     node n principal variation  w
w   partial derivative evaluation
w rn   exists leaf la l  w

w    vn   w
w     w
function equals right partial derivative vn  w
e la   w    similarly 

w


w   partial derivative evaluation function equals
exists leaf lb l  w

w    vn  w
w     w
left partial derivative vn  w
e lb   w   

w


proof theorem  given end subsection  based stability
     w
w   w        h 
best moves  assume w      w             wi    h          wn
sufficiently small appendix a    consequently   h      node n
tree w   rn  

 
 n leaf 

e n  w  
     n maximizing node 
 
w
max
v
 w
 
 
c
w   
w  
vn  w
ccn t  w

min  
w      n minimizing node  
w     vc  w
cc
 w
n t

   

    

fihoki   kaneko

w     changing h  n maxexample     figure    sketches example vn  w
w     h      value
imizing node  three best children value vn  w
continuously  not always linearly  changes h  best child depends sign
w     h less   minimax
h  always one c cn   w
w     sufficiently less  by least     vn  w
w    
values children c cn  w
h     
w   given
next goal show right left partial derivatives vn  w
w    respectively 
right left partial derivatives one best children cn   w
following propositions describe ordinary properties right left limits
basic functions max min  similar arguments found comprehensive textbook
calculus  give detailed proof here  however  rather difficult find
precisely assertion textbook 
proposition     let k natural number f   x        fk  x  continuous
function r   r  suppose functions value point x    i e  

 
maxi  x      mini  x     right partial derivative x
   x    then 
 
right partial derivative minimum maximum  x  point x exists
equal minimum maximum right partial derivatives  x     respectively 
maxi  

mini  

 x     max    x    
 x     min    x    
 
 
x
x
x
x
proof  let o h  landaus symbol  let us use denote residual terms converging
 
 
  faster h  i e   limh   o h 
h      recall  x     f   x                k 
positive h 


 
 
max  x   h  max  x     max  x     h    x     o h  max  x   




x



  max f   x      h    x      o h  f   x   

x


 
  h max    x     o h 
x
 

 

eq        function maxi  x  point x  right partial derivative maxi
argument applies right partial derivative mini  x  


 x    
x 

proposition     suppose functions value point x 

 
functions left derivative x
 x    then  left partial derivative minimum
maximum  x  point x  equal maximum minimum left partial
derivatives  x    
maxi  

mini  

 x     min  x    
 x     max  x    


x
x
x
x
   

filarge scale optimization evaluation functions minimax search

proof  using similar algebra proof proposition     find negative h 


 
 
 
max  x   h  max  x     h min  x     o h  


x

 
eq        function maxi  x  point x  left partial derivative mini x
 x   
note min max switched algebra negativity h 
argument applies left partial derivative mini  x  

lemma     let gi   n  w    

vn
w 
 w
wi 

 resp  gi  n  w    

vn
w    right  resp 
 w
wi
w rn internal

left 

w   
partial derivative minimax value vn  w
node
w   tree t  exist right left partial derivatives
n principal variation  w
w   respect              n   right left partial
gi   n  w   gi  n  w   vn  w
derivatives are 

 
maxcc    w
w   gi  c  w    n  maximizing node 
n t
 
gi  n  w    
 
mincc    w
w   gi  c  w    n  minimizing node 
n t


mincc    w
w   gi  c  w    n  maximizing node 
n t

gi  n  w    

 n  minimizing node  
maxcc    w
w   gi  c  w  
n t

proof  prove equalities basis mathematical induction leaf nodes
w    definition evaluation function 
lr t root r  leaf n l  w
w   clearly continuous partially differentiable respect
minimax value vn  w
component w rn   internal node n  assume  induction hypothesis 
right partial derivative gi   c  w   left partial derivative gi  c  w   exist
w     cn   w
w      h    eq       
child c cn t   recall cn   w
induction hypothesis proposition    
maxccn   w
w   vc
wi 

minccn   w
vc
vc
w   vc
w   
w     min
w   
 w
 w
 
 
   w
 
 
w
w
w
w 
w 
ccn  w
ccn  w




w     max
 w

similarly  proposition    
maxccn   w
w   vc
wi

minccn   w
vc
vc
w   vc
w   
w     max
w   
 w
 w


 w
 
 
w
w
w
w 
w 
ccn  w
ccn  w




w     min
 w

w    obvious gi   n  w    
now  prove theorem     leaf n l  w

w    lemma    ensures left
  w
e n  w    internal node n  w

right partial derivatives gi   n  w   gi  n  w   given one best children 
w  
thus  root r  always exist leaves la lb l  w
gi  n  w  

gi   r  w    


wi

gi  r  w    

e la   w   
   


wi

e lb   w   

    

fihoki   kaneko


g    n  w        
g  n  w        

wi

e a  w        
e a  w        

n






g    r  w       g  r  w        
w      
vr  w

r

c
 b


wi

e c  w        
e c  w        


wi

e b  w        
e b  w        

w   exists w     equal partial
figure     although partial derivative vr  w

 
derivative pv leaf wi e a  w   

w  
remark     definition  gi   n  w       gi  n  w      partial derivative vn  w
 

 
w   satisfying
respect wi exists point w leaf l l  w


w    
vn  w
e l  w     
wi
wi

    

w   respect
remark                  n   partial derivative minimax value vn  w

 
 

w     
wi exists w equals wi e l  w    l unique element l  w
w   partial derivative
remark     exists tree tr minimax value vn  w
 
w          
respect wi w   even leaves l pv unique   l  w

 
give different partial derivatives wi e l  w    example sketched figure    
partial derivative     b c 
a   game tree search pruning techniques
consider game tree search function takes root position r evaluationw   minimax values
function parameters w inputs  yields minimax tree trs  w
 w
w
w
vn tr  w
 w
 


n


  

call

game tree
search

static 
provided yields
w 
r


 
w      v  tr  w
w     root r  then 
constant tree respect w   i e   v  tr  w
w   yielded static game tree
theorems      apply minimax value vr trs  w
search  example  fixed depth minimax search minimax search considering limited
types moves  e g   capture promotion  static game tree search  minimax search
stand pat used quiescence search  beal        static  too  note stand
pat node n equivalent virtual move adding evaluation function e n  w  
w   eq        even n leaf node 
candidate node value vn  w
pruning techniques incorporated  part tree pruned explored 
 
w   trs  w
w   yielded
consider static search s  pruning     tree trs  w
 
  call pruning conservative  provided yields minimax value
w     vr t s   w
w    theorem   applies minimax
root r w rn   vr trs  w
w    w
r
w
value root r  vr t s   w
 w
  
yielded



static
game tree search conservative
w 
r
pruning  standard pruning  knuth   moore        conservative pruning  however 
many pruning techniques  e g   static exchange evaluation  reul          extended  futility
pruning  heinz         null move pruning  adelson velskiy et al          late move
reductions  romstad         prune sub tree without prove sub   

filarge scale optimization evaluation functions minimax search

tree irrelevant minimax value root  thus  pruning techniques
generally conservative 
a   summary
minimax value root tree explored game tree search wellconfigured pruning techniques continuous  result suggests continuity
objective function mmto eq       empirically observed section     
partial differentiability  theorem    suggest feasible consider leaves
principal variations search tree  one principal variation  stated
remark     use partial derivative unique leaf introduced section    
correct  otherwise  i e   multiple principal variations  partial derivative
may exist different partial derivative one leaves  stated
remark     although frequency cases depends target game
evaluation features  almost negligible experiments discussed previous work
 kaneko   hoki        

references
adelson velskiy  g  m   arlazarov  v  l     donskoy  m  v          methods
controlling tree search chess programs  artificial intelligence                 
akl  s  g     newborn  m  m          principal continuation killer heuristic 
proceedings      annual conference  acm     pp          new york  ny 
usa  acm 
anantharaman  t          evaluation tuning computer chess  linear discriminant methods  icca journal                 
baxter  j   tridgell  a     weaver  l          learning play chess using temporaldifferences  machine learning                 
beal  d  f          generalised quiescence search algorithm  artificial intelligence     
     
beal  d  f     smith  m  c          temporal difference learning applied game playing
results application shogi  theoretical computer science                
    
bertsekas  d  p     bertsekas  d  p          nonlinear programming   nd edition   athena
scientific 
bjornsson  y     marsland  t  a          learning control search extensions  caulfield 
h  j   chen  s  h   cheng  h  d   duro  r  j   honavar  v   kerre  e  e   lu  m  
romay  m  g   shih  t  k   ventura  d   wang  p  p     yang  y   eds    jcis  pp 
        jcis   association intelligent machinery  inc 
browne  c   powley  e   whitehouse  d   lucas  s   cowling  p   rohlfshagen  p   tavener 
s   perez  d   samothrakis  s     colton  s          survey monte carlo tree
search methods  computational intelligence ai games  ieee transactions
on             
   

fihoki   kaneko

buro  m          improving heuristic mini max search supervised learning  artificial
intelligence                 
buro  m   long  j  r   furtak  t     sturtevant  n  r          improving state evaluation 
inference  search trick based card games  ijcai  pp           
buro  m          statistical feature combination evaluation game positions 
journal artificial intelligence research            
campbell  m   hoane  jr   a  j     hsu  f  h          deep blue  artificial intelligence 
               
chellapilla  k     fogel  d          evolving neural networks play checkers without
relying expert knowledge  neural networks  ieee transactions on              
     
coulom  r          computing elo ratings move patterns game go  icga
journal                 
coulom  r          clop  confident local optimization noisy black box parameter tuning 
herik  h     plaat  a   eds    advances computer games     no       lncs 
pp          springer verlag 
duchi  j   hazan  e     singer  y          adaptive subgradient methods online learning
stochastic optimization  journal machine learning research               
fawcett  t  e          feature discovery problem solving systems  ph d  thesis  department computer science  university massachusetts  amherst 
furnkranz  j          machine learning games  survey  machines learn play
games  pp        nova science publishers  commack  ny  usa 
gelly  s   kocsis  l   schoenauer m   sebag  m   silver  d   szepesvari  c     teytaud  o 
        grand challenge computer go  monte carlo tree search extensions 
commun  acm                 
gelly  s     silver  d          monte carlo tree search rapid action value estimation
computer go  artificial intelligence                     
gomboc  d   buro  m     marsland  t  a          tuning evaluation functions maximizing concordance  theoretical computer science                  
heinz  e  a          extended futility pruning  icca journal               
heinz  e  a          adaptive null move pruning  icca journal                 
hoki  k  bonanza computer shogi program   http   www geocities jp bonanza 
shogi  last access        japanese 
hoki  k          optimal control minimax search results learn positional evaluation 
  th game programming workshop  gpw       pp        kanagawa  japan 
japanese 
hoki  k     kaneko  t          global landscape objective functions optimization shogi piece values game tree search  van den herik  h  j    
plaat  a   eds    advances computer games     no       lncs  pp         
springer verlag 
   

filarge scale optimization evaluation functions minimax search

hoki  k     muramatsu  m          efficiency three forward pruning techniques shogi 
futility pruning  null move pruning  late move reduction  lmr   entertainment
computing              
hsu  f  h   anantharaman  t  s   campbell  m  s     nowatzyk  a          deep thought 
marsland  t  a     schaeffer  j   eds    computers  chess  cognition  pp 
      springer verlag 
iida  h   sakuta  m     rollason  j          computer shogi  artificial intelligence        
           
kaneko  t          recent improvements computer shogi gps shogi  ipsj magazine                  japanese 
kaneko  t     hoki  k          analysis evaluation function learning comparison
sibling nodes  van den herik  h  j     plaat  a   eds    advances computer
games     no       lncs  pp          springer verlag 
knuth  d  e     moore  r  w          analysis alpha beta pruning  artificial
intelligence                
kocsis  l     szepesvari  c          bandit based monte carlo planning  machine learning  ecml       vol        pp          springer 
krogius  n   livsic  a   parma  b     taimanov  m          encyclopedia chess middlegames  combinations  chess informant 
levinson  r     weber  r          chess neighborhoods  function combination  reinforcement learning  marsland  t  a     frank  i   eds    computer games 
no       lncs  pp          springer verlag 
marsland  t  a          evaluation function factors  icca journal              
marsland  t  a     campbell  m          parallel search strongly ordered game trees 
acm computing surveys                 
nitsche  t          learning chess program  advances computer chess    pp 
        pergamon press 
nocedal  j     wright  s          numerical optimization  springer verlag 
nowatzyk  a          http   tim mann org dt eval tune txt 
pearl  j          scout  simple game searching algorithm proven optimal properties 
proceedings first annual national conference artificial intelligence 
pp         
reinefeld  a          improvement scout tree search algorithm  icca journal 
           
reinfeld  f               winning chess sacrifices combinations  wilshire book
company 
reinfeld  f          win chess  dover books chess   dover publications 
reul  f          static exchange evaluation  approach  icga journal              
   

fihoki   kaneko

romstad  t  introduction late move reductions  http   www glaurungchess com 
lmr html  last access       
russell  s  j     norvig  p          artificial intelligence  modern approach   nd edition  
prentice hall 
schaeffer  j          experiments search knowledge  ph d  thesis  department
computing science  university waterloo  canada 
schaeffer  j          history heuristic alpha beta search enhancements practice 
ieee transactions pattern analysis machine intelligence  pami             
     
schaeffer  j   hlynka  m     jussila  v          temporal difference learning applied
high performance game playing program  ijcai    proceedings   th
international joint conference artificial intelligence  pp          san francisco 
ca  usa  morgan kaufmann publishers inc 
silver  d     tesauro  g          monte carlo simulation balancing  icml     proceedings   th annual international conference machine learning  pp         
acm 
sutton  r  s     barto  a  g          reinforcement learning  introduction  adaptive
computation machine learning   mit press 
tanaka  t     kaneko  t  gps shogi   http   gps tanaka ecc u tokyo ac jp 
gpsshogi  last access        japanese 
tesauro  g          comparison training chess evaluation functions  machines
learn play games  pp          nova science publishers 
tesauro  g          programming backgammon using self teaching neural nets  artificial
intelligence                   
tibshirani  r          regression shrinkage selection via lasso  j  royal  statist 
soc b                 
tsuruoka  y   yokoyama  d     chikayama  t          game tree search algorithm based
realization probability  icga journal                 
ugajin  t     kotani  y          learning evaluation function based tree strap shogi 
  th game programming workshop  pp          japanese 
van den herik  h  j   uiterwijk  j  w  h  m     van rijswijck  j          games solved 
future  artif  intell                     
van der meulen  m          weight assessment evaluation functions  beal  d   ed   
advances in  computer chess    pp       
veness  j   silver  d   uther  w     blair  a          bootstrapping game tree search 
advances neural information processing systems     pp           
zobrist  a  l          new hashing method application game playing  icca
journal               

   


