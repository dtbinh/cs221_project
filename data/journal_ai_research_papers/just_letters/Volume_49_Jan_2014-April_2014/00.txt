journal of artificial intelligence research               

submitted       published     

multimodal distributional semantics
elia bruni

elia bruni unitn it

center for mind brain sciences 
university of trento  italy

nam khanh tran

ntran l s de

l s research center 
hannover  germany

marco baroni

marco baroni unitn it

center for mind brain sciences 
university of trento  italy
department of information engineering and computer science 
university of trento  italy

abstract
distributional semantic models derive computational representations of word meaning
from the patterns of co occurrence of words in text  such models have been a success
story of computational linguistics  being able to provide reliable estimates of semantic
relatedness for the many semantic tasks requiring them  however  distributional models
extract meaning information exclusively from text  which is an extremely impoverished
basis compared to the rich perceptual sources that ground human semantic knowledge  we
address the lack of perceptual grounding of distributional models by exploiting computer
vision techniques that automatically identify discrete visual words in images  so that the
distributional representation of a word can be extended to also encompass its co occurrence
with the visual words of images it is associated with  we propose a flexible architecture
to integrate text  and image based distributional information  and we show in a set of
empirical tests that our integrated model is superior to the purely text based approach 
and it provides somewhat complementary semantic information with respect to the latter 

   introduction
the distributional hypothesis states that words that occur in similar contexts are semantically similar  the claim has multiple theoretical roots in psychology  structuralist linguistics  lexicography and possibly even in the later writings of wittgenstein  firth       
harris        miller   charles        wittgenstein         however  the distributional hypothesis has had a huge impact on computational linguistics in the last two decades mainly
for empirical reasons  that is  because it suggests a simple and practical method to harvest
word meaning representations on a large scale  just record the contexts in which words
occur in easy to assemble large collections of texts  corpora  and use their contextual profiles as surrogates of their meaning  nearly all contemporary corpus based approaches to
semantics rely on contextual evidence in one way or another  but the most systematic and
extensive application of distributional methods is found in what we call distributional
semantic models  dsms   also known in the literature as vector space or semantic space
     ai access foundation  all rights reserved 

fibruni  tran   baroni

models of meaning  landauer   dumais        sahlgren        schtze        turney  
pantel        
in dsms  the meaning of a word is approximated with a vector that keeps track of
the patterns of co occurrence of the word in text corpora  so that the degree of semantic
similarity or  more generally  relatedness  budanitsky   hirst        of two or more words
can be precisely quantified in terms of geometric distance between the vectors representing
them  for example  both car and automobile might occur with terms such as street  gas
and driver  and thus their distributional vectors are likely to be very close  cuing the fact
that these words are synonyms  extended empirical evidence has shown that distributional
semantics is very good at harvesting effective meaning representations on a large scale 
confirming the validity of the distributional hypothesis  see some references in section    
below  
still  for all its successes  distributional semantics suffers of the obvious limitation that
it represents the meaning of a word entirely in terms of connections to other words  a long
tradition of studies in cognitive science and philosophy has stressed how models where the
meaning of symbols  e g   words  are entirely accounted for in terms of other symbols  e g  
other words  without links to the outside world  e g   via perception  are deeply problematic  an issue that is often referred to as the symbol grounding problem  harnad        
dsms have also come under attack for their lack of grounding  glenberg   robertson 
        although the specific criticisms vented at them might not be entirely well founded
 burgess         there can be little doubt that the limitation to textual contexts makes
dsms very dissimilar from humans  who  thanks to their senses  have access to rich sources
of perceptual knowledge when learning the meaning of words  so much so that some cognitive scientists have argued that meaning is directly embodied in sensory motor processing
 see the work in de vega  glenberg    graesser        for different views on embodiment in
cognitive science   indeed  in the last decades a large amount of behavioural and neuroscientific evidence has been amassed indicating that our knowledge of words and concepts is
inextricably linked with our perceptual and motor systems  for example  perceiving actiondenoting verbs such as kick or lick involves the activation of areas of the brain controlling
foot and tongue movements  respectively  pulvermueller         hansen  olkkonen  walter  and gegenfurtner        asked subjects to adjust the color of fruit images objects until
they appeared achromatic  the objects were generally adjusted until their color was shifted
away from the subjects gray point in a direction opposite to the typical color of the fruit 
e g   bananas were shifted towards blue because subjects overcorrected for their typical
yellow color  typical color also influences lexical access  for example  subjects are faster
at naming a pumpkin in a picture in which it is presented in orange than in a grayscale
representation  slowest if it is in another color  therriault  yaxley    zwaan         as
a final example  kaschak  madden  therriault  yaxley  aveyard  blanchard  and zwaan
       found that subjects are slower at processing a sentence describing an action if the
sentence is presented concurrently to a visual stimulus depicting motion in the opposite
   harnard  in the original paper  is discussing formal symbols  such as those postulated in fodors language
of thought  fodor         rather than the words of a natural language  however  when the latter are
represented in terms of connections to other words  as is the case in dsms  the same grounding problem
arises  and we follow the recent literature on the issue in referring to it as symbol grounding  where
our symbols are natural language words 

 

fimultimodal distributional semantics

direction of that described  e g   the car approached you is harder to process concurrently
to the perception of motion away from you   see the review in barsalou        for a review
of more evidence that conceptual and linguistic competence is strongly embodied 
one might argue that the concerns about dsms not being grounded or embodied are
exaggerated  because they overlook the fact that the patterns of linguistic co occurrence
exploited by dsms reflect semantic knowledge we acquired through perception  so that
linguistic and perceptual information are strongly correlated  louwerse         because
dogs are more often brown than pink  we are more likely to talk about brown dogs than
pink dogs  consequently  a child can learn useful facts about the meaning of the concept
denoted by dog both by direct perception and through linguistic input  this explains  among
other things  why congenitally blind subjects can have an excellent knowledge of color terms 
see  e g   connolly  gleitman    thompson schill         one could then hypothesize that
the meaning representations extracted from text corpora are indistinguishable from those
derived from perception  making grounding redundant  however  there is by now a fairly
extensive literature showing that this is not the case  many studies  andrews  vigliocco 
  vinson        baroni  barbu  murphy    poesio        baroni   lenci        riordan
  jones        have underlined how text derived dsms capture encyclopedic  functional
and discourse related properties of word meanings  but tend to miss their concrete aspects 
intuitively  we might harvest from text the information that bananas are tropical and eatable 
but not that they are yellow  because few authors will write down obvious statements such
as bananas are yellow   on the other hand  the same studies show how  when humans are
asked to describe concepts  the features they produce  equivalent in a sense to the contextual
features exploited by dsms  are preponderantly of a perceptual nature  bananas are yellow 
tigers have stripes  and so on  
this discrepancy between dsms and humans is not  per se  a proof that dsms will
face empirical difficulties as computational semantic models  however  if we are interested
in the potential implications of dsms as models of how humans acquire and use language
as is the case for many dsm developers  e g   griffiths  steyvers    tenenbaum       
landauer   dumais        lund   burgess        and many others  then their complete
lack of grounding in perception is a serious blow to their psychological plausibility  and
exposes them to all the criticism that classic ungrounded symbolic models have received 
even at the empirical level  it is reasonable to expect that dsms enriched with perceptual
information would outperform their purely textual counterparts  useful computational semantic models must capture human semantic knowledge  and human semantic knowledge
is strongly informed by perception 
if we accept that grounding dsms into perception is a desirable avenue of research  we
must ask where we can find a practical source of perceptual information to embed into dsms 
several interesting recent experiments use features produced by human subjects in concept
description tasks  so called semantic norms  as a surrogate of true perceptual features
 andrews et al         johns   jones        silberer   lapata        steyvers        
while this is a reasonable first step  and the integration methods proposed in these studies
   to be perfectly fair  this tendency might in part be triggered by the fact that  when subjects are asked to
describe concepts  they might be encouraged to focus on their perceptual aspects by the experimenters
instructions  for example mcrae  cree  seidenberg  and mcnorgan        asked subjects to list first
physical properties  such as internal and external parts  and how  the object  looks 

 

fibruni  tran   baroni

are quite sophisticated  using subject produced features is unsatisfactory both practically
and theoretically  see however the work reported by kievit kylar   jones        for a
crowdsourcing project that is addressing both kinds of concerns   practically  using subjectgenerated properties limits experiments to those words that denote concepts described in
semantic norms  and even large norms contain features for just a few hundred concepts 
theoretically  the features produced by subjects in concept description tasks are far removed
from the sort of implicit perceptual features they are supposed to stand for  for example 
since they are expressed in words  they are limited to what can be conveyed verbally 
moreover  subjects tend to produce only salient and distinctive properties  they do not
state that dogs have a head  since thats hardly a distinctive feature for an animal 
in this article  we explore a more direct route to integrate perceptual information into
dsms  we exploit recent advances in computer vision  grauman   leibe        and the
availability of documents that combine text and images to automatically extract visual
features that are naturally co occurring with words in multimodal corpora  these imagebased features are then combined with standard text based features to obtain perceptuallyenhanced distributional vectors  in doing this  we rely on a natural extension of the distributional hypothesis  that encompasses not only similarity of linguistic context  but also
similarity of visual context  interestingly  landauer and dumais  in one of the classic papers
that laid the groundwork for distributional semantics  already touched on the grounding
issue and proposed  speculatively  a solution along the lines of the one we are implementing
here   i f one judiciously added numerous pictures of scenes with and without rabbits to
the context columns in the          corpus matrix  and filled in a handful of appropriate cells
in the rabbit and hare word rows   a dsm  could easily learn that the words rabbit and hare
go with pictures containing rabbits and not to ones without  and so forth   landauer  
dumais        p        
although vision is just one source of perceptual data  it is a reasonable starting point 
both for convenience  availability of suitable data to train the models  and because it is
probably the dominating modality in determining word meaning  as just one piece of
evidence for this claim  the widely used subject generated semantic norms of mcrae et al 
       contain       distinct perceptual features in total  and  of these              are
visual in nature 
do the relatively low level and noisy features that we extract from images in multimodal corpora contribute meaningful information to the distributional representation of
word meaning  we report the results of a systematic comparison of the network of semantic relations entertained by a set of concrete nouns in the traditional text based and
novel image based distributional spaces confirming that image based features are  indeed 
semantically meaningful  moreover  as expected  they provide somewhat complementary
information with respect to text based features  having thus found a practical and effective way to extract perceptual information  we must consider next how to combine textand image derived features to build a multimodal distributional semantic model  we
propose a general parametrized architecture for multimodal fusion that  given appropriate
sample data  automatically determines the optimal mixture of text  and image based features to be used for the target semantic task  finally  we evaluate our multimodal dsms in
   we thank mike jones for pointing out this interesting historical connection to us 

 

fimultimodal distributional semantics

two separate semantic tasks  namely predicting the degree of semantic relatedness assigned
to word pairs by humans  and categorizing nominal concepts into classes  we show that
in both tasks multimodal dsms consistently outperform purely textual models  confirming
our supposition that  just like for humans  the performance of computational models of
meaning improves once meaning is grounded in perception 
the article is structured as follows  section   provides the relevant background from
computational linguistics and image analysis  and discusses related work  we lay out a
general architecture for multimodal fusion in distributional semantics in section    the
necessary implementation details are provided in section    section   presents the experiments in which we tested our approach  section   concludes summarizing our current
results as well as sketching what should come next 

   background and related work
in this section we first give a brief introduction to traditional distributional semantic models
 i e   those based solely on textual information   then  we describe the image analysis
techniques we adopt to extract and manipulate visual information  next  we discuss earlier
attempts to construct a multimodal distributional representation of meaning  finally  we
describe the most relevant strategies to combine information coming from text and images
proposed inside the computer vision community 
    distributional semantics
in the last few decades  a number of different distributional semantic models  dsms  of word
meaning have been proposed in computational linguistics  all relying on the assumption that
word meaning can be learned directly from the linguistic environment 
semantic space models are one of the most common types of dsm  they approximate
the meaning of words with vectors that record their distributional history in a corpus
 turney   pantel         a distributional semantic model is encoded in a matrix whose m
rows are semantic vectors representing the meanings of a set of m target words  each
component of a semantic vector is a function of the occurrence counts of the corresponding
target word in a certain context  see lowe        for a formal treatment   definitions of
context range from simple ones  such as documents or the occurrence of another word
inside a fixed window from the target word  to more linguistically sophisticated ones  such
as the occurrence of certain words connected to the target by special syntactic relations 
 pad   lapata        sahlgren        turney   pantel         after the raw targetcontext counts are collected  they are transformed into association scores that typically
discount the weights of components whose corresponding word context pairs have a high
probability of chance co occurrence  evert         the rank of the matrix containing the
semantic vectors as rows can optionally be decreased by dimensionality reduction  that
might provide beneficial smoothing by getting rid of noise components and or allow more
efficient storage and computation  landauer   dumais        sahlgren        schtze 
       finally  the distributional semantic similarity of a pair of target words is estimated
by a similarity function that takes their semantic vectors as input and returns a scalar
similarity score as output 
 

fibruni  tran   baroni

there are many different semantic space models in the literature  probably the best
known is latent semantic analysis  lsa  landauer   dumais         where a highdimensional semantic space for words is derived by the use of co occurrence information
between words and the passages where they occur  another well known example is the
hyperspace analog to language model  hal  lund   burgess         where each word is
represented by a vector containing weighted co occurrence values of that word with the other
words in a fixed window  other semantic space models rely on syntactic relations instead
of windows  grefenstette        curran   moens        pad   lapata         general
overviews of semantic space models are provided by clark         erk         manning and
schtze         sahlgren        and turney and pantel        
more recently  probabilistic topic models have been receiving increasing attention as
an alternative implementation of dsms  blei  ng    jordan        griffiths et al         
probabilistic topic models also rely on co occurrence information from large corpora to derive meaning but  differently from semantic space models  they are based on the assumption
that words in a corpus exhibit some probabilistic structure connected to topics  words are
not represented as points in a high dimensional space but as a probability distribution over
a set of topics  conversely  each topic can be defined as a probability distribution over
different words  probabilistic topic models tackle the problem of meaning representation
by means of statistical inference  use the word corpus to infer the hidden topic structure 
distributional semantic models  whether of the geometric or the probabilistic kind 
ultimately are mainly used to provide a similarity score for arbitrary pairs of words  and
that is how we will also employ them  indeed  such models have shown to be very effective
in modeling a wide range of semantic tasks including judgments of semantic relatedness and
word categorization 
there are several data sets to assess how well a dsm captures human intuitions about
semantic relatedness  such as the rubenstein and goodenough set  rubenstein   goodenough        and wordsim     finkelstein  gabrilovich  matias  rivlin  solan  wolfman 
  ruppin         usually they are constructed by asking subjects to rate a set of word
pairs according to a similarity scale  then  the average rating for each pair is taken as an
estimate of the perceived relatedness between the words  e g   dollar buck        cord smile 
       to measure how well a distributional model approximates human semantic intuitions 
usually a correlation measure between the similarity scores generated by the model and the
human ratings is computed  the highest correlation we are aware of on the wordsim   
set we will also employ below is of      and it was obtained by a model called temporal
semantic analysis  which captures patterns of word usage over time and where concepts
are represented as time series over a corpus of temporally ordered documents  radinsky 
agichtein  gabrilovich    markovitch         this temporal knowledge could be integrated
with the perceptual knowledge we encode in our model  as a more direct comparison point 
agirre  alfonseca  hall  kravalova  pasa  and soroa        presented an extensive evaluation of distributional and wordnet based semantic models on wordsim  both achieving a
maximum correlation of      across various parameters  
   wordnet  available at http   wordnet princeton edu   is a large computational lexicon of english
where nouns  verbs  adjectives and adverbs are grouped into sets of synonyms  synsets   each expressing
a distinct concept 

 

fimultimodal distributional semantics

humans are very good at grouping together words  or the concepts they denote  into
classes based on their semantic relatedness  murphy         therefore a cognitive aware
representation of meaning must show its proficiency also in categorization  e g   poesio
  almuhareb        baroni et al          concept categorization is moreover useful for
applications such as automated ontology construction and recognizing textual entailment 
unlike similarity ratings  categorization requires a discrete decision to group coordinates cohyponyms into the same class and it is performed by applying standard clustering techniques
to the model generated vectors representing the words to be categorized  as an example 
the almuhareb poesio data set  almuhareb   poesio         that we also employ below 
includes     concepts from wordnet  balanced in terms of frequency and degree of ambiguity  the distributional model of rothenhusler and schtze        exploits syntactic
information to reach state of the art performance on the almuhareb poesio data set  maximum clustering purity across various parameter         the window based distributional
approach of baroni and lenci         more directly comparable to our text based models 
achieves      purity 
other semantic tasks dsms have been applied to include semantic priming  generation
of salient properties of concepts and intuitions about the thematic fit of verb arguments  see 
e g   baroni   lenci        baroni et al         mcdonald   brew        pad   lapata 
      pad  pad    erk         distributional semantic vectors can be used in a wide
range of applications that require a representation of word meaning  and in particular an
objective measure of meaning relatedness  including document classification  clustering and
retrieval  question answering  automatic thesaurus generation  word sense disambiguation 
query expansion  textual advertising and some areas of machine translation  dumais       
turney   pantel        
    visual words
ideally  to build a multimodal dsm  we would like to extract visual information from
images in a way that is similar to how we do it for text  thanks to a well known image
analysis technique  namely bag of visual words  bovw   it is indeed possible to discretize
the image content and produce visual units somehow comparable to words in text  known
as visual words  bosch  zisserman    munoz        csurka  dance  fan  willamowski   
bray        nister   stewenius        sivic   zisserman        yang  jiang  hauptmann 
  ngo         therefore  semantic vectors can be extracted from a corpus of images
associated with the target  textual  words using a similar pipeline to what is commonly
used to construct text based vectors  collect co occurrence counts of target words and
discrete image based contexts  visual words   and approximate the semantic relatedness of
two words by a similarity function over the visual words representing them 
the bovw technique to extract visual word representations of documents was inspired
by the traditional bag of words  bow  method in information retrieval  bow in turn is
a dictionary based method to represent a  textual  document as a bag  i e   order is not
considered   which contains words from the dictionary  bovw extends this idea to visual
documents  namely images   describing them as a collection of discrete regions  capturing
their appearance and ignoring their spatial structure  the visual equivalent of ignoring word
order in text   a bag of visual word representation of an image is convenient from an image 

fibruni  tran   baroni

 




ffffff 

fififi 






figure    representing images by bovw   i  salient image patches or keypoints that contain rich local information are detected and represented as vectors of low level
features called descriptors   ii  descriptors are mapped to visual words on the
basis of their distance from centers of clusters corresponding to the visual words


 the preliminary clustering step is not shown
in the figure    iii  images are finally
represented as a bag of visual words feature vector according to the distribution
of visual words they contain  images depicting the same things with rotations 
occlusions  small differences in the low level descriptors might still have a similar
distribution of visual words  hence the same object can be traced very robustly
across images while these conditions change 

analysis point of view because it translates a usually large set of high dimensional local
descriptors into a single sparse vector representation across images  importantly  the size
of the original set varies from image to image  while the bag of visual word representation
is of fixed dimensionality  therefore  machine learning algorithms which by default expect
fixed dimensionality vectors as input  e g   for supervised classification or unsupervised
clustering  can be used to tackle typical image analysis tasks such as object recognition 
image segmentation  video tracking  motion detection  etc 
more specifically  similarly to terms in a text document  an image has local interest
points or keypoints defined as salient image patches that contain rich local information
about the image  however keypoint types in images do not come off the shelf like word
 

fimultimodal distributional semantics

types in text documents  local interest points have to be grouped into types  i e   visual
words  within and across images  so that an image can be represented by the number of
occurrences of each type in it  analogously to bow  the following pipeline is typically
followed  from every image of a data set  keypoints are automatically detected  note
that in most recent approaches a dense  pixelwise sampling of the keypoints is preferred
to detecting the most salient ones only  and this is the solution that we also adopt  as
explained in section        and represented as vectors of low level features called descriptors 
keypoint vectors are then grouped across images into a number of clusters based on their
similarity in descriptor space  each cluster is treated as a discrete visual word  with its
keypoints mapped onto visual words  each image can then be represented as a bovw feature
vector recording how many times each visual word occurs in it  in this way  we move from
representing the image by a varying number of high dimensional keypoint descriptor vectors
to a representation in terms of a single visual word count vector of fixed dimensionality
across all images  with the advantages we discussed above  visual word assignment and
its use to represent the image content is exemplified in figure    where two images with a
similar content are described in terms of bag of visual word vectors 
what kind of image content a visual word captures exactly depends on a number of
factors  including the descriptors used to identify and represent keypoints  the clustering
algorithm and the number of target visual words selected  in general  local interest points
assigned to the same visual word tend to be patches with similar low level appearance  but
these local patterns need not be correlated with object level parts present in the images
 grauman   leibe        
    multimodal distributional semantics
the availability of large amounts of mixed media on the web  on the one hand  and the
discrete representation of images as visual words  on the other  has not escaped the attention
of computational linguists interested in enriching distributional representations of word
meaning with visual features 
feng and lapata        propose the first multimodal distributional semantic model 
their generative probabilistic setting requires the extraction of textual and visual features
from the same mixed media corpus  because latent dimensions are here estimated through a
probabilistic process which assumes that a document is generated by sampling both textual
and visual words  words are then represented by their distribution over a set of latent
multimodal dimensions or topics  griffiths et al         derived from the surface textual
and visual features  feng and lapata experiment with a collection of documents downloaded
from the bbc news website as corpus  they test their semantic representations on the
free association norms of nelson  mcevoy  and schreiber        and on a subset of    
pairs from wordsim  obtaining gains in performance when visual information is taken into
account  correlations with human judgments of      and      respectively   compared to
the textual modality standalone       and      respectively   even if performance is still
well below state of the art for wordsim  see section     above  
the main drawbacks of this approach are that the textual and visual data must be
extracted from the same corpus  thus limiting the choice of the corpora to be used  and
that the generative probabilistic approach  while elegant  does not allow much flexibility
 

fibruni  tran   baroni

in how the two information channels are combined  below  we re implement the feng and
lapata method  mixlda  training it on the esp game data set  the same source of labeled
images we adopt for our model  this is possible because the data set contains both images
and the textual labels describing them  more in general  we recapture feng and lapatas
idea of a common latent semantic space in the latent multimodal mixing step of our pipeline
 see section       below  
leong and mihalcea        also exploit textual and visual information to obtain a multimodal distributional semantic model  while feng and lapata merge the two sources of
information by learning a joint semantic model  leong and mihalcea propose a strategy
akin to what we will call scoring level fusion below  come up with separate text  and
image based similarity estimates  and combine them to obtain the multimodal score  in
particular  they use two combination methods  summing the scores and computing their
harmonic mean  differently from feng and lapata  leong and mihalcea extract visual information not from a corpus but from a manually coded resource  namely the imagenet
database  deng  dong  socher  li    fei fei         a large scale ontology of images   using
a handcoded annotated visual resource such as imagenet faces the same sort of problems
that using a manually developed lexical database such as wordnet faces with respect to
textual information  that is  applications will be severely limited by imagenet coverage  for
example  imagenet is currently restricted to nominal concepts   and the interest of the
model as a computational simulation of word meaning acquisition from naturally occurring language and visual data is somewhat reduced  humans do not learn the meaning of
mountain from a set of carefully annotated images of mountains with little else crowding
or occluding the scene   in the evaluation  leong and mihalcea experiment with small subsets of wordsim  obtaining some improvements  although not at the same level we report
 the highest reported correlation is      on just    word pairs   furthermore they use the
same data set to tune and test their models 
in bruni  tran  and baroni        we propose instead to directly concatenate the textand image based vectors to produce a single multimodal vector to represent words  as in
what we call feature level fusion below  the text based distributional vector representing a word  taken there from a state of the art distributional semantic model  baroni  
lenci         is concatenated with a vector representing the same word with visual features  extracted from all the images in the esp game collection we also use here  we
obtain promising performance on wordsim and other test sets  although appreciably lower
than the results we report here  we obtain a maximum correlation of      when text  and
image based features are used together  compare to table   below  
attempts to use multimodal models derived from text and images to perform more
specific semantic tasks have also been reported  bergsma and goebel        use textual
and image based cues to model selectional preferences of verbs  which nouns are likely
arguments of verbs   their experiment shows that in several cases visual information is
more useful than text in this task  for example  by looking in textual corpora for words
such as carillon  migas or mamey  not much useful information is obtained to guess which
of the three is a plausible argument for the verb to eat  on the other hand  they also show
   http   image net org 

  

fimultimodal distributional semantics

that  by exploiting google image search functionality   enough images for these words are
found that a vision based model of edible things can classify them correctly 
finally  we evaluate our multimodal models in the task of discovering the color of concrete objects  showing that the relation between words denoting concrete things and their
typical color is better captured when visual information is also taken into account  bruni 
boleda  baroni    tran         moreover  we show that multimodality helps in distinguishing literal and nonliteral uses of color terms 
    multimodal fusion
when textual information is used for image analysis  this is mostly done with different
aims than ours  text is used to improve image related tasks  and typically there is an
attempt to model the relation between specific images and specific words or textual passages
 e g   barnard  duygulu  forsyth  de freitas  blei    jordan        berg  berg    shih 
      farhadi  hejrati  sadeghi  young  rashtchian  hockenmaier    forsyth        griffin 
wahab    newell        kulkarni  premraj  dhar  li  choi  berg    berg         in
contrast   i  we want to use image derived features to improve the representation of word
meaning and  ii  we are interested in capturing the meaning of word types on the basis of
sets of images connected to a word  and not to model specific word image relations 
despite these differences  some of the challenges addressed in the image analysis literature that deals with exploiting textual cues are similar to the ones we face  in particular 
the problem of merging  or fusing  textual and visual cues into a common representational
space is exactly the same we have to face when we construct a multimodal semantic space 
traditionally  the image analysis community distinguishes between two classes of fusion
schemes  namely early fusion and late fusion  the former fuses modalities in feature space 
the latter fuses modalities in semantic similarity space  analogously to what we will call
feature level and scoring level fusion  respectively  for example  escalante  hrnadez 
sucar  and montes        propose an image retrieval system for multimodal documents 
both early and late fusion strategies for the combination of the image and the textual
channels are considered  early fusion settings include a weighted linear combination of the
two channels and a global strategy where different retrieval systems are used contemporarily
on the entire  joint data set  late fusion strategies include a per modality strategy  where
documents are retrieved by using only one or the other channel and a hierarchical setting
where first text  image and their combination are used independently to query the database
and then results are aggregated with four weighted combinations  vreeswijk  huurnink 
and smeulders        train a visual concept classifier for abstract subject categories such as
biology and history by using a late fusion approach where image and text information are
combined at the output level  that is  first obtaining classification scores from the image  and
text based models separately and then joining them  similarly to our multimodal mixing
step  pham  maillot  lim  and chevallet        and caicedo  ben abdallah  gonzlez  and
nasraoui        propose an early fusion in which the two inputs are mapped onto the same
latent space using dimensionality reduction techniques  e g   singular value decomposition  
the multimodal representation obtained in this way is then directly used to retrieve image
documents 
   http   images google com 

  

fibruni  tran   baroni

   a framework for multimodal distributional semantics
in this section  a general and flexible architecture for multimodal semantics is presented 
the architecture makes use of distributional semantic models based on textual and visual
information to build a multimodal representation of meaning  to merge the two sources  it
uses a parameter based pipeline which is able to capture previously proposed combination
strategies  with the advantage of having all of them explored within a single system 
    input of the multimodal architecture
to construct a multimodal representation of meaning  a semantic model for each single
modality has to be implemented  independently of the actual parameters that are chosen for
its creation  that  from our point of view  can be in a black box   there are some requirements
that each model has to satisfy in order to guarantee a good functioning of the framework 
in the first place  each modality must provide a separate representation  to leave room for
the various fusion strategies afterwards  then  each modality must encode the semantic
information pertaining to each word of interest into a fixed size vectorial representation 
moreover  we assume that both text  and image based vectors are normalized and arranged
in matrices where words are rows and co occurring elements are columns 
in what follows  we assume that we harvested a matrix of text based semantic vectors 
and one of image based semantic vectors for the same set of target words  representing 
respectively  verbal and visual information about the words  in section   below we give the
details of how in our specific implementation we construct these matrices 
    multimodal fusion
the pipeline is based on two main steps 
    latent multimodal mixing  the text and vision matrices are concatenated  obtaining a single matrix whose row vectors are projected onto a single  common space
to make them interact 
    multimodal similarity estimation  information in the text  and image based
matrices is combined in two ways to obtain similarity estimates for pairs of target
words  at the feature level and at the scoring level 
figure   describes the infrastructure we propose for fusion  first  we introduce a mixing
phase to promote the interaction between modalities that we call latent multimodal mixing 
while this step is part of what other approaches would consider feature level fusion  see
below   we keep it separated as it might benefit the scoring level fusion as well 
once the mixing is performed  we proceed to integrate the textual and visual features 
as reviewed in section     above  in the literature fusion is performed at two main levels 
the feature level and the scoring level  in the first case features are first combined and
considered as a single input for operations  in the second case a task is performed separately
with different sets of features and the separate results are then combined  each approach
has its own advantages and limitations and this is why both of them are incorporated into
the multimodal infrastructure and together constitute what we call multimodal similarity
  

fimultimodal distributional semantics

ff
fi
 



 

 






fi
fi



 


ff
fi

 





 
fi



figure    multimodal fusion for combining textual and visual information in a semantic
model 



estimation  a feature level approach requires only one learning step  i e   determining the
parameters of the feature vector combination  and offers a richer vector based representation
of the combined information  that can also be used for other purposes  e g   image and text
features could be used together to train a classifier   benefits of a scoring level approach
include the possibility to have different representations  in principle  not even vectorial  and
different similarity scores for different modalities and the ease of increasing  or decreasing 
the number of different modalities used in the representation 
      latent multimodal mixing
this is a preparatory step in which the textual and the visual components are projected
onto a common representation of lower dimensionality to discover correlated latent factors 
the result is that new connections are made in each source matrix taking into account
information and connections present in the other matrix  originating from patterns of covariance that overlap  importantly  we assume that mixing is done via a dimensionality
reduction technique that has the following characteristics  a parameter k that determines
  

fibruni  tran   baroni

the dimensionality of the reduced space and the fact that when k equals the rank of the
original matrix the reduced matrix is identical or can be considered a good approximation
of the original one  the commonly used singular value decomposition reduction method
that we adopt here for the mixing step satisfies these constraints 
as a toy example of why mixing might be beneficial  consider the concepts pizza and
coin  that we could use as features in our text based semantic vectors  i e   record the cooccurrences of target words with these concepts as part of the vector dimensions   while
these words are not likely to occur in similar contexts in text  they are obviously visually similar  so  the original text features pizza and coin might not be highly correlated 
however  after mixing in multimodal space  they might both be associated with  have high
weights on  the same reduced space component  if they both have similar distributions to
visual features that cue roundness  consequently  two textual features that were originally
uncorrelated might be drawn closer to each other by multimodal mixing  if the corresponding concepts are visually similar  resulting in mixed textual features that are  in a sense 
visually enriched  and vice versa for mixed visual features  interestingly  psychologists have
shown that  under certain conditions  words such as pizza and coin  that are not strongly
associated but perceptually similar  can prime each other  e g   pecher  zeelenberg    raaijmakers        
note that the matrices obtained by splitting the reduced rank matrix back into the
original textual and visual blocks have the same number of feature columns as the original
textual and visual blocks  but the values in them have been smoothed by dimensionality
reduction  we explain the details of how this is achieved in our specific implementation in
the next paragraph   these matrices are then used to calculate a similarity score for a word
pair by  re  merging information at the feature and scoring levels 
mixing with svd in our implementation  we perform mixing across text  and imagebased features by applying the singular value decomposition  svd   to the matrix obtained by concatenating the two feature types row wise  so that each row of the concatenated
matrix describes a target word in textual and visual space   svd is a widely used technique
to find the best approximation of the original data points in a space of lower underlying
dimensionality whose basis vectors  principal components or latent dimensions  are
selected to capture as much of the variance in the original space as possible  manning 
raghavan    schtze        ch       by performing svd on the concatenated textual and
visual matrices  we project the two types of information into the same space  where they
are described as linear combinations of principal components  following the description by
pham et al          the svd of a matrix m of rank r is a factorization of the form
m   u v t
where



u   matrix of eigenvectors derived from m m t




   r  r diagonal matrix of singular values 

   square roots of the eigenvalues of m m t




t
 t

v   matrix of eigenvectors derived from m m

   computed with svdlibc  http   tedlab mit edu  dr svdlibc 

  

fimultimodal distributional semantics

in our context  the matrix m is given by normalizing two feature matrices separately and
then concatenating  by selecting the k largest values from matrix  and keeping the
corresponding columns in matrices u and v   the reduced matrix mk is given by
mk   uk k vkt
where k   r is the dimensionality of the latent space  while mk keeps the same number
of columns dimensions as m   its rank is now k  k is a free parameter that we tune on the
development sets  note that when k equals the rank of the original matrix  then trivially
mk   m   thus we can consider not performing any svd reduction as a special case of
svd  which helps when searching for the optimal parameters 
note also that  if m has n columns  then vkt is a k  n matrix  so that mk has the same
number of columns of m   if the first j columns of m contain textual features  and columns
from j     to n contain visual features  the same will hold for mk   although in the latter
the values of the features will have been affected by global svd smoothing  thus  in the
current implementation of the pipeline in figure    block splitting is attained simply by
dividing mk into a textual mixed matrix containing its first j columns  and a visual mixed
matrix containing the remaining columns 
      multimodal similarity estimation
similarity function following the distributional hypothesis  dsms describe a word in
terms of the contexts in which it occurs  therefore  to measure the similarity of two words
dsms need a function capable of determining the similarity of two such descriptions  i e  
of two semantic vectors   in the literature  there are many different similarity functions
used to compare two semantic vectors  including cosine similarity  euclidean distance  l 
norm  jaccards coefficient  jensen shannon divergence  lins similarity  for an extensive
evaluation of different similarity measures  see the work by weeds        
here we focus on cosine similarity since it has been shown to be a very effective measure
on many semantic benchmarks  bullinaria   levy        pad   lapata         also 
given that our system is based on geometric principles  the cosine  together with euclidean
distance  is the most principled choice to measure similarity  for example  some of the
measures listed above  having been developed from probabilistic considerations  will only be
applicable to vectors that encode well formed probability distributions  which is typically
not the case  for example  after multimodal mixing  our vectors might contain negative
values  
the cosine of two semantic vectors a and b is their dot product divided by the product
of their lengths 
pi n

i   ai  bi
qp
i n  
i n  
a

i   i
i   bi

cos a  b    qp

the cosine ranges from    orthogonal vectors  to      parallel vectors pointing in the
same or opposite directions have cosine values of   and     respectively  
  

fibruni  tran   baroni

feature level fusion in feature level fusion  fl   we use the linear weighted fusion
method to combine text  and image based feature vectors of words into a single representation and then we use the latter to estimate the similarity of pairs  the linear weighted
combination function is defined as
f     ft         fv
where  is the vector concatenate operator 
scoring level fusion in scoring level fusion  sl   text  and image based matrices are
used to estimate similarity of pairs independently  the scores are then combined to obtain
the final estimate by using a linear weighted scoring function 
s     st          sv
general form and special cases given fixed and normalized text  and image based
matrices  our multimodal approach is parametrized by k  dimensionality of latent space  
fl vs  sl    weight of text component in fl similarity estimation  and   weight of text
component in sl  
note that when k r  with r the rank of the original combined matrix  latent multimodal
mixing returns the original combined matrix  no actual mixing   picking sl with    or
   corresponds to using the textual or visual matrix only  respectively  we thus derive as
special cases the models in which only text  k r  sl      or only images  k r  sl      are
used  called text and image models in the results section below   the simple approach
of bruni et al          in which the two matrices are concatenated without mixing  is the
parametrization k r  fl        called naivefl model  below   the summing approach
of leong and mihalcea        corresponds to k r  sl        naivesl  below   picking
k r  sl      amounts to performing latent multimodal mixing  but then using textual
features only  and the reverse with mixed image features only for       textmixed and
imagemixed   respectively   reducing these and other models to the same parametrized
approach means that  given a development set for a specific task that requires similarity
measurements  we can discover in a data driven way which of the various models is best
for the task at hand  for example  for a certain task we might discover that we are better
off using text only  for another mixed text features  for yet another both text and image
features  and so on  
formally  given the set k         kn  r of n dimensionalities of the latent space  with kn
equal to the original dimensionality  and arbitrary steps between the chosen values   the
sets          m  r of m potential weights of the text block in fl  with       and m     
and          l  r of l weights of the text block in sl  with       and l       we can
calculate the number of possible configurations to explore by totc   n m   l   unless n  m
and l are very large  i e   we consider very small intervals between the values to be tested  
it is completely feasible to perform a full search for the best parameters for a certain task
without approximate optimization methods  in our experiments  n      m   l       and
consequently totc       
  

fimultimodal distributional semantics

   implementation details
both our implementation of the multimodal framework and of the visual feature extraction
procedure are publicly available and open source   moreover the visual feature extraction
procedure is presented by bruni  bordignon  liska  uijlings  and sergienya        
    construction of the text based semantic matrix
as reviewed in section     above  a text based distributional model is encoded in a matrix whose rows are semantic vectors representing the meaning of a set of target words 
important parameters of the model are the choice of target and contextual elements 
the source corpora used to extract co occurrence information  the context delimiting the
scope of co occurrence  and the function to transform raw counts into statistical association scores downplaying the impact of very frequent elements 
source corpora we collect co occurrence counts from the concatenation of two corpora 
ukwac and wackypedia  size     b and    m running words  or tokens  respectively  
ukwac is a collection of web pages based on a linguistically controlled crawl of the  uk
domain conducted in the mid     s  wackypedia was built from a mid      dump of the
english wikipedia  both corpora have been automatically annotated with lemma  dictionary form  and part of speech  pos  category information using the treetagger   they are
freely and publicly available    and they are widely used in linguistic research 
target and context elements since our source corpora are annotated with lemma and
part of speech information  we take both into account when extracting target and context
words  e g   the string sang is treated as an instance of the verb lemma sing   we collect
semantic vectors for a set of   k target words  lemmas   namely the top   k most frequent
nouns   k most frequent adjectives and  k most frequent verbs in the combined corpora 
the same   k lemmas are also employed as contextual elements  consequently  our textbased semantic models are encoded in a   k  k matrix   note that when we combine
the text matrices with the image based ones  we preserve only those rows  target words 
for which we also have an image based vector  trimming the matrix to size         k 
context we define context in terms of words that co occur within a window of fixed
width  in the tradition of the popular hal model  lund   burgess         window based
models are attractive for their simplicity and the fact that they do not require resourceintensive advanced linguistic annotation  they have moreover been reported to be at the
state of the art in various semantic tasks  rapp        sahlgren         and in bruni 
uijlings  baroni  and sebe        we show that the window based methods we use here
outperform both a document as context model and a sophisticated syntax  and lexicalpattern based model on the men and wordsim test sets introduced in section     below
 see also the post hoc analysis using the document based model discussed at the end of
section       below   we consider two variants  window  and window    we chose these
particular variants arbitrarily  as representatives of narrow and wide windows  respectively  
   see https   github com s m fuse  and https   github com vsem   respectively 
   http   www ims uni stuttgart de projekte corplex treetagger 
    http   wacky sslmit unibo it 

  

fibruni  tran   baroni

window  records sentence internal co occurrence with the nearest   content words to the left
and right of each target word  function words such as articles and prepositions are ignored  
window   considers a larger window of    content words to the left and right of the target 
a narrower window is expected to capture a narrower kind of semantic similarity  such as the
one that exists between terms that are closely taxonomically related  for example coordinate
concepts  dog and cat  or pairs of superordinate and subordinate concepts  animal and
dog   the rationale behind this expectation is that terms will share many narrow window
collocates only if they are very similar  both semantically and syntactically  on the other
hand  a broader window will capture a broader kind of topical similarity  such as one
would expect of words that tend to occur in the same paragraphs  for example  war and oil 
that are rather distant concepts in a taxonomic sense  but might easily occur in the same
discourse   see the work by sahlgren        for further discussion of the effects of context
width on distributional semantic models 
association score we transform raw co occurrence counts into nonnegative local mutual information  lmi  association scores  lmi scores are obtained by multiplying raw
counts by pointwise mutual information  and in the nonnegative case they are a close approximation to log likelihood ratio scores  that are one of the most widely used weighting
schemes in computational linguistics  evert         the nonnegative lmi of target element
t and context element c is defined as 


p t  c 
  
p t p c 



lm i t  c    max count t  c   log

it is worth observing that  in an extensive study of how parameters affect the quality of
semantic vectors  bullinaria and levy        and bullinaria and levy        found that
a model similar to our window   co occurrence statistics from ukwac  narrow window 
lemmatized content word collocates  nonnegative pointwise mutual information instead of
lmi  performs at or near the top in a variety of semantic tasks  thus  we have independent
grounds to claim that we are using a state of the art text based model 
    construction of the image based semantic matrix
given that image based semantic vectors are a novelty with respect to text based ones 
in the next subsections we dedicate more space to how we constructed them  including
full details about the source corpus we utilize as input of our pipeline  section         the
particular image analysis technique we choose to extract visual collocates and how we finally
arrange them into semantic vectors that constitute the visual block of our distributional
semantic matrix  section        
      image source corpus
we adopt as our source corpus the esp game data set   that contains    k images  labeled
through the famous game with a purpose developed by louis von ahn  in which two
    http   www cs cmu edu  biglou resources 

  

fimultimodal distributional semantics

 
fffififf
fififffi 
fifi

fffi  
ff fififf fi

  
 
fi  ff 

fi

fififffi

fifi


fififf
fiff

  fiff fi
fi


figure
   samples of images and their tags from the esp game data set

people partnered online must independently and rapidly agree on an appropriate word to
label random selected images  once a word is entered by both partners in a certain number
of game rounds  that word is added as a tag for that image  and it becomes a taboo term for
next rounds of the game involving the same image  to encourage players to produce more
terms describing the image  von ahn         the tags of images in the data set form a
vocabulary of        distinct word types  images have    tags on average       standard
deviation   while a word is a tag for    images on average         standard deviation  
to have the words in the same format as in our text based models  the tags are lemmatized and pos tagged  to annotate the words with their parts of speech  we could not
run a pos tagger  since here words are out of context  i e   each tag appears alphabetically
within the small list of words labeling the same image and not within the ordinary sentence
required by a pos tagger   thus we used a heuristic method  which assigned to the words
in the esp game vocabulary their most frequent tag in our textual corpora 
the esp game corpus is an interesting data set from our point of view since  on the
one hand  it is rather large and we know that the tags it contains are related to the images 
on the other hand  it is not the product of experts labelling representative images  but of a
noisy annotation process of often poor quality or uninteresting images  e g   logos  randomly
downloaded from the web  thus  analogously to the characteristics of a textual corpus  our
algorithms must be able to exploit large scale statistical information  while being robust
to noise  while cleaner and more illustrative examples of each concept are available in
carefully constructed databases such as imagenet  see section       noisy tag annotations
  

fibruni  tran   baroni

are available on a massive scale on sites such as flickr   and facebook    so if we want to
eventually exploit such data it is important that our methods can work on noisy input  a
further advantage of esp game with respect to imagenet is that its images are associated
not only with concrete noun categories but also with adjectives  verbs and nouns related
to events  e g   vacation  party  travel  etc   from a more practical point of view  clean
data sets such as imagenet are still relatively small  making experimentation with standard
benchmarks difficult  in concrete  looking at the benchmarks we experiment with  as of mid
      imagenet covers only just about half the pairs in the wordsim    test set  and less
than     of the almuhareb poesio words  while in the future we want to explore to what
extent higher quality data sources can improve image based models  this will require larger
databases  or benchmarks relying on a very restricted vocabulary 
the image samples in figure   exemplify different kinds of noise that characterize the
esp game data set  both on top and bottom left and top right there are images where
the scene is cluttered or partially occluded  the top center image is hardly a good representative of accompanying words such as building  tower s  or square  similarly  the center
bottom image is only partially a good illustration of a coin  and certainly not a very good
example of a man  finally  the bottom right image is useless from a visual feature extraction
perspective 
      image based semantic vector construction
we collect co occurrence counts of target words and image based contexts by adopting the
bovw pipeline that  as we already explained in      is particularly convenient in order to
discretize visual information into visual collocates  we are adopting what is currently
considered a standard implementation of bovw  in the future  we could explore more
cutting edge ways to build image based semantic vectors  such as local linear encoding
 wang  yang  yu  lv  huang    gong        or fisher encoding  perronnin  sanchez   
mensink         chatfield  lempitsky  vedaldi  and zisserman        present a systematic
evaluation of several recent methods 
our current implementation is composed of the following steps   i  extraction of the
local descriptors  that is  vectors of low level features that encode geometric or other
information about the area around each keypoint  i e   pixel of interest  here  sift descriptors    ii  constructing a vector representation of an image by assigning the
local descriptors to clusters corresponding to visual words  and recording their distribution
across these clusters in the vector  this presupposes a preliminary step in which a clustering
algorithm has been applied to the whole image collection or a sample  to determine the visual word vocabulary   iii  including some spatial information into the representation with
spatial binning   iv  summing visual word occurrences across the list of images associated
with a word label to obtain the co occurrence counts associated with each word label
and transforming these counts into association scores  analogously to what is done in text
analysis  the process  without spatial binning  is schematically illustrated in figure    for
a hypothetical example in which there are three images in the collection labeled with the
word monkey  more details follow 
    http   www flickr com
    http   www facebook com

  

fimultimodal distributional semantics

dense sampling
of pixels of
interest

mapping sift
descriptors to visual
word clusters

extracting
local
descriptors

sift  x 

monkey 

 

 

monkey

 

 

 

 

 

labeled
images

monkey 

 

  

instance
counts

 

monkey
monkey 

 

 

 

 

monkey 

 

  

  

 

monkey
total
counts

figure    the procedure to build an image based semantic vector for a target word  first 
a bag of visual word representation for each image labeled with the target word
is computed  in this case  three images are labeled with the target word monkey  
then  the visual word occurrences across instance counts are summed to obtain
the co occurrence counts associated with the target word 

local descriptors to construct the local descriptors of pixels of interest we use scaleinvariant feature transform  sift   lowe               we chose sift for its invariance
to image scale  orientation  noise  distortion and partial invariance to illumination changes 
a sift vector is formed by measuring the local image gradients in the region around each
location and orientation of the feature at multiple scales  in particular  the contents of
     sampling subregions are explored around each keypoint  for each of the resulting
   samples  the magnitude of the gradients at   orientations are calculated  which would
already result in a sift feature vector of     components  however  we extract color
sift descriptors in hsv  hue  saturation and value  space  bosch  zisserman    munoz 
       we use hsv because it encodes color information in a similar way to how humans
  

fibruni  tran   baroni

do  we compute sift descriptors for each hsv component  this gives      dimensions
per descriptor      per channel  color channels are then averaged to obtain the final
    dimensional descriptors  we experimented also with different color scales  such as
luv  lab and rgb  obtaining significantly worse performance compared to hsv on our
development set introduced in        therefore we do not conduct further experiments with
them  van de sande  gevers  and snoek        present a systematic evaluation of color
features 
instead of searching for interesting keypoints with a salient patch detection algorithm 
we use a more computationally intensive but also more thorough dense keypoint sampling
approach  with patches of fixed size and localized on a regular grid covering the whole image
and repeated over multiple scales  sift descriptors are computed on a regular grid every
five pixels  at four scales                 pixel radii  and zeroing the low contrast descriptors 
for their extraction we use the vl phow command included in the vlfeat toolbox  vedaldi
  fulkerson         this implementation has been shown to be very close to lowes original
but it is much faster for dense feature extraction  nowak  jurie  and triggs        report
a systematic evaluation of different patch sampling strategies 
importantly  sift feature vectors are extracted from a large corpus of representative
images to populate a feature space  which subsequently is quantized into a discrete number of
visual words by clustering  once this step is performed  every sift vector  local descriptor 
from the original or new images can be translated into a visual word by determining which
cluster it is nearest to in the quantized space 
visual vocabulary to map sift descriptors to visual words  we first cluster all local
descriptors extracted from all images in a training image corpus in their      dimensional
space using the k means clustering algorithm  and encode each descriptor by the index of the
cluster  visual word  to which it belongs  k means is the most common way of constructing
visual vocabularies  grauman   leibe         given a set x         xn  rd of n training
descriptors  k means aims to partition the n descriptors into k sets  k  n  so as to minimize
p
the cumulative approximation error ni     xi  qi       with k centroids          k  rd
and data to means assignments q         qn           k   we use an approximated version of
k means called lloyds algorithm        as implemented in the vlfeat toolbox 
to construct our visual vocabulary we extracted sift descriptors from all the    k
images of the esp game data set  to tune the parameter k we used the men development
set  see section         by varying k between     and      in steps of      we found the
optimal k being       it is most likely that the performance has not peaked even at     
visual words and enhancements could be attained by adopting larger visual vocabularies
via more efficient implementations of the bovw pipeline  as for example by chatfield et al 
       
image representation given a set of descriptors x         xn sampled from an image  let
qi be the assignment of each descriptor xi to its corresponding visual word  the bag ofvisual words representation of an image is a nonnegative vector v  rk such that vk     i  
qi   k    with q ranging from   to the number of visual words in the vocabulary  in our
case         this representation is a vector of visual words obtained via hard quantization
 i e   assignment of each local descriptor vector to the single nearest codeword  
  

fimultimodal distributional semantics

spatial binning a consolidated way of introducing weak geometry in bovw is the use
of spatial histograms  grauman   darrell        lazebnik  schmid    ponce         the
main idea is to divide the image in several  spatial  regions and to perform the entire visual
word extraction and counting pipeline for each region and then concatenate the vectors  in
our experiments the spatial regions are obtained by dividing the image in       for a total
of    regions  therefore  crossing the values for k with the spatial region  we increase the
feature dimensions    times  for a total of        components in our vectors 
co occurrence counts and weighting once the bovw representations are built 
each target  textual  word is associated to the list of images which are labeled with it  the
visual word occurrences across the list of images is summed to obtain the co occurrence
counts associated with the target  textual  word  in total         target words  those that
constitute esp game tags  have an image based semantic vector associated 
also in the image based semantic matrix  like in the text based one  raw counts are
transformed into nonnegative lmi  the difference is that here lmi is computed between a
target element t that is a textual word and a context element c that is a visual word instead 
note that  just like in the standard textual approach  we are accumulating visual words
from all images that contain a word without taking into account the fact that words might
denote concepts with multiple appearances  can be polysemous or even hide homonyms
 our bank vector will include visual words extracted from river as well as building pictures  
an interesting direction for further research would be to cluster the images associated to a
word in order to distinguish the visual senses of the word  e g   along the lines of what
was done for textual models by reisinger and mooney        
    multimodal fusion tuning
we performed two separate parameter optimizations  one specifically for the semantic relatedness task  using men development  see section        and the other specifically for
the clustering task  using battig  see section         we determined the best model by
performing an exhaustive search across svd k  from    to     in powers of     fl and sl
with  varying from   to    inclusive  in steps of     and similarly for   in total      models were explored and the one with the highest performance on the development data was
chosen  note that tuning was performed separately for the window  and window   models 

    mixlda
to reimplement feng and lapatas approach  discussed in section      in a comparable
setting to ours  we treat the esp game data set as a mixed media corpus where each
image together with the associated tags constitutes a document  for each image  we extract
the image based features with the procedure described above in       and use the words
labeling that image to obtain the text based features  these features are then stored in a
term by document matrix  in which each image is treated as a document and a term can be
either a textual tag or a visual word extracted from that image  we obtain a matrix of size
  k   k  with   k textual words  the word list resulting from the intersection of all the
words used in our experimental data sets     k visual words and    k documents  images  
  

fibruni  tran   baroni

the latent dirichlet allocation  mixlda  model is trained on this matrix and tuned on
the men development set by varying the number of topics kt     the optimal value we find
is kt        under mixlda  each target word in an evaluation set is represented by the
vector giving its distribution over the     latent topics 

   experiments
we test our semantic representation in three different tasks  that is  evaluating the distribution of different kinds of semantic relations among a words neighbours        modeling
word relatedness judgments       and clustering words into superordinate concepts       
together  these tasks should give us a clear idea of the general quality of our models and
of the relative contribution of visual information to meaning representation 
    differentiation between semantic relations
to acquire a qualitative insight into how well our text  and image based models are capturing word meaning  we test them on bless  baroni lenci evaluation of semantic similarity   a benchmark recently introduced by baroni and lenci        to analyze specific
aspects of lexico semantic knowledge  rather than focusing on a point estimate of quality
of a model on a specific semantic task  bless allows us to assess the overall pattern of
semantic relations that the model tends to capture  we run the bless evaluation before
combining the textual and the visual channels together as a sanity check on the semantic
meaningfulness of the image based vectors  looking for potential complementary information with respect to text which can further motivate fusion  note that since we are not
combining the textual and visual sources  there are no tuning parameters to report 
      benchmark and method
bless contains a set of     pivot words denoting concrete concepts  we use     pivots 
since for the remaining    we do not have a sufficiently large set of related words covered
by our models   for each of the pivots  the data set contains a number of related words  or
relata  instantiating the following   common semantic relations with the pivots  coord 
the relatum is a noun that is a co hyponym  coordinate  of the pivot  alligator lizard  
hyper  the relatum is a noun that is a hypernym  superordinate  of the pivot  alligatorreptile   mero  the relatum is a noun referring to a meronym  that is  a part or material
of the pivot  alligator teeth   attri  the relatum is an adjective expressing an attribute
of the pivot  alligator ferocious   event  the relatum is a verb referring to an action or
event involving the concept  alligator swim   ran n  ran j and ran v  finally  are control
cases where the pivot is matched to a set of random nouns  alligator trombone   adjectives
 alligator electronic  and verbs  alligator conclude   respectively 
for each pivot  bless contains a set of relata of each category  ranging from   hypernyms to    random nouns per pivot on average   in this way  bless can highlight the
broader semantic properties of a model independently of its more specific preferences  for
example  both a model that assigns a high score to alligator ferocious and a model that
assigns a high score to alligator green will be correctly treated as models that have picked
    lda was computed with gensim  http   radimrehurek com gensim 

  

fimultimodal distributional semantics

a relevant attribute of alligators  at the same time  the comparison of the specific relata
selected by the models allows a more granular qualitative analysis of their differences 
following the guidelines of baroni and lenci         we analyze a semantic model as
follows  we compute the cosine between the model vectors representing each of the    
pivots and each of its relata  picking the relatum with the highest cosine for each of the
  relations  the nearest hypernym  the nearest random noun  etc    we then transform
the   similarity scores collected in this way for each pivot onto standardized z scores  to
get rid of pivot specific effects   and produce a boxplot summarizing the distribution of
scores per relation across the     pivots  for example  the leftmost box in the first panel
of figure   reports the distribution of     standardized cosines of nearest coordinate relata
with the respective pivots   besides analyzing the distributions qualitatively  we also discuss
significant differences between the cosines of different relation types that were obtained via
tukeys honestly significance tests  thus correcting for multiple pairwise comparisons  abdi
  williams        
      results
in fig     we report bless nearest relata distributions for the purely textual model window    the window  distribution shows an even stronger skew in favour of coordinate
neighbours  and the purely visual model we call image in the next sections  the patterns
produced by the text based model  left panel  illustrate how a sensible word meaning profile
should look like  coordinates are the most similar terms  an alligator is maximally similar
to a crocodile   followed by superordinates  reptile  and parts  teeth   semantically related
adjectives  attri  ferocious  and verbs  event  swim  are less close to the pivots  but still
more so than any random item 
the right panel shows the distribution of relata in the image based semantic vectors 
the overall pattern is quite similar to the one observed with the text based vectors  there
is a clear preference for coordinates  followed by hypernyms and parts  then attributes
and events  with all random relata further away from the pivots than the semantically
meaningful categories  for both models  coordinates are significantly closer to the relata
than hypernyms and meronyms  that are significantly closer than attributes and events 
that are in turn significantly closer than any random category  although the difference
between hypernyms and parts is not significant with either representation  intriguingly the
image based vectors show a slight preference for the more imageable parts  teeth  than
the more abstract hypernyms  reptile   the only difference of statistical import is the one
between events and attributes  where the text based model shows a significant preference
for events  whereas the two categories are statistically indistinguishable in the image based
model  as we will see shortly  the relative preference of the latter for attributes is probably
due to its tendency to pick perceptual adjectives denoting color and size  
looking more closely at the specific relata picked by the text  and image based models 
the most striking differences pertain  again  to attributes  the text  and image based
models picked the same attribute for a pivot in just     of the cases  compare to    
overlap across all non random relation types   table   reports the attributes picked by the
text  vs  image based models for    random cases where the two mismatch 
  

fibruni  tran   baroni

image based semantic vectors

  

  

  

  

 

 

 

 

 

 

text based semantic vectors

coord

hyper

mero

attri

event

ran n

ran j

ran v

coord

hyper

mero

attri

event

ran n

ran j

ran v

figure    distribution of z normalized cosines of words instantiating various relations across
bless pivots  text based vectors from the window   model 

pivot
cabbage
carrot
cherry
deer
dishwasher
elephant
glider
gorilla
hat
hatchet

text
leafy
fresh
ripe
wild
electric
wild
heavy
wild
white
sharp

image
white
orange
red
brown
white
white
white
black
old
short

pivot
helicopter
onion
oven
plum
sofa
sparrow
stove
tanker
toaster
trout

text
heavy
fresh
electric
juicy
comfortable
wild
electric
heavy
electric
fresh

image
old
white
new
red
old
little
hot
grey
new
old

table    attributes preferred by text   window    vs  image based models 

  

fimultimodal distributional semantics

it is immediately clear from the table that  despite the fact that the pivots are nouns
denoting concrete concepts  the text based model almost never picks adjectives denoting
salient perceptual properties  and in particular visual properties  just white for hat and leafy
for cabbage   the text based model focuses instead on encyclopedic properties such as fresh 
ripe  wild  electric and comfortable  this is in line with earlier analyses of the ungrounded
semantics provided by text based models  andrews et al         baroni et al         baroni
  lenci        riordan   jones         and differs greatly from the trend found in the
image based model  in       cases  the closest attribute for the latter model is a color  in
the remaining cases  we have size  short  little   one instance of hot and  surprisingly  four
of old 
to conclude  the analysis we presented confirms  on the one hand  our hypothesis that
image based distributional vectors contain sufficient information to capture a network of
sensible word meaning relations  on the other  there are intriguing differences in the relations picked by the text  and image based models  pointing to their complementarity 
    word relatedness
as is standard in the distributional semantics literature  budanitsky   hirst        sahlgren 
       we assess the performance of our models on the task of predicting the degree of semantic relatedness between two words as rated by human judges  we test the models on
the ws and men benchmarks 
      benchmarks and method
ws  that is  wordsim       see also section      is a widely used benchmark constructed by
asking    subjects to rate a set of     word pairs on an    point meaning similarity scale and
averaging their ratings  e g   dollar buck gets a very high average rating  professor cucumber
a very low one   our target words cover     ws pairs  thus  the correlations reported below
are not directly comparable to those reported in other studies that used ws   however  our
text based models have much higher ws coverage        when evaluated on the larger ws
set they cover  window  and window   achieve      and      correlations  respectively 
we are thus comparing the multimodal approach with purely textual models that are at
the state of the art for ws  see results reported in section     above  
the second benchmark we use  men  for marco  elia and nam  the resource creators 
was developed by us  specifically for the purpose of testing multimodal models  we created
a large data set that  while comparable to ws and other benchmarks commonly used
by the computational semantics community  contains only words that appear as image
labels in the esp game and mirflickr  m   collections  thus ensuring full coverage to
researchers that train visual models from these resources  men consists of       word pairs
with        normalized semantic relatedness ratings provided by amazon mechanical turk
workers  via the crowdflower   interface   for example  beach sand has a men score of
      bakery zebra received a   score 
    http   www cs technion ac il  gabr resources data wordsim    
    http   press liacs nl mirflickr 
    http   crowdflower com 

  

fibruni  tran   baroni

compared to ws  men is sufficiently large to allow us to separate development and
test data  avoiding issues of overfitting  we use indeed       men pairs  development set 
for model tuning and       pairs for evaluation  test set   importantly  the development
set has been used to find the best configuration once for both the men test set and ws 
thus  the ws evaluation illustrates how well the parameters learned on training data from
a specific data set generalize when applied to the same semantic task but on a different
data set 
models are evaluated as follows  for each pair in a data set  we compute the cosine
of the model vectors representing the words in the pair  and then calculate the spearman
correlation of these cosines with the  pooled  human ratings of the same pairs  the idea
being that the higher the correlation the better the model can simulate the relatedness
scores 
men construction an earlier version of men has been used for the first time by the
authors by bruni et al         but since the current article is the first major publication
in which we focus specifically on it  and we have recently improved the benchmark by
extending the ratings  we provide here further details on how it was constructed 
the word pairs that constitute men were randomly selected from words that occur at
least     times in the concatenated ukwac and wackypedia text corpora and at least   
times as tags in the esp game and mirflickr  m tagged image collections  in order
to avoid picking only pairs that were weakly related  as would happen if we were to sample
random word pairs from a list  we ranked all possible pairs by their cosines according to our
text based model window    to gather the      word pairs needed for the construction
of men  we subsequently picked the first      word pairs  another      was sampled from
pairs placed between      and      in the cosine ranked list and the last block of      pairs
from the remaining items 
to acquire human semantic relatedness judgments  we decided to ask for comparative
judgments on two pair exemplars at a time rather than absolute scores for single pairs  as
was done by the creators of ws  this should constitute a more natural way to evaluate the
target pairs  since human judgments are comparative in nature  when a person evaluates
a given target  she does not do so in a vacuum  but in relation with a certain context 
moreover  binary choices were preferred because they make the construction of right and
wrong control items straightforward  see footnote      operationally  each word pair
was randomly matched with a comparison pair coming from the same set of      items
and rated by a single turker as either more or less related than the comparison item  the
validity of this approach is confirmed by the high annotation accuracy we observe in the
control set    and by the high correlation of the men scores with ratings collected on a
likert scale we report below 
    the control items are correct annotations created prior to running the job on amazon mechanical turk 
which act as hidden tests that are randomly shown to turkers as they complete the job  in this way 
we can calculate the quality of a contributors performance and reject their annotations if the accuracy
drops below a certain percentage  we set a required minimum precision equal to      but we obtained
almost      average accuracy overall   control items are also of great help to train quickly new workers
to perform the required task  to create our control items we harvested two equally sized sets of word
pairs from ws  one containing only pairs with a high relatedness score  one containing only pairs with
a low relatedness score  each control item was then obtained by juxtaposing a high score pair with a
low score pair and by treating the pair with the higher score as the one that should be selected by the

  

fimultimodal distributional semantics

in the instructions  annotators were warned that sometimes both candidate pairs could
contain words related in meaning and in such cases we asked them to pick the pair with the
more strongly related words  e g   both wheels car and dog race are somewhat related pairs 
but the first one should be preferred as every car has wheels but not every dog is involved
in a race   in other cases  annotators could find that neither pair contains closely related
words  and in such cases they were instructed to pick the pair that contained slightly more
related words  e g   neither auction car nor cup asphalt are closely related words  but the
first pair should be picked because fancy vintage cars are sold at auctions   we requested
participants to be native speakers and only accepted those connecting from an english
speaking country  we cannot guarantee that non natives did not take part in the study 
but our subject filtering techniques based on control pairs  see footnote     ensures that
only the data of speakers with a good command of english were retained 
to transform binary preference data to relatedness scores about the retrieved pairs  each
of them was evaluated against    randomly picked comparison pairs  thus it received a score
on a    point scale  given by the number of times out of    the pair was picked as the most
related of the two   the score was subsequently normalized between   and   by dividing
the number of times the pair was picked as the most related by     for example  fun night
was chosen as more related than the comparison pair    times  thus its normalized score
is given by               note that  in each comparison  we only recorded the preference
assigned to one of the two pairs  to avoid dependencies between the final scores assigned
to different pairs  that is  the times a pair was selected as a random comparison item for
another pair were not counted as ratings of that pair  
because raters saw the men pairs matched to different random items  with the number
of pairs also varying from rater to rater  it is not possible to compute annotator agreement
scores for men  however  to get a sense of human agreement  the first and third author
rated all       pairs  presented in different random orders  on a standard     likert scale 
the spearman correlation of the two authors is at       the correlation of their average
ratings with the men scores is at       on the one hand  this high correlation suggests
that men contains meaningful semantic ratings  on the other  it can also be taken as an
upper bound on what computational models can realistically achieve when simulating the
human men judgments 
the high score men pairs include not only pairs of terms that are strictly taxonomically close  cathedral church        but also terms that are connected by broader semantic
relations  such as whole part  flower petal         item and related event  boat fishing       
etc  for this reason  we prefer to refer to men as a semantic relatedness rather than
similarity score data set  note that ws is also capturing a broader notion of relatedness  agirre et al          men is publicly available and it can be downloaded from 
http   clic cimec unitn it  elia bruni men 
      results
table   reports the correlations on the men testing and ws data sets when using either
window  or window   as textual model  our automated tuning method selected k     
annotators as the most related  all control items were manually checked  examples of control items are
hotel word vs  psychology depression  telephone communication vs  face locomotive 

  

fibruni  tran   baroni

model
text
image
naivefl
naivesl
mixlda
textmixed
imagemixed
tunedfl
tunedsl

window 
men ws
    
    
    
    
    
    
    
    
    
    
         
    
    
         
         

window  
men ws
    
    
    
    
    
    
    
    
    
    
         
    
    
         
         

table    spearman correlation of the models on men and wordsim  all coefficients significant with p           tunedfl is the model selected automatically on the men
development data  tunedsl is automatically tuned after fixing sl similarity estimation 

 when textual information comes from window   and k        with window    as optimal 
and feature level  fl  similarity estimation with        in both cases  since the input
matrices are row normalized  the latter setting assigns equal weights to the textual and
visual components   these are the models called tunedfl in the table  the scoring level
 sl  strategy  again with similar weights assigned to the two channels  and same k values
as tunedfl  performed only slightly worse than tunedfl  and we report the results for the
best sl based models as tuned on the development men data as well  tunedsl   in all other
models reported in the table  naivefl  naivesl  mixlda  textmixed and imagemixed   
some parameters were tuned manually in order to gain insights on combination strategies
representing ideas from the earlier literature   
the first two rows of the table show results of the text  and image based models  before
any mixing  text shows comparable performances on both data sets  image correlates
significantly better with men than ws but the correlations are lower than those of text 
in accordance with what was found in earlier studies  in the next three rows we find the
results of the earlier multimodal approaches we took into consideration  bruni et al        
feng   lapata        leong   mihalcea         while the naivefl approach  analogous
to bruni et al s method   in which textual and visual matrices are concatenated without
mixing  performs slightly better than text on men  it attains lower performance on ws 
also naivesl  equivalent to leong and mihalceas summing approach   where text and
image sources are combined at the scoring level  obtains improvements only on men  loosing
several correlation points on ws compared to text 
our implementation of mixlda achieves very poor results both on men and ws  one
might attribute this to the fact that feng and lapatas approach is constrained to using the
same source for the textual and the visual model and our image data set is a poor source
    for textmixed and imagemixed   the best k values were found on the development data  they were both
set to     with both textual sources 

  

fimultimodal distributional semantics

textmixed
tunedfl
tunedsl

window 
    
    
    

window  
    
    
    

table    pearson correlation of some of our best multimodal combinations on the wordsim
subset covered by feng and lapata         all coefficients significant with p  
       pearson used instead of spearman for full comparability with feng and
lapata   the models assigned   similarity to the        pairs for which they were
missing a vector  feng and lapata        report      correlation for mixlda 

of textual data  our approach is however also outperforming the original mixlda by a
large margin on the latter ws test set  where we are strongly disfavoured  in particular 
feng and lapata        report a correlation of      for the subset of     ws pairs covered
by their model  we tested our system on the same subset  despite the fact that we are
missing one or both vectors for    of the pairs  almost one third   so that our models are
forced to assign   cosines to all these cases  despite this huge handicap  our models are
still attaining much higher correlations than the original mixlda on the feng and lapata
pairs  as illustrated for the most interesting fusion strategies in table   
analyzing now the effects of our fusion strategies  we can first see a uniform enhancement on both men and ws for textmixed and imagemixed  the models obtained by first
performing latent multimodal mixing on the combined matrix  but then using textual features only for textmixed and visual features only for imagemixed    textmixed reaches the best
performance overall on ws with both source textual models  and it is significantly better
than text on men according to a two tailed paired permutation test  moore   mccabe 
       looking then at the automatically selected tunedfl model  it reaches the best performance overall  not only it significantly outperforms text models on both data sets  but
it is significantly better than textmixed on men with window    the difference is approaching significance with window  as well  p          tunedsl is also very competitive  it is
also significantly better than text with both window sizes and textmixed for window    it
is noticeably worse than tunedfl on ws with window   only  and it is actually having a
slight advantage on men with window    the difference between tunedfl and tunedsl
is never significant  
it is worth remarking that while textmixed is a bit worse than the full fusion models 
it still achieves high correlations with the human judgments and it has an extremely high
correlation with the tunedfl best model            this suggests that most of the
benefits of multimodality are already captured by latent mixing  textmixed is an attractive
model because it has less parameters than the whole pipeline and it is more compact than
tunedfl  since it discards the visual features after using them for mixing 
validating the results while we have shown significant improvements when visual features are added to distributional models  one could object that improvements are due to the
fact that we are using more information  a larger number of features  higher dimensional
  

fibruni  tran   baroni

vectors  for feature level fusion  and a more complex model  two similarity scores as
independent variables to predict human judgments  for scoring level fusion  further experiments provide evidence to respond to this objection 
first  we built purely textual models with the same number of features as our multimodal
models  that is  instead of collecting co occurrence of the target terms with the   k most
frequent content lemmas in our corpus  see section     above   we extended the list of
context items to the    k most frequent content lemmas  the results with this larger
textual models were virtually identical to those with   k dimensional vectors reported in
table    correlation for the window   model on men was      instead of        thus  at
least when using our large corpus and a window based approach  with   k features we have
pretty much exhausted the useful textual information  and its the nature  not simply the
quantity of the extra visual features we add that matters 
to answer the objection that the scoring level approach is using a more complex model 
with two independent variables  text  and image base similarities  instead of one  we casted
the problem in standard inferential statistical terms  see  e g  baayen        ch      specifically  we fitted ordinary linear regression models to predict the men and ws ratings with
only text based similarities vs  text  and image based similarities  for comparability with
the spearman correlation results reported above  the analyses were also replicated after
transforming ratings and similarities into ranks   both variables were highly significant in
all experiments  and  more importantly  sequential f tests over the nested models revealed
that in all cases adding image based similarities explains significantly more variance than
what would be expected by chance given the extra parameter  p         
qualitative analysis to acquire qualitative insights into how multimodality is contributing to meaning representation  we first picked the top     most related pairs from the
combined men and ws norms  so that we would be confident that they are indeed highly
related pairs for humans  and then we looked  within this subset  at those pairs with the
most pronounced difference in cosines between text and tunedfl  using window   as our
textual source  that is  the first column of table   presents pairs that are considered very
related by humans and where relatedness was better captured by text  the second column
pairs where relatedness was better captured by tunedfl 
notice that      of the relations better captured by tunedfl are between coordinates
or synonyms pertaining to concrete objects  candy chocolate  bicycle bike  apple cherry 
military soldier  paws whiskers  stream waterfall and cheetah lion   that should indeed be
maximally visually similar  either the objects themselves or  in a case such as paws whiskers 
their surrounds   the purely text based model  on the other hand  captures relations
between times of the day  that  while imageable  are not well delimited concrete objects
 dawn dusk  sunrise sunset   it captures properties of concepts expressed by adjectives
 dog canine  skyscraper tall  cat feline  pregnancy pregnant  rain misty   and at least one
case where spotting the relation requires encyclopedic knowledge  grape wine   we thus
hypothesize that the added value of the multimodally enhanced model derives from the
power of vision in finding relations between concrete objects at the same taxonomic level 
that results in detecting particularly tight forms of relatedness  such as synonymy and
coordination 
  

fimultimodal distributional semantics

text
dawn dusk
sunrise sunset
canine dog
grape wine
foliage plant
foliage petal
skyscraper tall
cat feline
pregnancy pregnant
misty rain

tunedfl
pet puppy
candy chocolate
paw pet
bicycle bike
apple cherry
copper metal
military soldier
paws whiskers
stream waterfall
cheetah lion

table    top    pairs whose relatedness is better captured by text  window   
vs  tunedfl 

as observed by one reviewer  given the taxonomic nature of the information captured by
the multimodal approach  it will be interesting to compare it in future work with features
directly extracted from a linguistic taxonomy  such as wordnet  we observe in passing that
such a manually constructed resource  unlike those extracted from textual corpora  is likely
to reflect both the linguistic and the perceptual knowledge of the lexicographers who built
it 
going in the opposite direction  another reviewer observed that we might get more
mileage by combining visual features with textual models that are less taxonomic in nature 
this hypothesis is partially confirmed by the fact that we obtain a larger relative improvement by mixing vision with window   than with window   look back at table    and see
section     above on why we think that the narrower window mainly captures taxonomic
relations  the larger one broader topical themes   to further explore this conjecture  we
re ran the men and ws experiments combining the visual vectors with a document based
textual model  i e   a semantic space whose dimensions record the number of occurrences
of words in documents   such a space is expected to capture mostly topical information 
as it estimates relatedness on the basis of the tendency of words to occur in the same
documents  sahlgren         the document based model alone was not as good as the
window based models  it obtained a spearman correlation of      on men and of      on
ws   and combining it with image based models led to relative improvements comparable
or inferior to those attained with window    the best combined model correlations were
     on men and      on ws   we conclude that  while looking for textual models that
are more complementary with respect to visual information seems a reasonable direction
to develop multimodal systems that cover a broader range of semantic phenomena  simply
emphasizing the topical side of textual models evidently does not suffice 
  

fibruni  tran   baroni

      the concreteness factor in modeling relatedness ratings  a pilot
study
in both previous experiments  we have observed a trend towards a division of labour between text  and image based models  where the latter are more apt at capturing similarity
among concrete concepts and properties  one of the strongest limitations of the current
version of our framework is the fact that every target word is assumed to be equally perceptually salient and consequently uniformly enriched with visual information  intuitively  we
might want to distinguish instead between concrete words  such as chair or cat  that require
an integration of perceptual information for their representation  and abstract words  such
as consequence or absurd  that can be represented on a purely symbolic linguistic basis 
indeed  recchia and jones        recently presented evidence that  in lexical decision and
naming tasks  rich physical contexts favour the activation of concrete concepts  whereas rich
linguistic contexts facilitate the activation of abstract concepts  with the follow up pilot
experiment presented in this section we want to pave the way for a systematic introduction of the concreteness factor in multimodal meaning representation  operationally  we
separate the abstract from the concrete word pairs in our semantic relatedness benchmark
men  assessing the contribution of textual and visual information in approximating word
meaning in the two domains independently  importantly  we use an automated method
to determine if a word is concrete or abstract  with an eye to a future integration of an
automatically determined abstractness score into our fusion algorithm 
in particular  we use abstractness scores automatically assigned by the algorithm recently introduced by turney  neuman  assaf  and cohen         scores are calculated by
computing the difference between the sum of text based semantic similarities of a target
word with a set of concrete paradigm words and the sum of its semantic similarities with
a set of abstract paradigm words  all words  i e   both the paradigm words and the words
for which an abstractness score was computed  were represented in a co occurrence based
matrix gathered from a large corpus of university websites  co occurrence counts were then
transformed into positive pointwise mutual information scores  church   hanks        and
the resulting matrix was smoothed with svd  pairwise semantic similarity was measured
by cosines  the paradigm words were in turn selected with a supervised learning method
trained on subject rated words from the mrc psycholinguistic database machine usable
dictionary  coltheart         examples of highly abstract words in the automatically rated
list are purvey        sense       and improbable        while examples of highly concrete
words  i e   words with a very low abstractness score  are donut        bullet       and shoe 
     
once the abstractness score was assigned to all the men testing words  we divided
the data set into two subsets  one containing only concrete word pairs  men conc     
pairs   the other containing both abstract pairs and mixed pairs  that is pairs formed by one
concrete and one abstract word  men abst      pairs   a word was considered concrete
if its abstract score was       abstract otherwise  for example  the word pair arm bicycle
was considered concrete  with scores of      and      respectively   fun relax was considered
abstract  with scores of     and      respectively  and design orange was considered mixed
 with scores of      and      respectively   we experimented with window   as our purely
  

fimultimodal distributional semantics

model
window  
image
tunedfl

men conc
    
    
    

men abst
    
    
    

men full
    
    
    

table    spearman correlation of the models on men divided into concrete and abstract
subsets  results on the full data set are also repeated  all coefficients significant
with p         

textual model  image is our usual visual model and tunedfl trained on men development
is our multimodal model 
in table   we show the correlation scores for the three models on the two men subsets
 as well as repeating the correlations they attain on the full set   first of all  it is worth
noticing that all models have higher correlations with men conc than men abst  suggesting
that approximating similarity judgments for pairs of concrete pairs is in general an easier
task for distributional semantics  and  we suspect  for humans as well    besides this broad
effect  we also observe a clear interaction for the added value of the visual component
between men abst and men conc  in fact  tunedfl gains more than     in performance
on men conc compared to window    while its performance is essentially the same as that
of the text only model in the case of men abst  this indicates that visual information is
mostly beneficial in the concrete domain  while it maintains a neutral  timidly positive 
impact on the abstract domain  recall that  in any case  men abst also contains mixed
pairs  
to conclude  in this section we followed up on the qualitative analysis of the main
relatedness results with a pilot experiment focusing on the concreteness factor  we showed
that when we divide the men benchmark into concrete and abstract subsets  the visual
information enhances the text based model only in the concrete domain  where its impact
is very strong  we exploited an automatic scoring function to divide the data set into the
concrete and abstract subsets  we can thus see the results we are reporting here also as
a validation of turney et al s algorithm  and  more importantly for our purposes  as an
encouragement to incorporate the automated abstractness concreteness scoring in the way
in which our model mixes textual and visual information on a word by word basis 
    concept categorization
to verify if the conclusions reached on ws and men extend to different semantic tasks and 
in particular  to assess whether our multimodal approach is able to capture and organize
meaning as humans do  we use two existing concept categorization benchmarks that we
call battig and almuhareb poesio  ap   respectively  where the goal is to cluster a set of
 nominal  concepts into broader categories  as already discussed in section     
in particular  we use battig exclusively for tuning  in the same way we used the men
development set in the previous section  and ap for testing  only results on ap are
reported  while in the word relatedness task the tuning and testing sets were quite similar
  

fibruni  tran   baroni

 men development and men testing are two subsets of the same data set and the words
in ws are similar to those in men   here the task is more challenging since battig and ap
are two independent data sets which were built following different strategies and populated
with different kinds of concepts  namely very concrete and unambiguous concepts for battig 
vs  a mixture of concrete and abstract  possibly ambiguous concepts in ap  we adopted the
present challenging training and testing regime because we felt that neither data set was of
sufficient size to allow a split between development and testing data  more details follow 
      benchmarks and method
the battig benchmark was introduced by baroni et al         and it is based on the battig
and montague norms of van overschelde  rawson  and dunlosky         it consists of
   highly prototypical concepts from    common concrete categories  up to    concepts
per class   battig contains basic level concepts belonging to categories such as bird  eagle 
owl         kitchenware  bowl  spoon        or vegetable  broccoli  potato         in the version we
cover there are    concepts from    different classes 
ap was introduced by almuhareb and poesio        and it is made of     nouns from
   different wordnet classes  in the version we cover  ap contains     concepts to be
clustered into    classes such as vehicle  airplane  car         time  aeon  future        or social
unit  brigade  nation   the data set contains many difficult cases of unusual or ambiguous
instances of a class  such as casuarina and samba as trees 
for both sets  following the original proponents and others  we cluster the words based on
their pairwise cosines in the semantic space defined by a model using the cluto toolkit
 karypis         we use clutos built in repeated bisections with global optimization
method  accepting all of clutos default values  cluster quality is often evaluated by
percentage purity  zhao   karypis         if nir is the number of items from the i th true
 gold standard  class that were assigned to the r th cluster  n the total number of items 
and k the number of clusters  then
purity  

x
  i n
max  nri  
n i  

in words  the number of items belonging to the majority true class  i e   the most represented
class in the cluster  are summed up across clusters and divided by the total number of items 
in the best scenario purity will be   and it will approach   as cluster quality deteriorates 
since we lack full ap coverage  the results we report below are not directly comparable
with other studies that used it  however  our text based models do have perfect coverage 
and when evaluated on the full set achieve purities of       window   and       window   
that are at state of the art levels for comparable models  as reported in section     above 
so  again  we can confidently claim that the improvements achieved with multimodality are
obtained by comparing our approach to competitive purely textual models 
      results
table   reports percentage purities in the ap clustering task  also here the best automatically selected model  tunedfl  uses fl similarity estimation as in the previous task  and
has similar svd k     for window  and    for window    and        parameters to the
  

fimultimodal distributional semantics

model
text
image
naivefl
naivesl
mixlda
textmixed
imagemixed
tunedfl
tunedsl

window 
ap
    
    
    
    
    
    
    
    
    

window  
ap
    
    
    
    
    
    
    
    
    

table    percentage purities of the models on ap  tunedfl is the model automatically
selected on the battig data  tunedsl is automatically tuned after fixing sl similarity estimation 

ones found for relatedness  suggesting that this particular parameter choice is robust and
could be used out of the box in other tasks as well  tunedsl is the best sl based method
on the tuning battig set  same ks as tunedfl         for window   but        on
window   
analogously to the previous semantic task  we see that the image model alone is not
at the level of the text models  although its ap purities are significantly above chance
 p        based on simulated distributions for random cluster assignment   thus  we have
a further confirmation of the fact that image based vectors do capture important aspects
of meaning  as in the previous task  mixlda achieves very poor results 
looking at the text based models enhanced with visual information  we can see a general
improvement in performance in almost all the multimodal combination strategies  except
for naivefl with window   and naivesl with window   even if textmixed benefits from
visual smoothing in both cases  it is again outperformed by tunedfl  whose performance is
here very similar to that of tunedsl  that actually is slightly better on window   interestingly  tunedsl outperforms text on window  despite the fact this is the single combination
strongly unbalanced towards textual similarity           indicating that visual information can be beneficial even when textual information accounts for the lions share of the
composed estimate 
like in the relatedness task  adding an equal amount of further textual features instead
of image based ones does not help with window         purity with    k textual features 
and even lowers performance with window        purity   thus  the improvement brought
about by visual features must be attributed to their quality  not just quantity 
according to a two tailed permutation test  even the largest difference between tunedfl
and text on window   is not significant  this might be due to the brittleness of the purity
statistics leading to high variance in the permutations  and possibly to suboptimal tuning 
recall  in this respect  that the tuning phase was performed on a rather different data
set  battig  compared to the data set on which we eventually evaluated the models  ap  
  

fibruni  tran   baroni

however  the overall trends are very encouraging  and in line with what we found in the
relatedness study 

   conclusion
in this paper we have provided an extensive introduction to a new approach to distributional semantics that we named multimodal distributional semantics  a multimodal
distributional semantic model integrates a traditional text based representation of meaning
with information coming from vision  in this way  it tries to answer to the critique that distributional models lack grounding  since they base their representation of meaning entirely
on the linguistic input  neglecting statistical information inherent in perceptual experience 
that we humans instead exploit  of course  a truly multimodal representation of meaning
should account for the entire spectrum of human senses  on the other hand  this line of
research is still in its embryonic stage and there is still a shortage of both perceptual data
available and techniques to automatize their processing  this is why  in this article  we
focused our analysis on the visual perceptual channel  for which we have at our disposal
both large data sets and effective methods to analyze them 
in particular  we exploited the esp game data set  where the image documents are
tagged with words describing their content  to harvest visual information we adopted the
bag of visual words technique  which discretizes image content in ways that are analogous to
standard text based distributional representations  we introduced a multimodal framework
that optimizes text image fusion in a data driven fashion on development data 
we conducted a number of experiments to assess the quality of the obtained models 
we first investigated the general semantic properties of a purely image based model  to
assess its overall quality as well as to look for information complementary to that present in
text  we found systematic differences between the two modalities  such as the preference for
encyclopedic properties of a text based model and for perceptual properties in the case of the
image based model  we proceeded to test a selection of models obtained by the combination
of the text  and image based representations via our multimodal framework  we used two
benchmarks for word relatedness and one benchmark for word categorization and in both
cases we obtained a systematic improvement in performance with the multimodal models
compared to models based on standalone channels 
still  by looking at the numerical results  we cannot deny that the improvement in performance attained when including visual information is not dramatic  indeed  a pessimistic
interpretation of the experiments could be that they confirm the hypothesis by louwerse
and others  e g   louwerse        louwerse   connell        tillman  datla  hutchinson   
louwerse        that perceptual information is already encoded  to a sufficient degree  into
linguistic data  so direct visual features dont bring much to the table  however  we showed
through various statistical and validation tests that our most important result  namely that
adding visual information improves over using text alone  is robust and reliable  we think
a more realistic take home message is that the experiments we reported  while establishing
the basic result we just mentioned  had some drawbacks we should overcome in further
work 
first of all  we deliberately used general semantic benchmarks and state of the art text
models  so that the performance of computational methods might be getting close to the
  

fimultimodal distributional semantics

ceiling  at      correlation  our best models still have a few percentage points to go on
men  estimated upper bound based on raters agreement        see section         but
the improvements are bound to be quite small  concerning the ap benchmark  consider
how difficult it would be even for humans to categorize casuarina and samba among the
trees  indeed  an error analysis of the tunedfl clustering results suggests that factors
that might lead to better performance have little to do with vision  for example  the
model wrongly clusters branch  a social unit according to ap  with the trees  and merges
concepts such as melon and peach  fruit in ap  with mandarin and lime  trees   in lack of
further contextual information  its hard to dispute the model choices  similarly  tunedfl
splits the ap animal class into a cluster of small domestic mammals  cats  dogs  kittens 
mice  puppies and rats  and a cluster containing everything else  mostly larger mammals
such as cows and elephants   again  the clustering procedure had no information about the
classes we were searching for  e g   animals in general  and not small animals   and so it is
hard to see how performance could have improved thanks to better semantic features  visual
or of other kinds  moreover  all data sets include abstract terms  and are not specifically
designed to test the more grounded aspects of meaning  where visual features might help
most  we think it made sense to start our investigation with these general benchmarks of
semantics  as opposed to ad hoc test sets  to show the viability of the multimodal approach 
however  in the future we want to focus on experimental challenges where the strengths of
visually enhanced models might emerge more clearly  we took a first step in this direction
by bruni et al          where we focused specifically on how visual features can help in
processing both literal and metaphorical colours 
another factor to take into account is that both large scale image data sets and the
techniques to extract features from them are in their infancy  and we might be able to
improve performance further by developing better image based models  regarding the data
sets  we explained in section       above why we chose esp game  but obviously it is
sub optimal in many respects  as we also discuss there  regarding the features  as we
mentioned at the beginning of section        recent advances in image processing  such as
fisher encoding  might lead to better ways to extract the information contained in images 
in the experiments  we also compared our automatically tuned multimodal model to
other settings  showing its overall stability and superiority  with two important caveats 
first  in both experiments good results are already obtained by using visual information
to smooth text features  without using the visual features directly  what we called the
textmixed approach   note that this is already a multimodal approach  in that visual
information is crucially used to improve the quality of the textual dimensions  and indeed
weve seen that it consistently outperforms using non multimodally smoothed text features 
while textmixed is not as good as our full tuned model  its simplicity makes it a very
attractive approach 
second  although automated tuning led us to prefer feature level over scoring level
fusion on the development sets  tunedsl was clearly worse than tunedfl in just one case
 with window   on ws   suggesting that  at least for the evaluation settings we considered 
the difference between the two fusion strategies is not crucial  however  when comparing
the naive versions of both strategies to the tuned ones across the results  it is clear that
tuning is important to obtain consistently good performance  confirming the usefulness of
our general fusion architecture 
  

fibruni  tran   baroni

we also conducted a pilot experiment on the concreteness abstractness factor  to assess
its impact on meaning representation and to check if it is a good candidate for a new
weighted fusion strategy we plan to investigate in the future  in fact  in the current version
of the multimodal framework  the parametrization of the combination strategy works at a
global level  i e  it is the same for all words   it could be more productive to combine textual
and visual information on a word by word basis  and tune the two modality contributions
in meaning representation depending on the particular nature of each single word  concrete
vs  abstract does not constitute a neat binary distinction for all words  but it has to be rather
thought as an ideal distinction to be offset with a less abrupt  real world formulation  which
takes into account the degree according to which a certain word can be considered concrete
or abstract  there is no doubt that words such as backdrop  squalor or sharp evoke some
perceptual cues gathered from our experience about them  but at the same time there
is an unequivocal amount of abstractness accompanying them  we plan also to refine
the concreteness scoring method in order to make it focus specifically on the imageable
components of concreteness  as we expect them to be more relevant to our visual channel 
further developments will focus on the techniques to extract the image based semantic
models  for example  in a pilot study  bruni et al          we exploit new methods developed
in computer vision to improve object recognition by capturing object location  felzenszwalb 
girshick  mcallester    deva ramanan        de sande  uijlings  gevers    smeulders 
       we show that it is possible to extract better image based semantic vectors by first
localizing the objects denoted by words and then extracting visual information from the
object location and from its surround independently  interestingly  we discovered that
image based semantic vectors extracted from the object surround are more effective than
those based on the object location when tested on our word relatedness task  for example 
the fact that pictures containing deers and wolves depict similar surrounds tells us that
such creatures live in similar environments  and it is thus likely that they are somewhat
related  this can be seen as the distributional hypothesis transposed to images  objects
that are semantically similar occur in similar visual contexts  nevertheless  the work has
to be considered a proof of concept  since we experimented with    words only  in future
studies we will test a larger number of words 
while there is obviously much room for improvement  and many exciting routes to
explore  we hope that the framework and empirical results we presented in this study
convinced the reader that multimodal distributional semantics is a very promising avenue
to pursue in the development of human like models of meaning 

acknowledgments
we thank jasper uijlings for his valuable suggestions about the image analysis pipeline  a
lot of code and many ideas came from giang binh tran  and we owe gemma boleda many
further ideas and useful comments  peter turney kindly shared the abstractness score list
we used in section       and yair neuman generously helped with a preliminary analysis
of the impact of abstractness on our multimodal models  mirella lapata kindly made the
wordsim    set used in the experiments of feng and lapata        available to us  we
thank the jair associated editor and reviewers for helpful suggestions and constructive
  

fimultimodal distributional semantics

criticism  google partially funded this project with a google research award to the third
author  the bless study of section       was first presented by bruni et al         

references
abdi  h     williams  l          newman keuls and tukey test  in salkind  n   frey  b    
dougherty  d   eds    encyclopedia of research design  pp          sage  thousand
oaks  ca 
agirre  e   alfonseca  e   hall  k   kravalova  j   pasa  m     soroa  a          a study
on similarity and relatedness using distributional and wordnet based approaches  in
proceedings of hlt naacl  pp        boulder  co 
almuhareb  a     poesio  m          concept learning and categorization from the web 
in proceedings of cogsci  pp          stresa  italy 
andrews  m   vigliocco  g     vinson  d          integrating experiential and distributional
data to learn semantic representations  psychological review                  
baayen  h          analyzing linguistic data  a practical introduction to statistics using
r  cambridge university press  cambridge  uk 
barnard  k   duygulu  p   forsyth  d   de freitas  n   blei  d     jordan  m          matching words and pictures  journal of machine learning research              
baroni  m   barbu  e   murphy  b     poesio  m          strudel  a distributional semantic
model based on properties and types  cognitive science                 
baroni  m     lenci  a          concepts and properties in word spaces  italian journal
of linguistics               
baroni  m     lenci  a          distributional memory  a general framework for corpusbased semantics  computational linguistics                 
baroni  m     lenci  a          how we blessed distributional semantic evaluation  in
proceedings of the emnlp gems workshop  pp       edinburgh  uk 
barsalou  l          grounded cognition  annual review of psychology             
berg  t   berg  a     shih  j          automatic attribute discovery and characterization
from noisy web data  in eccv  pp          crete  greece 
bergsma  s     goebel  r          using visual information to predict lexical preference 
in proceedings of ranlp  pp          hissar  bulgaria 
blei  d  m   ng  a  y     jordan  m  i          latent dirichlet allocation  journal of
machine learning research             
bosch  a   zisserman  a     munoz  x          image classification using random forests
and ferns  in proceedings of iccv  pp      rio de janeiro  brazil 
bosch  a   zisserman  a     munoz  x          scene classification using a hybrid generative discriminative approach  ieee transactions on pattern analysis and machine
intelligence         
bruni  e   boleda  g   baroni  m     tran  n  k          distributional semantics in
technicolor  in proceedings of acl  pp          jeju island  korea 
  

fibruni  tran   baroni

bruni  e   bordignon  u   liska  a   uijlings  j     sergienya  i          vsem  an open
library for visual semantics representation  in proceedings of acl  sofia  bulgaria 
bruni  e   tran  g  b     baroni  m          distributional semantics from text and images 
in proceedings of the emnlp gems workshop  pp        edinburgh  uk 
bruni  e   uijlings  j   baroni  m     sebe  n          distributional semantics with eyes 
using image analysis to improve computational representations of word meaning  in
proceedings of acm multimedia  pp            nara  japan 
budanitsky  a     hirst  g          evaluating wordnet based measures of lexical semantic
relatedness  computational linguistics               
bullinaria  j     levy  j          extracting semantic representations from word cooccurrence statistics  a computational study  behavior research methods         
    
bullinaria  j     levy  j          extracting semantic representations from word cooccurrence statistics  stop lists  stemming and svd  behavior research methods 
           
burgess  c          theory and operational definitions in computational memory models 
a response to glenberg and robertson  journal of memory and language         
       
caicedo  j   ben abdallah  j   gonzlez  f     nasraoui  o          multimodal representation  indexing  automated annotation and retrieval of image collections via nonnegative matrix factorization  neurocomputing               
chatfield  k   lempitsky  v   vedaldi  a     zisserman  a          the devil is in the
details  an evaluation of recent feature encoding methods  in proceedings of bmvc 
dundee  uk 
church  k     hanks  p          word association norms  mutual information  and lexicography  computational linguistics               
clark  s          vector space models of lexical meaning  in lappin  s     fox  c   eds   
handbook of contemporary semantics   nd ed  blackwell  malden  ma  in press 
coltheart  m          the mrc psycholinguistic database  quarterly journal of experimental psychology     
connolly  a   gleitman  l     thompson schill  s          effect of congenital blindness on
the semantic representation of some everyday concepts  proceedings of the national
academy of sciences                     
csurka  g   dance  c   fan  l   willamowski  j     bray  c          visual categorization
with bags of keypoints  in in workshop on statistical learning in computer vision 
eccv  pp       prague  czech republic 
curran  j     moens  m          improvements in automatic thesaurus extraction  in
proceedings of the acl workshop on unsupervised lexical acquisition  pp       
philadelphia  pa 
  

fimultimodal distributional semantics

de sande  k  v   uijlings  j   gevers  t     smeulders  a          segmentation as selective
search for object recognition  in proceedings of iccv  pp            barcelona 
spain 
de vega  m   glenberg  a     graesser  a   eds            symbols and embodiment  debates
on meaning and cognition  oxford university press  oxford  uk 
deng  j   dong  w   socher  r   li  l  j     fei fei  l          imagenet  a large scale
hierarchical image database  in proceedings of cvpr  pp          miami beach 
fl 
dumais  s          data driven approaches to information access  cognitive science     
       
erk  k          vector space models of word meaning and phrase meaning  a survey  
language and linguistics compass                 
escalante  h  j   hrnadez  c  a   sucar  l  e     montes  m          late fusion of heterogeneous methods for multimedia image retrieval  in proceedings of icmr  vancouver 
canada 
evert  s          the statistics of word cooccurrences  dissertation  stuttgart university 
farhadi  a   hejrati  m   sadeghi  m  a   young  p   rashtchian  c   hockenmaier  j    
forsyth  d          every picture tells a story  generating sentences from images  in
proceedings of eccv  crete  greece 
felzenszwalb  p   girshick  r   mcallester  d     deva ramanan  d          object detection with discriminatively trained part based models  ieee transactions on pattern
analysis and machine intelligence               
feng  y     lapata  m          visual information in semantic representation  in proceedings of hlt naacl  pp        los angeles  ca 
finkelstein  l   gabrilovich  e   matias  y   rivlin  e   solan  z   wolfman  g     ruppin 
e          placing search in context  the concept revisited  acm transactions on
information systems                 
firth  j  r          papers in linguistics             oxford university press  oxford 
uk 
fodor  j          the language of thought  crowell press  new york 
glenberg  a     robertson  d          symbol grounding and meaning  a comparison of
high dimensional and embodied theories of meaning  journal of memory and language                 
grauman  k     darrell  t          the pyramid match kernel  discriminative classification
with sets of image features  in proceedings of iccv  pp            beijing  china 
grauman  k     leibe  b          visual object recognition  morgan   claypool  san
francisco 
grefenstette  g          explorations in automatic thesaurus discovery  kluwer  boston 
ma 
  

fibruni  tran   baroni

griffin  l   wahab  h     newell  a          distributional learning of appearance  plos
one         published online  http   www plosone org article info doi    
     journal pone         
griffiths  t   steyvers  m     tenenbaum  j          topics in semantic representation 
psychological review              
hansen  t   olkkonen  m   walter  s     gegenfurtner  k          memory modulates color
appearance  nature neuroscience              
harnad  s          the symbol grounding problem  physica d  nonlinear phenomena 
                 
harris  z          distributional structure  word                     
johns  b     jones  m          perceptual inference through global lexical similarity  topics
in cognitive science                
karypis  g          cluto  a clustering toolkit  tech  rep          university of minnesota
department of computer science 
kaschak  m   madden  c   therriault  d   yaxley  r   aveyard  m   blanchard  a     zwaan 
r          perception of motion affects language processing  cognition      b  b   
kievit kylar  b     jones  m          the semantic pictionary project  in proceedings of
cogsci  pp            austin  tx 
kulkarni  g   premraj  v   dhar  s   li  s   choi  y   berg  a  c     berg  t  l         
baby talk  understanding and generating simple image descriptions  in proceedings
of cvpr  colorado springs  msa 
landauer  t     dumais  s          a solution to platos problem  the latent semantic analysis theory of acquisition  induction  and representation of knowledge  psychological
review                  
lazebnik  s   schmid  c     ponce  j          beyond bags of features  spatial pyramid
matching for recognizing natural scene categories  in proceedings of cvpr  pp      
      washington  dc 
leong  c  w     mihalcea  r          going beyond text  a hybrid image text approach
for measuring word relatedness  in proceedings of ijcnlp  pp           
lloyd  s          least squares quantization in pcm  ieee transactions on information
theory             
louwerse  m          symbol interdependency in symbolic and embodied cognition  topics
in cognitive science            
louwerse  m     connell  l          a taste of words  linguistic context and perceptual
simulation predict the modality of words  cognitive science             
lowe  d          object recognition from local scale invariant features  in proceedings of
iccv  pp           
lowe  d          distinctive image features from scale invariant keypoints  international
journal of computer vision         
  

fimultimodal distributional semantics

lowe  w          towards a theory of semantic space  in proceedings of cogsci  pp         
edinburgh  uk 
lund  k     burgess  c          producing high dimensional semantic spaces from lexical
co occurrence  behavior research methods             
manning  c   raghavan  p     schtze  h          introduction to information retrieval 
cambridge university press  cambridge  uk 
manning  c     schtze  h          foundations of statistical natural language processing 
mit press  cambridge  ma 
mcdonald  s     brew  c          a distributional model of semantic context effects in
lexical processing  in proceedings of acl  pp        barcelona  spain 
mcrae  k   cree  g   seidenberg  m     mcnorgan  c          semantic feature production
norms for a large set of living and nonliving things  behavior research methods         
       
miller  g     charles  w          contextual correlates of semantic similarity  language
and cognitive processes             
moore  d     mccabe  g          introduction to the practice of statistics    edition  
freeman  new york 
murphy  g          the big book of concepts  mit press  cambridge  ma 
nelson  d   mcevoy  c     schreiber  t          the university of south florida word association  rhyme  and word fragment norms  http   www usf edu freeassociation  
nister  d     stewenius  h          scalable recognition with a vocabulary tree  in proceedings of the      ieee computer society conference on computer vision and pattern
recognition   volume    cvpr     pp           
nowak  e   jurie  f     triggs  b          sampling strategies for bag of features image
classification  in proceedings of eccv  pp          graz  austria 
pad  s     lapata  m          dependency based construction of semantic space models 
computational linguistics                 
pad  u   pad  s     erk  k          flexible  corpus based modelling of human plausibility
judgements  in proceedings of emnlp  pp          prague  czech republic 
pecher  d   zeelenberg  r     raaijmakers  j          does pizza prime coin  perceptual
priming in lexical decision and pronunciation  journal of memory and language     
       
perronnin  f   sanchez  j     mensink  t          improving the fisher kernel for large scale
image classification  in proceedings of eccv  pp          berlin  heidelberg 
pham  t  t   maillot  n   lim  j  h     chevallet  j  p          latent semantic fusion
model for image retrieval and annotation  in proceedings of cikm  pp         
lisboa  portugal 
poesio  m     almuhareb  a          identifying concept attributes using a classifier  in
proceedings of the acl workshop on deep lexical semantics  pp        ann arbor 
mi 
  

fibruni  tran   baroni

pulvermueller  f          brain mechanisms linking language and action  nature reviews
neuroscience            
radinsky  k   agichtein  e   gabrilovich  e     markovitch  s          a word at a time 
computing word relatedness using temporal semantic analysis  in proceedings of
www  pp          hyderabad  india 
rapp  r          word sense discovery based on sense descriptor dissimilarity  in proceedings of the  th mt summit  pp          new orleans  la 
recchia  g     jones  m          the semantic richness of abstract concepts  frontiers in
human neuroscience          
reisinger  j     mooney  r  j          multi prototype vector space models of word meaning  in proceedings of naacl  pp          los angeles  ca 
riordan  b     jones  m          redundancy in perceptual and linguistic experience 
comparing feature based and distributional models of semantic representation  topics
in cognitive science             
rothenhusler  k     schtze  h          unsupervised classification with dependency
based word spaces  in proceedings of the eacl gems workshop  pp        athens 
greece 
rubenstein  h     goodenough  j          contextual correlates of synonymy  communications of the acm                 
sahlgren  m          an introduction to random indexing  http   www sics se  mange 
papers ri intro pdf 
sahlgren  m          the word space model  dissertation  stockholm university 
sahlgren  m          the distributional hypothesis  italian journal of linguistics         
     
schtze  h          ambiguity resolution in natural language learning  csli  stanford 
ca 
silberer  c     lapata  m          grounded models of semantic representation  in proceedings of emnlp conll  pp            jeju  korea 
sivic  j     zisserman  a          video google  a text retrieval approach to object matching in videos  in proceedings of iccv  pp            nice  france 
steyvers  m          combining feature norms and text data with topic models  acta
psychologica                  
therriault  d   yaxley  r     zwaan  r          the role of color diagnosticity in object
recognition and representation  cognitive processing                 
tillman  r   datla  v   hutchinson  s     louwerse  m          from head to toe  embodiment through statistical linguistic frequencies  in proceedings of cogsci  pp 
          austin  tx 
turney  p   neuman  y   assaf  d     cohen  y          literal and metaphorical sense
identification through concrete and abstract context  in proceedings of emnlp  pp 
        edinburgh  uk 
  

fimultimodal distributional semantics

turney  p     pantel  p          from frequency to meaning  vector space models of semantics  journal of artificial intelligence research             
van de sande  k   gevers  t     snoek  c          evaluating color descriptors for object and
scene recognition  ieee transactions on pattern analysis and machine intelligence 
                 
van overschelde  j   rawson  k     dunlosky  j          category norms  an updated and
expanded version of the battig and montague        norms  journal of memory and
language             
vedaldi  a     fulkerson  b          vlfeat  an open and portable library of computer
vision algorithms  in proceedings of acm multimedia  pp            firenze  italy 
von ahn  l          games with a purpose  computer               
vreeswijk  d  t   huurnink  b     smeulders  a  w          text and image subject
classifiers  dense works better  in proceedings of acm multimedia  pp           
scottsdale  az 
wang  j   yang  j   yu  k   lv  f   huang  t     gong  y          locality constrained
linear coding for image classification  in proceedings of cvpr  pp            san
francisco  ca 
weeds  j          measures and applications of lexical distributional similarity  ph d 
thesis  department of informatics  university of sussex 
wittgenstein  l          philosophical investigations  blackwell  oxford  uk  translated
by g e m  anscombe 
yang  j   jiang  y  g   hauptmann  a     ngo  c  w          evaluating bag of visualwords representations in scene classification  in wang  j  z   boujemaa  n   bimbo 
a  d     li  j   eds    multimedia information retrieval  pp          acm 
zhao  y     karypis  g          criterion functions for document clustering  experiments
and analysis  tech  rep         university of minnesota department of computer
science 

  

fi