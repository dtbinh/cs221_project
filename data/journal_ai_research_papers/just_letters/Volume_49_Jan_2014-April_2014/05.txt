journal of artificial intelligence research                  

submitted        published      

algorithms and applications for the
same decision probability
suming chen
arthur choi
adnan darwiche

suming cs ucla edu
aychoi cs ucla edu
darwiche cs ucla edu

computer science department
university of california  los angeles
los angeles  ca      

abstract
when making decisions under uncertainty  the optimal choices are often difficult to
discern  especially if not enough information has been gathered  two key questions in this
regard relate to whether one should stop the information gathering process and commit
to a decision  stopping criterion   and if not  what information to gather next  selection
criterion   in this paper  we show that the recently introduced notion  same decision
probability  sdp   can be useful as both a stopping and a selection criterion  as it can provide additional insight and allow for robust decision making in a variety of scenarios  this
query has been shown to be highly intractable  being pppp  complete  and is exemplary of
a class of queries which correspond to the computation of certain expectations  we propose the first exact algorithm for computing the sdp  and demonstrate its effectiveness on
several real and synthetic networks  finally  we present new complexity results  such as the
complexity of computing the sdp on models with a naive bayes structure  additionally 
we prove that computing the non myopic value of information is complete for the same
complexity class as computing the sdp 

   introduction
probabilistic graphical models have often been used to model a variety of decision problems 
e g   in medical diagnosis  pauker   kassirer        kahn  roberts  shaffer    haddawy 
      van der gaag   coupe         fault diagnosis  lu   przytula         classification
 friedman  geiger    goldszmidt        ramoni   sebastiani        jordan         troubleshooting  heckerman  breese    rommelse         educational diagnosis  butz  hua   
maguire        arroyo   woolf        millan  descalco  castillo  oliveira    diogo        
and in intrusion detection  kruegel  mutz  robertson    valeur        modelo howard 
bagchi    lebanon         in these and similar applications  a decision maker is typically
in a position where they must decide which tests to perform or observations to make in
order to make a better informed decision  perhaps more critically  a decision maker must
also decide when to stop making observations and commit to a particular decision 
the same decision probability  sdp  was recently proposed by darwiche and choi
        in order to help quantify the robustness of a decision  in the context of decisionmaking with bayesian networks  in short  the sdp is the probability that we would make
the same decision  if we were to perform further observations that have yet to be made 
as such  the sdp can be treated as a measure for a decisions robustness with respect to
c
    
ai access foundation  all rights reserved 

fichen  choi   darwiche

unknown variables  quantifying our confidence that we would make the same decision  even
if we made further observations 
in this paper  we show how we can apply the sdp as a tool for information gathering  in
particular  as a way to determine if we should stop information gathering  as a stopping criterion   and if not  which pieces of information to gather next  as a selection criterion   we
compare the sdp to classical stopping and selection criteria through illustrative examples 
for instance  we demonstrate that the sdp can distinguish between stable and unstable
decisions that are indistinguishable by classical criteria  additionally  we also show that
there are scenarios where classical criteria may call for performing further observations  but
where the sdp indicates that our decision is unlikely to change 
notably  the sdp has been shown to be highly intractable  by choi  xue  and darwiche
        and the exact computation of the sdp has been limited to toy examples  with
few variables  through brute force enumeration  in this paper  we propose the first exact
algorithm for computing the sdp  this algorithm can be applied to real world networks that
are out of the scope of both brute force enumeration and previously proposed approximation
algorithms  and can be further applied to synthetic networks with as many as     variables 
we further provide new complexity results on the sdp  which both highlight its relative
intractability  even in naive bayes networks   but also its relationship to a broader class
of expectation computation problems  emphasizing the broader importance of developing
effective algorithms for the sdp and related problems 
our paper is thus structured as follows  we first introduce notation and discuss some
common stopping and selection criteria in section    we then review our previously introduced work on the sdp in section    in section    we discuss how the sdp can be applied
as both a stopping criterion and as a selection criterion  in section    we present a novel
exact algorithm for computing the sdp and discuss experimental results in section    in
section    we present some recent complexity results on the sdp  we then conclude our
paper in section   

   related work
when making decisions under uncertainty  it may be difficult to finalize a decision in the
presence of unobserved variables  given these unobserved variables  there are two fundamental questions  the first question is whether  given the current observations  the decision
maker is ready to commit to a decision  we will refer to this as the stopping criterion for
making a decision  assuming the stopping criterion is not met  the second question is what
additional observations should be made before the decision maker is ready to make a decision  this typically requires a selection criterion based on some measure for quantifying an
observations value of information  voi   in this section  we first introduce some necessary
notation  and then review some commonly used stopping and selection criteria 
    notation
throughout this paper  we use standard notation for variables and their instantiations 
where variables are denoted by upper case letters x and their instantiations by lower case
letters x  additionally  sets of variables are denoted by bold upper case letters x and
their instantiations by bold lower case letters x  we assume that the state of the world is
   

fialgorithms and applications for the same decision probability

described over random variables x  where the evidence e  x includes all known variables 
and where hidden variables u  x include all unknown variables  by definition  e  u   
and eu   x  we often discuss the ramifications of observing a subset of hidden variables
h  u on decision making  furthermore  we use d  u to denote the main hypothesis
variable that forms the basis for a decision  
    stopping criterion
given that there are hidden variables in our model and we have the choice of whether or
not to observe some subset  a stopping criterion determines when we stop the process of
information gathering and commit to a decision  note that we are concerned with making
a decision based on some hypothesis variable  such as the state of a patients health  for
a stopping criterion  the most basic approach used in a variety of domains is to commit
to a decision once the belief about a certain event crosses some threshold  as is done by
pauker and kassirer         kruegel et al          and lu and przytula         however 
this approach may not be robust  as further observations may cause the belief about the
event to fall below the threshold  van der gaag and bodlaender        note the possibility
of this and pose the stop problem  which asks whether or not the present evidence gathered
is sufficient for diagnosis  or if there exists further relevant evidence that can and should be
gathered 
other approaches involve ensuring that the uncertainty surrounding the decision variable
is sufficiently reduced  for instance  gao and koller        stop information gathering when
   the conditional entropy of the interest variable is reduced beyond some threshold or   
the margin between the first and second most likely states of the interest variable is above
some threshold  in any case  it is clear that threshold based stopping criteria are ubiquitous
for decision making under uncertainty 
alternatively  there are also several stopping criteria that involve the existence of a
budget  which can be an abstract quantity to represent the available resources that can
be used for information gathering  the budget may be representative of the number of
observations that are allowed  modelo howard et al         munie   shoham        yu 
krishnapuram  rosales    rao        chen  low  tan  oran  jaillet  dolan    sukhatme 
    a   or in terms of a monetary amount that may be spent on observations of varying
cost  greiner  grove    roth        krause   guestrin        bilgic   getoor         in the
context of a budget  the general stopping criterion is then to continue to make observations
until the budget is completely expended  as is done by modelo howard et al         and
munie and shoham         krause and guestrin        and bilgic and getoor        note
that the budget should be expended with the caveat that the value of information of an
observation is at least the cost of the observation 
    selection criterion  value of information
should the stopping criterion determine that further observations are necessary  a selection
criterion is then used to determine which variables should be selected for observation 
ideally  we want to observe all variables that will give us additional information with regards
   the work presented in this paper can be extended to the case of multiple hypothesis variables  but we
focus here on the case of one hypothesis variable for simplicity 

   

fichen  choi   darwiche

to our decision variable  however  due to resource constraints  such as a limited budget  this
is often not possible  in this basic approach  a common selection criterion is to then select
observations that will minimize the conditional entropy of the decision variable  vomlel 
      lu   przytula        krause   guestrin        yu et al         zhang   ji       
gao   koller        ognibene   demiris        shann   seuken         the entropy of a
variable x is defined as 
h x    

x

pr  x  log pr  x 

   

x

and is a measure of the uncertainty of the variables state  if the entropy of a variable is
high  that means that there is much uncertainty on what value that variable takes   the
uncertainty of the decision variables true state makes it difficult to make a decision  thus  a
natural selection criterion is to observe variables to minimize the conditional entropy of the
decision variable  where the conditional entropy of variable d given variable x is defined
as 
h d   x   

x

h d   x pr  x 

   

x

the conditional entropy is thus an expectation of what the entropy would be after
observing x  a similar selection criterion is to observe variables that will most greatly
increase the margin between the posterior probabilities of the first and second most likely
states of the decision variable  krause   guestrin        
these selection criteria involve utilizing the notion of value of information  voi  in order
to quantify the value of various observations  lindley        stratonovich        howard 
      raiffa         the voi of a set of variables can depend on various measures  in
the two example selection criteria we have discussed  those measures would be entropy and
margins of confidence  for instance  if observing a variable x would reduce the conditional
entropy h d   x  more than observing variable x  would  h d   x    h d   x      then
the value of observing x would be higher 
krause and guestrin        define a general notion of voi that is based on different
reward functions  in particular  given an arbitrary reward function r   a hypothesis variable
d  and evidence e  the voi of observing hidden variables h is 
v r  d  h  e    er r  d  h  e   r pr  d   e  

   

where
er r  d  h  e   

x

r pr  d   h  e  pr  h   e 

   

h

is the expected reward of observing variables h and r pr  d   e   is the reward had
we not observed variables h  by this definition  the reward function used by lu and
   in information theory  the logarithm is typically assumed to be base    cover   thomas         which
we also assume throughout the paper for convenience 
   a reward function is assumed to take as input the probability distribution of the hypothesis variable 
pr  d   and return some numeric value  we discuss reward functions further in section     

   

fialgorithms and applications for the same decision probability

d

d
 


pr  d   e       e      
        
        

x 

x 

e 

e 

h 

h 

figure    a simple bayesian network  under sensor readings  e       e        variables h 
and h  represent the health of sensors e  and e    on the left is the posterior on
the decision variable d  network cpts can be found in appendix c in figure    

przytula        and krause and guestrin        to select variables in order to minimize
the conditional entropy is then r pr  d   e     h d   e   so maximizing the expected
reward of observing variables h is then equivalent to minimizing the conditional entropy
h d   h   some other possible reward functions involve utility based reward functions or
threshold based reward functions  munie   shoham         
note that the vast majority of selection criteria use a myopic approach  in which out of
all possible observations  just one observation is considered at a time  and the observation
with the highest voi is selected each time  this approach is greedy and short sighted 
the optimal voi can only be computed by computing it non myopically  bilgic   getoor 
       we discuss the usage of non myopic voi in appendix a   

   same decision probability
the same decision probability  sdp  was initially introduced by darwiche and choi       
as a confidence measure for threshold based decisions in bayesian networks under noisy
sensor readings  prior to formally defining the sdp  we first show an example to provide
intuition  consider now the bayesian network in figure    which models a scenario involving
a hypothesis variable d  and two noisy sensors e  and e  that influence our belief in some
hypothesis d  networks such as this are typically used to compute the belief in the hypothesis
given some sensor readings  pr  d   e   the basis of whether or not to make a decision often
then depends on whether or not the posterior probability of that hypothesis d surpasses
some threshold t  hamscher  console    de kleer        heckerman et al         kruegel
et al         lu   przytula        
figure   shows a particular reading of two sensors and the resulting belief pr  d      
e       e        suppose our threshold is t        then as pr  d   e   t   we would make a
certain decision  notice in figure   that the health of those sensors is modeled by variables
h  and h    a sensor can either be truthful  stuck positive  readings always display as    
or lying  readings show the opposite value of the actual value   darwiche   choi        
if those variables had been observed  they could have informed us of the trustworthiness of
   for more on reward functions  see the list provided by krause and guestrin        

   

fichen  choi   darwiche

h 
t
p
l
t
p
l
t
p
l

h 
t
t
t
p
p
p
l
l
l

pr  h   e 
        
        
        
        
        
        
        
        
        

pr  d   h  e 
    
    
    
    
    
    
    
    
    

table    scenarios h for sensor readings e    e       e       for the network in figure   
where h    h    h     cases above the threshold t       are in bold  note t  p  l
respectively represent a truthful  stuck positive  and lying sensor 

the sensors e  and e  and thus allow us to make a better decision  we want to make a
more informed decision based on the probability pr  d   h  e  instead of making a decision
based on just pr  d   e  
consider table    which enumerates all of the possible health states of the sensors  in
only four of these cases does the probability of the hypothesis pass the threshold  in bold  
leading to the same decision  in the other five scenarios  a different decision would have
been made  the sdp is thus the probability of the four scenarios in which the same decision
would have been made  for this example  the sdp is 
                                                 
indicating a relatively robust decision 
choi et al         define the sdp formally as 
definition    same decision probability   let n be a bayesian network that is conditioned
on evidence e  where we are further given a hypothesis d  a threshold t   and a set of
unobserved variables h  suppose we are making a decision that is confirmed by the threshold
pr  d   e   t   the same decision probability in this scenario is
x
 pr  d   e  h   t  pr  h   e  
   
sdp  d  h  e  t    
h

where  pr  d   h  e   t   is an indicator function such that

  if pr  d   e  h   t
 pr  d   h  e   t    
  otherwise 
the sdp is notably hard to compute  choi et al         prove that computing the sdp
is in general pppp  complete   from previous work on the sdp  darwiche   choi       
choi et al          the two options for computing the sdp are
   the class pppp can be thought of as a counting variant of the nppp class  which contains the polynomial
time hierarchy ph and for which the map problem is complete  park   darwiche        

   

fialgorithms and applications for the same decision probability

d
 


pr  d 
   
   

d

s 

s 

s 

s 

figure    a bayesian network for intrusion detection  with its cpts given in table  
   an approximate algorithm developed by choi et al          this algorithm uses an
augmented variable elimination algorithm that produces a potentially weak bound
based on the one sided chebyshev inequality 
   a naive brute force method that enumerates over all possible instantiations 

   applying the same decision probability
we investigate the use of the sdp as a stopping criterion and a selection criterion  we
contrast the usage of the sdp with traditional methods discussed in section    and find
that using the sdp can provide more insight to a decision maker in some scenarios 
    sdp as a stopping criterion
by the definition of sdp  we can see that calculating a high sdp  in contrast to calculating
a low sdp  would indicate a higher degree of readiness to make a decision  as the chances
of the decision changing given further evidence gathering is lower  in this section we show
that computing the sdp can provide additional insight and thus can distinguish scenarios
that are otherwise indistinguishable based on standard stopping criteria 
the threshold based decision is a classical notion in decision making under uncertainty 
and it is commonly used as it requires no utilities to be elicited  examples of thresholdbased decisions are very prevalent in educational diagnosis  gertner  conati    vanlehn 
      conati  gertner    vanlehn        butz et al         xenos        arroyo   woolf 
      munie   shoham         intrusion detection  kruegel et al         modelo howard
et al          fault diagnosis  heckerman et al         lu   przytula         and medical
diagnosis  pauker   kassirer        kahn et al         van der gaag   coupe        
consider the sensor network in figure    which may correspond to an intrusion detection
application as discussed by kruegel et al          here  the hypothesis variable is d  
      with d     implying an intrusion  suppose we commit to a decision  and stop
performing observations  when our belief in the event d     surpasses some threshold t  
say t         there are four sensors in this model  s    s    s  and s    whose readings may
affect this decision 
consider the two following scenarios 
   s      and s      
   s      and s      
   

fichen  choi   darwiche

d s  pr  s    d 
   
    
  
    
  
    
    
 

d s  pr  s    d 
   
    
  
    
  
    
    
 

d s  pr  s    d 
   
    
    
  
  
    
 
    

d s  pr  s    d 
   
    
    
  
  
    
 
    

table    cpts for the network in figure    parameterization   
since pr  d       s       s                     and pr  d       s       s        
             it is clear that in both cases that the threshold has been crossed  we deem
that no further observations are necessary based on our beliefs surpassing our threshold 
hence  when using thresholds as a stopping criterion  as is commonly done  see kruegel
et al         lu   przytula        gao   koller         the two scenarios are identical in
that no more information is gathered and a decision is made 
from the viewpoint of sdp  however  these two scenarios are very different  in particular  the first scenario leads to an sdp of         this means that there is a        chance
that a different decision would be made if we were to further observe the two unobserved
sensors s  and s    the second scenario  however  leads to an sdp of       that is  we
would with certainty know that we would make the same decision if we were to also observe
the two unobserved sensors s  and s    no matter what the readings of s  and s  could be 
our beliefs in the event d     would always surpass our threshold       indeed  as we can
see in table    the sensors s  and s  are not as strong as sensors s  and s    and in this
example  they are not strong enough to reverse our decision 
this example provides a clear illustration of the utility of the sdp as a stopping criterion 
however  some may argue that it is clear that in the second case  we should stop gathering
information as pr  d       s       s              has a larger margin from the threshold
than pr  d       s       s                however  we show with the following example
that deciding to stop based solely on the margin is not robust  consider once again the
sensor network in figure   and the parameterizations of the sensor network shown in table  
and table    found in appendix c   which we respectively refer to as case   and case    
note that in this example  we use a threshold of t       
in both cases  when s      and s      are observed  pr  d       s       s        t  
in particular 
   case    pr  d       s       s               
   thus using the aforementioned margins of confidence stopping criterion used by gao and koller        
   note that the exact numbers of the cpts are not necessary to grasp these examples  cpts are
provided so that readers may reconstruct these networks 

   

fialgorithms and applications for the same decision probability

   case    pr  d       s       s               
by using the previously discussed margin stopping criterion  it would seem that in case
  we could stop information gathering  whereas for case   more information gathering is
necessary  however  we can compute the sdp for both cases for more insights on the
nature of robustness in these settings  for case    we find that the sdp is        whereas
for case    we find that the sdp is      even though in case   the margin is higher 
there is a greater chance that the decision would change given further information  this
demonstrates that we cannot use solely the margin to determine whether or not to stop
information gathering 
it is clear from these examples that sdp is a useful stopping criterion  first  the sdp
can pinpoint situations where further observations are unnecessary as they would never
reverse the decision under consideration  second  the sdp can also identify situations
where the decision to be made is not robust  and is likely to change upon making further
observations  in addition to these examples  in appendix a   we show how the sdp can be
a useful stopping criterion in the context of utility based decisions  e g  influence diagrams  
    sdp as a selection criterion
we now turn our attention to the use of sdp as a criterion for deciding which variables to
observe next  assuming that some stopping criterion indicates that further observations are
necessary  our proposal is based on using voi as the selection criterion  see equation    
while choosing the sdp as the reward function  we call this the sdp gain  and it is formally
defined as 
definition    given definition   of an sdp  the sdp gain of observing variables g out
of variables h is defined as the expected sdp of observing g  h subtracted by the sdp
over h 
g g    e g  h  e  t    sdp  d  h  e  t   
   
where the expected sdp is defined as 
e g  h  e  t    

x

sdp  d  h   g  ge  t  pr  g e 

   

g

and d is defined as the decision made given the current evidence 
note that if we observe some variables g  h such that the expected sdp is      that
indicates that after observing g and making a decision  the remaining variables h   g will
be rendered completely redundant  their observation will have no effect on the decision 
the goal of using the sdp gain as a selection criterion is to observe those variables which 
on average  will allow for the most stable decision given the collected observations 
we will next provide an example of using sdp as a selection criterion  contrasting it
with two other selection criteria  one based on reducing entropy of the hypothesis variable
d  and another based on maximizing the gap between the decision probability pr  d e  and
the given threshold t  krause   guestrin         while both criteria can be motivated as
reducing uncertainty  we show that both can indeed lead to less stable decisions than if the
sdp were to be used 
   

fichen  choi   darwiche

d

d
 


pr  d 
   
   
s 

s 

figure    a bayesian network with its cpts given in appendix c 

the example is given by the bayesian network in figure    where d is the hypothesis
variable and s   s  are sensors  a decision is triggered when pr  d       e        where
evidence e is over sensors s  and s    with no observations  empty evidence e   the sdp
is        suggesting that further observations may be needed  assuming a limited number
of observations  heckerman et al          and using a myopic approach of observing one
variable at a time  dittmer   jensen         we need now to select the next variable to
observe 
note that maximizing voi with negative entropy as the reward function amounts to
maximizing mutual information  as h d  x    h d   h d   x   cover   thomas       
krause   guestrin         the mutual information between variable d and sensor s  is
     whereas the mutual information between d and sensor s  is        hence  observing
s  will reduce the entropy of d the most  in terms of margin of confidence  another reward
function used by krause and guestrin         observing s  will on average lead to a    
margin between the states d     and d     whereas observing s  will only lead to a    
margin between the two states 
however  if we compute the corresponding sdp gains  g s    and g s     we find that
observing s  will  on average  lead to improving the decision stability the most  in particular  observing s  would give us an sdp of either   or       for an expected sdp
of        whereas observing s  would give us an sdp of either              or    for an
expected sdp of        therefore  g s           and g s            hence  observing s 
will on average allow us to make a decision that is less likely to change due to additional
information  beyond s    
some intuition to why this occurs is that although observing s  leads to greater information gain than observing s    it is superfluous information  note that pr  d       s       
        whereas pr  d       s             clearly  we can see that observing s  can lead
to a more skewed distribution with minimal conditional entropy  however  in the context
of threshold based decisions  we make a decision based solely on whether pr  d       e  is
above or below the threshold  meaning that we may not put as much emphasis on how much
below or above the threshold pr  d       e  is  in this case  although observing s  can on
average lead to a more extreme distribution  observing s    o leads to making an extremely
nonrobust decision  a decision that would change     of the time with observation of s    
observing s  before making a decision leads to a much more robust decision  this example
demonstrates the usefulness of sdp as a selection criterion for threshold based decisions 
as the sdp can be used to select observations that lead to more robust decisions 
   

fialgorithms and applications for the same decision probability

d
 


pr  d 
   
   

d

e 

h 

h 

h 

figure    a naive bayes network  cpts defined in appendix c  

   computing the same decision probability
computing the sdp involves computing an expectation over the hidden variables h  the
naive brute force algorithm would enumerate and check whether pr  d   h  e   t for all
instantiations h of h  we now present an algorithm that can save us the need to explore
every possible instantiation of h  to make the algorithm easier to understand  we will first
describe how to compute the sdp in a naive bayes network  this is no trivial problem 
we show in section   that computing the sdp in a naive bayes network is np hard  we
then generalize our algorithm to arbitrary networks 
    computing the sdp in naive bayes networks
we will find it more convenient to implement the test pr  d   h  e   t in the log odds
domain  where 
log o d   h  e    log

pr  d   h  e 
pr  d   h  e 

   

t
we then define the log odds threshold as    log  t
and  equivalently  test whether
log o d   h  e    
in a naive bayes network with d as the class variable  h and e as the leaf variables 
and q  h  the posterior log odds after observing a partial instantiation q    h            hj  
can be written as 

log o d   q  e    log o d   e   

j
x

w hi

   

i  

where whi is the weight of evidence hi and defined as 
whi   log

pr  hi   d  e 
pr  hi   d  e 

    

the weight of evidence whi is then the contribution of evidence hi to the quantity
log o d   q  e   chan   darwiche         note that all weights can be computed in time
and space linear in  h  using a floating point representation   table   depicts the weights
of evidence for the network in figure   
   additionally  note that for equation     since in naive bayes networks hi is d separated from e given
d  the term e can be dropped from the equation  we leave the term in because for general networks  hi
may not be d separated from e 

   

fichen  choi   darwiche

i
 
 
 

w hi
   
    
    

w hi
     
     
     

table    weights of evidence for the attributes in figure   
h 
   
h 
   

h 
     

h 
    
    

h 
    
   

   

h 
    
    

    

    

h 
    
    

    

figure    the search tree for the network of figure    a solid line indicates   and a dashed
line indicates   the quantity log o d   q  e  is displayed next to each node q in
the tree  nodes with log o d   q  e        are shown in bold 

one can then compute the sdp by enumerating the instantiations of variables h and
then using equation   to test whether log o d   h  e     figure   depicts a search tree
for the naive bayes network in figure    which can be used for this purpose  the leaves of
this tree correspond to instantiations h of variables h  more generally  every node in the
tree corresponds to an instantiation q  where q  h 
a brute force computation of the sdp would then entail 
   initializing the total sdp to   
   visiting every leaf node h in the search tree 
   checking whether log o d   h  e    and if so  adding pr  h   e  to the total sdp 
figure   depicts the quantity log o d   q  e  for each node q in the tree  indicating that five
leaf nodes  i e   five instantiations of variables h  will indeed contribute to the sdp 
we now state the key observation underlying our proposed algorithm  consider the node
corresponding to instantiation h      in the search tree  with log o d   h       e        
all four completions h of this instantiation  i e   the four leaf nodes below it  are such that
log o d   h  e         hence  we really do not need to visit all such leaves and add their
contributions pr  h e  individually to the sdp  instead  we can simply add pr  h      e 
to the sdp  which equals the sum of pr  h e  for these leaves  more importantly  we can
detect that all such leaves will contribute to the sdp by computing a lower bound using the
weights depicted in table    that is  there are two weights for variable h    the minimum
of which is       moreover  there are two weights for variable h    the minimum of which
      hence  the lowest contribution to the log odds made by any leaf below node h     
   

fialgorithms and applications for the same decision probability

h 
   
   

h 
     
h 
    
    

    

    

figure    the reduced search tree for the network of figure   
will be                    adding this contribution to the current log odds of     will
lead to a log odds of      which still passes the given threshold 
a similar technique can be used to compute upper bounds  allowing us to detect nodes
in the search tree where no leaf below them will contribute to the sdp  consider for example
the node corresponding to instantiation h      h      with log o d   h      h   
  e          neither of the leaves below this node will contribute to the sdp as their
log odds do not pass the threshold  this can be detected by considering the weights of
evidence for variable h  and computing the maximum of these weights         adding this
to the current log odds of      gives       which is still below the threshold  hence  no
leaf node below h      h     will contribute to the sdp and this part of the search tree
can also be pruned 
if we apply this pruning technique based on lower and upper bounds  we will actually
end up exploring only the portion of the tree shown in figure    the pseudocode of our
final algorithm is shown in algorithm    note that it takes linear time to compute the
upper and lower bounds  additionally  note that the specific ordering of h in which the
search tree is constructed is directly linked to the amount of pruning  we use an ordering
heuristic that ranks each query variable hi by the difference of its corresponding upper and
lower bound  h is then ordered from greatest difference to lowest difference as to allow
for earlier pruning 
    computing the sdp in arbitrary networks
we will generalize our algorithm to arbitrary networks by viewing such networks as naive
bayes networks but with aggregate attributes  for this  we first need the following notion 
definition    a partition of h given d and e is a set s            sk such that  si  h 
si  sj     s          sk   h  and si is independent  d separated  from sj   i    j  given
d and e 
figure   depicts an example partition 
the intuition behind a partition is that it allows us to view an arbitrary network as a
naive bayes network  with class variable d and aggregate attributes s            sk   that is 
each aggregate attribute si is viewed as a variable with states si   allowing us to view each
instantiation h as a set of values s            sk   we now have 

   

fichen  choi   darwiche

algorithm   computing the sdp in a naive bayes network  note  for q    h            hj   
p
wq is defined as ji   whi  

input 
n   naive bayes network with class variable d
h  attributes  h            hk  
  log odds threshold
e  evidence
output  same decision probability p

main 
global p       initial probability 
q      initial instantiation is empty set 
depth     initial depth of search tree 
dfs sdp q  h  depth 
return p
   procedure dfs sdp q  h  depth 
p
  
u pperbound  log o d   e    wq   ki depth   maxhi whi
p
  
lowerbound  log o d   e    wq   ki depth   minhi whi
  
if  u pperbound     then return
  
else if  lowerbound    then
  
add pr  q   e  to p  return
  
else
  
if depth   k then
  
for each value hdepth   of attribute hdepth   do
   
dfs sdp qhdepth     h   hdepth     depth     
proposition    for a partial instantiation q    s            sj   
log o d   q  e    log o d   e   

j
x

w si  

    

i  

where
wsi   log

pr  si     d  e 
pr  si   d  e 

proof 
pr  d   q  e 
pr  d   q  e 
pr  d   e pr  s    d  e        pr  sj   d  e 
  log
pr  d   e pr  s    d  e        pr  sj   d  e 

log o d   q  e    log

  log o d   e   

j
x
i  

   

w si

    

fialgorithms and applications for the same decision probability

e 

x 

h 

h 

d

x 

h 

h 

e 

x 

h 

h 

figure    the partition of h given d and e is  s     h    h    h    s     h     s   
 h    h    

since equations    and    are analogous to equations   and     we can now use algorithm   on an arbitrary network  this usage  however  requires some auxiliary computations
that were not needed or were readily available for naive bayes networks  we discuss these
computations next 
      finding a partition
we first need to compute a partition s            sk   which is done by pruning the network
structure as follows  we delete edges outgoing from nodes in evidence e and hypothesis d 
and delete  successively  all leaf nodes that are neither in h  e or d  we then identify the
components x            xk of the resulting network and define each non empty si   h  xi
as an element of the partition  this guarantees that in the original network structure  si
is d separated from sj by d and e for i    j  see  darwiche          in figure    network
pruning leads to the components x     x    x    e    h    h    h     x     d  e    h    and
x     x    h    h    
      computing posterior log odds  probability and weights of evidence
the quantities o d   e   pr  q   e  and wsi   which are referenced on lines       and   of
the algorithm  have simple closed forms in naive bayes networks  for arbitrary networks 
however  computing these quantities requires inference which we do using the algorithm
of variable elimination as described by darwiche         note that the network pruning
of deleting edges and removing the leaf nodes  as discussed above  guarantees that each
factor used by variable elimination will have all its variables in some component xi   hence 
variable elimination can be applied to each component xi in isolation  which is sufficient
to obtain all needed quantities 
   

fichen  choi   darwiche

      computing the min and max of evidence weights
we finally show how to compute the upper and lower bounds  maxsi wsi and minsi wsi  
which are referenced on lines   and   of the algorithm  these quantities can also be
computed using variable elimination  applied to each component xi in isolation  in this
case  however  we must eliminate variables xi   si first and then variables si   moreover 
the first set of variables is summed out  while the second set of variables is maxd out or
mind out  depending on whether we need maxsi wsi or minsi wsi   finally  this elimination
process is applied twice  once with evidence d  e and a second time with evidence d  e 
more precisely  for every component xi we have a set of factors for the case where d   d
and where d   d  using the same variable ordering  we perform variable elimination on both
sets of factors to eliminate
so that
are left with a
q iany nonquery  intermediary  variables
q we
i
i
i
set of factors d where d   pr  si   d  e   and a set of factors d where d   pr  si   d  e  
since the elimination order was the same  there is thus a one to one matching between
i
pr i  ei  s  
factors from both sets  and we can define a new set of factors i   id   pr id  ei  si     we
d

d

i

can then calculate wsi and wsi by respectively maximizing and minimizing out variables 
note that summing out variables and then maximizing variables is the variable elimination
algorithm used by dechter        in order to solve map  our algorithm here differs as we
perform both maximization and minimization  to both calculate wsi and wsi    and do so on
the set of factors i instead of on the factors  di or di   that result from simply summing
out the intermediary variables 
note that similarly to dechter         as we are first summing out variables and then
performing some maximization  and minimization in our case   the elimination order in
this case is constrained  meaning that we may be forced to use a poor ordering for variable
elimination that results in a high treewidth 
    complexity analysis
let n be the number of variables in the network  h    h   and w   maxi wi   where
wi is the width of constrained elimination order used
on component xi   the best case

time complexityof our algorithm is then o n exp w and the worst case time complexity is
o n exp  w   h    the intuition behind these bounds is that computing
 the maximum and
minimum weights for each aggregate attribute takes time o n exp w   this also bounds
the complexity of computing o d e   pr  q e  and corresponding weights wsi   moreover 
depending on the weights and the
 threshold t   traversing the search tree can take anywhere
from constant time to o exp h   since depth first
search can be implemented with linear

space  the space complexity is o n exp w  

   experimental results
we performed several experiments on both real and synthetic networks to test the performance of our algorithm across a wide variety of network structures  ranging from simple
naive bayes networks to highly connected networks  real networks were either learned from
datasets provided by the uci machine learning repository  bache   lichman        or
   

fialgorithms and applications for the same decision probability

network
car
emdec g
tcc e
ttt
caa
voting
nav
fire
chess

source
uci
hrl
hrl
uci
cresst
uci
cresst
cresst
uci

 h 
 h 
 
   
 
   
 
   
 
     
  
     
  
     
          
           
             

naive
     
     
     
     
     
     
      



approx
     
     
     
     
     
     
     
     
 

new
     
     
     
     
     
     
     
     
     

table    algorithm comparison on real networks  we show the time  in seconds  it takes
each algorithm  naive  approx  and new to compute the sdp in different networks 
note that  indicates that the computation did not complete in the    minute
time limit that we constrained  moreover    indicates that there was not sufficient
memory to complete the computation 

provided by hrl laboratories and cresst   the majority of the real networks used were
diagnostic networks  which made it clear which variable should be selected as the decision
variable as it would either be the knowledge or fault variable  for the unclear cases  the
decision variable was picked at random  both query and evidence variables were selected
at random for all real networks 
besides this algorithm  there are two other options available to compute the sdp     the
naive method to brute force the computation by enumerating over all possible instantiations
or    the approximate algorithm developed by choi et al          to compare our algorithm
with these two other approaches  we compute the sdp over the real networks  for each
network we selected at least     of the total network variables to be query variables so
that we could emphasize how the size of the query set greatly influences the computation
time  each computation was given    minutes to complete  as we believe that the value of
the threshold can greatly affect running time  we computed the sdp with thresholds t  
                                         and took the worst case time  the results of our experiments
with the three algorithms are shown in table    note that  h  is the number of query
variables and  h  is the number of instantiations the naive algorithm must enumerate over 
moreover   indicates that the computation did not complete in the    minute time limit and
  indicates that there was not sufficient memory to complete the computation  the networks
 car ttt voting nav chess  are naive bayes networks whereas the networks  caa fire  are
polytree networks and the others are more general networks 
given the real networks that we tested our algorithm on  it is clear that the algorithm
outperforms both the naive implementation and the approximate algorithm for both naive
bayes networks and polytree networks  note that the approximation algorithm is based
on variable elimination but can only use certain constrained orders  for a naive bayes
   http   www cse ucla edu 

   

fichen  choi   darwiche

    
    

average explored instantiations and running time
number of instantiations  x   e  

    
    
    
    
    
   
  

time  s 
 

 

 
 
number of subnetworks

 

 

 

figure    synthetic network average running time and average number of instantiations
explored by number of connected components 

network with hypothesis d being the root  the approximation algorithm will be forced to
use a particularly poor ordering  which explains its failure on the chess network 
to analyze how a more general network structure and the selected threshold affects
the performance of our algorithm  we generated synthetic networks with     variables and
varying treewidth using bngenerator  ide  cozman    ramos         for each network 
we randomly selected the decision variable     query variables  and evidence variables    we
then generated a partition for each network and grouped the networks by the size of obtained
partition  k   our goal was to test how our algorithms running time and ability to prune
the search space depends on k  the average time and average number of instantiations
explored are shown in figure   
in general  we can see that as k increases  the number of instantiations explored by
the algorithm decreases and its runtime improves  the network becomes more similar to a
naive bayes structure with increasing k  moreover  the larger k is  the more levels there are
in the search tree  which means that our algorithm will have more opportunities to prune 
in the worst case  a network may be unable to be disconnected at all  k       however  even
in this case our algorithm is still  on average  more efficient compared to the brute force
implementation  for some cases  after computing the maximum and minimum weight of
observing h  it will find that there does not exist any h that will change the decision  we
found that  given a time limit of   hours  the brute force algorithm could not solve any
synthetic networks  whereas our approach solved more than     of such networks 
we also test how the threshold affects computation time  here  we calculate the posterior
probability of the decision variable and then run repeatedly our algorithm with thresholds
that are varying increments away  the average running time for all increments can be seen
in figure    it is evident that when the threshold is set to be further away from the initial
    as the synthetic networks are binary  a brute force approach would need to explore     instantiations 

   

fialgorithms and applications for the same decision probability

    
    

average explored instantiations and running time
number of instantiations  x   e  

    
    
    
   
   
   
   
    

time  s 
   

   
   
   
   
threshold distance from initial posterior

   

figure    synthetic network average running time and average number of instantiations
explored by threshold distance from the initial posterior probability 

posterior probability  the algorithm finishes much faster  which is perhaps expected since
the usage of more extreme thresholds would allow for more search space pruning 
overall  our experimental results show that our algorithm is able to solve many sdp
problems that are out of reach of existing methods  we also confirm that our algorithm
completes much faster when the network can be disconnected or when the threshold is far
away from the initial posterior probability of the decision variable 

   the complexity of computing the same decision probability
we present here new complexity results for the sdp  we first prove that the complexity of
computing the sdp in naive bayes structures is np hard  we then show that the general
complexity of computing the sdp lies in the same complexity class as a general expectation
computation problem that is applicable to a wide variety of queries in graphical models 
such as the computation of non myopic value of information 
    computing the sdp in naive bayes
sdp is known to be pppp  complete  choi et al          we now show that sdp remains
hard for naive bayes networks 
theorem    computing the same decision probability in a naive bayes network is nphard 
proof  we reduce the number partition problem defined by karp        to computing the
sdp in a naive bayes model  suppose we are given a set of positive p
integers c p
          cn   and
we wish to determine whether there exists i              n  such that ji ci   j i cj   we
can solve this by considering a naive bayes network with a binary class variable d having
uniform probability  and binary attributes h            hn having cpts leading to weights of
   

fichen  choi   darwiche

evidence whi  t   ci and whi  f   ci   the construction of these cpts can be done by
solving the following system of equations 
pr  hi   t   d   t  
pr  hi   t   d   f  
pr  hi   f   d   t  
ci   log
pr  hi   f   d   f  
    pr  hi   t   d   t     pr  hi   f   d   t  
ci   log

    pr  hi   t   d   f     pr  hi   f   d   f  

we leave the exact derivations out  see exercise      in darwiche         we get the
result that 
pr  hi   t   d   f     pr  hi   f   d   t    

 ci

 
  

pr  hi   t   d   t     pr  hi   f   d   f       

 ci

 
  

note that given that these cpts have been defined such that whi  t   ci and whi  f  
ci   the set of integers can be partitioned if there is an instantiation h    h            hn   with
p
n
i   whi     since i would then include all indices i with hi   t in this case 
first 
pnthe naive bayes network satisfies a number of properties that we shall use
pnext 
n
whi is either        or    since all weights whi are integers  next  if i   whi   c 
i  p
then ni   whi   c where hi    hi   finally  pr  h            hn     pr  h            hn   when hi    hi  
as d has a uniform probability distribution and each leaf hi has been defined with a
symmetric cpt 
consider now the following sdp  the last step below is based on the above properties  
sdp  d   t   h            hn            
x
 pr  d   t   h            hn        pr  h            hn  
 
h       hn

 

x

 log o d   t   h            hn      pr  h            hn  

h       hn

 

x

h       hn

 

  x
 
 

n
x

h       hn

we then have

pn

i   whi

 

whi    pr  h            hn  

i  

 

n
x

 

whi      pr  h            hn  

i  

    for some instantiation h            hn iff
  n
 
x x
whi      pr  h            hn      
h       hn

i  

   

fialgorithms and applications for the same decision probability

hence  the partitioning problem can be solved iff
sdp  d   t   h            hn                  

    the complexity of computing the non myopic voi
the sdp was shown to be a pppp  complete problem by choi et al          the class pppp is
essentially the counting variant of the nppp class  which contains the polynomial hierarchy
ph and for which the map problem is complete  park   darwiche         we show in this
section that a general problem of computing expectations is also pppp  complete  with the
non myopic voi and sdp being an instance of such an expectation  thus  the development
of algorithms to compute the sdp will be beneficial to problems in the pppp class  which
in turn benefits computing an assortment of expectations  including non myopic voi 
the proposed expectation computation is based on using a reward function r with
some properties that we review next  in particular  the function r is assumed to map a
probability distribution pr  d   e  to a numeric value  we also assume that the minimum
l and maximum u of this range are polytime computable  these assumptions are not too
limitingfor example  both entropy and utility can be expressed using reward functions
that fall in this category  krause   guestrin        
we now consider the following computation of expectations 
d ept  given a polynomial time computable reward function r  hypothesis variable
d  unobserved variables h  evidence e  a real number n   and a distribution pr induced
by a bayesian network over variables x    the expectation decision problem asks  is
e 

x

r pr  d   h  e  pr  h   e 

h

greater than n  
note that the sdp falls as a special case when the reward function r is the sdp indicator
function  see definition     for example  in the definition used by choi et al          the
decision function outputs one of two decisions depending on whether pr  d e    t for some
value d of d and some threshold t  
we now have the following theorems  with proofs in appendix b 
theorem    d ept is pppp  hard 
theorem    d ept is in pppp  
this shows that d ept is pppp  complete and implies that computational problems
such as computing the non myopic voi using a variety of reward functions is also pppp complete 
    this proof also holds for influence diagrams constrained to have only one decision node 

   

fichen  choi   darwiche

   conclusion
in this paper  we have discussed some commonly used information gathering criteria for
graphical models such as value of information and have reviewed the recently introduced
notion of the same decision probability  sdp   in this paper  we have proposed the usage
of the sdp as a decision making tool by showing concrete examples of its usefulness as both
a stopping criterion and a selection criterion  as a stopping criterion  the sdp can allow
us to determine when no further observations are necessary  as a selection criterion  usage
of the sdp can allow us to select observations that allow us to increase decision robustness 
as we have justified the usage of the sdp  we have proposed an exact algorithm for its
computation  experimental results show that this algorithm has comparable running time
to the previous approximate algorithm and is also much faster than the naive brute force
algorithm  finally  we have presented several new complexity results 

acknowledgements
this paper combines and extends the work presented by chen  choi  and darwiche      b 
       this work has been partially supported by onr grant  n                 nsf
grant  iis          and nsf grant  iis          we would also like to thank the national
center for research on evaluation  standards    student testing and hughes research lab
for contributing sample diagnostic networks 

appendix a  miscellaneous topics
in this section we go into more details about notions that were mentioned earlier in the
paper  in particular  we continue our discussion from section     and go over the notion of
non myopic value of information  additionally  we also continue from where we left off in
section     and expand upon the notion of sdp as a stopping criterion in the context of
utility based decisions 
appendix a   non myopic value of information
myopic value of information is often used in many applications as it is easy to compute
 dittmer   jensen        vomlel        gao   koller         however  the problem with
myopic selection is that it is not optimal  as at times the whole is greater than the sum of
its parts  as each individual observation in a set h seemingly may not provide significant
value  but the voi of observing h can be very high  for instance  take the function
d   x   x    where alone neither x  nor x  is useful  but together they are determinative
of d  bilgic   getoor         only by computing the non myopic voi can the the optimal
voi be obtained 
due to the aforementioned problems with using myopic voi  more recently  researchers
have recently suggested using the non myopic voi instead of myopic voi and have proposed various methods to compute the non myopic voi  heckerman  horvitz    middleton 
      liao   ji        krause   guestrin        zhang   ji        bilgic   getoor        
computing the non myopic voi of some hidden variables h is difficult as it involves com   

fialgorithms and applications for the same decision probability

puting an expectation over the possible values of h  which quickly becomes intractable as
h becomes larger 
existing algorithms for computing the non myopic voi are approximate algorithms
 heckerman et al         liao   ji        or relatively limited algorithms that are restricted
to tree networks with few leaf variables  krause   guestrin         bilgic and getoor
       have developed the value of information lattice  voila   a framework in which
all subsets of hidden variables h are examined  and the optimal subset of features can be
found to increase classification accuracy while meeting some budget constraint 
appendix a   sdp as a stopping criterion for utility based decisions
in some cases the expected utility of different decisions  as well as the cost of reducing
uncertainty  making observations   is quantified  this is common in the decision theoretic
setting  howard        howard   matheson         where influence diagrams are commonly
used  influence diagrams can be seen as bayesian networks that incorporate decision and
utility nodes  howard   matheson        zhang        kjrulff   madsen         the
selection criterion for the decision theoretic setting is clear  the observations that lead to
the greatest increase of expected utility are selected  the usage of utilities and observation
costs is now prevalent  however  numerous researchers have noted the difficulty of coming
up with the actual numerical quantities  glasziou   hilden        lu   przytula       
bilgic   getoor        
to show how the sdp can be used as a stopping criterion in the decision theoretic context of expected utility decisions and influence diagrams  howard   matheson         we
extend the definition of the sdp to a more general setting to allow for more applications 
in particular  we assume that f is a polytime computable decision function that outputs
a decision d based on the distribution pr  d   e   for instance  the decision function most
commonly used in classification is to select the class with the highest posterior probability arg maxd pr  d   e   friedman et al          whereas for threshold based decisions  the
decision function would simply be to select a decision d if pr  d   d   e   t  
sdp is thus defined as the probability that the same decision would be made if the
hidden states of variables h were known  chen et al       b  
definition    same decision probability  generalized    given a decision function f 
hypothesis variable d  unobserved variables h  and evidence e  the same decision probability  sdp  is defined as
x
 f pr  d   h  e   h pr  h   e 
    
sdp  f  d  h  e   
h

where  f pr  d   h  e   h is an indicator function that

  if f pr  d   h  e     f pr  d   e  
 
  otherwise 
the original sdp definition  however  assumed that d is a binary variable  where
f pr  d   e     d when pr  d   e   t for some threshold t  darwiche   choi        
we now consider the use of sdp as a stopping criterion in the context of expectedutility decisions and influence diagrams  howard   matheson         in particular  we
   

fichen  choi   darwiche

q

c

s
i

p

figure     an influence diagram for an investment problem 
show that by using the sdp  we can distinguish high risk  high reward scenarios from lowrisk  low reward scenarios that are otherwise indistinguishable when we consider the usage
of voi utilities alone 
consider the influence diagram in figure     which consists of a bayesian network with
three variables  c  q and s   a decision node i  and a utility node p that is a direct
function of the utility function u  this influence diagram models an investment problem
in which a venture capital firm is deciding whether to invest an amount of    million in a
tech startup  i   t   or allowing the money to collect interest in the bank  i   f    in this
example  the profit of the investment  p   depends on the decision  i  and the success of the
company  s   which in turn depends on two factors      whether the existing competitor
companies are successful  c  and     whether the the co founders of the startup have a high
quality  original idea  q   both c and q are unobserved initially and independent of each
other  variable s is the latent hypothesis variable in this case and thus cannot be observed 
variables c and q  however  can be observed for a price 
the goal here is to choose the decision i   i with the maximum expected utility 
x
eu  i   e   
pr  s   e u i  s  
s

where u i  s  is the utility of decision i   i given evidence e on variables c and q 
figures    and    contain two different parameterizations of the influence diagram in
figure     we will refer to these as different scenarios of the investment problem 
in both scenarios  given no evidence on variables c and q  the best decision is i   f  
with an expected utility of     k  a decision maker may commit to this decision or decide
to observe variables c and q  with the hope of finding a better decision in light of the
additional information  the classical stopping criterion here is to compute the maximum
expected utility given that we observe variables c and q  heckerman et al         dittmer
  jensen        
x
max
eu  i   c  q pr  c  q  
i

c q

in both scenarios  the maximum expected utility comes out to        k  showing that
further observations may lead to a better decision   
    according to the formulation of krause and guestrin         we have computed the voi for variables
c and q using the reward function 

   

fialgorithms and applications for the same decision probability

q
t
f

pr  q 
   
   

c
t
f

pr  c 
   
   

q
t
t
f
f

pr  s   t     
    
    
    
    

c
t
f
t
f
i
t
t
f
f

s
t
f
t
f

u i  s 
       
       
       
       

figure     a parameterization of the influence diagram in figure    

q
t
f

pr  q 
   
   

c
t
f

pr  c 
   
   

q
t
t
f
f

pr  s   t     
    
    
    
    

c
t
f
t
f
i
t
t
f
f

s
t
f
t
f

u i  s 
       
       
       
       

figure     a parameterization of the influence diagram in figure    
up to this point  the above two scenarios are indistinguishable from the viewpoint of
classical decision making tools  remember that krause and guestrin        and bilgic and
getoor        remark that the budget for observations should be expended so long as the
value of information of the observation is greater than the cost of observation  according
to those selection criteria  both of the variables should thus be observed  as the expected
financial gain could very well increase 
the sdp  however  finds that these two scenarios are very different  in particular  with
respect to variables c and q  the sdp is     in the first scenario and is     in the second
scenario  that is  even though we stand to make a better decision in both scenarios upon
observing variables c and q  at least with respect to financial gain   and even though the
expected benefit from such observations is the same in both scenarios  it is very unlikely that
we would change the current decision of i   f in the second scenario in comparison to the
first  hence  given the additional information provided by the sdp  a decision maker may
act quite differently in these two scenarios  indeed  when we take a closer look at the second
scenario  there is a state of the world  when s   t   where deciding to invest would yield a
very large financial gain  however  the chance of this state manifesting itself is extremely
   

fichen  choi   darwiche

small  analogous to a lottery   meaning that a risk conscious decision maker may be more
averse to gamble in the second scenario and even waste resources to observe the variables
c and d  note that for this example we have assumed that the utility does not incorporate
any risk factor  as if it did a rational decision maker would then always choose to gather
more information despite a low probability of changing the current decision 
this illustrates the usefulness of sdp as a stopping criterion in the context of expectedutility decisions and influence diagrams  namely  using sdp  we can distinguish between
two very different scenarios  that are otherwise indistinguishable when we consider utilities
alone 

appendix b  proofs
in this section we provide proofs for theorems   and   
proof of theorem    we show d ept is pppp  hard by reduction from the following decision problem d sdp  which corresponds to the originally proposed notion of same decision
probability for threshold based decisions  darwiche   choi        
d sdp  given a decision based on probability pr  d   e  surpassing a threshold t   a set
of unobserved variables h  and a probability p  is the same decision probability 
x
 pr  d   h  e   t  pr  h   e 
    
h

greater than p 
here      denotes an indicator function which evaluates to   if the enclosed expression is
satisfied  and   otherwise  d sdp was shown to be pppp  complete by choi et al         
this same decision probability corresponds to an expectation with respect to the distribution pr  h   e   using the reward function 

  if pr  d   h  e   t
r pr  d   h  e    
  otherwise 
thus the same decision probability is  t iff this expectation is  t  
proof of theorem    to show that d ept is in pppp   we provide a probabilistic polynomialtime algorithm  with access to a pp oracle  that answers the decision problem d ept
correctly with probability greater than      this proof generalizes and simplifies the proof
given by choi et al         for d sdp 
consider the following probabilistic algorithm that determines if e   n  
   sample a complete instantiation x from the bayesian network  with probability pr  x  
we can do this in linear time  using forward sampling  henrion        
   if x is compatible with e  we can use a pp oracle to compute t   r pr  d   h  e   
first  the reward function r can be computed in polynomial time  by definition 
second  pr  d   h  e  can be computed using a pp oracle  since the inference is  pcomplete  roth         and since ppp   p p  
   

fialgorithms and applications for the same decision probability

   define a function a t            tn
ul   which defines a probability used by our probabilistic
algorithm to guess whether e   n  see lemma    
   declare that e   n with probability 
 a t  if x is compatible with e 


 
 

if x is not compatible with e 

the probability of declaring e   n is 
r 

x
h

which is greater than

 
 

 
a t pr  h  e        pr  e  
 

    

iff the following set of equivalent statements hold 
x

a t pr  h  e   

h

x

a t pr  h   e   

h

 
 


 
 tn
pr  h   e   
 
    ul
 


x  tn
pr  h   e     
  ul
h
x
 t  n  pr  h   e     

x  
h

pr  e 
 

h

x

r pr  d   h  e  pr  h   e    n 

h

thus r  

 
 

iff e   n  

lemma    the function a t   

 
 

 

  tn
  ul

maps a reward t to a probability in        

proof  values u and l are given  and denote upper and lower bounds on the reward t  but
also the threshold n   thus tn
ul is in        
note that a t  denotes a probability used by our algorithm to declare whether e   n  
which is higher or lower depending on the value of the reward t   r pr  d   h  e   

appendix c  conditional probability tables
in this section we provide conditional probability tables for the networks in figures         
and   

   

fichen  choi   darwiche

d
 


pr  d 
   
   

hi
t
t
p
p
n
n
l
l

d
 
 



xi
 

 

 

 


x 
 

 


ei
 
 
 
 
 
 
 
 

pr  x    d 
   
   
   
   

x 
 
 



pr  ei   hi   xi  
   
   
   
   
   
   
   
   

hi
t
p
n
l

x 
 

 


pr  x    x   
   
   
   
   

pr  hi  
    
    
    
    

figure     the cpts for the bayesian network given in figure    note that for the
cpts of variables ei   only the lines for the case ei     are given  since
pr  ei    hi   xi        pr  ei     hi   xi   

d s  pr  s    d 
   
    
  
    
    
  
 
    

d s  pr  s    d 
   
    
  
    
    
  
 
    

d s  pr  s    d 
   
    
  
    
  
    
 
    

d s  pr  s    d 
   
    
  
    
  
    
 
    

table    cpts for the network in figure    parameterization   

   

fialgorithms and applications for the same decision probability

d s  pr  s    d 
   
    
    
  
  
    
 
    

d s  pr  s    d 
   
    
    
  
  
    
 
    

d s  pr  s    d 
   
    
  
    
  
    
 
    

d s  pr  s    d 
   
    
  
    
  
    
 
    

table    cpts for the network in figure    parameterization   

d s  pr  s    d 
   
    
  o
   
    
  
  
    
 o
   
 
    

d s  pr  s    d 
   
   
   
  
  
   
 
   

table    cpts for the bayesian network in figure   

d h  pr  h    d 
   
    
  
    
  
    
 
    

d h  pr  h    d 
   
    
  
    
  
    
 
    

table    cpts for the network in figure    pr  h    d   pr  e    d  and pr  h   d  are
equal 

   

fichen  choi   darwiche

references
arroyo  i     woolf  b          inferring learning and attitudes from a bayesian network
of log file data  in proceedings of the   th international conference on artificial
intelligence in education  pp       
bache  k     lichman  m          uci machine learning repository  
bilgic  m     getoor  l          value of information lattice  exploiting probabilistic independence for effective feature subset acquisition  journal of artificial intelligence
research  jair            
butz  c  j   hua  s     maguire  r  b          a web based intelligent tutoring system for
computer programming  in web intelligence  pp          ieee computer society 
chan  h     darwiche  a          reasoning about bayesian network classifiers  in proceedings of the   th conference in uncertainty in artificial intelligence  pp         
chen  j   low  k  h   tan  c  k  y   oran  a   jaillet  p   dolan  j     sukhatme  g 
     a   decentralized data fusion and active sensing with mobile sensors for modeling
and predicting spatiotemporal traffic phenomena  in proceedings of the twenty eighth
conference annual conference on uncertainty in artificial intelligence  uai      pp 
        corvallis  oregon  auai press 
chen  s   choi  a     darwiche  a       b   the same decision probability  a new tool
for decision making  in proceedings of the sixth european workshop on probabilistic
graphical models  pp       
chen  s   choi  a     darwiche  a          an exact algorithm for computing the samedecision probability  in proceedings of the   rd international joint conference on
artificial intelligence  pp           
choi  a   xue  y     darwiche  a          same decision probability  a confidence measure for threshold based decisions  international journal of approximate reasoning
 ijar               
conati  c   gertner  a     vanlehn  k          using bayesian networks to manage uncertainty in student modeling  user modeling and user adapted interaction         
       
cover  t  m     thomas  j  a          elements of information theory  wiley interscience 
darwiche  a          modeling and reasoning with bayesian networks   st edition   cambridge university press 
darwiche  a     choi  a          same decision probability  a confidence measure for
threshold based decisions under noisy sensors  in proceedings of the fifth european
workshop on probabilistic graphical models  pp         
dechter  r          bucket elimination  a unifying framework for reasoning  artificial
intelligence                
dittmer  s     jensen  f          myopic value of information in influence diagrams  in proceedings of the thirteenth conference annual conference on uncertainty in artificial
intelligence  uai      pp         
   

fialgorithms and applications for the same decision probability

friedman  n   geiger  d     goldszmidt  m          bayesian network classifiers  machine
learning                   
gao  t     koller  d          active classification based on value of classifier  in advances
in neural information processing systems  nips       
gertner  a  s   conati  c     vanlehn  k          procedural help in andes  generating hints using a bayesian network student model  in proceedings of the national
conference on artificial intelligence  pp         
glasziou  p     hilden  j          test selection measures  medical decision making        
       
greiner  r   grove  a  j     roth  d          learning cost sensitive active classifiers 
artificial intelligence                  
hamscher  w   console  l     de kleer  j   eds            readings in model based diagnosis  morgan kaufmann publishers inc 
heckerman  d   breese  j  s     rommelse  k          decision theoretic troubleshooting 
communications of the acm               
heckerman  d   horvitz  e     middleton  b          an approximate nonmyopic computation for value of information  ieee transactions on pattern analysis and machine
intelligence                 
henrion  m          propagating uncertainty in bayesian networks by probabilistic logic
sampling  in proceedings of the second annual conference on uncertainty in artificial
intelligence  uai      pp         
howard  r  a          information value theory  ieee transactions on systems science
and cybernetics              
howard  r  a     matheson  j  e   eds            readings on the principles and applications of decision analysis  strategic decision group 
ide  j  s   cozman  f  g     ramos  f  t          generating random bayesian networks
with constraints on induced width  in proceedings of the   th european conference
on artificial intelligence  pp         
jordan  a          on discriminative vs  generative classifiers  a comparison of logistic
regression and naive bayes  advances in neural information processing systems     
    
kahn  c  e   roberts  l  m   shaffer  k  a     haddawy  p          construction of a
bayesian network for mammographic diagnosis of breast cancer  computers in biology
and medicine               
karp  r  m          reducibility among combinatorial problems  in complexity of computer computations  springer 
kjrulff  u  b     madsen  a  l          bayesian networks and influence diagrams  a
guide to construction and analysis  springer 
krause  a     guestrin  c          near optimal nonmyopic value of information in graphical models  in   st conference on uncertainty in artificial intelligence  pp         
   

fichen  choi   darwiche

krause  a     guestrin  c          optimal value of information in graphical models 
journal of artificial intelligence research  jair              
kruegel  c   mutz  d   robertson  w     valeur  f          bayesian event classification
for intrusion detection  in proceedings of the annual computer security applications
conference  acsac  
liao  w     ji  q          efficient non myopic value of information computation for influence diagrams  international journal of approximate reasoning                 
lindley  d  v          on a measure of the information provided by an experiment  annals
of mathematical statistics                  
lu  t  c     przytula  k  w          focusing strategies for multiple fault diagnosis  in
proceedings of the   th international flairs conference  pp         
millan  e   descalco  l   castillo  g   oliveira  p     diogo  s          using bayesian
networks to improve knowledge assessment  computers   education                 
modelo howard  g   bagchi  s     lebanon  g          determining placement of intrusion detectors for a distributed application through bayesian network modeling  in
proceedings of the   th international symposium on recent advances in intrusion
detection  pp         
munie  m     shoham  y          optimal testing of structured knowledge  in aaai   
proceedings of the   rd national conference on artificial intelligence  pp           
ognibene  d     demiris  y          towards active event recognition  in proceedings of
the   rd international joint conference on artificial intelligence  pp           
park  j  d     darwiche  a          complexity results and approximation strategies for
map explanations  journal of artificial intelligence research  jair              
pauker  s  g     kassirer  j  p          the threshold approach to clinical decision making  
the new england journal of medicine                   
raiffa  h          decision analysis  introductory lectures on choices under uncertainty 
addison wesley 
ramoni  m     sebastiani  p          robust bayes classifiers  artificial intelligence                   
roth  d          on the hardness of approximate reasoning  artificial intelligence         
     
shann  m     seuken  s          an active learning approach to home heating in the
smart grid  in proceedings of the   rd international joint conference on artificial
intelligence  pp           
stratonovich  r          on value of information  izvestiya of ussr academy of sciences 
technical cybernetics         
van der gaag  l  c     coupe  v  m  h          sensitivity analysis for threshold decision
making with bayesian belief networks  in ai ia  pp       
vomlel  j          bayesian networks in educational testing  international journal of
uncertainty  fuzziness and knowledge based systems      supp           
   

fialgorithms and applications for the same decision probability

xenos  m          prediction and assessment of student behaviour in open and distance
education in computers using bayesian networks  computers   education         
       
yu  s   krishnapuram  b   rosales  r     rao  r  b          active sensing  in international
conference on artificial intelligence and statistics  pp         
zhang  n  l          probabilistic inference in influence diagrams  in computational intelligence  pp         
zhang  y     ji  q          efficient sensor selection for active information fusion  ieee
transactions on systems  man  and cybernetics  part b                 

   

fi