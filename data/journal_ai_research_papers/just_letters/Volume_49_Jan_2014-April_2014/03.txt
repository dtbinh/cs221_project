journal of artificial intelligence research                  

submitted        published      

text based twitter user geolocation prediction
bo han

hanb   student  unimelb   edu   au

the university of melbourne  vic       australia
nicta victoria research laboratory

paul cook

paulcook   unimelb   edu   au

the university of melbourne  vic       australia

timothy baldwin

tb   ldwin   net

the university of melbourne  vic       australia
nicta victoria research laboratory

abstract
geographical location is vital to geospatial applications like local search and event detection  in
this paper  we investigate and improve on the task of text based geolocation prediction of twitter
users  previous studies on this topic have typically assumed that geographical references  e g  
gazetteer terms  dialectal words  in a text are indicative of its authors location  however  these
references are often buried in informal  ungrammatical  and multilingual data  and are therefore
non trivial to identify and exploit  we present an integrated geolocation prediction framework
and investigate what factors impact on prediction accuracy  first  we evaluate a range of feature
selection methods to obtain location indicative words  we then evaluate the impact of nongeotagged tweets  language  and user declared metadata on geolocation prediction  in addition  we
evaluate the impact of temporal variance on model generalisation  and discuss how users differ in
terms of their geolocatability 
we achieve state of the art results for the text based twitter user geolocation task  and also
provide the most extensive exploration of the task to date  our findings provide valuable insights
into the design of robust  practical text based geolocation prediction systems 

   introduction
the growing volume of user generated text posted to social media services such as twitter  facebook  and tumblr can be leveraged for many purposes ranging from natural disaster response to targeted advertising  tuten        nunez redo  daz  gil  gonzalez    huerta        yin  lampert 
cameron  robinson    power         in many circumstances it is important to know a users location in order to accomplish these tasks effectively  for example  disaster response managers must
know where to direct resources in order to effectively coordinate aid  and advertisers could benefit
from tailoring advertisements to a users location  similarly  search results localisation hinges on
knowledge of a users location  although many social media services allow a user to declare their
location  such metadata is known to be unstructured and ad hoc  hecht  hong  suh    chi       
 e g   melbo denoting melbourne  au      as well as oftentimes non geographical  e g   in my own
   throughout the paper  we present city names with iso        alpha   country level designators such as au  
australia and ca   canada  where us based city names are mentioned in the context of the north american
regional dataset used in experimentation  na   we use an iso        us designator such as us ca   california or
us pa   pennsylvania 
c
    
ai access foundation  all rights reserved 

fih an   c ook   baldwin

little bubble   text based geolocation  automatically predicting a users location based on the
content of their messages  is therefore becoming of increasing interest  e g   cheng  caverlee   
lee        and others   in this paper we investigate and improve text based geolocation prediction
for twitter users  specifically  we exploit the tweets and profile information of a given user to infer
their primary city level location  which we claim is sufficiently fine grained to support the sorts of
applications mentioned above 
as is well established in previous work  e g   wing   baldridge        and others   it is reasonable to assume that user posts in social media reflect their geospatial locum  because lexical priors
differ from region to region  for example  a user in london is much more likely to talk about piccadilly and tube than a user in new york or beijing  that is not to say that those words are uniquely
associated with london  of course  tube could certainly be mentioned by a user outside of the uk 
however  the use of a range of such words with high relative frequency is strongly indicative of the
fact that a user is located in london  most work in this area utilises geotagged data as ground truth
for evaluation  e g   eisenstein  oconnor  smith    xing        and others   the geotagged data
contains gps coordinates inserted with the users consent by a gps enabled device such as a smartphone  and offers accurate information about a users position at the time of tweeting  although
approaches to text based geolocation are offering increasingly promising results  the studies to date
on this topic have been limited in a number of important ways  we raise some key issues in section
  and investigate them in turn  focusing on the following issues 
    location indicative words
text based geolocation prediction models for social media are predominantly based on the full text
data of tweets  including common words with no geospatial dimension  e g   today   potentially
hampering prediction  and because of the large number of words observed in tweets  leading to
slower  more memory intensive models  we tackle this by automatically finding location indicative
words  liws  via feature selection  and demonstrating that the reduced feature set boosts geolocation accuracy  in section    we carry out extensive evaluation over a wide range of feature selection
methods proposed in the literature  and show that an information gain ratio based approach outperforms benchmark geolocation prediction methods by      percentage points in terms of accuracy 
and reduces the median prediction error distance by    km on a publicly available regional  north
america  dataset  we similarly demonstrate the effectiveness of liw selection on a global dataset
in section   
    non geotagged tweets
in addition to experimenting with geotagged data  we further extend our analysis to incorporate nongeotagged tweets  some recent work  e g   roller  speriosu  rallapalli  wing    baldridge       
has incorporated non geotagged training data  although little work has analysed the contribution of
non geotagged data  i e   the extent to which incorporating non geotagged data improves geolocation accuracy  furthermore  the evaluation of previous models has been restricted to geotagged data
 in order to have access to a ground truth  although the goal of this line of research is to be able to
infer locations for users whose locations are not known  however  it is unclear how well models
evaluated only on geotagged data will generalise to non geotagged data  for example  because geotagged tweets are sent from gps enabled devices such as smartphones  while non geotagged tweets
   

fit ext based t witter u ser g eolocation p rediction

are sent from a range of devices  including desktop computers   these two types of data could have
different characteristics  gouws  metzler  cai    hovy        
in section    we address these issues by training and testing on geotagged tweets  non geotagged
tweets  and the combination of the two  we show that by exploiting a users non geotagged tweets 
the city level accuracy is improved from       to       on a benchmark dataset  underlining
the potential contribution of non geotagged data  furthermore  the numbers also suggest that a
model trained on geotagged data indeed generalises to non geotagged data  although sub domain
differences between geotagged data and non geotagged data are observed 
    language influence
with some exceptions  e g   kinsella  murdock    ohare         most text based geolocation
studies have been carried out in an english only setting  or a primarily english setting  because
high accuracy language identification tools  lui   baldwin        nakatani        are now readily
available  this is not a problem  messages in the target language can be identified  and text based
geolocation methods can be applied to only those messages  however  it remains to be seen whether
text based geolocation approaches that have been shown to work well for english perform as well
on other languages  or perform well in a multilingual setting  english is tweeted throughout the
world  whereas languages such as indonesian are primarily tweeted in localised areas  as such  the
performance of methods developed and tested over english data could be very different when applied to other languages  we investigate the language influence on a multilingual dataset in section
   the results suggest that our model indeed generalises from a monolingual english to a multilingual setting  furthermore  the experiments reveal that geolocation prediction is much easier for
languages with more geographically restricted use  e g   indonesian  than languages that are more
diverse in usage  e g   english   we then go on to show that a composite model consisting of a
number of monolingual geolocation models based on language identification outperforms a model
trained on multilingual data 
    metadata and ensemble learning
although tweet based geolocation is worthy of study in its own right  tweets are accompanied by
rich metadata in public user profiles  this metadata is included in the payload of json objects containing tweets  and offers complementary information that may be exploited to improve accuracy 
e g   timezone data and the user declared location  while there has been some work on utilising
timezone  mahmud  nichols    drews        and user declared location  hecht et al         information for user geolocation  the metadata remains largely untouched in the literature  in section
   we investigate the performance of metadata based geolocation models and compare them with
benchmark methods  we show that by incorporating information from metadata and the tweet message in a stacking based approach  a city level accuracy of        and a median prediction error
distance of just  km  can be achieved over our global dataset  which is a substantial improvement
over any of the base classifiers 
    temporal influence
because twitter is a growing and evolving medium  the data in twitter streams tends to be locally temporal to the time of posting  in addition to evaluating the geolocation model on old
   

fih an   c ook   baldwin

time homogeneous data  sampled from the same time period as the training data   in section   
we evaluate the trained model on a new time heterogeneous dataset  which was collected approximately one year after the training and test data used in our earlier experiments  the observed
moderate decline in results indicates that the stacked geolocation model is indeed influenced by
temporal changes  error analysis reveals that this is primarily caused by the unreliability of the
base model trained on user declared locations  in contrast  we find that models trained on tweet
text and timezone information are relatively insensitive to temporal changes  this finding on the
one hand justifies the efforts to date in pursuing better text based geolocation prediction  and on the
other hand suggests that if user declared location data is to be used  the model has to be periodically
updated to remain current to temporal changes 
    user geolocatability and prediction confidence
we further discuss the geolocatability of users with regard to tweeting behaviour in section    
for instance  does mentioning many local place names have a strong influence on the prediction
accuracy  experiments suggest the number of liws  in particular  gazetted location names  and
user declared metadata are key to geolocating a user  because of different tweeting behaviours
among users  not all users are equally geolocatable  with only predictions for a proportion of them
being reliable  we further conduct a pilot study on approximating the prediction confidence through
a range of variables in section    
this paper advances the state of the art of text based geolocation prediction in a number of
directions  and provides practical guidelines for the design of a text based geolocation application 
this paper builds off our own previously published work  han  cook    baldwin      b       
with much more extensive evaluation  and new work in the following areas 
 a large scale comparative evaluation of twelve feature selection methods for user geolocation
 nine of which were not considered in our earlier work  in sections    
 the analysis of the impact of training on non geotagged data in section   
 a new set of experiments  and subsequent analysis  examining the influence of language in
section   
 further analysis of the utility of user supplied metadata and ensemble learning in section   
 more detailed analysis of model generalisation on temporal change in section    including
city level meta analysis 
 a new pilot study on user geolocatablility and privacy in section    
the proposed text based method primarily uses words for geolocation prediction  and intentionally excludes twitter specific entities  such as hashtags and user mentions  the prediction accuracy
therefore largely depends on whether the text contains sufficient geospatial information for geolocation prediction  therefore  although this paper focuses exclusively on twitter  the proposed method
could equally be applied to other forms of social media text  such as facebook status updates or
user submitted comments  to services such as youtube  
   

fit ext based t witter u ser g eolocation p rediction

   related work
while acknowledging potential privacy concerns  mao  shuai    kapadia        pontes  vasconcelos  almeida  kumaraguru    almeida         accurate geolocation prediction is a key driver
for location specific services such as localised search  and has been the target of research across
different disciplines  for example  the tagging of both user queries  wang  wang  xie  forman 
lu  ma    li        backstrom  kleinberg  kumar    novak        yi  raghavan    leggetter 
      and web pages  ding  gravano    shivakumar        amitay  harel  sivan    soffer       
zong  wu  sun  lim    goh        silva  martins  chaves  afonso    cardoso        bennett 
radlinski  white    yilmaz        has been considered in information retrieval  in geographical
information science  the primary focus has been on recognising location mentions in text  leidner
  lieberman         with named entity recognition tools typically employed to detect and extract
such mentions  quercini  samet  sankaranarayanan    lieberman        gelernter   mushegian 
       within the social media realm  geolocation methods have been applied to images on flickr
 crandall  backstrom  huttenlocher    kleinberg        serdyukov  murdock    van zwol       
hauff   houben        ohare   murdock        laere  schockaert    dhoedt         wikipedia
articles  lieberman   lin         individual tweets  kinsella et al          twitter users  eisenstein
et al         cheng et al         kinsella et al         wing   baldridge        roller et al        
han et al       b   and for identifying words and topics on twitter that are salient in particular
regions  eisenstein et al         yin  cao  han  zhai    huang        hong  ahmed  gurumurthy 
smola    tsioutsiouliklis        dalvi  kumar    pang        
identifying twitter users locations is non trivial  mainly due to the unavailability of reliable
geographic information  although twitter allows users to declare their location in their user profile 
the location descriptions are unstructured and ad hoc  cheng et al         hecht et al          e g  
people use vernacular expressions such as philly  or non standard spellings such as filladephia  to
refer to philadelphia  non geographical descriptions like in your heart are also commonly found 
without appropriate processing  the value of these location fields is greatly limited  hecht et al 
       demonstrate that trivially using these location fields in off the shelf geolocation tools is ineffective  alternatively  some tweets sent from mobile devices are geotagged with accurate gps
coordinates  however  the proportion of geotagged tweets is estimated to be a mere     cheng
et al          and the location of the vast majority of users are not geotagged  methods based on
ip addresses  buyukokkten  cho  garcia molina  gravano    shivakumar        can be applied to
the task  and in general web contexts have been shown to achieve around     accuracy at mapping
internet hosts to their locations  padmanabhan   subramanian         such methods are not applicable to twitter and many other social media services  however  as the ip address of the device
the message was sent from cannot be accessed via any of the public apis  doubtless twitter itself
has access to this information and can use it for user geolocation  although even here  geographical divisions of ip addresses are not always credible  for instance  departments in an international
corporation might use the same ip address range  but their true locations could be spread across the
world  vpns are also a complication for such approaches  any third party service provider making
use of twitter data  however  has to look to other sources of geospatially identifying information 
including the text content of the users posts and metadata information  as targeted in this research 
in the spatial data mining community  geographical references  e g   gazetteer terms  in text have
also been exploited to infer geolocation  intuitively  if a place is frequently mentioned by a user in
their tweets  they are likely tweeting from that region  methods building on this intuition range from
   

fih an   c ook   baldwin

naive gazetteer matching and rule based approaches  bilhaut  charnois  enjalbert    mathet        
to machine learning based methods  primarily based on named entity recognition  quercini et al  
      gelernter   mushegian         despite the encouraging results of this approach on longer
and more homogeneous documents sets  quercini et al          its performance is impeded by the
nature of tweets  they are short and informal  and the chances of a user not mentioning gazetted
places in their tweets is high  moreover  the handling of vernacular place names  e g   melbo for
melbourne  in this approach is limited  the reliance on named entity recognition is thwarted by the
unedited nature of social media data  where spelling and capitalisation are much more ad hoc than
in edited document collections  ritter  clark  mausam    etzioni        han  cook    baldwin 
    a  
moving beyond off the shelf solutions  recently  many robust machine learning methods have
been applied to geolocation  with the primary approach being to estimate locations based on the
textual content of tweets  for instance  cheng et al         exploit words known to be primarily used in particular regions  along with smoothing techniques  to improve a simple generative
geolocation model when applied to data from the continental united states  wing and baldridge
       divide the worlds surface into a uniform size grid  and compare the distribution of words in
a given users tweets to those in each grid cell using kullback leibler  kl  divergence to identify
that users most likely location  one limitation of this approach is that grid cells in rural areas tend
to contain very few tweets  while there are many tweets from more urban grid cells  roller et al 
       therefore extend this method to use an adaptive grid representation in which cells contain
approximately the same amount of data  based on a k d tree  bentley         kinsella et al        
examine geolocation prediction at different granularities  e g   zip codes  city  state and country  
chang  lee  m   and lee        prune noisy data based on geometrically local words  i e   words
that occur geographically close to each other  and are only found in a limited number of cities  and
non stop words that are dis similar to stop words  and they experiment with the reduced feature set
using both a gaussian mixture model and maximum likelihood estimation for location prediction 
beyond purely text based methods  language model based methods   other sources of information
have also been integrated  li  serdyukov  de vries  eickhoff  and larson        investigate geolocation prediction based on a linear rank combination of text and temporal factors  mahmud et al 
       combine timezone information and content based classifiers in a hierarchical model for geolocation  in particular  nouns  hashtags  and place names are considered as content in the method 
schulz  hadjakos  paulheim  nachtwey  and muhlhauser        combine scores from various geographical sources  e g   tweet text  user profile data   the sum of scores for a location is represented
by the aggregated height on a polygon partitioned map  and the highest polygon is the predicted
location 
topics discussed on twitter vary across geographical regions  intuitively  for instance  americans are more likely to talk about nba and baseball than australians  who probably mention afl
and rugby more often   to capture these regional topic variations in twitter  topic modelling based
approaches have also been used to incorporate geographical regions in the generative process  for
instance  eisenstein et al         introduce a geographical variable  r   instead of generating an observed word w from a per word topic distribution z as in the standard latent dirichlet allocation
 lda  model  blei  ng    jordan         their proposed approach refines this step by additionally
modeling the topic distributions across different geographical regions  i e   w is generated from a
per word region topic distribution rz   therefore  the observed user locations are generated from
geographical regions and the region variable in topic modeling is linked with user geographical
   

fit ext based t witter u ser g eolocation p rediction

locations  generally  a users location is predicted at the regional level by adopting the location
centroid for geotagged tweets from that region  hong et al         further improve the approach by
considering more fine grained factors in an additive generative model  in addition to introducing
per region topic variance  they incorporate per user topic variance  a regional language model  and
global background topics  to compensate for the computational complexity associated with these
extra hidden variables  they adopt sparse modeling in inference  on top of these geolocation prediction tasks  many other research problems also involve the modelling of geographical locations 
dalvi et al         exploit the impact of geographical locations on users discussions of pre defined
objects  e g   restaurants  in tweets  yin et al         propose ways to discover and compare topics
for geographical regions by jointly modelling locations and text  despite the benefits of incorporating per region topic variance in these models  a few concerns prevent us from using topic modeling
approaches in this study  first  the temporal currency of geographical topics can be limited  e g  
olympics or playoffs  these temporally specific topics are less indicative of location for future inference  e g   geolocating users after the model has been trained  furthermore  topic modelling is
generally computationally expensive  and suffers efficiency problems when applied to large volumes of data  such as that available through social media  therefore we experiment with language
model based methods that are better suited to large scale data 
social network information  including both explicit friendship relations  backstrom  sun   
marlow        sadilek  kautz    bigham        rout  bontcheva  preotiuc pietro    cohn       
and implicit social interactions  chandra  khan    muhaya        jurgens         has been shown
to be effective in predicting locations  city level prediction results range from approximately   
     rout et al         depending on a wide range of factors including the user density in the social
network and the precise scope of the geolocation prediction task  however  social networks are
dynamic  and this information is often more difficult to obtain than text data on a large scale  for
instance  obtaining social network information requires multiple requests to the rate limited twitter
api to reconstruct the full social graph  we therefore only focus on approaches based on text 
and metadata that accompanies each individual tweet  and leave the possibility of integrating social
network information to future work 

   key questions and geolocation prediction framework
though various geolocation prediction approaches have been proposed and adapted for social media
data  some fundamental questions remain  in the rest of the paper  we address each of the these
questions in turn 
 given that text based methods rely on salient words local to particular regions to disambiguate
geolocations  do location indicative words improve the accuracy over using the full word
set 
 does a model trained on geotagged data generalise to non geotagged data  what is the impact
of adding non geotagged texts to the training and test data  is there an inherent sub domain
difference between geotagged and non geotagged tweets given that geotagged tweets are primarily sent from mobile devices 
 does geolocation prediction accuracy vary by language  for example  is a user who primarily
tweets in japanese more geolocatable than a user who tweets mostly in english  if language
   

fih an   c ook   baldwin

does influence accuracy  how can we exploit this to improve multilingual geolocation prediction 
 does the user declared text metadata provide geographical information complementary to
that in the tweets themselves  how can we make use of these multiple sources of textual data
to produce a more accurate geolocation predictor 
 as twitter is rapidly growing and evolving  how do temporal factors influence the model
generalisation  will a model trained on old data perform comparably on new test data 
 from the perspective of privacy protection  how does a users tweeting behaviour affect their
geolocatability  i e   the ability of the model to predict their location  are there steps a user
can take to reduce the risk of inadvertently leaking geographical information while sharing
tweets with the public 
 can measures of prediction confidence be formulated to estimate the accuracy of the geolocation prediction 
in this paper  we focus on predicting twitter users primary  referred to as their home  geolocation  and following cheng et al         and others  assume that a given user will be based in a
single city based location throughout the time period of study  we approach geolocation prediction
as a text classification task  tweets from each city are taken to represent a class  all tweets from
a given user are aggregated and assigned to that users primary location  we characterise geolocation prediction by four key components  which we discuss in turn below      the representation of
different geolocations      the model      the feature set  and     the data 
    representation  earth grid vs  city
geolocations can be captured as points  or clustered based on a grid  wing   baldridge       
roller et al          city centres  cheng et al         kinsella et al         or topic regions  eisenstein et al         hong et al          a point based representation presents computational challenges  and is too fine grained for standard classification methods  as for dynamic location partitioning  the granularity of regions is hard to control and will potentially vary across time  and the
number of regions is a variable which will depend on the dataset and potentially also vary across
time  fixed grid based representations are hindered because there is considerable variability in the
shape and size of geographical regions  a coarse grained grid cell is perhaps appropriate in central
siberia  but for densely populated and linguistically culturally diverse regions such as luxembourg 
doesnt lead to a natural representation of the administrative  population based or language boundaries in the region  we therefore opt for a city based representation  which is able to capture these
boundaries more intuitively  the downside to this representation is that it is inappropriate for classifying users in rural areas  as we will see in figure    however  the bulk of twitter users are 
unsurprisingly  based in cities 
following han et al       b   we use the publicly available geonames dataset as the basis for
our city level classes   this dataset contains city level metadata  including the full city name  population  latitude and longitude  each city is associated with hierarchical regional information  such
as the state and country it is based in  so that london  gb  e g   is distinguished from london  ca 
   http   www geonames org  accessed on october   th       

   

fit ext based t witter u ser g eolocation p rediction

we hence use a city region country format to represent each city  e g   toronto  ca is represented
as toronto    ca  where    signifies the province of ontario and ca signifies canada    because
region coding schemes vary across countries  we only employ the first  and second level region
fields in geonames as the region  furthermore  if the second level field is too specific  i e   longer
than   letters in our setting   we only incorporate the first level region field  e g   instead of using
melbourne          au  we use melbourne    au   moreover  because cities are sometimes
complex in structure  e g   boston  us colloquially refers to the metropolitan area rather than the
city  which is made up of cities including boston  revere and chelsea   we collapse together cities
which are adjacent to one another within a single administrative region  as follows 
   identify all cities which share the same region code  i e   are located in the same state 
province  county  etc   in the geonames dataset 
   for each region  find the city c with the highest population 
   collapse all cities within   km of c into c  
   select the next largest city c  and repeat 
   remove all cities with a population of less than    k  the remaining cities form our citybased representation of geolocations 
as a result of this methodology  boston  us ends up as a single city  incorporating revere and
chelsea   but neighbouring manchester  us is a discrete city  incorporating bedford  because it is
in new hampshire  this algorithm identifies a total of       collapsed cities throughout the world 
    geolocation prediction models
various machine learning algorithms can be applied to the task of multi class text categorisation 
however  many state of the art learning algorithms are not appropriate for this particular task for
reasons of scalability  for example  support vector machines  vapnik        are not well suited
to massively multi class problems  i e         cities in our case   finally  we would ideally like to
have a learning algorithm which can be easily retrained  e g   to incorporate new training data from
the twitter data stream  as such  we primarily experiment with simple learning algorithms and
ensemble learning for geolocation prediction 
      g enerative vs   d iscriminative m odels
generative models  e g   naive bayes  are based on estimation of joint probability of observing a
word vector and a class  i e   p  w    w            wn   ci    where w    w          are words and ci  c is a
city from a combined set of cities c   in contrast  discriminative models are based on estimation of
a class given a word vector  i e   p  c w    w            wn     the objective of both models is to find a
   country code information can be found in http   download geonames org export dump countryinfo txt
   we use the great circle distance  vincenty        for all distance calculations in our experiments  as opposed to
euclidean distance  to properly capture the three dimensional surface of the earth  the proximity of cities varies
across the world  e g   cities on the east coast of the united states are much closer to each other than major cities in
australia  there is therefore scope to explore the impact of this   km setting on the city label set  which we leave to
future work 

   

fih an   c ook   baldwin

city cmax  c such that the relevant probability is maximised  in our experiments  we experiment
with both models  for instance  we choose a state of the art discriminative geolocation model based
on kl divergence over k d tree partitioned unigrams  kl   roller et al          we also adopt a
generative multinomial naive bayes  nb  model  hecht et al         as our default benchmark  for
two reasons      it incorporates a class prior  allowing it to classify an instance in the absence of any
features shared with the training data  and     generative models outperform discriminative models
when training data is relatively scarce  ng   jordan         
      s ingle vs   e nsemble m odels
in addition to single model comparisons  e g   discriminative kl vs  generative nb in sections  
and     we further combine multiple base classifiers  e g   heterogeneous nb models trained
on each of twitter text and user metadata  to improve the accuracy  first  we investigate the
accuracies of base classifiers and correlations between them  then  we apply different ensemble
learning strategies in section   
    feature set
predominantly  geolocations are inferred based on geographical references in the text  e g   place
names  local topics or dialectal words  however  these references are often buried in noisy tweet
text  in which lexical variants  e g   tmrw for tomorrow  and common words without any geospatial dimension  e g   weather  twitter  are prevalent  these noisy words have the potential to mislead
the model and also slow down the processing speed  to tackle this issue  we perform feature selection to identify location indicative words  rather than engineering new features or attempting
to capture named entities  e g   the white house  or higher order n grams  we focus on feature selection over simple word unigrams  see section     this is partly a pragmatic consideration  in that
unigram tokenisation is simpler   partly  however  it is for comparability with past work  in determining whether a strategically selected subset of words can lead to significant gains in prediction
accuracy  see sections   and    
in addition to feature selection  the feature set can be further refined and extended in various
ways  for instance  feature selection can be enhanced by incorporating non geotagged tweet data 
furthermore  languages can be used to shape the feature set  as words from different languages
carry varying amounts of geospatial information  e g   because dutch is primarily used only in the
netherlands  dutch words are usually more location indicative than english words  moreover  userprovided metadata  e g   location and timezone  is readily accessible in the tweet json objects 
this metadata can be appended as extra text features  in addition to features derived from tweet text 
we investigate the impact of these factors in later sections 

   there is certainly an abundance of twitter data to train models over  but the number of twitter users with sufficient amounts of geotagged tweets to be able to perform geolocation prediction is small  relative to the number of
parameters in the model  the product of the number of features and classes  
   also  preliminary results with both named entities and higher order n grams were disappointing 

   

fit ext based t witter u ser g eolocation p rediction

proportion of tweets
 relative to preceding step 

filtering criterion
geotagged
near a city
non duplicate and non foursquare
english

     
     
     
     

table    proportion of tweets remaining after filtering the data based on a series of cascaded criteria 
these numbers are based on a twitter corpus collected over two months 

    data
geolocation prediction models have primarily been trained and tested on geotagged data   we use
both regional datasets  i e   geotagged tweets collected from the continental us  eisenstein et al  
      mahmud et al         and global datasets  kinsella et al         han et al       b  in this
research  because of accessibility issues  e g   many tweets in older datasets have been deleted and
are thus not accessible now  and data sparseness  e g   there were only   k users in the study of
eisenstein et al          we are only able to experiment over a small number of public datasets  in
this paper  we employ three geotagged datasets 
   a regional north american geolocation dataset from roller et al          na hereafter   for
benchmarking purposes  na contains    k users    m tweets  from a total of     of our
pre defined cities  na is used as is to ensure comparability with previous work in section   
   a dataset with global coverage constructed by us in earlier work  han et al       b   world
hereafter   collected via the twitter public streaming api  from    sep       to    feb 
      the tweet collection is further shaped for different evaluation tasks  e g   geotagged
english data world in section    incorporating non geotagged english data world ng
in section    multilingual geotagged data world ml in section   and with rich metadata
world meta in section   
   a second dataset with global coverage novel to this research  live   which contains tweets
collected more than   year after world  from   mar       to   may         to analyse the
influence of temporal recency on geolocation prediction  unlike the other two datasets  live
is used only as a test dataset  in section    
world was restricted to english tweets in order to create a dataset similar to na  in which
english is the predominant language   but covering the entire world  it was pre processed by filtering the data as follows  first  all non geotagged tweets were removed  next  we eliminated all
tweets that arent close to a city by dividing the earth into          grid cells  and discarding
any tweet for which no city in our geonames class set is found in any of the   neighbouring grid
cells  we then assign each user to the single city in which the majority of their tweets occur  we
   one exception to this is cheng et al          who train on users whose user declared metadata location fields correspond to canonical locations  e g   boston  ma   and test on users whose locations are indicated with gps coordinates
in their metadata 
   https   dev twitter com docs streaming apis

   

ficumulative distribution of tweets

h an   c ook   baldwin

   

   

   

  

                                   
top n  of cities

 

 

the number of users
           

the number of users
   
     

figure    cumulative coverage of tweets for increasing numbers of cities based on    million geotagged tweets 

 

  
   
    
     
number of geotagged tweets

 
 
  
   
    
mean distance from city centre  kilometres 

figure    the number of users with different numbers of tweets  and different mean distances from
the city center  for world 

further remove cities with fewer than    feature types  i e   word types  to reduce data sparsity  this
results in      cities in world  as opposed to      cities in the full geonames class set   we
eliminated exact duplicate tweets and foursquare check ins  which encode the user location in the
form of im at          after that  non english tweets were further removed using langid py  an
open source language identification tool  lui   baldwin         this filtering is summarised in
table   which also shows the proportion of tweets remaining after each step  the total number of
users and tweets in world is    m and   m  respectively  similar to na  the development and
test datasets both contain   k users  and the remainder of the users are used in training  the development and test data was sampled such that each user has at least    geotagged tweets to alleviate
data sparsity   we tokenised the tweets with a twitter specific tokeniser  adapted from oconnor 
krieger    ahn        
although there are certainly instances of social media users with high mobility  li  wang   
chang         recent studies have shown that most users tend to tweet from within a limited region
 cho  myers    leskovec        hecht et al          we also analyse the spread of world in
   this restriction was not applied to the training data 

   

fit ext based t witter u ser g eolocation p rediction

figure    in terms of      the number of users with at least    geotagged tweets  and     the number
of users with differing levels of geographical spread in their tweets  measured as the average distance
between each of a users tweets and the centre of the city to which that user is allocated    this
preliminary analysis shows that most users have a relatively small number of geotagged tweets  and
most users stay near a single city  e g       users have a geographical spread of    kilometres or
less   the high proportion of users with an average distance of  km to the city centre is an artefact
of their geotagged tweets being mapped to a city centre before performing this analysis  in order to
investigate the coverage of the proposed city based partition  we examine the recall in our original
sample of    million geotagged tweets  prior to filtering  as described above   the analysis reveals
that       of tweets are close to  in a neighbouring         grid cell  to one of our pre defined
cities  and that the top     of cities contain     of the geotagged tweets after filtering  as shown
in figure    this supports our assumption that most  geotagged  twitter users are based in cities 
    evaluation measures
having formulated the geolocation prediction task into a discrete class space through the use of our
city class set  it is possible to use simple classification accuracy to evaluate our models  however 
given that all of our class labels have a location  in the form of latitudelongitude coordinates  
we can also sensitise the evaluation to distance based predictive error  for instance  if the correct
location for a user is seattle  us  a prediction of portland  us is arguably better than a prediction
of los angeles  us  on the basis of geospatial proximity  we use a number of evaluation measures
which capture spatial proximity  in line with previous work  wing   baldridge        roller et al  
        
   acc  city level accuracy  i e   the proportion of predictions that correspond to the correct city 
   acc      the proportion of predictions that are within a distance of     kilometres     
miles  from the correct city level location  this empirical measure  cheng et al         is a
relaxed version of acc  capturing near miss predictions 
   acc c  country level accuracy  i e   the proportion of predicted locations that are in the same
country as their corresponding true locations  this measure is useful for applications relying
on country specific twitter data  e g   sentiment analysis in specific countries 
   median  median prediction error  measured in kilometres between the predicted city centres
and the true geolocations  we prefer to use the median  as opposed to mean  distance because
the median is less sensitive to wildly incorrect predictions  e g   a user from london  gb
classified as being based in sydney  au  in contrast  the mean distance can increase substantially due to a small number of extreme misclassifications  although this effect is limited for
inherently bounded regional datasets such as na 
    the geographical spread is calculated over a random sub sample of    tweets for a given user  for efficiency reasons 
    in very recent work  priedhorsky  culotta  and valle        additionally proposed a set of probabilistic metrics
to evaluate tweet based geolocation prediction  including using the expected distance between a tweets true point
location to a random point location drawn from the probability distribution of the geolocation model  while we
strongly support this new direction for geolocation modelling and evaluation  depending on the application context 
we argue that point  or region based representations and related discrete evaluation measures are equally important
in user geolocation research 

   

fih an   c ook   baldwin

   finding location indicative words
precise user locations for individual messages are embedded in geotagged tweets in the form of
latitudelongitude coordinates  by mapping these coordinates to cities and representing each tweet
as a bag of words  we are able to make connections between words  i e   features  and cities  i e  
classes   in this section  we present a range of methods for ranking these words by their location
indicativeness  i e   the degree to which a word is associated with particular cities  words that either
explicitly  e g   place names  or implicitly  e g   dialectal words  slang or local references  encode
geographical information are collectively referred to as location indicative words  liws   it is
these words that we aim to automatically identify  examples of liws are 
   local words    local  that are used primarily in a single city  namely yinz  used in pittsburgh to
refer to the second person plural pronoun   dippy  used in pittsburgh to refer to a style of fried
egg  or something that can be dipped in coffee  and hoagie  used primarily in philadelphia 
to refer to a kind of sandwich    
   semi local words  n local  that refer to some feature of a relatively limited subset of cities 
namely ferry  found  e g   in seattle  new york and sydney   chinatown  common in many
of the largest cities in the us  canada and australia  but much less common in european and
asian cities   and tram  found  e g   in vienna  melbourne and prague 
in addition to liws there are common words  common  which arent expected to have substantial
regional frequency variation  namely twitter  iphone and today 
in the remainder of this section  we present various feature selection methods for identifying
liws  drawn from the work of han et al       b   chang et al         and laere et al          the
feature selection methods can be broadly categorised into three types      statistical      informationtheoretic  and     heuristic  to reduce low utility words and noise  for all feature selection methods 
we remove all words which include non alphabetic letters  are less than   letters long  or have a
word frequency      
    statistical based methods
statistical hypothesis testing is often used to determine whether an event occurs by chance  i e   the
null hypothesis  or not  i e   the alternative hypothesis  at a particular confidence level  e g      
 p          in our case  an event is defined to be a co occurrence between a word and a city  and
the null hypothesis assumes the co occurrence is by chance  i e   the word and city are independent 
the goal of feature selection is then to find wordcity pairs where the null hypothesis is rejected 
       

and

l og  l ikelihood

the   statistic is commonly used to examine the degree of independence between random variables  a contingency table representing the observations of the variables is formed  as in table   
the general form of the statistic is 
n

 oi  ei   
i

ei

    these words were identified with the aid of datasets of regional words such as dare  http   dare wisc edu  

   

fit ext based t witter u ser g eolocation p rediction

in c
ow c
ow c

w
non w word

not in c
ow c
ow c

table    contingency table for word and city co occurrence
where oi represents an observation  i e   co occurrence of a city  c  and word  w    and n is the
number of cells in the table  ow c and ow c denote the occurrence of word w in city c and non w
words in cities other than c  respectively  ew c denotes the expected frequency of w in c  calculated
from the marginal probabilities and total counts n  
ow c   ow c ow c   ow c

n
n
n
  ow c   ow c   ow c   ow c

ew c   p  w   p  c   n  
n

if the   statistic is larger than the number in the   distribution  with respect to the degrees of
freedom  in this case      then the null hypothesis that city c and word w are independent is rejected 
as with many statistical tests    can be ineffective when counts are low  we address this through
our word frequency thresholding and use of massive amounts of training data 
conventionally    is used to identify the set of features which satisfies a pre defined confidence
level  e g   p          however  in the case of liw selection  we instead use the   statistic to rank
all wordcity pairs  the selection of liws is deferred to the parameter tuning state  in which the
boundary between liws and common words is optimised using development data 
at this point  a different ranking of liws is produced per city  where what we desire is a global
ranking of liws capturing their ability to discriminate between cities in the combined label set 
there are various ways to do this aggregation  as suggested by laere et al          one approach to
selecting n features based on   is to iteratively aggregate the top m features from each city until
n features are obtained  alternatively  they can be ranked based on the highest scoring occurrence
of a given word for any city  by first sorting all cityword   test pairs  then selecting the first
occurrence of a word type for the aggregated ranking  these two aggregation approaches produce
different feature selection rankings  and are distinguished using chi and maxchi   respectively   
similar to the   test  the log likelihood ratio  loglike  dunning        has also been applied
to liw selection  laere et al          the loglike test determines whether h   the null hypothesis 
i e   the word is independent of the city  is more likely than h   the alternative hypothesis  i e   the
word is dependent on the city   following dunning  the likelihood of a hypothesis  l    is estimated
using binomial distributions 
   
   
k 
k 
n  k  n 
n  k  n 
l h      p      p   
p     p   
k   
k 
p    p  w c   

ow c
k 
 
n 
ow c   ow c

    one possible alternative to computing   for each word and city  and then aggregating these values into a final
ranking of words  would be to compute a single   value for each word from a contingency table with   rows as in
table    but with one column per city  nevertheless  this is not the standard use of   in feature selection  and we
leave this possibility to future work 

   

fih an   c ook   baldwin

ow c
k 
 
n 
ow c   ow c
k   k    represents the occurrences of word w in city c  not in city c   and n   n    represents all word
occurrences in city c  not in city c   l h    is a special case of l h    for which p  and p  are equal 
as below 
p    p  w c   

ow c   ow c
n
the loglike test statistic is then expanded using observations 
p    p    p  

loglike w      ow c log ow c   ow c log ow c   ow c log ow c   ow c log ow c   n log n
  ow c   ow c   log ow c   ow c     ow c   ow c   log ow c   ow c  
  ow c   ow c   log ow c   ow c     ow c   ow c   log ow c   ow c   
having calculated the loglike for each wordcity pair  we then aggregate across cities similarly to
chi  by selecting the top m features per city until n features are obtained   following laere et al 
         
      r ipley  s k s tatistic
spatial information can also be incorporated into the hypothesis testing  for example  the ripley k
function  ripley  osullivan   unwin        measures whether a given set of points is generated
from a homogeneous poisson distribution  the test statistic calculates the number of point pairs
within a given distance  over the square of the total number of points  with regards to liw
selection  the set of points  qw   is the subset of geotagged users using a particular word w  the test
statistic is formulated as follows  laere  quinn  schockaert    dhoedt        
k     a 

  p  q  qw   distance p  q     
 qw   

where a represents the total area under consideration  e g   the whole of north america  or the
whole globe   this is dropped when generating a ranking 
a larger value of k   indicates greater geographical compactness of the set qw  i e   p and q
are spatially close   however   qw    i e   the number of users who use word w  varies considerably
across words  and can dominate the overall statistic  a number of variations have been proposed
to alleviate this effect  including replacing the denominator with a factor based on l   and taking
the logarithm of the overall value  laere et al          the quadratic computational complexity of
ripley becomes an issue when  qw   is large  i e   for common words   randomised methods are
usually adopted to tackle this issue  e g   subsampling points from training data for ripley calculation relative to different distances   for our experiments  we adopt the optimised implementation
of laere et al  using       km with  k samples 
    information theory based methods
in addition to statistical methods  we also experiment with information theoretic feature selection
methods based on measures which have been shown to be effective in text classification tasks  e g  
information gain  ig   yang   pedersen        
    note also that  as we will see later in our experiments  there is almost no empirical difference between the two
aggregation methods for     so the choice of aggregation method here is largely arbitrary 

   

fit ext based t witter u ser g eolocation p rediction

      i nformation g ain and g ain r atio
information gain  ig  measures the decrease in class entropy a word brings about  where higher
values indicate greater predictability on the basis of that feature  given a set of words w  the ig of
a word w  w across all cities  c  is calculated as follows 
ig w    h c   h c w 
 h c w 


 p  w 
p  c w logp  c w    p  w 
p  c w logp  c w 
cc

cc

where p  w  and p  w  represent the probabilities of the presence and absence of word w  respectively  because h c  is the same for all words  only h c w   the conditional entropy given w 
needs to be calculated to rank the features 
words carry varying amounts of intrinsic entropy  which is defined as 
iv  w    p  w logp  w   p  w logp  w 
local words occurring in a small number of cities often have a low intrinsic entropy  where nonlocal common words have a high intrinsic entropy  akin to inverse city frequency  see section        
for words with comparable ig values  words with smaller intrinsic entropies should be preferred 
therefore  following quinlan        we further normalise ig w  using the intrinsic entropy of
word w  iv  w   culminating in information gain ratio  igr  
igr w   

ig w 
iv  w 

      l ogistic r egression  based f eature w eights
the previous two information theoretic feature selection methods  ig and igr  optimise across all
classes simultaneously  given that some liws may be strongly associated with certain locations 
but are less tied to other locations  we also conduct per class feature selection based on logistic
regression  lr  modelling    we consider this method to be information theoretic because of its
maximisation of entropy in cases where there is uncertainty in the training data 
given a collection of cities c  the lr model calculates the probability of a user  e g   represented
by word sequence  w    w            wn   assigned to a city c  c by linearly combining eligible lr
feature weights 
p  c w    w            wn    

m

 
exp 
k fk  
z
k  

where z is the normalisation factor  m is the total number of features  and fk and k are the features
and feature weights  respectively  as with other discriminative models  it is possible to incorporate
arbitrary features into lr  however  a feature  function  in our task is canonically defined as a word
wi and a city c  when w occurs in the set of messages for users in class c  a feature fk  wi   c  is
    for the logistic regression modeller  we use the toolkit of zhang le  https   github com lzhang   maxent  
with    iterations of l bfgs  nocedal        over the training data 

   

fih an   c ook   baldwin

denoted as  class   c  wi  c   each fk maps to a feature weight denoted as k  r  the method
results in a per city word ranking with words ranked in decreasing order of k   from which we
derive a combined feature ranking in the same manner as maxchi   following han et al       b    
notably  incorporating a regularisation factor balances model fitness and complexity  and could
potentially achieve better results  we dont explicitly perform regularisation in the modelling stage 
instead  we first obtain the feature list ranked by lr as other feature selection methods and then
evaluate the subset of top n ranked features on the development data  this is in fact equivalent to
filter based regularisation  cf  filter based feature selection  guyon   elisseeff         and we
leave experimentation with regularisation integrated into the models to future work 
      d istribution d ifference
liw selection can be likened to finding words that are maximally dissimilar to stop words  chang
et al          stop words like the and today are widely used across many cities  and thus exhibit
a relatively flat distribution  in contrast  liws are predominantly used in particular areas  and
are more skewed in distribution  to capture this intuition  liw selection is then based on the
distribution difference across cities between stop words and potential liw candidates  i e   all
non stop words   given a pre defined set of stop words s  the distribution difference is calculated
as 
distdi  wns    



di  wns   ws  

ws s

count ws  
count s 

where count ws   and count s  denote the number of occurrences of a stop word ws and the total
number of occurrences of all stop words  respectively  the difference  i e   di  wns   ws    between
a stop word ws and non stop word wns can be evaluated in various ways  e g   symmetric kldivergence  distdiskl    or the total variance  distditv   of absolute probability difference across
all cities c  chang et al         
diskl  wns   ws    



p  c wns   log

cc

ditv  wns   ws    



p  c ws  
p  c wns  
  p  c ws   log
p  c ws  
p  c wns  

 p  c wns    p  c ws   

cc

where p  c wns   and p  c ws   denote the probability of a word occurring in a city in the per word
city distribution for wns and ws   respectively  the non stop words are then sorted by distribution
difference in decreasing order  in our experiments  we use the implementation of chang et al  
    heuristic based methods
other than commonly used feature selection methods  a number of heuristics can be used to select
liws 
      d ecoupling c ity f requency and w ord f requency
high utility liws should have both of the following properties 
    as with loglike  the choice of aggregation method here is largely arbitrary  based on our empirical results for    

   

fit ext based t witter u ser g eolocation p rediction

   high term frequency  tf    there should be a reasonable expectation of observing it from
the users tweets in a city 
   high inverse city frequency  icf    the word should occur in tweets associated with a relatively small number of cities 
we calculate the icf of a word w simply as 
icf w  

 c 
cf w

where c is the set of cities and cf w is the number of cities with users who use w in the training data 
combining the two together  we are seeking words with high tf  icf   analogous to seeking words
with high tf  idf values in information retrieval  in standard tf  idf formulations  we multiply
tf and idf   a simple product of tf and icf tends to be dominated by the tf component 
however  for example  twitter scores as highly as jakarta  because twitter has a very high tf   we
resolve this by decoupling the two factors and applying a radix sort ranking  we first rank features
by icf then by tf   in decreasing order  as this approach is largely based on the inverse city
frequency  we denote it as icf below 
      g eographical s pread and d ensity
liws have peaky geographical distributions  cheng et al          in this section  we discuss two
heuristic measures for liw selection which are based on the geographical distribution of the word 
geographical spread  geospread   laere et al         estimates the flatness of a words distribution over cities  first  the earth is divided into   latitude by   longitude cells  for each word
w  the cells in which w occurs are stored  then  all neighbouring cells containing w are merged
by multi pass scanning until no more cells can be merged  the number of cells containing w after
merging is further stored  finally  the geospread score for the word w is calculated as follows 
geospread  w   

  of cells containing w after merging
max  w 

where max  w  represents the maximum frequency of w in any of the original unmerged cells 
smaller values indicate greater location indicativeness  this measure was originally used to rank
flickr tags by locality  e g   london is more location indicative than beautiful  it ignores the influence of stop words  as they are not common in flickr tags  however  stop words like the are
frequent in twitter  and occur in many locations  making the numerator small and denominator
large  furthermore  stop word frequencies in cells are usually high  consequently  the has a similarly small geospread to london  which is undesirable  in other words  geospread is flawed in
not being able to distinguish stop words from local words  although it can be effective at ranking
less common words  e g   london vs  beautiful  
geographical density  geoden  chang et al         strategically selects peaky words occurring
in dense areas  given a subset of cities c  c where word w  w is used  the geoden is calculated
   

fih an   c ook   baldwin

as 




 cc

geoden w   
 c   
 c  

cj  ck c j k dist cj  ck  
 c    c    





 

p  c w 

cc

p  c w 

cj  ck c j k dist cj  ck  
 c   

where dist cj   ck   is the great circle distance between cities cj and ck   similarly  p  c w  denotes
the distribution of word w across each city c  c   the denominator is made up of the square
of the number of cities  c   that w occurs in  which has a similar effect to icf above   and the
average distance between all cities where w is used  liws generally have a skewed geographical
distribution in a small number of locations  meaning that the denominator is small and the numerator
is large  the issue with this measure is the computational complexity for common words that occur
in many cities  furthermore  cities containing a small number of occurrences of w should not be
incorporated  to avoid systematic noise  e g   from travellers posting during a trip  one approach to
counter these issues is to set a minimum p  c w  threshold for cities  and further perform randomised
sampling from c   in this paper  we follow chang et al  in constructing the final c   first  all cities
containing w are ranked by p  c w  in decreasing order  then c is formed by adding cities according
to rank  stopping when the sum of p  c w  exceeds a pre defined threshold r  we choose r       in
our experiments  based on the findings of chang et al  

   benchmarking experiments on na
in this section  we compare and discuss the proposed feature selection methods  in particular 
we investigate whether using only liws for geolocation prediction is better than using the full
set of features  under various configurations of models and location partitions in section      the
subsequent experiments in this section are exclusively based on the public na dataset  we adopt the
same user partitions for training  dev and test as was used in the original paper  roller et al         
we primarily use the city based class representation in our experiments over na  but additionally
present results using the original k d tree partitions learned by roller et al  in section      for direct
comparability with their published results  for the distance based evaluation measures  acc    
and median   we calculate the users location based on the centroid of their tweets  and  depending
on the class representation used  represent the predicted location as either   a  a city centre  or  b 
the user centroid for a given k d tree cell  in the case of acc for the city based class representation 
we map the centroid for each user to the nearest city centre    km away  and use this as the basis
of the acc calculation  in the case that there is no city centre that satisfies this constraint    we map
the user to the null class  and will always misclassify the user   
    comparison of feature selection methods
first  we compare the effectiveness of the various feature selection methods on na using the citybased class representation  in total     k features were extracted from the training section of na 
    this occurs for               of test users 
    as such  the upper bound acc for the city based representation is        note also that the acc for the k d tree vs 
city based representation is not comparable  because of the different class structure and granularity 

   

fit ext based t witter u ser g eolocation p rediction

   

acc   

   

   
icf
geoden
ripley
igr
loglike
chi

   

   
     

   

   

   

   

   

   

   

   

   

   

   

top n  of features

figure    acc     for varying levels of feature selection on the na dataset  based on the citybased class representation 

we select the top n  of features  with a step size of     and then use the selected features within
a multinomial naive bayes learner  we return to explore the choice of learner in section       the
tuning of n for all methods is based on acc     over the   k held out users in the development
data  we present results for a sample of feature selection methods in figure    omitting methods
which are largely identical in behaviour to other methods presented in the graph  namely 
  distditv   distdiskl    icf
 maxchi  chi
  lr  ig  geospread    loglike
for all methods  the best result is achieved with a proper subset of features based on feature
selection  although the proportion of the features that gives the best results for a given method
varies greatly  e g   the optima for ripley  igr and geoden are          and      respectively  
this observation agrees with the expectations that      when only a small number of features is
used  the trained model generally underfits the data  and     if the model is trained using the full
feature set  noisy words  e g   the  cause overfitting  for instance  when using just the top    of
features in igr  the most likely class for users with features  noting that users with no feature
representation will default to the majority class  namely los angeles  us ca  is monterrey  mx 
because spanish words are highly location indicative of the small number of mexican cities in the
na dataset  the features which are selected last are generally high frequency function words  e g  
the  and common words  e g   facebook   which give little indication as to geolocation  and lead to
prediction errors 
two patterns can be observed in the results      chi   maxchi   ig  loglike  geospread   lr
and ripley  i e   local methods  which initially select features for each class  with the exception
   

fih an   c ook   baldwin

of ig and ripley  achieve their highest acc     at an early stage  then the numbers drop gradually  and     icf   igr  distdiskl   distditv and geoden  i e   the collective group  which
select features for all classes at once  gradually increase in accuracy as more features are added 
reach a peak when the majority of features are selected  then drop off in accuracy sharply  this
difference in behaviour can be attributed to the types of word that are preferred by the methods 
the local methods tend to prefer   local words  taking lr  for example  city names  e g  
philadelphia  and names of upper level administrative regions  e g   georgia  frequently occur in
the upper reaches of the ranking  in addition to these gazetted words  many local regional words are
also found in the upper reaches of the feature ranking  including informal place names  e g   philly 
an informal name for philadelphia  us pa   local transport references  e g   skytrain  a public transport system in vancouver  ca  and local greetings  e g   aloha in honolulu  us hi   however  it
is reasonable to believe that   local words  words that are predominantly used in one city and
are rarely mentioned in other cities  are not common  as a result  the accuracy is bounded by
the limited number of true   local words  this could be the reason for the early  yet remarkably
high  peak in accuracy  and subsequent sharp decline  for ripley  because of its reliance on pairwise
distances between users using a given word  ripley tends to rank   local words highly  in contrast 
the collective methods assume words carry varying amounts of geospatial information  by leveraging combinations of liws  the true location of a user can be collectively inferred  for instance 
brunswick is a common suburb street name in many cities  e g   melbourne  au and london  gb 
this word alone is insufficient to make reliable predictions  however  if other liws  e g   tram
and flinders  which are again not uniquely disambiguating in themselves  are also observed  then
the chance of the location being melbourne  au becomes high  since it is unlikely that users from
cities other than melbourne  au would use that combination of words  this strategy can also be
explained in information theoretic terms  by knowing more words  extra information is obtained 
and consequently the entropy is continuously reduced and the prediction of geolocation becomes
more certain 
among all the feature selection methods  igr  geoden and ripley are the stand out methods
in terms of acc      we further compare the accuracy of classifiers trained using the optimised
set of liws  based on the development data  to that of the full model  the performance is measured
on the   k held out test users  using the city based class representation  the results are displayed
in table    for the same subset of feature selection methods as were displayed in figure     and
show that using liws offers an improvement over the full feature set for all evaluation measures
and all feature selection methods  except for slight dips in acc c for igr and geoden  nevertheless  these numbers clearly demonstrate that feature selection can improve text based geolocation
prediction accuracy  igr performs best in terms of accuracy  achieving      and       absolute
improvements in acc and acc      respectively  over the full feature set 
    comparison with benchmarks
we further compare the best performing method from section     with a number of benchmarks
and baselines  we experiment with two class representations      the city based class representation based on geonames  and     the k d tree based partitioning of roller et al          which
creates grid cells containing roughly even amounts of data of differing geographical sizes  such that
higher population areas are represented with finer grained grids    for both class representations 
    recent work  schulz et al         also considers irregular sized polygons  based on administrative regions like cities 

   

fit ext based t witter u ser g eolocation p rediction

dataset

features

acc

acc    

acc c

median

na

full
icf
chi
igr
loglike
geoden
ripley

     
     
     
     
     
     
     

     
     
     
     
     
     
     

     
     
     
     
     
     
     

   
   
   
   
   
   
   

table    results on the full feature set compared to that for each of a representative sample of
feature selection methodologies on na with the city based class representation  the best
numbers are shown in boldface 

we compare learners with and without feature selection  as observed previously  acc is not comparable across the two class representations  results based on the distance based measures  acc    
and median   on the other hand  are directly comparable  acc c results are not presented for the kd tree based class representation because the k d tree cells do not map cleanly onto national borders 
although we could certainly take the country in which the centroid of a given k d tree cell lies as the
country label for the entire cell  such an approach would ignore known geo political boundaries 
we consider the following methods 
baseline  because the geographical distribution of tweets is skewed towards higher population
areas  as indicated in figure     we consider a most frequent class baseline  we assign all
users to the coordinates of the most common city centre  or k d tree grid centroid  in the
training data 
placemaker  following kinsella et al          we obtain results from yahoo  placemaker    a
publicly available geolocation service  the first   k bytes  the maximum query length allowed by placemaker  from the tweets for each user are passed to placemaker as queries 
the returned city centre predictions are mapped to our collapsed city representations  for
queries without results  or with a predicted location outside north america  we back off to
the most frequent class baseline   
multinomial naive bayes  this is the same model as was used in section     
kl divergence  the previous best results over na were achieved using kl divergence and a k d
tree grid  roller et al          using a k d tree  the earths surface is partitioned into nearrectangular polygons which vary in size  but contain approximately the same number of users 
locations are represented as cells in this grid  kl divergence is then utilised to measure the
similarity between the distribution of words in a users aggregated tweets and that in each grid
cell  with the predicted location being the centroid of the most similar grid cell   
    http   developer yahoo com geo placemaker   accessed in august      
    an alternative would be to query placemaker with each tweet  and then aggregate these predictions  e g   by selecting
the majority location  to get a final user level prediction  however  kinsella et al         found the accuracy of such
an approach to be largely similar to that of the approach we use 
    we use the same settings as roller et al          a median based k d tree partition  with each partition containing
approximately      users 

   

fih an   c ook   baldwin

partition

method

city

baseline
placemaker
nb
nb igr
lr
lr igr

acc

acc    

acc c

median

     
     
     
     
     
     

     
     
     
     
     
     

     
     
     
     
     
     

    
    
   
   
   
   

table    geolocation performance using city based partition on na  results using the optimised
feature set   igr  are also shown  the best performing method for each evaluation measure and class representation is shown in boldface 

partition

method

k d tree

baseline
nb
nb igr
kl
kl igr

acc

acc    

acc c

median

     
     
     
     
     

     
     
     
     
     







    
   
   
   
   

table    geolocation performance using k d tree based partition on na  results using the optimised feature set   igr  are also shown  the best performing method for each evaluation
measure and class representation is shown in boldface 

logistic regression  we also apply logistic regression from section       as a learner  instead of
modelling all the data  we use only the igr selected features from section      while regularisation is commonly employed in logistic regression learners  we made a conscious choice
not to use it in our experiments as the implementation of the regulariser would differ across
learners and complicate the direct comparison of feature selection methods  i e  it would be
difficult to tease apart the impact of the specific regulariser from the feature selection   having said that  if the objective were to maximise the raw classifier accuracy  as distinct from
exploring the impact of different features and feature selection methods on classification accuracy  we would advocate the incorporation of a regulariser 
instead of evaluating every possible combination of model  partition and feature set  we choose
representative combinations to test the extent to which liws improve accuracy  the results on the
city based partition are shown in table    we begin by considering the baseline results  the mostfrequent class for the city based representation is los angeles  us ca    both the majority class
baseline and placemaker perform well below multinomial naive bayes  nb  and logistic regression
 lr   and have very high median distances  furthermore  when using the features selected in section      i e   nb igr and lr igr   the performance is further improved by a large margin for
both models  demonstrating that identification of liws can improve text based geolocation prediction  finally  although lr performs poorly compared to nb  lr igr still improves substantially
    new york is further divided into suburbs  such as manhattan ny    us  brooklyn ny    us  in geonames  as
an artefact of this  these suburbs are not merged into a single city 

   

fit ext based t witter u ser g eolocation p rediction

over lr  we plan to further explore the reasons for lrs poor performance in future work  overall 
nb igr performs best for the city based representation in terms of acc  acc      and median
distance 
turning to the k d tree based partition in table    we again observe the low performance of the
most frequent class baseline  i e   a grid cell near new york state   nb and kl  representative
generative and discriminative models  respectively  are evaluated using software provided by
roller et al            both approaches clearly outperform the baseline over the k d tree class
representation  furthermore  performance increases again when using the resultant feature set of
liws    demonstrating that for a variety of approaches  identification of liws can improve textbased geolocation 
overall  compared to the previously published results for the k d tree based representation  kl  
igr based feature selection on the city based partition achieves a       absolute improvement in
terms of acc      and reduces the median prediction error by    km 
from the results on the k d tree based representation  it is not clear which of kl or nb is better
for our task  in terms of acc      nb outperforms kl  but kl igr outperforms nb igr  all
differences are small  however  suggesting that the two methods are largely indistinguishable for the
user geolocation task  as to the question of which class representation should be used for user geolocation  empirically  there seems to be little to separate the two  although further experimentation
may shed more light on this issue  the city based approach is intuitive  and enables a convenient
country level mapping for coarser grained geolocation tasks  furthermore  our observation from
figure   suggests most twitter users are from cities  we therefore use the city based partition for
the remainder of this paper for consistency and ease of interpretation 
a spin off benefit of feature selection is that it leads to more compact models  which are more
efficient in terms of computational processing and memory  comparing the model based on liws
selected using igr with the full model  we find that the prediction time is faster by a factor of
roughly five 

   experiments on world
in addition to establishing comparisons on na  we further evaluate the feature selection methods
on world  this extends the evaluation from regional benchmarks to global geolocation performance  similar to na  for world we reserve   k random users for each of dev and test  and the
remainder of the users are used for training  preprocessed as described in section       here and in
all experiments over world and related datasets  we base our evaluation on the city label set 
we apply the same tuning procedure as was used over na to obtain the optimal feature set for
each feature selection method  we present results for a representative sample of the best performing
methods in figure    once again  we omit methods that are largely identical in behaviour to other
methods  namely 
  distditv   distdiskl    icf
  maxchi   chi   loglike  ig  geospread    lr
    https   github com utcompling textgrounder wiki rolleretal emnlp    
    note that after liws are selected  a small proportion of users end up with no features  these users are not geolocatable
in the case of kl  a discriminative model  we turn off feature selection for such users  and backoff to the full feature
set  so that the number of test instances is consistent in all rows 

   

fih an   c ook   baldwin

    

acc   

    
    
    
icf
geoden
ripley
igr
lr

    
    
     

   

   

   

   

   

   

   

   

   

   

   

top n  of features

figure    acc     for varying percentages of features selected using representative feature selection methods on the world dataset 

the biggest differences over figure   are      the    based methods converge in behaviour with
lr  loglike and related methods  and     lr performs marginally better than loglike  and is
thus the method we present in the graph 
despite the difference in scope and data size  the overall trend over world mirrors that for
na  in particular  geoden  igr and ripley achieve the best acc     numbers on the dev data 
although the numbers are lower than those achieved for na in figure    this is because world
has fewer tweets per user than na  as we only utilise geo tagged data   and disambiguation at the
global level also makes it a more challenging task 
the results for multinomial naive bayes with the chosen feature selection methods on world
are shown in table    again geoden        igr       and ripley       achieve the best
accuracy  although there is no clear winner  igr achieves the best acc and ripley achieves the
best acc      nevertheless  the improved city based acc and acc     numbers confirm the
general effectiveness of feature selection  on the basis of these similar results and the earlier na
results  in which igr delivers better results   we adopt igr as our default liw feature selection
method for the remainder of the paper 
in summary  the findings on the utility of feature selection in table    na  and table    world 
tell a similar story  namely that feature selection improves user geolocation accuracy  the impact
of feature selection on na is much greater than world  because world has a larger number
of classes and smaller average number of tweets per user and also per class  making it a more
challenging dataset 
   

fit ext based t witter u ser g eolocation p rediction

dataset

features

acc

acc    

acc c

median

world

full
icf
igr
lr
geoden
ripley

     
     
     
     
     
     

     
     
     
     
     
     

     
     
     
     
     
     

   
   
   
   
   
    

table    results on the full feature set compared to that of each of a representative sample of feature
selection methodologies on world using nb  the best numbers are shown in boldface 

train
g
g ng
g
g ng

test
g
g
g ng
g ng

acc
     
     
     
     

acc    
     
     
     
     

acc c
     
     
     
     

median
   
   
   
   

g
g ng

ng
ng

     
     

     
     

     
     

   
   

g
g

g small
ng small

     
     

     
     

     
     

   
    

table    the results of geolocation models trained and tested on geotagged  g  and non geotagged
 ng  tweets  and their combination 

   exploiting non geotagged tweets
most twitter based geolocation research carried out to date  eisenstein et al         wing   baldridge        has been trained only on geotagged tweets  that is tweets with known geographical
coordinates  some work  roller et al         has also incorporated non geotagged tweets from
users whose location can be inferred from geotagged tweets  clearly  if it is possible to effectively
utilise non geotagged tweets  data sparsity can be ameliorated  as we arent restricting ourselves to
training on only the approximately    of tweets with known location   but there is a clear tradeoff
in the confidence we can place in the labels associated with those tweets users  in this section  we
investigate the utility of non geotagged tweets in geolocation prediction 
for experiments in this section  and the rest of the paper  we use world ng to denote
the dataset which incorporates both the geotagged and non geotagged tweets from the users in
world  we refer to the subparts of this dataset consisting of geotagged and non geotagged tweets
as g and ng  respectively  of the    m tweets in world ng    m are geotagged and the remaining    m are non geotagged  we use the same partitioning of users into training  development 
and testing sets for world ng as for world  we compare the relative impact of ng in which
we train and test the geolocation method on g  ng  or their combination  results are presented in
table   
the first row of table   shows the results using only geotagged data  our best result from table
    in rows two and three  we show results when the data for each user in the training and test
   

fih an   c ook   baldwin

datasets  respectively  is expanded to incorporate non geotagged data  without changing the set
of users or the label for any user in either case   in both cases  for all evaluation measures  the
performance is substantially better than the benchmark  i e   the first row   this finding is in line
with cheng et al s        results that data spareness is a big issue for text based geolocation  it also
validates our hypothesis that non geotagged tweets are indicative of location  the best results are
achieved when non geotagged tweets are incorporated in both the training and testing data  shown
in row four   in this case we achieve an accuracy of        a      percentage point increase over
the benchmark using only geotagged tweets to represent a given user  moreover  our prediction
is within    km of the correct location for almost one in every two users  and the country level
accuracy reaches almost       
although research on text based geolocation has used geotagged data for evaluation  the ultimate goal of this line of research is to be able to reliably predict the locations of users for whom the
location is not known  i e   where there is only non geotagged data  because geotagged tweets are
typically sent via gps enabled devices such as smartphones  while non geotagged tweets are sent
from a wider range of devices  there could be systematic differences in the content of geotagged
and non geotagged tweets  we examine this issue in rows five and six of table    where we test
our model on only non geotagged data  in this case we know a test users gold standard location
based on their geotagged tweets  however these geotagged tweets are not used to represent the user
in the test instance  instead  the user is represented only by their non geotagged tweets  the results
here are actually better than for experiments with the same training data but tested on geotagged
tweets  i e   rows one and two of the table     this confirms that a model trained on g or g ng
indeed generalises to ng data  however  it is not clear whether this finding is due to there being
much more non geotagged than geotagged data for a given user  or whether some property of the
non geotagged data makes it easier to classify  to explore this question  we carry out the following additional experiment  first  we construct a new dataset ng small by down sampling ng to
contain the same number of features per user as g  in terms of the feature token count   to make
the comparison fairer  we constructed a second new dataset  g small  in which we exclude
test users with more g tweets than ng tweets  this guarantees that users in ng small will contain
the same number of liws as in g small  we average over five iterations of random subsampling 
and list the result in the final row of table      here we see that the results for ng small are not
as good as g small  i e   row seven   suggesting that there might be minor sub domain differences
between geotagged and non geotagged tweets  though a strong conclusion cannot be drawn without
further in depth analysis  one possible explanation is that there could be differences  e g   demographic variations  between users who only have non geotagged tweets and users who have both
non geotagged tweets and geotagged tweets  however  comparing these two sources is beyond the
scope of this paper  nonetheless  the results suggest the difference between ng and g is largely due
to the abundant data in ng  this explanation is also supported by the recent work of priedhorsky
et al         

    note that this evaluation is over exactly the same set of users in all four cases  all that changes is whether we
incorporate extra tweets for the pre existing set of users  in the training or test data 
    we remove users who only have geotagged tweets in the test data  reducing the number of users marginally from
       to       
    note that we calculated the variance over the five iterations of random subsampling  and found it to be negligible for
all evaluation measures 

   

fit ext based t witter u ser g eolocation p rediction

in summary  we have quantitatively demonstrated the impact of non geotagged tweets on geolocation prediction  and verified that models trained on geotagged data are indeed applicable to
non geotagged data  even though minor sub domain differences appear to exist  we also established that representing a user by the combination of their geotagged and non geotagged tweets
produces the best results 

   language influence on geolocation prediction
previous research on text based geolocation has primarily focused on english data  most studies
have either explicitly excluded non english data  or have been based on datasets consisting of primarily english messages  e g   through selection of tweets from predominantly english speaking
regions  eisenstein et al         cheng et al         wing   baldridge        roller et al         
however  twitter is a multilingual medium and some languages might be powerful indicators of
location  for example  if a user posts mostly japanese tweets  this could be a strong indication that
the user is based in japan  which could be used to bias the class priors for the user  in this section 
we explore the influence of language on geolocation prediction  the predominant language in a
given tweet was identified using langid py    which has been trained to recognise    languages
 lui   baldwin        
to create a dataset consisting of multilingual geotagged tweets  we extract all geotagged data
 regardless of language  from the same twitter crawl that world was based on  this multilingual dataset consists of   m tweets from    m users    m tweets are in english as in world 
while the remaining   m tweets are in other languages  figure   shows the proportion of tweets
in the fifteen most common languages in the dataset    an immediate observation is the large difference in language distribution we observe for geo tagged tweets as compared to what has been
observed over all tweets  irrespective of geotag  hong  convertino    chi        baldwin  cook 
lui  mackinlay    wang         among the higher density languages on twitter  there appears to
be a weak positive bias towards english users geotagging their tweets  and a strong negative bias
against japanese  korean and german users geotagging their tweets  we can only speculate that the
negative bias is caused by stronger concerns awareness of privacy issues in countries such as japan 
south korea  germany and austria  we explored the question of whether this bias was influenced
by the choice of twitter client by looking at the distribution of twitter clients used to post messages
in each of english  german  japanese and korean   a  overall  irrespective of whether the message
is geotagged or not   based on a  m sample of tweets from    sep        and  b  for geotagged
tweets  based on world  overall  we found there to be huge variety in the choice of client used
within a given language  with the top    clients accounting for only       of posts  depending on
the language   and significant differences in popular clients between languages  e g  keitai web
is the most popular client for japanese  web for english and german  and twitter for android
for korean   for geotagged tweets  on the other hand  there is much greater consistency  with the
three most popular clients for all languages being twitter for ios  twitter for android and
foursquare  accounting for a relatively constant two thirds of posts for each language  this is
suggestive of the fact that the choice of client is one factor in biasing the relative proportion of
    based on the simplifying assumptions that   a  every tweet contains linguistic content  and  b  all tweets are monolingual  or at least are predominantly in a single language 
    we represent languages in figure   using two letter iso       codes 

   

fih an   c ook   baldwin

   
   
   

percentage

   

   

    

    

   

              

en

es

pt

ja

nl

                                                 
id

it

ru

de

tr

fr

ms

th

ko

ar

languages

figure    the percentage of tweets in world ml written in each of the fifteen most frequent
languages in the collected twitter data  these fifteen languages account for     of the
tweets in the full dataset 

geotagged tweets in the different languages  although more research is required to fully understand
this effect 
the training  development and test data is re partitioned for the multilingual setting to stratify
on language  and the resultant dataset is referred to as world ml  again  the development and
testing sets consist of   k users each  with the remaining users in the training set as in world 
although in section   we showed that adding non geotagged data improves geolocation accuracy 
the experiments in this section are based only on geotagged data  because of the prohibitive computational cost of experimenting with a much larger dataset  note that this doesnt limit the generalisability of our results  it simply means that we have to be careful to compare them to the monolingual
results from table   based on only geotagged tweets  the first row  
we first compare geolocation performance in a multilingual setting with that in an english only
setting  a comparison that past work on geolocation has not considered  the data in world ml
is further partitioned into two subsets  e and ne  according to whether the majority of a given
users tweets are in english or non english  respectively  of the   k test users in world ml 
      are english and       are non english  one challenge with the multilingual setting of these
experiments is tokenisation  although rudimentary tokenisation of many languages such as english
and french can be accomplished using whitespace and punctuation  tokenisation is much more
challenging for languages such as japanese and chinese which do not represent word boundaries
   

fit ext based t witter u ser g eolocation p rediction

train

test

e ne
e ne
e ne
e

e ne
e
ne
e

acc

acc    

acc c

     
     
     
     

     
     
     
     

     
     
     
     

median
   
    
   
   

table    results for multilingual geolocation  training and testing on english  e  and non english
 ne  users  and their combination 

with whitespace  however  amongst the most common languages on twitter  as shown in figure
    japanese is the only language which accounts for a substantial portion of the data       
and requires a specialised tokenisation strategy  compared to english   for japanese tweets we
apply the japanese morphological segmenter mecab  with the ipa dictionary     and post correct
tokenisation errors relating to twitter specific tokens such as mentions  hashtags  and urls  e g  
in instances where mecab over segments a mention into multiple morphemes   for non japanese
tweets  we apply the same tokeniser based on regular expressions used in our previous english only
experiments 
after resolving the tokenisation issue  we apply the same igr method from section       to
select the optimised feature selection cut off  based on acc over the development data  we observe
that a much larger proportion of tokens are selected in the multilingual setting compared to the
english only experiments  for example  of the    k token types in the multilingual experiment 
   k  the top      are selected as location indicative  while for the english only case   k  the top
     location indicative words are selected from the total of   k token types 
the experimental results are shown in table      the first row gives results for training and
testing on the full dataset of both english and non english tweets  the next two rows show the
results when testing on english  e  and non english  ne  subsets of the data  the much lower
accuracy for e compared to ne indicates that english tweets are much more difficult to geolocate
than non english tweets  one reason for this is that for many non english languages  there is a
strong bias towards a small number of cities  we verify this by calculating the class entropy with
respective to a language on the training data  the class probabilities are smoothed using a simple
add  method  with            where      is the size of the class set   as shown in table    the
class entropy on english  en  data is the largest  indicating that english is prevalent across a large
number of locations  in contrast  thai  th  and turkish  tr  have much smaller entropies  suggesting
the location distributions are heavily skewed  and user geolocation over these languages will be
easier than for english 
to explore the extent to which the geolocatability of a user varies with respect to the predominant language of their tweets  we further break down the results by language in table     which
shows results for the top    most frequent languages  by number of tweets  with at least     users
in our test data  this cut off on users ensures we do not consider under represented languages 
    http   sourceforge net projects mecab 
    the english only results reported here are not the same as for the comparable experiment in table   using only
geotagged data  because the test sets consist of different users in these two cases 

   

fih an   c ook   baldwin

language

entropy

language

entropy

language

entropy

en
es
pt
ja
nl

     
     
     
     
     

id
it
ru
de
tr

     
     
     
     
     

fr
ms
th
ko
ar

     
     
     
     
     

table    geolocation class entropy for top    languages

lang 
en
es
pt
id
nl
ja
ru
tr
ar
th
all

no 
    
   
   
   
   
   
   
   
   
   

per language majority class

unified multilingual

monolingual partitioning

acc acc     acc c med 

acc acc     acc c med 

acc acc     acc c med 

     
     
     
     
     
     
     
     
     
     

     
     
     
     
     
     
     
     
     
     

          
          
         
         
     
  
     
  
         
     
 
         
     
  

     
     
     
     
     
     
     
     
     
     

     
     
     
     
     
     
     
     
     
     

          
         
         
         
     
  
     
  
         
     
 
         
     
  

     
     
     
     
     
     
     
     
     
     

     
     
     
     
     
     
     
     
     
     

     
     
     
     
     
     
     
     
     
     

   
   
   
  
  
  
   
 
  
  

           

     

          

     

     

     

     

     

     

   

   

table     geolocation performance and comparison for the top    most frequent languages in the
multilingual test data  using     language prior  i e   the city where a language is mostly
used       a unified multilingual model  i e   training and testing on multilingual data
regardless of languages   and     language partitioned monolingual models  i e   first
identify the primary language of users  train one model per language  and classify test
users with the model corresponding to the language of their tweets 

we observe that the results vary remarkably by language in the multilingual section of table
    the results are overall lowest for english  en   although the lowest country level accuracy is for
arabic  ar   we speculate that this is caused by the large number of countries that arabic is spoken
in  and the relatively small number of arabic speakers in our training data  furthermore  the citylevel accuracy is better than     for indonesian  id   japanese  ja   russian  ru   turkish  tr  and
arabic  ar   the regions in which these languages are commonly spoken are more geographicallyrestricted than for english  suggesting that geolocation accuracy on languages with smaller geographic footprints will tend to be higher than for languages which are widely used throughout a
larger geographical area  this finding agrees with the recent work of priedhorsky et al          and
further underlines the power of language information in predicting locations  the best city level
accuracy of       is observed for turkish  one of the languages with the lowest city level entropy  
manually inspecting the outputs  we find that this is because our model predicts the city istanbul for
all turkish users  and a large proportion of turkish tweets come from this city 
   

fit ext based t witter u ser g eolocation p rediction

based on this finding  we further consider a language based benchmark which predicts the most
frequent city given the predominant language of a users tweets  denoted as per language majority
class   we also observe the performance gap between the multilingual model on english  the second
row of table    and an english only model  the bottom row in table     these results show that if
the target data is known to be written in a single language then a monolingual model outperforms
a multilingual one  it also suggests an alternative approach for multilingual geolocation prediction 
rather than training and predicting on multilingual data  e ne   we can train and evaluate models
on language specific data  motivated by this observation  we also apply a monolingual partitioned
model for users of a particular language based on langid py  i e   language partitions   e g  
selecting all japanese users in the training data  and only applying the japanese specific model to
japanese users in the test data  this is denoted as monolingual partitioning in table     and is
contrasted with the simple approach of a combined model for all languages and users  unified
multilingual  
by comparing the per language majority class with the unified multilingual model  we find
that the unified model performs better overall  with the exception of thai  th  and dutch  nl   both
of which are associated with a very small number of cities  and one city which is much larger than
the others  bangkok  th and amsterdam  nl  respectively   because of the relatively poor results
for this benchmark method on languages such as english  en  and spanish  es  which are frequent
on twitter  and its relatively poor overall performance  the per language majority class is not an
appropriate method for this task  nevertheless  when using a monolingual partitioning model  the
results are far superior  and the partitioning effect of language can be seen  this suggests that
modelling each language independently can improve geolocation performance 
in summary  this series of experiments has shown the influence of language on geolocation prediction  among the top    languages found on twitter  english is the most difficult to perform user
geolocation over  as english is the most global language  despite language variance  multilingual
geolocation prediction is certainly feasible  although the best way to leverage language for geolocation prediction is by training language partitioned monolingual models and geolocating users based
on their primary language 

   incorporating user meta data

the metadata accompanying tweets is a valuable source of geographical information beyond that
available in tweets  in this section  we explore incorporating metadata information into our textbased geolocation system  we begin by selecting four metadata fields that could potentially provide
insights into the location of a user  and first evaluate models trained on each of these sources of
information  we then consider a number of ways to incorporate information from this metadata
with our best text based method developed in section    as discussed in section    language has a
strong influence on geolocation prediction  and english posting users are the hardest to geolocate 
as such  we experiment only on english data  i e   world ng  for the remainder of this paper 
   

fih an   c ook   baldwin

data
training
test

loc

tz

desc

     
     

     
     

     
     

table     the proportion of users with non empty metadata fields in world ng
    unlock the potential of user declared metadata
we choose the following four user supplied metadata fields for our study  location  loc   timezone
 tz   description  desc   and the users real name  rname     in contrast to rich social network
information which is much more expensive to extract  these metadata fields are included in the
json object that is provided by the twitter streaming api  i e   we can extract this metadata at no
extra crawling cost  this information  however  is dynamic  i e   users can change their profiles 
including the metadata of interest to us  by aggregating the extracted tweet level metadata for each
user  we can calculate the ratio of users that change each metadata field      of users changed their
desc field during the approximately five months over which our dataset was collected  during this
same time period  for each of the other fields considered  less than    of users updated their data 
given the relatively small number of profile updates  we ignore the influence of these changes  and
use the most frequent value for each metadata field for each user in our experiments 
all of this user supplied metadata can be imprecise or inaccurate  because the user is free to
enter whatever textual information they choose  for example  some loc fields are not accurate
descriptions of geographical locations  e g   the best place in the universe   moreover  although
some loc fields are canonical renderings of a users true location  e g   boston  ma  usa   a large
number of abbreviations and non standard forms are also observed  e g   mel for melbourne  au  
cheng et al         find that only a small proportion of location fields in their us based dataset are
canonical locations  i e   of the form city  state   nevertheless  these non standard and inaccurate
location fields might still carry information about location  kinsella et al          similarly to how
the text of tweets can indicate location without explicitly mentioning place names 
these metadata fields also differ with respect to the explicitness of the location information they
encode  for instance  while loc and tz can give direct location information  desc might contain
references to location  e g   a geek and a lisp developer in bangalore  although rname does not
directly encode location there are regional preferences for names  bergsma  dredze  van durme 
wilson    yarowsky         e g   petrov might be more common in russia  and the name hasegawa
might be more common in japan  finally  for all of the tweets that we consider  the text field  i e   the
content of the tweet itself  and rname are always present  but loc  tz  and desc can be missing
if a user has chosen to not supply this information  the proportion of non empty metadata fields for
loc   tz and desc for users in world ng are listed in table    
    results of metadata based classifiers
because of the variable reliability and explicitness of the selected metadata  we incorporate these
fields into our statistical geolocation model in a similar manner to the message text  in prelimi    the user supplied real name could be any name  i e   it is not necessarily the users actual name  but is a different
field from the users screen name 

   

fit ext based t witter u ser g eolocation p rediction

classifier
loc
tz
desc
rname
baseline
text

acc

acc    

acc c

median

     
     
     
     

     
     
     
     

     
     
     
     

  
    
    
    

     
     

     
     

     
     

    
   

table     the performance of nb classifiers based on individual metadata fields  as well as a baseline  and the text only classifier with igr feature selection 

nary experiments  we considered bag of words features for the metadata fields  as well as bag ofcharacter n gram features for n                 we found character   grams to perform best  and
report results using these features here   a bag of character   grams represents the frequency of
each four character sequence including a start and end symbol   the geolocation performance of a
classifier trained on features from each metadata field in isolation  as well as the performance of a
most frequent city baseline  baseline  and our best purely text based classifier  text  replicated
from table     is shown in table    
the classifier based on each metadata field outperforms the baseline in terms of acc  acc     
and median error distance  this suggests these metadata fields do indeed encode geographicallyidentifying information  though some classifiers are less competitive than text  notably  despite
the potential for noise in the user supplied location fields  this classifier  loc  achieves even better
performance than the purely text based method  reaching a city level accuracy of over      predicting a location within    km of the true location for over half of the users  this suggests loc
contains valuable information  even though loc fields are noisy  cheng et al          and are not
easily captured by off the shelf geolocation tools  hecht et al          manual analysis suggests
many vernacular place names are captured in the statistical modelling  such as kiladelphia and
philly used to represent philadelphia  the utility of metadata fields is also confirmed by the recent
work of priedhorsky et al         
    ensemble learning on text based classifiers
to further analyse the behaviour of the four metadata classifiers  we consider the pairwise city level
prediction agreement between them  cohens kappa  carletta        is a conventional metric to
evaluate inter annotator agreement for categorical items  such as the predicted cities in our case  
larger kappa values indicate higher pairwise agreement  the double fault measure  giacinto  
roli        incorporates gold standard information  and is equal to the proportion of test cases for
which both classifiers make a false prediction  this measure offers the empirical lowest error bound
for the pairwise ensemble classifier performance 
    although we could certainly also consider character n grams for the text based classifier  we opted for a bag ofwords representation because it explicitly captures the liws that we believe are especially important for geolocation 
there could also be location indicative character n grams  the exploration of which we leave for future work 

   

fih an   c ook   baldwin

text

     

     

     

     

     

loc

     

     

     

     

     

tz

     

     

     

     

     

desc

     

     

     

     

     

rname

table     pairwise correlation of the base classifiers using cohens kappa  bottom left  in light
grey  higher numbers indicate greater prediction similarity  and the double fault measure
 top right  in white  lower numbers indicate greater prediction similarity  

pairwise scores for cohens kappa and the double fault measure are shown in table     the
kappa scores  bottom left of table     are very low  indicating that there is little agreement between
the classifiers  because the classifiers achieve better than baseline performance  but also give quite
different outputs  it might be possible to combine the classifiers to achieve better performance 
the double fault results  top right  further suggest that improved accuracy could be obtained by
combining classifiers 
we combine the individual classifiers using meta classification  we first adopt a feature concatenation strategy that incrementally combines the feature vectors of text  loc  tz  desc and
rname   we also consider stacked generalisation  wolpert         referred to simply as stacking 
in which the outputs from the base classifiers  and the true city level locations  are used to train a
second classifier which produces the final output  the base classifiers  and the second classifier 
are referred to as the l  and l  classifiers  respectively  in conventional applications of stacking 
homogeneous training data is used to train heterogeneous l  classifiers  in our case  however  we
train homogeneous l  multinomial bayes models on heterogeneous data  i e   different types of
data such as text  loc  and tz   we consider logistic regression  fan  chang  hsieh  wang   
lin        and multinomial bayes as the l  classifier 
we carry out    fold cross validation on the training users to obtain the l   final  classifier
results  a standard procedure for stacking experiments  we use stratified sampling when partitioning
the data because the number of users in different cities varies remarkably  and a simple random
sample could have a bias towards bigger cities  the ensemble learning results are tabulated in table
   
the combination of text and loc is an improvement over loc  i e   our best results so far  
however  using feature concatenation and multinomial naive bayes stacking  accuracy generally
drops as metadata feature sets that perform relatively poorly in isolation  i e   tz  desc  rname 
are incorporated  on the other hand  using logistic regression stacking  we see small increases in
accuracy as features that perform less well in isolation are incorporated  though desc and rname
are moderately useful  as shown in table      these fields contribute little to the strong ensembles
 i e   text  loc and tz   the best model  using logistic regression stacking and all features 
assigns users to the correct city in almost     of the test cases  and has a median error of just
 km  moreover  with this approach the country level accuracy reaches almost      indicating the
effectiveness of our method for this coarse grained geolocation task 
   

fit ext based t witter u ser g eolocation p rediction

feature concatenation
acc
acc    
     
     
     
     
     
     
     
     

  
  
  
  

features
text   loc
     tz
     desc
     rname

acc c
     
     
     
     

median
  
  
   
   

  
  
  
  

multinomial bayes stacking
features
acc
acc     acc c
text   loc
     
     
     
     tz
     
     
     
     desc
     
     
     
     rname      
     
     

median
  
  
  
  

  
  
  
  

logistic regression stacking
features
acc
acc     acc c
text   loc
     
     
     
     tz
     
     
     
     desc
     
     
     
     rname      
     
     

median
  
 
 
 

table     the performance of classifiers combining information from text and metadata using feature concatenation  top   multinomial bayes stacking  middle   and logistic regression
stacking  bottom   features such as      tz refer to the features used in row    in
combination with tz 

it is interesting to observe that  while we found nb to outperform lr as a standalone classifier
in section      as an l  classifier  lr clearly outperforms nb  the reason for this is almost certainly the fact that we use a much smaller feature set relative to the number of training instances
in our stacking experiments  under which circumstances  discriminative models tend to outperform
generative models  ng   jordan        

    temporal influence
in addition to the held out english test data in world ng  we also developed a new geotagged
test dataset to measure the impact of time on model generalisation  the training and test data in
world ng are time homogeneous as they are randomly partitioned based on data collected in
the same period  in contrast  the new test dataset  live  is much newer  collected more than  
year later than world ng  given that twitter users and topics change rapidly  a key question is
whether the statistical model learned from the old training data is still effective over the new
test data  this question has implications for the maintenance and retraining of geolocation models
over time  in the experiments in this section we train on world ng and test on our new dataset 
the live data was collected over    hours from   mar       to   mar        based on geotagged tweets from users whose declared language was english  recent status updates  up to     
were crawled for each user  and langid py was applied to the data to remove any remnant nonenglish messages  in addition to filtering users with less than    geotagged tweets for the test data
as in world ng  we further exclude users with less than     of geotagged tweets from one
   

fih an   c ook   baldwin

features
   text
   loc
   tz
            

acc
     
     
     
     

features
   text
   loc
   tz
            

acc
     
     
     
     

world ng
acc     acc c
     
     
     
     
     
     
     
     
live
acc    
     
     
     
     

acc c
     
     
     
     

median
   
  
    
 

median
   
   
    
  

table     generalisation comparison between the time homogeneous world ng and timeheterogeneous live               denotes stacking over text  loc and tz  

city  this is because if a users geotagged tweets are spread across different locations  it is less
credible to adopt the users most frequent location as their true primary location in evaluation  a
post check on the world ng test data shows that       out of   k users satisfy this requirement
on geographical coherence  and that we arent unnecessarily biasing the data in live in applying
this criterion  finally  all status updates are aggregated at the user level  as in world ng  after
filtering    k users were obtained  forming the final live dataset 
we use only text  loc and tz in this section  as they require less computation and achieve
accuracy comparable to our best results  as shown in table     the temporal factor impact on
geolocation prediction model generalisation is revealed in the accuracy for world ng and live
shown in table     acc and acc     numbers in the stacked model                drop by
approximately   and   percentage points  respectively  on live as compared to world ng  the
median prediction error distance also increases moderately from  km to   km  by decomposing
the stacked models and evaluating against the base classifiers  we find the accuracy declines are
primarily caused by accuracy drops in the loc classifier on the new live data  of approximately
   in acc and    in acc      this could be viewed as a type of over fitting  in that the stacked
classifier is relying too heavily on the predictions from the loc base classifier  the tz classifier
performs relatively constantly in terms of accuracy  although the median error increases slightly 
the text classifier is remarkably robust  with all numbers except for acc improving marginally 
we further investigate the poor loc classifier generalisation on live  first  we down sample
live to   k users  the same size as world ng  and then compare the per city prediction numbers on the two datasets using only the loc classifier  we find two factors jointly cause the accuracy
decrease on live      the composition of test users  and     the decline in per city recall  for instance     test users are from london  gb in world ng  this number sharply increases to     in
live  meaning that the influence of london  gb test users on the overall accuracy in live is almost
doubled  furthermore  the recall  the proportion of users from a given location who are correctly
predicted as being from that location  for london  gb drops from       in world ng to
      in live  we observe that the proportion of empty loc fields among london  gb test users
jumps from      world ng  to      live   this reduces the utility of the loc data in live
   

fit ext based t witter u ser g eolocation p rediction

rank

cities in live

 
 
 
 
 
 
 
 
 
  

los angeles  us
kuala lumpur  my
london  gb
jakarta  id
anaheim  us
singapore  sg
fort worth  us
chicago  us
pittsburgh  us
san antonio  us

live users

live recall

world ng users

world ng recall

   
   
   
   
  
  
  
  
  
  

     
     
     
     
     
     
     
     
     
     

  
  
  
  
  
   
  
   
  
  

     
     
     
     
     
     
     
     
     
     

table     the number of test users  and recall using
live  compared with world ng 

loc  

by city  for the top    largest cities in

and explains why the per city recall drops  all test users with an empty loc field are assigned to
the city with highest class prior in the model  i e   los angeles  us   overall  the ratios of empty
loc fields in world ng test data and live are       and        respectively  suggesting that
user declared locations in live carry much less geospatial information than in world ng  we
show other comparisons for the top    cities in terms of test users in table       as the accuracy
of more highly represented cities has a greater impact on overall results than that of smaller cities 
like london  gb  most cities shown in table    experience lower recall scores for live  and many
of them have more test users in live than in world ng  nevertheless  some cities have higher
recall and more test users in live  e g   los angeles  us and anaheim  us in table     the overall
numbers are  of course  determined by aggregated performance over all cities  to provide some insight        of cities in world ng have more than     in recall  but the number is only      
in live 
while an important base classifier in the stacked model  the loc accuracy numbers are most
influenced by temporal changes  whether it is because of an increased reluctance to supply a userdeclared location  although admittedly for users who geotag their tweets   or primarily due to variance in user proportions from different cities in the sampled stream  either way  a periodically retrained loc classifier would  no doubt  go some way towards remedying the temporal gap  overall 
the numbers suggest that time homogeneous data  world ng  is easier to classify than timeheterogeneous data  live   however  training on old data and testing on new data has been
shown to be empirically viable for the text and tz base classifiers in particular  this result also
validates efforts to optimise text based user geolocation classification accuracy  recently  similar
results on tweet level geolocation prediction were observed by priedhorsky et al          supporting
the claim that the accuracy of geolocation prediction suffers from diachronic mismatches between
the training and test data 

    we observe that the city proportions changed drastically between world ng and live  the reasons for this are
unclear  and we can only speculate that it is due to significant shifts in microblogging usage in different locations
around the world 

   

fih an   c ook   baldwin

    user tweeting behaviour
having improved and extended text based geolocation prediction  we now shift our focus to user
geolocatability  if a user wishes to keep their geolocation private  they can simply disable public
access of their tweets and metadata  however  if users choose to share their  non geotagged  tweets 
are there different tweeting behaviours which will make them more susceptible to geolocation privacy attacks  to investigate this question  in this section  we discuss the impact of user behaviour
on geolocation accuracy relative to predictions over live based on the stacking model from section
     
as an obvious first rule of thumb  geotagged tweets should be avoided  because they provide
immediate access to a users geographical footprint  e g   favourite bars  or their office address 
second  as an immediate implication of our finding that location metadata is a strong predictor of
geolocation  section       if a user wants to avoid privacy attacks  they should avoid presenting
location metadata  in effect disabling the loc base classifier in our stacked classifier  third  the text
of a users posts can be used to geolocate the user  at approximately     acc  from table      to
investigate the impact of the volume of tweets on user geolocatability  we perform a breakdown
of results over live across two dimensions      the number of liws  to investigate whether the
sheer volume of tweets from a user makes them more geolocatable  and     the source of geospatial
information which we exploit in the geolocation model  we evaluate these questions in figure  
in four feature combination settings  relative to the      tweet text based classifier      tweet textbased classifier with gazetteer names removed        metadata stacking using loc and tz  invariant
to tweet number changes   and     the stacking of text  loc and tz for all users  in each case 
we partition the data into    partitions of    of users each  ranked by the total number of liws
contained in the combined posts from that user  in addition to the acc for each user partition  we
also indicate the average number of liws per user in each partition  as shown in the second y axis 
on the right side of the graph  
overall  the more liws are contained in a users tweets  the higher the acc for text based methods  when gazetted terms are removed from the tweets  acc drops by a large margin  this suggests
gazetted terms play a crucial role in user geolocation  metadata also contributes substantially to accuracy  improving the text based accuracy consistently  moreover  if a user tweets a lot  the acc of
the tweet text based approach is comparable to our best model  even without access to the metadata
 as shown in the top right corner of the graph   as an overall recommendation  users who wish to
obfuscate their location should leave the metadata fields blank and avoid mentioning liws  e g  
gazetted terms and dialectal words  in their tweets  this will make it very difficult for our best geolocation models to infer their location correctly  as demonstrated to the bottom left of the graph  
a similar conclusion on user geolocatability was recently obtained by priedhorsky et al          to
help privacy conscious twitter users to avoid being geolocated by their tweets  we have made the
list of liws publicly available   

    our analysis is limited to behaviours that could easily be adopted by many users  given that our system predicts the
most likely city from a fixed set for a given user  one simple way to avoid being geolocated is to move far away from
any of these cities  however  it seems unlikely that this strategy would be widely adopted 
    our gazetteer is based on the ascii city names in the geonames data 
    http   www csse unimelb edu au tim etc liw jair tgz

   

fit ext based t witter u ser g eolocation p rediction

   
   
   
   
number of location indicative words

   

text
text without gazetteers
metadata stacking  loc  tz 
stacking  text  loc  tz 

accuracy

   
   
   
   
number of location indicative words  liws 

   
   

   
   
location indicative word partitions

   

 

   

    

figure    the impact of the use of liws on geolocation accuracy  users are sorted by the number
of liws in their tweets  and are partitioned into    bins  metadata includes loc and tz 

    prediction confidence
in the task setup to date  we have forced our models to geolocate all users  in practice  however 
many users dont explicitly mention any geolocating words in their posts  making the task nigh on
impossible even for a human oracle  an alternative approach would be to predict a user geolocation
only when the model is confident of its prediction  here  we consider a range of variables that
potentially indicate the prediction confidence 
absolute probability  ap   only consider predictions with probability above a specified threshold 
prediction coherence  pc   we hypothesise that for reliable predictions  the top ranked locations
will tend to be geographically close  in this preliminary exploration of coherence  we formulate pc as the sum of the reciprocal ranks of the predictions corresponding to the second level
administrative region in our class representation  i e   state or province  of the top ranking
prediction  calculated over the top    predictions    for example  suppose the top    secondlevel predictions were in the following states in the us  us tx  us fl  us tx  us tx 
us ca  us tx  us tx  us fl  us ca  us ny  the top ranking state level prediction is
therefore us tx  which also occurs at ranks         and    for different cities in texas   in
this case  pc would be                         
probability ratio  pr   if the model is confident in its prediction  the first prediction will tend to
be much more probable than other predictions  we formulate this intuition as pr  the ratio of
the probability of the first and second most probable predictions 
    it could be measured by the average distance between top predictions as well 

   

fih an   c ook   baldwin

   

acc    

   

   
absolute probability  ap 
prediction coherence  pc 
probability ratio  pr 
feature number  fn 
feature weight  fw 

   

                                                 
recall

figure    acc     for classification of the top n  most confident predictions for each measure
of text based prediction confidence on na

feature number  fn   we take the number of features found in a users posts as the prediction
accuracy  the intuition here is that a geolocation prediction based on more features is more
reliable than a prediction based on fewer features 
feature weight  fw   similar to fn  but in this case we use the sum of igr of all features  rather
than just the number of features 
we investigate these variables on both na and live results  in particular  we only evaluate them using the text based model  as we experiment only with text based user geolocation in
this section  nevertheless  exploration of other metadata classifiers is also possible  we sort the
predictions by confidence  independently for each measure of prediction confidence  and measure
acc     among the top n  of predictions for the following values of n                         akin
to a precisionrecall curve  as shown in figures   and    results on acc show a very similar trend 
and are omitted from the paper 
the naive ap method is least reliable with  surprisingly  accuracy increasing as ap decreases
in both figures  it appears that the raw probabilities are not an accurate reflection of prediction
confidence  we find this is because a larger ap usually indicates a user has few liw features  and
the model often geolocates the user to the city with the highest class prior  in comparison  pr 
which focuses on relative  as opposed to raw  probabilities  performs much better  with higher
pr generally corresponding to higher accuracy  in addition  pc shows different trends on the two
figures  it achieves comparable performance with pr on na  however it is incapable of estimating
the global prediction confidence  this is largely because world level pc numbers are often very
small and less discriminating than the regional pc numbers  reducing the utility of the geographic
proximity of the top predictions  furthermore  fn and fw display similar overall trends to pr  but
dont outperform pr 
   

fit ext based t witter u ser g eolocation p rediction

acc    

   

   

   
absolute probability  ap 
prediction coherence  pc 
probability ratio  pr 
feature number  fn 
feature weight  fw 

   

                                                 
recall

figure    acc     for classification of the top n  most confident predictions for each measure
of text based prediction confidence on live

these experiments suggest that there is indeed a trade off between coverage and accuracy  which
could be further exploited to obtain higher accuracy predictions in applications that do not require
all the data to be classified  pr  as well as fn and fw  are fairly effective indicators of predictive accuracy  a further extension on this line of research would be to investigate the prediction
confidence per city  e g   are users from new york  us more predictable than users from boston 
us 

    future work
this research could be expanded in a number of directions  first  hierarchical classification models  mahmud et al         ahmed  hong    smola        are becoming increasingly popular  and
could be combined with our stacked model  although explicit social network data  e g   followers 
can be non trivial to retrieve  user interactions can be reconstructed from the content of tweets  e g  
replies  retweets and user mentions  jurgens         this implicit network information could be
combined with our current text based geolocation methods to further improve geolocation accuracy  additionally  we hypothesise that text based geolocation prediction is a challenging task for
humans  and that our method is achieving or surpassing the accuracy levels of a human  it would be
interesting to test this hypothesis  e g   using crowdsourcing methods 
recently  priedhorsky et al         proposed evaluating message level geolocation  they use
gaussian mixture models to characterise n gram probability distributions and evaluate the geolocation prediction accuracy using probabilistic metrics  their conclusions strongly agree with our
findings  although our task setting is at the user level and the evaluation metrics are different  in the
future  we plan to adapt our methods to tweet level geolocation and carry out a systematic evaluation
with their probabilistic analysis of geolocation 
   

fih an   c ook   baldwin

    summary
in this paper  we have investigated a series of key issues relating to text based geolocation prediction
for twitter users  we applied a number of feature selection methods to identify location indicative
words  liws   and demonstrated the effectiveness of feature selection on both regional  na  and
global  world  datasets  we then extended our study to analyse the impact of non geotagged data 
the influence of language and the complementary geographical information in the user metadata 
we further evaluated our model on a time heterogeneous dataset to assess the models sensitivity
to temporal change  moreover  we discussed how users tweeting behaviour affects geolocation
prediction  and drew conclusions on how users make themselves less easily geolocatable  finally 
we explored various indicators to estimate prediction confidence  in terms of the balance between
prediction coverage and accuracy 
a number of conclusions can be drawn from this study  corresponding to the different sections of
the paper  we believe these findings contribute to a deeper understanding of text based geolocation
prediction  and further shape the design of practical solutions to the problem 
 we demonstrate that explicit selection of location indicative words improves geolocation prediction accuracy  as compared to using the full feature set 
 non geotagged tweets  from users whose location is known  boost the prediction accuracy
substantially in both training and testing  we also demonstrate that modeling on geotagged
data and inferencing on non geotagged data is indeed feasible  this is largely because of the
similarity between geotagged data and non geotagged data  although minor differences are
observed between geotagged and non geotagged tweets 
 modelling and inference on multilingual data is viable and easier than on monolingual english data  this is because tweet language strongly affects the prediction accuracy  due to the
uneven geographical distribution of languages in tweets  users of geographically diverse languages  e g   english and spanish  are much harder to geolocate than users of geographicallyfocused languages  e g   japanese or dutch   although trivially determining locations based
on the language in tweets is fine for geographically focused languages  it is insufficient for
the majority of users who post tweets using geographically diverse languages  by integrating
language information in different ways  we found training a range of monolingual models
based on language identification  and predicting location using a model based on the users
primary language  achieves better results than a monolithic multilingual model 
 user declared metadata  though noisy and unstructured  offers complementary location indicative information to what is contained in tweets  by combining tweet and metadata information through stacking  the best global geolocation results are attained  over     of english
users can be correctly predicted at the city level  with a median error distance of just  km 
 results on time heterogeneous evaluation suggest applying a model trained on old data to
predict new data is generally feasible  although the user declared location field  loc  is
sensitive to temporal change  classifiers based on the tweet content  text  and user timezone
 tz  generalise reasonably well across time 
 our pilot study on user geolocatability led to the following recommendations to preserve
geolocation privacy      reduce the usage of location indicative words  particularly gazetted
   

fit ext based t witter u ser g eolocation p rediction

terms  and     delete location sensitive metadata  e g   user declared location and timezone
metadata  
 probability ratio  which measures the ratio of the probability of the top prediction with that
of the second prediction  can be used to estimate prediction confidence  and select only users
where the system prediction is more accurate  e g   for downstream applications that require
more reliable geolocation predictions and where exhaustive user geolocation is not required 

acknowledgments
the authors wish to thank stephen roller and jason baldridge making their data and tools available
to replicate their na experiments 
nicta is funded by the australian government as represented by department of broadband 
communication and digital economy  and the australian research council through the ict centre
of excellence programme 

references
ahmed  a   hong  l     smola  a  j          hierarchical geographical modeling of user locations
from social media posts  in proceedings of the   nd international conference on world wide
web  www     pp        rio de janeiro  brazil 
amitay  e   harel  n   sivan  r     soffer  a          web a where  geotagging web content 
in proceedings of the   th annual international acm sigir conference on research and
development in information retrieval  sigir        pp          sheffield  uk 
backstrom  l   kleinberg  j   kumar  r     novak  j          spatial variation in search engine
queries  in proceeding of the   th international conference on world wide web  www    
pp          beijing  china 
backstrom  l   sun  e     marlow  c          find me if you can  improving geographical prediction with social and spatial proximity  in proceedings of the   th international conference
on world wide web  pp        raleigh  usa 
baldwin  t   cook  p   lui  m   mackinlay  a     wang  l          how noisy social media text 
how diffrnt social media sources   in proceedings of the  th international joint conference
on natural language processing  ijcnlp        pp          nagoya  japan 
bennett  p  n   radlinski  f   white  r  w     yilmaz  e          inferring and using location
metadata to personalize web search  in proceedings of the   th international acm sigir
conference on research and development in information retrieval  sigir     pp         
beijing  china 
bentley  j  l          multidimensional binary search trees used for associative searching  communication of the acm                
bergsma  s   dredze  m   van durme  b   wilson  t     yarowsky  d          broadly improving
user classification via communication based name and location clustering on twitter  in
proceedings of the      conference of the north american chapter of the association for
   

fih an   c ook   baldwin

computational linguistics  human language technologies  naacl hlt        pp      
      atlanta  usa 
bilhaut  f   charnois  t   enjalbert  p     mathet  y          geographic reference analysis for geographic document querying  in proceedings of the hlt naacl      workshop on analysis
of geographic references   volume    pp        edmonton  canada 
blei  d  m   ng  a  y     jordan  m  i          latent dirichlet allocation  journal of machine
learning research             
buyukokkten  o   cho  j   garcia molina  h   gravano  l     shivakumar  n          exploiting
geographical location information of web pages  in acm sigmod workshop on the web
and databases  webdb     pp        philadelphia  usa 
carletta  j          assessing agreement on classification tasks  the kappa statistic  computational
linguistics                
chandra  s   khan  l     muhaya  f          estimating twitter user location using social
interactionsa content based approach  in      ieee third international conference on
privacy  security  risk and trust  passat  and      ieee third international conference
on social computing  socialcom   pp          boston  usa 
chang  h  w   lee  d   m   e     lee  j           phillies tweeting from philly  predicting twitter
user locations with spatial word usage  in ieee acm international conference on advances
in social networks analysis and mining  asonam   pp          istanbul  turkey 
cheng  z   caverlee  j     lee  k          you are where you tweet  a content based approach
to geo locating twitter users  in proceedings of the   th acm international conference on
information and knowledge management  pp          toronto  canada 
cho  e   myers  s  a     leskovec  j          friendship and mobility  user movement in locationbased social networks  in proceedings of the   th acm sigkdd international conference
on knowledge discovery and data mining  pp            san diego  usa 
crandall  d  j   backstrom  l   huttenlocher  d     kleinberg  j          mapping the worlds
photos  in proceedings of the   th international conference on world wide web  www    
pp          madrid  spain 
dalvi  n   kumar  r     pang  b          object matching in tweets with spatial models  in
proceedings of the fifth acm international conference on web search and data mining
 wsdm        pp        seattle  usa 
ding  j   gravano  l     shivakumar  n          computing geographical scopes of web resources 
in proceedings of the   th international conference on very large data bases  vldb    
pp          cairo  egypt 
dunning  t          accurate methods for the statistics of surprise and coincidence  computational
linguistics              
eisenstein  j   oconnor  b   smith  n  a     xing  e  p          a latent variable model for
geographic lexical variation  in proceedings of the      conference on empirical methods
in natural language processing  emnlp        pp            cambridge  usa 
fan  r  e   chang  k  w   hsieh  c  j   wang  x  r     lin  c  j          liblinear  a library
for large linear classification  journal of machine learning research              
   

fit ext based t witter u ser g eolocation p rediction

gelernter  j     mushegian  n          geo parsing messages from microtext  transactions in gis 
              
giacinto  g     roli  f          design of effective neural network ensembles for image classification purposes  image and vision computing                  
gouws  s   metzler  d   cai  c     hovy  e          contextual bearing on linguistic variation in
social media  in proceedings of the workshop on languages in social media  lsm     pp 
      portland  usa 
guyon  i     elisseeff  a          an introduction to variable and feature selection  journal of
machine learning research              
han  b   cook  p     baldwin  t       a   automatically constructing a normalisation dictionary
for microblogs  in proceedings of the joint conference on empirical methods in natural
language processing and computational natural language learning       emnlp conll
       pp          jeju  korea 
han  b   cook  p     baldwin  t       b   geolocation prediction in social media data by finding
location indicative words  in proceedings of the   th international conference on computational linguistics  pp            mumbai  india 
han  b   cook  p     baldwin  t          a stacking based approach to twitter user geolocation
prediction  in proceedings of the   st annual meeting of the association for computational
linguistics  system demonstrations  pp       sofia  bulgaria 
hauff  c     houben  g  j          geo location estimation of flickr images  social web based
enrichment  in proceedings of the   th european conference on advances in information
retrieval  pp        barcelona  spain 
hecht  b   hong  l   suh  b     chi  e  h          tweets from justin biebers heart  the dynamics
of the location field in user profiles  in proceedings of the sigchi conference on human
factors in computing systems  pp          vancouver  canada 
hong  l   ahmed  a   gurumurthy  s   smola  a  j     tsioutsiouliklis  k          discovering
geographical topics in the twitter stream  in proceedings of the   st international conference
on world wide web  www        pp          lyon  france 
hong  l   convertino  g     chi  e  h          language matters in twitter  a large scale study 
in proceedings of the  th international conference on weblogs and social media  icwsm
       pp          barcelona  spain 
jurgens  d          thats what friends are for  inferring location in online social media platforms
based on social relationships  in proceedings of the  th international conference on weblogs
and social media  icwsm        pp          boston  usa 
kinsella  s   murdock  v     ohare  n          im eating a sandwich in glasgow  modeling
locations with tweets  in proceedings of the  rd international workshop on search and mining
user generated contents  pp        glasgow  uk 
laere  o  v   quinn  j   schockaert  s     dhoedt  b          spatially aware term selection for
geotagging  ieee transactions on knowledge and data engineering                
laere  o  v   schockaert  s     dhoedt  b          georeferencing flickr resources based on textual
meta data  information sciences            
   

fih an   c ook   baldwin

leidner  j  l     lieberman  m  d          detecting geographical references in the form of place
names and associated spatial natural language  sigspatial special            
li  r   wang  s     chang  k  c  c          multiple location profiling for users and relationships
from social network and content  vldb                  
li  w   serdyukov  p   de vries  a  p   eickhoff  c     larson  m          the where in the tweet 
in proceedings of the   th acm international conference on information and knowledge
management  cikm        pp            glasgow  uk 
lieberman  m  d     lin  j          you are where you edit  locating wikipedia contributors
through edit histories  in proceedings of the  rd international conference on weblogs and
social media  icwsm        pp          san jose  usa 
lui  m     baldwin  t          langid py  an off the shelf language identification tool  in proceedings of the   th annual meeting of the association for computational linguistics  acl
      demo session  pp        jeju  korea 
mahmud  j   nichols  j     drews  c          where is this tweet from  inferring home locations
of twitter users  in proceedings of the  th international conference on weblogs and social
media  icwsm        pp          dublin  ireland 
mao  h   shuai  x     kapadia  a          loose tweets  an analysis of privacy leaks on twitter 
in proceedings of the   th annual acm workshop on privacy in the electronic society  pp 
     chicago  usa 
nakatani  s          language detection library for java  http   code google com p 
language detection  
ng  a  y     jordan  m  i          on discriminative vs  generative classifiers  a comparison of
logistic regression and naive bayes  in advances in neural information processing systems
    nips      pp          whistler  canada 
nocedal  j          updating quasi newton matrices with limited storage  mathematics of computation                  
nunez redo  m   daz  l   gil  j   gonzalez  d     huerta  j          discovery and integration of
web     content into geospatial information structures  a use case in wild fire monitoring  in
proceedings of the  th international conference on availability  reliability and security  pp 
      vienna  austria 
oconnor  b   krieger  m     ahn  d          tweetmotif  exploratory search and topic summarization for twitter  in proceedings of fourth international aaai conference on weblogs and
social media  pp          washington  d c   usa 
ohare  n     murdock  v          modeling locations with social media  information retrieval 
            
osullivan  d     unwin  d  j          point pattern analysis  pp          john wiley   sons 
inc 
padmanabhan  v  n     subramanian  l          an investigation of geographic mapping techniques for internet hosts  in proceedings of the      conference on applications  technologies  architectures  and protocols for computer communications  sigcomm     pp 
        san diego  usa 
   

fit ext based t witter u ser g eolocation p rediction

pontes  t   vasconcelos  m   almeida  j   kumaraguru  p     almeida  v          we know where
you live  privacy characterization of foursquare behavior  in  th international workshop on
location based social networks  lbsn        pittsburgh  usa 
priedhorsky  r   culotta  a     valle  s  y  d          inferring the origin locations of tweets with
quantitative confidence  in proceedings of the   th acm conference on computer supported
cooperative work and social computing  baltimore  usa  to appear 
quercini  g   samet  h   sankaranarayanan  j     lieberman  m  d          determining the spatial
reader scopes of news sources using local lexicons  in proceedings of the   th sigspatial
international conference on advances in geographic information systems  gis     pp    
    san jose  usa 
quinlan  j  r          c     programs for machine learning  morgan kaufmann  san mateo 
usa 
ritter  a   clark  s   mausam    etzioni  o          named entity recognition in tweets  an experimental study  in proceedings of the      conference on empirical methods in natural
language processing  pp            edinburgh  uk 
roller  s   speriosu  m   rallapalli  s   wing  b     baldridge  j          supervised text based
geolocation using language models on an adaptive grid  in proceedings of the      joint
conference on empirical methods in natural language processing and computational natural language learning  pp            jeju island  korea 
rout  d  p   bontcheva  k   preotiuc pietro  d     cohn  t          wheres  wally   a classification approach to geolocating users based on their social ties  in proceedings of the   th acm
conference on hypertext and social media  pp        paris  france 
sadilek  a   kautz  h     bigham  j  p          finding your friends and following them to where
you are  in proceedings of the fifth acm international conference on web search and data
mining  pp          seattle  usa 
schulz  a   hadjakos  a   paulheim  h   nachtwey  j     muhlhauser  m          a multi indicator
approach for geolocalization of tweets  in proceedings of the  th international conference
on weblogs and social media  icwsm        pp          boston  usa 
serdyukov  p   murdock  v     van zwol  r          placing flickr photos on a map  in proceedings of the   nd international acm sigir conference on research and development in
information retrieval  sigir        pp          boston  usa 
silva  m  j   martins  b   chaves  m  s   afonso  a  p     cardoso  n          adding geographic
scopes to web resources  computers  environment and urban systems             
tuten  t  l          advertising      social media marketing in a web     world  praeger publishers 
westport  usa 
vapnik  v  n          the nature of statistical learning theory  springer verlag  new york  usa 
vincenty  t          direct and inverse solutions of geodesics on the ellipsoid with application of
nested equations  survey review                
wang  l   wang  c   xie  x   forman  j   lu  y   ma  w  y     li  y          detecting dominant
locations from search queries  in proceedings of the   th annual international acm sigir
   

fih an   c ook   baldwin

conference on research and development in information retrieval  sigir        pp     
     salvador  brazil 
wing  b  p     baldridge  j          simple supervised document geolocation with geodesic grids 
in proceedings of the   th annual meeting of the association for computational linguistics 
human language technologies  pp          portland  usa 
wolpert  d  h          stacked generalization  neural networks               
yang  y     pedersen  j  o          a comparative study on feature selection in text categorization 
in proceedings of the fourteenth international conference on machine learning  icml    
pp          san francisco  usa 
yi  x   raghavan  h     leggetter  c          discovering users specific geo intention in web
search  in proceedings of the   th international conference on world wide web  www    
pp          madrid  spain 
yin  j   lampert  a   cameron  m   robinson  b     power  r          using social media to
enhance emergency situation awareness  intelligent systems              
yin  z   cao  l   han  j   zhai  c     huang  t          geographical topic discovery and comparison  in proceedings of the   th international conference on world wide web  pp         
hyderabad  india 
zong  w   wu  d   sun  a   lim  e  p     goh  d  h  l          on assigning place names to
geography related web pages  in acm ieee joint conference on digital libraries  pp     
     denver  usa 

   

fi