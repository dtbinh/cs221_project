journal artificial intelligence research                  

submitted        published      

algorithms applications
same decision probability
suming chen
arthur choi
adnan darwiche

suming cs ucla edu
aychoi cs ucla edu
darwiche cs ucla edu

computer science department
university california  los angeles
los angeles  ca      

abstract
making decisions uncertainty  optimal choices often difficult
discern  especially enough information gathered  two key questions
regard relate whether one stop information gathering process commit
decision  stopping criterion   not  information gather next  selection
criterion   paper  show recently introduced notion  same decision
probability  sdp   useful stopping selection criterion  provide additional insight allow robust decision making variety scenarios 
query shown highly intractable  pppp  complete  exemplary
class queries correspond computation certain expectations  propose first exact algorithm computing sdp  demonstrate effectiveness
several real synthetic networks  finally  present new complexity results 
complexity computing sdp models naive bayes structure  additionally 
prove computing non myopic value information complete
complexity class computing sdp 

   introduction
probabilistic graphical models often used model variety decision problems 
e g   medical diagnosis  pauker   kassirer        kahn  roberts  shaffer    haddawy 
      van der gaag   coupe         fault diagnosis  lu   przytula         classification
 friedman  geiger    goldszmidt        ramoni   sebastiani        jordan         troubleshooting  heckerman  breese    rommelse         educational diagnosis  butz  hua   
maguire        arroyo   woolf        millan  descalco  castillo  oliveira    diogo        
intrusion detection  kruegel  mutz  robertson    valeur        modelo howard 
bagchi    lebanon         similar applications  decision maker typically
position must decide tests perform observations make
order make better informed decision  perhaps critically  decision maker must
decide stop making observations commit particular decision 
same decision probability  sdp  recently proposed darwiche choi
        order help quantify robustness decision  context decisionmaking bayesian networks  short  sdp probability would make
decision  perform observations yet made 
such  sdp treated measure decisions robustness respect
c
    
ai access foundation  rights reserved 

fichen  choi   darwiche

unknown variables  quantifying confidence would make decision  even
made observations 
paper  show apply sdp tool information gathering 
particular  way determine stop information gathering  as stopping criterion   not  pieces information gather next  as selection criterion  
compare sdp classical stopping selection criteria illustrative examples 
instance  demonstrate sdp distinguish stable unstable
decisions indistinguishable classical criteria  additionally  show
scenarios classical criteria may call performing observations 
sdp indicates decision unlikely change 
notably  sdp shown highly intractable  choi  xue  darwiche
        exact computation sdp limited toy examples 
variables  brute force enumeration  paper  propose first exact
algorithm computing sdp  algorithm applied real world networks
scope brute force enumeration previously proposed approximation
algorithms  applied synthetic networks many     variables 
provide new complexity results sdp  highlight relative
intractability  even naive bayes networks   relationship broader class
expectation computation problems  emphasizing broader importance developing
effective algorithms sdp related problems 
paper thus structured follows  first introduce notation discuss
common stopping selection criteria section    review previously introduced work sdp section    section    discuss sdp applied
stopping criterion selection criterion  section    present novel
exact algorithm computing sdp discuss experimental results section   
section    present recent complexity results sdp  conclude
paper section   

   related work
making decisions uncertainty  may difficult finalize decision
presence unobserved variables  given unobserved variables  two fundamental questions  first question whether  given current observations  decision
maker ready commit decision  refer stopping criterion
making decision  assuming stopping criterion met  second question
additional observations made decision maker ready make decision  typically requires selection criterion based measure quantifying
observations value information  voi   section  first introduce necessary
notation  review commonly used stopping selection criteria 
    notation
throughout paper  use standard notation variables instantiations 
variables denoted upper case letters x instantiations lower case
letters x  additionally  sets variables denoted bold upper case letters x
instantiations bold lower case letters x  assume state world
   

fialgorithms applications same decision probability

described random variables x  evidence e x includes known variables 
hidden variables u x include unknown variables  definition  e u  
eu   x  often discuss ramifications observing subset hidden variables
h u decision making  furthermore  use u denote main hypothesis
variable forms basis decision  
    stopping criterion
given hidden variables model choice whether
observe subset  stopping criterion determines stop process
information gathering commit decision  note concerned making
decision based hypothesis variable  state patients health 
stopping criterion  basic approach used variety domains commit
decision belief certain event crosses threshold  done
pauker kassirer         kruegel et al          lu przytula         however 
approach may robust  observations may cause belief
event fall threshold  van der gaag bodlaender        note possibility
pose stop problem  asks whether present evidence gathered
sufficient diagnosis  exists relevant evidence
gathered 
approaches involve ensuring uncertainty surrounding decision variable
sufficiently reduced  instance  gao koller        stop information gathering
   conditional entropy interest variable reduced beyond threshold   
margin first second likely states interest variable
threshold  case  clear threshold based stopping criteria ubiquitous
decision making uncertainty 
alternatively  several stopping criteria involve existence
budget  abstract quantity represent available resources
used information gathering  budget may representative number
observations allowed  modelo howard et al         munie   shoham        yu 
krishnapuram  rosales    rao        chen  low  tan  oran  jaillet  dolan    sukhatme 
    a   terms monetary amount may spent observations varying
cost  greiner  grove    roth        krause   guestrin        bilgic   getoor        
context budget  general stopping criterion continue make observations
budget completely expended  done modelo howard et al        
munie shoham         krause guestrin        bilgic getoor        note
budget expended caveat value information
observation least cost observation 
    selection criterion  value information
stopping criterion determine observations necessary  selection
criterion used determine variables selected observation 
ideally  want observe variables give us additional information regards
   work presented paper extended case multiple hypothesis variables 
focus case one hypothesis variable simplicity 

   

fichen  choi   darwiche

decision variable  however  due resource constraints  such limited budget 
often possible  basic approach  common selection criterion select
observations minimize conditional entropy decision variable  vomlel 
      lu   przytula        krause   guestrin        yu et al         zhang   ji       
gao   koller        ognibene   demiris        shann   seuken         entropy
variable x defined as 
h x   

x

pr  x  log pr  x 

   

x

measure uncertainty variables state entropy variable
high  means much uncertainty value variable takes  
uncertainty decision variables true state makes difficult make decision  thus 
natural selection criterion observe variables minimize conditional entropy
decision variable  conditional entropy variable given variable x defined
as 
h d   x   

x

h d   x pr  x 

   

x

conditional entropy thus expectation entropy would
observing x  similar selection criterion observe variables greatly
increase margin posterior probabilities first second most likely
states decision variable  krause   guestrin        
selection criteria involve utilizing notion value information  voi  order
quantify value various observations  lindley        stratonovich        howard 
      raiffa         voi set variables depend various measures 
two example selection criteria discussed  measures would entropy
margins confidence  instance  observing variable x would reduce conditional
entropy h d   x  observing variable x would  h d   x    h d   x    
value observing x would higher 
krause guestrin        define general notion voi based different
reward functions  particular  given arbitrary reward function r   hypothesis variable
d  evidence e  voi observing hidden variables h is 
v r  d  h  e    er r  d  h  e  r pr  d   e  

   


er r  d  h  e   

x

r pr  d   h  e  pr  h   e 

   

h

expected reward observing variables h r pr  d   e   reward
observed variables h  definition  reward function used lu
   information theory  logarithm typically assumed base    cover   thomas        
assume throughout paper convenience 
   reward function assumed take input probability distribution hypothesis variable 
pr  d   return numeric value  discuss reward functions section     

   

fialgorithms applications same decision probability




 


pr  d   e       e      
        
        

x 

x 

e 

e 

h 

h 

figure    simple bayesian network  sensor readings  e       e        variables h 
h  represent health sensors e  e    left posterior
decision variable d  network cpts found appendix c figure    

przytula        krause guestrin        select variables order minimize
conditional entropy r pr  d   e     h d   e   maximizing expected
reward observing variables h equivalent minimizing conditional entropy
h d   h   possible reward functions involve utility based reward functions
threshold based reward functions  munie   shoham         
note vast majority selection criteria use myopic approach 
possible observations  one observation considered time  observation
highest voi selected time  approach greedy short sighted
optimal voi computed computing non myopically  bilgic   getoor 
       discuss usage non myopic voi appendix a   

   same decision probability
same decision probability  sdp  initially introduced darwiche choi       
confidence measure threshold based decisions bayesian networks noisy
sensor readings  prior formally defining sdp  first show example provide
intuition  consider bayesian network figure    models scenario involving
hypothesis variable d  two noisy sensors e  e  influence belief
hypothesis d  networks typically used compute belief hypothesis
given sensor readings  pr  d   e   basis whether make decision often
depends whether posterior probability hypothesis surpasses
threshold  hamscher  console    de kleer        heckerman et al         kruegel
et al         lu   przytula        
figure   shows particular reading two sensors resulting belief pr  d      
e       e        suppose threshold        pr  d   e    would make
certain decision  notice figure   health sensors modeled variables
h  h    sensor either truthful  stuck positive  readings always display    
lying  readings show opposite value actual value   darwiche   choi        
variables observed  could informed us trustworthiness
   reward functions  see list provided krause guestrin        

   

fichen  choi   darwiche

h 

p
l

p
l

p
l

h 



p
p
p
l
l
l

pr  h   e 
        
        
        
        
        
        
        
        
        

pr  d   h  e 
    
    
    
    
    
    
    
    
    

table    scenarios h sensor readings e    e       e       network figure   
h    h    h     cases threshold       bold  note t  p  l
respectively represent truthful  stuck positive  lying sensor 

sensors e  e  thus allow us make better decision  want make
more informed decision based probability pr  d   h  e  instead making decision
based pr  d   e  
consider table    enumerates possible health states sensors 
four cases probability hypothesis pass threshold  in bold  
leading decision  five scenarios  different decision would
made  sdp thus probability four scenarios decision
would made  example  sdp is 
                                                 
indicating relatively robust decision 
choi et al         define sdp formally as 
definition    same decision probability   let n bayesian network conditioned
evidence e  given hypothesis d  threshold   set
unobserved variables h  suppose making decision confirmed threshold
pr  d   e    same decision probability scenario
x
 pr  d   e  h   pr  h   e  
   
sdp  d  h  e     
h

 pr  d   h  e    indicator function

  pr  d   e  h 
 pr  d   h  e     
  otherwise 
sdp notably hard compute  choi et al         prove computing sdp
general pppp  complete   previous work sdp  darwiche   choi       
choi et al          two options computing sdp
   class pppp thought counting variant nppp class  contains polynomial
time hierarchy ph map problem complete  park   darwiche        

   

fialgorithms applications same decision probability


 


pr  d 
   
   



s 

s 

s 

s 

figure    bayesian network intrusion detection  cpts given table  
   approximate algorithm developed choi et al          algorithm uses
augmented variable elimination algorithm produces potentially weak bound
based one sided chebyshev inequality 
   naive brute force method enumerates possible instantiations 

   applying same decision probability
investigate use sdp stopping criterion selection criterion 
contrast usage sdp traditional methods discussed section    find
using sdp provide insight decision maker scenarios 
    sdp stopping criterion
definition sdp  see calculating high sdp  contrast calculating
low sdp  would indicate higher degree readiness make decision  chances
decision changing given evidence gathering lower  section show
computing sdp provide additional insight thus distinguish scenarios
otherwise indistinguishable based standard stopping criteria 
threshold based decision classical notion decision making uncertainty 
commonly used requires utilities elicited  examples thresholdbased decisions prevalent educational diagnosis  gertner  conati    vanlehn 
      conati  gertner    vanlehn        butz et al         xenos        arroyo   woolf 
      munie   shoham         intrusion detection  kruegel et al         modelo howard
et al          fault diagnosis  heckerman et al         lu   przytula         medical
diagnosis  pauker   kassirer        kahn et al         van der gaag   coupe        
consider sensor network figure    may correspond intrusion detection
application discussed kruegel et al          here  hypothesis variable  
          implying intrusion  suppose commit decision  stop
performing observations  belief event     surpasses threshold  
say         four sensors model  s    s    s  s    whose readings may
affect decision 
consider two following scenarios 
   s      s      
   s      s      
   

fichen  choi   darwiche

s  pr  s    d 
   
    
 
    
 
    
    


s  pr  s    d 
   
    
 
    
 
    
    


s  pr  s    d 
   
    
    
 
 
    

    

s  pr  s    d 
   
    
    
 
 
    

    

table    cpts network figure    parameterization   
since pr  d       s       s                     pr  d       s       s        
             clear cases threshold crossed  deem
observations necessary based beliefs surpassing threshold 
hence  using thresholds stopping criterion  as commonly done  see kruegel
et al         lu   przytula        gao   koller         two scenarios identical
information gathered decision made 
viewpoint sdp  however  two scenarios different  particular  first scenario leads sdp         means        chance
different decision would made observe two unobserved
sensors s  s    second scenario  however  leads sdp       is 
would certainty know would make decision observe
two unobserved sensors s  s    matter readings s  s  could be 
beliefs event     would always surpass threshold       indeed 
see table    sensors s  s  strong sensors s  s   
example  strong enough reverse decision 
example provides clear illustration utility sdp stopping criterion 
however  may argue clear second case  stop gathering
information pr  d       s       s              larger margin threshold
pr  d       s       s                however  show following example
deciding stop based solely margin robust  consider
sensor network figure   parameterizations sensor network shown table  
table    found appendix c   respectively refer case   case    
note example  use threshold       
cases  s      s      observed  pr  d       s       s        
particular 
   case    pr  d       s       s               
   thus using aforementioned margins confidence stopping criterion used gao koller        
   note exact numbers cpts necessary grasp examples cpts
provided readers may reconstruct networks 

   

fialgorithms applications same decision probability

   case    pr  d       s       s               
using previously discussed margin stopping criterion  would seem case
  could stop information gathering  whereas case   information gathering
necessary  however  compute sdp cases insights
nature robustness settings  case    find sdp        whereas
case    find sdp     even though case   margin higher 
greater chance decision would change given information 
demonstrates cannot use solely margin determine whether stop
information gathering 
clear examples sdp useful stopping criterion  first  sdp
pinpoint situations observations unnecessary would never
reverse decision consideration  second  sdp identify situations
decision made robust  likely change upon making
observations  addition examples  appendix a   show sdp
useful stopping criterion context utility based decisions  e g  influence diagrams  
    sdp selection criterion
turn attention use sdp criterion deciding variables
observe next  assuming stopping criterion indicates observations
necessary  proposal based using voi selection criterion  see equation    
choosing sdp reward function  call sdp gain  formally
defined as 
definition    given definition   sdp  sdp gain observing variables g
variables h defined expected sdp observing g h subtracted sdp
h 
g g    e g  h  e    sdp  d  h  e    
   
expected sdp defined as 
e g  h  e     

x

sdp  d  h   g  ge   pr  g e 

   

g

defined decision made given current evidence 
note observe variables g h expected sdp     
indicates observing g making decision  remaining variables h   g
rendered completely redundant observation effect decision 
goal using sdp gain selection criterion observe variables which 
average  allow stable decision given collected observations 
next provide example using sdp selection criterion  contrasting
two selection criteria  one based reducing entropy hypothesis variable
d  another based maximizing gap decision probability pr  d e 
given threshold  krause   guestrin         criteria motivated
reducing uncertainty  show indeed lead less stable decisions
sdp used 
   

fichen  choi   darwiche




 


pr  d 
   
   
s 

s 

figure    bayesian network cpts given appendix c 

example given bayesian network figure    hypothesis
variable s   s  sensors  decision triggered pr  d       e      
evidence e sensors s  s    observations  empty evidence e   sdp
       suggesting observations may needed  assuming limited number
observations  heckerman et al          using myopic approach observing one
variable time  dittmer   jensen         need select next variable
observe 
note maximizing voi negative entropy reward function amounts
maximizing mutual information  h d  x    h d  h d   x   cover   thomas       
krause   guestrin         mutual information variable sensor s 
     whereas mutual information sensor s         hence  observing
s  reduce entropy most  terms margin confidence  another reward
function used krause guestrin         observing s  average lead    
margin states         whereas observing s  lead    
margin two states 
however  compute corresponding sdp gains  g s    g s     find
observing s  will  average  lead improving decision stability most  particular  observing s  would give us sdp either        expected sdp
       whereas observing s  would give us sdp either               
expected sdp        therefore  g s           g s            hence  observing s 
average allow us make decision less likely change due additional
information  beyond s    
intuition occurs although observing s  leads greater information gain observing s    superfluous information  note pr  d       s       
        whereas pr  d       s             clearly  see observing s  lead
skewed distribution minimal conditional entropy  however  context
threshold based decisions  make decision based solely whether pr  d       e 
threshold  meaning may put much emphasis much
threshold pr  d       e  is  case  although observing s 
average lead extreme distribution  observing s    leads making extremely
nonrobust decision  a decision would change     time observation s    
observing s  making decision leads much robust decision  example
demonstrates usefulness sdp selection criterion threshold based decisions 
sdp used select observations lead robust decisions 
   

fialgorithms applications same decision probability


 


pr  d 
   
   



e 

h 

h 

h 

figure    naive bayes network  cpts defined appendix c  

   computing same decision probability
computing sdp involves computing expectation hidden variables h 
naive brute force algorithm would enumerate check whether pr  d   h  e 
instantiations h h  present algorithm save us need explore
every possible instantiation h  make algorithm easier understand  first
describe compute sdp naive bayes network  trivial problem
show section   computing sdp naive bayes network np hard 
generalize algorithm arbitrary networks 
    computing sdp naive bayes networks
find convenient implement test pr  d   h  e  log odds
domain  where 
log o d   h  e    log

pr  d   h  e 
pr  d   h  e 

   


define log odds threshold   log  t
and  equivalently  test whether
log o d   h  e   
naive bayes network class variable  h e leaf variables 
q h  posterior log odds observing partial instantiation q    h            hj  
written as 

log o d   q  e    log o d   e   

j
x

w hi

   

i  

whi weight evidence hi defined as 
whi   log

pr  hi   d  e 
pr  hi   d  e 

    

weight evidence whi contribution evidence hi quantity
log o d   q  e   chan   darwiche         note weights computed time
space linear  h  using floating point representation   table   depicts weights
evidence network figure   
   additionally  note equation     since naive bayes networks hi d separated e given
d  term e dropped equation  leave term general networks  hi
may d separated e 

   

fichen  choi   darwiche


 
 
 

w hi
   
    
    

w hi
     
     
     

table    weights evidence attributes figure   
h 
   
h 
   

h 
     

h 
    
    

h 
    
   

   

h 
    
    

    

    

h 
    
    

    

figure    search tree network figure    solid line indicates   dashed
line indicates   quantity log o d   q  e  displayed next node q
tree  nodes log o d   q  e      shown bold 

one compute sdp enumerating instantiations variables h
using equation   test whether log o d   h  e    figure   depicts search tree
naive bayes network figure    used purpose  leaves
tree correspond instantiations h variables h  generally  every node
tree corresponds instantiation q  q h 
brute force computation sdp would entail 
   initializing total sdp   
   visiting every leaf node h search tree 
   checking whether log o d   h  e  so  adding pr  h   e  total sdp 
figure   depicts quantity log o d   q  e  node q tree  indicating five
leaf nodes  i e   five instantiations variables h  indeed contribute sdp 
state key observation underlying proposed algorithm  consider node
corresponding instantiation h      search tree  log o d   h       e        
four completions h instantiation  i e   four leaf nodes it 
log o d   h  e       hence  really need visit leaves add
contributions pr  h e  individually sdp  instead  simply add pr  h      e 
sdp  equals sum pr  h e  leaves  importantly 
detect leaves contribute sdp computing lower bound using
weights depicted table    is  two weights variable h    minimum
      moreover  two weights variable h    minimum
      hence  lowest contribution log odds made leaf node h     
   

fialgorithms applications same decision probability

h 
   
   

h 
     
h 
    
    

    

    

figure    reduced search tree network figure   
                  adding contribution current log odds    
lead log odds      still passes given threshold 
similar technique used compute upper bounds  allowing us detect nodes
search tree leaf contribute sdp  consider example
node corresponding instantiation h      h      log o d   h      h   
  e          neither leaves node contribute sdp
log odds pass threshold  detected considering weights
evidence variable h  computing maximum weights         adding
current log odds      gives       still threshold  hence 
leaf node h      h    contribute sdp part search tree
pruned 
apply pruning technique based lower upper bounds  actually
end exploring portion tree shown figure    pseudocode
final algorithm shown algorithm    note takes linear time compute
upper lower bounds  additionally  note specific ordering h
search tree constructed directly linked amount pruning  use ordering
heuristic ranks query variable hi difference corresponding upper
lower bound h ordered greatest difference lowest difference allow
earlier pruning 
    computing sdp arbitrary networks
generalize algorithm arbitrary networks viewing networks naive
bayes networks aggregate attributes  this  first need following notion 
definition    partition h given e set s            sk that  si h 
si sj     s        sk   h  si independent  d separated  sj      j  given
e 
figure   depicts example partition 
intuition behind partition allows us view arbitrary network
naive bayes network  class variable aggregate attributes s            sk   is 
aggregate attribute si viewed variable states si   allowing us view
instantiation h set values s            sk   have 

   

fichen  choi   darwiche

algorithm   computing sdp naive bayes network  note  q    h            hj   
p
wq defined ji   whi  

input 
n   naive bayes network class variable
h  attributes  h            hk  
  log odds threshold
e  evidence
output  same decision probability p

main 
global p      initial probability 
q     initial instantiation empty set 
depth    initial depth search tree 
dfs sdp q  h  depth 
return p
   procedure dfs sdp q  h  depth 
p
  
u pperbound log o d   e    wq   ki depth   maxhi whi
p
  
lowerbound log o d   e    wq   ki depth   minhi whi
  
 u pperbound     return
  
else  lowerbound  
  
add pr  q   e  p  return
  
else
  
depth   k
  
value hdepth   attribute hdepth  
   
dfs sdp qhdepth     h   hdepth     depth     
proposition    partial instantiation q    s            sj   
log o d   q  e    log o d   e   

j
x

w si  

    

i  


wsi   log

pr  si     d  e 
pr  si   d  e 

proof 
pr  d   q  e 
pr  d   q  e 
pr  d   e pr  s    d  e        pr  sj   d  e 
  log
pr  d   e pr  s    d  e        pr  sj   d  e 

log o d   q  e    log

  log o d   e   

j
x
i  

   

w si

    

fialgorithms applications same decision probability

e 

x 

h 

h 



x 

h 

h 

e 

x 

h 

h 

figure    partition h given e is  s     h    h    h    s     h     s   
 h    h    

since equations       analogous equations       use algorithm   arbitrary network  usage  however  requires auxiliary computations
needed readily available naive bayes networks  discuss
computations next 
      finding partition
first need compute partition s            sk   done pruning network
structure follows  delete edges outgoing nodes evidence e hypothesis d 
delete  successively  leaf nodes neither h  e d  identify
components x            xk resulting network define non empty si   h xi
element partition  guarantees original network structure  si
d separated sj e    j  see  darwiche          figure    network
pruning leads components x     x    x    e    h    h    h     x     d  e    h   
x     x    h    h    
      computing posterior log odds  probability weights evidence
quantities o d   e   pr  q   e  wsi   referenced lines        
algorithm  simple closed forms naive bayes networks  arbitrary networks 
however  computing quantities requires inference using algorithm
variable elimination described darwiche         note network pruning
deleting edges removing leaf nodes  discussed above  guarantees
factor used variable elimination variables component xi   hence 
variable elimination applied component xi isolation  sufficient
obtain needed quantities 
   

fichen  choi   darwiche

      computing min max evidence weights
finally show compute upper lower bounds  maxsi wsi minsi wsi  
referenced lines     algorithm  quantities
computed using variable elimination  applied component xi isolation 
case  however  must eliminate variables xi   si first variables si   moreover 
first set variables summed out  second set variables maxd out
mind out  depending whether need maxsi wsi minsi wsi   finally  elimination
process applied twice  evidence d  e second time evidence d  e 
precisely  every component xi set factors case  
  d  using variable ordering  perform variable elimination
sets factors eliminate

left
q iany nonquery  intermediary  variables
q



set factors   pr  si   d  e   set factors   pr  si   d  e  
since elimination order same  thus one to one matching

pr  ei  s  
factors sets  define new set factors   id   pr id  ei  si    






calculate wsi wsi respectively maximizing minimizing variables 
note summing variables maximizing variables variable elimination
algorithm used dechter        order solve map  algorithm differs
perform maximization minimization  to calculate wsi wsi   
set factors instead factors  di di   result simply summing
intermediary variables 
note similarly dechter         first summing variables
performing maximization  and minimization case   elimination order
case constrained  meaning may forced use poor ordering variable
elimination results high treewidth 
    complexity analysis
let n number variables network  h    h   w   maxi wi  
wi width constrained elimination order used
component xi   best case

time complexityof algorithm n exp w worst case time complexity
n exp  w   h    intuition behind bounds computing
maximum
minimum weights aggregate attribute takes time n exp w   bounds
complexity computing o d e   pr  q e  corresponding weights wsi   moreover 
depending weights
threshold   traversing search tree take anywhere
constant time exp h   since depth first
search implemented linear

space  space complexity n exp w  

   experimental results
performed several experiments real synthetic networks test performance algorithm across wide variety network structures  ranging simple
naive bayes networks highly connected networks  real networks either learned
datasets provided uci machine learning repository  bache   lichman       
   

fialgorithms applications same decision probability

network
car
emdec g
tcc e
ttt
caa
voting
nav
fire
chess

source
uci
hrl
hrl
uci
cresst
uci
cresst
cresst
uci

 h 
 h 
 
   
 
   
 
   
 
     
  
     
  
     
          
           
             

naive
     
     
     
     
     
     
      



approx
     
     
     
     
     
     
     
     
 

new
     
     
     
     
     
     
     
     
     

table    algorithm comparison real networks  show time  seconds  takes
algorithm  naive  approx  new compute sdp different networks 
note indicates computation complete    minute
time limit constrained  moreover    indicates sufficient
memory complete computation 

provided hrl laboratories cresst   majority real networks used
diagnostic networks  made clear variable selected decision
variable would either knowledge fault variable  unclear cases 
decision variable picked random  query evidence variables selected
random real networks 
besides algorithm  two options available compute sdp    
naive method brute force computation enumerating possible instantiations
   approximate algorithm developed choi et al          compare algorithm
two approaches  compute sdp real networks 
network selected least     total network variables query variables
could emphasize size query set greatly influences computation
time  computation given    minutes complete  believe value
threshold greatly affect running time  computed sdp thresholds  
                                         took worst case time  results experiments
three algorithms shown table    note  h  number query
variables  h  number instantiations naive algorithm must enumerate over 
moreover  indicates computation complete    minute time limit
  indicates sufficient memory complete computation  networks
 car ttt voting nav chess  naive bayes networks whereas networks  caa fire 
polytree networks others general networks 
given real networks tested algorithm on  clear algorithm
outperforms naive implementation approximate algorithm naive
bayes networks polytree networks  note approximation algorithm based
variable elimination use certain constrained orders  naive bayes
   http   www cse ucla edu 

   

fichen  choi   darwiche

    
    

average explored instantiations running time
number instantiations  x   e  

    
    
    
    
    
   
  

time  s 
 

 

 
 
number subnetworks

 

 

 

figure    synthetic network average running time average number instantiations
explored number connected components 

network hypothesis root  approximation algorithm forced
use particularly poor ordering  explains failure chess network 
analyze general network structure selected threshold affects
performance algorithm  generated synthetic networks     variables
varying treewidth using bngenerator  ide  cozman    ramos         network 
randomly selected decision variable     query variables  evidence variables   
generated partition network grouped networks size obtained
partition  k   goal test algorithms running time ability prune
search space depends k  average time average number instantiations
explored shown figure   
general  see k increases  number instantiations explored
algorithm decreases runtime improves  network becomes similar
naive bayes structure increasing k  moreover  larger k is  levels
search tree  means algorithm opportunities prune 
worst case  network may unable disconnected  k       however  even
case algorithm still  average  efficient compared brute force
implementation cases  computing maximum minimum weight
observing h  find exist h change decision 
found that  given time limit   hours  brute force algorithm could solve
synthetic networks  whereas approach solved     networks 
test threshold affects computation time  here  calculate posterior
probability decision variable run repeatedly algorithm thresholds
varying increments away  average running time increments seen
figure    evident threshold set away initial
    synthetic networks binary  brute force approach would need explore     instantiations 

   

fialgorithms applications same decision probability

    
    

average explored instantiations running time
number instantiations  x   e  

    
    
    
   
   
   
   
    

time  s 
   

   
   
   
   
threshold distance initial posterior

   

figure    synthetic network average running time average number instantiations
explored threshold distance initial posterior probability 

posterior probability  algorithm finishes much faster  perhaps expected since
usage extreme thresholds would allow search space pruning 
overall  experimental results show algorithm able solve many sdp
problems reach existing methods  confirm algorithm
completes much faster network disconnected threshold far
away initial posterior probability decision variable 

   complexity computing same decision probability
present new complexity results sdp  first prove complexity
computing sdp naive bayes structures np hard  show general
complexity computing sdp lies complexity class general expectation
computation problem applicable wide variety queries graphical models 
computation non myopic value information 
    computing sdp naive bayes
sdp known pppp  complete  choi et al          show sdp remains
hard naive bayes networks 
theorem    computing same decision probability naive bayes network nphard 
proof  reduce number partition problem defined karp        computing
sdp naive bayes model  suppose given set positive p
integers c p
          cn  
wish determine whether exists             n  ji ci   j i cj  
solve considering naive bayes network binary class variable
uniform probability  binary attributes h            hn cpts leading weights
   

fichen  choi   darwiche

evidence whi  t   ci whi  f   ci   construction cpts done
solving following system equations 
pr  hi        
pr  hi       f  
pr  hi   f      
ci   log
pr  hi   f     f  
    pr  hi           pr  hi   f      
ci   log

    pr  hi       f     pr  hi   f     f  

leave exact derivations  see exercise      darwiche         get
result that 
pr  hi       f     pr  hi   f        

 ci

 
  

pr  hi           pr  hi   f     f      

 ci

 
  

note given cpts defined whi  t   ci whi  f  
ci   set integers partitioned instantiation h    h            hn  
p
n
i   whi     since would include indices hi   case 
first 
pnthe naive bayes network satisfies number properties shall use
pnext 
n
whi either         since weights whi integers  next  i   whi   c 
i  p
ni   whi   c hi    hi   finally  pr  h            hn     pr  h            hn   hi    hi  
uniform probability distribution leaf hi defined
symmetric cpt 
consider following sdp  the last step based properties  
sdp  d   t   h            hn            
x
 pr  d     h            hn       pr  h            hn  
 
h       hn

 

x

 log o d     h            hn     pr  h            hn  

h       hn

 

x

h       hn

 

  x
 
 

n
x

h       hn



pn

i   whi

 

whi   pr  h            hn  

i  

 

n
x

 

whi      pr  h            hn  

i  

    instantiation h            hn iff
  n
 
x x
whi      pr  h            hn      
h       hn

i  

   

fialgorithms applications same decision probability

hence  partitioning problem solved iff
sdp  d   t   h            hn                  

    complexity computing non myopic voi
sdp shown pppp  complete problem choi et al          class pppp
essentially counting variant nppp class  contains polynomial hierarchy
ph map problem complete  park   darwiche         show
section general problem computing expectations pppp  complete 
non myopic voi sdp instance expectation  thus  development
algorithms compute sdp beneficial problems pppp class 
turn benefits computing assortment expectations  including non myopic voi 
proposed expectation computation based using reward function r
properties review next  particular  function r assumed map
probability distribution pr  d   e  numeric value  assume minimum
l maximum u range polytime computable  assumptions
limitingfor example  entropy utility expressed using reward functions
fall category  krause   guestrin        
consider following computation expectations 
d ept  given polynomial time computable reward function r  hypothesis variable
d  unobserved variables h  evidence e  real number n   distribution pr induced
bayesian network variables x    expectation decision problem asks 
e 

x

r pr  d   h  e  pr  h   e 

h

greater n  
note sdp falls special case reward function r sdp indicator
function  see definition     example  definition used choi et al         
decision function outputs one two decisions depending whether pr  d e   
value threshold  
following theorems  proofs appendix b 
theorem    d ept pppp  hard 
theorem    d ept pppp  
shows d ept pppp  complete implies computational problems
computing non myopic voi using variety reward functions pppp complete 
    proof holds influence diagrams constrained one decision node 

   

fichen  choi   darwiche

   conclusion
paper  discussed commonly used information gathering criteria
graphical models value information reviewed recently introduced
notion same decision probability  sdp   paper  proposed usage
sdp decision making tool showing concrete examples usefulness
stopping criterion selection criterion  stopping criterion  sdp allow
us determine observations necessary  selection criterion  usage
sdp allow us select observations allow us increase decision robustness 
justified usage sdp  proposed exact algorithm
computation  experimental results show algorithm comparable running time
previous approximate algorithm much faster naive brute force
algorithm  finally  presented several new complexity results 

acknowledgements
paper combines extends work presented chen  choi  darwiche      b 
       work partially supported onr grant  n                 nsf
grant  iis          nsf grant  iis          would thank national
center research evaluation  standards    student testing hughes research lab
contributing sample diagnostic networks 

appendix a  miscellaneous topics
section go details notions mentioned earlier
paper  particular  continue discussion section     go notion
non myopic value information  additionally  continue left
section     expand upon notion sdp stopping criterion context
utility based decisions 
appendix a   non myopic value information
myopic value information often used many applications easy compute
 dittmer   jensen        vomlel        gao   koller         however  problem
myopic selection optimal  times whole greater sum
parts  individual observation set h seemingly may provide significant
value  voi observing h high  instance  take function
  x  x    alone neither x  x  useful  together determinative
 bilgic   getoor         computing non myopic voi optimal
voi obtained 
due aforementioned problems using myopic voi  recently  researchers
recently suggested using non myopic voi instead myopic voi proposed various methods compute non myopic voi  heckerman  horvitz    middleton 
      liao   ji        krause   guestrin        zhang   ji        bilgic   getoor        
computing non myopic voi hidden variables h difficult involves com   

fialgorithms applications same decision probability

puting expectation possible values h  quickly becomes intractable
h becomes larger 
existing algorithms computing non myopic voi approximate algorithms
 heckerman et al         liao   ji        relatively limited algorithms restricted
tree networks leaf variables  krause   guestrin         bilgic getoor
       developed value information lattice  voila   framework
subsets hidden variables h examined  optimal subset features
found increase classification accuracy meeting budget constraint 
appendix a   sdp stopping criterion utility based decisions
cases expected utility different decisions  well cost reducing
uncertainty  making observations   quantified  common decision theoretic
setting  howard        howard   matheson         influence diagrams commonly
used  influence diagrams seen bayesian networks incorporate decision
utility nodes  howard   matheson        zhang        kjrulff   madsen        
selection criterion decision theoretic setting clear  observations lead
greatest increase expected utility selected  usage utilities observation
costs prevalent  however  numerous researchers noted difficulty coming
actual numerical quantities  glasziou   hilden        lu   przytula       
bilgic   getoor        
show sdp used stopping criterion decision theoretic context expected utility decisions influence diagrams  howard   matheson        
extend definition sdp general setting allow applications 
particular  assume f polytime computable decision function outputs
decision based distribution pr  d   e   instance  decision function
commonly used classification select class highest posterior probability arg maxd pr  d   e   friedman et al          whereas threshold based decisions 
decision function would simply select decision pr  d     e   
sdp thus defined probability decision would made
hidden states variables h known  chen et al       b  
definition    same decision probability generalized    given decision function f 
hypothesis variable d  unobserved variables h  evidence e  same decision probability  sdp  defined
x
 f pr  d   h  e   h pr  h   e 
    
sdp  f  d  h  e   
h

 f pr  d   h  e   h indicator function

  f pr  d   h  e     f pr  d   e  
 
  otherwise 
original sdp definition  however  assumed binary variable 
f pr  d   e     pr  d   e  threshold  darwiche   choi        
consider use sdp stopping criterion context expectedutility decisions influence diagrams  howard   matheson         particular 
   

fichen  choi   darwiche

q

c




p

figure     influence diagram investment problem 
show using sdp  distinguish high risk  high reward scenarios lowrisk  low reward scenarios otherwise indistinguishable consider usage
voi utilities alone 
consider influence diagram figure     consists bayesian network
three variables  c  q s   decision node i  utility node p direct
function utility function u  influence diagram models investment problem
venture capital firm deciding whether invest amount    million
tech startup  i     allowing money collect interest bank  i   f   
example  profit investment  p   depends decision  i  success
company  s   turn depends two factors      whether existing competitor
companies successful  c      whether co founders startup high
quality  original idea  q   c q unobserved initially independent
other  variable latent hypothesis variable case thus cannot observed 
variables c q  however  observed price 
goal choose decision   maximum expected utility 
x
eu  i   e   
pr  s   e u i  s  


u i  s  utility decision   given evidence e variables c q 
figures       contain two different parameterizations influence diagram
figure     refer different scenarios investment problem 
scenarios  given evidence variables c q  best decision   f  
expected utility     k  decision maker may commit decision decide
observe variables c q  hope finding better decision light
additional information  classical stopping criterion compute maximum
expected utility given observe variables c q  heckerman et al         dittmer
  jensen        
x
max
eu  i   c  q pr  c  q  


c q

scenarios  maximum expected utility comes        k  showing
observations may lead better decision   
    according formulation krause guestrin         computed voi variables
c q using reward function 

   

fialgorithms applications same decision probability

q

f

pr  q 
   
   

c

f

pr  c 
   
   

q


f
f

pr  s       
    
    
    
    

c

f

f



f
f



f

f

u i  s 
      
      
      
      

figure     parameterization influence diagram figure    

q

f

pr  q 
   
   

c

f

pr  c 
   
   

q


f
f

pr  s       
    
    
    
    

c

f

f



f
f



f

f

u i  s 
      
      
      
      

figure     parameterization influence diagram figure    
point  two scenarios indistinguishable viewpoint
classical decision making tools  remember krause guestrin        bilgic
getoor        remark budget observations expended long
value information observation greater cost observation  according
selection criteria  variables thus observed  expected
financial gain could well increase 
sdp  however  finds two scenarios different  particular 
respect variables c q  sdp     first scenario     second
scenario  is  even though stand make better decision scenarios upon
observing variables c q  at least respect financial gain   even though
expected benefit observations scenarios  unlikely
would change current decision   f second scenario comparison
first  hence  given additional information provided sdp  decision maker may
act quite differently two scenarios  indeed  take closer look second
scenario  state world  when     deciding invest would yield
large financial gain  however  chance state manifesting extremely
   

fichen  choi   darwiche

small  analogous lottery   meaning risk conscious decision maker may
averse gamble second scenario even waste resources observe variables
c d  note example assumed utility incorporate
risk factor  rational decision maker would always choose gather
information despite low probability changing current decision 
illustrates usefulness sdp stopping criterion context expectedutility decisions influence diagrams  namely  using sdp  distinguish
two different scenarios  otherwise indistinguishable consider utilities
alone 

appendix b  proofs
section provide proofs theorems     
proof theorem    show d ept pppp  hard reduction following decision problem d sdp  corresponds originally proposed notion same decision
probability threshold based decisions  darwiche   choi        
d sdp  given decision based probability pr  d   e  surpassing threshold   set
unobserved variables h  probability p  same decision probability 
x
 pr  d   h  e   pr  h   e 
    
h

greater p 
here      denotes indicator function evaluates   enclosed expression
satisfied    otherwise  d sdp shown pppp  complete choi et al         
same decision probability corresponds expectation respect distribution pr  h   e   using reward function 

  pr  d   h  e 
r pr  d   h  e    
  otherwise 
thus same decision probability iff expectation  
proof theorem    show d ept pppp   provide probabilistic polynomialtime algorithm  access pp oracle  answers decision problem d ept
correctly probability greater      proof generalizes simplifies proof
given choi et al         d sdp 
consider following probabilistic algorithm determines e   n  
   sample complete instantiation x bayesian network  probability pr  x  
linear time  using forward sampling  henrion        
   x compatible e  use pp oracle compute   r pr  d   h  e   
first  reward function r computed polynomial time  definition 
second  pr  d   h  e  computed using pp oracle  since inference  pcomplete  roth         since ppp   p p  
   

fialgorithms applications same decision probability

   define function a t            tn
ul   defines probability used probabilistic
algorithm guess whether e   n  see lemma    
   declare e   n probability 
a t  x compatible e 


 
 

x compatible e 

probability declaring e   n is 
r 

x
h

greater

 
 

 
a t pr  h  e       pr  e  
 

    

iff following set equivalent statements hold 
x

a t pr  h  e   

h

x

a t pr  h   e   

h

 
 


 
 tn
pr  h   e   
 
    ul
 


x  tn
pr  h   e     
  ul
h
x
 t n  pr  h   e     

x  
h

pr  e 
 

h

x

r pr  d   h  e  pr  h   e    n 

h

thus r  

 
 

iff e   n  

lemma    function a t   

 
 

 

  tn
  ul

maps reward probability        

proof  values u l given  denote upper lower bounds reward t 
threshold n   thus tn
ul        
note a t  denotes probability used algorithm declare whether e   n  
higher lower depending value reward   r pr  d   h  e   

appendix c  conditional probability tables
section provide conditional probability tables networks figures         
  

   

fichen  choi   darwiche


 


pr  d 
   
   

hi


p
p
n
n
l
l


 
 



xi
 

 

 

 


x 
 

 


ei
 
 
 
 
 
 
 
 

pr  x    d 
   
   
   
   

x 
 
 



pr  ei   hi   xi  
   
   
   
   
   
   
   
   

hi

p
n
l

x 
 

 


pr  x    x   
   
   
   
   

pr  hi  
    
    
    
    

figure     cpts bayesian network given figure    note
cpts variables ei   lines case ei     given  since
pr  ei    hi   xi       pr  ei     hi   xi   

s  pr  s    d 
   
    
 
    
    
 

    

s  pr  s    d 
   
    
 
    
    
 

    

s  pr  s    d 
   
    
 
    
 
    

    

s  pr  s    d 
   
    
 
    
 
    

    

table    cpts network figure    parameterization   

   

fialgorithms applications same decision probability

s  pr  s    d 
   
    
    
 
 
    

    

s  pr  s    d 
   
    
    
 
 
    

    

s  pr  s    d 
   
    
 
    
 
    

    

s  pr  s    d 
   
    
 
    
 
    

    

table    cpts network figure    parameterization   

s  pr  s    d 
   
    
 
   
    
 
 
    

   

    

s  pr  s    d 
   
   
   
 
 
   

   

table    cpts bayesian network figure   

h  pr  h    d 
   
    
 
    
 
    

    

h  pr  h    d 
   
    
 
    
 
    

    

table    cpts network figure    pr  h    d   pr  e    d  pr  h   d 
equal 

   

fichen  choi   darwiche

references
arroyo  i     woolf  b          inferring learning attitudes bayesian network
log file data  proceedings   th international conference artificial
intelligence education  pp       
bache  k     lichman  m          uci machine learning repository  
bilgic  m     getoor  l          value information lattice  exploiting probabilistic independence effective feature subset acquisition  journal artificial intelligence
research  jair            
butz  c  j   hua  s     maguire  r  b          web based intelligent tutoring system
computer programming  web intelligence  pp          ieee computer society 
chan  h     darwiche  a          reasoning bayesian network classifiers  proceedings   th conference uncertainty artificial intelligence  pp         
chen  j   low  k  h   tan  c  k  y   oran  a   jaillet  p   dolan  j     sukhatme  g 
     a   decentralized data fusion active sensing mobile sensors modeling
predicting spatiotemporal traffic phenomena  proceedings twenty eighth
conference annual conference uncertainty artificial intelligence  uai      pp 
        corvallis  oregon  auai press 
chen  s   choi  a     darwiche  a       b   same decision probability  new tool
decision making  proceedings sixth european workshop probabilistic
graphical models  pp       
chen  s   choi  a     darwiche  a          exact algorithm computing samedecision probability  proceedings   rd international joint conference
artificial intelligence  pp           
choi  a   xue  y     darwiche  a          same decision probability  confidence measure threshold based decisions  international journal approximate reasoning
 ijar               
conati  c   gertner  a     vanlehn  k          using bayesian networks manage uncertainty student modeling  user modeling user adapted interaction         
       
cover  t  m     thomas  j  a          elements information theory  wiley interscience 
darwiche  a          modeling reasoning bayesian networks   st edition   cambridge university press 
darwiche  a     choi  a          same decision probability  confidence measure
threshold based decisions noisy sensors  proceedings fifth european
workshop probabilistic graphical models  pp         
dechter  r          bucket elimination  unifying framework reasoning  artificial
intelligence                
dittmer  s     jensen  f          myopic value information influence diagrams  proceedings thirteenth conference annual conference uncertainty artificial
intelligence  uai      pp         
   

fialgorithms applications same decision probability

friedman  n   geiger  d     goldszmidt  m          bayesian network classifiers  machine
learning                   
gao  t     koller  d          active classification based value classifier  advances
neural information processing systems  nips       
gertner  a  s   conati  c     vanlehn  k          procedural help andes  generating hints using bayesian network student model  proceedings national
conference artificial intelligence  pp         
glasziou  p     hilden  j          test selection measures  medical decision making        
       
greiner  r   grove  a  j     roth  d          learning cost sensitive active classifiers 
artificial intelligence                  
hamscher  w   console  l     de kleer  j   eds            readings model based diagnosis  morgan kaufmann publishers inc 
heckerman  d   breese  j  s     rommelse  k          decision theoretic troubleshooting 
communications acm               
heckerman  d   horvitz  e     middleton  b          approximate nonmyopic computation value information  ieee transactions pattern analysis machine
intelligence                 
henrion  m          propagating uncertainty bayesian networks probabilistic logic
sampling  proceedings second annual conference uncertainty artificial
intelligence  uai      pp         
howard  r  a          information value theory  ieee transactions systems science
cybernetics              
howard  r  a     matheson  j  e   eds            readings principles applications decision analysis  strategic decision group 
ide  j  s   cozman  f  g     ramos  f  t          generating random bayesian networks
constraints induced width  proceedings   th european conference
artificial intelligence  pp         
jordan  a          discriminative vs  generative classifiers  comparison logistic
regression naive bayes  advances neural information processing systems     
    
kahn  c  e   roberts  l  m   shaffer  k  a     haddawy  p          construction
bayesian network mammographic diagnosis breast cancer  computers biology
medicine               
karp  r  m          reducibility among combinatorial problems  complexity computer computations  springer 
kjrulff  u  b     madsen  a  l          bayesian networks influence diagrams 
guide construction analysis  springer 
krause  a     guestrin  c          near optimal nonmyopic value information graphical models    st conference uncertainty artificial intelligence  pp         
   

fichen  choi   darwiche

krause  a     guestrin  c          optimal value information graphical models 
journal artificial intelligence research  jair              
kruegel  c   mutz  d   robertson  w     valeur  f          bayesian event classification
intrusion detection  proceedings annual computer security applications
conference  acsac  
liao  w     ji  q          efficient non myopic value of information computation influence diagrams  international journal approximate reasoning                 
lindley  d  v          measure information provided experiment  annals
mathematical statistics                  
lu  t  c     przytula  k  w          focusing strategies multiple fault diagnosis 
proceedings   th international flairs conference  pp         
millan  e   descalco  l   castillo  g   oliveira  p     diogo  s          using bayesian
networks improve knowledge assessment  computers   education                 
modelo howard  g   bagchi  s     lebanon  g          determining placement intrusion detectors distributed application bayesian network modeling 
proceedings   th international symposium recent advances intrusion
detection  pp         
munie  m     shoham  y          optimal testing structured knowledge  aaai   
proceedings   rd national conference artificial intelligence  pp           
ognibene  d     demiris  y          towards active event recognition  proceedings
  rd international joint conference artificial intelligence  pp           
park  j  d     darwiche  a          complexity results approximation strategies
map explanations  journal artificial intelligence research  jair              
pauker  s  g     kassirer  j  p          threshold approach clinical decision making  
new england journal medicine                   
raiffa  h          decision analysis introductory lectures choices uncertainty 
addison wesley 
ramoni  m     sebastiani  p          robust bayes classifiers  artificial intelligence                   
roth  d          hardness approximate reasoning  artificial intelligence         
    
shann  m     seuken  s          active learning approach home heating
smart grid  proceedings   rd international joint conference artificial
intelligence  pp           
stratonovich  r          value information  izvestiya ussr academy sciences 
technical cybernetics         
van der gaag  l  c     coupe  v  m  h          sensitivity analysis threshold decision
making bayesian belief networks  ai ia  pp       
vomlel  j          bayesian networks educational testing  international journal
uncertainty  fuzziness knowledge based systems      supp           
   

fialgorithms applications same decision probability

xenos  m          prediction assessment student behaviour open distance
education computers using bayesian networks  computers   education         
       
yu  s   krishnapuram  b   rosales  r     rao  r  b          active sensing  international
conference artificial intelligence statistics  pp         
zhang  n  l          probabilistic inference influence diagrams  computational intelligence  pp         
zhang  y     ji  q          efficient sensor selection active information fusion  ieee
transactions systems  man  cybernetics  part b                 

   


