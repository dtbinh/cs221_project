journal artificial intelligence research                  

submitted        published      

paramils  automatic algorithm configuration framework
frank hutter
holger h  hoos
kevin leyton brown

hutter   cs   ubc   ca
hoos   cs   ubc   ca
kevinlb   cs   ubc   ca

university british columbia       main mall
vancouver  bc  v t z   canada

thomas stutzle

stuetzle   ulb   ac  

universite libre de bruxelles  code  iridia
av  f  roosevelt    b      brussels  belgium

abstract
identification performance optimizing parameter settings important part development application algorithms  describe automatic framework algorithm
configuration problem  formally  provide methods optimizing target algorithms
performance given class problem instances varying set ordinal and or categorical parameters  review family local search based algorithm configuration procedures
present novel techniques accelerating adaptively limiting time spent evaluating individual configurations  describe results comprehensive experimental evaluation
methods  based configuration prominent complete incomplete algorithms
sat  present is  knowledge  first published work automatically configuring c plex mixed integer programming solver  algorithms considered default
parameter settings manually identified considerable effort  nevertheless  using
automated algorithm configuration procedures  achieved substantial consistent performance
improvements 

   introduction
many high performance algorithms parameters whose settings control important aspects
behaviour  particularly case heuristic procedures used solving computationally hard problems   example  consider c plex  commercial solver mixed integer
programming problems   cplex version       parameters affect solvers search
mechanism configured user improve performance  many acknowledgements literature finding performance optimizing parameter configurations heuristic algorithms often requires considerable effort  see  e g   gratch   chien        johnson       
diao  eskesen  froehlich  hellerstein  spainhower   surendra        birattari        adenso diaz
  laguna         many cases  tedious task performed manually ad hoc way  automating task high practical relevance several contexts 
development complex algorithms setting parameters heuristic algorithm
highly labour intensive task  indeed consume large fraction overall development
   use term heuristic algorithm includes methods without provable performance guarantees well
methods guarantees  nevertheless make use heuristic mechanisms  latter case  use
heuristic mechanisms often results empirical performance far better bounds guaranteed rigorous
theoretical analysis 
   http   www ilog com products cplex 
c
    
ai access foundation  rights reserved 

fih utter   h oos   l eyton  b rown   utzle

time  use automated algorithm configuration methods lead significant time
savings potentially achieve better results manual  ad hoc methods 
empirical studies  evaluations  comparisons algorithms central question comparing heuristic algorithms whether one algorithm outperforms another fundamentally superior  developers successfully optimized parameters  johnson         automatic algorithm configuration methods mitigate problem unfair
comparisons thus facilitate meaningful comparative studies 
practical use algorithms ability complex heuristic algorithms solve large
hard problem instances often depends critically use suitable parameter settings 
end users often little knowledge impact algorithms parameter
settings performance  thus simply use default settings  even carefully
optimized standard benchmark set  default configuration may perform well
particular problem instances encountered user  automatic algorithm configuration
methods used improve performance principled convenient way 
wide variety strategies automatic algorithm configuration explored literature  briefly  include exhaustive enumeration  hill climbing  gratch   dejong         beam
search  minton         genetic algorithms  terashima marn  ross   valenzuela rendon        
experimental design approaches  coy  golden  runger   wasil         sequential parameter optimization  bartz beielstein         racing algorithms  birattari  stutzle  paquete   varrentrapp 
      birattari        balaprakash  birattari   stutzle         combinations fractional experimental design local search  adenso diaz   laguna         discuss
related work extensively section    here  note authors refer
optimization algorithms performance setting  typically numerical  parameters
parameter tuning  favour term algorithm configuration  or simply  configuration  
motivated fact interested methods deal potentially large number
parameters  numerical  ordinal  e g   low  medium  high  categorical  e g   choice heuristic   categorical parameters used select combine discrete
building blocks algorithm  e g   preprocessing variable ordering heuristics   consequently 
general view algorithm configuration includes automated construction heuristic algorithm building blocks  best knowledge  methods discussed article
yet general ones available configuration algorithms many categorical
parameters 
give overview follows highlight main contributions  formally stating algorithm configuration problem section    section   describe paramils
 first introduced hutter  hoos   stutzle         versatile stochastic local search approach
automated algorithm configuration  two instantiations  basicils focusedils 
introduce adaptive capping algorithm runs  novel technique used
enhance search based algorithm configuration procedures independently underlying search
strategy  section     adaptive capping based idea avoiding unnecessary runs
algorithm configured developing bounds performance measure optimized 
present trajectory preserving variant heuristic extension technique  discussing experimental preliminaries section    section   present empirical evidence showing adaptive capping speeds basicils focusedils  show basicils
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

outperforms random search simple local search  well evidence focusedils
outperforms basicils 
present extensive evidence paramils find substantially improved parameter configurations complex highly optimized algorithms  particular  apply automatic
algorithm configuration procedures aforementioned commercial optimization tool c plex 
one powerful  widely used complex optimization algorithms aware of 
stated c plex user manual  version       page       great deal algorithmic development effort devoted establishing default ilog c plex parameter settings achieve
good performance wide variety mip models  demonstrate consistent improvements
default parameter configuration wide range practically relevant instance distributions  cases  able achieve average speedup order magnitude
previously unseen test instances  section     believe first results
published automatically configuring c plex piece software comparable complexity 
section   review wide range  separately published  paramils applications  specifically  survey work considered optimization complete incomplete heuristic
search algorithms problems propositional satisfiability  sat   probable explanation
 mpe   protein folding  university time tabling  algorithm configuration itself  three
cases  paramils integral part algorithm design process allowed exploration
large design spaces  could done effectively manual way
existing automated method  thus  automated algorithm configuration general paramils
particular enables new way  semi  automatic design algorithms components 
section   presents related work and  finally  section    offers discussion conclusions 
distill common patterns helped paramils succeed various applications 
give advice practitioners would apply automated algorithm configuration general
paramils particular  identify promising avenues research future work 

   problem statement notation
algorithm configuration problem consider work informally stated follows 
given algorithm  set parameters algorithm set input data  find parameter
values algorithm achieves best possible performance input data 
avoid potential confusion algorithms whose performance optimized algorithms used carrying optimization task  refer former target algorithms
latter configuration procedures  or simply configurators   setup illustrated
figure    different algorithm configuration problems considered literature  including setting parameters per instance basis adapting parameters algorithm
running  defer discussion approaches section   
following  define algorithm configuration problem formally introduce
notation use throughout article  let denote algorithm  let p            pk
parameters a  denote domain possible values parameter pi   throughout
work  assume parameter domains finite sets  assumption met
discretizing numerical parameters finite number values  furthermore  parameters
   

fih utter   h oos   l eyton  b rown   utzle

figure    configuration scenario includes algorithm configured collection problem instances  configuration procedure executes target algorithm specified parameter settings
instances  receives information performance runs  uses
information decide subsequent parameter configurations evaluate 

may ordered  exploit ordering relations  thus  effectively assume
parameters finite categorical  
problem formulation allows us express conditional parameter dependencies  for example 
one algorithm parameter might used select among search heuristics  heuristics
behaviour controlled parameters   case  values parameters
irrelevant heuristic selected  paramils exploits effectively searches
space equivalence classes parameter configuration space  addition  formulation supports
constraints feasible combinations parameter values  use         k denote
space feasible parameter configurations  a   denoting instantiation algorithm
parameter configuration  
let denote probability distribution space problem instances  denote element   may given implicitly  random instance generator distribution
generators  possible  and indeed common  consist finite sample
instances  case  define uniform distribution  
many ways measuring algorithms performance  example  might interested minimizing computational resources consumed given algorithm  such runtime 
memory communication bandwidth   maximizing quality solution found  since
high performance algorithms computationally challenging problems often randomized 
behaviour vary significantly multiple runs  thus  algorithm always achieve
performance  even run repeatedly fixed parameters single problem instance  overall goal must therefore choose parameter settings minimize cost
statistic algorithms performance across input data  denote statistic c   
example  might aim minimize mean runtime median solution cost 
intuition mind  define algorithm configuration problem formally 
definition    algorithm configuration problem   instance algorithm configuration problem   tuple ha    d  max   o  mi  where 
parameterized algorithm 
parameter configuration space a 
   currently extending algorithm configuration procedures natively support parameter types 

   

fiparam ils  n automatic lgorithm c onfiguration f ramework

distribution problem instances domain  
max cutoff time  or captime   run terminated still running 
function measures observed cost running a   instance
captime r  examples runtime solving instance  cost solution found 
statistical population parameter  such expectation  median  variance  
parameter configuration candidate solution algorithm configuration
problem  configuration   denotes distribution costs induced function o 
applied instances drawn distribution multiple independent runs randomized
algorithms  using captime   max   cost candidate solution defined
c      m o   

   

statistical population parameter cost distribution   optimal solution    minimizes c   
arg min c   
   


algorithm configuration procedure procedure solving algorithm configuration
problem  unfortunately  least algorithm configuration problems considered article  cannot optimize c closed form since access algebraic representation function  denote sequence runs executed configurator r  
          s        o              n   n   sn   n       ith run described five values 
denotes parameter configuration evaluated 
denotes instance algorithm run 
si denotes random number seed used run  we keep track seeds able block
them  see section        
denotes runs captime 
oi denotes observed cost run
note     s    vary one element r next  regardless whether
elements held constant  denote ith run r r i   subsequence
runs using parameter configuration  i e   runs     r   configuration
procedures considered article compute empirical estimates c   based solely r  
principle methods could used  compute cost estimates online 
runtime configurator  well offline  evaluation purposes 
definition    cost estimate   given algorithm configuration problem ha    d  max   o  mi 
define cost estimate cost c   based sequence runs r             s        o            
 n   n   sn   n      c   r     m  oi         sample statistic analogue
statistical population parameter m 
example  c   expected runtime distribution instances random number
seeds  c   r  sample mean runtime runs r  
configuration procedures paper anytime algorithms  meaning times
keep track configuration currently believed lowest cost  refer configuration incumbent configuration  short incumbent  inc   evaluate configurators
performance time means incumbents training test performance  defined follows 
   

fih utter   h oos   l eyton  b rown   utzle

definition    training performance   time configurator performed sequence runs r             s        o              n   n   sn   n      solve algorithm configuration problem ha    d  max   o  mi  thereby found incumbent configuration inc  
training performance time defined cost estimate c inc   r  
set instances              n   discussed called training set  true cost
parameter configuration cannot computed exactly  estimated using training performance  however  training performance configurator biased estimator incumbents
true cost  instances used selecting incumbent evaluating it 
order achieve unbiased estimates offline evaluation  set aside fixed set instances
              t     called test set  random number seeds  s             s t    unknown
configurator  use evaluation 
definition    test performance   time t  let configurators incumbent algorithm
configuration problem ha    d  max   o  mi inc  this found means executing sequence runs training set   furthermore  let r      inc        s     max   o              inc   t   
s t   max   ot    sequence runs instances random number seeds test set
 which performed offline evaluation purposes   configurators test performance
time defined cost estimate c inc   r    
throughout article  aim minimize expected runtime   see section       discussion
choice   thus  configurators training performance mean runtime runs
performed incumbent  test performance mean runtime incumbent
test set  note that  configurator free use max   test performance always
computed using maximal captime  max  
obvious automatic algorithm configurator choose runs order best
minimize c   within given time budget  particular  make following choices 
   parameter configurations   evaluated 
   problem instances   used evaluating      
many runs performed instance 
   cutoff time used run 
hutter  hoos leyton brown        considered design space detail  focusing
tradeoff  fixed  number problem instances used evaluation
parameter configuration  fixed  cutoff time used run  well interaction
choices number configurations considered  contrast  here  study
adaptive approaches selecting number problem instances  section      cutoff
time evaluation parameter configuration  section     study configurations
selected  sections          

   paramils  iterated local search parameter configuration space
section  address first important previously mentioned dimensions
automated algorithm configuration  search strategy  describing iterated local search
framework called paramils  start with  fix two dimensions  using unvarying
benchmark set instances fixed cutoff times evaluation parameter configuration  thus  stochastic optimization problem algorithm configuration reduces simple
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

optimization problem  namely find parameter configuration yields lowest mean runtime given benchmark set  then  section      address second question many
runs performed configuration 
    paramils framework
consider following manual parameter optimization process 
   begin initial parameter configuration 
   experiment modifications single parameter values  accepting new configurations whenever result improved performance 
   repeat step   single parameter change yields improvement 
widely used procedure corresponds manually executed local search parameter configuration space  specifically  corresponds iterative first improvement procedure search
space consisting possible configurations  objective function quantifies performance
achieved target algorithm given configuration  neighbourhood relation based
modification one single parameter value time  i e   one exchange neighbourhood  
viewing manual procedure local search algorithm advantageous suggests
automation procedure well improvement drawing ideas stochastic
local search community  example  note procedure stops soon reaches local optimum  a parameter configuration cannot improved modifying single parameter value  
sophisticated approach employ iterated local search  ils  lourenco  martin   stutzle 
      search performance optimizing parameter configurations  ils prominent stochastic
local search method builds chain local optima iterating main loop consisting
    solution perturbation escape local optima      subsidiary local search procedure
    acceptance criterion decide whether keep reject newly obtained candidate solution 
paramils  given pseudocode algorithm    ils method searches parameter configuration space  uses combination default random settings initialization  employs
iterative first improvement subsidiary local search procedure  uses fixed number  s  random moves perturbation  always accepts better equally good parameter configurations 
re initializes search random probability prestart    furthermore  based
one exchange neighbourhood  is  always consider changing one parameter time 
paramils deals conditional parameters excluding configurations neighbourhood configuration differ conditional parameter relevant  
    basicils algorithm
order turn paramils specified algorithm framework   executable configuration
procedure  necessary instantiate function better determines two parameter settings preferred  ultimately propose several different ways this 
here  describe simplest approach  call basicils  specifically  use term
basicils n   refer paramils algorithm function better         implemented
shown procedure    simply comparing estimates cn cost statistics c     c    
based n runs each 
   original parameter choices hr  s  prestart   h           i  from hutter et al         somewhat arbitrary 
though expected performance quite robust respect settings  revisit issue section     

   

fih utter   h oos   l eyton  b rown   utzle

algorithm framework    paramils     r  prestart   s 
outline iterated local search parameter configuration space  specific variants paramils
study  basicils n  focusedils  derived framework instantiating procedure
better  which compares        basicils n  uses bettern  see procedure     focusedils
uses betterf oc  see procedure     neighbourhood nbh   configuration set
configurations differ one parameter  excluding configurations differing conditional
parameter relevant  
input   initial configuration     algorithm parameters r  prestart   s 
output   best parameter configuration found 
               r
 
random  
 
better          
 
 
 

ils iterativefirstimprovement      
terminationcriterion  
ils  

 

         perturbation
             random   nbh   

 

         basic local search
iterativefirstimprovement    

 
  

         acceptancecriterion
better   ils   ils  
probability prestart ils random  

  

return overall best inc found 

  
  
  
  
  

procedure iterativefirstimprovement   
repeat
   
foreach    n bh      randomized order
better                break 

  
  

     
return  

basicils n   simple intuitive approach since evaluates every parameter configuration
running n training benchmark instances using random number seeds 
many related approaches  see  e g   minton        coy et al         adenso diaz  
laguna         deals stochastic part optimisation problem using estimate
based fixed training set n instances  benchmark instances heterogeneous
procedure    bettern         
procedure used basicils n   randomsearch n   compare two parameter configurations  procedure objective   n   returns user defined objective achieved a   first n instances
keeps track incumbent solution  inc   detailed procedure   page     
input
  parameter configuration     parameter configuration  
output
  true   better equal   first n instances  false otherwise
side effect   adds runs global caches performed algorithm runs r  r    potentially
updates incumbent inc
  cn      objective     n  
  cn      objective     n  
  return cn      cn     

   

fiparam ils  n automatic lgorithm c onfiguration f ramework

user identify rather small representative subset instances  approach find
good parameter configurations low computational effort 
    focusedils  adaptively selecting number training instances
question choose number training instances  n   basicils n   straightforward answer  optimizing performance using small training set leads good training
performance  poor generalization previously unseen test benchmarks  hand 
clearly cannot evaluate every parameter configuration enormous training setif did 
search progress would unreasonably slow 
focusedils variant paramils deals problem adaptively varying
number training samples considered one parameter configuration another  denote
number runs available estimate cost statistic c   parameter configuration
n     performed different numbers runs using different parameter configurations 
face question comparing two parameter configurations   n    n       
one option would simply compute empirical cost statistic based available number
runs configuration  however  lead systematic biases if  example  first
instances easier average instance  instead  compare   based n    runs
instances seeds  amounts blocking strategy  straight forward
adaptation known variance reduction technique  see     detailed discussion 
approach comparison leads us concept domination  say dominates  
least many runs conducted     performance a  
first n       runs least good a      runs 
definition    domination     dominates   n      n      cn          
cn           
ready discuss comparison strategy encoded procedure betterf oc          
used focusedils algorithm  see procedure     procedure first acquires one
additional sample configuration smaller n  i    one run configurations
number runs  then  continues performing runs way one configuration dominates other  point returns true   dominates     false otherwise 
keep track total number configurations evaluated since last improving step  i e  
since last time betterf oc returned true   denote number b  whenever betterf oc         
returns true  perform b bonus runs   reset b    mechanism ensures
perform many runs good configurations  error made every comparison two
configurations     decreases expectation 
difficult show limit  focusedils sample every parameter configuration
unbounded number times  proof relies fact that  instantiation paramils 
focusedils performs random restarts positive probability 
lemma    unbounded number evaluations   let n  j    denote number runs focusedils
performed parameter configuration end ils iteration j estimate c    then 
constant k configuration  with finite      limj p  n  j    k      
proof  ils iteration paramils  probability prestart     new configuration
picked uniformly random  probability       configuration   probability
   

fih utter   h oos   l eyton  b rown   utzle

procedure    betterf oc         
procedure used focusedils compare two parameter configurations  procedure objective   n  
returns user defined objective achieved a   first n instances  keeps track incumbent solution  updates r  a global cache algorithm runs performed parameter configuration    detailed procedure   page        n      length r    b global
counter denoting number configurations evaluated since last improvement step 
input
  parameter configuration     parameter configuration  
output
  true   dominates     false otherwise
side effect  adds runs global caches performed algorithm runs r  r    updates
global counter b bonus runs  potentially incumbent inc
  b b  
  n      n     
 
min     max  
 
n        n      b b    
else min     max  
repeat
n  min      
ci  max   objective max   i     n  min     n  max    adds new run rmax  
ci  min   objective min   i     adds new run rmin  
   dominates         dominates        
   dominates        
 
 
 
 
 

         perform b bonus runs 
  
  
  

cn      b      objective     n        b     adds b new runs r   
b  
return true

  

else return false

  
  
  

procedure dominates        
n        n      return false
return objective     n       objective     n      

visiting ils iteration thus p prestart
     hence  number runs performed
  
lower bounded binomial random
variable b k  j  p   then  constant k   k obtain
limj b k  j  p    limj jk pk    p jk      thus  limj p  n  j    k      
definition    consistent estimator   cn    consistent estimator c   iff
      lim p   cn    c            
n

cn    consistent estimator c    cost estimates become reliable
n approaches infinity  eventually eliminating overconfidence possibility mistakes
comparing two parameter configurations  fact captured following lemma 
lemma    no mistakes n    let       two parameter configurations
c       c      then  consistent estimators cn   limn p  cn      cn           
proof  write c  shorthand c      c  c      c  cn       c  cn       define
      c    c    midpoint c  c      c    c     
distance two points  since cn consistent estimator c  estimate
c  comes arbitrarily close real cost c    is  limn p   c  c             since
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

 m c        estimate c  cannot greater equal m  limn p  c  m      
similarly  limn p  c    m       since
p  c  c      p  c  c  c  m    p  c  c  c    m 
  p  c  c  c  m    p  c  c  c    c    m 
p  c  m    p  c    m  
limn p  c  c    limn  p  c  m    p  c    m               
combining two lemmata show limit  focusedils guaranteed
converge true best parameter configuration 
theorem    convergence focusedils   focusedils optimizes cost statistic c based
consistent estimator cn   probability finds true optimal parameter configuration
approaches one number ils iterations goes infinity 
proof  according lemma    n    grows unboundedly          
n      n      go infinity  lemma   states pairwise comparison  truly better
configuration preferred  thus eventually  focusedils visits finitely many parameter
configurations prefers best one others probability arbitrarily close one 
note many practical scenarios cost estimators may consistentthat is 
may fail closely approximate true performance given parameter configuration even
large number runs target algorithm  example  finite training set    used
configuration rather distribution problem instances  d  even large n   cn
accurately reflect cost parameter configurations training set    small
training sets    cost estimate based may differ substantially true cost defined
performance across entire distribution  d  larger training set    smaller
expected difference  it vanishes training set size goes infinity   thus  important use
large training sets  which representative distribution interest  whenever possible 

   adaptive capping algorithm runs
consider last dimensions automated algorithm configuration  cutoff time
run target algorithm  introduce effective simple capping technique
adaptively determines cutoff time run  motivation capping technique comes
problem encountered configuration procedures considered article  often
search performance optimizing parameter setting spends lot time evaluating parameter configuration much worse other  previously seen configurations 
consider  example  case parameter configuration   takes total    seconds
solve n       instances  i e   mean runtime     seconds per instance   another parameter configuration   takes     seconds solve first instances  order compare
mean runtimes     based set instances  knowing runtimes    
necessary run       instances  instead  already terminate first run  
     seconds  results lower bound   mean runtime            since
remaining    instances could take less zero time  lower bound exceeds mean
runtime     already certain comparison favour     insight
provides basis adaptive capping technique 
   

fih utter   h oos   l eyton  b rown   utzle

    adaptive capping basicils
section  introduce adaptive capping basicils  first introduce trajectory preserving
version adaptive capping  tp capping  provably change basicilss search trajectory lead large computational savings  modify strategy heuristically
perform aggressive adaptive capping  aggr capping   potentially yielding even better performance practice 
      rajectory  preserving c apping
observe comparisons parameter configurations paramils pairwise 
basicils n    comparisons based procedure bettern             either
best configuration encountered ils iteration best configuration last ils iteration  without adaptive capping  comparisons take long time  since poor parameter
configuration easily take order magnitude longer good configurations 
case optimizing mean non negative cost functions  such runtime solution
cost   implement bounded evaluation parameter configuration based n runs
given performance bound procedure objective  see procedure     procedure sequentially
performs runs parameter configuration run computes lower bound cn   
based n runs performed far  specifically  objective mean runtime
sum runtimes runs  divide sum n   since runtimes must
nonnegative  quantity lower bounds cn     lower bound exceeds bound passed
argument  skip remaining runs   order pass appropriate bounds
procedure objective  need slightly modify procedure bettern  see procedure   page     
adaptive capping  procedure objective bound additional third argument 
set line   bettern   cn      line   
approach results computation exactly function bettern used
original version basicils  modified procedure follows exactly search trajectory
would followed without capping  typically requires much less runtime  hence  within
amount overall running time  new version basicils tends able search
larger part parameter configuration space  although work focus objective
minimizing mean runtime decision algorithms  note adaptive capping approach
applied easily configuration objectives 
      aggressive c apping
demonstrate section      use trajectory preserving adaptive capping result
substantial speedups basicils  however  sometimes approach still less efficient
could be  upper bound cumulative runtime used capping computed
best configuration encountered current ils iteration  where new ils iteration begins
perturbation   opposed overall incumbent  perturbation resulted
new parameter configuration   new iterations best configuration initialized  
frequent case new performs poorly  capping criterion apply quickly
comparison performed overall incumbent 
counteract effect  introduce aggressive capping strategy terminate
evaluation poorly performing configuration time  heuristic extension
adaptive capping technique  bound evaluation parameter configuration per   

fiparam ils  n automatic lgorithm c onfiguration f ramework

procedure    objective   n  optional parameter bound 
procedure computes cn     either performing new runs exploiting previous cached runs 
optional third parameter specifies bound computation performed  parameter
specified  bound taken     n    number runs performed  
i e   length global array r   computing runtimes  count unsuccessful runs   
times cutoff time 
input
  parameter configuration   number runs  n   optional bound bound
output
  cn    cn    bound  otherwise large constant  maxpossibleobjective  plus
number instances remain unsolved bound exceeded
side effect  adds runs global cache performed algorithm runs  r   updates global
incumbent  inc
         maintain invariant  n  inc   n   
 
 

 
  inc n  inc     n
cn  inc   objective inc   n       adds n n  inc   runs rinc
         aggressive capping  update bound 

 

aggressive capping bound min bound  bm cn  inc   
         update run results tuple r  

      n
sum runtime sum runtimes r              r  i       tuple indices starting   
 i max max   n bound sum runtime 
n           oi   r  i 
n      i  i oi   unsuccessful   i    i oi    unsuccessful  
o i oi    previous run longer yet unsuccessful shorter yet successful re use result
 
else
  
o i objective newly executed run a   instance seed si captime
 
 
 
 
 

  
  
  
  

r  i        i   o i  
  n  sum runtime   o i     bound return maxpossibleobjective    n     
n   n  inc    sum runtimes r      sum runtimes rinc   inc
return   n  sum runtimes r  

formance incumbent parameter configuration multiplied factor call bound
multiplier  bm  comparison two parameter configurations   performed evaluations terminated preemptively  configuration solved
instances within allowed time taken better one   this behaviour achieved
line    procedure objective  keeps track number instances solved exceeding bound   ties broken favour moving new parameter configuration instead
staying current one 
depending bound multiplier  use aggressive capping mechanism may change
search trajectory basicils  bm   heuristic method reduces trajectorypreserving method  aggressive setting bm     means know parameter
configuration worse incumbent  stop evaluation  experiments set
bm      meaning lower bound performance configuration exceeds twice
performance incumbent solution  evaluation terminated   in section      revisit
choice bm      configuring parameters paramils itself  
   

fih utter   h oos   l eyton  b rown   utzle

    adaptive capping focusedils
main difference basicils focusedils latter adaptively varies number runs used evaluate parameter configuration  difference complicates 
prevent use adaptive capping  focusedils always compares pairs parameter configurations based number runs configuration  even though
number differ one comparison next 
thus  extend adaptive capping focusedils using separate bounds every number
runs  n   recall focusedils never moves one configuration    neighbouring
configuration      without performing least many runs   performed  
since keep track performance number runs n     bound
evaluation   always available  therefore  implement trajectory preserving
aggressive capping basicils 
basicils  focusedils inner workings adaptive capping implemented
procedure objective  see procedure     need modify procedure betterf oc  see procedure
  page      call objective right bounds  leads following changes
procedure betterf oc   subprocedure dominates line    takes bound additional
argument passes two calls objective line     two calls dominates
line    one call line    use bound cmax   three direct calls objective
lines          use bounds   cmax     respectively 

   experimental preliminaries
section give background information computational experiments presented
following sections  first  describe design experiments  next  present
configuration scenarios  algorithm benchmark data combinations  studied following section 
finally  describe low level details experimental setup 
    experimental design
describe objective function methods used selecting instances seeds 
      c onfiguration bjective   p enalized average runtime
section    mentioned algorithm configuration problems arise context various
different cost statistics  indeed  past work explored several them  maximizing solution
quality achieved given time  minimizing runtime required reach given solution quality 
minimizing runtime required solve single problem instance  hutter et al         
work focus objective minimizing mean runtime instances
distribution d  optimization objective naturally occurs many practical applications 
implies strong correlation c   amount time required obtain good
empirical estimate c    correlation helps make adaptive capping scheme effective 
one might wonder whether means right way aggregate runtimes  preliminary
experiments  found minimizing mean runtime led parameter configurations overall good runtime performance  including rather competitive median runtimes  minimizing
median runtime yielded less robust parameter configurations timed large  but       
fraction benchmark instances  however  encounter runs terminate within
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

given cutoff time mean ill defined  order penalize timeouts  define penalized
average runtime  par  set runs cutoff time max mean runtime
runs  unsuccessful runs counted p max penalization constant p   
study  use p      
      electing nstances eeds
mentioned previously  often finite set instances available upon evaluate
algorithm  case experiments report here  throughout study  configuration experiments performed training set containing half given benchmark instances 
remaining instances solely used test set evaluate found parameter configurations 
evaluations within paramils based n runs  selected n instances
random number seeds used following common blocking technique  see  e g   birattari
et al         ridge   kudenko         ensured whenever two parameter configurations
compared  cost estimates based exactly instances seeds 
serves avoid noise effects due differences instances use different seeds 
example  prevents us making mistake considering configuration better
configuration   tested easier instances 
dealing randomized target algorithms  tradeoff number
problem instances used number independent runs performed instance 
extreme case  given sample size n   one could perform n runs single instance
single run n different instances  latter strategy known result minimal variance
estimator common optimization objectives minimization mean runtime  which
consider study  maximization mean solution quality  see  e g   birattari        
consequently  performed multiple runs per instance wanted acquire
samples cost distribution instances training set 
based considerations  configuration procedures study article
implemented take list hinstance  random number seedi pairs one inputs  empirical
estimates cn    cost statistic c   optimized determined first n hinstance 
seedi pairs list  list hinstance  seedi pairs constructed follows  given training
set consisting problem instances  n   drew sample n instances uniformly
random without replacement added list  wished evaluate algorithm
samples training instances  could happen case randomized
algorithms  repeatedly drew random samples size described before 
batch corresponded random permutation n training instances  added final sample
size n mod     case n   sample drawn  paired
random number seed chosen uniformly random set possible seeds
added list hinstance  seedi pairs 
      c omparison c onfiguration p rocedures
since choice instances  and degree seeds  important final outcome
optimization  experimental evaluations always performed number independent
runs configuration procedure  typically      created separate list instances seeds
run explained above  kth run configuration procedure uses
kth list instances seeds   note  however  disjoint test set used measure performance
parameter configurations identical runs  
   

fih utter   h oos   l eyton  b rown   utzle

configuration scenario
p  swgcp
p e r  swgcp
p  qcp
p e r  qcp
c p l e x  r e g n    

type benchmark instances   citation
graph colouring  gent  hoos  prosser   walsh       
graph colouring  gent  hoos  prosser   walsh       
quasigroup completion  gomes   selman       
quasigroup completion  gomes   selman       
combinatorial auctions  cats   leyton brown  pearson   shoham       

table    overview five b r configuration scenarios 
algorithm
aps
pear

c plex

parameter type
continuous
categorical
integer
continuous
categorical
integer
continuous

  parameters type
 
  
 
  
  
 
 

  values considered
 
   
  
  
  
  
  

total   configurations    
     
         

         

table    parameter overview algorithms consider  information parameters algorithm given text 
detailed list parameters values considered found online appendix
http   www cs ubc ca labs beta projects paramils algorithms html 
performed paired statistical test compare final results obtained runs two
configuration procedures  paired test required since kth run procedures shared
kth list instances seeds  particular  performed two sided paired max wilcoxon
test null hypothesis difference performances  considering p values
     statistically significant  p values reported tables derived using
test  p values shown parentheses refer cases procedure expected perform better
actually performed worse 
    configuration scenarios
section    analyze configurators based five configuration scenarios  combining
high performance algorithm widely studied benchmark dataset  table   gives overview
these  dub b r scenarios  algorithms benchmark instance sets used
scenarios described detail sections              respectively  five
b r configuration scenarios  set fairly aggressive cutoff times five seconds per run
target algorithm allowed configuration procedure execute target algorithm
aggregate runtime five cpu hours  short cutoff times fairly short times algorithm
configuration deliberately chosen facilitate many configuration runs b r scenario  contrast  second set configuration scenarios  exclusively focusing c plex  
set much larger cutoff times allowed time configuration  defer description
scenarios section   
      target lgorithms
three target algorithms listed table   along configurable parameters 
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

aps first target algorithm used experiments aps  high performance dynamic
local search algorithm sat solving  hutter  tompkins   hoos        implemented ubcsat  tompkins   hoos         introduced       aps state of the art solver 
still performs competitively many instances  chose study algorithm
well known  relatively parameters  intimately familiar it  apss four
continuous parameters control scaling smoothing clause weights  well probability random walk steps  original default parameters set manually based experiments
prominent benchmark instances  manual experimentation kept percentage random
steps fixed took one week development time  subsequently gained
experience apss parameters general problem classes  hutter  hamadi  hoos  
leyton brown         chose promising intervals parameter  including  centered
at  original default  picked seven possible values parameter spread uniformly
across respective interval  resulting      possible parameter configurations  these exactly
values used hutter et al          starting configuration paramils  used
center point parameters domain 
pear second target algorithm considered pear  recent tree search algorithm
solving sat problems  pear state of the art sat solver industrial instances 
appropriate parameter settings best available solver certain types hardware
software verification instances  hutter  babic  hoos   hu         furthermore  configured
paramils  pear quantifier free bit vector arithmetic category      satisfiability
modulo theories competition  pear    parameters  including ten categorical  four integer 
twelve continuous parameters  default values manually engineered developer   manual tuning required one week   categorical parameters mainly control
heuristics variable value selection  clause sorting  resolution ordering  enable disable
optimizations  pure literal rule  continuous integer parameters mainly deal
activity  decay  elimination variables clauses  well interval randomized
restarts percentage random choices  discretized integer continuous parameters
choosing lower upper bounds reasonable values allowing three eight
discrete values spread relatively uniformly across resulting interval  including default 
served starting configuration paramils  number discrete values chosen according intuition importance parameter  discretization 
         possible parameter configurations  exploiting fact nine parameters
conditional  i e   relevant parameters take certain values  reduced          
configurations 
c plex third target algorithm used commercial optimization tool c plex        
massively parameterized algorithm solving mixed integer programming  mip  problems 
    user specifiable parameters  identified    parameters affect c plexs search trajectory  careful omit parameters change problem formulation  e g   changing
numerical accuracy solution   many c plex parameters deal mip strategy heuristics  such variable branching heuristics  probing  dive type subalgorithms 
amount type preprocessing performed  nine parameters governing
frequently different type cut used  those parameters four allowable
magnitude values value choose automatically  note last value prevents parameters ordinal   considerable number parameters deal simplex
   

fih utter   h oos   l eyton  b rown   utzle

barrier optimization  various algorithm components  categorical parameters
automatic option  considered categorical values well automatic one  contrast  continuous integer parameters automatic option  chose option instead
hypothesizing values might work well  identified numerical parameters
primarily deal numerical issues  fixed default values  numerical
parameters  chose five possible values seemed sensible  including default 
many categorical parameters automatic option  included automatic option choice
parameter  included manual options  finally  ended    configurable parameters  leading           possible configurations  exploiting fact seven
c plex parameters relevant conditional parameters taking certain values 
reduced           distinct configurations  starting configuration configuration
procedures  used default settings  obtained careful manual configuration
broad range mip instances 
      b enchmark nstances
applied target algorithms three sets benchmark instances  sat encoded quasi group
completion problems  sat encoded graph colouring problems based small world graphs 
mip encoded winner determination problems combinatorial auctions  set consisted
     instances  partitioned evenly training test sets 
qcp first benchmark set contained        instances quasi group completion problem  qcp   widely studied ai researchers  generated qcp instances
around solubility phase transition  using parameters given gomes selman        
specifically  order n drawn uniformly interval           number holes
h  open entries latin square  drawn uniformly             n       resulting
qcp instances converted sat cnf format  use complete solver  pear 
sampled      sat instances uniformly random  average      variables  standard deviation               clauses  standard deviation               
satisfiable  use incomplete solver  aps  randomly sampled      instances
subset satisfiable instances  determined using complete algorithm   number
variables clauses similar used pear 
sw gcp second benchmark set contained        instances graph colouring problem
 gcp  based small world  sw  graphs gent et al          these  sampled     
instances uniformly random use pear  average      variables  standard
deviation              clauses  standard deviation              satisfiable 
use aps  randomly sampled      satisfiable instances  again  determined using
complete sat algorithm   whose number variables clauses similar used
pear 
regions    third benchmark set generated      instances combinatorial auction
winner determination problem  encoded mixed integer linear programs  milps   used
regions generator combinatorial auction test suite  leyton brown et al         
goods parameter set     bids parameter set      resulting milp instances
contained     variables     inequalities average  standard deviation     variables
    inequalities 
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

scenario
p  swgcp
p e r  swgcp
p  qcp
p e r  qcp
c p l e x  r e g n    

default
     
    
     
    
    

test performance  penalized average runtime  cpu seconds 
mean stddev     runs
run best training performance
basicils
focusedils
basicils
focusedils
                   
    
    
        
       
   
   
                   
    
    
         
        
    
    
       
         
    
    

fig 
  a 
  b 
  c 
  d 
  e 

table    performance comparison default parameter configuration configurations found
basicils focusedils  both aggr capping bm       configuration scenario  list test performance  penalized average runtime      test instances  cpu seconds  algorithm default  mean stddev test performance across
   runs basicils        focusedils  run five cpu hours each   test performance run basicils focusedils best terms training performance  boldface indicates better basicils focusedils  algorithm configurations found focusedilss run best training performance listed online appendix http   www cs ubc ca labs beta projects paramils results html  column fig  gives reference scatter plot comparing performance configurations
algorithm defaults 

    experimental setup
carried experiments cluster    dual    ghz intel xeon pcs  mb
cache  gb ram  running opensuse linux       measured runtimes cpu time
reference machines  configuration procedures implemented ruby scripts 
include runtime scripts configuration time  easy configuration
scenarios  algorithm runs finish milliseconds  overhead scripts
substantial  indeed  longest configuration run observed took    hours execute five hours
worth target algorithm runtime  contrast  harder c plex scenarios described section
  observed virtually overhead 

   empirical evaluation basicils  focusedils adaptive capping
section  use b r scenarios empirically study performance basicils n  
focusedils  well effect adaptive capping  first demonstrate large speedups
paramils achieved default parameters study components responsible
success 
    empirical comparison default optimized parameter configurations
section  five b r configuration scenarios  compare performance
respective algorithms default parameter configuration final configurations found
basicils      focusedils  table   especially figure   show configurators led
substantial speedups 
table    report final performance achieved    independent runs configurator  independent configuration run  used different set training instances seeds
 constructed described section         note often rather large variance
performances found different runs configurators  configuration found
   

fih utter   h oos   l eyton  b rown   utzle

 

 

  

runtime  s   autotuned

runtime  s   autotuned

  

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 

  

 

  
 

 

  

 

  

 

  

  

 

  

 

 

  

 

  

runtime  s   default

  

 a  p  swgcp 
   s vs     s      vs timeouts
 

 

  

 

  

 

 

  

 

  

 

  

 

  

 

  

  

 

  

 

  

 

  

 

  

 

  

runtime  s   default

 c  p  qcp 
  s vs     s      vs   timeouts

 

  

 

  

 

 

  

 

  

 

  

 

  

 

  

 

  
 

 

  

  

runtime  s   autotuned

runtime  s   autotuned

 

  

 b  p e r  swgcp 
  s vs   s    vs   timeouts

  

  

 

  

runtime  s   default

 

  

runtime  s   autotuned

 

  

 

  

 

  

 

  

 

  

 

  

 

  
 

  

 

  

 

  

 

  

 

  

  

runtime  s   default

 d  p e r  qcp 
   s vs     s    vs   timeouts

 

 

  

 

  

 

  

 

  

 

  

 

  

 

  

runtime  s   default

 

  

 e  c p l e x  r e g n     
    s vs     s  timeouts

figure    comparison default vs automatically determined parameter configurations five b r
configuration scenarios  dot represents one test instance  timeouts  after one cpu hour 
denoted circles  dashed line five cpu seconds indicates cutoff time target
algorithm used configuration process  subfigure captions give mean runtimes
instances solved configurations  default vs optimized   well number
timeouts each 

run best training performance tended yield better test performance
others  reason  used configuration result algorithm configuration   note
choosing configuration found run best training set performance perfectly
legitimate procedure since require knowledge test set  course  improvements thus achieved come price increased overall running time  independent runs
configurator easily performed parallel  
figure    compare performance automatically found parameter configuration
default configuration  runs allowed last hour  speedups
obvious figure table    since penalized average runtime table counts
runtimes larger five seconds fifty seconds  ten times cutoff five seconds   whereas
data figure uses much larger cutoff time  larger speedups apparent scenarios
p  swgcp  p  qcp  p e r  qcp  corresponding speedup factors mean runtime
              respectively  see figure    
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

algorithm    randomsearch n     
outline random search parameter configuration space  inc denotes incumbent parameter
configuration  bettern compares two configurations based first n instances training
set 
input   number runs use evaluating parameter configurations  n   initial configuration
   
output   best parameter configuration inc found 
  inc    
  terminationcriterion  
 
random  
 
bettern    inc  
 
inc  
 

return inc

    empirical comparison basicils simple baselines
section  evaluate effectiveness basicils n   two components 
simple random search  used basicils initialization  we dub randomsearch n  
provide pseudocode algorithm    
simple local search  type iterative first improvement search used basicils n  
 we dub simplels n    
evaluate one component time  section section     study algorithms
without adaptive capping  investigate effect adaptive capping methods section
    
sufficient structure search space  expect basicils outperform randomsearch  local minima  expect basicils perform better simple local search 
experiments showed basicils indeed offer best performance 
here  solely interested comparing effectively approaches search space
parameter configurations  and found parameter configurations generalize unseen
test instances   thus  order reduce variance comparisons  compare configuration
methods terms performance training set 
table    compare basicils randomsearch b r configuration scenarios 
average  basicils always performed better  three five scenarios  difference
statistically significant judged paired max wilcoxon test  see section         table  
lists performance default parameter configuration scenarios  note
basicils randomsearch consistently achieved substantial  and statistically significant 
improvements default configurations 
next  compared basicils second component  simplels  basic local search
identical basicils  stops first local minimum encountered  used order
study whether local minima pose problem simple first improvement search  table   shows
three configuration scenarios basicils time perform multiple ils iterations 
training set performance statistically significantly better simplels  thus 
conclude search space contains structure exploited local search algorithm
well local minima limit performance iterative improvement search 
   

fih utter   h oos   l eyton  b rown   utzle

scenario
p  swgcp
p e r  swgcp
p  qcp
p e r  qcp
c p l e x  r e g n    

training performance  penalized average runtime  cpu seconds 
default randomsearch     
basicils     
     
         
         
     
         
         
     
          
         
    
         
         
    
         
         

p value
    
    
       
     
       

table    comparison randomsearch      basicils       without adaptive capping  table
shows training performance  penalized average runtime n       training instances  cpu
seconds   note approaches yielded substantially better results default configuration  basicils performed statistically significantly better randomsearch three
five b r configuration scenarios judged paired max wilcoxon test  see section
       
scenario
p  swgcp
p  qcp
p e r  qcp

simplels     
performance
        
         
        

basicils     
performance
avg    ils iterations
         
   
         
   
         
    

p value
       
       
     

table    comparison simplels      basicils       without adaptive capping  table shows
training performance  penalized average runtime n       training instances  cpu seconds   configuration scenarios p e r  swgcp c p l e x  r e g n      basicils complete first ils iteration    runs  two approaches thus identical
listed here  configuration scenarios  basicils found significantly better configurations
simplels 

    empirical comparison focusedils basicils
section investigate focusedilss performance experimentally  contrast previous comparison randomsearch  simplels  basicils using training performance 
compare focusedils basicils using test performance  becausein contrast basicils simplelsfocusedils grows number target algorithm runs used evaluate
parameter configuration time  even different runs focusedils  using different training sets
random seeds  use number target algorithm runs evaluate parameter configurations  however  eventually aim optimize cost statistic  c  therefore
test set performance  an unbiased estimator c  provides fairer basis comparison training performance  compare focusedils basicils  since basicils already outperformed
randomsearch simplels section     
figure   compares test performance focusedils basicils n   n        
     using single target algorithm run evaluate parameter configuration  basicils   
fast  generalize well test set all  example  configuration scenario
p  swgcp  basicils    selected parameter configuration whose test performance turned
even worse default  hand  using large number target algorithm runs
evaluation resulted slow search  eventually led parameter configurations
good test performance  focusedils aims achieve fast search good generalization test
set  configuration scenarios figure    focusedils started quickly led best
final performance 
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

 

 

mean runtime  s   test

mean runtime  s   test

  

 

  

 

  

 

  

basicils   
basicils    
basicils     
focusedils
 

  

 

 

   

 

 

  

   

  

basicils   
basicils    
basicils     
focusedils
 

  

cpu time used tuner  s 

 

 

  

  

cpu time used tuner  s 

 a  p  swgcp

 b  c p l e x  r e g n    

figure    comparison basicils n   n              vs focusedils  without adaptive
capping  show median test performance  penalized average runtime across       test
instances  across    runs configurators two scenarios  performance three
b r scenarios qualitatively similar  basicils    fastest move away
starting parameter configuration  performance robust all  basicils    
rather good compromise speed generalization performance  given enough time
outperformed basicils       focusedils started finding good configurations quickly
 except scenario p e r  qcp  took even longer basicils      improve
default  always amongst best approaches end configuration process 

scenario
p  swgcp
p e r  swgcp
p  qcp
p e r  qcp
c p l e x  r e g n    

test performance  penalized average runtime  cpu seconds 
default basicils     
focusedils
     
         
         
    
         
         
     
         
         
    
         
         
    
         
         

p value
       
      
     
      
       

table    comparison basicils      focusedils  without adaptive capping  table shows
test performance  penalized average runtime       test instances  cpu seconds  
configuration scenario  report test performance default parameter configuration  mean
stddev test performance reached    runs basicils      focusedils  pvalue paired max wilcoxon test  see section        difference two configurators
performance 

compare performance focusedils basicils      configuration scenarios table    three aps c plex scenarios  focusedils performed statistically significantly better basicils       results consistent past work focusedils achieved statistically significantly better performance basicils       hutter et al  
       however  found configuration scenarios involving pear algorithm 
basicils      actually performed better average focusedils  albeit statistically significantly  attribute fact complete  industrial solver pear  two
benchmark distributions qcp swgcp quite heterogeneous  expect focusedils
problems dealing highly heterogeneous distributions  due fact frequently tries
extrapolate performance based runs per parameter configuration 
   

fih utter   h oos   l eyton  b rown   utzle

 

   
basicils  capping
basicils  tp capping

mean runtime  s   train

mean runtime  s   train

  

 

  

 

  

 

  

 

 

  

  

basicils  capping
basicils  tp capping
 

   

 

   

   
  

 

  

cpu time used tuner  s 

 

  

 

  

cpu time used tuner  s 

 a  p  swgcp  significant 

 b  c p l e x  r e g n      significant 

figure    speedup basicils adaptive capping two configuration scenarios  performed   
runs basicils      without adaptive capping tp capping  time step 
computed training performance run configurator  penalized average runtime
n       training instances  plot median    runs 
scenario
p  swgcp
p e r  swgcp
p  qcp
p e r  qcp
c p l e x  r e g n    

training performance  penalized average runtime 
capping
tp capping
p value
         
         
       
         
         
    
         
         
       
                     
    
         
         
       

avg    ils iterations
capping tp capping
 
  
 
 
 
  
 
 
 
 

table    effect adaptive capping basicils       show training performance  penalized average runtime n       training instances  cpu seconds   configuration scenario 
report mean stddev final training performance reached    runs configurator without capping tp capping  p value paired max wilcoxon test difference
 see section         well average number ils iterations performed respective
configurator 

    empirical evaluation adaptive capping basicils focusedils
present experimental evidence use adaptive capping strong impact
performance basicils focusedils 
figure   illustrates extent tp capping sped basicils two configuration scenarios  cases  capping helped improve training performance substantially  p  swgcp 
basicils found solutions order magnitude faster without capping 
table   quantifies speedups five b r configuration scenarios  tp capping enabled
four times many ils iterations  in p  swgcp  improved average performance
scenarios  improvement statistically significant scenarios  except p e r  qcp 
aggressive capping improved basicils performance one scenario  scenario
p  swgcp  increased number ils iterations completed within configuration time
        leading significant improvement performance  first ils iteration
basicils  capping techniques identical  the best configuration iteration always
incumbent   thus  observe difference configuration scenarios p e r  swgcp
c p l e x  r e g n      none    runs configurator finished first ils iteration 
remaining two configuration scenarios  differences insignificant 
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

scenario
p  swgcp
p e r  swgcp
p  qcp
p e r  qcp
c p l e x  r e g n    

number ils iterations performed
capping
tp capping
p value
      
      
       
     
     
      
      
      
    
      
      
    
     
     
    

aggr capping
      
     
      
      
     

p value
       
     
     
       
       

number runs performed incumbent parameter configuration
scenario
capping
tp capping
p value
aggr capping
p value
p  swgcp
       
                                 
       
       
      
       
     
p e r  swgcp
p  qcp
                 
     
        
     
p e r  qcp
       
        
    
        
     
       
       
    
       
    
c p l e x  r e g n    

table    effect adaptive capping search progress focusedils  measured number ils
iterations performed number runs performed incumbent parameter configuration 
configuration scenario  report mean stddev measures across   
runs configurator without capping  tp capping  aggr capping  well
p values paired max wilcoxon tests  see section        differences capping
tp capping  capping aggr capping 

evaluate usefulness capping focusedils  training performance useful
quantity context comparing different versions focusedils  since number target
algorithm runs measure based varies widely runs configurator  instead 
used two measures quantify search progress  number ils iterations performed
number target algorithm runs performed incumbent parameter configuration  table  
shows two measures five b r configuration scenarios three capping schemes
 none  tp  aggr   focusedils tp capping achieved higher values without capping
scenarios measures  although differences statistically significant  
aggressive capping increased measures scenarios  differences
capping aggressive capping statistically significant  figure   demonstrates
two configuration scenarios focusedils capping reached solution qualities
quickly without capping  however  finding respective configurations  focusedils
showed significant improvement 
recall experiments section         compared various configurators without adaptive capping  one might wonder comparisons change presence adaptive
capping  indeed  adaptive capping worked box randomsearch enabled
evaluate        times many configurations without capping  improvement
significantly improved simple algorithm randomsearch point average performance came within    one basicils two domains  s p  swgcp p e r  swgcp 
compare much larger differences without capping reported table     p e r  qcp 
still     difference average performance  result significant  finally 
p  qcp c p l e x  r e g n     difference still substantial significant         
difference average performance  p values                 respectively  
adaptive capping reduced gap basicils focusedils  particular 
p  swgcp  where  even without adaptive capping  focusedils achieved best performance
encountered scenario  basicils caught using adaptive capping  similarly 
   

fih utter   h oos   l eyton  b rown   utzle

 

 
focusedils  capping
focusedils  tp capping
focusedils  aggr capping

mean runtime  s   test

mean runtime  s   test

  

 

  

 

  

 

  

 

  

 

  

 

  

focusedils  capping
focusedils  tpcapping
focusedils  aggr capping
   

 

   

   
  

 

  

cpu time used tuner  s 

 

  

 

  

 

  

 

  

cpu time used tuner  s 

 a  p  swgcp

 b  c p l e x  r e g n    

figure    speedup focusedils adaptive capping two configuration scenarios  performed   
runs focusedils without adaptive capping  tp capping aggr capping 
time step  computed test performance run configurator  penalized average
runtime      test instances  plot median    runs  differences
end trajectory statistically significant  however  capping time required
achieve quality lower two configuration scenarios  three scenarios 
gains due capping smaller 

c p l e x  r e g n      focusedils already performed well without adaptive capping
basicils not  here  basicils improved based adaptive capping  still could rival
focusedils  scenarios  adaptive capping affect relative performance much 
compare tables    without capping     with capping  details 

   case study  configuring c plex real world benchmarks
section  demonstrate paramils improve performance commercial optimization tool c plex variety interesting benchmark distributions  best knowledge 
first published study automatically configuring c plex 
use five c plex configuration scenarios  these  collected wide range mip benchmarks public benchmark libraries researchers  split      
disjoint training test sets  detail following 
regions    set almost identical regions    set  described section      
used throughout paper   instances much larger  generated       milp
instances generator provided combinatorial auction test suite  leytonbrown et al          based regions option goods parameter set    
bids parameter set        instances contain average       variables    
inequalities  respective standard deviations         
mja set comprises     machine job assignment instances encoded mixed integer
quadratically constrained programs  miqcp   obtained berkeley computational optimization lab  introduced akturk  atamturk s  gurel        
instances contain average       variables       constraints  respective
standard deviations             
   http   www ieor berkeley edu atamturk bcol   set called conic sch

   

fiparam ils  n automatic lgorithm c onfiguration f ramework

cls set comprises     capacitated lot sizing instances encoded mixed integer linear
programs  milp   obtained berkeley computational optimization lab
introduced atamturk munoz             instances contain     variables
    constraints 
mik set     milp encoded mixed integer knapsack instances obtained
berkeley computational optimization lab originally introduced atamturk
        instances contain average     variables     constraints  respective standard deviations         
qp set quadratic programs originated rna energy parameter optimization  andronescu  condon  hoos  mathews   murphy         mirela andronescu generated       instances experiments  instances contain            variables           
constraints  since instances polynomial time solvable quadratic programs  set
large number inconsequential c plex parameters concerning branch cut mechanism default values  ending    categorical    integer   continuous parameters configured  discretized parameter configuration space size            
study paramilss behavior harder problems  set significantly longer cutoff times
c plex scenarios b r scenarios previous section  specifically 
used cutoff time     cpu seconds run target algorithm training 
allotted two cpu days every run configurators  always  configuration
objective minimize penalized average runtime penalization constant    
table    compare performance c plexs default parameter configuration
final parameter configurations found basicils      focusedils  both aggressive capping bm       note that  similar situation described section      configuration
scenarios  e g   c p l e x  cls  c p l e x  mik  substantial variance different runs
configurators  run best training performance yielded parameter configuration
good test set  basicils outperformed focusedils    
scenarios terms mean test performance across ten runs  focusedils achieved better test
performance run best training performance one scenario  in performed almost well   scenarios c p l e x  r e g n     c p l e x  cls  focusedils performed
substantially better basicils 
note c plex configuration scenarios considered  basicils focusedils
found parameter configurations better algorithm defaults  sometimes
order magnitude  particularly noteworthy since ilog expended substantial effort
determine strong default c plex parameters  figure    provide scatter plots five scenarios  c p l e x  r e g n      c p l e x   c n c   c h   c p l e x  cls  c p l e x  mik  speedups quite
consistent across instances  with average speedup factors reaching   c p l e x   c n c   c h
   c p l e x  mik   finally  c p l e x  qp see interesting failure mode paramils 
optimized parameter configuration achieved good performance cutoff time used
   configuration scenario c p l e x  mik  nine ten runs focusedils yielded parameter configurations
average runtimes smaller two seconds  one run  however  demonstrated interesting failure mode focusedils aggressive capping  capping aggressively caused every c plex run unsuccessful 
focusedils selected configuration manage solve single instance test set  counting unsuccessful runs ten times cutoff time  resulted average runtime               seconds run 
 for full details  see section     hutter        

   

fih utter   h oos   l eyton  b rown   utzle

scenario
c p l e x  r e g n    
cp l e x c n c s c h
c p l e x  cls
c p l e x  mik
c p l e x  qp

test performance  penalized average runtime  cpu seconds 
mean stddev     runs
run best training performance
default
basicils
focusedils basicils
focusedils
  
     
        
  
    
    
         
        
    
    
   
       
       
  
    
    
     
         
    
    
   
       
       
   
   

fig 
  a 
  b 
  c 
  d 
  e 

table    experimental results c plex configuration scenarios 

configuration scenario  list test performance  penalized average runtime test instances  algorithm default  mean stddev test performance across ten runs basicils     
  focusedils  run two cpu days each   test performance run
basicils focusedils best terms training performance  boldface indicates better basicils focusedils  algorithm configurations found
focusedilss run best training performance listed online appendix
http   www cs ubc ca labs beta projects paramils results html 
column
fig  gives reference scatter plot comparing performance configurations
algorithm defaults 

configuration process      cpu seconds  see figure   f    performance carry
higher cutoff time used tests       cpu seconds  see figure   e    thus  parameter configuration found focusedils generalize well previously unseen test data 
larger cutoff times 

   review paramils applications
section  review number applications paramilssome dating back
earlier stages development  others recentthat demonstrate utility versatility 
    configuration saps  gls  sat j
hutter et al          first publication paramils  reported experiments three target algorithms demonstrate effectiveness approach  sat algorithm saps  which
  numerical parameters   local search algorithm gls  solving probable explanation  mpe  problem bayesian networks  which   numerical parameters  hutter  hoos  
stutzle         tree search sat solver sat j  which   categorical   numerical
parameters  http   www sat j org   compared respective algorithms default performance 
performance calibra system  adenso diaz   laguna         performance
basicils focusedils  four configuration scenarios studied  focusedils significantly outperformed calibra two performed better average third  fourth
one  configuring sat j   calibra applicable due categorical parameters 
focusedils significantly outperformed basicils 
overall  automated parameter optimization using paramils achieved substantial improvements
previous default settings  gls  sped factor        tuned parameters found
solutions better quality    seconds default found one hour   saps factors  
    saps qwh saps sw  respectively  sat j factor    
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

 

 

 

  

 

  

 

  

 

  

 

  

runtime  s   autotuned

 

  

  

 

  

 

  

 

  

 

  

 

  

 

  
 

  

 

  

 

  

 

  

 

  

 

  

runtime  s   default

 

  

 

  

 

  

 

  

 

  

 

 

  

runtime  s   default

 

  

 

  

 

  

 

  

  

 

  

 

  

 

  

 

  

  

runtime  s   default

 d  c p l e x  mik 
  s vs    s  timeouts

 

 

  

 
 

  

 

  

 

  

 

  

 

  

runtime  s   default

 

  

 c  c p l e x  cls 
   s vs     s  timeouts
 

  

 

  

 

  

 

  

 

  

 

  

 

 

  

 

  

 

  

 

  

 

  

 

  
 

 

  

 

runtime  s   autotuned

runtime  s   autotuned

 

  

 

  

  

 

 

 

  

  

  

  

 

  

 

 b  c p l e x   c n c   c h  
    s vs       s  timeouts

  

 

  

  
 

  

 a  c p l e x  r e g n     
  s vs     s  timeouts

runtime  s   autotuned

 

  

runtime  s   autotuned

runtime  s   autotuned

  

  
 

  

 

  

 

  

 

  

 

  

 

  

runtime  s   default

 e  c p l e x  qp 
   s vs    s    vs    timeouts

 

 

  

  

 

  

 

  

 

  

 

  

 

  

runtime  s   default

 

  

 f  c p l e x  qp  test cutoff    
seconds 
  s vs   s      vs     timeouts

figure    comparison default vs automatically determined parameter configuration five c plex
configuration scenarios  dot represents one test instance  time outs  after one cpu hour 
denoted red circles  blue dashed line     cpu seconds indicates cutoff time
target algorithm used configuration process  subfigure captions give mean
runtimes instances solved configurations  default vs optimized   well
number timeouts each 

    configuration spear industrial verification problems
hutter et al         applied paramils specific real world application domain  configuring
   parameters tree search dpll solver pear minimize mean runtime set
practical verification instances  particular  considered two sets industrial problem
instances  bounded model checking  bmc  instances zarpas        software verification
 swv  instances generated c alysto static checker  babic   hu        
instances problem distributions exhibited large spread hardness pear 
swv instances  default configuration solved many instances milliseconds failed
solve others days  despite fact pear specifically developed type
instances  developer generated problem instances  and thus intimate
domain knowledge   week manual performance tuning expended order
optimize solvers performance 
pear first configured good general performance industrial sat instances
previous sat competitions  already led substantial improvements default perfor   

fih utter   h oos   l eyton  b rown   utzle

mance      sat competition   pear default solved    instances ranked   th
first round competition  automatically configured version solved    instances
ranked  th  optimized version solved    instances  ranking  th  above minisat  
speedup factors due general optimization        swv bmc datasets 
respectively 
optimizing specific instance sets yielded further  much larger improvements  a factor
    swv     bmc   encouragingly  best parameter configuration found
software verification instances take longer    seconds solve swv
problem instances  compared multiple timeouts cpu day original default values  
key good performance application perform multiple independent runs focusedils  select found configuration best training performance  as done
sections       article  
    configuration satenstein
khudabukhsh  xu  hoos leyton brown         used paramils perform automatic algorithm
design context stochastic local search algorithms sat  specifically  introduced
new framework local search sat solvers  called satenstein  used paramils choose
good instantiations framework given instance distributions  satenstein spans three broad
categories sls based sat solvers  walksat based algorithms  dynamic local search algorithms
g  wsat variants  combined highly parameterized framework solver
total    parameters           unique instantiations 
focusedils used configure satenstein six different problem distributions 
resulting solvers compared eleven state of the art sls based sat solvers  results
showed automatically configured versions satenstein outperformed eleven
state of the art solvers six categories  sometimes large margin 
sat enstein work clearly demonstrated automated algorithm configuration methods
used construct new algorithms combining wide range components existing algorithms novel ways  thereby go beyond simple parameter tuning  due low
level manual work required approach  believe automated design algorithms
components become mainstream technique development algorithms hard
combinatorial problems 
key successful application focusedils configuring sat enstein careful
selection homogeneous instance distributions  instances could solved within
comparably low cutoff time    seconds per run  again  configuration best training
quality selected ten parallel independent runs focusedils per scenario 
    self configuration paramils
heuristic optimization procedure  paramils controlled number parameters 
number random configurations  r  sampled beginning search  perturbation
strength  s  probability random restarts  prestart   furthermore  aggressive capping
mechanism makes use additional parameter  bound multiplier  bm  throughout article 
used manually determined default values hr  s  prestart   bmi   h              i 
   see http   www cril univ artois fr sat    pear allowed participate second round
competition since source code publicly available 

   

fiparam ils  n automatic lgorithm c onfiguration f ramework

recent work  see section     hutter         evaluated whether focusedilss performance could improved using paramils automatically find better parameter configuration 
self configuration task  configuration scenarios play role instances  configurator optimized plays role target algorithm  avoid confusion  refer
configurator target configurator  here  set fairly short configuration times one cpu
hour target configurator  however  still significantly longer cutoff times
used experiments  parallelization turned crucial finish experiment reasonable amount time  basicils easier parallelize
focusedils  chose basicils      meta configurator 
although notion algorithm configurator configure intriguing 
case  turned yield small improvements  average performance improved four
five scenarios degraded remaining one  however  none differences
statistically significant 
    applications paramils
thachuk  shmygelska hoos         used basicils order determine performance optimizing
parameter settings new replica exchange monte carlo algorithm protein folding  dhp  d hp models   even though algorithm four parameters  two categorical
two continuous   basicils achieved substantial performance improvements  manuallyselected configurations biased favour either short long protein sequences  basicils
found configuration consistently yielded good mean runtimes types sequences 
average  speedup factor achieved approximately      certain classes protein
sequences    manually selected configurations performed worse previous
state of the art algorithm problem instances  robust parameter configurations
selected basicils yielded uniformly better performance 
recent work  fawcett  hoos chiarandini        used several variants paramils
 including version slightly extended beyond ones presented here  design
modular stochastic local search algorithm post enrollment course timetabling problem 
followed design approach used automated algorithm configuration order explore
large design space modular highly parameterised stochastic local search algorithms 
quickly led solver placed third track    nd international timetabling competition
 itc      subsequently produced improved solver shown achieve consistently
better performance top ranked solver competition 

   related work
many researchers us dissatisfied manual algorithm configuration  various
fields developed approaches automatic parameter tuning  start section
closely related workapproaches employ direct search find good parameter
configurationsand describe methods  finally  discuss work related problems 
finding best parameter configuration algorithm per instance basis  approaches
adapt parameters algorithms execution  see hoos        related
work automated algorithm design  
   basicils used  focusedils yet developed study conducted 

   

fih utter   h oos   l eyton  b rown   utzle

    direct search methods algorithm configuration
approaches automated algorithm configuration go back early     s  number
systems developed adaptive problem solving  one systems composer  gratch
  dejong         performs hill climbing search configuration space  taking moves
enough evidence gathered render neighbouring configuration statistically significantly
better current configuration  composer successfully applied improving five
parameters algorithm scheduling communication collection ground based
antennas spacecrafts  gratch   chien        
around time  multi tac system introduced minton               multitac takes input generic heuristics  specific problem domain  distribution problem instances  adapts generic heuristics problem domain automatically generates
domain specific lisp programs implementing them  beam search used choose best
lisp program program evaluated running fixed set problem instances
sampled given distribution 
another search based approach uses fixed training set introduced coy et al         
approach works two stages  first  finds good parameter configuration instance ii training set combination experimental design  full factorial fractional
factorial  gradient descent  next  combines parameter configurations             n thus determined setting parameter average values taken them  note
averaging step restricts applicability method algorithms numerical parameters 
similar approach  based combination experimental design gradient descent 
using fixed training set evaluation  implemented calibra system adenso diaz
laguna         calibra starts evaluating parameter configuration full factorial
design two values per parameter  iteratively homes good regions parameter
configuration space employing fractional experimental designs evaluate nine configurations
around best performing configuration found far  grid experimental design
refined iteration  local optimum found  search restarted  with coarser
grid   experiments showed calibras ability find parameter settings six target algorithms
matched outperformed respective originally proposed parameter configurations  main
drawback limitation tuning numerical ordinal parameters  maximum five
parameters  first introduced paramils  performed experiments comparing performance calibra  hutter et al          experiments reviewed section     
terashima marn et al         introduced genetic algorithm configuring constraint satisfaction algorithm large scale university exam scheduling  constructed configured
algorithm works two stages seven configurable categorical parameters  optimized choices genetic algorithm    problem instances 
found configuration improved performance modified brelaz algorithm  however  note
performed optimization separately instance  paper quantify
long optimizations took  stated issues time delivering solutions
method still matter research 
work automated parameter tuning found numerical optimization literature  particular  audet orban        proposed mesh adaptive direct search algorithm 
designed purely continuous parameter configuration spaces  algorithm guaranteed converge local optimum cost function  parameter configurations evaluated fixed
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

set large unconstrained regular problems cuter collection  using optimization objectives runtime number function evaluations required solving given problem instance 
performance improvements around     classical configuration four continuous parameters interior point methods reported 
algorithm configuration stochastic optimization problem  exists large body
algorithms designed problems  see  e g   spall         however  many algorithms
stochastic optimization literature require explicit gradient information thus inapplicable
algorithm configuration  algorithms approximate gradient function evaluations
 e g   finite differences   provably converge local minimum cost function
mild conditions  continuity  still  methods primarily designed deal
numerical parameters find local minima  aware applications general
purpose algorithms stochastic optimization algorithm configuration 
    methods algorithm configuration
sequential parameter optimization  spo   bartz beielstein        model based parameter optimization approach based design analysis computer experiments  dace  see  e g  
santner  williams   notz         prominent approach statistics blackbox function optimization  spo starts running target algorithm parameter configurations latin
hypercube design number training instances  builds response surface model based
gaussian process regression uses models predictions predictive uncertainties determine next parameter configuration evaluate  metric underlying choice promising
parameter configurations expected improvement criterion used jones  schonlau welch
        algorithm run  response surface refitted  new parameter configuration determined based updated model  contrast previously mentioned methods 
spo use fixed training set  instead  starts small training set doubles size
whenever parameter configuration determined incumbent already incumbent
previous iteration  recent improved mechanism resulted robust version  spo   hutter  hoos  leyton brown   murphy         main drawbacks spo variants 
fact entire dace approach  limitation continuous parameters optimizing
performance single problem instances  well cubic runtime scaling number data
points 
another approach based adaptations racing algorithms machine learning  maron  
moore        algorithm configuration problem  birattari et al               developed procedure dubbed f race used configure various stochastic local search algorithms  f race
takes input algorithm a  finite set algorithm configurations   instance distribution d  iteratively runs target algorithm surviving parameter configurations
number instances sampled  in simplest case  iteration runs surviving configurations one instance   configuration eliminated race soon enough statistical
evidence gathered it  iteration  non parametric friedman test used check
whether significant differences among configurations  case  inferior
configurations eliminated using series pairwise tests  process iterated
one configuration survives given cutoff time reached  various applications f race
demonstrated good performance  for overview  see birattari         however  since
start procedure candidate configurations evaluated  approach limited situations
space candidate configurations practically enumerated  fact  published ex   

fih utter   h oos   l eyton  b rown   utzle

periments f race limited applications around      configurations 
recent extension presented balaprakash et al         iteratively performs f race subsets
parameter configurations  approach scales better large configuration spaces  version
described balaprakash et al         handles algorithms numerical parameters 
    related algorithm configuration problems
point  focused problem finding best algorithm configuration
entire set  or distribution  problem instances  related approaches attempt find best
configuration algorithm per instance basis  adapt algorithm parameters
execution algorithm  approaches setting parameters per instance basis
described patterson kautz         cavazos oboyle         hutter et al         
furthermore  approaches attempt select best algorithm per instance basis
studied leyton brown  nudelman shoham         carchrae beck         gebruers 
hnich  bridge freuder         gagliolo schmidhuber         xu  hutter  hoos
leyton brown         related work  decisions restart algorithm made
online  run algorithm  horvitz  ruan  gomes  kautz  selman   chickering       
kautz  horvitz  ruan  gomes   selman        gagliolo   schmidhuber         so called reactive
search methods perform online parameter modifications  battiti  brunato   mascia        
last strategy seen complementary work  even reactive search methods tend
parameters remain fixed search hence configured using offline approaches
paramils 
    relation local search methods
since paramils performs iterated local search one exchange neighbourhood 
similar spirit local search methods problems  sat  selman  levesque  
mitchell        hoos   stutzle         csp  minton  johnston  philips   laird         mpe
 kask   dechter        hutter et al          since paramils local search method  existing
theoretical frameworks  see  e g   hoos        mengshoel         could principle used
analysis  main factor distinguishing problem ones faced standard local
search algorithms stochastic nature optimization problem  for discussion local
search stochastic optimization  see  e g   spall         furthermore  exists compact
representation objective function could used guide search  illustrate this 
consider local search sat  candidate variables flipped limited
occurring currently unsatisfied clauses  general algorithm configuration  hand 
mechanism cannot used  information available target algorithm
performance runs executed far  while  obviously   stochastic  local search
methods could used basis algorithm configuration procedures  chose iterated local
search  mainly conceptual simplicity flexibility 

    discussion  conclusions future work
work  studied problem automatically configuring parameters complex 
heuristic algorithms order optimize performance given set benchmark instances 
extended earlier algorithm configuration procedure  paramils  new capping mechanism
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

obtained excellent results applying resulting enhanced version paramils two
high performance sat algorithms well c plex wide range benchmark sets 
compared carefully chosen default configurations target algorithms  parameter configurations found paramils almost always performed much better evaluated
sets previously unseen test instances  configuration scenarios much two orders
magnitude  improvements c plexs default parameter configuration particularly
noteworthy  though claim found new parameter configuration c plex
uniformly better default  rather  given somewhat homogeneous instance set  find
configuration specific set typically outperforms default  sometimes factor high
    note achieved results even though intimately familiar c plex
parameters  chose parameters optimize well values consider based
single person day studying c plex user manual  success automated algorithm
configuration even extreme conditions demonstrates potential approach 
paramils source code executable freely available
http   www cs ubc ca labs beta projects paramils  
along quickstart guide data configuration scenarios studied article  
order apply paramils  automated algorithm configuration methods  practitioner must supply following ingredients 
parameterized algorithm must possible set configurable parameters externally  e g   command line call  often  search hard coded parameters hidden
algorithms source code lead large number additional parameters exposed 
domains parameters algorithm configurators must provided allowable
values parameter  depending configurator  may possible include additional knowledge dependencies parameters  conditional parameters
supported paramils  use paramils  numerical parameters must discretized
finite number choices  depending type parameter  uniform spacing
values spacing  uniform log scale  typically reasonable 
set problem instances homogeneous problem set interest is  better
expect algorithm configuration procedure perform it  possible
configure algorithm good performance rather heterogeneous instance sets  e g  
industrial sat instances  pear reported section       results
homogeneous subsets interest improve configure instances subset  whenever possible  set instances split disjoint training test sets
order safeguard over tuning  configuring small and or heterogeneous
benchmark set  paramils  or configuration procedure  might find configurations perform well independent test set 
objective function used median performance first study paramils
 hutter et al          since found cases optimizing median performance led
parameter configurations good median poor overall performance  cases 
optimizing mean performance yielded robust parameter configurations  however 
optimizing mean performance one define cost unsuccessful runs 
article  penalized runs counting ten times cutoff time 
deal unsuccessful runs principled manner open research question 
   paramils continues actively developed  currently maintained chris fawcett 

   

fih utter   h oos   l eyton  b rown   utzle

cutoff time unsuccessful runs smaller cutoff time run target
algorithm chosen  quickly configuration procedure able explore
configuration space  however  choosing small cutoff risks failure mode experienced c p l e x  qp scenario  recall there  choosing     seconds timeout
yielded parameter configuration good judged cutoff time  see
figure   f    performed poorly longer cutoffs  see figure   e    experiments  parameter configurations performing well low cutoff times turned scale
well harder problem instances well  many configuration scenarios  fact  noticed
automatically found parameter configurations showed much better scaling behaviour
default configuration  attribute use mean runtime configuration
objective  mean often dominated hardest instances distribution  however 
manual tuning  algorithm developers typically pay attention easier instances  simply
repeated profiling hard instances takes long  contrast  patient automatic
configurator achieve better results avoids bias 
computational resources amount  computational  time required application
automated algorithm configuration clearly depends target application  target
algorithm takes seconds solve instances homogeneous benchmark set interest 
experience single five hour configuration run suffice yield good results
domains achieved good results configuration times short half
hour  contrast  runs target algorithm slow performance large
cutoff time expected yield good results instances interest  time
requirements automated algorithm configuration grow  regularly perform multiple
parallel configuration runs pick one best training performance order deal
variance across configuration runs 
overall  firmly believe automated algorithm configuration methods paramils
play increasingly prominent role development high performance algorithms
applications  study methods rich fruitful research area many interesting questions remaining explored 
ongoing work  currently developing methods adaptively adjust domains
integer valued continuous parameters configuration process  similarly  plan
enhance paramils dedicated methods dealing continuous parameters require discretization user  another direction development concerns strategic
selection problem instances used evaluation configurations instance specific cutoff times used context  heuristically preventing configuration procedure spending inordinate amounts time trying evaluate poor parameter settings hard problem
instances  possible improve scalability 
believe significant room combining aspects methods studied
concepts related work similar algorithm configuration problems  particular 
believe would fruitful integrate statistical testing methodsas used  e g   f race
paramils  furthermore  see much potential use response surface models
active learning  believe combined approach  finally  algorithm
configuration problem studied article significant practical importance  much
gained studying methods related problems  particular  instance specific algorithm
configuration online adjustment parameters run algorithm 
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

acknowledgments
thank kevin murphy many helpful discussions regarding work  thank domagoj
babic  author pear  dave tompkins  author ubcsat aps implementation
used experiments  thank researchers provided instances instance
generators used work  particular gent et al          gomes selman         leytonbrown et al          babic hu         zarpas         le berre simon         akturk
et al          atamturk munoz         atamturk         andronescu et al          lin
xu created specific sets qcp swgcp instances used  thanks chris fawcett
ashique khudabukhsh comments draft article  finally  thank
anonymous reviewers well rina dechter adele howe valuable feedback  thomas
stutzle acknowledges support f r s  fnrs  research associate  holger
hoos acknowledges support nserc discovery grant        

references
adenso diaz  b    laguna  m          fine tuning algorithms using fractional experimental design
local search  operations research               
akturk  s  m   atamturk  a     gurel  s          strong conic quadratic reformulation machine job
assignment controllable processing times  research report bcol        university californiaberkeley 
andronescu  m   condon  a   hoos  h  h   mathews  d  h     murphy  k  p          efficient parameter
estimation rna secondary structure prediction  bioinformatics      i  i   
atamturk  a          facets mixedinteger knapsack polyhedron  mathematical programming 
           
atamturk  a    munoz  j  c          study lot sizing polytope  mathematical programming     
       
audet  c    orban  d          finding optimal algorithmic parameters using mesh adaptive direct search
algorithm  siam journal optimization                
babic  d    hu  a  j          structural abstraction software verification conditions  w  damm  h  h 
 ed    computer aided verification    th international conference  cav       volume      lecture
notes computer science   pp           springer verlag  berlin  germany 
balaprakash  p   birattari  m     stutzle  t          improvement strategies f race algorithm  sampling design iterative refinement  bartz beielstein  t   aguilera  m  j  b   blum  c   naujoks 
b   roli  a   rudolph  g     sampels  m   eds     th international workshop hybrid metaheuristics  mh      pp          
bartz beielstein  t          experimental research evolutionary computation  new experimentalism  natural computing series  springer verlag  berlin  germany 
battiti  r   brunato  m     mascia  f          reactive search intelligent optimization  volume   
operations research computer science interfaces  springer verlag  available online http   reactivesearch org thebook 
birattari  m          problem tuning metaheuristics seen machine learning perspective 
phd thesis  universite libre de bruxelles  brussels  belgium 
birattari  m   stutzle  t   paquete  l     varrentrapp  k          racing algorithm configuring metaheuristics  langdon  w  b   cantu paz  e   mathias  k   roy  r   davis  d   poli  r   balakrishnan  k  
honavar  v   rudolph  g   wegener  j   bull  l   potter  m  a   schultz  a  c   miller  j  f   burke  e  
  jonoska  n   eds    proceedings genetic evolutionary computation conference  gecco        pp         morgan kaufmann publishers  san francisco  ca  usa 
   

fih utter   h oos   l eyton  b rown   utzle

carchrae  t    beck  j  c          applying machine learning low knowledge control optimization
algorithms  computational intelligence                
cavazos  j    oboyle  m  f  p          method specific dynamic compilation using logistic regression 
cook  w  r   ed    proceedings acm sigplan international conference object oriented programming  systems  languages  applications  oopsla       pp            new york  ny  usa 
acm press 
coy  s  p   golden  b  l   runger  g  c     wasil  e  a          using experimental design find effective
parameter settings heuristics  journal heuristics             
diao  y   eskesen  f   froehlich  s   hellerstein  j  l   spainhower  l     surendra  m          generic online
optimization multiple configuration parameters application database server  brunner  m   
keller  a   eds      th ifip ieee international workshop distributed systems  operations management  dsom      volume      lecture notes computer science   pp        springer verlag 
berlin  germany 
fawcett  c   hoos  h  h     chiarandini  m          automatically configured modular algorithm post
enrollment course timetabling  technical report tr          university british columbia  department
computer science 
gagliolo  m    schmidhuber  j          dynamic algorithm portfolios  amato  c   bernstein  d     zilberstein  s   eds    ninth international symposium artificial intelligence mathematics  ai math     
gagliolo  m    schmidhuber  j          learning restart strategies  veloso  m  m   ed    proceedings
twentieth international joint conference artificial intelligence  ijcai     volume     pp     
      morgan kaufmann publishers  san francisco  ca  usa 
gebruers  c   hnich  b   bridge  d     freuder  e          using cbr select solution strategies constraint programming  munoz avila  h    ricci  f   eds    proceedings  th international conference case based reasoning  iccbr     volume      lecture notes computer science   pp 
         springer verlag  berlin  germany 
gent  i  p   hoos  h  h   prosser  p     walsh  t          morphing  combining structure randomness 
hendler  j    subramanian  d   eds    proceedings sixteenth national conference artificial
intelligence  aaai      pp            orlando  florida  aaai press   mit press  menlo park  ca 
usa 
gomes  c  p    selman  b          problem structure presence perturbations  kuipers  b   
webber  b   eds    proceedings fourteenth national conference artificial intelligence  aaai    
 pp           aaai press   mit press  menlo park  ca  usa 
gratch  j    chien  s  a          adaptive problem solving large scale scheduling problems  case
study  journal artificial intelligence research            
gratch  j    dejong  g          composer  probabilistic solution utility problem speed up
learning  rosenbloom  p    szolovits  p   eds    proceedings tenth national conference
artificial intelligence  aaai      pp           aaai press   mit press  menlo park  ca  usa 
hoos  h  h          mixture model behaviour sls algorithms sat  proceedings
eighteenth national conference artificial intelligence  aaai       pp            edmonton  alberta 
canada 
hoos  h  h          computer aided design high performance algorithms  technical report tr         
university british columbia  department computer science 
hoos  h  h    stutzle  t          stochastic local search foundations   applications  morgan kaufmann
publishers  san francisco  ca  usa 
horvitz  e   ruan  y   gomes  c  p   kautz  h   selman  b     chickering  d  m          bayesian
approach tackling hard computational problems  breese  j  s    koller  d   eds    proceedings
seventeenth conference uncertainty artificial intelligence  uai      pp           morgan
kaufmann publishers  san francisco  ca  usa 
   

fiparam ils  n automatic lgorithm c onfiguration f ramework

hutter  f          automated configuration algorithms solving hard computational problems  phd
thesis  university british columbia  department computer science  vancouver  canada 
hutter  f   babic  d   hoos  h  h     hu  a  j          boosting verification automatic tuning decision
procedures  proceedings formal methods computer aided design  fmcad      pp         
washington  dc  usa  ieee computer society 
hutter  f   hamadi  y   hoos  h  h     leyton brown  k          performance prediction automated
tuning randomized parametric algorithms  benhamou  f   ed    principles practice constraint programming cp       twelfth international conference  volume      lecture notes
computer science   pp           springer verlag  berlin  germany 
hutter  f   hoos  h     leyton brown  k          tradeoffs empirical evaluation competing algorithm designs  technical report tr          university british columbia  department computer
science 
hutter  f   hoos  h  h   leyton brown  k     murphy  k  p          experimental investigation
model based parameter optimisation  spo beyond  proceedings genetic evolutionary
computation conference  gecco         pp          
hutter  f   hoos  h  h     stutzle  t          efficient stochastic local search mpe solving  proceedings
nineteenth international joint conference artificial intelligence  ijcai      pp          
hutter  f   hoos  h  h     stutzle  t          automatic algorithm configuration based local search 
howe  a    holte  r  c   eds    proceedings twenty second national conference artificial
intelligence  aaai      pp             aaai press   mit press  menlo park  ca  usa 
hutter  f   tompkins  d  a  d     hoos  h  h          scaling probabilistic smoothing  efficient dynamic
local search sat  hentenryck  p  v   ed    principles practice constraint programming
cp       eighth international conference  volume      lecture notes computer science   pp 
         springer verlag  berlin  germany 
johnson  d  s          theoreticians guide experimental analysis algorithms  goldwasser 
m  h   johnson  d  s     mcgeoch  c  c   eds    data structures  near neighbor searches  methodology  fifth sixth dimacs implementation challenges   pp           american mathematical society  providence  ri  usa 
jones  d  r   schonlau  m     welch  w  j          efficient global optimization expensive black box
functions  journal global optimization             
kask  k    dechter  r          stochastic local search bayesian networks  seventh international
workshop artificial intelligence statistics  aistats    
kautz  h   horvitz  e   ruan  y   gomes  c  p     selman  b          dynamic restart policies  dechter 
r   kearns  m     sutton  r   eds    proceedings eighteenth national conference artificial
intelligence  aaai      pp           aaai press   mit press  menlo park  ca  usa 
khudabukhsh  a   xu  l   hoos  h  h     leyton brown  k          satenstein  automatically building local search sat solvers components  proceedings twenty first international joint conference
artificial intelligence  ijcai      pp          
le berre  d    simon  l          fifty five solvers vancouver  sat      competition  hoos  h  h 
  mitchell  d  g   eds    theory applications satisfiability testing  proceedings seventh
international conference  sat     volume      lecture notes computer science   pp          
springer verlag 
leyton brown  k   nudelman  e     shoham  y          learning empirical hardness optimization
problems  case combinatorial auctions  hentenryck  p  v   ed    principles practice
constraint programming cp       eighth international conference  volume      lecture notes
computer science   pp           springer verlag  berlin  germany 
leyton brown  k   pearson  m     shoham  y          towards universal test suite combinatorial
auction algorithms  jhingran  a   mason  j  m     tygar  d   eds    ec     proceedings  nd
   

fih utter   h oos   l eyton  b rown   utzle

acm conference electronic commerce   pp          new york  ny  usa  acm 
lourenco  h  r   martin  o     stutzle  t          iterated local search  f  glover   g  kochenberger
 eds    handbook metaheuristics  pp           kluwer academic publishers  norwell  ma  usa 
maron  o    moore  a          hoeffding races  accelerating model selection search classification
function approximation  cowan  j  d   tesauro  g     alspector  j   eds    advances neural
information processing systems    nips      volume     pp         morgan kaufmann publishers  san
francisco  ca  usa 
mengshoel  o  j          understanding role noise stochastic local search  analysis experiments  artificial intelligence                   
minton  s          analytic learning system specializing heuristics  bajcsy  r   ed    proceedings
thirteenth international joint conference artificial intelligence  ijcai      pp           morgan
kaufmann publishers  san francisco  ca  usa 
minton  s          automatically configuring constraint satisfaction programs  case study  constraints 
          
minton  s   johnston  m  d   philips  a  b     laird  p          minimizing conflicts  heuristic repair
method constraint satisfaction scheduling problems  artificial intelligence                
patterson  d  j    kautz  h          auto walksat  self tuning implementation walksat  electronic
notes discrete mathematics  endm     
ridge  e    kudenko  d          sequential experiment designs screening tuning parameters
stochastic heuristics  paquete  l   chiarandini  m     basso  d   eds    workshop empirical methods
analysis algorithms ninth international conference parallel problem solving
nature  ppsn    pp        
santner  t  j   williams  b  j     notz  w  i          design analysis computer experiments 
springer verlag  new york 
selman  b   levesque  h  j     mitchell  d          new method solving hard satisfiability problems 
rosenbloom  p    szolovits  p   eds    proceedings tenth national conference artificial
intelligence  aaai      pp           aaai press   mit press  menlo park  ca  usa 
spall  j  c          introduction stochastic search optimization  new york  ny  usa  john wiley  
sons  inc 
terashima marn  h   ross  p     valenzuela rendon  m          evolution constraint satisfaction strategies examination timetabling  proceedings genetic evolutionary computation conference
 gecco         pp           morgan kaufmann 
thachuk  c   shmygelska  a     hoos  h  h          replica exchange monte carlo algorithm protein
folding hp model  bmc bioinformatics            
tompkins  d  a  d    hoos  h  h          ubcsat  implementation experimentation environment
sls algorithms sat   max sat  theory applications satisfiability testing  proceedings seventh international conference  sat     volume        pp           springer verlag 
berlin  germany 
xu  l   hutter  f   hoos  h  h     leyton brown  k          satzilla  portfolio based algorithm selection
sat  journal artificial intelligence research             
zarpas  e          benchmarking sat solvers bounded model checking  bacchus  f    walsh  t 
 eds    theory applications satisfiability testing  proceedings eighth international conference  sat     volume      lecture notes computer science   pp           springer verlag 

   


