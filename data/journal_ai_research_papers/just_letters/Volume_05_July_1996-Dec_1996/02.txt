journal of artificial intelligence research               

submitted       published     

cue phrase classification using machine learning
diane j  litman

at t labs   research      mountain avenue
murray hill  nj       usa

diane research att com

abstract

cue phrases may be used in a discourse sense to explicitly signal discourse structure  but
also in a sentential sense to convey semantic rather than structural information  correctly
classifying cue phrases as discourse or sentential is critical in natural language processing
systems that exploit discourse structure  e g   for performing tasks such as anaphora resolution and plan recognition  this paper explores the use of machine learning for classifying
cue phrases as discourse or sentential  two machine learning programs  cgrendel and
c     are used to induce classification models from sets of pre classified cue phrases and
their features in text and speech  machine learning is shown to be an effective technique
for not only automating the generation of classification models  but also for improving
upon previous results  when compared to manually derived classification models already
in the literature  the learned models often perform with higher accuracy and contain new
linguistic insights into the data  in addition  the ability to automatically construct classification models makes it easier to comparatively analyze the utility of alternative feature
representations of the data  finally  the ease of retraining makes the learning approach
more scalable and exible than manual methods 

   introduction

cue phrases are words and phrases that may sometimes be used to explicitly signal discourse
structure in both text and speech  in particular  when used in a discourse sense  a cue
phrase explicitly conveys structural information  when used in a sentential sense  a cue
phrase instead conveys semantic rather than structural information  the following examples
 taken from a spoken language corpus that will be described in section    illustrate sample
discourse and sentential usages of the cue phrases  say  and  further  
 discourse
       we might have the concept of say a researcher who has worked for fifteen years
on a certain project        
 further  and this is crucial in ai and probably for expert databases as well        
 sentential
       let me just say that it bears a strong resemblance to much of the work that s
done in semantic nets and even frames  
       from a place that is even stranger and further away        
for example  when used in the discourse sense  the cue phrase  say  conveys the structural
information that an example is beginning  when used in the sentential sense   say  does
not convey any structural information and instead functions as a verb 
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

filitman

the ability to correctly classify cue phrases as discourse or sentential is critical for
natural language processing systems that need to recognize or convey discourse structure 
for tasks such as improving anaphora resolution  grosz   sidner        reichman        
consider the following example  again taken from the corpus that will be described in
section     
if the system attempts to hold rules  say as an expert database for an expert system 
then we expect it not only to hold the rules but to in fact apply them for us in
appropriate situations 
in this example  the cue phrases  say  and  then  are discourse usages  and explicitly
signal the boundaries of an intervening subtopic in the discourse structure  furthermore 
the referents of the noun phrases  the system    an expert database   and  an expert
system  are all possible referents for the pronoun  it   with the structural information
conveyed by the cue phrases  the system can determine that  the system  is more relevant
for interpreting the pronoun  it   as both  an expert database  and  an expert system 
occur within the embedded  and now concluded  subtopic  without the cue phrases  the
reasoning required to determine that the referent of the  the system  is the intended referent
of  it  would be much more complex 
correctly classifying cue phrases as discourse or sentential is important for other natural
language processing tasks as well  the discourse sentential distinction can be used to
improve the naturalness of synthetic speech in text to speech systems  hirschberg        
text to speech systems generate synthesized speech from unrestricted text  if a cue phrase
can be classified as discourse or sentential using features of the input text  it can then be
synthesized using different intonational models for the discourse and sentential usages  in
addition  by explicitly identifying rhetorical and other relationships  discourse usages of cue
phrases can be used to improve the coherence of multisentential texts in natural language
generation systems  zuckerman   pearl        moser   moore         cue phrases can
also be used to reduce the complexity of discourse processing in such areas as argument
understanding  cohen        and plan recognition  litman   allen        grosz   sidner 
      
while the problem of cue phrase classification has often been noted  grosz   sidner 
       until recently  models for classifying cue phrases were neither developed nor evaluated
based on careful empirical analyses  even though the literature suggests that some features
might be useful for cue phrase classification  there are no quantitative analyses of any actual
classification algorithms that use such features  nor any suggestions as to how different types
of features might be combined   most systems that recognize or generate cue phrases simply
assume that discourse uses are utterance or clause initial  reichman        zuckerman  
pearl         while there are empirical studies showing that the intonational prominence
of certain word classes varies with respect to discourse function  halliday   hassan       
altenberg         these studies do not investigate cue phrases per se 
to address these limitations  hirschberg and litman        conducted several empirical
studies specifically addressing cue phrase classification in text and speech  hirschberg and
litman pre classified a set of naturally occurring cue phrases  described each cue phrase in
terms of prosodic and textual features  the features were posited in the literature or easy
   this example is also described in more detail by hirschberg and litman        

  

ficue phrase classification using machine learning

to automatically code   then manually examined the data to construct classification models
that best predicted the classifications from the feature values 
this paper examines the utility of machine learning for automating the construction
of models for classifying cue phrases from such empirical data  a set of experiments are
described that use two machine learning programs  cgrendel  cohen              and
c     quinlan         to induce classification models from sets of pre classified cue phrases
and their features  the features  classes and training examples used in the studies of
hirschberg and litman         as well as additional features  classes and training examples  are given as input to the machine learning programs  the results are evaluated both
quantitatively and qualitatively  by comparing both the error rates and the content of the
manually derived and learned classification models  the experimental results show that
machine learning is indeed an effective technique  not only for automating the generation
of classification models  but also for improving upon previous results  the accuracy of
the learned classification models is often higher than the accuracy of the manually derived
models  and the learned models often contain new linguistic implications  the learning
paradigm also makes it easier to compare the utility of different knowledge sources  and to
update the model given new features  classes  or training data 
the next section summarizes previous work on cue phrase classification  section  
then describes the machine learning approach to cue phrase classification that is taken in
this paper  in particular  the section describes four sets of experiments that use machine
learning to automatically induce cue phrase classification models  the types of inputs and
outputs of the machine learning programs are presented  as are the methodologies that are
used to evaluate the results  section   presents and discusses the experimental results  and
highlights the many benefits of the machine learning approach  section   discusses the
practical utility of the results of this paper  finally  section   discusses the use of machine
learning in other studies of discourse  while section   concludes 

   previous work on classifying cue phrases
this section summarizes hirschberg s and litman s empirical studies of the classification of
cue phrases in speech and text  hirschberg   litman              litman   hirschberg 
       hirschberg s and litman s data  cue phrases taken from corpora of recorded and
transcribed speech  classified as discourse or sentential  and coded using both speech based
and text based features  will be used to create the input for the machine learning experiments  hirschberg s and litman s results  performance figures for manually developed cue
phrase classification models  will be used as a benchmark for evaluating the performance
of the classification models produced by machine learning 
the first study by hirschberg and litman investigated usage of the cue phrase  now 
by multiple speakers in a radio call in show  hirschberg   litman         a classification
model based on prosodic features was developed based on manual analysis of a  training 
set of    examples of  now   then evaluated on a previously unseen test set of    examples
of  now   in a follow up study  hirschberg   litman         hirschberg and litman tested
this classification model on a larger set of cue phrases  namely all single word cue phrases
in a technical keynote address by a single speaker  this corpus yielded     instances of   
  

filitman

prosodic model 

if composition of intermediate phrase   alone then
elseif composition of intermediate phrase    alone then
if position in intermediate phrase   first then
if accent   deaccented then
elseif accent   l  then
elseif accent   h  then
elseif accent   complex then
elseif position in intermediate phrase    first then

discourse

discourse

discourse

sentential

sentential

sentential

   
   
   
   
   
   
   
   

textual model 

if preceding orthography   true then
elseif preceding orthography   false then

   
    

discourse
sentential

figure    decision tree representation of the manually derived classification models of
hirschberg and litman 
different single word cue phrases derived from the literature   hirschberg and litman also
used the cue phrases in the first    minutes of this corpus to develop a complementary cue
phrase classification model based on textual features  litman   hirschberg         which
they then tested on the full corpus  hirschberg   litman         the first study will be
referred to as the  now  study  and the follow up study as the  multiple cue phrase  study 
note that the term  multiple  means that    different single word cue phrases  as opposed
to just the cue phrase  now   are considered  not that cue phrases consisting of multiple
words  e g   by the way   are considered 
the method that hirschberg and litman used to develop their prosodic and textual classification models was as follows  they first separately classified each example cue phrase in
the data as discourse  sentential or ambiguous while listening to a recording and reading a
transcription   each example was also described as a set of prosodic and textual features  
previous observations in the literature correlating discourse structure with prosodic information  and discourse usages of cue phrases with initial position in a clause  contributed to
the choice of features  the set of classified and described examples was then examined in
order to manually develop the classification models shown in figure    these models are
shown here using decision trees for ease of comparison with the results of c    and will be
explained below 
prosody was described using pierrehumbert s theory of english intonation  pierrehumbert         in pierrehumbert s theory  intonational contours are described as sequences
of low  l  and high  h  tones in the fundamental frequency  f   contour  the physical
   figure   contains a list of the    cue phrases  hirschberg and litman        provide full details regarding
the distribution of these cue phrases  the most frequent cue phrase is  and   which occurs     times 
the next most frequent cue phrase is  now   which occurs    times   but    like    or  and  so  also
each occur more than fifty times  the four least frequent cue phrases    essentially    otherwise    since 
and  therefore    each occur   times 
   the class ambiguous was not introduced until the multiple cue phrase study  hirschberg   litman       
litman   hirschberg        
   although a limited set of textual features were noted in the  now  data  the analysis of the  now  data
did not yield a textual classification model 

  

ficue phrase classification using machine learning

correlate of pitch   intonational contours have as their domain the intonational phrase 
a finite state grammar describes the set of tonal sequences for an intonational phrase  a
well formed intonational phrase consists of one or more intermediate phrases followed by a
boundary tone  a well formed intermediate phrase has one or more pitch accents followed
by a phrase accent  boundary tones and phrase accents each consist of a single tone  while
pitch accents consist of either a single tone or a pair of tones  there are two simple pitch
accents  h  and l   and four complex accents  l  h  l h   h  l  and h l    the
  indicates which tone is aligned with the stressed syllable of the associated lexical item 
note that not every stressed syllable is accented  lexical items that bear pitch accents are
called accented  while those that do not are called deaccented 
prosody was manually transcribed by hirschberg by examining the fundamental frequency  f   contour  and by listening to the recording  this transcription process was
performed separately from the process of discourse sentential classification  to produce the
f  contour  the recording of the corpus was digitized and pitch tracked using speech analysis software  this resulted in a display of the f  where the x axis represented time and the
y axis represented frequency in hz  various phrase final characteristics  e g   phrase accents 
boundary tones  as well as pauses and syllable lengthening  helped to identify intermediate
and intonational phrases  while peaks or valleys in the display of the f  contour helped to
identify pitch accents  similar manual transcriptions of prosodic phrasing and accent have
been shown to be reliable across coders  pitrelli  beckman    hirschberg        
once prosody was coded  hirschberg and litman represented every cue phrase in terms
of the following prosodic features   accent corresponded to the pitch accent  if any  that
was associated with the cue phrase  for both the intonational and intermediate phrases
containing each cue phrase  the feature composition of phrase represented whether or not
the cue phrase was alone in the phrase  the phrase contained only the cue phrase  or only
the cue phrase and other cue phrases   position in phrase represented whether the cue
phrase was first  the first lexical item in the prosodic phrase unit   possibly preceded by
other cue phrases  or not 
the textual features used in the multiple cue phrase study  hirschberg   litman       
litman   hirschberg        were extracted automatically from the transcript  the part of
speech of each cue phrase was obtained by running a program for tagging words with one of
approximately    parts of speech  church        on the transcript   several characteristics
of the cue phrase s immediate context were also noted  in particular  whether it was immediately preceded or succeeded by orthography  punctuation or a paragraph boundary  
and whether it was immediately preceded or succeeded by a lexical item corresponding to
another cue phrase 
with this background  the classification models shown in figure   can now be explained 
the prosodic model uniquely classifies any cue phrase using the features composition of
intermediate phrase  position in intermediate phrase  and accent  when a cue phrase is
uttered as a single intermediate phrase   possibly with other cue phrases  i e   line     in
figure     or in a larger intermediate phrase with an initial position  possibly preceded by
   only the features used in figure   are discussed here 
   another syntactic feature   dominating constituent   was obtained by running the parser fidditch  hindle 
      on the transcript  however  since this feature did not appear in any models manually derived from
the training data  litman   hirschberg         the feature was not pursued 

  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
prosodic
         
         
textual
         
         
default class
         
         

table        confidence intervals for the error rates     of the manually derived classification models of hirschberg and litman  testing data  multiple cue phrase corpus  
other cue phrases  and a l  accent or deaccented  it is classified as discourse  when part of
a larger intermediate phrase and either in initial position with a h  or complex accent  or
in a non initial position  it is sentential  the textual model classifies cue phrases using only
the single feature preceding orthography   when a cue phrase is preceded by any type of
orthography  it is classified as discourse  otherwise  the cue phrase is classified as sentential 
when the prosodic model was used to classify each cue phrase in its training data  i e  
the     examples of  now  from which the model was developed  the error rate was       
the error rate of the textual model on the training examples from the multiple cue phrase
corpus was        litman   hirschberg        
the prosodic and textual models were evaluated by quantifying their performance in
correctly classifying example cue phrases in two test sets of data  as shown in the rows
labeled  prosodic  and  textual  in table    each test set is a subset of the     examples
from the multiple cue phrase corpus  the first test set      examples  consists of only the
classifiable cue phrases  i e   the cue phrases that both hirschberg and litman classified as
discourse or that both classified as sentential  note that those cue phrases that hirschberg
and litman classified as ambiguous or that they were unable to agree upon are not included
in the classifiable subset   these cue phrases will be considered in the learning experiments
described in section      however   the second test set  the classifiable non conjuncts
     examples   was created from the classifiable cue phrases by removing all instances of
 and    or  and  but   this subset was considered particularly reliable since       of nonconjuncts were classifiable compared to       of all example cue phrases  the error rate of
the prosodic model was       for the classifiable cue phrases and       for the classifiable
non conjuncts  hirschberg   litman         the error rate of the textual model was      
for the classifiable cue phrases and       for the classifiable non conjuncts  hirschberg  
litman         the last row of the table shows error rates for a simple  default class 
baseline model that always predicts the most frequent class in the corpus  sentential   these
rates are       for the classifiable cue phrases and       for the classifiable non conjuncts 
   a classification model based on part of speech was also developed  litman   hirschberg       
hirschberg   litman         however  it did not perform as well as the model based on orthography
 the error rate of the part of speech model was       in the larger test set  as opposed to       for the
orthographic model   furthermore  a model that combined orthography and part of speech performed
comparably to the simpler orthographic model  hirschberg   litman         hirschberg and litman
also had preliminary observations suggesting that adjacency of cue phrases might prove useful 
   following hirschberg and litman         the original     and    example sets  hirschberg   litman 
      are combined 

  

ficue phrase classification using machine learning

although not computed by hirschberg and litman  table   also associates margins of errors with each error percentage  which are used to compute confidence intervals  freedman 
pisani    purves          the margin of error is    standard errors for a     confidence
interval using a normal table   the lower bound of a confidence interval is computed by
subtracting the margin of error from the error rate  while the upper bound is computed by
adding the margin of error  thus  the     confidence interval for the prosodic model on
the classifiable cue phrase test set is                 analysis of the confidence intervals
indicates that the improvement of both the prosodic and textual models over the default
model is significant  for example  the upper bounds of the error rates of the prosodic and
textual models on the classifiable cue phrase test set         and         are both lower
than the lower bound of the default class error rate          this methodology of using statistical inference to determine whether differences in error rates are significant is discussed
more fully in section     

   experiments using machine learning

this section describes experiments that use the machine learning programs c     quinlan 
      and cgrendel  cohen              to automatically induce cue phrase classification
models  cgrendel and c    are similar to each other and to other learning methods such
as neural networks and cart  brieman  friedman  olshen    stone        in that all induce
classification models from preclassified examples  each program takes the following inputs 
names of the classes to be learned  names and possible values of a fixed set of features  and
the training data  i e   a set of examples for which the class and feature values are specified  
the output of each program is a classification model  expressed in c    as a decision tree
and in cgrendel as an ordered set of if then rules  both cgrendel and c    learn the
classification models using greedy search guided by an  information gain  metric 
the first group of machine learning experiments replicate the training and testing conditions used by hirschberg and litman         reviewed in the previous section   to support
a direct comparison of the manual and machine learning approaches  the second group of
experiments evaluate the utility of training from larger amounts of data than was feasible
for the manual analysis of hirschberg and litman  the third set of experiments allow the
machine learning algorithms to distinguish among the    cue phrases  to evaluate the utility of developing classification models specialized for particular cue phrases  the fourth set
of experiments consider all the examples in the multiple cue phrase corpus  not just the
classifiable cue phrases  this set of experiments attempt to predict a third classification
unknown  as well as the classifications discourse and sentential  finally  within each of these
four sets of experiments  each individual experiment learns a classification model using a
different feature representation of the training data  some experiments consider features in
isolation  to comparatively evaluate the utility of each individual feature for classification 
other experiments consider linguistically motivated sets of features  to gain insight into
feature interactions 

    the machine learning inputs

this section describes the inputs to both of the machine learning programs  namely  the
names of the classifications to be learned  the names and possible values of a fixed set of
  

filitman

classification
judge  judge 
all cue phrases
non conjuncts

total
   
   

classifiable cue phrases
discourse sentential
d d
s s
   
   
   
   

unknown
    d s s d d   s     d   s
  
 
 
 
 
 
 
  
 
 
 
 
 
 

table    determining the classification of cue phrases 
features  and training data specifying the class and feature values for each example in the
training set 
      classifications

the first input to each learning program specifies the names of a fixed set of classifications 
hirschberg and litman s   way classification of cue phrases by   judges  hirschberg  
litman        is transformed into the classifications used by the machine learning programs
as shown in table    recall from section   that each judge classified each cue phrase as
discourse  sentential  or ambiguous  these classifications are shown as d  s  and   in table   
as discussed in section    the classifiable cue phrases are those cue phrases that the judges
both classified as either discourse or as sentential usages  thus  in the machine learning
experiments  a cue phrase is assigned the classification discourse if both judges classified it
as discourse  d d  as shown in column   of table     similarly  a cue phrase is assigned the
classification sentential if both judges classified it as sentential  s s  as shown in column
                of the     examples in the full corpus were classifiable  while            
of the     non conjuncts were classifiable 
for some of the machine learning experiments  a third cue phrase classification will also
be considered  in particular  a cue phrase is assigned the classification unknown if both
hirschberg and litman classified it as ambiguous       as shown in column     or if they
were unable to agree upon its classification  d s  s d  d    s      d    s  as shown in
columns        in the full corpus     cue phrases        were judged ambiguous by both
judges        there were only   cases       of true disagreement  d s      cue phrases
       were judged ambiguous by the first judge but classified by the second judge    d
and   s   when the conjunctions  and    or  and  but  were removed from the corpus 
only    examples        were judged ambiguous by both judges    instances of  actually  
  instances each of  because  and  essentially   and   instance of  generally    indeed  
 like  and  now   there was only   case       of true disagreement  an instance of  like   
  cue phrases         an instance each of  like  and  otherwise    were judged ambiguous
by the first judge 
      features

a second component of the input to each learning program specifies the names and potential
values of a fixed set of features  the set of primitive features considered in the learning
experiments are shown in figure    feature values can either be a numeric value or one of a
fixed set of user defined symbolic values  the feature representation shown here follows the
representation of hirschberg and litman except as noted  length of intonational phrase  p  

ficue phrase classification using machine learning

 prosodic features

  length of intonational phrase  p l   integer 
  position in intonational phrase  p p   integer 
  length of intermediate phrase  i l   integer 
  position in intermediate phrase  i p   integer 
  composition of intermediate phrase  i c   only  only cue phrases  other 
  accent  a   h   l   l  h  l h   h  l  h l   deaccented  ambiguous 
  accent   a    h   l   complex  deaccented  ambiguous 
 textual features
  preceding cue phrase  c p   true  false  na 
  succeeding cue phrase  c s   true  false  na 
  preceding orthography  o p   comma  dash  period  paragraph  false  na 
  preceding orthography   o p    true  false  na 
  succeeding orthography  o s   comma  dash  period  false  na 
  succeeding orthography   o s    true  false  na 
  part of speech  pos   article  coordinating conjunction  cardinal numeral  subordinating conjunction 
preposition  adjective  singular or mass noun  singular proper noun  intensifier  adverb  verb base form 
na 

 lexical feature

  token  t   actually  also  although  and  basically  because  but  essentially  except  finally  first  further 

generally  however  indeed  like  look  next  no  now  ok  or  otherwise  right  say  second  see  similarly 
since  so  then  therefore  well  yes 

figure    representation of features  for use by c    and cgrendel 
l  and length of intermediate phrase  i l  represent the number of words in the intonational
and intermediate phrases containing the cue phrase  respectively  this feature was not coded
in the  now  data  but was coded  although not used  in the later multiple cue phrase
data  position in intonational phrase  p p  and position in intermediate phrase  i p  use
numeric values rather than the earlier symbolic values  e g   first in figure     composition
of intermediate phrase  i c  replaces the value alone  meaning that the phrase contained
only the example cue phrase  or only the example plus other cue phrases  from figure  
with the more primitive values only and only cue phrases  whose disjunction is equivalent to
alone   i c also uses the value other rather than  alone  as was used in figure     accent
 a  uses the value ambiguous to represent all cases where the prosodic analysis yields a
disjunction  e g    h  l or h     accent   a   re represents some of the symbolic values
of the feature accent  a  using a more abstract level of description  in particular  l  h 
l h   h  l  and h l  are represented as separate values in a but as a single value   the
superclass complex   in a   while useful abstractions can often result from the learning
process  a  is explicitly represented in advance as it is a prosodic feature representation
that has the potential to be automated  see section    
in all the textual features  the value na  not applicable  reects the fact that    recorded
examples were not included in the transcription  which was done independently of the
  

filitman

studies performed by hirschberg and litman         in the coding used by hirschberg and
litman  preceding cue phrase  c p  and succeeding cue phrase  c s  represented the actual
cue phrase  e g    and   when there was a preceding or succeeding cue phrase  here the value
true encodes all such cases  as with the prosodic feature set a   preceding orthography 
 o p   and succeeding orthography   o s   re represent some of the symbolic values of
preceding orthography  o p  and succeeding orthography  o s   respectively  using a more
abstract level of description  e g   comma  dash  and period are represented as separate values
in o s but as the single value true in o s    this is done because the reliability of coding
detailed transcriptions of orthography is not known  part of speech  pos  represents the
part of speech assigned to each cue phrase by church s program for tagging part of speech in
unrestricted text  church         while the program can assign approximately    different
values  only the subset of values that were actually assigned to the cue phrases in the
transcripts of the corpora are shown in the figure  finally  the lexical feature token  t  is
new to this study  and represents the actual cue phrase being described 
      training data

the final input to each learning program is training data  i e   a set of examples for which
the class and feature values are specified  consider the following utterance  taken from the
multiple cue phrase corpus  hirschberg   litman        
example     now   now that we have all been welcomed here   it s time to get on with
the business of the conference 
this utterance contains two cue phrases  corresponding to the two instances of  now   the
brackets and parentheses illustrate the intonational and intermediate phrases  respectively 
that contain the example cue phrases  note that a single intonational phrase contains both
examples  but that each example is uttered in a different intermediate phrase  if we were
only interested in the feature length of intonational phrase  p l   the two examples would
be represented in the training data as follows 
p l class
  discourse
  sentential
the first column indicates the value assigned to the feature p l  while the second column
indicates how the example was classified  thus  the length of the intonational phrase
containing the first instance of  now  is   words  and the example cue phrase is classified
as a discourse usage  if we were only interested in the feature composition of intermediate
phrase  i c   the two examples would instead be represented in the training data as follows 
i c class
only discourse
other sentential
that is  the intermediate phrase containing the first instance of  now  contains only the
cue phrase  now   while the intermediate phrase containing the second instance of  now 
contains  now  as well as   other lexical items that are not cue phrases  note that while
the value of p l is the same for both examples  the value of i c is different 
  

ficue phrase classification using machine learning

    the machine learning outputs

the output of both machine learning programs are classification models  in c    the model
is expressed as a decision tree  which consists of either a leaf node  a class assignment   or a
decision node  a test on a feature  with one branch and subtree for each possible outcome of
the test   the following example illustrates the non graphical representation for a decision
node testing a feature with n possible values 
if test  then      
   

elseif testn then

   

tests are of the form  feature operator value      feature  is the name of a feature  e g 
accent   while  value  is a valid value for that feature  e g   deaccented   for features with
symbolic values  e g   accent   there is one branch for each symbolic value  and the operator
    is used  for features with numeric values  e g   length of intonational phrase   there
are two branches  each comparing the numeric value with a threshold value  the operators
   and     are used  given a decision tree  a cue phrase is classified by starting at the
root of the tree and following the appropriate branches until a leaf is reached  section  
shows example decision trees produced by c    
in cgrendel the classification model is expressed as an ordered set of if then rules of
the following form 
if test            testk then class
the  if  part of a rule is a conjunction of tests on the values of  varying  features  where
tests are again of the form  feature operator value   as in c      feature  is the name of
a feature  and  value  is a valid value for that feature  unlike c     the operators   or  
 
are used for features with symbolic values  while  or  are used for features with numeric
values  the  then  part of a rule specifies a class assignment  e g  discourse   given a set
of if then rules  a cue phrase is classified using the rule whose  if  part is satisfied  if there
or two or more such rules and the rules disagree on the class of an example  cgrendel
applies one of two conict resolution strategies  chosen by the user   choose the first rule 
or choose the rule that is most accurate on the data  the experiments reported here use
the second strategy  if there are no such rules  cgrendel assigns a default class  section  
shows example rules produced by cgrendel 
both c    and cgrendel learn their classification models using greedy search guided
by an  information gain  metric  c    uses a divide and conquer process  training examples
are recursively divided into subsets  using the tests discussed above   until all of the subsets
belong to a single class  the test chosen to divide the examples is that which maximizes
a metric called a gain ratio  a local measure of progress  which does not consider any
subsequent tests   this metric is based on information theory and is discussed in detail by
quinlan         once a test is selected  there is no backtracking  ideally  the set of chosen
tests should result in a small final decision tree  cgrendel generates its set of if then rules
using a method called separate and conquer  to highlight the similarity with divide and
conquer  
   an additional type of test may be invoked by a c    option 

  

filitman

many rule learning systems generate hypotheses using a greedy strategy in which
rules are added to the rule set one by one in an effort to form a small cover of
the positive examples  each rule  in turn is created by adding one condition
after another to the antecedent until the rule is consistent with the negative
data   cohen       
although cgrendel is claimed to have two advantages over c     these advantages do
not come into play for the experiments reported here  first  if then rules appear to be easier
for people to understand than decision trees  quinlan         however  for the cue phrase
classification task  the decision trees produced by c    are quite compact and thus easily
understood  furthermore  a rule representation can be derived from c    decision trees 
using the program c   rules  second  cgrendel allows users to exploit prior knowledge of
a learning problem  by constraining the syntax of the rules that can be learned  however  no
prior knowledge is exploited in the cue phrase experiments  the main reason for using both
c    and cgrendel is to increase the reliability of any comparisons between the machine
learning and manual results  in particular  if comparable results are obtained using both
c    and cgrendel  then any performance differences between the learned and manually
derived classification models are less likely to be due to the specifics of a particular learning
program  and more likely to reect the learned manual distinction 

    evaluation

the output of each machine learning experiment is a classification model that has been
learned from the training data  these learned models are qualitatively evaluated by examining their linguistic content  and by comparing them with the manually derived models of
figure    the learned models are also quantitatively evaluated by examining their error
rates on testing data and by comparing these error rates to each other and to the error
rates shown in table    the error rate of a classification model is computed by using the
model to predict the classifications for a set of examples where the classifications are already
known  then comparing the predicted and known classifications  in the cue phrase domain 
the error rate is computed by summing the number of discourse examples misclassified as
sentential with the number of sentential examples misclassified as discourse  then dividing
by the total number of examples 
the error rates of the learned classification models are estimated using two methodologies  train and test error rate estimation  weiss   kulikowski         holds out  a test
set of examples  which are not seen until after training is completed  that is  the model is
developed by examining only the training examples  the error of the model is then estimated
by using the model to classify the test examples  this was the evaluation method used by
hirschberg and litman  the resampling method of cross validation  weiss   kulikowski 
      estimates error rate using multiple train and test experiments  for example  in   fold cross validation  instead of dividing examples into training and test sets once     runs of
the learning program are performed  the total set of examples is randomly divided into   
disjoint test sets  each run thus uses the     of the examples not in the test set for training
and the remaining     for testing  note that for each iteration of the cross validation  the
learning process begins from scratch  thus a new classification model is learned from each
training sample  an estimated error rate is obtained by averaging the error rate on the test  

ficue phrase classification using machine learning

ing portion of the data from each of the    runs  while this method does not make sense for
humans  computers can truly ignore previous iterations  for sample sizes in the hundreds
 the classifiable subset of the multiple cue phrase sample and the classifiable non conjunct
subset provide     and     examples  respectively     fold cross validation often provides
a better performance estimate than the hold out method  weiss   kulikowski         the
major advantage is that in cross validation all examples are eventually used for testing  and
almost all examples are used in any given training run 
the best performing learned models are identified by comparing their error rates to
the error rates of the other learned models and to the manually derived error rates  to
determine whether the fact that an error rate e  is lower than another error rate e  is
also significant  statistical inference is used  in particular  confidence intervals for the two
error rates are computed  at a     confidence level  when an error rate is estimated using
only a single error rate on a test set  i e   the train and test methodology   the confidence
interval is computed using a normal approximation to the binomial distribution  freedman
et al          when the error rate is estimated using the average from multiple error
rates  i e   the cross validation methodology   the confidence interval is computed using a
t table  freedman et al          if the upper bound of the     confidence interval for e 
is lower than the lower bound of the     confidence interval for the error rate e   then the
difference between e  and e  is assumed to be significant   

    the experimental conditions
this section describes the conditions used in each set of machine learning experiments  the
experiments differ in their use of training and testing corpora  methods for estimating error
rates  and in the features and classifications used  the actual results of the experiments are
presented in section   
      four sets of experiments

the learning experiments can be conceptually divided into four sets  each experiment in
the first set estimates error rate using the train and test method  where the training and
testing samples are those used by hirschberg and litman         the  now  data and the
two subsets of the multiple cue phrase corpus  respectively   this allows a direct comparison
of the manual and machine learning approaches  however  only the prosodic experiments
conducted by hirschberg and litman        are replicated  the textual training and testing
conditions are not replicated as the original training corpus  the first    minutes of the
multiple cue phrase corpus   litman   hirschberg        is a subset of  rather than disjoint
from  the test corpus  the full    minutes of the multiple cue phrase corpus   hirschberg  
litman        
in contrast  each experiment in the second set uses cross validation to estimate error
rate  furthermore  both training and testing samples are taken from the multiple cue
phrase corpus  each experiment uses     of the examples from the multiple cue phrase
data for training  and the remaining     for testing  thus each experiment in the second
set trains from much larger amounts of data      classifiable examples  or     classifiable
    thanks to william cohen for suggesting this methodology 

  

filitman

prosody
hl  features
phrasing
length
position
intonational
intermediate
text
adjacency
orthography
preceding
succeeding
speech text

p l
x
x
x
x

p p i l i p
x x x
x
x x x
x
x
x
x
x x

i c a a 
x x x
x x x
x
x

c p

x
x
x

x

x

x

x

x

x

x

x

c s o p

x
x
x
x

o p  o s

o s  pos

x

x

x

x

x
x

x
x

x

x

x

x

x
x

x
x

x

x

table    multiple feature sets and their components 
non conjuncts  than each experiment in the first set       nows    the reliability of the
testing is not compromised due to the use of cross validation  weiss   kulikowski        
each experiment in the third set replicates an experiment in the second set  with the exception that the learning program is now allowed to distinguish between cue phrases  this
is done by adding a feature representing the cue phrase  the feature token from figure   
to each experiment from the second set  since the potential use of such a lexical feature
was noted but not used by hirschberg and litman         these experiments provide qualitatively new linguistic insights into the data  for example  the same features may now be
used differently to predict the classifications of different cue phrases or sets of cue phrases 
finally  each experiment in the fourth set replicates an experiment in the first  second 
and third set  with the exception that all     examples in the multiple cue phrase corpus
are now considered  this is because in practice  any learned cue phrase classification model
will likely be used to classify all cue phrases  even those that are dicult for human judges
to classify  the experiments in the fourth set allow the learning programs to attempt to
learn the class unknown  in addition to the classes discourse and sentential 
      feature representations within experiment sets

within each of these four sets of experiments  each individual experiment represents the
data using a different subset of the available features  first  the data is represented in
each of    single feature sets  corresponding to each prosodic and textual feature shown in
figure    these experiments comparatively evaluate the utility of each individual feature
for classification  the representations of example   shown above illustrate how data is
represented using the single feature set p l  and using the single feature set i c 
second  the data is represented in each of the    multiple feature sets shown in table   
each of these sets contains a linguistically motivated subset of at least   of the    features 
the first   sets use only prosodic features  prosody considers all the prosodic features that
were coded for each example cue phrase  hl  features considers only the coded features
that were also used in the model shown in figure    phrasing considers all features of both
the intonational and intermediate phrases containing the example cue phrase  i e   length
  

ficue phrase classification using machine learning

example     

   now that we have all been welcomed here   it s time to get on with the business of the conference 
p p i l i p i c
a
a 
c p c s o p o p  o s o s  pos class
 
 
  only h  l complex f
t
par  t
f
f
adv  disc 
 
 
  other h 
h 
t
f
f
f
f
f
adv  sent 
now

p l
 
 

figure    representation of example   in feature set speech text 
of phrase  position of example in phrase  and composition of phrase   length and position
each consider only one of these features  but with respect to both the intonational and
intermediate phrase  conversely  intonational and intermediate each consider only one type
of phrase  but consider all of the features  the next   sets use only textual features  text
considers all the textual features  adjacency and orthography each consider a single textual
feature  but consider both the preceding and succeeding immediate context  preceding and
succeeding consider contextual features relating to both orthography and cue phrases  but
limit the context  the last set  speech text  uses all of the prosodic and textual features 
figure   illustrates how the two example cue phrases in example   would be represented
using speech text  consider the feature values for the first example cue phrase  since this
example is the first lexical item in both the intonational and intermediate phrases which
contain it  its position in both phrases  p p and i p  is    since the intermediate phrase
containing the cue phrase contains no other lexical items  its length  i l  is   word and its
composition  i c  is only the cue phrase  the values for a and a  indicate that when the
intonational phrase is described as a sequence of tones  the complex pitch accent h  l is
associated with the cue phrase  with respect to the textual features  the utterance was
transcribed such that it began a new paragraph  thus the example cue phrase was not
preceded by another cue phrase  c p   but it was preceded by a form of orthography  o p
and o p    since the example cue phrase was immediately followed by another instance
of  now  in the transcription  the cue phrase was succeeded by another cue phrase  c s 
but was not succeeded by orthography  o s and o s    finally  the output of the part of
speech tagging program when run on the transcript of the corpus yields the value adverb
for the cue phrase s part of speech  pos  
the first set of experiments replicate only the prosodic experiments conducted by
hirschberg and litman         cue phrases are represented using the subset of the feature sets that only consist of prosodic features  in the second set of experiments  examples
are represented using all    different feature sets  the    single feature sets and the   
multiple feature sets   in the third set of experiments  examples are represented using   
tokenized feature sets  constructed by adding the lexical feature token from figure    the
cue phrase being described  to each of the    single and    multiple feature sets from the
second set of experiments  these tokenized feature sets will be referred to using the names
of the single and multiple feature sets  concatenated with      the following illustrates
how the two cue phrases in example   would be represented using p l  
p l t
class
  now discourse
  now sentential
  

filitman

the representation is similar to the p l representation shown earlier  except for the second
column which indicates the value assigned to the feature token  t  

   results

this section examines the results of running the two learning programs   c    and cgrendel   in the four sets of cue phrase classification experiments described above  the learned
classification models will be compared with the classification models shown in figure   
while the error rates of the learned classification models will be compared with the error
rates shown in table   and with the error rates of the other learned models  as will be
seen  the results suggest that machine learning is useful for automating the generation of
linguistically viable classification classification models  for generating classification models
that perform with lower error rates than manually developed hypotheses  and for adding to
the body of linguistic knowledge regarding cue phrases 

    experiment set    replicating hirschberg and litman

the first group of experiments replicate the training  testing  and evaluation conditions
used by hirschberg and litman         in order to investigate how well machine learning
performs in comparison to the manual development of cue phrase classification models 
figure   shows the best performing prosodic classification models learned by the two
machine learning programs  the top of the figure replicates the manually derived prosodic
model from figure   for ease of comparison  when all of the prosodic features are used
to represent the     training examples of  now   i e   each example is represented using
feature set prosody from table       the classification models that are learned are shown
after the manually derived model at the top of figure    note that using both learning
programs  the same decision tree is also learned when the smaller feature sets phrasing and
position are used to represent the  now  data  the bottom portion of the figure shows the
classification models that are learned when the same examples are represented using only
the single prosodic feature position in intonational phrase  p p   the same model is also
learned when the examples are represented using the multiple feature set intonational 
recall that c    represents each learned classification model as a decision tree  each
level of the tree  shown by indentation  specifies a test on a single feature  with a branch for
every possible outcome of the test  a branch can either lead to the assignment of a class  or
to another test  for example  the c    classification model learned from prosody classifies
cue phrases using the two features position in intonational phrase  p p  and position in
intermediate phrase  i p   note that not all of the available features in prosody  recall
table    are used in the decision tree  the tree initially branches based on the value of
the feature position in intonational phrase    the first branch leads to the class assignment
discourse  the second branch leads to a test of the feature position in intermediate phrase 
the first branch of this test leads to the class assignment discourse  while the second branch
leads to sentential  c    produces both unsimplified and pruned decision trees  the goal
    in experiment set    the feature set prosody does not contain the features p l and i l  recall that
phrasal length was only coded in the later multiple cue phrase study 
    for ease of comparison to figure    the original symbolic representation of the feature value is used
rather than the integer representation shown in figure   

  

ficue phrase classification using machine learning

manually derived prosodic model  repeated from figure    

if composition of intermediate phrase   alone then
elseif composition of intermediate phrase    alone then
if position in intermediate phrase   first then
if accent   deaccented then
elseif accent   l  then
elseif accent   h  then
elseif accent   complex then
elseif position in intermediate phrase    first then

discourse

discourse

discourse

sentential

sentential

sentential

   
   
   
   
   
   
   
   

decision tree learned from prosody  from phrasing  and from position using c    

if position in intonational phrase   first then
elseif position in intonational phrase    first then
if position in intermediate phrase   first then
elseif position in intermediate phrase    first then
discourse

discourse
sentential

ruleset learned from prosody  from phrasing  and from position using cgrendel 

if  position in intonational phrase    first     position in intermediate phrase    first  then
default is on discourse

sentential

decision tree learned from p p and from intonational using c    

if position in intonational phrase   first then
elseif position in intonational phrase    first then

discourse
sentential

ruleset learned from p p and from intonational using cgrendel 

if position in intonational phrase    first then
default is on discourse

sentential

figure    example c    and cgrendel classification models learned from different prosodic
feature representations of the  now  data 

  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
p p
         
         
prosody
         
         
phrasing
         
         
position
         
         
intonational
         
         
manual prosodic
         
         

table        confidence intervals for the error rates     of the best performing cgrendel
prosodic classification models  testing data   training data was the  now  corpus 
testing data was the multiple cue phrase corpus  
of the pruning process is to take a complex decision tree that may also be overfitted to the
training data  and to produce a tree that is more comprehensible and whose accuracy is
not comprised  quinlan         since almost all trees are improved by pruning  quinlan 
       only simplified decision trees are considered in this paper 
in contrast  cgrendel represents each learned classification model as a set of if then
rules  each rule specifies a conjunction of tests on various features  and results in the
assignment of a class  for example  the cgrendel ruleset learned from prosody classifies
cue phrases using the two features position in intonational phrase  p p  and position in
intermediate phrase  i p   the same two features used in the c    decision tree   if the
values of both features are not first  the if then rule applies and the cue phrase is classified
as sentential  if the value of either feature is first  the default applies and the cue phrase is
classified as discourse 
an examination of the learned classification models of figure   shows that they are
comparable in content to the portion of the manually derived model that classifies cue
phrases solely on phrasal position  line       in particular  all of the classification models
say that if the cue phrase is not in an initial phrasal position classify it as sentential 
on the other hand  the manually derived model also assigns the class sentential given an
initial phrasal position in conjunction with certain combinations of phrasal composition and
accent  the learned classification models instead classify the cue phrase as discourse in all
other cases  as will be shown  the further discrimination of the manually obtained model
does not significantly improve performance when compared to the learned classification
models  and in fact in one case significantly degrades performance 
the error rates of the learned classification models on the  now  training data from
which they were developed is as follows     for the models learned from prosody  phrasing
and position  and    for the models learned from p p and intonational  recall from
section   that the error rate of the manually developed prosodic model of figure   on
the same training data was    
table   presents     confidence intervals for the error rates of the best performing
cgrendel prosodic classification models  for ease of comparison  the row labeled  manual
prosodic  presents the error rates of the manually developed prosodic model of figure   on
the same two test sets  which were originally shown in table    the table includes all the
cgrendel models whose performance matches or exceeds the manual performance 
  

ficue phrase classification using machine learning

comparison of the error rates of the learned and manually developed models suggests
that machine learning is an effective technique for automating the development of cue phrase
classification models  in particular  within each test set  the     confidence interval for
the error rate of the classification models learned from the multiple feature sets prosody 
phrasing  and position each overlaps with the confidence interval for the error rate of the
manual prosodic model  this is also true for the error rates of p p and intonational in the
classifiable non conjunct test set  thus  machine learning supports the automatic construction of a variety of cue phrase classification models that achieve similar performance as the
manually constructed models 
the results from p p and from intonational in the classifiable cue phrase test set are
shown in italics  as they suggest that machine learning may also be useful for improving
performance  although the very simple classification model learned from p p and intonational performs worse than the manually derived model on the training data  when tested
on the classifiable cue phrases  the learned model  with an upper bound error rate of       
outperforms the manually developed model  with a lower bound error rate of         this
suggests that the manually derived model might have been overfitted to the training data 
i e   that the prosodic feature set most useful for classifying  now  did not generalize to
other cue phrases  as noted above  the use of simplified learned classification models helps
to guard against overfitting in the learning approach  the ease of inducing classification
models from many different sets of features using machine learning supports the generation
and evaluation of a wide variety of hypotheses  e g  p p  which was a high performing but
not the optimal performing model on the training data  
note that the manual prosodic manual performs significantly better in the smaller test
set  which does not contain the cue phrases  and    or   and  but    in contrast  the
performance improvement for p p and intonational in the smaller test set is not significant 
this also suggests that the manually derived model does not generalize as well as the learned
models 
finally  for the feature sets shown in table    the decision trees produced by c    perform
with the same error rates as the rulesets produced by cgrendel  for both test sets  recall
from figure   that the c    decision trees and cgrendel rules are in fact semantically
equivalent for each feature set  the fact that comparable results are obtained using c   
and cgrendel adds an extra degree of reliability to the experiments  in particular  the
duplication of the results suggests that the ability to match and perhaps even to improve
upon manual performance by using machine learning is not due to the specifics of either
learning program 

    experiment set    using different training sets
the second group of experiments evaluate the utility of training from larger amounts of
data  this is done by using    fold cross validation to estimate error  where for each run
    of the examples in a sample are used for training  and over the    runs  all of the
examples are used for testing   in addition  the experiments in this second set take both
the training and testing data from the multiple cue phrase corpus  in contrast to the previous
set of experiments where the training data was taken from the  now  corpus  as will be
seen  these changes improve the results  such that more of the learned classification models
  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
p l
         
           
p p
         
         
i l
         
           
i p
         
         
i c
           
           
a
         
           
a 
         
           
prosody
         
         
hl  features
         
         
phrasing
         
         
length
         
           
position
         
         
intonational
         
         
intermediate
         
         
manual prosodic
         
         

table        confidence intervals for the error rates     of all cgrendel prosodic classification models  testing data   training and testing were done from the multiple
cue phrase corpus using cross validation  
perform with lower or comparable error rates when compared to the manually developed
models 
      prosodic models

table   presents the error rates of the classification models learned by cgrendel  in
the    different prosodic experiments   for experiment sets   and    the c    error rates
are presented in appendix a   each numeric cell shows the     confidence interval for the
error rate  which is equal to the error percentage obtained by cross validation  the margin
of error        standard errors  using a t table   the top portion of the table considers
the models learned from the single prosodic feature sets  figure     the middle portion
considers the models learned from the multiple feature sets  table     while the last row
considers the manually developed prosodic model  the error rates shown in italics indicate
that the performance of the learned classification model exceeds the performance of the
manual model  given the same test set   the error rates shown in parentheses indicate the
opposite case   that the performance of the manual model exceeds the performance of the
learned model  such cases were omitted in table   
as in experiment set    comparison of the error rates of the learned and manually
developed models suggests that machine learning is an effective technique for not only
automating the development of cue phrase classification models  but also for improving
performance  when evaluated on the classifiable cue phrase test set  five learned models
have improved performance compared to the manual model  all of the models except i c
perform at least comparably to the manual model  note that in experiment set    only two
learned models outperformed the manual model  and only five learned models performed
at least comparably  the ability to use large training sets thus appears to be an advantage
of the automated approach 
  

ficue phrase classification using machine learning

manually derived prosodic model  repeated from figure    

if composition of intermediate phrase   alone then
elseif composition of intermediate phrase    alone then
if position in intermediate phrase   first then
if accent   deaccented then
elseif accent   l  then
elseif accent   h  then
elseif accent   complex then
elseif position in intermediate phrase    first then

discourse

discourse

discourse

sentential

sentential

sentential

   
   
   
   
   
   
   
   

decision tree learned from p p using c    

if position in intonational phrase    then
elseif position in intonational phrase     then

discourse
sentential

ruleset learned from p p using cgrendel 

if position in intonational phrase    then
default is on discourse

sentential

decision tree learned from prosody using c    

if position in intonational phrase    then
if position in intermediate phrase    then
elseif position in intermediate phrase     then
elseif position in intonational phrase     then
if length of intermediate phrase    then
elseif length of intermediate phrase     then

discourse
sentential

discourse
sentential

ruleset learned from prosody using cgrendel 

if  position in intonational phrase        length of intermediate phrase     then
if     position in intonational phrase        length of intonational phrase      then
if  length of intermediate phrase        length of intonational phrase        accent   h   then
if  length of intermediate phrase        length of intonational phrase        accent   h  l  then
if  length of intermediate phrase        accent   deaccented  then
if  length of intermediate phrase        length of intonational phrase        accent   l   then
sentential

sentential

sentential
sentential

sentential

sentential

default is on discourse

figure    example c    and cgrendel classification models learned from different prosodic
feature representations of the classifiable cue phrases in the multiple cue phrase
corpus 
when tested on the classifiable non conjuncts  where the error rate of the manually
derived model decreases   machine learning is useful for automating but not for improving
performance  this might reect the fact that the manually derived theories already achieve
optimal performance with respect to the examined features in this less noisy subcorpus 
and or that the automatically derived theory for this subcorpus was based on a smaller
training set than used in the larger subcorpus 
an examination of some of the best performing learned classification models shows that
they are quite comparable in content to relevant portions of the prosodic model of figure   
and often contain further linguistic insights  consider the classification model learned from
the single feature position in intonational phrase  p p   shown near the top of figure   
  

filitman

both of the learned classification models say that if the cue phrase is not in the initial
position of the intonational phrase  classify as sentential  otherwise classify as discourse 
note the correspondence with line     in the manually derived prosodic model  also note
that the classification models are comparable   to the p p classification models learned
from experiment set    shown in figure     despite the differences in training data  the
fact that the single prosodic feature position in intonational phrase  p p  can classify cue
phrases at least as well as the more complicated manual and multiple feature learned models
is again a new result of the learning experiments 
figure   also illustrates the more complex classification models learned using prosody 
the largest prosodic feature set  the c    model is similar to lines     and     of the manual
model   the length value   is equivalent to the composition value alone   in the ruleset
induced from prosody by cgrendel  the first   if then rules correlate sentential status with
 among other things  non initial position     and the second   rules with h  and h  l
accents  these rules are similar to lines         in figure    however  the last   if then rules
in the ruleset also correlate no accent and l  with sentential status when the phrase is of a
certain length  while lines     and     in figure   provide a different interpretation and do
not take length into account  recall that length was coded by hirschberg and litman only
in their test data  length was thus never used to generate or revise their prosodic model 
the utility of length is a new result of this experiment set 
although not shown  the models learned from phrasing  position  and intonational also
outperform the manual model  as can be seen from table    these models correspond to
all of the feature sets that are supersets of p p but subsets of prosody 
      textual models

table   presents the error rates of the classification models learned by cgrendel  in the
   different textual experiments  unlike the experiments involving the prosodic feature sets 
none of the learned textual models perform significantly better than the manually derived
model  however  the results suggest that machine learning is still an effective technique
for automating the development of cue phrase classification models  in particular  five
learned models  o p  o p   text  orthography  and preceding  perform comparably to the
manually derived model  in both test sets  note that these five models are learned from
the five textual feature sets that include either the feature o p or o p   recall figure  
and table     these models perform significantly better than all of the remaining learned
textual models 
figure   shows the best performing learned textual models  note the similarity to the
manually derived model  as with the prosodic results  the best performing single feature
models perform comparably to those learned from multiple features  in fact  in cgrendel 
the rulesets learned from the multiple feature sets orthography and preceding are identical
to the rulesets learned from the single features o p and o p   even though more features
were available for use   the corresponding error rates in table   are not identical due to the
    the different feature values in the two figures reect the fact that phrasal position was represented in
the  now  corpus using symbolic values  as in figure     and in the multiple cue phrase corpus using
integers  as in figure    
    tests such as  feature  x  and  feature  y  are merged in the figure for simplicity  e g    y  feature
 x  

  

ficue phrase classification using machine learning

model
classifiable cue phrases  n      classifiable non conjuncts  n     
c p
           
           
c s
           
           
o p
         
         
o p 
         
         
o s
           
           
o s 
           
           
pos
           
           
text
         
         
adjacency
           
           
orthography
         
         
preceding
         
         
succeeding
           
           
manual textual
         
         

table        confidence intervals for the error rates     of all cgrendel textual classification models  testing data   training and testing were done from the multiple
cue phrase corpus using cross validation  
manually derived textual model  repeated from figure    
if preceding orthography   true then discourse
elseif preceding orthography   false then sentential
decision tree learned from o p   from text  from orthography  and from preceding using c    

if preceding orthography    na then
elseif preceding orthography    false then
elseif preceding orthography    true then

discourse
sentential
discourse

ruleset learned from o p  from o p   from orthography  and from preceding using cgrendel 

if preceding orthography    false then
default is on discourse

sentential

ruleset learned from text using cgrendel 

if preceding orthography    false then
if part of speech   article then
default is on discourse

sentential

sentential

figure    example c    and cgrendel classification models learned from different textual
feature representations of the classifiable cue phrases in the multiple cue phrase
corpus 
estimation using cross validation   the cgrendel model text also incorporates the feature
part of speech  in c     the models text  orthography and preceding are all identical to o p  
      prosodic textual models

table   presents the error rates of the classification models learned by cgrendel when the
data is represented using speech text  the complete set of prosodic and textual features  recall
  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
speech text
         
         
manual prosodic
         
         
manual textual
         
         

table        confidence intervals for the error rates     of the cgrendel prosodic textual
classification model  testing data   training and testing were done from the multiple cue phrase corpus using cross validation  
table     since hirschberg and litman did not develop a similar classification model that
combined both types of features  for comparison the last two rows show the error rates of
the separate prosodic and textual models  only when the learned model is compared to the
manual prosodic model  using the classifiable cue phrases for testing  does learning result in
a significant performance improvement  this is consistent with the results discussed above 
where several learned prosodic models performed better than the manually derived prosodic
model in this test set  the performance of speech text is not significantly better or worse
than the performance of either the best prosodic or textual learned models  tables   and   
respectively  
figure   shows the c    and cgrendel hypotheses learned from speech text  the c   
model classifies cue phrases using the prosodic and textual features that performed best in
isolation  position in intonational phrase and preceding orthography   as discussed above   in
conjunction with the additional feature length of intermediate phrase  which also appears
in the model learned from prosody in figure     like line     in the manually derived
textual model  the learned model associates the presence of preceding orthography with
the class discourse  unlike line       however  cue phrases not preceded by orthography
may be classified as either discourse or sentential  based on prosodic feature values  which
were not available for use by the textual model   the branch of the learned decision tree
corresponding to the last three lines is also similar to lines           and     of the manually
derived prosodic model   recall that a length value of   is equivalent to a composition value
alone  
the cgrendel model uses similar features to those used by c    as well as the prosodic
feature accent  also used in prosody in figure     and the textual features part of speech
 also used in text in figure    and preceding cue phrase  like c     and unlike line     
of the manually derived textual model  the cgrendel model classifies cue phrases lacking
preceding orthography as sentential only in conjunction with certain other feature values 
unlike line     in the manual model  the learned model also classifies some cue phrases with
preceding orthography as sentential  if the orthography is a comma  and other feature values
are present   finally  the third and fifth learned rules elaborate line     with additional
prosodic as well as textual features  while the first and last learned rules elaborate line     

    experiment set    adding the feature token

each experiment in the third group replicates an experiment from the second group  with
the exception that the data representation now also includes the lexical feature token from
  

ficue phrase classification using machine learning

manually derived prosodic model  repeated from figure    

if composition of intermediate phrase   alone then
elseif composition of intermediate phrase    alone then
if position in intermediate phrase   first then
if accent   deaccented then
elseif accent   l  then
elseif accent   h  then
elseif accent   complex then
elseif position in intermediate phrase    first then

discourse

discourse

discourse

sentential

sentential

sentential

manually derived textual model  repeated from figure    

if preceding orthography   true then
elseif preceding orthography   false then

   
   
   
   
   
   
   
   
   
    

discourse
sentential

decision tree learned from speech text using c    

if position in intonational phrase    then
if preceding orthography    na then
elseif preceding orthography    true then
elseif preceding orthography    false then
if length of intermediate phrase      then
elseif length of intermediate phrase     then
if length of intermediate phrase    then
elseif length of intermediate phrase     then
elseif position in intonational phrase     then
if length of intermediate phrase    then
elseif length of intermediate phrase     then
discourse

discourse

discourse
discourse
sentential

discourse

sentential

ruleset learned from speech text using cgrendel 

if  preceding orthography   false        position in intonational phrase       then
if  preceding orthography   false     length of intermediate phrase     then
if  preceding orthography   false     length of intonational phrase        preceding cue phrase   na 
   accent   h   then
if  preceding orthography   comma     length of intermediate phrase        length of intonational phrase     
   part of speech   adverb  then
if  preceding orthography   comma        length of intonational phrase        accent   h   then
if  preceding orthography   comma        length of intermediate phrase    
   length of intonational phrase      then
if  position in intonational phrase        length of intermediate phrase   
   preceding cue phrase   na  then
sentential

sentential

sentential

sentential

sentential

sentential

default is on discourse

sentential

figure    c    and cgrendel classification models learned from the prosodic textual feature representation of the classifiable cue phrases in the multiple cue phrase corpus 

  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
p l 
         
         
p p 
         
         
i l 
         
         
i p 
         
         
i c 
         
         
a 
         
         
a  
         
         
prosody 
         
         
hl  features 
         
         
phrasing 
         
         
length 
         
         
position 
         
         
intonational 
         
         
intermediate 
         
         
manual prosodic
         
         

table        confidence intervals for the error rates     of all cgrendel prosodic  tokenized classification models  testing data   training and testing were done from
the multiple cue phrase corpus using cross validation  
figure    these experiments investigate how performance changes when classification models are allowed to treat different cue phrases differently  as will be seen  learning from
tokenized feature sets often further improves the performance of the learned classification
models  in addition  the classification models now contain new linguistic information regarding particular tokens  e g    so   
      prosodic models

table   presents the error of the learned classification models on both test sets from the
multiple cue phrase corpus  for each of the tokenized prosodic feature sets  again  the error
rates in italics indicate that the performance of the learned classification model meaningfully
exceeds the performance of the  manual prosodic  model  which did not consider the feature
token  
one way that the improvement obtained by adding the feature token can be seen is by
comparing the performance of the learned and manually derived models  in table    six
cgrendel classification models have lower  italicized  error rates than the manual model 
in table    only five of these models are italicized  thus  adding the feature token results
in an additional learned model   length    outperforming the manually derived model 
conversely  in table    no learned models perform significantly worse than the manually
derived manual  in contrast  in table    several non tokenized models perform worse than
the manual model  i c in the larger test set  and p l  i l  i c  a  a   and length in the
non conjunct test set  
the improvement obtained by adding the feature token can also be seen by comparing
the performance of the tokenized  table    and non tokenized  table    versions of each
model to each other  for convenience  cases where tokenization yields improvement are
highlighted in table    the table shows that the error rate of the tokenized versions of the
feature sets is significantly lower than the error of the non tokenized versions  for p l  i c 
  

ficue phrase classification using machine learning

model
p l
i l
i c
a
a 
length

classifiable cue phrases  n     
non tokenized tokenized    
         
         
         
         
         
         
         
         
         
         

classifiable non conjuncts  n     
non tokenized
tokenized    
         
         
         
         
         
         
         
         
         
         
         
         

table    cases where adding the feature token improves the performance of a prosodic
model 
a  a   and length in both test sets  and for i l in only the non conjunct test set  note the
overlap between the feature sets of table   and those discussed in the previous paragraph 
figure   shows several tokenized single feature prosodic classification models  the first
cgrendel model in the figure shows the ruleset learned from p l   which reduces the
            error rate of p l  length of intonational phrase  to              when
trained and tested using the classifiable non conjuncts  table     note that the first rule
uses only a prosodic feature  like the rules of experiment sets   and     and is in fact
similar to line     of the manual model   recall that the length value   is equivalent to
the composition value alone   however  unlike the rules of the previous experiment sets 
the next   rules use both the prosodic feature and the lexical feature token  also unlike
the rules of the previous experiment sets  the remaining rules classify cue phrases using
only the feature token  examination of the learned rulesets in figures   and   shows that
the same cue phrases often appear in this last type of rule  some of these cue phrases  for
example   finally    however   and  ok   are in fact always discourse usages in the multiple
cue phrase corpus  for the other cue phrases  classifying cue phrases using only token
corresponds to classifying cue phrases using their default class  the most frequent type of
usage in the multiple cue phrase corpus   recall the use of a non tokenized default class
model in table   
the second example shows the ruleset learned from i c   composition of intermediate
phrase    the first rule corresponds to line     of the manually derived model    the
next six rules classify particular cue phrases as discourse  independently of the value of i c 
note that although in this model the cue phrase  say  is classified using only token  in the
previous model a more sophisticated strategy for classifying  say  could be found 
the third example shows the cgrendel ruleset learned from a   accent    the first
rule corresponds to line     of the manually derived prosodic model  in contrast to line
     however  cgrendel uses deaccenting to predict discourse for only the tokens  say 
and  so   if the token is  finally    however    now  or  ok   discourse is assigned  for all
accents   in all other deaccented cases  sentential is assigned  using the default   similarly 
in contrast to line      the complex accent l h  predicts discourse for the cue phrases
 further  and  indeed   and also for  finally    however    now  and  ok    and sentential
otherwise 
    as discussed in relation to figure    the i c values only and only cue phrases in the multiple cue phrase
corpus replace the value alone in the  now  corpus 

  

filitman

manually derived prosodic model  repeated from figure    

if composition of intermediate phrase   alone then
elseif composition of intermediate phrase    alone then
if position in intermediate phrase   first then
if accent   deaccented then
elseif accent   l  then
elseif accent   h  then
elseif accent   complex then
elseif position in intermediate phrase    first then

   
   
   
   
   
   
   
   

discourse

discourse

discourse

sentential

sentential

sentential

ruleset learned from p l  using cgrendel 

if length of intonational phrase    then
if     length of intonational phrase         token   although  then
if     length of intonational phrase         token   indeed  then
if  length of intonational phrase         token   say  then
if      length of intonational phrase         token   then  then
if  length of intonational phrase         token   well  then
if token   finally then
if token   further then
if token   however then
if token   now then
if token   ok then
if token   otherwise then
if token   so then
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default is on sentential

ruleset learned from i c  using cgrendel 

if composition of intermediate phrase   only then
if token   finally then
if token   however then
if token   now then
if token   ok then
if token   say then
if token   so then

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default is on sentential

ruleset learned from a  using cgrendel 

if accent   l  then
if  accent   deaccented     token   say  then
if  accent   deaccented     token   so  then
if  accent   l h      token   further  then
if  accent   l h      token   indeed  then
if token   finally then
if token   however then
if token   now then
if token   ok then
discourse

discourse

discourse
discourse

discourse

discourse

discourse

discourse

discourse

default is on sentential

figure    example cgrendel classification models learned from different tokenized 
prosodic feature representations of the classifiable non conjuncts in the multiple
cue phrase corpus 

  

ficue phrase classification using machine learning

model
classifiable cue phrases  n      classifiable non conjuncts  n     
c p 
           
         
c s 
           
         
o p 
         
         
o p  
         
         
o s 
         
         
o s  
           
         
pos 
           
         
text 
         
         
adjacency 
           
         
orthography 
         
         
preceding 
         
         
succeeding 
         
         
manual textual
         
         

table         confidence intervals for the error rates     of all cgrendel textual  tokenized classification models  testing data   training and testing were done from
the multiple cue phrase corpus using cross validation  
to summarize  new prosodic results of experiment set   are that features relating to
length  composition  and accent  while not useful  in isolation  for predicting the classification of all cue phrases  are in fact quite useful for predicting the class of individual cue
phrases or subsets of cue phrases   recall that the result of experiment sets   and   was
that without token  only the prosodic feature position in intonational phrase was useful in
isolation  
      textual models

table    presents the error of the learned classification models on both test sets from
the multiple cue phrase corpus  for each of the tokenized textual feature sets  as in experiment set    table     none of the cgrendel classification models have lower  italicized 
error rates than the manual model  however  adding the feature token does improve the
performance of many of the learned rulesets  in that the following models  unlike their
non tokenized counterparts  are no longer outperformed by the manual model  o s  and
succeeding  in the larger test set  and c p   c s   o s   o s    pos   adjacency  
and succeeding  in the non conjunct test set 
the improvement obtained by adding the feature token can also be seen by comparing
the performance of the tokenized  table     and non tokenized  table    versions of each
model to each other  as shown in table     the table shows that the error rates of the
tokenized versions of the feature sets are significantly lower than the error of the nontokenized versions  for c p  c s  pos  and adjacency in both test sets  and for o p  o s 
o s   text  and succeeding in the non conjunct test set  note the overlap between the feature
sets of table    and those discussed in the previous paragraph 
figure   shows several tokenized single textual feature classification models  the first
cgrendel model shows the ruleset learned from c p   preceding cue phrase    which
reduces the             error rate of c p to             when trained and tested using
the classifiable non conjuncts  table      this ruleset correlates preceding cue phrases with
discourse usages of  indeed   and omitted transcriptions of  further    now   and  so  with
  

filitman

manually derived textual model  repeated from figure    

if preceding orthography   true then
elseif preceding orthography   false then

discourse
sentential

ruleset learned from c p  using cgrendel 

if  preceding cue phrase   true     token   indeed  then
if  preceding cue phrase   na     token   further  then
if  preceding cue phrase   na     token   now  then
if  preceding cue phrase   na     token   so  then
if token   although then
if token   finally then
if token   however then
if token   ok then
if token   say then
if token   similarly then

discourse
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default is on sentential

discourse

ruleset learned from o p  using cgrendel 

if preceding orthography   false then
if  preceding orthography   comma     token   then  then
sentential

default is on discourse

sentential

ruleset learned from o s  using cgrendel 

if succeeding orthography   comma then
if  succeeding orthography   false     token   so  then
if succeeding orthography   na then
if token   although then
if token   finally then
if token   now then
if token   ok then
if token   say then
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default is on sentential

ruleset learned from pos  using cgrendel 

if  part of speech   adverb     token   finally  then
if  part of speech   singular proper noun     token   further  then
if  part of speech   adverb     token   however  then
if  part of speech   adverb     token   indeed  then
if  part of speech   subordinating conjunction     token   so  then
if token   although then
if token   now then
if token   say then
if token   ok then
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default is on sentential

figure    example cgrendel classification models learned from different tokenized  textual
feature representations of the classifiable non conjuncts in the multiple cue phrase
corpus 

  

ficue phrase classification using machine learning

model
c p
c s
o p
o s
o s 
pos
text
adjacency
succeeding

classifiable cue phrases  n     
non tokenized tokenized    
         
         
         
         
         
         
         
         
 

classifiable non conjuncts  n     
non tokenized
tokenized    
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         

table     cases where adding the feature token improves the performance of a textual
model 
discourse usages  the classifications for the rest of the cue phrases are predicted using only
the feature token 
the second example shows the cgrendel ruleset learned from o p   preceding orthography    this ruleset correlates no preceding orthography with sentential usages of cue
phrases  as in both the manually derived model and the learned models from experiment
set     unlike those models  however  the cue phrase  then  is also classified as sentential 
even when it is preceded by orthography  namely  by a comma  
the third example shows the cgrendel ruleset learned from o s   succeeding orthography   this ruleset correlates the presence of succeeding commas with discourse usages of
cue phrases  except for the cue phrase  so   which is classified as a discourse usage without
any succeeding orthography  the model also correlates cue phrases that were omitted from
the transcript with discourse usages  the classifications for the rest of the cue phrases are
predicted using only the feature token 
the last example shows the cgrendel ruleset learned from pos   part of speech   
this ruleset classifies certain cue phrases as discourse usages depending on both part ofspeech and token  as well as independently of part of speech 
finally  figure    shows the classification model learned from text   the largest tokenized textual feature set  note that three of the four features used in the tokenized  single
textual feature models of figure   are incorporated into this tokenized  multiple textual
feature model 
to summarize  new textual results of experiment set   are that features based on adjacent cue phrases  succeeding orthography  and part of speech  while not useful  in isolation 
for predicting the classification of all cue phrases  are in fact quite useful in conjunction with
only the feature token   recall that the result of experiment set   was that without token 
only the textual features preceding orthography and preceding orthography  were useful in
isolation  
      prosodic textual models

table    presents the error rates of the classification models learned by cgrendel
when the data is represented using speech text   the complete set of prosodic and textual
  

filitman

ruleset learned from text  using cgrendel 

if preceding orthography   false then
if  preceding orthography   comma     token   although  then
if  preceding orthography   comma     token   no  then
if  preceding orthography   comma     token   then  then
if  succeeding orthography   false     preceding cue phrase   na     token   similarly  then
if token   actually then
if token   first then
if token   since then
if token   yes then
sentential

sentential

sentential

sentential

sentential

sentential

sentential

sentential

sentential

default is on discourse

figure     cgrendel classification model learned from a tokenized  multiple textual feature
representation of the classifiable non conjuncts in the multiple cue phrase corpus 
model
classifiable cue phrases  n      classifiable non conjuncts  n     
speech text 
         
         
manual prosodic
         
         
manual textual
         
         

table         confidence intervals for the error rates     of the cgrendel
prosodic textual  tokenized classification models  testing data   training and
testing were done from the multiple cue phrase corpus using cross validation  
features  as in experiment set    the performance of speech text  is not better than the
performance of either the best learned  tokenized  prosodic or textual models  tables  
and     respectively  
comparison of tables   and    also shows that for the feature set speech text  tokenization does not improve performance  this is in contrast to the prosodic and textual feature
sets  where tokenization improves the performance of many learned models  namely those
shown in tables   and     

    experiment set    adding the classification ambiguous
in practice  a cue phrase classification model will have to classify all the cue phrases in a
recording or text  not just those that are  classifiable   the experiments in the fourth set
replicate the experiments in experiment sets       and    with the exception that all     cue
phrases in the multiple cue phrase corpus are now used  this means that cue phrases are
now classified as discourse  sentential  as well as unknown  defined in table     experiment
set   investigates whether machine learning can explicitly recognize the new class unknown 
recall that the studies of hirschberg and litman did not attempt to predict the class
unknown  as it did not occur in their  now  training corpus  thus in experiment set    the
class unknown similarly can not be learned from the training data  however  the unknown
examples can be added to the testing data of experiment set    obviously performance will
degrade  as the models must incorrectly classify each unknown example as either discourse
  

ficue phrase classification using machine learning

or sentential  for example  when tested on the full corpus of     example cue phrases 
the     confidence intervals for the error rates of p p and intonational are             
recall that when tested on the subset of the corpus corresponding to the     classifiable cue
phrases  the error was              table    
unfortunately  the results of rerunning experiment sets   and   do not show promising
results for classifying cue phrases as unknown  despite the presence of    examples of
unknown  most of the learned models still classify unknown cue phrases as only discourse or
sentential  for example  when cgrendel is used for learning  only   of the possible    nontokenized models    phrasing and speech text  contain rules that predict the class unknown 
furthermore  each of these models only contains one rule for unknown  and each of these
rules only applies to   of the possible     examples  similarly  only four of the possible   
tokenized models  length   phrasing   prosody   and speech text   contain at least one rule
for the class unknown  when compared to training and testing using only the classifiable
cue phrases in the corpus  the error rate on the full corpus is typically  but not always 
significantly higher  the best performing model in experiment set   is speech text   with
a             error rate      confidence interval  
in sum  experiment set   addressed a problem that was previously unexplored in the
literature   the ability to develop classification models that predict not only discourse and
sentential usages of cue phrases  but also usages which human judges find dicult to classify 
unfortunately  the results of the experiments suggest that learning how to classify cue
phrases as unknown is a dicult problem  perhaps with more training data  recall that
there are only    examples of unknown  or with additional features better results could be
obtained 

    discussion
the experimental results suggest that machine learning is a useful tool for both automating
the generation of classification models and improving upon manually derived results  in
experiment sets   and   the performance of many of the learned classification models is
comparable to the performance of the manually derived models  in addition  when tested
on the classifiable cue phrases  several learned prosodic classification models  as well as
the learned prosodic textual model  outperform hirschberg and litman s manually derived
prosodic model  experiment set   shows that learning from tokenized feature sets even
further improves performance  especially in the non conjunct test set  more tokenized than
non tokenized learned models perform at least as well as the manually derived models 
many tokenized learned models also outperform their non tokenized counterparts 
while the textual classification models do not outperform the better prosodic classification models  they have the advantage that the textual feature values are obtained directly
from the transcript  while determining the values of prosodic features requires manual analysis   see  however  section   for a discussion of the feasibility of automating the prosodic
analysis  in addition  a transcript may not always be available   on the other hand  almost
all the high performing textual models are dependent on orthography  while manual tran    recall that experiment sets   and   constructed    prosodic models     textual models  and  
prosodic textual model 

  

filitman

scriptions of prosodic features have been shown to be reliable across coders  pitrelli et al  
       there are no corresponding results for the reliability of orthography 
examination of the best performing learned models shows that they are often comparable in content to the relevant portions of the manually derived models  examination
of the models also provides new contributions to the cue phrase literature  for example 
experiment sets   and   demonstrate the utility of classifying cue phrases based on only a
single prosodic feature   phrasal position    experiment set   also demonstrates the utility
of the prosodic feature length and the textual feature preceding cue phrase for classifying
cue phrases   in conjunction with other prosodic and textual features  finally  the results of
experiment set   demonstrate that even though many features are not useful by themselves
for classifying all cue phrases  they may nonetheless be very informative in their tokenized
form  this is true for the prosodic features based on phrasal length  phrasal composition 
and accent  and for the textual features based on adjacent cue phrases  succeeding position 
and part of speech   

   utility
the results of the machine learning experiments are quite promising  in that when compared
to manually derived classification models already in the literature  the learned classification
models often perform with comparable if not higher accuracy  thus  machine learning
appears to be an effective technique for automating the generation of classification models 
however  given that the experiments reported here still rely on manually created training
data  a discussion of the practical utility of the results is in order 
even given manually created training data  the results established by hirschberg and
litman          obtained using even less automation than the experiments of this paper
  are already having practical import  in particular  the manually derived cue phrase
classification models are used to improve the naturalness of the synthetic speech in a text tospeech system  hirschberg         using the text based model  the text to speech system
classifies each cue phrase in a text to be synthesized as either a discourse or sentential
usage  using the prosodic model  the system then conveys this usage by synthesizing the
cue phrase with the appropriate type of intonation  the speech synthesis could be further
improved  and the output made more varied  by using any one of the higher performing
learned prosodic models presented in this paper 
the results of this paper could also be directly applied in the area of text generation 
for example  moser and moore        are concerned with the implementation of cue selection and placement strategies in natural language generation systems  such systems could
be enhanced by using the text based models of cue phrase classification  particularly the
    the empirical studies performed by holte        show that for many other datasets  the accuracy of
single feature rules and decision trees is often competitive with the accuracy of more complex learned
models 
    in contrast  the prosodic features phrasal composition and accent were previously known to be useful
in conjunction with each other and with phrasal position  hirschberg   litman         while part ofspeech was known to be useful only in conjunction with orthography  hirschberg   litman        
length  adjacent cue phrases  and succeeding position were not used in either of the manually derived
models  hirschberg   litman         although length and adjacent cue phrases were shown to be useful
  again only in conjunction with other prosodic and textual features   in experiment set    

  

ficue phrase classification using machine learning

tokenized models  to additionally specify preceding and succeeding orthography  part ofspeech  and adjacent cue phrases that are appropriate for discourse usages 
finally  if the results of this paper could be fully automated  they could also be used in
natural language understanding systems  by enhancing their ability to recognize discourse
structure  the results obtained by litman and passonneau        and passonneau and
litman  in press  suggest that algorithms that use cue phrases  in conjunction with other
features  to predict discourse structure outperform algorithms that do not take cue phrases
into account  in particular  litman and passonneau develop several algorithms that explore
how features of cue phrases  prosody and referential noun phrases can be best combined
to predict discourse structure  quantitative evaluations of their results show that the best
performing algorithms all incorporate the use of discourse usages of cue phrases  where cue
phrases are classified as discourse using only phrasal position   as discussed in section   
discourse structure is useful for performing tasks such as anaphora resolution and plan
recognition  recent work has also shown that if discourse structure can be recognized  it
can be used to improve retrieval of text  hearst        and speech  stieman        
although the prosodic features were manually labeled by hirschberg and litman  there
are recent results suggesting that at least some aspects of prosody can be automatically
labeled directly from speech  for example  wightman and ostendorf        develop an
algorithm that is able to automatically recognize prosodic phrasing with        accuracy
 measured by comparing automatically derived labels with hand marked labels   this accuracy is only slightly less than human human accuracy  recall that the experimental results
of this paper show that models learned from the single feature position in intonational
phrase   which could be automatically computed given such an automatic prosodic phrasing algorithm   perform at least as well as any other learned prosodic model  similarly 
accenting versus deaccenting can be automatically labeled with     accuracy  wightman
  ostendorf         while a more sophisticated labeling scheme that distinguishes between
four types of accent classes  and is somewhat similar to the prosodic feature accent  used
in this paper  can be labeled with     accuracy  ostendorf   ross  in press   recall from
experiment set   that the tokenized models learned using accent  also classify cue phrases
with good results 
although the textual features were automatically extracted from a transcript  the transcript itself was manually created  many natural language understanding systems do not
deal with speech at all  and thus begin with such textual representations  in spoken language systems the transcription process is typically automated using a speech recognition
system  although this introduces further sources of error  

   related work
this paper has both compared the results obtained using machine learning to previously
existing manually obtained results  and has also used machine learning as a tool for developing theories given new linguistic data  as in the models resulting from experiment set   
where the new feature token was considered   siegel        similarly uses machine learning
 in particular  a genetic learning algorithm  to classify cue phrases from a previously unstudied set of textual features  a feature corresponding to token  as well as textual features
containing the lexical or orthographic item immediately to the left of and in the   positions
  

filitman

to the right of the example  siegel s input consists of one judge s non ambiguous examples
taken from the data used by hirschberg and litman        as well as additional examples 
his output is in the form of decision trees  siegel reports a     estimated error rate  with
half of the corpus used for training and half for testing  siegel and mckeown        also
propose a method for developing linguistically viable rulesets  based on the partitioning of
the training data produced during induction 
machine learning has also been used in several other areas of discourse analysis  for example  learning has been used to develop rules for structuring discourse into multi utterance
segments  grosz and hirschberg        use the classification and regression tree system
cart  brieman et al         to construct decision trees for classifying aspects of discourse
structure from intonational feature values  litman and passonneau        and passonneau
and litman  in press  use the system c    to construct decision trees for classifying utterances as discourse segment boundaries  using features relating to prosody  referential noun
phrases  and cue phrases  in addition  c    has been used to develop anaphora resolution
algorithms  by training on corpora tagged with appropriate discourse information  aone  
bennett         similarly  mccarthy and lehnert        use c    to learn decision trees
to classify pairs of phrases as coreferent or not  soderland and lehnert        use the
machine learning program id   a predecessor of c     to support corpus driven knowledge
acquisition in information extraction  machine learning often results in algorithms that
outperform manually derived alternatives  litman   passonneau        passonneau   litman  in press  aone   bennett        mccarthy   lehnert         although statistical
inference is not always used to evaluate the significance of the performance differences 
finally  machine learning has also been used with great success in many other areas of
natural language processing  as discussed above  the work of most researchers in discourse
analysis has concentrated on the direct application of existing symbolic learning approaches
 e g   c      and on the comparison of learning and manual methods  while researchers
in other areas of natural language processing have also addressed these issues  they have
in addition applied a much wider variety of learning approaches  and have been concerned
with the development of learning methods particularly designed for language processing  a
recent survey of learning for natural language  wermter  riloff    scheler        illustrates
both the type of learning approaches that have been used and modified  in particular 
symbolic  connectionist  statistical  and hybrid approaches   as well as the scope of the
problems that have proved amenable to the use of learning techniques  e g   grammatical
inference  syntactic disambiguation  and word sense disambiguation  

   conclusion
this paper has demonstrated the utility of machine learning techniques for cue phrase
classification  machine learning supports the automatic generation of linguistically viable
classification models  when compared to manually derived models already in the literature 
many of the learned models contain new linguistic insights and perform with at least as
high  if not higher  accuracy  in addition  the ability to automatically construct classification models makes it easier to comparatively analyze the utility of alternative feature
representations of the data  finally  the ease of retraining makes the learning approach
more scalable and extensible than manual methods 
  

ficue phrase classification using machine learning

a first set of experiments were presented that used the machine learning programs

cgrendel  cohen              and c     quinlan        to induce classification models

from the preclassified cue phrases and their features that were used as training data by
hirschberg and litman         these results were then evaluated with the same testing data
and methodology used by hirschberg and litman         a second group of experiments
used the method of cross validation to both train and test from the testing data used by
hirschberg and litman         a third set of experiments induced classification models
using the new feature token  a fourth set of experiments induced classification models
using the new classification unknown 
the experimental results indicate that several learned classification models  including
extremely simple one feature models  have significantly lower error rates than the models
developed by hirschberg and litman         one possible explanation is that the handbuilt classification models were derived using very small training sets  as new data became
available  this data was used for testing but not for updating the original models  in contrast  machine learning in conjunction with cross validation  experiment set    supported
the building of classification models using a much larger amount of the data for training 
even when the learned models were derived using the same small training set  experiment
set     the results showed that the learning approach helped guard against overfitting on
the training data 
while the prosodic classification model developed by hirschberg and litman demonstrated the utility of combining phrasal position with phrasal composition and accent  the
best performing prosodic models of experiment sets   and   demonstrated that phrasal
position was in fact even more useful for predicting cue phrases when used by itself  the
other high performing classification models of experiment set   also demonstrated the utility of classifying cue phrases based on the prosodic feature length and the textual feature
preceding cue phrase  in combination with other features 
just as the machine learning approach made it easy to retrain when new training examples became available  experiment set     machine learning also made it easy to retrain
when new features become available  in particular  when the value of the feature token
was added to all the representations in experiment set    it was trivial to relearn all of the
models  experiment set     allowing the learning programs to treat cue phrases individually further improved the accuracy of the learned classification models  and added to the
body of linguistic knowledge regarding cue phrases  experiment set   demonstrated that
while not useful by themselves for classifying all cue phrases  the prosodic features based
on phrasal length  phrasal composition  and accent  and textual features based on adjacent
cue phrases  succeeding position  and part of speech  were in fact useful when used only in
conjunction with the feature token 
a final advantage of the machine learning approach is that the ease of inducing classification models from many different sets of features supports an exploration of the comparative
utility of different knowledge sources  this is especially useful for understanding the tradeoffs between the accuracy of a model and the set of features that are considered  for
example  it might be worth the effort to code a feature that is not automatically obtainable
or that is expensive to automatically obtain if adding the feature results in a significant
improvement in performance 
  

filitman

in sum  the results of this paper suggest that machine learning is a useful tool for
cue phrase classification  when the amount of data precludes effective human analysis 
when the exibility afforded by easy retraining is needed  e g   due to additional training
examples  new features  new classifications   and or when an analysis goal is to gain a better
understanding of the different aspects of the data 
several areas for future work remain  first  there is still room for performance improvement  the error rates of the best performing learned models  even though they outperform
the manually derived models  perform with error rates in the teens  note that only the
features that were coded or discussed by hirschberg and litman        were considered in
this paper  it may be possible to further lower the error rates by considering new types
of prosodic and textual features  e g   other contextual textual features  siegel         or
features that have been proposed in connection with the more general topic of discourse
structure   and or by using different kinds of learning methods  second  experiment set
   and the previous literature  show that as yet  there are no models for predicting when
a cue phrase usage should be classified as unknown  rather than as discourse or sentential 
again  it may be possible to improve the performance of the existing learned models by
considering new features and or learning methods  or perhaps performance could be improved by providing more training data  finally  it is currently an open question whether
the textual models developed here  which were based on transcripts of speech  are applicable
to written texts  textual models thus need to be developed using written texts as training
data  machine learning should continue to be a useful tool for helping to address these
issues 

appendix a  c    results for experiment sets   and  
tables        and    present the c    error rates for experiment sets   and    the c   
results for experiment set   are shown in the  non tokenized  columns  a comparison of
tables    and   shows that except for a in the larger test set  the c    prosodic error rates
fall within the cgrendel confidence intervals  a similar comparison of tables    and  
shows that except for o p in the larger test set  the c    textual error rates fall within the
cgrendel confidence intervals  finally  a comparison of tables    and   shows that the
c    error rate of speech text falls within the cgrendel confidence interval  the fact that
comparable cgrendel and c    results are generally obtained suggests that the ability to
automate as well as to improve upon manual performance is not due to the specifics of
either learning program 
the c    results for experiment set   are shown in the  tokenized  columns of tables        and     comparison with tables       and    shows that the error rates of c   
and cgrendel are not as similar as in experiment set    however  the error rates reported
in the tables use the default c    and cgrendel options when running the learning programs  comparable performance between the two learning programs can in fact generally
be achieved by overriding one of the default c    options  as detailed by quinlan        
the default c    approach   which creates a separate subtree for each possible feature value
  might not be appropriate when there are many values for a feature  this situation characterizes the feature token  when the c    default option is changed to allow feature values
to be grouped into one branch of the decision tree  the problematic c    error rates do
  

ficue phrase classification using machine learning

model
p l
p p
i l
i p
i c
a
a 
prosody
hl  features
phrasing
length
position
intonational
intermediate

classifiable cue phrases  n     
non tokenized tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

classifiable non conjuncts  n     
non tokenized
tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table     error rates     of the c    prosodic classification models  testing data   training
and testing were done from the multiple cue phrase corpus using cross validation  
model
c p
c s
o p
o p 
o s
o s 
pos
text
adjacency
orthography
preceding
succeeding

classifiable cue phrases  n     
non tokenized tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

classifiable non conjuncts  n     
non tokenized
tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table     error rates     of the c    textual classification models  testing data   training
and testing were done from the multiple cue phrase corpus using cross validation  
indeed improve  for example  the a  error rate for the classifiable non conjuncts changes
from        table     to      which is within the             cgrendel confidence
interval  table    

acknowledgements
i would like to thank william cohen and jason catlett for their helpful comments regarding
the use of cgrendel and c     and sandra carberry  rebecca passonneau  and the three
anonymous jair reviewers for their helpful comments on this paper  i would also like to
  

filitman

model
speech text

classifiable cue phrases  n     
non tokenized tokenized    
    
    

classifiable non conjuncts  n     
non tokenized
tokenized    
    
    

table     error rates     of the c    prosodic textual classification model  testing data 
 training and testing were done from the multiple cue phrase corpus using crossvalidation  
thank william cohen  ido dagan  julia hirschberg  and eric siegel for comments on a
preliminary version of this paper  litman        

references

altenberg  b          prosodic patterns in spoken english  studies in the correlation
between prosody and grammar for text to speech conversion  vol     of lund studies
in english  lund university press  lund 
aone  c     bennett  s  w          evaluating automated and manual acquisition of
anaphora resolution strategies  in proceedings of the thirty third annual meeting of
the association for computational linguistics  acl  
brieman  l   friedman  j   olshen  r     stone  c          classification and regression
trees  monterey  ca  wadsworth and brooks 
church  k  w          a stochastic parts program and noun phrase parser for unrestricted
text  in proceedings of the second conference on applied natural language processing 
cohen  r          a computational theory of the function of clue words in argument understanding  in proceedings of the tenth international conference on computational
linguistics  coling  
cohen  w  w          compiling knowledge into an explicit bias  in proceedings of the
ninth international conference on machine learning 
cohen  w  w          ecient pruning methods for separate and conquer rule learning
systems  in proceedings of the thirteenth international joint conference on artificial
intelligence  ijcai  
freedman  d   pisani  r     purves  r          statistics  w  w  norton and company 
grosz  b     hirschberg  j          some intonational characteristics of discourse structure  in proceedings of the international conference on spoken language processing
 icslp  
grosz  b  j     sidner  c  l          attention  intentions  and the structure of discourse 
computational linguistics                  
  

ficue phrase classification using machine learning

halliday  m  a  k     hassan  r          cohesion in english  longman 
hearst  m  a          multi paragraph segmentation of expository text  in proceedings of
the thirty second annual meeting of the association for computational linguistics
 acl  
hindle  d  m          acquiring disambiguation rules from text  in proceedings of the
twenty seventh annual meeting of the association for computational linguistics
 acl  
hirschberg  j          accent and discourse context  assigning pitch accent in synthetic
speech  in proceedings of the eighth national conference on artificial intelligence
 aaai  
hirschberg  j     litman  d          now let s talk about  now   identifying cue phrases
intonationally  in proceedings of the twenty fifth annual meeting of the association
for computational linguistics  acl  
hirschberg  j     litman  d          empirical studies on the disambiguation of cue phrases 
computational linguistics                  
holte  r  c          very simple classification rules perform well on most commonly used
datasets  machine learning                
litman  d     hirschberg  j          disambiguating cue phrases in text and speech  in
proceedings of the thirteenth international conference on computational linguistics
 coling  
litman  d  j          classifying cue phrases in text and speech using machine learning 
in proceedings of the twelfth national conference on artificial intelligence  aaai  
litman  d  j     allen  j  f          a plan recognition model for subdialogues in conversation  cognitive science              
litman  d  j     passonneau  r  j          combining multiple knowledge sources for
discourse segmentation  in proceedings of the thirty third annual meeting of the
association for computational linguistics  acl  
mccarthy  j  f     lehnert  w  g          using decision trees for coreference resolution  in
proceedings of the fourteenth international joint conference on artificial intelligence
 ijcai  
moser  m     moore  j  d          investigating cue selection and placement in tutorial
discourse  in proceedings of the thirty third annual meeting of the association for
computational linguistics  acl  
ostendorf  m     ross  k   in press   a multi level model for recognition of intonation labels 
in y  sagisaka  n  c     higuchi  n   eds    computing prosody  springer verlag 
passonneau  r  j     litman  d  j   in press   discourse segmentation by human and
automated means  computational linguistics     
  

filitman

pierrehumbert  j  b          the phonology and phonetics of english intonation  ph d 
thesis  massachusetts institute of technology  distributed by the indiana university
linguistics club 
pitrelli  j   beckman  m     hirschberg  j          evaluation of prosodic transcription
labeling reliability in the tobi framework  in proceedings of the international conference on spoken language processing  icslp  
quinlan  j  r          c      programs for machine learning  san mateo  ca  morgan
kaufmann 
reichman  r          getting computers to talk like you and me  discourse context 
focus  and semantics  cambridge  ma  mit press 
siegel  e  v          competitively evolving decision trees against fixed training cases
for natural language processing  in k  e  kinnear  j   ed    advances in genetic
programming  cambridge  ma  mit press 
siegel  e  v     mckeown  k  r          emergent linguistic rules from the automatic
grouping of training examples  disambiguating clue words with decision trees  in
proceedings of the twelfth national conference on artificial intelligence  aaai  
soderland  s     lehnert  w          corpus driven knowledge acquisition for discourse
analysis  in proceedings of the twelfth national conference on artificial intelligence
 aaai  
stieman  l  j          a discourse analysis approach to structured speech  in working
notes of aaai spring symposium series  empirical methods in discourse interpretation and generation 
weiss  s  m     kulikowski  c          computer systems that learn  classification
and prediction methods from statistics  neural nets  machine learning  and expert
systems  san mateo  ca  morgan kaufmann 
wermter  s   riloff  e     scheler  g          connectionist  statistical and symbolic approaches to learning for natural language processing  berlin  germany  springerverlag 
wightman  c  w     ostendorf  m          automatic labeling of prosodic patterns  ieee
transactions on speech and audio processing                 
zuckerman  i     pearl  j          comprehension driven generation of meta technical
utterances in math tutoring  in proceedings of the fifth national conference on
artificial intelligence  aaai  

  

fi