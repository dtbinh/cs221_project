journal artificial intelligence research               

submitted       published     

cue phrase classification using machine learning
diane j  litman

at t labs   research      mountain avenue
murray hill  nj       usa

diane research att com

abstract

cue phrases may used discourse sense explicitly signal discourse structure 
sentential sense convey semantic rather structural information  correctly
classifying cue phrases discourse sentential critical natural language processing
systems exploit discourse structure  e g   performing tasks anaphora resolution plan recognition  paper explores use machine learning classifying
cue phrases discourse sentential  two machine learning programs  cgrendel
c     used induce classification models sets pre classified cue phrases
features text speech  machine learning shown effective technique
automating generation classification models  improving
upon previous results  compared manually derived classification models already
literature  learned models often perform higher accuracy contain new
linguistic insights data  addition  ability automatically construct classification models makes easier comparatively analyze utility alternative feature
representations data  finally  ease retraining makes learning approach
scalable exible manual methods 

   introduction

cue phrases words phrases may sometimes used explicitly signal discourse
structure text speech  particular  used discourse sense  cue
phrase explicitly conveys structural information  used sentential sense  cue
phrase instead conveys semantic rather structural information  following examples
 taken spoken language corpus described section    illustrate sample
discourse sentential usages cue phrases  say   further  
discourse
       might concept say researcher worked fifteen years
certain project        
 further  crucial ai probably expert databases well        
sentential
       let say bears strong resemblance much work that s
done semantic nets even frames  
       place even stranger away        
example  used discourse sense  cue phrase  say  conveys structural
information example beginning  used sentential sense   say 
convey structural information instead functions verb 
c      ai access foundation morgan kaufmann publishers  rights reserved 

filitman

ability correctly classify cue phrases discourse sentential critical
natural language processing systems need recognize convey discourse structure 
tasks improving anaphora resolution  grosz   sidner        reichman        
consider following example  taken corpus described
section     
system attempts hold rules  say expert database expert system 
expect hold rules fact apply us
appropriate situations 
example  cue phrases  say   then  discourse usages  explicitly
signal boundaries intervening subtopic discourse structure  furthermore 
referents noun phrases  the system    an expert database    an expert
system  possible referents pronoun  it   structural information
conveyed cue phrases  system determine  the system  relevant
interpreting pronoun  it    an expert database   an expert system 
occur within embedded  and concluded  subtopic  without cue phrases 
reasoning required determine referent  the system  intended referent
 it  would much complex 
correctly classifying cue phrases discourse sentential important natural
language processing tasks well  discourse sentential distinction used
improve naturalness synthetic speech text to speech systems  hirschberg        
text to speech systems generate synthesized speech unrestricted text  cue phrase
classified discourse sentential using features input text 
synthesized using different intonational models discourse sentential usages 
addition  explicitly identifying rhetorical relationships  discourse usages cue
phrases used improve coherence multisentential texts natural language
generation systems  zuckerman   pearl        moser   moore         cue phrases
used reduce complexity discourse processing areas argument
understanding  cohen        plan recognition  litman   allen        grosz   sidner 
      
problem cue phrase classification often noted  grosz   sidner 
       recently  models classifying cue phrases neither developed evaluated
based careful empirical analyses  even though literature suggests features
might useful cue phrase classification  quantitative analyses actual
classification algorithms use features  nor suggestions different types
features might combined   systems recognize generate cue phrases simply
assume discourse uses utterance clause initial  reichman        zuckerman  
pearl         empirical studies showing intonational prominence
certain word classes varies respect discourse function  halliday   hassan       
altenberg         studies investigate cue phrases per se 
address limitations  hirschberg litman        conducted several empirical
studies specifically addressing cue phrase classification text speech  hirschberg
litman pre classified set naturally occurring cue phrases  described cue phrase
terms prosodic textual features  the features posited literature easy
   example described detail hirschberg litman        

  

ficue phrase classification using machine learning

automatically code   manually examined data construct classification models
best predicted classifications feature values 
paper examines utility machine learning automating construction
models classifying cue phrases empirical data  set experiments
described use two machine learning programs  cgrendel  cohen             
c     quinlan         induce classification models sets pre classified cue phrases
features  features  classes training examples used studies
hirschberg litman         well additional features  classes training examples  given input machine learning programs  results evaluated
quantitatively qualitatively  comparing error rates content
manually derived learned classification models  experimental results show
machine learning indeed effective technique  automating generation
classification models  improving upon previous results  accuracy
learned classification models often higher accuracy manually derived
models  learned models often contain new linguistic implications  learning
paradigm makes easier compare utility different knowledge sources 
update model given new features  classes  training data 
next section summarizes previous work cue phrase classification  section  
describes machine learning approach cue phrase classification taken
paper  particular  section describes four sets experiments use machine
learning automatically induce cue phrase classification models  types inputs
outputs machine learning programs presented  methodologies
used evaluate results  section   presents discusses experimental results 
highlights many benefits machine learning approach  section   discusses
practical utility results paper  finally  section   discusses use machine
learning studies discourse  section   concludes 

   previous work classifying cue phrases
section summarizes hirschberg s litman s empirical studies classification
cue phrases speech text  hirschberg   litman              litman   hirschberg 
       hirschberg s litman s data  cue phrases taken corpora recorded
transcribed speech  classified discourse sentential  coded using speech based
text based features  used create input machine learning experiments  hirschberg s litman s results  performance figures manually developed cue
phrase classification models  used benchmark evaluating performance
classification models produced machine learning 
first study hirschberg litman investigated usage cue phrase  now 
multiple speakers radio call in show  hirschberg   litman         classification
model based prosodic features developed based manual analysis  training 
set    examples  now   evaluated previously unseen test set    examples
 now   follow up study  hirschberg   litman         hirschberg litman tested
classification model larger set cue phrases  namely single word cue phrases
technical keynote address single speaker  corpus yielded     instances   
  

filitman

prosodic model 

composition intermediate phrase   alone
elseif composition intermediate phrase    alone
position intermediate phrase   first
accent   deaccented
elseif accent   l 
elseif accent   h 
elseif accent   complex
elseif position intermediate phrase    first

discourse

discourse

discourse

sentential

sentential

sentential

   
   
   
   
   
   
   
   

textual model 

preceding orthography   true
elseif preceding orthography   false

   
    

discourse
sentential

figure    decision tree representation manually derived classification models
hirschberg litman 
different single word cue phrases derived literature   hirschberg litman
used cue phrases first    minutes corpus develop complementary cue
phrase classification model based textual features  litman   hirschberg        
tested full corpus  hirschberg   litman         first study
referred  now  study  follow up study  multiple cue phrase  study 
note term  multiple  means    different single word cue phrases  as opposed
cue phrase  now   considered  cue phrases consisting multiple
words  e g   by way   considered 
method hirschberg litman used develop prosodic textual classification models follows  first separately classified example cue phrase
data discourse  sentential ambiguous listening recording reading
transcription   example described set prosodic textual features  
previous observations literature correlating discourse structure prosodic information  discourse usages cue phrases initial position clause  contributed
choice features  set classified described examples examined
order manually develop classification models shown figure    models
shown using decision trees ease comparison results c   
explained below 
prosody described using pierrehumbert s theory english intonation  pierrehumbert         pierrehumbert s theory  intonational contours described sequences
low  l  high  h  tones fundamental frequency  f   contour  the physical
   figure   contains list    cue phrases  hirschberg litman        provide full details regarding
distribution cue phrases  frequent cue phrase  and   occurs     times 
next frequent cue phrase  now   occurs    times   but    like    or   so 
occur fifty times  four least frequent cue phrases    essentially    otherwise    since 
 therefore    occur   times 
   class ambiguous introduced multiple cue phrase study  hirschberg   litman       
litman   hirschberg        
   although limited set textual features noted  now  data  analysis  now  data
yield textual classification model 

  

ficue phrase classification using machine learning

correlate pitch   intonational contours domain intonational phrase 
finite state grammar describes set tonal sequences intonational phrase 
well formed intonational phrase consists one intermediate phrases followed
boundary tone  well formed intermediate phrase one pitch accents followed
phrase accent  boundary tones phrase accents consist single tone 
pitch accents consist either single tone pair tones  two simple pitch
accents  h  l   four complex accents  l  h  l h   h  l  h l   
  indicates tone aligned stressed syllable associated lexical item 
note every stressed syllable accented  lexical items bear pitch accents
called accented  called deaccented 
prosody manually transcribed hirschberg examining fundamental frequency  f   contour  listening recording  transcription process
performed separately process discourse sentential classification  produce
f  contour  recording corpus digitized pitch tracked using speech analysis software  resulted display f  x axis represented time
y axis represented frequency hz  various phrase final characteristics  e g   phrase accents 
boundary tones  well pauses syllable lengthening  helped identify intermediate
intonational phrases  peaks valleys display f  contour helped
identify pitch accents  similar manual transcriptions prosodic phrasing accent
shown reliable across coders  pitrelli  beckman    hirschberg        
prosody coded  hirschberg litman represented every cue phrase terms
following prosodic features   accent corresponded pitch accent  if any 
associated cue phrase  intonational intermediate phrases
containing cue phrase  feature composition phrase represented whether
cue phrase alone phrase  the phrase contained cue phrase 
cue phrase cue phrases   position phrase represented whether cue
phrase first  the first lexical item prosodic phrase unit   possibly preceded
cue phrases  not 
textual features used multiple cue phrase study  hirschberg   litman       
litman   hirschberg        extracted automatically transcript  part
speech cue phrase obtained running program tagging words one
approximately    parts speech  church        transcript   several characteristics
cue phrase s immediate context noted  particular  whether immediately preceded succeeded orthography  punctuation paragraph boundary  
whether immediately preceded succeeded lexical item corresponding
another cue phrase 
background  classification models shown figure   explained 
prosodic model uniquely classifies cue phrase using features composition
intermediate phrase  position intermediate phrase  accent  cue phrase
uttered single intermediate phrase   possibly cue phrases  i e   line    
figure     larger intermediate phrase initial position  possibly preceded
   features used figure   discussed here 
   another syntactic feature   dominating constituent   obtained running parser fidditch  hindle 
      transcript  however  since feature appear models manually derived
training data  litman   hirschberg         feature pursued 

  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
prosodic
        
        
textual
        
        
default class
        
        

table        confidence intervals error rates     manually derived classification models hirschberg litman  testing data  multiple cue phrase corpus  
cue phrases  l  accent deaccented  classified discourse  part
larger intermediate phrase either initial position h  complex accent 
non initial position  sentential  textual model classifies cue phrases using
single feature preceding orthography   cue phrase preceded type
orthography  classified discourse  otherwise  cue phrase classified sentential 
prosodic model used classify cue phrase training data  i e  
    examples  now  model developed  error rate       
error rate textual model training examples multiple cue phrase
corpus        litman   hirschberg        
prosodic textual models evaluated quantifying performance
correctly classifying example cue phrases two test sets data  shown rows
labeled  prosodic   textual  table    test set subset     examples
multiple cue phrase corpus  first test set      examples  consists
classifiable cue phrases  i e   cue phrases hirschberg litman classified
discourse classified sentential  note cue phrases hirschberg
litman classified ambiguous unable agree upon included
classifiable subset   these cue phrases considered learning experiments
described section      however   second test set  classifiable non conjuncts
     examples   created classifiable cue phrases removing instances
 and    or   but   subset considered particularly reliable since       nonconjuncts classifiable compared       example cue phrases  error rate
prosodic model       classifiable cue phrases       classifiable
non conjuncts  hirschberg   litman         error rate textual model      
classifiable cue phrases       classifiable non conjuncts  hirschberg  
litman         last row table shows error rates simple  default class 
baseline model always predicts frequent class corpus  sentential  
rates       classifiable cue phrases       classifiable non conjuncts 
   classification model based part of speech developed  litman   hirschberg       
hirschberg   litman         however  perform well model based orthography
 the error rate part of speech model       larger test set  opposed      
orthographic model   furthermore  model combined orthography part of speech performed
comparably simpler orthographic model  hirschberg   litman         hirschberg litman
preliminary observations suggesting adjacency cue phrases might prove useful 
   following hirschberg litman         original        example sets  hirschberg   litman 
      combined 

  

ficue phrase classification using machine learning

although computed hirschberg litman  table   associates margins errors error percentage  used compute confidence intervals  freedman 
pisani    purves          the margin error   standard errors     confidence
interval using normal table   lower bound confidence interval computed
subtracting margin error error rate  upper bound computed
adding margin error  thus      confidence interval prosodic model
classifiable cue phrase test set                 analysis confidence intervals
indicates improvement prosodic textual models default
model significant  example  upper bounds error rates prosodic
textual models classifiable cue phrase test set                 lower
lower bound default class error rate          methodology using statistical inference determine whether differences error rates significant discussed
fully section     

   experiments using machine learning

section describes experiments use machine learning programs c     quinlan 
      cgrendel  cohen              automatically induce cue phrase classification
models  cgrendel c    similar learning methods
neural networks cart  brieman  friedman  olshen    stone        induce
classification models preclassified examples  program takes following inputs 
names classes learned  names possible values fixed set features 
training data  i e   set examples class feature values specified  
output program classification model  expressed c    decision tree
cgrendel ordered set if then rules  cgrendel c    learn
classification models using greedy search guided  information gain  metric 
first group machine learning experiments replicate training testing conditions used hirschberg litman         reviewed previous section   support
direct comparison manual machine learning approaches  second group
experiments evaluate utility training larger amounts data feasible
manual analysis hirschberg litman  third set experiments allow
machine learning algorithms distinguish among    cue phrases  evaluate utility developing classification models specialized particular cue phrases  fourth set
experiments consider examples multiple cue phrase corpus 
classifiable cue phrases  set experiments attempt predict third classification
unknown  well classifications discourse sentential  finally  within
four sets experiments  individual experiment learns classification model using
different feature representation training data  experiments consider features
isolation  comparatively evaluate utility individual feature classification 
experiments consider linguistically motivated sets features  gain insight
feature interactions 

    machine learning inputs

section describes inputs machine learning programs  namely 
names classifications learned  names possible values fixed set
  

filitman

classification
judge  judge 
cue phrases
non conjuncts

total
   
   

classifiable cue phrases
discourse sentential
d d
s s
   
   
   
   

unknown
    d s s d d   s     d   s
  
 
 
 
 
 
 
  
 
 
 
 
 
 

table    determining classification cue phrases 
features  training data specifying class feature values example
training set 
      classifications

first input learning program specifies names fixed set classifications 
hirschberg litman s   way classification cue phrases   judges  hirschberg  
litman        transformed classifications used machine learning programs
shown table    recall section   judge classified cue phrase
discourse  sentential  ambiguous  classifications shown d  s    table   
discussed section    classifiable cue phrases cue phrases judges
classified either discourse sentential usages  thus  machine learning
experiments  cue phrase assigned classification discourse judges classified
discourse  d d  shown column   table     similarly  cue phrase assigned
classification sentential judges classified sentential  s s  shown column
                    examples full corpus classifiable             
    non conjuncts classifiable 
machine learning experiments  third cue phrase classification
considered  particular  cue phrase assigned classification unknown
hirschberg litman classified ambiguous       shown column    
unable agree upon classification  d s  s d  d    s      d    s  shown
columns        full corpus     cue phrases        judged ambiguous
judges          cases       true disagreement  d s      cue phrases
       judged ambiguous first judge classified second judge    d
  s   conjunctions  and    or   but  removed corpus 
   examples        judged ambiguous judges    instances  actually  
  instances  because   essentially     instance  generally    indeed  
 like   now     case       true disagreement  an instance  like   
  cue phrases         instance  like   otherwise    judged ambiguous
first judge 
      features

second component input learning program specifies names potential
values fixed set features  set primitive features considered learning
experiments shown figure    feature values either numeric value one
fixed set user defined symbolic values  feature representation shown follows
representation hirschberg litman except noted  length intonational phrase  p  

ficue phrase classification using machine learning

prosodic features

  length intonational phrase  p l   integer 
  position intonational phrase  p p   integer 
  length intermediate phrase  i l   integer 
  position intermediate phrase  i p   integer 
  composition intermediate phrase  i c   only  cue phrases  other 
  accent  a   h   l   l  h  l h   h  l  h l   deaccented  ambiguous 
  accent   a    h   l   complex  deaccented  ambiguous 
textual features
  preceding cue phrase  c p   true  false  na 
  succeeding cue phrase  c s   true  false  na 
  preceding orthography  o p   comma  dash  period  paragraph  false  na 
  preceding orthography   o p    true  false  na 
  succeeding orthography  o s   comma  dash  period  false  na 
  succeeding orthography   o s    true  false  na 
  part of speech  pos   article  coordinating conjunction  cardinal numeral  subordinating conjunction 
preposition  adjective  singular mass noun  singular proper noun  intensifier  adverb  verb base form 
na 

lexical feature

  token  t   actually  also  although  and  basically  because  but  essentially  except  finally  first  further 

generally  however  indeed  like  look  next  no  now  ok  or  otherwise  right  say  second  see  similarly 
since  so  then  therefore  well  yes 

figure    representation features  use c    cgrendel 
l  length intermediate phrase  i l  represent number words intonational
intermediate phrases containing cue phrase  respectively  feature coded
 now  data  coded  although used  later multiple cue phrase
data  position intonational phrase  p p  position intermediate phrase  i p  use
numeric values rather earlier symbolic values  e g   first figure     composition
intermediate phrase  i c  replaces value alone  meaning phrase contained
example cue phrase  example plus cue phrases  figure  
primitive values cue phrases  whose disjunction equivalent
alone   i c uses value rather  alone  as used figure     accent
 a  uses value ambiguous represent cases prosodic analysis yields
disjunction  e g    h  l h     accent   a   re represents symbolic values
feature accent  a  using abstract level description  particular  l  h 
l h   h  l  h l  represented separate values single value  
superclass complex   a   useful abstractions often result learning
process  a  explicitly represented advance prosodic feature representation
potential automated  see section    
textual features  value na  not applicable  ects fact    recorded
examples included transcription  done independently
  

filitman

studies performed hirschberg litman         coding used hirschberg
litman  preceding cue phrase  c p  succeeding cue phrase  c s  represented actual
cue phrase  e g    and   preceding succeeding cue phrase  value
true encodes cases  prosodic feature set a   preceding orthography 
 o p   succeeding orthography   o s   re represent symbolic values
preceding orthography  o p  succeeding orthography  o s   respectively  using
abstract level description  e g   comma  dash  period represented separate values
o s single value true o s    done reliability coding
detailed transcriptions orthography known  part of speech  pos  represents
part speech assigned cue phrase church s program tagging part speech
unrestricted text  church         program assign approximately    different
values  subset values actually assigned cue phrases
transcripts corpora shown figure  finally  lexical feature token  t 
new study  represents actual cue phrase described 
      training data

final input learning program training data  i e   set examples
class feature values specified  consider following utterance  taken
multiple cue phrase corpus  hirschberg   litman        
example     now   now welcomed here   it s time get
business conference 
utterance contains two cue phrases  corresponding two instances  now  
brackets parentheses illustrate intonational intermediate phrases  respectively 
contain example cue phrases  note single intonational phrase contains
examples  example uttered different intermediate phrase 
interested feature length intonational phrase  p l   two examples would
represented training data follows 
p l class
  discourse
  sentential
first column indicates value assigned feature p l  second column
indicates example classified  thus  length intonational phrase
containing first instance  now    words  example cue phrase classified
discourse usage  interested feature composition intermediate
phrase  i c   two examples would instead represented training data follows 
i c class
discourse
sentential
is  intermediate phrase containing first instance  now  contains
cue phrase  now   intermediate phrase containing second instance  now 
contains  now  well   lexical items cue phrases  note
value p l examples  value i c different 
  

ficue phrase classification using machine learning

    machine learning outputs

output machine learning programs classification models  c    model
expressed decision tree  consists either leaf node  a class assignment  
decision node  a test feature  one branch subtree possible outcome
test   following example illustrates non graphical representation decision
node testing feature n possible values 
test       
   

elseif testn

   

tests form  feature operator value      feature  name feature  e g 
accent    value  valid value feature  e g   deaccented   features
symbolic values  e g   accent   one branch symbolic value  operator
    used  features numeric values  e g   length intonational phrase  
two branches  comparing numeric value threshold value  operators
       used  given decision tree  cue phrase classified starting
root tree following appropriate branches leaf reached  section  
shows example decision trees produced c    
cgrendel classification model expressed ordered set if then rules
following form 
test            testk class
 if  part rule conjunction tests values  varying  features 
tests form  feature operator value   c      feature  name
feature   value  valid value feature  unlike c     operators    
 
used features symbolic values  used features numeric
values   then  part rule specifies class assignment  e g  discourse   given set
if then rules  cue phrase classified using rule whose  if  part satisfied 
two rules rules disagree class example  cgrendel
applies one two con ict resolution strategies  chosen user   choose first rule 
choose rule accurate data  experiments reported use
second strategy  rules  cgrendel assigns default class  section  
shows example rules produced cgrendel 
c    cgrendel learn classification models using greedy search guided
 information gain  metric  c    uses divide conquer process  training examples
recursively divided subsets  using tests discussed above   subsets
belong single class  test chosen divide examples maximizes
metric called gain ratio  a local measure progress  consider
subsequent tests   metric based information theory discussed detail
quinlan         test selected  backtracking  ideally  set chosen
tests result small final decision tree  cgrendel generates set if then rules
using method called separate conquer  to highlight similarity divide
conquer  
   additional type test may invoked c    option 

  

filitman

many rule learning systems generate hypotheses using greedy strategy
rules added rule set one one effort form small cover
positive examples  rule  turn created adding one condition
another antecedent rule consistent negative
data   cohen       
although cgrendel claimed two advantages c     advantages
come play experiments reported here  first  if then rules appear easier
people understand decision trees  quinlan         however  cue phrase
classification task  decision trees produced c    quite compact thus easily
understood  furthermore  rule representation derived c    decision trees 
using program c   rules  second  cgrendel allows users exploit prior knowledge
learning problem  constraining syntax rules learned  however 
prior knowledge exploited cue phrase experiments  main reason using
c    cgrendel increase reliability comparisons machine
learning manual results  particular  comparable results obtained using
c    cgrendel  performance differences learned manually
derived classification models less likely due specifics particular learning
program  likely ect learned manual distinction 

    evaluation

output machine learning experiment classification model
learned training data  learned models qualitatively evaluated examining linguistic content  comparing manually derived models
figure    learned models quantitatively evaluated examining error
rates testing data comparing error rates error
rates shown table    error rate classification model computed using
model predict classifications set examples classifications already
known  comparing predicted known classifications  cue phrase domain 
error rate computed summing number discourse examples misclassified
sentential number sentential examples misclassified discourse  dividing
total number examples 
error rates learned classification models estimated using two methodologies  train and test error rate estimation  weiss   kulikowski         holds out  test
set examples  seen training completed  is  model
developed examining training examples  error model estimated
using model classify test examples  evaluation method used
hirschberg litman  resampling method cross validation  weiss   kulikowski 
      estimates error rate using multiple train and test experiments  example    fold cross validation  instead dividing examples training test sets once     runs
learning program performed  total set examples randomly divided   
disjoint test sets  run thus uses     examples test set training
remaining     testing  note iteration cross validation 
learning process begins scratch  thus new classification model learned
training sample  estimated error rate obtained averaging error rate test  

ficue phrase classification using machine learning

ing portion data    runs  method make sense
humans  computers truly ignore previous iterations  sample sizes hundreds
 the classifiable subset multiple cue phrase sample classifiable non conjunct
subset provide         examples  respectively     fold cross validation often provides
better performance estimate hold out method  weiss   kulikowski        
major advantage cross validation examples eventually used testing 
almost examples used given training run 
best performing learned models identified comparing error rates
error rates learned models manually derived error rates 
determine whether fact error rate e  lower another error rate e 
significant  statistical inference used  particular  confidence intervals two
error rates computed      confidence level  error rate estimated using
single error rate test set  i e   train and test methodology   confidence
interval computed using normal approximation binomial distribution  freedman
et al          error rate estimated using average multiple error
rates  i e   cross validation methodology   confidence interval computed using
t table  freedman et al          upper bound     confidence interval e 
lower lower bound     confidence interval error rate e  
difference e  e  assumed significant   

    experimental conditions
section describes conditions used set machine learning experiments 
experiments differ use training testing corpora  methods estimating error
rates  features classifications used  actual results experiments
presented section   
      four sets experiments

learning experiments conceptually divided four sets  experiment
first set estimates error rate using train and test method  training
testing samples used hirschberg litman         the  now  data
two subsets multiple cue phrase corpus  respectively   allows direct comparison
manual machine learning approaches  however  prosodic experiments
conducted hirschberg litman        replicated  textual training testing
conditions replicated original training corpus  the first    minutes
multiple cue phrase corpus   litman   hirschberg        subset of  rather disjoint
from  test corpus  the full    minutes multiple cue phrase corpus   hirschberg  
litman        
contrast  experiment second set uses cross validation estimate error
rate  furthermore  training testing samples taken multiple cue
phrase corpus  experiment uses     examples multiple cue phrase
data training  remaining     testing  thus experiment second
set trains much larger amounts data      classifiable examples      classifiable
    thanks william cohen suggesting methodology 

  

filitman

prosody
hl  features
phrasing
length
position
intonational
intermediate
text
adjacency
orthography
preceding
succeeding
speech text

p l
x
x
x
x

p p i l i p
x x x
x
x x x
x
x
x
x
x x

i c a 
x x x
x x x
x
x

c p

x
x
x

x

x

x

x

x

x

x

x

c s o p

x
x
x
x

o p  o s

o s  pos

x

x

x

x

x
x

x
x

x

x

x

x

x
x

x
x

x

x

table    multiple feature sets components 
non conjuncts  experiment first set       nows    reliability
testing compromised due use cross validation  weiss   kulikowski        
experiment third set replicates experiment second set  exception learning program allowed distinguish cue phrases 
done adding feature representing cue phrase  the feature token figure   
experiment second set  since potential use lexical feature
noted used hirschberg litman         experiments provide qualitatively new linguistic insights data  example  features may
used differently predict classifications different cue phrases sets cue phrases 
finally  experiment fourth set replicates experiment first  second 
third set  exception     examples multiple cue phrase corpus
considered  practice  learned cue phrase classification model
likely used classify cue phrases  even dicult human judges
classify  experiments fourth set allow learning programs attempt
learn class unknown  addition classes discourse sentential 
      feature representations within experiment sets

within four sets experiments  individual experiment represents
data using different subset available features  first  data represented
   single feature sets  corresponding prosodic textual feature shown
figure    experiments comparatively evaluate utility individual feature
classification  representations example   shown illustrate data
represented using single feature set p l  using single feature set i c 
second  data represented    multiple feature sets shown table   
sets contains linguistically motivated subset least      features 
first   sets use prosodic features  prosody considers prosodic features
coded example cue phrase  hl  features considers coded features
used model shown figure    phrasing considers features
intonational intermediate phrases containing example cue phrase  i e   length
  

ficue phrase classification using machine learning

example     

   now welcomed here   it s time get business conference 
p p i l i p i c

a 
c p c s o p o p  o s o s  pos class
 
 
  h  l complex f

par 
f
f
adv  disc 
 
 
  h 
h 

f
f
f
f
f
adv  sent 


p l
 
 

figure    representation example   feature set speech text 
phrase  position example phrase  composition phrase   length position
consider one features  respect intonational
intermediate phrase  conversely  intonational intermediate consider one type
phrase  consider features  next   sets use textual features  text
considers textual features  adjacency orthography consider single textual
feature  consider preceding succeeding immediate context  preceding
succeeding consider contextual features relating orthography cue phrases 
limit context  last set  speech text  uses prosodic textual features 
figure   illustrates two example cue phrases example   would represented
using speech text  consider feature values first example cue phrase  since
example first lexical item intonational intermediate phrases
contain it  position phrases  p p i p     since intermediate phrase
containing cue phrase contains lexical items  length  i l    word
composition  i c  cue phrase  values a  indicate
intonational phrase described sequence tones  complex pitch accent h  l
associated cue phrase  respect textual features  utterance
transcribed began new paragraph  thus example cue phrase
preceded another cue phrase  c p   preceded form orthography  o p
o p    since example cue phrase immediately followed another instance
 now  transcription  cue phrase succeeded another cue phrase  c s 
succeeded orthography  o s o s    finally  output part
speech tagging program run transcript corpus yields value adverb
cue phrase s part speech  pos  
first set experiments replicate prosodic experiments conducted
hirschberg litman         cue phrases represented using subset feature sets consist prosodic features  second set experiments  examples
represented using    different feature sets  the    single feature sets   
multiple feature sets   third set experiments  examples represented using   
tokenized feature sets  constructed adding lexical feature token figure    the
cue phrase described     single    multiple feature sets
second set experiments  tokenized feature sets referred using names
single multiple feature sets  concatenated      following illustrates
two cue phrases example   would represented using p l  
p l
class
  discourse
  sentential
  

filitman

representation similar p l representation shown earlier  except second
column indicates value assigned feature token  t  

   results

section examines results running two learning programs   c    cgrendel   four sets cue phrase classification experiments described above  learned
classification models compared classification models shown figure   
error rates learned classification models compared error
rates shown table   error rates learned models 
seen  results suggest machine learning useful automating generation
linguistically viable classification classification models  generating classification models
perform lower error rates manually developed hypotheses  adding
body linguistic knowledge regarding cue phrases 

    experiment set    replicating hirschberg litman

first group experiments replicate training  testing  evaluation conditions
used hirschberg litman         order investigate well machine learning
performs comparison manual development cue phrase classification models 
figure   shows best performing prosodic classification models learned two
machine learning programs  top figure replicates manually derived prosodic
model figure   ease comparison  prosodic features used
represent     training examples  now   i e   example represented using
feature set prosody table       classification models learned shown
manually derived model top figure    note using learning
programs  decision tree learned smaller feature sets phrasing
position used represent  now  data  bottom portion figure shows
classification models learned examples represented using
single prosodic feature position intonational phrase  p p   model
learned examples represented using multiple feature set intonational 
recall c    represents learned classification model decision tree 
level tree  shown indentation  specifies test single feature  branch
every possible outcome test  branch either lead assignment class 
another test  example  c    classification model learned prosody classifies
cue phrases using two features position intonational phrase  p p  position
intermediate phrase  i p   note available features prosody  recall
table    used decision tree  tree initially branches based value
feature position intonational phrase    first branch leads class assignment
discourse  second branch leads test feature position intermediate phrase 
first branch test leads class assignment discourse  second branch
leads sentential  c    produces unsimplified pruned decision trees  goal
    experiment set    feature set prosody contain features p l i l  recall
phrasal length coded later multiple cue phrase study 
    ease comparison figure    original symbolic representation feature value used
rather integer representation shown figure   

  

ficue phrase classification using machine learning

manually derived prosodic model  repeated figure    

composition intermediate phrase   alone
elseif composition intermediate phrase    alone
position intermediate phrase   first
accent   deaccented
elseif accent   l 
elseif accent   h 
elseif accent   complex
elseif position intermediate phrase    first

discourse

discourse

discourse

sentential

sentential

sentential

   
   
   
   
   
   
   
   

decision tree learned prosody  phrasing  position using c    

position intonational phrase   first
elseif position intonational phrase    first
position intermediate phrase   first
elseif position intermediate phrase    first
discourse

discourse
sentential

ruleset learned prosody  phrasing  position using cgrendel 

 position intonational phrase    first     position intermediate phrase    first 
default discourse

sentential

decision tree learned p p intonational using c    

position intonational phrase   first
elseif position intonational phrase    first

discourse
sentential

ruleset learned p p intonational using cgrendel 

position intonational phrase    first
default discourse

sentential

figure    example c    cgrendel classification models learned different prosodic
feature representations  now  data 

  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
p p
        
        
prosody
        
        
phrasing
        
        
position
        
        
intonational
        
        
manual prosodic
        
        

table        confidence intervals error rates     best performing cgrendel
prosodic classification models  testing data   training data  now  corpus 
testing data multiple cue phrase corpus  
pruning process take complex decision tree may overfitted
training data  produce tree comprehensible whose accuracy
comprised  quinlan         since almost trees improved pruning  quinlan 
       simplified decision trees considered paper 
contrast  cgrendel represents learned classification model set if then
rules  rule specifies conjunction tests various features  results
assignment class  example  cgrendel ruleset learned prosody classifies
cue phrases using two features position intonational phrase  p p  position
intermediate phrase  i p   the two features used c    decision tree  
values features first  if then rule applies cue phrase classified
sentential  value either feature first  default applies cue phrase
classified discourse 
examination learned classification models figure   shows
comparable content portion manually derived model classifies cue
phrases solely phrasal position  line       particular  classification models
say cue phrase initial phrasal position classify sentential 
hand  manually derived model assigns class sentential given
initial phrasal position conjunction certain combinations phrasal composition
accent  learned classification models instead classify cue phrase discourse
cases  shown  discrimination manually obtained model
significantly improve performance compared learned classification
models  fact one case significantly degrades performance 
error rates learned classification models  now  training data
developed follows     models learned prosody  phrasing
position     models learned p p intonational  recall
section   error rate manually developed prosodic model figure  
training data    
table   presents     confidence intervals error rates best performing
cgrendel prosodic classification models  ease comparison  row labeled  manual
prosodic  presents error rates manually developed prosodic model figure  
two test sets  originally shown table    table includes
cgrendel models whose performance matches exceeds manual performance 
  

ficue phrase classification using machine learning

comparison error rates learned manually developed models suggests
machine learning effective technique automating development cue phrase
classification models  particular  within test set      confidence interval
error rate classification models learned multiple feature sets prosody 
phrasing  position overlaps confidence interval error rate
manual prosodic model  true error rates p p intonational
classifiable non conjunct test set  thus  machine learning supports automatic construction variety cue phrase classification models achieve similar performance
manually constructed models 
results p p intonational classifiable cue phrase test set
shown italics  suggest machine learning may useful improving
performance  although simple classification model learned p p intonational performs worse manually derived model training data  tested
classifiable cue phrases  learned model  with upper bound error rate       
outperforms manually developed model  with lower bound error rate        
suggests manually derived model might overfitted training data 
i e   prosodic feature set useful classifying  now  generalize
cue phrases  noted above  use simplified learned classification models helps
guard overfitting learning approach  ease inducing classification
models many different sets features using machine learning supports generation
evaluation wide variety hypotheses  e g  p p  high performing
optimal performing model training data  
note manual prosodic manual performs significantly better smaller test
set  which contain cue phrases  and    or    but    contrast 
performance improvement p p intonational smaller test set significant 
suggests manually derived model generalize well learned
models 
finally  feature sets shown table    decision trees produced c    perform
error rates rulesets produced cgrendel  test sets  recall
figure   c    decision trees cgrendel rules fact semantically
equivalent feature set  fact comparable results obtained using c   
cgrendel adds extra degree reliability experiments  particular 
duplication results suggests ability match perhaps even improve
upon manual performance using machine learning due specifics either
learning program 

    experiment set    using different training sets
second group experiments evaluate utility training larger amounts
data  done using    fold cross validation estimate error  run
    examples sample used training  and    runs 
examples used testing   addition  experiments second set take
training testing data multiple cue phrase corpus  contrast previous
set experiments training data taken  now  corpus 
seen  changes improve results  learned classification models
  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
p l
        
          
p p
        
        
i l
        
          
i p
        
        
i c
          
          

        
          
a 
        
          
prosody
        
        
hl  features
        
        
phrasing
        
        
length
        
          
position
        
        
intonational
        
        
intermediate
        
        
manual prosodic
        
        

table        confidence intervals error rates     cgrendel prosodic classification models  testing data   training testing done multiple
cue phrase corpus using cross validation  
perform lower comparable error rates compared manually developed
models 
      prosodic models

table   presents error rates classification models learned cgrendel 
   different prosodic experiments   for experiment sets      c    error rates
presented appendix a   numeric cell shows     confidence interval
error rate  equal error percentage obtained cross validation margin
error        standard errors  using t table   top portion table considers
models learned single prosodic feature sets  figure     middle portion
considers models learned multiple feature sets  table     last row
considers manually developed prosodic model  error rates shown italics indicate
performance learned classification model exceeds performance
manual model  given test set   error rates shown parentheses indicate
opposite case   performance manual model exceeds performance
learned model  cases omitted table   
experiment set    comparison error rates learned manually
developed models suggests machine learning effective technique
automating development cue phrase classification models  improving
performance  evaluated classifiable cue phrase test set  five learned models
improved performance compared manual model  models except i c
perform least comparably manual model  note experiment set    two
learned models outperformed manual model  five learned models performed
least comparably  ability use large training sets thus appears advantage
automated approach 
  

ficue phrase classification using machine learning

manually derived prosodic model  repeated figure    

composition intermediate phrase   alone
elseif composition intermediate phrase    alone
position intermediate phrase   first
accent   deaccented
elseif accent   l 
elseif accent   h 
elseif accent   complex
elseif position intermediate phrase    first

discourse

discourse

discourse

sentential

sentential

sentential

   
   
   
   
   
   
   
   

decision tree learned p p using c    

position intonational phrase  
elseif position intonational phrase    

discourse
sentential

ruleset learned p p using cgrendel 

position intonational phrase  
default discourse

sentential

decision tree learned prosody using c    

position intonational phrase  
position intermediate phrase  
elseif position intermediate phrase    
elseif position intonational phrase    
length intermediate phrase  
elseif length intermediate phrase    

discourse
sentential

discourse
sentential

ruleset learned prosody using cgrendel 

 position intonational phrase       length intermediate phrase   
   position intonational phrase       length intonational phrase    
 length intermediate phrase       length intonational phrase       accent   h  
 length intermediate phrase       length intonational phrase       accent   h  l 
 length intermediate phrase       accent   deaccented 
 length intermediate phrase       length intonational phrase       accent   l  
sentential

sentential

sentential
sentential

sentential

sentential

default discourse

figure    example c    cgrendel classification models learned different prosodic
feature representations classifiable cue phrases multiple cue phrase
corpus 
tested classifiable non conjuncts  where error rate manually
derived model decreases   machine learning useful automating improving
performance  might ect fact manually derived theories already achieve
optimal performance respect examined features less noisy subcorpus 
and or automatically derived theory subcorpus based smaller
training set used larger subcorpus 
examination best performing learned classification models shows
quite comparable content relevant portions prosodic model figure   
often contain linguistic insights  consider classification model learned
single feature position intonational phrase  p p   shown near top figure   
  

filitman

learned classification models say cue phrase initial
position intonational phrase  classify sentential  otherwise classify discourse 
note correspondence line     manually derived prosodic model  note
classification models comparable   p p classification models learned
experiment set    shown figure     despite differences training data 
fact single prosodic feature position intonational phrase  p p  classify cue
phrases least well complicated manual multiple feature learned models
new result learning experiments 
figure   illustrates complex classification models learned using prosody 
largest prosodic feature set  c    model similar lines         manual
model   the length value   equivalent composition value alone   ruleset
induced prosody cgrendel  first   if then rules correlate sentential status
 among things  non initial position     second   rules h  h  l
accents  rules similar lines         figure    however  last   if then rules
ruleset correlate accent l  sentential status phrase
certain length  lines         figure   provide different interpretation
take length account  recall length coded hirschberg litman
test data  length thus never used generate revise prosodic model 
utility length new result experiment set 
although shown  models learned phrasing  position  intonational
outperform manual model  seen table    models correspond
feature sets supersets p p subsets prosody 
      textual models

table   presents error rates classification models learned cgrendel 
   different textual experiments  unlike experiments involving prosodic feature sets 
none learned textual models perform significantly better manually derived
model  however  results suggest machine learning still effective technique
automating development cue phrase classification models  particular  five
learned models  o p  o p   text  orthography  preceding  perform comparably
manually derived model  test sets  note five models learned
five textual feature sets include either feature o p o p   recall figure  
table     models perform significantly better remaining learned
textual models 
figure   shows best performing learned textual models  note similarity
manually derived model  prosodic results  best performing single feature
models perform comparably learned multiple features  fact  cgrendel 
rulesets learned multiple feature sets orthography preceding identical
rulesets learned single features o p o p   even though features
available use   the corresponding error rates table   identical due
    different feature values two figures ect fact phrasal position represented
 now  corpus using symbolic values  as figure     multiple cue phrase corpus using
integers  as figure    
    tests  feature x   feature y  merged figure simplicity  e g    y feature
x  

  

ficue phrase classification using machine learning

model
classifiable cue phrases  n      classifiable non conjuncts  n     
c p
          
          
c s
          
          
o p
        
        
o p 
        
        
o s
          
          
o s 
          
          
pos
          
          
text
        
        
adjacency
          
          
orthography
        
        
preceding
        
        
succeeding
          
          
manual textual
        
        

table        confidence intervals error rates     cgrendel textual classification models  testing data   training testing done multiple
cue phrase corpus using cross validation  
manually derived textual model  repeated figure    
preceding orthography   true discourse
elseif preceding orthography   false sentential
decision tree learned o p   text  orthography  preceding using c    

preceding orthography    na
elseif preceding orthography    false
elseif preceding orthography    true

discourse
sentential
discourse

ruleset learned o p  o p   orthography  preceding using cgrendel 

preceding orthography    false
default discourse

sentential

ruleset learned text using cgrendel 

preceding orthography    false
part of speech   article
default discourse

sentential

sentential

figure    example c    cgrendel classification models learned different textual
feature representations classifiable cue phrases multiple cue phrase
corpus 
estimation using cross validation   cgrendel model text incorporates feature
part of speech  c     models text  orthography preceding identical o p  
      prosodic textual models

table   presents error rates classification models learned cgrendel
data represented using speech text  complete set prosodic textual features  recall
  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
speech text
        
        
manual prosodic
        
        
manual textual
        
        

table        confidence intervals error rates     cgrendel prosodic textual
classification model  testing data   training testing done multiple cue phrase corpus using cross validation  
table     since hirschberg litman develop similar classification model
combined types features  comparison last two rows show error rates
separate prosodic textual models  learned model compared
manual prosodic model  using classifiable cue phrases testing  learning result
significant performance improvement  consistent results discussed above 
several learned prosodic models performed better manually derived prosodic
model test set  performance speech text significantly better worse
performance either best prosodic textual learned models  tables     
respectively  
figure   shows c    cgrendel hypotheses learned speech text  c   
model classifies cue phrases using prosodic textual features performed best
isolation  position intonational phrase preceding orthography   discussed above  
conjunction additional feature length intermediate phrase  which appears
model learned prosody figure     line     manually derived
textual model  learned model associates presence preceding orthography
class discourse  unlike line       however  cue phrases preceded orthography
may classified either discourse sentential  based prosodic feature values  which
available use textual model   branch learned decision tree
corresponding last three lines similar lines               manually
derived prosodic model   recall length value   equivalent composition value
alone  
cgrendel model uses similar features used c    well prosodic
feature accent  also used prosody figure     textual features part of speech
 also used text figure    preceding cue phrase  c     unlike line     
manually derived textual model  cgrendel model classifies cue phrases lacking
preceding orthography sentential conjunction certain feature values 
unlike line     manual model  learned model classifies cue phrases
preceding orthography sentential  if orthography comma  feature values
present   finally  third fifth learned rules elaborate line     additional
prosodic well textual features  first last learned rules elaborate line     

    experiment set    adding feature token

experiment third group replicates experiment second group 
exception data representation includes lexical feature token
  

ficue phrase classification using machine learning

manually derived prosodic model  repeated figure    

composition intermediate phrase   alone
elseif composition intermediate phrase    alone
position intermediate phrase   first
accent   deaccented
elseif accent   l 
elseif accent   h 
elseif accent   complex
elseif position intermediate phrase    first

discourse

discourse

discourse

sentential

sentential

sentential

manually derived textual model  repeated figure    

preceding orthography   true
elseif preceding orthography   false

   
   
   
   
   
   
   
   
   
    

discourse
sentential

decision tree learned speech text using c    

position intonational phrase  
preceding orthography    na
elseif preceding orthography    true
elseif preceding orthography    false
length intermediate phrase     
elseif length intermediate phrase   
length intermediate phrase  
elseif length intermediate phrase    
elseif position intonational phrase    
length intermediate phrase  
elseif length intermediate phrase    
discourse

discourse

discourse
discourse
sentential

discourse

sentential

ruleset learned speech text using cgrendel 

 preceding orthography   false       position intonational phrase     
 preceding orthography   false     length intermediate phrase   
 preceding orthography   false     length intonational phrase       preceding cue phrase   na 
   accent   h  
 preceding orthography   comma     length intermediate phrase       length intonational phrase    
   part of speech   adverb 
 preceding orthography   comma       length intonational phrase       accent   h  
 preceding orthography   comma       length intermediate phrase   
   length intonational phrase    
 position intonational phrase       length intermediate phrase   
   preceding cue phrase   na 
sentential

sentential

sentential

sentential

sentential

sentential

default discourse

sentential

figure    c    cgrendel classification models learned prosodic textual feature representation classifiable cue phrases multiple cue phrase corpus 

  

filitman

model
classifiable cue phrases  n      classifiable non conjuncts  n     
p l 
        
        
p p 
        
        
i l 
        
        
i p 
        
        
i c 
        
        
a 
        
        
a  
        
        
prosody 
        
        
hl  features 
        
        
phrasing 
        
        
length 
        
        
position 
        
        
intonational 
        
        
intermediate 
        
        
manual prosodic
        
        

table        confidence intervals error rates     cgrendel prosodic  tokenized classification models  testing data   training testing done
multiple cue phrase corpus using cross validation  
figure    experiments investigate performance changes classification models allowed treat different cue phrases differently  seen  learning
tokenized feature sets often improves performance learned classification
models  addition  classification models contain new linguistic information regarding particular tokens  e g    so   
      prosodic models

table   presents error learned classification models test sets
multiple cue phrase corpus  tokenized prosodic feature sets  again  error
rates italics indicate performance learned classification model meaningfully
exceeds performance  manual prosodic  model  which consider feature
token  
one way improvement obtained adding feature token seen
comparing performance learned manually derived models  table    six
cgrendel classification models lower  italicized  error rates manual model 
table    five models italicized  thus  adding feature token results
additional learned model   length    outperforming manually derived model 
conversely  table    learned models perform significantly worse manually
derived manual  contrast  table    several non tokenized models perform worse
manual model  i c larger test set  p l  i l  i c  a  a   length
non conjunct test set  
improvement obtained adding feature token seen comparing
performance tokenized  table    non tokenized  table    versions
model other  convenience  cases tokenization yields improvement
highlighted table    table shows error rate tokenized versions
feature sets significantly lower error non tokenized versions  p l  i c 
  

ficue phrase classification using machine learning

model
p l
i l
i c

a 
length

classifiable cue phrases  n     
non tokenized tokenized    
        
        
        
        
        
        
        
        
        
        

classifiable non conjuncts  n     
non tokenized
tokenized    
        
        
        
        
        
        
        
        
        
        
        
        

table    cases adding feature token improves performance prosodic
model 
a  a   length test sets  i l non conjunct test set  note
overlap feature sets table   discussed previous paragraph 
figure   shows several tokenized single feature prosodic classification models  first
cgrendel model figure shows ruleset learned p l   reduces
           error rate p l  length intonational phrase             
trained tested using classifiable non conjuncts  table     note first rule
uses prosodic feature  like rules experiment sets       fact
similar line     manual model   recall length value   equivalent
composition value alone   however  unlike rules previous experiment sets 
next   rules use prosodic feature lexical feature token  unlike
rules previous experiment sets  remaining rules classify cue phrases using
feature token  examination learned rulesets figures     shows
cue phrases often appear last type rule  cue phrases 
example   finally    however    ok   fact always discourse usages multiple
cue phrase corpus  cue phrases  classifying cue phrases using token
corresponds classifying cue phrases using default class  the frequent type
usage multiple cue phrase corpus   recall use non tokenized default class
model table   
second example shows ruleset learned i c   composition intermediate
phrase    first rule corresponds line     manually derived model   
next six rules classify particular cue phrases discourse  independently value i c 
note although model cue phrase  say  classified using token 
previous model sophisticated strategy classifying  say  could found 
third example shows cgrendel ruleset learned a   accent    first
rule corresponds line     manually derived prosodic model  contrast line
     however  cgrendel uses deaccenting predict discourse tokens  say 
 so   token  finally    however    now   ok   discourse assigned  for
accents   deaccented cases  sentential assigned  using default   similarly 
contrast line      complex accent l h  predicts discourse cue phrases
 further   indeed   and  finally    however    now   ok    sentential
otherwise 
    discussed relation figure    i c values cue phrases multiple cue phrase
corpus replace value alone  now  corpus 

  

filitman

manually derived prosodic model  repeated figure    

composition intermediate phrase   alone
elseif composition intermediate phrase    alone
position intermediate phrase   first
accent   deaccented
elseif accent   l 
elseif accent   h 
elseif accent   complex
elseif position intermediate phrase    first

   
   
   
   
   
   
   
   

discourse

discourse

discourse

sentential

sentential

sentential

ruleset learned p l  using cgrendel 

length intonational phrase  
   length intonational phrase        token   although 
   length intonational phrase        token   indeed 
 length intonational phrase        token   say 
    length intonational phrase        token   then 
 length intonational phrase         token   well 
token   finally
token  
token   however
token  
token   ok
token   otherwise
token  
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

ruleset learned i c  using cgrendel 

composition intermediate phrase  
token   finally
token   however
token  
token   ok
token   say
token  

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

ruleset learned a  using cgrendel 

accent   l 
 accent   deaccented     token   say 
 accent   deaccented     token   so 
 accent   l h      token   further 
 accent   l h      token   indeed 
token   finally
token   however
token  
token   ok
discourse

discourse

discourse
discourse

discourse

discourse

discourse

discourse

discourse

default sentential

figure    example cgrendel classification models learned different tokenized 
prosodic feature representations classifiable non conjuncts multiple
cue phrase corpus 

  

ficue phrase classification using machine learning

model
classifiable cue phrases  n      classifiable non conjuncts  n     
c p 
          
        
c s 
          
        
o p 
        
        
o p  
        
        
o s 
        
        
o s  
          
        
pos 
          
        
text 
        
        
adjacency 
          
        
orthography 
        
        
preceding 
        
        
succeeding 
        
        
manual textual
        
        

table         confidence intervals error rates     cgrendel textual  tokenized classification models  testing data   training testing done
multiple cue phrase corpus using cross validation  
summarize  new prosodic results experiment set   features relating
length  composition  accent  useful  in isolation  predicting classification cue phrases  fact quite useful predicting class individual cue
phrases subsets cue phrases   recall result experiment sets    
without token  prosodic feature position intonational phrase useful
isolation  
      textual models

table    presents error learned classification models test sets
multiple cue phrase corpus  tokenized textual feature sets  experiment set    table     none cgrendel classification models lower  italicized 
error rates manual model  however  adding feature token improve
performance many learned rulesets  following models  unlike
non tokenized counterparts  longer outperformed manual model  o s 
succeeding  larger test set  c p   c s   o s   o s    pos   adjacency  
succeeding  non conjunct test set 
improvement obtained adding feature token seen comparing
performance tokenized  table     non tokenized  table    versions
model other  shown table     table shows error rates
tokenized versions feature sets significantly lower error nontokenized versions  c p  c s  pos  adjacency test sets  o p  o s 
o s   text  succeeding non conjunct test set  note overlap feature
sets table    discussed previous paragraph 
figure   shows several tokenized single textual feature classification models  first
cgrendel model shows ruleset learned c p   preceding cue phrase   
reduces            error rate c p            trained tested using
classifiable non conjuncts  table      ruleset correlates preceding cue phrases
discourse usages  indeed   omitted transcriptions  further    now    so 
  

filitman

manually derived textual model  repeated figure    

preceding orthography   true
elseif preceding orthography   false

discourse
sentential

ruleset learned c p  using cgrendel 

 preceding cue phrase   true     token   indeed 
 preceding cue phrase   na     token   further 
 preceding cue phrase   na     token   now 
 preceding cue phrase   na     token   so 
token   although
token   finally
token   however
token   ok
token   say
token   similarly

discourse
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

discourse

ruleset learned o p  using cgrendel 

preceding orthography   false
 preceding orthography   comma     token   then 
sentential

default discourse

sentential

ruleset learned o s  using cgrendel 

succeeding orthography   comma
 succeeding orthography   false     token   so 
succeeding orthography   na
token   although
token   finally
token  
token   ok
token   say
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

ruleset learned pos  using cgrendel 

 part of speech   adverb     token   finally 
 part of speech   singular proper noun     token   further 
 part of speech   adverb     token   however 
 part of speech   adverb     token   indeed 
 part of speech   subordinating conjunction     token   so 
token   although
token  
token   say
token   ok
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

figure    example cgrendel classification models learned different tokenized  textual
feature representations classifiable non conjuncts multiple cue phrase
corpus 

  

ficue phrase classification using machine learning

model
c p
c s
o p
o s
o s 
pos
text
adjacency
succeeding

classifiable cue phrases  n     
non tokenized tokenized    
        
        
        
        
        
        
        
        
 

classifiable non conjuncts  n     
non tokenized
tokenized    
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        

table     cases adding feature token improves performance textual
model 
discourse usages  classifications rest cue phrases predicted using
feature token 
second example shows cgrendel ruleset learned o p   preceding orthography    ruleset correlates preceding orthography sentential usages cue
phrases  as manually derived model learned models experiment
set     unlike models  however  cue phrase  then  classified sentential 
even preceded orthography  namely  comma  
third example shows cgrendel ruleset learned o s   succeeding orthography   ruleset correlates presence succeeding commas discourse usages
cue phrases  except cue phrase  so   classified discourse usage without
succeeding orthography  model correlates cue phrases omitted
transcript discourse usages  classifications rest cue phrases
predicted using feature token 
last example shows cgrendel ruleset learned pos   part of speech   
ruleset classifies certain cue phrases discourse usages depending part ofspeech token  well independently part of speech 
finally  figure    shows classification model learned text   largest tokenized textual feature set  note three four features used tokenized  single
textual feature models figure   incorporated tokenized  multiple textual
feature model 
summarize  new textual results experiment set   features based adjacent cue phrases  succeeding orthography  part of speech  useful  in isolation 
predicting classification cue phrases  fact quite useful conjunction
feature token   recall result experiment set   without token 
textual features preceding orthography preceding orthography  useful
isolation  
      prosodic textual models

table    presents error rates classification models learned cgrendel
data represented using speech text   complete set prosodic textual
  

filitman

ruleset learned text  using cgrendel 

preceding orthography   false
 preceding orthography   comma     token   although 
 preceding orthography   comma     token   no 
 preceding orthography   comma     token   then 
 succeeding orthography   false     preceding cue phrase   na     token   similarly 
token   actually
token   first
token   since
token   yes
sentential

sentential

sentential

sentential

sentential

sentential

sentential

sentential

sentential

default discourse

figure     cgrendel classification model learned tokenized  multiple textual feature
representation classifiable non conjuncts multiple cue phrase corpus 
model
classifiable cue phrases  n      classifiable non conjuncts  n     
speech text 
        
        
manual prosodic
        
        
manual textual
        
        

table         confidence intervals error rates     cgrendel
prosodic textual  tokenized classification models  testing data   training
testing done multiple cue phrase corpus using cross validation  
features  experiment set    performance speech text  better
performance either best learned  tokenized  prosodic textual models  tables  
    respectively  
comparison tables      shows feature set speech text  tokenization improve performance  contrast prosodic textual feature
sets  tokenization improves performance many learned models  namely
shown tables       

    experiment set    adding classification ambiguous
practice  cue phrase classification model classify cue phrases
recording text   classifiable   experiments fourth set
replicate experiments experiment sets          exception     cue
phrases multiple cue phrase corpus used  means cue phrases
classified discourse  sentential  well unknown  defined table     experiment
set   investigates whether machine learning explicitly recognize new class unknown 
recall studies hirschberg litman attempt predict class
unknown  occur  now  training corpus  thus experiment set   
class unknown similarly learned training data  however  unknown
examples added testing data experiment set    obviously performance
degrade  models must incorrectly classify unknown example either discourse
  

ficue phrase classification using machine learning

sentential  example  tested full corpus     example cue phrases 
    confidence intervals error rates p p intonational            
recall tested subset corpus corresponding     classifiable cue
phrases  error             table    
unfortunately  results rerunning experiment sets     show promising
results classifying cue phrases unknown  despite presence    examples
unknown  learned models still classify unknown cue phrases discourse
sentential  example  cgrendel used learning    possible    nontokenized models    phrasing speech text  contain rules predict class unknown 
furthermore  models contains one rule unknown 
rules applies   possible     examples  similarly  four possible   
tokenized models  length   phrasing   prosody   speech text   contain least one rule
class unknown  compared training testing using classifiable
cue phrases corpus  error rate full corpus typically  but always 
significantly higher  best performing model experiment set   speech text  
           error rate      confidence interval  
sum  experiment set   addressed problem previously unexplored
literature   ability develop classification models predict discourse
sentential usages cue phrases  usages human judges find dicult classify 
unfortunately  results experiments suggest learning classify cue
phrases unknown dicult problem  perhaps training data  recall
   examples unknown  additional features better results could
obtained 

    discussion
experimental results suggest machine learning useful tool automating
generation classification models improving upon manually derived results 
experiment sets     performance many learned classification models
comparable performance manually derived models  addition  tested
classifiable cue phrases  several learned prosodic classification models  as well
learned prosodic textual model  outperform hirschberg litman s manually derived
prosodic model  experiment set   shows learning tokenized feature sets even
improves performance  especially non conjunct test set  tokenized
non tokenized learned models perform least well manually derived models 
many tokenized learned models outperform non tokenized counterparts 
textual classification models outperform better prosodic classification models  advantage textual feature values obtained directly
transcript  determining values prosodic features requires manual analysis   see  however  section   discussion feasibility automating prosodic
analysis  addition  transcript may always available   hand  almost
high performing textual models dependent orthography  manual tran    recall experiment sets     constructed    prosodic models     textual models   
prosodic textual model 

  

filitman

scriptions prosodic features shown reliable across coders  pitrelli et al  
       corresponding results reliability orthography 
examination best performing learned models shows often comparable content relevant portions manually derived models  examination
models provides new contributions cue phrase literature  example 
experiment sets     demonstrate utility classifying cue phrases based
single prosodic feature   phrasal position    experiment set   demonstrates utility
prosodic feature length textual feature preceding cue phrase classifying
cue phrases   conjunction prosodic textual features  finally  results
experiment set   demonstrate even though many features useful
classifying cue phrases  may nonetheless informative tokenized
form  true prosodic features based phrasal length  phrasal composition 
accent  textual features based adjacent cue phrases  succeeding position 
part of speech   

   utility
results machine learning experiments quite promising  compared
manually derived classification models already literature  learned classification
models often perform comparable higher accuracy  thus  machine learning
appears effective technique automating generation classification models 
however  given experiments reported still rely manually created training
data  discussion practical utility results order 
even given manually created training data  results established hirschberg
litman          obtained using even less automation experiments paper
  already practical import  particular  manually derived cue phrase
classification models used improve naturalness synthetic speech text tospeech system  hirschberg         using text based model  text to speech system
classifies cue phrase text synthesized either discourse sentential
usage  using prosodic model  system conveys usage synthesizing
cue phrase appropriate type intonation  speech synthesis could
improved  and output made varied  using one higher performing
learned prosodic models presented paper 
results paper could directly applied area text generation 
example  moser moore        concerned implementation cue selection placement strategies natural language generation systems  systems could
enhanced using text based models cue phrase classification  particularly
    empirical studies performed holte        show many datasets  accuracy
single feature rules decision trees often competitive accuracy complex learned
models 
    contrast  prosodic features phrasal composition accent previously known useful
conjunction phrasal position  hirschberg   litman         part ofspeech known useful conjunction orthography  hirschberg   litman        
length  adjacent cue phrases  succeeding position used either manually derived
models  hirschberg   litman         although length adjacent cue phrases shown useful
  conjunction prosodic textual features   experiment set    

  

ficue phrase classification using machine learning

tokenized models  additionally specify preceding succeeding orthography  part ofspeech  adjacent cue phrases appropriate discourse usages 
finally  results paper could fully automated  could used
natural language understanding systems  enhancing ability recognize discourse
structure  results obtained litman passonneau        passonneau
litman  in press  suggest algorithms use cue phrases  in conjunction
features  predict discourse structure outperform algorithms take cue phrases
account  particular  litman passonneau develop several algorithms explore
features cue phrases  prosody referential noun phrases best combined
predict discourse structure  quantitative evaluations results show best
performing algorithms incorporate use discourse usages cue phrases  where cue
phrases classified discourse using phrasal position   discussed section   
discourse structure useful performing tasks anaphora resolution plan
recognition  recent work shown discourse structure recognized 
used improve retrieval text  hearst        speech  sti eman        
although prosodic features manually labeled hirschberg litman 
recent results suggesting least aspects prosody automatically
labeled directly speech  example  wightman ostendorf        develop
algorithm able automatically recognize prosodic phrasing        accuracy
 measured comparing automatically derived labels hand marked labels   accuracy slightly less human human accuracy  recall experimental results
paper show models learned single feature position intonational
phrase   could automatically computed given automatic prosodic phrasing algorithm   perform least well learned prosodic model  similarly 
accenting versus deaccenting automatically labeled     accuracy  wightman
  ostendorf         sophisticated labeling scheme distinguishes
four types accent classes  and somewhat similar prosodic feature accent  used
paper  labeled     accuracy  ostendorf   ross  press   recall
experiment set   tokenized models learned using accent  classify cue phrases
good results 
although textual features automatically extracted transcript  transcript manually created  many natural language understanding systems
deal speech all  thus begin textual representations  spoken language systems transcription process typically automated using speech recognition
system  although introduces sources error  

   related work
paper compared results obtained using machine learning previously
existing manually obtained results  used machine learning tool developing theories given new linguistic data  as models resulting experiment set   
new feature token considered   siegel        similarly uses machine learning
 in particular  genetic learning algorithm  classify cue phrases previously unstudied set textual features  feature corresponding token  well textual features
containing lexical orthographic item immediately left   positions
  

filitman

right example  siegel s input consists one judge s non ambiguous examples
taken data used hirschberg litman        well additional examples 
output form decision trees  siegel reports     estimated error rate 
half corpus used training half testing  siegel mckeown       
propose method developing linguistically viable rulesets  based partitioning
training data produced induction 
machine learning used several areas discourse analysis  example  learning used develop rules structuring discourse multi utterance
segments  grosz hirschberg        use classification regression tree system
cart  brieman et al         construct decision trees classifying aspects discourse
structure intonational feature values  litman passonneau        passonneau
litman  in press  use system c    construct decision trees classifying utterances discourse segment boundaries  using features relating prosody  referential noun
phrases  cue phrases  addition  c    used develop anaphora resolution
algorithms  training corpora tagged appropriate discourse information  aone  
bennett         similarly  mccarthy lehnert        use c    learn decision trees
classify pairs phrases coreferent not  soderland lehnert        use
machine learning program id   a predecessor c     support corpus driven knowledge
acquisition information extraction  machine learning often results algorithms
outperform manually derived alternatives  litman   passonneau        passonneau   litman  press  aone   bennett        mccarthy   lehnert         although statistical
inference always used evaluate significance performance differences 
finally  machine learning used great success many areas
natural language processing  discussed above  work researchers discourse
analysis concentrated direct application existing symbolic learning approaches
 e g   c      comparison learning manual methods  researchers
areas natural language processing addressed issues 
addition applied much wider variety learning approaches  concerned
development learning methods particularly designed language processing 
recent survey learning natural language  wermter  riloff    scheler        illustrates
type learning approaches used modified  in particular 
symbolic  connectionist  statistical  hybrid approaches   well scope
problems proved amenable use learning techniques  e g   grammatical
inference  syntactic disambiguation  word sense disambiguation  

   conclusion
paper demonstrated utility machine learning techniques cue phrase
classification  machine learning supports automatic generation linguistically viable
classification models  compared manually derived models already literature 
many learned models contain new linguistic insights perform least
high  if higher  accuracy  addition  ability automatically construct classification models makes easier comparatively analyze utility alternative feature
representations data  finally  ease retraining makes learning approach
scalable extensible manual methods 
  

ficue phrase classification using machine learning

first set experiments presented used machine learning programs

cgrendel  cohen              c     quinlan        induce classification models

preclassified cue phrases features used training data
hirschberg litman         results evaluated testing data
methodology used hirschberg litman         second group experiments
used method cross validation train test testing data used
hirschberg litman         third set experiments induced classification models
using new feature token  fourth set experiments induced classification models
using new classification unknown 
experimental results indicate several learned classification models  including
extremely simple one feature models  significantly lower error rates models
developed hirschberg litman         one possible explanation handbuilt classification models derived using small training sets  new data became
available  data used testing updating original models  contrast  machine learning conjunction cross validation  experiment set    supported
building classification models using much larger amount data training 
even learned models derived using small training set  experiment
set     results showed learning approach helped guard overfitting
training data 
prosodic classification model developed hirschberg litman demonstrated utility combining phrasal position phrasal composition accent 
best performing prosodic models experiment sets     demonstrated phrasal
position fact even useful predicting cue phrases used itself 
high performing classification models experiment set   demonstrated utility classifying cue phrases based prosodic feature length textual feature
preceding cue phrase  combination features 
machine learning approach made easy retrain new training examples became available  experiment set     machine learning made easy retrain
new features become available  particular  value feature token
added representations experiment set    trivial relearn
models  experiment set     allowing learning programs treat cue phrases individually improved accuracy learned classification models  added
body linguistic knowledge regarding cue phrases  experiment set   demonstrated
useful classifying cue phrases  prosodic features based
phrasal length  phrasal composition  accent  textual features based adjacent
cue phrases  succeeding position  part of speech  fact useful used
conjunction feature token 
final advantage machine learning approach ease inducing classification models many different sets features supports exploration comparative
utility different knowledge sources  especially useful understanding tradeoffs accuracy model set features considered 
example  might worth effort code feature automatically obtainable
expensive automatically obtain adding feature results significant
improvement performance 
  

filitman

sum  results paper suggest machine learning useful tool
cue phrase classification  amount data precludes effective human analysis 
exibility afforded easy retraining needed  e g   due additional training
examples  new features  new classifications   and or analysis goal gain better
understanding different aspects data 
several areas future work remain  first  still room performance improvement  error rates best performing learned models  even though outperform
manually derived models  perform error rates teens  note
features coded discussed hirschberg litman        considered
paper  may possible lower error rates considering new types
prosodic textual features  e g   contextual textual features  siegel        
features proposed connection general topic discourse
structure   and or using different kinds learning methods  second  experiment set
   and previous literature  show yet  models predicting
cue phrase usage classified unknown  rather discourse sentential 
again  may possible improve performance existing learned models
considering new features and or learning methods  perhaps performance could improved providing training data  finally  currently open question whether
textual models developed here  based transcripts speech  applicable
written texts  textual models thus need developed using written texts training
data  machine learning continue useful tool helping address
issues 

appendix a  c    results experiment sets    
tables           present c    error rates experiment sets      c   
results experiment set   shown  non tokenized  columns  comparison
tables      shows except larger test set  c    prosodic error rates
fall within cgrendel confidence intervals  similar comparison tables     
shows except o p larger test set  c    textual error rates fall within
cgrendel confidence intervals  finally  comparison tables      shows
c    error rate speech text falls within cgrendel confidence interval  fact
comparable cgrendel c    results generally obtained suggests ability
automate well improve upon manual performance due specifics
either learning program 
c    results experiment set   shown  tokenized  columns tables            comparison tables          shows error rates c   
cgrendel similar experiment set    however  error rates reported
tables use default c    cgrendel options running learning programs  comparable performance two learning programs fact generally
achieved overriding one default c    options  detailed quinlan        
default c    approach   creates separate subtree possible feature value
  might appropriate many values feature  situation characterizes feature token  c    default option changed allow feature values
grouped one branch decision tree  problematic c    error rates
  

ficue phrase classification using machine learning

model
p l
p p
i l
i p
i c

a 
prosody
hl  features
phrasing
length
position
intonational
intermediate

classifiable cue phrases  n     
non tokenized tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

classifiable non conjuncts  n     
non tokenized
tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table     error rates     c    prosodic classification models  testing data   training
testing done multiple cue phrase corpus using cross validation  
model
c p
c s
o p
o p 
o s
o s 
pos
text
adjacency
orthography
preceding
succeeding

classifiable cue phrases  n     
non tokenized tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

classifiable non conjuncts  n     
non tokenized
tokenized    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

table     error rates     c    textual classification models  testing data   training
testing done multiple cue phrase corpus using cross validation  
indeed improve  example  a  error rate classifiable non conjuncts changes
       table          within            cgrendel confidence
interval  table    

acknowledgements
would thank william cohen jason catlett helpful comments regarding
use cgrendel c     sandra carberry  rebecca passonneau  three
anonymous jair reviewers helpful comments paper  would
  

filitman

model
speech text

classifiable cue phrases  n     
non tokenized tokenized    
    
    

classifiable non conjuncts  n     
non tokenized
tokenized    
    
    

table     error rates     c    prosodic textual classification model  testing data 
 training testing done multiple cue phrase corpus using crossvalidation  
thank william cohen  ido dagan  julia hirschberg  eric siegel comments
preliminary version paper  litman        

references

altenberg  b          prosodic patterns spoken english  studies correlation
prosody grammar text to speech conversion  vol     lund studies
english  lund university press  lund 
aone  c     bennett  s  w          evaluating automated manual acquisition
anaphora resolution strategies  proceedings thirty third annual meeting
association computational linguistics  acl  
brieman  l   friedman  j   olshen  r     stone  c          classification regression
trees  monterey  ca  wadsworth brooks 
church  k  w          stochastic parts program noun phrase parser unrestricted
text  proceedings second conference applied natural language processing 
cohen  r          computational theory function clue words argument understanding  proceedings tenth international conference computational
linguistics  coling  
cohen  w  w          compiling knowledge explicit bias  proceedings
ninth international conference machine learning 
cohen  w  w          ecient pruning methods separate and conquer rule learning
systems  proceedings thirteenth international joint conference artificial
intelligence  ijcai  
freedman  d   pisani  r     purves  r          statistics  w  w  norton company 
grosz  b     hirschberg  j          intonational characteristics discourse structure  proceedings international conference spoken language processing
 icslp  
grosz  b  j     sidner  c  l          attention  intentions  structure discourse 
computational linguistics                  
  

ficue phrase classification using machine learning

halliday  m  a  k     hassan  r          cohesion english  longman 
hearst  m  a          multi paragraph segmentation expository text  proceedings
thirty second annual meeting association computational linguistics
 acl  
hindle  d  m          acquiring disambiguation rules text  proceedings
twenty seventh annual meeting association computational linguistics
 acl  
hirschberg  j          accent discourse context  assigning pitch accent synthetic
speech  proceedings eighth national conference artificial intelligence
 aaai  
hirschberg  j     litman  d          let s talk  now   identifying cue phrases
intonationally  proceedings twenty fifth annual meeting association
computational linguistics  acl  
hirschberg  j     litman  d          empirical studies disambiguation cue phrases 
computational linguistics                  
holte  r  c          simple classification rules perform well commonly used
datasets  machine learning                
litman  d     hirschberg  j          disambiguating cue phrases text speech 
proceedings thirteenth international conference computational linguistics
 coling  
litman  d  j          classifying cue phrases text speech using machine learning 
proceedings twelfth national conference artificial intelligence  aaai  
litman  d  j     allen  j  f          plan recognition model subdialogues conversation  cognitive science              
litman  d  j     passonneau  r  j          combining multiple knowledge sources
discourse segmentation  proceedings thirty third annual meeting
association computational linguistics  acl  
mccarthy  j  f     lehnert  w  g          using decision trees coreference resolution 
proceedings fourteenth international joint conference artificial intelligence
 ijcai  
moser  m     moore  j  d          investigating cue selection placement tutorial
discourse  proceedings thirty third annual meeting association
computational linguistics  acl  
ostendorf  m     ross  k   in press   multi level model recognition intonation labels 
y  sagisaka  n  c     higuchi  n   eds    computing prosody  springer verlag 
passonneau  r  j     litman  d  j   in press   discourse segmentation human
automated means  computational linguistics     
  

filitman

pierrehumbert  j  b          phonology phonetics english intonation  ph d 
thesis  massachusetts institute technology  distributed indiana university
linguistics club 
pitrelli  j   beckman  m     hirschberg  j          evaluation prosodic transcription
labeling reliability tobi framework  proceedings international conference spoken language processing  icslp  
quinlan  j  r          c      programs machine learning  san mateo  ca  morgan
kaufmann 
reichman  r          getting computers talk me  discourse context 
focus  semantics  cambridge  ma  mit press 
siegel  e  v          competitively evolving decision trees fixed training cases
natural language processing  k  e  kinnear  j   ed    advances genetic
programming  cambridge  ma  mit press 
siegel  e  v     mckeown  k  r          emergent linguistic rules automatic
grouping training examples  disambiguating clue words decision trees 
proceedings twelfth national conference artificial intelligence  aaai  
soderland  s     lehnert  w          corpus driven knowledge acquisition discourse
analysis  proceedings twelfth national conference artificial intelligence
 aaai  
sti eman  l  j          discourse analysis approach structured speech  working
notes aaai spring symposium series  empirical methods discourse interpretation generation 
weiss  s  m     kulikowski  c          computer systems learn  classification
prediction methods statistics  neural nets  machine learning  expert
systems  san mateo  ca  morgan kaufmann 
wermter  s   riloff  e     scheler  g          connectionist  statistical symbolic approaches learning natural language processing  berlin  germany  springerverlag 
wightman  c  w     ostendorf  m          automatic labeling prosodic patterns  ieee
transactions speech audio processing                 
zuckerman  i     pearl  j          comprehension driven generation meta technical
utterances math tutoring  proceedings fifth national conference
artificial intelligence  aaai  

  


