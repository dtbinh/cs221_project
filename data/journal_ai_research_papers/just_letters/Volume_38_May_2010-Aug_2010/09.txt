journal of artificial intelligence research                  

submitted       published     

approximate model based diagnosis
using greedy stochastic search
alexander feldman

a b feldman tudelft nl

delft university of technology
mekelweg         cd  delft  the netherlands

gregory provan

g provan cs ucc ie

university college cork
college road  cork  ireland

arjan van gemund

a j c vangemund tudelft nl

delft university of technology
mekelweg         cd  delft  the netherlands

abstract
we propose a stochastic fault diagnosis algorithm  called safari  which trades off
guarantees of computing minimal diagnoses for computational efficiency  we empirically
demonstrate  using the   xxx and iscas   suites of benchmark combinatorial circuits 
that safari achieves several orders of magnitude speedup over two well known deterministic algorithms  cda and ha   for multiple fault diagnoses  further  safari can compute a
range of multiple fault diagnoses that cda and ha cannot  we also prove that safari
is optimal for a range of propositional fault models  such as the widely used weak fault
models  models with ignorance of abnormal behavior   we discuss the optimality of safari in a class of strong fault circuit models with stuck at failure modes  by modeling the
algorithm itself as a markov chain  we provide exact bounds on the minimality of the diagnosis computed  safari also displays strong anytime behavior  and will return a diagnosis
after any non trivial inference time 

   introduction
model based diagnosis  mbd  is an area of artificial intelligence that uses a system model 
together with observations about system behavior  to isolate sets of faulty components  diagnoses  that explain the observed behavior according to some minimality criterion  the
standard mbd formalization  reiter        frames a diagnostic problem in terms of a set
of logical clauses that include mode variables describing the nominal and fault status of
system components  from this the diagnostic status of the system can be computed given
an observation of the systems sensors  mbd provides a sound and complete approach to
enumerating multiple fault diagnoses  and exact algorithms can guarantee finding a diagnosis optimal with respect to the number of faulty components  probabilistic likelihood 
etc 
the biggest challenge  and impediment to industrial deployment  is the computational
complexity of the mbd problem  the mbd problem of determining if there exists a diagnosis with at most k faults is np hard for the arbitrary propositional models we consider in
this article  bylander  allemang  tanner    josephson        friedrich  gottlob    nejdl 
       computing the set of all diagnoses is harder still  since there are possibly exponenc
    
ai access foundation  all rights reserved 

fifeldman  provan    van gemund

tially many such diagnoses  since almost all proposed mbd algorithms have been complete
and exact  with some authors proposing possible trade offs between completeness and faster
consistency checking by employing methods such as bcp  williams   ragno         the
complexity problem still remains a major challenge to mbd 
to overcome this complexity problem  we propose a novel approximation approach for
multiple fault diagnosis  based on a stochastic algorithm  safari  stochastic fault diagnosis algorithm  sacrifices guarantees of optimality  but for diagnostic systems in which
faults are described in terms of an arbitrary deviation from nominal behavior  safari can
compute diagnoses several orders of magnitude faster than competing algorithms 
our contributions are as follows      this paper introduces an approximation algorithm
for computing diagnoses within an mbd framework  based on a greedy stochastic algorithm 
    we show that we can compute minimal cardinality diagnoses for weak fault models in
polynomial time  calling an incomplete sat solver that implements boolean constraint
propagation   bcp  only   and that more general frameworks  such as a sub class of strong
fault models  are also amenable to this class of algorithm      we model safari search as a
markov chain to show the performance and optimality trade offs that the algorithm makes 
    we apply this algorithm to a suite of benchmark combinatorial circuits  demonstrating order of magnitude speedup over two state of the art deterministic algorithms  cda
and ha   for multiple fault diagnoses      we compare the performance of safari against
a range of max sat algorithms for our benchmark problems  our results indicate that 
whereas the search complexity for the deterministic algorithms tested increases exponentially with fault cardinality  the search complexity for this stochastic algorithm appears
to be independent of fault cardinality  safari is of great practical significance  as it can
compute a large fraction of minimal cardinality diagnoses for discrete systems too large or
complex to be diagnosed by existing deterministic algorithms 

   technical background
our discussion continues by formalizing some mbd notions  this paper uses the traditional
diagnostic definitions  de kleer   williams         except that we use propositional logic
terms  conjunctions of literals  instead of sets of failing components 
central to mbd  a model of an artifact is represented as a propositional formula over
some set of variables  discerning two subsets of these variables as assumable and observable  
variables gives us a diagnostic system 
definition    diagnostic system   a diagnostic system ds is defined as the triple ds  
hsd  comps  obsi  where sd is a propositional theory over a set of variables v   comps 
v   obs  v   comps is the set of assumables  and obs is the set of observables 
throughout this paper we will assume that obs  comps    and sd      not all
propositional theories used as system descriptions are of interest to mbd  diagnostic systems can be characterized by a restricted set of models  the restriction making the problem
   with formulae in conjunctive normal form  cnf   bcp is implemented through the unit resolution
rule 
   in the mbd literature the assumable variables are also referred to as component  failure mode  or
health variables  observable variables are also called measurable  or control variables 

   

fiapproximate model based diagnosis using greedy stochastic search

of computing diagnosis amenable to algorithms like the one presented in this paper  we
consider two main classes of models 
definition    weak fault model   a diagnostic system ds   hsd  comps  obsi belongs
to the class wfm iff for comps    h    h            hn    sd is equivalent to  h   f     h  
f             hn  fn   and comps  v      where v  is the set of all variables appearing
in the propositional formulae f    f            fn  
note the conventional selection of the sign of the health variables h    h          hn   alternatively  negative literals  e g   f    f            fn can be used to express faults  in which case a
weak fault model is in the form  f   f             fn  fn    other authors use ab for
abnormal or ok for healthy 
weak fault models are sometimes referred to as models with ignorance of abnormal
behavior  de kleer  mackworth    reiter         or implicit fault systems  alternatively 
a model may specify faulty behavior for its components  in the following definition  with
the aim of simplifying the formalism throughout this paper  we adopt a slightly restrictive
representation of faults  allowing only a single fault mode per assumable variable  this can
be easily generalized by introducing multi valued logic or suitable encodings  hoos        
definition    strong fault model   a diagnostic system ds   hsd  comps  obsi belongs
to the class sfm iff sd is equivalent to  h   f        h   f               hn  fn     
 hn  fn     such that    i  j  n  k           hi    comps  f j k  is a propositional
formula  and none of hi appears in fj k  
membership testing for the wfm and sfm classes can be performed efficiently in many
cases  for example  when a model is represented explicitly as in def    or def    
    a running example
we will use the boolean circuit shown in fig    as a running example for illustrating all
the notions and algorithms in this paper  the subtractor  shown there  consists of seven
components  an inverter  two or gates  two xor gates  and two and gates  the expression
h   o  i  models the normative  healthy  behavior of an inverter  where the variables i 
o  and h represent input  output and health respectively  similarly  an and gate is modeled
as h   o   i   i     and an or gate by h   o   i   i      finally  an xor gate is specified
as h   o    i   i     
the above propositional formulae are copied for each gate in fig    and their variables
renamed in such a way as to properly connect the circuit and disambiguate the assumables 
thus obtaining a propositional formula for the boolean subtractor  given by 
sdw    h    i    y  p      h    d    x  i      h    j  y  p   
  h    m  l  j     h    b  m  k     h    x  l   
  h    k  y  p  

   

a strong fault model for the boolean circuit shown in fig    is constructed by assigning
fault modes to the different gate types  we will assume that  when malfunctioning  the
output of an xor gate has the value of one of its inputs  an or gate can be stuck at one 
   

fifeldman  provan    van gemund

x
y
p

h 

h 

i

j

h 

d

h 

b

h 

l

h 

h 

m

k

figure    a subtractor circuit
an and gate can be stuck at zero  and an inverter behaves like a buffer  this gives us the
following strong fault model formula for the boolean subtractor circuit 
sds   sdw   h    i  y     h    d  x     h   j  
  h   m    h   b    h    x  l     h   k 

   

for both models  sds and sdw    the set of assumable variables is comps    h    h            h   
and the set of observable variables is obs    x  y  p  d  b  
    diagnosis and minimal diagnosis
the traditional query in mbd computes terms of assumable variables which are explanations for the system description and an observation 
definition    health assignment   given a diagnostic system ds   hsd  comps  obsi 
an assignment  to all variables in comps is defined as a health assignment 
a health assignment  is a conjunction of propositional literals  in some cases it is convenient to use the set of negative or positive literals in   these two sets are denoted as
lit     and lit       respectively 
in our example  the all nominal assignment is     h   h          h    the health
assignment     h   h   h   h   h   h   h  means that the two and gates from fig   
are malfunctioning  what follows is a formal definition of consistency based diagnosis 
definition    diagnosis   given a diagnostic system ds   hsd  comps  obsi  an observation   which is an instantiation of some variables in obs  and a health assignment   
is a diagnosis iff sd         
traditionally  other authors  de kleer   williams        arrive at minimal diagnosis by computing a minimal hitting set of the minimal conflicts  broadly  minimal health assignments
incompatible with the system description and the observation   while this paper makes no
use of conflicts  hence the equivalent  direct definition above 
there is a total of    possible diagnoses given sdw and an observation     x  y  p 
b  d  example diagnoses are     h   h          h  and     h   h   h          h   
trivially  given a weak fault model  the all faulty health assignment  in our example
   

fiapproximate model based diagnosis using greedy stochastic search

a   h          h    is a diagnosis for any instantiation of the observable variables in obs
 cf  def     
in the analysis of our algorithm we need the opposite notion of diagnosis  i e   health
assignments inconsistent with a model and an observation  in the mbd literature these
assignments are usually called conflicts  conflicts  however  do not necessarily instantiate
all variables in comps  as in this paper we always use full health instantiations  the use
of the term conflict is avoided to prevent confusion 
in the mbd literature  a range of types of preferred diagnosis has been proposed 
this turns the mbd problem into an optimization problem  in the following definition we
consider the common subset ordering 
definition    minimal diagnosis   a diagnosis   is defined as minimal  if no diagnosis
  exists such that lit        lit       
consider the weak fault model sdw of the circuit shown in fig    and an observation
    x  y  p  b  d  in this example  two of the minimal diagnoses are    
h   h   h   h   h   h   h  and     h   h          h   h   h    the diagnosis
    h   h   h   h   h   h   h  is non minimal as the negative literals in   form
a subset of the negative literals in    
note that the set of all minimal diagnoses characterizes all diagnoses for a weak fault
model  but that does not hold in general for strong fault models  de kleer et al         
in the latter case  faulty components may exonerate each other  resulting in a health
assignment containing a proper superset of the negative literals of another diagnosis not to
be a diagnosis  in our example  given sds and     x  y  p  b  d  it follows that
    h   h   h   h          h  is a diagnosis  but     h   h   h   h          h 
is not a diagnosis  despite the fact that the negative literals in   form a superset of the
negative literals in    
definition    number of minimal diagnoses   let the set   sd    contain all minimal diagnoses of a system description sd and an observation   the number of minimal
diagnoses  denoted as    sd      is defined as the cardinality of   sd    
continuing our running example     sdw           and    sds            the number
of non minimal diagnoses of sdw    is    
definition    cardinality of a diagnosis   the cardinality of a diagnosis  denoted as    
is defined as the number of negative literals in  
diagnosis cardinality gives us another partial ordering  a diagnosis is defined as minimal
cardinality iff it minimizes the number of negative literals 
definition    minimal cardinality diagnosis   a diagnosis   is defined as minimalcardinality if no diagnosis   exists such that             
the cardinality of a minimal cardinality diagnosis computed from a system description sd
and an observation  is denoted as mincard  sd     for our example model sdw and an
observation     x  y  p  b  d  it follows that mincard  sdw           note that
in this case all minimal diagnoses are also minimal cardinality diagnoses 
   

fifeldman  provan    van gemund

a minimal cardinality diagnosis is a minimal diagnosis  but the opposite need not hold 
in the general case  there are minimal diagnoses which are not minimal cardinality diagnoses  consider the example sdw and   given earlier in this section  and the two resulting
minimal diagnoses   and     from these two  only   is a minimal cardinality diagnosis 
definition     number of minimal cardinality diagnoses   let the set   sd    contain all minimal cardinality diagnoses of a system description sd and an observation  
the number of minimal cardinality diagnoses  denoted as    sd      is defined as the
cardinality of   sd    
computing the number of minimal cardinality diagnoses for the running example results in
   sdw               sds            and    sdw           
    converting propositional formulae to clausal form
our approach is related to satisfiability  and safari uses a sat solver  sat solvers commonly accept their input in conjunctive normal form  cnf   although there exist sat
solvers that work directly on propositional formulae  thiffault  bacchus    walsh        
converting a propositional formula to cnf can be done with  tseitin        or without
 forbus   de kleer        the introduction of intermediate variables  in both cases important structural information is lost  which may lead to performance degradation when
checking if a formula is consistent or when computing a solution 
lemma    a fault model sd   f   f          fn  sd  wfm or sd  sfm  with
n    comps  component variables can be converted to cnf in time o  comps   where
 is the time for converting the largest subformula fi     i  n  to cnf 
proof  sketch   the conversion of sd to cnf can be done by     converting each subformula
fi to cnf and     concatenating the resulting cnfs in the final cnf equivalent of sd 
the complexity of     is o n  while the complexity of     is  in the worst case  o  m      
where m is the largest number of variables in a subformula fi   as a result  the total time
for converting sd is dominated by  and it is linear in  comps  
lemma   is useful in the cases in which each subformula fi is small  this is the case in many
practical situations where sd is composed of small component models  this is also the case
with our experimental benchmark  cf  sec     where the model of a combinational circuit
is the conjunction of fault models of simple logic gates  x bit and gates  typically x      
xor gates  etc    ideally  safari would use a non cnf sat solver  but for practical reasons
we have constrained our reasoning to diagnostic models with concise cnf encodings 
consider  for example  the formula  x   y      x   y          xn  yn    which is
in disjunctive normal form   dnf  and  converted to cnf  has  n clauses  although
similar examples of propositional formulae having exponentially many clauses in their cnf
representations are easy to find  they are artificial and are rarely encountered in mbd 
furthermore  the boolean circuits with which we have tested the performance of safari
do not show exponential blow up when converted to cnf 
   note that all dnf formulae are also propositional formulae 

   

fiapproximate model based diagnosis using greedy stochastic search

    complexity of diagnostic inference
this section discusses the complexity of the problems in which we are interested  namely
the problem of computing a single or the set of all minimal diagnoses  using two minimality
criteria  subset minimality    and cardinality minimality     we assume as input a cnf
formula defined over a variable set v   of which     comps  are assumable  or fault 
variables  table   introduces the notation that we use to define these   types of diagnosis 
table    summary of definitions of types of diagnosis of interest
symbol

diagnoses






 
 
all
all

preference criterion





 subset minimality 
 cardinality minimality 
 subset minimality 
 cardinality minimality 

the complexity of computing the set of all diagnoses is harder than computing a single
diagnosis  since the number of diagnoses is  in the worst case  exponential in the input size
 number of components   this problem is bounded from below by the problem of counting
the number of diagnoses  this problem has been shown to be  co np  complete  hermann
  pichler        
if we restrict our clauses to be horn or definite horn  then we can reduce the complexity
of the problems that we are solving  at the expense of decreased model expressiveness  under
a horn clause restriction  for sd  wfm  determining if a first minimal diagnosis exists
is in p   under the same restriction  for sd  sfm  deciding if a first minimal diagnosis
exists is np hard  friedrich et al          in both cases  sd  wfm  sfm  deciding if a
next diagnosis exists is np hard 
the diagnosis problems of interest in this article are intractable in the worst case  the
complexity of a closely related problem  propositional abduction problems  paps   has
been studied by eiter and gottlob         they show that for a propositional pap  the
problem of determining if a solution exists is p   complete  computing a minimal diagnosis
is a search problem  and hence it is more difficult to pose a decision question for proving
complexity results  consequently  one can just note that computing a diagnosis minimal
with respect to     requires o log  comps   calls to an np oracle  eiter   gottlob 
       asking the oracle at each step if a diagnosis containing at most k faulty components
exists 
results on abduction problems indicate that the task of approximate diagnosis is intractable  roth        has addressed the problems of abductive inference  and of approximating such inference  roth focuses on counting the number of satisfying assignments for
a range of ai problems  including some instances of paps  in addition  roth shows that
approximating the number of satisfying assignments for these problems is intractable 
abdelbar        has studied the complexity of approximating horn abduction problems 
showing that even for a particular horn restriction of the propositional problem of interest 
the approximation problem is intractable  in particular  for an abduction problem with
costs assigned to the assumables  which can be used to model the preference ordering   
   

fifeldman  provan    van gemund

he has examined the complexity of finding the least cost proof  lcp  for the evidence
 obs   where the cost of a proof is taken to be the sum of the costs of all hypotheses that
must be assumed in order to complete the proof  for this problem he has shown that it is
np  hard to approximate an lcp within a fixed ratio r of the cost of an optimal solution 
for any r     
safari approximates the intractable problems denoted in table    we show that for
wfm  safari can efficiently compute a single diagnosis that is minimal under  by using
a satisfiability oracle  for sd  sfm  safari generates a sound but possibly sub optimal
diagnosis  or set of diagnoses   we have referred to papers indicating that it is intractable
to approximate  within a fixed ratio  a minimal diagnosis  in the following  we adopt a
stochastic approach that cannot provide fixed ratio guarantees  however  safari trades off
optimality for efficiency and can compute most diagnoses with high likelihood 

   stochastic mbd algorithm
in this section we discuss an algorithm for computing multiple fault diagnoses using stochastic search 
    a simple example  continued 
consider the boolean subtractor shown in fig     its weak fault model sdw given by     
and the observation   from the preceding section  the four minimal diagnoses associated
to sdw   are      h  h  h  h  h  h  h        h  h  h  h  h  h  h   
    h   h          h   h    and     h   h   h          h   h   
a nave deterministic algorithm would check the consistency of all the   comps  possible health assignments for a diagnostic problem      in the case of our running example 
furthermore  most deterministic algorithms first enumerate health assignments of small
cardinality but with high a priori probability  which renders these algorithms impractical in
situations when the minimal diagnosis is of a higher cardinality  such performance is not
surprising even when using state of the art mbd algorithms which utilize  for example conflict learning  or partial compilation  considering the bad worst case complexity of finding
all minimal diagnoses  cf  sec       
in what follows  we will show a two step diagnostic process that requires fewer consistency checks  the first step involves finding a random non minimal diagnosis as a starting
point  cf  sec      for details on computing random sat solutions with equal likelihood  
the second step attempts to minimize the fault cardinality of this diagnosis by repeated
modification of the diagnosis 
the first step is to find one random  possibly non minimal diagnosis of sdw      such
a diagnosis we can obtain from a classical dpll solver after modifying it in two ways     
not only determine if the instance is satisfiable but also extract the satisfying solution and
    find a random satisfiable solution every time the solver is invoked  both modifications
are trivial  as dpll solvers typically store their current variable assignments and it is easy
to choose a variable and value randomly  according to a uniform distribution  instead of
deterministically when branching  the latter modification may possibly harm a dpll
variable or value selection heuristics  but later in this paper we will see that this is of no
   

fiapproximate model based diagnosis using greedy stochastic search

concern for the type of problems we are considering as diagnostic systems are typically
underconstrained 
in the subtractor example we call the dpll solver with sdw    as an input and we
consider the random solution  and obviously a diagnosis      h   h   h   h   h  
h   h              in the second step of our stochastic algorithm  we will try to minimize
  by repetitively choosing a random negative literal  flipping its value to positive  thus
obtaining a candidate with a smaller number of faults   and calling the dpll solver  if the
new candidate is a diagnosis  we will try to improve further this newly discovered diagnosis 
otherwise we will mark the attempt a failure and choose another negative literal  after
some constant number of failures  two in this example   we will terminate the search and
will store the best diagnosis discovered so far in the process 
after changing the sign of h  in   we discover that the new health assignment is
not consistent with sdw      hence it is not a diagnosis and we discard it  instead 
the algorithm attempts changing h  to h  in     this time successfully obtaining a new
diagnosis     h   h   h   h   h   h   h  of cardinality    next the algorithm
tries to find a diagnosis of even smaller cardinality by randomly choosing h  and h  in
    respectively  and trying to change their sign  but both attempts return an inconsistency 
hence the climb is aborted and   is stored as the current best diagnosis 
repeating the process from another random initial dpll solution  gives us a new diagnosis     h   h   h   h   h   h   h    changing the sign of h    again  leads
to inconsistency  but the next two flips  of h  and h    lead to a double fault diagnosis
    h   h          h   h    the diagnosis   can not be improved any further as it is
minimal  hence the next two attempts to improve   fail and   is stored in the result 
this process is illustrated in fig     the search for   is on the left and for   on the right 
gates which are shown in solid black are suspected as faulty when the health assignment
they participate in is tested for consistency  and inconsistent candidates are crossed out 
let us consider the result  we have found two diagnoses    and     where   is not
a minimal diagnosis  this we have done at the price of    calls to a dpll subroutine 
the suboptimal diagnosis   is of value as its cardinality is near the one of a minimal
diagnosis  hence we have demonstrated a way to find an approximation of all minimal
diagnoses  while drastically reducing the number of consistency checks in comparison to a
deterministic algorithm  sacrificing optimality  next we will formalize our experience into
an algorithm  the behavior of which we will analyze extensively in the section that follows 
diagnosing a strong fault model is known to be strictly more difficult than a weak fault
model  friedrich et al          in many diagnostic instances this problem is alleviated by
the fact that there exist  although without a guarantee  continuities in the diagnostic search
space similar to the one in the weak fault models  let us discuss the process of finding a
minimal diagnosis of the subtractors strong fault model sds and the observation    both
from sec       
the six distinct diagnoses                of sds and   are shown in fig     of these only
  and    are minimal such that                   it is visible in fig    that in all diagnoses
component variables h  and h  are false  while h  and h  are true  healthy   hence  any
satisfying assignment of sds    would contain h   h   h   h    starting from the
maximal cardinality diagnosis      we must flip the variables h    h    and h  in order to
reach the two minimal diagnoses  the key insight is that  as shown in fig     this is always
   

fifeldman  provan    van gemund

figure    an example of a stochastic diagnostic process
h 
  
   
   
h 
  
   
   

h 

h 

h 

h 

h 

h 

























h 

h 

h 

h 

h 

h 

























h 
   
   
   
h 
   
   
   

h 

h 

h 

h 

h 

h 

























h 

h 

h 

h 

h 

h 

























figure    diagnoses of a strong fault model
possible by flipping a single literal at a time from health to faulty and receiving another
consistent assignment  diagnosis  
in what follows we will formalize our experience so far in a stochastic algorithm for
finding minimal diagnoses 
    a greedy stochastic algorithm
algorithm   shows the pseudocode of safari 
   

fiapproximate model based diagnosis using greedy stochastic search

algorithm   safari  a greedy stochastic hill climbing algorithm for approximating the
set of minimal diagnoses
   function safari ds    m  n   returns a trie
inputs  ds   hsd  comps  obsi  diagnostic system
  term  observation
m   integer  climb restart limit
n   integer  number of tries
local variables  sdcnf   cnf
m  n  integers
      terms
r  set of terms  result
  
sdcnf  wfftocnf sd 
  
for n                 n do
  
  randomdiagnosis sdcnf    
 get a random sat solution 
  
m 
  
while m   m do
  
   improvediagnosis  
 flip an unflipped health variable 

  
if sdcnf         then
 consistency check 
  
  
   
m 
   
else
   
mm  
   
end if
   
end while
   
unless issubsumed r    then
   
addtotrie r   
   
removesubsumed r   
   
end unless
   
end for
   
return r
    end function

safari accepts two input parameters  m and n   there are n independent searches
that start from randomly generated starting points  the algorithm tries to improve the
cardinality of the initial diagnoses  while preserving their consistency  by randomly flipping fault literals  the change of a sign of literal is done in one direction only  from faulty
to healthy  each attempt to find a minimal diagnosis terminates after m unsuccessful attempts to improve the current diagnosis stored in   thus  increasing m will lead to a
better exploration of the search space and  possibly  to diagnoses of lower cardinality  while
decreasing it will improve the overall speed of the algorithm 
safari uses a number of utility functions  wfftocnf converts the propositional
formula in sd to cnf  cf  sec       the improvediagnosis subroutine takes a term  as
an argument and changes the sign of a random negative literal in   if there are no negative
literals  the function returns its original argument 
   

fifeldman  provan    van gemund

the implementation of randomdiagnosis uses a modified dpll solver returning a
random sat solution of sd    consider the original dpll algorithm  davis  logemann 
  loveland        without the unit resolution rule  one can show that if  in the event
of branching  the algorithm chooses unassigned variables and their polarity with equal
probability  the dpll algorithm is equally likely to compute any satisfiable solution  if such
exists   note that the order in which variables are assigned does not matter  of course 
the dpll algorithm may end up with a partial assignment  i e   some of the variables are
dont care  this is not a problem because the partial assignment can be extended to
a full satisfiable assignment by randomly choosing the signs of the unassigned variables
from a uniform distribution  taking into consideration the unit resolution rule  does not
change the likelihood of the modified dpll solver finding a particular solution because it
only changes the order in which variables are assigned  a formal proof that this modified
dpll solver computes a sat assignment with equal probability is beyond the scope of this
paper  but the idea is to build a probabilistic model of the progress of the dpll solver  this
probabilistic model is a balanced tree where nodes iterate between branching and performing
unit resolution  assigning values to zero or more unit clauses   as the branching probability
is set to be equal and all leaf nodes  sat solutions  are at equal depth  one can show the
equal likelihood of arriving to any sat solution  as most up to date sat solvers are based
on dpll  creating a randomized dpll solver that computes any satisfiable solution with
equal probability is not difficult  of course  random polarity decisions may effect negatively
branching heuristics  marques silva        but such analysis is also beyond the scope of
this paper 
similar to deterministic methods for mbd  safari uses a sat based procedure for
checking the consistency of sd  to increase the implementation efficiency of safari 
we combine a bcp based ltms engine  mcallester        and a full fledged dpll solver in
two stage consistency checking  experimentation shows that combining ltms and dpll
in such a way allows an order of magnitude safari speed up compared to pure dpll  while
the soundness and completeness properties of consistency checking are preserved 
we have implemented the two stage consistency checking as follows  first  safari calls
a bcp based ltms  forbus   de kleer        to check if sd         if the result
is unsat then the candidate  is not a diagnosis   if the ltms result is not unsat  it
means that the consistency of the candidate is unknown and a call to a complete dpll
engine is needed  for the full dpll checking we use posit  freeman        or minisat
 een   sorensson        
safari benefits from the two stage sat procedure because a typical mbd instance
involves many consistency checks  o  comps     for n      m    comps    as sd  
does not change during the search and each time only a small number of assumption clauses
have to be updated  the incremental nature of ltms greatly improves the search efficiency 
even though the dpll running time per instance is the same as ltms  dpll performs
bcp when doing unit propagation   dpll construction is expensive and should be avoided
when possible  dpll initialization is typically slow as it involves building data structures
for clauses and variables  counting literals  initializing conflict databases  etc  on the other
hand  our implementation of ltms is both incremental  does not have to be reinitialized
   it can be shown that if a bcp consistency check of sd     returns unsat  then the formula is
unsat  the opposite is not necessarily true  

   

fiapproximate model based diagnosis using greedy stochastic search

before each consistency check  and efficient as it maintains only counters for each clause 
each counter keeps the number of unassigned literals  assigning a value to a variable
requires decrementing some or all of the clause counters  if a counter becomes zero  a
contradiction handler is signaled 
there is no guarantee that two diagnostic searches  starting from random diagnoses 
would not lead to the same minimal diagnosis  to prevent this  we store the generated
diagnoses in a trie r  forbus   de kleer         from which it is straightforward to extract
the resulting diagnoses by recursively visiting its nodes  a diagnosis  is added to the trie r
by the function addtotrie  iff no subsuming diagnosis is contained in r  the issubsumed
subroutine checks on that condition   after adding a diagnosis  to the resulting trie r  all
diagnoses contained in r and subsumed by  are removed by a call to removesubsumed 
    basic properties of the greedy stochastic search
before we continue with the topics of completeness and optimality  we show that safari is
sound  i e   it returns diagnoses only 
lemma    soundness   safari is sound 
proof  sketch   the consistency check in line   of alg    guarantees that only terms  for
which it holds that sd         will be added to the result set r  according to def   
these terms  are diagnoses 
one of the key factors in the success of the proposed algorithm is the exploitation of the
continuity of the search space of diagnosis models  where by continuity we mean that we
can monotonically reduce the cardinality of a non minimal diagnosis  through the exploitation of this continuity property  safari can be configured to guarantee finding a minimal
diagnosis in weak fault models in a polynomial number of calls to a satisfiability oracle 
the hypothesis which comes next is well studied in prior work  de kleer et al         
as it determines the conditions under which minimal diagnoses represent all diagnoses of a
model and an observation  this paper is interested in the hypothesis from the computational
viewpoint  it defines a class of models for which it is possible to establish a theoretical bound
on the optimality and performance of safari 
hypothesis    minimal diagnosis hypothesis   let ds   hsd  comps  obsi be a diagnostic system and   a diagnosis for an arbitrary observation   the minimal diagnosis hypothesis  mdh  holds in ds iff for any health assignment  such that lit      lit       
 is also a diagnosis 
it is easy to show that mdh holds for all weak fault models  there are other theories
sd   wfm for which mdh holds  e g   one can directly construct a theory as a conjunction
of terms for which mdh holds   unfortunately  no necessary condition is known for mdh
to hold in an arbitrary sd  the lemma which comes next is a direct consequence of mdh
and weak fault models 
lemma    given a diagnostic system ds   hsd  comps  obsi  sd  wfm  and a
diagnosis  for some observation   it follows that  is non minimal iff another diagnosis
  can be obtained by changing the sign of exactly one negative literal in  
   

fifeldman  provan    van gemund

proof  sketch   from def    and sd  wfm  it follows that if  is a minimal diagnosis 
any diagnosis   obtained by flipping one positive literal in  is also a diagnosis  applying
the argument in the other direction gives us the above statement 
safari operates by performing subset flips on non minimal diagnoses  attempting to compute minimal diagnoses  we next formalize this notion of flips  in order to characterize
when safari will be able to compute a minimal diagnosis 
definition     subset flip     given a diagnostic system ds   hsd  comps  obsi and
a health assignment  with a non empty set of negative literals  lit           a subset
flip  turns one of the negative literals in  to a positive literal  i e   it creates a health
assignment   with one more positive literal 
we next characterize flips based on whether they produce consistent models after the flip 
definition     valid subset flip   given a diagnostic system ds   hsd  comps  obsi 
an observation   and a non minimal diagnosis   a valid flip exists if we can perform a
subset flip in  to create   such that sd          
given these notions  we can define continuity of the diagnosis search space in terms of literal
flipping 
definition     continuity   a system model sd and an observation  satisfy the continuity
property with respect to the set of diagnoses   sd   iff for any diagnosis k   sd 
there exists a sequence    h             k    k   k          n i  such that for i  
           n     it is possible to go from i to i   via a valid subset flip  i   sd    
and n    sd    
the above definition allows for trivial continuity in the cases when a model and an observation lead to minimal diagnoses only  no non minimal diagnoses   as we will see in sec    
models and observations such that all diagnoses are minimal are rare in practice  of course 
such problems can be created artificially   note that the safari algorithm still works and
its theoretical properties are preserved even in the case of trivial continuity 
given def      we can easily show the following two lemmata 
lemma    if sd satisfies mdh  then it satisfies the continuity property 
proof  follows directly from hypothesis   and def    
lemma    sd  wfm satisfies the continuity property 
proof  sketch   it is straightforward to show that if sd  wfm then sd satisfies mdh 
then from lemma   it follows that sd satisfies the continuous property 
our greedy algorithm starts with an initial diagnosis and then randomly flips faulty assumable variables  we now use the mdh property to show that  starting with a non minimal
diagnosis   the greedy stochastic diagnosis algorithm can monotonically reduce the size of
the seed diagnosis to obtain a minimal diagnosis through appropriately flipping a fault
variable from faulty to healthy  if we view this flipping as search  then this search is continuous in the diagnosis space 
   

fiapproximate model based diagnosis using greedy stochastic search

proposition    given a diagnostic system ds   hsd  comps  obsi  an observation  
and sd  wfm  safari configured with m    comps  and n     returns one minimal
diagnosis 
proof  the diagnosis improvement loop starts  in the worst case  from a health assignment
 which is a conjunction of negative literals only  necessarily  in this case   is a diagnosis
as sd  wfm  a diagnosis   that is subsumed by  would be found with at most m
consistency checks  provided that   exists  as m is set to be equal to the number of literals
in  and there are no repetitions in randomly choosing of which literal to flip next  if  after
trying all the negative literals in   there is no diagnosis  then from lemma   it follows that
 is a minimal diagnosis 
through a simple inductive argument  we can continue this process until we obtain a
minimal diagnosis 
from proposition   it follows that there is an upper bound of o  comps   consistency
checks for finding a single minimal diagnosis  in most of the practical cases  however  we
are interested in finding an approximation to all minimal cardinality diagnoses  as a result
the complexity of the optimally configured safari algorithm becomes o  comps   s  
where s is the number of minimal cardinality diagnoses for the given observation  section  
discusses in more detail the computation of multiple minimal cardinality diagnoses 
the number of assumable variables in a system of practical significance may exceed
thousands  rendering an optimally configured safari computationally too expensive  in
sec   we will see that while it is more computationally efficient to configure m    comps  
it is still possible to find a minimal diagnosis with high probability 
it is simple to show that flip based search algorithms are complete for continuous diagnosis search spaces given weak fault models  i e   sd  wfm  and models that follow
mdh  i e   lemma    we can formally characterize the guarantee of finding a minimal diagnosis with safari in terms of a continuous diagnosis space  note that this is a sufficient 
but not necessary  condition  for example  we may configure safari to flip multiple literals
at a time to circumvent problems of getting trapped in discontinuous diagnosis spaces 
theorem    given a diagnostic system ds   hsd  comps  obsi  and a starting diagnosis
  safari configured with m    comps  and n     is guaranteed to compute a minimal
diagnosis if the diagnosis space is continuous 
proof  given an initial diagnosis   safari attempts to compute a minimal diagnosis by
performing subset flips  if the diagnosis space is continuous  then we know that there exists
a sequence of valid flips leading to a minimal diagnosis  hence safari is guaranteed to find
a minimal diagnosis from  
finally  we show that safari provides a strong probabilistic guarantee of computing all
minimal diagnoses 
theorem    the probability of safari  configured with m    comps   of computing all
minimal diagnoses of a diagnostic system ds   hsd  comps  obsi and an observation 
is denoted as pr   given a continuous diagnosis space  sd     it holds that pr    for
n   
   

fifeldman  provan    van gemund

proof  sketch   since     the search space is continuous      at each step there is a non zero
probability of flipping any unflipped literal  and     there is a polynomial upper bound of
steps   comps   for computing a diagnosis  safari can compute any non minimal diagnosis
with non zero probability  hence as n    safari will compute all minimal diagnoses 

    complexity of inference using greedy stochastic search
we next look at the complexity of safari  and its stochastic approach to computing sound
but incomplete diagnoses  we show that the primary determinant of the inference complexity is the consistency checking  safari randomly computes a partial assignment   and
then checks if  can be extended to create a satisfying assignment during each consistency
check  i e   it checks the consistency of  with sd  this is solving the satisfiability problem  sat   which is np complete  cook         we will show how we can use incomplete
satisfiability checking to reduce this complexity  at the cost of completeness guarantees 
in the following  we call  the complexity of a consistency check  and assume that there
are  components that can fail  i e       comps  
lemma    given a diagnostic system ds   hsd  comps  obsi with sd  wfm  the
worst case complexity of finding any minimal diagnosis is o       where  is the cost of a
consistency check 
proof  there is an upper bound of  succeeding consistency checks for finding a single
minimal diagnosis since there is a maximum of  steps for computing the all healthy
diagnosis  as safari performs a consistency check after each flip and at each step the
algorithm must flip at most  literals  the total complexity is o      
in most practical cases  however  we are interested in finding an approximation to all minimal cardinality diagnoses 
as 
a result the complexity of the optimally configured safari


  
algorithm becomes o      where    is the cardinality of the minimal cardinality
diagnoses for the given observation  cf  sec       
the complexity of bcp is well known  allowing us to get more precise bounds on the
worst case complexity of computing one minimal diagnosis with safari  in what follows
we will assume that sd is represented in cnf  cf  sec       
lemma    given a diagnostic system ds   hsd  comps  obsi  sd  wfm  and sd
having c clauses and n variables  the worst case complexity under wfm of finding any
minimal diagnosis is o    cn  when using bcp for consistency checks  
proof  sketch   an implementation of bcp  forbus   de kleer        maintains a total of
c counters for the number of unsatisfied literals in each clause  a consistency check requires
decrementing some or all counters for each of the n variables in sd  this gives us an upper
bound of o cn  on the execution time of bcp  combining the complexity of bcp with
lemma   gives us the desired result 
   more efficient implementations of bcp exist  zhang   stickel        

   

fiapproximate model based diagnosis using greedy stochastic search

   optimality analysis  single diagnosis 
in contrast to deterministic algorithms  in the safari algorithm there is no absolute guarantee that the optimum solution  minimal diagnosis  is found  below we will provide an
intuition behind the performance of the safari algorithm by means of an approximate 
analytical model that estimates the probability of reaching a diagnostic solution of specific
minimality 
    optimality of safari in weak fault models
we will start by considering a single run of the algorithm without retries where we will
assume the existence of only one minimal diagnosis  next  we will extend the model by
considering retries 
      basic model
consider a diagnostic system ds   hsd  comps  obsi such that sd  wfm  and an
observation  such that  manifests only one minimal diagnosis   for the argument that
follows we will configure safari with m      n      and we will assume that the starting
solution is the trivial all faulty diagnosis 
when safari randomly chooses a faulty variable and flips it  we will be saying that it
is a success if the new candidate is a diagnosis  and a failure otherwise  let k denote the
number of steps that the algorithm successfully traverses in the direction of the minimal
diagnosis of cardinality     thus k also measures the number of variables whose values are
flipped from faulty to healthy in the process of climbing 
let f  k  denote the probability distribution function  pdf  of k  in the following we
derive the probability p k  of successfully making a transition from k to k      a diagnosis
at step k has k positive literals and  comps   k negative literals  the probability of the
next variable flip being successful equals the probability that the next negative to positive
flip out of the h  k negative literals does not conflict with a negative literal belonging to
a diagnosis solution   consequently  of the     k literals only comps       k literals
are allowed to flip  and therefore the success probability equals 
p  k   

  
 comps       k
  
 comps   k
 comps   k

   

the search process can be modeled in terms of the markov chain depicted in fig     where
k equals the state of the algorithm  running into an inconsistency is modeled by the
transitions to the state denoted fail 
the probability of exactly attaining step k  and subsequently failing  is given by 
f  k        p k      

k
y

p i 

   

i  

substituting     in     gives us the pdf of k 

k 
y
  
  
 
f  k   
 comps   k    
 comps   i
i  

   

   

fifeldman  provan    van gemund

k  

   p   

p   

k  

   p   

p   

k  

   p   

p i 

k i

p n    

   p i     

k n

 

fail

figure    model of a safari run for m     and a single diagnosis   n    comps      

at the optimum goal state k    comps      the failure probability term in     is correct
as it equals unity 
if p were independent of k  f would be geometrically distributed  which implies that the
chance of reaching a goal state k    comps    is slim  however  the fact that p decreases
with k moves the probability mass to the tail of the distribution  which works in favor of
reaching higher k solutions  for instance  for single fault solutions          the distribution
becomes uniform  figure   shows the pdf for problem instances with  comps        for
an increasing fault cardinality     in order to decrease sampling noise  the empirical f  k 
values in fig    are computed by taking the average over    samples of k 
   

   
      
      
       

    

      
      
       

    

f k 

    

f k 

    
    

    

    

    

 

 

  

  

  

  

   

k

 

 

  

  

  

  

   

k

figure    empirical  left  and analytic  right  f  k  for no retries and a single diagnosis
in the next section we show that retries will further move probability mass towards the
optimum  increasing the tail of the distribution  which is needed for  almost always  reaching
optimality 
      modeling retries
in this section we extend the model to account for retries  which has a profound effect on
the resulting pdf of f   again  consider the transition between step k and k      where the
algorithm can spend up to m              m retries before exiting with failure  as can be
   

fiapproximate model based diagnosis using greedy stochastic search

seen by the algorithm  cf  alg      when a variable flip produces an inconsistency a retry is
executed while m is incremented 
from elementary combinatorics we can compute the probability of having a diagnosis
after flipping any of m different negative literals at step k  similar to      at stage k there
are  comps   k faulty literals from which m are chosen  as variable flips leading to
inconsistency are recorded and not attempted again  there is no difference between choosing
the m variables in advance or one after another   the probability of advancing from stage
k to stage k     becomes 
  
p  k      

m
 comps k
m

   

the progress of safari can be modeled for values of m     as a markov chain  similar to
the one shown in fig    with the transition probability of p replaced by p   the resulting
pdf of the number of successful steps becomes 
 
 
k
  
  
y

m
m
   
    comps i
f  k     comps k  
m

i  

m

it can be seen that     is a restricted case of     for m     
the retry effect on the shape of the pdf is profound  whereas for single fault solutions
the shape for m     is uniform  for m     most of the probability mass is already located
at the optimum k    comps       fig    plots f for a number of problem instances with
increasing m   as expected  the effect of m is extremely significant  note that in case of
the real system  for m    comps  the pdf would consist of a single  unit probability spike
at  comps      
although we were unable to find an analytic treatment of the transition model above  the
graphs immediately show that for large m the probability of moving to k    comps     
is very large  hence  we expect the pdf to have a considerable probability mass located at
k    comps       depending on m relative to  comps  
    optimality of safari in strong fault models
from the above analysis we have seen that in wfm it is easy  starting from a non minimal
diagnosis  to reach a subset minimal diagnosis  as will be discussed in more detail below 
this is not necessarily the case for strong fault models  in many practical cases  however 
strong fault models exhibit  at least partially  behavior similar to mdh  thus allowing greedy
algorithms like safari to achieve results that are close to the optimal values 
      partial continuity in strong fault stuck at models
in what follows we will restrict our attention to a large subclass of sfm  called sfsm
 struss   dressler        
definition     strong fault stuck at model   a system ds   hsd  comps  obsi belongs to the class sfsm iff sd is equivalent to  h   f      h   l          hn 
fn     hn  ln   such that    i  j  n   hi    comps  fj is a propositional formula 
none of hi appears in fj   and lj is a positive or negative literal in fj  
   

fifeldman  provan    van gemund

m  

m  

    

    
      
       

    
f k 

f k 

    

    

    

 

      
       

    

    

 

  

  

  

  

 

   

 

  

  

k
m  

   

  

  

   

    
      
       

   

      
       

   
    
f k 

    
f k 

  

m  

    

    

    

    

    

    

    

 

  
k

 

  

  

  

  

   

k

 

 

  

  
k

figure    empirical  left  and analytic  right  f   k  for multiple retries and a single diagnosis

mdh  cf  hypothesis    does not hold for sfsm models  consider an adder whose inputs
and outputs are all zeroes  and whose gate models are all stuck at   when faulty  in this
case  the all nominal assignment is a diagnosis  but  for example  a stuck at   output gate
is not a diagnosis  there is a contradiction with the zero output  
many practical observations involving sfsm models  however  lead to partial continuity  this means that there are groups of diagnoses that differ in at most one literal  i e   a
flip based search can improve the cardinality of a diagnosis  we next formalize this notion 
definition     partial continuity   a system model sd and an observation  satisfy the
partial continuity property with respect to a set s   sd     iff for every diagnosis 
such that i  s satisfying lit       lit   i   there exists a finite sequence of valid subset
flips from i to  
at one extreme of the spectrum  sd and  satisfy the partial continuity property with
respect to the set of all of its diagnoses while at the other extreme  the partial continuity
   

fiapproximate model based diagnosis using greedy stochastic search

property is satisfied with respect to a singleton s  consider  for example  sd  wfm
where s consists of the single all faulty diagnosis  
note that the continuous property is trivally satisfied with respect to any diagnosis
k   sd     i e   there always exists a sequence containing k only     hk i   we are
only interested in the non trivial cases  for which        
consider a system sd and an observation  that satisfy the partial continuity property
with respect to some diagnosis k   we say that the diagnoses in the flip sequence  that
contains k form a continuous subspace  alternatively  given a diagnostic system sd and an
observation   a continuous diagnostic subspace of sd is a set of diagnoses    sd 
with the property that  for any diagnosis     there is another diagnosis    such that
 lit        lit          
unfortunately  in the general sfsm case  we cannot derive bounds for the sizes of the
continuous subspaces  and hence  for the optimality of safari  in what follows  and with
the help of a few examples  we illustrate the fact that partial continuity depends on the
model and the observation and then we express the optimality of safari as a function of this
topologically dependent property  later  in sec     we collect empirical data that continuous
subspaces leading to near optimal diagnoses exist for a class of benchmark sfsm circuits 
our first example illustrates the notion of discontinuity  lack of partial continuity with
respect to any diagnoses   we show a rare example of a model and and an observation
leading to a set of diagnoses that contains diagnoses of cardinality m and m   q  q      
but has no diagnoses of cardinality m      m           m   q    
a discontinuity example consider  for example  the boolean circuit shown in fig   
and modeled by the propositional formula 

 h    y  x     h    y  x  
   
sdd  
 h    y  x     h    y  x  
and an observation d   x  y  note  that sdd   sfsm  there are exactly two diagnoses
of sdd  d        h   h  and      h   h    note that this model cannot have single
faults  as only    is minimal             and            if the algorithm starts from    it
is not possible to reach the minimal diagnosis    by performing single flips  similarly we
can construct models which impose an arbitrarily bad bound on the optimality of safari 
such models  however  are not common and we will see that the greedy algorithm performs
well on a wide class of strong fault models 
h 
x

y
h 

figure    a two inverters circuit
obviously  continuity in the distribution of the cardinalities in a set of diagnoses is a necessary  but not sufficient  condition for safari to progress  such models impose arbitrary
difficulty to safari  leading to suboptimal diagnoses of any cardinality 
   

fifeldman  provan    van gemund

an example of partial continuity we continue the running example started in sec    
first  we create a system description sdsa for a sfsm model  let sdsa   sdw  sdf  
where sdw is given by      the second part of sdsa   the strong fault description sdf  
specifies that the output of a faulty gate must be stuck at   
sdf    h   i    h   d    h   j    h   m  
  h   b    h   l    h   k 

   

it is clear that sdsa  sfsm  we next compute the diagnoses of sdsa         x  y 
p  b d   there is one minimal diagnosis of sdsa    and it is     h   h   h      h 
 cf  fig      if we choose the two literals h  and h  from   and change the signs of h 
and h    we create two new health assignments       h   h   h   h   h   h   h 
and      h   h   h   h   h   h   h    it can be checked that both    and    are
diagnoses  i e   sdsa            and sdsa             note that    and    are
diagnoses of the weak part of the model  i e                sdw       this follows from
mdh and the fact that   is a minimal diagnosis of sdw      furthermore     is also a
diagnosis in the strong fault stuck at model       sdsa       because sdw     h 
does not lead to a contradictory value for j in the strong fault part sdf   a similar argument
applies to      sdw     h  does not contradict m in sdf   equivalently  if negating h 
in     which makes j stuck at    results in a diagnosis  and negating h  in     which makes
m stuck at    also results in a diagnosis  negating both h  and h  in   will also result in
a diagnosis  consider the fact that the fault mode of h  sets m only  but does not impose
constraints on j   the above argument can be extended similarly to h    h    and h    hence 
any assignment of comps containing h   h  is a diagnosis of sdsa      no matter what
combination of signs we take for h    h    h    h    and h    note that a health assignment
containing h  is a diagnosis conditioned on k     
x  
y  
p  

h 

d  

h 

h 
i  

l  
h 

h 

m  

j  

h 

b  

h 
k  

figure    continuous subspace in a strong fault  stuck at   model of a subtractor
consider an alternative way of computing a set of ambiguous diagnoses of sdsa      given
sdsa       we can compute a consistent assignment to all internal variables  for example
by propagation   there is exactly one such assignment  and it is    i  j  k  l  m 
sdsa              cf  fig      note that for components h    h    h    and h    a
change in the state of a component  healthy or faulty  does not lead to a different output
value  for example the output j of the h  or gate is   because the gate is healthy and its
   

fiapproximate model based diagnosis using greedy stochastic search

inputs are   but j would also be   for a stuck at   or gate  h     as a result  no diagnostic
reasoner can determine if the components in the dashed region of fig    are healthy or faulty
 stuck at     equivalently  one can change the signs of h    h    and h  in the diagnosis  
and the resulting assignments are still diagnoses  we call the set of components modeled
by h    h    h    and h  an ambiguity group  clearly  safari can start from a diagnosis
     h   h   h   h   h   h   h              and reach              by
performing valid subset flips 
to make our reasoning precise  we restrict the class of sfsm models to exclude malformed circuits such as ones having disconnected inputs or outputs  etc  furthermore  we
assume that each component has exactly one output  the set of all component output variables is denoted as cout   the latter is not a big restriction as multi output component
models can be replaced by multiple components  each having a single output  
definition     well formed diagnostic system  wfds    the diagnostic system ds  
hsd  comps  obsi is well formed  ds  wfds  iff for any observation  and for any
diagnosis    sd     there is exactly one assignment  to all component outputs
cout such that sd           
consider an sfsm model sd    h   f      h   l          hn  fn     hn  ln   
we denote as comps the set of those hi     i  n  for which the respective li literals are
negative  cf  def       i e   comps is the set of components whose failure modes are stuckat    similarly  we use comps  for the set of component variables whose stuck at li literals
are positive  comps  comps    comps  comps  comps       in a wfds 
an observation  and a diagnosis  force the output of each component either to a negative
or to a positive value  we denote the set of health variables whose respective component
outputs are forced to negative values as g  ds       similarly  we have g   ds      for
the components whose outputs have positive values  with all this we can define the notion
of a component ambiguity group 
definition     component ambiguity group   given a system ds   hsd  comps  obsi 
sd  sfsm  sd  wfds  an observation   and a diagnosis    sd   the component
ambiguity group u ds       u  comps  is defined as u ds         g  ds      
comps     g   ds       comps    
finally  we show that a component ambiguity group leads to a continuous subspace  in
the general case we cannot say much about the size of the component ambiguity groups 
from experimentation  we have noticed that it is difficult to assign the inputs of an sfsm
to values that generate small continuous subspaces  either sd       or sd   leads
to large component ambiguity groups   of course  it is possible to consider an adder  or a
multiplier  for example  whose inputs are all zeroes and whose gate models are all stuck at  
when faulty  but the number of such inputs circuit combinations is small 
proposition    a diagnostic system sd  sd  sfsm  sd  wfds  and an observation
 entail continuous diagnostic subspaces 
   any multi output boolean function can be replaced by a composition of single output boolean functions 

   

fifeldman  provan    van gemund

proof  from def     and the fact that sd  wfds it follows that the output values of a
subset of the components have the same sign as the models stuck at value  we denote this
set as comps   comps  comps  any health assignment  that differs only in signs
of components belonging to comps is also a diagnosis  if the set of diagnoses of sd  
contains all possible assignments to the assumables in comps then those diagnoses form
a continuous space  cf  def      
to best illustrate proposition    consider the or gate modeled by h  in fig     its output is
  either because the gate is healthy and one of the gates inputs is    or because the gate is
stuck at    in this situation  it is not possible to determine if the component is healthy or
faulty 
clearly   u ds       is a lower bound for the progress of safari in stuck at models 
it can be shown that if safari starts from a diagnosis  of maximum cardinality for the
given subspace  safari is guaranteed  for m    comps   to improve the cardinality of
 by at least  u ds        in practice  safari can proceed even further as the stuckat ambiguity groups are only one factor of diagnostic uncertainty  a stuck at component
effectively disconnects inputs from outputs  hence gates from the fan in region are not
constrained  for instance  continuing our example  for h    all predecessors in the cone of
h   components h    h    h    h    and h    constitute a continuous health subspace 
contrary to a component ambiguity group  this set is conditional on the health state of
another component  a thorough study of stuck at continuity is outside the scope of this
paper but as we shall see in sec     continuous subspaces justify safari experiments on
stuck at models 
      performance modeling with stuck at models
to further study the optimality of safari in strong fault models  we first define a case
in which the algorithm cannot improve a non minimal diagnosis by changing the sign of a
faulty literal  note that the existence of such cases is not a sufficient condition for safari
to be suboptimal  as it is possible to reach a minimal diagnosis by first changing the sign
of some other faulty literal  thus circumventing the missing diagnosis 
from the preceding section we know that the number of invalid flips does not depend
on k  i e   it is determined by the observation vector and the fault modes  the probability
of safari to progress from any non minimal diagnosis becomes
p k      

    x 
m
 comps k
m

    

where  x  is the number of invalid flips  the ratio of the number of invalid flips  x  to
 comps  we will call sfm density d  the density d gives the average probability of trying
an invalid flip throughout the diagnostic search  an approximation of the probability of
success of safari is 
p k      

  
m
 comps k
m

   

d

    

fiapproximate model based diagnosis using greedy stochastic search

plugging p into     allows us to predict f  k  for the sfm models for which our assumptions
hold  this pdf  both measured from an implementation of safari and generated from    
and      is shown in fig    for different values of the density d 
m       comps                

m       comps                

    

    
d  
d      
d       
d      

   

    
f k 

f k 

    
    

    

    

    

    

    

 

 

  

  

  

d  
d      
d       
d      

   

  

   

k

 

 

  

  

  

  

   

k

figure    empirical  left  and analytic  right  f   k  for various diagnostic densities  multiple
retries and a single diagnosis

from fig    it is visible that increasing the density d leads to a shift of the probability
density of the length of the walk k to the left  the effect  however  is not that profound
even for large values of d  and is easily compensated by increasing m   as discussed in the
preceding sections 
it is interesting to note that bounds on d can be computed from sd  independent of   
and these bounds can be used to further improve the performance of safari 
    validation
in the preceding sections we have illustrated the progress of safari with synthetic circuits
exposing specific behavior  diagnoses   in the remainder of this section we will plot the pdf
of the greedy search on one of the small benchmark circuits  for more information on the
      model cf  sec     
the progress of safari with a weak fault model of the       circuit is shown in fig     
we have chosen a difficult observation leading to a minimal diagnosis of cardinality    left 
and an easy observation leading to a single fault diagnosis  right   both plots show that
the probability mass shifts to the right when increasing m and the effect is more profound
for the smaller cardinality 
the effect of the stuck at   and stuck at   fault modes  sfm  on the probability of
success of safari is shown in fig     
obviously  in this case the effect of increasing m is smaller  although still depending
on the difficulty of the observation vector  last  even for small values of m   the absolute
probability of safari finding a minimal diagnosis is sizeable  allowing the use of safari
   

fifeldman  provan    van gemund

             

             

   

   
m  

m  

m  

   

m  

   

m  
   

m  
   

   

   

   

   

 

 

  

  

m  

f k 

f k 

m  

  
k

  

  

 
  

  

  

  
k

  

  

figure     empirical f   k  for a weak fault model of the       circuit with observations
leading to two different minimal cardinality diagnoses and various m

               s a  

               s a  

   

   
m  

    

m  
   

    

 
  

m  

    

m  
f k 

f k 

m  

m  

m  
m  

   

    

  

  
k

  

  

 
  

  

  

  

  

  

k

figure     empirical f   k  for stuck at   and stuck at   strong fault models of the      
circuit with various m

as a practical anytime algorithm which always returns a diagnosis  the optimality of which
depends on the time allocated to its computation 

   optimality analysis  multiple diagnoses 
the preceding section described the process of computing one diagnosis with safari  n  
    in this section we discuss the use of safari in computing  or counting  all minimalcardinality diagnoses  n       for the rest of the section we will assume that safari is
configured with m    comps  
   

fiapproximate model based diagnosis using greedy stochastic search

consider a system description sd  sd  wfm  and an observation   the number
of minimal diagnoses    sd     can be exponential in  comps   furthermore  in practice  diagnosticians are interested in sampling from the set of minimal cardinality diagnoses
  sd     recall that   sd       sd     as the minimal cardinality diagnoses
cover a significant part of the a posteriori diagnosis probability space  de kleer         in
what follows  we will see that safari is very well suited for that task 
theorem    the probability of safari configured with m    comps  computing a minimal diagnosis of cardinality    in a system with  comps  component variables approaches
 comps    for  comps       
proof  sketch   assume a minimal diagnosis of cardinality    exists  from proposition  
it follows that safari configured with m    comps  is guaranteed to compute minimal
diagnoses  starting from the all faulty assignment  consider a step k in improving the
diagnosis cardinality  if state k contains more than one diagnosis  then at state k    safari
will either     flip a literal belonging to this diagnosis  note that a literal may belong to
more than one diagnosis  and subsequently prevent safari from reaching this diagnosis or
    flip a literal belonging to a diagnosis which has already been invalidated  i e   one or
more of its literals have been flipped at an earlier step  
the probability that a solution of cardinality    survives a flip at iteration k  i e   is
not invalidated  is 
p  k      

 comps       k
  
 
 comps   k
 comps   k

    

similarly to our basic model  sec          the probability that a diagnosis  survives until
it is returned by the algorithm 
 comps    

y

f   comps           

 comps    

p i   

i  

y
i  

 comps       i
 comps   i

    

rewriting the right hand side of eq       gives us 
f   comps           

  comps       
     comps       
 
                     comps 
 comps  

    

since
 
  comps       
 
 comps  
  comps            comps               comps 

    

it holds that
  comps       
   comps   
 comps  
 comps    
lim

    

as a result  for small    relative to  comps  
f   comps                comps   
which gives us the above theorem 
   

    

fifeldman  provan    van gemund

the distribution hi      of the cardinalities of the minimal diagnoses in   sd   depends
on the topology of sd and on   i e   we can create sd and  having any hi       we denote
the cardinality distribution of the minimal diagnoses computed by safari as h     
theorem   gives us a termination criterion for safari which can be used for enumerating
and counting minimal cardinality diagnoses  instead of running safari with
p a fixed n   it
is sufficient to compute the area under the output distribution function
h  this value
p
will converge to a single value  hence we can terminate safari after the change of
h
drops below a fixed threshold  note that safari is efficient in enumerating the minimalcardinality diagnoses  as they are computed with a probability that is exponentially higher
than that of the probability of computing minimal diagnoses of higher cardinality  as shown
in theorem   
corollary    safari computes diagnoses of equal cardinality with equal probability 
proof  sketch   from theorem   it follows that the probability of success f of safari in
computing a diagnosis  depends only on    and not on the actual composition of  
the above corollary gives us a simple termination criterion for safari in the cases when
all minimal diagnoses are also minimal cardinality diagnoses  it can be proven that in this
case all minimal cardinality diagnoses are computed with the same probability 
we will see that  given an input cardinality distribution hi       safari produces an
output distribution h     that is highly skewed to the right  due to theorem    to facilitate
the study of how safari transforms hi      into h     we will use a monte carlo simulation
of safari  the advantage is that the monte carlo simulation is much simpler for analysing
the run time behavior of safari than studying the algorithm itself 
algorithm   monte carlo simulation of safari
   function safarisimulate   n   returns a cardinality distribution
inputs     a set of minimal diagnoses
n   integer  number of tries
local variables  hi   h  vectors  cardinality distributions
b  vector  fault distribution  n  i  c  integers
  
hi  cardinalitydistribution   
  
for n                n do
  
for c                 hi   do
  
b c   c  hi  c 
  
end for
  
for i                    do
 
  
c  discreteinverserandomvalue pb b
  
b c   b c   c
   
end for
   
h c   h c     
   
end for
   
return h
    end function
   

fiapproximate model based diagnosis using greedy stochastic search

algorithm   simulates which diagnoses from the input set of minimal diagnoses  are
reached by safari in n tries  the auxiliary subroutine cardinalitydistribution
computes the input distribution hi by iterating over all diagnoses in    we store the input
cardinality distribution hi and the resulting cardinality distribution h in vectors  note the
vector sums in lines   and   and the division of a vector by scalar in line    
the outermost loop of alg     lines        simulates the n runs of safari  this is done
by computing and updating an auxiliary vector b  which contains the distribution of the
component variables in  according to the cardinalities of the diagnoses these variables
belong to  initially  b is initialized with the number of literals in single faults in position   
the number of literals in double faults in position    for example if there are three double
faults in hi   b          etc  this is done in lines      of alg     we assume that diagnoses
do not share literals  this restriction can be easily dropped by counting all the assumables
in the input   the latter assumption does not change the results of this section  
lines       simulate the process of the actual bit flipping of safari  at each step
the simulation draws a random literal from the probability distribution function  pdf   pb b  
this is done by the discreteinverserandomvalue function in line    each bit flip
invalidates a diagnosis from the set    i e   a diagnosis of cardinality c cannot be reached
by safari  after a diagnosis has been invalidated  the vector b is updated  for example  if
the simulation invalidates a quadruple fault  b      b        line     note that the number
of iterations in the loop in lines       equals the number of diagnoses in    as a result
after terminating this loop  the value of the integer variable c is equal to the cardinality of
the last invalidated diagnosis  the latter is the diagnosis which safari computes in this
run  what remains is to update the resulting pdf with the right cardinality  line     
the simulation in alg    links the distribution of the actual diagnoses in  to the
distribution of the cardinalities of the diagnoses returned by safari  as  can be arbitrarily set  we will apply alg    to a range of typical input distributions  the results of the
simulation as well as the results of running safari on synthetic problems with the same
input distributions are shown in fig     
fig     shows     that alg    predicts the actual behavior of safari  compare the second
and third column of plots   and     that safari computes diagnoses of small cardinality
in agreement with theorem    the only case when the output distribution is not a steep
exponential is when the cardinalities in the set of the input minimal diagnoses grow exponentially  table   summarizes the parameters of exponential fits for the input cardinality
distributions shown in fig      a is the initial  zero  cardinality   is the decay constant  and
r  is the coefficient of determination   we have seen that safari is suited for computing
multiple diagnoses of small probability of occurrence  in the next section we will provide
an alternative argument leading to similar conclusions 

   experimental results
this section discusses empirical results measured from an implementation of safari  in order to compare the optimality and performance of safari to various diagnostic algorithms 
we have performed more than a million diagnosis computations on    dual cpu nodes belonging to a cluster  each node contains two     ghz amd opteron dp     processors
and   gb of ram 
   

fifeldman  provan    van gemund

degenerate input

prediction  model 

   
 

 

h    

 

h    

h    

 

   
 

 

  
  

   

 

   
 

  
  

   

 
 

  
  

   

h    

h    

   
   

  

exponential input

  
  

 

h    

h    
  
  

  

 

prediction  model 
   

 

  

  

   
   
 

  

   

h    

h    

h    
 

  
  

safari

   

 

   
 

 

reverse exponential input

   

  

 

   

  

  
  

safari

 
  
  

   

prediction  model 

 
 

   

  

 

   

   

 
 

   

  
  

   

 
  
  

 

safari

   

    

   

   

prediction  model 

   

  
  

safari

h    

h    

h    

   

 

 

 

normal input

h    

   

 

 

h    

  
  

prediction  model 

 

 

   
 

uniform input

 

safari

   
   

 

 
  

  

 

 

 
  

figure     predicted and actual cardinality distributions
   

  

fiapproximate model based diagnosis using greedy stochastic search

table    fit coefficients to exponential and goodness of fit for the cardinality distribution
in fig    
a



r 

   
   
      
   

    
    
    
    

 
    
 
    

input distribution
uniform
normal
exponential
reverse exponential

the default configuration of safari  when not stated otherwise  was m     and n     
that is  safari is configured for a maximum number of   retries before giving up the
climb  and a total of   attempts  to provide more precise average run time optimality and
performance data  all stochastic algorithms  i e   ones based on sls max sat and safari 
have been repeatedly run    times on each model and observation vector 
    implementation notes and test set description
we have implemented safari in approximately       lines of c code  excluding the ltms 
interface  and dpll code  and it is a part of the lydia package  
traditionally  mbd algorithms have been tested on diagnostic models of digital circuits
like the ones included in the iscas   benchmark suite  brglez   fujiwara         as
models derived from iscas   are large  from a traditional diagnostic perspective   we
have also considered four medium sized circuits from the   xxx family  hansen  yalcin 
  hayes         in order to provide both weak  and strong fault cases  we have translated
each circuit to a weak  stuck at    s a     and stuck at    s a    model  in the stuck at
models  the output of each faulty gate is assumed to be the same constant  cf  def      
the performance of diagnostic algorithms depends to various degrees on the observation
vectors  algorithm designers strive to produce algorithms  the performance of which is not
dependent on the observation vectors   hence  we have performed our experimentation
with a number of different observations for each model  we have implemented an algorithm
 alg     that generates observations leading to diagnoses of different minimal cardinality 
varying from   to nearly the maximum for the respective circuits  for the   xxx models
it is the maximum   the experiments omit nominal scenarios as they are trivial from the
viewpoint of mbd 
algorithm   uses a number of auxiliary functions  randominputs  line    assigns
uniformly distributed random values to each input in in  note that for the generation of
observation vectors we partition the observable variables obs into inputs in and outputs
out and use the input output information which comes with the original   xxx iscas  
circuits for simulation   given the all healthy health assignment and the diagnostic system  computenominaloutputs  line    performs simulation by propagating the input
assignment   the result is an assignment  which contains values for each output variable
in out 
   lydia  safari  and the diagnostic benchmark can be downloaded from http   fdir org lydia  

   

fifeldman  provan    van gemund

algorithm   algorithm for generation of observation vectors
   function makealphas ds  n  k  returns a set of observations
inputs  ds   hsd  comps  obsi  diagnostic system
obs   in  out  in  out   
n   integer  number of tries for safari
k  integer  maximal number of diagnoses per cardinality
local variables      n     terms
c  integer  best cardinality so far
a  set of terms  observation vectors   result
  
for k                k do
  
  randominputs in 
  
  computenominaloutputs ds   
  
c 
  
for all v  out do
  
n    flip   v 
  
  smallestcardinalitydiagnosis safari sd  n    comps   n   
  
if      c then
   
c    
   
a  a  n
   
end if
   
end for
   
end for
   
return a
    end function
the loop in lines       increases the cardinality by greedily flipping the values of the
output variables  for each new candidate observation n   alg    uses the diagnostic oracle
safari to compute a minimal diagnosis of cardinality c  as safari returns more than
one diagnosis  up to n    we use smallestcardinalitydiagnosis to choose the one of
smallest cardinality  if the cardinality c of this diagnosis increases in comparison to the
previous iteration  the observation is added to the list 
by running alg    we get up to k observations leading to faults of cardinality               m 
where m is the cardinality of the mfmc diagnosis  feldman  provan    van gemund 
    b  for the respective circuit  alg    clearly shows a bootstrapping problem  in order
to create potentially difficult observations for safari  we require safari to solve those
difficult observations  although we have seen in sec    that safari is heavily biased
towards generating diagnoses of small cardinality  there is no guarantee  to alleviate this
problem  for the generation of observation vectors  we have configured safari to compute
subset minimal diagnoses with m    comps  and n increased to    
table   provides an overview of the fault diagnosis benchmark used for our experiments 
the third and fourth columns show the number of observable and assumable variables  which
characterize the size of the circuits  the next three columns show the number of observation
vectors with which we have tested the weak  s a    and s a   models  for the stuck at
models  we have chosen those weak fault model observations which are consistent with their
   

fiapproximate model based diagnosis using greedy stochastic search

table    an overview of the   xxx iscas   benchmark circuits
name

description

     
  l  
     
     

  bit
  bit
  bit
  bit

c   
c   
c   
c    
c    
c    
c    
c    
c    
c    

   channel interrupt controller
   bit sec circuit
  bit alu
   bit sec circuit
   bit sec dec
   bit alu
  bit alu
  bit alu
   bit multiplier
   bit adder

variables
 obs   comps 

carry lookahead generator
magnitude comparator
adder
alu

observations
weak s a   s a  

  
  
  
  

  
  
  
  

   
   
   
   

   
  
   
   

  
  
   
   

  
  
  
  
  
   
  
   
  
   

   
   
   
   
   
     
     
     
     
     

   
   
     
   
   
     
   
     
   
     

   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   

respective system descriptions  as in strong fault models it is often the case that sd    
we have not considered such scenarios  
    comparison to complete algorithms
table   shows the results from comparing safari to implementations of two state of the art
complete and deterministic diagnostic algorithms  a modification for completeness of cda
 williams   ragno        and ha  feldman   van gemund         table   shows  for
each model and for each algorithm  the percentage of all tests for which a diagnosis could
be computed within a cut off time of   minute 
as it is visible from the three rightmost columns of table    safari could find diagnoses for all observation vectors  while the performance of the two deterministic algorithms
 columns two to seven  degraded with the increase of the model size and the cardinality of
the observation vector  furthermore  we have observed a degradation of the performance of
cda and ha with increased cardinality of the minimal cardinality diagnoses  while the
performance of safari remained unaffected 
    comparison to algorithms based on allsat and model counting
we have compared the performance of safari to that of a pure sat based approach 
which uses blocking clauses for avoiding duplicate diagnoses  jin  han    somenzi        
although sat encodings have worked efficiently on a variety of other domains  such as
planning  the weak health modeling makes the diagnostic problem so underconstrained that
an uninformed allsat strategy  i e   a search not exploiting the continuity imposed by
the weak fault modeling  is quite inefficient  even for small models 
   

fifeldman  provan    van gemund

table    comparison of cda   ha   and safari    of tests solved 
name

weak

cda
s a  

     
  l  
     
     

   
   
   
    

   
   
   
    

   
   
   
    

c   
c   
c   
c    
c    
c    
c    
c    
c    
c    

    
  
    
   
 
 
 
 
 
 

    
    
    
   
 
 
 
 
 
 

    
    
    
   
 
 
 
 
 
 

s a  

weak

ha
s a  

s a  

weak

   
   
   
   

   
   
   
   

   
   
   
   

   
   
   
   

   
   
   
   

   
   
   
   

   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   

    
    
    
    
   
 
   
   
   
   

    
    
    
    
 
    
   
   
   
   

    
    
    
    
   
    
   
   
   
  

safari
s a   s a  

to substantiate our claim  we have experimented with the state of the art satisfiability
solver relsat  version       bayardo   pehoushek         instead of enumerating all
solutions and filtering the minimal diagnoses only  we have performed model counting  whose
relation to mbd has been extensively studied  kumar         while it was possible to solve
the two smallest circuits  the solver did not terminate for any of the larger models within
the predetermined time of   hour  the results are shown in table   
the second column of table   shows the model count returned by relsat  with sample single fault observations from our benchmark  the third column reports the time for
model counting  this slow performance on relatively small diagnostic instances leads us
to the conclusion that specialized solvers like safari are better suited for finding minimal
diagnoses than off the shelf allsat  model counting  implementations that do not encode
inference properties similar to those encoded in safari 
we have used the state of the art  non exact model counting method samplecount
 gomes  hoffmann  sabharwal    selman        to compute lower bounds of the model
counts  the results are shown in the third and fourth columns of table    configured with
the default settings          t      z       cutoff        flips   samplecount could not
find lower bounds for circuits larger than c      although the performance of samplecount is significantly better than relsat  the fact that samplecount computes lower
bounds and does not scale to large circuits prevent us from building a diagnosis algorithm
based on approximate model counting 
a satisfiability based method for diagnosing an optimized version of iscas   has been
used by smith  veneris  and viglas         in a more recent paper  smith  veneris  ali   
viglas         the sat based approach has been replaced by a quantified boolean formula
 qbf  solver for computing multiple fault diagnoses  these methods report good absolute
   

fiapproximate model based diagnosis using greedy stochastic search

table    model count and time for counting
relsat
models
time  s 

name

samplecount
models
time  s 

     
  l  
     
     

           
            
             
             

 
   
       
       

              
               
               
               

   
   
   
   

c   
c   
c   
c    
c    
c    
c    
c    
c    
c    












            
            
            
            
            
            
            
            
            
            

       
       
       
       
       
       
       
       
       
       

               
               
                
                







   
    
    
    







execution time for single and double faults  and we believe that they scale well for higher
cardinalities   but require modifications of the initial circuits  i e   introduce cardinality and
test constraints  and suggest specialized heuristics for the sat solvers in order to improve
the search performance  comparison of the performance of safari to the timings reported
by these papers would be difficult due to a number of reasons like the use of different and
optimized benchmark sets  trading off memory for speed  rewriting the original circuits  etc 
    performance of the greedy stochastic search
table   shows the absolute performance of safari  m    comps   n       this varies
from under a millisecond for the small models  to approx     s for the largest strong fault
model  these fast absolute times show that safari is suitable for on line reasoning tasks 
where autonomy depends on speedy computation of diagnoses 
for each model  the minimum and maximum time for computing a diagnosis has been
computed  these values are shown under columns tmin and tmax   respectively  the small
range of tmax  tmin confirms our theoretical results that safari is insensitive to the fault
cardinalities of the diagnoses it computes  the performance of cda and ha   on the
other hand  is dependent on the fault cardinality and quickly degrades with increasing fault
cardinality 
    optimality of the greedy stochastic search
from the results produced by the complete diagnostic methods  cda and ha   we know
the exact cardinalities of the minimal cardinality diagnoses for some of the observations  by
considering these observations  which lead to single and double faults  we have evaluated
   

fifeldman  provan    van gemund

table    performance of safari  ms 
weak
name

tmin

s a  
tmax

     
  l  
     
     

    
    
    
    

    
    
    
    

c   
c   
c   
c    
c    
c    
c    
c    
c    
c    

    
     
     
     
      
      
      
        
        
       

     
     
     
      
      
      
        
        
        
        

tmin
    
    
    
    

s a  
tmax
    
    
    
    

tmin
    
    
    
    

tmax
    
    
   
    

    
     
    
     
     
     
     
     
     
     
     
     
     
      
     
      
      
      
      
      
               
      
     
       
        
               
                         
        
                                  
                                     

the average optimality of safari  table   shows these optimality results for the greedy
search  the second column of table   shows the number of observation vectors leading to
single faults for each weak fault model  the third column shows the average cardinality of
safari  the second and third column are repeated for the s a   and s a   models 
table   shows that  for sd  wfm  the average cardinality returned by safari is
near optimal for both single and double faults  the c     model shows the worst case
results for the single fault observations  while c    is the most difficult weak fault model for
computing a double fault diagnosis  these results can be improved by increasing m and n
as discussed in sec    
with strong fault models  results are close to optimal for the small models and the
quality of diagnosis deteriorates for c     and bigger  this is not surprising  considering
the modest number of retries and number of flips with which safari was configured 
    computing multiple minimal cardinality diagnoses
we next show the results of experiments supporting the claims made in sec     for that 
we have first chosen these observations  for which we could compute    sd     with a
deterministic algorithm like cda or ha  mostly observations leading to single or double
faults   we have then configured safari with m    comps  and n        sd     
finally  from the diagnoses computed by safari we have filtered the minimal cardinality
ones  the results are summarized in table   
table   repeats the same columns for weak  s a    and s a   models and the data
in these columns are to be interpreted as follows  the columns marked with     show
the minimal and maximal number of minimal cardinality diagnoses per model as computed
by a deterministic algorithm  the columns mc show the percentage of minimal cardinality
   

fiapproximate model based diagnosis using greedy stochastic search

table    optimality of safari  average cardinality 
single faults
s a  
s a  
  card    card 

name

weak
  card 

     
  l  
     
     

  
  
  
  

 
    
    
    

  
  
  
  

 
    
    
    

  
  
  
  

c   
c   
c   
c    
c    
c    
c    
c    
c    
c    

  
  
  
  
  
  
 
  
  
  

    
    
 
    
    
    
    
 
 
    

  
  
  
  
  
  
  
 
  
  

    
    
   
 
    
    
   
    
     
     

  
  
  
  
  
  
  
  
  
  

 
    
    
   

weak
  card 

double faults
s a  
s a  
  card    card 

  
  
  
  

 
    
   
    

  
  
  
  

       
        
       
    
 
     
       
     
   
 
     
 
        

    
    
    
    

    

 
 
 

  
  
  
 
 
  
 
 
 
 

 
    
    
    

  
  
  
  

 
    
   
    

       
        
       
 
  
 
 
       
   

   
 
  

    
 

    
    
    
    
    
    

   

     

table      of all minimal cardinality diagnoses computed by safari
weak
mc

name

   

     
  l  
     
     

     
     
     
      

   
    
    
    

c   
c   
c   
c    
c    
c    
c    
c    
c    
c    

     
     
      
        
        
     
      
      
      
      

    
    
    
    
    
   
    
    
   
    

s a  
mc mf

   

 
 
 
 

  
  
     
     

   
   
    
    

 
 
 
    

     
     
     
     

   
    
    
    

 
 
 
    

     
     
      
      
      
     
      
     
     
      

    
    
    
    
    
    
    
    
    
    

 
 
 
 
    
 
    
    
   
     

     
     
      
      
      
      
      
     
      
      

  
    
    
    
    
    
    
    
    
  

 
 
 
    
    
 
    
    
    
    

    
    
 
    
    
    
    
    
    
    

   

s a  
mc mf

mf

diagnoses returned by safari  from all minimal cardinality diagnoses  for those  for which
   sd          the columns mf show the percentage of observations for which safari
could not compute any minimal cardinality diagnosis 
   

fifeldman  provan    van gemund

the results shown in table   show that even for moderate values of n  n          
safari was capable of computing a significant portion of all minimal cardinality diagnoses 
this portion varies from       to      for weak fault models and from     to      for
strong fault models  the percentage of cases in which safari could not reach a minimalcardinality diagnosis is limited  at most         and is mainly in the cases in which there
exists only one single fault diagnosis  note that even in the cases in which safari cannot
compute any minimal cardinality diagnoses  the result of safari can still be useful  for
example  a subset minimal diagnosis of small cardinality differing in one or two literals
only nevertheless brings useful diagnostic information  a discussion on diagnostic metrics is
beyond the scope of this paper  
    experimentation summary
we have applied safari to a suite of benchmark combinatorial circuits encoded using
weak fault models and stuck at strong fault models  and shown significant performance
improvements for multiple fault diagnoses  compared to two state of the art deterministic
algorithms  cda and ha   our results indicate that safari shows at least an order ofmagnitude speedup over cda and ha for multiple fault diagnoses  moreover  whereas the
search complexity for the deterministic algorithms tested increases exponentially with fault
cardinality  the search complexity for this stochastic algorithm appears to be independent
of fault cardinality 
we have compared the performance of safari to that of an algorithm based on maxsat  and safari shows at least an order of magnitude speedup in computing diagnoses 
we have compared the optimality of safari to that of an algorithm based on sls maxsat  and safari consistently computes diagnoses of smaller cardinality whereas the sls
max sat diagnostic algorithm often fails to compute any diagnosis 

   related work
this paper     generalizes feldman  provan  and van gemund      a       introduces important theoretical results for strong fault models      extends the experimental results
there  and     provides a comprehensive optimality analysis of safari 
on a gross level  one can classify the types of algorithms that have been applied to solve
mbd as being based on search or compilation  the search algorithms take as input the diagnostic model and an observation  and then search for a diagnosis  which may be minimal
with respect to some minimality criterion  examples of search algorithms include a  based
algorithms  such as cda  williams   ragno        and hitting set algorithms  reiter 
       compilation algorithms pre process the diagnostic model into a form that is more
efficient for on line diagnostic inference  examples of such algorithms include the atms
 de kleer        and other prime implicant methods  kean   tsiknis         dnnf  darwiche         and obdd  bryant         to our knowledge  all of these approaches adopt
exact methods to compute diagnoses  in contrast  safari adopts a stochastic approach to
computing diagnoses 
at first glance  it seems like mbd could be efficiently solved using an encoding as
a sat  jin et al          constraint satisfaction  freuder  dechter  ginsberg  selman   
tsang        or bayesian network  kask   dechter        problem  however  one needs to
   

fiapproximate model based diagnosis using greedy stochastic search

take into account the increase in formula size  over a direct mbd encoding   in addition to
the underconstrained nature of mbd problems 
safari has close resemblance to max sat  hoos   stutzle        and we have conducted extensive experimentation with both complete  partial and weighted  and sls based
max sat  as the results of these experiments are long  we have published them in a separate technical report  feldman  provan    van gemund      a   the results show that
although max sat can compute diagnoses in many of the cases  the performance of maxsat degrades when increasing the circuit size or the cardinality of the injected faults  in
particular  safari outperforms max sat by at least an order of magnitude for the class of
diagnostic problems we have considered  in the case of sls based max sat  the optimality
of max sat based inference is significantly worse than that of safari 
we show that safari exploits a particular property of mbd problems  called diagnostic
continuity  which improves the optimality of safari compared to  for example  straightforward allsat encodings  jin et al          we experimentally confirm this favorable
performance and optimality of safari  although safari has close resemblance to maxsat  safari exploits specific landscape properties of the diagnostic problems  which allow
    simple termination criteria and     optimality bounds  due to the hybrid nature of
safari  the use of ltms and sat   safari avoids getting stuck in local optima and performs better than max sat based methods  incorporating approaches from max sat  and
in particular saps  hutter  tompkins    hoos         in future versions of safari may
help in solving more general abduction problems  which may not expose the continuous
properties of the models we have considered 
stochastic algorithms have been discussed in the framework of constraint satisfaction
 freuder et al         and bayesian network inference  kask   dechter         the latter
two approaches can be used for solving suitably translated mbd problems  it is often the
case  though  that these encodings are more difficult for search than specialized ones 
mbd is an instance of constraint optimization  with particular constraints over failure
variables  mbd has developed algorithms to exploit these domain properties  and our
proposed approach differs significantly from almost all mbd algorithms that appear in the
literature  while most advanced mbd algorithms are deterministic  safari borrows from
sls algorithms that  rather than backtracking  may randomly flip variable assignments
to determine a satisfying assignment  complete mbd algorithms typically make use of
preferences  e g   fault mode probabilities  to improve search efficiency  safari uses this
technique on top of its stochastic search over the space of diagnoses 
a closely related diagnostic approach is that of fijany  vatan  barrett  james  williams 
and mackey         who map the minimal hitting set problem into the problem of finding
an assignment with bounded weight satisfying a monotone sat problem  and then propose
to use efficient sat algorithms for computing diagnoses  the approach of fijany et al  has
shown speedups in comparison with other diagnosis algorithms  the main drawback is the
number of extra variables and clauses that must be added in the sat encoding  which is
even more significant for strong fault models and multi valued variables  in contrast  our
approach works directly on the given diagnosis model and requires no conversion to another
representation 
our work bears the closest resemblance to preference based or cost based abduction
 cba   charniak   shimony        santos jr          of the algorithmic work in this
   

fifeldman  provan    van gemund

area  the primary paper that adopts stochastic local search is by abdelbar  gheita  and
amer         in this paper  they present a hybrid two stage method that is based on
iterated local search  ils  and repetitive simulated annealing  rsa   the ils stage of
the algorithm uses a simple hill climbing method  randomly flipping assumables  for the
local search phase  and tabu search for the perturbation phase  rsa repeatedly applies
simulated annealing  sa   starting each time from a random initial state  the hybrid
method initially starts from an arbitrary state  or a greedily chosen state  it then applies
the ils algorithm  if this algorithm fails to find the optimal solution after a fixed number
 of hill climbing steps  or after a fixed number r of repetitions of the perturbation local
search cycle   ils based search is terminated and the rsa algorithm is run until the optimal
solution is found 
our work differs from that of abdelbar et al         in several ways  first  our initial
state is generated using a random sat solution  the hill climbing phase that we use next
is similar to that of abdelbar et al   however  we randomly restart should hill climbing not
identify a better diagnosis  rather than applying tabu search or simulated annealing  our
approach is simpler than that of abdelbar et al   and for the case of weak fault models
is guaranteed to be optimal  in future work we plan to compare our approach to that of
abdelbar et al  for strong fault models 
in      safari competed against the diagnostic algorithms ngde  de kleer       
and rodon  bunus  isaksson  frey    munker        in the synthetic track of the first
diagnostic competition dxc    kurtoglu  narasimhan  poll  garcia  kuhn  de kleer  van
gemund    feldman         the conditions under which the dxc   experiments were
conducted were similar to the ones described in this paper  the cpu and memory performance of safari were an order of magnitude better than the competing algorithms despite
the fact that ngde and rodon performed better than the complete algorithms discussed
in this section  in this paper  in addition to computational metrics  we have informally
used the minimality of a diagnosis as an optimality criterion  the dxc   organizers  however  have defined a utility metric which approximates the expected repair effort of a circuit
 feldman  provan    van gemund      b   with this utility metric  safari scored slightly
worse than the two competing algorithms  which is to be expected as safari trades off
diagnostic precision for computational efficiency  we refer the reader to the dxc papers
mentioned above for a more thorough analysis of the competition results 

   conclusion and future work
we have described a greedy stochastic algorithm for computing diagnoses within a modelbased diagnosis framework  we have shown that subset minimal diagnoses can be computed
optimally in weak fault models and in an important subset of strong fault models  and that
almost all minimal cardinality diagnoses can be computed for more general fault models 
   hill climbing proceeds as follows  given a current state s with a cost of f  s   a neighbouring state s
is generated by flipping a randomly chosen assumable hypothesis  if f  s   is better than f  s   then s
becomes the current state  otherwise  it is discarded  if  iterations elapse without a change in the
current state  the local search exits 
   perturbation local search  starting from a current state s with a cost of f  s   randomly chooses an
assumable variable h  and applies tabu search to identify a better state by flipping h based on its tabu
status 

   

fiapproximate model based diagnosis using greedy stochastic search

we argue that safari can be of broad practical significance  as it can compute a significant fraction of minimal cardinality diagnoses for systems too large or complex to be
diagnosed by existing deterministic algorithms 
in future work  we plan to experiment on models with a combination of weak and strong
failure mode descriptions  we also plan on experimenting with a wider variety of stochastic
methods  such as simulated annealing and genetic search  using a larger set of benchmark
models  last  we plan to apply our algorithms to a wider class of abduction and constraint
optimization problems 

references
abdelbar  a  m          approximating cost based abduction is np hard  artificial intelligence                    
abdelbar  a  m   gheita  s  h     amer  h  a          exploring the fitness landscape and
the run time behaviour of an iterated local search algorithm for cost based abduction 
experimental   theoretical artificial intelligence                 
bayardo  r  j     pehoushek  j  d          counting models using connected components 
in proc  aaai    pp         
brglez  f     fujiwara  h          a neutral netlist of    combinational benchmark circuits
and a target translator in fortran  in proc  iscas    pp         
bryant  r  e          symbolic boolean manipulation with ordered binary decision diagrams  acm computing surveys                 
bunus  p   isaksson  o   frey  b     munker  b          rodon   a model based diagnosis
approach for the dx diagnostic competition  in proc  dx    pp         
bylander  t   allemang  d   tanner  m     josephson  j          the computational complexity of abduction  artificial intelligence           
charniak  e     shimony  s  e          cost based abduction and map explanation  artificial intelligence                 
cook  s  a          the complexity of theorem proving procedures  in proc  stoc    pp 
       
darwiche  a          model based diagnosis using structured system descriptions  journal
of artificial intelligence research            
davis  m   logemann  g     loveland  d          a machine program for theorem proving 
communications of the acm                
de kleer  j          an assumption based tms  artificial intelligence                 
de kleer  j          using crude probability estimates to guide diagnosis  artificial intelligence                 
de kleer  j          minimum cardinality candidate generation  in proc  dx    pp     
    
de kleer  j   mackworth  a     reiter  r          characterizing diagnoses and systems 
artificial intelligence                   
   

fifeldman  provan    van gemund

de kleer  j     williams  b          diagnosing multiple faults  artificial intelligence 
              
een  n     sorensson  n          an extensible sat solver  in proc  sat    vol       of
lecture notes in computer science  pp          springer 
eiter  t     gottlob  g          the complexity of logic based abduction  journal of the
acm              
feldman  a   provan  g     van gemund  a       a   computing minimal diagnoses by
greedy stochastic search  in proc  aaai    pp         
feldman  a   provan  g     van gemund  a       b   computing observation vectors for
max fault min cardinality diagnoses  in proc  aaai    pp         
feldman  a   provan  g     van gemund  a       a   a family of model based diagnosis
algorithms based on max sat  tech  rep  es          delft university of technology 
feldman  a   provan  g     van gemund  a       b   the lydia approach to combinational
model based diagnosis  in proc  dx    pp         
feldman  a     van gemund  a          a two step hierarchical algorithm for model based
diagnosis  in proc  aaai    pp         
fijany  a   vatan  f   barrett  a   james  m   williams  c     mackey  r          a novel
model based diagnosis engine  theory and applications  in proc  ieee aerospace   
vol     pp         
forbus  k     de kleer  j          building problem solvers  mit press 
freeman  j  w          improvements to propositional satisfiability search algorithms 
ph d  thesis  university of pennsylvania 
freuder  e  c   dechter  r   ginsberg  m  l   selman  b     tsang  e  p  k          systematic versus stochastic constraint satisfaction  in proc  ijcai    vol     pp           
friedrich  g   gottlob  g     nejdl  w          physical impossibility instead of fault
models  in proc  aaai    pp         
gomes  c  p   hoffmann  j   sabharwal  a     selman  b          from sampling to model
counting  in proc  ijcai    pp           
hansen  m   yalcin  h     hayes  j          unveiling the iscas    benchmarks  a case
study in reverse engineering  ieee design   test               
hermann  m     pichler  r          counting complexity of propositional abduction  in
proc  ijcai    pp         
hoos  h          sat encodings  search space structure  and local search performance  in
proc  ijcai    pp         
hoos  h     stutzle  t          stochastic local search  foundations and applications 
morgan kaufmann publishers inc 
hutter  f   tompkins  d  a  d     hoos  h  h          scaling and probabilistic smoothing 
efficient dynamic local search for sat  in proc  cp    pp         
   

fiapproximate model based diagnosis using greedy stochastic search

jin  h   han  h     somenzi  f          efficient conflict analysis for finding all satisfying
assignments of a boolean circuit  in proc  tacas    pp         
kask  k     dechter  r          stochastic local search for bayesian networks  in proc 
aistat    pp         
kean  a     tsiknis  g  k          clause management systems  computational intelligence 
        
kumar  t  k  s          a model counting characterization of diagnoses  in proc  dx   
pp       
kurtoglu  t   narasimhan  s   poll  s   garcia  d   kuhn  l   de kleer  j   van gemund  a  
  feldman  a          first international diagnosis competition   dxc    in proc 
dx    pp         
marques silva  j  p          the impact of branching heuristics in propositional satisfiability
algorithms  in proc  epia    pp       
mcallester  d  a          truth maintenance  in proc  aaai    vol     pp           
reiter  r          a theory of diagnosis from first principles  artificial intelligence         
     
roth  d          on the hardness of approximate reasoning  artificial intelligence           
       
santos jr   e          a linear constraint satisfaction approach to cost based abduction 
artificial intelligence              
smith  a   veneris  a   ali  m  f     viglas  a          fault diagnosis and logic debugging
using boolean satisfiability  ieee transactions on cad of integrated circuits and
systems                    
smith  a   veneris  a     viglas  a          design diagnosis using boolean satisfiability 
in proc  asp dac    pp         
struss  p     dressler  o          physical negation   integrating fault models into the general diagnostic engine  in readings in model based diagnosis  pp          morgan
kaufmann publishers inc 
thiffault  c   bacchus  f     walsh  t          solving non clausal formulas with dpll
search  in proc  cp    pp         
tseitin  g          on the complexity of proofs in propositional logics  in siekmann  j    
wrightson  g   eds    automation of reasoning  classical papers in computational
logic             vol     springer verlag 
williams  b     ragno  r          conflict directed a  and its role in model based embedded systems  journal of discrete applied mathematics                     
zhang  h     stickel  m  e          an efficient algorithm for unit propagation  in proc 
ai math    pp         

   

fi