journal artificial intelligence research                  

submitted        published      

cause identification aviation safety incident reports
via weakly supervised semantic lexicon construction
muhammad arshad ul abedin
vincent ng
latifur khan

arshad student utdallas edu
vince hlt utdallas edu
lkhan utdallas edu

department computer science
erik jonsson school engineering   computer science
university texas dallas
    w  campbell road  ms ec  
richardson  tx       u s a 

abstract
aviation safety reporting system collects voluntarily submitted reports aviation safety incidents facilitate research work aiming reduce incidents  effectively reduce incidents  vital accurately identify incidents occurred 
precisely  given set possible causes  shaping factors  task cause identification involves identifying shaping factors responsible
incidents described report  investigate two approaches cause identification 
approaches exploit information provided semantic lexicon  automatically constructed via thelen riloffs basilisk framework augmented linguistic
algorithmic modifications  first approach labels report using simple heuristic  looks words phrases acquired semantic lexicon learning
process report  second approach recasts cause identification text classification problem  employing supervised transductive text classification algorithms
learn models incident reports labeled shaping factors using models
label unseen reports  experiments show heuristic based approach
learning based approach  when given sufficient training data  outperform baseline
system significantly 

   introduction
safety paramount importance comes aviation industry       alone 
     incidents    including    fatal accidents     casualties    improve
aviation safety situation  aviation safety reporting system  asrs  established
     make safety incident data available researchers  asrs collects voluntarily submitted reports aviation safety incidents written flight crews  attendants  controllers
related parties  reports contain number fixed fields free text narrative describing incident  however  data grown quite large years
getting increasingly difficult  impossible  analyze reports human
means  become necessary reports analyzed automated means 
   http   asrs arc nasa gov 
   http   www flightsafety gov 
c
    
ai access foundation  rights reserved 

fiabedin  ng   khan

take full advantage data reduce safety incidents  necessary extract
reports happened why  known  possible
identify correlations incidents causes  take fruitful measures
toward eliminating causes  however  fixed fields reports devoted various
aspects happened incidents  fixed field indicates
incidents causes  instead  reporter discusses report narrative thinks
caused incident  along incident description  thus cause incident
extracted analyzing free text narrative  example  report shown next
illustrate task 
report         descending lit encountered instrument meteorological conditions  rime ice  rain  moderate chop  turned
heading auto pilot direct lit attitude indicator remained
bank  xchking  noticed radio magnetic indicators    degree
headings  switched    corrected course  auto pilot flight
director kicked off  continued problems altitude select
auto pilot attempted re engage it  radar vectors
approach descent      feet noticed altitude      feet
mean sea level  stopped descent climbed      feet mean sea
level  air traffic control noted altitude deviation time noticed 
thankful backup time flight director problems
cockpit  occurred end    hour crew day  bad weather  instrument problems  lack crew rest  first officer  pilot flying 
right seat    hours rest due inability go sleep
night before  tired trip lit orl lit  eaten
  hours  
posse et al         identify    important cause types  shaping factors 
influence occurrence aviation safety incident described asrs report 
shaping factors contextual factors influenced reporters behavior
incident thus contributed occurrence incident  factors
attributed humans  e g   pilot flight attendant psychological pressure 
overly heavy taskload  unprofessional attitude impacts performance  
related surrounding environment  e g   physical environment snow 
communication environment auditory interference   detailed description
   shaping factors found section     
report  find incident influenced three shaping factors 
namely physical environment  which concerns bad weather  mentioned above   resource
deficiency  which concerns problems equipment   duty cycle  which refers
physical exhaustion due long hours duty without adequate rest replenishment  
three shaping factors indicated different words phrases report 
instance  bad weather condition expressed using phrases rime ice  rain
moderate chop  details equipment problem appear sentence fragments
   improve readability  report preprocessed original form using steps described
section     

   

ficause identification via weakly supervised semantic lexicon construction

attitude indicator remained bank     degree headings flight director problems 
issue long hours duty illustrated sentence fragments    hour
crew day tired trip  goal cause identification task aviation
safety domain  then  identify    shaping factors contributed incident
described report using lexical cues appearing report narrative 
however  mentioned earlier  sheer volume data makes prohibitive
analyze reports manually identify associated shaping factors  thus 
focus research automated cause identification asrs reports  involves
automatically analyzing report narrative identifying responsible shaping factors 
brings problem domain natural language processing  nlp  
since set texts  i e   report narratives  set possible labels
texts  i e   shaping factors   task naturally cast text classification
task  however  unlike topic based text classification  cause based text classification
addressed extensively nlp community  previous work causal analysis quite
different nature cause based text classification task  specifically  previous
cause analysis works involve text classification  focusing instead determining
existence causal relation two sentences events  instance 
work causal analysis question answering  question may involve
cause s  event  e g   kaplan   berry rogghe        garcia        khoo  chan    niu 
      girju         here  focus finding causal relationship two sentence
components  another example  causal analysis equipment malfunction reports
attempted grishman ksiezyk         whose work restricted analysis
reports related one specific piece equipment studied  analyze cause effect
relations events leading malfunction described reports 
cause identification aviation safety reports rather challenging problem 
result number factors specific asrs dataset  first  unlike many nlp problems
underlying corpus composed set well edited texts newspaper
reports  reviews  legal medical documents    asrs reports mostly written
informal manner  since edited except removing author identity
information  reports tend contain spelling grammatical mistakes  second 
employ large amount domain specific acronyms  abbreviations terminology  third 
incident described report may caused one shaping factor 
thus reports multiple shaping factor labels  making task challenging
binary classification  even multi class problems instance one
label  all  scarcity labeled data task  coupled highly imbalanced
class distributions  makes difficult acquire accurate classifier via supervised learning 
previous work cause identification asrs reports done primarily
researchers nasa  see posse et al         and  knowledge  involved manual
analysis reports  specifically  nasa brought together experts aviation safety 
human factors  linguistics english language participate series brainstorming
sessions  generated collection seed keywords  simple expressions template
expressions related shaping factor  labeled reports shaping
factors looking related expressions report narrative  however 
   recently  work started processing blogs  may grammatical either  blogs
typically full domain specific terminology 

   

fiabedin  ng   khan

major weakness associated approach  involves large amount human effort
identifying relevant keywords expressions  yet resulting list keywords
expressions means exhaustive  moreover  evaluated approach
   manually labeled reports  small scale evaluation means satisfactory
judged current standard nlp research  one contributions research
annotation      asrs reports shaping factors  serve standard
evaluation dataset different cause identification methods compared 
paper  investigate two alternative approaches cause identification 
exploit information provided automatically constructed semantic lexicon 
specifically  view large amount human involvement nasas work 
aim replace manual selection seed words bootstrapping approach
automatically constructs semantic lexicon  specifically  motivated thelen riloffs
       basilisk framework  learn semantic lexicon  consists set words
phrases semantically related shaping factors  follows  starting small
set seed words phrases  augment seeds iteration automatically
finding fixed number words phrases related seeds corpus adding
seed list  importantly  however  propose four modifications
basilisk framework potentially improve quality generated lexicon 
first linguistic modification  addition using parse based features  e g   subjectverb verb object features  basilisk  employ features computed
robustly  e g   n grams   remaining three algorithmic modifications
basilisk framework  involving     use probabilistic semantic similarity measure     
use common word pool      enforcement minimum support maximum
generality constraints words extraction patterns  favors addition
frequently occurring content bearing words disfavors overly general extraction patterns 
mentioned above  investigate two approaches cause identification exploit
automatically learned semantic lexicon  first approach heuristic approach 
which  motivated posse et al          labels report shaping factor contains
least word phrase relevant shaping factor  unlike posse et al s
work  relevant words phrases employed heuristic procedure
manually identified  automatically acquire words phrases via semisupervised semantic lexicon learning procedure described above  second approach
machine learning approach somewhat orthogonal nasas approach  instead
human identify seed words phrases relevant shaping factor 
humans annotate small subset available incident reports shaping
factors  apply machine learning algorithm train classifier automatically
label unseen report  using combinations n gram features words phrases
automatically acquired aforementioned semantic lexicon learning procedure 
see  acquire cause identifier using support vector machines  svms  
shown effective topic based text classification  since small
number labeled reports  attempt combine labeled unlabeled reports using
transductive version svms 
since approaches rely simple linguistic knowledge sources involve n grams
words phrases automatically acquired semantic lexicon learning procedure  one may argue use simple features sufficient cause
   

ficause identification via weakly supervised semantic lexicon construction

identification  important point means arguing
features sufficient cause identification  however  use simple features
relevant task motivated work performed nasa researchers 
who  mentioned above  manually identified seed words phrases shaping
factor  posse et al          semantic lexicon learning procedure precisely aims learn
words phrases  error analysis reveals simple linguistic features
sufficient learning cause identification  and sophisticated knowledge
sources needed improve performance   one first attempts tackle cause
identification task  believe use simple features good starting point
establishes baseline future studies domain specific problem
compared 
evaluate aforementioned two approaches manually annotated asrs reports  experiments show number interesting results  first  best performance
achieved using heuristic approach  label report basis presence
automatically acquired lexicon words phrases report  achieving f measure
        importantly  method significantly surpasses performance
baseline system  labels report basis presence small set manually
identified seed words phrases  results suggest employing automatically
acquired semantic lexicon relevant useful cause based text classification
asrs reports  second  words phrases learned semantic lexicon  used
features training svms classification approach  improve performance
svm classifier trained solely n gram based features amount
training data small  however  increase amount training data  by crossvalidation   using lexicon words phrases features addition unigrams
bigrams helps improve classifier performance statistically significantly  particular 
observed f measure        svm classifiers using combination
unigrams  bigrams lexicon words phrases features  results confirm
words phrases learned semantic lexicon relevant valuable
features identifying responsible shaping factors  nevertheless  magnitude
improvement indicates still much room improvement  may
achieved using deeper semantic features 
summary  believe work automated cause identification makes five
primary contributions 
show instead manually analyzing incident reports identify
relevant shaping factors  possible reduce amount human effort required
task manually analyzing small subset reports identifying
shaping factors rest reports using automated methods 
propose several modifications thelen riloffs        semi supervised lexicon learning framework  show modified basilisk framework allows us
acquire semantic lexicon yields significantly better performance cause
identification original basilisk framework  equally importantly  none
modifications geared towards cause identification task  hence
applicable generally semantic lexicon learning task  fact  addi   

fiabedin  ng   khan

tional experiments suggest modified basilisk yields better accuracy original
basilisk bootstrapping general semantic categories 
show semantic lexicon learning useful cause identification asrs
reports  particular  words phrases learned semantic lexicon
profitably used improve heuristic based approach learning based
approach  when given sufficient training data  cause identification  addition 
believe similar cause identification task causes described
text  may useful learn semantic lexicon containing key words
phrases related different types possible causes use key words
phrases features machine learning 
attempt deduce weaknesses approaches help direct future
research  performed analysis errors made best performing
system  namely heuristic approach using semantic lexicon learned
modified basilisk method randomly chosen subset test reports 
manually annotated subset reports relevant shaping factors 
set annotated reports  made publicly available  serve
standard evaluation set task future research comparing
approaches cause identification 
rest paper organized follows  section    discuss dataset 
shaping factors  reports preprocessed annotated  section   defines
baseline  simply looks small set manually extracted seed words
phrases report narratives  section    describe semantic lexicon learning
procedure  based basilisk lexicon learning procedure  thelen   riloff 
      augmented modifications  section    discuss heuristic based
learning based approaches cause identification  evaluate two approaches
section   discuss related work section    finally  section    summarize
conclusions discuss future work 

   dataset
dataset used research aviation safety incident reports publicly available
website aviation safety reporting system    used         reports collected period january      december       report contains
free text narrative written reporter several fixed fields incident
time place incident  environment information  details aircrafts
involved  reporting persons credentials  details anomaly  detector  resolution
consequence incident itself  description situation  words 
fixed fields report contain various information happened 
physical circumstances  cover incident took place  discussed
posse et al         ferryman  posse  rosenthal  srivastava  statler        
narrative report contains information shaping factors incident 
   available http   asrs arc nasa gov search database html

   

ficause identification via weakly supervised semantic lexicon construction

reason  decided analyze free text narrative report using nlp techniques identify shaping factor s  incident may be  constructed
corpus task combining narratives         reports 
    shaping factors
incidents described asrs reports happen variety reasons  posse et al 
       focus    shaping factors  simply shapers  following short description
shaping factors  taken verbatim work posse et al  
   attitude  indication unprofessional antagonistic attitude controller
flight crew member 
   communication environment  interferences communications cockpit
noise  auditory interference  radio frequency congestion  language barrier 
   duty cycle  strong indication unusual working period e g   long day  flying
late night  exceeding duty time regulations  short inadequate rest
periods 
   familiarity  indication lack factual knowledge  new unfamiliar company  airport  aircraft 
   illusion  illusions include bright lights cause something blend in  black hole 
white out  sloping terrain 
   physical environment  unusual physical conditions could impair flying
make things difficult  unusually hot cold temperatures inside cockpit 
cluttered workspace  visual interference  bad weather  turbulence 
   physical factors  pilot ailment could impair flying make things difficult  tired  fatigued  drugged  incapacitated  influenced alcohol 
suffering vertigo  illness  dizziness  hypoxia  nausea  loss sight  loss hearing 
   preoccupation  preoccupation  distraction  division attention creates
deficit performance  preoccupied  busy  doing something else  
distracted 
   pressure  psychological pressure  feeling intimidated  pressured  pressed
time  low fuel 
    proficiency  general deficit capabilities  inexperience  lack training 
qualified  current  lack proficiency 
    resource deficiency  absence  insufficient number  poor quality resource 
overworked unavailable controller  insufficient out of date chart  equipment malfunction  inoperative  deferred  missing equipment 
   

fiabedin  ng   khan

    taskload  indicators heavy workload many tasks once  shorthanded crew 
    unexpected  something sudden surprising expected 
    other  anything else could shaper  shift change  passenger discomfort  disorientation 
    preprocessing
semantic lexicon learning approach cause identification  need identify
    part of speech  pos  word text      phrases chunks
sentences      grammatical roles words governing words  ideally 
achieve high accuracies three tagging tasks  would manually annotate section
asrs corpus appropriate annotations  e g   pos tags  chunks  train
appropriate taggers tag rest corpus  however  laborintensive task  beyond scope paper  therefore  used publicly
available tools trained standard corpora three tasks  inevitable
produce accurate automatic annotations corpus  see 
caused problem task 
corpus  first identify sentence boundaries using tool mxterminator    second  run pos tagger crftagger  phan      b   uses penn
treebank tag set  marcus  santorini    marcinkiewicz         sentences detected
mxterminator  third  run chunker crfchunker  phan      a  tagged
text identify different types phrases  also  minipar parser  lin        run
sentences identify grammatical roles words  however  report text
preprocessed applying tools reasons described following paragraphs 
reports asrs data set usually informally written  using various domain
specific abbreviations acronyms  general  observed van delden gomez
        posse et al         ferryman et al          narratives tend written
short  abbreviated manner  tend contain poor grammar  also  text
converted upper case  following example narrative report 
taxiing ramp laf night  made wrong turn
crossed rwy        active time 
sign indicate rwy xing  clred directions xing  acft field
time  mention atis signs
construction ramp area  ctlr didnt question
us  brought sit crossed
active rwy  commuter ops   days hvy flying 
reduced rest  rwy signs busy last min commuter paper work changes  contributed rwy
incursion     hr day   hr flt time 
   ftp   ftp cis upenn edu pub adwait jmx   trained wall street journal corpus

   

ficause identification via weakly supervised semantic lexicon construction

reports need preprocessing nlp techniques applied them 
since off the shelf tools  e g   pos tagger  trained mixed case texts 
example  running crftagger  which trained wsj corpus correct cases 
first two sentences yield following 
   taxiing nnp from nnp the dt ramp nnp at in laf nnp at in
night nn    
   made nnp a dt wrong nnp turn nnp and cc crossed vbd
rwy nnp       cd     the dt active nnp at in the dt time nn    
seen  tagger mislabels words taxiing  from  made  wrong
active proper nouns  nnp   instead tagging verb  preposition  verb 
adjective adjective respectively  occurs good feature detecting proper
nouns sentence case first character  since words begin capital
letter  tagger mistakes significant portion words nnp  another reason
tagger performs poorly corpus lot abbreviations appear text 
example  xing hvy short crossing heavy  since
likely known pos tagger trained standard well edited corpus  would
identified unknown words  likely tagged nouns instead verb
adjective respectively  similar problems observed parsers chunkers 
reason  decided preprocess text expanding abbreviations
restoring cases words 
expand acronyms abbreviations  rely official list acronyms
abbreviations used asrs reports    small number cases  abbreviation
acronym may one expansion  example  arr may mean either arrival
arrive  cases arbitrarily chose one possibilities    then  restore case 
set english word lists  place names person names  applied text
identify known words  word report text appeared word lists 
converted lower case  unknown words left uppercase  result
process aforementioned narrative follows 
taxiing ramp laf night  made wrong turn crossed
runway        active time  sign indicate
runway crossing  cleared directions crossing 
aircraft field time  mention automatic terminal
information service signs construction ramp area 
controller didnt question us  brought situation
crossed active runway  commuter operations   days heavy flying 
   see http   akama arc nasa gov asrsdbonline pdf asrs decode pdf 
   better option would disambiguate alternative expansions based context  e g  
method followed banko   brill         however  number ambiguities acronyms
abbreviations list small      exact   either pos variations
word  thus effect ambiguities performance nlp tools expected
minimal 
   http   wordlist sourceforge net 

   

fiabedin  ng   khan

reduced rest  runway signs busy last minute commuter paper work
changes  contributed runway incursion     hour day   hour flight time 
ran pos tagger  crftagger  processed text observe
errors  example  tagged version aforementioned two sentences are 
   taxiing vbg from in the dt ramp nn at in laf nnp at in night nn    
   made vbn a dt wrong jj turn nn and cc crossed vbd runway nn       cd
    the dt active jj at in the dt time nn    
sentences correctly tagged  however  case restoration method
arguably simplistic  hence  determine need perform fine grained case
restoration  sought measure much would gain accurately restoring
case words sentences present heuristic method  check this 
randomly picked     sentences corpus  first ran pos tagger
sentences case restored aforementioned heuristic case restoration
method  then  manually corrected capitalization sentences re ran
pos tagger case restored sentences  tags thus generated compared 
found       agreement  means likely gain much terms
pos tagging accuracy correctly case restored text heuristically case restored
text  five differences      words  three nnps mislabeled nns 
essentially effect outcomes research  therefore  marginal utility
applying sophisticated case restoration methods seem enough justify
additional effort necessary  limit preprocessing step expansion abbreviations acronyms followed heuristic case restoration procedure described above 
complete flow preprocessing shown figure   
    human annotation procedure
recall need reports labeled shaping factors training cause identification classifiers testing performance two approaches cause identification 
additionally  order learn semantic lexicon via bootstrapping  need small set
seed words phrases related shaping factor starting point  result 
performing language normalization  performed two types annotations      labeling
set reports shaping factors      identifying set seed words phrases
reports  annotation procedure described detail following sections 
      annotating reports shaping factors
nasa previously developed heuristic approach tackle cause identification
task  posse et al          approach evaluated    manually annotated reports 
far satisfactory far establishing strong baseline method concerned 
thus decided annotate set reports evaluating automatic cause
identification methods 
complete set         reports  chose random set      reports
annotation  subset divided two parts  first part  consisting     reports 
   

ficause identification via weakly supervised semantic lexicon construction

figure    flow chart text preprocessing
annotated two persons  one undergraduate student one graduate student  
report  asked answer following question 
shaping factor s  responsible incident described report 
annotators trained similar way labeled    reports used
evaluation nasa researchers  see posse et al          specifically  background
reading  annotators referred works posse et al  ferryman et al         
describe shaping factors  give examples words
phrases indicate influence shaping factors described incidents 
definitions shapers repeated section      following posse et al s method 
annotators explicitly instructed adhere definitions much possible
annotating reports shaping factors  annotations completed 
inter annotator agreement computed using krippendorffs        statistics
described artstein poesio         using measuring agreement set valued
items  masi  scoring metric  passonneau         observed inter annotator agreement 
  case found       indicates reliable agreement     
reports  completely agreed annotations    reports  completely disagreed
    reports partially agreed    reports  annotators asked discuss
discrepancies  discussion  found discrepancies could
   

fiabedin  ng   khan

primarily attributed vagueness descriptions shaping factors posse et
al s paper  interpreted differently two annotators 
annotators agreed descriptions shapers interpreted 
resolved differences annotation  discussion  remaining     
reports annotated one annotators  annotator asked
annotate subset reports      reports  cross verification purpose    
inter annotator agreement    case observed            reports
annotated first annotator divided three sets  training set      reports 
training cause identification classifiers  held out development set      reports 
parameter tuning  test set       reports  evaluating performance
approaches cause identification  distribution shaping factors training 
development test sets shown second  third fourth columns table   
      extracting seed words phrases
separate process  first author went first     reports annotators
worked on  selected words phrases relevant shaping factors 
judgment whether word phrase relevant shaping factor based careful
reading description shaping factors works posse et al        
ferryman et al          well example seed words selected nasa experts
shown two papers  specific task case was 
report  word phrase indicative
shaping factors  is  identify assign appropriate
shaping factor 
note seed words phrases chosen without regard shaping factor
annotation document  picked possibility relevant
respective shaping factors  number seed words phrases shaping
factor shown last column table    see      seed words phrases
manually selected     training reports  completeness  show
seed words phrases extracted reports appendix a  facilitate
research topic  annotated data used research made available
http   www utdallas edu  maa       asrs html 
since gold standard compare list annotated
words phrases  difficult directly compute precision  however  get rough
idea precision  asked one annotators examine list identify
words phrases list believes correct  disagreement
one word  yields precision         provides suggestive evidence
annotation fairly reliable  manually identified words phrases
used baseline cause identification system  see section    served seeds
semantic lexicon learning procedure  see section    
    fairly standard procedure nlp research cross annotate subset data
complexity cost individual annotation high  see works zaidan  eisner  piatko       
kersey  di eugenio  jordan  katz         instance 

   

ficause identification via weakly supervised semantic lexicon construction

table    distribution shaping factors training  test development sets
shaping factor
reports reports
reports
seed
training set
test set development words
test set
attitude
  
  
 
 
communication environment
  
  
  
 
duty cycle
 
  
 
  
familiarity
  
  
 
 
illusion
 
 
 
 

  
   
  
 
physical environment
  
   
  
  
physical factors
  
  
 
 
preoccupation
  
   
  
 
pressure
 
  
 
  
proficiency
  
   
  
  
resource deficiency
   
   
  
  
taskload
 
  
 
 
unexpected
 
  
 
 
total
   
    
   
   

   baseline system cause identification
discussed introduction  goal research label incident reports
shaping factors caused incidents  evaluate performance cause
identification methods  need baseline uses amount training data
methods described paper performs reasonably well test set 
given cause identification relatively new under investigated task  standard
baseline adopted task  fact  knowledge  related works
cause identification aviation safety domain conducted researchers
nasa  see posse et al         ferryman et al          result  construct baseline
system motivated posse et al s work  specifically  baseline takes input set
seed words phrases manually collected shaping factors  see section        
labels report occurrence heuristic  seed word phrase found
report  baseline annotates report shaping factor associated
seed  example     hour duty day seed phrase associated shaping
factor duty cycle  then  occurrence heuristic label report contains
phrase    hour duty daywith duty cycle  approach simple attractive
    need training      evaluated easily  searching
seed words narrative report labeled      report potentially
labeled one shaping factors  seed words phrases indeed
relevant respective shaping factors  identify reports related
shaping factors high degree precision 
   

fiabedin  ng   khan

   semantic lexicon learning
described section    baseline uses seed words phrases manually extracted
    reports combination occurrence heuristic label reports
shaping factors  however  reports used evaluation may contain exactly
words phrases  may contain different variations  synonyms  words
phrases semantically similar seed words phrases  thus baseline
may able label reports correctly looking words phrases
seed words list 
address potential problem  propose use semantic lexicon learning algorithms learn words phrases semantically similar seed words phrases
reports corpus containing narratives         reports  using weakly supervised bootstrapping algorithm may allow us learn large number useful words
phrases corpus would required huge amounts human effort
done manually  below  first describe general bootstrapping approach section     
then  section      describe basilisk framework learning semantic lexicon
unannotated corpus  thelen   riloff         finally  section      discuss
modifications basilisk framework 
    weakly supervised lexicon learning
mentioned earlier  employ weakly supervised bootstrapping approach building
semantic lexicon  use manually extracted seed words phrases
shaping factor  described section        create initial semantic lexicon 
select words phrases unannotated reports semantically similar
words already appearing semantic lexicon  reports corpus need
labeled shaping factors  semantic similarity two words measured
using features extracted corpus word  process repeated iteratively 
iteration  certain number words added semantic lexicon 
words augmented lexicon used seeds following iteration 
process shown figure   

figure    flow chart lexicon learning procedure

   

ficause identification via weakly supervised semantic lexicon construction

    basilisk framework
basilisk  bootstrapping approach semantic lexicon induction using semantic knowledge 
instantiation aforementioned generic semantic lexicon learning framework  thelen   riloff         basilisk framework works first identifying patterns
extracting noun phrases corpus appear one three syntactic roles 
subject  direct object  prepositional phrase object  example  discussed thelen riloff  sentence john arrested collaborated smith
murdered brown  extraction patterns  subject  arrested  extracts
john  murdered  object  extracts brown collaborated  pp object 
extracts smith  then  semantic category sk   pattern pool constructed
patterns tend extract words sk   measure tendency pattern pj
extract words sk   r log f metric used  defined as 
r log f  pj    

fj
log  fj  
nj

   

here  fj number  distinct  words sk pattern pj extracts  nj
total number  distinct  words corpus pj extracts  metric high
high precision patterns  i e   patterns extract primarily words sk   high recall
patterns  i e   patterns extract large number words sk    iteration i 
top       i  patterns  in terms r log f scores  put pattern pool sk  
depleted patterns  i e   patterns extracted words already semantic
lexicon  considered step  then  head nouns phrases extracted
resulting patterns pattern pool put word pool sk  
next  subset words word pool selected added seed words
list  words word pool chosen relevant sk  
specifically  word wi word pool sk   first avglog score calculated 
defined follows 

avglog  wi   sk    

w
pi
x

log   fj     

j  

w pi

   

here  w pi number patterns extract word wi   pattern pj
extracts wi   fj number words extracted pj belong sk   then 
semantic category sk   five words chosen highest avglog score
category sk  
multi category learning  thelen riloff        experimented different scoring metrics reported achieved best performance calculating diff
score word  given word word pool semantic category  diff
score takes consideration score word gets categories  returns
score based words score semantic category relative categories 
precisely  diff score defined follows 
dif f  wi   sk     avglog  wi   sk   max  avglog  wi   sl   
l  k

   

   

fiabedin  ng   khan

here  sk semantic category wi evaluated  thus diff score
high strong evidence wi belongs semantic category sk little evidence
belongs semantic categories  semantic category  diff score
calculated word categorys word pool  top five words
highest diff score added lexicon category  two additional checks
made stage      word word pool added category
earlier iteration  word discarded      word found
one word pool added category highest score    
completed semantic categories  iteration ends  next iteration
begins augmented lexicon 
    modifications basilisk framework
see later subsection  analysis framework reveals
cases words selected basilisk may relevant ones  reason 
propose three algorithmic modifications basilisk framework      using new semantic
similarity measure      merging word pools one single pool assigning words
semantic categories      imposing minimum support maximum generality criteria
patterns words added pattern pools word pools  addition  propose
one linguistic modification  employ type feature computed
robust manner words phrases corpus  namely  n gram features 
rest subsection discusses modifications 
      modification    new semantic similarity measure
seen section      basilisk framework uses avglog scoring function measure
semantic similarity words  diff score multi category learning uses
avglog function compute evidence word belonging semantic category
relative categories  however  closer examination avglog function shows
may able properly predict semantic similarity circumstances 
understand reason  let us first make following observations  pattern pj occurs
     times  extracts words category sk   times  unlikely pj strongly
related sk   similarly  word wi occurs      times  extracted pattern pj  
times  pj small influence classification wi   however  avglog score
able take factors consideration  precisely considers
absolute number semantic category members extracted patterns extract
word frequency extraction  see case  let us consider
word wi extracted three patterns p    p  p    frequencies shown
table    p    p  p  extract five distinct seed words  avglog score
word w would       irrespective fact patterns actually extract word
seed words list tiny fraction occurrence corpus  p  extracts
seed word    occurrence  p     time  p    pattern extracts w
often  extracts lexicon word      times appears text  clearly 
    approach effectively assumes word belong one category  reasonable
assumption specific task since shaping factors distinct meanings 

   

ficause identification via weakly supervised semantic lexicon construction

patterns would suggest wi related semantic category  yet gets
good score 
table    illustration problem avglog  unrelated words may high
similarity score  wi word appears corpus extracted
patterns p    p  p 

patterns extract wi
number times wi extracted pattern pj
number times pattern pj occurs text
number times word category sk extracted pattern pj
number category words extracted pattern pj
log   fj     
avglog  wi  

p 
  
   
 
 
    

p 
p 
  
  
        
 
 
 
 
         
    

keeping mind  propose probabilistic metric  semprob  computes
probability word wi belongs semantic category sk given extracted
patterns p    p            pn   specifically  semprob calculated follows 
semp rob  wi   sk     p rob  sk  wi  
x
 
p rob  sk  pj   p rob  pj  wi  

   

pj

words  semprob assumes semantic category sk word wi
conditionally independent given pj   pattern extracts wi   probabilities
equation estimated using maximum likelihood estimation corpus  specifically 
compute p rob  pj  wi    divide number times pj extracts wi corpus
total number times wi appears corpus  compute p rob  sk  pj    divide
number times pj extracts word semantic category sk total number
times pj appears corpus  given word wi given semantic category
sk   sum products two quantities patterns extract wi
gives probability category sk given word wi   method suffer
problem faced avglog since depends probability word extracted
patterns patterns probability extracting words category 
example table    semprob metric word wi         illustrating
low probability wi belonging semantic category sk is  details given
table   
      modification    common word pool
since compute eqn     every word word pool categories
assign word semantic category probability highest  change
framework one common word pool semantic categories 
   

fiabedin  ng   khan

table    illustration effectiveness semprob  unrelated words get low similarity
score 

patterns extract wi
number times wi extracted pattern pj
number times pattern pj occurs text
number times word category sk extracted pattern pj
p rob  wi extracted pj  
p rob  pj extracts word sk  
p rob  wi extracted pj   p rob  pj extracts word sk  
semp rob  wi   sk     p rob  wi belongs semantic category sk  

p 
  
   
 
   
    
     

p 
p 
  
  
   
    
 
 
   
   
    
     
            
      

still separate pattern pools different semantic categories  words related
patterns pattern pools put common word pool  allocated
probable semantic category there  separate word pools
semantic category  add fixed number words category
iterations  constraint may undesirably cause word added category
likely  however  since one word pool modification 
constraint add fixed number words category 
assign word likely category  thus number words added
different categories may vary iteration 
      modification    minimum support maximum generality
scenarios semprob metric produce undesirable results 
example  consider infrequent word wi occurs entire corpus exactly once 
assume pattern pj   extracts wi   extracts words semantic category sk
    probability  so  according semprob  probability wi belongs sk becomes
     however  sufficient evidence wi belongs sk   cases
uncommon  imposed minimum word frequency constraint words
put word pool  words appear less certain number times
considered  pattern appears infrequently corpus lead
problem  consider infrequent pattern  pj   appears exactly twice corpus
extracts two words  one words happen seed word 
word     probability belong category seed word pj
r log f value      however  since pj infrequent  convey good evidence
membership semantic category  allow pj put words
word pool  therefore  disallow low frequency patterns included
pattern pool adding constraint patterns put pattern pool must
minimum pattern frequency  besides two constraints imposed frequency
occurrence words patterns  employ two additional constraints  first
   

ficause identification via weakly supervised semantic lexicon construction

maximum pattern generality constraint  motivated rychly kilgarriff        
remove consideration patterns general  i e   patterns extract
many words   imposing upper limit number distinct words pattern
added pattern pool extract  second maximum word frequency
constraint  since content bearing words likely lower frequency  see davidov
  rappoport         impose upper limit maximum number times word
appears corpus  four thresholds associated four frequency based
constraints tuned automatically using held out development set 
      modification    n gram patterns
addition parse tree based subject verb verb object patterns already employed
basilisk  employ n gram based extraction patterns  goal robustly capturing context words appear  construct n gram extraction
patterns follows  noun adjective  x  corpus  create two n gram
patterns extracting x   a  preceding n words   hxi   b  hxi   succeeding
n words  example  sentence     solid line thunderstorms detected     
bigram patterns thunderstorms would be  line hxi hxi detected 
complete sentence approaching atl area solid line thunderstorms
detected vicinity airport  words extracting bigram patterns
would be 
atl  approaching hxi  hxi area
area  atl hxi  hxi solid
solid  area hxi  hxi line
line  solid hxi  hxi thunderstorms
thunderstorms  line hxi  hxi detected
vicinity  hxi  hxi
airport  hxi
addition constructing n gram patterns extracting words  construct
n gram patterns extracting phrases  so  first remove articles  a  an  the 
possessive pronouns adjectives  e g   my  his  beginning phrases
corpus  noun phrase adjective phrase  x  appears corpus 
create two n gram patterns extracting x   a  preceding n words   hxi   b 
hxi   succeeding n words  example  sentence last   legs
approaching end   hour duty day   hour hard time flying day  would
extract following phrases following bigram patterns 
  legs  last hxi  hxi approaching
end  approaching hxi  hxi
   

fiabedin  ng   khan

  hour duty day  end hxi  hxi  
  hour hard time flying day  day hxi
thus use three types patterns experiments  bigram patterns extracting
words  bigram patterns extracting phrases  parse tree based subject verb verbobject patterns  patterns generated reports corpus generated
combining narratives         unlabeled reports described section     
see  three types patterns beneficial use far performance
concerned  section    show automatically select best subset
patterns use based development set 

   semantic lexicon based approaches cause identification
asrs reports
investigate heuristic based approach learning based approach cause identification  exploit information provided automatically acquired semantic
lexicon  section describes details two approaches 
    heuristic based approach
heuristic based approach operates essentially way baseline cause
identification system described section    occurrence heuristic used label
report shaping factors  difference words phrases used
occurrence heuristic baseline manually identified  whereas
heuristic based approach acquired modified basilisk procedure 
    learning based approach
learning based approach cause identification problem recast classification task  note multi class multi labeled classification task    
classes report labeled one class  number approaches
proposed tackle multi class multi labeled classification tasks  rest
section  describe three existing approaches multi class multi labeled text classification explore experiments  section         provide overview
theory support vector machines  svms   underlying learning algorithm use
train classifiers employed three approaches  section        
      three approaches multi class multi labeled text classification
one versus all  approach  train one binary classifier shaping factor
sk determine whether report labeled sk   specifically  follow
one versus all classification scheme  given sk   reports training set
contains sk set labels  assigned annotator  positive instances
binary classifier rest reports training set negative instances 
training  apply classifiers report test set independently
reports  label report sk corresponding classifier classifies
   

ficause identification via weakly supervised semantic lexicon construction

report positive  thus convert cause identification multi class multi labeled
document classification task 
learning algorithm used principle train classifiers oneversus all scheme  use support vector machines   training testing classifiers 
primarily due successes various text classification tasks  classifier trained
two types features      unigrams bigrams report narratives     
words phrases semantic lexicon  feature values tf idf values 
shaping factor labeled data set      reports substantially larger
set    reports annotated nasa researchers  see section     arguably fairly
small machine learning perspective  hence  conceivable performance
svm classifiers would limited small size training data  result 
investigate whether improve one versus all approach using transductive
svm  version inductive svm described attempts improve
classifier performance combining labeled unlabeled data  see section      
overview transductive learning   cause identification task  unlabeled
reports test set serve unlabeled data transductive learning procedure 
metalabeler  second approach  employ metalabeler  tang  rajan    narayanan 
      classifying multi class multi labeled text data  here  model first learned
predicts number labels instance may have  addition  set binary classifier models  one possible label  learned predict likelihood label
instance  instance classified  first model predicts k  number
possible labels instance  output second set classifiers  k
labels chosen highest likelihood instance 
implementation approach  first model learned using svmmulticlass  
implementation multi class svm described crammer singer           
second set classifiers set described section        case 
given instance x  decision functions f  x    w x b classifiers
evaluated  positive decision values sorted  top k labels corresponding
highest values decision functions assigned instance 
multiclass classifier set binary classifiers trained using types
features one versus all approach  namely unigrams bigrams reports 
words phrases semantic lexicon  feature values
one versus all approach  namely tf idf values 
ensembles pruned sets  pruned sets approach  read  pfahringer    holmes 
       multi class multi label text classification problem transformed multiclass single label text classification problem selecting subset label combinations
frequently occurring dataset assigning unique pseudo label chosen
label combination 
first step algorithm choose label sets training  step 
label sets chosen meet minimum frequency requirement training
set  using minimum frequency constraint prunes away infrequently occurring label sets
frequency less p  leaving label combinations frequent thus
    implemented svmlight software package joachims       
    available http   svmlight joachims org svm multiclass html

   

fiabedin  ng   khan

important  training instances labeled pruned label sets
removed training set  minimum cardinality parameter  b  used
reintroduce pruned instances back training set order minimize
information loss pruning process  first label sets rejected instances
broken smaller subsets least size b  new subsets
frequency higher p reintroduced  pruned training instances whose label
sets supersets newly accepted label sets reinstated training set 
role parameter b case ensure many instances small
label sets put back  cause average number labels reduce 
resulting smaller number labels per instance classification time 
next step learn classifiers selected label sets  first  accepted label
set assigned unique pseudo label  thus transforming multi label classification problem single label classification problem  ensemble classifiers learned
predict pseudo labels given instance  using multi class svm implementation metalabeler   classifier ensemble trained different
random sample training data  since     label sets training classifiers
represent subset label combinations present original training data
    test data may contain label combinations present training
data  ensemble classifiers allows system generate label combinations
observed training time  example  let label combinations  l    l     l    l   
present training data  then  one classifier ensemble labels test instance
 l    l    another classifier ensemble labels instance  l    l    
instance may labeled  l    l    l     depending actual voting policy
effect classification time  even combination present training data 
classifiers ensemble built using two types features one versusall approach  namely unigrams bigrams reports words phrases
semantic lexicon learned modified basilisk framework 
finally  classifying instance  classifiers assigns one pseudo label
instance  pseudo labels mapped back original label combination
vote actual label counted normalized dividing number
classifiers    order bring prediction possible label range
         threshold used label prediction value
greater equal assigned instance  scheme used make possible
assign label combinations unseen training time test instances 
      overview support vector machines
svms shown effective text classification  joachims        
describe two versions svms      inductive svms  learn classifier solely
labeled data      transductive svms  learn classifier labeled
unlabeled data 
inductive svms  given training set consisting data points belonging two classes 
inductive svm aims find separating hyperplane maximizes distance
separating hyperplane nearest data points  nearest data points act
support vectors plane 
   

ficause identification via weakly supervised semantic lexicon construction

formally  let data set data points
    xi   ci    xi rn   ci            m 

   

point xi represented n dimensional vector associated class label
ci   inductive svm classifier attempts find hyperplane w x b    
maximum distance nearest data points opposite labels  hyperplane would
middle two hyperplanes containing support vectors class 
 
  therefore 
two hyperplanes wxb     wxb      distance  w 
desired separating hyperplane found solving following quadratic programming
optimization problem 
minimize
subject

 
 w  
 
ci  w xi b      

   

however  practice many classes linearly separable  handle cases  set
slack variables used represent misclassification point xi   problem
becomes 
x
 
 w     c

minimize
 


subject

ci  w xi b            

   

additional variables representing training errors c constant representing trade off training error margin  details found cortes
vapnik         experiments  use radial basis function  rbf 
kernel 



 
every dot product replaced function k  x  x     exp  x  x         
addition  c chosen cross validation training set 
transductive svms  transductive setting  addition set labeled data
points  exploit set unlabeled data points     xi  xi rn     k  
taken test set  described joachims         goal minimize
expected number classification errors test set  expected error rate
defined vapnik        follows 
z
 x
   
 hl  xi     ci   dp  x    c          dp  xk   ck  
r  l   
k


l     hl hypothesis learned l   a  b  zero   b
one otherwise  labeling ci test data hyperplane maximizes
separations training testing positive negative instances found solving
following quadratic programming optimization problem  modified version
eqn     
x
x
 
j
 w     c
  c
minimize
 


subject

j

ci  w xi b            

cj w xj b   j   j        j k
   

   

fiabedin  ng   khan

similar inductive svm section        use rbf kernel experiments
involving transductive svm 

   evaluation
goal evaluation study effectiveness two approaches cause identification  namely semantic lexicon learning approach classification approach 
testing performance approaches randomly chosen set reports
manually annotated shaping factors caused incidents described  section         start describing experimental setup  section      
followed baseline results  section      performance two approaches
 sections           describe experiment increase amount
training data available classification approach investigate impacts
performance  section       that  perform analysis errors bestperforming approach  section      conduct additional experiments attempt
gain better insight cause identification task help direct future research
 section       finally  present summary major conclusions draw
experiments  section      
    experimental setup
described section              reports entire corpus  manually
annotated      incident reports shaping factors  used first    
    manually extract initial seed words phrases semantic lexicon
learning procedure      train classifiers identifying shaping factors associated
report  remaining reports  used      reports test data     reports
development data  for parameter tuning  
      evaluation metrics
mentioned section         shaping factors  report may labeled
one shaping factors  evaluate performance cause
identification approaches based well automatic annotations match human
annotations reports test set  evaluation  use precision  recall
f measure  computed described sebastiani         specifically 
shaping factor si                     let ni number reports test set
human annotator labeled si   i e   number true si  labeled reports test
set  further  let pi number reports automatic labeling scheme ci
labeled si   let tpi number reports ci labeled correctly si  
then  shaping factor si   following performance metrics 
precisioni fraction reports really caused shaping factor si among
reports labeled si labeling scheme 
p recisioni  

   

tpi
pi

ficause identification via weakly supervised semantic lexicon construction

recalli percentage reports really caused shaping factor si labeled
labeling scheme shaping factor si  
recalli  

tpi
ni

thus obtain measure labeling schemes performance shaping
factors  obtain overall performance labeling scheme  sum counts
 i e   ni   pi tpi   shaping factors compute micro averaged precision 
recall f measure aggregated counts described sebastiani repeated
follows 
p
tpi
p recision   pi
pi
pi
tpi
recall   pi
ni
  p recision recall
f  measure  
p recision   recall
thus labeling scheme one set overall scores reflecting performance
classes 
      statistical significance tests
determine whether labeling scheme better another  apply two statistical
significance tests mcnemars test  everitt        dietterich        stratified approximate randomization test  noreen        test whether difference performances really statistically significant  mcnemars test compares two labeling schemes
basis errors  i e   whether labeling schemes making mistakes   stratified approximate randomization test compares labeling schemes
f measure  tests extensively used machine learning nlp literature  particular  stratified approximate randomization standard significance test
employed organizers message understanding conferences determine
difference f measure scores achieved two information extraction systems significant  see chinchor        chinchor  hirschman    lewis         since ultimately
concerned difference f measure scores two labeling schemes cause
identification  discussion statistical significance rest section focused solely stratified approximate randomization test  tests  determine
significance level p        
    baseline system
recall use baseline heuristic method described section   
occurrence heuristic used label report using seed words phrases manually
extracted     training reports  results  shown experiment   section
table    reported terms precision  p   recall  r   f measure  f   last
two columns show whether particular automatic labeling scheme significantly better
   

fiabedin  ng   khan

baseline respect mcnemars test  mn  stratified approximate randomization test  ar   statistical significance insignificance denoted x
x  respectively   evaluated      reports test set  baseline achieves
precision         recall        f measure        
table    report labeling performance different methods 
approach feature set
p
r
f mn
ar
experiment    baseline
heuristic seed words
                  n a n a
experiment    semantic lexicon approach
lexicon modified basilisk
                 
x
x
heuristic
lexicon original basilisk
                 
x
x
experiment    supervised one versus all classification approach
unigrams
                 
x
x
unigrams bigrams
                 
x
x
svm
lexicon words
                 
x
x
unigrams lexicon words
                 
x
x
unigrams  bigrams  lexicon words                  
x
x
experiment    transductive one versus all classification approach
unigrams
                 
x
x
unigrams bigrams
                 
x
x
svm
lexicon modified basilisk
                 
x
x
unigrams lexicon words
                 
x
x
unigrams  bigrams  lexicon words                  
x
x
experiment    metalabeler approach
unigrams
                 
x
x
unigrams bigrams
                 
x
x
svm
lexicon words
                 
x
x
unigrams lexicon words
                 
x
x
unigrams  bigrams  lexicon words                  
x
x
experiment    ensembles pruned sets approach
unigrams
                 
x
x
unigrams bigrams
                 
x
x
svm
lexicon modified basilisk
                 
x
x
unigrams lexicon words
                 
x
x
unigrams  bigrams  lexicon words                  
x
x
experiment    additional training data   fold cross validation
unigrams
                 
x
x
unigrams bigrams
                 
x
x
svm
lexicon words
                 
x
x
unigrams lexicon words
                 
x
x
unigrams  bigrams  lexicon words                  
x
x

   

ficause identification via weakly supervised semantic lexicon construction

    experiments semantic lexicon approach
recall semantic lexicon learning approach  label report test set using
occurrence heuristic combination semantic lexicon learned modified
basilisk framework described section      showing results approach 
first describe tune parameters modified basilisk framework 
      parameters
modified basilisk framework five parameters tune  first four thresholds resulting four frequency based constraints involving minimum support
maximum generality  see modification   section         specifically  four
threshold parameters     minimum frequency word  m inw        maximum frequency word  m axw        minimum frequency pattern  m inp   
    maximum number words extracted pattern  m axp    addition  recall
section       three types patterns  namely  subject verb verb object patterns  bigram patterns extracting words  bigram patterns extracting phrases  
fifth parameter pattern parameter  determines subset
three types patterns use  goal tune five parameters jointly
development set  words  want find parameter combination yields
best f measure occurrence heuristic used label reports development set  however  maintain computational tractability  need limit number
values parameter take  specifically  limit five different combinations four threshold parameters  see table     combination 
find subset three types patterns yields best f measure development set  hence total number experiments need run          the number
 non empty  subsets three types patterns     the number combinations
first four parameters    experiment indicates combination   table   
together bigram patterns extracting phrases  yields best f measure
development set  therefore chosen best parameter combination involving
five parameters 
new words phrases acquired first two iterations modified basilisk
using parameter combination shown appendix b  see new
words acquired first two iterations eight    categories  reasons
    unlike original basilisk framework  modified basilisk employs common
word pool  thus longer requiring five words must added category
bootstrapping iteration      application minimum support words led
filtering infrequently extracted words  two reasons together ensure
modified basilisk framework focuses learning high precision words category 
      results
semantic lexicon learned using best parameter combination  based performance development set  used label reports test set  see
row   experiment   table    modified basilisk approach achieves precision
        recall        f measure         comparison baseline 
method lower precision higher recall  increased recall shows
   

fiabedin  ng   khan

table    combinations four threshold parameters modified basilisk framework 
combination
combination
combination
combination
combination
combination

 
 
 
 
 

inw
  
  
  
  
  

axw
    
    
    
    
    

inp
   
   
   
   
   

axp
   
   
   
   
   

reports covered expanded lexicon  however  learned lexicon contains
general words resulted drop precision  overall  higher fmeasure  statistically significantly better baseline according
significance tests  vindicates premise learning words phrases
relevant shaping factors help us identify shaping factors reports 
      results using original basilisk
better understand whether proposed linguistic algorithmic modifications
basilisk framework  see section      indeed beneficial cause identification
task  repeated experiment described above  except replaced lexicon
generated using modified basilisk framework one generated using original
basilisk framework  specifically  implemented original basilisk framework
described thelen riloff         one minor difference  case
bigram patterns extracting phrases  word pools described section     populated
entire phrases instead head words  done seed words list
extracted section       contains words phrases hence would learn
entire phrases 
parameter tune original basilisk framework pattern parameter 
which  mentioned above  determines subset three types patterns use 
therefore  construct seven lexicons  corresponding seven non empty subsets
three types patterns  using original basilisk framework  determine
lexicon yields best performance development set  experiment indicates
best development result achieved bigram patterns extracting
phrases used  applying corresponding semantic lexicon combination
occurrence heuristic classify reports test set  observe precision        
recall        f measure         see row   experiment   section
table     lower precision higher recall indicates lexicon learned
words general  i e   words appear many reports little
discriminative power   new words phrases acquired first two iterations
original basilisk shown appendix c  seen  original basilisk framework
adds lot words  many relevant shaping factors
added  semantically similar seed words shaping factor 
   

ficause identification via weakly supervised semantic lexicon construction

hence  although recall improves small amount  precision drops significantly  leading
precipitation f measure  results suggest proposed modifications
original basilisk framework indeed beneficial far cause identification task
concerned 
    experiments classification approach
recall classification approach cause identification  train svm classifier
shaping factor sk determine whether report labeled sk   desired 
approach allows report test set potentially receive multiple labels  since
resulting    svm classifiers applied independently report  investigate
effect different feature sets performance cause identification  employ five
feature sets experiments      unigrams only      unigrams bigrams      lexicon
words only      unigrams lexicon words      unigrams  bigrams lexicon words 
unigrams bigrams generated reports training set first
removing stop words ignoring case information  semantic lexicon
one constructed modified basilisk framework  showing results
supervised transductive experiments  first describe parameters associated
classification approach 
      parameters
svm classifier  two parameters tune  first parameter
percentage features use  feature selection shown improve performance
text classification tasks  yang   pedersen         result  employ information
gain  ig   one effective methods feature selection according yang
pedersens experimental results  since assume words semantic lexicon
relevant cause identification  apply feature selection lexicon words 
rather  apply feature selection unigrams bigrams  specifically 
unigrams used features  as first five feature sets mentioned
beginning subsection   select n   unigrams highest ig 
value n tuned using development set  unigrams bigrams used
features  as second fifth feature sets   combine unigrams bigrams
one feature set select n   unigrams bigrams highest ig 
value n tuned using development set  experiments  tested   
values n                      
second parameter associated svm classifiers classification threshold 
default  svm sets classification threshold    meaning every data point
classification value   classified positive  rest classified
negative  however  since svm classifier trained optimize classification accuracy 
best classification threshold may   cause identification task 
goal optimize f measure  result  parameterize classification threshold 
allowing take one    values                             
usual  tune two parameters described jointly rather independently 
words  possible value combination percentages features
   

fiabedin  ng   khan

classification threshold  compute f measure classifiers development set
classes choose value pair yields maximum f measure 
get better idea two parameters impact performance  show
figure   f measure changes development set vary values
two parameters  experiment underlying svm classifiers employ
unigrams features  see  best f measure achieved employing
top     unigrams classification threshold      using default parameter values
 no feature selection classification threshold    yields f measure approximately
     overall  results provide suggestive evidence parameters
large impact performance 
f measure vs  classification threshold
different percentages unigram features
   
top     unigrams
top     unigrams
top     unigrams
top     unigrams
top     unigrams
top     unigrams
top     unigrams
top     unigrams
top     unigrams
top      unigrams

  
  

f measure    

  
  
  
  
  
  
  
 
  

    

  

    
 
   
classification threshold

 

   

 

figure    variation f measure different percentages unigram features classification thresholds used svm classification 

      supervised one versus all classifiers  results discussions
results supervised one versus all classification approach using five feature sets
described shown experiment   section table      see 
feature sets    unigrams only     unigrams lexicon words  used  achieve
best results f measure scores                respectively  however  even
best results statistically indistinguishable baseline result  according
approximate randomization test   significantly worse result produced
    recall supervised approach  svm classifiers trained     reports
training set 

   

ficause identification via weakly supervised semantic lexicon construction

modified basilisk approach  row   experiment     see appendix d  contains
statistical significance test results obtained applying stratified approximate randomization test pair experiments table    
fact  indicate occurrence heuristic made effective use
learned semantic lexicon svm classifiers  svm classifiers trained
lexicon words features  row   experiment    produced significantly worse
f measure score          occurrence heuristic           due large
drops recall precision  overall  results suggest supervised approach performs worse heuristic based semantic lexicon approach task 
hypothesize limited amount training data available svm learner contributed poor performance supervised approach  test hypothesis
section    
two additional observations worth mentioning  first  comparing rows    
experiment    see lexicon words useful cause identification
presence unigrams  second  comparing rows     rows     experiment
   see using bigrams hurts performance  likely reason attributed
feature selection method  since choose top n   features  bigram features
significantly outnumber unigram features  thus potentially diminishing effect
latter  one solution problem employ separate parameters selecting
unigrams bigrams  decided choice  would lead explosion
size parameter space 
      transductive one versus all classifiers  results discussions
investigate whether useful exploit unlabeled data  employ transductive svm
combine labeled unlabeled data  essentially  repeated experiments
supervised one versus all classification approach  except trained transductive
svm classifier using  labeled  reports training set  unlabeled 
reports test set described section        two parameters percentage
features used classification threshold tuned jointly maximize f measure
development set  described supervised approach  except transductive
svms used parameter tuning step trained using training set labeled data
development set unlabeled data 
results transductive svm classifiers shown experiment   section
table    overall  transductive results significantly worse corresponding
results experiment    however  conclusions draw transductive
results slightly different drawn supervised results  first  using
bigrams significantly improves performance lexicon words absent  comparing
rows     experiment    hurts performance lexicon words present
 comparing rows       second  adding lexicon words unigram only feature
set  comparing rows      significantly improves performance  suggesting potential
usefulness lexicon features  nevertheless  experiments     indicate    
using lexicon words features far adequate      best performance
achieved lexicon words added unigrams features 
   

fiabedin  ng   khan

      results additional supervised approaches
next  present results two additional supervised approaches  namely metalabeler ensembles pruned sets  section         feature sets used
approaches used one versus all method  oneversus all method  approaches use svm underlying learning algorithm
classifier training 
metalabeler  parameter needs tuned metalabeler approach
percentage features use  n    selected based classification performance  f measure  development set 
results metalabeler approach shown experiment   section table    interesting points results  first  metalabeler
method results much better precision methods  second  method
shows consistent performance improvement bigram features added  seen
comparing first second  fourth fifth rows metalabeler results 
third  inclusion lexicon word features found improve performance 
seen comparing first fourth  second fifth  rows metalabeler
results  two observations show metalabeler approach properly take
advantage increasingly richer feature sets used experiments  best
performance occurring types features used  fifth row   unfortunately 
approach suffers poor recall  fact prevents even matching  let alone
surpassing  f measure scores methods  since method discards less
probable labels assigns labels documents  precision much improved
recall suffers 
ensembles pruned set  among parameters ensembles pruned sets
approach  number classifiers ensemble    size sample
training data classifier ensemble trained  chosen
ones used read et al          namely        respectively  rest
parameters pruned set approach  namely minimum cardinality  b   minimum
support  p   percentage features use  n    threshold label assignment  t 
selected jointly based classification performance  f measure  development
set  values specific value b chosen         possible
values p tested experiment          threshold parameter chosen
values                        percentage features  n chosen
values                         thus     parameter combinations feature set 
parameter combinations  combination performance
development test set best  in terms f measure  chosen running system
test set 
results pruned set approach shown experiment   section table   
here  see best performance combination unigram lexicon word features 
better performance using unigrams lexicon words individually  however 
performance degraded inclusion bigrams combination  precision
much lower methods  indicates selection label
sets training set     reports may adequate 
   

ficause identification via weakly supervised semantic lexicon construction

    experiments using additional training data
results experiments somewhat surprising  best performing supervised classification approach one versus all approach performs significantly worse
modified basilisk approach  hypothesize poor performance attributed scarcity  labeled  training data  test hypothesis  conducted
set experiments increased amount training data one versus all
supervised classification approach applying cross validation  specifically  take
test set      reports split five disjoint subsets equal size  t    t            t   
then  construct training set merging tj      j 
original training set     reports  that  train svm classifier merged
training set test set ti   done five folds  compute
f measure entire test set  words  results report set
experiments f measure scores averaged five folds  experimented
five set features used supervised experiments section      two
parameters  percentage features used classification threshold  tuned
exactly way supervised experiments 
results set experiments shown experiment   section table   
comparison results experiment    f measure increases uniformly significantly 
provides empirical evidence performance supervised classifiers limited
amount data trained  feature sets    unigrams
lexicon words     unigrams  bigrams lexicon words   achieve best results
f measure scores               respectively difference
statistically insignificant  two results turn significantly better
modified basilisk  row   experiment     according approximate randomization
test  addition  except feature set    lexicon words only   results obtained
experiment significantly better baseline  according approximate
randomization test  overall  results suggest difficulty cause identification
task  comparing rows   experiments      see f measure increases
   number training reports increased          
points deserve mentioning  previous learning based experiments  using lexicon words features yields worst result set experiments 
combining unigrams lexicon words still yields one best results  nevertheless 
comparison experiment    using bigrams still improve performance 
hurt performance  from statistical significance point view   perhaps
importantly  comparing rows     experiment    see augmenting unigrams
lexicon words yields significantly better performance  indicates lexicon
words indeed useful features cause identification  usefulness may
revealed small labeled training set used  seen experiment    learning algorithms attempt learn features important relevant given classification
task based training examples see  training examples 
better able learn relevance features  results show
poignant illustration phenomenon  svm learner able use lexicon word
features effectively given large number training instances  seen
clearly svm learning curves section        indicates lexicon
   

fiabedin  ng   khan

words useful features sufficiently large training data  however 
lexicon words may still used effectively ways linguistic features even
training set small  see results experiment    uses
lexicon words combination occurrence heuristic achieve performances
statistically significantly better baseline 
    error analysis lessons learned
order gain clearer insight cause identification problem help direct
future research  manually analyzed errors made best performing system  i e  
heuristic based approach using semantic lexicon learned modified basilisk
framework  randomly chosen     report subset test set  specifically 
looked false negatives  cases annotator labeled report shaping
factor system not  false positives  cases system labeled
report shaping factor annotator not   false negative  tried
determine system failed correctly label report  false positive 
tried determine system labeled report erroneously  table   shows
number false positives false negatives along reasons errors
discovered analysis  following sections discuss errors reasons
detail  note since shaping factor may indicated one keyword
single report  one reason false negative  positive  error 
thus sum frequencies different types false negative  positive  errors greater
total number false negatives  positives  
table    error analysis details  different reasons false positive false negative
errors 
false negatives
sentence fragments bigger phrases
implicit causes cannot identified keywords
phrases learned
false positives
keyword general
keyword indicates concept appears report
contribute incident
wrongly learned keyword
keyword used negative context
keyword used hypothetical context

  
  
  
  
  
  
  

percentage
      
      
      

 
 
 

     
     
     

      
      

false negatives  false negative error  read report narrative identify
word  phrase sentence fragment may indicate shaping factor
system missed  analysis  identified three reasons false negatives
follows 
   

ficause identification via weakly supervised semantic lexicon construction

   required sentence fragments larger phrase  identified    sentence
fragments bigger phrases  i e   consist two phrases  
example  sentence fragment never dca consists  
phrases  never been  to  dca before  together  convey meaning
reporter unfamiliar dca  possible identify single
word phrase conveys meaning  since framework learns
phrases  possible learn sentence fragments 
   cause identifiable specific words phrases     instances  specific
word  phrase sentence fragment could identified could pinpoint shaping
factors responsible incident  example  number reports  including
report         describe incidents miscommunication
pilot air traffic controller  miscommunication must understood
following conversation  human reading report easily understand
pilot claiming controller said one thing controller claiming
said something different  detect kind scenario  machine would need
generate complete model discourse identifies specific topic
conversation  participants  claims participant makes topic 
fact claims contradictory  fact contradiction arises
miscommunication them  preprocessed narrative report
shown appendix e 
   missing phrases     cases necessary phrase missing semantic
lexicon learned modified basilisk framework     phrases  six
phrases infrequent considered modified basilisk framework due
minimum frequency criterion  example  phrase temperature flux
appears entire corpus hence considered system 
two phrases verb phrases  could learned focused
learning noun phrases adjective phrases  four phrases
semantically similar seed word shaping factors  example 
phrase garbled transmission semantically similar seed word
shaping factor communication environment  disturbance  static  radio
discipline  congestion noise  finally  two phrases
learned system  learned time put
word pool  words higher scores selected instead 
false positives  case false positives  looked report narrative
keyword found content determine indication shaping
factor incident described report incorrect  different reasons
identified follows 
   general keywords  observed large number false positives due
keywords general  i e   keywords extracted learned
shaping factor may appear phrases related shaping
factor   example  keyword failure correct indicator resource deficiency
appears text complete electrical failure  alternator failure  etc  
appears text failure follow air traffic control instructions 
   

fiabedin  ng   khan

indicate resource deficiency shaping factor  identified    cases
caused keywords general 
   concept present contributing incident  another frequently faced
problem sometimes concepts identified keywords present
report  act shaper incident described report 
example  report         reporter mentions flying solo 
indication taskload  incident due physical environments  namely
snow foggy weather  fact flying solo merely mentioned
part description overall situation  preprocessed version report
given appendix e  total  observed    cases 
   incorrectly learned words phrases  six cases semantic lexicon learner learned incorrect words phrases related
shaping factors assigned  example  framework incorrectly learned word shaping factor resource deficiency  thus
number reports mislabeled resource deficiency 
   negative context  three cases keyword appeared
negative context  typically signaled contextual valence shifter
hardly  polanyi   zaenen         example  keyword aircraft damage  indicator resource deficiency  appears report        apparent
aircraft damage  results false positive 
   hypothetical context  one case keyword appeared
hypothetical context reporter conjectures possible scenario 
keyword single pilot  indicator taskload  appeared report       
could happen pilot especially single pilot  resulting false positive 
lessons learned  error analysis provides valuable insight nature
problem well hints one proceed order improve performance
system  analyzing frequent errors  present following lessons
learned analysis  first all  useful learn high precision keywords
phrases general ones largest part false positive errors attributed
general keywords  however  high precision keywords phrases
likely low frequencies  hence one would adapt learning methods
learn useful words phrases infrequent ones  second  one must take account
fact relevant portions text may larger phrases  even going
clause sentences  cannot identified learning words phrases  n grams
reasonable size  thus  robust methods needed learn useful sentence
fragments useful sentence structures  finally  cases one cannot hope
identify using methods look keywords  phrases  sentence fragments even sentence
structures  i e   cases cause incident understood
discourse  cases concept present description yet plays part
incident  much deeper analysis simple bag of anything models needed
avoiding two types errors  represent almost one third
errors analyzed subset  former needs method distinguish relevant
   

ficause identification via weakly supervised semantic lexicon construction

sentences irrelevant ones  example  patwardhan riloff        discuss relevant
sentence classifier trained small set seed patterns set documents
marked relevant irrelevant useful context  latter problem
requires discourse analysis method that  discussed earlier  model conversations
identify relations correctly  shows though possible identify shaping
factors reports using words phrases certain extent  much deeper natural
language techniques needed accurately identify full range causes 
    additional analyses
section present outcomes number additional analyses performed
cause identification task approaches task  section       study
relative difficulties classifying different shaping factors  sections            
show learning curves semantic lexicon based approach learning based
approach respectively  i e   performances two approaches vary
provided different amounts training data  finally section       discuss
outcomes experiment conducted determine modifications basilisk
framework useful learning general semantic categories 
      per class results
get insight classes difficult classify  perform analysis
per class performance two labeling schemes  best heuristic based method  i e  
occurrence heuristic using lexicon learned modified basilisk framework   see
first part table    best learning based method  i e     fold svm classifiers
using unigrams  bigrams lexicon words features   see second part table    
conjunction table    two classes stand prominently difficult classify
illusion taskload  classes little representation training 
test development sets  small number seed words  result poor
performance approaches  easily identifiable classes physical
environment  physical factors  resource deficiency preoccupation 
labeling schemes f measures better      general classes better
representation training  testing development sets  reasonable
number words phrases semantic lexicon  believe difference
characteristics classes valuable insight helpful future work 
      lexicon learning curve
mentioned section        used total     seed words phrases 
first glance  number seeds may seem large far bootstrapping experiments
concerned  however  considering fact     seeds distributed   
shaping factors  average      words phrases per shaping factor 
nevertheless  would still interesting examine cause identification performance
affected reduce number seeds shaping factor used modified
basilisk bootstrapping process  result  ran set experiments measure
cause identification performance uses semantic lexicon learned modified basilisk
given different number seed words  parameters specific modified
   

fiabedin  ng   khan

table    per class performance results  upper table shows per class performance
occurrence heuristic using lexicon learned modified basilisk framework 
lower table shows per class performance   fold svm classifiers using unigrams 
bigrams lexicon words features 

shaping factor
attitude
communication environment
duty cycle
familiarity
illusion

physical environment
physical factors
preoccupation
pressure
proficiency
resource deficiency
taskload
unexpected
overall

tp
 
 
 
  
 
  
   
  
  
  
  
   
 
 
   

fn
  
  
  
  
 
   
  
  
  
  
   
   
  
 
   

tn
   
   
   
   
   
   
   
   
   
   
   
   
   
   
     

fp
  
  
 
  
 
  
  
 
  
  
  
   
 
  
   

precision
      
      
      
      
     
      
      
      
      
      
      
      
     
      
      

recall
      
      
      
      
     
      
      
      
      
      
      
      
     
      
      

f measure
      
      
      
      
     
      
      
      
      
      
      
      
     
      
      

shaping factor
attitude
communication environment
duty cycle
familiarity
illusion

physical environment
physical factors
preoccupation
pressure
proficiency
resource deficiency
taskload
unexpected
overall

tp
 
  
  
  
 
  
   
  
  
 
   
   
 
 
   

fn
  
  
  
  
 
   
  
  
  
  
   
   
  
  
   

tn
   
   
   
   
   
   
   
   
   
   
   
   
   
   
     

fp
 
  
  
  
 
  
   
  
  
 
   
   
 
 
   

precision
      
      
      
      
     
      
      
      
      
      
      
      
     
     
      

recall
     
      
      
      
     
      
      
      
      
      
      
      
     
     
      

f measure
      
      
      
      
     
      
      
      
      
      
      
      
     
     
      

   

ficause identification via weakly supervised semantic lexicon construction

basilisk set described section        specifically  chose top            
             seed words phrases shaping factor  in terms frequency
entire corpus   ran modified basilisk framework ten iterations using
aforementioned parameters 
note  however  shaping factors number manually selected
seed words phrases  example  illusion  taskload unexpected       
seed words phrases respectively  whereas resource deficiency physical environment
      respectively  see last column table     hence  experiments
number seeds used shaping factor exceeds number manually
selected seeds shaper  manually selected seeds used  example  since
unexpected three manually selected seeds  used experiments
least three seeds used shaping factor 
occurrence heuristic used lexicons thus generated evaluate
performance test set  resulting learning curve  terms f measure
test set      reports  shown figure    addition  since baseline
compare performance based seed words  baseline learning curve
corresponding reduced seed words set shown  expected  increasing
number seed words monotonically improves f measure  however  improvement
baseline particularly small fewer seven seed words used 
highest improvement observed seven seed words phrases  on  adding
seeds improves overall performance  improvement baseline slowly
diminishes 
lexicon learning curve
  
  
  

f measure    

  
  
  
  
  
baseline
performance learned lexicon

  
  
  
 

 

 

 

 
  
  
number seeds

  

  

  

  

figure    variation f measure different number seeds words per category 

   

fiabedin  ng   khan

svm learning curve
  
f measure test set
  
  

f measure    

  
  
  
  
  
  
  
  
 

   

   

                   
number training instances

   

        

figure    variation f measure different number training reports 

      svm learning curve
discussed section      hypothesize failure svm classifiers perform better baseline due scarcity training instances available
learner  one may argue svm shown work well small datasets 
so  natural question is  much smaller training set see
statistically significant drop cause identification performance  answer question 
plot learning curve one versus all classification approach  using features
combination unigrams  bigrams  lexicon word features five fold cross validation
setting  setting yields best performance table    specifically 
generated random subsets training sets sizes                       instances  parameters  namely percentage features classification threshold  chosen
way original experiment described section      f measure
evaluated entire test set  curve shown figure    data point
computed averaging results five independent runs  see 
general trend performance improvement increase number training
instances  addition  trained     training set  see cause
identification system started perform statistically significantly worse system
trained available instances according stratified approximate
randomization test 
   

ficause identification via weakly supervised semantic lexicon construction

      general usefulness modifications basilisk
order test whether modifications made basilisk framework useful
lexicon learning general  added two general categories shaping factors
bootstrapping experiments  namely people equipment  two categories
added because  firstly  words phrases added categories would easy verify
 i e   whether words phrases representing people equipment   secondly 
similar original context basilisk framework originally evaluated  i e   learning words categories building  event  human  location 
time  weapon terrorism reports   two additional categories added
seed lexicon described section        bootstrapped running original basilisk modified basilisk separately ten iterations  parameters specific
basilisk frameworks set way described section        seed
words two categories selected manner done thelen
riloff         i e   phrases corpus sorted frequency five
frequent phrases belonging categories manually identified  seed
words used two categories 
people  captain  controller  first officer  rptr  passenger
equipment  aircraft  airplane  collision avoidance system ii  engine  auto pilot
order verify words phrases learned two frameworks correctly
belong assigned category  first author computer science graduate student
affiliated research went generated lexicons  appendices f g
show lexicons generated original basilisk modified basilisk respectively 
facilitate analysis  divide words phrases generated lexicon three
categories      determined correct human judges     
determined correct one judge      determined incorrect
judges 
lexicon generated original basilisk  find category people    
   words phrases determined correct judges    determined
exactly one judges correct  category equipment       words
phrases correct according judges     correct according exactly one
judges  hand  lexicon generated modified basilisk  find
category people        words phrases determined correct
judges    determined exactly one judges correct  category
equipment        words phrases correct according judges   
correct according exactly one judges  comparison clearly shows
modifications made basilisk framework specific particular
task  rather  modifications improved lexicon building performance general 
    summary conclusions
end section providing summary major conclusions draw
experiments 
   

fiabedin  ng   khan

heuristic approach cause identification  labels report using occurrence heuristic combination words phrases automatically acquired
using modified basilisk framework  surpasses performance baseline system  applies occurrence heuristic combination seed words
phrases manually identified training documents  difference f measure
two systems statistically significant according mcnemars test
stratified approximate randomization test  suggests words
phrases semantic lexicon learned via modified basilisk relevant effective
cause identification 
adding learned lexicon words n gram based feature set training svm
classifiers beneficial cause identification training set sufficiently
large  exhibited statistically significant increase f measure  provides
suggestive evidence words phrases semantic lexicon learned via
modified basilisk relevant useful features cause identification 
used combination occurrence heuristic  semantic lexicon learned
modified basilisk framework offers significantly better performance
cause identification task one obtained using original basilisk framework  additional experiments reveal modified basilisk useful
cause identification  offers performance superior original basilisk
bootstrapping general semantic categories people equipment 
among three multi class multi labeled text classification approaches experimented with  one versus all works significantly better metalabeler pruned
sets cause identification  transductive learning  used combination
one versus all approach  significantly hurts performance  suggesting unlabeled data cannot profitably exploited given fairly small amount labeled
data 
best system achieves f measure around        indicates cause
identification difficult task  lot room improvement 
provide directions future research  performed analysis errors made
best performing system  particular  found performance currently
limited part several factors  first  number cases
relevant text indicating responsible shaping factor may larger phrases 
second  indicators shaping factor may mentioned report without influencing incident described report  finally  cases
shaping factors cannot identified simply looking words  phrases even
sentence fragments much deeper analysis required cases 
increasing number seed words phrases employed modified basilisk improves cause identification performance  marginal performance improvement
added seed diminishes successive additions  words  results
seem suggest using seed words unlikely improve much
current performance  rather would promising start small number
high frequency seeds improve upon bootstrapping process 
   

ficause identification via weakly supervised semantic lexicon construction

learning curve plotted one versus all classification approach shows
cause identification performance increases number training instances 
particular  trained     training set  see resulting cause
identification system performs statistically significantly worse one trained
available instances 
overall  approaches rely automatically learned lexicon words phrases
adequate cause identification  relevant task  mentioned previously  use motivated labor intensive procedure nasa
researchers employed manually identifying seed words phrases shaping factor  posse et al          work represents one first attempts tackle cause
identification task  believe use simple features good starting point
establishes baseline future studies problem compared 
main take home message research though possible solve
problem set solve  namely automated cause identification  learning
relevant keywords sentence fragments suitable bag of words models 
remains significant portion data remains unlabeled mislabeled
methods  match performance level achieved topical text classification
tasks  much deeper linguistic analysis relevant sentence detection discourse analysis
methods identifying disagreements  disputes hostile attitudes needed 
lesson cornerstone research area 

   related work
section  describe works related research  particular 
discussion focuses causal analysis well approaches semantic lexicon construction text classification  organized follows  first  discuss causal analysis
appeared different fields  second  discuss different semantic lexicon
learning algorithms  third  discuss works deal extraction pattern learning 
fourth  describe different algorithms unsupervised word clustering thesaurus
building  finally  include discussion related work multi class multi labeled text
classification 
causal analysis  major research causality performed mainly fields
philosophy psychology  field philosophy  seminal works causality
conducted hume               provides one influential definitions
cause object followed another  objects  similar first 
followed objects similar second  or  words  where  first object
been  second never existed  basis later  much stronger
definitions causation  e g   lewis        ganeri  noordhof    ramachandran        
notable investigations causation field psychology include cheng        
defines causation terms probabilistic contrast model  griffiths tenenbaum
        discuss learning cause effect relationships using causal graphical
models  halpern pearl         provide explanations causality means
structural equations governing random variables representing events  although
   

fiabedin  ng   khan

works provide important background definitions contributing understanding
causality  order identify causes naturally written text must turn nlp 
field nlp  little work cause identification similar problem 
research causality focuses mainly identifying causal relations two sentence
components  instance  girju        describes method automatically discovering
lexico semantic patterns refer causation  particular  focuses explicit
intra sentential pattern hn p  verb n p  i  verb simple causative  shows
patterns used improve performance system answering
cause effect type questions  khoo et al         use graphical pattern matching identify
causal relations medical article abstracts  use hand crafted patterns
matched parse trees sentences  subtrees parse tree match
patterns extracted causes effects  similarly  garcia        uses hand crafted
extraction patterns identify causal relations sentences french language 
limitation approaches focus identifying causal relations
sentence  whereas reports multi sentence discourses 
grishman ksiezyk        use domain modeling  discourse analysis causal inference find cause effect relations events leading equipment malfunctions
short equipment failure reports  specifically  first apply syntactic analysis
produce parse trees sentences reports using augmented context free
grammar  apply semantic analysis map     verbs syntactic relations
domain specific predicates relations     noun phrases references components
domain model  finally  apply discourse analysis predicates construct
time graph showing temporal causal relationships elementary facts 
temporal relations derived text structures words  e g   when  then 
etc   order appearance text  causal relations determined querying simulation model equipment built using domain knowledge  specifically 
possible causal link posed query model test relation holds 
overall  method relies heavily domain model equipment studied 
research focuses one specific piece equipment 
nasas research identifying causes incidents report narratives
performed posse et al          describe specific experiment
brought together experts manually analyze report narratives identify words 
phrases expressions related shaping factors  mentioned earlier  later
work ferryman et al         take manually extracted expressions ground truth
compare anomalies described reports shaping factors derived
applying expressions reports  specifically  attempt learn
expressions automatically  rather  focus finding possible correlations
shaping factors anomalies 
algorithms semantic lexicon learning  number semantic lexicon learning
algorithms follow iterative bootstrapping approach  starting small number
semantically labeled seed words  roark charniak        propose method constructing semantic lexicons based co occurrence statistics nouns conjunctions  lists
appositives  start small seed nouns list  iteratively add similar words
list  word similarity measured ratio many times word occur
   

ficause identification via weakly supervised semantic lexicon construction

together seed word number times word appear corpus 
construction  rank words log likelihood statistic  dunning         however 
due general brevity reports  co occurrences lists rather
corpus  useful us use context based similarities thelen riloff
        describe basilisk framework learning semantic lexicon using extraction patterns features  apply weakly supervised bootstrapping approach
start small manually constructed seed lexicon iteratively add semantically
similar words it  this  described detail section      basis
lexicon learning approach 
number improvements basilisk framework  generally bootstrapping approaches  proposed  basilisk framework  number iterations
parameter chosen arbitrarily  rather making arbitrary choice 
yangarber        proposes method detecting termination unsupervised semantic
pattern learning processes  method requires documents must labeled
relevant irrelevant  since information available corpus  useful us  curran  murphy  scholz        suggest improvement traditional
bootstrapping methods discarding words contexts appear related
one category  order minimize semantic drift enforce mutual exclusion 
hand  handle cases comparing conditional probabilities
different categories words belong  zhang  zhou  huang  wu       
present bootstrapping graph mutual reinforcement based bootstrapping  gmr 
 hassan  hassan    emam         modification basilisk method  similar us 
explore using n grams capture context  use different set pattern
word scoring formulas  learning multiple categories simultaneously  introduce
scoring system based entropy pattern  report better results basilisk
muc   dataset  see sundheim        
among non bootstrapping approaches  ando        presents new method constructing semantic lexicons unannotated corpus using set semantic classes set
seed words phrases semantic class  uses spectral analysis improve
feature vectors projecting useful portions vectors subspace removing harmful portions vectors  resultant feature vectors used
centroid based classifier using cosine similarity measure label words  avancini 
lavelli  sebastiani  zanoli        take classification approach semantic lexicon
construction  cast problem term  meaning words phrases  categorization task  dual document categorization task   similar bag of word
model  represent terms bag of documents  use variation adaptive
boosting algorithm  adaboost m h kr   trained small seed lexicon
used classify noun terms corpus zero  one semantic categories 
algorithms learning extraction patterns  approach semantic lexicon construction uses extraction patterns features  present methods aim
improve extraction pattern collection process  riloff        describes autoslog ts
system learns extraction patterns untagged text  however  needs pre classified
corpus text classified relevant irrelevant  mentioned earlier 
access information  phillips riloff        present method boot   

fiabedin  ng   khan

strapping algorithm learn role identifying nouns  used learn important
extraction patterns  role identifying expressions  however  focus mainly
identifying roles words events 
patwardhan riloff        provide another extraction pattern learning approach
using relevant regions  require documents pre classified relevant
irrelevant documents  using small set seed patterns  classify sentences
documents relevant irrelevant sentences  semantically appropriate extraction patterns learned using semantic affinity metric separated primary
secondary patterns  approach directly usable us due unavailability
documents pre classified relevant irrelevant categories 
recently  internet increasingly used natural language research  patwardhan riloff        use autoslog ts system  riloff        learn domain specific
extraction patterns processing documents retrieved querying web selected
domain specific words  using web interesting promising enhancement and 
mentioned section    intend extend work using google corpus  brants  
franz        
algorithms thesaurus building unsupervised word clustering  another
area research closely related semantic lexicon learning thesaurus building 
building thesaurus requires discovering groups semantically similar words  though
stops short assigning semantic class labels words  thus shares problem
measuring semantic similarity grouping similar words semantic lexicon building
task  discuss several approaches thesaurus building task 
clustering used extensively thesaurus building  mostly unsupervised nature ability handle large volumes data  seminal work
direction pereira  tishby  lee         present unsupervised method
soft clustering words using distributions words different contexts  approach generates overlapping word clusters  grouping words based contexts
appear in  baker mccallum        use pereira et al s distributional clustering technique perform feature space reduction supervised classification nave bayes
using clusters features  lin pantel        present approach generating
collection sets semantically similar words  concepts  using clustering method 
unicon  dependency relations features  pantel lin        present another
clustering approach  clustering committee  using contextual features point wise
mutual information feature values  compare better lin pantels
results  rohwer freitag        present clustering based automatic thesaurus building
process unannotated corpus  propose information theoretic co clustering
algorithm groups together highly frequent words clusters similar part of speech
category  pursue additional process  lexicon optimization  grow lexicon
assigning less frequent words likely clusters 
among non cluster based methods  davidov rappoport        present unsupervised method discovering groups words similar meanings  achieve
    identifying high frequency words content words      identifying symmetric
lexical relationship patterns      applying graph clique set algorithm generate word
categories co occurrence information content words symmetric patterns 
   

ficause identification via weakly supervised semantic lexicon construction

concentrating performance issues plague attempts build thesaurus
large corpus  rychly kilgarriff        present two methods improving performance
general context based thesaurus building algorithms  first method compare
word pairs context common  second method use
heuristic removing contexts general  i e   contexts
certain number distinct words   research  adopted second method
 see section       applied partitioned sequential approach construction
process  though thesaurus building usually require annotated corpus set
seed words phrases  directly applicable task growing semantic
lexicon learn words specific semantic categories 
method control words learned classes discovered
word groups belong to  may possible adapt method semantic lexicon
growing classifying word groups semantic classes using seed words
phrases  however  method extended extract noun adjective phrases 
algorithms multi class multi labeled text classification  mentioned previously  cause identification  cast text classification problem  multi class
multi labeled text classification problem  since    shaping factors total
document may labeled one shaping factors  several
popular approaches solving multi class multi labeled text classification problem 
first  one approaches followed research  independently train binary
classifier class  apply classifier test instance isolation 
case  underlying learner support vector machines  joachims         godbole
sarawagi        suggest number improvements scheme  namely  including class
labels suggested preliminary set classifiers features  removing negative examples
close classification hyperplane  selectively removing classes
one versus others classifications scheme  another notable method  followed tsoumakas
vlahavas        read et al          treat unique set labels
new label  thus converting problem multi class single labeled one  works
differ construction new labels  former  called random
k labelsets  rakel  builds ensemble classifiers randomly sampling label sets
size k  whereas latter adopts method filtering observed label sets minimum
support  tang et al          hand  take different approach  train one
classifier predicts number labels test instance would have  choose
many labels instance based output another classifier ranks labels
likelihood instance  works use svm underlying learner 
addition  approaches make assumption classes correlated high
degree  however  analysis dataset present evidence strong
correlation      documents multiple labels test set     unique
label sets  seven frequency least five  thus increasing number
labels would aggravate already imbalanced class distribution 
among approaches  mention two systems use probabilistic generative models  mccallum nigam        propose system starts small set keywords
unlabeled documents  learns nave bayes classifier bootstrapping process
keyword induced labels using hierarchical shrinkage expectation maximization
   

fiabedin  ng   khan

held out data set  ueda saito        present another generative model called parametric mixture models  treats multi labeled text parametric mixture words
relevant label  work closely related latent dirichlet allocation  blei 
ng    jordan         generative models usually assume document related
particular topic would high frequency words related topic  research 
documents mostly devoted description event occurred  cause
event mentioned briefly  makes generative models less suitable
task hand generative models would likely generate models related events
causes  comprehensive review different approaches multi class
multi label text classification found work tsoumakas katakis        

   conclusions
investigated two approaches cause identification task  goal
understand aviation safety incident happened via identification causes 
shaping factors  responsible incident  approaches exploit information
provided semantic lexicon  automatically constructed via thelen riloffs
       basilisk framework augmented three algorithmic modifications  namely 
use probabilistic similarity measure  use common word pool  enforcement minimum support maximum generality constraints words extraction
patterns  one linguistic modification  the use n gram based extraction patterns  
heuristic based approach labels report employing occurrence heuristic 
simply looks words phrases acquired semantic lexicon learning process report  learning based approach labels report employing inductive
transductive support vector machines learn models reports labeled shaping factors  experimental results indicate heuristic based approach
supervised learning approach  when given sufficient training data  significantly outperform baseline  which  motivated nasas work  labels report simply using
occurrence heuristic combination set manually identified seed words
phrases  importantly  results heuristic based approach indicate modifications original basilisk framework beneficial far cause identification
concerned  results learning based approach indicates usefulness lexicon
words used combination unigrams features training svm
classifier  overall  set prove possible automate cause
identification task manually analyzing small number reports using information thus generated train machine learning methods identify shaping factors
rest reports  experiments able prove feasibility approach 
usefulness learning semantic lexicon using words features 
nevertheless  best system achieves f measure around        indicates
cause identification difficult task  lot room improvement 
particular  analysis errors made best system     randomly chosen test
documents provides valuable insights task well directions future research 
experience current research  intend extend work
following directions  first foremost  plan extend approach handle text
fragments bigger phrases  second  order improve quality labeling 
   

ficause identification via weakly supervised semantic lexicon construction

propose work improving lexicon learning performance using different
semantic similarity measures  instance  would study performance
semantic similarities weighting functions suggested curran moens       
context  third  plan use thoroughly normalized text better parsing
tagging  well relevant region information  ko  park    seo        patwardhan
  riloff         fourth  propose augment semantic lexicon  specifically using
google n grams corpus  brants   franz        extract frequent n gram patterns
words  fifth  propose explore recent lexicon construction methods
unsupervised word clustering  pantel   ravichandran         spectral analysis  mutual
exclusion bootstrapping  co clustering exploiting symmetric patterns  finally  order
handle shaping factors difficult identify words occurring
reports  propose employ much deeper analysis text semantic level 
taken step making annotated incident reports publicly available 
hope stimulate research under investigated problem nlp
community 

acknowledgments
authors would thank anonymous reviewers provided us comments
invaluable improving quality paper  research supported
part nasa grant nnx  ac  a  opinions  findings  conclusions recommendations expressed paper authors necessarily reflect
views official policies  either expressed implied  nasa 

   

fiabedin  ng   khan

appendix a  seed words
seed words manually extracted     reports training set  see
section       details  
shaping factor
attitude
communication
environment
duty cycle
familiarity
illusion

physical
environment

physical factors
preoccupation
pressure
proficiency

resource
deficiency

taskload
unexpected

seed words
get homeitis  attitude  inattentiveness  get thereitis  complacency  overconfidence  sarcastic  inattention
disturbance  static  radio discipline  congestion  noise
   hour duty day  inadequate rest  last   legs  heavy flying  reduced
rest  all night flight     hour day  red eye  ten leg day  night
familiarization  familiar  new  first departure  unfamiliar  unfamiliarity  familiar  low time  first landing
bright lights
noise abatement policy  disoriented  confused  medical emergency 
economic considerations  disorientation  drunk passenger  confusion
cold  clouds  dark  setting sun  sun glare  obscured  visibility  hazy
stratus  birds  fog bank  solid overcast  snow  weather  rime  gust  low
weather  surface winds  jet blast  lightning  sea gulls  high ceilings 
hot  tailwind  chop  dark  sea gull  winds  scattered  high tailwinds  extremely dark  bright  icing  turbulence  rpted wind 
terrain  bird strike  crosswind  thunderstorm  glare  reduced visibility  high flying birds  fog  severe winter weather  cloud  ice
tired  hypoxia  tiredness  tired  fatigued  disorientation  fatigue  rest
distracted  preoccupied  mental lapse  busy  distrs  distraction 
attention  inattention  absorbed
hurry  running late  pressure  low fuel  fuel considerations  behind
schedule  late  peer pressure  pressure  rushing
mistakes  mistaken  new hire  inexperience  forgotten  less    
hours  newly rated  training  recent pilot  inadvertently  bad turn 
misinterped
loose connection  erratic  blown  overheated  bang  collapse  idea 
unavailable  placarded  crack  service  damage  smoke  inoperative  failure  leak  deferred items  communication failure  loss 
unreliable  fdrs problem  bump  shaking  master caution  inadequately lighted  unreadable  disconnected  malfunction  shudder  absence  hazard  inaccurate  unflagged  fire  broken  fluctuations 
compressor stall  deferral  unusable  wrong  intermittently  warning 
discrepancies  faulty  deferred  intermittent  missing
single pilot  solo
unexpected  suddenly  unforecast

   

ficause identification via weakly supervised semantic lexicon construction

appendix b  sample lexicon words learned modified basilisk
semantic lexicon words learned modified basilisk framework
first two iterations 
shaping factor
attitude
communication
environment
duty cycle
familiarity
illusion

physical
environment
physical factors
preoccupation

pressure
proficiency
resource
deficiency
taskload
unexpected

new words

aligned  fairly new  familiar
initial confusion  minimum fuel emergency  misunderstanding 
weather emergency
trws  conflict message  cumulonimbus  large cells  numerous thunderstorms  occasionally severe  thunderstorm cells  weather buildups 
weather cell  weather en route
first factor
adequate attention  much attention  close attention  close enough
attention  crew attention  enough attention  much attention  proper
attention  strict attention  close attention

different  amiss  awry  obviously wrong  resulting loss  seriously
wrong  slight loss  temporary loss  terribly wrong  wrong

   

fiabedin  ng   khan

appendix c  sample lexicon words learned original basilisk
semantic lexicon words learned original basilisk framework first
two iterations 
shaping factor
attitude

communication
environment

duty cycle

familiarity

illusion



physical
environment

physical factors

preoccupation

new words
air traffic control security  aileron yoke displacement  anomalous vfr omni directional radio range information  assured tfr
avoidance  betrayal  concern urgency  forgetting air carrier x 
magnified problem  operational complacency  unseen unknown
turbulence
     noise  bna runway    approach plate  lightspeed   k
noise  non  noise  overspd bell  active noise  clearance delivery
transmission  left engine stall  static emergency locator transmitter  stuck trim elevator movement
   plus    layover    different time frames    back to back continuous duty trips    hour break     minutes    hour    minute flight time
day  pacific daylight time departure  tpa flight  xc   departure 
scheduled    leg continuous duty
partial unfamiliarity  perceived familiarity  command familiarity  command unfamiliarity  blue panel indication light  dispatch
work desks  generally unfamiliar  inexperience unfamiliarity  new
everyday  past experience familiarity
      nautical mile ssw          point     end     feet side  elmendorf required use      mile downwind  airspace e  foxtrot
intersection  lateral boundaries  mile right
misinformation  flight management system heading anomalies  confusion conflict  disoriented confused  intense panic  micro sleep 
miss numerous times  mistake inconvenience  note closure problem 
start terror
mht class celsius  strato cumulus  thur morning  clouds underneath  compacted snow ice  fair weather cumulus  next morning
weather  puffy cumulus clouds  thin scattered clouds  well developed
cumulus clouds
hypoxia carbon monoxide  minimum equipment list          
basically tired  cardiac distress  indicating system problem  internal
bleeding  interrupted fuel flow  oncoming seizure  stress overload 
upper respiratory problems
captain first officer attention  terminal radar approach control facility distraction  close enough attention  consequently attention  good enough attention  lip service  mind attention  much
mind  real attention  real close attention
continued next page

   

ficause identification via weakly supervised semantic lexicon construction

shaping factor
pressure

proficiency

resource
deficiency

taskload

unexpected

new words
minimum equipment list pressure  consistent answer  elevator pressure  intense pressure  part   coordinated universal time  repercussion  right engine pressure  significant pressure  slow gear  wheel
pressure
  p school  cl   ground school  basic flight training  hard lesson 
initial annual proficiency training  occurrence strive  rating
training  several military flying clubs  situation event  time limited
simulator sessions
air traffic control loss  altitude deviation loss  apparently inoperative  either inoperative  even reexamining  intermittent inoperative  known traffic conflict loss  observed loss  recently los 
thankfully accurate
        turboprop  a    type aircraft  aviat husky a  two place
tail dragger aircraft  cessna     type aircraft  cessna model
    type aircraft  l          lga mht flight  mcdonnell douglas
md    solo cross country flts  solo cross country privileges
significant    jolt  approximately      sec  choppy aircraft  consistently moderate  contributing workload factor  industry issue 
severe  rapid immediate  real cushion

   

fiabedin  ng   khan

appendix d  additional stratified approximate randomization tests

mlw

olw

svm u

svm ub

svm l

svm ul

svm ubl

svmt u

svmt ub

svmt l

svmt ul

svmt ubl

svm  u

svm  ub

svm  l

svm  ul

svm  ubl

methoda
sw
mlw
olw
svm u
svm ub
svm l
svm ul
svm ubl
svmt u
svmt ub
svmt l
svmt ul
svmt ubl
svm  u
svm  ub
svm  l
svm  ul
svm  ubl

sw

ascertain statistical significance difference f measure scores
different report labeling methods  performed stratified approximate randomization
test       shuffles pairs results experiments     table   
table shows method column statistically significantly better
method row level p         before  statistical significance
insignificance denoted x x  respectively 

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
 

a  legend  sw   occurrence heuristic using seed words  mlw   occurrence heuristic using modified
basilisk lexicon  olw   occurrence heuristic using original basilisk lexicon  svm u   svm using
unigrams  svm ub   svm using unigrams bigrams  svm l   svm using lexicon words  svm ul
  svm using unigrams lexicon words  svm ubl   svm using unigrams  bigrams lexicon
words  svmt u   transductive svm using unigrams  svmt ub   transductive svm using unigrams
bigrams  svmt l   transductive svm using lexicon words  svmt ul   transductive svm using
unigrams lexicons  svmt ubl   transductive svm using unigrams  bigrams lexicon words 
svm  u     fold svm using unigrams  svm  ub     fold svm using unigrams bigrams  svm  l
    fold svm using lexicon words  svm  ul     fold svm using unigrams lexicon words  svm ubl     fold svm using unigrams  bigrams lexicon words 

   

ficause identification via weakly supervised semantic lexicon construction

appendix e  sample preprocessed reports
report acn       
returning waukegan regional airport practice area located      mile
w airport  flying solo student pilot       feet mean sea level visual
flight rules  cloud area   mile w airport obscured view ahead reduced
altitude proceed visual flight rules returned      feet passing thin
cloud line  area n  containing fix references airport location  shrouded
clouds fog ground level  true lake michigan shoreline
e  ground substantially snow covered  although airspace airport
undoubtedly clear  practice area  orientation field lost me 
climbed      feet increase overview  without benefit  returning      feet 
flew believed n airfield landfall airport  must
s  however  proceeding flew ord class b airspace  coinciding
lost  contacted waukegan tower  realizing flown federal aviation
regulation had  directed contact ord approach frequency given 
beginning ord approach vectored back waukegan airport  frequency changed
tower control blessedly cleared land  time lost   hour    minutes
      hours 
report acn       
following event occurred repositioning  taxi  w side
side isp airport  initially contacted longitude island tower asking permission repos
w side ops base operations office tower  the side   controller
replied start taxi via taxiway w hold short runway    read back
instructions stating start taxi via taxiway w holding short runway    taxiing 
aircraft taxiway w holding short runway    performing run up 
controller asked able get around aircraft  replied able 
controller said use caution taxiing around aircraft cross runway   
taxiing across runway    noticed aircraft short final runway    clear
runway aircraft touched down  controller came frequency
said instructed hold short runway    replied cleared across
runway    controller said call tower park  replied roger  call
park  called talked controller minutes later said
instructed hold short runway    told cleared across
runway  feel pilots controllers need listen decipher
said acting it 

   

fiabedin  ng   khan

appendix f  lexicon learned original basilisk categories people
equipment
following table shows words phrases learned original basilisk framework
categories people equipment  see section        
category
people

equipment

new words
agreed judges correct  abq tower procedure specialist  acn        reporter  afsfo  avp tower specialist  air route
traffic control center specialist  air traffic control facility reps 
bdr tower specialist  bhm control  buf field operations officer 
cae tower specialist  chicago quality control  dfw maintenance
manager  flight service station dispatcher  sfolm captain 
sii program manager  stearman pilot  tlh supervisor  bur local
controller  casino manager  cos air traffic control chief  flight test
engineers  local balloon repairman  outbound captain first officer  repair facility pilot  shift boss  spokesperson  station management individual  technician desk  tower supervisor manager
identified one judge correct  flight standards district
office orl  maintenance supervisor  approach controller verbatim  freighter aircraft approach  tower  passenger
fatigue
agreed judges incorrect  acn         acn        
at  aircraft  b            srm  emb service manual  non air
carrier aircraft  rptr acn         rptr acn         rptr
acn         rptr acn         rptr acn         rptr acn
       cabin company  aircraft center  reliable research resources
agreed judges correct  collision avoidance system ii    distance measuring equipment screen  collision avoidance
system ii b         collision avoidance system ii ehsi  collision
avoidance system ii ivsi display  collision avoidance system ii
missed approach point page  collision avoidance system ii rr 
continued next page

   

ficause identification via weakly supervised semantic lexicon construction

category

new words
identified one judge correct  collision avoidance system ii vsi overlay  resolution advisory stopped aircraft  collision avoidance system ii stop climb alert  collision avoidance
system ii traffic   climb advisory  collision avoidance system ii traffic   traffic aural warning  collision avoidance system
ii   mile circle  collision avoidance system ii   mile scale  collision avoidance system ii   mile scale  collision avoidance system ii popup traffic  collision avoidance system ii resolution
advisory alerts  collision avoidance system ii resolution advisory
climb priority  collision avoidance system ii resolution advisory
climb warning  collision avoidance system ii resolution advisory
signals  collision avoidance system ii resolution advisory zone 
collision avoidance system ii resolution advisory traffic advisory
alert  collision avoidance system ii resolution advisory traffic advisory alerts advisories  collision avoidance system ii resolution
advisory altitude deviation  collision avoidance system ii traffic
advisory resolution advisory alerts  collision avoidance system ii windshear warning  collision avoidance system ii advisory alert  collision avoidance system ii advisory alert warning 
collision avoidance system ii warning aircraft
agreed judges incorrect  collision avoidance system ii    oclock         mile  collision avoidance system ii resolution advisory climb command  collision avoidance
system ii resolution advisory area  collision avoidance system
ii resolution advisory climb descent  collision avoidance system ii resolution advisory data tag  collision avoidance system
ii resolution advisory descent  collision avoidance system ii resolution advisory green band target  collision avoidance system ii
resolution advisory increase climb  collision avoidance system ii
resolution advisory maneuvering  collision avoidance system ii
resolution advisory messages  collision avoidance system ii resolution advisory recovery procedure  collision avoidance system
ii resolution advisory requirement  collision avoidance system ii
resolution advisory requiring climb  collision avoidance system
ii resolution advisory resolution  collision avoidance system ii
traffic advisory notification  collision avoidance system ii traffic
advisory resolution advisory aircraft  collision avoidance system
ii traffic advisory resolution advisory event  collision avoidance
system ii action requirements  collision avoidance system ii advice 
collision avoidance system ii advisories instructions  collision
avoidance system ii caution  collision avoidance system ii quit

   

fiabedin  ng   khan

appendix g  lexicon learned modified basilisk categories people
equipment
following table shows words phrases learned modified basilisk framework
categories people equipment  see section        
category
people

equipment

new words
agreed judges correct  first officer  first officer    first officer  cp  captain  captain rptr  captain trainee 
co captain  co pilot  first officer  first officer      initial operating experience captain  paxs  pilot flying first officer 
potomac controller  rpting captain  rpting first officer  rpting pilot  rptr captain  rptr pilot  s o  zoa supervisor  air
carrier pilot  aircraft x pilot  aircraft commander  passenger  analyst  first officer  baron pilot  biplane pilot  controller 
facility person  first observer  flight attendant      flight attendants
passenger  flying captain  forward observer  passenger  passenger crew  passenger flight attendants  right seat pilot  second observer  sic  specialist  student captain  supervisor controller 
tower controller  tower operator  training pilot
identified one judge correct  rptr  gate passenger 
first officer
agreed judges incorrect  departure departure 
neither captain  clrly
agreed judges correct      auto pilot   
  auto pilot    autoplts  autoflt  autothrottle 
autothrottle auto pilot  autothrottles  autothrottles auto pilot  autothrust  auto pilot
     auto pilot      auto pilot b  auto pilot autothrust  auto pilot pms  auto pilot throttles  autopilot autothrottles  cessna      collision avoidance system
ii system  engs          aircraft abcd  aircraft auto pilot 
aircraft engine  allowed aircraft  automatic pilot  automatic throttle 
automatic throttles  autopilot  center auto pilot  craft  emergency
engine  left auto pilot  left hand engine  parked plane  right autopilot
identified one judge correct 
problem engine  maintenance aircraft  later aircraft  aircraft aircraft  collision
avoidance system ii alert      constant speed drive  auto pilot
autothrottles  wdb    perf
agreed judges incorrect  aircraft beginning  aircraft
parallel  normal aircraft  person property  persons property 
aircraft  time aircraft

   

ficause identification via weakly supervised semantic lexicon construction

references
ando  r  k          semantic lexicon construction  learning unlabeled data via
spectral analysis  proceedings  th conference computational natural
language learning  pp      
artstein  r     poesio  m          inter coder agreement computational linguistics 
computional linguistics                 
avancini  h   lavelli  a   sebastiani  f     zanoli  r          automatic expansion
domain specific lexicons term categorization  acm transactions speech
language processing  tslp              
baker  l  d     mccallum  a  k          distributional clustering words text classification  proceedings   st annual international acm sigir conference
research development information retrieval  pp        
banko  m     brill  e          mitigating paucity of data problem  exploring effect training corpus size classifier performance natural language processing 
proceedings  st international conference human language technology
research 
blei  d  m   ng  a  y     jordan  m  i          latent dirichlet allocation  journal
machine learning research             
brants  t     franz  a          web  t   gram version    linguistic data consortium 
philadelphia  usa 
cheng  p  w          covariation causation  causal power theory  psychological
review                  
chinchor  n          statistical significance muc   results  proceedings
 th message understanding conference  pp       
chinchor  n   hirschman  l     lewis  d  d          evaluating message understanding systems  analysis third message understanding conference  muc    
computational linguistics             
cortes  c     vapnik  v          support vector networks  machine learning             
    
crammer  k     singer  y          algorithmic implementation multiclass kernelbased vector machines  journal machine learning research            
curran  j  r     moens  m          improvements automatic thesaurus extraction 
proceedings acl      workshop unsupervised lexical acquisition  pp 
     
curran  j  r   murphy  t     scholz  b          minimising semantic drift mutual
exclusion bootstrapping  proceedings   th conference pacific association computational linguistics  pp         
   

fiabedin  ng   khan

davidov  d     rappoport  a          efficient unsupervised discovery word categories
using symmetric patterns high frequency words  proceedings   st international conference computational linguistics   th annual meeting
association computational linguistics  pp         
dietterich  t  g          approximate statistical tests comparing supervised classification learning algorithms  neural computation                   
dunning  t          accurate methods statistics surprise coincidence  computational linguistics               
everitt  b  s          analysis contingency tables  chapman hall 
ferryman  t  a   posse  c   rosenthal  l  j   srivastava  a  n     statler  i  c         
happened  why  toward understanding human error based automated
analyses incident reports volume ii  tech  rep  nasa tp             national
aeronautics space administration 
ganeri  j   noordhof  p     ramachandran  m          counterfactuals preemptive
causation  analysis                 
garcia  d          coatis  nlp system locate expressions actions connected
causality links  proceedings   th european workshop knowledge
acquisition  modeling mangement  pp         
girju  r          automatic detection causal relations question answering  proceedings acl      workshop multilingual summarization question
answering  pp       
godbole  s     sarawagi  s          discriminative methods multi labeled classification 
proceedings  th pacific asia conference knowledge discovery data
mining  pp       
griffiths  t  l     tenenbaum  j  b          structure strength causal induction 
cognitive psychology             
grishman  r     ksiezyk  t          causal temporal text analysis  role
domain model  proceedings   th international conference computational
linguistics  pp         
halpern  j  y     pearl  j          causes explanations  structural model approach 
part i  causes  british journal philosophy science             
hassan  h   hassan  a     emam  o          unsupervised information extraction approach
using graph mutual reinforcement  proceedings      conference empirical
methods natural language processing  pp         
hume  d         original work published         enquiry concerning human understanding  oxford university press  usa 
hume  d         original work published         treatise human nature  oxford
university press  usa 
joachims  t          advances kernel methods   support vector learning  chap  making
large scale svm learning practical  mit press 
   

ficause identification via weakly supervised semantic lexicon construction

joachims  t          text categorization suport vector machines  learning many
relevant features  proceedings   th european conference machine learning  pp         
joachims  t          transductive inference text classification using support vector
machines  proceedings   th international conference machine learning 
pp         
kaplan  r     berry rogghe  g          knowledge based acquisition causal relationships
text  knowledge acquisition                
kersey  c   di eugenio  b   jordan  p     katz  s          ksc pal  peer learning agent
encourages students take initiative  proceedings  th workshop
innovative use nlp building educational applications  pp       
khoo  c  s  g   chan  s     niu  y          extracting causal knowledge medical
database using graphical patterns  proceedings   th annual meeting
association computational linguistics  pp         
ko  y   park  j     seo  j          improving text categorization using importance
sentences  information processing management               
krippendorff  k          content analysis  introduction methodology  sage publications  inc 
lewis  d          causation  journal philosophy                  
lin  d          dependency based evaluation minipar  proceedings lrec
workshop evaluation parsing systems  pp         
lin  d     pantel  p          induction semantic classes natural language text 
proceedings  th acm sigkdd international conference knowledge discovery data mining  pp         
marcus  m  p   santorini  b     marcinkiewicz  m  a          building large annotated
corpus english  penn treebank  computational linguistics                 
special issue using large corpora 
mccallum  a     nigam  k          text classification bootstrapping keywords 
em shrinkage  proceedings acl workshop unsupervised learning
natural language processing  pp       
noreen  e  w          computer intensive methods testing hypotheses   introduction  wiley 
pantel  p     lin  d          discovering word senses text  proceedings  th
acm sigkdd international conference knowledge discovery data mining 
pp         
pantel  p     ravichandran  d          automatically labeling semantic classes  proceedings human language technology conference north american chapter
association computational linguistics  pp         
passonneau  r          computing reliability coreference annotation  proceedings
fourth international conference language resources evaluation  vol    
pp           
   

fiabedin  ng   khan

patwardhan  s     riloff  e          learning domain specific information extraction patterns web  proceedings coling acl workshop information
extraction beyond document  pp       
patwardhan  s     riloff  e          effective information extraction semantic affinity
patterns relevant regions  proceedings      joint conference empirical methods natural language processing computational natural language
learning  pp         
pereira  f  c  n   tishby  n     lee  l          distributional clustering english words 
proceedings   st annual meeting association computational linguistics  pp         
phan  x  h       a   crfchunker  crf english phrase chunker  http   crfchunker 
sourceforge net  
phan  x  h       b   crftagger  crf english pos tagger 
sourceforge net  

http   crftagger 

phillips  w     riloff  e          exploiting role identifying nouns expressions information extraction  proceedings international conference recent advances
natural language processing 
polanyi  l     zaenen  a          contextual valence shifters  computing attitude
affect text  theory applications  pp       springer verlag 
posse  c   matzke  b   anderson  c   brothers  a   matzke  m     ferryman  t         
extracting information narratives  application aviation safety reports 
proceedings      ieee aerospace conference  pp           
read  j   pfahringer  b     holmes  g          multi label classification using ensembles
pruned sets  proceedings  th ieee international conference data
mining  pp          
riloff  e          automatically generating extraction patterns untagged text 
proceedings   th national conference artificial intelligence  pp           
roark  b     charniak  e          noun phrase co occurrence statistics semi automatic
semantic lexicon construction  proceedings   th international conference
computational linguistics  pp           
rohwer  r     freitag  d          towards full automation lexicon construction 
proceedings computational lexical semantics workshop hlt naacl      
pp      
rychly  p     kilgarriff  a          efficient algorithm building distributional
thesaurus  and sketch engine developments   proceedings acl     
demo poster sessions  pp       
sebastiani  f          machine learning automated text categorization  acm computing
surveys              
sundheim  b  m          overview fourth message understanding evaluation
conference  proceedings fourth message understanding conference  pp   
   
   

ficause identification via weakly supervised semantic lexicon construction

tang  l   rajan  s     narayanan  v  k          large scale multi label classification via
metalabeler  proceedings international world wide web conference  pp     
    
thelen  m     riloff  e          bootstrapping method learning semantic lexicons
using extraction pattern contexts  proceedings      conference empirical
methods natural language processing  pp         
tsoumakas  g     katakis  i          multi label classification  overview  international
journal data warehousing mining             
tsoumakas  g     vlahavas  i  p          random k  labelsets  ensemble method
multilabel classification  proceedings   th european conference machine
learning  vol       lecture notes computer science  pp         
ueda  n     saito  k          parametric mixture models multi labeled text  advances
neural information processing systems     pp         
van delden  s     gomez  f          retrieving nasa problem reports  case study
natural language information retrieval  data knowledge engineering         
       
vapnik  v  n          statistical learning theory  wiley 
yang  y     pedersen  j  o          comparative study feature selection text categorization  proceedings   th international conference machine learning 
pp         
yangarber  r          counter training discovery semantic patterns  proceedings
  st annual meeting association computational linguistics  pp 
       
zaidan  o  f   eisner  j     piatko  c          using annotator rationales improve machine learning text categorization  proceedings human language technology conference north american chapter association computational
linguistics  pp         
zhang  q   zhou  y   huang  x     wu  l          graph mutual reinforcement based
bootstrapping  information retrieval technology                    

   


