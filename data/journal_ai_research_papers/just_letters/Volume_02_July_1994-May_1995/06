journal artificial intelligence research                 

submitted        published     

adaptive load balancing  study multi agent
learning
andrea schaerf

aschaerf dis uniroma  it

dipartimento di informatica e sistemistica
universita di roma  la sapienza   via salaria      i       roma  italy

yoav shoham

robotics laboratory  computer science department
stanford university  stanford  ca        usa

moshe tennenholtz

faculty industrial engineering management
technion  haifa        israel

shoham flamingo stanford edu
moshet ie technion ac il

abstract
study process multi agent reinforcement learning context load balancing distributed system  without use either central coordination explicit communication  first define precise framework study adaptive load balancing 
important features stochastic nature purely local information
available individual agents  given framework  show illuminating results
interplay basic adaptive behavior parameters effect system eciency 
investigate properties adaptive load balancing heterogeneous populations 
address issue exploration vs  exploitation context  finally  show
naive use communication may improve  might even harm system eciency 

   introduction
article investigates multi agent reinforcement learning context concrete
problem undisputed importance   load balancing  real life provides us many examples emergent  uncoordinated load balancing  trac alternative highways tends
even time  members computer science department tend use powerful networked workstations  eventually find lower load machines
inviting  on  would understand dynamics emergent
load balancing systems apply lesson design multi agent systems 
define formal yet concrete framework study issues  called multiagent multi resource stochastic system  involves set agents  set resources 
probabilistically changing resource capacities  probabilistic assignment new jobs agents 
probabilistic job sizes  agent must select resource new job 
eciency resource handles job depends capacity resource
lifetime job well number jobs handled resource
period time  performance measure system aims globally optimizing
resource usage system ensuring fairness  that is  system shouldn t made
ecient expense particular agent   two common criteria load balancing 
c      ai access foundation morgan kaufmann publishers  rights reserved 

fischaerf  shoham    tennenholtz

agent choose appropriate resource order optimize measures 
make important assumption  spirit reinforcement learning  sutton 
       information available agent prior experience  particular 
agent necessarily know past  present  future capacities resources  
unaware past  current  future jobs submitted various agents  even
relevant probability distributions  goal agent thus adapt resourceselection behavior behavior agents well changing capacities
resources changing load  without explicitly knowing are 
interested several basic questions 

good resource selection rules 
fact different agents may use different resource selection rules affect
system behavior 

communication among agents improve system eciency 
following sections show illuminating answers questions  contribution paper therefore twofold  apply multi agent reinforcement learning
domain adaptive load balancing use basic domain order demonstrate
basic phenomena multi agent reinforcement learning 
structure paper follows  section   discuss general setting 
objective section motivate study point impact  formal
framework defined discussed section    section   completes discussion
framework introducing resource selection rule parameters  function
 control knobs  adaptive process  section   present experimental results
adaptive behavior within framework show various parameters affect
eciency adaptive behavior  case heterogeneous populations investigated
section    case communicating populations discussed section    section  
discuss impact results  section   put work perspective
related work  finally  section    conclude brief summary 

   general setting

paper applies reinforcement learning domain adaptive load balancing  however  presenting model use detailed study  need clarify several
points general setting  particular  need explain interpretation
reinforcement learning interpretation load balancing adopt 
much work devoted recent years distributed adaptive load balancing  one find related work field distributed computer systems  e g   pulidas 
towsley    stankovic        mirchandaney   stankovic        billard   pasquale       
glockner   pasquale        mirchandaney  towsley    stankovic        zhou        eager 
lazowska    zahorjan         organization theory management science  e g   malone 
   many applications capacities resources known  least extent  point
discussed later  basically  paper wish investigate far one go using purely
local feedback without use global information  kaelbling        sutton        

   

fiadaptive load balancing  study multi agent learning

       distributed ai  e g   bond   gasser         although motivations
above mentioned lines research similar  settings discussed essential
differences 
work distributed computer systems adopts view set computers
controls certain resources  autonomous decision making capability  jobs
arrive dynamic fashion  decision making agents different computers
 also called nodes  try share system load coordinate activities means
communication  actual action performed  based information received
computers  may controlled various ways  one ways adopted control
related decisions learning automata  narendra   thathachar        
above mentioned work agent associated set resources 
agent related resources associated node distributed system 
much work management science distributed ai adopts somewhat complementary
view  difference classical work distributed operating systems  agent
associated set resources controls  agents autonomous entities
negotiate among  zlotkin   rosenschein        kraus   wilkenfeld       
use shared resources  alternatively  agents  called managers case  may
negotiate task executed processors may execute  malone        
model adopt avor models used distributed ai organization
theory  assume strict separation agents resources  jobs arrive agents
make decisions execute them  resources passive  i e  
make decisions   typical example setting computerized framework set
pcs  controlled different user submits jobs executed
one several workstations  workstations assumed independent
shared among users  example real life situation motivated
study terminology adopt taken framework  however 
real life situations related model areas different classical distributed
computer systems 
canonical problem related model following one  arthur         agent 
embedded multi agent system  select among set bars  or set restaurants  
agent makes autonomous decision performance bar  and therefore
agents use it  function capacity number agents use it 
decision going bar stochastic process decision bar use
autonomous decision respective agent  similar situation arises product
manager decides processor use order perform particular task  model
present section   general model situations investigated 
situations job arrives agent  rather node consisting particular resources 
decides upon resource  e g   restaurant  job executed 
a priori association agents resources 
discuss way agents behave framework  common theme
among above mentioned lines research load balancing achieved means
communication among active agents active resources  through related decisionmaking agents   study adopt complementary view  consider agents
act purely local fashion  based purely local information described recent
reinforcement learning literature  mentioned  learning automata used
   

fischaerf  shoham    tennenholtz

field distributed computer systems order perform adaptive load balancing  nevertheless  related learning procedures rely heavily communication among agents  or
among decision making agents autonomous computers   work applies recent work
reinforcement learning ai information agent gets purely local  hence 
agent know ecient service restaurant choosing
place eat  don t assume agents may informed agents load
restaurants restaurants announce current load  makes
work strictly different work applying reinforcement learning adaptive load
balancing 
features make model study basic general  moreover 
discussion raises question whether reinforcement learning  based purely
local information feedback  guarantee useful load balancing  combination
model use perspective reinforcement learning makes contribution
novel  nevertheless  mentioned  and discuss section    model
use original us captures many known problems situations distributed
load balancing  apply reinforcement learning  discussed recent ai literature 
model investigate properties related process 

   multi agent multi resource stochastic system

section define concrete framework study dynamic load balancing 
model present captures adaptive load balancing general setting mentioned
section    restrict discussion discrete  synchronous systems  and thus
definition refer n   natural numbers   similar definitions possible
continuous case  concentrate case job executed using
resources  although somewhat restricting  common practice much work
distributed systems  mirchandaney   stankovic        

definition     multi agent multi resource stochastic system   tuple ha  r  p   d  c 
sri    fa          g set agents  r   fr          rm g set resources 
p   n          job submission function    n     probabilistic job size
function  c   rn     probabilistic capacity function  sr resource selection
rule 

intuitive interpretation system follows  resources
certain capacity  real number  capacity changes time  determined
function c   time point agent either idle engaged  idle  may
submit new job probability given p   job certain size
real number  size submitted job determined function d   we
use unit token referring job sizes resource capacities  mean
tokens come integer quantities   new job agent selects one
resources  choice made according rule sr  since much say
rule  discuss separately next section 
model  job may run resource  furthermore  limit
number jobs served simultaneously given resource  and thus queuing occurs  
however  quality service provided resource given time deteriorates
   

fiadaptive load balancing  study multi agent learning

number agents using time  specifically  every time point resource
distributes current capacity  i e   tokens  equally among jobs served it 
size job reduced amount and  drops  or below  zero  job
completed  agent notified this  becomes idle again  thus  execution time
job j depends size  capacity time resource processing it 
number agents using resource execution j  
measure system s performance twofold  aim minimize timeper token  averaged jobs  well minimize standard deviation
random variable  minimizing quantities ensure overall system eciency well
fairness  question selection rules yield ecient behavior  turn next
definition rules 

   adaptive resource selection rules
rule agents select resource new job  selection rule  sr  
heart adaptive scheme topic section  throughout section
following one make assumption homogeneity  namely  assume
agents use sr  notice although system homogeneous  agent
act based local information  sections     relax homogeneity
assumption discuss heterogeneous communicating populations 
already emphasized  among possible adaptive srs interested
purely local srs  ones access experience particular agent 
setting experience consists results previous job submissions  job submitted
agent already completed  agent knows name r resource used 
point time  tstart   job started  point time  tstop   job finished 
job size   therefore  input sr is  principle  list elements form
 r  tstart  tstop      notice type input captures general type systems
interested in  basically  wish assume little possible information
available agent order capture real loosely coupled systems global
information unavailable 
whenever agent selects resource job execution  may get feedback
non negligible time  feedback may depend decisions made agents
agent i s decision  forces agent rely non trivial portion
history makes problem much harder 
uncountably many possible adaptive srs aim gain exhaustive understanding them  rather  experimented family intuitive
relatively simple srs compared non adaptive ones  motivation choosing particular family srs partially due observations made
cognitive psychologists people tend behave multi agent stochastic recurrent situations  principle  set srs captures two robust aspects
observations   the law effect   thronkide         power law practice   blackburn         family rules  called
  partially resembles learning rules
discussed learning automata literature  narendra   thathachar         partially resembles interval estimation algorithm  kaelbling         agents maintain
complete history experience  instead  agent  a  condenses history
   

fischaerf  shoham    tennenholtz

vector  called eciency estimator  denoted eea   length vector
number resources  i th entry vector represents agent s evaluation
current eciency resource  specifically  eea  r  positive real number  
vector seen state learning automaton  addition eea   agent keeps
vector jda  stores number completed jobs submitted agent
resources  since beginning time  thus  within
  need specify
two elements 
   agent updates eea job completed
   agent selects resource new job  given eea jda
loosely speaking  eea maintained weighted sum new feedback
previous value eea   resource selected probably one highest
eea entry except low probability resource chosen  two
steps explained precisely following two subsections 

    updating eciency estimator
take function updating eea

eea  r     wt        w  eea  r 
represents time per token newly completed job computed
feedback  r  tstart  tstop    following way  

   tstop   tstart  s
take w real value interval         whose actual value depends jda r  
means take weighted average new feedback value old
value eciency estimator  w determines weights given pieces
information  value w obtained following function 

w   w        w  jda r 
formula w real valued constant  term      w  jda r  correcting
factor  major effect jda  r  low  jda  r  increases  reaching
value several hundreds  term becomes negligible respect w 

    selecting resource

second ingredient adaptive srs
function pda selecting resource
new job based eea jda   function probabilistic  first define following
function
 
jda r     
 r  n
 
pda r     ee
 
n
e  ee  
jd  r     




   using parallel processing terminology  viewed stretch factor  quantifies stretching
program s processing time due multiprogramming  ferrari  serazzi    zeigner        

   

fiadaptive load balancing  study multi agent learning

n positive real valued parameter e  eea  represents average values
eea  r  resources satisfying jda  r       turn probability function 
define pda normalized version pd a  

pda r     pd a r  
  rpd a  r  normalization factor  
function pda clearly biases selection towards resources performed
well past  strength bias depends n  larger value n 
stronger bias  extreme cases  value n high  e g        agent
always choose resource best record  strategy  always choosing
best   although perhaps intuitively appealing  general good one 
allow agent exploit improvements capacity load resources 
discuss sr following subsection  expand issue exploration versus
exploitation sections     
summarize  defined general setting investigate emergent load
balancing  particular  defined family adaptive resource selection rules 
parameterized pair  w  n   parameters serve knobs tune
system optimize performance  next section turn experimental
results obtained system 

    best choice sr  bcsr 

best choice sr  bcsr  learning rule assumes high value n  i e 
always chooses best resource given point  assume w fixed given
value discussing bcsr  previous work  shoham   tennenholtz              
showed learning rules strongly resemble bcsr useful several natural
multi agent learning settings  suggests need carefully study case
adaptive load balancing  demonstrate  bcsr always useful load
balancing setting 
difference bcsr learning rule value n low 
latter case agent gives relatively high probability selection resource
didn t give best results past  case agent might able notice
behavior one resources improved due changes system 
note exploration  non best  resources crucial dynamics
system includes changes capacities resources  cases  agent could
take advantage possible increases capacity resources uses bcsr  one
might wonder  however  whether cases main dynamic changes system
stem load changes  relying bcsr sucient  latter true 
able ignore parameter n concentrate bcsr  systems
capacity resources fixed  order clarify point  consider following
example 
   r jda  r        i e   agent going submit first job   assume
agent chooses resource randomly  with uniform probability distribution  

   

fischaerf  shoham    tennenholtz

suppose two resources  r  r    whose respective  fixed  capacities 
cr  cr    satisfy equality cr     cr    assume load system varies

certain low value certain high one 
system s load low agents adopt bcsr  system evolve
way almost agents would preferring r  r   due
fact that  case low load  overlaps jobs  hence r  much
ecient  hand  system s load high  r  could busy
agents would prefer r   since performance obtained using
less crowded resource r  could better one obtained using overly crowded
resource r   extreme case high load  expect agents use r  one
third time 
assume load system starts low level  increases
high value  decreases reach original value  load increases 
agents  mostly using r   start observing r  s performance becoming
worse and  therefore  following bcsr start using r  too  now  load
decreases  agents using r  observe improvement performance
r   value stored r   i e   eea       still ect previous
situation  hence  agents keep using r   ignoring possibility obtaining
much better results moved back r   situation  randomized selection
makes agents able use r   with certain probability  therefore
may discover performance r  better r  switch back r  
improve system s eciency significant manner 
example shows bcsr is  general case  good choice 
general true value n high 
discussion assumed changes load unforeseen 
able predict changes load  agents simply use bcsr
load fixed use low value n changes  case  instead 
without even realizing system changed way  agents would need
 and  see  would able to  adapt dynamic changes well other 

   experimental results
section compare srs
another  well non adaptive 
benchmark selection rules 
non adaptive srs consider paper agents partition
according capacities load system fixed predetermined
manner agent uses always resource  later paper  sr
kind identified configuration vector  specifies  resource  many
agents use it  test adaptive srs  compare performance nonadaptive srs perform best particular problem  creates highly competitive
set benchmarks adaptive srs 
addition  compare adaptive srs load querying sr defined
follows  agent  new job  asks resources busy
always chooses less crowded one 
   

fiadaptive load balancing  study multi agent learning

    experimental setting
introduce particular experimental setting  many results described
obtained  present order concrete experiments  however 
qualitative results experiments observed variety experimental
settings 
one motivation particular setting stems pcs workstations problem
mentioned section    example  part study related set computers
located single site  computers relatively high load peak hours
day low load night  i e   chances user pc submits job
higher day time week days night weekend   another
part study related set computers split around world 
load quite random structure  i e   due difference time zones  users may use pcs
unpredictable hours  
another motivation particular setting stems restaurant problem mentioned section    for discussion related  bar problem  see arthur        
example  consider set snack bars located industrial park  snack
bars relatively high loads peak hours day low load night
 i e   chances employee choose go snack bar higher day
employees present day   conversely  assume
set bars near airport load quite random structure  i e   airport
employees may use snack bars quite unpredicted hours  
although particular real situations  would emphasize general
motivation study fact related phenomena observed
various different settings 
take n   number agents         number resources 
   first set experiments take capacities resources fixed 
particular  take c        c        c        c        c        assume
agents probability submitting new job  assume
agents distribution size jobs submit  specifically  assume
uniform distribution integers range          
ease exposition  assume point time corresponds second 
consequently count time minutes  hours  days  weeks  hour
main point reference  assume  simplicity  changes system  i e   load
change capacity change  happen beginning new hour  probability
submitting job second  corresponds load system  vary
time  crucial factor agents must adapt  note agents
submit jobs second  probability submission may change  particular
concentrate three different values quantity  called llo   lhi lpeak  
assume system load switches values  actual values llo   lhi
lpeak following quantitative results                roughly correspond
agent submitting               jobs per hour  per agent  respectively 
   

fischaerf  shoham    tennenholtz

load

configuration
time per token
llo
f               g
      
lhi
f                g
      
lpeak f                  g
       
figure    best non adaptive srs fixed load
following  measuring success  refer average time pertoken   however  adaptive srs give best average time per token
found fair 

    fixed load

start case load fixed  case interesting
adaptive behavior  however  satisfactory sr show reasonably ecient behavior
basic case  order useful system stabilizes 
start showing behavior non adaptive benchmark srs case fixed
load   figure   shows give best results  three loads 
see  big difference three loads mentioned above 
load particularly high  agents scatter around resources rate
proportional capacities  load low use best resource 
given above  easy see adaptive sr effective enables
moving quickly one configuration other 
static setting this  expect best non adaptive srs perform better adaptive ones  since information gained exploration adaptive srs
built in non adaptive ones  experimental results confirm intuition 
shown figure   lhi   figure shows performance obtained population
value n varies      three values w                
note values  n  w  good choices dynamic cases  see later
paper  values intervals                    respectively   deterioration
performance adaptive srs respect non adaptive ones small 
encouraging result  since adaptive srs meant particularly suitable dynamic
systems  following subsections see indeed are 

    changing load

begin explore dynamic settings  consider case
load system  that is  probability agents submitting job time  changes
time  paper present two dynamic settings  one load changes
according fixed pattern random perturbations another
load varies random fashion  specifically  first case fix load lhi
   data shown later refer  convenience  time      tokens 
   non adaptive srs human designed srs used benchmarks  assume knowledge
load capacity  available adaptive srs design 

   

fiadaptive load balancing  study multi agent learning


v
e
r

g
e



e
p
e
r


k
e
n

 
  





weight  w      
weight  w      
weight  w      

  





  
  





  
  
  
 



























 
   
   
 
    
exponent randomization function  n

 

figure    performance adaptive selection rules fixed load
ten consecutive hours  five days week  two randomly chosen hours
lpeak   llo rest week  second case  fix number
hours week load first case  distribute completely
randomly week 
results obtained two cases similar  figure   shows results obtained
adaptive srs case random load  best non adaptive deterministic
sr gives time per token value        obtained configuration  partition
agents  f                g  adaptive srs superior  load querying sr instead gets
time per token value         obviously better  far
performances adaptive srs 
observe following phenomenon  given fixed n  resp  fixed w  average
time per token non monotonic w  resp  n   phenomenon strongly related
issue exploration versus exploitation mentioned phenomena observed
study q learning  watkins        
notice two parameters n w interplay  fact  value
w minimum time per token value obtained different value n 
precisely  higher w lower n must order obtain best results  means
that  order obtain high performance  highly exploratory activity  low n 
matched giving greater weight recent experience  high w    parameter
   

fischaerf  shoham    tennenholtz


v
e
r

g
e



e
p
e
r


k
e
n

 
  
  
  


weight  w      




weight  w      
weight  w      













  












  
  
  
 













 
   
   
 
    
exponent randomization function  n

 

figure    performance adaptive selection rules random load
matching  intuitively explained following qualitative way  exploration
activity pays allows agent detect changes system  however 
effective if  change detected  significantly affect eciency estimator
 i e   w high   otherwise  cost exploration activity greater gain 

    changing capacities
consider case capacity resources vary time 
particular  demonstrate results case previously mentioned setting 
assume capacities rotate randomly among resources and  five consecutive
days  resource gets capacity    one day       days    
  days   load varies randomly 
results experiment shown figure    best non adaptive sr
case gives time per token value         obtained configuration
f                  g   adaptive srs give much better results  slightly
   usually capacities change less dramatic fashion  use above mentioned setting
order demonstrate applicability approach severe conditions 
   load querying sr gives results case fixed capacities  sr
obviously uenced change 

   

fiadaptive load balancing  study multi agent learning


v
e
r

g
e



e
p
e
r


k
e
n

 




    




  





    



    






  




  

    



 








weight  w      

weight  w      
weight  w      




 

 
 
 
     
    
exponent randomization function  n

figure    performance adaptive selection rules changing capacities
worse case fixed capacities  phenomena mentioned visible
case too  see example weight     mismatches low values n 

   heterogeneous populations
throughout previous section assumed agents use sr  i e 
homogeneity assumption  assumption models situation sort
centralized off line controller which  beginning  tells agents behave
leaves agents make decisions 
situation described different on line centralized controller makes every decision  however  would move even
investigate situation agent able make decision
strategy use and  maybe  adjust time 
step toward study systems kind  drop homogeneity assumption
consider situation part population uses one sr part
uses second one 
first set experiments  consider setting discussed subsection    
confront one other  two populations  called      size     agents
each   population uses different sr
  sr population  for        
   

fischaerf  shoham    tennenholtz




v
e
r

g
e



e
p
e
r


k
e
n

 



  
  



  























  
  










  
  


  t 
  t 



   
   
   
 
    
exponent randomization function  n   

 

figure    performance   populations    agents n      w    w       
determined pair parameters  wi  ni    measure success population
defined average time per token members  denoted ti  
figure   shows result obtained w    w         n       different
values n    case randomly varying load 
results expose following phenomenon  two populations obtain different
outcomes ones obtain homogeneous case  specifically   
n      results obtained agents use n  generally better results
obtained ones use n    despite fact homogeneous population
uses n  gets better results homogeneous population uses n   
phenomenon described following intuitive explanation  n 
above mentioned range  population uses n  less  exploring   i e  
 exploiting   one  left might able
adapt changes satisfactory manner  however  joined
population  gets advantages experimental activity agents population 
without paying it  fact  exploring agents  trying unload
crowded resources  make service agents well 
worth observing figure   n  low  e g   n     agents use
n  take role explorers lose lot  agents use n  gain
situation  conversely  high values n   e g   n     performances exploiters 
   

fiadaptive load balancing  study multi agent learning


v
e
r

g
e



e
p
e
r


k
e
n



 
  
  



  


  t 
  t 










  
  
  










  
 
















 
   
   
 
    
exponent randomization function  n 

 

figure    performance   populations       agents n      w    w       
use n    deteriorate  means exploiters static  hinder
other  explorers take advantage it 
better understanding phenomena involved  experimented
asymmetric population  composed one large group one small one  instead two
groups similar size  figure   shows results obtained using setting similar
one above  population   composed    members population   consists
   members  case  every value n     exploiters better
explorers  experiments show case  higher n  better t 
is  i e  exploiters exploit  gain 
results suggest single agent gets best results noncooperative always adopting resource best performance  i e   use bcsr  
given rest agents use adaptive  i e   cooperative  sr  however 
agents non cooperative lose   conclusion  selfish interest
agent match interest population  contrary results
obtained basic contexts multi agent learning  shoham   tennenholtz        
shown how  fixed value w  coexisting populations adopting
different values n interact  similar results obtained fix value n
   fact illuminating instance well known prisoners dilemma  axelrod        

   

fischaerf  shoham    tennenholtz


v
e
r

g
e



e
p
e
r


k
e
n

 
  




  t 
  t 

  
  
  




















  

























  
  

 

                                        
weight estimator parameter  w  

 

figure    performance   populations    agents n    n      w       
use two different values w  cases  agents adopting lower value w
general winners  shown figure   n    n      w         w
low corresponding agents get poor results longer winners 
case high n figure   
another interesting phenomenon obtained confronting adaptive agents
load querying agents  load querying agents agents able consult resources
submit jobs  load querying agent submit job
unloaded resource given point  confronting load querying agents
adaptive ones  results obtained adaptive agents obviously worse
results obtained load querying ones  better results obtained
complete population adaptive agents  means load querying agents play
role  parasites   above mentioned  exploiters   load querying agents help
maintaining load balancing among resources  therefore help rest
agents  another result obtain agents adopt deterministic srs may behave
parasites worsen performance adaptive agents 
assertions supported experiments described figure    population    agents  uses adaptive sr parameters  n  w   faced
minority    agents use different srs  stated above  particular  four
cases consider  minority behaves following ways   i  choose resource
   

fiadaptive load balancing  study multi agent learning

   agents
   agents
t 
      
       
      
      
      
      
       load querying       
      
using res          

t 

      
      
      
      

figure    performance   populations       agents various srs
gave best results   ii  conservative updating history   iii 
load querying agents   iiii  use deterministically resource capacity   
 in basic experimental setting  

   communication among agents
point  assumed direct communication among agents 
motivation considered situations absolutely
transmission channels protocols  assumption agreement idea
multi agent reinforcement learning  systems massive communication feasible
much concerned multiple agent adaptation  problem reduces
supplying satisfactory communication mechanisms  multi agent reinforcement learning
interesting real life forces agents act without a priori arranged communication channels must rely action feedback mechanisms  however  interest
understand effects communication system eciency  as shoham   tennenholtz        tan         agents augmented sort communication
capabilities  study extension led illuminating results 
present 
assume agent communicate agents 
call neighbors  therefore consider relation neighbor of assume exive  symmetric transitive  consequence  relation neighbor of partitions
population equivalence classes  call neighborhoods 
form communication consider based idea eciency estimators agents within neighborhood shared among decision made
 i e   agent chooses resource   reader notice naive
form communication sophisticated types communication possible 
however  form communication natural concentrate agents
update behavior based past information  particular  type
communication similar ones used above mentioned work incorporating
communication framework multi agent reinforcement learning 
suppose different srs may used different agents population 
impose condition within single neighborhood  sr used
members 
assume agent keeps history updates
usual way  choice  instead  based agent eciency estimator 
   

fischaerf  shoham    tennenholtz


v
e
r

g
e



e
p
e
r


k
e
n

 
  
  














  





  



  



  
 














  
















    cns    agents
     cns   agents
     cns   agents

 
   
   
 
    
exponent randomization function  n

 

figure    performance adaptive selection rules random load profile communicating agents
average eciency estimators agents corresponding neighborhood 
average called neighborhood eciency estimator  neighborhood eciency
estimator physical storage  value recalculated time member needs it 
order compare behavior communicating agents non communicating ones 
assume single population might be  aside neighborhoods defined
above  neighborhoods allow sharing eciency estimators among
members  members neighborhoods behave described previous
sections  i e   agent relies history  thing common
among members neighborhood members use sr 
call communicating neighborhood  cn   neighborhood eciency estimators shared decision taken non communicating neighborhood  ncn  
neighborhood done 
first set experiments ran  regards population composed cns 
size  particular  considered cns various sizes  starting    cns
size    going   cns size     load profile exploited random load change
defined subsection      value w taken      n taken various
values  results obtained shown figure   
   

fiadaptive load balancing  study multi agent learning

results show communicating populations get good results 
reason members cn tend conservative  sense
mostly use best resource  fact  since rely average several agents 
picture system tends much static  particular  bigger
cn conservative members tend be  example  consider values
 n  w  give best results non communicating agents  values give quite bad
performance cns since turn conservative 
using adaptive values  n  w   behavior communicating population improves reaches performance slightly worse performance
non communicating population  tuning parameters using finer grain  possible
obtain performance equal one obtained non communicating population 
however  seems clear obvious gain achieved form communication
capability  intuitive explanation two opposite effects caused
communication  one hand  agents get fairer picture system prevents using bad resources therefore getting bad performance 
hand  since agents cn  better  picture system  tend
use best resources thus compete them  fact  agents behave
selfishly selfish interest may agree interest population
whole 
interesting message get fact agents may
 distorted  picture system  which typical non communicating populations  
turns advantage population whole 
sharing data among agents leads poorer performances case
agents common views loads target jobs toward  lightly loaded 
resources  quickly become overloaded  order profitably use shared data 
allow form reasoning fact data shared 
problem however scope paper  see e g   lesser        
order understand behavior system cns ncns face other 
consider ncn    agents together set cns equal size  different values
size  results corresponding experiments shown figure    
members cns  inclined use best resources  behave parasites
sense explained section    exploit adaptiveness rest population
obtain good performance best resources  reason get better results
rest population  shown experimental results 
interesting observe ncn uses conservative selection rule 
cns obtain even better results  intuitive explanation behavior
although groups  i e   communicating ones one high value n 
tend conservative  communicating ones  win  conservative
 clever  way  making use better picture situation 
conclusion draw section proposed form communication
agents may provide useful means improve performance population
setting  however  claim communication agents completely
useless  nevertheless  observed provide straightforward significant
improvement  results support claim sole past history agent
   

fischaerf  shoham    tennenholtz

   agents
         ncn
         ncn
         ncn
         ncn
          ncn
          ncn
          ncn
          ncn

   agents
         cn
         cns
         cns
          cns
         cn
         cns
         cns
          cns

t 

      
      
      
      
      
      
      
      

t 

      
      
      
      
      
      
      
      

figure     performance cns ncns together
reasonable information base decision  assuming consider available
kind real time information  e g   current load resources  

   discussion
previous sections devoted report experimental study  synthesize observations view motivation  discussed sections     
mentioned  model general model active autonomous agents
select among several resources dynamic fashion based local information 
fact agents use local information makes possibility ecient loadbalancing questionable  however  showed adaptive load balancing based purely
local feedback feasible task  hence  results complementary ones obtained
distributed computer systems literature  mirchandaney stankovic        put
it         significant work illustrated possible design
learning controller able dynamically acquire relevant job scheduling information
process trial error  use information provide good performance  
study presented paper supplies complementary contribution able
show useful adaptive load balancing obtained using purely local information
framework general organizational theoretic model 
study identified various parameters adaptive process investigated
affect eciency adaptive load balancing  part study supplies
useful guidelines systems designer may force agents work based
common selection rule  observations  although somewhat related previous observations made contexts models  huberman   hogg         enable demonstrate
aspects purely local adaptive behavior non trivial model 
results disagreement selfish interest agents common
interest population sharp contrast previous work multi agent learning
 shoham   tennenholtz              dynamic programming perspective
earlier work distributed systems  bertsekas   tsitsiklis         moreover  explore
interaction different agent types affects system s eciency well
   

fiadaptive load balancing  study multi agent learning

individual agent s eciency  related results interpreted guidelines
designer may partial control system 
synthesis observations teaches us adaptive load balancing
one adopts reinforcement learning perspective agents rely local
information activity  additional step performed attempts bridge
gap local view previous work adaptive load balancing communicating
agents  whose decisions may controlled learning automata means 
therefore rule possibility communication current status resources
joint decision making  enable limited sharing previous history  show
limited communication may help  even deteriorate system eciency 
leaves us major gap previous work communication among agents
basic tool adaptive load balancing work  much left done attempting
bridge gap  see major challenge research 

   related work
section   mentioned related work field distributed computer systems
 mirchandaney   stankovic        billard   pasquale        glockner   pasquale       
mirchandaney et al         zhou        eager et al          typical example work
paper mirchandaney stankovic         work learning automata
used order decide action taken  however  suggested algorithms heavily
rely communication information sharing among agents  sharp contrast
work  addition  differences type model use
model presented above mentioned work work distributed computer
systems 
applications learning algorithms load balancing problems given mehra
        mehra wah         however  work well  agents  sites 
authors  terminology  ability communicate exchange workload values 
even though values subject uncertainty due delays  addition  differently
work  learning activity done off line  particular  learning phase
whole system dedicated acquisition workload indices  load indices
used running phase threshold values job migration different sites 
spite differences  similarities work abovementioned work  one important similarity use learning procedures 
difference classical work parallel distributed computation  bertsekas
  tsitsiklis        applies numerical iterative methods solution problems
network ow parallel computing  similarities related study
division society groups  somewhat resembles work group formation
 billard   pasquale        distributed computer systems  information sharing
allow section   similar limited communication discussed tan        
classification load balancing problems given ferrari         work falls
category load independent non preemptive pure load balancing  problems
investigate seen sender initiated problems  although case sender
agent  overloaded  resource 
   

fischaerf  shoham    tennenholtz

one may wonder work differs work adaptive load balancing
operations research  or   e g   queuing theory bonomi  doshi  kaufmann  lee   
kumar         indeed  commonalities  work  individual
decisions made locally  based information obtained dynamically runtime 
cases systems constructed suciently complex interesting
results tend obtained experimentally  however  careful look relevant
literature reveals essential difference perspective topic
reinforcement learning perspective  permits free communication within system 
thus significant element uncertainty framework  particular  issue
exploration versus exploitation  lies heart approach  completely
absent work or 
work adaptive load balancing related topics carried
artificial intelligence community  see e g   kosoresow        gmytrasiewicz  durfee   
wehe        wellman         work too  however  tends based form
communication among agents  whereas case load balancing obtained purely
learning activity 
article related previous work co learning  shoham   tennenholtz 
             framework co learning framework multi agent learning 
differs frameworks discussed multi agent reinforcement learning  narendra  
thathachar        tan        yanco   stein        sen  sekaran    hale        due
fact considers case stochastic interactions among subsets agents 
purely local feedback revealed agents based interactions 
framework co learning similar respects number dynamic frameworks
economics  kandori  mailath    rob         physics  kinderman   snell         computational ecologies  huberman   hogg         biology  altenberg   feldman        
study adaptive load balancing treated study co learning 
relevant work literature field learning automata  see narendra   thathachar         fact  agent setting seen learning automaton  therefore  one may hope theoretical results interconnected automata
n player games  see e g   el fattah        abdel fattah        narendra   wheeler jr  
      wheeler jr    narendra        could imported framework  unfortunately 
due stochastic nature job submissions  i e   agent interactions  real valued
 instead binary  feedback  problem fit completely theoretical
framework learning automata  hence  results concerning optimality  convergence expediency learning rules linear reward penalty linear reward inaction 
easily adapted setting  fact use stochastic model
interaction among agents  makes work closely related above mentioned work
co learning  nevertheless  work largely uenced learning automata theory
resource selection rules closely resemble reinforcement schemes learning automata 
last least  work related work applying organization theory management techniques field distributed ai  fox        malone        durfee  lesser 
  corkill         model closely related models decision making management
organization theory  e g   malone        applies reinforcement learning perspective context  makes work related psychological models decision making
 arthur        
   

fiadaptive load balancing  study multi agent learning

    summary

work applies idea multi agent reinforcement learning problem load
balancing loosely coupled multi agent system  agents need adapt one another well changing environment  demonstrated adaptive behavior
useful ecient load balancing context identified pair parameters
affect eciency non trivial fashion  parameter  holding parameter
fixed  gives rise certain tradeoff  two parameters interplay non trivial
illuminating way  exposed illuminating results regarding heterogeneous
populations  group parasitic less adaptive agents gain exibility agents  addition  showed naive use communication may
improve  might even deteriorate  system eciency 

acknowledgments

thank anonymous reviewers steve minton  whose stimulating comments helped
us improving earlier version paper 

references

abdel fattah  y  m          stochastic automata modeling certain problems collective
behavior  ieee transactions systems  man  cybernetics                  
altenberg  l     feldman  m  w          selection  generalized transmission 
evolution modifier genes  i  reduction principle  genetics               
arthur  w          inductive reasoning  bounded rationality bar problem  tech  rep 
           working paper   santa fe institute  appeared american economic
review    
axelrod  r          evolution cooperation  new york  basic books 
bertsekas  d     tsitsiklis  j          parallel distributed computation  numerical
methods  prentice hall 
billard  e     pasquale  j          effects delayed communication dynamic group
formation  ieee transactions systems  man  cybernetics                    
blackburn  j  m          acquisition skill  analysis learning curves  ihrb report
no     
bond  a  h     gasser  l          readings distributed artificial intelligence  ablex
publishing corporation 
bonomi  f   doshi  b   kaufmann  j   lee  t     kumar  a          case study
adaptive load balancing algorithm  queuing systems           
durfee  e  h   lesser  v  r     corkill  d  d          coherent cooperation among communicating problem solvers  ieee transactions computers                
   

fischaerf  shoham    tennenholtz

eager  d   lazowska  e     zahorjan  j          adaptive load sharing homogeneous
distributed systems  ieee transactions software engineering                  
el fattah  y  m          stochastic automata modeling certain problems collective
behavior  ieee transactions systems  man  cybernetics                  
ferrari  d          study load indices load balancing schemes  tech  rep  ucb csd
        computer science division  eecs   univ  california  berkeley 
ferrari  d   serazzi  g     zeigner  a          measurement tuning computer
systems  prentice hall 
fox  m  s          organizational view distributed systems  ieee transactions
systems  man  cybernetics            
glockner  a     pasquale  j          coadaptive behavior simple distributed job
scheduling system  ieee transactions systems  man  cybernetics         
        
gmytrasiewicz  p   durfee  e     wehe  d          utility communication coordinating intelligent agents  proc   th nat  conf  artificial intelligence
 aaai      pp          
huberman  b  a     hogg  t          behavior computational ecologies  huberman  b  a   ed    ecology computation  elsevier science 
kaelbling  l          learning embedded systems  mit press 
kandori  m   mailath  g     rob  r          learning  mutation long equilibria
games  mimeo  university pennsylvania 
kinderman  r     snell  s  l          markov random fields applications 
american mathematical society 
kosoresow  a  p          fast first cut protocol agent coordination  proc 
  th nat  conf  artificial intelligence  aaai      pp          
kraus  s     wilkenfeld  j          function time cooperative negotiations 
proc   th nat  conf  artificial intelligence  aaai      pp          
lesser  v  r          retrospective view fa c distributed problem solving  ieee
transactions systems  man  cybernetics                    
malone  t  w          modeling coordination organizations markets  management
science                     
mehra  p          automated learning load balancing strategies distributed
computer system  ph d  thesis  department electrical computer engineering 
university illinois urbana champaign 
   

fiadaptive load balancing  study multi agent learning

mehra  p     wah  b  w          population based learning load balancing policies
distributed computer system  proceedings computing aerospace   conference 
aiaa  pp            
mirchandaney  r     stankovic  j          using stochastic learning automata job
scheduling distributed processing systems  journal parallel distributed
computing             
mirchandaney  r   towsley  d     stankovic  j          analysis effects delays
load sharing  ieee transactions computers                     
narendra  k     thathachar  m  a  l          learning automata  introduction 
prentice hall 
narendra  k     wheeler jr   r  m          n player sequential stochastic game
identical payoffs  ieee transactions systems  man  cybernetics               
     
pulidas  s   towsley  d     stankovic  j          imbedding gradient estimators load balancing algorithms  proceedings  th international conference distributed
computer systems  ieee  pp          
sen  s   sekaran  m     hale  j          learning coordinate without sharing information 
proc    th nat  conf  artificial intelligence  aaai     
shoham  y     tennenholtz  m          emergent conventions multi agent systems  initial experimental results observations  proc   rd int  conf  principles
knowledge representation reasoning  kr      pp          
shoham  y     tennenholtz  m          co learning evolution social activity 
tech  rep  stan cs tr          dept  computer science  stanford university 
sutton  r          special issue reinforcement learning  machine learning          
tan  m          multi agent reinforcement learning  independent vs  cooperative agents 
proceedings   th international conference machine learning 
thronkide  e  l          animal intelligence  experimental study associative
processes animals  psychological monographs    
watkins  c          learning delayed rewards  ph d  thesis  cambridge university 
wellman  m  p          market oriented programming environment application
distributed multicommodity ow problems  journal artificial intelligence research 
        
wheeler jr   r  m     narendra  k          learning models decentralized decision
making  automatica                  
   

fischaerf  shoham    tennenholtz

yanco  h     stein  l          adaptive communication protocol cooperating mobile robots  animals animats  proceedings second international
conference simulation adaptive behavior  pp          
zhou  s          trace driven simulation study dynamic load balancing  ieee transactions software engineering                    
zlotkin  g     rosenschein  j  s          domain theory task oriented negotiation 
proc    th int  joint conf  artificial intelligence  ijcai      pp          

   


