journal of artificial intelligence research                 

submitted       published     

pac learning recursive logic programs 
negative results
william w  cohen

at t bell laboratories
    mountain avenue  murray hill  nj       usa

wcohen research att com

abstract

in a companion paper it was shown that the class of constant depth determinate k ary
recursive clauses is eciently learnable  in this paper we present negative results showing
that any natural generalization of this class is hard to learn in valiant s model of paclearnability  in particular  we show that the following program classes are cryptographically
hard to learn  programs with an unbounded number of constant depth linear recursive
clauses  programs with one constant depth determinate clause containing an unbounded
number of recursive calls  and programs with one linear recursive clause of constant locality 
these results immediately imply the non learnability of any more general class of programs 
we also show that learning a constant depth determinate program with either two linear
recursive clauses or one linear recursive clause and one non recursive clause is as hard as
learning boolean dnf  together with positive results from the companion paper  these
negative results establish a boundary of ecient learnability for recursive function free
clauses 

   introduction
inductive logic programming  ilp   muggleton        muggleton   de raedt        is
an active area of machine learning research in which the hypotheses of a learning system
are expressed in a logic programming language  while many different learning problems
have been considered in ilp  including some of great practical interest  muggleton  king 
  sternberg        king  muggleton  lewis    sternberg        zelle   mooney       
cohen      b   a class of problems that is frequently considered is to reconstruct simple
list processing or arithmetic functions from examples  a prototypical problem of this sort
might be learning to append two lists  often  this sort of task is attempted using only
randomly selected positive and negative examples of the target concept 
based on its similarity to the problems studied in the field of automatic programming
from examples  summers        biermann         we will  informally  call this class of
learning tasks automatic logic programming problems  while a number of experimental
systems have been built  quinlan   cameron jones        aha  lapointe  ling    matwin 
       the experimental success in automatic logic programming systems has been limited 
one common property of automatic logic programming problems is the presence of recursion   the goal of this paper is to explore by analytic methods the computational limitations
on learning recursive programs in valiant s model of pac learnability          in brief  this
model requires that an accurate approximation of the target concept be found in polynomial time using a polynomial sized set of labeled examples  which are chosen stochastically  
while it will surprise nobody that such limitations exist  it is far from obvious from previous
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

ficohen

research where these limits lie  there are few provably fast methods for learning recursive
logic programs  and even fewer meaningful negative results 
the starting point for this investigation is a series of positive learnability results appearing in a companion paper  cohen         these results show that a single constant depth
determinate clause with a constant number of  closed  recursive calls is pac learnable  they
also show that a two clause constant depth determinate program consisting of one nonrecursive clause and one recursive clause of the type described above is pac learnable  if some
additional  hints  about the target concept are provided 
in this paper  we analyze a number of generalizations of these learnable languages  we
show that that relaxing any of the restrictions leads to dicult learning problems  in particular  learning problems that are either as hard as learning dnf  an open problem in
computational learning theory   or as hard as cracking certain presumably secure cryptographic schemes  the main contribution of this paper  therefore  is a delineation of the
boundaries of learnability for recursive logic programs 
the paper is organized as follows  in section   we define the classes of logic programs and
the learnability models that are used in this paper  in section   we present cryptographic
hardness results for two classes of constant depth determinate recursive programs  programs
with n linear recursive clauses  and programs with one n ary recursive clause  we also
analyze the learnability of clauses of constant locality  another class of clauses that is paclearnable in the nonrecursive case  and show that even a single linearly recursive local
clause is cryptographically hard to learn  we then turn  in section    to the analysis of
even more restricted classes of recursive programs  we show that two different classes of
constant depth determinate programs are prediction equivalent to boolean dnf  the class
of programs containing a single linear recursive clause and a single nonrecursive clause  and
the class of programs containing two linearly recursive clauses  finally  we summarize the
results of this paper and its companion  discuss related work  and conclude 
although this paper can be read independently of its companion paper we suggest that
readers planning to read both papers begin with the companion paper  cohen        

   background

for completeness  we will now present the technical background needed to state our results 
however  aside from sections     and      which introduce polynomial predictability and
prediction preserving reducibilities  respectively  this background closely follows that presented in the companion paper  cohen         readers are encouraged to skip this section
if they are already familiar with the material 

    logic programs

we will assume that the reader has some familiarity in logic programming  such as can
be obtained by reading one of the standard texts  lloyd          our treatment of logic
programs differs only in that we will usually consider the body of a clause to be an ordered
set of literals  we will also consider only logic programs without function symbols i e  
programs written in datalog 
the semantics of a datalog program p will be defined relative to to a database   db  
which is a set of ground atomic facts   when convenient  we will also think of db as a
   

fipac learning recursive logic programs  negative results

conjunction of ground unit clauses   in particular  we will interpret p and db as a subset
of the set of all extended instances   an extended instance is a pair  f  d  in which the
instance fact f is a ground fact  and the description d is a set of ground unit clauses  an
extended instance  f  d  is covered by  p  db   iff
db   d   p   f
if extended instances are allowed  then function free programs can encode many computations that are usually represented with function symbols  for example  a function free
program that tests to see if a list is the append of two other lists can be written as follows 

program p  

append xs ys ys 
null xs  
append xs ys zs 
components xs x xs    
components zs x zs    
append xs  ys zs   

database db  

null nil  
here the predicate components a b c  means that a is a list with head b and tail c  thus
an extended instance equivalent to append                    would have the instance fact
f   append  list     list    list      and a description containing these atoms 
components list     list    components list    nil  
components list      list     components list     list   
components list    nil 
the use of extended instances and function free programs is closely related to  attening 
 rouveirol        de raedt   dzeroski         some experimental learning systems also
impose a similar restriction  quinlan        pazzani   kibler         another motivation
for using extended instances is technical  under the  sometimes quite severe  syntactic
restrictions considered in this paper  there are often only a polynomial number of possible
ground facts i e   the herbrand base is polynomial  hence if programs were interpreted
in the usual model theoretic way it would be possible to learn a program equivalent to any
given target by simply memorizing the appropriate subset of the herbrand base  however 
if programs are interpreted as sets of extended instances  such trivial learning algorithms
become impossible  even for extremely restricted program classes there are still an exponential number of extended instances of size n  further discussion can be found in the
companion paper  cohen        
below we will define some of the terminology for logic programs that will be used in this
paper 
      input output variables

if a b            br is an  ordered  definite clause  then the input variables of the literal bi
are those variables which also appear in the clause a b            bi     all other variables
appearing in bi are called output variables  
   

ficohen

      types of recursion

a literal in the body of a clause is a recursive literal if it has the same predicate symbol
and arity as the head of the clause  if every clause in a program has at most one recursive
literal  the program is linear recursive   if every clause in a program has at most k recursive
literals  the program is k ary recursive   if every recursive literal in a program contains no
output variables  the program is closed recursive 
      depth

the depth of a variable appearing in a  ordered  clause a b            br is defined as follows 
variables appearing in the head of a clause have depth zero  otherwise  let bi be the first
literal containing the variable v   and let d be the maximal depth of the input variables of
bi   then the depth of v is d     the depth of a clause is the maximal depth of any variable
in the clause 
      determinacy

the literal bi in the clause a b            br is determinate iff for every possible substitution
 that unifies a with some fact e such that
db   b             bi   

there is at most one maximal substitution  so that db   bi   a clause is determinate
if all of its literals are determinate  informally  determinate clauses are those that can be
evaluated without backtracking by a prolog interpreter 
the term ij  determinate  muggleton   feng        is sometimes used for programs that
are depth i  determinate  and contain literals of arity j or less  a number of experimental systems exploit restrictions associated with limited depth and determinacy  muggleton
  feng        quinlan        lavrac   dzeroski        cohen      c   the learnability of constant depth determinate clauses has also received some formal study  dzeroski 
muggleton    russell        cohen      a  
      mode constraints and declarations

mode declarations are commonly used in analyzing prolog code or describing prolog code 
for instance  the mode declaration  components            indicates that the predicate components can be used when its first argument is an input and its second and third arguments
are outputs  formally  we define the mode of a literal l appearing in a clause c to be a
string s such that the initial character of s is the predicate symbol of l  and for j    
the j  th character of s is a     if the  j      th argument of l is an input variable and a
    if the  j      th argument of l is an output variable   this definition assumes that all
arguments to the head of a clause are inputs  this is justified since we are considering only
how clauses behave in classifying extended instances  which are ground   a mode constraint
is a set of mode strings r   fs           sk g  and a clause c is said to satisfy a mode constraint
r for p if for every literal l in the body of c   the mode of l is in r 
we define a declaration to be a tuple  p  a   r  where p is a predicate symbol  a  is an
integer  and r is a mode constraint  we will say that a clause c satisfies a declaration if
   

fipac learning recursive logic programs  negative results

the head of c has arity a  and predicate symbol p  and if for every literal l in the body of
c the mode of l appears in r 
      determinate modes

in a typical setting  that facts in the database db and extended instances are not arbitrary 
instead  they are representative of some  real  predicate  which may obey certain restrictions  let us assume that all database and extended instance facts will be drawn from some
 possibly infinite  set f   informally  a mode is determinate if the input positions of the
facts in f functionally determine the output positions  formally  if f   p t           tk   is a
fact with predicate symbol p and pff is a mode  then define inputs  f  pff  to be hti           ti i 
where i            ik are the indices of ff containing a      and define outputs  f  pff  to be
htj           tj i  where j           jl are the indices of ff containing a      we define a mode
string pff for a predicate p to be determinate for f iff
k

l

fhinputs  f  pff   outputs  f  pff i   f   fg
is a function  any clause that satisfies a declaration dec   detdec must be determinate 
the set of all declarations containing only modes determinate for f will be denoted
detdec f   since in this paper the set f will be assumed to be fixed  we will generally omit
the subscript 
      bounds on predicate arity

we will use the notation a db for the set of all databases that contain only facts of arity
a or less  and a dec for the set of all declarations  p  a   r  such that every string s   r is
of length a     or less 
      size measures

the learning models presented in the following section will require the learner to use resources polynomial in the size of its inputs  assuming that all predicates are arity a or
less for some constant a allows very simple size measures to be used  in this paper  we will
measure the size of a database db by its cardinality  the size of an extended instance  f  d 
by the cardinality of d  the size of a declaration  p  a   r  by the cardinality of r  and the
size of a clause a b            br by the number of literals in its body 

    a model of learnability
      preliminaries

let x be a set  we will call x the domain   and call the elements of x instances   define a
concept c over x to be a representation of some subset of x   and define a language lang
to be a set of concepts  in this paper  we will be rather casual about the distinction between
a concept and the set it represents  when there is a risk of confusion we will refer to the
set represented by a concept c as the extension of c   two sets c  and c  with the same
extension are said to be equivalent   define an example of c to be a pair  e  b  where b     if
e   c and b     otherwise  if d is a probability distribution function  a sample of c from
   

ficohen

x drawn according to d is a pair of multisets s     s   drawn from the domain x according
to d  s   containing only positive examples of c   and s   containing only negative ones 
associated with x and lang are two size complexity measures   for which we will use
the following notation 

 the size complexity of a concept c   lang is written j c j  
 the size complexity of an instance e   x is written j ej  
 if s is a set  sn stands for the set of all elements of s of size complexity no greater
than n  for instance  xn   fe   x   j ej  ng and langn   fc   lang   j c j  ng 
we will assume that all size measures are polynomially related to the number of bits needed
to represent c or e  this holds  for example  for the size measures for logic programs and
databases defined above 
      polynomial predictability

we now define polynomial predictability as follows  a language lang is polynomially
predictable iff there is an algorithm pacpredict and a polynomial function m          ne   nt 
so that for every nt      every ne      every c   langn   every              every
             and every probability distribution function d  pacpredict has the following
behavior 
t

   given a sample s     s   of c from xn drawn according to d and containing at least
m          ne   nt  examples  pacpredict outputs a hypothesis h such that
e

prob d h   c     d c   h         
where the probability is taken over the possible samples s   and s   and  if pacpredict
is a randomized algorithm  over any coin ips made by pacpredict 
   pacpredict runs in time polynomial in         ne   nt   and the number of examples 
and
   the hypothesis h can be evaluated in polynomial time 
the algorithm pacpredict is called a prediction algorithm for lang  and the function m          ne   nt   is called the sample complexity of pacpredict  we will sometimes
abbreviate  polynomial predictability  as  predictability  
the first condition in the definition merely states that the error rate of the hypothesis
must  usually  be low  as measured against the probability distribution d from which the
training examples were drawn  the second condition  together with the stipulation that the
sample size is polynomial  ensures that the total running time of the learner is polynomial 
the final condition simply requires that the hypothesis be usable in the very weak sense
that it can be used to make predictions in polynomial time  notice that this is a worst case
learning model  as the definition allows an adversarial choice of all the inputs of the learner 
   

fipac learning recursive logic programs  negative results

      relation to other models

the model of polynomial predictability has been well studied  pitt   warmuth         and
is a weaker version of valiant s        criterion of pac learnability   a language lang is
pac learnable iff there is an algorithm paclearn so that
   paclearn satisfies all the requirements in the definition of polynomial predictability 
and
   on inputs s   and s     paclearn always outputs a hypothesis h   lang 
thus if a language is pac learnable it is predictable 
in the companion paper  cohen         our positive results are all expressed in the model
of identifiability from equivalence queries  which is strictly stronger than pac learnability 
that is  anything that is learnable from equivalence queries is also necessarily pac learnable  
since this paper contains only negative results  we will use the the relatively weak model
of predictability  negative results in this model immediately translate to negative results
in the stronger models  if a language is not predictable  it cannot be pac learnable  nor
identifiable from equivalence queries 
      background knowledge in learning

in a typical ilp system  the setting is slightly different  as the user usually provides clues
about the target concept in addition to the examples  in the form of a database db of
 background knowledge  and a set of declarations  to account for these additional inputs it
is necessary to extend the framework described above to a setting where the learner accepts
inputs other than training examples  following the formalization used in the companion
paper  cohen         we will adopt the notion of a  language family  
if lang is a set of clauses  db is a database and dec is a declaration  we will define
lang db   dec  to be the set of all pairs  c  db   such that c   lang and c satisfies dec  
semantically  such a pair will denote the set of all extended instances  f  d  covered by
 c  db    next  if db is a set of databases and dec is a set of declarations  then define
lang db   dec     flang db   dec     db

  db and dec   decg

this set of languages is called a language family  
we will now extend the definition of predictability queries to language families as follows 
a language family lang db  dec   is polynomially predictable iff every language in the set
is predictable  a language family lang db  dec   is polynomially predictable iff there is
a single algorithm identify db   dec   that predicts every lang db   dec  in the family
given db and dec  
the usual model of polynomial predictability is worst case over all choices of the target
concept and the distribution of examples  the notion of polynomial predictability of a
language family extends this model in the natural way  the extended model is also worstcase over all possible choices for database db   db and dec   dec   this worst case
   an equivalence query is a question of the form  is h equivalent to the target concept   which is answered
with either  yes  or a counterexample  identification by equivalence queries essentially means that the
target concept can be exactly identified in polynomial time using a polynomial of such queries 

   

ficohen

model may seem unintuitive  since one typically assumes that the database db is provided
by a helpful user  rather than an adversary  however  the worst case model is reasonable
because learning is allowed to take time polynomial in the size of smallest target concept
in the set lang db   dec    this means that if the database given by the user is such that
the target concept cannot be encoded succinctly  or at all  learning is allowed to take more
time 
notice that for a language family lang db   dec  to be polynomially predictable  every
language in the family must be polynomially predictable  thus to show that a family is not
polynomially predictable it is sucient to construct one language in the family for which
learning is hard  the proofs of this paper will all have this form 

    prediction preserving reducibilities

the principle technical tool used in our negative results in the notion of prediction preserving
reducibility   as introduced by pitt and warmuth         prediction preserving reducibilities
are a method of showing that one language is no harder to predict than another  formally 
let lang  be a language over domain x  and lang  be a language over domain x  
we say that predicting lang  reduces to predicting lang   denoted lang   lang    if
there is a function fi   x    x    henceforth called the instance mapping   and a function
fc   lang    lang    henceforth called the concept mapping   so that the following all hold 
   x   c if and only if fi  x    fc  c     i e   concept membership is preserved by the
mappings 
   the size complexity of fc  c   is polynomial in the size complexity of c  i e   the size
of concept representations is preserved within a polynomial factor 
   fi  x  can be computed in polynomial time 
note that fc need not be computable  also  since fi can be computed in polynomial time 
fi x  must also preserve size within a polynomial factor 
intuitively  fc  c   returns a concept c    lang  that will  emulate  c  i e   make
the same decisions about concept membership on examples that have been  preprocessed 
with the function fi   if predicting lang  reduces to predicting lang  and a learning
algorithm for lang  exists  then one possible scheme for learning concepts from lang 
would be the following  first  convert any examples of the unknown concept c  from
the domain x  to examples over the domain x  using the instance mapping fi   if the
conditions of the definition hold  then since c  is consistent with the original examples 
the concept fc  c   will be consistent with their image under fi   thus running the learning
algorithm for lang  should produce some hypothesis h that is a good approximation of
fc  c    of course  it may not be possible to map h back into the original language lang  
as computing fc    may be dicult or impossible  however  h can still be used to predict
membership in c   given an example x from the original domain x   one can simply predict
x   c  to be true whenever fi  x    h  
pitt and warmuth        give a more rigorous argument that this approach leads to a
prediction algorithm for lang    leading to the following theorem 
   

fipac learning recursive logic programs  negative results

theorem    pitt and warmuth  assume lang   lang   then if lang  is not polynomially predictable  lang  is not polynomially predictable 

   cryptographic limitations on learning recursive programs

theorem   allows one to transfer hardness results from one language to another  this is
useful because for a number of languages  it is known that prediction is as hard as breaking
cryptographic schemes that are widely assumed to be secure  for example  it is known
that predicting the class of languages accepted by deterministic finite state automata is
 cryptographically hard   as is the class of languages accepted by log space bounded turing
machines 
in this section we will make use of theorem   and previous cryptographic hardness
results to show that certain restricted classes of recursive logic programs are hard to learn 

    programs with n linear recursive clauses

in a companion paper  cohen        we showed that a single linear closed recursive clause
was identifiable from equivalence queries  in this section we will show that a program with
a polynomial number of such clauses is not identifiable from equivalence queries  nor even
polynomially predictable 
specifically  let us extend our notion of a  family of languages  slightly  and let
dlog n  s  represent the language of log space bounded deterministic turing machines with
up to s states accepting inputs of size n or less  with the usual semantics and complexity
measure   also let d depthlinrecprog denote the family of logic programs containing
only depth d linear closed recursive clauses  but containing any number of such clauses  we
have the following result 
theorem   for every n and s  there exists a database db n s     db and declaration
dec n s     detdec of sizes polynomial in n and s such that
dlog n  s     depthlinrecprog db n s   dec n s  
hence for d    and a     d depthlinrecprog db  a detdec   is not uniformly polynomially predictable under cryptographic assumptions  
proof  recall that a log space bounded turing machine  tm  has an input tape of length
n  a work tape of length log  n which initially contains all zeros  and a finite state control
with state set q  to simplify the proof  we assume without loss of generality that the tape
and input alphabets are binary  that there is a single accepting state qf   q  and that the
machine will always erase its work tape and position the work tape head at the far left after
it decides to accept its input 
at each time step  the machine will read the tape squares under its input tape head and
work tape head  and based on these values and its current state q   it will
   i e   a machine represents the set of all inputs that it accepts  and its complexity is the number of states 
   specifically  this language is not uniformly polynomially predictable unless all of the following cryptographic problems can be solved in polynomial time  solving the quadratic residue problem  inverting the
rsa encryption function  and factoring blum integers  this result holds because all of these cryptographic problems can be reduced to learning dlog turing machines  kearns   valiant        

   

ficohen






write either a   or a   on the work tape 
shift the input tape head left or right 
shift the work tape head left or right  and
transition to a new internal state q  
a deterministic machine can thus be specified by a transition function

   f    g  f    g  q    f    g  fl  rg  fl  rg  q
let us define the internal configuration of a tm to consist of the string of symbols
written on the worktape  the position of the tape heads  and the internal state q of the
machine  thus a configuration is an element of the set
con  f    glog  n  f          log  ng  f          ng  q

a simplified specification for the machine is the transition function

    f    g  con   con
where the component f    g represents the contents of the input tape at the square below
the input tape head 
notice that for a machine whose worktape size is bounded by log n  the cardinality of
con is only p   jqjn  log  n  a polynomial in n and s   jqj  we will use this fact in our
constructions 
the background database db n s is as follows  first  for i             p  an atom of the
form coni ci   is present  each constant ci will represent a different internal configuration of
the turing machine  we will also arbitrarily select c  to represent the  unique  accepting
configuration  and add to db n s the atom accepting c    thus
db n s  fcon i  ci gpi     faccepting  c  g

next  we define the instance mapping  an instance in the turing machine s domain is
a binary string x   b       bn   this is mapped by fi to the extended instance  f  d  where

f  accepting  c   
d  ftruei gb  x  b      ffalsei gb  x  b   
i

i

i

i

the description atoms have the effect of defining the predicate truei to be true iff the i th
bit of x is a      and the defining the predicate falsei to be true iff the i th bit of x is
     the constant c  will represent the start configuration of the turing machine  and the
predicate accepting c  will be defined so that it is true iff the turing machine accepts input
x starting from state c 
we will let dec n s    accepting      r  where r contains the modes coni     and coni     
for i             p  and truej and falsej for j             n 
finally  for the concept mapping fc   let us assume some arbitrary one to one mapping
 between the internal configurations of a turing machine m and the predicate names
   

fipac learning recursive logic programs  negative results

con         conp   such that the start configuration   log  n      q   maps to con  and the accepting configuration   log  n      qf   maps to con   we will construct the program fc  m  
as follows  for each transition       c    c  in     where c and c  are in con   construct a
clause of the form

accepting c 

conj  c    truei   conj    c     accepting c   

where i is the position of the input tape head which is encoded in c  con j     c   and
con j       c    for each transition       c     c   in    construct an analogous clause  in
which truei is replaced with falsei 
now  we claim that for this program p   the machine m will accept when started in
configuration ci iff
db n s   d   p   accepting  ci  
and hence that this construction preserves concept membership  this is perhaps easiest to see by considering the action of a top down theorem prover when given the goal
accepting  c    the sequence of subgoals accepting  ci    accepting  ci             generated by the
theorem prover precisely parallel the sequence of configurations ci         entered by the turing
machine 
it is easily verified that the size of this program is polynomial in n and s  and that the
clauses are linear recursive  determinate  and of depth one  completing the proof 
there are number of ways in which this result can be strengthened  precisely the
same construction used above can be used to reduce the class of nondeterministic log space
bounded turing machines to the constant depth determinate linear recursive programs 
further  a slight modification to the construction can be used to reduce the class of log space
bounded alternating turing machines  chandra  kozen    stockmeyer        to constantdepth determinate   ary recursive programs  the modification is to emulate configurations
corresponding to universal states of the turing machine with clauses of the form
accepting c 
conj  c    truei  
conj     c     accepting c    
conj     c     accepting c   
where conj    and conj    are the two successors to the universal configuration conj   this is
a very strong result  since log space bounded alternating turing machines are known to be
able to perform every polynomial time computation 

    programs with one n ary recursive clause

we will now consider learning a single recursive clause with arbitrary closed recursion 
again  the key result of this section is an observation about expressive power  there is
a background database that allows every log space deterministic turing machine m to
be emulated by a single recursive constant depth determinate clause  this leads to the
following negative predictability result 
   

ficohen

theorem   for every n and s  there exists a database db n s     db and declaration
dec n s     detdec of sizes polynomial in n and s such that
dlog n  s     depthrec db n s   dec n s  
hence for d    and a     d depthrec db n   a detdec   is not uniformly polynomially
predictable under cryptographic assumptions 

proof  consider a dlog machine m   as in the proof of theorem    we assume without
loss of generality that the tape alphabet is f    g  that there is a unique starting configura 

tion c   and that there is a unique accepting configuration c   we will also assume without
loss of generality that there is a unique  failing  configuration cf ail  and that there is exactly
one transition of the form
   b  cj    c j
for every combination of i   f          ng  b   f    g  and cj   con   fc   cf ailg  thus on
input x   x       xn the machine m starts with config c    then executes transitions
until it reaches config c  or config cf ail  at which point x is accepted or rejected
 respectively   we will use p for the number of configurations   recall that p is polynomial
in n and s  
to emulate m   we will convert an example x   b       bn into the extended instance
fi x      f  d  where

f  accepting  c   
d  fbit i  bi gni  
thus the predicate bit i  x   binds x to the i th bit of the tm s input tape  we also will
define the following predicates in the background database db n s  

 for every possible b   f    g and j      j  p n   the predicate statusb j  b c y  will
be defined so that given bindings for variables b and c   statusb j  b c y  will fail if
c   cf ail  otherwise it will succeed  binding y to active if b   b and c   cj and
binding y to inactive otherwise 
 for j      j  p n   the predicate nextj  y c  will succeed iff y can be bound to
either active or inactive  if y     then c will be bound to cj   otherwise  c will be
bound to the accepting configuration c  
 the database also contains the fact accepting  c    
it is easy to show that the size of this database is polynomial in n and s 
the declaration dec n s is defined to be  accepting      r  where r includes the modes
status bj            next j         and bit i     for b   f    g  j             p  and i             n 
now  consider the transition rule    b  cj     c j   and the corresponding conjunction
transibj  biti  bibj     statusb j  c bibj  yibj     nextj    yibj  c ibj     accepting c ibj  
   

fipac learning recursive logic programs  negative results

given db n s and d  and assuming that c is bound to some configuration c  this conjunction
will fail if c   cf ail  it will succeed if xi    b or c    cj   in this case yibj will be bound to
inactive  c ibj will be bound to c   and the recursive call succeeds because accepting c   is in
db n s   finally  if xi   b and c   cj   transibj will succeed only if the atom accepting cj    
is provable  in this case  yibj will be bound to active and c ibj will be bound to cj    
from this it is clear that the clause fc  m   below
 
accepting c 
transibj
i

 f      ng  b f   g
j  f      pg

will correctly emulate the machine m on examples that have been preprocessed with the
function fi described above  hence this construction preserves concept membership  it is
also easily verified that the size of this program is polynomial in n and s  and that the
clause is determinate and of depth three 

    one k local linear closed recursive clause

so far we have considered only one class of extensions to the positive result given in the
companion paper  cohen        namely  relaxing the restrictions imposed on the recursive
structure of the target program  another reasonable question to ask is if linear closed
recursive programs can be learned without the restriction of constant depth determinacy 
in earlier papers  cohen      a      a      b  we have studied the conditions under
which the constant depth determinacy restriction can be relaxed while still allowing learnability for nonrecursive clauses  it turns out that most generalizations of constant depth
determinate clauses are not predictable  even without recursion  however  the language of
nonrecursive clauses of constant locality is a pac learnable generalization of constant depth
determinate clauses  below  we will define this language  summarize the relevant previous
results  and then address the question of the learnability of recursive local clauses 
define a variable v appearing in a clause c to be free if it appears in the body of c but
not the head of c   let v  and v  be two free variables appearing in a clause  v  touches v 
if they appear in the same literal  and v  inuences v  if it either touches v   or if it touches
some variable v  that inuences v   the locale of a free variable v is the set of literals that
either contain v   or that contain some free variable inuenced by v   informally  variable
v  inuences variable v  if the choice of a binding for v  can affect the possible choices of
bindings for v  
the locality of a clause is the size of its largest locale  let k localnonrec denote the
language of nonrecursive clauses with locality k or less   that is  k localnonrec is the
set of logic programs containing a single nonrecursive k local clause   the following facts
are known  cohen      b  
 for fixed k and a  the language family k localnonrec a db  a dec  is uniformly
pac learnable 
 for every constant d  every constant a  every database db   a db  every declaration
dec   a detdec   and every clause c   d depthnonrec db   dec    there is an
   

ficohen

equivalent clause c   in k localnonrec db   dec  of size bounded by kj c j   where k
is a function only of a and d  and hence is a constant if d and a are also constants  
hence
k localnonrec db  a dec 
is a pac learnable generalization of

d depthnonrec db  a detdec  
it is thus plausible to ask if recursive programs of k local clauses are pac learnable  some
facts about the learnability of k local programs follow immediately from previous results 
for example  an immediate consequence of the construction of theorem   is that programs
with a polynomial number of linear recursive k local clauses are not predictable for k    
similarly  theorem   shows that a single recursive k local clause is not predictable for k    
it is still reasonable to ask  however  if the positive result for bounded depth determinate
recursive clauses  cohen        can be extended to k ary closed recursive k local clauses 
unfortunately  we have the following negative result  which shows that even linear closed
recursive clauses are not learnable 

theorem   let dfa s  denote the language of deterministic finite automata with s states 

and let k locallinrec be the set of linear closed recursive k local clauses  for any constant s there exists a database db s     db and a declaration dec s     dec   both of size
polynomial in s  such that
dfa s     locallinrec db s   dec s  

hence for k    and a     k locallinrec a db   dec  is not uniformly polynomially
predictable under cryptographic assumptions 

proof  following hopcroft and ullman        we will represent a dfa m over the alphabet

 as a tuple  q   q  f     where q  is the initial state  q is the set of states  f is the set of
accepting states  and    q     q is the transition function  which we will sometimes
think of as a subset of q    q   to prove the theorem  we need to construct a database
db s of size polynomial in s such that every s state dfa can be emulated by a linear
recursive k local clause over db s  
rather than directly emulating m   it will be convenient to emulate instead a modification of m   let m  be a dfa with state set q   q   fq      qe   qf g  where q       qe and qf
are new states not found in q  the initial state of m  is q       the only final state of m  is
qf   the transition function of m  is
 
      f q      a  q     qe  c  qf  g  
f qi  b  qe g
 

qi f

where a  b  and c are new letters not in   note that m  is now a dfa over the alphabet
   fa  b  cg  and  as described  need not be a complete dfa over this alphabet   that
is  there may be pairs  qi   a  such that   qi   a  is undefined   however  m  can be easily
   

fipac learning recursive logic programs  negative results

m

 


q


 

 

  

m 

 



q



   

 

 

 

 







q 
q
q
q
q
  

  

 

 

a

 

  

m 




 

 

 

 

b c    








 







b

 

a b c
 

 

c

e


q

 

r

a b c

 

f

a b c    
a b c    


 

a b 
   







q
q
q
q
q









  

a



  

 

 



 
 

 

 

 





 
 

 
  b  



e

c

 

f

figure    how a dfa is modified before emulation with a local clause

   

ficohen

made complete by introducing an additional rejecting state qr   and making every undefined
transition lead to qr   more precisely  let    be defined as
       f qi  x  qr  j qi   q    x      fa  b  cg       qj    qi   x  qj       g
thus m      q      q   fqr g  fqf g      is a  completed  version of m    with q    q   fqr g  we
will use m   in the construction below  we will also let q    q    fqr g and        fa  b  cg 
examples of m   m  and m   are shown in figure    notice that aside from the arcs into
and out of the rejecting state qr   the state diagram of m   is nearly identical to that of m  
the differences are that in m   there is a new initial state q     with a single outgoing arc
labeled a to the old initial state q    also every final state of m has in m   an outgoing arc
labeled b to a new state qe   which in turn has a single outgoing arc labeled c to the final
state qf   it is easy to show that

x   l m   iff axbc   l m   
now  given a set of states q  we define a database db that contains the following
predicates 
 arcq   q  s x t  is true for any s   q   any t   q   and any x      unless s   qi 
x     and t    qj  
 state s  is true for any s   q  
 accept c nil qe qf   is true 
as motivation for the arc predicates  observe that in emulating m   it is clearly useful to be
able to represent the transition function     the usefulness of the arc predicates is that any
transition function    can be represented using a conjunction of arc literals  in particular 
the conjunction
 
arc q   q  s  x  t  
i

j

i

 q   q    
i

j

j

succeeds when     s  x     t   and fails otherwise 
let us now define the instance mapping fi as fi  x     f  d  where

f   accept  a  xbc  q      q  
and d is a set of facts that defines the components relation on the list that corresponds to
the string xbc  in other words  if x          n   then d is the set of facts
components        n bc            n bc 
components        n bc            n bc 
  
 
components c c nil 
the declaration dec n will be dec n    accept      r  where r contains the modes
components            state      and arc q   q           for qi   qj in q    and       
finally  define the concept mapping fc  m   for a machine m to be the clause
i

j

   

fipac learning recursive logic programs  negative results

accept x ys s t 
v
 q   q     arcq   q  s x t 
  components ys x  ys     state u    accept x  ys  t u  
where    is the transition function for the corresponding machine m   defined above  it is
easy to show this construction is polynomial 
in the clause x is a letter in    ys is a list of such letters  and s and t are both states
in q    the intent of the construction is that the predicate accept will succeed exactly when
 a  the string xys is accepted by m   when m   is started in state s   and  b  the first action
taken by m   on the string xys is to go from state s to state t  
since all of the initial transitions in m   are from q     to q  on input a  then if the
predicate accept has the claimed behavior  clearly the proposed mapping satisfies the requirements of theorem    to complete the proof  therefore  we must now verify that the
predicate accept succeeds iff xys is accepted by m   in state s with an initial transition to
t 
from the definition of dfas the string xys is accepted by m   in state s with an initial
transition to t iff one of the following two conditions holds 
   s  x     t   ys is the empty string and t is a final state of m    or 
   s  x     t   ys is a nonempty string  and hence has some head x   and some tail
ys   and ys  is accepted by m   in state t   with any initial transition 
the base fact accept c nil qe qf   succeeds precisely when the first case holds  since in
m   this transition is the only one to a final state  in the second case  the conjunction of the
arc conditions in the fc  m   clause succeeds exactly when   s  x     t  as noted above  
further the second conjunction in the clause can be succeeds when ys is a nonempty string
with head x   and tail ys  and x ys  is accepted by m   in state t with initial transition
to any state u   which corresponds exactly to the second case above 
thus concept membership is preserved by the mapping  this completes the proof 
i

j

i

j

   dnf hardness results for recursive programs

to summarize previous results for determinate clauses  it was shown that while a single
k ary closed recursive depth d clause is pac learnable  cohen         a set of n linear closed
recursive depth d clauses is not  further  even a single n ary closed recursive depth d clauses
is not pac learnable  there is still a large gap between the positive and negative results 
however  in particular  the learnability of recursive programs containing a constant number
of k ary recursive clauses has not yet been established 
in this section we will investigate the learnability of these classes of programs  we will
show that programs with either two linear closed recursive clauses or one linear closed recursive clause and one base case are as hard to learn as boolean functions in disjunctive
normal form  dnf   the pac learnability of dnf is a long standing open problem in computational learning theory  the import of these results  therefore  is that establishing the
learnability of these classes will require some substantial advance in computational learning
theory 
   

ficohen

    a linear recursive clause plus a base clause

previous work has established that two clause constant depth determinate programs consisting of one linear recursive clause and one nonrecursive clause can be identified  given
two types of oracles  the standard equivalence query oracle  and a  basecase oracle   cohen 
        the basecase oracle determines if an example is covered by the nonrecursive clause
alone   in this section we will show that in the absence of the basecase oracle  the learning
problem is as hard as learning boolean dnf 
in the discussion below  dnf n  r  denotes the language of r term boolean functions in
disjunctive normal form over n variables 

theorem   let d depth   clause be the set of   clause programs consisting of one

clause in d depthlinrec and one clause in d depthnonrec  then for any n and
any r there exists a database db n r     db and a declaration dec n r     dec   both of sizes
polynomial in n and r  such that
dnf n  r     depth   clause db n r   dec n r  

hence for a    and d    the language family d depth   clause db  a detdec   is
uniformly polynomially predictable only if dnf is polynomially predictable 

proof  we will produce a db n r   db and dec n r     detdec such that predicting
dnf can be reduced to predicting   depth   clause db n r   dec n r    the construction
makes use of a trick first used in theorem   of  cohen      a   in which a dnf formula is
emulated by a conjunction containing a single variable y which is existentially quantified
over a restricted range 
we begin with the instance mapping fi   an assignment    b       bn will be converted
to the extended instance  f  d  where
f  p   
d  fbit i  bi gni  
next  we define the database db n r to contain the binary predicates true    false           truer  
falser which behave as follows 

 truei x y  succeeds if x      or if y   f          rg   fig 
 falsei x y  succeeds if x      or if y   f          rg   fig 
further  db n r contains facts that define the predicate succ y z  to be true whenever
z   y      and both y and z are numbers between   and r  clearly the size of db n r is
polynomial in r 
let dec n r    p     r  where r contains the modes bit i      for i             n  true j       
and false j         for j             r  and succ        
now let  be an r term dnf formula     ri    sj    lij over the variables v           vn 
we may assume without loss of generality that  contains exactly r terms  since any dnf
formula with fewer than r terms can be padded to exactly r terms by adding terms of the
i

   

fipac learning recursive logic programs  negative results

background database 

for i             r
truei  b  y   for all b  y   b     or y   f          rg but y    i
falsei  b  y   for all b  y   b     or y   f          rg but y    i
succ y z 
if z   y     and y   f          rg and z   f          rg

dnf formula   v    v    v      v    v      v    v  
equivalent program 
p y  succ y z  p z  
p y  bit   x      bit   x      bit   x      bit   x     
true   x  y    false   x   y    true  x   y   
false   x  y    false   x  y  
true   x  y    false   x   y  
instance mapping  fi          p     fbit      bit       bit      bit    g 
figure    reducing dnf to a recursive program
form v  v   we now define the concept mapping fc    to be the program cr  cb where cr
is the linear recursive depth   determinate clause

p y   succ y  z     p z  
and cb is the nonrecursive depth   determinate clause
s
n
 
 r  
p y  
bit k  xk    
bij
i

i   j   

k   

where bij is defined as follows 

bij 

 

truei  xk  y  if lij   vk
falsei  xk  y  if lij   vk

an example of the construction is shown in figure    we suggest that the reader refer
to this figure at this point  the basic idea behind the construction is that first  the clause
cb will succeed only if the variable y is bound to i and the i th term of  succeeds  the
definitions of truei and falsei are designed to ensure that this property holds   second  the
recursive clause cr is constructed so that the program fc    succeeds iff cb succeeds with
y bound to one of the values           n 
we will now argue more rigorously for the correctness of the construction  clearly  fi    
and fc    are of the same size as  and  respectively  since db n r is also of polynomial
size  this reduction is polynomial 
figure   shows the possible proofs that can be constructed with the program fc    
notice that the program fc    succeeds exactly when the clause cb succeeds for some value
   

ficohen

p   

 a 
a 
aa  
 
b   





succ      p   


  
a


a 


aa  
 
b   

succ      p   


 a
 


a 


aa  
 
b   
   

p n   

b  i   v bit  x     v v b
i

i

ij


 a
 


a 


aa  
b n   
 

succ n   n  p n 
b n 

figure    space of proofs possible with the program fc   
vs l must be true  in
of y between
 
and
r
 
now 
if

is
true
then
some
term
t
i  
j    ij
v
v
s 
s
this case j    bij succeeds with y bound to the value i and j    bi  j for every i     i also
succeeds with y bound to i  on the other hand  if  is false for an assignment  then each ti
fails  and hence for every possible binding of y generated by repeated use of the recursive
clause cr the base clause cb will also fail  thus concept membership is preserved by the
mapping 
this concludes the proof 
i

i

i

    two linear recursive clauses

recall again that a single linear closed recursive clause is identifiable from equivalence
queries  cohen         a construction similar to that used in theorem   can be used to
show that this result cannot be extended to programs with two linear recursive clauses 
theorem   let d depth   clause  be the set of   clause programs consisting of two
clauses in d depthlinrec   thus we assume that the base case of the recursion is given
as background knowledge   then for any constants n and r there exists a database db n r  
  db and a declaration dec n r     dec   both of sizes polynomial in n  such that
dnf n  r     depth   clause  db n r   dec n r  
hence for any constants a    and d    the language family
d depth   clause   db  a detdec  
   

fipac learning recursive logic programs  negative results

is uniformly polynomially predictable only if dnf is polynomially predictable 

proof  as before  the proof makes use of a prediction preserving reducibility from dnf to

d depth   clause  db   dec   for a specific db and dec   let us assume that  is a dnf
with r terms  and further assume that r    k    again  this assumption is made without
loss of generality  since the number of terms in  can be increased by padding with vacuous
terms   now consider a complete binary tree of depth k      the k th level of this tree has
exactly r nodes  let us label these nodes            r  and give the other nodes arbitrary labels 

now construct a database db n r as in theorem    except for the following changes 
 the predicates truei  b y  and falsei b y  also succeed when y is the label of a node at
some level below k 
 rather than the predicate succ  the database contains two predicates leftson and
rightson that encode the relationship between nodes in the binary tree 
 the database includes the facts p              p   r   where               r are the leaves
of the binary tree  these will be used as the base cases of the recursive program that
is to be learned 
let  be the label of the root of the binary tree  we define the instance mapping to be

fi  b       b     p    fbit   b           bit n  bn  g 
note that except for the use of  rather than    this is identical to the instance mapping
used in theorem    also let dec n r    p     r  where r contains the modes bit i      for i  
          n  true j        and false j         for j             r  leftson         and rightson        
the concept mapping fc    is the pair of clauses r   r   where r  is the clause
s
n
 
 r  
p y  
bit k  xk    
bij   leftson y  z     p z  
i

k   

and r  is the clause

p y  

n
 
k   

bit k  xk    

i   j   

s
 r  
i

i   j   

bij   rightson  y  z     p z  

note that both of these clause are linear recursive  determinate  and have depth    also 
the construction is clearly polynomial  it remains to show that membership is preserved 
figure   shows the space of proofs that can
v be constructed
v v with the program fc     as
in figure    b  i  abbreviates the conjunction bit i  xi    bij   notice that the program
will succeed only if the recursive calls manage to finally recurse to one of the base cases
p              p   r    which correspond to the leaves of the binary tree  both clauses will both
succeed on the the first k     levels of the tree  however  to reach the base cases of the
recursion at the leaves of the tree  the recursion must pass through the k th level of the tree 
that is  one of the clauses above must succeed on some node y of the binary tree  where
y is on the k th level of the tree  and hence the label of y is a number between   and r 
the program thus succeeds on fi     precisely when there is some number y between   and
   

ficohen

p  

 
  b
 b
 

h

 h
 
 bb
 
   
  b
   
  bb
 
 
b
 
 
 
b
 
 
 
b
 
b
 
 
b   p l 
b  
p r 
 z
 z
 
   
z
x   
z

x
 
 
z

z
 
  z
 
  z
 
 
  z
 
  z


e
x
x
x
ex


e


e


e

   

   

   

b
 b
 b




b
b

   

   

b    p ll      l  b    p ll      r 

p     

   



j
 j

j


j

j

b
 b
 b

b

b

b n  p rr      lr  b n  p rr      r 

p     

p        
r

p     
r

figure    proofs possible with the program fc   

r such that the conjunction b i  succeeds  which  by the argument given in theorem   
can happen if and only if  is satisfied by the assignment    thus  the mappings preserve

concept membership  this completes the proof 

notice that the programs fc    used in this proof all have the property that the depth
of every proof is logarithmic in the size of the instances  this means that the hardness
result holds even if one additionally restricts the class of programs to have a logarithmic
depth bound 

    upper bounds on the diculty of learning

the previous sections showed that several highly restricted classes of recursive programs
are at least as hard to predict as dnf  in this section we will show that these restricted
classes are also no harder to predict than dnf 
we will wish to restrict the depth of a proof constructed by a target program  thus  let
h n  be any function  we will use langh n  for the set of programs in the class lang such
that all proofs of an extended instance  f  d  have depth bounded by h j dj   
   

fipac learning recursive logic programs  negative results

theorem   let dnf n    be the language of dnf boolean functions  with any number

of terms   and recall that d depth   clause is the language of   clause programs consisting of one clause in d depthlinrec and one clause in d depthnonrec  and that
d depth   clause  is the language of   clause programs consisting of two clauses in
d depthlinrec 
for all constants d and a  and all databases db   db and declarations dec   a detdec  
there is a polynomial function poly  n  such that

 d depth   clause db   dec   dnf poly  j db j     
 d depth   clause h n   db   dec   dnf poly  j db j      if h n  is bounded by c log n
for some constant c 
hence if either of these language families is uniformly polynomially predictable  then dnf n   
is polynomially predictable 

proof  the proof relies on several facts established in the companion paper  cohen        
 for every declaration dec  there is a clause bottom d dec  such that every nonrecursive depth d determinate clause c is equivalent to some subclause of bottom d  
further  the size of bottom  d is polynomial in dec   this means that the language of subclauses of bottom  is a normal form for nonrecursive constant depth
determinate clauses 

 every linear closed recursive clause cr that is constant depth determinate is equivalent to some subclause of bottom  plus a recursive literal lr   further  there are
only a polynomial number of possible recursive literals lr  
 for any constants a  a   and d  any database db   a db  any declaration dec  
 p  a   r   any database db   a db   and any program p in d depth   clause db   dec   
the depth of a terminating proof constructing using p is no more than hmax  where
hmax is a polynomial in the size of db and dec  
 at can be assumed without loss of generality that the database db and all decsriptions
d contain an equality predicate   where an equality predicate is simply a predicate
equal x y  which is true exactly when x   y  
the idea of the proof is to contruct a prediction preserving reduction between the two
classes of recursive programs listed above to and dnf  we will begin with two lemmas 

lemma   let dec   a detdec   and let c be a nonrecursive depth d determinate clause

consistent with dec  let subclausec denote the language of subclauses of c   and let
monomial u  denote the language of monomials over u variables  then there is a polynomial poly   so that for any database db   db 
subclausec  db   dec   monomial poly   j db j   

   

ficohen

proof of lemma  follows immediately from the construction used in theorem   of

dzeroski  muggleton  and russell  dzeroski et al           the basic idea of the construction is to introduce a propositional variable representing the  success  of each connected
chain of literals in c   any subclause of c can then be represented as a conjunction of these
propositions  
this lemma can be extended as follows 

lemma   let dec   a detdec   and let s   fc          crg be a set of r nonrecursive depth 

d determinate clauses consistent with dec  each of length n or less  let subclauses denote
the set of all programs of the form p    d          ds  such that each di is a subclause of
some cj   s  
then there is a polynomial poly   so that for any database db   db 
subclauses  db   dec   dnf poly    j db j   r    

proof of lemma  by lemma    for each ci   s   there is a set of variables vi of size
polynomial in j db j such
every clause in subclausec can be emulated by a monomial
sr that
over
v
v
 
clearly 
jv j is polynomial in n and r  and every clause in
i   let v  
i
i  
s
i

i

subclausec can be also emulated by a monomial over v   further  every disjunction

of r such clauses can be represented by a disjunction of such monomials 
since the ci  s all satisfy a single declaration dec    p  a  r   they have heads with the
same principle function and arity  further  we may assume  without loss of generality  since
an equality predicate is assumed  that the variables appearing in the heads of these clauses
are all distinct  since the ci s are also nonrecursive  every program
p   subclauses can
s
be represented as a disjunction d            dr where for all i  di     i subclausec    hence
every p   subclauses can be represented by an r term dnf over the set of variables v  
i

i

let us now introduce some additional notation  if c and d are clauses  then we will use
c u d to denote the result of resolving c and d together  and c i to denote the result of
resolving c with itself i times  note that c u d is unique if c is linear recursive and c and
d have the same predicate in their heads  since there will be only one pair of complementary
literals  
now  consider some target program

p    cr  cb     d depth   clause db   dec 
where cr is the recursive clause and cb is the base  the proof of any extended instance
 f  d  must use clause cr repeatedly h times and then use clause cb to resolve away
the final subgoal  hence the nonrecursive clause crh u cb could also be used to cover the
instance  f  d  
since the depth of any proof for this class of programs is bounded by a number hmax
that is polynomial in j db j and ne   the nonrecursive program

p     fcrh u cb      h  hmax g
   

fipac learning recursive logic programs  negative results

is equivalent to p on extended instances of size ne or less 
finally  recall that we can assume that cb is a subclause of bottom d   also  there
is a polynomial sized set lr   lr           lr of closed recursive literals such that for some
lr   lr   the clause cr is a subclause of bottom d   lr   this means that if we let s
be the polynomial sized set
s    f bottom d   lr  h u bottom d j    h  hmax and lr   lr g
then p     subclauses    thus by lemma    d depth   clause  dnf  this concludes
the proof of the first statement in the the theorem 
to show that
d depth   clause h n   db   dec   dnf poly  j db j    
a similar argument applies  let us again introduce some notation  and define
meshh n  cr    cr    as the set of all clauses of the form
p

i

i

i

i

cr   u cr   u       u cr  
where for all j   cr   cr  or cr   cr    and h   h n   notice that for functions
h n   c log n the number of such clauses is polynomial in n 
now let p be the predicate appearing in the heads of cr  and cr    and let c   respectively
    be a a version of c  db   in which every instance of the predicate p has been replaced
db
with a new predicate p   if p is a recursive program p   fcr    cr  g in d depth   clause 
   
over the database db   then p   db is equivalent  to the nonrecursive program p     db
i 

ij

where

i 

i h

ij

p     fc  j c   meshh n  cr    cr   g
e

now recall that there are a polynomial number of recursive literals lr   and hence a
polynomial number of pairs of recursive literals lr   lr   this means that the set of clauses
 
s   
fc  j c   meshh n  bottom d   lr   bottom d   lr  g
i

i

 l

ri

e

  

 lrj   lr lr

j

i

j

is also polynomial sized  furthermore  for any program p in the language d depth   clause 
p     subclauses    the second part of the theorem now follows by application of lemma   
an immediate corollary of this result is that theorems   and   can be strengthened as
follows 
corollary    for all constants d    and a     the language family
d depth   clause db  a detdec  
is uniformly polynomially predictable if and only if dnf is polynomially predictable 
for all constants d    and a     the language family
d depth   clause   db  a detdec  
is uniformly polynomially predictable if and only if dnf is polynomially predictable 
   on extended instances of size n or less 
e

   

ficohen

thus in an important sense these learning problems are equivalent to learning boolean
dnf  this does not resolve the questions of the learnability of these languages  but does
show that their learnability is a dicult formal problem  the predictability of boolean dnf
is a long standing open problem in computational learning theory 

   related work
the work described in this paper differs from previous formal work on learning logic programs in simultaneously allowing background knowledge  function free programs  and recursion  we have also focused exclusively on computational limitations on ecient learnability
that are associated with recursion  as we have considered only languages known to be paclearnable in the nonrecursive case  since the results of this paper are all negative  we have
concentrated on the model of polynomial predictability  negative results in this model immediately imply a negative result in the stronger model of pac learnability  and also imply
negative results for all strictly more expressive languages 
among the most closely related prior results are the negative results we have previously
obtained for certain classes of nonrecursive function free logic programs  cohen      b  
these results are similar in character to the results described here  but apply to nonrecursive
languages  similar cryptographic results have been obtained by frazier and page        for
certain classes of programs  both recursive and nonrecursive  that contain function symbols
but disallow background knowledge 
some prior negative results have also been obtained on the learnability of other firstorder languages using the proof technique of consistency hardness  pitt   valiant        
haussler        showed that the language of  existential conjunction concepts  is not paclearnable by showing that it can be hard to find a concept in the language consistent with a
given set of examples  similar results have also been obtained for two restricted languages
of horn clauses  kietz         a simple description logic  cohen   hirsh         and for the
language of sorted first order terms  page   frisch         all of these results  however  are
specific to the model pac learnability  and none can be easily extended to the polynomial
predictability model considered here  the results also do not extend to languages more
expressive than these specific constrained languages  finally  none of these languages allow
recursion 
to our knowledge  there are no other negative learnability results for first order languages  a discussion of prior positive learnability results for first order languages can be
found in the companion paper  cohen        

   summary
this paper and its companion  cohen        have considered a large number of different
subsets of datalog  our aim has been to be not comprehensive  but systematic  in particular  we wished to find precisely where the boundaries of learnability lie as various syntactic
restrictions are imposed and relaxed  since it is all too easy for a reader to  miss the forest
for the trees   we will now briey summarize the results contained in this paper  together
with the positive results of the companion paper  cohen        
   

fipac learning recursive logic programs  negative results

local
clauses

constant depth determinate
clauses

ncr 

ncr 

ncr jcb 

ncr   cb 

k  ncr 

n  ncr 

kcr 

kcr 

kcrjcb 

kcr  cbdnf

k  k crdnf

n  kcr 

 cr 

 cr 

 crjcb 

 cr  cb dnf

    cr dnf

n   cr 

table    a summary of the learnability results
throughout these papers  we have assumed that a polynomial amount of background
knowledge exists  that the programs being learned contain no function symbols  and that
literals in the body of a clause have small arity  we have also assumed that recursion is
closed   meaning that no output variables appear in a recursive clause  however  we believe
that this restriction can be relaxed without fundamentally changing the results of the paper 
in the companion paper  cohen        we showed that a single nonrecursive constantdepth determinate clause was learnable in the strong model of identification from equivalence
queries   in this learning model  one is given access to an oracle for counterexamples that
is  an oracle that will find  in unit time  an example on which the current hypothesis is
incorrect and must reconstruct the target program exactly from a polynomial number of
these counterexamples  this result implies that a single nonrecursive constant depth determinate clause is pac learnable  as the counterexample oracle can be emulated by drawing
random examples in the pac setting   the result is not novel  dzeroski et al          however
the proof given is independent  and is also of independent interest  notably  it is somewhat
more rigorous than earlier proofs  and also proves the result directly  rather than via reduction to a propositional learning problem  the proof also introduces a simple version of the
forced simulation technique  variants of which are used in all of the positive results 
we then showed that the learning algorithm for nonrecursive clauses can be extended
to the case of a single linear recursive constant depth determinate clause  leading to the
result that this restricted class of recursive programs is also identifiable from equivalence
queries  with a bit more effort  this algorithm can be further extended to learn a single
k ary recursive constant depth determinate clause 
we also considered extended the learning algorithm to learn recursive programs consisting of more than one constant depth determinate clauses  the most interesting extension
was to simultaneously learn a recursive clause cr and a base clause cb   using equivalence
queries and also a  basecase oracle  that indicates which counterexamples should be covered
by the base clause cb   in this model  it is possible to simultaneously learn a recursive clause
and a nonrecursive base case in all of the situations for which a recursive clause is learned
   

ficohen

language family
d depthnonrec a db  a detdec 
d depthlinrec a db  a detdec 
d depth k rec a db  a detdec 
d depth   clause a db  a detdec 
kd maxreclang a db  a detdec  
d depth   clause a db  a detdec 
d depth   clause  a db  a detdec  
d depthlinrecprog a db  a detdec  
d depthrec a db  a detdec  
k locallinrec a db  a dec  
 

b
 
 
 
 
 
 
 
 
 
 

r
 
 
 
 
 
 
 

l r oracles
  eq
 
eq
k
eq
 
eq base
k
eq base
 
eq
 
eq
n  
eq
  n
eq
   
eq

notation learnable
cb
yes
 cr
yes
kcr
yes
 crjcb yes
kcrjcb
yes
 cr  cb  dnf
    cr  dnf
n   cr no
ncr
no
 cr
no

table    summary by language of the learnability results  column b indicates the number
of base  nonrecursive  clauses allowed in a program  column r indicates the number of recursive clauses  l r indicates the number of recursive literals allowed in
a single recursive clause  eq indicates an oracle for equivalence queries and base
indicates a basecase oracle  for all languages except k locallinrec  all clauses
must be determinate and of depth d 
alone  for instance  one can learn a k ary recursive clause to together with its nonrecursive
base case  this was our strongest positive result 
these results are summarized in tables   and    in table    a program with one rary recursive clause is denoted rcr  a program with one r ary recursive clause and one
nonrecursive basecase is denoted rcr  cb   or rcrjcb if there is a  basecase  oracle  and
a program with s different r ary recursive clauses is denoted s  rcr   the boxed results
are associated with one or more theorems from this paper  or its companion paper  and
the unmarked results are corollaries of other results  a     after a program class indicates
that it is identifiable from equivalence queries  thus the positive results described above are
summarized by the four     entries in the lower left hand corner of the section of the table
concerned with constant depth determinate clauses 
table   presents the same information in a slightly different format  and also relates the
notation of table   to the terminology used elsewhere in the paper 
this paper has considered the learnability of the various natural generalizations of the
languages shown to be learnable in the companion paper  consider for the moment single
clauses  the companion paper showed that for any fixed k a single k ary recursive constantdepth determinate clause is learnable  here we showed that all of these restrictions are
necessary  in particular  a program of n constant depth linear recursive clauses is not
polynomially predictable  hence the restriction to a single clause is necessary  also  a single
clause with n recursive calls is hard to learn  hence the restriction to k ary recursion is
necessary  we also showed that the restriction to constant depth determinate clauses is
necessary  by considering the learnability of constant locality clauses   constant locality
clauses are the only known generalization of constant depth determinate clauses that are
pac learnable in the nonrecursive case  however  we showed that if recursion is allowed 
   

fipac learning recursive logic programs  negative results

then this language is not learnable  even a single linear recursive clause is not polynomially
predictable 
again  these results are summarized in table    a     after a program class means that
it is not polynomially predictable  under cryptographic assumptions  and hence neither
pac learnable nor identifiable from equivalence queries 
the negative results based on cryptographic hardness give an upper bound on the expressiveness of learnable recursive languages  but still leave open the learnability of programs
with a constant number of k ary recursive clauses in the absence of a basecase oracle  in
the final section of this paper  we showed that the following problems are  in the model of
polynomial predictability  equivalent to predicting boolean dnf 
 predicting two clause constant depth determinate recursive programs containing one
linear recursive clause and one base case 
 predicting two clause recursive constant depth determinate programs containing two
linear recursive clauses  even if the base case is known 
we note that these program classes are the very nearly the simplest classes of multi clause
recursive programs that one can imagine  and that the pac learnability of dnf is a longstanding open problem in computational learning theory  these results suggest  therefore 
that pac learning multi clause recursive logic programs is dicult  at the very least  they
show that finding a provably correct pac learning algorithm will require substantial advances
in computational learning theory  in table    a    dnf   respectively  dnf  means that
the corresponding language is prediction equivalent to dnf  respectively at least as hard
as dnf  
to further summarize table    with any sort of recursion  only programs containing
constant depth determinate clauses are learnable  the only constant depth determinate
recursive programs that are learnable are those that contain a single k ary recursive clause
 in the standard equivalence query model  or a single k ary recursive clause plus a base
case  if a  basecase oracle  is allowed   all other classes recursive programs are either
cryptographically hard  or as hard as boolean dnf 

   conclusions

inductive logic programming is an active area of research  and one broad class of learning
problems considered in this area is the class of  automatic logic programming  problems 
prototypical examples of this genre of problems are learning to append two lists  or to
multiply two numbers  most target concepts in automatic logic programming are recursive
programs  and often  the training data for the learning system are simply examples of the
target concept  together with suitable background knowledge 
the topic of this paper is the pac learnability of recursive logic programs from random
examples and background knowledge  specifically  we wished to establish the computational
limitations inherit in performing this task  we began with some positive results established
in a companion paper  these results show that one constant depth determinate closed k ary
recursive clause is pac learnable  and that further  a program consisting of one such recursive
clause and one constant depth determinate nonrecursive clause is also pac learnable given
an additional  basecase oracle  
   

ficohen

in this paper we showed that these positive results are not likely to be improved  in
particular  we showed that either eliminating the basecase oracle or learning two recursive clauses simultaneously is prediction equivalent to learning dnf  even in the case of
linear recursion  we also showed that the following problems are as hard as breaking  presumably  secure cryptographic codes  pac learning n linear recursive determinate clauses 
pac learning one n ary recursive determinate clause  or pac learning one linear recursive
k local clause 
these results contribute to machine learning in several ways  from the point of view
of computational learning theory  several results are technically interesting  one is the
prediction equivalence of several classes of restricted logic programs and boolean dnf  this
result  together with others like it  cohen      b   reinforces the importance of the learnability problem for dnf  this paper also gives a dramatic example of how adding recursion
can have widely differing effects on learnability  while constant depth determinate clauses
remain pac learnable when linear recursion is added  constant locality clauses become cryptographically hard 
our negative results show that systems which apparently learn a larger class of recursive
programs must be taking advantage either of some special properties of the target concepts
they learn  or of the distribution of examples that they are provided with  we believe that
the most likely opportunity for obtaining further positive formal results in this area is to
identify and analyze these special properties  for example  in many examples in which
foil has learned recursive logic programs  it has made use of  complete example sets  
datasets containing all examples of or below a certain size  rather than sets of randomly
selected examples  quinlan   cameron jones         it is possible that complete datasets
allow a more expressive class of programs to be learned than random datasets  in fact  some
progress has been recently made toward formalizing this conjecture  de raedt   dzeroski 
      
finally  and most importantly  this paper has established the boundaries of learnability
for determinate recursive programs in the pac learnability model  in many plausible automatic programming contexts it would be highly desirable to have a system that offered some
formal guarantees of correctness  the results of this paper provide upper bounds on what
one can hope to achieve with an ecient  formally justified system that learns recursive
programs from random examples alone 

acknowledgements
the author wishes to thank three anonymous jair reviewers for a number of useful suggestions on the presentation and technical content 

references
aha  d   lapointe  s   ling  c  x     matwin  s          inverting implication with small
training sets  in machine learning  ecml    catania  italy  springer verlag  lecture
notes in computer science       
   

fipac learning recursive logic programs  negative results

biermann  a          the inference of regular lisp programs from examples  ieee transactions on systems  man and cybernetics        
chandra  a  k   kozen  d  c     stockmeyer  l  j          alternation  journal of the
acm              
cohen  w  w       a   cryptographic limitations on learning one clause logic programs  in
proceedings of the tenth national conference on artificial intelligence washington 
d c 
cohen  w  w       b   pac learning non recursive prolog clauses  to appear in artificial
intelligence 
cohen  w  w       c   rapid prototyping of ilp systems using explicit bias  in proceedings
of the      ijcai workshop on inductive logic programming chambery  france 
cohen  w  w       a   pac learning nondeterminate clauses  in proceedings of the eleventh
national conference on artificial intelligence seattle  wa 
cohen  w  w       b   recovering software specifications with inductive logic programming  in proceedings of the eleventh national conference on artificial intelligence
seattle  wa 
cohen  w  w          pac learning recursive logic programs  ecient algorithms  journal
of ai research             
cohen  w  w     hirsh  h          the learnability of description logics with equality
constraints  machine learning           
de raedt  l     dzeroski  s          first order jk clausal theories are pac learnable 
in wrobel  s   ed    proceedings of the fourth international workshop on inductive
logic programming bad honnef bonn  germany 
dzeroski  s   muggleton  s     russell  s          pac learnability of determinate logic
programs  in proceedings of the      workshop on computational learning theory
pittsburgh  pennsylvania 
frazier  m     page  c  d          learnability of recursive  non determinate theories  some
basic results and techniques  in proceedings of the third international workshop on
inductive logic programming bled  slovenia 
haussler  d          learning conjunctive concepts in structural domains  machine learning        
hopcroft  j  e     ullman  j  d          introduction to automata theory  languages  and
computation  addison wesley 
kearns  m     valiant  l          cryptographic limitations on learning boolean formulae
and finite automata  in   th annual symposium on the theory of computing  acm
press 
   

ficohen

kietz  j  u          some computational lower bounds for the computational complexity
of inductive logic programming  in proceedings of the      european conference on
machine learning vienna  austria 
king  r  d   muggleton  s   lewis  r  a     sternberg  m  j  e          drug design by
machine learning  the use of inductive logic programming to model the structureactivity relationships of trimethoprim analogues binding to dihydrofolate reductase 
proceedings of the national academy of science     
lavrac  n     dzeroski  s          background knowledge and declarative bias in inductive
concept learning  in jantke  k  p   ed    analogical and inductive inference  international workshop aii     springer verlag  daghstuhl castle  germany  lectures in
artificial intelligence series      
lloyd  j  w          foundations of logic programming  second edition  springer verlag 
muggleton  s     de raedt  l          inductive logic programming  theory and methods 
journal of logic programming                     
muggleton  s     feng  c          ecient induction of logic programs  in inductive logic
programming  academic press 
muggleton  s   king  r  d     sternberg  m  j  e          protein secondary structure
prediction using logic based machine learning  protein engineering                 
muggleton  s  h   ed            inductive logic programming  academic press 
page  c  d     frisch  a  m          generalization and learnability  a study of constrained
atoms  in inductive logic programming  academic press 
pazzani  m     kibler  d          the utility of knowledge in inductive learning  machine
learning        
pitt  l     warmuth  m  k          reductions among prediction problems  on the difficulty of predicting automata  in proceedings of the  rd annual ieee conference
on structure in complexity theory washington  d c  computer society press of the
ieee 
pitt  l     valiant  l          computational limitations on learning from examples  journal
of the acm                  
pitt  l     warmuth  m          prediction preserving reducibility  journal of computer
and system sciences              
quinlan  j  r     cameron jones  r  m          foil  a midterm report  in brazdil  p  b 
 ed    machine learning  ecml    vienna  austria  springer verlag  lecture notes
in computer science       
quinlan  j  r          learning logical definitions from relations  machine learning        
   

fipac learning recursive logic programs  negative results

quinlan  j  r          determinate literals in inductive logic programming  in proceedings
of the eighth international workshop on machine learning ithaca  new york  morgan
kaufmann 
rouveirol  c          flattening and saturation  two representation changes for generalization  machine learning         
summers  p  d          a methodology for lisp program construction from examples 
journal of the association for computing machinery                  
valiant  l  g          a theory of the learnable  communications of the acm          
zelle  j  m     mooney  r  j          inducing deterministic prolog parsers from treebanks 
a machine learning approach  in proceedings of the twelfth national conference on
artificial intelligence seattle  washington  mit press 

   

fi