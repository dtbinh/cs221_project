journal of artificial intelligence research                 

submitted        published     

provably bounded optimal agents
stuart j  russell

computer science division  university of california
berkeley  ca        usa

devika subramanian

computer science department  cornell university
ithaca  ny        usa

russell cs berkeley edu
devika cs cornell edu

abstract

since its inception  artificial intelligence has relied upon a theoretical foundation centred around perfect rationality as the desired property of intelligent systems  we argue 
as others have done  that this foundation is inadequate because it imposes fundamentally
unsatisfiable requirements  as a result  there has arisen a wide gap between theory and
practice in ai  hindering progress in the field  we propose instead a property called bounded
optimality  roughly speaking  an agent is bounded optimal if its program is a solution to
the constrained optimization problem presented by its architecture and the task environment  we show how to construct agents with this property for a simple class of machine
architectures in a broad class of real time environments  we illustrate these results using
a simple model of an automated mail sorting facility  we also define a weaker property 
asymptotic bounded optimality  abo   that generalizes the notion of optimality in classical
complexity theory  we then construct universal abo programs  i e   programs that are
abo no matter what real time constraints are applied  universal abo programs can be
used as building blocks for more complex systems  we conclude with a discussion of the
prospects for bounded optimality as a theoretical basis for ai  and relate it to similar trends
in philosophy  economics  and game theory 

   introduction

since before the beginning of artificial intelligence  philosophers  control theorists and
economists have looked for a satisfactory definition of rational behaviour  this is needed to
underpin theories of ethics  inductive learning  reasoning  optimal control  decision making 
and economic modelling  doyle        has proposed that ai itself be defined as the computational study of rational behaviour effectively equating rational behaviour with intelligence  the role of such definitions in ai is to ensure that theory and practice are correctly
aligned  if we define some property p   then we hope to be able to design a system that
provably possesses property p   theory meets practice when our systems exhibit p in reality  furthermore  that they exhibit p in reality should be something that we actually care
about  in a sense  the choice of what p to study determines the nature of the field 
there are a number of possible choices for p  
 perfect rationality  the classical notion of rationality in economics and philosophy 
a perfectly rational agent acts at every instant in such a way as to maximize its
expected utility  given the information it has acquired from the environment  since
action selection requires computation  and computation takes time  perfectly rational
agents do not exist for non trivial environments 
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

firussell   subramanian

 calculative rationality  the notion of rationality studied in ai  a calculatively rational

agent eventually returns what would have been the rational choice at the beginning of
its deliberation  there exist systems such as inuence diagram evaluators that exhibit
this property for a decision theoretic definition of rational choice  and systems such
as nonlinear planners that exhibit it for a logical definition of rational choice  this
is assumed to be an interesting property for a system to exhibit since it constitutes
an  in principle  capacity to do the right thing  calculative rationality is of limited
value in practice  because the actual behaviour exhibited by such systems is absurdly
far from being rational  for example  a calculatively rational chess program will choose
the right move  but may take      times too long to do so  as a result  ai systembuilders often ignore theoretical developments  being forced to rely on trial and error
engineering to achieve their goals  even in simple domains such as chess  there is little
theory for designing and analysing high performance programs 
 metalevel rationality  a natural response to the problems of calculative rationality 
a metalevel rational system optimizes over the object level computations to be performed in the service of selecting actions  in other words  for each decision it finds
the optimal combination of computation sequence plus action  under the constraint
that the action must be selected by the computation  full metalevel rationality is
seldom useful because the metalevel computations themselves take time  and the metalevel decision problem is often more dicult than the object level problem  simple
approximations to metalevel rationality have proved useful in practice for example  metalevel policies that limit lookahead in chess programs but these engineering
expedients merely serve to illustrate the lack of a theoretical basis for agent design 
 bounded optimality  a bounded optimal agent behaves as well as possible given its
computational resources  bounded optimality specifies optimal programs rather than
optimal actions or optimal computation sequences  only by the former approach
can we avoid placing constraints on intelligent agents that cannot be met by any
program  actions and computations are  after all  generated by programs  and it is
over programs that designers have control 
we make three claims 
   a system that exhibits bounded optimality is desirable in reality 
   it is possible to construct provably bounded optimal programs 
   artificial intelligence can be usefully characterized as the study of bounded optimality 
particularly in the context of complex task environments and reasonably powerful
computing devices 
the first claim is unlikely to be controversial  this paper supports the second claim in
detail  the third claim may  or may not  stand the test of time 
we begin in section   with a necessarily brief discussion of the relationship between
bounded optimality and earlier notions of rationality  we note in particular that some important distinctions can be missed without precise definitions of terms  thus in section   we
provide formal definitions of agents  their programs  their behaviour and their rationality 
   

fiprovably bounded optimal agents

together with formal descriptions of task environments  these elements allow us to prove
that a given agent exhibits bounded optimality  section   examines a class of agent architectures for which the problem of generating bounded optimal configurations is eciently
soluble  the solution involves a class of interesting and practically relevant optimization
problems that do not appear to have been addressed in the scheduling literature  we illustrate the results by showing how the throughput of an automated mail sorting facility
might be improved  section   initiates a discussion of how bounded optimal configurations
might be learned from experience in an environment  in section    we define a weaker property  asymptotic bounded optimality  abo   that may be more robust and tractable than
the strict version of bounded optimality  in particular  we can construct universal abo
programs  a program is universally abo if it is abo regardless of the specific form of
time dependence of the utility function   universal abo programs can therefore be used as
building blocks for more complex systems  we conclude with an assessment of the prospects
for further development of this approach to artificial intelligence 

   historical perspective
the classical idea of perfect rationality  which developed from aristotle s theories of ethics 
work by arnauld and others on choice under uncertainty  and mill s utilitarianism  was put
on a formal footing in decision theory by ramsey        and vonneumann and morgernstern
        it stipulates that a rational agent always act so as to maximize its expected utility 
the expectation is taken according to the agent s own beliefs  thus  perfect rationality does
not require omniscience 
in artificial intelligence  the logical definition of rationality  known in philosophy as the
 practical syllogism   was put forward by mccarthy         and reiterated strongly by
newell         under this definition  an agent should take any action that it believes is
guaranteed to achieve any of its goals  if ai can be said to have had a theoretical foundation  then this definition of rationality has provided it  mccarthy believed  probably
correctly  that in the early stages of the field it was important to concentrate on  epistemological adequacy  before  heuristic adequacy    that is  capability in principle rather than
in practice  the methodology that has resulted involves designing programs that exhibit
calculative rationality  and then using various speedup techniques and approximations in
the hope of getting as close as possible to perfect rationality  our belief  albeit unproven  is
that the simple agent designs that fulfill the specification of calculative rationality may not
provide good starting points from which to approach bounded optimality  moreover  a theoretical foundation based on calculative rationality cannot provide the necessary guidance
in the search 
it is not clear that ai would have embarked on the quest for calculative rationality had it
not been operating in the halcyon days before formal intractability results were discovered 
one response to the spectre of complexity has been to rule it out of bounds  levesque and
brachman        suggest limiting the complexity of the environment so that calculative and
perfect rationality coincide  doyle and patil        argue strongly against this position 
   this usage of the term  universal  derives from its use in the scheduling of randomized algorithms by
luby  sinclair and zuckerman        

   

firussell   subramanian

economists have used perfect rationality as an abstract model of economic entities  for
the purposes of economic forecasting and designing market mechanisms  this makes it
possible to prove theorems about the properties of markets in equilibrium  unfortunately 
as simon        pointed out  real economic entities have limited time and limited powers
of deliberation  he proposed the study of bounded rationality  investigating        the shape
of a system in which effectiveness in computation is one of the most important weapons
of survival   simon s work focussed mainly on satisficing designs  which deliberate until
reaching some solution satisfying a preset  aspiration level   the results have descriptive value for modelling various actual entities and policies  but no general prescriptive
framework for bounded rationality was developed  although it proved possible to calculate
optimal aspiration levels for certain problems  no structural variation was allowed in the
agent design 
in the theory of games  bounds on the complexity of players have become a topic of
intense interest  for example  it is a troubling fact that defection is the only equilibrium
strategy for unbounded agents playing a fixed number of rounds of the prisoners  dilemma
game  neyman s theorem  neyman         recently proved by papadimitriou and yannakakis         shows that an essentially cooperative equilibrium exists if each agent is a
finite automaton with a number of states that is less than exponential in the number of
rounds  this is essentially a bounded optimality result  where the bound is on space rather
than on speed of computation  this type of result is made possible by a shift from the
problem of selecting actions to the problem of selecting programs 
i  j  good        distinguished between perfect or  type i  rationality  and metalevel
or  type ii  rationality  he defines this as  the maximization of expected utility taking into
account deliberation costs   simon        also says   the global optimization problem is
to find the least cost or best return decision  net of computational costs   although type ii
rationality seems to be a step in the right direction  it is not entirely clear whether it can be
made precise in a way that respects the desirable intuition that computation is important 
we will try one interpretation  although there may be others   the key issue is the space
over which the  maximization  or  optimization  occurs  both good and simon seem to
be referring to the space of possible deliberations associated with a particular decision 
conceptually  there is an  object level machine  that executes a sequence of computations
under the control of a  meta level machine   the outcome of the sequence is the selection of
an external action  an agent exhibits type ii rationality if at the end of its deliberation and
subsequent action  its utility is maximized compared to all possible deliberate act pairs in
which it could have engaged  for example  good discusses one possible application of type
ii rationality in chess programs  in this case  the object level steps are node expansions in
the game tree  followed by backing up of leaf node evaluations to show the best move  for
simplicity we will assume a per move time limit  then a type ii rational agent will execute
whichever sequence of node expansions chooses the best move  of all those that finish before
   for example  it is conceivable that good and simon really intended to refer to finding an agent design
that minimizes deliberation costs in general  all their discussions  however  seem to be couched in terms
of finding the right deliberation for each decision  thus  type ii or metalevel rationality coincides with
bounded optimality if the bounded optimal agent is being designed for a single decision in a single
situation 

   

fiprovably bounded optimal agents

the time limit   unfortunately  the computations required in the  metalevel machine  to
select the object level deliberation may be extremely expensive  good actually proposes a
fairly simple  and nearly practical  metalevel decision procedure for chess  but it is far from
optimal  it is hard to see how a type ii rational agent could justify executing a suboptimal
object level computation sequence if we limit the scope of the optimization problem to a
single decision  the diculty can only be resolved by thinking about the design of the
agent program  which generates an unbounded set of possible deliberations in response to
an unbounded set of circumstances that may arise during the life of the agent 
philosophy has also seen a gradual evolution in the definition of rationality  there has
been a shift from consideration of act utilitarianism   the rationality of individual acts   to
rule utilitarianism  or the rationality of general policies for acting  this shift has been caused
by diculties with individual versus societal rationality  rather than any consideration of
the diculty of computing rational acts  some consideration has been given more recently
to the tractability of general moral policies  with a view to making them understandable
and usable by persons of average intelligence  brandt         cherniak        has suggested
a definition of  minimal rationality   specifying lower bounds on the reasoning powers of
any rational agent  instead of upper bounds  a philosophical proposal generally consistent
with the notion of bounded optimality can be found in dennett s  moral first aid manual 
        dennett explicitly discusses the idea of reaching equilibrium within the space of
decision procedures  he uses as an example the phd admissions procedure of a philosophy
department  he concludes  as do we  that the best procedure may be neither elegant nor
illuminating  the existence of such a procedure  and the process of reaching it  are the
main points of interest 
many researchers in ai  some of whose work is discussed below  have worked on the
problem of designing agents with limited computational resources  the      aaai symposium on ai and limited rationality  fehling   russell        contains an interesting
variety of work on the topic  much of this work is concerned with metalevel rationality 
metareasoning   reasoning about reasoning   is an important technique in this area 
since it enables an agent to control its deliberations according to their costs and benefits 
combined with the idea of anytime  dean   boddy        or exible algorithms  horvitz 
       that return better results as time goes by  a simple form of metareasoning allows
an agent to behave well in a real time environment  a simple example is provided by
iterative deepening algorithms used in game playing  breese and fehling        apply similar ideas to controlling multiple decision procedures  russell and wefald        give a
general method for precompiling certain aspects of metareasoning so that a system can eciently estimate the effects of individual computations on its intentions  giving fine grained
control of reasoning  these techniques can all be seen as approximating metalevel rationality  they provide useful insights into the general problem of control of reasoning  but there
is no reason to suppose that the approximations used are optimal in any sense 
the intuitive notion of bounded optimality seems to have become current in the ai
community in the mid      s  horvitz        uses the term bounded optimality to refer
to  the optimization of computational utility given a set of assumptions about expected
   one would imagine that in most cases the move selected will be the same move selected by a type
i agent  but this is in a sense  accidental  because further deliberation might cause the program to
abandon it 

   

firussell   subramanian

problems and constraints in reasoning resources   russell and wefald        say that an
agent exhibits bounded optimality for a given task environment  if its program is a solution
to the constrained optimization problem presented by its architecture   recent work by
etzioni        and russell and zilberstein        can be seen as optimizing over a welldefined set of agent designs  thereby making the notion of bounded optimality more precise 
in the next section  we build a suitable set of general definitions from the ground up  so
that we can begin to demonstrate examples of provably bounded optimal agents 

   agents  architectures and programs
intuitively  an agent is just a physical entity that we wish to view in terms of its perceptions
and actions  what counts in the first instance is what it does  not necessarily what it thinks 
or even whether it thinks at all  this initial refusal to consider further constraints on the
internal workings of the agent  such as that it should reason logically  for example  helps in
three ways  first  it allows us to view such  cognitive faculties  as planning and reasoning
as occurring in the service of finding the right thing to do  second  it makes room for those
among us  agre   chapman        brooks        who take the position that systems can
do the right thing without such cognitive faculties  third  it allows more freedom to consider
various specifications  boundaries and interconnections of subsystems 
we begin by defining agents and environments in terms of the actions and percepts
that they exchange  and the sequence of states they go through  the agent is described
by an agent function from percept sequences to actions  this treatment is fairly standard
 see  e g   genesereth   nilsson         we then go  inside  the agent to look at the agent
program that generates its actions  and define the  implementation  relationship between
a program and the corresponding agent function  we consider performance measures on
agents  and the problem of designing agents to optimize the performance measure 

    specifying agents and environments

an agent can be described abstractly as a mapping  the agent function  from percept
sequences to actions  let o be the set of percepts that the agent can receive at any instant 
and a be the set of possible actions the agent can carry out in the external world  since
we are interested in the behaviour of the agent over time  we introduce a set of time points
or instants  t  the set t is totally ordered by the   relation with a unique least element 
without loss of generality  we let t be the set of non negative integers 
the percept history of an agent is a sequence of percepts indexed by time  we define
the set of percept histories to be ot   fot   t   og  the prefix of a history ot   ot
till time t is denoted ot and is the projection of ot on     t   we can define the set of
percept history prefixes as ot   fot j t   t  ot   otg  similarly  we define the set of
action histories at   fat   t   ag  the set of action history prefixes is at  defined as
the set of projections at of histories at   at  

definition   agent function  a mapping
f   ot   a
   

fiprovably bounded optimal agents

where

at t    f  ot 
note that the agent function is an entirely abstract entity  unlike the agent program that
implements it  note also that the  output  of the agent function for a given percept sequence
may be a null action  for example if the agent is still thinking about what to do  the agent
function specifies what the agent does at each time step  this is crucial to the distinction
between perfect rationality and calculative rationality 
agents live in environments  the states of an environment e are drawn from a set x 
the set of possible state trajectories is defined as xt   fx t   t   xg  the agent does not
necessarily have full access to the current state x t t   but the percept received by the agent
does depend on the current state through the perceptual filtering function fp  the effects
of the agent s actions are represented by the environment s transition function fe  which
specifies the next state given the current state and the agent s action  an environment is
therefore defined as follows 

definition   environment e   a set of states x with a distinguished initial state x   a
transition function fe and a perceptual filter function fp such that

x t       x 
x t t        fe at  t   x t t  
ot t    fp x t t  
the state history x t is thus determined by the environment and the agent function  we
use the notation effects f  e   to denote the state history generated by an agent function
f operating in an environment e   we will also use the notation  e  at   to denote the
state history generated by applying the action sequence at starting in the initial state of
environment e  
notice that the environment is discrete and deterministic in this formulation  we can
extend the definitions to cover non deterministic and continuous environments  but at the
cost of additional complexity in the exposition  none of our results depend in a significant
way on discreteness or determinism 

    specifying agent implementations

we will consider a physical agent as consisting of an architecture and a program  the
architecture is responsible for interfacing between the program and the environment  and
for running the program itself  with each architecture m   we associate a finite programming
language lm   which is just the set of all programs runnable by the architecture  an agent
program is a program l   lm that takes a percept as input and has an internal state drawn
from a set i with initial state i    the initial internal state depends on the program l 
but we will usually suppress this argument   the set of possible internal state histories is
it   fi t   t   ig  the prefix of an internal state history i t   it till time t is denoted i t
and is the projection of i t on     t  
   

firussell   subramanian

definition   an architecture m is a fixed interpreter for an agent program that runs the

program for a single time step  updating its internal state and generating an action 
m   lm  i  o   i  a
where
hi t t       at t i   m  l  i t t   ot t  
thus  the architecture generates a stream of actions according to the dictates of the program 
because of the physical properties of the architecture  running the program for a single
time step results in the execution of only a finite number of instructions  the program may
often fail to reach a  decision  in that time step  and as a result the action produced by the
architecture may be null  or the same as the previous action  depending on the program
design  

    relating agent specifications and implementations

we can now relate agent programs to the corresponding agent functions  we will say that an
agent program l running on a machine m implements the agent function agent l  m    the
agent function is constructed in the following definition by specifying the action sequences
produced by l running on m for all possible percept sequences  note the importance of the
 markovian  construction using the internal state of the agent to ensure that actions can
only be based on the past  not the future 

definition   a program l running on m implements the agent function f   agent l  m   
defined as follows  for any environment e    x  fe  fp   f  ot    at  t  where
hi t t       at t i   m  l  i t t   ot t  
ot  t 
x t t     
x t   
i t   

 
 
 
 

fp x t t  
fe at t   x t t  
x 
i 

although every program l induces a corresponding agent function agent l  m    the
action that follows a given percept is not necessarily the agent s  response  to that percept 
because of the delay incurred by deliberation  it may only reect percepts occurring much
earlier in the sequence  furthermore  it is not possible to map every agent function to an
implementation l   lm   we can define a subset of the set of agent functions f that are
implementable on a given architecture m and language lm  
feasible m     ff j  l   lm   f   agent l  m  g
feasibility is related to  but clearly distinct from  the notion of computability  computability refers to the existence of a program that eventually returns the output specified by
a function  whereas feasibility refers to the production of the output at the appropriate
point in time  the set of feasible agent functions is therefore much smaller than the set of
computable agent functions 
   

fiprovably bounded optimal agents

    performance measures for agents

to evaluate an agent s performance in the world  we define a real valued utility function u
on state histories 
u   xt    
the utility function should be seen as external to the agent and its environment  it defines
the problem to be solved by the designer of the agent  some agent designs may incorporate
an explicit representation of the utility function  but this is by no means required  we will
use the term task environment to denote the combination of an environment and a utility
function 
recall that the agent s actions drive the environment e through a particular sequence
of states in accordance with the function effects f  e    we can define the value of an agent
function f in the environment e as the utility of the state history it generates 
v  f  e     u  effects f  e   
if the designer has a set e of environments with a probability distribution p over them 
instead of a single environment e   then the value of the agent in e is defined as the
expected value over the elements of e  by a slight abuse of notation 

v  f  e   

x

e e

p e  v  f  e  

we can assign a value v  l  m  e   to a program l executed by the architecture m in the
environment e simply by looking at the effect of the agent function implemented by the
program 
v  l  m  e     v  agent l  m    e     u  effects agent l  m    e   
as above  we can extend this to a set of possible environments as follows 

v  l  m  e   

x

e e

p e  v  l  m  e  

    perfect rationality and bounded optimality

as discussed in section    a perfectly rational agent selects the action that maximizes its
expected utility  given the percepts so far  in our framework  this amounts to an agent
function that maximizes v  f  e  over all possible agent functions 
definition   a perfectly rational agent for a set e of environments has an agent function
fopt such that
fopt   argmaxf  v  f  e  
this definition is a persuasive specification of an optimal agent function for a given
set of environments  and underlies several recent projects in intelligent agent design  dean
  wellman       doyle        hansson   mayer         a direct implementation of this
specification  which ignores the delay incurred by deliberation  does not yield a reasonable
   

firussell   subramanian

solution to our problem   the calculation of expected utilities takes time for any real agent 
in terms of our simple formal description of agents introduced above  it is easy to see where
the diculty has arisen  in designing the agent program  logicists and decision theorists
have concentrated on specifying an optimal agent function fopt in order to guarantee the
selection of the best action history  the function fopt is independent of the architecture m  
unfortunately  no real program in lm implements this function in a non trivial environment 
because optimal actions cannot usually be computed before the next percept arrives  that
is  quite frequently  fopt    feasible m   
suppose the environment consists of games of chess under tournament rules against some
population of human grandmasters  and suppose m is some standard personal computer 
then fopt describes an agent that always plays in such a way as to maximize its total
expected points against the opposition  where the maximization is over the moves it makes 
we claim that no possible program can play this way  it is quite possible  using depth first
alpha beta search to termination  to execute the program that chooses  say  the optimal
minimax move in each situation  but the agent function induced by this program is not the
same as fopt  in particular  it ignores such percepts as the dropping of its ag indicating a
loss on time 
the trouble with the perfect rationality definition arose because of unconstrained optimization over the space of f  s in the determination of fopt   without regard to feasibility 
 similarly  metalevel rationality assumes unconstrained optimization over the space of deliberations   to escape this quandary  we propose a machine dependent standard of rationality  in which we maximize v over the implementable set of agent functions feasible m   
that is  we impose optimality constraints on programs rather than on agent functions or
deliberations 

definition   a bounded optimal agent with architecture m for a set e of environments
has an agent program lopt such that
lopt   argmaxl lm v  l  m  e 

we can see immediately that this specification avoids the most obvious problems with
type i and type ii rationality  consider our chess example  and
suppose the computer has
  
 
a total program memory of   megabytes  then there are   possible programs that can
be represented in the machine  of which a much smaller number play legal chess  under
tournament conditions  one or more of these programs will have the best expected performance  each is a suitable candidate for lopt  thus bounded optimality is  by definition  a
feasible specification  moreover  a program that achieves it is highly desirable  we are not
yet ready to announce the identity of lopt for chess on an eight megabyte pc  so we will
begin with a more restricted problem 

   provably bounded optimal agents

in order to construct a provably bounded optimal agent  we must carry out the following
steps 
 specify the properties of the environment in which actions will be taken  and the
utility function on the behaviours 
   

fiprovably bounded optimal agents

 specify a class of machines on which programs are to be run 
 propose a construction method 
 prove that the construction method succeeds in building bounded optimal agents 
the methodology is similar to the formal analysis used in the field of optimal control  which
studies the design of controllers  agents  for plants  environments   in optimal control
theory  a controller is viewed as an essentially instantaneous implementation of an optimal
agent function  in contrast  we focus on the computation time required by the agent  and
the relation between computation time and the dynamics of the environment 

    episodic  real time task environments

in this section  we will consider a restricted class of task environments which we call episodic
environments  in an episodic task environment  the state history generated by the actions of
the agent can be considered as divided into a series of episodes  each of which is terminated
by an action  let a   a be a distinguished set of actions that terminate an episode 
the utility of the complete history is given by the sum of the utilities of each episode 
which is determined in turn by the state sequence  after each a   a   the environment
 resets  to a state chosen at random from a stationary probability distribution pinit   in
order to include the effects of the choice of a in the utility of the episode  we notionally
divide the environment state into a  configuration  part and a  value  part  such that
the configuration part determines the state transitions while the value part determines the
utility of a state sequence  actions in a  reset the configuration part  while their  value 
is recorded in the value part  these restrictions mean that each episode can be treated as
a separate decision problem  and translate into the following property  if agent program l 
has higher expected utility on individual episodes than agent l   it will have higher expected
utility in the corresponding episodic task environment 
a real time task environment is one in which the utility of an action depends on the
time at which it is executed  usually  this dependence will be suciently strong to make
calculative rationality an unacceptably bad approximation to perfect rationality 
an automated mail sorter  provides an illustrative example of an episodic task environment  see figure     such a machine scans handwritten or printed addresses  zipcodes  on
mail pieces and dispatches them to appropriate bins  each episode starts with the arrival of
a new mail piece and terminates with the execution of the physical action recommended by
the sorter  routing of the piece to a specific bin  the  configuration part  of the environment corresponds to the letter feeder side  which provides a new  randomly selected letter
after the previous letter is sorted  the  value part  of the state corresponds to the state of
the receiving bins  which determines the utility of the process  the aim is to maximize the
accuracy of sorting while minimizing the reject percentage and avoiding jams  a jam occurs
if the current piece is not routed to the appropriate bin  or rejected  before the arrival of
the next piece 
we now provide formal definitions for three varieties of real time task environments 
fixed deadlines  fixed time cost and stochastic deadlines 
   see  sackinger et al        boser et al        for details of an actual system  the application was
suggested to us by bernhard boser after an early presentation of our work at the      nec symposium 

   

firussell   subramanian

camera
sacks of mail

zipcode
buckets

reject

figure    an automated mail sorting facility provides a simple example of an episodic 
real time task environment 
      fixed deadlines

the simplest and most commonly studied kind of real time task environment contains a
deadline at a known time  in most work on real time systems  such deadlines are described
informally and systems are built to meet the deadline  here  we need a formal specification
in order to connect the description of the deadline to the properties of agents running in
deadline task environments  one might think that deadlines are part of the environment
description  but in fact they are mainly realized as constraints on the utility function  one
can see this by considering the opposite of a deadline   the  starter s pistol   the two
are distinguished by differing constraints on the utilities of acting before or after a specific
time 
definition   fixed deadline  the task environment he  u i has a fixed deadline at time td
if the following conditions hold 
 taking an action in a  at any time before the deadline results in the same utility 

u   e  at      u   e  a  td      at   t   
where    denotes sequence concatenation  t  td   at   t    a    and a  t    and a  td    
contain no action in a  
 actions taken after td have no effect on utility 

u   e  at     u   e  at    if u   e  at d     u   e  at d    and t  td
      fixed time cost

task environments with approximately fixed time cost are also very common  examples
include consultations with lawyers  keeping a taxi waiting  or dithering over where to invest
one s money  we can define a task environment with fixed time cost c by comparing the
utilities of actions taken at different times 
   

fiprovably bounded optimal agents

definition   fixed time cost 
the task environment he  u i has a fixed time cost if  for
t
t
any action history prefixes a   and a   satisfying
    at   t     a  and at   t     at   t  
    a  t      and a  t      contain no action in a 
the utilities differ by the difference in time cost 
u   e  at        u   e  at        c t    t  

strictly speaking  there are no task environments with fixed time cost  utility values have a
finite range  so one cannot continue incurring time costs indefinitely  for reasonably short
times and reasonably small costs  a linear utility penalty is a useful approximation 
      stochastic deadlines

while fixed deadline and fixed cost task environments occur frequently in the design of
real time systems  uncertainty about the time dependence of the utility function is more
common  it also turns out to be more interesting  as we see below 
a stochastic deadline is represented by uncertainty concerning the time of occurrence of
a fixed deadline  in other words  the agent has a probability distributionppd for the deadline
time td   we assume that the deadline must come eventually  so that t t pd  t       we
also define the cumulative deadline distribution pd  
if the deadline does not occur at a known time  then we need to distinguish between
two cases 
 the agent receives a percept  called a herald  dean   boddy         which announces
an impending deadline  we model this using a distinguished percept od  

ot td     od
if the agent responds immediately  then it  meets the deadline  
 no such percept is available  in which case the agent is walking blindfolded towards
the utility cliff  by deliberating further  the agent risks missing the deadline but may
improve its decision quality  an example familiar to most readers is that of deciding
whether to publish a paper in its current form  or to embellish it further and risk
being  scooped   we do not treat this case in the current paper 
formally  the stochastic deadline case is similar to the fixed deadline case  except that td is
drawn from the distribution pd   the utility of executing an action history prefix at in e is
the expectation of the utilities of that state history prefix over the possible deadline times 
definition   stochastic deadline  a task environment class he  u i of fixed deadline task
environments has a stochastic deadline distributed according to pd if  for any action history
prefix at  
x
u   e  at      pd  t  u   et   at   
t  t

 

 

where het   u i is a task environment in he  u i with a fixed deadline at t  
 

   

firussell   subramanian

the mail sorter example is well described by a stochastic deadline  the time between
the arrival of mail pieces at the image processing station is distributed according to a density
function pd   which will usually be poisson 

    agent programs and agent architecture

we consider simple agent programs for episodic task environments  constructed from elements of a set r   fr            rn g of decision procedures or rules  each decision procedure
recommends  but does not execute  an action ai   a   and an agent program is a fixed
sequence of decision procedures  for our purposes  a decision procedure is a black box with
two parameters 

 a run time ti     which is an integer that represents the time taken by the procedure
to compute an action 

 a quality qi     which is a real number  this gives the expected reward resulting
from executing its action ai at the start of an episode 

qi   u   e  ai  

   

let mj denote an agent architecture that executes decision procedures in the language j  
let tm denote the maximum runtime of the decision procedures that can be accommodated
in m   for example  if the runtime of a feedforward neural network is proportional to its
size  then tm will be the runtime of the largest neural network that fits in m  
the architecture m executes an agent program s   s        sm by running each decision
procedure in turn  providing the same input to each as obtained from the initial percept 
when a deadline arrives  at a fixed time td   or heralded by the percept od    or when
the entire sequence has been completed  the agent selects the action recommended by the
highest quality procedure it has executed 

m  s  i t td   ot td     hi   action i t td   i
m  s  i t ts   ot ts     hi   action i t ts  i where ts   psi s ti
m  s  i t t   od    hi   action i t t  i

   

where m updates the agent s internal state history i t t  such that action i t t   is the
action recommended by a completed decision procedure with the highest quality  when
this action is executed  the internal state of the agent is re initialized to i    this agent
design works in all three of the task environment categories described above 
next we derive the value v  s  m  e   of an agent program s in environment e running
on m for the three real time regimes and show how to construct bounded optimal agents
for these task environments 

    bounded optimality with fixed deadlines

from equation    we know that the agent picks the action in a  recommended by the
decision procedure r with the highest quality that is executed before the deadline td arrives 
   

fiprovably bounded optimal agents

p

let s        sj be the longest prefix of the program s such that ji   ti  td   from definition  
and equation    it follows that
v  s  m  e     qj
   
where qi   maxfq           qi g  given this expression for the value of the agent program  we
can easily show the following 
theorem   let r   arg maxri   r titd qi   the singleton sequence r is a bounded optimal
program for m in an episodic task environment with a known deadline td 
that is  the best program is the single decision procedure of maximum quality whose runtime
is less than the deadline 

    bounded optimality with fixed time cost

from equation    we know that the agent picks the action in a  recommended by the best
decision procedure in the sequence  since m runs the entire sequence s   s        sm when
there is no deadline  from definition   and equation    we have

v  s  m  e     qm   c

m
x
i  

ti

   

given this expression for the value of the agent program  we can easily show the following 
theorem   let r   arg maxri   r qi   cti   the singleton sequence r is a bounded optimal
program for m in an episodic task environment with a fixed time cost c 
that is  the optimal program is the single decision procedure whose quality  net of time
cost  is highest 

    bounded optimality with stochastic deadlines

with a stochastic deadline distributed according to pd  the value of an agent program
    sm is an expectation  from definition    we can calculate this as
p ps  t  v s s    m 
et   where het  u i is a task environment with a fixed deadline at t  aft t d
ter substituting for v  s  m  et  from equation    this expression simplifies to a summation 
over the procedures in the sequence  of the probability of interruption after the ith procedure
in the sequence multiplied by the quality of the best completed decision procedure 
m
x
pi
v  s   v  s  m  e     pd pij  
   
   tj     pd   j    tj   qi
i  
rt
where pd  t      
pd t  dt  and pd  t      for t  pmi   ti 
a simple example serves to illustrate the value function  consider r   fr    r    r g  the
rule r  has a quality of     and needs   seconds to run  we will represent this by r             
the other rules are r              r              the deadline distribution function pd is a
uniform distribution over   to    seconds  the value of the sequence r  r r  is
v  r  r r                                                
a geometric intuition is given by the notion of a performance profile  as shown in figure   

   

firussell   subramanian

q

   
   
   

p t 
t

 

 

 

figure    performance profile for r r  r   with pd superimposed 

definition    performance profile  for a sequence s  the performance profile qs  t  gives
the quality of the action returned if the agent is interrupted at t 

qs t    maxfqi  

i
x

j   

tj  tg

for a uniform deadline density function  the value of a sequence is proportional to the
area under the performance profile up to the last possible interrupt time  note that the
height of the profile during the interval of length ti while rule i is running is the quality of
the best of the previous rules 
from definition     we have the following obvious property 
lemma   the performance profile of any sequence is monotonically nondecreasing 
it is also the case that a sequence with higher quality decisions at all times is a better
sequence 
lemma   if  t qs   t   qs   t   then v  s    v  s    
in this case we say that qs  dominates qs   
we can use the idea of performance profiles to establish some useful properties of optimal
sequences 
lemma   there exists an optimal sequence that is sorted in increasing order of q s 

p

without lemma    there are ni   i  possible sequences to consider  the ordering constraint eliminates all but  n sequences  it also means that in proofs of properties of sequences  we now need consider only ordered sequences  in addition  we can replace qi in
equation   by qi  
the following lemma establishes that a sequence can always be improved by the addition
of a better rule at the end 
lemma   for every sequence s   s        sm sorted in increasing order of quality  and single
step z with qz  qsm   v  sz    v  s  
   

fiprovably bounded optimal agents

corollary   there exists an optimal sequence ending with the highest quality rule in r 
the following lemma reects the obvious intuition that if one can get a better result in
less time  there s no point spending more time to get a worse result 
lemma   there exists an optimal sequence whose rules are in nondecreasing order of ti  
we now apply these preparatory results to derive algorithms that construct bounded
optimal programs for various deadline distributions 
      general distributions

for a general deadline distribution  the dynamic programming method can be used to obtain
an optimal sequence of decision rules in pseudo polynomial time  we construct an optimal
sequence by using the definition of v  s  m  e   in equation    optimal sequences generated
by the methods are ordered by qi  in accordance with lemma   
we construct the table s  i  t   where each entry in the table is the highest value of
any sequence that ends with rule ri at time t  we assume the rule indices are arranged
in
p
increasing order of quality  and t ranges from the start time   to the end time l   ri  r ti  
the update rule is 

s  i  t    maxk      i    s  k  t   ti      qi   qk       pd  t   
with boundary condition
s  i         for each rule i and s     t      for each time t
from corollary    we can read off the best sequence from the highest value in row n of the
matrix s  
theorem   the dp algorithm computes an optimal sequence in time o n l  where n is
the number of decision procedures in r 

the dependence on l in the time complexity of the dp algorithm means that the algorithm is not polynomial in the input size  using standard rounding and scaling methods 
however  a fully polynomial approximation scheme can be constructed  although we do not
have a hardness proof for the problem  john binder        has shown that if the deadline
distribution is used as a constant time oracle for finding values of p  t   any algorithm will
require an exponential number of calls to the oracle in the worst case 
      long uniform distributions

if the deadline is uniformly distributed over a time interval greater than the sum of the
running times of the rules  we will call the distribution a long uniform distribution  consider
the rule sequence s   s        sm drawn from the rule set r  with a long uniform distribution 
the probability that the deadline arrives during rule si of the sequence s is independent of
the time at which si starts  this permits a simpler form of equation   

v  s  m  e    pmi     pd  ti   qi   qm      pmi   pd  ti  
   

   

firussell   subramanian

to derive an optimal sequence under a long uniform distribution  we obtain a recursive
specification of the value of a sequence as with a   r and s   s        sm being some sequence
in r 

v  as  m  e    v  s  m  e    qapd  t     qmpd  ta 

   

this allows us to define a dynamic programming scheme for calculating an optimal sequence
using a state function s  i  j   denoting the highest value of a rule sequence that starts with
rule i and ends in rule j   from lemma   and equation    the update rule is 

s  i  j     maxi kj  s  k  j     pd  tk  qi   pd  ti qj  

   

with boundary condition

s  i  i         pd  ti  qi

   

from corollary    we know that an optimal sequence for the long uniform distribution ends
in rn   the rule with the highest quality in r  thus  we only need to examine s  i  n     
i  n  each entry requires o n  computation  and there are n entries to compute  thus 
the optimal sequence for the long uniform case can be calculated in o n    

theorem   an optimal sequence of decision procedures for a long uniform deadline distribution can be determined in o n   time where n is the number of decision procedures in
r 
      short uniform distributions

p

when ni   pd  ti       for a uniform deadline distribution pd  we call it short  this means
that some sequences are longer than the last possible deadline time  and therefore some rules
in those sequences have no possibility of executing before the deadline  for such sequences 
we cannot use equation   to calculate v  s   however  any such sequence can be truncated
by removing all rules that would complete execution after the last possible deadline  the
value of the sequence is unaffected by truncation  and for truncated sequences the use of
equation   is justified  furthermore  there is an optimal sequence that is a truncated
sequence 
since the update rule   correctly computes s  i  j   for truncated sequences  we can use
it with short uniform distributions provided we add a check to ensure that the sequences
considered are truncated  unlike the long uniform case  however  the identity of the last rule
in an optimal sequence is unknown  so we need to compute all n  entries in the s  i  j   table 
each entry computation takes o n  time  thus the time to compute an optimal sequence is
o n   

theorem   an optimal sequence of decision procedures for a short uniform deadline distribution can be determined in o n   time where n is the number of decision procedures in
r 
   

fiprovably bounded optimal agents

      exponential distributions

for an exponential distribution  pd t      e fit   exponential distributions allow an optimal
sequence to be computed in polynomial time  let pi stand for the probability that rule i
is interrupted  assuming it starts at    then pi   pd ti         e fiti   for the exponential
distribution  v  s  m  e  simplifies out as 

v  s  m  e   

i
i
h
ij        pj   pi  qi   mj       pj   qm

mx
   h
i  

this yields a simple recursive specification of the value v  as  m  e  of a sequence that
begins with the rule a 

v  as  m  e         pa  p qa        pa v  s  m  e 
we will use the state function s  i  j   which represents the highest value of any rule sequence
starting with i and ending in j  

s  i  j     maxi kj       pi  pk qi        pi s  k  j   
with boundary condition s  i  i    qi     pi   for any given j   s  i  j   can be calculated in
o n    from corollary    we know that there is an optimal sequence whose last element is
the highest valued rule in r 

theorem   an optimal sequence of decision procedures for an exponentially distributed
stochastic deadline can be determined in o n   time where n is the number of decision
procedures in r 

the proof is similar to the long uniform distribution case 

    simulation results for a mail sorter

the preceding results provide a set of algorithms for optimizing the construction of an agent
program for a variety of general task environment classes  in this section  we illustrate these
results and the possible gains that can be realized in a specific task environment  namely 
a simulated mail sorter 
first  let us be more precise about the utility function u on episodes  there are four
possible outcomes  the utility of outcome i is ui 
   the zipcode is successfully read and the letter is sent to the correct bin for delivery 
   the zipcode is misread and the letter goes to the wrong bin 
   the letter is sent to the reject bin 
   the next letter arrives before the recognizer has finished  and there is a jam  since
letter arrival is heralded  jams cannot occur with the machine architecture given in
equation   
   

firussell   subramanian

 

 
mu  

   

   

   

   
p t 

accuracy

lambda    

   

   

   

   

 

 
 

 

 
 
computation time  sec 

 

  

 

 

 
 
time  sec 

 

  

figure     a  accuracy profile      e x    for          b  poisson arrival distribution  for
mean      sec
without loss of generality  we set u        and u         if the probability of a rule
recommending a correct destination bin is pi  then qi   piu         pi u    pi   we assume
that u   u   hence there is a threshold probability below which the letter should be sent
to the reject bin instead  we will therefore include in the rule set r a rule rreject that
has zero runtime and recommends rejection  the sequence construction algorithm will then
automatically exclude rules with quality lower than qreject   u   the overall utility for an
episode is chosen to be a linear combination of the quality of sorting  qi    the probability of
rejection or the rejection rate  given by p  t    where t  is the runtime of the first non reject
rule executed   and the speed of sorting  measured by the arrival time mean  
the agent program in  boser et al        uses a single neural network on a chip 
we show that under a variety of conditions an optimized sequence of networks can do
significantly better than any single network in terms of throughput or accuracy  we examine
the following experimental conditions 
 we assume that a network that executes in time t has a recognition accuracy p that
depends on t  we consider p     e t   the particular choice of  is irrelevant because
the scale chosen for t is arbitrary  we choose         for convenience  figure   a   
we include rreject with qreject   u  and treject     
 we consider arrival time distributions that are poisson with varying means  figure   b  shows three example distributions  for means       and   seconds 
 we create optimized sequences from sets of    networks with execution times taken
at equal intervals from t     to    
 we compare
 a  bo sequence  a bounded optimal sequence 
 b  best singleton  the best single rule 
 c      rule  the rule whose execution time is the mean of the distribution  i e   it
will complete in     of cases  
   

fiprovably bounded optimal agents

 
bo sequence
best singleton
    rule
    rule

average utility per second

   

   

   

   

 
 

  

  

  
  
mean arrival time

  

  

  

figure    graph showing the achievable utility per second as a function of the average time
per letter  for the four program types         
 d      rule  the rule whose execution time guarantees that it will complete in    
of cases 
in the last three cases  we add rreject as an initial step  the bo sequence will include
it automatically 
 we measure the utility per second as a function of the mean arrival rate  figure    
this shows that there is an optimal setting of the sorting machinery at   letters per
minute  inter arrival time      seconds  for the bounded optimal program  given that
we have fixed  at     
 finally  we investigate the effect of the variance of the arrival time on the relative
performance of the four program types  for this purpose  we use a uniform distribution
centered around    seconds but with different widths to vary the variance without
affecting the mean  figure    
we notice several interesting things about these results 
 the policy of choosing a rule with a     probability of completion performs poorly
for rapid arrival rates        but catches up with the performance of the best single
rule for slower arrival rates         this is an artifact of the exponential accuracy
profile for any         where the difference in quality of the rules with run times
greater than   seconds is quite small 
 the policy of choosing a rule with a     probability of completion fares as well as
the best single rule for very high arrival rates        but rapidly diverges from it
thereafter  performing far worse for arrival time means greater than   seconds 
   

firussell   subramanian

 
bo sequence
best singleton
    rule
    rule

average utility per second

   

   

   

   

 
 

  

  

  
  
variance in arrival time

   

   

figure    graphs showing the utility gain per second as a function of the arrival time
variance  for the four program types for the uniform distribution with a mean of
   seconds 

 both the best sequence and the best single rule give their best overall performance
at an arrival rate of around   letters per minute  the performance advantage of the
optimal sequence over the best single rule is about    at this arrival rate  it should
be noted that this is a significant performance advantage that is obtainable with no
extra computational resources  for slower arrival rates        the difference between
the performance of the best rule and the best sequence arises from the decreased
rejection rate of the best sequence  with the exponential accuracy profile        
the advantage of running a rule with a shorter completion time ahead of a longer rule
is the ability to reduce the probability of rejecting a letter  for high arrival rates
 inter arrival times of   to   seconds   it is useful to have a few short rules instead of
a longer single rule 

 figure   shows that the best sequence performs better than the best single rule as the

variance of the arrival time increases   the performance of the optimal sequence also
appears to be largely unaffected by variance  this is exactly the behaviour we expect
to observe   the ability to run a sequence of rules instead of committing to a single
one gives it robustness in the face of increasing variance  since realistic environments
can involve unexpected demands of many kinds  the possession of a variety of default
behaviours of graded sophistication would seem to be an optimal design choice for a
bounded agent 

   the performance of the     rule is at because the uniform distributions used in this experiment have
fixed mean and are symmetric  so that the     rule is always the rule that runs for    seconds  the
    rule changes with the variance  and the curve exhibits some discretization effects  these could be
eliminated using a finer grained set of rules 

   

fiprovably bounded optimal agents

   learning approximately bounded optimal programs

the above derivations assume that a suitable rule set r is available ab initio  with correct
qualities qi and runtimes ti   and that the deadline distribution is known  in this section  we
study ways in which some of this information can be learned  and the implications of this
for the bounded optimality of the resulting system  we will concentrate on learning rules
and their qualities  leaving runtimes and deadline distributions for future work 
the basic idea is that the learning algorithms will converge  over time  to a set of
optimal components   the most accurate rules and the most accurate quality estimates for
them  as this happens  the value of the agent constructed from the rules  using the quality
estimates  converges to the value of lopt  thus there are two sources of suboptimality in the
learned agent 
 the rules in r may not be the best possible rules   they may recommend actions
that are of lower utility than those that would be recommended by some other rules 
 there may be errors in estimating the expected utility of the rule  this can cause the
algorithms given above to construct suboptimal sequences  even if the best rules are
available 
our notional method for constructing bounded optimal agents     learns sets of individual decision procedures from episodic interactions  and     arranges them in a sequence
using one of the algorithms described earlier so that the performance of an agent using
the sequence is at least as good as that of any other such agent  we assume a parameterized learning algorithm lj  k that will be used to learn one rule for each possible runtime
k   f           tm g  since there is never a need to include two rules with the same runtime
in the r  this obviates the need to consider the entire rule language j in the optimization
process 
our setting places somewhat unusual requirements on the learning algorithm  like
most learning algorithms  lj  k works by observing a collection t of training episodes in e 
including the utility obtained for each episode  we do not  however  make any assumptions
about the form of the correct decision rule  instead  we make assumptions about the
hypotheses  namely that they come from some finite language jk   the set of programs
in j of complexity at most k  this setting has been called the agnostic learning setting by
kearns  schapire and sellie         because no assumptions are made about the environment
at all  it has been shown  theorems   and   in kearns  schapire and sellie        that  for
some languages j   the error in the learned approximation can be bounded to within  of
the best rule in jk that fits the examples  with probability       the sample size needed
to guarantee these bounds is polynomial in the complexity parameter k  as well as   and    
in addition to constructing the decision procedures  lj  k outputs estimates of their
quality qi   standard chernoff hoeffding bounds can be used to limit the error in the quality
estimate to be within q with probability     q   the sample size for the estimation of quality
is also polynomial in  q and  q  
thus the error in each agnostically learned rule is bounded to within  of the best rule
in its complexity class with probability       the error in the quality estimation of these
rules is bounded by q with probability     q   from these bounds  we can calculate a bound
on the utility deficit in the agent program that we construct  in comparison to lopt  
   

firussell   subramanian

theorem   assume an architecture mj that executes sequences of decision procedures in
an agnostically learnable language j whose runtimes range over     tm    for real time task

environments with fixed time cost  fixed deadline  and stochastic deadline  we can construct
a program l such that
v  lopt   m  e    v  l  m  e       q
with probability greater than     m    q    where m is the number of decision procedures in
lopt  

proof  we prove this theorem for the stochastic deadline regime  where the bounded

optimal program is a sequence of decision procedures  the proofs for the fixed cost and
fixed deadline regimes  where the bounded optimal program is a singleton  follow as a
special case  let the best decision procedures for e be the set r   fr            rn g  and
let lopt   s         sm  be an optimal sequence constructed from r  let r   fr          rng be
the set of decision procedures returned by the learning algorithm  with probability greater
than     m  qi   qi   for all i  where qi refers to the true quality of ri   the error in the
estimated quality q i of decision procedure ri is also bounded  with probability greater than
    mq   jq i   qi j  q for all i 
let s   s        sm be those rules in r that come from the same runtime classes as the
rules s         sm  in r   then  by equation    we have
v  lopt   m  e    v  s  m  e   
because the error in v is a weighted average of the errors in the individual qi   similarly  we
have
jv   s  m  e    v  s  m  e j  q
now suppose that the sequence construction algorithm applied to r produces a sequence
l   s        sl   by definition  this sequence appears to be optimal according to the estimated
value function v    hence
v   l  m  e   v   s  m  e 
as before  we can bound the error on the estimated value 
jv   l  m  e    v  l  m  e j  q
combining the above inequalities  we have
v  lopt   m  e    v  l  m  e       q
 

 

 

although the theorem has practical applications  it is mainly intended as an illustration
of how a learning procedure can converge on a bounded optimal configuration  with some
additional work  more general error bounds can be derived for the case in which the rule
execution times ti and the real time utility variation  time cost  fixed deadline  or deadline
distribution  are all estimated from the training episodes  we can also obtain error bounds
for the case in which the rule language j is divided up into a smaller number of coarser
runtime classes  rather than the potentially huge number that we currently use 
   

fiprovably bounded optimal agents

   asymptotic bounded optimality

the strict notion of bounded optimality may be a useful philosophical landmark from which
to explore artificial intelligence  but it may be too strong to allow many interesting  general
results to be obtained  the same observation can be made in ordinary complexity theory 
although absolute eciency is the aim  asymptotic eciency is the game  that a sorting
algorithm is o n log n  rather than o n   is considered significant  but replacing a  multiply
by    by a  shift left   bit  is not considered a real advance  the slack allowed by the
definitions of complexity classes is essential in building on earlier results  in obtaining robust
results that are not restricted to specific implementations  and in analysing the complexity of
algorithms that use other algorithms as subroutines  in this section  we begin by reviewing
classical complexity  we then propose definitions of asymptotic bounded optimality that
have some of the same advantages  and show that classical optimality is a special case of
asymptotic bounded optimality  lastly  we report on some preliminary investigations into
the use of asymptotic bounded optimality as a theoretical tool in constructing universal
real time systems 

    classical complexity

a problem  in the classical sense  is defined by a pair of predicates  and such that output
z is a solution for input x if and only if  x  and  x  z   hold  a problem instance is an
input satisfying   and an algorithm for the problem class always terminates with an output
z satisfying  x  z   given an input x satisfying  x   asymptotic complexity describes the
growth rate of the worst case runtime of an algorithm as a function of the input size  we
can define this formally as follows  let ta  x  be the runtime of algorithm a on input x 
and let ta  n  be the maximum runtime of a on any input of size n  then algorithm a has
complexity o f  n   if
 k  n   n n   n    ta  n   kf  n 
intuitively  a classically optimal algorithm is one that has the lowest possible complexity 
for the purposes of constructing an asymptotic notion of bounded optimality  it will be
useful to have a definition of classical optimality that does not mention the complexity
directly  this can be done as follows 
definition    classically optimal algorithm  an algorithm a is classically optimal if and
only if
 k  n   a   n n   n    ta  n   kta  n 
to relate classical complexity to our framework  we will need to define the special case of task
environments in which traditional programs are appropriate  in such task environments 
an input is provided to the program as the initial percept  and the utility function on
environment histories obeys the following constraint 
definition    classical task environment  hep   u i is a classical task environment for
problem p if
 
l outputs a correct solution for p
v  l  m  ep     u   t  l  m  ep    ifotherwise
 

   

firussell   subramanian

where t  l  m  ep   is the running time for l in ep on m   m is a universal turing machine 
and u is some positive decreasing function 
the notion of a problem class in classical complexity theory thus corresponds to a class of
classical task environments of unbounded complexity  for example  the traveling salesperson problem contains instances with arbitrarily large numbers of cities 

    varieties of asymptotic bounded optimality

the first thing we will need is a complexity measure on environments  let n e   be a suitable
measure of the complexity of an environment  we will assume the existence of environment
classes that are of unbounded complexity  then  by analogy with the definition of classical
optimality  we can define a worst case notion of asymptotic bounded optimality  abo  
letting v  l  m  n  e  be the minimum value of v  l  m  e   for all e in e of complexity n 
we have
definition    worst case asymptotic bounded optimality  an agent program l is timewise
 or spacewise  worst case asymptotically bounded optimal in e on m iff
 k  n   l   n n   n    v  l  km  n  e   v  l   m  n  e 
where km denotes a version of the machine m speeded up by a factor k  or with k times
more memory  
in english  this means that the program is basically along the right lines if it just needs a
faster  larger  machine to have worst case behaviour as good as that of any other program
in all environments 
if a probability distribution is associated with the environment class e  then we can use
the expected value v  l  m  e  to define an average case notion of abo 
definition    average case asymptotic bounded optimality  an agent program l is timewise
 or spacewise  average case asymptotically bounded optimal in e on m iff
 k  l  v  l  km  e   v  l    m  e 
for both the worst case and average case definitions of abo  we would be happy with a
program that was abo for a nontrivial environment on a nontrivial architecture m   unless
k were enormous   in the rest of the paper  we will use the worst case definition of abo 
almost identical results can be obtained using the average case definition 
the first observation that can be made about abo programs is that classically optimal
programs are a special case of abo programs  
   the classical definitions allow for optimality up to a constant factor k in the runtime of the algorithms 
one might wonder why we chose to use the constant factor to expand the machine capabilities  rather
than to increase the time available to the program  in the context of ordinary complexity theory  the
two alternatives are exactly equivalent  but in the context of general time dependent utilities  only the
former is appropriate  it would not be possible to simply  let l run k times longer   because the programs
we wish to consider control their own execution time  trading it off against solution quality  one could
imagine slowing down the entire environment by a factor of k  but this is merely a less realistic version
of what we propose 
   this connection was suggested by bart selman 

   

fiprovably bounded optimal agents

theorem   a program is classically optimal for a given problem p if and only if it is
timewise worst case abo for the corresponding classical task environment class hep   u i 
this observation follows directly from definitions         and    
in summary  the notion of abo will provide the same degree of theoretical robustness
and machine independence for the study of bounded systems as asymptotic complexity does
for classical programs  having set up a basic framework  we can now begin to exercise the
definitions 

    universal asymptotic bounded optimality

asymptotic bounded optimality is defined with respect to a specific value function v   in
constructing real time systems  we would prefer a certain degree of independence from the
temporal variation in the value function  we can achieve this by defining a family v of value
functions  differing only in their temporal variation  by this we mean that the value function
preserves the preference ordering of external actions over time  with all value functions in
the family having the same preference ordering  
for example  in the fixed cost regime we can vary the time cost c to generate a family of
value functions  in the stochastic deadline case  we can vary the deadline distribution pd to
generate another family  also  since each of the three regimes uses the same quality measure
for actions  then the union of the three corresponding families is also a family  what we will
show is that a single program  which we call a universal program  can be asymptotically
bounded optimal regardless of which value function is chosen within any particular family 
definition    universal asymptotic bounded optimality  uabo   an agent program l is
uabo in environment class e on m for the family of value functions v iff l is abo in e
on m for every vi   v  
a uabo program must compete with the abo programs for every individual value function
in the family  a uabo program is therefore a universal real time solution for a given task 
do uabo programs exist  if so  how can we construct them 
it turns out that we can use the scheduling construction from  russell   zilberstein 
      to design uabo programs  this construction was designed to reduce task environments with unknown interrupt times to the case of known deadlines  and the same insight
applies here  the construction requires the architecture m to provide program concatenation  e g   the lisp prog construct   a conditional return construct  and the null program
  the universal program lu has the form of a concatenation of individual programs of
increasing runtime  with an appropriate termination test after each  it can be written as
lu    l   l     lj    
where each lj consists of a program and a termination test  the program part in lj is any
program in lm that is abo in e for a value function vj that corresponds to a fixed deadline
at td    j   where  is a time increment smaller than the execution time of any non null
program in lm  
   the value function must therefore be separable  russell   wefald         since this preservation of rank
order allows a separate time cost to be defined  see chapter   of  keeney   raiffa        for a thorough
discussion of time dependent utility 

   

firussell   subramanian

q

l u on  m

   

l opt on m

   
   

p t 
t

 

  

figure    performance profiles for lu running on  m   and for lopt running on m
before proceeding to a statement that lu is indeed uabo  let us look at an example 
consider the simple  sequential machine architecture described earlier  suppose we can
select rules from a three rule set with r              r             and r              since
the shortest runtime of these rules is   seconds  we let       then we look at the optimal
programs l    l   l   l          for the fixed deadline task environments with td                     
these are 

l      l    r   l    r   l    r         
hence the sequence of programs in lu is    r   r    r          
now consider a task environment class with a value function vi that specifies a stochastic
deadline uniformly distributed over the range              for this class  lopt   r  r  is a
bounded optimal sequence   it turns out that lu has higher utility than lopt provided it is
run on a machine that is four times faster  we can see this by plotting the two performance
profiles  qu for lu on  m and qopt for lopt on m   qu dominates qopt  as shown in figure   
to establish that the lu construction yields uabo programs in general  we need to
define a notion of worst case performance profile  let q  t  l  m  n  e  be the minimum
value obtained by interrupting l at t  over all e in e of complexity n  we know that each
lj in lu satisfies the following 

 l   n n   nj   vj lj   kj m  n  e   vj l    m  n  e 
for constants kj   nj   the aim is to prove that

 vi   v  k  n   l   n n   n    vi lu   km  n  e   vi l   m  n  e 
given the definition of worst case performance profile  it is fairly easy to show the following
lemma  the proof is essentially identical to the proof of theorem   in russell and zilberstein 
      
   notice that  in our simple model  the output quality of a rule depends only on its execution time and
not on the input complexity  this also means that worst case and average case behaviour are the same 

   

fiprovably bounded optimal agents

 
bo sequence
abo sequence

average utility per second

   

   

   

   

 
 

  

  

  
  
mean arrival time

  

  

  

i   as a function of mean
figure    throughput and accuracy improvement of lu over lopt
arrival time          poisson arrivals 

lemma   if lu is a universal program in e for v   and li is abo on m in e for vi   v  
then q t  lu   km  n  e  dominates q t  li   m  n  e  for k    maxj kj   n   maxj nj  
this lemma establishes that  for a small constant penalty  we can ignore the specific realtime nature of the task environment in constructing bounded optimal programs  however 
we still need to deal with the issue of termination  it is not possible in general for lu
to terminate at an appropriate time without access to information concerning the timedependence of the utility function  for example  in a fixed time cost task environment  the
appropriate termination time depends on the value of the time cost c 
for the general case with deterministic time dependence  we can help out lu by supplying  for each vi   an  aspiration level  qi  ti  li   m  n  e   where ti is the time at which
li acts  lu terminates when it has completed an lj such that qj  qi  ti   li  m  n  e   by
construction  this will happen no later than ti because of lemma   

theorem   in task environments with deterministic time dependence  an lu with a suitable
aspiration level is uabo in e on m  
with deadline heralds  the termination test is somewhat simpler and does not require any
additional input to lu  
theorem    in a task environment with stochastic deadlines  lu is uabo in e on m if
it terminates when the herald arrives 
returning to the mail sorting example  it is fairly easy to see that lu  which consists of
a sequence of networks  like the optimal programs for the stochastic deadline case  will be
abo in the fixed deadline regime  it is not so obvious that it is also abo in any particular
   

firussell   subramanian

stochastic deadline case   recall that both regimes can be considered as a single family 
we have programmed a constructor function for universal programs  and applied it to the
mail sorter environment class  varying the letter arrival distribution gives us different value
functions vi   v   figure   shows that lu  on  m   has higher throughput and accuracy
i across the entire range of arrival distributions 
than lopt
given the existence of uabo programs  it is possible to consider the behaviour of compositions thereof  the simplest form of composition is functional composition  in which
the output of one program is used as input by another  more complex  nested compositional structures can be entertained  including loops and conditionals  zilberstein        
the main issue in constructing uabo compositions is how to allocate time among the
components  provided that we can solve the time allocation problem when we know the
total runtime allowed  we can use the same construction technique as used above to generate composite uabo programs  where optimality is among all possible compositions of
the components  zilberstein and russell         show that the allocation problem can be
solved in linear time in the size of the composite system  provided the composition is a tree
of bounded degree 

   conclusions and further work
we examined three possible formal bases for artificial intelligence  and concluded that
bounded optimality provides the most appropriate goal in constructing intelligent systems 
we also noted that similar notions have arisen in philosophy and game theory for more or
less the same reason  the mismatch between classically optimal actions and what we have
called feasible behaviours those that can be generated by an agent program running on a
computing device of finite speed and size 
we showed that with careful specification of the task environment and the computing
device one can design provably bounded optimal agents  we exhibited only very simple
agents  and it is likely that bounded optimality in the strict sense is a dicult goal to
achieve when a larger space of agent programs is considered  more relaxed notions such
as asymptotic bounded optimality  abo  may provide more theoretically robust tools for
further progress  in particular  abo promises to yield useful results on composite agent
designs  allowing us to separate the problem of designing complex abo agents into a discrete
structural problem and a continuous temporal optimization problem that is tractable in
many cases  hence  we have reason to be optimistic that artificial intelligence can be
usefully characterized as the study of bounded optimality  we may speculate that provided
the computing device is neither too small  so that small changes in speed or size cause
significant changes in the optimal program design  nor too powerful  so that classically
optimal decisions can be computed feasibly   abo designs should be stable over reasonably
wide variations in machine speed and size and in environmental complexity  the details of
the optimal designs may be rather arcane  and learning processes will play a large part in
their discovery  we expect that the focus of this type of research will be more on questions
of convergence to optimality for various structural classes than on the end result itself 
perhaps the most important implication  beyond the conceptual foundations of the field
itself  is that research on bounded optimality applies  by design  to the practice of artificial
intelligence in a way that idealized  infinite resource models may not  we have given  by
   

fiprovably bounded optimal agents

way of illustrating this definition  a bounded optimal agent  the design of a simple system
consisting of sequences of decision procedures that is provably better than any other program
in its class  a theorem that exhibits a bounded optimal design translates  by definition 
into an agent whose actual behaviour is desirable 
there appear to be plenty of worthwhile directions in which to continue the exploration
of bounded optimality  from a foundational point of view  one of the most interesting
questions is how the concept applies to agents that can incorporate a learning component 
 note that in section    the learning algorithm was external to the agent   in such a
case  there will not necessarily be a largely stable bounded optimal configuration if the
agent program is not large enough  instead  the agent will have to adapt to a shorter term
horizon and rewrite itself as it becomes obsolete 
with results on the preservation of abo under composition  we can start to examine
much more interesting architectures than the simple production system studied above  for
example  we can look at optimal search algorithms  where the algorithm is constrained to
apply a metalevel decision procedure at each step to decide which node to expand  if any
 russell   wefald         we can also extend the work on asymptotic bounded optimality
to provide a utility based analogue to  big o  notation for describing the performance of
agent designs  including those that are suboptimal 
in the context of computational learning theory  it is obvious that the stationarity
requirement on the environment  which is necessary to satisfy the preconditions of pac
results  is too restrictive  the fact that the agent learns may have some effect on the
distribution of future episodes  and little is known about learning in such cases  aldous  
vazirani         we could also relax the deterministic and episodic requirement to allow
non immediate rewards  thereby making connections to current research on reinforcement
learning 
the computation scheduling problem we examined is interesting in itself  and does not
appear to have been studied in the operations research or combinatorial optimization literature  scheduling algorithms usually deal with physical rather than computational tasks 
hence the objective function usually involves summation of outputs rather than picking the
best  we would like to resolve the formal question of its tractability in the general case  and
also to look at cases in which the solution qualities of individual processes are interdependent
 such as when one can use the results of another   practical extensions include computation
scheduling for parallel machines or multiple agents  and scheduling combinations of computational and physical  e g   job shop and ow shop  processes  where objective functions are
a combination of summation and maximization  the latter extension broadens the scope
of applications considerably  an industrial process  such as designing and manufacturing a
car  consists of both computational steps  design  logistics  factory scheduling  inspection
etc   and physical processes  stamping  assembling  painting etc    one can easily imagine
many other applications in real time financial  industrial  and military contexts 
it may turn out that bounded optimality is found wanting as a theoretical framework  if
this is the case  we hope that it is refuted in an interesting way  so that a better framework
can be created in the process 
   

firussell   subramanian

appendix  additional proofs
this appendix contains formal proofs for three subsidiary lemmata in the main body of the
paper 

lemma   there exists an optimal sequence that is sorted in increasing order of q s 
proof  suppose this is not the case  and s is an optimal sequence  then there must be

two adjacent rules i  i     where qi   qi    see figure     removal of rule i     yields a
sequence s  such that qs  t   qs  t   from lemma   and the fact that ti    ti     ti     by
lemma    s  must also be optimal  we can repeat this removal process until s  is ordered
by qi   proving the theorem by reductio ad absurdum  
 

lemma   for every sequence s   s        sm sorted in increasing order of quality  and single
step z with qz  qsm   v  sz    v  s  
proof  we calculate v  sz     v  s  using equation   and show that it is non negative 
v  sz     v  s    qz      pd   pmj   tj     tz      qm     pd   pmj   tj     tz   
p
   qz   qm       pd    mj   tj     tz   

which is non negative since qz  qm   
q

t i  

qi  
qi
qi  
qi  

t

ti

t i  

figure    proof for ordering by qi  lower dotted line indicates original profile  upper dotted
line indicates profile after removal of rule i     

lemma   there exists an optimal sequence whose rules are in nondecreasing order of ti  
proof  suppose this is not the case  and s is an optimal sequence  then there must be
two adjacent rules i  i     where qi  qi   and ti   ti    see figure     removal of rule i
yields a sequence s  such that qs  t   qs  t   from lemma    by lemma    s  must also be
 

optimal  we can repeat this removal process until s  is ordered by ti  proving the theorem
by reductio ad absurdum  
   

fiprovably bounded optimal agents

q

qi  
qi

t i  

qi  

t

t i  

ti

figure    proof for ordering by ti   dotted line indicates profile after removal of rule i 

acknowledgements

we would like to acknowledge stimulating discussions with michael fehling  michael genesereth  russ greiner  eric horvitz  henry kautz  daphne koller  and bart selman on the
subject of bounded optimality  with dorit hochbaum  nimrod megiddo  and kevin glazebrook on the subject of dynamic programming for scheduling problems  and with nick
littlestone and michael kearns on the subject of agnostic learning  we would also like to
thank the reviewers for their many constructive suggestions  many of the early ideas on
which this work is based arose in discussions with the late eric wefald  thanks also to
ron parr for his work on the uniform distribution case  rhonda righter for extending the
results to the exponential distribution  and patrick zieske for help in implementing the dynamic programming algorithm  the first author was supported by nsf grants iri         
iri         and iri          by a visiting fellowship from the serc while on sabbatical
in the uk  and by the nec research institute  the second author was supported by nsf
grant iri         

references

agre  p     chapman  d          pengi  an implementation of a theory of activity  in
proc   th national conference on artificial intelligence  seattle  wa  morghan kaufmann 
aldous  d     vazirani  u          a markovian extension of valiant s learning model  in
proc    st annual symposium on foundations of computer science  st  louis  mo 
ieee comput  soc  press 
binder  j          on the complexity of deliberation scheduling with stochastic deadlines  
boser  b  e   sackinger  e   bromley  j     lecun  y          hardware requirements for
neural network pattern classifiers   a case study and implementation  ieee micro 
          
brandt  r          in search of a credible form of rule utilitarianism  in nakhnikian  g    
castaneda  h   eds    morality and the language of conduct 
   

firussell   subramanian

breese  j  s     fehling  m  r          control of problem solving  principles and architecture  in shachter  r  d   levitt  t   kanal  l     lemmer  j   eds    uncertainty in
artificial intelligence    north holland  amsterdam 
brooks  r  a          a robust  layered control system for a mobile robot  ieee journal
of robotics and automation           
cherniak  c          minimal rationality  mit press  cambridge 
dean  t     boddy  m          an analysis of time dependent planning  in proc  of aaai    pp        
dean  t  l     wellman  m  p          planning and control  morgan kaufmann  san
mateo  ca 
dennett  d          the moral first aid manual  tanner lectures on human values  university
of michigan 
doyle  j          what is rational psychology  toward a modern mental philosophy  ai
magazine           
doyle  j          artificial intelligence and rational self government  tech  rep   technical
report cmu cs        
doyle  j     patil  r          two theses of knowledge representation  language restrictions  taxonomic classification  and the utility of representation services  artificial
intelligence              
etzioni  o          tractable decision analytic control  in proc  of  st international conference on knowledge representation and reasoning  pp          
fehling  m     russell  s  j          proceedings of the aaai spring symposium on limited
rationality  aaai 
genesereth  m  r     nilsson  n  j          logical foundations of artificial intelligence 
morgan kaufmann  mateo  ca 
good  i  j          twenty seven principles of rationality  in in godambe  v  p     sprott 
d  a   eds    foundations of statistical inference  pp           holt  rinehart  winston   toronto 
hansson  o     mayer  a          heuristic search as evidential reasoning  in proceedings
of the fifth workshop on uncertainty in artificial intelligence  windsor  ontario 
horvitz  e  j          reasoning about beliefs and actions under computational resource
constraints  in levitt  t   lemmer  j     kanal  l   eds    uncertainty in artificial
intelligence    north holland  amsterdam 
kearns  m   schapire  r     sellie  l          toward ecient agnostic learning  in proc   th
ann  workshop on computational learning theory  pittsburgh  pa  morgan kaufmann 
   

fiprovably bounded optimal agents

keeney  r     raiffa  h          decisions with multiple objectives  preferences and value
tradeoffs  wiley  new york 
levesque  h     brachman  r          expressiveness and tractability in knowledge representation and reasoning  computational intelligence           
luby  m   sinclair  a     zuckerman  d          optimal speedup of las vegas algorithms 
information processing letters             
mccarthy  j          programs with common sense  in proceedings of the symposium on
the mechanization of thought processes  teddington  england  hmso 
newell  a          the knowledge level  ai magazine          
neyman  a          bounded complexity justifies cooperation in the finitely repeated prisoners  dilemma  economics letters              
papadimitriou  c     yannakakis  m          on complexity as bounded rationality  in
proc  acm symposium on the theory of computation 
ramsey  f  p          truth and probability  in braithwaite  r   ed    the foundations of
mathematics and other logical essays  harcourt brace jovanovich  new york 
russell  s  j     wefald  e  h       a   on optimal game tree search using rational metareasoning  in proc  ijcai    
russell  s  j     wefald  e  h       b   principles of metareasoning  in proc  kr    
russell  s  j     wefald  e  h          do the right thing  studies in limited rationality 
mit press  cambridge  ma 
russell  s  j     zilberstein  s          composing real time systems  in proc  ijcai    
sydney 
sackinger  e   boser  b  e   bromley  j     lecun  y          application of the anna
neural network chip to high speed character recognition  ieee transactions on neural
networks             
simon  h  a          on how to decide what to do  in models of bounded rationality 
volume   
simon  h  a          models of bounded rationality  volume    mit press  cambridge 
von neumann  j     morgenstern  o          theory of games and economic behavior 
princeton university press  princeton 
zilberstein  s          operational rationality through compilation of anytime algorithms 
ph d  thesis  computer science division  university of california  berkeley 
zilberstein  s     russell  s          optimal composition of real time systems  submitted
to artificial intelligence 
   

fi