journal of artificial intelligence research                 

submitted        published     

cost sensitive classification  empirical evaluation
of a hybrid genetic decision tree induction algorithm
peter d  turney
knowledge systems laboratory  institute for information technology
national research council canada  ottawa  ontario  canada  k a  r  

turney ai iit nrc ca

abstract
this paper introduces icet  a new algorithm for cost sensitive classification  icet
uses a genetic algorithm to evolve a population of biases for a decision tree induction algorithm  the fitness function of the genetic algorithm is the average cost of classification
when using the decision tree  including both the costs of tests  features  measurements  and
the costs of classification errors  icet is compared here with three other algorithms for
cost sensitive classification  eg   cs id   and idx  and also with c     which classifies without regard to cost  the five algorithms are evaluated empirically on five realworld medical datasets  three sets of experiments are performed  the first set examines the
baseline performance of the five algorithms on the five datasets and establishes that icet
performs significantly better than its competitors  the second set tests the robustness of
icet under a variety of conditions and shows that icet maintains its advantage  the third
set looks at icets search in bias space and discovers a way to improve the search 

   introduction
the prototypical example of the problem of cost sensitive classification is medical diagnosis  where a doctor would like to balance the costs of various possible medical tests with the
expected benefits of the tests for the patient  there are several aspects to this problem  when
does the benefit of a test  in terms of more accurate diagnosis  justify the cost of the test 
when is it time to stop testing and make a commitment to a particular diagnosis  how much
time should be spent pondering these issues  does an extensive examination of the various
possible sequences of tests yield a significant improvement over a simpler  heuristic choice
of tests  these are some of the questions investigated here 
the words cost  expense  and benefit are used in this paper in the broadest sense 
to include factors such as quality of life  in addition to economic or monetary cost  cost is
domain specific and is quantified in arbitrary units  it is assumed here that the costs of tests
are measured in the same units as the benefits of correct classification  benefit is treated as
negative cost 
this paper introduces a new algorithm for cost sensitive classification  called icet
 inexpensive classification with expensive tests  pronounced iced tea   icet uses a
genetic algorithm  grefenstette        to evolve a population of biases for a decision tree
induction algorithm  a modified version of c     quinlan         the fitness function of the
genetic algorithm is the average cost of classification when using the decision tree  including
both the costs of tests  features  measurements  and the costs of classification errors  icet
has the following features      it is sensitive to test costs      it is sensitive to classification
error costs      it combines a greedy search heuristic with a genetic search algorithm      it
can handle conditional costs  where the cost of one test is conditional on whether a second

      national research council canada  all rights reserved  published by permission 

fit urney

test has been selected yet      it distinguishes tests with immediate results from tests with
delayed results 
the problem of cost sensitive classification arises frequently  it is a problem in medical
diagnosis  nez               robotics  tan   schlimmer              tan         industrial production processes  verdenius         communication network troubleshooting
 lirov   yue         machinery diagnosis  where the main cost is skilled labor   automated
testing of electronic equipment  where the main cost is time   and many other areas 
there are several machine learning algorithms that consider the costs of tests  such as
eg   nez               cs id   tan   schlimmer              tan         and idx
 norton         there are also several algorithms that consider the costs of classification
errors  breiman et al         friedman   stuetzle        hermans et al         gordon  
perlis        pazzani et al         provost        provost   buchanan  in press  knoll et al  
       however  there is very little work that considers both costs together 
there are good reasons for considering both the costs of tests and the costs of classification errors  an agent cannot rationally determine whether a test should be performed without
knowing the costs of correct and incorrect classification  an agent must balance the cost of
each test with the contribution of the test to accurate classification  the agent must also consider when further testing is not economically justified  it often happens that the benefits of
further testing are not worth the costs of the tests  this means that a cost must be assigned to
both the tests and the classification errors 
another limitation of many existing cost sensitive classification algorithms  eg   csid   is that they use greedy heuristics  which select at each step whatever test contributes
most to accuracy and least to cost  a more sophisticated approach would evaluate the interactions among tests in a sequence of tests  a test that appears useful considered in isolation 
using a greedy heuristic  may not appear as useful when considered in combination with
other tests  past work has demonstrated that more sophisticated algorithms can have superior
performance  tcheng et al         ragavan   rendell        norton        schaffer       
rymon        seshu        provost        provost   buchanan  in press  
section   discusses why a decision tree is the natural form of knowledge representation
for classification with expensive tests and how we measure the average cost of classification
of a decision tree  section   introduces the five algorithms that we examine here  c   
 quinlan         eg   nez         cs id   tan   schlimmer              tan        
idx  norton         and icet  the five algorithms are evaluated empirically on five realworld medical datasets  the datasets are discussed in detail in appendix a  section   presents three sets of experiments  the first set  section      of experiments examines the baseline performance of the five algorithms on the five datasets and establishes that icet
performs significantly better than its competitors for the given datasets  the second set  section      tests the robustness of icet under a variety of conditions and shows that icet
maintains its advantage  the third set  section      looks at icets search in bias space and
discovers a way to improve the search  we then discuss related work and future work in section    we end with a summary of what we have learned with this research and a statement of
the general motivation for this type of research 

   cost sensitive classification
this section first explains why a decision tree is the natural form of knowledge representation for classification with expensive tests  it then discusses how we measure the average
cost of classification of a decision tree  our method for measuring average cost handles
   

fic ost  s ensitive c lassification   e mpirical e valuation

aspects of the problem that are typically ignored  the method can be applied to any standard
classification decision tree  regardless of how the tree is generated  we end with a discussion
of the relation between cost and accuracy 
   

decision trees and cost sensitive classification

the decision trees used in decision theory  pearl        are somewhat different from the
classification decision trees that are typically used in machine learning  quinlan        
when we refer to decision trees in this paper  we mean the standard classification decision
trees of machine learning  the claims we make here about classification decision trees also
apply to decision theoretical decision trees  with some modification  a full discussion of
decision theoretical decision trees is outside of the scope of this paper 
the decision to do a test must be based on both the cost of tests and the cost of classification errors  if a test costs     and the maximum penalty for a classification error is     then
there is clearly no point in doing the test  on the other hand  if the penalty for a classification
error is          the test may be quite worthwhile  even if its information content is relatively low  past work with algorithms that are sensitive to test costs  nez             
tan        norton        has overlooked the importance of also considering the cost of classification errors 
when tests are inexpensive  relative to the cost of classification errors  it may be rational
to do all tests  i e   measure all features  determine the values of all attributes  that seem possibly relevant  in this kind of situation  it is convenient to separate the selection of tests from
the process of making a classification  first we can decide on the set of tests that are relevant  then we can focus on the problem of learning to classify a case  using the results of
these tests  this is a common approach to classification in the machine learning literature 
often a paper focuses on the problem of learning to classify a case  without any mention of
the decisions involved in selecting the set of relevant tests  
when tests are expensive  relative to the cost of classification errors  it may be suboptimal to separate the selection of tests from the process of making a classification  we may be
able to achieve much lower costs by interleaving the two  first we choose a test  then we
examine the test result  the result of the test gives us information  which we can use to influence our choice for the next test  at some point  we decide that the cost of further tests is not
justified  so we stop testing and make a classification 
when the selection of tests is interleaved with classification in this way  a decision tree is
the natural form of representation  the root of the decision tree represents the first test that
we choose  the next level of the decision tree represents the next test that we choose  the
decision tree explicitly shows how the outcome of the first test determines the choice of the
second test  a leaf represents the point at which we decide to stop testing and make a classification 
decision theory can be used to define what constitutes an optimal decision tree  given    
the costs of the tests      the costs of classification errors      the conditional probabilities of
test results  given sequences of prior test results  and     the conditional probabilities of
classes  given sequences of test results  however  searching for an optimal tree is infeasible
 pearl         icet was designed to find a good  but not necessarily optimal  tree  where
good is defined as better than the competition  i e   idx  cs id   and eg   
   not all papers are like this  decision tree induction algorithms such as c     quinlan        automatically
select relevant tests  aha and bankert         among others  have used sequential test selection procedures in
conjunction with a supervised learning algorithm 

   

fit urney

   

calculating the average cost of classification

in this section  we describe how we calculate the average cost of classification for a decision
tree  given a set of testing data  the method described here is applied uniformly to the decision trees generated by the five algorithms examined here  eg   cs id   idx  c     and
icet   the method assumes only a standard classification decision tree  such as generated
by c      it makes no assumptions about how the tree is generated  the purpose of the
method is to give a plausible estimate of the average cost that can be expected in a real world
application of the decision tree 
we assume that the dataset has been split into a training set and a testing set  the
expected cost of classification is estimated by the average cost of classification for the testing set  the average cost of classification is calculated by dividing the total cost for the
whole testing set by the number of cases in the testing set  the total cost includes both the
costs of tests and the costs of classification errors  in the simplest case  we assume that we
can specify test costs simply by listing each test  paired with its corresponding cost  more
complex cases will be considered later in this section  we assume that we can specify the
costs of classification errors using a classification cost matrix 
suppose there are c distinct classes  a classification cost matrix is a c  c matrix  where
the element c i  j is the cost of guessing that a case belongs in class i  when it actually
belongs in class j  we do not need to assume any constraints on this matrix  except that costs
are finite  real values  we allow negative costs  which can be interpreted as benefits  however  in the experiments reported here  we have restricted our attention to classification cost
matrices in which the diagonal elements are zero  we assume that correct classification has
no cost  and the off diagonal elements are positive numbers   
to calculate the cost of a particular case  we follow its path down the decision tree  we
add up the cost of each test that is chosen  i e   each test that occurs in the path from the root
to the leaf   if the same test appears twice  we only charge for the first occurrence of the test 
for example  one node in a path may say patient age is less than    years and another node
may say patient age is more than   years  but we only charge once for the cost of determining the patients age  the leaf of the tree specifies the trees guess for the class of the case 
given the actual class of the case  we use the cost matrix to determine the cost of the trees
guess  this cost is added to the costs of the tests  to determine the total cost of classification
for the case 
this is the core of our method for calculating the average cost of classification of a decision tree  there are two additional elements to the method  for handling conditional test
costs and delayed test results 
we allow the cost of a test to be conditional on the choice of prior tests  specifically  we
consider the case where a group of tests shares a common cost  for example  a set of blood
tests shares the common cost of collecting blood from the patient  this common cost is
charged only once  when the decision is made to do the first blood test  there is no charge
for collecting blood for the second blood test  since we may use the blood that was collected
for the first blood test  thus the cost of a test in this group is conditional on whether another
member of the group has already been chosen 
common costs appear frequently in testing  for example  in diagnosis of an aircraft
engine  a group of tests may share the common cost of removing the engine from the plane
   this restriction seems reasonable as a starting point for exploring cost sensitive classification  in future work 
we will investigate the effects of weakening the restriction 

   

fic ost  s ensitive c lassification   e mpirical e valuation

and installing it in a test cell  in semiconductor manufacturing  a group of tests may share the
common cost of reserving a region on the silicon wafer for a special test structure  in image
recognition  a group of image processing algorithms may share a common preprocessing
algorithm  these examples show that a realistic assessment of the cost of using a decision
tree will frequently need to make allowances for conditional test costs 
it often happens that the result of a test is not available immediately  for example  a
medical doctor typically sends a blood test to a laboratory and gets the result the next day 
we allow a test to be labelled either immediate or delayed  if a test is delayed  we cannot
use its outcome to influence the choice of the next test  for example  if blood tests are
delayed  then we cannot allow the outcome of one blood test to play a role in the decision to
do a second blood test  we must make a commitment to doing  or not doing  the second
blood test before we know the results of the first blood test 
delayed tests are relatively common  for example  many medical tests must be shipped
to a laboratory for analysis  in gas turbine engine diagnosis  the main fuel control is frequently shipped to a specialized company for diagnosis or repair  in any classification problem that requires multiple experts  one of the experts might not be immediately available 
we handle immediate tests in a decision tree as described above  we handle delayed tests
as follows  we follow the path of a case from the root of the decision tree to the appropriate
leaf  if we encounter a node  anywhere along this path  that is a delayed test  we are then
committed to performing all of the tests in the subtree that is rooted at this node  since we
cannot make the decision to do tests below this node conditional on the outcome of the test at
this node  we must pledge to pay for all the tests that we might possibly need to perform 
from this point onwards in the decision tree 
our method for handling delayed tests may seem a bit puzzling at first  the difficulty is
that a decision tree combines a method for selecting tests with a method for classifying
cases  when tests are delayed  we are forced to proceed in two phases  in the first phase  we
select tests  in the second phase  we collect test results and classify the case  for example  a
doctor collects blood from a patient and sends the blood to a laboratory  the doctor must tell
the laboratory what tests are to be done on the blood  the next day  the doctor gets the results
of the tests from the laboratory and then decides on the diagnosis of the patient  a decision
tree does not naturally handle a situation like this  where the selection of tests is isolated
from the classification of cases  in our method  in the first phase  the doctor uses the decision
tree to select the tests  as long as the tests are immediate  there is no problem  as soon as the
first delayed test is encountered  the doctor must select all the tests that might possibly be
needed in the second phase   that is  the doctor must select all the tests in the subtree rooted
at the first delayed test  in the second phase  when the test results arrive the next day  the
doctor will have all the information required to go from the root of the tree to a leaf  to make
a classification  the doctor must pay for all of the tests in the subtree  even though only the
tests along one branch of the subtree will actually be used  the doctor does not know in
advance which branch will actually be used  at the time when it is necessary to order the
blood tests  the laboratory that does the blood tests will naturally want the doctor to pay for
all the tests that were ordered  even if they are not all used in making the diagnosis 
in general  it makes sense to do all of the desired immediate tests before we do any of the
desired delayed tests  since the outcome of an immediate test can be used to influence the
decision to do a delayed test  but not vice versa  for example  a medical doctor will question
   this is a simplification of the situation in the real world  a more realistic treatment of delayed tests is one of
the areas for future work  section      

   

fit urney

a patient  questions are immediate tests  before deciding what blood tests to order  blood
tests are delayed tests   
when all of the tests are delayed  as they are in the bupa data in appendix a     we
must decide in advance  before we see any test results  what tests are to be performed  for a
given decision tree  the total cost of tests will be the same for all cases  in situations of this
type  the problem of minimizing cost simplifies to the problem of choosing the best subset of
the set of available tests  aha and bankert         the sequential order of the tests is no
longer important for reducing cost 
let us consider a simple example to illustrate the method  table   shows the test costs
for four tests  two of the tests are immediate and two are delayed  the two delayed tests
share a common cost of        there are two classes    and    table   shows the classification cost matrix  figure   shows a decision tree  table   traces the path through the tree for a
particular case and shows how the cost is calculated  the first step is to do the test at the root
of the tree  test alpha   in the second step  we encounter a delayed test  delta   so we must
calculate the cost of the entire subtree rooted at this node  note that epsilon only costs       
since we have already selected delta  and delta and epsilon have a common cost  in the third
step  we do test epsilon  but we do not need to pay  since we already paid in the second step 
in the fourth step  we guess the class of the case  unfortunately  we guess incorrectly  so we
pay a penalty of        
table    test costs for a simple example 
test

group

cost

delayed

 

alpha

     

no

 

beta

      

no

 

delta

a

      if first test in group a 
      otherwise

yes

 

epsilon

a

       if first test in group a 
      otherwise

yes

table    classification costs for a simple example 
actual class

guess class

cost

 

 

     

 

 

      

 

 

      

 

 

     

   in the real world  there are many factors that can influence the sequence of tests  such as the length of the delay
and the probability that the delayed test will be needed  when we ignore these many factors and pay attention
only to the simplified model presented here  it makes sense to do all of the desired immediate tests before we
do any of the desired delayed tests  we do not know to what extent this actually occurs in the real world  one
complication is that medical doctors in most industrialized countries are not directly affected by the cost of the
tests they select  in fact  fear of law suits gives them incentive to order unnecessary tests 

   

fic ost  s ensitive c lassification   e mpirical e valuation

alpha    
t

f

beta    
t

delta    
f

 

t

f

 
beta    
t

epsilon    
f

 

t

 

 

f

 

figure    decision tree for a simple example 

table    calculating the cost for a particular case 
step

action

result

cost

 

do alpha

alpha    

     

 

do delta

delta    

                               

 

do epsilon

epsilon    

already paid  in step   

 

guess class    

actual class    

      

total cost

      

in summary  this section presents a method for estimating the average cost of using a
given decision tree  the decision tree can be any standard classification decision tree  no
special assumptions are made about the tree  it does not matter how the tree was generated 
the method requires     a decision tree  figure         information on the calculation of test
costs  table         a classification cost matrix  table     and     a set of testing data  table
    the method is  i  sensitive to the cost of tests   ii  sensitive to the cost of classification
errors   iii  capable of handling conditional test costs  and  iv  capable of handling delayed
tests  in the experiments reported in section    this method is applied uniformly to all five
algorithms 
   

cost and accuracy

our method for calculating cost does not explicitly deal with accuracy  however  we can
handle accuracy as a special case  if the test cost is set to       for all tests and the classification cost matrix is set to a positive constant value k when the guess class i does not equal
the actual class j  but it is set to       when i equals j  then the average total cost of using the
decision tree is pk   where p        is the frequency of errors on the testing dataset and
   

fit urney

         p   is the percentage accuracy on the testing dataset  thus there is a linear relationship between average total cost and percentage accuracy  in this situation 
more generally  let c be a classification cost matrix that has cost x on the diagonal 
c i  i   x   and cost y off the diagonal    i  j      c i  j   y     where x is less than y  x   y   we
will call this type of classification cost matrix a simple classification cost matrix  a cost
matrix that is not simple will be called a complex classification cost matrix   when we have
a simple cost matrix and test costs are zero  equivalently  test costs are ignored   minimizing
cost is exactly equivalent to maximizing accuracy 
it follows from this that an algorithm that is sensitive to misclassification error costs but
ignores test costs  breiman et al         friedman   stuetzle        hermans et al        
gordon   perlis        pazzani et al         provost        provost   buchanan  in press 
knoll et al         will only be interesting when we have a complex cost matrix  if we have
a simple cost matrix  an algorithm such as cart  breiman et al         that is sensitive to
misclassification error cost has no advantage over an algorithm such as c     quinlan       
that maximizes accuracy  assuming other differences between these two algorithms are negligible   most of the experiments in this paper use a simple cost matrix  the only exception is
section         therefore we focus on comparison of icet with algorithms that are sensitive
to test cost  idx  cs id   and eg    in future work  we will examine complex cost matrices
and compare icet with algorithms that are sensitive to misclassification error cost 
it is difficult to find information on the costs of misclassification errors in medical practice  but it seems likely that a complex cost matrix is more appropriate than a simple cost
matrix for most medical applications  this paper focuses on simple cost matrices because  as
a research strategy  it seems wise to start with the simple cases before we attempt the complex cases 
provost  provost        provost   buchanan  in press  combines accuracy and classification error cost using the following formula 
score   a  accuracy  b  cost

   

in this formula  a and b are arbitrary weights that the user can set for a particular application  both accuracy and cost  as defined by provost  provost        provost   buchanan  in press   can be represented using classification cost matrices  we can represent
accuracy using any simple cost matrix  in interesting applications  cost will be represented by a complex cost matrix  thus score is a weighted sum of two classification cost
matrices  which means that score is itself a classification cost matrix  this shows that
equation     can be handled as a special case of the method presented here  there is no loss
of information in this translation of provosts formula into a cost matrix  this does not mean
that all criteria can be represented as costs  an example of a criterion that cannot be represented as a cost is stability  turney  in press  

   algorithms
this section discusses the algorithms used in this paper  c     quinlan         eg   nez 
       cs id   tan   schlimmer              tan         idx  norton         and icet 

   we will occasionally say simple cost matrix or complex cost matrix  this should not cause confusion 
since test costs are not represented with a matrix 

   

fic ost  s ensitive c lassification   e mpirical e valuation

   

c   

c     quinlan        builds a decision tree using the standard tdidt  top down induction
of decision trees  approach  recursively partitioning the data into smaller subsets  based on
the value of an attribute  at each step in the construction of the decision tree  c    selects
the attribute that maximizes the information gain ratio  the induced decision tree is pruned
using pessimistic error estimation  quinlan         there are several parameters that can be
adjusted to alter the behavior of c     in our experiments with c     we used the default settings for all parameters  we used the c    source code that is distributed with  quinlan 
      
   

eg 

eg   nez        is a tdidt algorithm that uses the information cost function  icf 
 nez        for selection of attributes  icf selects attributes based on both their information gain and their cost  we implemented eg  by modifying the c    source code so that
icf was used instead of information gain ratio 
icf for the i th attribute  icf i   is defined as follows  
i i

   
icf i                           
  ci     

where       

   

in this equation  i i is the information gain associated with the i th attribute at a given stage
in the construction of the decision tree and c i is the cost of measuring the i th attribute  c   
selects the attribute that maximizes the information gain ratio  which is a function of the
information gain i i   we modified c    so that it selects the attribute that maximizes icf i  
the parameter  adjusts the strength of the bias towards lower cost attributes  when
       cost is ignored and selection by icf i is equivalent to selection by i i   when
       icf i is strongly biased by cost  ideally   would be selected in a way that is sensitive to classification error cost  this is done in icet  see section       nez        does
not suggest a principled way of setting    in our experiments with eg    was set to    in
other words  we used the following selection measure 
i i

   
                ci    

   

in addition to its sensitivity to the cost of tests  eg  generalizes attributes by using an isa
tree  a generalization hierarchy   we did not implement this aspect of eg   since it was not
relevant for the experiments reported here 
   

cs id 

cs id   tan   schlimmer              tan        is a tdidt algorithm that selects the
attribute that maximizes the following heuristic function 
 

  i i  
              ci

   

   this is the inverse of icf  as defined by nez         nez minimizes his criterion  to facilitate comparison
with the other algorithms  we use equation      this criterion is intended to be maximized 

   

fit urney

we implemented cs id  by modifying c    so that it selects the attribute that maximizes
    
cs id  uses a lazy evaluation strategy  it only constructs the part of the decision tree
that classifies the current case  we did not implement this aspect of cs id   since it was not
relevant for the experiments reported here 
   

idx

idx  norton        is a tdidt algorithm that selects the attribute that maximizes the following heuristic function 
i i
      ci

   

we implemented idx by modifying c    so that it selects the attribute that maximizes     
c    uses a greedy search strategy that chooses at each step the attribute with the highest
information gain ratio  idx uses a lookahead strategy that looks n tests ahead  where n is a
parameter that may be set by the user  we did not implement this aspect of idx  the lookahead strategy would perhaps make idx more competitive with icet  but it would also complicate comparison of the heuristic function     with the heuristics     and     used by eg 
and cs id  
   

icet

icet is a hybrid of a genetic algorithm and a decision tree induction algorithm  the genetic
algorithm evolves a population of biases for the decision tree induction algorithm  the
genetic algorithm we use is genesis  grefenstette          the decision tree induction
algorithm is c     quinlan         modified to use icf  that is  the decision tree induction
algorithm is eg   implemented as described in section     
icet uses a two tiered search strategy  on the bottom tier  eg  performs a greedy
search through the space of decision trees  using the standard tdidt strategy  on the top
tier  genesis performs a genetic search through a space of biases  the biases are used to
modify the behavior of eg   in other words  genesis controls eg s preference for one
type of decision tree over another 
icet does not use eg  the way it was designed to be used  the n costs  c i   used in
eg s attribute selection function  are treated by icet as bias parameters  not as costs  that
is  icet manipulates the bias of eg  by adjusting the parameters  c i   in icet  the values of
the bias parameters  c i   have no direct connection to the actual costs of the tests 
genetic algorithms are inspired by biological evolution  the individuals that are evolved
by genesis are strings of bits  genesis begins with a population of randomly generated
individuals  bit strings  and then it measures the fitness of each individual  in icet  an
individual  a bit string  represents a bias for eg   an individual is evaluated by running eg 
on the data  using the bias of the given individual  the fitness of the individual is the average cost of classification of the decision tree that is generated by eg   in the next generation  the population is replaced with new individuals  the new individuals are generated
from the previous generation  using mutation and crossover  sex   the fittest individuals in
the first generation have the most offspring in the second generation  after a fixed number of
   we used genesis version      which is available at url ftp   ftp aic nrl navy mil pub galist src ga genesis tar z or ftp   alife santafe edu pub user area ec ga src gensis     tar gz 

   

fic ost  s ensitive c lassification   e mpirical e valuation

generations  icet halts and its output is the decision tree determined by the fittest individual  figure   gives a sketch of the icet algorithm 

genesis
fittest

genetic algorithm

decision tree
population of
biases
eg 

data

fitness

decision tree

classifier

function
eg 
decision tree

classifier
eg 

decision tree

classifier

figure    a sketch of the icet algorithm 
genesis has several parameters that can be used to alter its performance  the parameters we used are listed in table    these are essentially the default parameter settings
 grefenstette         we used a population size of    individuals and       trials  which
results in    generations  an individual in the population consists of a string of n     numbers  where n is the number of attributes  tests  in the given dataset  the n     numbers are
represented in binary format  using a gray code   this binary string is used as a bias for
eg   the first n numbers in the string are treated as if they were the n costs  c i   used in icf
 equation       the first n numbers range from   to        and are coded with    binary digits each  the last two numbers in the string are used to set  and cf  the parameter  is
used in icf  the parameter cf is used in c    to control the level of pruning of the decision
tree  the last two numbers are coded with   binary digits each   ranges from    cost is
ignored  to    maximum sensitivity to cost  and cf ranges from    high pruning  to      low
pruning   thus an individual is a string of   n      bits 
each trial of an individual consists of running eg   implemented as a modification to
c     on a given training dataset  using the numbers specified in the binary string to set c i
  i        n       and cf  the training dataset is randomly split into two equal sized subsets
     for odd sized training sets   a sub training set and a sub testing set  a different random
split is used for each trial  so the outcome of a trial is stochastic  we cannot assume that
identical individuals yield identical outcomes  so every individual must be evaluated  this
means that there will be duplicate individuals in the population  with slightly different fitness
scores  the measure of fitness of an individual is the average cost of classification on the
sub testing set  using the decision tree that was generated on the sub training set  the aver   a gray code is a binary code that is designed to avoid hamming cliffs  in the standard binary code    is represented as      and   is represented as       these numbers are adjacent  yet the hamming distance from
     to      is large  in a gray code  adjacent numbers are represented with binary codes that have small
hamming distances  this tends to improve the performance of a genetic algorithm  grefenstette        

   

fit urney

table    parameter settings for genesis 
parameter

setting

experiments

 

total trials

    

population size

  

structure length

  n     

crossover rate

   

mutation rate

     

generation gap

   

scaling window

 

report interval

   

structures saved

 

max gens w o eval

 

dump interval

 

dumps saved

 

options

acefgl

random seed

         

rank min

    

age cost is measured as described in section      after       trials  the most fit  lowest cost 
individual is then used as a bias for eg  with the whole training set as input  the resulting
decision tree is the output of icet for the given training dataset  
the n costs  bias parameters   c i   used in icf  are not directly related to the true costs of
the attributes  the    individuals in the first generation are generated randomly  so the initial
values of c i have no relation to the true costs  after    generations  the values of c i may
have some relation to the true costs  but it will not be a simple relationship  these values of
c i are more appropriately thought of as biases than costs  thus genesis is searching
through a bias space for biases for c    that result in decision trees with low average cost 
the biases c i range from   to         when a bias c i is greater than        the i th
attribute is ignored  that is  the i th attribute is not available for c    to include in the decision tree  even if it might maximize icf i   this threshold of       was arbitrarily chosen 
there was no attempt to optimize this value by experimentation 
we chose to use eg  in icet  rather than idx or cs id   because eg  has the parameter    which gives genesis greater control over the bias of eg   icf i is partly based on
the data  via the information gain  i i   and it is partly based on the bias  via the pseudo   the       partition of sub training and sub testing sets could mean that icet may not work well on small
datasets  the smallest dataset of the five we examine here is the hepatitis dataset  which has     cases  the
training sets had     cases and the testing sets had    cases  the sub training and sub testing sets had    or   
cases  we can see from figure   that icet performed slightly better than the other algorithms on this dataset
 the difference is not significant  

   

fic ost  s ensitive c lassification   e mpirical e valuation

cost  c i    the exact mix of data and bias can be controlled by varying    otherwise  there
is no reason to prefer eg  to idx or cs id   which could easily be used instead of eg  
the treatment of delayed tests and conditional test costs is not hard wired into eg   it
is built into the fitness function used by genesis  the average cost of classification  measured as described in section     this makes it relatively simple to extend icet to handle
other pragmatic constraints on the decision trees 
in effect  genesis lies to eg  about the costs of the tests  how can lies improve the
performance of eg   eg  is a hill climbing algorithm that can get trapped at a local optimum  it is a greedy algorithm that looks only one test ahead as it builds a decision tree 
because it looks only one step ahead  eg  suffers from the horizon effect  this term is taken
from the literature on chess playing programs  suppose that a chess playing program has a
fixed three move lookahead depth and it finds that it will loose its queen in three moves  if it
follows a certain branch of the game tree  there may be an alternate branch where the program first sacrifices a pawn and then loses its queen in four moves  because the loss of the
queen is over its three move horizon  the program may foolishly decide to sacrifice its pawn 
one move later  it is again faced with the loss of its queen  analogously  eg  may try to
avoid a certain expensive test by selecting a less expensive test  one test later  it is again
faced with the more expensive test  after it has exhausted all the cheaper tests  it may be
forced to do the expensive test  in spite of its efforts to avoid the test  genesis can prevent
this short sighted behavior by telling lies to eg   genesis can exaggerate the cost of the
cheap tests or it can understate the cost of the expensive test  based on past trials  genesis
can find the lies that yield the best performance from eg  
in icet  learning  local search in eg   and evolution  in genesis  interact  a common
form of hybrid genetic algorithm uses local search to improve the individuals in a population
 schaffer et al          the improvements are then coded into the strings that represent the
individuals  this is a form of lamarckian evolution  in icet  the improvements due to eg 
are not coded into the strings  however  the improvements can accelerate evolution by altering the fitness landscape  this phenomenon  and other phenomena that result from this form
of hybrid  is known as the baldwin effect  baldwin        morgan        waddington       
maynard smith        hinton   nowlan        ackley   littman        whitley   gruau 
      whitley et al         anderson  in press   the baldwin effect may explain much of the
success of icet 

   experiments
this section describes experiments that were performed on five datasets  taken from the irvine collection  murphy   aha         the five datasets are described in detail in
appendix a  all five datasets involve medical problems  the test costs are based on information from the ontario ministry of health         the main purpose of the experiments is
to gain insight into the behavior of icet  the other cost sensitive algorithms  eg   cs id  
and idx  are included mainly as benchmarks for evaluating icet  c    is also included as a
benchmark  to illustrate the behavior of an algorithm that makes no use of cost information 
the main conclusion of these experiments is that icet performs significantly better than its
competitors  under a wide range of conditions  with access to the irvine collection and the
information in appendix a  it should be possible for other researchers to duplicate the
results reported here 
medical datasets frequently have missing values    we conjecture that many missing values in medical datasets are missing because the doctor involved in generating the dataset
   

fit urney

decided that a particular test was not economically justified for a particular patient  thus
there may be information content in the fact that a certain value is missing  there may be
many reasons for missing values other than the cost of the tests  for example  perhaps the
doctor forgot to order the test or perhaps the patient failed to show up for the test  however 
it seems likely that there is often information content in the fact that a value is missing  for
our experiments  this information content should be hidden from the learning algorithms 
since using it  at least in the testing sets  would be a form of cheating  two of the five
datasets we selected had some missing data  to avoid accusations of cheating  we decided to
preprocess the datasets so that the data presented to the algorithms had no missing values 
this preprocessing is described in appendices a   and a   
note that icet is capable of handling missing values without preprocessing  it inherits this ability from its c    component  we preprocessed the data only to avoid accusations
of cheating  not because icet requires preprocessed data 
for the experiments  each dataset was randomly split into    pairs of training and testing
sets  each training set consisted of two thirds of the dataset and each testing set consisted of
the remaining one third  the same    pairs were used in all experiments  in order to facilitate
comparison of results across experiments 
there are three groups of experiments  the first group of experiments examines the baseline performance of the algorithms  the second group considers how robust icet is under a
variety of conditions  the final group looks at how icet searches bias space 
   

baseline performance

this section examines the baseline performance of the algorithms  in section        we look
at the average cost of classification of the five algorithms on the five datasets  averaged
across the five datasets  icet has the lowest average cost  in section        we study test
expenditures and error rates as functions of the penalty for misclassification errors  of the
five algorithms studied here  only icet adjusts its test expenditures and error rates as functions of the penalty for misclassification errors  the other four algorithms ignore the penalty
for misclassification errors  icet behaves as one would expect  increasing test expenditures
and decreasing error rates as the penalty for misclassification errors rises  in section       
we examine the execution time of the algorithms  icet requires    minutes on average on a
single processor sparc     since icet is inherently parallel  there is significant room for
speed increase on a parallel machine 
     

average cost of classification

the experiment presented here establishes the baseline performance of the five algorithms 
the hypothesis was that icet will  on average  perform better than the other four algorithms  the classification cost matrix was set to a positive constant value k when the guess
class i does not equal the actual class j  but it was set to       when i equals j  we experimented with seven settings for k                                      and        
initially  we used the average cost of classification as the performance measure  but we
found that there are three problems with using the average cost of classification to compare
the five algorithms  first  the differences in costs among the algorithms become relatively

    a survey of    datasets from the irvine collection  url ftp   ftp ics uci edu pub machine learning databases 
summary table  indicates that     of the medical datasets     out of     have missing values  while only
       out of     of the non medical datasets have missing values 

   

fic ost  s ensitive c lassification   e mpirical e valuation

small as the penalty for classification errors increases  this makes it difficult to see which
algorithm is best  second  it is difficult to combine the results for the five datasets in a fair
manner    it is not fair to average the five datasets together  since their test costs have different scales  see appendix a   the test costs in the heart disease dataset  for example  are
substantially larger than the test costs in the other four datasets  third  it is difficult to combine average costs for different values of k in a fair manner  since more weight will be given
to the situations where k is large than to the situations where it is small 
to address these concerns  we decided to normalize the average cost of classification  we
normalized the average cost by dividing it by the standard cost  let f i        be the frequency of class i in the given dataset  that is  f i is the fraction of the cases in the dataset that
belong in class i  we calculate f i using the entire dataset  not just the training set  let c i  j be
the cost of guessing that a case belongs in class i  when it actually belongs in class j  let t
be the total cost of doing all of the possible tests  the standard cost is defined as follows 
t   min     f i   max c i  j

   

i  j

i

we can decompose formula     into three components 
t

   

min     f i 

   

max c i  j

   

i

i  j

we may think of     as an upper bound on test expenditures      as an upper bound on error
rate  and     as an upper bound on the penalty for errors  the standard cost is always less
than the maximum possible cost  which is given by the following formula 
t   max c i  j
i  j

    

the point is that     is not really an upper bound on error rate  since it is possible to be
wrong with every guess  however  our experiments suggest that the standard cost is better
for normalization  since it is a more realistic  tighter  upper bound on the average cost  in
our experiments  the average cost never went above the standard cost  although it occasionally came very close 
figure   shows the result of using formula     to normalize the average cost of classification  in the plots  the x axis is the value of k and the y axis is the average cost of classification
as a percentage of the standard cost of classification  we see that  on average  the sixth plot
in figure     icet has the lowest classification cost  the one dataset where icet does not
perform particularly well is the heart disease dataset  we discuss this later  in sections      
and        
to come up with a single number that characterizes the performance of each algorithm 
we averaged the numbers in the sixth plot in figure      we calculated     confidence
regions for the averages  using the standard deviations across the    random splits of the
    we want to combine the results in order to summarize the performance of the algorithms on the five datasets 
this is analogous to comparing students by calculating the gpa  grade point average   where students are to
courses as algorithms are to datasets 
    like the gpa  all datasets  courses  have the same weight  however  unlike the gpa  all algorithms  students  are applied to the same datasets  have taken the same courses   thus our approach is perhaps more fair
to the algorithms than gpa is to students 

   

fit urney

bupa liver disease

heart disease
   
average   standard cost

average   standard cost

   
  
  
  
  
 
  

  
  
  
  
 

   

    

     

  

cost of misclassification error

hepatitis prognosis

pima indians diabetes
average   standard cost

average   standard cost

  
  
  
 

  
  
  
  
 

   

    

     

  

cost of misclassification error

   

    

     

cost of misclassification error

thyroid disease

average of five datasets
   
average   standard cost

   
average   standard cost

     

   

  

  
  
  
  
 
  

    

cost of misclassification error

   

  

   

  
  
  
  
 

   

    

     

  

cost of misclassification error

   

    

     

cost of misclassification error

icet 
eg  
cs id  
idx 
c    

figure    average cost of classification as a percentage of the standard cost of
classification for the baseline experiment 
datasets  the result is shown in table   
table   shows the averages for the first three misclassification error costs alone      
     and        in addition to showing the averages for all seven misclassification error costs
     to          we have two averages  the two columns in table     based on two groups of
data  to address the following argument  as the penalty for misclassification errors increases 
the cost of the tests becomes relatively insignificant  with very high misclassification error
cost  the test cost is effectively zero  so the task becomes simply to maximize accuracy  as
   

fic ost  s ensitive c lassification   e mpirical e valuation

table    average percentage of standard cost for the baseline experiment 
algorithm

average classification cost as percentage of standard
     confidence
misclassification error costs
from       to          

misclassification error costs
from       to       

icet

     

     

eg 

     

     

cs id 

     

     

idx

     

     

c   

     

     

we see in figure    the gap between c     which maximizes accuracy  and the other algorithms becomes smaller as the cost of misclassification error increases  therefore the benefit
of sensitivity to test cost decreases as the cost of misclassification error increases  it could be
argued that one would only bother with an algorithm that is sensitive to test cost when tests
are relatively expensive  compared to the cost of misclassification errors  thus the most realistic measure of performance is to examine the average cost of classification when the cost of
tests is the same order of magnitude as the cost of misclassification errors      to       
this is why table   shows both averages 
our conclusion  based on table    is that icet performs significantly better than the
other four algorithms when the cost of tests is the same order of magnitude as the cost of
misclassification errors            and        when the cost of misclassification errors dominates the test costs  icet still performs better than the competition  but the difference is less
significant  the other three cost sensitive algorithms  eg   cs id   and idx  perform significantly better than c     which ignores cost   the performance of eg  and idx is indistinguishable  but cs id  appears to be consistently more costly than eg  and idx 
     

test expenditures and error rates as functions of the penalty for errors

we argued in section   that expenditures on tests should be conditional on the penalty for
misclassification errors  therefore icet is designed to be sensitive to both the cost of tests
and the cost of classification errors  this leads us to the hypothesis that icet tends to spend
more on tests as the penalty for misclassification errors increases  we also expect that the
error rate of icet should decrease as test expenditures increase  these two hypotheses are
confirmed in figure    in the plots  the x axis is the value of k and the y axis is     the average expenditure on tests  expressed as a percentage of the maximum possible expenditure on
tests  t   and     the average percent error rate  on average  the sixth plot in figure     test
expenditures rise and error rate falls as the penalty for classification errors increases  there
are some minor deviations from this trend  since icet can only guess at the value of a test
 in terms of reduced error rate   based on what it sees in the training dataset  the testing
dataset may not always support that guess  note that plots for the other four algorithms  corresponding to the plots for icet in figure    would be straight horizontal lines  since all four
algorithms ignore the cost of misclassification error  they generate the same decision trees
for every possible misclassification error cost 

   

fit urney

  

  

  
  
  
  

  
 

 
    

     

  
  
  
  

  

average   maximum test expenditures

  
  
  
  
 

average   error rate

average   maximum test expenditures

  

 
    

     

  

  

  
  
  
  

 
  

 
   

    

     

cost of misclassification error

average of five datasets

  

average   maximum test expenditures

thyroid disease
  
 

  

 
  
 
  

 

 

average   error rate

average   maximum test expenditures

     

  

cost of misclassification error

 
   

    

pima indians diabetes
  

  

 
   

cost of misclassification error

hepatitis prognosis
  

   

  

 

cost of misclassification error

  

  

  

average   error rate

   

  

    

     

cost of misclassification error

  

  
  

  

  
  
  
  

  

 
  

average   error rate

  

  

average   error rate

average   maximum test expenditures

heart disease
  

average   error rate

average   maximum test expenditures

bupa liver disease
   

 
   

    

     

cost of misclassification error

  test expenditures 
  error rate 

figure    average test expenditures and average error rate
as a function of misclassification error cost 
     

execution time

in essence  icet works by invoking c         times  section       fortunately  quinlans
       implementation of c    is quite fast  table   shows the run times for the algorithms 
using a single processor sun sparc     one full experiment takes about one week  roughly
   minutes for an average run  multiplied by   datasets  multiplied by    random splits  multiplied by   misclassification error costs equals about one week   since genetic algorithms
can easily be executed in parallel  there is substantial room for speed increase with a parallel
machine  each generation consists of    individuals  which could be evaluated in parallel 
reducing the average run time to about half a minute 
   

robustness of icet

this group of experiments considers how robust icet is under a variety of conditions  each
section considers a different variation on the operating environment of icet  the icet
   

fic ost  s ensitive c lassification   e mpirical e valuation

table    elapsed run time for the five algorithms 
algorithm

average elapsed run time for each dataset  minutes seconds
bupa

heart

hepatitis

pima

thyroid

average

icet

     

     

     

     

     

     

eg 

   

   

   

   

   

   

cs id 

   

   

   

   

   

   

idx

   

   

   

   

   

   

c   

   

   

   

   

   

   

algorithm itself is not modified  in section        we alter the environment by labelling all
tests as immediate  in section        we do not recognize shared costs  so there is no discount
for a group of tests with a common cost  in section        we experiment with complex classification cost matrices  where different types of errors have different costs  in section       
we examine what happens when icet is trained with a certain penalty for misclassification
errors  then tested with a different penalty  in all four experiments  we find that icet continues to perform well 
     

all tests immediate

a critic might object that the previous experiments do not show that icet is superior to the
other algorithms due to its sensitivity to both test costs and classification error costs  perhaps
icet is superior simply because it can handle delayed tests  while the other algorithms treat
all tests as immediate    that is  the method of estimating the average classification cost
 section      is biased in favor of icet  since icet uses the method in its fitness function 
and against the other algorithms  in this experiment  we labelled all tests as immediate  otherwise  nothing changed from the baseline experiments  table   summarizes the results of
the experiment  icet still performs well  although its advantage over the other algorithms
has decreased slightly  sensitivity to delayed tests is part of the explanation of icets performance  but it is not the whole story 
     

no group discounts

another hypothesis is that icet is superior simply because it can handle groups of tests that
share a common cost  in this experiment  we eliminated group discounts for tests that share a
common cost  that is  test costs were not conditional on prior tests  otherwise  nothing
changed from the baseline experiments  table   summarizes the results of the experiment 
icet maintains its advantage over the other algorithms 
     

complex classification cost matrices

so far  we have only used simple classification cost matrices  where the penalty for a classification error is the same for all types of error  this assumption is not inherent in icet  each
    while the other algorithms cannot currently handle delayed tests  it should be possible to alter them in some
way  so that they can handle delayed tests  this comment also extends to groups of tests that share a common
cost  icet might be viewed as an alteration of eg  that enables eg  to handle delayed tests and common
costs 

   

fit urney

table    average percentage of standard cost for the no delay experiment 
algorithm

average classification cost as percentage of standard
     confidence
misclassification error costs
from       to          

misclassification error costs
from       to       

icet

     

     

eg 

     

     

cs id 

     

     

idx

     

     

c   

     

     

table    average percentage of standard cost for the no discount experiment 
algorithm

average classification cost as percentage of standard
     confidence
misclassification error costs
from       to          

misclassification error costs
from       to       

icet

     

     

eg 

     

     

cs id 

     

     

idx

     

     

c   

     

     

element in the classification cost matrix can have a different value  in this experiment  we
explore icets behavior when the classification cost matrix is complex 
we use the term positive error to refer to a false positive diagnosis  which occurs when
a patient is diagnosed as being sick  but the patient is actually healthy  conversely  the term
negative error refers to a false negative diagnosis  which occurs when a patient is diagnosed as being healthy  but is actually sick  the term positive error cost is the cost that is
assigned to positive errors  while negative error cost is the cost that is assigned to negative
errors  see appendix a for examples  we were interested in icets behavior as the ratio of
negative to positive error cost was varied  table   shows the ratios that we examined 
figure   shows the performance of the five algorithms at each ratio 
our hypothesis was that the difference in performance between icet and the other algorithms would increase as we move away from the middles of the plots  where the ratio is     
since the other algorithms have no mechanism to deal with complex classification cost  they
were designed under the implicit assumption of simple classification cost matrices  in fact 
figure   shows that the difference tends to decrease as we move away from the middles 
this is most pronounced on the right hand sides of the plots  when the ratio is      the
extreme right hand sides of the plots   there is no advantage to using icet  when the ratio is
       the extreme left hand sides of the plots   there is still some advantage to using icet 
   

fic ost  s ensitive c lassification   e mpirical e valuation

bupa liver disease

heart disease
   
average   standard cost

average   standard cost

   
  
  
  
  
 
   

  
  
  
  
 

   

    

   

ratio of negative to positive error cost

hepatitis prognosis
average   standard cost

average   standard cost

   

  
  
  
  
 

  
  
  
  
 

   

    

   

ratio of negative to positive error cost

thyroid disease

    

average of five datasets
   
average   standard cost

average   standard cost

   
ratio of negative to positive error cost

   
  
  
  
  
 
   

    

pima indians diabetes

   

   

   
ratio of negative to positive error cost

  
  
  
  
 

   

    

   

ratio of negative to positive error cost

   

    

ratio of negative to positive error cost

icet 
eg  
cs id  
idx 
c    

figure    average cost of classification as a percentage of the standard cost of
classification  with complex classification cost matrices 
the interpretation of these plots is complicated by the fact that the gap between the algorithms tends to decrease as the penalty for classification errors increases  as we can see in
figure    in retrospect  we should have held the sum of the negative error cost and the positive error cost at a constant value  as we varied their ratio   however  there is clearly an
asymmetry in the plots  which we expected to be symmetrical about a vertical line centered
on     on the x axis  the plots are close to symmetrical for the other algorithms  but they are
asymmetrical for icet  this is also apparent in table     which focuses on a comparison of
the performance of icet and eg   averaged across all five datasets  see the sixth plot in
figure     this suggests that it is more difficult to reduce negative errors  on the right hand
sides of the plots  negative errors have more weight  than it is to reduce positive errors  on
   

fit urney

table    actual error costs for each ratio of negative to positive error cost 
ratio of negative to
positive error cost

negative
error cost

positive
error cost

     

  

   

    

  

   

   

  

   

   

  

  

   

   

  

   

   

  

   

   

  

table     comparison of icet and eg 
with various ratios of negative to positive error cost 

algorithm

average classification cost as percentage of standard
     confidence  as the ratio of
negative to positive error cost is varied
     

    

   

   

   

   

   

icet

      

     

     

     

     

     

     

eg 

     

     

     

     

     

     

     

icet eg   as   

  

  

  

  

  

  

  

the left hand sides  positive errors have more weight   that is  it is easier to avoid false positive diagnoses  a patient is diagnosed as being sick  but the patient is actually healthy  than
it is to avoid false negative diagnoses  a patient is diagnosed as being healthy  but is actually
sick   this is unfortunate  since false negative diagnoses usually carry a heavier penalty  in
real life  preliminary investigation suggests that false negative diagnoses are harder to avoid
because the sick class is usually less frequent than the healthy class  which makes the
sick class harder to learn 
     

poorly estimated classification cost

we believe that it is an advantage of icet that it is sensitive to both test costs and classification error costs  however  it might be argued that it is difficult to calculate the cost of classification errors in many real world applications  thus it is possible that an algorithm that
ignores the cost of classification errors  e g   eg   cs id   idx  may be more robust and
useful than an algorithm that is sensitive to classification errors  e g   icet   to address this
possibility  we examine what happens when icet is trained with a certain penalty for classification errors  then tested with a different penalty 
our hypothesis was that icet would be robust to reasonable differences between the
penalty during training and the penalty during testing  table    shows what happens when
icet is trained with a penalty of      for classification errors  then tested with penalties of
   

fic ost  s ensitive c lassification   e mpirical e valuation

table     performance when training set classification error cost is      

algorithm

average classification cost as percentage of
standard      confidence  for testing set
classification error cost of 
   

    

    

icet

      

      

     

eg 

     

     

     

cs id 

     

     

     

idx

     

     

     

c   

     

     

     

           and       we see that icet has the best performance of the five algorithms 
although its edge is quite slight in the case where the penalty is      during testing 
we also examined what happens     when icet is trained with a penalty of      and
tested with penalties of             and        and     when icet is trained with a penalty
of        and tested with penalties of               and         the results show essentially
the same pattern as in table     icet is relatively robust to differences between the training
and testing penalties  at least when the penalties have the same order of magnitude  this suggests that icet is applicable even in those situations where the reliability of the estimate of
the cost of classification errors is dubious 
when the penalty for errors on the testing set is       icet works best when the penalty
for errors on the training set is also       when the penalty for errors on the testing set is
      icet works best when the penalty for errors on the training set is also       when the
penalty for errors on the testing set is         icet works best when the penalty for errors
on the training set is       this suggests that there might be an advantage in some situations
to underestimating the penalty for errors during training  in other  words icet may have a
tendency to overestimate the benefits of tests  this is likely due to overfitting the training
data  
   

searching bias space

the final group of experiments analyzes icets method for searching in bias space  section
      studies the roles of the mutation and crossover operators  it appears that crossover is
mildly beneficial  compared to pure mutation  section       considers what happens when
icet is constrained to search in a binary bias space  instead of a real bias space  this constraint actually improves the performance of icet  we hypothesized that the improvement
was due to a hidden advantage of searching in binary bias space  when searching in binary
bias space  icet has direct access to the true costs of the tests  however  this advantage can
be available when searching in real bias space  if the initial population of biases is seeded
with the true costs of the tests  section       shows that this seeding improves the performance of icet 
     

crossover versus mutation

past work has shown that a genetic algorithm with crossover performs better than a genetic
algorithm with mutation alone  grefenstette et al         wilson         this section
   

fit urney

attempts to test the hypothesis that crossover improves the performance of icet  to test this
hypothesis  it is not sufficient to merely set the crossover rate to zero  since crossover has a
randomizing effect  similar to mutation  we must also increase the mutation rate  to compensate for the loss of crossover  wilson        spears        
it is very difficult to analytically calculate the increase in mutation rate that is required to
compensate for the loss of crossover  spears         therefore we experimentally tested
three different mutation settings    the results are summarized in table     when the crossover rate was set to zero  the best mutation rate was       for misclassification error costs
from     to          the performance of icet without crossover was not as good as the performance of icet with crossover  but the difference is not statistically significant  however 
this comparison is not entirely fair to crossover  since we made no attempt to optimize the
crossover rate  we simply used the default value   the results suggest that crossover is
mildly beneficial  but do not prove that pure mutation is inferior 
table     average percentage of standard cost for mutation experiment 
average classification cost as percentage of
standard      confidence

icet
crossover
rate

mutation
rate

misclassification
error costs
from       to          

misclassification
error costs
from       to       

   

     

     

     

   

    

     

     

   

    

     

     

   

    

     

     

     

search in binary space

icet searches for biases in a space of n     real numbers  inspired by aha and bankert
        we decided to see what would happen when icet was restricted to a space of n
binary numbers and   real numbers  we modified icet so that eg  was given the true cost
of each test  instead of a pseudo cost or bias  for conditional test costs  we used the nodiscount cost  see section         the n binary digits were used to exclude or include a test 
eg  was not allowed to use excluded tests in the decision trees that it generated 
to be more precise  let b      b n be n binary numbers and let c      c n be n real numbers  for this experiment  we set c i to the true cost of the i th test  in this experiment  genesis does not change c i   that is  c i is constant for a given test in a given dataset  instead 
genesis manipulates the value of b i for each i  the binary number b i is used to determine
whether eg  is allowed to use a test in its decision tree  if b i       then eg  is not allowed
to use the i th test  the i th attribute   otherwise  if b i       eg  is allowed to use the i th
test  eg  uses the icf equation as usual  with the true costs c i   thus this modified version
of icet is searching through a binary bias space instead of a real bias space 
our hypothesis was that icet would perform better when searching in real bias space
    each of these three experiments took one week on a sparc     which is why we only tried three settings for
the mutation rate 

   

fic ost  s ensitive c lassification   e mpirical e valuation

than when searching in binary bias space  table    shows that this hypothesis was not confirmed  it appears to be better to search in binary bias space  rather than real bias space 
however  the differences are not statistically significant 
table     average percentage of standard cost for the binary search experiment 
algorithm

average classification cost as percentage of
standard      confidence
misclassification
error costs
from       to          

misclassification
error costs
from       to       

icet  binary space

     

     

icet  real space

     

     

eg 

     

     

cs id 

     

     

idx

     

     

c   

     

     

when we searched in binary space  we set c i to the true cost of the i th test  genesis
manipulated b i instead of c i   when we searched in real space  genesis set c i to whatever
value it found useful in its attempt to optimize fitness  we hypothesized that this gives an
advantage to binary space search over real space search  binary space search has direct
access to the true costs of the tests  but real space search only learns about the true costs of
the tests indirectly  by the feedback it gets from the fitness function 
when we examined the experiment in detail  we found that icet did well on the heart
disease dataset when it was searching in binary bias space  although it did poorly when it
was searching in real bias space  see section         we hypothesized that icet  when
searching in real space  suffered most from the lack of direct access to the true costs when it
was applied to the heart disease dataset  these hypotheses were tested by the next experiment 
     

seeded population

in this experiment  we returned to searching in real bias space  but we seeded the initial population of biases with the true test costs  this gave icet direct access to the true test costs 
for conditional test costs  we used the no discount cost  see section         in the baseline
experiment  section       the initial population consists of    randomly generated strings 
representing n     real numbers  in this experiment  the initial population consists of    randomly generated strings and one manually generated string  in the manually generated
string  the first n numbers are the true test costs  the last two numbers were set to      for
   and     for cf   this string is exactly the bias of eg   as implemented here  section
     
our hypotheses were     that icet would perform better  on average  when the initial
population is seeded than when it is purely random      that icet would perform better  on
average  searching in real space with a seeded population than when searching in binary
space    and     that icet would perform better on the heart disease dataset when the ini   

fit urney

tial population is seeded than when it is purely random  table    appears to support the first
two hypotheses  figure   appears to support the third hypothesis  however  the results are
not statistically significant   
table     average percentage of standard cost for the seeded population
experiment 
algorithm

average classification cost as percentage of
standard      confidence
misclassification
error costs
from       to          

misclassification
error costs
from       to       

icet  seeded
search in real space

     

     

icet  unseeded
search in real space

     

     

icet  unseeded
search in binary space

     

     

eg 

     

     

cs id 

     

     

idx

     

     

c   

     

     

this experiment raises some interesting questions  should seeding the population be
built into the icet algorithm  should we seed the whole population with the true costs  perturbed by some random noise  perhaps this is the right approach  but we prefer to modify
icf i  equation       the device by which genesis controls the decision tree induction  we
could alter this equation so that it contains both the true costs and some bias parameters   
this seems to make more sense than our current approach  which deprives eg  of direct
access to the true costs  we discuss some other ideas for modifying the equation in
section     
incidentally  this experiment lets us answer the following question  does the genetic
search in bias space do anything useful  if we start with the true costs of the tests and reasonable values for the parameters  and cf  how much improvement do we get from the
genetic search  in this experiment  we seeded the population with an individual that represents exactly the bias of eg   the first n numbers are the true test costs and the last two numbers are     for  and    for cf   therefore we can determine the value of genetic search by
comparing eg  with icet  icet starts with the bias of eg   as a seed in the first genera    note that it does not make sense to seed the binary space search  since it already has direct access to the true
costs 
    we would need to go from the current    trials     random splits of the data  to about    trials to make the
results significant  the experiments reported here took a total of    days of continuous computation on a sun
sparc     so    trials would require about six more months 
    this idea was suggested in conversation by k  de jong 

   

fic ost  s ensitive c lassification   e mpirical e valuation

heart disease
   

  

  

average   standard cost

average   standard cost

bupa liver disease
   

  

  

  
 
  

  

  

  
 

   

    

     

  

cost of misclassification error

  

  

  

  

  
 

  

  
 

   

    

     

  

   

    

     

cost of misclassification error

thyroid disease

average of five datasets

   

   

  

  

average   standard cost

average   standard cost

     

  

cost of misclassification error

  

  

  
 
  

    

pima indians diabetes
   
average   standard cost

average   standard cost

hepatitis prognosis
   

  

   

cost of misclassification error

  

  

  
 

   

    

     

  

cost of misclassification error

   

    

     

cost of misclassification error

icet 
eg  
cs id  
idx 
c    

figure    average cost of classification as a percentage of the standard cost of
classification for the seeded population experiment 
tion  and attempts to improve the bias  the score of eg  in table    shows the value of the
bias built into eg   the score of icet in table    shows how genetic search in bias space
can improve the built in bias of eg   when the cost of misclassification errors has the same
order of magnitude as the test costs      to        eg  averages     of the standard cost 
while icet averages     of the standard cost  when the cost of misclassification errors
ranges from     to          eg  averages     of the standard cost  while icet averages
    of the standard cost  both of these differences are significant with more than     confidence  this makes it clear that genetic search is adding value 
   

fit urney

   discussion
this section compares icet to related work and outlines some possibilities for future work 
   

related work

there are several other algorithms that are sensitive to test costs  nez              tan  
schlimmer              tan        norton         as we have discussed  the main limitation of these algorithms is that they do not consider the cost of classification errors  we cannot rationally determine whether a test should be performed until we know both the cost of
the test and the cost of classification errors 
there are also several algorithms that are sensitive to classification error costs  breiman
et al         friedman   stuetzle        hermans et al         gordon   perlis        pazzani et al         provost        provost   buchanan  in press  knoll et al          none of
these algorithms consider the cost of tests  therefore they all focus on complex classification
cost matrices  since  when tests have no cost and the classification error matrix is simple  the
problem reduces to maximizing accuracy 
the fis system  pipitone et al         attempts to find a decision tree that minimizes the
average total cost of the tests required to achieve a certain level of accuracy  this approach
could be implemented in icet by altering the fitness function  the main distinction between
fis  pipitone et al         and icet is that fis does not learn from data  the information
gain of a test is estimated using a qualitative causal model  instead of training cases  qualitative causal models are elicited from domain experts  using a special knowledge acquisition
tool  when training data are available  icet can be used to avoid the need for knowledge
acquisition  otherwise  icet is not applicable and the fis approach is suitable 
another feature of icet is that it does not perform purely greedy search  several other
authors have proposed non greedy classification algorithms  tcheng et al         ragavan  
rendell        norton        schaffer        rymon        seshu         in general  these
results show that there can be an advantage to more sophisticated search procedures  icet is
different from these algorithms in that it uses a genetic algorithm and it is applied to minimizing both test costs and classification error costs 
icet uses a two tiered search strategy  at the bottom tier  eg  performs a greedy search
through the space of classifiers  on the second tier  genesis performs a non greedy search
through a space of biases  the idea of a two tiered search strategy  where the first tier is
search in classifier space and the second tier is search in bias space  also appears in  provost 
      provost   buchanan  in press  aha   bankert        schaffer         our work goes
beyond aha and bankert        by considering search in a real bias space  rather than search
in a binary space  our work fits in the general framework of provost and buchanan  in
press   but differs in many details  for example  their method of calculating cost is a special
case of ours  section      
other researchers have applied genetic algorithms to classification problems  for example  frey and slate        applied a genetic algorithm  in particular  a learning classifier system  lcs   to letter recognition  however  fogarty        obtained higher accuracy using a
simple nearest neighbor algorithm  more recent applications of genetic algorithms to classification have been more successful  de jong et al          however  the work described here
is the first application of genetic algorithms to the problem of cost sensitive classification 
we mentioned in section     that decision theory may be used to define the optimal solution to the problem of cost sensitive classification  however  searching for the optimal solution is computationally infeasible  pearl         we attempted to take a decision theoretic
   

fic ost  s ensitive c lassification   e mpirical e valuation

approach to this problem by implementing the ao  algorithm  pearl        and designing a
heuristic evaluation function to speed up the ao  search  lirov   yue         we were
unable to make this approach execute fast enough to be practical 
we also attempted to apply genetic programming  koza        to the problem of costsensitive classification  again  we were unable to make this approach execute fast enough to
be practical  although it was faster than the ao  approach 
the cost sensitive classification problem  as we have treated it here  is essentially a
problem in reinforcement learning  sutton        karakoulas  in preparation   the average
cost of classification  measured as described in section      is a reward punishment signal
that could be optimized using reinforcement learning techniques  this is something that
might be explored as an alternative approach 
   

future work

this paper discusses two types of costs  the cost of tests and the cost of misclassification
errors  these two costs have been treated together in decision theory  but icet is the first
machine learning system that handles both costs together  the experiments in this paper have
compared icet to other machine learning systems that can handle test costs  nez       
      tan   schlimmer              tan        norton         but we have not compared
icet to other machine learning systems that can handle classification error costs  breiman
et al         friedman   stuetzle        hermans et al         gordon   perlis        pazzani et al         provost        provost   buchanan  in press  knoll et al          in future
work  we plan to address this omission  a proper treatment of this issue would make this
paper too long 
the absence of comparison with machine learning systems that can handle classification
error costs has no impact on most of the experiments reported here  the experiments in this
paper focussed on simple classification cost matrices  except for section         when the
classification cost matrix is simple and the cost of tests is ignored  minimizing cost is exactly
equivalent to maximizing accuracy  see section       therefore  c     which is designed to
maximize accuracy  is a suitable surrogate for any of the systems that can handle classification error costs 
we also did not experiment with setting the test costs to zero  however  the behavior of
icet when the penalty for misclassification errors is very high  the extreme right hand sides
of the plots in figure    is necessarily the same as its behavior when the cost of tests is very
low  since icet is sensitive to the relative differences between test costs and error costs  not
the absolute costs  therefore  given the behavior we can observe in the extreme right hand
sides of the plots in figure    we can expect that the performance of icet will tend to converge with the performance of the other algorithms as the cost of tests approaches zero 
one natural addition to icet would be the ability to output an i dont know class  this
is easily handled by the genesis component  by extending the classification cost matrix so
that a cost is assigned to classifying a case as unknown  we need to also make a small
modification to the eg  component  so that it can generate decision trees with leaves
labelled unknown  one way to do this would be to introduce a parameter that defines a
confidence threshold  whenever the confidence in a certain leaf drops below the confidence
threshold  that leaf would be labelled unknown  this confidence parameter would be made
accessible to the genesis component  so that it could be tuned to minimize average classification cost 
the mechanism in icet for handling conditional test costs has some limitations  as it is
   

fit urney

currently implemented  it does not handle the cost of attributes that are calculated from other
attributes  for example  in the thyroid dataset  appendix a     the fti test is calculated
based on the results of the tt  and t u tests  if the fti test is selected  we must pay for the
tt  and t u tests  if the tt  and t u tests have already been selected  the fti test is free
 since the calculation is trivial   the ability to deal with calculated test results could be
added to icet with relatively little effort 
icet  as currently implemented  only handles two classes of test results  tests with
immediate results and tests with delayed results  clearly there can be a continuous range
of delays  from seconds to years  we have chosen to treat delays as distinct from test costs 
but it could be argued that a delay is simply another type of test cost  for example  we could
say that a group of blood tests shares the common cost of a one day wait for results  the cost
of one of the blood tests is conditional on whether we are prepared to commit ourselves to
doing one or more of the other tests in the group  before we see the results of the first test 
one difficultly with this approach to handling delays is the problem of assigning a cost to the
delay  how much does it cost to bring a patient in for two blood samples  instead of one  do
we include the disruption to the patients life in our estimate of the cost  to avoid these
questions  we have not treated delays as another type of test cost  but our approach does not
readily handle a continuous range of delays 
the cost of a test can be a function of several things      it can be a function of the prior
tests that have been selected      it can be a function of the actual class of the case      it can
be a function of other aspects of the case  where information about these other aspects may
be available through other tests      it can be a function of the test result  this list seems
comprehensive  but there may be some possibilities we have overlooked  let us consider
each of these four possibilities 
first  the cost of a test can be a function of the prior tests that have been selected  icet
handles a special case of this  where a group of tests shares a common cost  as it is currently
implemented  icet does not handle the general case  however  we could easily add this
capability to icet by modifying the fitness function 
second  the cost of a test can be a function of the actual class of the case  for example  a
test for heart disease might involve heavy exercise  appendix a     if the patient actually
has heart disease  the exercise might trigger a heart attack  this risk should be included in
the cost of this particular test  thus the cost of this test should vary  depending on whether
the patient actually has heart disease  we have not implemented this  although it could easily
be added to icet by modifying the fitness function 
third  the cost of a test can be a function of the results of other tests  for example  drawing blood from a newborn is more costly than drawing blood from an adult  to assign a cost
to a blood test  we need to know the age of the patient  the age of the patient can be represented as the result of another test  the patient age test  this is slightly more complex
than the preceding cases  because we must now insure that the blood test is always accompanied with the patient age test  we have not implemented this  although it could be added to
icet 
fourth  the cost of a test can be a function of the test result  for example  injecting a
radio opaque die for an x ray might cause an allergic reaction in the patient  this risk should
be added to the cost of the test  this makes the cost of the test a function of one of the possible outcomes of the test  in a situation like this  it may be wise to precede the injection of the
die with a screening test for allergies  this could be as simple as asking a question to the
patient  this question may have no relevance at all for determining the correct diagnosis of
   

fic ost  s ensitive c lassification   e mpirical e valuation

the patient  but it may serve to reduce the average cost of classification  this case is similar
to the third case  above  again  we have not implemented this  although it could be added to
icet 
attribute selection in eg   cs id   and idx shares a common form  we may view
n
attribute selection as a function from  to        n     which takes as input n information
gain values i      i n  one for each attribute  and generates as output the index of one of
the attributes  we may view c      c n and  as parameters in the attribute selection function  these parameters may be used to control the bias of the attribute selection procedure  in
this view  icet uses genesis to tune the parameters of eg s attribute selection function 
in the future  we would like to investigate more general attribute selection functions  for
n
example  we might use a neural network to implement a function from  to        n    
genesis would then be used to tune the weights in the neural network    the attribute
selection function might also benefit from the addition of an input that specifies the depth of
the decision tree at the current node  where the information gain values are measured  this
would enable the bias for a test to vary  depending on how many tests have already been
selected 
another area for future work is to explore the parameter settings that control genesis
 table     there are many parameters that could be adjusted in genesis  we think it is significant that icet works well with the default parameter settings in genesis  since it
shows that icet is robust with respect to the parameters  however  it might be possible to
substantially improve the performance of icet by tuning some of these parameters  a recent
trend in genetic algorithm research is to let the genetic algorithm adjust some of its own
parameters  such as mutation rate and crossover rate  whitley et al          another possibility is to stop breeding when the fitness levels stop improving  instead of stopping after a
fixed number of generations  provost and buchanan  in press  use a goodness measure as a
stopping condition for the bias space search 

   conclusions
the central problem investigated here is the problem of minimizing the cost of classification
when the tests are expensive  we argued that this requires assigning a cost to classification
errors  we also argued that a decision tree is the natural form of knowledge representation
for this type of problem  we then presented a general method for calculating the average cost
of classification for a decision tree  given a decision tree  information on the calculation of
test costs  a classification cost matrix  and a set of testing data  this method is applicable to
standard classification decision trees  without regard to how the decision tree is generated 
the method is sensitive to test costs  sensitive to classification error costs  capable of handling conditional test costs  and capable of handling delayed tests 
we introduced icet  a hybrid genetic decision tree induction algorithm  icet uses a
genetic algorithm to evolve a population of biases for a decision tree induction algorithm 
each individual in the population represents one set of biases  the fitness of an individual is
determined by using it to generate a decision tree with a training dataset  then calculating the
average cost of classification for the decision tree with a testing dataset 
we analyzed the behavior of icet in a series of experiments  using five real world medical datasets  three groups of experiments were performed  the first group looked at the
baseline performance of the five algorithms on the five datasets  icet was found to have sig    this idea was suggested in conversation by m  brooks 

   

fit urney

nificantly lower costs than the other algorithms  although it executes more slowly  an average time of    minutes  for a typical dataset  is acceptable for many applications  and there
is the possibility of much greater speed on a parallel machine  the second group of experiments studied the robustness of icet under a variety of modifications to its input  the
results show that icet is robust  the third group of experiments examined icets search in
bias space  we discovered that the search could be improved by seeding the initial population of biases 
in general  our research is concerned with pragmatic constraints on classification problems  provost   buchanan  in press   we believe that many real world classification problems involve more than merely maximizing accuracy  turney  in press   the results
presented here indicate that  in certain applications  a decision tree that merely maximizes
accuracy  e g   trees generated by c     may be far from the performance that is possible
with an algorithm that considers such realistic constraints as test costs  classification error
costs  conditional test costs  and delayed test results  these are just a few of the pragmatic
constraints that are faced in real world classification problems 

appendix a  five medical datasets
this appendix presents the test costs for five medical datasets  taken from the irvine collection  murphy   aha         the costs are based on information from the ontario ministry of
health         although none of the medical data were gathered in ontario  it is reasonable
to assume that other areas have similar relative test costs  for our purposes  the relative costs
are important  not the absolute costs 
a  

bupa liver disorders

the bupa liver disorders dataset was created by bupa medical research ltd  and it was
donated to the irvine collection by richard forsyth    table    shows the test costs for the
bupa liver disorders dataset  the tests in group a are blood tests that are thought to be
sensitive to liver disorders that might arise from excessive alcohol consumption  these tests
share the common cost of       for collecting blood  the target concept was defined using
the sixth column  class   was defined as drinks     and class   was defined as drinks 
   table    shows the general form of the classification cost matrix that was used in the
experiments in section    for most of the experiments  the classification error cost equals the
positive error cost equals the negative error cost  the exception is in section        for the
experiments with complex classification cost matrices  the terms positive error cost and
negative error cost are explained in section        there are     cases in this dataset  with
no missing values  column seven was originally used to split the data into training and testing sets  we did not use this column  since we required ten different random splits of the
data  in our ten random splits  the ten training sets all had     cases and the ten testing sets
all had     cases 
a  

heart disease

the heart disease dataset was donated to the irvine collection by david aha    the princi    the bupa liver disorders dataset has the url ftp   ftp ics uci edu pub machine learning databases liverdisorders bupa data 
    the heart disease dataset has the url ftp   ftp ics uci edu pub machine learning databases heart disease 
cleve mod 

   

fic ost  s ensitive c lassification   e mpirical e valuation

table     test costs for the bupa liver disorders dataset 
test

description

group

cost

delayed

 

mcv

mean corpuscular volume

a

      if first test in group a 
      otherwise

yes

 

alkphos

alkaline phosphotase

a

      if first test in group a 
      otherwise

yes

 

sgpt

alamine aminotransferase

a

      if first test in group a 
      otherwise

yes

 

sgot

aspartate aminotransferase

a

      if first test in group a 
      otherwise

yes

 

gammagt

gamma glutamyl transpeptidase

a

      if first test in group a 
      otherwise

yes

 

drinks

number of half pint equivalents of
alcoholic beverages drunk per day

diagnostic class  drinks    
or drinks   

 

 

selector

field used to split data into two sets

not used

 

table     classification costs for the bupa liver disorders dataset 
actual class

guess class

cost

   drinks     

   drinks     

     

   drinks     

   drinks    

positive error cost

   drinks    

   drinks     

negative error cost

   drinks    

   drinks    

     

pal medical investigator was robert detrano  of the cleveland clinic foundation  table   
shows the test costs for the heart disease dataset  a nominal cost of       was assigned to
the first four tests  the tests in group a are blood tests that are thought to be relevant for
heart disease  these tests share the common cost of       for collecting blood  the tests in
groups b and c involve measurements of the heart during exercise  a nominal cost of      
was assigned for tests after the first test in each of these groups  the class variable has the
values buff  healthy  and sick  there was a fifteenth column  which specified the class
variable as h  healthy   s   s   s   or s   four different types of sick   but we
deleted this column  table    shows the classification cost matrix  there are     cases in
this dataset  we deleted all cases for which there were missing values  this reduced the
dataset to     cases  in our ten random splits  the training sets had     cases and the testing
sets had    cases 
a  

hepatitis prognosis

the hepatitis prognosis dataset was donated by gail gong    table    shows the test costs
for the hepatitis dataset  unlike the other four datasets  this dataset deals with prognosis  not
    the hepatitis prognosis dataset has the url ftp   ftp ics uci edu pub machine learning databases hepatitis 
hepatitis data 

   

fit urney

table     test costs for the heart disease dataset 
test

description

 

age

 

group

cost

delayed

age in years

     

no

sex

patients gender

     

no

 

cp

chest pain type

     

no

 

trestbps

resting blood pressure

     

no

 

chol

serum cholesterol

a

      if first test in group a 
      otherwise

yes

 

fbs

fasting blood sugar

a

      if first test in group a 
      otherwise

yes

 

restecg

resting electrocardiograph

      

yes

 

thalach

maximum heart rate
achieved

b

        if first test in group b 
      otherwise

yes

 

exang

exercise induced angina

c

       if first test in group c 
      otherwise

yes

  

oldpeak

st depression induced by
exercise relative to rest

c

       if first test in group c 
      otherwise

yes

  

slope

slope of peak exercise st
segment

c

       if first test in group c 
      otherwise

yes

  

ca

number of major vessels
coloured by fluoroscopy

       

yes

  

thal

    normal      fixed defect 
    reversible defect

        if first test in group b 
      otherwise

yes

  

num

diagnosis of heart disease

diagnostic class

 

b

table     classification costs for the heart disease dataset 
actual class

guess class

cost

buff

buff

     

buff

sick

positive error cost

sick

buff

negative error cost

sick

sick

     

diagnosis  with prognosis  the diagnosis is known  and the problem is to determine the likely
outcome of the disease  the tests that were assigned a nominal cost of       either involve
asking a question to the patient or performing a basic physical examination on the patient 
the tests in group a share the cost of       for collecting blood  note that  although performing a histological examination of the liver costs         asking the patient whether a
histology was performed only costs        thus the prognosis can exploit the information
conveyed by a decision  to perform a histological examination  that was made during the
diagnosis  the class variable has the values    die  and    live   table    shows the classification costs  the dataset contains     cases  with many missing values  in our ten random
   

fic ost  s ensitive c lassification   e mpirical e valuation

table     test costs for the hepatitis prognosis dataset 
test

description

 

class

 

group

cost

delayed

prognosis of hepatitis

prognostic class  live or die

 

age

age in years

     

no

 

sex

gender

     

no

 

steroid

patient on steroids

     

no

 

antiviral

patient on antiviral

     

no

 

fatigue

patient reports fatigue

     

no

 

malaise

patient reports malaise

     

no

 

anorexia

patient anorexic

     

no

 

liver big

liver big on physical exam

     

no

  

liver firm

liver firm on physical exam

     

no

  

spleen palpable

spleen palpable on physical

     

no

  

spiders

spider veins visible

     

no

  

ascites

ascites visible

     

no

  

varices

varices visible

     

no

  

bilirubin

bilirubin  blood test

a

      if first test in group a 
      otherwise

yes

  

alk phosphate

alkaline phosphotase

a

      if first test in group a 
      otherwise

yes

  

sgot

aspartate aminotransferase

a

      if first test in group a 
      otherwise

yes

  

albumin

albumin  blood test

a

      if first test in group a 
      otherwise

yes

  

protime

protime  blood test

a

      if first test in group a 
      otherwise

yes

  

histology

was histology performed 

     

no

table     classification costs for the hepatitis prognosis dataset 
actual class

guess class

cost

   die 

   die 

     

   die 

   live 

negative error cost

   live 

   die 

positive error cost

   live 

   live 

     

splits  the training sets had     cases and the testing sets had    cases  we filled in the missing values  using a simple single nearest neighbor algorithm  aha et al          the missing
values were filled in using the whole dataset  before the dataset was split into training and
testing sets  for the nearest neighbor algorithm  the data were normalized so that the mini   

fit urney

mum value of a feature was   and the maximum value was    the distance measure used was
the sum of the absolute values of the differences  the difference between two values was
defined to be   if one or both of the two values was missing 
a  

pima indians diabetes

the pima indians diabetes dataset was donated by vincent sigillito     the data were collected by the national institute of diabetes and digestive and kidney diseases  table   
shows the test costs for the pima indians diabetes dataset  the tests in group a share the
cost of       for collecting blood  the remaining tests were assigned a nominal cost of
       all of the patients were females at least    years old of pima indian heritage  the
class variable has the values    healthy  and    diabetes   table    shows classification costs 
the dataset includes     cases  with no missing values  in our ten random splits  the training
sets had     cases and the testing sets had     cases 
table     test costs for the pima indians diabetes dataset 
test

description

group

cost

delayed

 

times pregnant

number of times pregnant

     

no

 

glucose tol

glucose tolerance test

       if first test in group a 
       otherwise

yes

 

diastolic bp

diastolic blood pressure

     

no

 

triceps

triceps skin fold thickness

     

no

 

insulin

serum insulin test

       if first test in group a 
       otherwise

yes

 

mass index

body mass index

     

no

 

pedigree

diabetes pedigree function

     

no

 

age

age in years

     

no

 

class

diagnostic class

diagnostic class

 

a

a

table     classification costs for the pima indians diabetes dataset 

a  

actual class

guess class

cost

   healthy 

   healthy 

     

   healthy 

   diabetes 

positive error cost

   diabetes 

   healthy 

negative error cost

   diabetes 

   diabetes 

     

thyroid disease

the thyroid disease dataset was created by the garavan institute  sydney  australia  the
file was donated by randolf werner  obtained from daimler benz  daimler benz obtained
    the pima indians diabetes dataset has the url ftp   ftp ics uci edu pub machine learning databases pimaindians diabetes pima indians diabetes data 

   

fic ost  s ensitive c lassification   e mpirical e valuation

the data from j r  quinlan    table    shows the test costs for the thyroid disease dataset 
a nominal cost of       was assigned to the first    tests  the tests in group a share the cost
of       for collecting blood  the fti test involves a calculation based on the results of the
tt  and t u tests  this complicates the calculation of the costs of these three tests  so we
chose not to use the fti test in our experiments  the class variable has the values  
 hypothyroid      hyperthyroid   and    normal   table    shows the classification costs 
there are      cases in this dataset  with no missing values  in our ten random splits  the
training sets had      cases and the testing sets had      cases 
table     test costs for the thyroid disease dataset 
test

description

 

age

 

group

cost

delayed

age in years

     

no

sex

gender

     

no

 

on thyroxine

patient on thyroxine

     

no

 

query thyroxine

maybe on thyroxine

     

no

 

on antithyroid

on antithyroid medication

     

no

 

sick

patient reports malaise

     

no

 

pregnant

patient pregnant

     

no

 

thyroid surgery

history of thyroid surgery

     

no

 

i    treatment

patient on i    treatment

     

no

  

query hypothyroid

maybe hypothyroid

     

no

  

query hyperthyroid

maybe hyperthyroid

     

no

  

lithium

patient on lithium

     

no

  

goitre

patient has goitre

     

no

  

tumour

patient has tumour

     

no

  

hypopituitary

patient hypopituitary

     

no

  

psych

psychological symptoms

     

no

  

tsh

tsh value  if measured

a

       if first test in group a  yes
       otherwise

  

t 

t  value  if measured

a

       if first test in group a  yes
      otherwise

  

tt 

tt  value  if measured

a

       if first test in group a  yes
       otherwise

  

t u

t u value  if measured

a

       if first test in group a  yes
      otherwise

  

fti

fti  calculated from
tt  and t u

not used

 

  

class

diagnostic class

diagnostic class

 

    the thyroid disease dataset has the url ftp   ftp ics uci edu pub machine learning databases thyroid disease ann train data 

   

fit urney

table     classification costs for the thyroid disease dataset 
actual class

guess class

cost

   hypothyroid 

   hypothyroid 

     

   hypothyroid 

   hyperthyroid 

minimum negative error cost  positive error cost 

   hypothyroid 

   normal 

negative error cost

   hyperthyroid 

   hypothyroid 

minimum negative error cost  positive error cost 

   hyperthyroid 

   hyperthyroid 

     

   hyperthyroid 

   normal 

negative error cost

   normal 

   hypothyroid 

positive error cost

   normal 

   hyperthyroid 

positive error cost

   normal 

   normal 

     

acknowledgments
thanks to dr  louise linney for her help with interpretation of the ontario ministry of
healths schedule of benefits  thanks to martin brooks  grigoris karakoulas  cullen schaffer  diana gordon  tim niblett  steven minton  and three anonymous referees of jair for
their very helpful comments on earlier versions of this paper  this work was presented in
informal talks at the university of ottawa and the naval research laboratory  thanks to
both audiences for their feedback 

references
ackley  d     littman  m          interactions between learning and evolution  in proceedings of the second conference on artificial life  c  langton  c  taylor  d  farmer  and s 
rasmussen  editors  california  addison wesley 
aha  d w   kibler  d     albert  m k          instance based learning algorithms  machine
learning           
aha  d w     bankert  r l          feature selection for case based classification of cloud
types  an empirical comparison  case based reasoning  papers from the      workshop  edited by d w  aha  technical report ws        pp           menlo park  ca 
aaai press 
anderson  r w   in press   learning and evolution  a quantitative genetics approach  journal of theoretical biology 
baldwin  j m          a new factor in evolution  american naturalist              
breiman  l   friedman  j   olshen  r     stone  c          classification and regression
trees  california  wadsworth 
de jong  k a   spears  w m     gordon  d f          using genetic algorithms for concept
learning  machine learning              

   

fic ost  s ensitive c lassification   e mpirical e valuation

fogarty  t c          technical note  first nearest neighbor classification on frey and slates
letter recognition problem  machine learning             
frey  p w     slate  d j           letter recognition using holland style adaptive classifiers 
machine learning             
friedman  j h     stuetzle  w          projection pursuit regression  journal of the american statistics association              
gordon  d f     perlis  d          explicitly biased generalization  computational intelligence           
grefenstette  j j          optimization of control parameters for genetic algorithms  ieee
transactions on systems  man  and cybernetics              
grefenstette  j j   ramsey  c l     schultz  a c          learning sequential decision rules
using simulation models and competition  machine learning             
hermans  j   habbema  j d f     van der burght  a t          cases of doubt in allocation
problems  k populations  bulletin of the international statistics institute              
hinton  g e     nowlan  s j          how learning can guide evolution  complex systems 
           
karakoulas  g   in preparation   a q learning approach to cost effective classification  technical report  knowledge systems laboratory  national research council canada  also
submitted to the twelfth international conference on machine learning  ml    
knoll  u   nakhaeizadeh  g     tausend  b          cost sensitive pruning of decision trees 
proceedings of the eight european conference on machine learning  ecml     pp 
         berlin  germany  springer verlag 
koza  j r          genetic programming  on the programming of computers by means of
natural selection  cambridge  ma  mit press 
lirov  y     yue  o  c          automated network troubleshooting knowledge acquisition 
journal of applied intelligence             
maynard smith  j          when learning guides evolution  nature               
morgan  c l          on modification and variation  science             
murphy  p m     aha  d w          uci repository of machine learning databases  university of california at irvine  department of information and computer science 
norton  s w          generating better decision trees  proceedings of the eleventh international joint conference on artificial intelligence  ijcai     pp           detroit  michigan 
nez  m          economic induction  a case study  proceedings of the third european
working session on learning  ewsl     pp           california  morgan kaufmann 

   

fit urney

nez  m          the use of background knowledge in decision tree induction  machine
learning             
ontario ministry of health         schedule of benefits  physician services under the health
insurance act  october          ontario  ministry of health 
pazzani  m   merz  c   murphy  p   ali  k   hume  t     brunk  c          reducing misclassification costs  knowledge intensive approaches to learning from noisy data  proceedings of the eleventh international conference on machine learning  ml     pp          new brunswick  new jersey 
pearl  j          heuristics  intelligent search strategies for computer problem solving  massachusetts  addison wesley 
pearl  j          probabilistic reasoning in intelligent systems  networks of plausible inference  california  morgan kaufmann 
pipitone  f   de jong  k a     spears  w m          an artificial intelligence approach to
analog systems diagnosis  in testing and diagnosis of analog circuits and systems 
ruey wen liu  editor  new york  van nostrand reinhold 
provost  f j          goal directed inductive learning  trading off accuracy for reduced error
cost  aaai spring symposium on goal driven learning 
provost  f j     buchanan  b g   in press   inductive policy  the pragmatics of bias selection  machine learning 
quinlan  j r          c     programs for machine learning  california  morgan kaufmann 
ragavan  h     rendell  l          lookahead feature construction for learning hard concepts  proceedings of the tenth international conference on machine learning  ml    
pp           california  morgan kaufmann 
rymon  r          an se tree based characterization of the induction problem  proceedings
of the tenth international conference on machine learning  ml     pp           california  morgan kaufmann 
schaffer  c          selecting a classification method by cross validation  machine learning              
schaffer  j d   whitley  d     eshelman  l j          combinations of genetic algorithms
and neural networks  a survey of the state of the art  in combinations of genetic algorithms and neural networks  d  whitley and j d  schaffer  editors  california  ieee
computer society press 
seshu  r          solving the parity problem  proceedings of the fourth european working
session on learning  ewsl     pp           california  morgan kaufmann 
spears  w m          crossover or mutation  foundations of genetic algorithms    foga    edited by d  whitley  california  morgan kaufmann 

   

fic ost  s ensitive c lassification   e mpirical e valuation

sutton  r s          introduction  the challenge of reinforcement learning  machine learning             
tan  m     schlimmer  j          cost sensitive concept learning of sensor use in approach
and recognition  proceedings of the sixth international workshop on machine learning 
ml     pp           ithaca  new york 
tan  m     schlimmer  j          csl  a cost sensitive learning system for sensing and
grasping objects  ieee international conference on robotics and automation  cincinnati  ohio 
tan  m          cost sensitive learning of classification knowledge and its applications in
robotics  machine learning           
tcheng  d   lambert  b   lu  s   rendell  l          building robust learning systems by
combining induction and optimization  proceedings of the eleventh international joint
conference on artificial intelligence  ijcai     pp           detroit  michigan 
turney  p d   in press   technical note  bias and the quantification of stability  machine
learning 
verdenius  f          a method for inductive cost optimization  proceedings of the fifth
european working session on learning  ewsl     pp           new york  springerverlag 
waddington  c h          canalization of development and the inheritance of acquired characters  nature               
whitley  d   dominic  s   das  r     anderson  c w          genetic reinforcement learning
for neurocontrol problems  machine learning              
whitley  d     gruau  f          adding learning to the cellular development of neural networks  evolution and the baldwin effect  evolutionary computation             
whitley  d   gordon  s     mathias  k          lamarckian evolution  the baldwin effect
and function optimization  parallel problem solving from nature  ppsn iii  y  davidor  h p  schwefel  and r  manner  editors  pp        berlin  springer verlag 
wilson  s w          classifier systems and the animat problem  machine learning            

   

fi