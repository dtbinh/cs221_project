journal artificial intelligence research                 

submitted       published      

flexibly instructable agents
scott b  huffman

price waterhouse technology centre     willow road
menlo park  ca       usa

john e  laird

artificial intelligence laboratory
university michigan       beal ave 
ann arbor  mi            usa

huffman tc pw com
laird eecs umich edu

abstract

paper presents approach learning situated  interactive tutorial instruction within ongoing agent  tutorial instruction exible  and thus powerful 
paradigm teaching tasks allows instructor communicate whatever types
knowledge agent might need whatever situations might arise  support exibility  however  agent must able learn multiple kinds knowledge broad
range instructional interactions  approach  called situated explanation  achieves
learning combination analytic inductive techniques  combines
form explanation based learning situated instruction full suite
contextually guided responses incomplete explanations  approach implemented
agent called instructo soar learns hierarchies new tasks domain knowledge interactive natural language instructions  instructo soar meets
three key requirements exible instructability distinguish previous systems 
    take known unknown commands instruction point      handle
instructions apply either current situation hypothetical situation specified language  as in  instance  conditional instructions       learn 
instructions  class knowledge uses perform tasks 

   introduction
intelligent  autonomous agents future called upon perform wide
varying range tasks  wide range circumstances  course
lifetimes  performing tasks requires knowledge  number possible tasks
circumstances large variable time  as general agent   becomes
nearly impossible preprogram knowledge required  thus  knowledge must
added agent s lifetime  unfortunately  knowledge cannot added
current intelligent systems perform  must shut programmed
new task 
work examines alternative  intelligent agents taught perform tasks
tutorial instruction  part ongoing performance  tutorial instruction
highly interactive dialogue focuses specific task s  performed 
working tasks  student may receive instruction needed complete tasks
understand aspects domain previous instructions  situated  interactive
form instruction produces strong human learning  bloom         although

c      ai access foundation morgan kaufmann publishers  rights reserved 

fihuffman   laird

received little attention ai  potential powerful knowledge source
artificial agents well 
much tutorial instruction s power comes communicative exibility  instructor communicate whatever type knowledge student may need whatever
situation needed  challenge designing tutorable agent support
breadth interaction learning abilities required exible communication 
paper  present theory learning tutorial instruction within ongoing
agent  developing theory  given special attention supporting communicative exibility instructor  the human user   began identifying properties
tutorial instruction instructor s perspective  properties 
derived set requirements instructable agent must meet support exible instructability  requirements drove development theory evaluation 
finally  implemented theory instructable agent called instructo soar
 huffman        huffman   laird               evaluated performance  
identifying requirements exible instructability provides target   set evaluation
criteria   instructable agents  requirements encompass ways agent interacts
instructor  comprehends instructions  learns them  general
requirements common interactive learning systems  e g   agent expected
learn general knowledge instructions  learn quickly  with minimal number
examples   integrate learned previous knowledge  etc  requirements
specific tutorial instruction 
theory learning tutorial instruction specifies analytic inductive
learning techniques combined within agent meet requirements  producing
general learning wide range instructional interactions  present learning
framework called situated explanation utilizes situation instruction applies
larger instructional context  the instruction s type place current dialogue 
guide learning process  situated explanation combines form explanation based
learning  dejong   mooney        mitchell  keller    kedar cabelli        situated individual instruction  full suite contextually guided responses
incomplete explanations  responses include delaying explanation information available  inducing knowledge complete explanations  completing explanations
instruction  abandoning explanation favor weaker learning methods 
previous explanation based learning systems employed one cases static
sequence options  chosen dynamically among options based
context example  dynamic selection required exible instructability  learning framework cast within computational model general intelligent
behavior called problem space computational model 
instructo soar implemented agent embodies theory  interactive natural language instructions  instructo soar learns perform new tasks  extends
known tasks apply new situations  acquires variety types domain
knowledge  allows exible instruction previous instructable systems  e g  
learning apprentice systems  mitchell  mahadevan    steinberg        meeting three
   work inspired human students  taken cues psychological effects
appropriate  theory s potential cognitive model discussed elsewhere  huffman       
huffman  miller    laird        

   

fiflexibly instructable agents

push green button 
thats new one  that 
move grey table 
ok  next 
move green button 
that 
move arm up 
oh  see  next 
move down 
ok  next 
operator finished 

turn light  push button 
mean pushing button
causes light come on 
yes 
   
never grasp red blocks 
not 
red blocks explosive 
light turn on 
   

figure    example tutorial instruction 
key requirements tutorial instruction      take known unknown commands
instruction point      handle instructions apply either current situation hypothetical situation specified language  as in  instance  conditional
instructions       learn  instructions  class knowledge uses
perform tasks 
follows  first discuss properties requirements tutorial instruction 
then  present approach implementation instructo soar  including
series examples illustrating instructional capabilities supported  conclude
discussion limitations areas research 

   properties tutorial instruction
tutorial instruction situated  interactive instruction given agent attempts
perform tasks  situated applies particular task situations arise
domain  interactive agent may request instruction needed  type
instruction common task oriented dialogues experts apprentices  grosz 
       example tutorial instruction given instructo soar robotic domain
shown figure   
tutorial instruction number properties make exible easy
instructor produce 
p   situation specificity  instructions given particular tasks particular situations  teach task  instructor need provide suggestions specific
situation hand  rather producing global procedure includes general conditions applicability step  handles possible contingencies  etc 
situation help disambiguate otherwise ambiguous instruction  number authors discussed advantages situation specific knowledge elicitation
 e g   davis        gruber        
p   situation specification needed  although instructions typically apply
situation hand  instructor free specify situations needed 
instance  specifying contingencies using conditional instructions 
p   incremental as needed elicitation  knowledge elicited incrementally part
agent s ongoing performance  instructions given agent unable
   

fihuffman   laird

perform task  thus  directly address points agent s knowledge
lacking 
p   task structuring instructor  instructor structure larger tasks
smaller subtasks way desired  instance  task requiring ten primitive steps
may taught simple sequence ten steps  two subtasks five steps
each  etc  agent know instructed action subtask is 
perform situation hand  ask instruction 
p   knowledge level interaction  instructor provides knowledge agent
knowledge level  newell         is  instructions refer objects
actions world  symbol level structures  e g   data structures  within
agent  interaction occurs natural language  language instructor
uses talk task  rather requiring artificial terminology syntax
specify agent s internal data processes 
tutorial instructions provide knowledge applicable agent s current situation
closely related one  thus  type instruction appropriate tasks
local control structure  control decisions made based presently available
information  local control structure characteristic constructive synthesis tasks 
primitive steps composed one another form complete solution 
work focuses type task  

   requirements instructable agent
although easing instructor s burden providing knowledge  properties tutorial
instruction described place severe requirements instructable agent  general 
agent must solve three conceptually distinct problems  must     comprehend individual instructions produce behavior      support exible dialogue instructor 
    produce general learning interaction  properties tutorial instruction described previous section place requirements solutions
problems  follows  identify key requirements problem turn 

    comprehending instructions  mapping problem

mapping problem involves comprehending instructions given natural language transforming information contain agent s internal representation
   contrast  problem solving methods constraint satisfaction heuristic classification involve global
control strategies  strategies either follow fixed global regime require aggregation
information multiple problem solving states make control decisions  possible produce
global control strategy using combination local decisions  yost   newell         however  teaching
global method casting purely sequence local decisions may dicult  types
instruction  beyond scope work  required teach global methods natural way 
acquire knowledge tasks involve known global control strategy  may ecient use
method based knowledge acquisition tool  e g   birmingham   klinker        birmingham   siewiorek 
      eshelman  ehret  mcdermott    tan        marcus   mcdermott        musen       
control strategy built in 

   

fiflexibly instructable agents

language  required agent apply information communicated instructions
knowledge level  property p   above  internal processing 
solving mapping problem general involves complexities natural language comprehension  carpenter        point out  instructions linguistically complex dicult interpret independent diculty task
instructed  even linguistically simple instructions  actions objects often incompletely specified  requiring use context domain knowledge produce complete
interpretation  chapman        dieugenio   webber        frederking        martin  
firby        
general requirement mapping problem tutorable agent straightforward 

m    tutorable agent must able comprehend map aspects instruction
fall within scope information possibly represent 

agent cannot expected interpret aspects fall outside representation abilities  these abilities may augmented instruction  occurs building
existing abilities   detailed analysis could break general requirement
set specific ones 
work focused mapping problem  rather  agent implemented uses fairly standard natural language processing techniques handle instructions
express sucient range actions situations demonstrate capabilities 
concentrated efforts interaction transfer problems 

    supporting interactive dialogue  interaction problem
interaction problem problem supporting exible dialogue instructor 
properties tutorial instruction indicate dialogue occurs agent s
ongoing performance address lacks knowledge  property p    within dialogue 
agent must handle instructions apply different kinds situations  properties
p  p   structure tasks different ways  property p   
instructable agent moves toward solving interaction problem degree
supports properties  work  concentrate instructor s utterances
within dialogue  since exibility instructor goal  considered
potential complexity agent s utterances  e g   give instructor various kinds
feedback  much detail 
properties exible interaction specified terms individual instruction
events  instruction event utterance single instruction particular
point discourse  support truly exible dialogue  instructable agent must
able handle instruction event coherent current discourse point 
instruction event initiated either student teacher  carries knowledge
type applied particular task situation  thus  exible tutorable agent
support instruction events with 

i   flexible initiation  instruction events initiated agent instructor 
   

fihuffman   laird

i   flexibility knowledge content  knowledge carried instruction event
piece types knowledge agent uses applicable
way within ongoing task discourse context 

i   situation exibility  instruction event apply either current task
situation specified hypothetical situation 

following sections discuss requirements detail 
      flexible initiation

human tutorial dialogues  initiation instruction mixed student teacher 
one study indicates teacher initiation prevalent early instruction  student
initiation increases student learns more  drops student
masters task  emihovich   miller        
instructor initiated instruction dicult support instruction events
interrupt agent s ongoing processing  upon interrupting agent  instruction event
may alter agent s knowledge way could change invalidate reasoning
agent previously engaged  diculties  instructable systems
date fully supported instructor initiated instruction   likewise  instructosoar handle instructor initiated instruction 
agent initiated instruction directed  at least  two possible ways  verification
impasses  learning apprentice systems  leap  mitchell et al        
disciple  kodratoff   tecuci      b  ask instructor verify alter reasoning
step  advantage approach step examined instructor 
disadvantage  course  step must examined  alternative approach
drive instruction requests impasses agent s task performance  golding  rosenbloom    laird        laird  hucka  yager    tuck         approach used
instructo soar  impasse indicates agent s knowledge lacking needs
instruction  advantage approach agent learns  becomes
autonomous  need instruction decreases time  disadvantage
lacks knowledge recognized reaching impasses  e g   impasse occur
performance correct inecient 
      flexibility knowledge content

exible tutorable agent must handle instruction events involving knowledge
applicable way within ongoing task discourse context  requirement
dicult meet general  wide range knowledge may relevant
particular situation  requires robust ability relate utterance ongoing
discourse task situation  instructable systems met requirement fully 
however  define constrained form requirement  limited instructions command actions  i e   imperatives   imperative commands especially
prevalent tutorial instruction procedures  supporting exible knowledge content
   systems learned purely observing expert  e g   dent  boticario  mcdermott  mitchell  
zabowski        redmond         observation type instructor initiatedness  instruction
interactive dialogue 

   

fiflexibly instructable agents

commands means allowing instructor give relevant command point
dialogue teaching task  call ability command exibility 
command given  three possibilities      commanded action
known  agent performs it      commanded action known  agent
know perform current situation  extra  unknown steps needed  
    commanded action unknown  thus  command exibility allows instructor
teaching procedure skip steps     command subtask unknown    
point  cases  agent asks instruction  interaction pattern
results  procedures commanded taught needed 
observed human instruction  wertsch        notes     adults spontaneously follow
communication strategy use directives children understand
guide children behaviors necessary carry directives  
command exibility gives instructor great exibility teaching set tasks instructions hierarchically structure tasks whatever way instructor
wishes  mathematical analysis  huffman        revealed number possible
sequences instructions used teach given procedure grows exponentially
number actions procedure  procedure   primitive actions 
    possible instruction sequences         
      situation flexibility

exible tutorable agent must handle instructions apply either current task
situation hypothetical situation instructor specifies  instructors make
frequent use options  instance  analysis protocol student
taught use ight simulator revealed         instructions       involved
hypothetical situations  remainder applying current situation time
given 
instructions apply current situation  imperative commands  e g  
 move yellow table    called implicitly situated  huffman   laird         since
instruction says nothing situation applied 
current situation  the task performed current state  implied 
contrast  instructions specify elements situation meant
apply explicitly situated  huffman   laird         agent meant carry
instructions immediately  as implicitly situated instruction   rather
situation arises one specified  examples include conditionals instructions
purpose clauses  dieugenio         following  


using chocolate chips  add coconut mixture pressing
pie pan 



restart this  hit r shift r 



get interval want  center joystick again 

   examples taken protocol tutorial instruction written source instruction  a
cookbook  

   

fihuffman   laird

number researchers pointed  ford   thompson        haiman       
johnson laird         conditional clauses introduce shared reference speaker
hearer forms explicit background interpreting evaluating consequent  
here  clauses italics indicate hypothetical situation command
remainder instruction meant apply  cases  situation partially
specified  remainder drawn current situation   when using chocolate
chips  and cooking recipe  current point process     
general  hypothetical situation may created referred across multiple
utterances  agent presented handles implicitly single explicitly situated
instructions  deal hypothetical situations exist multiple
instructions 

    producing general learning  transfer problem

transfer problem problem learning generally applicable knowledge instructions  transfer appropriate situations future  general learning
based instructions apply specific situations  property p   above   many types
knowledge may learned  since instructions provide type knowledge
agent lacking  property p   
solving problem involves simply memorizing instructions future use 
rather  conditions applying instruction must determined situation 
consider  example  following exchange instructor agent 
block open oce door 
that 
pick red block 
now  drop here  next door 
proper conditions performing  pick up  action  simple memorization yields poor learning  e g   whenever blocking open office door  pick
red block  however  block s color  even fact block  irrelevant case  rather  fact block weighs  say  five pounds 
giving enough friction oor hold open door  crucial  thus  proper
learning might be 
trying block open door 
object obj picked up 
obj weighs   pounds
propose picking obj 
here  original instruction generalized  color red isa block drop out 
specialized  weight     added  
transfer problem places number demands tutorable agent 
t   general learning specific cases  agent instructed particular
situation  expected learn general knowledge apply suciently
similar situations 
   types conditionals follow pattern  akatsuka         relevant
tutorial instruction 

   

fiflexibly instructable agents

t   fast learning  instructable agent expected learn new procedures quickly 
t  

t  
t  

t  

typically  task taught once 
maximal use prior knowledge  agent must apply prior knowledge
learning instruction  maxim machine learning systems general  if
knowledge  use it   particularly relevant learning instruction
learning expected happen quickly 
incremental learning  agent must able continually increase knowledge
instruction  new knowledge must smoothly integrated agent s
existing knowledge part ongoing performance 
knowledge type exibility  since type knowledge  e g   control knowledge 
causal knowledge  etc   might communicated instructions  exible tutorable
agent must able learn type knowledge uses  make testable
criterion laying types knowledge agent based particular
computational model 
dealing incorrect knowledge  agent s knowledge clearly incomplete
 otherwise  would need instruction   may incorrect  general tutorable agent must able perform learn effectively despite incorrect knowledge 

t   learning instruction coexisting learning sources 

addition instruction  complete agent able learn
sources knowledge available  might include learning observation demonstrations  experimentation environment  analogy  etc 
theory learning tutorial instruction presented focuses extending
incomplete knowledge instruction   requirements t  t  list  handling incorrect knowledge  t   learning sources  t   planned extensions
progress 
table   summarizes requirements must met instructable agent support exible tutorial instruction  indicates requirements targeted instructosoar  made two simplifications using requirements evaluate instructosoar  first  treat requirement binary  is  either completely met
unmet  reality  requirements could broken finer grained pieces evaluated separately  second  treat requirement independently  table indicates
instructo soar s performance requirement alone  account potential interactions them  interactions complex  instance 
pursuing fast learning  t    agent may sacrifice good general learning  t  
bases generalizations examples  addressed tradeoffs
evaluation instructo soar 

   related work

although extensive research agents learn tutorial instruction per se  learning instruction like input long time goal ai  carbonell 
   

fihuffman   laird

problem requirement
mapping m  mapping representable
information
interaction i  flexible initiation instruction
i  flexibility instructional knowledge
content
i  situation exibility
implicitly situated
explicitly situated single utterance
explicitly situated multiple utterance
transfer t  general learning specific cases

t 
t 
t 
t 
t 
t 

instructo soar 



 as needed show
capabilities 

 only agent initiated 
partial  command exibility 

partial
yes
yes

yes
 via situated explanation 
fast learning
yes
 new procedures
taught once 
maximal use prior knowledge
yes
incremental learning
yes
knowledge type exibility
yes
 learns pscm
knowledge types 
ability deal incorrect knowledge
 only extending incomplete knowledge 
learning instruction coexisting
 not demonstrated 
learning sources

table    requirements exible tutorable agent  instructo soar s performance them 
michalski    mitchell        mccarthy        rychener         early non interactive systems learned declarative  ontological knowledge language  haas   hendrix        lindsay         simple tasks unsituated descriptions  lewis  newell    polk        simon 
      simon   hayes         task heuristics non operational advice  hayes roth 
klahr    mostow        mostow        
work concentrated behaving based interactive natural language instructions  shrdlu  winograd        performed natural language commands small
amount rote learning   e g   learning new goal specifications directly transforming
sentences state descriptions  recent systems act response language
 concentrating mapping problem  minimal learning include sonja
 chapman         animnl  dieugenio   webber         homer  vere   bickmore 
      
recent work focused learning situated natural language instructions  martin firby        discuss approach interpreting learning
elliptical instructions  e g    use shovel   matching instruction expectations
generated task execution failure  alterman et al  s flobn  alterman  zito wolf   
carpenter        carpenter   alterman        searches instructions environment
   

fiflexibly instructable agents

order operate devices  flobn learns relating device s instructions known
procedures operating similar devices  systems target learning exible
interactive instructions types instructions imperatives  however 
bulk work learning instruction like input rubric
learning apprentice systems  lass   closely related programming by demonstration
 pbd  systems  cypher          employed  instance  recent work learning
within software agents  dent et al         maes        maes   kozierok        mitchell 
caruana  freitag  mcdermott    zabowski         systems learn interacting
expert  either observing expert solving problems  cypher        donoho   wilkins 
      mitchell et al         redmond        segre        vanlehn        wilkins        
attempting solve problems allowing expert guide critique decisions
made  golding et al         gruber        kodratoff   tecuci      b  laird
et al         porter  bareiss    holte        porter   kibler         las learned
particular types knowledge  e g   operator implementations  mitchell et al          goal
decomposition rules  kodratoff   tecuci      b   operational versions functional goals
 segre         control knowledge control features  gruber         procedure schemas  a
combination goal decomposition control knowledge   vanlehn         useful macrooperations  cypher         heuristic classification knowledge  porter et al         wilkins 
       etc 
tutorial instruction exible type instruction supported past
lass  three reasons  first  instructor may command unknown tasks tasks
unachieved preconditions agent instruction point  command exibility   past
lass limit input particular commands observations particular times  e g   commanding observing directly executable actions  typically allow unknown
commands all  second  tutorial instruction allows use explicitly situated instructions  situation exibility   teach contingencies may present
current situation  past lass not  third  tutorial instruction requires types
task knowledge learned  knowledge type exibility   past lass learn subset
types knowledge use perform tasks 

   theory learning tutorial instruction

theory learning tutorial instruction consists learning framework  situated
explanation  placed within computational model general agenthood  problem space
computational model  first describe computational model learning
framework 

    problem space computational model

computational model  cm   a set operations entities interpreted
computational terms   newell et al         p      computational model general
instructable agent must meet two requirements 
   support general computation agenthood 
   close correspondence knowledge level  tutorial instructions
provide knowledge knowledge level  newell         cm com   

fihuffman   laird

ponents knowledge level  dicult mapping learning
instructions be  addition  close correspondence knowledge level
allow us use cm identify types knowledge agent uses 
many potential cms ruled requirements  standard programming languages  e g   lisp  theoretical cms turing machines push down automata
support general computation  operations constructs symbol level 
without direct correspondence knowledge level  similarly  connectionist neural
network models computation  e g   rumelhart   mcclelland        employ  by design 
computational operations entities level far knowledge level  thus 
models appropriate top level cm instructable agent  however  higher levels description computational system implemented lower levels
 newell         cms might used implementation substrate higher
level cm instructable agent 
another alternative logic  entities well matched knowledge
level  e g   propositions  well formed formulas   logics specify set legal operations
 e g   modus ponens   thus defining space possibly computed  however 
logic provides notion computed  is  logics alone specify
control logical operations  application  desirable cm instructable
agent include control knowledge  control knowledge crucial type knowledge
general agenthood  communicated instructions 
since one goals identify agent s knowledge types  might appear
selecting theory knowledge representation would appropriate selecting
computational model  theories define functions structures used represent knowledge  e g   kl one  brachman         define possible content
structures  e g   conceptual dependency theory  schank        cyc  guha   lenat 
       however  computational structure must added theories produce working agents  thus  rather alternative specifying computational model  theory
knowledge representation addition  content theory knowledge representation would provide fine grained breakdown knowledge learned
instructable agent within category knowledge specified cm 
employed particular content theory work thus far  however 
computational model adopted called problem space computational model
 pscm   newell et al         yost         pscm general formulation computation knowledge level agent  many applications built within  rosenbloom  laird    newell      a   specifies agent terms computation within
problem spaces  without reference symbol level structures used implementation 
components approximate knowledge level  newell et al          pscm
apt choice identifying agent s knowledge types  soar  laird  newell    rosenbloom        symbol level implementation pscm 
schematic pscm agent shown figure    perception motor modules
connect agent external environment  pscm agent reaches goal moving
sequence states problem space  progresses toward goals sequentially
applying operators current state  operators transform state  may produce
motor commands  pscm  operators powerful simple strips operators
 fikes  hart    nilsson         perform arbitrary computation  e g  
   

fiflexibly instructable agents

external environment

perceptual modules

motor modules

figure    processing pscm based agent  triangles represent problem spaces 
squares  states  arrows  operators  ovals  impasses 
include conditional effects  multiple substeps  reactivity different situations  etc   
pscm agent reaches impasse immediately available knowledge
sucient either select fully apply operator  occurs  another problem
space context   subgoal   created  goal resolving impasse  second
context may impasse well  causing third context arise  on 
computational entities pscm mediated agent s knowledge
states operators  small set basic pscm level operations entities
agent performs 
   state inference  simple monotonic inferences always applied
made without using pscm operator  inferences augment agent s representation state inferring state properties based state properties
 including delivered perception   instance  agent might know
block held gripper closed positioned directly block 
   operator selection  agent must select operator apply  given current
state  process involves two types knowledge 
     proposal knowledge  indicates operators deemed appropriate current situation  knowledge similar  precondition  knowledge simple strips
operators 
     control knowledge  orders proposed operators  e g    a better b    c
best    d rejected  
   

fihuffman   laird

   operator application  selected  operator may applied directly 
indirectly via subgoal 
     operator effects  operator applied directly current problem space 
agent knowledge effects operator state motor
commands produced  if any  
     sub operator selection  operator applied reaching impasse selecting operators subgoal  here  knowledge apply operator selection
knowledge     above  sub operators 
   operator termination  operator must terminated application
completed  termination conditions  goal concept  mitchell et al         
operator indicate state conditions operator meant achieve 
example  termination conditions pick up blk  might blk held
arm raised  
functions performed agent using knowledge  thus  define set
knowledge types present within pscm agent  knowledge types  five types total 
summarized table    soar implementation pscm  knowledge
within soar agents types 
soar s implementation pscm  learning occurs whenever results returned
subgoal resolve impasses  learning process  called chunking  creates rules
 called chunks  summarize processing subgoal leading creation
result  depending type result  chunks may correspond five types
pscm knowledge  similar situations arise future  chunks allow impasse
caused original subgoal avoided producing results directly  chunking
form explanation based learning  rosenbloom   laird         although
summarization mechanism  taking inductive deductive steps subgoals 
chunking produce inductive deductive learning  miller        rosenbloom
  aasman         chunking occurs continuously  making learning part ongoing
activity soar pscm agent 
pscm clarifies task instructable agent  must able learn
five types pscm knowledge instruction  next section discusses learning
process itself 

    learning instructions situated explanation

learning instruction involves analytic learning  learning based prior knowledge  inductive learning  going beyond prior knowledge   analytic learning needed
agent must learn instructions combine known elements   e g   learning pick objects combining known steps pick particular object  agent s
prior knowledge elements used produce better faster learning  inductive learning needed agent must learn new task goals domain knowledge
   pscm operators explicit termination knowledge string conditional
effects take place time  respond  or wait for  external environment  etc 
strips operators  contrast  need explicit termination knowledge  defined
single list effects   terminated  definition applying effects 

   

fiflexibly instructable agents

entity knowledge type example
state
inference
gripper closed   directly obj   holding obj 
operator proposal
goal pick obj table x  docked tablex  propose moving table x 
operator control
goal pick small metal obj table x  prefer moving table x fetching magnet 
operator effects
effect operator move table x robot
becomes docked table x 
operator termination
termination conditions pick obj gripper
raised   holding obj 
table    five types knowledge pscm agents 
beyond scope prior knowledge  goal research produce
powerful analytic inductive techniques  rather specify techniques
come together produce variety learning variety instructional situations faced
instructable agent  resulting approach called situated explanation 
instruction requirements t  t  specify general learning  t   must occur
single  specific examples  t    making maximal use prior knowledge  t   
requirements bode strongly learning approach based explanation  use
explanation produce general learning common theme machine learning  e g  
dejong   mooney        fikes et al         minton  carbonell  knoblock  kuokka  etzioni 
  gil        rosenbloom  laird    newell        schank   leake        many others 
cognitive science  anderson        chi  bassok  lewis  reimann    glaser        lewis 
      rosenbloom   newell         forming explanations enables general learning
specific cases  requirement t   explanation indicates features case
important generalized  learning explaining typically requires
single example  requirement t   prior knowledge employed construct
explanation  requirement t   provides strong bias allows fast learning 
thus  use explanation based method core learning instruction approach  fall back inductive methods explanation fails  standard
explanation based learning  explaining reasoning step involves forming  proof   using
prior knowledge  step leads current state reasoning toward current
goal  proof path reasoning current state goal  step
explained  diagrammed figure    general learning produced forming
rule includes causally required features state  goal  step appearing
proof  features appear generalized away 
figure   indicates three key elements explanation  step explained 
endpoints explanation  a state goal g reached   steps
required complete explanation  form elements explanation take
situated explanation instruction 


step explained  situated explanation  step explained individual
instruction given agent 
   

fihuffman   laird

reasoning step
explained
 indicated instruction i 

steps  agents knowledge

   



g

 mk  

figure    caricature explanation reasoning step applies situation starting
state   goal g achieved 





alternatively  entire instruction episode   e g   full sequence instructions
new procedure   could explained once  applying explanation single steps
results knowledge applicable step  as golding et al         laird et al  
       explaining full sequences reasoning steps results learning schemas
encode whole reasoning episode  as mooney        schank   leake        vanlehn         learning factored pieces knowledge rather monolithic schemas
allows reactive behavior  since knowledge accessed locally based current situation  drummond        laird   rosenbloom         meshes
pscm s local control structure  explaining individual instructions supported
psychological results self explanation effect  shown subjects
self explain instructional examples re deriving individual lines example   students virtually never ect overall solution try recognize
plan spans lines   vanlehn jones        p       
endpoints explanation  endpoints explanation   state goal g
achieved   correspond situation instruction applies to  situation
exibility  requirement i    stipulates situation may either current
state world goal pursued hypothetical situation specified explicitly instruction  instruction specify situational
features implicitly situated  applies agent s current situation  alternatively  instruction specify features g  making two kinds explicitly
situated instructions  example   if light on  push button  indicates
hypothetical state light on   to turn machine  ip switch  indicates
hypothetical goal turning machine  situation  s  g  produced
instruction  based current task situation situation features
instruction specifies 
required steps  complete explanation instruction  agent must
bring prior knowledge bear complete path instruction
achievement situation goal  pscm agent s knowledge applies current
situation select apply operators make inferences  explaining
instruction   knowledge applied internally situation  s  g  associated
  is  explanation takes form forward internal projection within
situation  depicted figure    agent  imagines  state  
runs forward  applying instructed step knowledge
subsequent states operators  knowledge includes normally used
   

fiflexibly instructable agents

external world knowledge operators  expected effects used
produce effects projected world  g reached within projection 
projected path   step instructed   g comprises
explanation   indicating features     g causally required
success  explanation allows agent learn general knowledge  as
standard ebl  realized agent soar s chunking mechanism  rosenbloom  
laird         however  agent s prior knowledge may insucient  causing
incomplete explanation  described below 
combining elements produces approach learning tutorial instruction
conceptually quite simple  instruction received  agent first
determines situation meant apply to  attempts explain
step indicated leads goal achievement situation  or prohibits it  negative
instructions   explanation made  produces general learning knowledge
ik indicating key features situation instruction cause success 
explanation cannot completed  indicates agent missing one
pieces prior knowledge mk  of pscm type  needed explain instruction 
missing knowledge  in figure    missing arrows  causes incomplete explanation precluding achievement g projection  instance  agent may know key
effect operator  crucial state inference  needed reach g  radically 
action commanded may completely unknown thus inexplicable 
shown figure    four general options learning agent might follow
cannot complete explanation   o   could delay explanation later 
hope missing knowledge  mk   learned meantime  alternatively 
 o  o   could try complete explanation somehow learning missing
knowledge  missing knowledge could learned  o   inductively  e g   inducing
 gap  explanation  described vanlehn  jones   chi        many
others   or   o   instructable agent s case  instruction  finally   o  
could abandon explanation altogether try learn desired knowledge another
way instead 
given incomplete explanation  would dicult choose option
follow  identifying missing knowledge mk general case dicult credit assignment problem  with algorithmic solution   nothing incomplete
explanation predicts whether mk learned later explanation delayed  thus  past machine learning systems responded incomplete explanations
either single way  multiple ways  tried fixed sequence 
many authors  bergadano   giordana        hall        vanlehn        vanlehn  jones 
  chi        widmer         instance  describe systems make inductions complete incomplete explanations  option o    diculty determining missing
knowledge  systems either base induction multiple examples  and or bias
induction underlying theory teacher s help  sierra  vanlehn        
example  induces multiple partially explained examples  constrains induction
requiring examples unexplainable piece missing knowledge  the disjunct  sierra s terminology   swale  schank   leake 
      uses underlying theory  anomalies  explanations complete incomplete explanations events  occam  pazzani      b  uses options o  o  static order 
   

fihuffman   laird

delay explanation mk learned

o 

delay 


instruction
context








g

incomplete explanation
 missing knowledge mk 





k

g

learn mk inductively complete explanation

o 
k

k

 

induce





g


k

learn mk instruction complete explanation

o 









k

g



g

abandon explanation  learn another way 

o 







k

g

figure    options faced incomplete explanation missing knowledge
mk  
first attempts fill gaps incomplete explanation inductively  biased
naive theory  fails  abandons explanation falls back correlational learning
methods  pet  porter   kibler        example system delays explanation
reasoning step learns knowledge  option o   
however  indicated figure    instructable agent additional information
available besides incomplete explanation itself  namely  instructional context
 that is  type instruction place within dialogue  often indicates
option appropriate given incomplete explanation  thus  situated explanation includes four options dynamically selects based
instructional context  situated explanation instruction situation  s  g  
missing knowledge mk precludes completing explanation learn knowledge ik  
options o  o  take following form 

o   delay explanation later  instructional context indicate likelihood missing knowledge mk learned later  instance  instruction
given teaching new procedure cannot immediately explained re 

maining steps procedure unknown  known later  assuming
instructor completes teaching procedure   cases  agent discards
current  incomplete explanation simply memorizes  s use  s  g   rote learning   later  mk learned  recalled explained  s  g   causing ik
learned 
   

fiflexibly instructable agents

given instruction knowledge ik learned 
determine situation  s  g   current hypothetical  applies

explain  s  g  forward projecting      g
  success  g met   learn ik complete explanation   ebl  
  failure  missing knowledge mk   options 
o   delay explanation later 
o   induce mk   completing explanation 
o   take instruction learn mk   completing explanation 
o   abandon explanation  instead  learn ik inductively 
table    situated explanation 

o   induce mk   completing explanation  cases  instructional context
localizes missing knowledge mk part particular operator  instance 

purpose clause instruction   to x  y   suggests single operator
cause x occur  localization tightly constrains  gap 
incomplete explanation  agent use heuristics induce strong guess
mk needed span gap  inducing mk allows explanation
completed ik learned 
o   take instruction learn mk   completing explanation  default response agent  when options deemed appropriate  ask
instructor explain further  instruction teach agent mk  
again  learning mk allows explanation completed ik learned 
o   abandon explanation learn ik another way  instructional
context indicate missing knowledge mk would dicult learn 
occurs either instructor refuses give information asked
to  agent projected multiple operators may missing pieces
knowledge  multiple potential mk s   since unknown whether mk ever
acquired  agent abandons explanation altogether  instead  attempts
learn ik directly  using inductive heuristics   without explanation base
learning on 
options made clearer examples presented following sections 
situated explanation summarized table    unlike knowledge acquisition approaches  include explicit check consistency newly learned knowledge
added agent s knowledge base  kodratoff tecuci      a  point out  techniques situated explanation biased toward consistency acquire
new knowledge current knowledge insucient  use current knowledge
deriving new knowledge  however  domains  explicit consistency checks  such
used wilkins         odysseus  may required 
situated explanation meets requirement learning incremental  t  
occurs ongoing processing agent adds new pieces knowledge
   

fihuffman   laird

t 
t 
t 
t 
t 

i 
i 

general learning specific cases
fast learning  each task instructed once 
maximal use prior knowledge
incremental learning
knowledge type exibility
a  state inference
b  operator proposal
c  operator control
d  operator effects
e  operator termination
command exibility
a  known command
b  skipped steps
c  unknown command
situation exibility
a  implicitly situated
b  explicitly situated  hypothetical state
hypothetical goal

table    expanded requirements tutorial instruction met instructo soar 
agent s memory modular way  local control structure pscm allows new
knowledge added independent current knowledge  con ict
pieces knowledge  for example  proposing two different operators situation  
impasse arise reasoned resolved instruction 

  

instructo soar

instructo soar instructable agent built within soar   thus  pscm  
uses situated explanation learn tutorial instruction   instructo soar engages

interactive dialogue instructor  receiving natural language instructions
learning perform tasks extend knowledge domain  section
next describe instructo soar meets targeted requirements tutorial instruction 
shown expanded form table    section describes system s basic
performance learning new procedures  extending procedures new situations 
imperative commands  implicitly situated instructions   next describes learning
types knowledge handling explicitly situated instructions 

   overview soar  systems built within it  see  rosenbloom  laird    newell      b  

   

fiflexibly instructable agents

figure    robotic domain instructo soar applied 

    domain agent s initial knowledge
primary domain instructo soar applied simulated robotic
world shown figure     agent simulated hero robot  room tables 
buttons  blocks different sizes materials  electromagnet  light  magnet
toggled closing gripper around it  red button toggles light off  green
button toggles dim bright  on 
instructo soar consists set problem spaces within soar contain three
main categories knowledge  natural language processing knowledge  originally developed
nl soar  lewis         knowledge obtaining using instruction  knowledge task domain itself  task knowledge extended learning
instruction  instructo soar expand natural language capabilities per se
takes instruction  although learn sentences map onto new operators
learns  complete  noiseless perception world  recognize set basic
object properties  e g   type  color  size  relationships  e g   robot docked at table 
   techniques applied limited way ight domain  pearson  huffman  willis 
laird    jones         soar controls ight simulator instructions given taking off 

   

fihuffman   laird

pick red block 
move yellow table 
move arm red block 
move up 
move down 
close hand 
move up 
operator finished 

figure    instructions given instructo soar teach pick block 
gripper holding object  objects above  directly above  left of  right of one another  
set properties relations extended instruction  described below 
agent begins knowledge set primitive operators map
natural language sentences  execute  include moving tables  opening
closing hand  moving arm up  down  above  left of  right things 
agent internally project operators  however  effects
various conditions unknown  instance  agent know operators
affect light magnet  magnet attract metal objects  also  agent
begins knowledge complex operators  that involve combinations primitive
operators   picking arranging objects  pushing buttons  etc 

    learning new procedures delayed explanation
instructo soar learns new procedures  pscm operators  instructions

shown figure    picking block  since  pick up  known procedure
initially  told  pick red block   agent realizes must learn new
operator 
perform pscm operator  operator must selected  implemented  terminated  select operator future based command requires knowledge
operator s argument structure  a template   natural language maps
structure  thus  learn new operator  agent must learn four things 
   template  knowledge operator s arguments instantiated 
picking blocks  agent acquires new operator single argument 
object picked up 
   mapping natural language  mapping natural language semantic
structures instantiation new operator  operator selected
commanded future  picking blocks  agent learns map
semantic object  pick      single argument new operator template 
   implementation  perform operator  new operators performed
executing sequence smaller operators  implementation takes form
selection knowledge sub operators  e g   move proper table  move
arm  etc  
   

fiflexibly instructable agents

   termination conditions  knowledge recognize new operator achieved
  goal concept new operator   pick up   termination conditions
include holding desired block  arm raised 
requirement t    fast learning   stipulates first execution new procedure  agent must able perform least task without re instructed 
thus  agent must learn  form  four parts new operator
first execution 
general implementation new operator learned situated explanation
steps  first execution new operator  though  instructions
performing cannot explained  agent yet know goal
operator  e g   agent know termination conditions  pick up  
steps following current one reach goal  however  instructional context
  explaining instructed steps procedure learned   clear missing
knowledge remaining steps procedure s goal acquired later 
instructor expected teach procedure completion  thus  agent delays
explanation  option o   memorizes implementation instruction rote 
episodic form  end first execution new procedure  agent induces
procedure s goal   termination conditions   using set simple inductive heuristics 
later executions procedure  original instructions recalled explained
learn general implementation 
describe details process using  pick up  example 
      first execution

example  shown figure    begins instruction  pick red block  
agent comprehends instruction  producing semantic structure resolving  the red
block  block environment  however  semantic structure correspond
known operator  indicating agent must learn new operator  which
calls  say  new op     learn template new operator  agent simply assumes
argument structure command used request operator required
argument structure operator itself  case  template new operator
generated argument structure directly corresponds semantic arguments
 pick up  command  here  one argument  object   agent learns mapping
semantic structure new operator s template  used presented
similar requests future  simple approach learning templates mappings
sucient imperative sentences direct arguments  fail commands
complex arguments  path constraints   move dynamite room 
keeping far heater possible   
next  new operator selected execution  since implementation unknown 
agent immediately reaches impasse asks instructions  instruction
figure   given  comprehended executed turn  instructions provide
implementation new operator  implicitly situated   applies
current situation agent finds itself 
point  agent may given another command cannot directly completed   one requests either another unknown procedure known procedure
   

fihuffman   laird

instruction
explained

steps

   



 
 
 

g 

figure    instructions teaching new operator cannot explained termination
conditions new operator learned 
agent know perform current situation due skipped steps 
command exibility  requirement i    example  within instructions  pick up  
command  move red block  cannot completed skipped step
 the arm must raised move something   impasse arises instructor
indicates needed step   move up    continues instructing  pick up  
ultimately  implementation new operator learned proper level
generality explaining instructed step  however  illustrated figure   
initial execution forming explanation impossible  goal new
operator steps  further instructions  needed reach yet known 
since missing pieces explanation expected available later  agent
delays explanation resorts rote learning instructed step 
instructo soar  rote learning occurs side effect language comprehension 
reading sentence  agent learns set rules encode sentence s
semantic features  rules allow nl soar resolve referents later sentences  implementing simple version grosz s focus space mechanism  grosz         rules record
instruction  indexed goal applies place instruction
sequence  result essentially episodic case records specific  lock step sequence instructions given perform new operator  instance  recorded
 to pick up  that is  new op    red block  rb   first told move yellow table  yt    course  information contained within case could generalized 
point generalization would purely heuristic  agent cannot
explain steps episode  thus  instructo soar takes conservative approach
leaving case rote form 
finally  agent told  the operator finished   indicating goal
new operator achieved  instruction triggers agent learn termination
conditions new operator  learning termination conditions inductive concept
formation problem  agent must induce features hold current
state imply positive instance new operator s goal achieved  standard concept
learning approaches may used here  long produce strong hypothesis within
small number examples  due  fast learning  requirement  t    instructo soar
uses simple heuristic strongly bias induction  hypothesizes everything
changed initial state new operator requested current
state part new operator s termination conditions  case  changes
robot docked table  holding block  block gripper
air 
   

fiflexibly instructable agents

heuristic gives reasonable guess  clearly simple  conditions
changed may matter  e g   perhaps doesn t matter picking blocks
robot ends table  unchanged conditions may matter  e g   learning build
 stoplight   block colors important although change  thus  agent
presents induced set termination conditions instructor possible alteration
verification  instructor add remove conditions  example   pick
up  case instructor might say  the robot need docked yellow table 
remove condition deemed unnecessary  verifying termination conditions 
instructo soar performs induction ebl  chunking  overgeneral theory
make inductive leaps  similar to  e g   miller        rosenbloom   aasman       
vanlehn  ball    kowalski         type inductive learning advantage
agent alter bias ect available knowledge  case  agent
uses instruction  the instructor s indications features add remove  alter
induction  knowledge sources could employed  but current
implementation  include analogy known operators  e g   pick actions
domains   domain specific heuristics  etc 
first execution new operator  then  agent 
carries sequence instructions achieving new operator 
learns operator template new operator 
learns mapping natural language new operator 
learns rote execution sequence new operator 
learns termination conditions new operator 
since agent learned necessary parts operator  able
perform task without instruction  however  since implementation
operator rote  perform exact task  learned generally
pick things yet 
      generalizing new operator s implementation

agent knows goal concept full  though rote  implementation sequence
new operator  thus  information needs explain instruction
implementation sequence leads goal achievement  provided underlying domain
knowledge sucient 
instruction explained recalling episodic memory internally projecting effects rest path achievement termination conditions
new operator  projection  proof  instructed operator lead
goal achievement situation  soar s chunking mechanism essentially computes
weakest preconditions situation instruction required success  similar
standard ebl  form general rule proposing instructed operator  rule learned
instruction  move yellow table  shown figure    rule generalizes
original instruction dropping table s color  specializes adding facts
table object sitting object small  only small objects
   

fihuffman   laird



goal new op     obj  
 obj table  t  small  obj  
robot docked  t 
gripper status open  
propose operator move to table  t  
figure    general operator proposal rule learned instruction  move
yellow table   new op    newly learned  pick up  operator  
grasped gripper   rule tests gripper open 
condition important grasping block instructed case  
learning general proposal rules step instruction sequence  agent
perform task without reference rote case  instance  asked  pick
green block   agent selects new op    instantiated green block  then 
general sub operator proposal rules one figure   fire one one  match
current situation  implement operator  performing implementation
steps  agent recognizes termination conditions met  the gripper raised
holding green block   new op   terminated 
since general proposal rules implementing task directly conditional
state  agent perform task starting state along implementation
path react unexpected conditions  e g   another robot stealing block  
contrast  rote implementation initially learned applied starting
original starting state  reactive steps conditional
current state 

    recall strategies

described agent recalls explains step new operator s implementation sequence  operator s termination conditions induced 
still two open issues   a  point learning termination conditions
agent perform recall projection    b  many steps recalled
projected sequence time 
investigate issues  implemented two different recall project strategies 
   immediate complete recall  agent recalls attempts explain full
sequence instructions new operator immediately learning new
operator s termination conditions 
   lazy single step recall  agent recalls attempts explain single instructions sequence asked perform operator starting
initial state  is  point execution operator  agent
   technical details soar s chunking mechanism forms rules found  huffman 
      laird  congdon  altmann    doorenbos        

   

fiflexibly instructable agents

recalls next instruction  attempts explain forward projecting it  however  projection result path goal achievement without
instructions recalled  rather recalling next instruction
sequence continue forward projection  agent gives explaining
instruction simply executes external world 
strategies represent extremes continuum strategies    strategy
use parameter agent  dynamically select strategies
running  possible extension would reason time pressure different
situations select appropriate strategy  next  brie describe implications
recall strategy 
      immediate complete recall strategy

immediate complete recall explanation involves internally projecting multiple operators
 the full instruction sequence  immediately first execution new operator 
projection begins state agent new operator first suggested 
projection successfully achieves termination conditions new operator 
agent learns general implementation rules every step  advantage strategy
agent learns general implementation new operator immediately
first execution  e g   agent pick objects right away  
strategy three important disadvantages  first  requires agent reconstruct initial state commanded perform new operator 
reconstruction may dicult amount information state large  although
small robotic domain used here  
second  recall projection entire sequence instructed steps time consuming 
requiring time proportional length instruction sequence  process 
agent s performance tasks hand suspended  suspension could awkward
agent pressure act quickly 
third  illustrated figure    multiple step projections susceptible compounding errors underlying domain knowledge  projection successive operator
begins state ects agent s knowledge effects prior operators
sequence  knowledge incomplete incorrect  state move
ecting actual effects prior operators  minor domain knowledge problems knowledge individual operators  alone would produce error
single step explanation  may combine within projection cause error 
lead incomplete explanations  more rarely  spuriously successful explanations  e g  
reaching success early instruction sequence  
      lazy single step recall strategy

lazy single step recall strategy  agent waits recall explain instructions
asked perform new operator second time initial state  addition 
agent recalls single instruction internally project time  recalled
    implemented lazy complete recall strategy  described  see huffman 
      details  

   

fihuffman   laird

opx
op 

s 

op 

op 

s 
s 

op 

s 

   

g tc

opx

internally projected path
 reflecting agents incorrect
knowledge operator effects 

sx

states reflecting
actual operator effects

sx

states reflecting
projected operator effects

g tc

state meets
termination conditions
current goal

op 

s 
op 

    sn    g  
tc

correct path  reflecting
actual operator effects 

figure    multiple step projections result incomplete explanations due compounding errors domain knowledge 
operator projected  agent applies whatever general knowledge rest
implementation new operator  general knowledge  however 
include rote memories past instructions  is  agent know
rest path complete new operator using general knowledge  recall
instructions sequence rote memories  rather  internal projection
terminated single recalled operator applied external world 
strategy addresses three disadvantages immediate complete strategy 
first  require reconstruction original instruction state  rather  waits
similar state occur again 
second  recalling projecting single instruction time require timeconsuming introspection suspends agent s ongoing activity   pick up  
instance  table   shows longest time agent s external action  movements
instruction requests  suspended using strategy  as measured soar decision cycles 
last    milliseconds instructo soar sgi r     indigo  
immediate complete strategy external actions     decision cycles  about
   seconds indigo  immediately following first execution  order recall
explain complete instruction sequence  using lazy single step strategy 
one instruction ever recalled explained time action taken world 
thus  longest time without action    decision cycles  about   seconds  
total recall explanation time proportional length instruction sequence
cases      vs      decision cycles   lazy single step strategy  time
interleaved execution instructions rather fully taken first
execution 
third  lazy single step strategy overcomes problem compounding domain
theory errors beginning projection instruction current state
world external execution previous instructions  thus  beginning state
projection correctly ects effects previous operators implementation
sequence 
major disadvantage strategy requires number executions
new operator equal length instruction sequence order learn whole
   

fiflexibly instructable agents

immediate complete lazy single step
largest time without external action    
  
largest total recall explanation time      end  st exec n       during  nd exec n  
execution

decision cycles  log scale 

table    timing comparison  soar decision cycles  learning  pick up  using immediate complete lazy single step recall strategies 
    

 r        
 r        

    

   

   

  
 

  

execution number  log scale    pick up 
 a 

 

  

execution number  log scale    move left of 
 b 

figure     decision cycles versus execution number learn  a  pick  b  move
objects left one another  using lazy single step strategy 
general implementation  limiting recall single step allows single
sub operator per execution generalized  disadvantage  however  leads two
interesting learning characteristics 
back to front generalization  generalized learning starts end implementation sequence moves towards beginning  second execution
new operator  path goal known last instruction sequence
 it leads directly goal completion   general proposal instruction
learned  third execution  second last instruction projected 
proposal learned previously last operator applies  leading goal achievement
allowing general proposal second last instruction learned 
pattern continues back entire sequence full implementation
learned generally  figure    shows  resulting learning curves closely approximate power law practice  rosenbloom   newell         r         a 
 b   
effectiveness hierarchical instruction  due back to front effect 
agent learns new procedure quickly steps taught using hierarchical organization taught sequence  figure    depicts
at  nine step instruction sequence teaching instructo soar move one block
   

fihuffman   laird

 
move left of block  block  

 

 

 

move arm

move table  table 
 

graphical

  

moveleftof arm block  

 

 

move  block 

figure    

 

move arm

close gripper

view

move arm

move table  table 





move left of block block   

open gripper

 



instruction

sequence



 
move left of block  block  

 

  

 
moveleftof arm block  

pick  block 

put  block 

  
move table  table 
 

 
move table  table 

 

 

 
move  block 

figure    

  
move arm

grasp  block 

graphical

move arm

  
open gripper

 
move arm

view

close gripper



hierarchical instruction sequence
move left of block block    new operators shown bold 



left another  figure    depicts hierarchical instruction sequence procedure  contains    instructed steps  maximum   subsequence 
breaking instruction sequence shorter subsequences  hierarchical organization allows multiple subtrees hierarchy generalized execution 
general learning n step operator takes n executions using
instruction
hpn subtasks
sequence  taught hierarchically


h
 level
hierarchy

p
subsequence  h h n executions required full generalization  hierarchy figure    irregular structure  results apspeedup
length every subsequence small  in case  smaller n    empirically 
sequence figure    takes nine  n   executions generalize  whereas hierarchical sequence takes six  hierarchical organization additional advantage
operators learned used future instructions 
   

fiflexibly instructable agents

    supporting command flexibility

command exibility  requirement i    stipulates instructor may request either
unknown procedure  known procedure agent know perform
current state  skipping steps   point  lead multiple levels embedded
instruction  seen  instructo soar learns completely new procedures
instructions unknown commands  addition  agent asked perform
known procedure unfamiliar situation   one agent know
step take   learns extend knowledge procedure situation 
example contained instructions  pick red block   agent
asked  move red block   agent knows perform operator
arm raised  however  case arm lowered  agent reaches
impasse asks instruction    told  move up   agent internally
projects raising arm  allows achieve moving red block 
projection learns general rule  move arm trying move object
table agent docked at  rule extends  move above  procedure
cover situation 
operator   even one previously learned instruction   may require extension
apply new situation  agent learns general implementation
new operator  reason possible situations operator
might performed  limits explanations series situations arises
actual execution new operator learned 
newly learned operators may included instructions later operators  leading
learning operator hierarchies  one hierarchy operators learned instructo soar
shown figure     learning procedural hierarchies identified fundamental
component children s skill acquisition tutorial instruction  wood  bruner    ross 
       learning hierarchy figure     instructo soar learned four new operators  extension known operator  move above   extension new operator
 extending  pick up  work robot already holding block   command
exibility  hierarchy taught exponentially many different ways  huffman         instance  new operators appear sub operators  e g   grasp 
taught either teaching higher operators  e g   pick up  

    abandoning explanation domain knowledge incomplete

general operator implementation learning described thus far depends explaining
instructions using prior domain knowledge  as opposed learning operator termination conditions  inductive   domain knowledge incomplete  making
explanation impossible  sequences multiple operators  pinpointing knowledge
missing extremely dicult credit assignment problem  sequences known contain
one operator  however  constrained case  described next section  
    another option would search  i e   apply weak method means ends analysis 
example  search would easy  cases  could costly  event  since goal
instructo soar investigate use instruction  agent always asks instructions
reaches impasse task performance  nothing instructo soar precludes use search
knowledge sources  however 

   

fihuffman   laird

lineup block  block  block  

move left of block  block  

pick  block 

move arm

moveleftof arm block  

move table  table 

grasp  block 

put  blockx 

move left of block  block  

put  block 

move arm

 lg  metal 

open gripper
grasp  magnet 

move  block 

move arm

 small 

move table  table 

move  blk mag 

move arm

close gripper

move arm

figure     hierarchy operators learned instructo soar  primitive operators
light print  learned operators bold 
general  explanation failure detected end projection instruction sequence could caused missing knowledge operator sequence 
thus  faced incomplete explanation sequence multiple instructions 
instructo soar abandons explanation instead tries induce knowledge directly
instructions  option o   
example  consider case instructo soar s knowledge secondary operator effects  frame axiom type knowledge  removed teaching procedure  example  although agent knows closing hand causes
status closed  longer knows closing hand around block causes block
held  now  agent taught new procedure  pick red block 
first execution  agent attempts recall explain instructions usual 
fails missing knowledge  is  block picked
projection instructions  since agent s knowledge indicate held 
agent records fact procedure s instructions cannot explained 
later  agent asked perform procedure  recalls instructions  however  recalls explaining instructions failed past  thus 
abandons explanation instead attempts induce general proposal rule directly
instruction   
    since incomplete explanation procedure may indicate effect s  operator
instruction sequence unknown  another alternative  not yet implemented instructo soar  would
agent observe effects operator sequence performed  comparing
observations effects predicted domain knowledge  differences would allow agent

   

fiflexibly instructable agents

g  newop     pick up  
object   redblock 

 redblock   yellowtable 

op  movetotable
destination   yellowtable 

figure     use op to g path heuristic  op  move yellow table  
g  pick red block  
 pick up  example  agent first recalls command move yellow
table  learn proposal rule operator  call op    agent must induce set
conditions state performing op contribute achieving  pick
up  goal  call g   instructo soar uses two simple heuristics induce state
conditions 
op to g path  object obj   filling slot op   object obj  
attached g  include shortest existing path  heuristically length less
three  relationships obj   obj   set induced conditions 
heuristic captures intuition operator involves object 
relationship objects relevant goal probably important  figure   
shows operation  move yellow table   figure indicates 
path g s object  red block  destination op   yellow table 
relationship block table 
op features unachieved  termination condition  essentially  primary
effect  op achieved state op performed considered
important condition 
heuristic captures intuition primary effects op probably
important  therefore  matters achieved op selected 
example  op  s primary effect robot ends docked table  thus 
fact robot initially docked table added inferred set
conditions proposing op  
heuristics implemented soar operators compute appropriate conditions  set conditions induced  presented instructor  add
remove conditions verifying them  upon verification  rule learned proposing op
 e g   move to table  t   induced conditions hold  e g   goal pick up  b  
 b isa block  on  b  t    rule similar rule learned explanation  figure     applies picking block  overspecific   stipulate
learn new operator effects could complete explanation procedure  learning effects
operators observation explored number researchers  carbonell   gil       
pazzani      b  shen        sutton   pinette        thrun   mitchell        

   

fihuffman   laird

object must small  overgeneral   similar induction occurs step  pick up  
agent learns general implementation full  pick up  operator  however 
unless corrections made instructor  induced implementation correct
one learned explanation  instance  applies  wrongly  block instead
small object  complex domain  inferring implementation rules would
even less successful  surprisingly  psychological research shows human subjects 
learning procedural instructions degrades lack domain knowledge  kieras
  bovair        
returning targeted instruction requirements table    instructo soar s learning procedures illustrates  t   general learning specific instructions   t   fast learning  because procedure need instructed once   t   using prior domain
knowledge construct explanations   t   incremental learning agent s ongoing performance  two types pscm knowledge learned   t  b   operator proposals
sub operators procedure   t  e   procedure s termination conditions 
learning involves either delayed explanation  domain knowledge inadequate 
abandoning explanation favor simple induction  instructions  i   a   implicitly situated imperative commands  either  i  a   known procedures   i  b   known
procedures steps skipped   i  c   unknown procedures 

   beyond imperative commands

next  turn learning remaining types pscm knowledge  t  a c d   various
kinds explicitly situated instructions  i  b    explicitly situated instruction 
instructo soar constructs hypothetical situation  goal state  includes
objects  properties  relationships mentioned explicitly instruction well
features current situation needed carry instruction   
hypothetical situation used context situated explanation instruction 

    hypothetical goals learning effects operators

goal explicitly specified instruction purpose clause  dieugenio          to
x  y   basic knowledge learned instruction operator
proposal rule goal achieve x 
consider example instructo soar s domain 
  turn light  push red button 

agent taught push buttons  know red button s
effect light  purpose clause instruction example  agent creates
hypothetical situation goal stated purpose clause  here   turn light   
state current state  goal achieved  here  light off  
within situation  agent attempts explain instruction forward projecting
action pushing red button 
agent knew pushing red button toggles light  projection 
light would come on  thus  explanation would succeed  general operator
    see  huffman        details features determined 

   

fiflexibly instructable agents

proposal rule would learned  proposed pushing red button light
goal turn on 
however  since actuality agent missing knowledge  mk   pushing
button affects light  light come within projection  explanation
incomplete 
instructo soar s explanation sequence operators fails  agent
try induce missing knowledge needed complete explanation 
could associated multiple operators  rather  explanation simply
abandoned  described section      however  case  unexplainable sequence
contains one operator  addition  form instruction gives agent
strong expectation operator s intended effect  based purpose clause 
agent expects specified action  pushing button  cause achievement
specified goal  turning light   dieugenio        found empirically type
expectation holds     naturally occurring purpose clauses 
expectation constrains  gap  incomplete explanation  state
pushing button state light on  one action performed
produce effect  based constrained gap  agent attempts induce missing
knowledge mk order complete explanation  option o    straightforward
inference mk simply unknown effect single action produce
expected goal conditions   e g   pushing button cause light come on 
instructor asked verify inference   
verified  instructo soar heuristically guesses state conditions
effect occur  uses op to g path heuristic naive causality
theory  pazzani      a  guess causes inferred operator effect  here  op tog path notices light red button table  addition 
agent includes fact inferred effect hold  the light off 
operator caused it  result presented instructor 
think push button causes 
light
following conditions 
light currently on  light table  button table
right conditions 
here  heuristics recognized matters button pushed  the red
one   instructor add condition saying   the button must red   
instructor verifies conditions  agent adds new piece operator effect
knowledge memory 


projecting push button  b  
 l isa light status off  table  t 
 b isa button color red  table  t 
light  l status on 

    inference rejected  agent abandons explanation directly induces proposal rule
pushing button instruction  described section     

   

fihuffman   laird

immediately learned  rule applies light forward projection
current instruction  light comes on  completing instruction s explanation
achieving goal  explanation  agent learns proposal rule proposes
pushing red button goal turn light  thus  agent acquired
new knowledge multiple levels  inferring unknown effect operator supported
learning proposal operator 
example illustrates  i   b   use hypothetical goal instructions use
option o  dealing incomplete explanations   inferring missing knowledge  
learn new operator effects  t  d    thus extending domain knowledge 

    hypothetical states learn contingencies

instructors use instructions hypothetical states  e g   conditionals   if  state conditions         either teach general policies   if lights leave
room  turn off    teach contingencies performing task  instructosoar handles these  here  describe latter 
contingency instruction indicates course action followed current
task performed future situation different current situation  instructors
often use contingency instructions teach situations differ current
one crucial way alter agent s behavior  contingency instructions
common human instruction  ford thompson        found    
conditional statements instruction manual communicated contingency options
student 
consider interaction 
  grasp blue block 

that s new one me  that 

  blue block metal  pick magnet 

blue block made metal  instructor communicating were 
different course action would required 
conditional instruction  if blue block metal  pick magnet  
agent needs learn operator proposal rule picking magnet appropriate conditions  agent begins constructing hypothetical situation
 pick magnet  applies   if blue block metal  indicates hypothetical state
variant current state blue block material metal 
current goal   grasp blue block   goal hypothetical situation 
within situation  agent projects picking magnet explain
allow block grasped  however  agent missing much knowledge needed
complete explanation  know goal concept  grasp  yet  rest
instructions reach goal 
since instruction explained contingency  rest instructions
agent given  grasp blue block  may  and case  not  apply
contingent situation  block metal  normal grasp sequence 
instance  agent learns close hand around grasped object  grasping
metal object  hand closed around magnet  since knowledge complete
   

fiflexibly instructable agents

grasping metal object needed explain contingency instruction  agent
know might learn missing knowledge  abandons explanation
 option o    instead  uses heuristics described section     directly induce
operator proposal rule  grasp magnet   addition conditions generated
heuristics  conditions indicated antecedent instruction included 
result presented instructor alteration verification 
i m guessing conditions  pick magnet 
goal  grasp block  are 
block metal
right 
  right 

interaction agent learns rule proposes picking magnet
goal grasp metal block  learning completed  since agent yet
finished grasping blue block  continues receive instruction task 
contingencies indicated point  learning contingencies illustrates  i  b  
handling hypothetical state instructions 

    learning reject operators

final examples illustrate learning reject operator   type operator control
knowledge pscm  examples detail remaining option dealing
incomplete explanations   o   completing explanation instruction 
consider instructions 
  never grasp green blocks 

why 
 a    trust me 
 b    green blocks explosive 
negative imperative prohibits step applying hypothetical situation
might apply  thus  instructo soar creates hypothetical situation
prohibited action might executed  case  state graspable green block 
since goal specified instruction  current goal  default
goal  maintaining happiness   which always considered one agent s current goals 
used  hypothetical situation  agent internally projects  grasp  action 
expecting  unhappy  result  however  resulting state  agent grasping
green block  acceptable according agent s knowledge  thus  projection
explain action prohibited 
agent deals incomplete explanation asking instruction 
attempt learn mk complete explanation  however  instructor decline
give information saying  a  trust me  although instructor provide mk   prohibition single operator  grasping green block 
explained  agent induce plausible mk complete explanation  option
o    since agent knows final state prohibited operator meant
 unhappy   simply induces state avoided  converse learning recognize desired goal reached  learning operator s termination
   

fihuffman   laird

conditions   agent conservatively guesses features hypothetical
state  here  green block held   taken together  make state
avoided  inference conservative  current implementation
instructor even asked verify it  state inference rule results follows 


goal   happiness   
 b isa block color green 
holding gripper  b  
state fails achieve   happiness   

rule applies final state projection  never grasp     state s failure
achieve happiness completes agent s explanation  never grasp     
learns rule rejects proposed operator grasping green block 
alternatively  instructor could provide instruction   b  green blocks
explosive  instruction provide missing knowledge mk needed complete incomplete explanation  option o     b   agent learns state inference
rule  blocks color green explosiveness high  instructo soar learns state
inferences simple statements  b   conditionals  e g    if magnet
powered directly metal block  magnet stuck block   essentially translating utterance directly rule    state inference instructions
used introduce new features extend agent s representation vocabulary
 e g  stuck to  
rule learned  green blocks explosive  adds explosiveness high
block agent simulated grasping hypothetical situation  agent knows
touching explosive object may cause explosion   negative result  negative
result completes explanation  never grasp      agent learns avoid
grasping objects explosiveness high 
completing explanation instruction  as  b   produce
general learning heuristically inferring missing knowledge  as  a     b  
agent later told blue blocks explosive  avoid grasping well 
general  multiple levels instruction lead higher quality learning single level
learning based explanation composed strong lower level knowledge
 mk   rather inductive heuristics alone  mk  here  state inference rule 
available future use 
agent learned reject  grasp  operator recognize
bad state performing would lead to  agent recognize bad state
reached another path  instance  agent led individual
steps grasping explosive block without instructor ever mentioning  grasp  
agent finally asked  close gripper  around explosive object  so 
immediately recognizes undesirable state arrived reverses
close gripper action  process  learns reject close gripper hand
around explosive object  future reach undesirable state
path 
    translation occurs chunking  uninteresting way  instructo soar use explanation learn state inferences  extension would try explain inference holds using
deeper causal theory 

   

fiflexibly instructable agents

notice effect situated nature instructo soar s learning  agent
learns avoid operators lead bad state arise agent s
performance  initial learning bad state recognitional rather predictive 
alternatively  agent first learns bad state  could extensive reasoning
determine every possible operator could lead state  every possible
previous state  learn reject operators appropriate times  unsituated
reasoning would expensive  agent would reason huge number
possible situations  addition  whenever new operators learned  agent would
reason possible situations could arise  learn
could ever led bad state  rather costly reasoning  instructo soar simply
learns situations arise 
another alternative completely avoiding bad states would think
effects every action taking it  see bad state result  highly cautious
execution strategy would appropriate dangerous situations  appropriate
safer situations agent time pressure   moving less
cautious execution strategies currently implemented instructo soar  
 never grasp     examples illustrated agent s learning one type
operator control knowledge  namely operator rejection  t  c    learning state inferences
 t  a    use instruction complete incomplete explanations  option o   
final category learning discuss second type operator control knowledge 

    learning operator comparison knowledge
another type control knowledge besides operator rejection rules operator comparison
rules  compare two operators express preference one given
situation  instructo soar learns operator comparison rules asking instructor s
feedback multiple operators proposed point achieve particular
goal  multiple operators proposed  instance  agent taught two
different methods achieving goal  e g   pick metal block either using
magnet directly gripper   instructor asked either select one
proposed operators indicate action appropriate  selecting one
proposed choices causes agent learn rule prefers selected operator
proposed operators situations current situation  alternatively 
instructor indicates operator outside set proposed operators 
instructo soar attempts explain operator usual way  learn general
rule proposing it  addition  agent learns rules preferring instructed operator
currently proposed operators 
two weaknesses instructo soar s learning operator comparison rules 
first  instructor required indicate preference step needed complete procedure  rather simply choosing overall methods  is 
instructor cannot say  use method grab block gripper  instead
using magnet   must indicate preference individual step method
employing gripper  pscm  knowledge steps procedure
accessed independently  separate proposal rules  rather aggregate method 
independent access improves exibility reactivity   agent combine steps
   

fihuffman   laird

different methods needed based current situation   higher level grouping
steps would simplify instruction selecting complete methods 
second weakness although agent uses situated explanation explain
selection instructor makes  explain selection better
possibilities  preferences viable operators often based global considerations 
e g    prefer actions lead overall faster cheaper goal achievement   learning based
type global preference  which turn may learned instruction 
point research 

   discussion results
shown instructo soar learns various kinds instructions  although
domain used demonstrate behavior simple  enough complexity exhibit
variety different types instructional interactions occur tutorial instruction 
   requirements tutorial instruction places instructable agent  listed
table     instructo soar meets    listed expanded form table    either fully partially  three particular distinguish instructo soar previous instructable
systems 






command exibility  instructor give command task
instruction point  whether agent knows task perform
current situation 

situation exibility  agent learn implicitly situated instructions
explicitly situated instructions specifying either hypothetical goals states 

knowledge type exibility  agent able learn types knowledge uses task performance  the five pscm types  instruction 

earlier  claimed handling tutorial instruction s exibility requires breadth
learning interaction capabilities  combining command  situation  knowledge type
exibility  instructo soar displays    distinct instructional capabilities  listed table    variety instructional behavior require    different learning techniques 
arises one general technique  situated explanation pscm based agent  applied
range instructional situations 
series examples illustrated situated explanation uses instruction s
situation context learning process  first  situation instruction applies provides endpoints attempting explain instruction  second 
instructional context indicate option follow explanation cannot
completed  context learning new procedure indicates delaying explanation
 option o   best  since full procedure eventually taught  step cannot
explained previously taught procedure  missing knowledge could anywhere
procedure  best abandon explanation  option o   learn another way  instructions provide explicit context  purpose clause  localize missing
knowledge giving strong expectations single operator achieve single
goal  localization makes plausible induce missing knowledge complete
   

fiflexibly instructable agents

  
  
  
  
  
  
  

instructional capability
learning completely new procedures
extending procedure apply new situation
hierarchical instruction  handling instructions
procedure embedded instruction others
altering induced knowledge based
instruction
learning procedures inductively domain
knowledge incomplete
learning avoid prohibited actions
general learning due instruction

   learning avoid indirect achievement bad
state
   inferences simple specific statements
    inferences simple generic statements
    inferences conditionals
    learning operator perform hypothetical
goal
    learning operator perform hypothetical
state  general policy  active times 
    learning operator perform hypothetical
state  contingency within particular procedure
    learning operator effects
    learning non perceivable operator effects associated inferences recognize
    learning control knowledge  learning set
operators prefer
    learning control knowledge  learning operators
indifferent

example
pick

move move
teaching pick within line

removing docked at pick
up s termination conditions
learning secondary operator
effects knowledge removed
 never grasp red blocks  
avoid grasping  red
blocks explosive  
closing hand around explosive
block
 the grey block metal  
 white magnets powered  
 if condition  and condition  
concluded state feature 
 to turn light  push
red button  
 if light bright  dim
light  
 if block metal  grasp
magnet  pick
pushing red button turns
light
magnet becomes stuck to
metal block moved
two ways grasp small metal
block
two ways grasp small metal
block

table    instructional capabilities demonstrated instructo soar 

   



fihuffman   laird

explanation  option o    cases  default ask instruction missing
knowledge complete explanation  option o   

    empirical evaluation

empirical evaluations machine learning systems take one four forms  appropriate addressing different evaluation questions 
a  comparison systems  technique useful evaluating overall
performance compares state art  used
systems available learning task 
b  comparison altered version system  technique evaluates
impact component system overall performance  typically 
system compared version without key component  sometimes called
 lesion study   
c  measuring performance systematically generated series problems  technique evaluates method affected different dimensions input  e g  
noise training data  
d  measuring performance known hard problems  known hard problems provide
evaluation overall performance extreme conditions  instance  concept
learners  performance often measured standard  dicult datasets 
evaluation techniques applied limited ways instructo soar 
dicult apply great depth two reasons  first  whereas machine
learning efforts concentrate depth single type learning single type input 
tutorial instruction requires breadth learning range instructional interactions  whereas depth measured quantitative performance  breadth measured
 possibly qualitative  coverage   here  coverage      instructability requirements  second  tutorial instruction extensively studied machine learning 
battery standard systems problems available  nonetheless  evaluation
techniques  b    c    d  applied instructo soar address specific
evaluation questions 
b  comparison altered version  removed frame axiom knowledge illustrate
effect prior knowledge agent s performance  described section     
without prior knowledge  agent unable explain instructions must resort
inductive methods  thus  removing frame axiom knowledge increased amount
instruction required reduced learning quality  compared versions
agent use different instruction recall strategies  section      
c  performance systematically varied input  examined effects varying three
dimensions instructions given agent  first  compared learning curves
instruction sequences different lengths  section       graphs figure   
show  instructo soar s execution time instructed procedure varies
number instructions sequence used teach it  total execution time drops
   

fiflexibly instructable agents

time procedure executed  according power law function  procedure learned general form  second  compared teaching procedure
hierarchical subtasks versus using instruction sequence  based
power law result  predicted hierarchical instruction would allow faster general
learning instruction  prediction confirmed empirically  third 
examined number instruction orderings used teach given procedure instructo soar order measure value supporting command
exibility  rather experimental measurement  performed mathematical
analysis  analysis showed due command exibility  number instruction sequences used teach given procedure large  growing
exponentially number primitive steps procedure  huffman        
d  performance known hard problem  since learning tutorial instruction
extensively studied machine learning  standard  dicult
problems  created comprehensive instruction scenario crossing command
exibility  situation exibility  knowledge type exibility requirements  scenario  described detail  huffman         contains     instructions demonstrates    instructo soar s    instructional capabilities table    it
include learning indifference selecting two operators   agent learns
      chunks scenario  including examples type pscm
knowledge  extend agent s domain knowledge significantly 

   limitations research
work s limitations fall three major categories  limitations tutorial instruction
teaching technique  limitations agent s general capabilities  limitations
incomplete solutions mapping  interaction  transfer problems  discuss
turn 

    limitations tutorial instruction

tutorial instruction highly interactive situated  however  much human
instruction either non interactive unsituated  or both   considered work  non interactive instruction  content ow information
student controlled primarily information source  examples include classroom
lectures  instruction manuals  textbooks  one issue using type instruction
locating extracting information needed particular problems  carpenter
  alterman         non interactive instruction contain situated information  e g  
worked out example problems  chi et al         vanlehn        unsituated information
 e g   general expository text  
unsituated instruction conveys general abstract knowledge applied
large number different situations  general purpose knowledge often described
 declarative   singley   anderson         example  physics class  students
taught f   a  general equation applies specific ways great variety
situations  advantage unsituated instruction precisely ability compactly
communicate abstract knowledge broadly applicable  sandberg   wielinga        
   

fihuffman   laird

however  use abstract knowledge  students must learn applies specific
situations  singley   anderson        

    limitations agent

agent s inherent limitations constrain taught  developed
theory learning tutorial instruction within particular computational model
agents  the pscm   within computational model  implemented agent
particular set capabilities demonstrate theory  thus  weaknesses
computational model specific implemented agent must examined 
      computational model

problem space computational model well suited situated instruction
elements  close correspondence knowledge level  facilitating mapping
instructions elements   inherently local control structure  however 
pscm s local application knowledge makes dicult learn global control regimes
instruction  must translated series local decisions
result local learning 
second weakness pscm provides theory functional types
knowledge used intelligent agent  gives indication possible content
knowledge  content theory knowledge would allow finer grained analysis
agent s instructability  within larger grained knowledge types analysis provided
pscm 
      implemented agent s capabilities

producing definitive agent goal work  rather  instructosoar agent s capabilities developed needed demonstrate instructional learning capabilities  thus  limited number ways    instance 
performs simple actions serially static world  would sucient dynamic
domain ying airplane  multiple goals multiple levels granularity 
involving achievement and or maintenance conditions environment  may
active  pearson et al          instructo soar s procedures implemented
series locally decided steps  precluding instruction containing procedure wide  i e   nonlocal  path constraints  e g    go room  don t walk carpeting    
single agent world  precluding instructions involve cooperation
agents  e g   two robots carrying couch  instructions require reasoning
agents  potential actions  e g    don t go alley  enemy
may block in   
agent complete perception  clearly unrealistic real physical domains  
never told look  asked notice feature overlooked  contrast  instruction protocols show human students often told attend
features notice  instructo soar s world noise free  agent need
    limitations particular agent implemented here  soar  used
build powerful agents  e g   jones et al         pearson et al         

   

fiflexibly instructable agents

reason receive instruction failed actions  complete perception
noise free environment  agent explicitly reason uncertainty
perceptions actions  demonstrated handling instructions explicitly
describe uncertain probabalistic outcomes    agent reason time
 as  e g   vere bickmore s        homer does   cannot taught perform tasks
time dependent way  keep track states seen actions performs
 other episodic instruction memory   cannot asked  do
before   similarly  cannot learn procedures defined particular sequence
actions  rather set state conditions achieve  example  cannot taught
dance  dancing result net change external world  finally  whenever agent know next  asks instruction 
never tries determine solution search weak methods means ends
analysis  adding capability would decrease need instruction 
addition agent s capabilities  instructo soar limited solutions
mapping  interaction  transfer problems incomplete various ways 
limitations discussed next 

    mapping problem
instructo soar employs straightforward approach mapping instructions

agent s internal language  leaves problems mapping dicult natural language constructions unaddressed  relevant problems include reference resolution  incompleteness  use domain knowledge comprehension  mapping
even require instruction  interaction resolve referent 
  grab explosive block 

one that 
  red one 

type interaction supported instructo soar 
addition general linguistic problems  instructo soar makes limited
use semantic information learning new operators  example  first reads
 move red block left yellow block   creates new operator  make
use semantic information communicated  move   to left of   complete
agent would try glean information could semantics unfamiliar
command 

    interaction problem
agent s shortcomings interaction problem center around three requirements 
 i   exible initiation instruction   i   full exibility knowledge content   i  
situation exibility   i     instructo soar  instruction initiated agent 
    instruction protocols analyzed  instructions incomplete  missing conditions
instructo soar learns   rarely described uncertainty explicitly 

   

fihuffman   laird

limits instructor s ability drive interaction interrupt agent s actions
instruction   no  don t push button    
 i    instructo soar provides exibility commands  instructions
communicate kinds information  similar notion discourse coherence  mann
  thompson         fully exible tutorable agent needs support instruction event
knowledge coherence  is  instruction event delivering knowledge makes
sense current context  great variety knowledge could relevant
point makes requirement dicult 
 i    instructo soar provides situation exibility handling implicitly
explicitly situated instructions  hypothetical situations referred within
single instruction  human tutors often refer one hypothetical situation course
multiple instructions 

    transfer problem

work focused primarily transfer problem   producing general learning
tutorial instruction   requirements met  however  inductive
heuristics instructo soar uses powerful 
addition  two transfer problem requirements achieved  first   t  
instructo soar yet demonstrated instructional learning coexistence learning knowledge sources  nothing instructo soar s theory precludes coexistence  however  learning knowledge sources could invoked possibly
enhanced instruction  instance  instructor might invoke learning observation pointing set objects saying  this tower   similarly  instruction
containing metaphor could invoke analogical learning  one application instruction
could potentially enhance learning mechanisms within  personal assistant  software
agents learn observing users  e g   maes        mitchell et al          adding
ability learn verbal instructions addition observations would allow users
explicitly train agents situations learning observation alone may
dicult slow 
second   t   instructo soar cannot recover incorrect knowledge leads
either invalid explanations incorrect external performance  incorrect knowledge
may part agent s initial domain theory  may learned faulty
instruction  inability recover incorrect knowledge precludes instruction general
case exceptions  instance   never grasp red blocks   later   it s ok
grasp ones safety signs them   order avoid learning anything incorrect 
whenever instructo soar attempts induce new knowledge  asks instructor s
verification adding knowledge long term memory  human students
ask much verification  appear jump conclusions  alter later
prove incorrect based information 
rather always verifying knowledge learned  next generation instructable
agents learn reasonable inferences without verification  although may ask
verifications extreme cases   recently produced agent  pearson  
    recently added simple interruptability capability new version instructo soar
incorporates recovery incorrect knowledge  pearson   huffman        

   

fiflexibly instructable agents

huffman        incorporates current research incremental recovery incorrect
knowledge  pearson   laird         agent learns correct overgeneral knowledge
infers completing explanations instructions  correction process triggered
using overgeneral knowledge results incorrect performance  e g   action
agent expects succeed not   long run  believe work could push
research incremental theory revision error recovery  instructable agents
taught many types knowledge may need revision 

    conclusion

although much work machine learning aims depth particular kind learning 

instructo soar demonstrates breadth   interaction instructor learn variety

types knowledge   arising one underlying technique  kind breadth
crucial building instructable agent great variety instructions
variety knowledge communicate  instructable agents begin
basic knowledge domain  instructo soar uses analytic  explanationbased approach learn instructions  makes use knowledge 
instructions may either implicitly explicitly situated  instructo soar situates
explanations instruction within situation indicated instruction  finally 
agent s knowledge often deficient explaining instructions  instructosoar employs four different options dealing incomplete explanations  selects
options dynamically depending instructional context 
availability effectiveness  tutorial instruction potentially powerful knowledge source intelligent agents  instructo soar illustrates simple
domain  realizing instruction s potential fielded applications require linguistically able agents incorporate robust techniques acquiring knowledge
instruction  refining knowledge needed based performance
instruction 

acknowledgements
work performed first author graduate student university
michigan  sponsored nasa onr contract ncc        university
michigan predoctoral fellowship  thanks paul rosenbloom  randy jones 
anonymous reviewers helpful comments earlier drafts 

references

akatsuka  n          conditionals discourse bound  traugott  e  c   ed   
conditionals  pp          cambridge univ  press  cambridge 
alterman  r   zito wolf  r     carpenter  t          interaction  comprehension 
instruction usage  journal learning sciences                   
anderson  j  r          architecture cognition  harvard university press  cambridge 
ma 
   

fihuffman   laird

bergadano  f     giordana  a          knowledge intensive approach concept induction  proceedings international conference machine learning  pp 
        
birmingham  w     klinker  g          knowledge acquisition tools explicit problemsolving methods  knowledge engineering review        
birmingham  w     siewiorek  d          automated knowledge acquisition computer
hardware synthesis system  knowledge acquisition             
bloom  b  s            sigma problem  search methods group instruction
effective one to one tutoring  educational researcher               
brachman  r  j          introduction kl one  brachman  r  j   ed    research
natural language understanding  pp         bolt  beranek newman inc  
cambridge  ma 
carbonell  j  g     gil  y          learning experimentation  proceedings
international workshop machine learning  pp          
carbonell  j  g   michalski  r  s     mitchell  t  m          overview machine
learning  michalski  r  s   carbonell  j  g     mitchell  t  m   eds    machine
learning  artificial intelligence approach  morgan kaufmann 
carpenter  t     alterman  r          reading agent  proceedings twelfth
national conference artificial intelligence seattle  wa 
chapman  d          vision  instruction  action  ph d  thesis  massachusetts institute
technology  artificial intelligence laboratory 
chi  m  t  h   bassok  m   lewis  m  w   reimann  p     glaser  r          selfexplanations  students study use examples learning solve problems 
cognitive science              
cypher  a   ed            watch do  programming demonstration  mit press 
cambridge  mass 
davis  r          interactive transfer expertise  acquisition new inference rules 
artificial intelligence                  
dejong  g  f     mooney  r  j          explanation based learning  alternative view 
machine learning                 
dent  l   boticario  j   mcdermott  j   mitchell  t     zabowski  d          personal
learning apprentice  proceedings international joint conference artificial
intelligence 
dieugenio  b          understanding natural language instructions  computational approach purpose clauses  ph d  thesis  university pennsylvania  ircs report
      
   

fiflexibly instructable agents

dieugenio  b     webber  b          plan recognition understanding instructions 
hendler  j   ed    proceedings first international conference artificial intelligence planning systems  pp        college park  md 
donoho  s  k     wilkins  d  c          exploiting ordering observed problem solving
steps knowledge ase refinement  apprenticeship approach  proceedings
  th national conference artifical intelligence seattle  wa 
drummond  m          situated control rules  proceedings first international conference principles knowledge representation toronto  canada  morgan kaufmann 
emihovich  c     miller  g  e          talking turtle  discourse analysis logo
instruction  discourse processes              
eshelman  l   ehret  d   mcdermott  j     tan  m          mole  tenacious knowledgeacquisition tool  international journal man machine studies                
fikes  r  e   hart  p  e     nilsson  n  j          learning executing generalized robot
plans  artificial intelligence             
ford  c  a     thompson  s  a          conditionals discourse  text based study
english  traugott  e  c   ed    conditionals  pp          cambridge
univ  press  cambridge 
frederking  r  e          integrated natural language dialogue  computational model 
kluwer academic press  boston 
golding  a   rosenbloom  p  s     laird  j  e          learning search control outside
guidance  proceedings tenth international joint conference artificial
intelligence  pp          
grosz  b  j          representation use focus dialogue understanding  ph d 
thesis  university california  berkeley 
gruber  t          automated knowledge acquisition strategic knowledge  machine
learning                   
guha  r  v     lenat  d  b          cyc  mid term report  ai magazine                
haas  n     hendrix  g  g          learning told  acquiring knowledge
information management  michalski  r  s   carbonell  j  g     mitchell  t  m 
 eds    machine learning  artificial intelligence approach  morgan kaufmann 
haiman  j          conditionals topics  language             
hall  r  j          learning failing explain  machine learning               
hayes roth  f   klahr  p     mostow  d  j          advice taking knowledge refinement 
iterative view skill acquisition  anderson  j  r   ed    cognitive skills
acquisition  pp           lawrence erlbaum associates  hillsdale  nj 
   

fihuffman   laird

huffman  s  b          instructable autonomous agents  ph d  thesis  university michigan  dept  electrical engineering computer science 
huffman  s  b     laird  j  e          dimensions complexity learning interactive
instruction  erickson  j   ed    proceedings cooperative intelligent robotics
space iii  spie volume      
huffman  s  b     laird  j  e          learning procedures interactive natural language instructions  utgoff  p   ed    machine learning  proceedings tenth
international conference 
huffman  s  b     laird  j  e          learning highly exible tutorial instruction 
proceedings   th national conference artificial intelligence  aaai    
seattle  wa 
huffman  s  b   miller  c  s     laird  j  e          learning instruction  knowledgelevel capability within unified theory cognition  proceedings fifteenth
annual conference cognitive science society  pp          
johnson laird  p  n          conditionals mental models  traugott  e  c   ed   
conditionals  cambridge univ  press  cambridge 
jones  r  m   tambe  m   laird  j  e     rosenbloom  p  s          intelligent automated agents ight training simulators  proceedings third conference
computer generated forces  pp        orlando  fl 
just  m  a     carpenter  p  a          verbal comprehension instructional situations 
klahr  d   ed    cognition instruction  lawrence erlbaum associates  hillsdale 
nj 
kieras  d  e     bovair  s          role mental model learning operate
device  cognitive science             
kodratoff  y     tecuci  g       a   disciple    interactive apprentice system weak
theory fields  proceedings tenth international joint conference artificial
intelligence  pp          
kodratoff  y     tecuci  g       b   techniques design disciple learning apprentice  international journal expert systems               
laird  j  e   congdon  c  b   altmann  e     doorenbos  r          soar user s manual 
version    
laird  j  e   hucka  m   yager  e  s     tuck  c  m          correcting extending
domain knowledge using outside guidance  proceedings seventh international
conference machine learning 
laird  j  e   newell  a     rosenbloom  p  s          soar  architecture general
intelligence  artificial intelligence               
   

fiflexibly instructable agents

laird  j  e     rosenbloom  p  s          integrating execution  planning  learning
soar external environments  proceedings eighth national conference
artificial intelligence  pp             aaai press 
lewis  c          learn why  analysis based generalization procedures 
cognitive science              
lewis  r  l          architecturally based theory human sentence comprehension 
ph d  thesis  carnegie mellon university  school computer science 
lewis  r  l   newell  a     polk  t  a          toward soar theory taking instructions immediate reasoning tasks  proceedings annual conference
cognitive science society 
lindsay  r  k          inferential memory basis machines understand natural
language  feigenbaum  e  a     feldman  j   eds    computers thought  pp 
         r  oldenbourg kg 
maes  p          agents reduce work information overload  communications
acm         
maes  p     kozierok  r          learning interface agents  proceedings national
conference artificial intelligence  pp          
mann  w  c     thompson  s  a          rhetorical structure theory  toward functional
theory text organization  text                 
marcus  s     mcdermott  j          salt  knowledge acquisition language proposeand revise systems  artificial intelligence               
martin  c  e     firby  r  j          generating natural language expectations
reactive execution system  proceedings thirteenth annual conference
cognitive science society  pp          
mccarthy  j          advice taker  minsky  m   ed    semantic information processing  pp           mit press  cambridge  mass 
miller  c  m          model concept acquisition context unified theory
cognition  ph d  thesis  university michigan  dept  computer science
electrical engineering 
minton  s   carbonell  j  g   knoblock  c  a   kuokka  d  r   etzioni  o     gil  y         
explanation based learning  problem solving perspective  artificial intelligence     
       
mitchell  t   caruana  r   freitag  d   mcdermott  j     zabowski  d          experience
learning personal assistant  communications acm         
mitchell  t  m   keller  r  m     kedar cabelli  s  t          explanation based generalization  unifying view  machine learning    
   

fihuffman   laird

mitchell  t  m   mahadevan  s     steinberg  l  i          leap  learning apprentice
system vlsi design  kodratoff  y     michalski  r  s   eds    machine learning 
artificial intelligence approach  vol  iii  morgan kaufmann 
mooney  r  j          learning plan schemata observation  explanation based learning plan recognition  cognitive science              
mostow  d  j          learning told  machine transformation advice
heuristic search procedure  michalski  r  s   carbonell  j  g     mitchell  t  m 
 eds    machine learning  artificial intelligence approach  morgan kaufmann 
musen  m  a          automated support building extending expert models  machine learning                   
newell  a          knowledge level  ai magazine              
newell  a          unified theories cognition  harvard university press  cambridge 
massachusetts 
newell  a   yost  g   laird  j  e   rosenbloom  p  s     altmann  e          formulating
problem space computational model  proceedings   th anniversary
symposium  school computer science  carnegie mellon university 
pazzani  m       a   computational theory learning causal relationships  cognitive
science              
pazzani  m       b   learning predict explain  integration similarity based 
theory driven  explanation based learning  journal learning sciences        
        
pearson  d  j     huffman  s  b          combining learning instruction recovery
incorrect knowledge  gordon  d     shavlik  j   eds    proceedings     
machine learning workshop agents learn agents 
pearson  d  j   huffman  s  b   willis  m  b   laird  j  e     jones  r  m         
symbolic solution intelligent real time control  ieee robotics autonomous
systems              
pearson  d  j     laird  j  e          toward incremental knowledge correction agents
complex environments  muggleton  s   michie  d     furukawa  k   eds    machine
intelligence  vol      oxford university press 
porter  b  w   bareiss  r     holte  r  c          concept learning heuristic classification weak theory domains  artificial intelligence                  
porter  b  w     kibler  d  f          experimental goal regression  method learning
problem solving heuristics  machine learning             
redmond  m  a          learning observing understanding expert problem solving 
ph d  thesis  georgia institute technology 
   

fiflexibly instructable agents

rosenbloom  p  s     aasman  j          knowledge level inductive uses chunking
 ebl   proceedings national conference artificial intelligence 
rosenbloom  p  s     laird  j  e          mapping explanation based generalization onto
soar  proceedings national conference artificial intelligence  pp          
rosenbloom  p  s   laird  j  e     newell  a          chunking skill knowledge 
bouma  h     elsendoorn  a  g   eds    working models human perception 
pp           academic press  london  england 
rosenbloom  p  s   laird  j  e     newell  a   eds         a   soar papers  research
integrated intelligence  mit press  cambridge  mass 
rosenbloom  p  s   laird  j  e     newell  a   eds         b   soar papers  research
integrated intelligence  mit press  cambridge  mass 
rosenbloom  p  s     newell  a          chunking goal hierarchies  generalized
model practice  michalski  r  s   carbonell  j  g     mitchell  t  m   eds   
machine learning  artificial intelligence approach  volume ii  morgan kaufmann 
rumelhart  d  e     mcclelland  j  l   eds            parallel distributed processing  explorations microstructure cognition  mit press  cambridge  ma 
rychener  m  d          instructible production system  retrospective analysis 
michalski  r  s   carbonell  j  g     mitchell  t  m   eds    machine learning 
artificial intelligence approach  pp           morgan kaufmann 
sandberg  j     wielinga  b          situated cognition   proceedings
international joint conference artificial intelligence  pp          
schank  r  c          conceptual information processing  american elsevier  new york 
schank  r  c     leake  d  b          creativity learning case based explainer 
artificial intelligence              
segre  a  m          learning apprentice system mechanical assembly  third ieee
conference artificial intelligence applications  pp          
shen  w          discovery autonomous learning environment  machine learning              
simon  h  a          artificial intelligence systems understand  proceedings
fifth international joint conference artificial intelligence  pp            
simon  h  a     hayes  j  r          understanding complex task instructions  klahr 
d   ed    cognition instruction  lawrence erlbaum associates  hillsdale  nj 
singley  m  k     anderson  j  r          transfer cognitive skill  harvard university
press 
   

fihuffman   laird

sutton  r  s     pinette  b          learning world models connectionist networks 
proceedings seventh annual conference cognitive science society  pp 
      
thrun  s  b     mitchell  t  m          integrating inductive neural network learning
explanation based learning  proceedings international joint conference
artificial intelligence  pp          
vanlehn  k          learning one subprocedure per lesson  artificial intelligence         
     
vanlehn  k   ball  w     kowalski  b          explanation based learning correctness 
towards model self explanation effect  proceedings   th annual
conference cognitive science society  pp          
vanlehn  k     jones  r          learning physics via explanation based learning correctness analogical search control  proceedings international machine
learning workshop 
vanlehn  k   jones  r  m     chi  m  t  h          model self explanation effect 
journal learning sciences              
vere  s     bickmore  t          basic agent  computational intelligence           
wertsch  j  v          social interaction higher psychological processes  clarification application vygotsky s theory  human development           
widmer  g          tight integration deductive inductive learning  proceedings
international workshop machine learning  pp        
wilkins  d  c          knowledge base refinement improving incomplete incorrect
domain theory  kodratoff  y     michalski  r  s   eds    machine learning 
artificial intelligence approach  volume iii  pp           morgan kaufmann 
winograd  t          understanding natural language  academic press  new york 
wood  d   bruner  j  s     ross  g          role tutoring problem solving  journal
child psychology psychiatry             
yost  g  r          acquiring knowledge soar  ieee expert               
yost  g  r     newell  a          problem space approach expert system specification 
proceedings international joint conference artificial intelligence  pp 
      

   


