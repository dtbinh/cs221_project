journal of artificial intelligence research                 

submitted       published      

opus  an efficient admissible algorithm for
unordered search
geoffrey i  webb

webb deakin edu au

deakin university  school of computing and mathematics
geelong  vic        australia 

abstract
opus is a branch and bound search algorithm that enables efficient admissible search
through spaces for which the order of search operator application is not significant  the
algorithms search efficiency is demonstrated with respect to very large machine learning
search spaces  the use of admissible search is of potential value to the machine learning
community as it means that the exact learning biases to be employed for complex learning
tasks can be precisely specified and manipulated  opus also has potential for application
in other areas of artificial intelligence  notably  truth maintenance 

   introduction
many artificial intelligence problems involve search  consequently  the development of
appropriate search algorithms is central to the advancement of the field  due to the complexity of the search spaces involved  heuristic search is often employed  however  heuristic
algorithms cannot guarantee that they will find the targets they seek  in contrast  an admissible search algorithm is one that is guaranteed to uncover the nominated target  if it
exists  nilsson         this greater utility is usually obtained at a significant computational
cost 
this paper describes the opus  optimized pruning for unordered search  family of
search algorithms  these algorithms provide efficient admissible search of search spaces in
which the order of application of search operators is not significant  this search efficiency
is achieved by the use of branch and bound techniques that employ domain specific pruning
rules to provide a tightly focused traversal of the search space 
while these algorithms have wide applicability  both within and beyond the scope of
artificial intelligence  this paper focuses on their application in classification learning  of
particular significance  it is demonstrated that the algorithms can efficiently process many
common classification learning problems  this contrasts with the seemingly widespread
assumption that the sizes of the search spaces involved in machine learning require the use
of heuristic search 
the use of admissible search is of potential value in machine learning as it enables better
experimental evaluation of alternative learning biases  search is used in machine learning
in an attempt to uncover classifiers that satisfy a learning bias  when heuristic search is
used it is difficult to determine whether the search technique introduces additional implicit
biases that cannot be properly identified  such implicit biases may confound experimental
results  in contrast  if admissible search is employed the experimenter can be assured that
c
    
ai access foundation and morgan kaufmann publishers  all rights reserved 

fiwebb

the search technique is not introducing confounding unidentified implicit biases into the
experimental situation 
the use of opus for admissible search has already led to developments in machine
learning that may not otherwise have been possible  in particular  webb        compared
classifiers developed through true optimization of laplace accuracy estimate with those obtained through heuristic search that sought but failed to optimize this measure  in general 
the latter proved to have higher predictive accuracy than the former  this surprising result 
that could not have been obtained without the use of admissible search  led quinlan and
cameron jones        to develop a theory of oversearching 
this paper offers two distinct contributions to the fields of computing  artificial intelligence and machine learning  first  it offers a new efficient admissible search algorithm for
unordered search  second  it demonstrates that admissible search is possible for a range of
machine learning tasks that were previously thought susceptible only to efficient exploration
through non admissible heuristic search 

   unordered search spaces
for most search problems  the order in which operators are applied is significant  for
example  when attempting to stack blocks it matters whether the red block is placed on the
blue block before or after the blue block is placed on the green  when attempting to navigate
from point a to point b  it is not possible to move from point c to point b before moving to
point c  however  for some search problems  the order in which operators are applied is not
significant  for example  when searching through a space of logical expressions  the effect
of conjoining expression a with expression b and then conjoining the result with expression
c is identical to the result obtained by conjoining a with c followed by b  both sequences
of operations result in expressions with equivalent meaning  in general  a search space is
unordered if for any sequence o of operator applications and any state s  all states that can
be reached from s by a permutation of o are identical  it is this type of search problem 
search through unordered search spaces  that is the subject of this investigation 
special cases of search through unordered search spaces are provided by the subset
selection  narendra   fukunaga        and minimum test set  moret   shapiro       
search problems  subset selection involves the selection of a subset of objects that maximizes
an evaluation criterion  the minimum test set problem involves the selection of a set of
tests that maximizes an evaluation criterion  such search problems are encountered in many
domains including machine learning  truth maintenance and pattern recognition  rymon
       has demonstrated that reiters        and de kleer  mackworth  and reiters       
approaches to diagnosis can be recast as subset selection problems 
the opus algorithms traverse the search space using a search tree  the root of the
search tree is an initial state  branches denote the application of search operators and the
nodes that they lead to denote the states that result from the application of those operators 
different variants of opus are suited to each of optimization search and satisficing search 
for optimization search  a goal state is an optimal solution  for satisficing search  a goal
state is an acceptable solution  it is possible that a search space may include multiple goal
states 
   

fian efficient admissible algorithm for unordered search

the opus algorithms take advantage of the properties of unordered search spaces to
optimize the effect of any pruning of the search tree that may occur  in particular  when
expanding a node n in a search tree  the opus algorithms seek to identify search operators
that can be excluded from consideration in the search tree descending from n without
excluding a sole goal node from that search tree  the opus algorithms differ from most
previous admissible search algorithms employed in machine learning  clearwater   provost 
      murphy   pazzani        rymon        segal   etzioni        webb        in that
when such operators are identified  they are removed from consideration in all branches of
the search tree that descend from the current node  in contrast  the other algorithms only
remove a single branch at a time without altering the operators considered below sibling
branches  thereby pruning fewer nodes from the search space 
if it is not possible to apply an operator more than once on a path through the search
space  search with unordered operators can be considered to be a subset selection problem
select a subset of operators whose application  in any order  leads to a goal state  if a single
operator may be applied multiple times on a single path through the search space  search
with unordered operators can be considered as a sub multiset selection problemselect the
multiset of operators whose application leads to the desired result 
a search tree that traverses an unordered search space in which multiple applications of
a single operator are not allowed may be envisioned as in figure    this example includes
four search operators  named a  b  c and d  each node in the search tree is labeled by the
set of operators by which it is reached  thus  the initial state is labeled with the empty
set  at depth one are all sets containing a single operator  at depth two all sets containing
two operators and so on  up to depth four  any two nodes with identical labels represent
equivalent states 
there is considerable duplication of nodes in this search tree  the label  a  b  c  d  occurs
   times   in figure    and the following figures   the number of unique nodes is listed
below each depth of the search tree  where this number can be derived from the number
of combinations to be considered  this derivation is also indicated 
it is common during search to prune regions of the search tree on the basis of investigations that determine that a goal state cannot lie within those regions  figure   shows a
search tree with the sub tree below  c  pruned  note that  due to the duplication inherent
in such a search tree  the number of unique nodes remaining in the tree is identical to that
in the unpruned tree  however  if it has been deemed that no node descending from  c 
may be a goal  then all nodes elsewhere in the search tree that have identical labels  are
reached via identical sets of operator applications  to any nodes that occur in the pruned
region of the tree could also be pruned  figure   shows the search tree remaining when all
nodes below  c  and all their duplicates have been deleted  it can be seen that the number
of unique nodes in the remaining search tree  the tree at depths      and    has been pruned
by more than half  similar results are obtained in the case where multiple applications of
a single operator are allowed and the nodes are consequently labeled with multisets 
the opus algorithms do not provide pruning rulesmechanisms for identifying sections
of the search tree that may be pruned  rather  they take pruning rules as input and seek
to optimize the effect of each pruning action that results from application of those rules 
the opus algorithms were designed for use with admissible pruning rules  when
used solely with admissible pruning rules the algorithms are admissible  that is  they are
   

fiwebb

  a  b  

 a 

  a  c  

  a  d  

  a  b  

 b 

  b  c  

  b d  

  a  b  c  

  a  b  c  d  

  a  b  d  

  a  b  c  d  

  a  b  c  

  a  b  c  d  

  a  c  d  

  a  b  c  d  

  a  b  d  

  a  b  c  d  

  a  c  d  

  a  b  c  d  

  a  b  c  

  a  b  c  d  

  a  b  d  

  a  b  c  d  

  a  b  c  

  a  b  c  d  

  b  c  d  

  a  b  c  d  

  a  b  d  

  a  b  c  d  

  c  b  d  

  a  b  c  d  

  a  b  c  

  a  b  c  d  

  a  c  d  

  a  b  c  d  

  a  b  c  

  a  b  c  d  

  b  c  d  

  a  b  c  d  

  a  c  d  

  a  b  c  d  

  
  a  c  

 c 

  b  c  

  c  d  

  a  d  

 d 

  b  d  

  c  d  
 c   
 

 c   
 

 c   
 

  b  c  d  

  a  b  c  d  

  a  b  d  

  a  b  c  d  

  a  c  d  

  a  b  c  d  

  a  b  d  

  a  b  c  d  

  b  c  d  

  a  b  c  d  

  a  c  d  

  a  b  c  d  

  b  c  d  

  a  b  c  d  

 c   
 

 c   
 

figure    simple unordered operator search tree
guaranteed to find a goal state if one exists in the search space  however  the algorithms
may also be used with non admissible pruning heuristics to obtain efficient non admissible
search 
the opus algorithms are not only admissible  when used with admissible pruning
rules   they are systematic  pearl         that is  in addition to guaranteeing that a goal
will be found if one exists  the algorithms guarantee that no state will be visited more than
once during a search  so long as it is not possible to reach a single node by application of
different sets of operators  

   fixed order search
a number of recent machine learning algorithms have performed restricted admissible search
 clearwater   provost        rymon        schlimmer        segal   etzioni        webb 
       all of these algorithms are based on an organization of the search tree  that  when
considering the search problem illustrated in figures   to    traverse the search space in the
manner depicted in figure    such an organization is achieved by arranging the operators
in a predefined order  and then applying at a node all and only operators that have a higher
order than any operator that appears in the path leading to the node  this strategy will be
   

fian efficient admissible algorithm for unordered search

  a  b  

  a 

  a  c  

  a  d  

  a  b  

  b 

  b  c  

  b  d  

  a  b   c  

  a  b   c  d  

  a  b   d  

  a  b   c  d  

  a  b   c  

  a  b   c  d  

  a  c  d  

  a  b   c  d  

  a  b   d  

  a  b   c  d  

  a  c  d  

  a  b   c  d  

  a  b   c  

  a  b   c  d  

  a  b   d  

  a  b   c  d  

  a  b   c  

  a  b   c  d  

  b  c  d  

  a  b   c  d  

  a  b   d  

  a  b   c  d  

  c  b  d  

  a  b   c  d  

  a  b   d  

  a  b   c  d  

  a  c  d  

  a  b   c  d  

  a  b   d  

  a  b   c  d  

  b  c  d  

  a  b   c  d  

  a  c  d  

  a  b   c  d  

  b  c  d  

  a  b   c  d  

  

 c 

  a  d  

  d 

  b  d  

  c  d  
 c   
 

 c   
 

 c   
 

 c   
 

 c   
 

figure    simple unordered operator search tree with pruning beyond application of operator c

called fixed order search   fixed order search has also been used for non admissible search 
for example  buchanan  feigenbaum    lederberg        
figure   illustrates the effect of pruning the sub tree descending below operator c  under
fixed order search  as can be seen  this is substantially less effective than the optimized
pruning illustrated in figure    schlimmer        ensures that the pruning effect illustrated
in figure   is obtained within the efficient search tree organization illustrated in figure    by
maintaining an explicit representation of all nodes that are pruned  the resulting search tree
is depicted in figure    this approach requires the considerable computational overhead of
identifying and marking all pruned states following every pruning action  and the restrictive
storage overhead of maintaining the representation   one of the search problems tackled
below contains      states  to represent whether a state is pruned requires a single bit 
thus       bits would be required to represent the required information for this problem 
a requirement well beyond the capacity of computational machinery into the foreseeable
future   further  it is open to debate whether this approach does truly prune all identified
nodes from the search space  nodes that that have been pruned will still need to be
generated when encountered in previously unexplored regions of the search tree in order to
   

fiwebb

  a  b  

  a  b   d  

  a 
  a  b   d  
  a  d  

  a  b  

  a  b   d  

  b 
  a  b   d  
  b  d  
  

 c 

  a  b   d  
  a  d  
  a  b   d  
  d 

 c   
 

 c   
 

  b  d  

 c   
 

 c   
 

 c   
 

figure    simple unordered operator search tree with maximal pruning beyond application
of operator c

  a  b  

  a  b  c  

  a  b   c  d  

  a  b  d  
  a 

  a  c  

  a  c  d  

  a  d  
  b  c  
  

  b  c  d  

  b 
  b  d  
 c 

  c  d  

  d 
 c   
 

  c   
 

 c   
 

 c   
 

 c   
 

figure    static search tree organization used by fixed order search

   

fian efficient admissible algorithm for unordered search

  a  b  c  
  a  b  
  a 

  a  c  

  a  b   c  d  

  a  b  d  
  a  c  d  

  a  d  
  

  b 

  b  c  

  b  c  d  

  b  d  
 c 
  d 

 c   
 

  c   
 

 c   
 

 

 c   
 

figure    effect of pruning under fixed order search
  a  b  

  a  b  d  

 a 
  a  d  
  

 b 

  b d  

 c 
 d 
 c   
 

  c   
 

  c   
 

  c   
 

 c   
 

figure    optimal pruning under fixed order search
be checked against the list of pruned nodes  consider  for example  the node labeled  a  in
figure    when expanding this node it will be necessary to generate the node labeled  a 
c   even if this node has been marked as pruned  only once it is generated is it possible
to identify it as a node that has been pruned  this node could in principle be pruned
anyway by application of some variant of the technique that identified it as prunable in
the first place  viewed in this light  it can be argued that schlimmers        approach
does not reduce the number of nodes that must be generated under fixed order search 
all that it saves is the computational cost of determining for some nodes whether they
require pruning or not   this assumes that the optimistic pruning mechanism will be able
to determine for any node n from the search space below a pruned node m that n should
also be pruned  irrespective of where n is encountered in the search tree  if the optimistic
pruning mechanism is deficient in that it cannot do this  then schlimmers        approach
will increase the amount of true pruning performed to the extent that it overcomes this
deficiency  

   the feature subset selection algorithm
fixed order search traverses the search space in a naive mannerthe topology of the search
tree is determined in advance and takes no account of the efficiency of the resulting search 
in contrast  the feature subset selection  fss  algorithm  narendra   fukunaga       
performs branch and bound search in unordered search spaces  traversing the search space
   

fiwebb

 c 

  a  b  

  a b  d  

  a 

  

  a  d  
  b 

  b  d  

  d 
 c   
 

  c   
 

 c   
 

 c   
 

 c   
 

figure    pruning under fss like search
so as to visit each state at most once and dynamically organizing the search tree so as to
maximize the proportion of the search space placed under unpromising operators  it can
be viewed as a form of fixed order search in which the order is altered at each node of
the search tree so as to manipulate the topology of the search tree for the sake of search
efficiency  unlike schlimmer         the pruning mechanism ensures that nodes that are
identified as prunable are not generated 
the power of this measure is illustrated by figure    in this figure  fixed order search
is performed on the simple example problem illustrated in figures   to    with the order
changed so that the operator to be pruned  c  is placed first  as can be seen  this achieves
the amount of pruning achieved by optimal pruning  this effect can be achieved with
negligible computational or storage overhead 
however  fss is severely limited in its applicability as
 it is restricted to optimization search 
 it is restricted to tasks for which each operator may only be applied once  subset
selection  
 it is restricted to search for a single solution 
 it requires that the values of states in the search space be monotonically decreasing 
that is  the value of a state cannot increase as a result of an operator application 
and
 the only form of pruning that it supports is optimistic pruning 

   the opus algorithms
the opus algorithms generalize the idea of search space reorganization from fss  two
variations of opus are defined  opuss is a variant for satisficing search  search in which
any qualified object is sought   opuso is a variant for optimization search  search in which
an object that optimizes an evaluation function is sought   whereas fss uses node values
for pruning  opuso uses optimistic evaluation of the search space below a node  this
removes the requirement that the values of states in the search space be monotonically
decreasing and opens the possibility of performing other types of pruning in addition to
optimistic pruning 
   

fian efficient admissible algorithm for unordered search

in the analysis to follow  where comments apply equally to both variants the name
opus will be employed  when a comment applies to only one variant of the algorithm  it
will be distinguished by its respective superscript 
opus uses a branch and bound  lawler   wood        search strategy that traverses
the search space in a manner similar to that illustrated in figure   so as to guarantee
that no two equivalent nodes in the search space are both visited  however  it organizes
the search tree so as to optimize the effect of pruning  achieving the effect illustrated in
figure   without any significant computational or storage overhead 
rather than maintaining an operator order  opus maintains at each node  n  the set
of operators n active that can be applied in the search space below n  when the node is
expanded  the operators in n active are examined to determine if any can be pruned  any
operators that can be pruned are removed from n active  new nodes are then created for
each of the operators remaining in n active and their sets of active operators are initialized
so as to ensure that every combination of operators will be considered at only one node in
the search tree 
it should be kept in mind that it is possible that many states in a search space may
be goal states  for satisficing search all states that satisfy a given criteria are goal states 
for optimization search  all states that optimize the evaluation criteria are goal states  for
efficiency sake  the opus algorithms allow sections of the search space to be pruned even if
they contain a goal state  so long as there remain other goal states in the remaining search
space 
    opuss
the opuss algorithm is presented in figure    this description of opuss follows the
conventions employed in the search algorithm descriptions provided by pearl        
this definition of opuss assumes that a single operator cannot be applied more than
once along a single path through the search space  if an operator may be applied multiple
times  the order of steps  a and  b should be reversed  unless otherwise specified  the
following discussion of opus assumes that each operator may be applied at most once
along a single path 
if it is desired to obtain all solutions that satisfy the search criterion 
 step   should be altered to exit successfully  returning the set of all solutions 
 step  b should be altered to not exit  but rather to add the current node to the set
of solutions  and
 the domain specific pruning mechanisms employed at step   should also be modified
so that no goal state may be pruned from the search space 
this form of search could be used in an assumption based truth maintenance system to find
the set of all maximally general consistent assumptions  this would provide efficient search
without the need to maintain and search an explicit database of inconsistent assumptions
such as the atms no good set  de kleer et al          unless otherwise specified  the
discussion of opus below assumes that a single solution is sought 
the algorithm does not specify the order in which nodes should be selected for expansion
at step    nodes may be selected at random  by a domain specific selection function  or by
   

fiwebb

data structure 
each node  n  in the search tree has associated with it three items of information 
n state the state from the search space that is associated with the node 
n active the set of operators to be explored in the sub tree descending from the node  and
n mostrecentoperator the operator that was applied to the parent nodes state to create the current nodes state 
algorithm 
   initialize a list called op en of unexpanded nodes as follows 
 a  set op en to contain one node  the start node s 
 b  set s active to the set of all operators   o    o       on  
 c  set s state to the start state 
   if op en is empty  exit with failure  no goal state exists 
   remove from op en a node n  the next node to be expanded 
   initialize to n active a set containing those operators that have yet to be examined  called
remainingoperators 
   initialize to    a set of nodes  called n ewn odes  that will contain the descendants of n that
are not pruned 
   generate the children of n by performing the following steps for every operator o in n active 
 a  generate n    a node for which n   state is set to the state formed by application of o to
n state 
 b  if n   state is a goal state  exit successfully with the goal represented by n   
 c  set n   mostrecentoperator to o 
 d  add n  to n ewn odes 
   while there is a node n  in n ewn odes such that pruning rules determine that no sole remaining goal state is accessible from n  using only operators in remainingoperators  prune
all nodes in the search tree below n  from the search tree below n as follows 
 a  remove n  from n ewn odes 
 b  remove n   mostrecentoperator from remainingoperators 
   allocate the remaining operators to the remaining nodes by processing each node n  in
n ewn odes in turn as follows 
 a  remove n   mostrecentoperator from remainingoperators 
 b  set n   active to remainingoperators 
   add the nodes in n ewn odes to op en  
    go to step   

figure    the opuss algorithm
   

fian efficient admissible algorithm for unordered search

the order in which nodes are placed in op en   first in first out node selection results in
breadth first search while last in first out node selection results in depth first search 
the order of processing is also unspecified at steps      and    depending upon the
domain  practical advantage may be obtained by specific orderings at these steps 
opuss has been used in a machine learning context to search the space of all generalizations that may be formed through deletion of conjuncts from a highly specific classification
rule  the goal of this search is to uncover the set of all most general rules that cover
identical objects in the training data to those covered by the original rule  webb      a  
    opuso
a number of changes are warranted if opus is to be applied to optimization search  the
following definition of opuso  a variant of opus for optimization search  assumes that
two domain specific functions are available  the first of these functions  value n   returns
the value of the state for node n  such that the higher the value returned  the higher the
preference for the state    the second function  optimisticv alue n  o  returns a value such
that if there exists a node  b  that can be created by application of any combination of
operators in the set of operators o to the state for node n  and b represents a best solution
 maximizes value for the search space   optimisticv alue n  o  will be no less than value b  
this is used for pruning sections of the search tree  in general  the lower the values returned
by optimisticv alue  the greater the efficiency of pruning  at any time  it is possible to prune
any node with an optimistic value that is less than or equal to the best value of a node
explored to date 
opuso is able to take advantage of the presence of optimistic values to further optimize
the effect of pruning beyond that obtained solely by maximizing the proportion of the
search space placed under nodes that are immediately pruned  generalizing a heuristic
used in fss  nodes with lower optimistic values are given more active operators and thus
have greater proportions of the search space placed beneath them than nodes with higher
optimistic values  this is achieved by the order of processing at step    the rationale
for this strategy is that the lower the optimistic value the higher the probability that the
node and its associated search tree will be pruned before it is expanded  maximizing the
proportion of the search space located below nodes with low optimistic value maximizes the
proportion of the search space to be pruned and thus not explicitly explored 
figure   illustrates this effect with respect to a simple machine learning tasksearch
for a propositional expression that describes the most target examples and no non target
examples  the seven search operators each represent conjunction with a specific proposition
male  f emale  single  married  young  mid and old  respectively  search starts from the
expression anything  a total of     expressions may be formed by conjunction of any
combination of these expressions  twelve objects are defined 
male  single  young  target
male  single  mid  target
male  single  old  target
male  married  young  non target
   for ease of exposition  it will be assumed that optimization means maximization of a value  it would be
trivial to transform the algorithm and discussion to accommodate other forms of optimization 

   

fiwebb

male  married  mid  non target
male  married  old  non target
female  single  young  non target
female  single  mid  non target
female  single  old  non target
female  married  young  non target
female  married  mid  non target
female  married  old  non target 
of these objects  the first three are distinguished as targets  the value of an expression
is determined by two functions  negcover and poscover  the negcover of an expression
is the number of non target objects that it matches  the poscover of an expression is the
number of target objects that it matches  the expression anything matches all objects  the
value of an expression is  if negcover is not equal to zero  otherwise the value equals
poscover  this preference function avoids expressions that cover any negative objects and
favors  of those expressions that cover no negative objects  those expressions that cover the
most positive objects  the optimistic value of a node equals the poscover of the nodes
expression 
figure   depicts the nine nodes considered by opuso for this search task  for each
node the following are listed 
 the expression 
 the number of target and the number of non target objects matched  cover  
 the value 
 the potential value  and
 the operators placed in the nodes set of active operators and hence included in the
search tree below the node 
the search space is traversed as follows  the first node  anything  is expanded  producing its seven children for which values and optimistic values are determined  no node
can be pruned as all have potential values greater than the best value so far encountered 
the active operators are then distributed  maximizing the proportion of the search space
placed below nodes with low optimistic values  of the two nodes with the highest optimistic
values  male and single  one receives no active operator and the other receives the first as
its sole active operator  one or the other is then expanded  if it is the one with no active
operators  single  no further nodes are generated  then the other  male  is expanded  generating a single node  male  single  with a value of    immediately this node is generated 
all remaining open nodes can be pruned as none has an optimistic value greater than this
new maximum value    
note that no nodes can be pruned until the node for malesingle is considered as  up to
that point  no node has been encountered with a lower optimistic value than the best actual
value  consequently  if the search tree was not distributed in accord with potential value  the
set of active operators for the node male would be  f emale  single  married  young  mid  old  
instead of considering a single node when male was expanded  it would be necessary to
   

fian efficient admissible algorithm for unordered search

male
cover    
value infinity
potval  
ao  single 

male  single
cover    
value  
potval  
ao   

female
cover    
value infinity
potval  
ao  male  married 
single  young  mid old  
single
cover    
value infinity
potval  
ao   
anything
cover    
value infinity
potval  
ao  male  female 
married  single 
young  mid  old 

married
cover    
value infinity
potval  
ao  male  single  young 
mid  old  
young
cover    
value infinity
potval  
ao  male  single 
mid  old 
mid
cover    
value infinity
potval  
ao  male  single  old 
old
cover    
value infinity
potval  
ao  male  single 

figure    effect of pruning when search tree ordered on optimistic value

   

fiwebb

consider six nodes  if the search space was more complex and continued to depth three
or beyond  there would be a commensurate increase in the proportion of the search space
explored unnecessarily 
note also that the search in this example does not terminate when the goal node is first
encountered  as the system cannot determine that it is a goal node until all other nodes
that might have higher values have been explored or pruned 
      the opuso algorithm
opuso  the algorithm for achieving the above effect  can be defined as in figure     note
that optimistic pruning need not be performed at step   as it is performed at step   a 
irrespective 
this definition of opuso assumes that a single operator cannot be applied more than
once along a single path through the search space  to allow multiple applications of a single
operator  the order of steps  a and  b should be reversed 
the algorithm could also be modified to identify and return all maximal solutions
through a modification similar to that outlined above to allow opuss to return all solutions 
it is possible to further improve the performance of opuso if there is a lower limit on
an acceptable solution  then  the objective of the search is to find a highest valued node
so long as that value is greater than a pre specified minimum  in this case  all nodes whose
potential value is less than or equal to the minimum may also be pruned at step   a 
like opuss  opuso does not specify the order in which nodes in open should be
expanded  step     selection of a node with the highest optimistic value will minimize the
size of the search tree  if there is a single node n that optimizes the optimistic value  the
search cannot terminate until n has been expanded  this is because no node with a lower
optimistic value may yield a solution with a value higher than the optimistic value of n 
however  an expansion of n may yield a solution that has a value higher than other candidates optimistic values  allowing those other candidates to be discarded without expansion 
thus  selecting a single node with the highest optimistic value is optimal with respect to the
number of nodes expanded because it maximizes the number of nodes that may be pruned
without expansion  where multiple nodes all maximize the optimistic value  at least one
of these must be expanded before the search can terminate  and then the search will only
terminate if expansion of that node leads to a node with a value equal to that optimistic
value  
in many cases it is more important to consider the number of nodes explored by an
algorithm  rather than the number of nodes expanded  a node is explored if it is evaluated 
every time a node is expanded  all of its children will be explored  many of these children
may be pruned  however  and never be expanded  in addition to minimizing the number
of nodes expanded  this form of best first search will also minimize the number of nodes
explored  within the constraint that where nodes have equal optimistic values it is not
possible to anticipate which one to select in order to minimize the number of nodes explored  
this is due to the strategy that the algorithm employs to distribute operators beneath nodes 
the nodes that opuso expands under best first search will be those with highest optimistic
value  opuso always allocates fewer active operators to a node with higher optimistic value
than to a node with lower optimistic value  the number of nodes examined when a node
   

fian efficient admissible algorithm for unordered search

algorithm 
   initialize a list called op en of unexpanded nodes as follows 
 a  set op en to contain one node  the start node s 
 b  set s active to the set of all operators   o    o       on  
 c  set s state to the start state 
   initialize best   the best node examined so far  to s 
   if op en is empty  exit successfully with the solution represented by best  
   remove from op en a node n  the next node to be expanded 
   initialize to n active a set containing those operators that have yet to be examined  called
remainingoperators 
   initialize to    a set of nodes  called n ewn odes  that will contain the descendants of n that
are not pruned 
   generate the children of n by performing the following steps for every operator o in n active 
 a  generate n    a node for which n   state is set to the state formed by application of o to
n state 
 b  if value n    is greater than value best  
i  set best to n   
ii  prune the search tree by removing from op en all nodes x such that
optimisticv alue x  x active  is less than value best   
 c  add n  to n ewn odes 
 d  set n   mostrecentoperator to o 
   while there is a node n  in n ewn odes such that pruning rules determine that no sole remaining goal state is accessible from n  using only operators in remainingoperators  prune
all nodes in the search tree below n  from the search tree below n as follows 
 a  remove n  from n ewn odes 
 b  remove n   mostrecentoperator from remainingoperators 
   allocate the remaining operators to the remaining nodes by processing each node n  in
n ewn odes in turn as follows  each time selecting the previously unselected node that minimizes optimisticv alue n    remainingoperators  
 a  remove n   mostrecentoperator from remainingoperators 
 b  set n   active to remainingoperators 
    perform optimistic pruning while adding the remaining nodes to op en by processing each
node n  in n ewn odes in turn as follows 
 a  if optimisticv alue n    n   active  is greater than value best   
i  add n  to op en  
    go to step   

figure     the opuso algorithm

   

fiwebb

n is expanded equals the number of active operators at n  hence  the number of nodes
examined for those nodes expanded will be minimized  within the constraints of the use
only of information that can be derived from the current state and the operators that are
active at that state  
however  while this best first approach minimizes the number of nodes expanded  it may
not be storage optimal due to the large potential storage overheads  if the storage overhead
is of concern  depth first rather than best first traversal may be employed  at the cost of a
potential increase in the number of nodes that must be expanded  if depth first search is
employed  nodes should be added to op en by order of optimistic value at step     this
will ensure that nodes open at a single depth will be expanded in a best first manner  with
the benefits outlined above 
      relation to previous search algorithms
opuso can be viewed as an amalgamation of fss  narendra   fukunaga        with a 
 hart  nilsson    raphael         fss performs branch and bound search in unordered
search spaces  traversing the search space so as to visit each state at most once and dynamically organizing the search tree so as to maximize the proportion of the search space placed
under unpromising operators  however  fss requires that the values of states in the search
space be monotonically decreasing  that is  the value of a state cannot increase as a result
of an operator application  opuso generalizes from fss by employing both the actual
values of states and optimistic evaluation of nodes in the search tree  in a manner similar
to a   in consequence  there are only two minor constraints upon the values of states and
the optimistic values of nodes in the search spaces that opuso can search  these are the
requirements that
 for at least one goal state g and for any node n  if g lies below a node n in the search
tree  the optimistic value of n be no lower than the value of g  and
 that any and only states of maximal value be goal states 
it follows that opuso has wider applicability than fss 
opuso also differs from fss by integrating pruning mechanisms other than optimistic
pruning into the search process  this facility is crucial when searching large search spaces
such as those encountered in machine learning 
a further innovation of the opus algorithms is the use of the restricted set of operators
available at a node in the search tree to enable more focused pruning than would otherwise
be the case  there may be circumstances in which it would be possible to reach a goal
from the state at a node n  but only through application of operators that are not active
at n  the pruning rules are able to take account of the active operators to provide pruning
in this contextpruning that would not otherwise be possible  similarly  the set of active
operators can be used to calculate a more concise estimate of the optimistic value than
would otherwise be possible 
opuso differs from a  in the manner in which it dynamically organizes the search tree
so as to maximize the proportion of the search space placed under unpromising operators 
it also differs from a  in that a  relies upon the value of a node being equivalent to the
   

fian efficient admissible algorithm for unordered search

sum of costs of the operations that lead to that node  whereas opus allows any method
for determining a nodes value 
rymon        discusses dynamic organization of the search tree during admissible search
through unordered search spaces for the purpose of altering the topology of the data structure  se tree  produced  this contrasts with the use of dynamic organization of the search
tree in opuso to increase search efficiency 
    opus and non admissible search
as was pointed out above  although the opus algorithms were designed for admissible
search  if they are applied with non admissible pruning rules they may also be used for
non admissible search  this may be useful if efficient heuristic search is required  most
non admissible heuristic search strategies embed the heuristics in the search technique  for
example  beam search relies upon the use of a fixed maximum number of alternative options
that are to be considered at any stage during the search  the heuristic is to prune all but
the n best solutions at each stage during search  the precise implications of this heuristic
for a particular search task may be difficult to evaluate  in contrast  the use of opus with
non admissible pruning rules places the non admissible heuristic in a clearly defined rule
which may be manipulated to suit the circumstances of a particular search problem 
another feature of opuso is that at all stages it has available the best solution encountered to date during the search  this means that the search can be terminated at any
time  when terminated prematurely  the current best solution would be returned on the
understanding that this solution may not be optimal  if the algorithm is to be employed
in this context  it may be desirable to employ best first search  opening nodes with highest
actual  as opposed to optimistic  value first  on the assumption that this should lead to
early investigation of high valued nodes 
    complexity and efficiency considerations
opus ensures that no state is examined more than once  unless identical states can be
formed by different combinations of operator applications   using a similar search tree organization strategy to that of fixed order search  it differs  however  in that instead of placing
the largest subsection of the search space under the highest ordered operator  the second
largest subsection under the second highest ordered operator  and so on  whenever pruning
occurs  the largest possible proportion of the search space is placed under the pruned node 
and hence is immediately pruned 
if there are n operators active at the node e being expanded  the search tree below and
including that node will contain every combination of any number of those operators  the
application of none of the operators results in e   thus  the search tree below and including
e will contain  n nodes  exactly half of these   n    will have a label including any single
operator o  opus ensures that if any operator o is pruned when a node e is expanded  that
all nodes containing o are removed from the search tree below e and are never examined
 except  of course  the node reached by a single application of o that must be examined in
order to determine that o should be pruned   thus  the search tree below a node is almost
exactly halved if a single operator can be pruned  each subsequent operator pruned at
that node reduces the remaining search tree by the same proportion  thus  the size of the
   

fiwebb

remaining search tree is divided by almost exactly  p   where p is the number of operators
pruned 
in contrast  the number of nodes pruned under fixed order search depends upon the
ranking of the operator within the fixed operator ranking scheme  only for the highest
ranked operator will the same proportion of the search tree be pruned as under opus  in
general  when an operator is pruned  only those nodes whose labels include that operator in
combination exclusively with lower ranked operators will be pruned  this effect is illustrated
in figure   in which pruning below  c  removes only  c  d  from the search tree  thus 
 nr     nodes are immediately pruned from the search tree  where n is the number of
operators active at the node being expanded and r is the ranking within those operators of
the operator being pruned  with the highest rank being    this contrasts with the  n    
nodes pruned by opus 
however  the difference in the number of nodes explored under the two strategies is not
quite as great as this analysis might suggest  as  assuming the availability of a reasonable
optimistic pruning mechanism  fixed order search can also prune the operator every time
that it is examined deeper in the search tree in combination with higher ranked operators 
thus  in figure    when they were eventually examined  pruning would occur at nodes
 a  b  c    a  c  and  b  c   thus   a  b  c  d    a  c  d  and  b  c  d  would also be pruned from
the search tree  in other words  under fixed order search  if an operator is pruned it will not
be considered in combination with any lower ranked operator  but will be considered with
every combination of any number of higher ranked operators  there are  r  combinations
of higher ranked operator  it follows that fixed order search considers this many more nodes
than opus when a single operator is pruned  thus  for each operator that can be pruned
at a node n  opus explores  r  less nodes below n than fixed order search 
as the rank order of the operators pruned will tend to grow as the number of operators
grows  it follows that  in the average case  the advantage accrued from the use of opus will
grow exponentially as the number of operators grows  opus will tend to have the greatest
relative advantage for the largest search spaces 
note that opus is not always able to guarantee that the maximal possible pruning
occurs as the result of a single pruning action  for example  if opus is being used to
search the space of subsets of a set of items  and it can be determined that no superset
of the set s at a node may be a solution  but some items are not active at the current
node  supersets of s that contain the items that are not active may be explored elsewhere
in the search tree  an algorithm that could prune all such supersets could perform more
pruning than opus  while it might be claimed that schlimmers        search method
performs such pruning  it should be recalled that it does not prevent the pruned nodes from
being generated elsewhere in the tree  but rather  ensures that such nodes are pruned once
generated  opus  if armed with suitable pruning rules  should also be able to prune such
nodes when encountered  opus maximizes the pruning performed within the constraints
of the localized information to which it has access 
however  while the constraint provided by the active operators prevents opus from
performing some pruning  it also enables it to perform other pruning that would not otherwise be possible  this is because it is only necessary when considering whether to prune
a node to determine whether nodes that can be reached by active operators may contain a
solution  thus  to continue the example of subset search  even when supersets of the set at
   

fian efficient admissible algorithm for unordered search

the current node n are potential solutions  it will still be possible to prune the search tree
below n if all of the supersets that are potential solutions contain items that are not active
at n  schlimmers        approach does not allow pruning in such a context 
to illustrate this effect  let us revisit the search space examined in figures   to    even
though the search space below  c  has been pruned  optimal pruning cannot take this
into account in its optimistic evaluations of other nodes as there is no mechanism by which
this information can be communicated to the optimistic evaluation function  other than by
actually exploring the space below the node to be evaluated  which defeats the purpose of
optimistic evaluation   for example  when evaluating the optimistic value of the node  a  
the optimistic evaluation function cannot return a different value than would be the case
if  c  had not been pruned  by contrast  the optimistic evaluation function employed by
opuso can take account of this by taking the active operators for the current node into
consideration  such an optimistic evaluation function is described in section     below  it
will often be possible to use the information that particular operators are not available in
the search tree below a node to substantially improve the quality of the optimistic evaluation
of that node 
it should also be noted that no algorithm that does not employ backtracking can guarantee that it will minimize the number of nodes expanded under depth first search  if a
poor node is chosen for expansion under depth first search  the system is stuck with having
to explore the search space below that node before it can return to explore alternatives  no
algorithm can guarantee against a poor selection unless the optimistic evaluation function
has high enough accuracy to prevent the need for backtracking  it follows that no algorithm
that requires backtracking can guarantee that it will minimize the number of nodes that are
expanded  thus  opus is heuristic with respect to minimizing computational complexity
under depth first search 
the storage requirements of opus will depend upon whether depth  breadth or bestfirst search is employed  if depth first search is employed  the maximum storage requirement
will be less than the maximum depth of the search tree multiplied by the maximum branching factor  however  if breadth or best first search is employed  in the worst case  the storage
requirement is exponential  at any stage during the search  the storage requirement is that
of storing the frontier nodes of the search  the number of frontier nodes cannot exceed the
number of leaf nodes in the complete search tree  for search in which no operator may be
applied more than once  subset selection   if there is no pruning  the number of leaf nodes
is  n    where n is the number of operators  this assertion can be justified as follows  if
the order in which operators are considered is invariant  all nodes reached via the last operator considered will be a leaf node  as the search is admissible  the last operator must be
considered with every combination of other operators  there are  n    other combinations
of operators  the order in which operators are considered will not alter the number of
leaf nodes in the absence of pruning  for search in which there is no limit on the number
of applications of a single operator  sub multiset selection  there is no upper limit on the
potential storage requirements 
irrespective of the storage requirements  in the worst case opus will have to explore
every node in the search space  this will only occur if no pruning is possible during a search 
if operators can only be applied once per solution  the number of nodes in the search space
will equal  n   where n is the number of operators  thus  the worst case computational
   

fiwebb

complexity of opus is exponential  irrespective of whether depth  breadth or best first
search is employed 
opus is clearly inappropriate  both in terms of computational and  when using breadth
or best first search  storage requirements  for search problems in which substantial proportions of the search space cannot be pruned  for domains in which substantial pruning is
possible  however  the average case complexity  computational and or storage  may turn
out to be polynomial  experimental evidence that this is indeed the case for some machine
learning tasks is presented below in section     
    how the search efficiency of opus might be improved
as is noted in section      the opus algorithms are not always able to guarantee that the
maximum possible amount of pruning is performed  as noted  one restriction upon the
amount of pruning performed is the localization inherent in the use of active operators 
while this localization allows some pruning that would not otherwise be possible  it also
has the potential to restrict the number of supersets of the set of operators at a pruned
node that are also pruned  there may be value in developing mechanisms that enable
such pruning to be propagated beyond the node at which a pruning action occurs and the
sub tree below that node 
another aspect of the algorithms that has both positive and negative aspects is the type
of information returned by the pruning mechanisms  these mechanisms allow the pruning
of any branch of the search tree so long as at least one goal is not below that branch  this
contrasts with an alternative strategy of only pruning branches that do not lead to any
goal  the strategy used can be beneficial  as it maximizes the amount of pruning that can
be performed  however  it is always possible that a branch containing a goal that could
be found with little exploration will be pruned in favor of a branch containing a goal that
requires extensive exploration to uncover  there is potential for gain through augmenting
the current pruning mechanisms with means of estimating the search cost of uncovering a
goal beneath each branch in a tree 

   evaluating the effectiveness of the opus algorithms
theoretical analysis has demonstrated that opus will explore fewer nodes than fixed order
search and that the magnitude of this advantage will increase as the size of the search
space increases  however  the precise magnitude of this gain will depend upon the extent
and distribution within the search tree of pruning actions  of further interest  there are a
number of distinct elements to each of the opus algorithms  includingoptimistic pruning 
other pruning  pruning in addition to optimistic pruning   dynamic reorganization of the
search tree  and maximization of the proportion of the search space placed under nodes with
low optimistic value  the following experiments evaluate the magnitude of the advantage
to opus obtained for real world search tasks and explore the relative contribution of each
of the distinct elements of the opus algorithms 
to this end  opuso was applied to a class of real search tasksfinding pure conjunctive
expressions that maximize the laplace accuracy estimate with respect to a training set of
preclassified example objects  this is  for example  the search task that cn  purports to
heuristically approximate  clark   niblett        when forming the disjuncts of a disjunc   

fian efficient admissible algorithm for unordered search

tive classifier  machine learning systems have employed opuso in this manner to develop
rules for inclusion both in sets of decision rules  webb        and in decision lists  webb 
    b    the current experiments were performed using the cover learning system  which 
by default  performs repeated search for pure conjunctive classifiers within a cn  like covering algorithm that develops disjunctive rules  this more extended search for disjunctive
rules was not used in the experiments  as it makes it difficult to compare alternative search
algorithms  this is because  if two alternative algorithms find different pure conjunctive
rules for the first disjunct  their subsequent search will explore different search spaces  
numerous efficient admissible search algorithms exist for developing classifiers that are
consistent with a training set of examples  the two classic algorithms for this purpose are
the least generalization algorithm  plotkin        and the version space algorithm  mitchell 
       the least generalization algorithm finds the most specialized class description that
covers all objects in a training set containing only positive examples  the version space algorithm finds all class descriptions that are complete and consistent with respect to a training
set of both positive and negative examples  hirsh        has generalized the version space
algorithm to find all class descriptions that are complete and consistent to within defined
bounds of the training examples  the least generalization and version space algorithms will
usually require a strong inductive bias in the class description language  restriction on the
types of class descriptions that will be considered  if they are to find useful class descriptions
 mitchell         se tree based learning  rymon        demonstrates admissible search for
a set of consistent class descriptions within more complex class description languages than
may usefully be employed with the least generalization or version space algorithms  oblow
       describes an algorithm that employs admissible search for pure conjunctive terms
within a heuristic outer search for k dnf class descriptions that are consistent with the
training set 
however  for many learning tasks it is desirable to consider class descriptions that are
inconsistent with the training set  one reason for this is that the training set may contain
noise  examples that are inaccurate   another reason is that it may not be possible to accurately describe the target class in the available language for expressing class descriptions 
in this case it is necessary to consider approximations to the target class  a further reason
is that the training set may contain insufficient information to reliably determine the exact
class description  in this case  the best solution may be an approximation that is known to
be incorrect but for which there is strong evidence that the level of error is low 
both clearwater and provost        and segal and etzioni        use admissible fixedorder search to explore classifiers that are inconsistent with the training set  however  the
admissible search of clearwater and provost        is not computationally feasible for large
search spaces  segal and etzioni        bound the depth of the search space considered in
order to maintain computational tractability  smyth and goodman        use optimistic
pruning to search for optimal rules  but do not structure their search to ensure that states
are not searched multiple times  no other previous admissible search algorithm has been
employed in machine learning to find classifiers that are inconsistent with the training
set and maximize an arbitrary preference function  the following experiments seek to
demonstrate that such search is feasible using opus 
where it is allowed that a class description may be inconsistent with the training set 
it is helpful to employ an explicit preference function  such a function is applied to a
   

fiwebb

class description and returns a measure of its desirability  this evaluation will usually take
account of how well the description fits that training set and may also include a bias toward
particular types of class descriptions  for example  a preference for syntactic simplicity  such
a preference function expresses an inductive bias  mitchell        
opuso may be employed for admissible search in such contexts  provided a search space
can be defined that may be traversed by a finite number of unordered search operators 
for example  opuso may be employed to search for a class description in a language of
pure conjunctive descriptions by examining a search space starting with the most general
possible class description true and employing search operators  each of which has the effect
of conjoining a specific clause to the current description  such search may be performed
with an arbitrary preference function  provided appropriate optimistic evaluation functions
can be defined 
the next section describes experiments in which opuso was applied in this manner 
    the search task
the pure conjunctive expressions consisted of conjunctions of clauses of the form attribute   
value  for attributes with more than two values  such a language is more expressive than
a language allowing only conjunctions of clauses of the form attribute   value  indeed 
it has equivalent expressiveness to a language that supports internal disjunction  for example  with respect to an attribute a with the values x  y and z  a language restricted to
conjunctions of equality expressions cannot express a    x  whereas a language restricted to
conjunctions of inequality expressions can express a   x using the expression a    y  a    z 
in internal disjunctive  michalski        terms  a    x is equivalent to a   y or z 
it should be noted that
 for attributes with more than two values the search space for conjunctions of inequality expressions is far larger than the search space for conjunctions of equality
expressions  for each attribute  the size of the search space is multiplied by  n for the
former and by n     for the latter  where n is the number of values for the attribute 
 the software employed in this experimentation can also be used to search the smaller
search spaces of equality expressions with the same effects as are demonstrated in the
following experiments 
search starts from the most general expression  true  each operator performs conjunction of the current expression with a term a    v  where a is an attribute and v is any
single value for that attribute 
the laplace  clark   boswell        preference function was used to determine the goal
of the search  this function provides a conservative estimate of the predictive accuracy of
a class description  e  it is defined as
value e   

poscover e     
poscover e    negcover e    noof classes

where poscover e  is the number of positive objects covered by e  negcover e  is the
number of negative objects covered by e  and noof classes is the number of classes for the
learning task 
   

fian efficient admissible algorithm for unordered search

the laplace preference function trades off accuracy against generality  it favors class
descriptions that cover more positive objects over class descriptions that cover fewer  and
favors class descriptions for which a lower proportion of the cover is negative over those for
which it is higher  in the following study  the laplace preference function was employed
with a pruning mechanism at step   a of the opuso algorithm that pruned sections of
the search space with optimistic values less than or equal to the value of a class description
that covered no objects  if there was no solution with a value higher than that obtained by
a class description that covered no objects  no rule was developed for the class 
the optimistic value function is derived from the observation that the cover of specializations of an expression must be subsets of the cover of that expression  thus  specializations
of an expression may not cover more positive objects  but may cover fewer negative objects
than are covered by the original expression  as the laplace preference function is maximized when positive cover is maximized and negative cover is minimized  no specialization
of the expression at a node may have higher value than that obtained with the positive
cover of that expression and the smallest negative cover within the sub tree below the node 
the smallest negative cover within a sub tree below a node n is obtained by the expression
formed by applying all operators active at n to the expression at n 
other pruning can be performed through the application of cannotimprove n    n     a
boolean function that is true of any two nodes n  and n  in the search tree such that n  is
either the child or sibling of n  and no specialization of n  may have a higher value than
the highest value in the search tree below n  inclusive but excluding the search tree below
n    this function may be defined as
cannotimprove x  y   neg x   neg y   pos x   pos y 
where neg n  denotes the set of negative objects covered by the description for node n
and pos n  denotes the set of positive objects covered by the description for node n  if
cannotimprove n    n    then search below n  cannot lead to a higher valued result than can
be obtained by search through specializations of n  excluding nodes in the search space
below n    this can be shown where n  is the parent and n  is the child node as follows  if
n  is the parent of n  then the expression for n  must be a specialization of the expression
for n  and all operators available for n  must be available for n    for any expression g
and its specialization  s  if neg g   neg s  then neg g    neg s   as specialization can
only decrease cover   it follows that for any further specialization of n    n    obtained by
applications of operators o  there must be a specialization of n  obtained by application
of operators o  n    which is a generalization of n  and which has identical negative cover
to n    as n  is a generalization of n    it must cover all positive objects covered by n   
therefore  n  must have equal or greater positive cover and equal negative cover to n  and
consequently must have an equal or greater value  it follows that it must be possible to
reach from n  a node of at least as great a value as the greatest valued node below n 
without applying the operator that led from n  to n   
next we consider the case where n  and n  are siblings  it follows from the definition
of cannotimprove that neg n     neg n    and pos n     pos n     let the operators o 
and o  be those that led from the parent node p to n  and n    respectively  it follows that
o  cannot exclude any negative objects from expressions below p not also excluded by o 
and that o  cannot exclude any positive objects from expressions below p not also excluded
   

fiwebb

table    summary of experimental data sets

domain
audiology
house votes   
lenses
lymphography
monk  
monk  
monk  
multiplexor  f   
mushroom
primary tumor
slovenian breast cancer
soybean large
tic tac toe
wisconsin breast cancer

description
medical diagnosis
predict us senators political
affiliation from voting record 
spectacle lens prescription 
medical diagnosis 
artificial data 
artificial data 
artificial data 
artificial data  requiring disjunctive concept description 
identify poison mushrooms 
medical diagnosis 
medical prognosis 
botanical diagnosis 
identify won or lost positions 
medical diagnosis 

 
values
   
  

 
objects
   
   

 
classes
  
 

 
  
  
  
  
  

  
   
   
   
   
   

 
 
 
 
 
 

   
  
  
   
  
  

    
   
   
   
   
   

 
  
 
  
 
 

by o    therefore  application of o  below n  will have no effect on the negative cover of
the expression but may reduce positive cover  for any expression e reached below n  by a
sequence of operator applications o  application of o to n  cannot result in an expression
with lower positive or higher negative cover than that of e 
the cannotimprove function was employed to prune nodes at step   of the opuso
algorithm 
    experimental method
this search was performed on fourteen data sets from the uci repository of machine learning
databases  murphy   aha         these were all the data sets from the repository that the
researcher could at the time of the experiments identify as capable of being readily expressed
as a categorical attribute value learning tasks  these fourteen data sets are described in
table    the number of attribute values  presented in column    treats missing values as
distinct values  the space of class descriptions that opus considers for each domain  and
hence the size of the search space examined for each pure conjunctive rule developed  is
 n   where n is the number of attribute values  thus  for the audiology domain  for each
class description developed  the search space was of size        columns   and   present the
number of objects and number of classes represented in the data set  respectively 
the search was repeated once for each class in each data set  for each such search  the
objects belonging to the class in question were treated as the positive objects and all other
objects in the data set were treated as negative objects  this search was performed using
   

fian efficient admissible algorithm for unordered search

each of the following search methodsopuso  opuso without optimistic pruning  opuso
without other pruning  opuso without optimistic reordering  and fixed order search  such
as performed by clearwater and provost         rymon         schlimmer         segal
and etzioni        and webb        
optimistic pruning was disabled by removing the condition from step   a of the opuso
algorithm  in other words  step    a i was always performed 
other pruning was disabled by removing step   from the opuso algorithm 
optimistic reordering was disabled by changing step   to process each node in a predetermined fixed order  rather than in order by optimistic value  under this treatment  the
topology of the search tree is organized in a fixed order  but operators that are pruned at
a node are removed from consideration in the entire subtree below that node 
fixed order search was emulated by disabling step  b and disabling optimistic reordering  as described above 
all of the algorithms are to some extent under specified  opuso  no optimistic pruning
and no other pruning are all leave unspecified the order in which operators leading to nodes
with equal optimistic values should be considered at step    such ambiguities were resolved
in the following experiments by ordering operators leading to nodes with higher actual
values first  where two operators tied on both optimistic and actual values  the operator
mentioned first in the names file that describes the data was selected first 
no optimistic reordering and fixed order search both leave unspecified the fixed order
that should be employed for traversing the search space  as fixed order search is representative of previous approaches to unordered search employed in machine learning  and thus
it is important to obtain a realistic evaluation of its performance  ten alternative random
orders were generated and all employed for each fixed order search task  while  due to
the high variability in performance under different orderings  it would have been desirable
to explore more than ten alternative orderings  this was infeasible due to the tremendous
computational demands of this algorithm  the comparison with no optimistic reordering
was considered less crucial  as it is used solely to evaluate the effectiveness of one aspect
of the opuso algorithm  and thus  due to the tremendous computational expense of this
algorithm  a single fixed ordering was used  employing the order in which attribute values
are mentioned in the names file 
all of the algorithms leave unspecified the order in which nodes with equal optimistic
values should be selected from op en under best first search  or directly expanded under
depth first search  under best first search nodes with equal optimistic values were removed
from op en in a last in first off order  under depth first search  nodes with equal optimistic
value were expanded in the same order as was employed for allocating operators at step   
note that the fixed order search and opuso with disabled optimistic reordering conditions both used optimistic and other pruning  note also that while fixed order search
ordered the topology of the search tree in the manner depicted in figure    it explored that
tree in either a best or depth first manner 
    experimental results
tables   and   present the number of nodes examined by each search in this experiment 
for each data set the total number of nodes explored under each condition is indicated 
   

fiwebb

table    number of nodes explored under best first search

data set
audiology
house votes   
lenses
lymphography
monk  
monk  
monk  
multiplexor  f   
mushroom
primary tumor
slovenian b  c 
soybean large
tic tac toe
wisconsin b  c 

opuso
     
   
  
     
   
     
   
     
   
      
      
     
     
       

no
optimistic
pruning

   
   
     
     
     
      
      
   
      
         
    
         


no
other
pruning
      
   
  
     
   
     
   
     
   
      
      
      
     
         

no
optimistic
reordering

       
  
       
   
      
   
     
       
         

          
      


fixed order
 mean 

         
  
         
   
     
   
     

          
          

      


 execution terminated after exceeding virtual memory limit of     megabytes 
 only one of ten runs completed 

for fixed order search  the mean of all ten runs is presented  tables   and   present for
fixed order search the number of runs that completed successfully  the minimum number of
nodes examined by a successful run  the mean number of nodes examined by successful runs
 repeated from tables   and    and the standard deviations for those runs  every node
generated at step  a is counted in the tally of the number of nodes explored  a hyphen
   indicates that the search could not be completed as the number of open nodes made
the system exceed a predefined virtual memory limit of     megabytes  an asterisk    
indicates that the search was terminated due to exceeding a pre specified compute time
limit of twenty four cpu hours   for comparison  the longest cpu time taken for any data
set by opuso was sixty seven cpu seconds on the wisconsin breast cancer data under
depth first search  
it should be noted that one pure conjunctive rule was developed for each class  as a
separate search was performed for each rule  the number of searches performed equals the
number of classes  thus  for the audiology data using best first search opuso explored
just       nodes to perform    admissible searches of the      node search space 
for only two search tasks does opuso with best first search explore more nodes than an
alternative  for the lenses data  opuso explores    nodes while no optimistic reordering
explores     for the monk   data  opuso explores       nodes while the best of ten fixedorder runs with different random fixed orders explores       nodes  it is possible that these
outcomes have arisen from situations where two sibling nodes share the same optimistic
value  in such a case  if two approaches each select different nodes to expand first  one
   

fian efficient admissible algorithm for unordered search

table    number of nodes explored under depth first search

data set
audiology
house votes   
lenses
lymphography
monk  
monk  
monk  
multiplexor  f   
mushroom
primary tumor
slovenian b  c 
soybean large
tic tac toe
wisconsin b  c 

opuso
     
   
  
     
   
      
   
     
   
      
      
     
     
       

no
optimistic
pruning
 
          
   
          
      
      
      
       
 
          
           
 
          
 

no
other
pruning
      
   
  
     
   
      
   
     
   
      
      
      
     
         

no
optimistic
reordering
         
      
  
       
   
      
   
     
         
         
           
          
      
 

fixed order
 mean 
 
         
  
          
     
      
     
     
           
          
           
 
       
 

  execution terminated after exceeding the    cpu hour limit 
 only three of ten runs completed 

table    number of nodes explored under best first fixed order search
data set
audiology
house votes   
lenses
lymphography
monk  
monk  
monk  
multiplexor  f   
mushroom
primary tumor
slovenian b  c 
soybean large
tic tac toe
wisconsin b  c 

runs
 
  
  
  
  
  
  
  
 
  
 
 
  
 

minimum

       
  
       
   
     
   
     

          
          

     


mean

sd


         
  
         
   
     
   
     

          
          

      



       
 
         
   
   
   
   

          
 

     


 execution terminated for all ten runs after exceeding the
virtual memory limit of     megabytes 

   

fiwebb

table    number of nodes explored under depth first fixed order search
data set
audiology
house votes   
lenses
lymphography
monk  
monk  
monk  
multiplexor  f   
mushroom
primary tumor
slovenian b  c 
soybean large
tic tac toe
wisconsin b  c 

runs
 
  
  
  
  
  
  
  
 
  
  
 
  
 

minimum
 
         
  
       
   
     
   
     
           
          
           
 
      
 

mean

sd

 
         
  
          
     
      
     
     
           
          
           
 
       
 

 
         
  
          
   
     
   
     
          
          
           
 
      
 

  execution terminated for all ten runs after exceeding the
   cpu hour limit 

may turn out to be a better choice than the other  leading to the exploration of fewer
nodes  to test the plausibility of this explanation  opuso was run again on the lenses
data set with step   altered to ensure that where two siblings have equal optimistic value
they are ordered in the same order as was employed with no optimistic reordering  this
resulted in the exploration of just    nodes  fewer than any alternative  when opuso and
fixed order were run with fixed order using the order of attribute declaration in the data
file to determine operator order and opuso using the same order to order siblings with
equal optimistic values  the numbers of nodes explored for the monk   data were       for
opuso and       for fixed order search 
it is notable that this effect is only apparent for very small search spaces  this is
significant because it suggests that there is only an effect of small magnitude resulting from
a poor choice of node to expand when two nodes have equal optimistic value  this is to
be expected  consider the case where there are two nodes n  and n  with equal highest
optimistic value  v  but n  leads to a goal whereas n  does not  if n  is expanded first  so
long as no child of n  has an optimistic value greater than or equal to v  the next node to
be expanded will be n    as n  will now be the node with the highest optimistic value   if a
child of n  has an optimistic value greater than v  the optimistic evaluation function cannot
be very good  as the fact that n  had an optimistic value of v means that no node below n 
can have a value greater than v   thus  the number of unnecessary node expansions due to
this effect can never exceed the number of times that nodes with equal highest optimistic
values are encountered during the search 
in contrast to the case with best first search  as discussed in section      opus is only
heuristic with respect to minimizing the number of nodes expanded under depth first search 
   

fian efficient admissible algorithm for unordered search

nonetheless  for only one search task  the monk   data set  does opuso explore more
nodes under depth first search          than an alternative  both no optimistic reordering
and fixed order search that explore        and        nodes respectively   these results
demonstrate that this heuristic is not optimal for this data  it should be noted  however 
that the single exception for depth first search again occurs only for a relatively small search
space  this suggests that efficient exploration of the search space below a poor choice of
node can do much to minimize the damage done by that poor choice  even when there is
no backtracking as is the case for depth first search 
for five data sets  house votes     lymphography  mushroom  primary tumor and
soybean large   disabling optimistic pruning has little effect under best first search  disabling optimistic pruning always has large effect under depth first search  under best first
search the smallest increase caused by disabling optimistic pruning is an increase of just
one node for both the lymphography and mushroom data sets  of those data sets for
which it was possible to complete the search without optimistic pruning  the biggest effect
was an almost       fold increase in the number of nodes explored for the tic tac toe
data  under depth first search  of those data sets for which processing could be completed
without optimistic pruning  the smallest increase was a five fold increase for the monk  
data and the largest increase was a        fold increase for the lymphography data 
for seven data sets  house votes     lenses  monk    monk    monk    f   multiplexor 
tic tac toe  disabling other pruning had little or no effect under best first or depth first
search  the largest effects are     fold increases for the soybean large and wisconsin
breast cancer data sets under best first search and for the audiology  soybean large and
wisconsin breast cancer data sets under depth first search 
from these results it is apparent that while there are some data sets for which each
pruning technique has little effect  so long as the other is also employed   there are also
data sets for which other pruning more than halves the amount of the search space explored
and data sets for which optimistic pruning reduces the amount of the search space explored
to thousandths of that which would otherwise be explored 
the effect of optimistic reordering was also highly variable  for two search tasks  bestfirst search for the lenses data set and depth first search for the monk   data set  its use
actually resulted in a slight increase in the number of nodes explored  this is discussed
above  in many cases  however  the effect of disabling optimistic reordering was far greater
than that of disabling optimistic pruning  processing could not be completed without
optimistic reordering for three of the best first search tasks and one of the depth first search
tasks  of those tasks for which search could be completed  the largest effect for best first
search was a       fold increase in the number of nodes explored for the soybean large data 
under depth first search  of those tasks for which search could be completed  the largest
effect was an       fold increase for the slovenian beast cancer data  while it would be
desirable to evaluate the effect of alternative fixed orderings of operators on these results 
it seems that optimistic reordering is critical to the general success of the algorithm 
for all but one data set  the monk   data under depth first search   fixed order search
on average explores substantially more nodes than opuso  it was asserted in section    
that the average case advantage from the use of opuso as opposed to fixed order search
will tend to grow exponentially as the number of search operators increases  the number
of search operators for the search tasks above equal the number of attribute values in the
   

filog advantage

webb

  
  
  
  
  
  
  
  
  
  
  
 
 
 
 
 
 
 
 
 
 
  













 best first search
 depth first search


 
  

                                              
search space size

figure     plot of difference in nodes explored by fixed order and opuso search against
search space size 

corresponding data sets  analysis of tables   and   reveals that the relative advantage
to opuso for the data sets with fewest attribute values  lenses  monk      and    and
f   multiplexor  is approximately a two fold reduction in the number of nodes examined 
as the number of attribute values increases  so does the relative advantage  for the four
data sets with the greatest number of attribute values  audiology  mushroom  soybean
large and wisconsin breast cancer  in only one case  depth first search of the mushroom
data  does the fixed order search terminate  in this one case  opuso enjoys a         fold
advantage  these results lend credibility to the claim that opusos average case advantage
over fixed order search is exponential with respect to the size of the search space  this is
illustrated in figure     in this figure  for searches for which fixed order search terminated
within the resource constraints  the size of the search space is plotted against log   f  o 
where f is the number of nodes explored by fixed order search and o is the number of nodes
explored by opuso 
it seems clear from these results that admissible fixed order search is not practical for
many of these search tasks within the scope of current technology 
it is interesting to observe that under best first search  for all of the four artificial data
sets  monk    monk    monk   and f   multiplexor  fixed order search often explores
slightly fewer nodes than opuso with optimistic reordering disabled  the difference between these two types of search is that the latter deletes pruned operators from the sets
of active operators under higher ordered operators whereas the former does not  thus
the latter prunes more nodes from the search tree with each pruning operation  it seems
   

fian efficient admissible algorithm for unordered search

counter intuitive that this increased pruning should sometimes lead to the exploration of
more nodes  to understand this effect it is necessary to recall that other pruning can prune
solutions from the search tree so long as there are alternative solutions available  for the
artificial data sets in question  retaining alternative solutions in the search tree in some cases
leads to a slight increase in search efficiency as the alternative can be encountered earlier
than the first solution  despite this minor advantage for a number of artificial data sets to
fixed order search over opuso with optimistic reordering disabled  the latter enjoys a large
advantage for all other data sets for which processing could be completed  for the house
votes    data  fixed order search explores over     times as many nodes under best first
search and over     times as many under depth first search 
it can be seen that there is some reason to believe that the the average case number
of nodes explored by opuso is only polynomial with respect to the search space size for
these machine learning search tasks  the numbers of nodes explored for the three largest
search spaces are certainly not suggestive of an exponential explosion in the numbers of
nodes examined  audiology     nodes in the search space        and       nodes examined  soybean large     nodes in the search space        and       nodes examined 
mushroom     nodes in the search space      and     nodes examined  
it is interesting that there is little difference in the number of nodes explored by opuso
using either best or depth first search for most data sets  surprisingly  slightly fewer nodes
are explored by depth first search for three of the data sets  audiology  lenses and mushroom   this will be for similar reasons to those presented above in the context of the occasional slight advantage enjoyed by fixed order search over opuso with optimistic reordering
disabled  in some cases depth first search fortuitously encounters alternative solutions to
those found by best first search  to evaluate the plausibility of this explanation  opuso
was run on the three data sets in question using the fixed order ordering to order operators
with equal optimistic values  the resulting numbers of nodes explored were audiology 
      lenses     and mushroom       as can be seen  these numbers are in all cases lower
than the numbers of nodes explored under depth first search  as is the case when opuso
was outperformed by other best first strategies  this effect appears to be of small magnitude
and thus is only significant where small numbers of nodes need to be explored  for four
of the data sets depth first search explores substantially more nodes than best first search
 slovenian breast cancer       monk          primary tumor       and tic tac toe 
     
    summary of experimental results
the experiments demonstrate that admissible search for pure conjunctive classifiers is feasible using opuso for the types of learning task contained in the uci repository 
they also support the theoretical findings that opuso will in general explore fewer
nodes than fixed order search and that the magnitude of this advantage will tend to grow
exponentially with respect to the size of the search space 
optimistic pruning and other pruning are both demonstrated to individually provide
large decreases in the number of nodes explored for some search spaces but to have little
effect for others  optimistic reordering is demonstrated to have a large impact upon the
number of nodes explored 
   

fiwebb

the results with respect to the search of the largest search spaces suggest that the
average case complexity of the algorithm is less than exponential with respect to search
space size 

   summary and future research
the opus algorithms have potential application in many areas of endeavor  they can
be used to replace admissible search algorithms for unordered search spaces that maintain
explicit lists of pruned nodes  such as currently used in atms  de kleer         they
may also support admissible search in a number of application domains  such as learning
classifiers that are inconsistent with a training set  that have previously been tackled by
heuristic search 
in addition to their applications for admissible search  the opus algorithms may also be
used for efficient non admissible search through the application of non admissible pruning
rules  the opuso algorithm is also able to return a solution if prematurely terminated at
any time  although this solution may be non optimal 
the availability of admissible search is an important step forward for machine learning
research  while the studies in this paper have employed opuso to optimize the laplace
preference function  the algorithm could be used to optimize any learning bias  this means
that for the first time it is possible to isolate the effect of an explicit learning bias from
any implicit learning bias that might be introduced by a heuristic search algorithm and its
interaction with that explicit bias 
the application of opuso to provide admissible search in machine learning has already
proved to be productive  webb        used opuso to demonstrate that heuristic search
that fails to optimize the laplace accuracy estimate within a covering algorithm frequently
results in the inference of better classifiers than found by admissible search that does optimize this preference function  it was to explain this result that quinlan and cameron jones
       developed their theory of oversearching 
the research reported herein has demonstrated that opus can provide efficient admissible search for pure conjunctive classifiers on all categorical attribute value data sets in the
uci repository  it would be interesting to see if the techniques can be extended to more
powerful machine learning paradigms such as continuous attribute value and first order logic
domains 
the research has also demonstrated the power of pruning  this issue has been given
scant attention in the context of search for machine learning  although it is presented here
in the context of admissible search  the pruning rules presented are equally applicable to
heuristic search  the development of these and other pruning rules may prove important
as machine learning tackles ever more complex search spaces 
opus provides efficient admissible search in unordered search spaces  when creating
a machine learning system it is necessary to consider not only what to search for  the
explicit learning biases  but also how to search for it  appropriate search algorithms   it
has been assumed previously that such algorithms must necessarily be heuristic techniques
for approximating the desired explicit biases  admissible search decouples these two issues
by removing confounding factors that may be introduced by the search algorithm  by
guaranteeing that the search uncovers the defined target  admissible search makes it possible
   

fian efficient admissible algorithm for unordered search

to systematically study explicit learning biases  by supporting efficient admissible search 
opus for the first time brings to machine learning the ability to clearly and explicitly
manipulate the precise inductive bias employed in a complex machine learning task 

acknowledgements
this research has been supported by the australian research council  i am grateful to
riichiro mizoguchi for pointing out the potential for application of opus in truth maintenance  i am also grateful to mike cameron jones  jon patrick  ron rymon  richard
segal  jason wells  leslie wells and simon yip for numerous helpful comments on previous
drafts of this paper  i am especially indebted to my anonymous reviewers whose insightful 
extensive and detailed comments greatly improved the quality of this paper 
the breast cancer  lymphography and primary tumor data sets were provided by the
ljubljana oncology institute  slovenia  thanks to the uci repository  its maintainers 
patrick murphy and david aha  and its donors  for providing access to the data sets used
herein 

references
buchanan  b  g   feigenbaum  e  a     lederberg  j          a heuristic programming
study of theory formation in science  in ijcai     pp       
clark  p     boswell  r          rule induction with cn   some recent improvements  in
proceedings of the fifth european working session on learning  pp         
clark  p     niblett  t          the cn  induction algorithm  machine learning    
       
clearwater  s  h     provost  f  j          rl   a tool for knowledge based induction  in
proceedings of second intl  ieee conf  on tools for ai  pp       los alamitos  ca 
ieee computer society pres 
de kleer  j          an assumption based tms  artificial intelligence             
de kleer  j   mackworth  a  k     reiter  r          characterizing diagnoses  in proceedings aaai     pp         boston  ma 
hart  p   nilsson  n     raphael  b          a formal basis for the heuristic determination
of minimum cost paths  ieee transactions on system sciences and cybernetics 
ssc               
hirsh  h          generalizing version spaces  artificial intelligence          
lawler  e  l     wood  d  e          branch and bound methods  a survey  operations
research              
michalski  r  s          a theory and methodology of inductive learning  in michalski 
r  s   carbonell  j  g     mitchell  t  m   eds    machine learning  an artificial
intelligence approach  pp         springer verlag  berlin 
   

fiwebb

mitchell  t  m          version spaces  a candidate elimination approach to rule learning 
in proceedings of the fifth international joint conference on artificial intelligence 
pp         
mitchell  t  m          the need for biases in learning generalizations  technical report
cbm tr      rutgers university  department of computer science  new brunswick 
nj 
moret  b  m  e     shapiro  h  d          on minimizing a set of tests  siam journal on
scientific and statistical computing                 
murphy  p     aha  d          uci repository of machine learning databases   machinereadable data repository   university of california  department of information and
computer science  irvine  ca 
murphy  p     pazzani  m          exploring the decision forest  an empirical investigation
of occams razor in decision tree induction  journal of artificial intelligence research 
          
narendra  p     fukunaga  k          a branch and bound algorithm for feature subset
selection  ieee transactions on computers  c            
nilsson  n  j          problem solving methods in artificial intelligence  mcgraw hill  new
york 
oblow  e  m          implementing valiants learnability theory using random sets  machine learning          
pearl  j          heuristics  intelligent search strategies for computer problem solving 
addison wesley  reading  mass 
plotkin  g  d          a note on inductive generalisation  in meltzer  b     mitchie  d 
 eds    machine intelligence    pp          edinburgh university press  edinburgh 
quinlan  j  r     cameron jones  r  m          oversearching and layered search in
empirical learning  in ijcai    pp           montreal  morgan kaufmann 
reiter  r          a theory of diagnosis from first principles  artificial intelligence     
     
rymon  r          search through systematic set enumeration  in proceedings kr     pp 
       cambridge  ma 
rymon  r          an se tree based characterization of the induction problem  in proceedings of the      international conference on machine learning san mateo  ca 
morgan kaufmann 
schlimmer  j  c          efficiently inducing determinations  a complete and systematic
search algorithm that uses optimal pruning  in proceedings of the      international
conference on machine learning  pp         san mateo  ca  morgan kaufmann 
   

fian efficient admissible algorithm for unordered search

segal  r     etzioni  o          learning decision lists using homogeneous rules  in aaai   
smyth  p     goodman  r  m          an information theoretic approach to rule induction
from databases  ieee transactions on knowledge and data engineering            
    
webb  g  i          techniques for efficient empirical induction  in barter  c  j    
brooks  m  j   eds    ai    proceedings of the third australian joint conference
on artificial intelligence  pp         adelaide  springer verlag 
webb  g  i          systematic search for categorical attribute value data driven machine
learning  in rowles  c   liu  h     foo  n   eds    ai    proceedings of the sixth
australian joint conference on artificial intelligence  pp         melbourne  world
scientific 
webb  g  i       a   generality is more significant than complexity  toward alternatives to
occams razor  in zhang  c   debenham  j     lukose  d   eds    ai    proceedings of the seventh australian joint conference on artificial intelligence  pp      
armidale  world scientific 
webb  g  i       b   recent progress in learning decision lists by prepending inferred
rules  in spicis    proceedings of the second singapore international conference
on intelligent systems  pp  b   b    singapore 

   

fi