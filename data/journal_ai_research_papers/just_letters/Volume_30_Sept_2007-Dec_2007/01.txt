journal of artificial intelligence research                   

submitted        published      

graph abstraction in real time heuristic search
vadim bulitko
nathan sturtevant
jieshan lu
timothy yau

bulitko   ualberta   ca
nathanst   cs   ualberta   ca
jieshan   cs   ualberta   ca
thyau   ualberta   ca

department of computing science  university of alberta
edmonton  alberta  t g  e   canada

abstract
real time heuristic search methods are used by situated agents in applications that require the
amount of planning per move to be independent of the problem size  such agents plan only a
few actions at a time in a local search space and avoid getting trapped in local minima by improving their heuristic function over time  we extend a wide class of real time search algorithms
with automatically built state abstraction and prove completeness and convergence of the resulting
family of algorithms  we then analyze the impact of abstraction in an extensive empirical study in
real time pathfinding  abstraction is found to improve efficiency by providing better trading offs
between planning time  learning speed and other negatively correlated performance measures 
keywords  learning real time heuristic search  state abstraction  goal directed navigation 

   introduction and motivation
in this paper we study the problem of agent centered real time heuristic search  koenig        
the distinctive property of such search is that an agent must repeatedly plan and execute actions
within a constant time interval that is independent of the size of the problem being solved  this
restriction severely limits the range of applicable algorithms  for instance  static search algorithms
 e g   a  of hart  nilsson    raphael         re planning algorithms  e g   d  of stenz        
anytime algorithms  e g   ara  of likhachev  gordon    thrun        and anytime re planning
algorithms  e g   ad  of likhachev  ferguson  gordon  stentz    thrun        cannot guarantee a
constant bound on planning time per action  lrta  provides such guarantees by planning only a
few actions at a time and updating its heuristic function  but the solution quality can be poor during
a lengthy convergence process  korf        ishida        
as a motivating example  consider navigation in gridworld maps in commercial computer
games  in such games  an agent can be tasked to go to any location on the map from its current
location  the agent must react quickly to the users command regardless of the maps size and
complexity  consequently  game companies impose a time per action limit on their pathfinding algorithms  as an example  bioware corp   a major game company  limits planning time to     ms
for all pathfinding units  and there can be many units planning simultaneously  
an additional challenge comes in the form of limited sensing in virtual reality trainers where
artificial intelligence controlled characters may not have access to the entire map a priori  in order
to avoid unrealistic behavior  dini  van lent  carpenter    iyer         such agents have to build
an internal map model based on sensing a limited amount of the map around their position 
an efficient search agent would minimize the delay incurred while planning its actions  explore
and learn the environment quickly  and always discover an optimal path to the goal  unfortunately 
c
    
ai access foundation  all rights reserved 

fib ulitko   s turtevant  l u     yau

these measures are negatively correlated  or antagonistic  in that optimizing performance for one
measure results in worse performance for one of the others  for instance  reducing the amount of
planning done before each action improves the agents response time  but leads to slower learning
due to lower quality actions taken by the agent 
we propose to use graph abstraction to improve efficiency of search agents and make the
following four contributions  first  we introduce a new algorithm  path refinement learning
real time search  pr lrts     which enhances existing real time heuristic search algorithms with
automatically built graph abstraction  pr lrts learns its heuristic function in an abstract space
thereby substantially accelerating learning  actions in the abstract space are then refined to actions
in the environment by the a  algorithm  this approach allows agents to generate actions in constant
time  explore the environment quickly  and converge to near optimal solutions  in this paper we use
the previously published clique abstraction  sturtevant   buro         our contributions specific
to abstraction are three fold  first  we introduce the initial clique building and the repair procedure
in more detail than previously published  second  we prove a worst case bound on suboptimality
of the path induced by abstraction  third  we present the first application of state abstraction to
real time heuristic search 
the standard practice in the heuristic search literature is to promote new algorithms as trading a
small amount of one performance measure for a large gain in another performance measure  for
instance  state abstraction in non real time heuristic search has been shown to trade little solution
quality for a substantial reduction in running time  e g   holte  mkadmi  zimmer    macdonald 
      botea  muller    schaeffer         unfortunately  it is not always clear whether the tradeoffs are made optimally  as the second contribution  we demonstrate that pr lrts outperforms
a number of other algorithms with respect to two antagonistic measures  e g   learning speed and
amount of planning per action  
as the third contribution  we analyze effects of abstraction on search with respect to commonly
used performance measures  solution suboptimality  amount of planning per action  total travel 
total planning time  and memory footprint  knowing the effects deepens our understanding of realtime heuristic search methods as well as guides a practitioner in selecting the most appropriate
search algorithm configuration for her application  fourth  we show theoretically that pr lrts
unifies and extends several well known existing heuristic search algorithms and satisfies the realtime operation  completeness  and convergence properties  this contribution can be viewed as a
follow up to previous unification and extension efforts  bulitko   lee        
the rest of the paper is organized as follows  we begin by formulating the problem of real time
heuristic search in section    the new algorithm  pr lrts  is described in section    empirical
results follow in section    theoretical results are presented in section    we then review existing
agent centered search algorithms as well as work on automatic graph abstraction in section    the
paper is concluded by a discussion of current limitations and future research 

   real time heuristic search
the defining property of real time heuristic search is that the amount of planning performed by an
agent per action has a constant upper bound that does not depend on the problem size  low bounds
are preferred in applications  as they guarantee the agents fast response when presented with a new
goal  a real time search agent plans its next action by considering states in a local search space
   an early version of this algorithm was published as a conference paper  bulitko  sturtevant    kazakevich        

  

fig raph a bstraction in r eal   time h euristic s earch

  sc  s 
  while sc    sg do
 
sense the environment  update agents model
 
compute partial path p that originates in the current state sc
 
execute p
 
update current state sc
  end while
figure    real time heuristic search  a single trial  
surrounding its current position  a heuristic function  or simply heuristic  estimates the cumulative
cost between a state and the goal  and is used by the agent to rank available actions and select the
most promising one  this process is shown schematically in figure    agents current state sc is
set to the initial state s  in line    as long as the goal sg is not reached  line     the agent senses
the environment around it  see section   for details  and updates its model of the search graph it
is operating on in line    then it computes a  partial  path from its current state toward the goal
state in line    the real time property requires that lines   and   execute in a constant bounded time
regardless of problem size  this is accomplished by calling a real time heuristic search algorithm
in line    in this paper  we discuss three candidate algorithms  lrta  in section      lrts in
section      and pr lrts in section    each of them would be called from line    the agent then
executes the path in line   and updates its current state in line   
a trial is defined as the agents problem solving experience while traveling from its start state
to the goal state  once the goal state is reached  the agent is teleported to the start state and the next
trial begins  a convergence process is defined as the first sequence of trials until the agent no longer
updates its heuristic function or its model of the search problem  the first trial without such updates
is the final trial and the learning process is said to have converged 
    learning real time a   lrta  
we first review the best known real time heuristic search algorithm  learning real time a 
 lrta    korf         the algorithm is shown in figure    in line    a d ply breadth first search
with duplicate detection is used to find frontier states precisely d actions away from the current state
s  the standard path max  mero        technique is used to deal with possible inconsistencies in
the heuristic function when computing g   h values  the value of each state  s  is the sum of the
cost of a shortest path from sc to s  denoted by g s  s   and the estimated cost of a shortest path
from s to sg  i e   the heuristic value h s  sg     the state that minimizes the sum is identified as s 
in line    the heuristic value of the current state s is updated in line    finally  a path of one action
toward the most promising frontier state s  is returned in line   
path lrta  sc   sg   d 
 
 
 
 

generate successor states of sc up to d actions away
find state s  with the lowest g sc   s      h s    sg  
update h sc   sg   to g sc   s      h s    sg   if it is greater than the current h
return the first action along an optimal path from sc to s 
figure    the lrta  algorithm 

  

fib ulitko   s turtevant  l u     yau

    learning real time search  lrts 
lrts extends lrta  in three ways  it puts a weight on the heuristic function  it uses the maxof min learning rule  and it utilizes backtracking  we review these extensions in more detail in
section     and walk through lrts operation below  lrts has three control parameters  lookahead
d  n  optimality weight           and learning quota t         it operates as follows  in the
current state sc   the agent running lrts conducts a full width d ply lookahead search  line   in
figure     at each ply  it finds the most promising state  line     assuming that the initial heuristic
h is admissible  it can safely increase h sc   to the maximum among the f  values of promising states
for all levels  line     if the total learning amount u  updated in line    exceeds the learning quota
t   the agent backtracks to the previous state from which it planned  lines        otherwise  it returns
a path of d moves between the current state sc and the most promising state at level d  line     the
learning amount u is reset to   when the agent is in the start state  i e   at the beginning of each trial  
path lrts sc   sg   d    t  
 
 
 

generate successor states of sc   i actions away  i           d
on level i  find the state si with the lowest f  si       g sc   si     h si   sg  
update h sc   sg   to max f  si   if it is greater than the current h

 
 
 
 
 
 

increase the amount of learning u by h
if u  t then
return a path of d actions from sc to sd
else
return a path of d actions to backtrack to the previous state  set u   t
end if

 id

figure    the lrts algorithm 
lrts parameters have been previously studied at length  bulitko   lee         here we summarize the trends  higher lookahead d reduces convergence travel  convergence memory  and suboptimality  however  it increases the first move lag  a lower heuristic weight  leads to less optimal
solutions and  generally speaking  reduces convergence travel and convergence memory  first move
lag is not influenced by   a lower learning quota t causes more backtracking and tends to reduce
convergence travel and convergence memory  t does not affect the first move lag 
    notation
definition     a search problem is defined as a tuple  g  c  s    sg   h    where g    s  e  is a
directed weighted graph  henceforth search graph   s is a finite set of states  or vertices  and
e  s  s is a finite set of edges between them  the edge weights are defined by the cost function
c   e        with c s    s    being the travel cost for the edge e    s    s     s   s is the start
state  sg  s is the goal state  and h    s        is the initial heuristic function  we assume
that h   sg        out edges of a state are called moves or actions  the number of out edges  i e  
out degree of a state  is called the branching factor of a state 
definition     a solution to a search problem is a path from the start state s  to the goal state sg  
the path is denoted by  s    s            sg   where each si is a valid state and there is a valid edge for
each pair of states  si   si      the travel cost of a path is the sum of travel costs of its edges 
  

fig raph a bstraction in r eal   time h euristic s earch

definition     at all times  a search agent resides in a single search state sc  s called the current
state  the agent can change its current state only by executing actions and thus incurring travel
cost  initially  the current state coincides with the start state s    an agent is said to succeed when it
makes its current state coincide with the goal state sg  
we assume that the goal state is reachable from any state the agent can get to from its start
state  this is needed for completeness in all real time heuristic search algorithms  we also follow
the standard practice in real time heuristic search literature and assume that the environment is
stationary and deterministic  additionally  to support backtracking  shue   zamani        shue 
li    zamani         i e   reversing agents actions   we require that every action has a reverse
action  this is needed only when backtracking is enabled in our algorithm 
definition     the travel cost from state s  to state s  denoted by dist s    s    is defined as the cost
of a shortest path from s  to s    throughout the paper  we will assume that dist satisfies the triangle
inequality  s    s    s   s  dist s    s     dist s    s      dist s    s      then  for any state  s  h  s 
is defined as the minimal travel cost to the goal  h  s    dist s  sg    a heuristic function  h  is an
approximation of h   it admissible if it does not overestimate h   s  s  h s   h  s    the value
of h in state s will be referred to as the heuristic value of state s  we assume that for any heuristic
function h sg       which trivially holds for an admissible h 
in our experiments we break all ties between moves in a fixed fashion  e g   always prefer the
action north  then north east  then east  etc   which entails that the agents behavior will be
identical on all trials after the final trial  it does not necessarily mean that the entire search graph is
explored or the learned heuristic is accurate for all states 
definition     convergence travel is the cumulative cost of all edges traversed by the agent during
the convergence process  convergence planning is the amount of all planning effort expended by the
agent during the convergence process  the first move lag is the amount of planning effort expended
by the agent on the first move of its final trial  convergence memory is measured as the total
number of heuristic values stored during the convergence process  the standard practice in the realtime heuristic search literature  e g   korf        shimbo   ishida        is to store the heuristic
values in a hash table  hash table misses are handled by a procedurally specified initial heuristic h 
 e g   the manhattan distance in grid based pathfinding   then convergence memory is the number
of entries in the hash table after convergence  finally  suboptimality is defined in percentage points
as the final trial solution cost excess relative to the shortest path cost  for instance  if the agent
incurred the travel cost of     and the shortest path cost is      the suboptimality is     
we measure planning effort in two ways  first  we report the number of states the algorithm
touched  i e   considered  during planning  this measure is called edges traversed  e g   holte
et al         p        second  we report physical cpu time  measured on a    ghz powerpc g 
computer with gcc     under mac os         we measure convergence memory in terms of the
number of heuristic values stored  this is meaningful because each heuristic value stored takes the
same fixed amount of memory  i e   double type of c    in our implementation of each algorithm 
definition     a search algorithm exhibits real time performance on a heuristic search problem if
its planning effort per move is constant bounded and the constant is independent of the problem size
 assuming a fixed maximum branching factor  
  

fib ulitko   s turtevant  l u     yau

the objectives of a real time search agent are to be complete  i e   to arrive at a goal state on
every trial   to converge  i e   finish the learning process after a finite number of trials   and to
minimize the five performance measures described above  in the rest of the paper we will discuss
how existing and the new algorithms compare in terms of these objectives 
    application  goal directed navigation
one of the motivating applications of heuristic search is goal directed navigation  also known as
pathfinding  it is a special case of the heuristic search problem formalized in the previous section
where the search graph  s  e  is defined by a terrain map  thus  the states vertices correspond to
geographical positions on a map  the edges describe passability or blocking  and the cost function
represents the difficulty time of traversing the terrain 
real time pathfinding is motivated primarily by time sensitive robotics  e g   koenig   simmons        koenig        kitano  tadokoro  noda  matsubara  takahashi  shinjou    shimada 
      koenig  tovey    smirnov        and computer games  the latter include real time strategy
games  e g   blizzard entertainment         first person shooters  e g   id software         and roleplaying games  e g   bioware corp          in all of these  time plays a critical role since a number
of agents can perform pathfinding simultaneously and gamers would like rapid response and fluid
gameplay  as a result  pathfinding has become a major computational expense  in age of empires
ii  ensemble studios        it takes up to        of the simulation time  pottinger        
in this paper  we follow the footsteps of furcy and koenig         shimbo and ishida        
koenig         botea et al          hernandez and meseguer      a      b   sigmundarson and
bjornsson         koenig and likhachev        and situate our empirical study in navigation on
two dimensional grid based maps  the cells are square and each cell is connected to four cardinally
 i e   west  north  east  south  and four diagonally neighboring cells  each cell can be occupied by
an agent  i e   free  or by a wall  i e   blocked  
each free grid cell constitutes a vertex state in the search space s  if the agent can travel between
any two free neighboring cells  s  and s    an edge  s    s 
  is added to the set of edges e  in this
paper  we set the edge costs to   for cardinal moves and to   for diagonal moves  the cell initially
occupied by the agent is s    the target cell is sg   an example of converting a grid based map to
a search problem defined by  g  c  s    sg   h    is shown in figure    note that we do not allow
diagonal moves that cut corners and  thus  the state s  is not connected to states s    s    s    sg  
this is done because a non zero size agent will not be able to pass through a zero width bottleneck
formed by two diagonally adjacent blocked cells  in the case when there is only one corner  e g  
between states
 s  and s  in figure     allowing to cut it would lead to the actual travel distance
exceeding   since a non zero width agent will have to walk around the corner 
video games often feature repeated pathfinding experiences on the same map for two reasons 
 i  there are units that commute between the same source and destination  e g   resource collectors in
real time strategy games  and  ii  all ally units can share results of their learning  i e   the heuristic
function   since a trial typically improves heuristic values of many states  even a single trial of a
single unit can be of use to other units with different start states as long as they all share a goal
state  this is often the case with state abstraction as an entire region of a map  e g   a room in a
role playing game or the players home base in a real time strategy game  can be mapped into a
single abstract state  thus  single trial learning experiences of multiple units can be approximated
by multi trial learning experience of a single unit  the latter is the scenario we study in this paper  in
  

fig raph a bstraction in r eal   time h euristic s earch

goal

s 

s 

sg

s 

start

s 

s 

s 

s 

s 

s 

figure    a    grid based map  left  converted to a   state search graph  right   thinner
 cardinaldirection edges have the cost of    thicker diagonal edges have the cost of   
line with furcy and koenig         shimbo and ishida         sigmundarson and bjornsson       
and others 

   search graph discovery
in this paper  we do not require a search agent to know the problem in its entirety  instead  a portion
of the search problem in the neighborhood of the current state sc is sensed by the agent at each time
step  we assume that an agent can remember parts of the problem it has sensed so far  in other
words  at all times an agent has an internal representation  model  of what the search space is like 
the model is updated as the agent discovers the search graph  line   of figure    
let us illustrate the exploration process in goal directed navigation  the terrain map is initially
unknown to the agent  as it moves around the environment  grid cells whose coordinates are within
a fixed visibility radius of the agents current position are sensed  formally  the agent situated in cell
 x  y  can check the status  free blocked  of any cell  x    y     if  x  x     r and  y  y      r  where
r  n is a visibility radius  thus  for any two visible cells  x    y     and  x     y      the agent can tell
if there is an edge between them and its cost  this is similar to virtual sensors used by thalmann 
noser  and huang        
one common approach is to assume a regular structure of the unknown part of the search
space  koenig et al         koenig        bulitko   lee        koenig   likhachev         for
instance  in grid based pathfinding  the agent can assume that there are no obstacles in the gridworld
until it senses otherwise  this is sometimes called the free space assumption   we demonstrate
this in figure    where the agent assumes that the space is obstacle free  a  and builds its internal
model accordingly  b   exploration reveals obstacles in the environment  c  which cause the agent
to update its model  d   we impose the restriction that a search agent never needs to add edges to its
model during exploration and the weights of discovered edges never change  in other words  agents
initial model is optimistic and contains a superset of edges of the actual search graph  adding edges
or allowing arbitrary edge weight changes may require the agent to explore the environment explicitly  combining exploration and exploitation effectively is an active research area  for early work 
refer to sutton        and is not addressed in this paper 
map discovery is natural in robotics where sensors have limited ranges  in software domains 
the agent can theoretically have access to an entire environment  several types of arguments have
been made to justify restricting an agents senses in software domains  first  omniscient virtual
  

fib ulitko   s turtevant  l u     yau

actual search space 

agent s model 

explored actual search space 

updated agent s model 

 a 

 b 

 c 

 d 

figure     a   initially only the part of the search space shown with solid lines is sensed by an agent
 shown as a stick figure   the agents model assumes a regular structure for the unknown
part  b   as the agent moves north east  it senses an additional part of the search space
 c  and updates its model correspondingly  d  
humans tend to behave unrealistically and  thus  are less suitable for virtual reality trainers  dini
et al          likewise  in commercial games  revealing the entire map to an ai player is viewed
negatively as cheating  second  it can be computationally expensive to sense  orkin        and
reason about an entire environment  thalmann et al         aylett   luck         consequently 
localized sensing is used in large scale multi unit systems  reynolds        

   path refinement learning real time search  pr lrts 
real time heuristic search algorithms plan using a small part of the search graph that surrounds
an agents current state  in order to avoid getting stuck in infinite loops  they update the heuristic
function over time  this approach guarantees that each action is planned in a constant bounded
amount of time  the downside is slow convergence 
the central idea of pr lrts is to address this downside by running real time search on a
smaller abstract search graph and then refining the produced abstract path into a ground level path 
the abstract graph is an image of the original graph under an abstraction operator  the operator
maps a region of states in the original graph to a single abstract state in the abstract graph  when
applied multiple times  a hierarchy of abstractions are formed  the hierarchy is a forest  a tree for
each connected component of the search graph  and will be formalized in section     
a variety of terminologies have been used in the literature for discussing the relationship between states at different levels of abstraction  in different contexts the abstract states have been
referred to as clusters  botea et al          sectors regions  sturtevant         and images  holte
et al          because the abstraction is a forest  and in line with  bacchus   yang        bulitko
et al         sturtevant   buro         we sometimes call an image of an abstraction operator parent
and its pre image children  these terms are not to be confused with successor states in lookahead
search  we first describe pr lrts at an intuitive level and illustrate it with an example in section      then we give formal details in section     and describe the abstraction operator in detail 
    path refinement
pr lrts computes paths at several levels of abstraction  first  a path is found through the most
abstract search space  at level     such an abstract path defines a region of the lower level abstract
  

fig raph a bstraction in r eal   time h euristic s earch

path pr lrts sc   sg  
 
 
 
 
 
 
 
 
 
  
  
  
  

if level sc       then
return 
end if
p  pr lrts parent sc    parent sg   
if p     then
sg   child end p  
end if
c    s   parent s   p 
switch algorithm level sc    
a    return a  sc   sg   c 
lrts   return lrts sc   sg   c 
pass through   return p
end switch

figure    the pr lrts algorithm 
space that will be searched when refining the abstract path  this refinement proceeds incrementally
until the level    i e   ground  search space is reached and a ground path is produced  in order to
keep the amount of planning per move constant bounded regardless of the ground space size  we
need to have a real time algorithm on the most abstract search graph  in this paper  we use lrts at
a fixed top level of abstraction      and a  for refinement at the lower levels   some abstract levels
can be left as pass through to merely increase the amount of state aggregation  no processing is
carried out at them  this design choice was motivated by experimentation  section    
pr lrts operates recursively as presented in figure    in line   it checks if the states passed
to it are above the top level of abstraction on which pathfinding is to occur  if so  an empty path
is returned  line     otherwise  the function calls itself recursively to compute a path between the
abstract image of sc  denoted by parent sc   in line    and the abstract image of sg   the returned
path  if non empty as checked in line    is used to derive the new destination in line    specifically 
the new destination sg is a child of the end of the abstract path p   in line    we compute the
corridor c comprised of pre images of the states on path p  the corridor c will be empty if the
path p computed in line   was empty  finally  we run the algorithm assigned to our current level of
abstraction  i e   the level of sc and sg   in lines    and     it will be the a  or the lrts tasked to
find either a full  in the case of a   or a partial path  in the case of lrts  from sc to sg limited to
the set of states c  by convention  an empty corridor  c     allows a  lrts to search its entire
graph  note that no processing happens at a pass through level  line      
   because an agent explores its environment while moving about  we actually use a local repair a  instead of a   it
is described in section   
   while any child can be used  some choices may lead to better performance  intuitively  the child chosen by
child end p   should be the closest representative of the abstract state end p  among children end p    in
pathfinding  we implement child s  to return the element of children s  that is geographically closest to the average coordinates of states in children s   also  if the goal state sg happens to be in the pre image of end p  then
we pick it as child end p   
   also note that the functions child and parent handle pass through levels  specifically  in line    the state sg will be
computed by child at the first non pass through level below the level at which path p is computed  likewise  in line
   the states s forming the corridor c are at the first non pass through level  level i  below the level of path p  level
j   thus  parent s  will apply the abstraction mapping j  i times so that parent s  and p are both at level j 

  

fib ulitko   s turtevant  l u     yau

our implementation of a  is standard  hart et al         except it is run  line     on a subgraph
defined by the corridor c  line     our implementation of lrts is taken from the literature  bulitko
  lee        and is described in section      like a   we run lrts in the corridor c 

figure    the path refinement process  the original graph  level    is shown at the bottom  the
abstract graph  level    is shown at the top 
for illustration purposes  consider an example in figure    in the example        so only one
level of abstraction  shown at the top  is used in addition to the ground level  shown at the bottom  
sc is the current state while sg is the destination state  lrts is assigned to level   while a  is
assigned to level    subfigure  i  shows the ground state space below and one level of abstraction
above  the agent must plan a path from sc to sg located at the ground level  first  the abstract
parents of sc and sg   parent sc     s c and parent sg     s g   are located  then lrts with d    
plans three steps in the abstract space  ii   a corridor c at the ground level comprised of children
of the abstract path is then built  iii   a child representing the end of the abstract path is set as the
new destination sg  iv   finally  a  is run within the corridor to find a path from sc to the new
destination sg  v  
while an agent is executing a path computed by pr lrts  new areas of the search graph may
be seen  this causes updates to the abstraction hierarchy that the agent maintains  pr lrts clears
and recomputes its abstract paths upon discovering new areas of the search graph  also  if a ground
path proves invalid  e g   runs into a newly discovered obstacle   the execution stops and pr lrts
replans from the current state using the updated abstraction hierarchy 
graph discovery can lead to arbitrary updates to the abstract search graphs an agent maintains 
in our implementation  lrts operating on an abstract graph resets its heuristic function if its abstract search graph is updated in any way  on the other hand  updates to the ground level graph are
limited to state and edge removals  section     consequently  the heuristic learned at the ground
level remains admissible and there is no need to reset it upon updates 
    automatic graph abstraction
we use the term abstraction operator  or abstraction  for short  to mean a graph homomorphism in
line with holte et al          namely  abstraction is a many to one function that maps  abstracts 
one or more states to a single abstract state  adjacent vertices are mapped to adjacent or identical
vertices  property   below   given such a graph homomorphism function and a model of a search
problem  a pr lrts agent builds   additional abstract search graphs  collectively called an abstrac  

fig raph a bstraction in r eal   time h euristic s earch

tion hierarchy  as follows  it first applies the graph homomorphism to the search graph of the model
 called ground level graph   the result is an abstract search graph at level    the process is then
repeated until an abstract search graph at level   is computed  any homomorphic abstraction can be
used as long as the resulting hierarchy of abstract graphs satisfies several key properties  in the following we introduce the properties informally and illustrate them with an example  in appendix b
we formalize them 
property   every abstract graph is a search graph in the sense of definition     in section   
property   every state has a unique abstract parent  except states at the top level of abstraction  
property   every state at any abstract level  has at least one child state below 
property   given a heuristic search problem  the number of children of any abstract state is upperbounded by a constant independent of the number of states in the ground level graph 
a corollary of this property is that the number of ground level states that abstract into a single
state at any fixed level of abstraction is also constant bounded with a constant independent of the
ground level graph size 
property    graph homomorphism  every edge in the search graph at a level of abstraction has
either a corresponding edge at the level above or the states connected by the edge abstract into a
single abstract state 
property   if an abstract edge exists between two states then there is an edge between at least some
child of one state and some child of the other 
property   any two children of an abstract state are connected through a path whose states are all
children of the abstract state 
property   the abstraction hierarchy is consistent with agents model of its search problem at all
times  that is  properties   through   are satisfied with respect to the agents model 
in this paper  we use a clique based abstraction mechanism  sturtevant   buro         it operates by finding fully connected components  cliques  in the search graph and mapping each to a
single abstract state  this method of building abstractions is favored in recent analysis by sturtevant
and jansen        and earlier analysis by holte et al         section      who showed that reduction
of search effort due to abstraction is maximized by minimizing edge diameter of the set of children
and maximizing its size  for any clique  its edge diameter  i e   the maximum number of edges
between any two elements  is one while the number of states in a clique is maximized 
we present the clique based abstraction mechanism by developing several stages of a handtraceable example  we then illustrate how each of the properties introduced above is satisfied in the
example  a formal introduction of the clique abstraction technique complete with pseudocode is
found in appendix a  we review other ways of building abstraction in section      note that while
general clique computation is np complete  finding cliques in two dimensional grid based search
graphs can be done efficiently  appendix a  
  

fib ulitko   s turtevant  l u     yau

a single application of the abstraction procedure is illustrated in figure    cliques of size four
are first located in the graph  meaning that states s    s    s  and s  are abstracted into s     there are
no cliques of size three which are not already abstracted in the first step  so cliques of size two will
be abstracted next  this includes s  and s  which are abstracted into s     and s  and s  which are
abstracted into s     because sg has degree    we add it to s     however s  has degree two  so it is
abstracted into its own parent  s     adding degree   states to their neighbors reduces the number of
resulting abstract states but increases the edge diameter of the set of children  it becomes   for the
set  s    s    sg     this is a minor detail of our abstraction that happens to be effective in grid based
pathfinding  one can use pure clique abstraction as well 
s 

s 

sg

s  

s 
s 

s 

s  

s 
s  

s 

s 

s  

s 

level    original graph 

level    abstract graph 

figure    clique abstraction  the original search graph from figure   shown on the left is abstracted
into the search graph on the right 

s 

s 

sg

s  
s   

s 
s 

s 

s  

s 
s  

s 

s 

s   
 

s  

s   

s 

level    original graph 

level  

level  

level  

figure    three iterations of the clique abstraction procedure 
the abstraction process can be successively applied until a single abstract state for each connected component of the original graph remains  figure    level     we can now illustrate the
abstraction properties with figure    property   requires that each of the four abstraction levels
in figure   is a search graph in the sense of definition     in section    property   requires each
  

fig raph a bstraction in r eal   time h euristic s earch

state at levels       and   to have a unique parent at the level above  property   requires that each
state at levels       and   has a non empty set of children at the level below  property   places an
upper bound on the number of children each abstract state can have  in this example the bound is
   properties   and   require that  for any two abstract states connected by a path  their parents and
any of their children are also connected  consider  for instance  abstract states s   and s     they are
connected at level   as there is an abstract path p    s     s     s     s     between them  thus  any child
of s   is also connected to any child of s   at level    for instance  s  is connected to s    property  
requires that all children of node s   are connected by an internal path within s      s     s     s     s     form
a clique  so this property is satisfied 
the costs of abstract edges  e g   edge  s     s     in figure    can be defined in an arbitrary way
as long as the resulting search graph satisfies properties in section    however  for better performance  a low cost abstract path should be an abstraction of a low cost ground path  in this paper we
experiment with grid based navigation and  correspondingly  define the cost of edge  s     s     as the
euclidean distance between the average coordinates of children s     and children s      figure     

figure     coordinates and edge costs for all levels of the abstraction hierarchy  at the grid level
 leftmost illustration  vertex
 coordinates are given through column row labels  ground
edges cost    cardinal     diagonal   abstract states are labeled with  x  y   abstract
edges are labeled with their approximate cost 

in practice  property   is satisfied by repairing an agents abstraction hierarchy upon updates
to the agents model  to illustrate  imagine an agent just discovered that discrepancies between
the terrain elevation in state s  and s   figure    prevent it from being able to traverse the edge
 s    s     it will then update its model by removing the edge  additionally  degree one state s  will
join the clique  s    s     at this point  an agents abstraction hierarchy needs to be repaired  this is
accomplished by replacing abstract states s   and s   with a single abstract state s     the edges  s     s    
and  s     s     will be removed  if more than one level of abstraction is used then the repair has to be
propagated to higher levels as well  the repair mechanism is presented in detail in appendix a   
we will prove in section   that the pr lrts algorithm can operate with any abstraction mechanism
that satisfies the properties listed above 
  

fib ulitko   s turtevant  l u     yau

figure     two of the the six maps used in the experiments 

   empirical study
empirical evaluation of the effects that state abstraction has on learning real time heuristic search
is presented in four parts  in section      we introduce the concept of trading off antagonistic
measures and demonstrate that pr lrts makes such trade offs efficiently  this is due to the use
of abstraction and  consequently  we investigate the effects of abstraction independently of lrts
control parameters in section      we then study how pr lrts performance scales with problem
size  section       finally  we examine the interplay between the effects of abstraction and the lrts
control parameters  as it is the most domain specific study we present these details in appendix f 
the experimental setup is as follows  we used      problems randomly generated over three
maps modeled after environments from a role playing game  bioware corp         and three maps
modeled after battlefields from a real time strategy game  blizzard entertainment         the six
maps had                               and       states on grids from          to          
two maps are in figure     the other four maps are shown in appendix c  the      problems were
uniformly distributed across five buckets where each bucket represents a range of optimal solution
costs  the first     problems had the optimal path cost in the          range  the next     problems
fell into the          bucket and so on until the last     problems that were in the           bucket 
we experimented with various assignments of algorithms  a   lrts  none  to levels of abstraction  through experimentation  we found that keeping lrts at the top  a  at the bottom level
and leaving intermediate levels pass through yielded the best results in our testbed  in the following  we present results of     pr lrts configurations  denoted as lrts   d    t    where   is the
level of abstraction at which lrts with control parameters d    t operates  with a  running at the
bottom level  with        we run lrts at the ground level and do not run a  at all  the lrts
parameter space was as follows                      lookahead depth d                optimality
weight                         and learning quota t             two visibility radii were used 
   and       in our analysis  we will focus on the case of visibility radius of     in line with the
previous publications in the area  bulitko et al         bulitko   lee         experiments with
the visibility radius of      yielded similar results  as a point of reference  we ran a single nonreal time algorithm  a   the algorithms were implemented within the hierarchical open graph
framework  sturtevant        in c   and run on a cluster  with an aggregate of     years of intel
xeon    ghz cpu 
  

fig raph a bstraction in r eal   time h euristic s earch

    antagonistic performance measure trade off
from a practitioners viewpoint  this section can be viewed as a parameter selection guide  we start
by finding sets of parameters to optimize performance of pr lrts along a single measure  then
we will consider optimizing pairs of antagonistic performance measures 
the research on optimizing single performance measures within lrts was published by bulitko
and lee         in table   we extend the results to include a  and pr lrts  the best algorithms
for a single performance measure are a  and lrta  and do not use abstraction  the only exception
is convergence planning which is an interplay between planning per move and convergence travel 
table    optimizing a single performance measure 
measure
convergence travel
first move lag  states touched 
conv  memory
suboptimality
conv  planning  states touched 

the best algorithm
a 
lrta 
a 
a  or lrta 
lrts   d             or        or lrts   d             or       

the power of abstraction comes when we attempt to optimize two negatively correlated  or
antagonistic  performance measures simultaneously  consider  for instance  convergence travel and
first move lag  in order to lower convergence travel  the agent needs to select better actions  this
is done by increasing the amount of planning per move which  in turn  increases its first move
lag  as these measures are negatively correlated  performance along one measure can be traded
for performance along the other  thus  we are interested in algorithms that make such trade offs
efficiently  in order to make our analysis more specific  we first introduce the concept of dominance
with respect to a set of parameterized algorithms 
definition     algorithm a is said to dominate algorithm b with respect to performance measures
x and y on a set of problems p if as average performance measured in both x and y is not worse
than bs  avgp x a  is not worse than avgp x b  and avgp y a  is not worse than avgp y b  
algorithm c is called dominated in a set of algorithms if the set contains another algorithm that
dominates it 
the definition is illustrated in figure    where non dominated algorithms are shown as solid circles and dominated algorithms are shown as hollow circles  intuitively  non dominated algorithms
make the trade off between performance measures x and y most efficiently among all algorithms in
a set  they should be considered in practice when one wants to optimize performance in both measures  dominated algorithms can be safely excluded from consideration regardless of the relative
importance of measures x and y in a particular application 
non dominated algorithms for ten pairs of antagonistic measures are summarized in table   
a  and weighted version of korfs lrta  are extreme cases of the performance measures  a 
minimizes convergence travel and uses no heuristic memory  lrta  minimizes first move lag  all
non dominated algorithms between them are pr lrts with abstraction  in other words  abstraction
and path refinement improve efficiency of trading off antagonistic performance measures  figure   
shows a dominance plot for convergence planning against first move lag  pr lrts forms a frontier
  

fiperformance
measure  

performance
measure  

worse

worse

b ulitko   s turtevant  l u     yau

b

a
better

better

nondominated
algorithms

better

performance
measure  

better

worse

performance
measure  

worse

figure     left  algorithm a dominates algorithm b  left   right  all non dominated algorithms
are shown as solid circles  dominated algorithms are shown as hollow circles 
of non dominated algorithms  the rightmost non dominated point is a weighted lrta  which has
an extremely low first move lag   plots for other combinations are in appendix d 

firstmove lag  states touched 

dominated
nondominated

 

  

lrts         
 

  

lrts         

lrts         

 

  

lrts        
 

  

 

  
convergence planning  states touched 

 

  

figure     dominance for convergence planning against first move lag 
the dominance analysis above is done with respect to performance measures averaged over a
benchmark set of problems  dominance analysis at the level of individual problems is found in
appendix e and shows similar trends 
    effects of abstraction on individual performance measures
in this section we study effects of abstraction on individual performance measures  we arbitrarily choose three diverse lrts parameter combinations of lookahead d  optimality weight   and
learning quota t                                          the plots are in figure     a qualitative
summary is in table    and an analysis of the trends is below 
convergence planning decreases with abstraction level  this is because the increase of planning per move at higher abstraction levels is overcompensated for by the decrease in convergence
travel  the exact shape of the curves is due to an interplay between these two measures 
  

fig raph a bstraction in r eal   time h euristic s earch

table    trading off antagonistic performance measures 
measure  
first move lag
 states touched 
first move lag
 states touched 
first move lag
 states touched 
first move lag
 time 
first move lag
 time 
first move lag
 time 
suboptimality
suboptimality
suboptimality
suboptimality

measure  
conv  travel
conv  memory
conv  plan 
 states touched 
conv  travel
conv  memory
conv  plan 
 time 
conv  plan 
 states touched 
conv  plan 
 time 
conv  travel
conv  memory

non dominated algorithms  extreme cases are in italic 
a   lrta          
lrts       d                                   t          
a   lrta          
lrts       d                              t          
lrts       d              t     
lrta         
a   lrta          
lrts       d                              t          
a   lrta                
lrts       d                           t          
a   lrta          
lrts       d                        t          
a  
lrts       d                                t          
a 
a 
a 

first move lag increases with the abstraction level  this is due to the fact that the corridor at
the ground level induced by the abstract path of length d computed by lrts at the abstract level
increases with the abstraction level  there are two additional factors affecting shape of the curves 
first  the average out degree of abstract states varies with abstraction level  second  boundaries of
abstract graphs can often be seen with lookahead of d     at higher abstraction level 
convergence memory decreases with abstraction level as the learning algorithm  lrts  operates on smaller abstract maps and incurs smaller travel cost  in practice  the amount of learning in
lrts tends to correlate tightly with its travel  for instance  for lrts             the correlation
between convergence memory and convergence travel is empirically measured at        with the
confidence of     
suboptimality increases with abstraction  the increase is due to the fact that each abstraction
level progressively simplifies the ground graph topology and  while the abstract path is guaranteed to
be refinable into a ground path  it may lead the agent away from the shortest solution  an illustrative
example is given in appendix b   where a refinement of a complete abstract path is      longer
than the optimal ground path  derivation of a theoretical upper bound on suboptimality due to
abstraction is found in appendix b    a second mechanism explains why suboptimality rises faster
with shallower lrts searches  specifically  a  at the ground level refines an abstract d step path
by finding a ground level solution from the current state to a ground representative of the end of the
abstract path  this solution is guaranteed to be optimal within the corridor and does not necessarily
have to pass geographically closely to intermediate states of the abstract path  thus  giving a  a
corridor induced by a longer abstract path liberates it from having to plot a path to possibly far off
intermediate states on the abstract path  this phenomenon is illustrated in appendix b   where
feeding a  the abstract path in small fragments results in more suboptimality than giving it the
big picture  the abstract path in its entirety  a third factor affecting the suboptimality curves
  

fi 

 

    
x   

  
b ulitko
  s turtevant  l u     yau

 
 

convergence travel

  

 

x   

 
 
 

  
 

  

  

  

  abstraction
 
  level 
abstraction
level
abstraction level

  
 

first move lag

    

first move lag
first move lag

  

 

    

    

       
 

    
    

    

  

    
    
    

  

    
                      
abstraction
level
abstraction
level
abstraction
level

    

  

    

 

x   
 
 x   

   
    x    

 

  

   

   
   

 

  

   

    
    
 

  

 

    
    
    

 

  
    
    
  
      
 
  
    
    
  

    
    

       

   

  
  
  
abstraction
level
abstraction level

    
    
      
        

  
  

  

x   
x   
  
    
    
 
 
x   
  
 
 
 
      
abstraction level
       
    
        

suboptimality    
convergence memory
suboptimality
   
convergence
memory
convergence
memory
suboptimality
   

convergence travel
convergence travel

  

 

  

 

   

x   
x   
  

  

convergence
memory memory
convergence
convergence
memoryconvergence
planning planning
convergence
convergenceplanning

first move lag
first move
convergence travel
first move lag
lag
convergence planning
convergencetravel
travel
convergence
convergence
planning
convergence
planning

 

x     
  x   
 

   

 
 
 
abstraction level

 

  
  
   
abstraction
level
abstraction
level

   

   
   
    

     
     
     
 abstraction
  level
 
level
abstraction
abstraction
level
abstraction
level
abstraction level

 
 
 
abstraction level

     
 

 

  

   
 

  

 

  
   
     
   
 
   
    
     

  
  
   
abstraction
level
abstraction
level

d       t  
d       t  
 
 
 
d         t    
abstraction level
d         t    
d         t  
d         t  

 

d       t  
d         t    
 
 
 
    
     level     
abstraction
abstraction
level
abstraction
level
abstraction
level
abstraction
level

 
     

d         t  

suboptimality    

suboptimality    
suboptimality    

figure     effects of abstraction in  pr lrts 
error bars indicate the standard errors and are too
d       t  
d       t  
d       t  
 
 
 
 
 
d         t    
d         t    
d         t    
       
small to see for most data points abstraction
level
d         t  
d         t  
d         t  

       

in the figure is the optimality weight   setting  to lower values leads to higher suboptimality
 
independently
  
 
  of abstraction
 
 
  bulitko   lee        
  
    abstraction
  
  
  
level
convergence
travel
decreases
with abstraction as the bottom level search is constrained within
abstraction
level
abstraction level
a narrow corridor induced by an abstract path  the decrease is most noticeable for shallow lookahead searches  d     and d       algorithms using lookahead of d     have low convergence
travel even without abstraction  and the convergence travel is lower bounded by double the optimal
solution cost  one optimal solution for the first trial at which the map is discovered and one for the
final trial with no map discovery or heuristic learning   consequently  abstraction has diminished
gains for deeper lookahead  d       although this effect would disappear on larger maps 
table    qualitative effects of abstraction  general trends 
measure   parameter
first move lag
convergence planning
convergence memory
suboptimality
convergence travel

  






given that higher abstraction reduces convergence travel  one may ask how this compares to
reducing convergence travel of non abstract algorithms by simply terminating their convergence
process before the final trial  in figure    we compare four algorithms on a single problem  a  
non abstract lrts           and two abstract versions  lrts             and lrts             
the left plot in the figure demonstrates a well known fact that convergence of learning heuristic
search algorithms is non monotinic  e g  shimbo   ishida         the right plot shows the cost of
the shortest solution as a function of cumulative travel  we prefer algorithms that find shorter solutions after traveling as little as possible  in the plot  the abstract algorithms perform better  lower
  

fig raph a bstraction in r eal   time h euristic s earch

a 
lrts        
lrts         

travel on the trial

   

lrts         

   
   
   
   
  

 

 

 
trial

 

a 
lrts        
lrts         

   
shortest solution found

   

   

   
   
   
  

  

lrts         

   

   

   

   
   
    
cumulative travel

    

    

figure     convergence process at the level of individual trials 
curves  and are preferred  in other words  for this single problem  it is better to run abstract algorithms than non abstract algorithms regardless of how early the convergence process is terminated 
we observe that this is not the case for all problems and for all assignments of d    t we tried  in
certain cases  prematurely terminating convergence process of a non abstract algorithm can indeed
be beneficial  future research will investigate to what extent one can automatically select the best
algorithm and a number of trials to run it for 
    effects of abstraction  scaling up with problem size
in this section we investigate the effects of abstraction as the problem size increases  we measure the
size of the problem as the cost of a shortest path between the start and the goal position  henceforth
optimal solution cost  
figures    and    show five performance measures plotted as bucket averages  for each data
point  we use the middle of the bucket  e g                   as the horizontal coordinate  the error bars
indicate standard errors  overall  the results demonstrate that abstraction enables pr lrts to be
applied to larger problems by significantly dampening the increase in convergence travel  convergence planning  and convergence memory  these advantages come at the price of suboptimality and
first move lag  the former clearly increases with abstraction when lookahead is small  figure    
and is virtually bucket independent  the lookahead of d      figure     draws the curves together
as deeper lookahead diminishes effects of abstraction on suboptimality  cf  figure     
first move lag is virtually bucket independent except in the case of d     and abstraction levels
of   and    figure      there  first move lag is capped for problems in lower buckets as the goal
is seen from the start state at these higher levels of abstraction  consequently  lrts computes an
abstract path that is shorter than nine moves  this leads to a smaller corridor and less work for
a  when refining the path  consequently  the first move lag is reduced  as the problems become
larger  lrts has room to compute a full nine move abstract path and the first move lag increases 
for abstraction level   this phenomenon takes place up to bucket    where seeing the goal state from
the start state is not frequent enough to make an impact  this does not happens with abstraction level
  as proximity of the abstract goal continues to cut the search short even for the largest problems 
finally  we observe a minute decrease in first move lag for larger problems  this appears to be
due to the fact that problems in the higher buckets tend to have their start state located in a cluttered
region of the map  so that the optimal solution cost is necessarily higher   walls reduce the number
of states touched by the agent on its first move and reduce the first move lag 
  

fib ulitko   s turtevant  l u     yau

 

 

x   

 
convergence planning

convergence travel

 
 
 
 
 
 

    

   

 

   

 

 

 

              
optimal solution cost

x   

firstmove lag

 

              
optimal solution cost

   

   

 

              
optimal solution cost

  

    

suboptimality    

convergence memory

l  

  

    

   

l  
l  

  

l  

  

l  

  
 

 

 

              
optimal solution cost

              
optimal solution cost

figure     scaling up  each curve shows bucketed means for lrtsl             error bars indicate standard errors and are too small to see for most data points 

   theoretical analysis
pr lrts subsumes several known algorithms when no abstraction is used  clearly  lrts  bulitko   lee        is a special case of pr lrts when no abstraction is used  lrts itself subsumes and generalizes several real time search algorithms including lrta   korf         weighted
lrta   shimbo   ishida          trap  bulitko        and sla  sla t  shue   zamani       
shue et al         
theorem      real time operation  for any heuristic search problem  lrts   d    t   the amount
of planning per any action is constant bounded  the constant depends on the constant control
parameters d  n            t        but is independent of the problems number of states 
we first prove an auxiliary lemma 
lemma      downward refinement property  for any abstract path p    sa           sb    any two
children of its ends are connected by a path lying entirely in the corridor induced by p  this means
that any abstract path can be refined within the corridor formed by its children  formally 
   k    p    sa           sb    p   s k   e k    
s a  children s    s b  children sm  
p     s a           s b    p    s k      e k        s   p   s   sp children s     
  

     

fig raph a bstraction in r eal   time h euristic s earch

 

    

    

    
    

 

 

 

 

 

   

 

              
optimal solution cost

x   

firstmove lag

    

 
convergence planning

convergence travel

    

    
    
    

              
optimal solution cost

    

              
optimal solution cost

l  

   

   

  

 

              
optimal solution cost

suboptimality    

convergence memory

l  

 

l  
l  

 

l  

 

 

              
optimal solution cost

figure     scaling up  each curve shows bucketed means for lrtsl             error bars indicate standard errors and are too small to see for most data points 
proof  the proof is by induction on the number of edges in the abstract path  the base case is   
this means that any two children of a single abstract state are connected by a path that lies entirely
in the set of children of the abstract state  this holds due to property   
suppose the statement holds for all abstract paths of length j  we will now show that then it
holds for all abstract paths of length j    consider an arbitrary abstract path p   s k   e k    k  
  that has j     edges  then we can represent p as  s            sj     sj      consider arbitrary children
s    children s    and s j    children sj      we need to show that there is path p    s k 
    e k      between them that lies entirely in the union of children of all states on p  let us denote
it by cp    let s j   be an arbitrary child of state sj     since s  and sj   are only j edges apart  by
inductive supposition  there is a path between s   and s j   that lies entirely in cp   all that is left
is to show is that s j   and s j   are connected within cp   if s j   and s j   have the same parent 
property   guarantees they can be connected  if they have different parents  then property   provides
the same guarantee  either way  the induction step is completed  
we can now prove theorem     
proof  at the abstract level    lrts d    t   considers no more than bd abstract states by the
algorithm design  cf  section       here b is maximum degree of any state  as assumed earlier in
the paper  the maximum degree of any state does not depend on the number of states  the resulting
abstract path of no longer than d abstract edges induces a corridor at the ground level  the corridor
consists of all ground level states that abstract to abstract states on the path  the size of the corridor
  

fib ulitko   s turtevant  l u     yau

is upper bounded by the number of edges in the path  at most d  multiplied by the maximum number
of ground level children of any abstract state at level    the latter is upper bounded by a constant
independent of the number of ground level states due to property    a  running in a corridor of
constant bounded size takes a constant bounded time  finally  abstraction repair is o    and   is
independent of graph size  appendix a     
completeness is defined as the ability to reach the goal state on every trial  we prove completeness for lrts   d    t   based on the following reasoning  recall that lrts   d    t   uses
the lrts algorithm to build an abstract path at level    it then uses a corridor restricted a  at the
ground level to refine the abstract path into a sequence of ground level edges  due to property  
of section      a  will always be able to find a path between the ground level states sc and sg that
lie within the corridor c by the time execution gets to line   in figure    due to the exploration
process  the agents model of the search graph may be different from what the graph actually is in
reality  consequently  the path found by a  may contain a ground level edge that the agent believes
to exist but in reality does not  the following lemma demonstrates that such an execution failure is
possible only a finite number of times for a given search graph 
lemma     there are only a finite number of path execution failures on each trial 
proof  by contradiction  suppose there are an infinite number of such failures  each failure is due
to a discovery of at least one new blocked edge or vertex in the ground level graph  then there will
be infinitely many blocked edges or vertices in a finite graph  
a direct corollary to this lemma is that for any trial  there will be a moment of time after which
no graph discoveries are made on that trial  therefore  executing a s path will indeed allow the
agent to follow its abstract path on the actual map 
lemma     lrts is complete on an abstract graph 
proof  first  we show that any abstract graph satisfies the properties under which lrts is shown to
be complete  theorem      bulitko   lee         that is  the abstract graph is finite  each action
is reversible  there are no self loops  all actions have a positive cost  and the goal state is reachable
from every state  the graph also has to be stationary and deterministically traversible  p      bulitko
  lee         due to abstraction mechanism requirements in section      the properties listed above
are satisfied by the clique abstraction mechanism as long as the ground level graph satisfies these
properties as well  which we require in section     thus  lrts running on an abstract graph as if it
were a ground graph is complete 
in pr lrts  however  lrts on an abstract graph does not execute its own actions  instead 
its current  abstract  state is computed as abstract parent of the agents current ground level state 
therefore  a critical question is whether the agent is able to find a ground level path from its current
state to the ground level state corresponding to the end of its abstract path as computed in line  
of figure    the failure to do so would mean that the corridor computed in line   of figure   and
used to refine the path does not contain a ground level path from sc to sg   due to the downward
refinement property  lemma       this can only be due to graph discovery 
according to lemma      after a finite number of failures  the a  algorithm operating at the
ground level is guaranteed to find path to reach the end of the abstract path computed by lrts 
thus  lrts has the effective ability to execute its own abstract actions  putting these results
  

fig raph a bstraction in r eal   time h euristic s earch

together  we conclude that for any valid d    t parameters  lrts on the abstract graph finds its
goal on every trial  
the two lemmas lead directly to the following statement 
theorem     lrts   d    t   is complete 
proof  this follows directly from lemma     and lemma      
theorem     lrts   d    t   with fixed tie breaking converges to its final solution after a finite
number of trials  on all subsequent trials  it does not update its search graph model or the heuristic
and follows the same path 
proof  follows from lemma     and theorem     of  bulitko   lee        in the same way
lemma     and theorem     were proved above  
theoretical results on suboptimality are found in appendix b  

   related research
existing heuristic search methods for situated methods can be divided into two categories  full
search and real time search  full search algorithms form an entire solution given their current
knowledge of the search graph  in contrast  real time search plans only a small segment  frequently
just the first action  of their solution and executes it right away  due to the local nature of planning 
real time search algorithms need to update the heuristic function to avoid getting stuck in local
minima of their heuristic function 
    full search
a common full search algorithm is a version of a   hart et al         called local repair a   stout 
       in it  a full search is conducted from agents current state to the goal state under the free space
assumption  the agent then executes the computed path until either the destination is reached or the
path becomes invalid  e g   a previously unknown wall blocks the way   in the latter case  the agent
replans from its current position to the goal  local repair a  suffers from two problems  first  it
searches for a shortest solution and  for a general search problem  may end up expanding a number
of states exponential in the solution cost due to inaccuracies in the heuristic function  pearl        
second  re planning episodes do not re use results of previous search 
the first problem is addressed by suboptimal versions of a  which are frequently implemented
via weighting the heuristic function  pohl               such a weighted a   wa   usually finds
a longer solution in less time  once a suboptimal solution is found  it can be improved upon by
conducting additional searches  this can be done by re using the open list between successive
searches  hansen  zilberstein    danilchenko        likhachev et al         hansen   zhou       
or by re running a  in a tunnel induced by a suboptimal solution  furcy         in the later case 
beam search with backtracking can be used in place of weighted a   furcy   koenig        
the second problem is addressed by incremental search methods such as d   stenz         d 
lite  koenig   likhachev      a  and lpa   koenig   likhachev      b   these algorithms reuse
some information from the previous search  thus speeding up subsequent replanning episodes 
  

fib ulitko   s turtevant  l u     yau

in all of these algorithms  a full path has to be computed before the first move can be executed
by the agent  consequently  the planning time per move is not constant bounded and increases with
the problem size  thus  agent centered full search is not real time 
    learning real time search
since the seminal work on lrta   korf         research in the field of learning real time heuristic
search has flourished resulting in over twenty algorithms with numerous variations  most of them
can be described by the following four attributes 
the local search space is the set of states whose heuristic values are accessed in the planning
stage  the two common choices are full width limited depth lookahead  korf        shimbo  
ishida        shue   zamani        shue et al         furcy   koenig        hernandez  
meseguer      a      b  sigmundarson   bjornsson        rayner  davison  bulitko  anderson 
  lu        and a  shaped lookahead  koenig        koenig   likhachev         additional
choices are decision theoretic based shaping  russell   wefald        and dynamic lookahead
depth selection  bulitko        lustrek   bulitko        
the local learning space is the set of states whose heuristic values are updated  common
choices are  the current state only  korf        shimbo   ishida        shue   zamani        shue
et al         furcy   koenig        bulitko         all states within the local search space  koenig 
      koenig   likhachev        and previously visited states and their neighbors  hernandez  
meseguer      a      b  sigmundarson   bjornsson        rayner et al         
a learning rule is used to update the heuristic values of the states in the learning space  the
common choices are dynamic programming or mini min  korf        shue   zamani        shue
et al         hernandez   meseguer      a      b  sigmundarson   bjornsson        rayner
et al          their weighted versions  shimbo   ishida         max of mins  bulitko         modified dijkstras algorithm  koenig         and updates with respect to the shortest path from the
current state to the best looking state on the frontier of the local search space  koenig   likhachev 
       additionally  several algorithms learn more than one heuristic function  russell   wefald 
      furcy   koenig        shimbo   ishida        
control strategy decides on the move following the planning and learning phases  commonly
used strategies include  the first move of an optimal path to the most promising frontier state  korf 
      furcy   koenig        hernandez   meseguer      a      b   the entire path  bulitko 
       and backtracking moves  shue   zamani        shue et al         bulitko        sigmundarson   bjornsson        
given the multitude of proposed algorithms  unification efforts have been undertaken  in particular  bulitko and lee        suggested a framework  called learning real time search  lrts   to
combine and extend lrta   korf         weighted lrta   shimbo   ishida         sla   shue
  zamani         sla t  shue et al          and to a large extent   trap  bulitko         in the
dimensions described above  lrts operates as follows  it uses a full width fixed depth local search
space with transposition tables to prune duplicate states  lrts uses a max of mins learning rule to
update the heuristic value of the current state  its local learning space   the control strategy moves
the agent to the most promising frontier state if the cumulative volume of heuristic function updates
on a trial is under a user specified quota or backtracks to its previous state otherwise  section      
within lrts  the unification of several algorithms was accomplished through implementing
several methods for local search space selection  the learning rule  and the control strategy  each
  

fig raph a bstraction in r eal   time h euristic s earch

of these methods can be engaged at run time via user specified parameters  the resulting parameter space contained all the original algorithms plus numerous new combinations  enabling tuning
performance according to a specific problem and objective function of a particular application  as
a demonstration  bulitko et al         tuned lrts for ten maps from the computer game baldurs
gate  bioware corp         and achieved a convergence speed that is two orders of magnitude
faster than lrta   while finding paths within    of optimal  at the same time  lrts was about
five times faster on the first move than incremental a   despite the improvements  lrts and other
real time search algorithms converge more slowly than a  and  visually  may behave unintelligently
by repeatedly revisiting dead ends and corners 
    state abstraction
the idea of abstraction has been previously applied to full search methods  in particular  hpa  and
pra   botea et al         sturtevant   buro        use abstraction to speed up a  search  instead
of running a  on the lowest level graph  they instead run a  on a smaller abstract graph  pra 
computes an abstract path and then refines it in a similar manner to pr lrts  however  pra 
dynamically chooses which abstract level to use  and computes a path at each intermediate level
 i e   it does not have pass through levels   pra  also widens its corridors to decrease suboptimality
at the cost of lower speed 
hpa  abstracts a map using large regions  and selects connection points  gates  between neighboring regions  for all gates of a region  optimal paths between all gates are pre computed off line
using a  and are stored in a table  this means that refining an abstract path  i e   a sequence of
region gates  can be done simply by concatenating stored optimal paths  smoothing is applied as a
post processing step to decrease suboptimality of the resulting path 
both of these algorithms are based on the ideas presented by holte et al          who used an
abstraction mechanism in a similar manner to our use of the clique abstraction  their method  the
star abstraction  can also be described as a radius abstraction  that is  a state is selected  and
is aggregated together with all states in a fixed radius of the original state  holte et al        s
work did not initially gain wide acclaim  because  at the time  there was little interest in problems
which were small enough to fit in memory  motivating applications  such as pathfinding in computer
games  have resulted in a resurgence of interest in such techniques 
this class of algorithms first plan an abstract path  which is then refined into a traversable path 
another approach is to build an abstraction which can be directly used for planning in the realworld  this includes methods like framed quad trees  yahja  stentz  singh    brummit        
which efficiently represent sparse maps  quad trees are a multi resolution representation  as some
areas of the map are represented at high resolution  and others are represented at lower resolution 
this abstraction differs from abstractions like the clique abstraction in that it can only be applied
once  further applications would not produce lower resolution maps  although the clique abstraction
could be applied to the graph implied by the framed quad tree representation 
one other common use of abstraction is to provide better heuristics  holte  perez  zimmer  and
macdonald        used the result of an abstract search to provide a more accurate heuristic for lowlevel search and performed no path refinement  similarly  pattern databases are abstractions which
are built and solved off line  the abstract solution costs are stored and then used during search as a
heuristic function  culberson   schaeffer        felner  zahavi  schaeffer    holte        
  

fib ulitko   s turtevant  l u     yau

pr lrts presented in this paper is the first real time heuristic search algorithm to use
automatically built state abstraction  path refinement algorithms listed above conduct a full search
and therefore cannot guarantee constant bounded planning time for all agents moves 

   limitations and future work
the results presented in this paper open several directions for future research  first  pr lrts is
able to operate with a wide class of homomorphic graph abstraction techniques  thus  it would
be of interest to investigate the extent to which effects of graph abstraction on real time search
presented in this paper are specific to the clique abstraction mechanism and the pathfinding domain 
recent work has shown that the clique abstraction has parameters that are well tuned to minimize
work done in traditional path planning  sturtevant   jansen         our experiments in pathfinding
have suggested that the clique abstraction is well suited to map abstraction because it represents key
properties of the underlying space well  in particular  the branching factor stays roughly constant
at higher levels of abstraction  on an empty map  for instance  the number of nodes at each level
of abstraction will be reduced by a factor of four by the clique abstraction  but the branching factor
of every state will stay the same   corner states will have   neighbors  edge states will have  
neighbors  and middle states will have   neighbors   this may not be the case in other domains  for
instance  in the sliding tile puzzle the maximum branching factor of abstract states quickly increases
with abstraction level  as a result  the corridor derived from an abstract path in pr lrts becomes
excessively wide and does not effectively constrain a  search at the ground level  we conjecture that
algorithms which use homomorphic abstractions will only be effective in a domain if the abstraction
preserves the average  minimum  and maximum branching factor from the original problem at each
level of abstraction  clique abstraction  then is likely to work well in three dimensional pathfinding 
while problem specific mechanisms would be needed for permutation type puzzles  it is an area of
open research to provide such an abstraction 
second  pr lrts uses an abstract solution to restrict its search in the original ground level
graph  it is interesting to combine this with a complementary approach of using the cost of an
optimal solution to an abstract problem as a heuristic estimate for the original search graph in the
context of real time search  in particular  we are looking at effective ways of propagating heuristic
values from higher to lower levels of the abstraction hierarchy 
third  state aggregation is just one way of generalizing learning  future research will consider
combining it with function approximation for the heuristic function  as is commonly practiced in
large scale applications of reinforcement learning 
fourth  we are presently investigating applications of pr lrts to dynamic environments  in
particular  we are studying the extent to which savings in memory gained by learning at a higher
abstraction level will afford application of pr lrts to moving target search  an existing algorithm  ishida   korf        requires learning a number of heuristic values quadratic in the size of
the map  this is prohibitive in the case of commercial game maps 
finally  we are presently extending the graph abstraction method presented in this paper to
stochastic environments formulated as markov decision processes 
  

fig raph a bstraction in r eal   time h euristic s earch

   conclusions
situated agents in real time environments are expected to act quickly while efficiently learning an
initially unknown environment  response time and learning speed are antagonistic performance
measures as more planning leads to better actions and  consequently  faster convergence but longer
response time  full search algorithms  such as local repair a   converge quickly but do not have
a constant bounded planning time per move  real time heuristic search algorithms have constantbounded planning times per move  but learn slowly 
in this paper  we attempted to combine the best of both approaches and suggest a hybrid algorithm  pr lrts  that learns a heuristic function in a smaller abstract space and uses corridorrestricted a  to generate a partial ground level path  in a large scale empirical study  pr lrts
was found to dominate virtually all tested algorithms that do not use abstraction with respect to
several performance measure pairs  the combination of learning and planning brings real time performance to much larger search spaces  substantially benefiting applications such as pathfinding in
robotics and video games 

acknowledgments
funding was provided by the national science and engineering research council of canada  the
alberta ingenuity centre for machine learning  the informatics circle of research excellence  and
the university of alberta  we appreciate input from david thue  rich korf  rob holte  csaba
szepesvari  david furcy  and adi botea  special thanks go to jonathan schaeffer and the anonymous reviewers whose detailed comments greatly improved this paper  this research has been enabled by the use of westgrid computing resources  which are funded in part by the canada foundation for innovation  alberta innovation and science  bc advanced education  and the participating
research institutions  in particular  we would like to acknowledge help from roman baranowski 
masao fujinaga  and doug phillips 

appendix a  clique abstraction
below we will describe the clique abstraction mechanism in several stages  first  we present the
algorithm for building an initial abstraction hierarchy using the free space assumption  then we
describe the repair procedure that updates the abstract graphs as an agent explores the environment 
finally  we consider suboptimality of solution caused by abstraction on examples and derive a worstcase upper bound 
a   building initial abstraction hierarchy
the pseudo code for building an initial clique abstraction is in figure     the abstract procedure
 lines   and     takes a set of states at some level i and maps them to a single abstract state at level
i      this involves creating a new abstract state and storing parent and child links  if  in line    
a new abstract edge is added where one already exists  we do not add an extra edge but increase a
count associated with the edge  such counts are used to facilitate abstraction repair as described in
the next section 
in general  clique finding is an np complete problem  garey   johnson         however 
in eight connected two dimensional grid based search graphs the largest possible clique size is   
  

fib ulitko   s turtevant  l u     yau

graph cliqueabstraction graph g 
 
initialize graph g    
 
for i        
 
for each unabstracted state s in g
 
if s is part of some i clique c
 
g    g     abstract c  
 
end if
 
end for each
 
end for
 
   for each unabstracted state s in g
  
if degree s     
  
set parent s  to parent neighbor s  
  
else
  
g    g     abstract n  
  
end if
   end for each
  
   for each edge e    v    v   
  
if parent v       parent v   
  
g    g      parent v     parent v     
  
end if
   end for each
   return g  
figure     building the initial clique abstraction 
because the degree of each
state is also constant bounded  as required in section    the time per

clique constant  i e      state accesses to check eight neighbors and find   which form a   clique
together with the current state   thus  the total running time for doing a single clique abstraction is
o  s    where  s  is the number of states in the original search graph  if the abstraction procedure
reduces the graph size by at least a constant factor greater than one  the total cost of abstracting a
graph will also be o  s   as the cost of each additional abstraction step is reduced exponentially 
a   repairing abstraction hierarchy
as the agent explores its environment  it may find some edges or states blocked  in such cases  it will
remove the corresponding states and edges from its model and will need to propagate the changes
to all abstract graphs in the abstraction hierarchy  we will demonstrate the repair code in figure   
with an example that also shows how the repair procedure can have amortized constant time cost 
in figure    we remove edges from the level   graph at the bottom left of the figure  the right
side of the figure shows the full abstract graph after all edges have been removed  at each level we
show a portion of the abstract graph and assume that there are more states and edges in the graph 
they are shown schematically in level   in gray 
at level   there are four states marked a which form an abstract state at level    this is also
true for the states marked a  a and a are joined by an edge at level    which is abstracted from
  

fig raph a bstraction in r eal   time h euristic s earch

removeedge edge e  level l  graph g 
 
decrease edge count of e
 
if child edge count of e      return end if
 
e    v    v   
 
remove e from g l 
 
if parent v      parent v   
 
addtorepairq parent v    
 
else
 
removeedge  parent v     parent v      l      g 
 
end if
removestate state s  level l  graph g 
   for each edge e incident to s
  
removeedge e  l  g 
   end if
   remove s from g l 
   addtorepairq parent s  
handlerepairq  
   while repairq not empty
  
remove state s at lowest level l of g
  
if abstraction properties do not hold in s
  
addtorepairq parent s  
  
split state s into s        sn so that abstraction properties holds in si
  
for i           n either 
  
   merge si into existing abstract state
  
   extract si into new abstract state
  
end for
  
end if
   end while
figure     repairing abstraction hierarchy 
four edges at level    when we remove these edges from the level   graph using the removeedge  
procedure from figure     the first three removals simply decrement the count associated with the
abstract edge between a and a  line       the fourth removal  however  will result in removing
the edge between a and a  line     this removal will be recursively propagated  line    into the
abstraction hierarchy  but will not change the abstract graph at level    because the edge count will
again be decremented 
there are    edges which must be removed to perform the full split between the top and bottom
states at level   in figure     removing the first edge between e and e at level   requires the
removal of    underlying edges at level   which correspond to   edges from level    all edges
between a  b  a and b  
state repair first occurs when we remove the edge from e to e  in this case e and e have the
same parent  so g is added to the repair queue  line   and     the repair queue is processed after
each set of removal operations  once the edge from e to e is removed  children of g at level  
no longer form a clique  thus  g must be split into two states h and h  initially these states will
  

fib ulitko   s turtevant  l u     yau

before removal   repair
level  

after removal   repair
h 

level  

to split

split

g

e 

h
f 

e 

level  

level  

level  

to split

e

f

b 

c 

d 

a

b

c

d

e

level  

to split

e

f

f

a 

b 

c 

d 

a

b

c

d

split

e

    level   edges 

a 

f

a 

level  

level  

to split

a

split

   level   edges 

a 

f 

b

c

d

split

a

b

c

d

figure     an example of repairing the clique abstraction 

have an edge between them  but this edge will be removed when the last of the edges from level
  are removed  the repair code can work with many abstraction mechanisms  specifically  the
check that an abstract states children still form a clique  line     can be changed to check for the
corresponding property of a non clique abstraction 
for this example  the amortized cost of abstraction repair is constant  imagine an agent traversing the graph at level   from left to right and discovering a wall splitting the top and bottom rows of
the states  as shown by to split label in the figure   at each step more of the graph is sensed by
the agent and edges will be removed from level   graph  removing the three edges  a  a    a  b  
and  b  a  at level   requires removing six edges at level    similarly  removing the three edges
 e  e    e  f   and  f  e  requires removing    edges at level    in general  an agent traveling
at level   must move twice as far  or remove twice as many states  before repair is required at an
additional level of abstraction  thus  the number of abstraction levels repaired when traversing n
ground edges  is 
n
n
n
n
n
                     log   n    o n  
 
 
 
  
n

consequently  in this example  the amortized repair cost per edge traveled is o     in general  the
worst case complexity of repair is o    and  in pr lrts    is a constant independent of graph size 
this is because repairs are propagated only up the abstraction hierarchy  line    in figure     
  

fig raph a bstraction in r eal   time h euristic s earch

appendix b  abstraction properties
abstraction properties were informally introduced and illustrated with an example in section     
the appendix makes the presentation mathematically precise  in this section  variables i  k  m run
natural numbers including   
property    an agent using abstraction maintains a hierarchy of   abstract search graphs in addition to its model of the environment  each of the abstract graphs is a search graph in the sense
of section    in the following we denote the abstract search graph at level i     i    by
 g i   c i   s   i   sg  i   h   i    as before  g i     s i   e i   
property    each state s in the search graph at level n     has a unique parent state s  in level
n     abstract search graph  more formally 


s  s k   k      s   s k      parent s    s   

 b   

property    each state s in search graph at level m  for     m     has at least one child
state s  at level m     the notation children s  represents the set of children of state s  thus 
s   children s  


s  s k   k     s   s k     s   children s   

 b   

property    given a heuristic search problem s  for any instance of that problem  the number of
children of any abstract state is upper bounded by a constant independent of the number of states 
s  s is a search problem m   s  e   c  s    sg   h     s i      i    s  s i 
   children s     m   

 b   

property     graph homomorphism  every edge  s    s     e k   k   n has either a corresponding abstract edge at level k     or s  and s  abstract into the same state 
s    s   s k   k    
  s    s     e k     parent s     parent s      e k       parent s      parent s        b   

property    if an edge exists between abstract states s  and s  then there is an edge between some
child of s  and some child of s   
s    s   s k   k    


 
 
 s    s     e k    s   children s    s   children s     s     s      e k      
for the last property  we need the following definition 
  

 b   

fib ulitko   s turtevant  l u     yau

definition b   a path p in space  s k   e k       k    is defined as an ordered sequence of
states from s k  whose any two sequential states constitute a valid edge in e k   formally  p is a
path in  s k   e k   if and only if 
s            sm  s k   p    s            sm     i     i  m   si   si      e k     

 b   

we use the notation p   s k   e k   to indicate that both the vertices and the edges of the path p
are in the sets s k   e k  respectively  the notation s  p indicates that state s is on the path p 
property   any two children of an abstract state are connected through a path whose states are all
children of the abstract state 
s  s k       k    s     s    children s  p    s             s       s k      e k        b   
b   abstraction induced suboptimality  examples
abstraction can cause suboptimality  in figure    left  we are refining an abstract path  solid
arrows indicate the abstract path  ground level path is shown with thinner dashed arrows  the
agents position is shown with a and the goals position is g  the white cells form the corridor
induced by the abstract path  an optimal path is shown on the right 

figure     abstraction causes suboptimality 
partial path refinement can increase suboptimality  refining an entire abstract path  figure    
left  can yield shorter paths than refining a segment of an abstract path  figure     right   solid
arrows indicate the abstract path  the ground level path is shown with thinner dashed arrows  the
agents position is shown with a and the goals position is g 
b   abstraction induced suboptimality  an upper bound
there are two factors that contribute to the suboptimality of paths returned by pr lrts  the first
factor is the parameters chosen for lrts  which can be weighted to allow suboptimality  this effect
has been analyzed in the literature  bulitko   lee         here we analyze the suboptimality that
can be introduced by the abstraction  for simplicity of analysis we consider a uniform abstraction
where at each level k states are abstracted into a parent at the next level of abstraction  this assumption simplifies our analysis and also enables application of this analysis to non clique abstraction
mechanism that maintain this property  before proving our result  we introduce two simple lemmas 
  

fig raph a bstraction in r eal   time h euristic s earch

figure     partial path refinement increases suboptimality 
lemma b   suppose all abstract edges have the same cost  if a lowest cost path p between states
a and b has j edges then a lowest cost abstract path between their abstract parents a  and b   has
at most j abstract edges 
proof  we prove this by contradiction  suppose the lowest cost abstract path q between a  and b  
has m   j edges  then consider the abstract images of all states on p  they either have an abstract
edge between them or coincide due to property    thus they form an abstract path p  between a 
and b   and due to property   it has no more than j edges  since by the assumption of our theorem
all abstract edges have the same cost  the lowest cost path q between a  and b   must have a higher
cost than path p  between a  and b    figure     right   this results in a contradiction  
lemma b   any path created by refining an abstract edge at level   cannot be longer than o k    
at level   
proof  this is demonstrated in the right portion of figure     we assume that every abstract state
has exactly k children  so  at level   of the abstraction any state a cannot have more than k  
children  assuming that a path cannot visit a single node more than once  the refined path through
a can therefore have no more than o k     edges  
we can now present our main result 
theorem b   assume that every abstract state has k children and the ground level edge costs are
in     e   at level   of an abstraction  the cost of a path created by refining an abstract path from
level   to level    the original space  is at most o ek     times more costly than the optimal path if all
abstract edges happen to have uniform cost and o e  k      if all abstract edges have costs in     ek    
 from lemma b    
proof  first  we deal with the case where all edges in the abstract graph have uniform cost  consider
two level   states a and b that abstract into level   states a    b    left side of figure      if a lowestcost path p between a and b has j edges then a lowest cost abstract path between a  and b   has at
most j abstract edges by lemma b   
  

fib ulitko   s turtevant  l u     yau

path p   at most j edges

path q  m   j edges

a 

b 

a

b

a 

path p  j edges

b 

path p   at most j edges

figure     proving that any lowest cost abstract path will have no more than j edges 
suppose the agent is in state a and is seeking to go to state b  the agent first computes a
lowest cost abstract path between a  and b     in the worst case  the abstract path will have j edges 
suppose there are two abstract paths between a  and b     t   and t   as shown in figure     left  they
both have j edges and  due to the uniform abstract edge cost assumption  the same cost  in the worst
case scenario  t   is refined into a lowest cost path t  between a and b while t   is refined into the
highest cost path t  between a and b  by analyzing the cost ratio of t  and t  we will arrive at the
upper bound of the theorem 
  edge

path t     j edges

a 

level  

b 

level  
path t     j edges

k   edges

figure     paths t     t   are the same cost yet refine into the shortest and longest paths 
due to lemma b    one abstract edge at level   can be refined into at most k   level   edges  in
the worst case  t  has j edges while t  has jk      edges  the result of abstracting   levels of k  
states into a single state   furthermore  all edges on t  have a cost of   leading to the total cost of t 
being j  all edges on t  have cost e leading to the total cost of t  being e jk        thus  the ratio
of t  and t  costs is no higher than ek   which proves the first statement of the theorem 
in the case when abstract edges have non uniform costs in     ek      we again consider two abstract paths t   and t   from a  to b     now they can both have cost ejk     which is the highest possible
cost of a level   image of a cost j ground path  on path t     the abstract cost might be overestimated
so that there are j abstract edges  each of cost ek   which refine into the level   path t  of j edges
of cost   each  thus  the total cost of t  is j which is the lowest possible cost between a and b 
path t   has the same cost as t   but with ejk   abstract edges  each of cost    since each of these
abstract edges can be refined into at most k   edges at level    path t   is refined into the path t 
of no more than ejk    k   edges  each of which has cost e  consequently  the total cost of t  is
e  ejk    k     je  k      thus  the ratio between the costs of t  and t  is e  k      
  

fig raph a bstraction in r eal   time h euristic s earch

t  
t  
a

a 

b

a

b

b 

w
c

c
t  

w

w

j

w

w

j

figure     a grid based example achieving the worst case suboptimality 
the worst case upper bound is tight  and occurs when we both severely underestimate the cost
of a suboptimal path and overestimate the cost of the optimal path  in figure    we show how this
can happen in practice  the level   map is shown on the left  the lowest cost path  t    between states
a and b is a straight line and has the cost j  all corridors have width    the length of the corridors 
w  is chosen so that at level   of the abstraction  all states in a corridor will abstract together into a
single state  in this map there are only cliques of size two  i e   k     in theorem b    
the right part of figure    shows level   abstract graph in thick lines and the original map
in light gray  in this abstraction  the path t   between a  and b    the abstract parents of a and
b  goes through the lower part of the map  the path t   has the abstract cost  c   j   w but its
abstract edges refine to w ground level edges each  thus  the total cost of its refined path t  is
w    c   j     cw   jw  path t   is an abstract image of t  and has the abstract cost w   k   for
each of its j edges  leading to the total abstract cost of jk     jw  it is shown in the right side of the
figure as a highly zigzagged path 
we can now choose c so that t   costs just as much as t     then the agent can have the bad luck
of choosing to refine t     to make this a certainty  we can make the cost of t   slightly higher than
the cost of t     this is accomplished by setting  c   j   w  jw  from here   c  jw  j  w
and c  jw   jk     j     as a result  the agent chooses to refine t   into t    which has cost
 cw   jw    j        j     o j       the ratio between this and the cost of t  is       which
corresponds to the bound of the theorem for k      e     
our experimental results demonstrate that such large suboptimality does not occur in practice  as an illustration  consider a histogram of suboptimality values for the      problems and
all parametrizations of pr lrts in figure    
if suboptimality does become a practical concern  one can use ideas from hpa   botea
et al          where optimal path costs within regions were pre computed and cached  such precomputation will help prevent the severe over  and under estimation of abstract path costs which
was assumed by the worst case analysis in theorem b   

appendix c  maps used in the empirical study
the four additional maps are shown in figure    
  

fib ulitko   s turtevant  l u     yau

 

percentage of problems

  

 

  

 

  

 

  

 

  

  

  

  
  
suboptimality    

   

   

figure     histogram of suboptimality in our experiments 

figure     the four additional maps used in the experiments 

appendix d  dominance on average  plots
six plots corresponding to entries in table   are shown in figures        
  

fig raph a bstraction in r eal   time h euristic s earch

a 
lrts         
           
        
           
lrts
           
lrts          
        
           

dominated
nondominated

lrts         

firstmove lag  states touched 

lrts
        
lrts
        
           
  
 

  

lrts
lrts          
        
lrts         
 

lrts         
 

  

lrts         

lrts         
lrts         

lrts         

 

  

lrts        
 

 

  

  
convergence travel

a 

dominated
nondominated

lrts         
lrts            
lrts         
 
lrts            
 
lrts
lrts          
        

 

firstmove lag  seconds 

  

lrtslrts
        
        
 
 
lrts         
lrts         
lrts         
lrts            
 

 

lrts
lrts
        
         lrts            
   
 

  

lrts
        
lrts
        
 
 

lrts        
 

 

  

  
convergence travel

a 

dominated
nondominated
 

firstmove lag  seconds 

  

lrts         
 

lrts         
lrts            
 

 

  

lrts
lrts
        
         lrts            
   
 
lrts
lrts          
        

lrts        
 

  
convergence planning  seconds 

 

  

figure     dominance for several pairs of performance measures  part   

appendix e  dominance on individual problems
in section     we introduced the concept of dominance and demonstrated that pr lrts with abstraction dominates all but extreme of the search algorithms that do not use abstraction  this analysis was done using cost values averaged over the      problems  in this section we consider
  

fib ulitko   s turtevant  l u     yau

a 
lrts            
        
lrts         
           
lrts          
           
           
        

dominated
nondominated

 

firstmove lag  states touched 

lrts         
           
        
           
 

  

lrts         
        
lrts         
           
        
           
 

lrts
           
lrts          
        
 

  

lrts
lrts          
        

lrts
        
lrts
        
  

 

  

lrts        

 

   

    

    

convergence memory
a 
lrts            
         
 

dominated
non dominated

lrts            
lrts          
           
lrts
lrts           
 

  

first move lag  seconds 

  

lrts          
lrts          
           
           
 
lrts
           
lrts            
           

  

lrts
lrts           
           

  

lrts          

lrts         
lrts         

 

   

    

    

convergence memory

dominated
nondominated

  
lrts         

suboptimality    

  

lrts         

  

lrts         
lrts
lrts
        
           
  

  

lrts         
lrts         
           
lrts
lrts          
           

 

 

a 
 

  

 

  
convergence planning  states touched 

 

  

figure     dominance for several pairs of performance measures  part   
dominance on individual problems  due to high variance in the problems and their difficulty  we
report percentages of problems on which dominance is achieved  for every pair of algorithms  we
measure the percentage of problems on which the first algorithm dominates the second  we then
measure the percentage of problems on which the second algorithm dominates the first  the ratio
between these two percentages we call the dominance ratio 
  

fig raph a bstraction in r eal   time h euristic s earch

 

  

 

firstmove lag

  

 

  

 

  

 

  
 
  

 

 

  

 

  

  

convergence travel
 

x   

convergence travel

firstmove lag
   

  

   

  
lrts          

lrts          

   
  
 
 
 
 

   
   
   
   

 
  
lrts        

  

   
   
lrts        

 

x   

   

figure     top  lrts             is shown as a filled star  lrts           is shown as a hollow
star  bottom left  convergence travel  bottom right  first move lag 
table    statistics for the two algorithms from figure    
algorithm

convergence travel

first move lag

both

lrts          

      

      

      

lrts         

      

     

     

dominance ratio
     

at the top of figure    we see a reproduction of the corresponding plot from figure    where
two particular algorithms are marked with stars  the filled star is lrts             that uses three
levels of abstraction  the hollow star is lrts           that operates entirely at the ground level 
statistics are reported in table    the bottom left of the figure shows advantages of the pr lrts
with respect to convergence travel  on approximately     of the      problems  the pr lrts
travels less than the lrts before convergence  points below the    degree line   with respect to
the first move lag  the pr lrts is superior to the lrts on     of the problems  bottom right in the
figure   finally  on     of the problems the pr lrts dominates the lrts  i e   outperforms it with
  

fib ulitko   s turtevant  l u     yau

  

suboptimality    

  
  
  
 
 
 
  

 

 

 

  

  
convergence planning

 

convergence planning

x   

 

  

  

suboptimality    

 
  

 

lrts          

lrts          

 

 
 
 

 

 
 
 
lrts        

 

  

  

  

 

 

 

 

x   

  

  
  
lrts        

  

figure     top  lrts             is shown as a filled star  lrts           is shown as a hollow
star  bottom left  convergence planning  bottom right  suboptimality 
respect to both measures   on the other hand  the lrts dominates the pr lrts on approximately
   of the problems  this leads to the dominance ratio of       
table    statistics for the two algorithms from figure    
algorithm

convergence planning

suboptimality

both

lrts          

      

      

      

lrts         

      

      

     

dominance ratio
    

similarly  figure    compares two algorithms with respect to convergence planning and suboptimality of the final solution  at the top of the figure  we have the corresponding plot from figure   
with lrts             shown as a filled star and lrts           shown as a hollow star  percent
points for domination on individual problems are found in table    the plot at the bottom left of
the figure shows that pr lrts has lower convergence planning cost than the lrts on     of
the problems  the plot at the bottom right shows suboptimality of the solutions these algorithms
  

fig raph a bstraction in r eal   time h euristic s earch

produced  the pr lrts is more optimal than the lrts     of the time  finally  the pr lrts
dominates the lrts on     of the problems  domination the other way  i e   the lrts dominates
the pr lrts  happens only on       of the problems  this leads to the dominance ratio of      
there are several factors that influence the results  first  there is a high variance in the difficulty
of individual problems due to their distribution over five buckets by optimal path distance  consequently  there is high variance in how the algorithms trade off antagonistic performance measures
on these problems  in the case when there is a large difference between mean values  such as in
figure     dominance on average is supported by dominance on the majority of individual problems  conversely  a small difference in mean values  e g        in suboptimality for the algorithms
in figure     does not lead to overwhelming dominance at the level of individual problems 
we extended this analysis to all pairs of algorithms displayed in figures         for convergence travel and first move lag  the dominance ratio varies between      and  with the values
below infinity averaging        with the standard error of         for convergence planning and
suboptimality  the dominance ratio varies between      and  with the values below infinity averaging      with the standard error of       finally  only a set of     algorithms was tested in
our study  therefore  the results should be viewed as an approximation to the actual dominance
relationship among the algorithms 

appendix f  interaction between abstraction and lrts parameters
in section     we observed general trends in influence of abstraction on the five performance measures  as the abstraction level adds another dimension to the parameter space of lrts  previously
defined by d    t   the natural question is how the four parameters interact  in order to facilitate a
comprehensible visualization in this paper  we will reduce the lrts parameter space from d    t to
d   by setting t     i e   disabling backtracking in lrts   this is justified for two reasons  first 
recent studies  bulitko   lee        sigmundarson   bjornsson        have shown that effects of
backtracking are highly domain specific 
table   gives an overview of the influence of abstraction on the parameters of lrts at a qualitative level  a more detailed analysis for each of the five performance measures follows  it is
important to note that these experiments were performed on a set of fixed cost paths and fixed size
maps  consequently  map boundary effects are observed at higher levels of abstraction  we will
detail their contribution below 
table    influence of lrts parameters on the impact of abstraction  each cell in the table represents the impact of abstraction either amplified  a  or diminished  d  by increase in d
or   lower case a and d indicate minor effect    indicates no effect 
increase in d
d
a
a
d
d

measure   control parameter
convergence travel
first move lag
convergence planning
convergence memory
suboptimality

increase in 
a
a
a
a

convergence travel  increasing the abstraction level generally decreases convergence travel as
lrts learns on smaller abstract maps  independently  increasing the lookahead depth in lrts has a
  

fib ulitko   s turtevant  l u     yau

convergence travel
x   

x   

level  
level  
optimality weight 

 
 
 
 
 
 
   
optimality weight 

 

difference in convergence travel
 

 

 

   

   

 
   

 
   
   

 

 

   

 

   

lookahead depth d

 

convergence travel

 
 
lookahead depth d

 

difference in convergence travel
    

 
level  
level  
optimality weight 

    
    
    
 
 
   
optimality weight 

    

   

    
    
   

   

 
   
   

 

 

 

   

lookahead depth d

 

 
 
lookahead depth d

 

figure     convergence travel  impact of abstraction as a function of d    top two graphs 
lrts d    vs  lrts   d     bottom two graphs  lrts   d    vs  lrts   d    
similar effect  bulitko   lee         convergence travel is lower bounded by the doubled optimal
cost from the start to the goal  as the first trial has to reveal parts of the map and  consequently 
cannot be final   therefore  decreasing convergence travel via either of two mechanisms diminishes
the gains from the other mechanism  this effect can be seen in figure    where there is a noticeable
gap in convergence travel between abstractions levels   and    but with a lookahead of    there is
only a small difference between using abstraction levels   and    thus  increasing the lookahead
slightly diminishes the effect of abstraction  hence the d in the table   increasing  increases the
convergence travel  the higher the value of   the more there is to be gained from using abstraction 
an increase in  amplifies the advantage of abstraction 
first move lag generally increases with both the abstraction level and with lookahead depth 
as lookahead depth increases  the size of the corridor used for a  search increases as well  thus 
increasing d amplifies the first move lag due to abstraction  because pr lrts must plan once within
the lookahead space  within lrts  and once inside the corridor  within a    figure     
deeper lookahead amplifies the impact of abstraction  in the simplified analysis below  we
assume that the map is obstacle free which leads to all levels of abstraction being regular grids
 ignoring boundary effects   the length of a path between two points  expressed in the number of
actions  is  thus  decreased by a factor of two with each abstraction level  under these assumptions 
the total number of states pr lrts touches on the first move is  d    at the abstract graph and
  

fig raph a bstraction in r eal   time h euristic s earch

firstmove lag

difference in firstmove lag
   

 
level  
level  

   
optimality weight 

    
    
    
 
 
   
optimality weight 

   

   

   
   
   
   
   

   

 
   
   

 

 

   

 

   

lookahead depth d

 

firstmove lag

 
 
lookahead depth d

 

difference in firstmove lag
 

   

level  
level  
optimality weight 

    
    
    
    
 
 
   
optimality weight 

   
    

    
   
    

 
   
   

 

 

 

   

lookahead depth d

 

 
 
lookahead depth d

 

figure     first move lag  impact of abstraction as a function of d    top two graphs  lrts d   
vs  lrts   d     bottom two graphs  lrts   d    vs  lrts   d    
 d       at the ground graph  the latter quantity is simply the number of edges in the ground
path computed as the number of edges in the abstract path  d  multiplied by the reduction factor
of      adding  more abstraction levels increases the first move lag to  d         the increase is
a linear function of lookahead depth d  thus  larger values of d amplify the effect of adding extra
abstraction levels 
there are several points glossed over by our simplified analysis  first  the reduction in the
path length is not always two fold as we assumed above  in the presence of walls  higher levels of
abstraction are less likely to locate and merge fully fledged   element cliques  second  boundaries
of the abstract graph can be reached by lrts in less than d moves at the higher abstraction level 
this effectively decreases the quantity d in the formula above and the size of the corridor can be
reduced from our generous estimate d     finally  feeding a  longer abstract path often improves
its performance as we have analyzed in a previous section  cf  figure      this explains why at
abstraction level   deepening lookahead has diminishing returns as seen in figure    
optimality weight does not affect the number of states touched by lrts at the abstract level 
on the other hand  it can change the cost of the resulting a  search as a different abstract path may
be computed by lrts  overall  however  the effect of  on the first move lag and the impact of
abstraction is inconsequential  figure     
  

fib ulitko   s turtevant  l u     yau

convergence planning

 

difference in convergence planning

x   

 

 

x   

level  
level  

 
optimality weight 

 
 
 
 
 
   

   
   

 
   

   

 

optimality weight 

   
   

 

 

 

   

lookahead depth d

 

convergence planning

 

difference in convergence planning
     

 

 

x   

level  
level  

     
optimality weight 

 
 
 
 
 
   
optimality weight 

 
 
lookahead depth d

   

     
     
    

   

 

 
   
   

 

 

    

 

   

lookahead depth d

 

 
 
lookahead depth d

 

figure     convergence planning  impact of abstraction as a function of d    top two graphs 
lrts d    vs  lrts   d     bottom two graphs  lrts   d    vs  lrts   d    
convergence planning  as the abstraction level increases  convergence planning generally
decreases  the effect of d is more complex  because deeper lookahead increases the cost of each
individual planning step  but overall decreases planning costs as convergence is faster  the interplay
of these two trends moderates the overall influence as seen in figure    
the effect of  on convergence planning is non trivial  in general  lower values of  reduce the
convergence planning cost  note that convergence planning cost is a product of average planning
time per unit of distance and the convergence travel  as we discussed above  optimality weight
amplifies the effects of abstraction convergence travel  at the same time  it does not substantially
affect increase in planning per move as the abstraction goes up  combining these two influences  we
conclude that optimality weight will amplify effects of abstraction on convergence planning  this
is confirmed empirically in figure    
convergence memory  abstraction decreases the amount of memory used at convergence because there are fewer states over which to learn  the effects of d and  are the same as for convergence travel described above  this is because there is a strong correlation between convergence
travel and convergence memory that we have previously discussed  visually figures    and   
display very similar trends 
suboptimality  increasing the abstraction level increases suboptimality  for plain lrts  lookahead depth has no effect on suboptimality of the final solution  however  when we combine deeper
  

fig raph a bstraction in r eal   time h euristic s earch

convergence memory

difference in convergence memory
    

 
level  
level  
optimality weight 

    
    
   
 
 
   
optimality weight 

   

   

   
   
   
   

 
   
   

 

 

 

   

lookahead depth d

 

convergence memory

 
 
lookahead depth d

 

difference in convergence memory
  

 
level  
level  

  
optimality weight 

   
   
  
 
 
   
optimality weight 

  

   

  
  
  
  
   

  

 
   
   

 

 

  

 

   

lookahead depth d

 

 
 
lookahead depth d

 

figure     convergence memory  impact of abstraction as a function of d    top two graphs 
lrts d    vs  lrts   d     bottom two graphs  lrts   d    vs  lrts   d    

lookahead with abstraction the suboptimality arising from abstraction decreases  with deeper lookahead the abstract goal state is seen earlier making pr lrts a corridor constrained a   additionally 
as we discussed in section     and figure     refining shorter paths  computed by lrts with lower
d  introduces additional suboptimality  as suboptimality is lower bounded by     increasing lookahead diminishes the effects of abstraction on suboptimality  figure      hence d in table   
increasing  decreases the amount of suboptimality when no abstraction is used  when combined with abstraction increasing  has a minor amplification effect on the difference abstraction
makes  figure     for two reasons  first  at abstract levels the graphs are fairly small and  makes
less difference there  second  the degree suboptimality of an abstract path does not translate directly
into the degree of suboptimality of the resulting ground path as the a  may still find a reasonable
ground path  thus  the influence of  at the abstract level is overshadowed by the suboptimaly
introduced by the process of refinement itself  cf  figure     

  

fib ulitko   s turtevant  l u     yau

suboptimality    

difference in suboptimality    
 

 
level  
level  

 
optimality weight 

  
  
  
 
   
   

 

   
 

optimality weight 

 

 

   

 
 
 
  

   

  

 
   

lookahead depth d

 

suboptimality    

 
 
lookahead depth d

 

difference in suboptimality    
 

 
level  
level  

 
optimality weight 

  
  
  
 
   
   

 

   
optimality weight 

 

 

  

 

   
 
 
 

   

  

 
   

lookahead depth d

 

 
 
lookahead depth d

 

figure     suboptimality  impact of abstraction as a function of d    top two graphs  lrts d   
vs  lrts   d     bottom two graphs  lrts   d    vs  lrts   d    

  

fig raph a bstraction in r eal   time h euristic s earch

references
aylett  r     luck  m          applying artificial intelligence to virtual reality  intelligent virtual
environments  applied artificial intelligence             
bacchus  f     yang  q          downward refinement and the efficiency of hierarchical problem
solving   artificial intelligence               
bioware corp          baldurs gate   published by interplay  http   www bioware com bgate  
november          
blizzard entertainment         warcraft iii  reign of chaos   published by blizzard entertainment 
http   www blizzard com war   july         
botea  a   muller  m     schaeffer  j          near optimal hierarchical path finding  journal of
game development            
bulitko  v          learning for adaptive real time search  tech  rep  http     arxiv  org   abs   cs ai
           computer science research repository  corr  
bulitko  v     lee  g          learning in real time search  a unifying framework  journal of
artificial intelligence research  jair                
bulitko  v   sturtevant  n     kazakevich  m          speeding up learning in real time search via
automatic state abstraction  in proceedings of the national conference on artificial intelligence  aaai   pp              pittsburgh  pennsylvania 
culberson  j     schaeffer  j          searching with pattern databases  in csci  canadian ai
conference   advances in artificial intelligence  pp          springer verlag 
dini  d  m   van lent  m   carpenter  p     iyer  k          building robust planning and execution
systems for virtual worlds  in proceedings of the artificial intelligence and interactive digital
entertainment conference  aiide   pp        marina del rey  california 
ensemble studios         age of empires ii  age of kings   published by microsoft game studios 
http   www microsoft com games age   june          
felner  a   zahavi  u   schaeffer  j     holte  r          dual lookups in pattern databases  in
proceedings of the international joint conference on artificial intelligence  ijcai   pp     
     edinburgh  united kingdom 
furcy  d          itsa   iterative tunneling search with a   in proceedings of the national
conference on artificial intelligence  aaai   workshop on heuristic search  memory based
heuristics and their applications  boston  massachusetts 
furcy  d     koenig  s          speeding up the convergence of real time search  in proceedings
of the national conference on artificial intelligence  aaai   pp         
furcy  d     koenig  s          limited discrepancy beam search  in proceedings of the international joint conference on artificial intelligence  ijcai   pp         
garey  m  r     johnson  d  s          computers and intractability  a guide to the theory of
np completeness  w  h  freeman   co   new york  ny  usa 
hansen  e  a     zhou  r          anytime heuristic search  journal of artificial intelligence
research  jair              
  

fib ulitko   s turtevant  l u     yau

hansen  e  a   zilberstein  s     danilchenko  v  a          anytime heuristic search  first results 
tech  rep  cmpsci        computer science department  university of massachusetts 
hart  p   nilsson  n     raphael  b          a formal basis for the heuristic determination of
minimum cost paths  ieee transactions on systems science and cybernetics               
hernandez  c     meseguer  p       a   improving convergence of lrta  k   in proceedings of
the international joint conference on artificial intelligence  ijcai   workshop on planning
and learning in a priori unknown or dynamic domains  pp        edinburgh  uk 
hernandez  c     meseguer  p       b   lrta  k   in proceedings of the international joint
conference on artificial intelligence  ijcai   pp            edinburgh  uk 
holte  r   mkadmi  t   zimmer  r  m     macdonald  a  j          speeding up problem solving
by abstraction  a graph oriented approach  artificial intelligence                  
holte  r   perez  m   zimmer  r     macdonald  a          hierarchical a   searching abstraction
hierarchies efficiently  tech  rep  tr        university of ottawa 
id software         doom   published by id software  http   en wikipedia org wiki doom  december          
ishida  t          moving target search with intelligence  in national conference on artificial
intelligence  aaai   pp         
ishida  t     korf  r          moving target search  in proceedings of the international joint
conference on artificial intelligence  ijcai   pp         
kitano  h   tadokoro  s   noda  i   matsubara  h   takahashi  t   shinjou  a     shimada  s         
robocup rescue  search and rescue in large scale disasters as a domain for autonomous agents
research  in proceedings of the ieee conference on man  systems  and cybernetics  vol    
pp         
koenig  s          exploring unknown environments with real time search or reinforcement learning  in proceedings of the neural information processing systems  pp           
koenig  s          a comparison of fast search methods for real time situated agents  in proceedings of int  joint conf  on autonomous agents and multiagent systems  pp           
koenig  s     likhachev  m       a   d  lite  in proceedings of the national conference on
artificial intelligence  aaai   pp         
koenig  s     likhachev  m       b   incremental a   in advances in neural information processing systems  nips   pp           
koenig  s          agent centered search  artificial intelligence magazine                
koenig  s     likhachev  m          real time adaptive a   in proceedings of the international
joint conference on autonomous agents and multiagent systems  aamas   pp         
koenig  s     simmons  r          solving robot navigation problems with initial pose uncertainty
using real time heuristic search  in proceedings of the international conference on artificial
intelligence planning systems  pp           
koenig  s   tovey  c     smirnov  y          performance bounds for planning in unknown terrain 
artificial intelligence              
  

fig raph a bstraction in r eal   time h euristic s earch

korf  r          real time heuristic search  artificial intelligence                  
likhachev  m   ferguson  d   gordon  g   stentz  a     thrun  s          anytime dynamic a   an
anytime  replanning algorithm  in proceedings of the international conference on automated
planning and scheduling  icaps  
likhachev  m   gordon  g  j     thrun  s          ara   anytime a  with provable bounds on suboptimality  in thrun  s   saul  l     scholkopf  b   eds    advances in neural information
processing systems     mit press  cambridge  ma 
lustrek  m     bulitko  v          lookahead pathology in real time path finding  in proceedings of
the national conference on artificial intelligence  aaai   workshop on learning for search 
pp          boston  massachusetts 
mero  l          a heuristic search algorithm with modifiable estimate  artificial intelligence     
     
orkin  j            states   a plan  the ai of f e a r  in proceedings of the game developers
conference  gdc   http   www jorkin com gdc     orkin jeff fear doc 
pearl  j          heuristics  addison wesley 
pohl  i          first results on the effect of error in heuristic search  in meltzer  b     michie  d 
 eds    machine intelligence  vol     pp          american elsevier  new york 
pohl  i          the avoidance of  relative  catastrophe  heuristic competence  genuine dynamic
weighting and computaional issues in heuristic problem solving  in proceedings of the international joint conference on artificial intelligence  ijcai   pp       
pottinger  d  c          terrain analysis in realtime strategy games  in proceedings of computer
game developers conference  www gamasutra com features gdcarchive      pottinger doc 
rayner  d  c   davison  k   bulitko  v   anderson  k     lu  j          real time heuristic search
with a priority queue  in proceedings of the international joint conference on artificial
intelligence  ijcai   pp            hyderabad  india 
reynolds  c  w          flocks  herds and schools  a distributed behavioral model  in siggraph
    proceedings of the   th annual conference on computer graphics and interactive techniques  pp        new york  ny  usa  acm press 
russell  s     wefald  e          do the right thing  studies in limited rationality  mit press 
shimbo  m     ishida  t          controlling the learning process of real time heuristic search 
artificial intelligence              
shue  l  y   li  s  t     zamani  r          an intelligent heuristic algorithm for project scheduling
problems  in proceedings of the   nd annual meeting of the decision sciences institute 
shue  l  y     zamani  r          an admissible heuristic search algorithm  in proceedings of the
 th international symposium on methodologies for intelligent systems  ismis      vol     
of lnai  pp       
sigmundarson  s     bjornsson  y          value back propagation vs  backtracking in realtime search  in proceedings of the national conference on artificial intelligence  aaai  
workshop on learning for search  boston  massachusetts  usa  aaai press 
  

fib ulitko   s turtevant  l u     yau

stenz  a          the focussed d  algorithm for real time replanning  in proceedings of the
international joint conference on artificial intelligence  ijcai   pp           
stout  b          smart moves  intelligent pathfinding  game developer magazine  october       
sturtevant  n          hog   hierarchical open graph  http   www cs ualberta ca nathanst hog  
sturtevant  n          memory efficient abstractions for pathfinding  in proceedings of the third
conference on artificial intelligence and interactive digital entertainment  pp        stanford  california 
sturtevant  n     buro  m          partial pathfinding using map abstraction and refinement  in
proceedings of the national conference on artificial intelligence  aaai   pp           
pittsburgh  pennsylvania 
sturtevant  n     jansen  r          an analysis of map based abstraction and refinement  in
proceedings of the  th international symposium on abstraction  reformulation and approximation  whistler  british columbia   in press  
sutton  r          integrated architectures for learning  planning  and reacting based on approximating dynamic programming  in proceedings of the seventh international conference on
machine learning  pp          morgan kaufmann 
thalmann  d   noser  h     huang  z          autonomous virtual actors based on virtual sensors 
in lecture notes in computer science  lncs   creating personalities for synthetic actors 
towards autonomous personality agents  vol        pp        springer verlag  london 
yahja  a   stentz  a  t   singh  s     brummit  b          framed quadtree path planning for mobile
robots operating in sparse environments  in in proceedings  ieee conference on robotics
and automation   icra   leuven  belgium 

   

fi