journal artificial intelligence research                  

submitted       published      

probabilistic planning via heuristic forward search
weighted model counting
carmel domshlak

dcarmel   ie   technion   ac   il

technion   israel institute technology 
haifa  israel

jorg hoffmann

j oerg  h offmann   deri  

university innsbruck  deri 
innsbruck  austria

abstract
present new algorithm probabilistic planning observability  algorithm 
called probabilistic ff  extends heuristic forward search machinery conformant ff problems probabilistic uncertainty initial state action effects  specifically 
probabilistic ff combines conformant ffs techniques powerful machinery weighted
model counting  weighted  cnfs  serving elegantly define search space
heuristic function  evaluation probabilistic ff shows fine scalability range probabilistic domains  constituting several orders magnitude improvement previous results
area  use problematic case point main open issue addressed
research 

   introduction
paper address problem probabilistic planning observability  kushmerick 
hanks    weld         known ai planning community conditional  majercik  
littman        conformant  hyafil   bacchus        probabilistic planning  problems
given initial belief state form probability distribution world states w  
set actions  possibly  probabilistic effects  set alternative goal states wg w  
solution problem single sequence actions transforms system one
goal states probability exceeding given threshold   basic assumption
problem system cannot observed time plan execution  setting
useful controlling systems uncertain initial state non deterministic actions  sensing
expensive unreliable  non probabilistic conformant planning may fail due non existence
plan achieves goals      certainty  even plan  plan
necessarily contain information actions useful achieve requested
threshold  
state of the art performance probabilistic planners advancing much slowly
deterministic planners  scaling      step plans problems    world states
      step plans problems     world states  kushmerick et al         majercik  
littman        hyafil   bacchus         since probabilistic planning inherently harder
deterministic counterpart  littman  goldsmith    mundhenk         difference evolution
rates surprising  however  recent developments area  onder  whelan    li 
      bryce  kambhampati    smith        huang         particular work here  show
dramatic improvements probabilistic planning obtained 
c
    
ai access foundation  rights reserved 

fid omshlak   h offmann

paper introduce probabilistic ff  new probabilistic planner based heuristic forward search space implicitly represented probabilistic belief states  planner natural
extension recent  non probabilistic  conformant planner conformant ff  hoffmann   brafman         main trick replace conformant ffs sat based techniques recent
powerful technique probabilistic reasoning weighted model counting  wmc  propositional cnfs  sang  beame    kautz         detail  conformant ff forward search
belief space belief state corresponds set world states considered
possible  main trick conformant ff use cnf formulas implicit representation belief states  implicit  context  means formulas  a  encode semantics
executing action sequence initial belief state  propositional variables corresponding
facts time stamps  actual knowledge belief states  and be  inferred
formulas  particularly  fact p known true belief state
 a  p m   time endpoint formula  knowledge computed
conformant ff belief states known facts  well  symmetrically  facts
known false  suffices strips style planning  is  determine applicable
actions goal belief states  heuristic function  ffs  hoffmann   nebel        relaxed
planning graph technique enriched approximate sat reasoning 
basic ideas underlying probabilistic ff are 
 i  define time stamped bayesian networks  bns  describing probabilistic belief states 
 ii  extend conformant ffs belief state cnfs model bns 
 iii  addition sat reasoning used conformant ff  use weighted model counting
determine whether probability  unknown  goals belief state high enough 
 iv  introduce approximate probabilistic reasoning conformant ffs heuristic function 
note synergetic effect  probabilistic ff re uses conformant ffs technology recognize
facts true false probability    fully serves determine applicable actions 
well detect whether part goal already known  fact  conformant ffs cnfbased techniques specifically made suit probabilistic setting  without probabilities
one could imagine successfully replacing cnfs bdds  probabilities seems much
problematic 
algorithms present cover probabilistic initial belief states given bayesian networks 
deterministic probabilistic actions  conditional effects  standard action preconditions 
experiments show approach quite effective range domains  contrast
sat csp based approaches mentioned  majercik   littman        hyafil   bacchus 
       probabilistic ff find     step plans problem instances billions world states 
however  comparison entirely fair due different nature results provided 
sat csp based approaches provide guarantees length solution  approach
closely related probabilistic ff implemented pond  bryce et al          system 
probabilistic ff  conformant probabilistic planning threshold   using non admissible 
planning graph based heuristic guide search  hence comparison probabilistic ff
pond fair  experiments perform comparative evaluation probabilistic ff
pond  two approaches related  significant differences search
   

fip robabilistic  ff

space representation  well definition computation heuristic function   run
two approaches range domains partly taken probabilistic planning literature 
partly obtained enriching conformant benchmarks probabilities  partly obtained
enriching classical benchmarks probabilistic uncertainty  almost cases  conformant ff
outperforms pond least order magnitude  make interesting observations
regarding behavior two planners  particular identify domain derived
classical logistics domain approaches fail scale  apparent reason neither
approach good enough detecting many times  early point plan  probabilistic
action must applied order sufficiently support high goal threshold end plan 
devising methods better regard pressing open issue line work 
paper structured follows  next section provides technical background  formally
defining problem address illustrating running example  section   details
probabilistic belief states represented time stamped bayesian networks  bayesian
networks encoded weighted cnf formulas  necessary reasoning performed
representation  section   explains illustrates extension conformant ffs heuristic function probabilistic settings  section   provides empirical results  section  
concludes  proofs moved appendix a 

   background
probabilistic planning framework consider adds probabilistic uncertainty subset
classical adl language  namely  sequential  strips conditional effects  strips
planning tasks described set propositions p triples  a  i  g   corresponding
action set  initial world state  goals  g sets propositions  describes
concrete initial state wi   g describes set goal states w g  actions pairs
 pre a   e a   precondition  conditional  effects  conditional effect e triple
 con e   add e   del e    possibly empty  proposition sets  corresponding effects condition  add  delete lists  respectively  precondition pre a  proposition set 
action applicable world state w w pre a   applicable w 
result applying w undefined  applicable w  conditional effects
e e a  w con e  occur  occurrence conditional effect e w results world
state w add e    del e  
action applied w  proposition q q add e  del e  
 possibly same  occurring e  e e a   result applying w undefined  thus 
require actions self contradictory  is  a  every e  e e a  
exists world state w con e  con e    add e  del e       finally  action
sequence plan world state results iterative execution actions  starting
wi   leads goal state w g 
    probabilistic planning
probabilistic planning setting extends  i  probabilistic uncertainty
initial state   ii  actions probabilistic effects  general  probabilistic planning
   pond use implicit belief states  probabilistic part heuristic function uses sampling techniques 
rather probabilistic reasoning techniques employ 

   

fid omshlak   h offmann

tasks quadruples  a  bi   g     corresponding action set  initial belief state  goals 
acceptable goal satisfaction probability  before  g set propositions  initial state
longer assumed known precisely  instead  given probability distribution
world states  bi   bi  w  describes likelihood w initial world state 
similarly classical planning  actions pairs  pre a   e a    effect set e a 
richer structure semantics  e e a  pair  con e    e   propositional condition set probabilistic outcomes  probabilistic outcome  e 
triplet  p r    add    del     add delete lists before  p r   probability outcome occurs result effect e  naturally 
p require probabilistic effects
define probability distributions outcomes  is   e  p r        special case
deterministic effects e modeled way via  e       p r        unconditional actions
modeled single effect e con e      before  applicable w 
result applying w undefined  otherwise  applicable w  exists
exactly one effect e e a  con e  w   e   applying w results
w add     del   probability p r    likelihood  b  a   w   world state w
belief state  b  a   resulting applying probabilistic action b  given
 b  a   w    

x

wpre a 

b w 

x

 e 


p r   w   w     add    del    

   

e effect con e  w     kronecker step function takes
value   argument predicate evaluates true    otherwise 
formalism covers problem description features supported previously proposed
formalisms conformant probabilistic planning  kushmerick et al         majercik   littman 
      hyafil   bacchus        onder et al         bryce et al         huang         corresponds called unary nondeterminism   nd  normal form  rintanen         note
succinct forms specifying probabilistic planning problems  rintanen        
yet  nd normal form appears intuitive perspective knowledge engineering 
example   say robot block physically one two locations 
information captured propositions r    r  robot  b    b  block  respectively  robot either move one location another  carrying block 
robot moves without block  move guaranteed succeed  provides us
pair symmetrically defined deterministic actions  move right  move lef t   action move right empty precondition  single conditional effect e     r        
p r        add      r     del      r     robot tries move carrying block 
move succeeds probability      probability     robot ends moving
without block  probability     move robot fails completely  provides us
pair  again  symmetrically defined  probabilistic actions  move b right  move b lef t  
action move b right empty precondition  two conditional effects specified
table   
specified semantics structure components  a  bi   g     
ready specify actual task probabilistic planning setting  recall actions
transform probabilistic belief states belief states  action sequence   belief
   

fip robabilistic  ff

e a 

con e 

e

r  b  

e

r  b 

 e 

p r  

add  

del  

 
 
 
 

   
   
   
   

 r    b   
 r   



 r    b   
 r   



table    possible effects outcomes action move b right example   
state b  new belief state  b  a  resulting applying b given


  hi
b 
 b  a     b  a   
 
  hai 





  b  a          hai   a    

   

setting  achieving g certainty typically unrealistic  hence  specifies required
lower bound probability achieving g  sequence actions called plan
ba  g  belief state ba    bi   a  
    specifying initial belief state
considering initial belief state  practical considerations force us limit attention
compactly representable probability distributions bi   numerous alternatives
compact representation structured probability distributions  bayes networks  bns   pearl       
date far popular representation model   therefore  probabilistic ff
assume initial belief state bi described bn nbi set propositions p 
excellent introductions bns abound  e g   see jensen         suffices briefly
define notation  bn n    g    represents probability distribution directed acyclic
graph g  set nodes x stands random variables  assumed discrete paper  
  set tables conditional probabilities  cpts one table tx node x x  
possible value x dom x   where dom x  denotes domain x   table tx
lists probability event x   x given possible value assignment immediate
ancestors  parents  p a x  g  thus  table size exponential in degree x  usually 
assumed either in degree small  pearl         probabilistic dependence x
p a x  induces significant local structure allowing compact representation tx  shimony 
            boutilier  friedman  goldszmidt    koller          otherwise  representation
distribution bn would good idea first place   joint probability complete
assignment variables x given product  x   terms taken respective
cpts  pearl        


p r   x     p a x     
tx   x     p a x     
p r    
xx

xx

   stands partial assignment provided corresponding subset x  
   bns choice here  framework support models well  e g  stochastic decision trees 

   

fid omshlak   h offmann

probabilistic ff allow nbi described multi valued variables underlying
planning problem  significantly simplifies process specifying nbi since strips
 
propositions p
sknot correspond true random variables underlying problem specification 
specifically  let i   pi partition p proposition set pi uniquely corresponds
domain multi valued variable underlying problem  is  every world state w
every pi    pi        exactly one proposition q pi holds w  variables
bn nbi describing initial belief state bi x    x            xk    dom xi     pi
 pi        dom xi      q  q  pi    q  
example   illustration nbi   consider running example  say robot
known initially one two possible locations probability p r r         
p r r           suppose correlation belief initial locations robot
block  believe that  robot r    p r b           and p r b           
robot r    p r b           and p r b            initial belief state bn nbi defined
two variables r  robot  b  block  dom r     r    r    dom b     b    b    
respectively  depicted figure   
r 
   

r 
   

r

   b

r 
r 

b 
   
   

b 
   
   

figure    bayes network nbi example   
hard see strips style actions equivalently specified terms
multi valued variables x   specifically   pi        action add proposition
q pi without deleting proposition q pi   thus  consider setting
xi   q   pi        adding deleting q pi standard semantics setting xi   q
xi   q  respectively  simplicity presentation  assume actions selfcontradictory level x wellif two conditional effects e  e e a  possibly occur
world state w  subsets x affected two effects disjoint  finally 
goal g directly corresponds partial assignment x  unless g self contradictory 
requiring q q q  q pi   

   belief states
section  explain representation of  reasoning about  belief states  first explain
probabilistic belief states represented time stamped bns  explain
bns encoded reasoned form weighted cnf formulas  representation
belief states weighted cnfs illustrated belief state running example
figure    finally provide details works probabilistic ff 
   specifying nbi directly p would require identifying multi valued variables anyway  followed connecting
propositions corresponding multi valued variable complete dag  normalizing cpts
propositions certain manner 

   

fip robabilistic  ff

   
r
     
r 

r  r 
       
r   



b   

ii
ii
ii
ii
ii
  
  
uu
uu
u
u
uu
uu

b  b 
r         
r         

y   

r 
 
 
 

r 
 
 
 

   r
n      
n
n
nnn
nnn
n
n
       
nn
nnn
r  b               
ppp
ppp
       
ppp othrw
ppp
ppp
p  
   b   

b  b 
 
   
b    
   
b     

r  r 
r     
r     
   r   

   b   

b  b 
b     
b     

figure    bayes network nba running example     action sequence
  hmove b right  move lef ti 

    bayesian networks
probabilistic ff performs forward search space belief states  search states belief
states  that is  probability distributions world states w   search restricted belief
states reachable initial belief state bi sequences actions a  key decision
one make actual representation belief states  let bi initial belief state
captured bn nbi   let ba belief state resulting applying bi sequence
actions a  one well known problems area decision theoretic planning
description ba directly state variables x becomes less less structured number
 especially stochastic  actions increases  overcome limitation  represent belief
states ba bn nba explicitly captures sequential application starting bi   trading
representation size cost inference  compared representing belief states directly
distributions world states  formally specify structure bn nba   assuming
actions applicable corresponding belief states application  later
showing probabilistic ff makes sure indeed case  note belief state
bns similar spirit structure proposed ai literature verifying
probabilistic plan achieves goals certain probability  dean   kanazawa        hanks  
mcdermott        kushmerick et al         
figure   illustrates construction nba running example   hmove b right 
move lef ti  general  let   ha            sequence actions  numbered according
appearance a    m  let x t  replica state variables x   x t  x t 
   

fid omshlak   h offmann

corresponding x x   variable set nba union x              x m    plus
additional variables introduce actions a 
first  x    x      set parents p a x      conditional probability tables
tx    simply copy state variable x nbi   now  consider action a 
let   a  action introduce discrete variable y t 
mediates
variable layers x t   x t    domain y t  set dom y t      ee a   e   is 
union probabilistic outcomes possible effects a  parents y t  nba set
p a y t     

 

ee a 


x i     con e  dom x      

   

and  dom p a y t      set
ty  t   y i 

 
p r   
       
  

con  e   
 
otherwise

   

e   denotes effect e  e  
refer set variables y t  created actions y  now  let ex  a 
e a  probabilistic effects affect variable x x   ex  a      set
p a x t       x t     
 
   x   x  
 
   
tx t   x t    x   x t     x    
   otherwise
otherwise  ex  a       let x dom x  value provided x  e   e ex  a  
recall outcomes effects e a  mutually exclusive  hence  set p a x t     
 x t     y t     



tx i   x i    x   x i     x   y i  



  
        


  

e   ex  a  x   x  
e     ex  a  x   x    
otherwise

   

e   denotes effect responsible outcome  
hard verify equations     capture frame axioms probabilistic semantics oursactions  principle  accomplishes construction nba variables
xba  
t   x t    note  however  mediating variable y t  really needed
truly probabilistic actions  specifically  deterministic action a  let ex  a  e a 
conditional effects add and or delete propositions associated domain variable x x   ex  a      set p a x t       x t      tx t  according equation   
otherwise  set

 n

p a x t       x t    
x t  
  con e  dom x      
   
eex  a 

specify tx t  follows  let xe dom x  value  the deterministic outcome
of  effect e ex  a  provides x  dom p a x t      exists e ex  a 
   

fip robabilistic  ff

con e    set
tx t   x t 

 
  
  x      
  

x   xe  
otherwise

   

x    x t     
otherwise

   

otherwise  set
tx t   x t 

 
  
  x      
  

due self consistency action  hard verify equations     consistent 
and  together equation    capture semantics conditional deterministic actions 
special treatment deterministic actions illustrated figure   direct dependencies
x    x     
proposition   let  a  nbi   g    probabilistic planning problem  m step sequence
actions applicable bi   let p r joint probability distribution induced nba
variables xba   belief state ba corresponds marginal distribution p r x m    is 
ba  x     p r x m     g m  partial assignment provided g x m    probability
ba  g  achieves g starting bi equal p r g m    
already mentioned  belief state bns constructed along principles outlined
used dean kanazawa         hanks mcdermott         kushmerick et al 
        thus correctness proposition   immediate previous results 
point  worth bringing attention fact variables x              x m  completely
deterministic  moreover  cpts variables nba compactly representable due
either low number parents  local structure induced large amount context specific
independence  both  compactness cpts nba implied compactness
strips style specification planning actions  exploiting compactness action
specification  size nba description kept linear size input
number actions a 
proposition   let  a  nbi   g    probabilistic planning problem described k state variables  m step sequence actions a  then   nba     o  nbi   m k    
largest description size action a 
proof proposition    well proofs formal claims paper  relegated
appendix a  pp      
    weighted cnfs
given representation belief states bns  next select mechanism reasoning
bns  general  computing probability query bns known  pcomplete  roth         addition  hard verify  using analysis similar ones
darwiche        brafman domshlak         networks arising work
typically exhibit large tree width  numerous exact algorithms inference bns
proposed literature  darwiche        dechter        zhang   poole        
classical algorithms scale well large networks exhibiting high tree width  positive
   

fid omshlak   h offmann

side  however  observation guides recent advances area probabilistic reasoning
real world domains typically exhibit significant degree deterministic dependencies
context specific independencies problem variables  targeting property practical
bns already resulted powerful inference techniques  chavira   darwiche        sang et al  
       general principle underlying techniques
 i  compile bn n weighted propositional logic formula  n   cnf 
 ii  perform efficient weighted model counting  n   reusing  and adapting  certain
techniques appear powerful enhancing backtracking dpll style search sat 
one observation early stages developing probabilistic ff type
networks type queries problems make machinery solving bns
weighted cnf model counting attractive needs  first  section     already
shown bns representing belief states exhibit large amount deterministic nodes
context specific independence  second  queries interest correspond computing
probability evidence g m  nba   type query clear interpretation terms
model counting  sang et al          hence  taking route probabilistic ff  compile
belief state bns weighted cnfs following encoding scheme proposed sang et al         
answer probabilistic queries using cachet  sang  bacchus  beame  kautz    pitassi         one
powerful systems date exact weighted model counting cnfs 
general  weighted cnfs weights formulas specified follows  let
v    v            vn   set propositional variables dom vi      vi   vi    let  

   non negative  real valued weight function literals v 
dom vi   r
partial assignment v q
weight    assignment defined product literals
weights  is       l  l   finally  propositional logic formula called weighted
defined weighted set propositional variables  weighted formula v 
weight    defined sum weights complete assignments v satisfying
  is 
x
    
          
dom v 

dom v    dom vi    instance  variables vi  vi      vi       
   simply stands number complete assignments v satisfy  
given initial belief state bn nbi   sequence actions   ha            applicable
bi   describe weighted cnf encoding  nba    or  ba    short  belief state
ba built used probabilistic ff  first  formally specify generic scheme introduced
sang et al         encoding bn n variables x weighted cnf  n   
encoding formula  n   contains two sets variables  first  variable z x
value z dom z   formula  n   contains state proposition literals  z  z   weighted
 z     z       state propositions act  ba   regular sat propositions  now 
variable z xba   let dom z     z            zk   arbitrary fixed ordering dom z  
recall row tz  i  cpt z corresponds assignment  or set assignments  p a z   thus  number rows tz upper bounded number different
assignments p a z    as happens case  significantly lower dependence z p a z  induces substantial local structure  following ordering dom z 
above  entry tz  i  j  contains conditional probability p r zj      every cpt entry
   

fip robabilistic  ff

procedure basic wmc  
  return  
empty clause return  
select variable v
return basic wmc  v    v    basic wmc  v    v 
figure    basic dppl style weighted model counting 
tz  i  j  last one  i e   tz  i  k    formula  n   contains chance proposition literals
 hzji i  hzji i   chance variables aim capturing probabilistic information cpts
nba   specifically  weight literal hzji set p r zj     z            zj    
conditional probability entry true  given row true  prior entry row
true 
tz  i  j 
pj 
  k   tz  i  k 



hzj     hzji

hzji  

    

considering clauses  n    variable z x   cpt entry tz  i  j  
formula  n   contains clause


hz i hzj 
hzji zj  
    

conjunction literals forming assignment dom p a z    clauses
ensure weights complete assignments variables  n   equal probability corresponding atomic events postulated bn n   illustrate construction
equations        let boolean variables b parents ternary variable c  with
dom c     c    c    c     bn  let p r c   a  b         p r c   a  b        
p r c   a  b         let raw corresponding assignment a  b p a c  i th
row cpt tc   encoding bn  first two entries raw tc captured
pair respective chance propositions
hc i i  hc i i  according
equation     weights


   


propositions set hc         hc                then  according
equation     encoding contains three clauses

b hc i c 

b hc i hc i c 

b hc i hc i c 

finally  variable z x   formula  n   contains standard set clauses encoding
exactly one relationship state propositions capturing value z  accomplishes encoding n  n    next section     illustrate encoding
belief state bn running example 
weighted cnf encoding  ba   belief state bn nba provides input weighted
model counting procedure  simple recursive dppl style procedure basic wmc underlying cachet  sang et al         depicted figure    formula  v obtained setting
   

fid omshlak   h offmann

literal v true  theorem   sang et al         shows weighted cnf encoding
bn n   p r q e  general query respect n   query q  evidence e 
have 
basic wmc  q e 
p r q e   
 
    
basic wmc  e 
query q evidence e fact arbitrary formulas propositional logic  note that 
special  and relevant us  case empty evidence  equation    reduces p r q   
basic wmc q   is  single call basic wmc procedure  corollary   immediate
proposition   theorem   sang et al         
corollary   let  a  bi   g    probabilistic planning task bn nbi describing bi  
m step sequence actions applicable bi   probability ba  g  achieves g starting
bi given by 
ba  g    wmc   ba   g m    
    
g m  conjunction goal literals time stamped time endpoint a 
    example  weighted cnf encoding belief states
illustrate generic bn to wcnf encoding scheme sang et al         belief
state bn nba running example figure   
     introduce time stamped state propositions r   i   r   i   b   i   b   i   likewise 
introduce four state propositions                            corresponding values
variable y      first set clauses  ba   ensure exactly one relationship
state propositions capturing value variable nba  

                         

 i j   

 yi     yj       
 i   

    

 r   i  r   i      r   i  r   i  
 b   i  b   i      b   i  b   i  
proceed encoding cpts nba   root nodes one row
cpts chance propositions identified corresponding state variables  sang
et al          hence  root variable r    need neither additional clauses special
chance propositions  state proposition r       ba   treated chance proposition
 r             
encoding variable b    bit involved  cpt tb    contains two  content wise
different  rows corresponding given r  given r  cases  cases induce
non deterministic dependence b    r      encode content tb    introduce
two chance variables hb       hb        hb       i         hb       i        
positive literals hb       hb       capture events b  given r  b  given r   
negations hb       hb       capture complementary events b  given r  b 
given r    respectively  consider given r  row tb      encode row  need
   

fip robabilistic  ff



 ba   contain r      hb       b      r      hb       b       similar encoding
required row given r    thus encoding tb   introduces four additional clauses 


r      hb       b        r      hb       b     


    
r      hb       b        r      hb       b     

finished nbi part nba   proceed encoding variable y    corresponding probabilistic action move b right  encode first row ty    introduce three chance propositions h       i  h       i  h       i  general  chance variables needed last entries cpt rows  weights chance propositions
   
         
set according equation    h              h             

   
 
h                    using chance propositions  add  ba   four clauses
equation     notably first four clauses equation    below 
proceeding second row ty      observe value r    b    case fully
determines value y      deterministic dependence encoded without using
chance propositions using last two clauses equation    

r      b      h              

r      b      h       h              

r      b      h       h       h              
    

r      b      h       h       h              


r              b           

using state chance variables introduced r    b     y      encode cpts r   
b    as 
r             r                r        

       r      r               r      r       

       r      r               r      r     

b             b        

    

       b      b        
       b      b      
since cpts r    b    completely deterministic  encoding well using
chance propositions  finally  encode  deterministic  cpts r    b    as 
r       r      
b       b      b      

    

 b      b      
unary clause  r       reduction  r      r        r      r        accomplishes encoding  ba   
   

fid omshlak   h offmann

    conformant ff probabilistic ff
besides fact weighted model counting attractive kinds bns arising context  weighted cnf representation belief states works extremely well ideas underlying conformant ff  hoffmann   brafman         outlined introduction already 
give details 
stated  conformant ff forward search non probabilistic belief space
belief state corresponds set world states considered possible  main trick
conformant ff use cnf formulas implicit representation belief states 
formulas  a  encode semantics executing action sequence initial belief state  facts
known true false inferred formulas  computation partial
knowledge constitutes lazy kind belief state representation  comparison approaches
use explicit enumeration  bonet   geffner        bdds  bertoli  cimatti  pistore  roveri 
  traverso        fully represent belief states  basic ideas underlying probabilistic ff are 
 i  define time stamped bayesian networks  bn  describing probabilistic belief states  section     above  
 ii  extend conformant ffs belief state cnfs model bn  section     above  
 iii  addition sat reasoning used conformant ff  use weighted model counting
determine whether probability  unknown  goals belief state high enough
 directly below  
 iv  introduce approximate probabilistic reasoning conformant ffs heuristic function  section   below  
detail  given probabilistic planning task  a  bi   g     belief state ba corresponding
applicable bi m step action sequence a  proposition q p  say q known
ba ba  q       negatively known ba ba  q       unknown ba   otherwise  begin
determining whether q known  negatively known  unknown time m  re using
conformant ff machinery  classification requires two sat tests  ba   q m 
 ba   q m   respectively  information provided classification used threefold  first 
subgoal g g negatively known time m  ba  g       extreme 
subgoals g known time m  ba  g       finally  subgoals
g known rest unknown time m  accomplish evaluating belief state ba
testing whether
ba  g    wmc   ba   g m    

    

note sets  positively negatively  known propositions time steps
allows us significantly simplify cnf formula  ba   g m  inserting
corresponding values known propositions 
evaluating considered action sequence a  get ba  g    done 
otherwise  forward search continues  actions applicable ba  and thus used
generate successor belief states  actions whose preconditions known ba  
   

fip robabilistic  ff

   heuristic function
key component heuristic search procedure heuristic function  quality  informedness  computational cost function determine performance search 
heuristic function usually obtained solutions relaxation actual problem interest  pearl        russell   norvig         classical planning  successful idea
use relaxation ignores delete effects actions  mcdermott        bonet   geffner 
      hoffmann   nebel         particular  heuristic planning system based
notion relaxed plan  plan achieves goals assuming delete
lists actions empty  relaxed plan computed using graphplan style  blum   furst 
      technique combining forward chaining graph construction phase backward chaining
plan extraction phase  heuristic value h w  provides world state w encountered
search length relaxed plan w  conformant ff  methodology
extended setting conformant planning initial state uncertainty  without uncertainty
action effects   herein  extend conformant ffs machinery handle probabilistic initial
states effects  section     provides background techniques used conformantff  sections         detail algorithms forward backward chaining phases
probabilistic ff  respectively  algorithms two phases probabilistic ff heuristic
computation illustrated running example sections          respectively 
    conformant ff
specify relaxed plans computed ff  provide coarse sketch
computed conformant ff  purpose latter slowly prepare reader
come  conformant ffs techniques re used probabilistic ff anyway  hence
described full detail part sections         
formally  relaxed plans classical planning computed follows  starting w 
builds relaxed planning graph sequence alternating proposition layers p  t  action
layers a t   p     w  a t  set actions whose preconditions
contained p  t   p  t      obtained p  t  including add effects  with fulfilled
conditions  actions a t   is  p  t  always contains facts true one
would execute  the relaxed versions of  actions earlier layers a t     relaxed
planning graph constructed either reaches propositional layer p  m  contains
goals  construction reaches fixpoint p  t    p  t      without reaching goals 
latter case corresponds  all  situations relaxed plan exist 
existence relaxed plan necessary condition existence real plan  state w
excluded search space setting h w      former case g p  m   relaxed
plan subset actions a             a m  suffices achieve goals  under ignoring
delete lists   extracted simple backchaining loop  goal p  m   select
action a             a m  achieves goal  iterate process considering
actions preconditions respective effect conditions new subgoals  heuristic estimate
h w  set length extracted relaxed plan  is  number actions selected
backchaining process 
aiming extending machinery conformant planning  conformant ff  hoffmann brafman        suggested extend relaxed planning graph additional fact layers  t  containing facts unknown time t  reason unknown
   

fid omshlak   h offmann

facts become known relaxed planning graph  complexity type reasoning
prohibitive  conformant ff relaxes planning task ignoring delete lists 
one unknown conditions action effect  is  action appears
layer a t   effect e con e  p  t   t  con e   t      
con e   t  arbitrarily reduced contain exactly one literal  reasoning done
con e  reduced form beginning 
v
relaxation converts implications   ccon e up  t  c t   q t      action effects
induce unknown propositions   projections take form binary implications c t  q t       arbitrary c con e   t   due layered structure
planning graph  set binary implications c t  q t      seen forming
directed acyclic graph imp  given relaxations  graph captures exactly dependencies truth propositions time  hence  checking whether proposition q becomes
known time done follows  first  backchain implication edges imp end
q t   collect set support q t   leafs  reached  then  cnf formula
describing possible initial states  test sat check whether
 

l
lsupport q t  

test succeed least one leafs support q t   true every possible
initial state  given relaxations  case if  applying actions
relaxed planning graph  q always true time t  
process extracting relaxed plan constructed conformant relaxed planning
graph extension ffs respective process machinery selects actions responsible
relevant paths imp  overall conformant ff heuristic machinery sound complete
relaxed tasks  yields heuristic function highly informative across range challenging
domains  hoffmann   brafman        
work  adopt conformant ffs relaxations  ignoring delete lists action effects  well one propositions effects condition  accordingly  adopt
following notations conformant ff  given set actions a  denote   
  function
 
set possible actions     maps action similar
empty delete lists one conditioning propositions effect removed 
 
 
  
denote action set obtained applying   
   a   write a 
    a  
  actions

 
 


denote

a 
a  is  a  
 
a 
 



 


action
sequence
  sequence
 
 
 
actions obtained applying    every action along a  is 
 
hi 
  hi
a  
 
   
 
 

ha          hai
probabilistic planning task  a  bi   g     task  a  
    bi   g    called relaxation
 
 
 a  bi   g     finally  a   plan  a     bi   g     called relaxed plan
 a  bi   g    
   following conformant ff terminology  leafs refer nodes zero in degree 
   note would possible full sat check  without   projection  without relying imp   see
whether q becomes known t  however  indicated above  full check every unknown proposition
every level relaxed planning graph every search state would likely expensive  computationally 

   

fip robabilistic  ff

next two sections describe machinery underlying probabilistic ff heuristic
estimation  due similarity conceptual relaxations used probabilistic ff
conformant ff  probabilistic ff inherits almost conformant ffs machinery  course 
new contributions algorithms dealing probabilistic belief states probabilistic
actions 
    probabilistic relaxed planning graphs
conformant ff  probabilistic ff computes heuristic function two steps  first
one chaining forward build relaxed planning graph  second step chaining backward
extract relaxed plan  section  describe detail probabilistic ffs forward chaining step 
building probabilistic relaxed planning graph  or prpg  short   section      show
one extract  probabilistic  relaxed plan prpg  provide detailed illustration
prpg construction process basis running example  since illustration
lengthy  moved separate section     
algorithms building prpg quite involved  instructive first consider  some
of  key points delving details  main issue is  course  need
extend conformant ffs machinery ability determine goal set sufficiently
likely  rather known true sure  achieve that  must introduce
relaxed planning effective reasoning probabilistic initial state  effects
probabilistic actions  turns reasoning obtained certain weighted
extension implication graph  nutshell  want determine likely fact
q true time t  propagate certain weights backwards implication graph 
starting q t   weight q t  set    weight p t   gives estimate
probability achieving q given p holds   computing probability exactly would 
course  expensive  estimation based assuming independence various
probabilistic events involved  choice made carefully  experimented widely
various options deciding favor technique 
simplifying assumption weight propagation constitutes  course  another relaxation 
top relaxations already inherited conformant ff  particularly problematic
aspect assuming independence under estimating technique  actual weight
node p t   probability achieving q given p holds may lower
estimate  effect  prpg may decide wrongly relaxed plan exists  even execute
relaxed actions contained successful prpg  probability achieving goal
execution may less required threshold  words  lose soundness  relative
relaxed tasks  relaxed planning process 
experimented alternative weight propagation method  based opposite assumption  relevant probabilistic events always co occur  hence weights must
propagated according simple maximization operations  propagation method yielded
uninformative heuristic values  hence inacceptable empirical behaviour probabilistic ff 
even simple benchmarks  view  seems unlikely under estimating yet informative efficient weight computation exists  experimented alternative
non under estimating propagation schemes  particular one based assuming probabilistic events completely disjoint  and hence weights added   schemes gave better
   

fid omshlak   h offmann

performance maximization  lagged far behind independence assumption
challenging benchmarks 
let us get actual algorithm building prpg  coarse outline algorithm
follows  prpg built layer wise fashion  iteration extending prpg  reaching
time t  another layer  reaching time      actions new step whose
preconditions known hold t  effects conditioned unknown facts  note reduction
effect conditions single fact  constitute new edges implication graph  difference
conformant ff  dont obtain single edge condition add effect  instead  obtain edges
condition chance nodes  chance node represents probabilistic outcome
effect  chance nodes  turn  linked edges respective add effects  weights
chance nodes set probabilities respective outcomes  weights
nodes set    weights static weights dynamically modified
weight propagation  rather  static weights form input propagation 
implication graph edges inserted layer  algorithm checks whether new
facts become known  check done much corresponding check conformant ff 
testing whether disjunction support leafs proposition p     implied
initial state formula  two differences conformant ff are      leafs relevant whose
dynamic weight    otherwise  achieving leaf guaranteed accomplish p          
another reason p become known may outcomes unconditional effect  or
effect known condition  result achievement p time      elegantly formulate
overall test single implication test support leafs whose dynamic weight equals
weight 
ffs conformant ffs algorithms  prpg process two termination criteria 
prpg terminates positively goal probability high enough time t  prpg terminates
negatively if       nothing changed may result higher goal propability
future   goal probability layer computed based weighted model counting
formula derived support leafs goals known true  criteria negative
termination check  whether new facts become known unknown  not negatively known  
whether possibly relevant new support leafs appeared  whether goal probability
increased  neither case  stop safelyif prpg terminates unsuccessfully
guarantee relaxed plan  corresponding belief hence
dead end 
let us get details  figure   depicts main routine building prpg belief
state ba   already specified  sets p  t    t   a t  contain propositions
known hold time  hold probability     propositions unknown hold
time  hold probability less   greater     actions known
applicable time t  respectively  layers   prpg capture applying relaxed actions
starting ba   layers   prpg correspond m step action sequence leading
initial belief state belief state question ba   inherit latter technique
conformant ff  sense  prpg reasons past  may look confusing first
sight  simple reason  imagine prpg starts level   instead  then  check whether
proposition becomes known  sat tests regarding support leafs belief
state formula   ba    instead initial state formula  similarly weighted model counting
test whether goal likely enough   testing  ba   possible  expensive
   

fip robabilistic  ff

procedure build prpg a  a   nbi    g      
    
returns bool saying relaxed plan belief state
given   ham           a  i 
builds data structures relaxed plan extracted
    nbi    imp   
p  m      p   p known     m      p   p unknown  
    
a t      at   
    n oop
build timestep t  a t  
endfor
    
get p t  g   
a t      a  
    a  pre a  p  t   n oop
build timestep t  a t  
p  t        p  t 
 t         t 
p  t         m  support p t          m  support p t  
get p t      g    get p t  g 
return false
endif
      
endwhile
   t  return true

figure    main routine building probabilistic relaxed planning graph  prpg  
computationally   negative index layers chain implication graph way back
initial state  hence enable us perform sat tests typically much smaller initial
state formula 
returning figure    prpg initialized empty implication set imp  p  m 
 m  assigned propositions known unknown initial belief state 
weighted cnf formula initialized  nbi    formula implication weighted model checking tests run asking whether proposition becomes known whether
goal likely enough  prpg built  incrementally extended clauses
capture behavior different effect outcomes 
loop builds sets p time steps   iterative invocation
build timestep procedure time expands prpg single time level 
iteration    sets p  t       t      made contain propositions
known unknown applying relaxed version action  remember
  ha            i   simplify presentation  action set a t  contains set dummy
actions n oop simply
transport

propositions time layer time layer t   
formally  n oop   noopp   p p   pre noopp       e noopp        p        
         p       
   conformant ff  configuration implemented option  significantly slows search
domains  brings advantages cases 

   

fid omshlak   h offmann

subsequent loop constructs relaxed planning graph layer   onwards by 
again  iterative invocation build timestep procedure  actions layer  
relaxations actions whose preconditions known hold time certainty 
iterative construction controlled two termination tests  first  goal estimated hold
layer probability higher   know relaxed plan estimate extracted 
otherwise  graph reaches fix point  know relaxed  and thus  real  plan
bi exists  postpone discussion two termination criteria  focus
time layer construction procedure build timestep 
procedure build timestep t  a  
builds p  t        t       implication edges     
induced action set
p  t         p  t    t        
effects e action a  con e  p  t   t 
 e 
 t          t      add  
introduce new fact  t    t     p r  
imp    imp    t   p t         p add   
endfor
con e   t 
sthen
imp    imp  e    con e  t    t   
else
v
    e   t     e    t   t  
endif
endfor
p  t     
build w impleafs p t       imp 
support p t           l   l leafs impp t      p t     l     l  
w
lsupport p t     l p  t         p  t       p  endif
endfor
 t          t        p  t     

figure    building time step prpg 
build timestep procedure shown figure    first loop build timestep proceeds
outcomes  relaxed  actions given set may occur time t 
probabilistic outcome introduce new chance proposition weighted conditional likelihood
outcome   that  extend imp binary implications new chance
proposition add list outcome  uncertain condition con e 
corresponding effect time t  is  con e   t   add implications
con e  chance propositions created outcomes e  otherwise  con e 
known time t  uncertainty ability make effect e hold time
t  case  ground chance propositions created outcomes e
implication graph  simply extend running formula clauses capturing exactly
one relationship chance propositions corresponding alternative outcomes e
   course  implementation special case treatment deterministic actions  using chance nodes
 rather single chance node static weight    

   

fip robabilistic  ff

time t  way  probabilistic uncertainty outcome e treated
property initial belief state bi   type knowledge add knowledge
base formula initializing build prpg  nbi   
notation
impvu
impu
leafs imp  
e imp  

description
graph containing exactly paths node v node u imp 
subgraph imp formed node u ancestors u imp 
set zero in degree nodes subgraph imp imp 
set time stamped action effects responsible implication edges
subgraph imp imp 
table    overview notations around implication graph 

second loop checks whether proposition p  unknown time t  becomes known
time      part build timestep procedure somewhat involved  table   provides
overview main notations used follows discussing various uses
implication graph imp 
first thing second loop build timestep  call build w impleafs procedure associates node v t   impp t    estimate p t     v t    probability achieving
p time     effects e impv t  p t       given v holds time   words 
dynamic weight  according p t       implication graph nodes computed  note v t  
either time stamped proposition q t   q p  chance proposition  t  
probabilistic outcome  
discuss build w impleafs procedure detail below  proceeding understand
second loop build timestep  main thing need know following lemma 
lemma   given node v t   impp t      p t     v t       v t    if 
given v time   sequence effects e impv t  p t      achieves p     probability   
words  v t   leads p t      certainty iff dynamic weight v t   equals static
weight  simple consequence weight propagation arranged  hold true
reasonable weight propagation scheme  do mark node certain not   full
proof lemma appears appendix pp      
re consider second loop build timestep  happens following 
finished build w impleafs weight propagation p time     
   collect leafs support p t       impp t  meet criteria lemma   
   check  by call sat solver  whether knowledge base formula implies disjunction leafs 
implication holds  examined fact p time added set facts known time
t  finally  procedure removes set facts known possibly hold time    
facts proven hold time     certainty 
understand above  consider following  lemma    support p t       contains
exactly set leafs achieving lead p t      certainty  hence basically
   

fid omshlak   h offmann

procedure build w impleafs  p t   imp 
top down propagation weights p t  p t  nodes impp t 
p t   p t       
decreasing time steps     t           m 
chance nodes  t   impp t 


q
  p t   r t      
   radd   r t    imp
p t 
p t    t         t        
endfor
fact nodes q t   impp t 
    

a t
e a   con e    q

h    ep
p t    t   
      e   t  imp
p t 
endfor
p t   q t        
endfor
endfor

figure    build w impleafs procedure weight back propagation implication graph 
use implication test conformant ff  note  however  word basically
previous sentence hides subtle important detail  difference situation conformantff  support p t       may contain two kinds nodes      proposition nodes start layer
prpg  i e   layer corresponding initial belief      chance nodes later layers
prpg  corresponding outcomes effects unknown conditions  point
discussed updates onwthe formula neededthose keep track alternative
effect outcomes  hence testing lsupport p t     l testing whether either      p
known     always triggered certainty least one proposition true
initial world      p known     triggered outcomes effect
appear certainty  get following result 
lemma   let  a  nbi   g    probabilistic planning task  sequence actions applicable
bi     
  relaxation function a  time step m  proposition p
p  p  t  constructed build prpg a  a   nbi    g      
     p time achieved
 
relaxed plan starting a  
    probability      that is  p negatively known time t  p  t p  t  

    probability    that is  p known time t  p p  t  
consequence arguments outlined above  full proof lemma   given
appendix pp      
let us consider weight propagating  procedure build w impleafs depicted figure   
procedure performs layered  top down weight propagation given node  p t  imp
   weight propagation scheme build w impleafs procedure similar nature used heuristics
module recent probabilistic temporal planner prottle little  aberdeen  thiebaux        
   note instantiated     called build timestep 

   

fip robabilistic  ff

leafs impp t    order traversal ensures node impp t  processed successors impp t    chance nodes  t    dynamic weight
p t    t    set
   probability outcome takes place time given corresponding action
effect e   take place   times
   estimate probability achieving p time effects e imp t  p t    
first quantity given global  static weight   t    assigned  t   first
loop build timestep  second quantity derived dynamic weights p t   r t      
r add    computed previous iteration outermost loop build w impleafs 
making heuristic assumption effect sets e impr t    p t    different r add  
pairwise independent  set probability failure achieve p effects
e imp t  p t     computation  t   decomposed artifacts  
weight propagation starts taking place  fact nodes q t    dynamic weight
p t   q t    set probability action effect conditioned q time allows
 possibly indirectly  achieving desired fact p time t  making heuristic assumption
independence various effects conditioned q   computing p t   q t   
decomposed outcomes effects 
procedure get p  t  g 
estimates probability achieving g time p 
g   p  t   t  return   endif
g p  t  return   endif
g g   p  t 
l leafs impg t     introduce chance proposition hlg weight g t   l 
w
v
g      lleafs impg t    l  lleafs impg t   up  m   l hlg i 
endfor
v
return wmc  gg p  t  g  

figure    estimating goal likelihood given time step 
remains explained build prpg procedure two termination criteria
loop constructing planning graph layer   onwards  first test made
call get p procedure  checks whether prpg built time layer contains
relaxed plan  a  nbi   g     get p procedure shown figure    first  one
subgoals negatively known time t  then  lemma    overall probability achieving
goal    extreme  subgoals known time t  probability
achieving goal    correctness latter test implied lemma   non interference
relaxed actions  leaves us main case uncertain
subgoals  uncertainty either due dependence subgoals actual initial world
state  due achieving subgoals using probabilistic actions  due both  uncertainty
initial state fully captured weighted cnf formula  nbi     likewise 
outcomes chance propositions  t   introduced implication graph build timestep
procedure chained imp propositions add lists outcomes 
   

fid omshlak   h offmann

chained imp unknown  relaxed  conditions outcomes  any  therefore 
action outcome time   relevant achieving subgoal g g time t 
corresponding node  t   must appear impg t    weight back propagated
build w impleafs g t   imp  leafs impg t    get p procedure exploits
back propagated estimates by  again  taking heuristic assumption independence
achieving different subgoals  namely  probability achieving unknown sub goals g   p  t 
estimated weighted model counting formula   conjoined probabilistic theories
g achieving unknown goal g isolation  understand formulas g   consider that 
order make g true t  must achieve least one leafs l impg t    hence left part
conjunction  hand  make l true  achieves g t   estimated 
probability g t   l   hence right part conjunction requires us pay price set
l true   
explained start section  positive prpg termination test may fire even
real goal probability high enough  is  get p may return value higher real
goal probability  due approximation  independence assumption  done weight propagation  course  due approximation  may happen get p returns value lower
real goal probability 
second prppg termination test comes check whether reached point
construction prpg allows us conclude relaxed plan  a  nbi   g   
starts given action sequence a  termination criterion asks whether  time step
time step      potentially relevant changes occurred  potentially relevant change
would goal satisfaction probability estimate get p grows  known unknown
propositions grow  support leafs latter propositions imp correspond
initial belief state grow    none occurs  would hold future iterations   t 
implying required goal satisfaction probability would never reached  words 
prpg construction complete 
theorem   let  a  nbi   g    probabilistic planning task  sequence actions appli 
cable bi     
  relaxation function a  build prpg a  a   nbi    g         returns
 
false  relaxed plan  a  bi   g    starts a    
note theorem   holds despite approximation done weight propagation  making
assumption probabilistic independence  theorem   hold  requirement
weight propagation this  real weight still grows  estimated weight still grows 
requirement met independence assumption  would met assumption
co occurence  propagating weights maximization operations  thereby conservatively underestimating weights  propagation  prpg fails cannot conclude
plan respective belief  another good argument  besides bad quality heuristics
observed empirically  using conservative estimation 
    introduce extra chance propositions hlg i  instead assign weight g t   l  l itself 
outcome correct  pay setting l false 
    understand latter  note prpg always added replicas probabilistic actions
irrelevant achieving goals  effects known conditions  action effects  since
irrelevant  influence estimate goal satisfaction probability  chance propositions corresponding
outcomes effects may become support leafs unknown proposition p  latter case 
set support leafs support p t    infinitely grow   projection support p t   
initial belief state  that is  support p t    t   guaranteed reach fix point 

   

fip robabilistic  ff

full proof theorem   given appendix pp       theorem finalizes
presentation analysis process constructing probabilistic relaxed planning graphs 
    example  prpg construction
illustrate construction prpg algorithm figures      let us consider simplification running examples    
 i  actions  move b right  move lef t  constitute action set a 
 ii  goal g    r    b     required lower bound probability success       
 iii  initial belief state bi given bn nbi example   
 iv  belief state ba evaluated heuristic function corresponds actions sequence
  hmove b righti 
effects outcomes actions considered construction prpg described
table    embr re notation effect e table    effect e table   effectively
ignored due emptiness add effects 


e a 

con e 

con e   
 

 e 

p r  

add  

   
   
   
   

 r    b   
 r   

 r   

   
   
   
   

 r   
 r   
 b   
 b   

embr

 r    b   

 r   

aml  move lef t 

eml

 r   

 r   

mbr
 
mbr
 
mbr
 
ml

noopr 
noopr 
noopb 
noopb 

er 

 r   
 r   
 b   
 b   

 r   
 r   
 b   
 b   

r 
r 
b 
b 

ambr

 move b right 

er 
eb 
eb 

table    actions   
  relaxation prpg construction example 
initialization phase build prpg procedure results    nbi    imp     
p                r    r    b    b     content     depicted first column
nodes figure    first loop build prpg  constructing prpg past layers
corresponding a  makes single iteration  calls build timestep procedure    
a        ambr   n oop s   in follows  using names actions refer
mbr empty  thus adds
  
  relaxations given table     add list outcome  
nodes implication graph  that  chance nodes introduced imp call
build timestep appear second column figure    first outer loop build timestep
results imp given columns     figure               extension  
second outer loop build timestep  weight propagating procedure build w impleafs
called unknown fact p           r       r       b       b        generating p   oriented weights table    p         set supporting leafs support p      
   

fid omshlak   h offmann


wv



   ml    

  






mbr     
mbr


  aa

 aa    
ml
ml



  
  












mbr
mbr    

    
q         

 
  


  
qqq
rrrr
  


  
qq
  
rrrr
  
qqq

r
 
r
    

      r     
      r     
    
         
r      


   
  
  

  
  

 
rs
hi  
hi   




   r     
   r      
   r     
   r     
r      





b      



   b      



b      



   b      



 

   b     



   b     



   b     



   b     



 



mbr
     

ml
  



mbr
     
  
  
  
  
  
  
  
hi   
r

    
   r     
   

   b     



   b     



   b     



   b     



   b     
 

   b     

figure    implication graph imp  odd columns nodes depict sets unknown propositions  t   even columns nodes depict change propositions introduced
probabilistic outcomes actions a t  

 p      none implied   nbi   thus set known facts p     remains equal
p             equal       

r     
r     
b     
b     

   
   
mbr
mbr
r
r
r  r  b  b   
 
    b  b 
 
 
 
       
 
 
 
     
 

r  r  b  b 
 
     
 
   
 

table    columns table correspond nodes implication graph imp 
row provides weights p    p         entry row p   
empty node associated corresponding column belong
implication subgraph impp     
finished loop  build prpg procedure proceeds loop
builds future layers prpg  test goal  un satisficing get p    g    evaluates
true get get p    g                thus loop proceeds first iteration 
see former  consider implication graph imp constructed far  columns     fig   

fip robabilistic  ff

ure     goal g    r    b    leafs impr           r        leafs impb         
 r       b         r       b              nbi   
get p    g    wmc   nbi   r  b     

r     hr  r  i   r  hr  r  i   
b     hr  b  hb  b  i   r      hr  b  i   b      hb  b  i   

    


 hr  r  i    r       r          
 hb  b  i    b       b          

 

    

 hr  b  i    b       r            
observe two models  nbi   consistent r  immediately falsify sub formula
 nbi   r    hence 

get p    g    wmc  nbi   r  b   r        b         

wmc  nbi   r  b   r        b       

  bi  r    b     hr  r  i   hr  b  i    bi  r    b     hr  r  i   hr  b  i   hb  b  i 

                           
      
first iteration loop  build prpg calls build timestep procedure
    a       ambr   aml   n oop s  chance nodes introduced imp call
build timestep appear forth column figure    first outer loop build timestep
results imp given columns     figure               extension  
before  second loop build timestep  build w impleafs procedure called
unknown fact p           r       r       b       b        generating p    oriented weights 
interesting case case weight propagation build w impleafs r       imp   resulting
weights
r       r          

r       r           

ml

r                
r 

r                
r       r          
r       r          



r       r           
r       mbr
       
mbr
r              

     



r       r           
r       r           

     

nodes impr        that  set supporting leafs r      assigned support r        
 r       r        since    nbi   implies r      r       fact r  concluded
known time    added p      nodes p        still
support p        p      thus remain unknown time     well  putting
things together  call build w impleafs procedure results p        r       
   

fid omshlak   h offmann

       r       b       b        loop build prpg procedure proceeds checking fixpoint termination test  immediately fails due p        p      hence 
loop proceeds next iteration corresponding     
test goal  un satisficing get p    g    still evaluates true
get p    g                 let us follow evaluation get p    g  detail well  considering implication graph imp constructed far time      columns     figure    
g        b        leafs impb           r       b         still     nbi   
obtain
get p    g    wmc   nbi   b     

b     hr  b  hb  b  i   r      hr  b  i   b      hb  b  i   

    

structure b  equation    identical equation     weights associated
auxiliary chance propositions different  notably
 hb  b  i    b       b          

 

 hr  b  i    b       r             

    

difference  hr  b  i  equation    equation    stems fact r     
supports b      via effect embr time   via different instance
effect time    now  model  nbi   falsify b  one sets r 
b  false  hence 
get p    g    bi  r    b     hr  b  i   
bi  r    b     hr  b  i   hb  b  i   
bi  r    b     hb  b  i 
                                  
       
verified get p    g      loop proceeds construction time     
calls build timestep procedure     a       ambr   aml   n oop s  chance
nodes introduced imp call build timestep appear sixth column figure   
first outer loop build timestep results imp given columns     figure   


mbr
mbr
   nbi   mbr
   


   


   

 
 
 




mbr
mbr
mbr
mbr
mbr
mbr
   


   


   


   


   


   
 
 
 
 
 
 

    

next  build w impleafs procedure called usual unknown fact p         
 r       b       b        information worth detailing leafs impb         
mbr
 b       r       mbr
        support b          b               however  still
w
lsupport p     l p         thus set known facts p     remains equal
p        r    
   

fip robabilistic  ff

returning call build w impleafs procedure  build prpg proceeds checking
fixpoint termination condition  time  first three equalities condition hold  yet
condition satisfied due get p    g    get p t  g   see latter  notice
get p    g    wmc   b     
given equation    


b    hr  b  hb  b  mbr
       r      hr  b  i   b      hb  b  i   

    



 hb  b  i    b       b          

 

 hr  b  i    b       r             
 mbr
      

 

b       mbr
      

    

     

hard verify
get p    g    get p    g    bi  r    b     mbr
      
                  
       
note get p    g    therefore build prpg aborts loop
passing goal satisficing test  sets      finalizes construction prpg  thus 
example 
    extracting probabilistic relaxed plan
construction prpg succeeds reaching goals estimated probability success get p t  g  exceeding   extract relaxed plan consisting a             a t
    use size heuristic value evaluated belief state ba  
get technical details  consider key differences
relaxed  no delete lists  probabilistic planning one hand  relaxed classical relaxed qualitative conformant planning hand  relaxed probabilistic planning  might
make sense execute action numerous times consecutive time steps  fact 
might essential think throwing dice game   appears  contrast 
relaxed classical qualitatively uncertain settings needed effect
executed  remains true forever  another complication probabilistic planning required
goal achievement probability specified conjunction  or  possibly  complicated
logical combination  different facts  increasing probability achieving individual sub goal g g relaxed planning always increase overall probability achieving g 
choosing right distribution effort among sub goals pass required threshold
whole goal g non trivial problem 
fundamental problem aforementioned lack guarantees weight propagation 
one hand  construction prpg lemma   imply a  
  concatenated
r
arbitrary linearization a             a t    executable bi   hand  due
independence assumption made build w impleafs procedure  get p t  g 
   

fid omshlak   h offmann

r
imply probability achieving g a  
  concatenated exceeds   real relaxed
plan  sense  might even exist constructed prpg 
answer difficulties extract relaxed plans correct relative
weight propagation  namely  use implication graph reduction algorithm computes
minimal subset graph still according weight propagation sufficiently
supports goal  relaxed plan corresponds subset  obviously  solves
difficulty lack real relaxed plans  relaxed plan extraction according
independence assumption  besides ignoring deletes removing one condition
effect   mechanism naturally takes care need apply action several times 
corresponds several implication graph edges needed order obtain sufficient
weight  choice effort distributed among sub goals circumvented sense
sub goals considered conjunction  is  reduction performed all 
course  remains choice parts implication graph removed 
found useful heuristic make choice based actions already
applied path belief  detail below 
making another assumption top previous relaxations course bad heuristic
quality  relaxed plans extract guaranteed actually achieve desired goal probability  since relaxed plans used search guidance  per se theoretical weakness
marginal importance  however  over estimation goal probability might result bad
heuristic relaxed plan include right actions  apply often
enough  section    discuss example domain probabilistic ff fails scale
precisely reason 
figure   shows main routine extract prplan extracting relaxed plan given
prpg  note index highest prpg layer  c f  figure     sub routines
extract prplan shown figures        high level  extract prplan procedure consists
two parts 

   reduction implication graph  aiming identifying set time stamped action effects
ignored without decreasing estimate goal achievement probability get p t  g 
desired threshold  
   extraction valid relaxed plan ar  schematically  constructing prpg ar instead
full set a             a t   would still result get p t  g   
first part accomplished reduce implication graph procedure  depicted figure    
first step algorithm  procedure considers parts implication graph
relevant achieving unknown sub goals  next  reduce implication graph performs
greedy iterative elimination actions future layers              prpg probability estimate get p t  g  reduced set actions goes   while  principle  action a             a t    considered elimination  reduce implication graph examine repetitions actions already appear a  specifically  reduce implication graph
iterates actions a  
    repeats somewhere future layers prpg 
one repetition a t   considered removal  removing repetition found safe
respect achieving     effectively removed eliminating edges imp
induced a t    procedure considers next repetition a  removing another
    note formula wmc constructed exactly get p function  c f  figure   

   

fip robabilistic  ff

procedure extract prplan p rp g a  a   nbi    g      
     
selects actions a             a t   
imp    reduce implication graph  
extract subplan imp  
sub goal g p  t   
decreasing time steps    t           
g g t 
a t     e e a   con e  p  t      e    g add  
add to relaxed plan one time
sub goal pre a  con e  
else
imp g t     construct support graph support g t   
extract subplan imp g t   
endif
endfor
endfor

figure    extracting probabilistic relaxed plan 
copy safe anymore  procedure breaks inner loop considers next
action 
procedure reduce implication graph  
operates prpg 
returns sub graph imp 
imp    gg p  t   impg t  
actions a  
 
edges   t    p t       imp   induced a t   a t     
imp    imp
remove imp edges induced a t  
g g   p  t 
l leafs imp g t      introduce chance proposition hlg weight g t    l 
v
w
g      lleafs imp
  l  lleafs imp
 up  m   l hlg i 
g t  

g t  

endfor
v
wmc  gg p  t   g   imp    imp else break endif
endfor
endfor
return imp

figure     procedure reducing implication graph 
illustrate intuition behind focus repetitions actions a  let us consider following example simple logistics style planning problem probabilistic actions 
suppose two locations b  truck known initially a  heavy
uneasy grab package known initially truck  goal package
unloaded b reasonably high probability  two actions use moving
truck b  am    unloading package  au    moving truck necessarily
   

fid omshlak   h offmann

move truck b  extremely high probability  hand  unloading bothersome package succeeds extremely low probability  leaving package
truck otherwise  given data  consider belief state ba corresponding trying move
truck once  is  action sequence ham i  achieve desired probability success 
prpg expanded large time horizon   allowing action au
applied sufficiently many times  however  fact truck b known belief state ba  
thus implication graph contain amount applications   trimming
away applications still keep probability sufficiently high 
reader might ask point hope achieve trimming away
applications   point is  intuitively  implication graph reduction mechanism
means understand accomplished already  path ba   without
understanding  relaxed planning quite indiscriminative search states  consider
example  assume one two troubled packages  p   p   
truck  unload actions au  au    prpg ba contains copies au  au  layers
large horizon   now  say search starts unload p    resulting belief  prpg
still steps situation changed p    step prpg still contains
copies au  au  hence heuristic value remains before 
words  without implication graph reduction technique  relevant things accomplished
may remain hidden behind things yet accomplished  example 
really critical because  soon tried unload p   p   
time horizon decreases one step  heuristic value reduced  is  however  often
case sub task must accomplished sub task attacked 
situations  without implication graph reduction  search staggers across huge plateau
first task completed  observed variety benchmarks  hence designed
implication graph reduction make relaxed planning aware already done 
course  since weight propagation may over estimate true probabilities  hence overestimate achieved past  implication graph reduction may conclude prematurely
sub task completed  leads us main open question research 
get back end section    discuss context example
probabilistic ffs performance bad 
let us get back explaining extract prplan procedure  implication graph reduction  procedure proceeds relaxed plan extraction  process makes use proposition
sets g             g t    used store time stamped sub goals arising layers  
relaxed plan extraction  sub routine extract subplan  figure    
   adds constructed relaxed plan time stamped actions responsible edges
reduced implication graph imp  
   subgoals everything outside implication graph condition applicability effects
responsible edges imp  
later phases process  sub goals added sets g             g t  
sub goal procedure simply inserts given proposition sub goal first layer
appearance prpg  accomplished extract and subgoal pass extract subplan
imp   subgoal goal conjuncts known time  
next phase process  sub goals considered layer layer decreasing order
time steps    sub goal g time t  certain supporting actions selected
   

fip robabilistic  ff

procedure extract subplan imp  
actions helpful achieving uncertain goals g  t  
subgoals essential conditions actions
edge   t   p t       imp  
action effect e e a  responsible time time
add to relaxed plan time
sub goal  pre a  con e   p  t  
endif endfor
procedure sub goal p  
inserts propositions p sub goals
layers first appearance prpg
p p
t     argmint  p p  t  
t    g t       g t     p  endif
endfor
procedure construct support graph support g t   
takes subset support g t   leafs impg t    weighted according g t  
returns sub graph imp imp 

imp   
open    support g t  
open   
open    open    p t   
choose a t    e e a   con e     p 
 e     p t     t    impg t  g t    t        t   
 e 
choose q add   g t   q t          
imp    imp   p t     t       t    q t       
open    open  q t      
endfor endwhile
return imp

figure     sub routines extract prplan 
relaxed plan  action effect e e a  known applicable
time    guarantee achieve g certainty  added constructed relaxed
plan    otherwise 
   use construct support graph procedure extract sub graph imp g t  consisting set
implications together ensure achieving g time t 
   use already discussed procedure extract subplan
 a  add constructed relaxed plan time stamped actions responsible edges
imp g t   
 b  subgoal everything outside implication graph imp g t  condition applicability
effects responsible edges imp g t   
   

fid omshlak   h offmann

processing way sub goals g    finalizes extraction relaxed plan
estimate  section     provides detailed illustration process prpg constructed
section      event  easy verify relaxed plan extract sound relative
weight propagation  following sense 
proposition   let  a  nbi   g    probabilistic planning task  sequence actions ap 
plicable bi     
  relaxation function build prpg a  a   nbi    g        
returns true  let a   s           a t   s actions selected a             a t   
extract prplan  constructing relaxed planning graph using a   s           a t   s  
get p t  g   
proof  construction  reduce implication graph leaves enough edges graph
weight propagation underlying get p still concludes goal probability high enough 
    example  extracting relaxed plan prpg
illustrate process relaxed plan extraction prpg figure    constructed
belief state problem specification example section      example
     g        b     thus implication graph imp gets immediately reduced
sub graph imp depicted figure   a  plan belief state question consists
single action ambr   action instances considered elimination outer loop
reduce implication graph ambr     ambr      ambr     chosen examined 
implication sub graph imp   imp reduced removing edges due ambr     
resulting imp appears   figure   b  b  components evaluated formula
b  given equation    equation     respectively  weights associated
chance propositions equation    reduced implication graph imp
 hb  b  i    b       b          
 hr  b  i    b       r            

 

    

mbr
 mbr
         b                   

weight model counting b  evaluates           thus imp replace imp  
alternative action removal ambr      seen example section     attempt action elimination result probability estimate lower  
hence  effect reduce implication graph prpg processed extract prplan
procedure reduction implication graph edges relevant achieving  b   
time      reduced implication sub graph imp returned reduce implication graph
procedure depicted figure   a 
next  extract subplan procedure iterates edges imp adds initially
empty relaxed plan applications ambr times      action ambr preconditions 
e ambr   known time    hence  extract subplan
condition r  effect mbr
 
invokes sub goal procedure  r      latter added proposition set g    
subsequent call sub goal g p  t      sub goal  r     leads extensions g     g   
    dashed edges figure   b removed imp either latter stage imp chosen replace
imp  

   

fip robabilistic  ff



mbr
         
qq
  
qqq
q
q
qq


   r      
r      



b      



   b      



   r     



mbr
        
rrr
  
rrr
r
r

    
b     



   b     





mbr
     

    
b     

  



   b     



    
b     

 a 


mbr
         
qq
  
qqq
q
q
qq

r
r                                 r     

b      



   b      



 

   b     



mbr
     



   b     



   b     



   b     



  

 

   b     

 b 


   ml
     

r      



   r      



r      



   r      



wv

r
  

   r     
        





rs

   r     

   r     

 c 
figure     illustrations various steps relaxed plan extraction prpg constructed
section      and  particular  implication graph latter  depicted
figure   

already r  g     hence  outer loop extract prplan starts g       
g       r    
since g    empty  first sub goal considered extract prplanis r  g     r 
time    action effect time   passes test statementthe condition r  ml
known time    true   r    hence  subgoal r      processed
extracting sub plan support achieving certainty  first  construct support graph
procedure called support r          r       r        see section       extracted sub    fact  easy see construction sub goal procedure p belongs g t   condition
noops effect p cannot known time   

   

fid omshlak   h offmann

graph imp r      original implication graph imp depicted figure   c  invoking
procedure extract subplan imp r      results adding  i  application aml time     ii 
new subgoals  hence  proposition sets g     g    get emptied  thus end
extracting relaxed plan hambr      aml      ambr    i 

   empirical evaluation
implemented probabilistic ff c  starting conformant ff code        
probabilistic ff behaves exactly conformant ff  except conformant ff cannot handle
non deterministic effects   otherwise  probabilistic ff behaves described previous sections  uses cachet  sang et al         weighted model counting  better home
strengths weaknesses approach  empirical evaluation probabilistic ff
done two steps  section     evaluate probabilistic ff problems non trivial uncertain initial states  deterministic actions  section     examine probabilistic ff
problems probabilistic action effects  sources uncertainty  compare
probabilistic ffs performance probabilistic planner pond  bryce et al         
reasons choosing pond reference point twofold  first  similarly probabilistic ff 
pond constitutes forward search planner guided non admissible heuristic function based
 relaxed  planning graph computations  second  knowledge  pond clearly
efficient probabilistic planner reported literature   
experiments run pc running  ghz  gb main memory  mb cache
running linux  unless stated otherwise  domain problem pair tried four levels desired probability success                         run planner time limited
     seconds user time  probabilistic ff run default configuration inherited ff 
performing one trial enforced hill climbing switching best first search case failure 
domains without probabilistic effects  found probabilistic ffs simpler relaxed plan extraction developed case  domshlak   hoffmann         performs better one described
here  hence switch simpler version domains   
unlike probabilistic ff  heuristic computation pond element randomization 
namely  probability goal achievement estimated via sending set random particles
relaxed planning graph  the number particles input parameter   problem instance  averaged runtime performance pond    independent runs  special
cases pond timed runs certain problem instance  yet
   runs  average report pond uses lower bounding time threshold     s replace missing time points  cases  ponds best case performance differs lot
average performance  cases  best case performance reported  note that 
following suggestion dan bryce  pond run default parameter setting  and  par    experiments used recent version     pond significantly enhances pond     bryce et al  
       authors would thank dan bryce rao kambhampati providing us binary distribution
pond    
    without probabilistic effects  relaxed plan extraction proceeds much conformant ff  additional
straightforward backchaining selecting support unknown goals  complicated techniques developed
deal relaxed plan extraction probabilistic effects appear unstable behavior
simpler techniques  probabilistic effects  simple backchaining meaningful
information many times action must applied order sufficiently support goal 

   

fip robabilistic  ff

      
t  s  l

     
t  s  l

      
t  s  l

     
t  s  l

         
         

           
        

          
          

          
          

           
          

cube uni   
cube cub   

         
         

           
         

           
          

           
           

            
            

bomb      
bomb      
bomb     
bomb     

               
             
             
            

        
        
        
        

          
           
           
           

          
           
           
            

          
           
            
            

log  
log  
log  

                
                 
                

           
           
           

           
           
           

           
           
           

           
            
            

grid  
grid  
grid  

                
                
                

          
             
             

           
            
              

            
              
              

            
              
               

rovers  
roversp  
roverspp  
roversppp  

               
                
                
                

           
           
           
            

           
           
            
            

           
            
            
     unsat

           
            
             
     unsat

instance

 actions  facts  states

safe uni   
safe cub   

table    empirical results problems probabilistic initial states  times seconds  search
space size  s   number calls heuristic function   plan length l 

ticular  includes number random particles      selected computing ponds heuristic
estimate  bryce et al         
    initial state uncertainty deterministic actions
examine performance probabilistic ff pond collection domains
probabilistic initial states  deterministic action effects  consider domains one
one  discussing set runtime plots  problem instances  table   shows
details  providing features instance size well detailed results probabilistic ff 
including number explored search states plan length 
first three domains probabilistic versions traditional conformant benchmarks  safe 
cube  bomb  safe  n combinations one opens safe  given probability
distribution combination right one  type action safe trying
combination  objective open safe probability   experimented
two probability distributions n combinations  uniform one  safe uni  distribution
declines according cubic function  safe cub   table   shows probabilistic ff
solve efficiently even n       figure    compares probabilistic ff
pond  plotting time performance identical linear scale  x axes show number
combinations 
graphs easy see probabilistic ff outperforms pond least order
magnitude safe uni safe cub  interesting observation necessarily
difference time performance  relative performance planner safe uni
safe cub  note safe cub somewhat easier safe uni sense that  safe cub  fewer
combinations must tried guarantee given probability opening safe 
   

fid omshlak   h offmann

pff

pond   

  

  
p     
p     
p     
p     

  

  

  

  

  

time  sec 

time  sec 

  

p     
p     
p     
p     

  

  

  

  

  

  

 

 
  

  

  

  

  

  

 combinations

  

  

 combinations

 a  uniform prior distribution combinations 
pff

pond   

  

  
p     
p     
p     
p     

  

  

  

  

  

time  sec 

time  sec 

  

p     
p     
p     
p     

  

  

  

  

  

  

 

 
  

  

  

  

  

 combinations

  

  

  

 combinations

 b  cubic decay prior distribution combinations 
figure     safe domain  probabilistic ff  left  vs  pond  right  
dominant part probability mass lies combinations head cubic distribution
 the last combination probability   right combination  thus needs tried
even         question whether heuristic functions probabilistic ff
pond exploit difference safe uni safe cub  table   figure    provide
affirmative answer question heuristic function probabilistic ff  picture
pond less clear times spent pond  otherwise identical  instances safe uni
safe cub roughly same   
another interesting observation that  probabilistic ff pond  moving  
           is  planning qualitative uncertainty truly probabilistic planning 
    safe cub n                   pond undergoes exponential blow up shown
graphs since data points would obscure data points  anyway  believe blow up due
unfortunate troubles numerics 

   

fip robabilistic  ff

pff

pond   

  

    
p     
p     
p     
p     

  

p     
p     
p     
p     

    
    
    
time  sec 

time  sec 

  

  

  

    
   
   
   

 
   
 

 
 

 

 
  
n grid nxnxn

  

  

 

 

 
  
n grid nxnxn

  

  

  

  

 a  uniform prior distribution initial position 
pff

pond   

  

    
p     
p     
p     
p     

  

p     
p     
p     
p     

    
    
    
time  sec 

time  sec 

  

  

  

    
   
   
   

 
   
 

 
 

 

 
  
n grid nxnxn

  

  

 

 

 
  
n grid nxnxn

 b  cubic decay prior distribution initial position 
figure     cube domain  probabilistic ff  left  vs  pond  right  

typically result performance decline  even get improved performance  except
       safe uni   reason seems plans become shorter  trend
observed domains  trend particularly remarkable probabilistic ff  since
moving             means move case model counting needed
case needed   in words  probabilistic ff automatically specializes
qualitative uncertainty  using model counting  knowledge  true
pond  uses techniques cases  
cube  task move corner   dimensional grid  actions correspond
moving current cube cell one  up    adjacent cube cells  again  created
problem instances uniform cubic distributions  over initial position dimension  
again  probabilistic ff scales well  easily solving instances          cube  within
time limit  pond capable solving cube problems cube width     figure   
   

fid omshlak   h offmann

compares probabilistic ff pond detail  plotting time performance
different linear scales  with x axes capturing width grid dimension   showing
least order magnitude advantage probabilistic ff  note that 
probabilistic ff generally becomes faster decreasing  with decreasing hardness
achieving objective   seem substantial effect performance
pond 
probabilistic ff exploits relative easiness cube cub  e g   see table     time
performance pond cube cub cube uni qualitatively identical 
tried version cube task move grid center  probabilistic ff
bad so  reaching performance limit n      weakness cube center domain
inherited conformant ff  detailed hoffmann brafman         reason
weakness lies inaccuracy heuristic function domain  two sources
inaccuracy  first  solve cube center reality  one must start moving corner
order establish position  relaxation  without delete lists  necessary  second 
relaxed planning graph computation over approximates achieved future
steps  already achieved path considered belief state  even
moderately long paths actions  relaxed planning graph comes  wrong  conclusion
goal already achieved  relaxed plan becomes empty heuristic
information 
next consider famous bomb in the toilet domain  or bomb  short   version
bomb contains n bombs toilets  bomb may armed armed independently probability   n  resulting huge numbers initially possible world states  dunking
bomb unclogged toilet disarms bomb  clogs toilet  toilet unclogged
flushing it  table   shows probabilistic ff scales nicely n       becomes faster
increases  latter logical desirable toilets means disarming
devices  resulting shorter plans needed  figures       compare probabilistic ff
pond  plotting time performance probabilistic ff linear scale  pond
logarithmic scale  four pairs graphs correspond four choices number toilets
                x axes graphs correspond number potentially armed
bombs  checked problems n                  figure    shows time
probabilistic ff least four orders magnitude faster pond  extremes 
hardest combination n                   took probabilistic ff less   seconds 
pond timed out problem instances  addition 
bomb well  probabilistic ff exhibit nice pattern improved performance
move non probabilistic          probabilistic planning  specifically      
      initial state good enough already  
performance probabilistic ff improves number toilets  pond seems
exhibit inverse dependence  is  sensitive number states
problem  see table    rather optimal solution depth 
finally  remark that  though length optimality explicitly required probabilistic conformant planning  safe  cube  bomb  probabilistic ffs plans optimal  the shortest
possible  
   

fip robabilistic  ff

pff

pond   

  
p     
p     
p     
p     

    

 
   

time  sec 

time  sec 

 

 

  

 

 

   
p     
p     
p     
p     

 

    
 

  

  
  bombs

  

 

  

  
  bombs

  

 a     toilets
pff

pond   

  
p     
p     
p     
p     

    

 
   

time  sec 

time  sec 

 

 

  

 

 

   
p     
p     
p     
p     

 

    
 

  

  
  bombs

  

 

  

  
  bombs

  

 b     toilets
figure     bomb domain  probabilistic ff  left  vs  pond  right  

next three domains adaptations benchmarks deterministic planning  logistics 
grid  rovers  assume reader familiar domains  logistics x
instance contains    cities     airplanes     packages  city x locations 
packages chance      airport origin city  uniformly
locations city  effects loading unloading actions conditional  right 
position package  note higher values x increase space world states 
initial uncertainty  grid complex grid world run aips   planning competition  mcdermott         featuring locked positions must opened matching keys 
grid x modification instance nr     of    run aips        grid    locked
positions     keys   must transported goal position  lock x possible  uniformly distributed shapes    goal keys x possible  uniformly distributed
initial positions  effects pickup key  putdown key  open lock actions conditional 
   

fid omshlak   h offmann

pff

pond   

  
p     
p     
p     
p     

    

 
   

time  sec 

time  sec 

 

 

  

 

 

   
p     
p     
p     
p     

 

    
 

  

  
  bombs

  

 

  

  
  bombs

  

 c    toilets
pff

pond   

  
p     
p     
p     
p     

    

 
   

time  sec 

time  sec 

 

 

  

 

 

   
p     
p     
p     
p     

 

    
 

  

  
  bombs

  

 

  

  
  bombs

  

 d    toilet
figure     bomb domain  probabilistic ff  left  vs  pond  right  

finally  last set problems comes three cascading modifications instance nr     of
    rovers domain used aips   planning competition  problem instance  
waypoints    rovers    objectives    rock soil samples  rovers roversppp modify
instance domain follows 
rovers original aips   problem instance nr     use hear mainly comparison 
roversp  sample chance     original waypoint  chance    
others two waypoints  objective may visible   waypoints
uniform distribution  this probabilistic adaptation domain suggested bryce  
kambhampati        
   

fip robabilistic  ff

sandcastle

sandcastle

   
pff
pond

pff
pond  min 
pond  avg 
   

   

  
time  sec 

time  sec 

   

   

 

   

   

 

    
   

   

   

   

   


   

   

   

   

 a 

   

   

   

   


   

   

   

 b 

figure     probabilistic ff pond problems  a  sand castle   b  slipperygripper 

roverspp enhances roversp conditional probabilities initial state  stating whether
objective visible waypoint depends whether rock sample  intuition  large piece rock  located waypoint  probability visibility much
higher latter case  specifically  visibility objective depends
locations two rock samples  rock sample present  visibility probability
drops     
roversppp extends roverspp introducing need collect data water existence 
soil samples certain probability       wet  communicated
sample data  additional operator tests whether sample wet  so  fact knowthat water contained goal set true  probability wet depends
location sample 
show runtime plots logistics  grid  rovers  since pond runs either time
memory considered instances domains  table   shows scaling behavior
probabilistic ff three domains similar observed previous domains 
goals roversppp problem cannot achieved probabilities             
proved probabilistic ffs heuristic function  providing correct answer split seconds 
    probabilistic actions
first two domains probabilistic actions famous sand castle  majercik   littman 
      slippery gripper  kushmerick et al         domains  domains simple 
posed first challenges probabilistic planners  performance domains serves
indicator progress relative previous ideas probabilistic planning 
sand castle  states specified two boolean variables moat castle  state
transitions given two actions dig moat erect castle  goal erect castle 
   

fid omshlak   h offmann

 d walkgrid

 d walkgrid

pff
pond

    

   

   

  

  

time  sec 

time  sec 

    

 

 

   

   

    

    

pff
pond
 

 

 

 

 

  

 

grid width

 a 

 

 

 
 
grid width

 

 

  

 b 

figure     probabilistic ff pond problems  a   d walkgrid         b 
 d walkgrid        

building moat dig moat might fail probability      erecting castle erect castle
succeeds probability      moat already built  probability       otherwise  failed  erect castle destroys moat probability      figure    a  shows
probabilistic ff pond solve problem less second arbitrary high values
  performance planners almost independent required probability
success 
slippery gripper already bit complicated domain  states slippery gripper
specified four boolean variables grip dry  grip dirty  block painted  block held 
four actions dry  clean  paint  pickup  initial state  block neither painted
held  gripper clean  gripper dry probability      goal
clean gripper holding painted block  action dry dries gripper probability      action
clean cleans gripper probability       action paint paints block probability   
makes gripper dirty probability   block held  probability    
not  action pickup picks block probability      gripper dry 
probability     gripper wet 
figure    b  depicts  on log scale  relative performance probabilistic ff pond
slippery gripper function growing   performance probabilistic ff nicely flat
around      seconds  time  comparison pond somewhat problematic  because 
fixed   pond slippery gripper exhibited huge variance runtime  figure    b 
plot best runtimes pond  well average runtimes  best run times pond
different values vary around couple seconds  average runtimes significantly
worse   for high values pond timed out sample runs  thus plot provides
lower bound average runtimes  
next two domains   d walkgrid  d walkgrid  robot pre plan sequence conditional movements taking corner grid farthest  from initial
   

fip robabilistic  ff

position  corner  hyafil   bacchus          d walkgrid grid one dimensional 
 d walkgrid grid two dimensional  figure    a  depicts  on log scale  snapshot
relative performance probabilistic ff pond one dimensional grids width n
       robot initially         get     n   try moving two
possible directions  two movement actions moves robot right direction
probability      keeps place probability      easy see figure    a 
difference two planners domain substantialwhile runtime probabilisticff grows linearly x  dependence pond seemingly exponential 
 d walkgrid domain already much challenging probabilistic planning 
 d walkgrid problems n n grids robot initially         get  n  n  
try moving four possible directions  four movement actions advances
robot right direction probability      opposite direction probability   
either two directions probability      figure    a  depicts  on log scale 
snapshot relative performance probabilistic ff pond  d walkgrid
low required probability success         function grids width n 
plot shows probabilistic ff still scales well increasing n  though linearly anymore  
pond time outs grid widths n      higher values   however  probabilistic ff
reach time out limit rather small grids  notably n     n           
       respectively  reason probabilistic ffs heuristic function good
enough estimating many times  early point plan  probabilistic action must
applied order sufficiently support high goal threshold end plan  explain
phenomenon detail end section  find appears variant
well known logistics domain 
last set problems comes standard logistics domain  problem instance
x y z contains x locations per city  cities  z packages  see probabilistic ff
scales much worse  logistics  presence probabilistic effects initial
state uncertainty  we explain reason end section   hence use much
smaller instances ones used section      namely  allow direct comparison
previous results domain  closely follow specification hyafil bacchus        
use instances configurations x y z                        distinguish two
levels uncertainty 
l x y z correspond problems uncertainty outcome load unload
actions  specifically  probabilities success load       trucks    
airplanes  unload            respectively 
ll x y z extends l x y z independent uniform priors initial location
package within start city 
figure    depicts  on log scale  runtimes probabilistic ff pond l        l       
l        function growing   problems  planners appear scale well 
runtime probabilistic ff optimal runtime pond roughly same 
average runtime pond somewhat degrading                    shows
planners much efficient domain previously known sat csp
based techniques  however  moving ll x y z changes picture planners  results
follows 
   

fid omshlak   h offmann

l      

l      

   

pff
pond  min 
pond  avg 

 

   

  

time  sec 

  

time  sec 

time  sec 

   
pff
pond  min 
pond  avg 

  

    
    

l      

   
pff
pond  min 
pond  avg 

 

   

    

   


 a 

    

    

    
    

 

   

    

   


 b 

    

    

    
    

    

   

    

    



 c 

figure     probabilistic ff pond problems logistics  a  l         b  l       
 c  l       

   ll        runtimes probabilistic ff identical l       
optimal runtimes pond slightly degraded    seconds  however  examined
values   runs pond resulted timeouts 
   ll        runtimes probabilistic ff identical l      
                         yet probabilistic ff time outed         optimal runtimes
pond degraded l            seconds  again  values
  runs pond resulted timeouts 
   ll        probabilistic ff experienced hard times  finishing      seconds  
      time outing examined values   optimal runtimes pond
degraded l               seconds  well  values  
runs pond resulted timeouts 
tried variant ll x y z non uniform priors initial locations packages  resulted qualitatively similar picture absolute relative performance 
ll x y z domain remains challenging  deserves close attention future developments probabilistic planning  context  interesting close look
reasons failure probabilistic ff is  turns probabilistic ff good enough
estimating many times  early point plan  probabilistic action must applied
order sufficiently support high goal threshold end plan  make concrete 
consider logistics example uncertain effects load unload actions  consider package p must go city city b  lets say p initially airport 
goal threshold high  means that  able succeed  package brought
airport high probability loading onto airplane  exactly point
probabilistic ffs heuristic function fails  relaxed plan contains actions unloading p
airport  effect search proceeds quickly loading p onto plane
bringing b  search gets point b unloaded goal location  goal threshold cannot achieved matter many times one unloads p  point 
   

fip robabilistic  ff

probabilistic ffs enforced hill climbing enters loop eventually fails relaxed plan
 which over estimates past achievements  becomes empty   
challenge devise methods better recognizing many times p
unloaded airport order sufficiently support goal threshold  error made
probabilistic ff lies propagation weights implication graph over estimates
goal probability  note much critical actions must applied early
plan  actions applied later  action appears early plan 
relaxed plan  executed  long  recall weight propagation proceeds
backwards  goal towards current state  single backwards step  propagation
makes approximation might lose precision results  several backwards steps 
imprecisions accumulate  hence quality approximation decreases quickly
number backwards steps  longer distance goal current state is 
information lost  observed phenomenon detailed experiments different
weight propagation schemes  is  different underlying assumptions  propagation
schemes tried  independence assumption  presented paper  far
accurate one  schemes failed deliver good results even much shorter distances
goal current state 
interesting consider issue affects pond  uses different method
estimating probability goal achievement  instead performing backwards propagation
aggregation weight values  pond sends set random particles relaxed planning
graph forward fashion  stops graph building enough particles end goal 
empirical results  seems method suffers similar difficulties probabilistic ff 
large extent  ponds optimal runtimes ll x y z much higher
l x y z  indicates always challenging pond recognize need
applying action many times early plan  interestingly  pond never times out
l x y z  often time out ll x y z  indicates that  extent  matter
chance whether ponds random particles recognize need applying action
many times early plan  intuitive explanation good cases
sufficiently many particles failed reach goal due taking wrong effect a 
based intuition  one would expect helps increase number random particles
ponds heuristic function  so  running pond ll x y z increased number
particles          instead default value     surprise  qualitative behavior
pond change  time outing similar number cases  unclear us reason
phenomenon is  certainly  observed situation encoded ll x y z
solved satisfaction either probabilistic ffs weight propagation ponds random particle
methods  current configurations 
time writing  unclear authors better methods could devised  seems
unlikely weight propagation least one resort expensive reasoning exists
manages long distances better independence assumption  alternative way
might simply define weaker notion plans allows repeat certain kinds actions
    happen l        l        l       instances simply small
high goal probability achieved without thinking much problem  one increases size
instances  problem appears  problem appears earlier presence initial state uncertainty even
small instances ll        ll        ll       uncertainty start position
packages one needs try unloading start airports often 

   

fid omshlak   h offmann

throwing dice unloading package arbitrarily many times  however  since assumption
observability plan execution  executing plan would
still arise question often action tried  since logistics fairly well solved
domain simpler formalisms virtue probabilistic ff  even probabilistic setting
long effects deterministic consider addressing problem quite pressing open
question 

   conclusion
developed probabilistic extension conformant ffs search space representation  using
synergetic combination conformant ffs sat based techniques recent techniques
weighted model counting  provided extension conformant relaxed planning
approximate probabilistic reasoning  resulting planner scales well range benchmark domains  particular outperforms close relative  pond  least order magnitude
almost cases tried 
point may somewhat obvious  would emphasize achievements
solve  this particular  problem all  probabilistic ff inherits strengths
weaknesses conformant ff  domains ffs conformant ffs heuristic
functions yield bad estimates  e g  mentioned cube center variant   whats more  probabilistic setting introduces several new potential impediments ffs performance  one thing 
weighted model counting inherently harder sat testing  though happen
set benchmarks  bound cases cost exact model counting becomes
prohibitive even small examples  promising way address issue lies recent methods
approximate model counting  gomes  sabharwal    selman        gomes  hoffmann  sabharwal    selman         methods much efficient exact model counters 
provide high confidence lower bounds number models  lower bounds used
probabilistic ff place exact counts  shown good lower bounds
high confidecne achieved quickly  challenge extend methods
currently designed non weighted cnfs handle weighted model counting 
importantly perhaps  presence probabilistic effects fundamental weakness probabilistic ffs ponds heuristic information  becomes pitfall performance even straightforward adaptation logistics domain  otherwise easy
kind planners  outlined  key problem that  obtain high enough confidence
goal achievement  one may apply particular actions several times early plan 
neither probabilistic ffs ponds heuristics good enough identifying many times 
view  finding techniques address issue currently important open topic
area 
apart addressing latter challenge  intend work towards applicability real word
settings  particularly  look space application settings rovers domain hints at 
medication type treatment planning domains  power supply restoration domain  bertoli 
cimatti  slaney    thiebaux        
   

fip robabilistic  ff

acknowledgments
authors would thank dan bryce rao kambhampati providing binary distribution pond     carmel domshlak partially supported israel science foundations
grant          well c  wellner research fund  major parts research
accomplished time jorg hoffmann employed intelligent information
systems institute  cornell university 

appendix a  proofs
proposition   let  a  nbi   g    probabilistic planning problem described k state variables  m step sequence actions a  then   nba     o  nbi   m k    
largest description size action a 
proof  proof rather straightforward  exploits local structure nba cpts 
first nodes cpts layer x    nba constitutes exact copy nbi   then    m 
t th layer nba contains k     node  y t    x t   
first  let us consider action node y t    specifying cpt ty  t  straightforward
manner prescribed eq    might result exponential blow up  eq    suggests
original description compact specification ty  t    therefore  ty  t 
described space o    description efficiently used answering queries
ty  t   y i        eq     next  consider cpt tx t  state variable node x t  x t   
time  rather evident eq    tx t  described space o   queries
tx t   x t    x   x t     x   could efficiently answered  thus  summing layers
  m  description size  nba     o  nbi     m k      
lemma   given node v t   impp t    p t   v t       v t    if  given v
time   sequence effects e impv t  p t    achieves p probability   
proof  proof lemma   backward induction time layers impv t  p t   
time t  node impp t  time stamped p t  itself  node
p t   p t      p t        but  given p time t  empty plan corresponding  empty 
e impp t p t    trivially re establishes p certainty  assuming claim holds
nodes impp t  time stamped              t  show holds nodes
time stamped  
easy see that  node v t   impp t    get p t   v t       v t   
goes zero  first  consider chance nodes  t   impvp t    node  lb
set zero p t   r t           r add    however 
inductive assumption  case effects e imp t  p t      achieve p
probability    given occurrence time  
now  consider fact nodes q t   impvp t    node  get nullified
effect e e a   a t    con e    q  latter happens if  possible outcomes e   i  node  t   belongs impp t     ii  estimate p t    t        t    
words  inductive assumption  given outcome  e  time   effects e imp t  p t    achieve p probability    thus  given q time   effects
e impq t  p t    achieve p probability   independently actual outcome e  alternatively  q t   lb      effect e conditioned q t   exists
   

fid omshlak   h offmann

outcome e that  according proved chance nodes time stamped
  effects e imp t  p t      achieve p probability    hence  whole set
effects e impq t  p t      achieve p probability   
lemma   let  a  nbi   g    probabilistic planning task  sequence actions applicable
bi     
  relaxation function a  time step m  proposition p
p  p  t  constructed build prpg a  a   nbi    g      
     p time achieved
relaxed plan starting a  
 
    probability      that is  p negatively known time t  p  t p  t  

    probability    that is  p known time t  p p  t  
proof  proof direction straightforward induction t    claim
immediate direct initialization  m  p  m   assume that    t 
p  t   p  t    p negatively known time   p p  t    p known
time  
first  consider p t   t  p  t   suppose p egatively know time t 
inductive assumption  property prpg construction  t    p  t   
 t  p  t   p    t    p  t     therefore  p added  t   and
then  possibly  moved p  t   first loop build timestep procedure 
however  so  exists action a t     e e a    e   i 
con e   t    p  t      ii  p add    again  assumption induction
pre a  known time    con e  negatively known time    hence 
non zero probability occurring time implies p achieved time probability
greater    contradicting p negatively know time t 
now  let us consider p t  p  t   notice that    m  p t  p  t 

 
l  
    

lsupport p t  

thus  world state w consistent bi   either q w fact proposition
q m  support p t    or  effect e action a t   a t      t  con e 
p  t     t      e   support p t    first case  lemma   immediately implies
concatenation a  
  arbitrary linearization  relaxed  actions a             a t   
achieves p probability    thus p known time t  second case  inductive
assumption implies con e  known time t  together lemma   implies
concatenation a  
  arbitrary linearization  relaxed  actions a             a t   
achieves p probability   
proof direction induction well    claim
immediate direct initialization p  m   assume that    t  p
negatively known time   p  t   p  t    p known time   p p  t   
first  suppose p negatively known time t  yet p    t  p  t  
inductive assumption plus a t    containing noop actions propositions
 t    p  t     know p negatively known time    so  p become
negatively known time due  e   e e a   pre a  known
   

fip robabilistic  ff

time    con e  negatively known time    inductive assumption 
latter conditions imply con e   t    p  t     pre a  p  t     so  p
added  t  p  t  first loop build timestep procedure  contradicting
assumption p    t  p  t  
now  let us consider p known time t  inductive assumption  p  t    contains
facts known time    thus a t    maximal subset actions a  
  applicable
time    let us begin exhaustive classification effects e actions a t   
respect p time t 
 i   e    p add    con e  p  t   
 ii   e    p add    con e   t   
 iii   e    p   add   con e    p  t     t   
set  i  empty  then  construction build w impleafs p t   imp  
  t       e   support p t   
e  i   likewise  construction build timestep  notably  update   
e  i  
 

 t    
  t    e  

putting two facts together  eq     holds p time t  thus p p  t  
now  suppose set  i  empty  hard verify subset effects  iii 
makes p known time t  thus  event least one effects  ii  occurs must hold
probability    first  construction build w impleafs p t   imp  
 
support  p t  
support  con e  t    
e ii 

then    lemma   event least one effects  ii  occurs holds
probability  
 

l
e ii 
lsupport con e  t   

putting two facts together  eq     holds p time t  thus p p  t  

theorem   let  a  nbi   g    probabilistic planning task  sequence actions appli 
cable bi     
  relaxation function a  build prpg a  a   nbi    g         returns
 
false  relaxed plan  a  bi   g    starts a    
proof  let     last layer prpg upon termination build prpg  every
t  construction prpg lemma    sets p  t    t   contain
 and all  propositions known  respectively unknown  executing actions
action layers including a t    
   

fid omshlak   h offmann

first  let us show build prpg returns false  corresponding termination criterion would hold future iterations  p  t        p  t   a t        a t  
subsequently  since p  t       t        p  t   t  a t        a t  
p  t       t        p  t       t       given that  show p  t        p  t     
 t         t      
assume contrary exists p t      p  t      p t        p  t      
p t       t       construction sets p  t      p  t      build timestep
procedure 
 

l  
lsupport p t    

 

 

    

l

lsupport p t    

consider exhaustive classification effects e actions a t      respect p
time     
 i   e    p add    con e  p  t     
 ii   e    p add    con e   t     
 iii   e    p   add   con e    p  t       t     
suppose set  i  empty  let e  i   p  t    p  t      con e 
p  t   thus   t 
w    e   support p t       
w update build timestep
  t   e    t   thus lsupport p t     l  contradicting eq     
alternatively  assume set  i  empty  using arguments similar proof
lemma    p t      p  t      p t        p  t      case imply
 
l

e ii 
lsupport con e  t    

 

 

    

l

e ii 
lsupport con e  t  

however  a t        a t    t         t   p  t        p  t  together imply
action effects possibly take place time     feasible take place time
t  therefore  since e  ii  con e   t      definition  ii   eq    
implies
 
 
support  con e  t        m    
support  con e  t    m  
    
e ii 

e ii 

contradicting termination condition  hence  arrived contradiction assumption
p t        p  t      
shown p  t        p  t       t         t       show
termination criteria implies that  q t       t      
 m  support p t          m  support p t       
   

fip robabilistic  ff

let ep t    set effects actions a t      con e   t       and 
outcome  e   p add    given that 
 m  support p t          m 

 

support con e  t      

 

support con e  t  

eep t   

   m 

 

    

eep t   

   m  support p t      
first third equalities definition support sets via lemma    second
equation termination condition 
last things remains shown termination criteria implies get p t  
   g   get p t      g   considering simple cases first  g   p  t       t      
p  t       t        p  t       t      get p t      g   get p t      g       otherwise  g p  t       p  t        p  t      get p t      g   get p t      g      
leaves us case g p  t       t      g  t          
p  t        p  t        t         t       termination condition 
g  t    g  t        g  t      
get p t      g   get p t  g  know action effects become feasible a t 
increase estimate probability achieving g g  t      time time
     however  p  t        p  t    t         t   a t        a t  
action effect become feasible time     already feasible time t  thus
get p t      g   get p t  g  imply get p t      g   get p t      g  
point shown build prpg returns false  corresponding termination criterion would hold future iterations  now  assume contrary claim
theorem build prpg returns false iteration t  yet exists relaxed plan
 a  bi   g    starts a  
    first       lemma   implies exists time
g p  t    so  persistence negative termination condition implies
g p  t   however  case would get p t  g       see second get p
procedure   thus build prpg would return true ever getting check negative
termination condition iteration t  alternatively       build prpg would terminated
returning true negative termination condition checked even once 
leaves us case         get p t  g       get p t  g 
contradict reaching negative termination condition iteration t   assume
g p  t   t  p  t   t  contains facts negatively known time
t  thus persistence negative termination condition together g   p  t   t  would
imply relaxed plan      let us consider sub goals g  t      
    subgoals g g  t   implications impg t  due deterministic
outcomes effects e impg t     uncertainty achieving g  t  time
due uncertainty initial state  since initial
v belief state reasoned
relaxation  case get p t  g    wmc  gg p  t  g   provides us
upper bound probability achieving goal g a  
  concatenated
   

fid omshlak   h offmann

arbitrary linearization arbitrary subset a             a t     termination subcondition get p t      g   get p t  g  persistence action sets a t    t 
imply get p t  g  provides us upper bound probability achieving g
a  
  concatenated arbitrary linearization arbitrary subset a             a t   
t  together get p t  g      latter conclusion contradicts assumption
desired relaxed plan exists 
    exists subgoal g g  t  implications impg t  due truly
probabilistic outcomes effects e impg t 
actions a t 
v    repeating  relaxed  v
a t      necessarily result wmc  gg p  t    g     wmc  gg p  t  g   
contradicting termination sub condition condition get p t      g   get p t  g  
hence  arrived contradiction assumption build prpg returns false time t 
yet exists relaxed plan  a  bi   g    starts a  
  

references
bertoli  p   cimatti  a   pistore  m   roveri  m     traverso  p          mbp  model based planner 
proc  ijcai   workshop planning uncertainty incomplete information 
seattle  wa 
bertoli  p   cimatti  a   slaney  j     thiebaux  s          solving power supply restoration problems planning via symbolic model checking  proceedings   th european conference artificial intelligence  ecai   pp          lion  france 
blum  a  l     furst  m  l          fast planning planning graph analysis  artificial
intelligence                  
bonet  b     geffner  h          planning heuristic search  artificial intelligence          
    
bonet  b     geffner  h          planning incomplete information heuristic search belief
space  proceedings  th international conference artificial intelligence planning
scheduling systems  aips   pp        breckenridge  co 
boutilier  c   friedman  n   goldszmidt  m     koller  d          context specific independence
bayesian networks  proceedings twelfth conference uncertainty artificial
intelligence  uai   pp          portland  or 
brafman  r  i     domshlak  c          factored planning  how  when  not  proceedings   th national conference artificial intelligence  aaai   pp          boston 
ma 
bryce  d     kambhampati  s          heuristic guidance measures conformant planning 
proceedings   th international conference automated planning scheduling
 icaps   pp          whistler  bc  canada 
bryce  d   kambhampati  s     smith  d          sequential monte carlo probabilistic planning
reachability heuristics  proceedings   th international conference automated
planning scheduling  icaps   pp          cumbria  uk 
   

fip robabilistic  ff

chavira  m     darwiche  a          compiling bayesian networks local structure  proceedings   th international joint conference artificial intelligence  ijcai   pp 
          edinburgh  scotland 
darwiche  a          recursive conditioning  artificial intelligence                
darwiche  a          constant space reasoning dynamic bayesian networks  international journal approximate reasoning                
dean  t     kanazawa  k          model reasoning persistence causation  computational intelligence            
dechter  r          bucket elimination  unified framework reasoning  artificial intelligence 
          
domshlak  c     hoffmann  j          fast probabilistic planning weighted model counting  proceedings   th international conference automated planning
scheduling  icaps   pp          cumbria  uk 
gomes  c  p   hoffmann  j   sabharwal  a     selman  b          sampling model counting 
proceedings   th international joint conference artificial intelligence  ijcai     hyderabad  india 
gomes  c  p   sabharwal  a     selman  b          model counting  new strategy obtaining good bounds  proceedings   th national conference artificial intelligence
 aaai      pp        boston  ma 
hanks  s     mcdermott  d          modeling dynamic uncertain world i  symbolic
probabilistic reasoning change  artificial intelligence             
hoffmann  j     nebel  b          planning system  fast plan generation heuristic
search  journal artificial intelligence research             
hoffmann  j     brafman  r          conformant planning via heuristic forward search  new
approach  artificial intelligence                  
huang  j          combining knowledge compilation search efficient conformant probabilistic planning  proceedings   th international conference automated planning
scheduling  icaps   pp          cumbria  uk 
hyafil  n     bacchus  f          utilizing structured representations csps conformant
probabilistic planning  proceedings european conference artificial intelligence
 ecai   pp            valencia  spain 
jensen  f          introduction bayesian networks  springer verlag  new york 
kushmerick  n   hanks  s     weld  d          algorithm probabilistic planning  artificial
intelligence                  
little  i   aberdeen  d     thiebaux  s          prottle  probabilistic temporal planner  proceedings   th national conference artificial intelligence  aaai      pp      
      pittsburgh  pa 
littman  m  l   goldsmith  j     mundhenk  m          computational complexity probabilistic planning  journal artificial intelligence research         
   

fid omshlak   h offmann

majercik  s  m     littman  m  l          maxplan  new approach probabilistic planning  proceedings  th international conference artificial intelligence planning
systems  aips   pp        pittsburgh  pa 
majercik  s  m     littman  m  l          contingent planning uncertainty via stochastic
satisfiability  artificial intelligence                   
mcdermott  d               ai planning systems competition  ai magazine             
mcdermott  d  v          using regression match graphs control search planning  artificial
intelligence                   
onder  n   whelan  g  c     li  l          engineering conformant probabilistic planner  journal
artificial intelligence research          
pearl  j          heuristics   intelligent search strategies computer problem solving  addisonwesley 
pearl  j          probabilistic reasoning intelligent systems  networks plausible inference 
morgan kaufmann  san mateo  ca 
rintanen  j          expressive equivalence formalisms planning sensing  proceedings   th international conference automated planning scheduling  icaps  
pp          trento  italy 
roth  d          hardness approximate reasoning  artificial intelligence              
    
russell  s     norvig  p          artificial intelligence  modern approach    edition   pearson 
sang  t   bacchus  f   beame  p   kautz  h     pitassi  t          combining component caching
clause learning effective model counting   online  proceedings  th international conference theory applications satisfiability testing  sat   vancouver  bc 
canada 
sang  t   beame  p     kautz  h          solving bayes networks weighted model counting 
proceedings   th national conference artificial intelligence  aaai   pp         
pittsburgh  pa 
shimony  s  e          role relevance explanation i  irrelevance statistical independence  international journal approximate reasoning               
shimony  s  e          role relevance explanation ii  disjunctive assignments approximate independence  international journal approximate reasoning              
zhang  n  l     poole  d          simple approach bayesian network computations 
proceedings   th canadian conference artificial intelligence  pp          banff 
alberta  canada 

   


