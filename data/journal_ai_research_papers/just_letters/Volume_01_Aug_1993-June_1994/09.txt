journal of artificial intelligence research                 

submitted        published     

substructure discovery using minimum description
length and background knowledge
diane j  cook
lawrence b  holder

department of computer science engineering
box      
university of texas at arlington
arlington  tx       usa

cook cse uta edu
holder cse uta edu

abstract

the ability to identify interesting and repetitive substructures is an essential component to discovering knowledge in structural data  we describe a new version of our subdue substructure discovery system based on the minimum description length principle 
the subdue system discovers substructures that compress the original data and represent
structural concepts in the data  by replacing previously discovered substructures in the
data  multiple passes of subdue produce a hierarchical description of the structural regularities in the data  subdue uses a computationally bounded inexact graph match that
identifies similar  but not identical  instances of a substructure and finds an approximate
measure of closeness of two substructures when under computational constraints  in addition to the minimum description length principle  other background knowledge can be used
by subdue to guide the search towards more appropriate substructures  experiments in
a variety of domains demonstrate subdue s ability to find substructures capable of compressing the original data and to discover structural concepts important to the domain 

   introduction
the large amount of data collected today is quickly overwhelming researchers  abilities to
interpret the data and discover interesting patterns within the data  in response to this
problem  a number of researchers have developed techniques for discovering concepts in
databases  these techniques work well for data expressed in a non structural  attributevalue representation  and address issues of data relevance  missing data  noise and uncertainty  and utilization of domain knowledge  however  recent data acquisition projects
are collecting structural data describing the relationships among the data objects  correspondingly  there exists a need for techniques to analyze and discover concepts in structural
databases 
one method for discovering knowledge in structural data is the identification of common substructures within the data  the motivation for this process is to find substructures
capable of compressing the data and to identify conceptually interesting substructures that
enhance the interpretation of the data  substructure discovery is the process of identifying
concepts describing interesting and repetitive substructures within structural data  once
discovered  the substructure concept can be used to simplify the data by replacing instances
of the substructure with a pointer to the newly discovered concept  the discovered substructure concepts allow abstraction over detailed structure in the original data and provide
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

ficook   holder
new  relevant attributes for interpreting the data  iteration of the substructure discovery
and replacement process constructs a hierarchical description of the structural data in terms
of the discovered substructures  this hierarchy provides varying levels of interpretation that
can be accessed based on the goals of the data analysis 
we describe a system called subdue  holder  cook    bunke        holder   cook 
      that discovers interesting substructures in structural data based on the minimum
description length principle  the subdue system discovers substructures that compress
the original data and represent structural concepts in the data  by replacing previouslydiscovered substructures in the data  multiple passes of subdue produce a hierarchical description of the structural regularities in the data  subdue uses a computationally bounded
inexact graph match that identifies similar  but not identical  instances of a substructure and
finds an approximate measure of closeness of two substructures when under computational
constraints  in addition to the minimum description length principle  other background
knowledge can be used by subdue to guide the search towards more appropriate substructures 
the following sections describe the approach in detail  section   describes the process of
substructure discovery and introduces needed definitions  section   compares the subdue
discovery system to other work found in the literature  section   introduces the minimum
description length encoding used by this approach  and section   presents the inexact
graph match algorithm employed by subdue  section   describes methods of incorporating
background knowledge into the substructure discovery process  the experiments detailed
in section   demonstrate subdue s ability to find substructures that compress the data and
to re discover known concepts in a variety of domains  section   details the hierarchical
discovery process  we conclude with observations and directions for future research 

   substructure discovery
the substructure discovery system represents structured data as a labeled graph  objects
in the data map to vertices or small subgraphs in the graph  and relationships between
objects map to directed or undirected edges in the graph  a substructure is a connected
subgraph within the graphical representation  this graphical representation serves as input
to the substructure discovery system  figure   shows a geometric example of such an input
graph  the objects in the figure  e g   t   s   r   become labeled vertices in the graph  and
the relationships  e g   on t  s    shape c  circle   become labeled edges in the graph 
the graphical representation of the substructure discovered by subdue from this data is
also shown in figure   
an instance of a substructure in an input graph is a set of vertices and edges from
the input graph that match  graph theoretically  to the graphical representation of the
substructure  for example  the instances of the substructure in figure   are shown in
figure   
the substructure discovery algorithm used by subdue is a computationally constrained
beam search  the algorithm begins with the substructure matching a single vertex in the
graph  each iteration through the algorithm selects the best substructure and expands the
instances of the substructure by one neighboring edge in all possible ways  the new unique
generated substructures become candidates for further expansion  the algorithm searches
   

fisubstructure discovery

input graph

substructure

t 

pe

s 

triangle

a
sh

c 
r 

t 

t 

s 

s 

on

t 

pe

square

a
sh

s 

figure    example substructure in graph form 
instance

 

instance

 

instance

 

instance

t 

t 

t 

t 

s 

s 

s 

s 

 

figure    instances of the substructure 
for the best substructure until all possible substructures have been considered or the total
amount of computation exceeds a given limit  the evaluation of each substructure is guided
by the mdl principle and other background knowledge provided by the user 
typically  once the description length of an expanding substructure begins to increase 
further expansion of the substructure will not yield a smaller description length  as a
result  subdue makes use of an optional pruning mechanism that eliminates substructure
expansions from consideration when the description lengths for these expansions increases 

   related work
several approaches to substructure discovery have been developed  winston s arch program  winston        discovers substructures in order to deepen the hierarchical description
of a scene and to group objects into more general concepts  the arch program searches for
two types of substructure in the blocks world domain  the first type involves a sequence
of objects connected by a chain of similar relations  the second type involves a set of
objects each having a similar relationship to some  grouping  object  the main difference
between the substructure discovery procedures used by the arch program and subdue is
that the arch program is designed specifically for the blocks world domain  for instance 
the sequence discovery method looks for supported by and in front of relations only 
subdue s substructure discovery method is domain independent  although the inclusion of
domain specific knowledge would improve subdue s performance 
motivated by the need to construct a knowledge base of chemical structures  levinson
 levinson        developed a system for storing labeled graphs in which individual graphs
   

ficook   holder
are represented by the set of vertices in a universal graph  in addition  the individual graphs
are maintained in a partial ordering defined by the subgraph of relation  which improves
the performance of graph comparisons  the universal graph representation provides a
method for compressing the set of graphs stored in the knowledge base  subgraphs of
the universal graph used by several individual graphs suggest common substructure in the
individual graphs  one difference between the two approaches is that levinson s system
is designed to incrementally process smaller individual graphs  whereas  subdue processes
larger graphs all at once  also  levinson s system discovers common substructure only
as an indirect result of the universal graph construction  whereas  subdue s main goal
is to discover and output substructure definitions that reduce the minimum description
length encoding of the graph  finally  the subgraph of partial ordering used by levinson s
system is not included in subdue  but maintaining this partial ordering would improve the
performance of the graph matching procedure by pruning the number of possible matching
graphs 
segen  segen        describes a system for storing graphs using a probabilistic graph
model to represent subsets of the graph  alternative models are evaluated based on a minimum description length measure of the information needed to represent the stored graphs
using the model  in addition  segen s system clusters the graphs into classes based on
minimizing the description length of the graphs according to the entire clustering  apart
from the probabilistic representation  segen s approach is similar to levinson s system in
that both methods take advantage of commonalities in the graphs to assist in graph storage and matching  the probabilistic graphs contain information for identifying common
substructure in the exact graphs they represent  the portion of the probabilistic graph
with high probability defines a substructure that appears frequently in the exact graphs 
this notion was not emphasized in segen s work  but provides an alternative method to
substructure discovery by clustering subgraphs of the original input graphs  as with levinson s approach  graphs are processed incrementally  and substructure is found across several
graphs  not within a single graph as in subdue 
the labyrinth system  thompson   langley        extends the cobweb incremental
conceptual clustering system  fisher        to handle structured objects  labyrinth uses
cobweb to form hierarchical concepts of the individual objects in the domain based on
their primitive attributes  concepts of structured objects are formed in a similar manner
using the individual objects as attributes  the resulting hierarchy represents a componential
model of the structured objects  because cobweb s concepts are probabilistic  labyrinth
produces probabilistic models of the structured objects  but with an added hierarchical
organization  the upper level components of the structured object hierarchy produced by
labyrinth represent substructures common to the examples  therefore  although not the
primary focus  labyrinth is discovering substructure  but in a more constrained context
than the general graph representation used by subdue 
conklin et al   conklin   glasgow        have developed the i mem system for constructing an image hierarchy  similar to that of labyrinth  used for discovering common
substructures in a set of images and for ecient retrieval of images similar to a given image 
images are expressed in terms of a set of relations defined by the user  specific and general
 conceptual  images are stored in the hierarchy based on a subsumption relation similar
   

fisubstructure discovery
to levinson s subgraph of partial ordering  image matching utilizes a transformational
approach  similar to subdue s inexact graph match  as a measure of image closeness 
as with the approaches of segen and levinson  i mem is designed to process individual
images  therefore  the general image concepts that appear higher in i mem s hierarchy
will represent common substructures across several images  subdue is designed to discover
common substructures within a single image  subdue can mimic the individual approach
of these systems by processing a set of individual images as one disconnected graph  the
substructures found will be common to the individual images  the hierarchy also represents
a componential view of the images  this same view can be constructed by subdue using
multiple passes over the graph after replacing portions of the input graph with substructures
discovered during previous passes  i mem has performed well in a simple chess domain
and molecular chemistry domains  conklin   glasgow         however  i mem requires
domain specific relations for expressing images in order for the hierarchy to find relevant
substructures and for image matching to be ecient  again  maintaining the concepts
 images  graphs  in a partially ordered hierarchy improves the eciency of matching and
retrieval  and suggests a possible improvement to subdue 
the clip system  yoshida  motoda    indurkhya        for graph based induction is
more similar to subdue than the previous systems  clip iteratively discovers patterns in
graphs by expanding and combining patterns discovered in previous iterations  patterns
are grouped into views based on their collective ability to compress the original input
graph  during each iteration clip uses existing views to contract the input graph and
then considers adding to the views new patterns consisting of two vertices and an edge from
the contracted graph  the compression of the new proposed views is estimated  and the
best views  according to a given beam width  are retained for the next iteration 
clip discovers substructures  patterns  differently than subdue  first  clip produces
a set of substructures that collectively compress the input graph  whereas  subdue produces
only single substructures evaluated using the more principled minimum description length 
clip has the ability to grow substructures agglomeratively  i e   merging two substructures
together   whereas  subdue always produces new substructures using incremental growth
along one new edge  clip initially estimates the compression value of new views based on
the compression value of the parent view  whereas  subdue performs an expensive exact
measurement of compression for each new substructure  finally  clip employs an ecient
graph match based on graph identity  not graph isomorphism as in subdue  graph identity
assumes an ordering over the incident edges of a vertex and does not consider all possible
mappings when looking for occurrences of a pattern in an input graph  these differences
in clip suggest possible enhancements to subdue 
research in pattern recognition has begun to investigate the use of graphs and graph
grammars as an underlying representation for structural problems  schalkoff         many
results in grammatical inference are applicable to constrained classes of graphs  e g   trees 
 fu        miclet         the approach begins with a set of sample graphs and produces a
generalized graph grammar capable of deriving the original sample graphs and many others 
the production rules of this general grammar capture regularities  substructures  in the
sample graphs  jeltsch and kreowski  jeltsch   kreowski        describe an approach that
begins with a maximally specific grammar and iteratively identifies common subgraphs in
the right hand sides of the production rules  these common subgraphs are used to form
   

ficook   holder
new  more general production rules  although their method does not address the underlying
combinatorial nondeterminism  heuristic approaches could provide a feasible method for
extracting substructures in the form of graph grammars  furthermore  the graph grammar
production rule may provide a suitable representation for background knowledge during the
substructure discovery process 

   minimum description length encoding of graphs

the minimum description length principle  mdlp  introduced by rissanen  rissanen 
      states that the best theory to describe a set of data is that theory which minimizes
the description length of the entire data set  the mdl principle has been used for decision
tree induction  quinlan   rivest         image processing  pednault        pentland       
leclerc         concept learning from relational data  derthick         and learning models
of non homogeneous engineering domains  rao   lu        
we demonstrate how the minimum description length principle can be used to discover
substructures in complex data  in particular  a substructure is evaluated based on how well
it can compress the entire dataset using the minimum description length  we define the
minimum description length of a graph to be the number of bits necessary to completely
describe the graph 
according to the minimum description length  mdl  principle  the theory that best
accounts for a collection of data is the one that minimizes i  s     i  gjs    where s is the
discovered substructure  g is the input graph  i  s   is the number of bits required to encode
the discovered substructure  and i  gjs   is the number of bits required to encode the input
graph g with respect to s  
the graph connectivity can be represented by an adjacency matrix  consider a graph
that has n vertices  which are numbered              n      an n  n adjacency matrix a can
be formed with entry a i  j   set to   or    if a i  j        then there is no connection from
vertex i to vertex j   if a i  j        then there is at least one connection from vertex i to
vertex j   undirected edges are recorded in only one entry of the matrix  the adjacency
matrix for the graph in figure   is shown below 
x              
triangle                  
y                    
square                  
r              
rectangle            
the encoding of the graph consists of the following steps  we assume that the decoder
has a table of the lu unique labels in the original graph g 
   determine the number of bits vbits needed to encode the vertex labels of the graph 
first  we need  lg v   bits to encode the number of vertices v in the graph  then 
encoding the labels of all v vertices requires  v lg lu   bits  we assume the vertices are
specified in the same order they appear in the adjacency matrix  the total number
of bits to encode the vertex labels is
vbits   lg v   v lg lu
   

fisubstructure discovery

triangle

e

p
ha

s
x

on

pe

square

a
sh
y

on

pe

rectangle

a
sh
r

figure    mdl example graph 
for the example in figure    v      and we assume that there are lu     unique
labels in the original graph  the number of bits needed to encode these vertices is
lg       lg           bits 
   determine the number of bits rbits needed to encode the rows of the adjacency matrix
a  typically  in large graphs  a single vertex has edges to only a small percentage of
the vertices in the entire graph  therefore  a typical row in the adjacency matrix will
have much fewer than v  s  where v is the total number of vertices in the graph  we
apply a variant of the coding scheme used by  quinlan   rivest        to encode bit
strings with length n consisting of k  s and  n   k   s  where k   n   k   in our
case  row i     i  v   can be represented as a bit string of length v containing ki
 s  if we let b   maxi ki   then the ith row of the adjacency matrix can be encoded as
follows 
 a  encoding the value of ki requires lg b      bits 
 
 b  given that only ki  s occur in the row bit string of length v   only kvi strings
of  s and  s are
since all of these strings have equal probability of
 possible 

v
occurrence  lg ki bits are needed to encode the positions of  s in row i  the
value of v is known from the vertex encoding 
finally  we need an additional lg b      bits to encode the number of bits needed to
specify the value of ki for each row  the total encoding length in bits for the adjacency
matrix is

rbits   lg b       

v
x
i  

   v      lg b     
   

 

lg b        lg kvi
v
x
i  

 

lg kvi

ficook   holder
for the example in figure    b      and
of
the
 the number
 
 bits
 needed
  to encode

 
 
 
 
 
 
adjacency matrix is    lg    lg    lg    lg    lg    lg    lg          
bits 
   determine the number of bits ebits needed to encode the edges represented by the
entries a i  j       of the adjacency matrix a  the number of bits needed to encode
entry a i  j   is  lg m    e i  j       lg lu    where e i  j   is the actual number of edges
between vertex i and j in the graph and m   maxi j e i  j    the  lg m  bits are needed
to encode the number of edges between vertex i and j   and      lg lu   bits are needed
per edge to encode the edge label and whether the edge is directed or undirected  in
addition to encoding the edges  we need to encode the number of bits  lg m  needed
to specify the number of edges per entry  the total encoding of the edges is

ebits   lg m  

v x
v
x
i   j   

lg m   e i  j       lg lu  

  lg m   e     lg lu    

v x
v
x
i   j   

a i  j   lg m

  e     lg lu      k      lg m
where e is the number of edges in the graph  and k is the number of  s in the adjacency
matrix a  for the example in figure    e      k      m      lu      and the number
of bits needed to encode the edges is       lg        lg        
the total encoding of the graph takes  vbits   rbits   ebits  bits  for the example in
figure    this value is       bits 
both the input graph and discovered substructure can be encoded using the above
scheme  after a substructure is discovered  each instance of the substructure in the input
graph is replaced by a single vertex representing the entire substructure  the discovered
substructure is represented in i  s   bits  and the graph after the substructure replacement is
represented in i  gjs   bits  subdue searches for the substructure s in graph g minimizing
i  s     i  gjs   

   inexact graph match

although exact structure match can be used to find many interesting substructures  many
of the most interesting substructures show up in a slightly different form throughout the
data  these differences may be due to noise and distortion  or may just illustrate slight
differences between instances of the same general class of structures  consider the image
shown in figure    the pencil and the cube would make ideal substructures in the picture 
but an exact match algorithm may not consider these as strong substructures  because they
rarely occur in the same form and level of detail throughout the picture 
given an input graph and a set of defined substructures  we want to find those subgraphs
of the input graph that most closely resemble the given substructures  furthermore  we want
to associate a distance measure between a pair of graphs consisting of a given substructure
and a subgraph of the input graph  we adopt the approach to inexact graph match given
by bunke and allermann  bunke   allermann        
   

fisubstructure discovery

g 

g 

b

b

a
a

b

 

 

a

 

 
a
a

b

b
 
b

figure    two similar graphs g  and g   
in this inexact match approach  each distortion of a graph is assigned a cost  a distortion
is described in terms of basic transformations such as deletion  insertion  and substitution
of vertices and edges  the distortion costs can be determined by the user to bias the match
for or against particular types of distortions 
an inexact graph match between two graphs g  and g  maps g  to g  such that g  is
interpreted as a distorted version of g   formally  an inexact graph match is a mapping
f   n    n    fg  where n  and n  are the sets of vertices of g  and g   respectively  a
vertex v   n  that is mapped to   i e   f  v       is deleted  that is  it has no corresponding
vertex in g   given a set of particular distortion costs as discussed above  we define the cost
of an inexact graph match cost f    as the sum of the cost of the individual transformations
resulting from f   and we define matchcost g    g   as the value of the least cost function that
maps graph g  onto graph g  
given g    g   and a set of distortion costs  the actual computation of matchcost g    g  
can be determined using a tree search procedure  a state in the search tree corresponds to
a partial match that maps a subset of the vertices of g  to a subset of the vertices in g  
initially  we start with an empty mapping at the root of the search tree  expanding a state
corresponds to adding a pair of vertices  one from g  and one from g   to the partial mapping
constructed so far  a final state in the search tree is a match that maps all vertices of g  to
g  or to   the complete search tree of the example in figure   is shown in figure    for
this example we assign a value of   to each distortion cost  the numbers in circles in this
figure represent the cost of a state  as we are eventually interested in the mapping with
minimum cost  each state in the search tree gets assigned the cost of the partial mapping
that it represents  thus the goal state to be found by our tree search procedure is the
final state with minimum cost among all final states  from figure   we conclude that the
minimum cost inexact graph match of g  and g  is given by the mapping f          f         
the cost of this mapping is   
given graphs g  with n vertices and g  with m vertices  m  n  the complexity of the
full inexact graph match is o nm      because this routine is used heavily throughout the
   

ficook   holder

        

        

        

   

  

                                                                             
 

 

  

 

 

 

 

 

  

 

  

 

  

figure    search tree for computing matchcost g  g   from figure   
discovery and evaluation process  the complexity of the algorithm can significantly degrade
the performance of the system 
to improve the performance of the inexact graph match algorithm  we extend bunke s
approach by applying a branch and bound search to the tree  the cost from the root of the
tree to a given node is computed as described above  nodes are considered for pairings in
order from the most heavily connected vertex to the least connected  as this constrains the
remaining match  because branch and bound search guarantees an optimal solution  the
search ends as soon as the first complete mapping is found 
in addition  the user can place a limit on the number of search nodes considered by
the branch and bound procedure  defined as a function of the size of the input graphs  
once the number of nodes expanded in the search tree reaches the defined limit  the search
resorts to hill climbing using the cost of the mapping so far as the measure for choosing the
best node at a given level  by defining such a limit  significant speedup can be realized at
the expense of accuracy for the computed match cost 
another approach to inexact graph match would be to encode the difference between
two graphs using the mdl principle  smaller encodings would indicate a lower match cost
between the two graphs  we leave this as a future research direction 

   guiding the discovery process with background knowledge
although the principle of minimum description length is useful for discovering substructures that maximize compression of the data  scientists may realize more benefit from the
discovery of substructures that exhibit other domain specific and domain independent characteristics 
to make subdue more powerful across a wide variety of domains  we have added the
ability to guide the discovery process with background knowledge  although the minimum
description length principle still drives the discovery process  the background knowledge can
be used to input a bias toward certain types of substructures  this background knowledge
is encoded in the form of rules for evaluating substructures  and can represent domainindependent or domain dependent rules  each time a substructure is evaluated  these input
   

fisubstructure discovery
rules are used to determine the value of the substructure under consideration  because
only the most favored substructures are kept and expanded  these rules bias the discovery
process of the system 
each background rule can be assigned a positive  zero  or negative weight  that biases
the procedure toward a type of substructure  eliminates the use of the rule  or biases the
procedure away from a type of substructure  respectively  the value of a substructure is
defined as the description length  dl  of the input graph using the substructure multiplied by the weighted value of each background rule from a set of rules r applied to the
substructure 

value s    dl g  s  

jrj
y
r  

ruler  s er

   

three domain independent heuristics that have been incorporated as rules into the subdue system are compactness  connectivity  and coverage  for the definitions of these rules 

we will let g represent the input graph  s represent a substructure in the graph  and i
represent the set of instances of the substructure s in g  the instance weight w of an
instance i   i of a substructure s is defined to be
 i  s 
   
w i  s        matchcost
size i   
where size i     vertices i     edges i   if the match cost is greater than the size of the
larger graph  then w i  s       the instance weights are used in these rules to compute a
weighted average over instances of a substructure  a value of   is added to each formula so
that the exponential weights can be used to control the rule s significance 
the first rule  compactness  is a generalization of wertheimer s factor of closure  which
states that human attention is drawn to closed structures  wertheimer         a closed
substructure has at least as many edges as vertices  whereas a non closed substructure
has fewer edges than vertices  prather         thus  closed substructures have a higher
compactness value  compactness is defined as the weighted average of the ratio of the
number of edges in the substructure to the number of vertices in the substructure 

compactness s        j i j

x

i i

edges i 
w i  s     vertices
 i 

   

the second rule  connectivity  measures the amount of external connection in the instances of the substructure  the connectivity rule is a variant of wertheimer s factor
of proximity  wertheimer         and is related to earlier numerical clustering techniques
 zahn         these works demonstrate the human preference for  isolated  substructures 
that is  substructures that are minimally related to adjoining structure  connectivity measures the  isolation  of a substructure by computing the inverse of the average number of
external connections over all the weighted instances of the substructure in the input graph 
an external connection is defined here as an edge that connects a vertex in the substructure
to a vertex outside the substructure  the formula for determining the connectivity of a
substructure s with instances i in the input graph g is given below 
   

ficook   holder
 

connectivity s         

x

ji j i i w i  s   num external conns i 

   

   

the third rule  coverage  measures the fraction of structure in the input graph described
by the substructure  the coverage rule is motivated from research in inductive learning and
provides that concept descriptions describing more input examples are considered better
 michalski   stepp         although mdl measures the amount of structure  the coverage
rule includes the relevance of this savings with respect to the size of the entire input graph 
coverage is defined as the number of unique vertices and edges in the instances of the
substructure divided by the total number of vertices and edges in the input graph  in this
formula  the unique structure i  of an instance i is the number of vertices and edges in i
that have not already appeared in previous instances in the summation 

coverage s       

p
i i w i  s   unique

size g 

structure i 

   

domain dependent rules can also be used to guide the discovery process in a domain
where scientists can contribute their expertise  for example  cad circuits generally consist
of two types of components  active and passive components  the active components are
the main driving components  identifying the active components is the first step in understanding the main function of the circuit  to add this knowledge to subdue we include
a rule that assigns higher values to substructures  circuit components  representing active
components and lower values to substructures representing passive components  since the
active components have higher scores  they are expected to be selected  the system can
then focus the attention on the active components which will be expanded to the functional
substructures 
another method of biasing the discovery process with background knowledge is to let
background rules affect the prior probabilities of possible substructures  however  choosing
the appropriate prior probabilities to express desired properties of substructures is dicult  but indicates a future direction for the inclusion of background knowledge into the
substructure discovery process 

   experiments
the experiments in this section evaluate subdue s substructure discovery capability in
several domains  including chemical compound analysis  scene analysis  cad circuit design
analysis  and analysis of an artificially generated structural database 
two goals of our substructure discovery system are to find substructures that can reduce
the amount of information needed to describe the data  and to find substructures that are
considered interesting for the given database  as a result  we evaluate the subdue system
in this section along these two criteria  first  we measure the amount of compression that
subdue provides across a variety of databases  second  we use the subdue system with the
additional background knowledge rules to re discover substructures that have been identified
as interesting by experts in each specific domain  section     describes the domains used
in these experiments  and section     presents the experimental results 
   

fisubstructure discovery

ch  oh

o
ch  

ch  

o

c

o
oh

figure    cortisone 
ch  
c
ch
 

ch  

h

c

c
ch

 

ch

ch

 
c

ch  

 

ch  

h

c

c
ch

ch

 

 

ch

ch

 

 

c

c
ch  

h

h

ch

 

c
ch

 

c
h

figure    natural rubber  all cis polyisoprene  

    domains
      chemical compound analysis

chemical compounds are rich in structure  identification of the common and interesting
substructures can benefit scientists by identifying recurring components  simplying the data
description  and focusing on substructures that stand out and merit additional attention 
chemical compounds are represented graphically by mapping individual atoms  such as
carbon and oxygen  to labeled vertices in the graph  and by mapping bonds between the
atoms onto labeled edges in the graph  figures       and   show the graphs representing
the chemical compound databases for cortisone  rubber  and a portion of a dna molecule 
      scene analysis

images and scene descriptions provide a rich source of structure  images that humans
encounter  both natural and synthesized  have many structured subcomponents that draw
our attention and that help us to interpret the data or the scene 
discovering common structures in scenes can be useful to a computer vision system 
first  automatic substructure discovery can help a system interpret an image  instead of
working from low level vertices and edges  subdue can provide more abstract structured
components  resulting in a hierarchical view of the image that the machine can analyze at
many levels of detail and focus  depending on the goal of the analysis  second  substructure
discovery that makes use of an inexact graph match can help identify objects in a  d image
of a  d scene where noise and orientation differences are likely to exist  if an object appears often in the scene  the inexact graph match driving the subdue system may capture
slightly different views of the same object  although an object may be dicult to identify
   

ficook   holder

o
ch  o
n

adenine

n
n

n
o

o

n

p

o

o
h
n

oh

o

n

ch  

o

h
p

ho

o
n

h

n

h

o

n

guanine
n
o
p

o

o

ch  o

o

thymine

ch 

o

h

n

n

o

o

n
h

oh

n

cytosine

ch 
ch  

o

h

p

ho

o

o

o
o

ch  o
n

thymine
p

n

h

n

o

n

o
o

n
n

ch  

o

h

oh

ch 

adenine

n
h

o
p

ho

o
o

figure    portion of a dna molecule 

figure    scene analysis example 
   

o

fisubstructure discovery

f

a

k

x

l

t

p

m

figure     possible vertices and labels 

l

l
l

l

l

l

l

l

t

l

l
t
t
t

l

t
m

t
t
a
l

l

l

l

l

l

l
t

t

l

a

l

a

f
l

l

a

figure     portion of graph representing scene in figure   
from just one  d picture  subdue will match instances of similar objects  and the differences between these instances can provide additional information for identification  third 
substructure discovery can be used to compress the image  replacing common interesting
substructures by a single vertex simplifies the image description and reduces the amount of
storage necessary to represent the image 
to apply subdue to image data  we extract edge information from the image and
construct a graph representing the scene  the graph representation consists of eight types
of vertices and two types of arcs  edge and space   the vertex labels  f   a  l  t  k  x  p  and
m  follow the waltz labelings  waltz        of junctions of edges in the image and represent
the types of vertices shown in figure     an edge arc represents the edge of an object in the
image  and a space arc links non connecting objects together  the edge arcs represent an
edge in the scene that connects two vertices  and the space arcs connect the closest vertices
from two disjoint neighboring objects  distance  curve  and angle information has not been
included in the graph representation  but can be added to give additional information about
the scene  figure    shows the graph representation of a portion of the scene depicted in
figure    in this figure  the edge arcs are solid and the space arcs are dashed 
   

ficook   holder

vcc

ext pin

drain
drain
gate
n mosfet

gate
source

source
connect

drain

drain
gate
connect

gate

n mosfet

source

ext pin

gnd

figure     amplifier circuit and graph representation 
      cad circuit analysis

in this domain  we employ subdue to find circuit components in cad circuit data  discovery of substructures in circuit data can be a valuable tool to an engineer who is attempting to
identify common reusable parts in a circuit layout  replacing individual components in the
circuit description by larger substructure descriptions will also simplify the representation
of the circuit 
the data for the circuit domain was obtained from national semiconductor  and consists of a set of components making up a circuit as output by the cadence design system 
the particular circuit used for this experiment is a portion of an analog to digital converter  figure    presents a circuit for an amplifier and gives the corresponding graph
representation 
      artificial domain

in the final domain  we artificially generate graphs to evaluate subdue s ability to discover
substructures capable of compressing the graph  four substructures are created of varying
sizes with randomly selected vertices and edges  see figure      the name of a substructure
reects the number of vertices and edges in its graph representation  next  these substructures are embedded in larger graphs whose size is    times the size of the substructure 
the graphs vary across four parameters  number of possible vertex and edge labels  one
times and two times the number of labels used in the substructure   connectivity of the
substructure    or   external connections   coverage of the instances      and       and
   

fisubstructure discovery

e 
e 

e 

n 

n 

e 
n 

e 

n 

n 

n 
e 

n 

e 
e 
n 

e 
n 

e 
n 

e 
n 

e 

e 

n 

n 

n 

n 

e 

e 
e 
n 

e 
n 

n 

e 

e 
n 

n 

e 
n 

n 

e 

e 
e 
e 

figure     four artificial substructures used to evaluate subdue 

the amount of distortion in the instances       or   distortions   this yields a total of   
graphs     for each different substructure  

    experimental results
      experiment    data compression

in the first experiment  we test subdue s ability to compress a structural database  using
a beam width of   and subdue s pruning mechanism  we applied the discovery algorithm to
each of the databases mentioned above  we repeat the experiment with match thresholds
ranging from     to     in increments of      table   shows the description length  dl  of the
original graph  the description length of the best substructure discovered by subdue  and
graph
the value of compression  compression here is defined as dldlofofcompressed
original graph   figure    
shows the actual discovered substructures for the first four datasets 
as can be seen from table    subdue was able to reduce the database to slightly
larger than    of its original size in the best case  the average compression value over
all of these domains  treating the artificial graphs as one value  is       the results of
this experiment demonstrate that the substructure discovered by subdue can significantly
reduce the amount of data needed to represent an input graph  we expect that compressing
the graph using combinations of substructures and hierarchies of substructures will realize
even greater compression in some databases 
   

ficook   holder

database
dloriginal thresholdoptimal dlcompressed compression
rubber
      
   
     
    
cortisone
      
   
      
    
dna
       
   
       
    
pencils
       
   
      
    
cad   m 
       
   
      
    
cad   s segdec
       
   
       
    
cad   s drvblk
        
   
       
    
cad   blanksub
       
   
       
    
cad   and 
      
   
      
    
artificial  avg  over    graphs         
           
       
    
table    graph compression results 

ch  

h

ch 

o

a

o

c
c

c

c

c

ch

ch
 

 

 a 

c

c

 b 

c
l

o

 c 

a

 d 

figure     best substructure for  a  rubber database   b  cortisone database   c  dna
database  and  d  image database 

   

fisubstructure discovery

figure     benzene ring discovered by subdue 
      experiment    re discovery of known substructures using background
knowledge

another way of evaluating the discovery process is to evaluate the interestingness of the
discovered substructures  the determination of this value will change from domain to
domain  as a result  in this second set of experiments we test subdue s ability to discover
substructures that have already been labeled as important by experts in the domains under
consideration 
in the chemical compound domain  chemists frequently describe compounds in terms of
the building block components that are heavily used  for example  in the rubber compound
database shown in figure    the compound is made up of a chain of structures that are
labeled by chemists as isoprene units  subdue s ability to re discover this structure is
exemplified in figure   a  this substructure  which was discovered using the mdl principle
with no extra background knowledge  represents an isoprene unit 
although subdue was able to re discover isoprene units without extra background
knowledge  the substructure affording the most compression will not always be the most interesting or important substructure in the database  for example  in the cortisone database
the benzene ring which consists of a ring of carbons is not discovered using only the mdl
principle  however  the additional background rules can be used to increase the chance of
finding interesting substructures in these domains  in the case of the cortisone compound 
we know that the interesting structures exhibit a characteristic of closure  therefore  we
give a strong weight       to the compactness background rule and use a match threshold of
    to allow for deviations in the benzene ring instances  in the resulting output  subdue
finds the benzene ring shown in figure    
in the same way  we can use the background rules to find the pencil substructure in
the image data  when the image in figure   is viewed  the substructure of interest is the
pencil in its various forms  however  the substructure that afforded the most compression
does not make up an entire pencil  we know that the pencils have a high degree of closure
and of coverage  so the weights for these rules are set to      with these weights  subdue
is able to find the pencil substructure shown in figure    for all tested match thresholds
between     and     

   hierarchical concept discovery

after a substructure is discovered  each instance of the substructure in the input graph can
be replaced by a single vertex representing the entire substructure  the discovery procedure
can then be repeated on the compressed data set  resulting in new interesting substructures 
if the newly discovered substructures are defined in terms of existing substructure concepts 
the substructure definitions form a hierarchy of substructure concepts 
   

ficook   holder

l

l

a

a
l

figure     pencil substructure discovered by subdue 

hierarchical concept discovery also adds the capability to improve subdue s performance  when subdue is applied to a large input graph  the complexity of the algorithm
prevents consideration of larger substructures  using hierarchical concept discovery  subdue can first discover those smaller substructures which best compress the data  applying
the compression reduces the graph to a more manageable size  increasing the chance that
subdue will find the larger substructures on the subsequent passes through the database 
once subdue selects a substructure  all vertices that comprise the exact instances of
the substructure are replaced in the graph by a single vertex representing the discovered
substructure  edges connecting vertices outside the instance to vertices inside the instance
now connect to the new vertex  edges internal to the instance are removed  the discovery
process is then applied to the compressed data  if a hierarchical description of concepts is
particularly desired  heavier weight can be given to substructures which utilize previously
discovered substructures  the increased weight reects increased attention to this substructure  figure    illustrates the compressed rubber compound graph using the substructure
shown in figure   a 
to demonstrate the ability of subdue to find a hierarchy of substructures  we let the system make multiple passes through a database that represents a portion of a dna molecule 
figure   shows a portion of two chains of a double helix  using three pairs of bases which
are held together by hydrogen bonds  figure    shows the substructures found by subdue
after each of three passes through the data  note that  on the third pass  subdue linked
together the instances of the substructure in the second pass to find the chains of the double
helix 
although replacing portions of the input graph with the discovered substructures compresses the data and provides a basis for discovering hierarchical concepts in the data  the
substructure replacement procedure becomes more complicated when concepts with inexact
instances are discovered  when inexact instances of a discovered concept are replaced by
a single vertex in the data  all distortions of the graph  differences between the instance
graph and the substructure definition  must be attached as annotations to the vertex label 
   

fisubstructure discovery

highest valued substructure

ch  

h

s  
 

c

c
ch

ch

 

 

compressed graph using discovered substructure

g

s 

 

ch

ch

c
 

c
 

ch

ch

 

 
c

ch  

ch

h

 

c
ch

s 

s 

ch

h

 

 

s 

s
 

c

c
ch

ch

 

 

ch

ch

 

 

c

c
ch  

h

h

 

ch

 

c
h

figure     compressed graph for rubber compound data 

   

c
ch

 

ficook   holder

highest valued substructure
after first pass

ch  o

s   

o
o

highest valued substructure
after second pass

s 

c

ch  o

o

s   

 
o

p
p

o
ch  o

highest valued substructure
after third pass

o
o
o

s 

p

oh

oh
o

 

s   

ch  o

o

s 

oh

o

s 

oh

o
o

p

o

oh
o
ch  o

o
o

p

oh
o

figure     hierarchical discovery in dna data 

   

fisubstructure discovery

   conclusions

extracting knowledge from structural databases requires the identification of repetitive substructures in the data  substructure discovery identifies interesting and repetitive structure
in structural data  the substructures represent concepts found in the data and a means of
reducing the complexity of the representation by abstracting over instances of the substructure  we have shown how the minimum description length  mdl  principle can be used to
perform substructure discovery in a variety of domains  the substructure discovery process
can also be guided by background knowledge  the use of an inexact graph match allows
deviation in the instances of a substructure  once a substructure is discovered  instances
of the substructure can be replaced by the concept definition  affording compression of the
data description and providing a basis for discovering hierarchically defined structures 
future work will combine structural discovery with discovery of concepts using a linearbased representation such as autoclass  cheeseman  kelly  self  stutz  taylor    freeman 
       in particular  we will use subdue to compress the data fed to autoclass  and
let subdue evaluate the interesting structures in the classes generated by autoclass  in
addition  we will be developing a parallel implementation of the autoclass   subdue
system that will enable application of substructure discovery to larger structural databases 

acknowledgements

this project is supported by nasa grant nas         the authors would like to thank
mike shay at national semiconductor for providing the circuit data  we would also like
to thank surnjani djoko and tom lai for their help with this project  thanks also to the
reviewers for their numerous insightful comments 

references

bunke  h     allermann  g          inexact graph matching for structural pattern recognition  pattern recognition letters                 
cheeseman  p   kelly  j   self  m   stutz  j   taylor  w     freeman  d          autoclass 
a bayesian classification system  in proceedings of the fifth international workshop
on machine learning  pp        
conklin  d     glasgow  j          spatial analogy and subsumption  in proceedings of the
ninth international machine learning workshop  pp          
derthick  m          a minimal encoding approach to feature discovery  in proceedings of
the ninth national conference on artificial intelligence  pp          
fisher  d  h          knowledge acquisition via incremental conceptual clustering  machine
learning                 
fu  k  s          syntactic pattern recognition and applications  prentice hall 
holder  l  b   cook  d  j     bunke  h          fuzzy substructure discovery  in proceedings
of the ninth international machine learning conference  pp          
   

ficook   holder
holder  l  b     cook  d  j          discovery of inexact concepts from structural data 
ieee transactions on knowledge and data engineering                 
jeltsch  e     kreowski  h  j          grammatical inference based on hyperedge replacement  in fourth international workshop on graph grammars and their application
to computer science  pp          
leclerc  y  g          constructing simple stable descriptions for image partitioning  international journal of computer vision                
levinson  r          a self organizing retrieval system for graphs  in proceedings of the
second national conference on artificial intelligence  pp          
michalski  r  s     stepp  r  e          learning from observation  conceptual clustering 
in michalski  r  s   carbonell  j  g     mitchell  t  m   eds    machine learning 
an artificial intelligence approach  vol  i  pp           tioga publishing company 
miclet  l          structural methods in pattern recognition  chapman and hall 
pednault  e  p  d          some experiments in applying inductive inference principles
to surfa ce reconstruction  in proceedings of the international joint conference on
artificial intelligence  pp            
pentland  a          part segmentation for object recognition  neural computation    
      
prather  r          discrete mathemetical structures for computer science  houghton
min company 
quinlan  j  r     rivest  r  l          inferring decision trees using the minimum description length principle  information and computation              
rao  r  b     lu  s  c          learning engineering models with the minimum description length principle  in proceedings of the tenth national conference on artificial
intelligence  pp          
rissanen  j          stochastic complexity in statistical inquiry  world scientific publishing
company 
schalkoff  r  j          pattern recognition  statistical  structural and neural approaches 
john wiley   sons 
segen  j          graph clustering and model learning by data compression  in proceedings
of the seventh international machine learning workshop  pp         
thompson  k     langley  p          concept formation in structured domains  in fisher 
d  h     pazzani  m   eds    concept formation  knowledge and experience in unsupervised learning  chap     morgan kaufmann publishers  inc 
waltz  d          understanding line drawings of scenes with shadows  in winston  p  h 
 ed    the psychology of computer vision  mcgraw hill 
   

fisubstructure discovery
wertheimer  m          laws of organization in perceptual forms  in ellis  w  d   ed    a
sourcebook of gestalt psychology  pp           harcourt  brace and company 
winston  p  h          learning structural descriptions from examples  in winston  p  h 
 ed    the psychology of computer vision  pp           mcgraw hill 
yoshida  k   motoda  h     indurkhya  n          unifying learning methods by colored
digraphs  in proceedings of the learning and knowledge acquisition workshop at
ijcai    
zahn  c  t          graph theoretical methods for detecting and describing gestalt clusters 
ieee transactions on computers                

   

fi