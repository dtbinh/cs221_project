journal of artificial intelligence research               

submitted       published     

dynamic backtracking
matthew l  ginsberg

ginsberg cs uoregon edu

cirl  university of oregon 
eugene  or            usa

abstract

because of their occasional need to return to shallow points in a search tree  existing
backtracking methods can sometimes erase meaningful progress toward solving a search
problem  in this paper  we present a method by which backtrack points can be moved
deeper in the search space  thereby avoiding this diculty  the technique developed is
a variant of dependency directed backtracking that uses only polynomial space while still
providing useful control information and retaining the completeness guarantees provided
by earlier approaches 

   introduction
imagine that you are trying to solve some constraint satisfaction problem  or csp  in the
interests of definiteness  i will suppose that the csp in question involves coloring a map of
the united states subject to the restriction that adjacent states be colored differently 
imagine we begin by coloring the states along the mississippi  thereby splitting the
remaining problem in two  we now begin to color the states in the western half of the
country  coloring perhaps half a dozen of them before deciding that we are likely to be able
to color the rest  suppose also that the last state colored was arizona 
at this point  we change our focus to the eastern half of the country  after all  if we can t
color the eastern half because of our coloring choices for the states along the mississippi 
there is no point in wasting time completing the coloring of the western states 
we successfully color the eastern states and then return to the west  unfortunately  we
color new mexico and utah and then get stuck  unable to color  say  nevada  what s more 
backtracking doesn t help  at least in the sense that changing the colors for new mexico
and utah alone does not allow us to proceed farther  depth first search would now have
us backtrack to the eastern states  trying a new color for  say  new york in the vain hope
that this would solve our problems out west 
this is obviously pointless  the blockade along the mississippi makes it impossible for
new york to have any impact on our attempt to color nevada or other western states 
what s more  we are likely to examine every possible coloring of the eastern states before
addressing the problem that is actually the source of our diculties 
the solutions that have been proposed to this involve finding ways to backtrack directly
to some state that might actually allow us to make progress  in this case arizona or earlier 
dependency directed backtracking  stallman   sussman        involves a direct backtrack
to the source of the diculty  backjumping  gaschnig        avoids the computational overhead of this technique by using syntactic methods to estimate the point to which backtrack
is necessary 

c      ai access foundation and morgan kaufmann publishers  all rights reserved 

figinsberg

in both cases  however  note that although we backtrack to the source of the problem 
we backtrack over our successful solution to half of the original problem  discarding our
solution to the problem of coloring the states in the east  and once again  the problem is
worse than this   after we recolor arizona  we are in danger of solving the east yet again
before realizing that our new choice for arizona needs to be changed after all  we won t
examine every possible coloring of the eastern states  but we are in danger of rediscovering
our successful coloring an exponential number of times 
this hardly seems sensible  a human problem solver working on this problem would
simply ignore the east if possible  returning directly to arizona and proceeding  only if the
states along the mississippi needed new colors would the east be reconsidered   and even
then only if no new coloring could be found for the mississippi that was consistent with the
eastern solution 
in this paper we formalize this technique  presenting a modification to conventional
search techniques that is capable of backtracking not only to the most recently expanded
node  but also directly to a node elsewhere in the search tree  because of the dynamic way
in which the search is structured  we refer to this technique as dynamic backtracking 
a more specific outline is as follows  we begin in the next section by introducing a
variety of notational conventions that allow us to cast both existing work and our new
ideas in a uniform computational setting  section   discusses backjumping  an intermediate
between simple chronological backtracking and our ideas  which are themselves presented
in section    an example of the dynamic backtracking algorithm in use appears in section
  and an experimental analysis of the technique in section    a summary of our results and
suggestions for future work are in section    all proofs have been deferred to an appendix
in the interests of continuity of exposition 

   preliminaries
definition     by a constraint satisfaction problem  i  v    we will mean a set i of vari 

ables  for each i   i   there is a set vi of possible values for the variable i   is a set of
constraints  each a pair  j  p   where j    j           jk   is an ordered subset of i and p is a
subset of vj       vjk  
a solution to the csp is a set vi of values for each of the variables in i such that vi   vi
for each i and for every constraint  j  p   of the above form in    vj            vjk     p  

in the example of the introduction  i is the set of states and vi is the set of possible
colors for the state i  for each constraint  the first part of the constraint is a pair of adjacent
states and the second part is a set of allowable color combinations for these states 
our basic plan in this paper is to present formal versions of the search algorithms
described in the introduction  beginning with simple depth first search and proceeding to
backjumping and dynamic backtracking  as a start  we make the following definition of a
partial solution to a csp 

definition     let  i  v    be a csp  by a partial solution to the csp we mean an ordered
subset j  i and an assignment of a value to each variable in j  
  

fidynamic backtracking

we will denote a partial solution by a tuple of ordered pairs  where each ordered pair

 i  v   assigns the value v to the variable i  for a partial solution p   we will denote by p the
set of variables assigned values by p  

constraint satisfaction problems are solved in practice by taking partial solutions and
extending them by assigning values to new variables  in general  of course  not any value can
be assigned to a variable because some are inconsistent with the constraints  we therefore
make the following definition 

definition     given a partial solution p to a

csp  an eliminating explanation for a
variable i is a pair  v  s   where v   vi and s  p   the intended meaning is that i
cannot take the value v because of the values already assigned by p to the variables in s  
an elimination mechanism  for a csp is a function that accepts as arguments a partial
solution p   and a variable i    p   the function returns a  possibly empty  set  p  i  of
eliminating explanations for i 

for a set e of eliminating explanations  we will denote by eb the values that have been
identified as eliminated  ignoring the reasons given  we therefore denote by b p  i  the set
of values eliminated by elements of  p  i  
note that the above definition is somewhat exible with regard to the amount of work
done by the elimination mechanism   all values that violate completed constraints might
be eliminated  or some amount of lookahead might be done  we will  however  make the
following assumptions about all elimination mechanisms 
   they are correct  for a partial solution p   if the value vi    b p  i   then every
constraint  s  t   in  with s  p  fig is satisfied by the values in the partial solution
and the value vi for i  these are the constraints that are complete after the value vi
is assigned to i 
   they are complete  suppose that p is a partial solution to a csp  and there is some
solution that extends p while assigning the value v to i  if p   is an extension of p
with  v  e      p     i   then
e    p     p      
   
in other words  whenever p can be successfully extended after assigning v to i but
p   cannot be  at least one element of p     p is identified as a possible reason for the
problem 
   they are concise  for a partial solution p   variable i and eliminated value v   there
is at most a single element of the form  v  e      p  i   only one reason is given why
the variable i cannot have the value v  

lemma     let  be a complete elimination mechanism for a csp  let p be a partial solution to this csp and let i    p   now if p can be successfully extended to a complete solution
after assigning i the value v   then v    b p  i  
i apologize for the swarm of definitions  but they allow us to give a clean description of
depth first search 
  

figinsberg

algorithm      depth first search  given as inputs a constraint satisfaction problem

and an elimination mechanism  
   set p     p is a partial solution to the csp  set ei    for each i   i   ei is the
set of values that have been eliminated for the variable i 
   if p   i   so that p assigns a value to every element in i   it is a solution to the
original problem  return it  otherwise  select a variable i   i   p   set ei   b p  i  
the values that have been eliminated as possible choices for i 
   set s   vi   ei  the set of remaining possibilities for i  if s is nonempty  choose an
element v   s   add  i  v   to p   thereby setting i s value to v   and return to step   
   if s is empty  let  j  vj   be the last entry in p   if there is no such entry  return failure 
remove  j  vj   from p   add vj to ej   set i   j and return to step   

we have written the algorithm so that it returns a single answer to the csp  the modification to accumulate all such answers is straightforward 
the problem with algorithm     is that it looks very little like conventional depth first
search  since instead of recording the unexpanded children of any particular node  we are
keeping track of the failed siblings of that node  but we have the following 

lemma     at any point in the execution of algorithm      if the last element of the partial
solution p assigns a value to the variable i  then the unexplored siblings of the current node
are those that assign to i the values in vi   ei  
proposition     algorithm     is equivalent to depth first search and therefore complete 

as we have remarked  the basic difference between algorithm     and a more conventional description of depth first search is the inclusion of the elimination sets ei  the
conventional description expects nodes to include pointers back to their parents  the siblings of a given node are found by examining the children of that node s parent  since we
will be reorganizing the space as we search  this is impractical in our framework 
it might seem that a more natural solution to this diculty would be to record not the
values that have been eliminated for a variable i  but those that remain to be considered 
the technical reason that we have not done this is that it is much easier to maintain
elimination information as the search progresses  to understand this at an intuitive level 
note that when the search backtracks  the conclusion that has implicitly been drawn is
that a particular node fails to expand to a solution  as opposed to a conclusion about the
currently unexplored portion of the search space  it should be little surprise that the most
ecient way to manipulate this information is by recording it in approximately this form 

   backjumping

how are we to describe dependency directed backtracking or backjumping in this setting 
in these cases  we have a partial solution and have been forced to backtrack  these more
sophisticated backtracking mechanisms use information about the reason for the failure to
identify backtrack points that might allow the problem to be addressed  as a start  we need
to modify algorithm     to maintain the explanations for the eliminated values 
  

fidynamic backtracking

algorithm     given as inputs a constraint satisfaction problem and an elimination mechanism  
   set p   ei    for each i   i   ei is a set of eliminating explanations for i 
   if p   i   return p   otherwise  select a variable i   i   p   set ei    p  i  
   set s   vi   ebi  if s is nonempty  choose an element v   s   add  i  v   to p and
return to step   
   if s is empty  let  j  vj   be the last entry in p   if there is no such entry  return failure 
remove  j  vj   from p   we must have ebi   vi  so that every value for i has been
eliminated  let e be the set of all variables appearing in the explanations for each
eliminated value  add  vj   e   fj g  to ej   set i   j and return to step   

lemma     let p be a partial solution obtained during the execution of algorithm     

and let i   p be a variable assigned a value by p   now if p    p can be successfully
extended to a complete solution after assigning i the value v but  v  e     ei   we must have

e    p   p       

in other words  the assignment of a value to some variable in p   p   is correctly identified
as the source of the problem 
note that in step   of the algorithm  we could have added  vj   e   p   instead of  vj   e  
fj g  to ej   either way  the idea is to remove from e any variables that are no longer assigned
values by p  
in backjumping  we now simply change our backtrack method  instead of removing a
single entry from p and returning to the variable assigned a value prior to the problematic
variable i  we return to a variable that has actually had an impact on i  in other words  we
return to some variable in the set e  

algorithm      backjumping  given as inputs a constraint satisfaction problem and an
elimination mechanism  
   set p   ei    for each i   i  

   if p   i   return p   otherwise  select a variable i   i   p   set ei    p  i  
   set s   vi   ebi  if s is nonempty  choose an element v   s   add  i  v   to p and
return to step   
   if s is empty  we must have ebi   vi   let e be the set of all variables appearing in
the explanations for each eliminated value 
   if e     return failure  otherwise  let  j  vj   be the last entry in p such that j   e  
remove from p this entry and any entry following it  add  vj   e   p   to ej   set i   j
and return to step   
  

figinsberg

in step    we add  vj   e   p   to ej   removing from e any variables that are no longer
assigned values by p  

proposition     backjumping is complete and always expands fewer nodes than does depthfirst search 

let us have a look at this in our map coloring example  if we have a partial coloring
p and are looking at a specific state i  suppose that we denote by c the set of colors that
are obviously illegal for i because they conict with a color already assigned to one of i s
neighbors 
one possible elimination mechanism returns as  p  i  a list of  c  p   for each color
c   c that has been used to color a neighbor of i  this reproduces depth first search  since
we gradually try all possible colors but have no idea what went wrong when we need to
backtrack since every colored state is included in p   a far more sensible choice would take
 p  i  to be a list of  c  fng  where n is a neighbor that is already colored c  this would
ensure that we backjump to a neighbor of i if no coloring for i can be found 
if this causes us to backjump to another state j   we will add i s neighbors to the eliminating explanation for j  s original color  so that if we need to backtrack still further  we
consider neighbors of either i or j   this is as it should be  since changing the color of one of
i s other neighbors might allow us to solve the coloring problem by reverting to our original
choice of color for the state j  
we also have 

proposition     the amount of space needed by backjumping is o i v   where i   ji j is

the number of variables in the problem and v is the number of values for that variable with
the largest value set vi  

this result contrasts sharply with an approach to csps that relies on truth maintenance
techniques to maintain a list of nogoods  de kleer         there  the number of nogoods
found can grow linearly with the time taken for the analysis  and this will typically be
exponential in the size of the problem  backjumping avoids this problem by resetting the
set ei of eliminating explanations in step   of algorithm     
the description that we have given is quite similar to that developed in  bruynooghe 
       the explanations there are somewhat coarser than ours  listing all of the variables
that have been involved in any eliminating explanation for a particular variable in the csp 
but the idea is essentially the same  bruynooghe s eliminating explanations can be stored
in o i   space  instead of o i v     but the associated loss of information makes the technique
less effective in practice  this earlier work is also a description of backjumping only  since
intermediate information is erased as the search proceeds 

   dynamic backtracking

we finally turn to new results  the basic problem with algorithm     is not that it backjumps to the wrong place  but that it needlessly erases a great deal of the work that has
been done thus far  at the very least  we can retain the values selected for variables that
are backjumped over  in some sense moving the backjump variable to the end of the partial
  

fidynamic backtracking

solution in order to replace its value without modifying the values of the variables that
followed it 
there is an additional modification that will probably be clearest if we return to the
example of the introduction  suppose that in this example  we color only some of the eastern
states before returning to the western half of the country  we reorder the variables in order
to backtrack to arizona and eventually succeed in coloring the west without disturbing the
colors used in the east 
unfortunately  when we return east backtracking is required and we find ourselves
needing to change the coloring on some of the eastern states with which we dealt earlier 
the ideas that we have presented will allow us to avoid erasing our solution to the problems
out west  but if the search through the eastern states is to be ecient  we will need to
retain the information we have about the portion of the east s search space that has been
eliminated  after all  if we have determined that new york cannot be colored yellow  our
changes in the west will not reverse this conclusion   the mississippi really does isolate one
section of the country from the other 
the machinery needed to capture this sort of reasoning is already in place  when we
backjump over a variable k  we should retain not only the choice of value for k  but also k s
elimination set  we do  however  need to remove from this elimination set any entry that
involves the eventual backtrack variable j   since these entries are no longer valid   they
depend on the assumption that j takes its old value  and this assumption is now false 

algorithm      dynamic backtracking i  given as inputs a constraint satisfaction problem and an elimination mechanism  
   set p   ei    for each i   i  
   if p   i   return p   otherwise  select a variable i   i   p   set ei   ei    p  i  
   set s   vi   ebi  if s is nonempty  choose an element v   s   add  i  v   to p and
return to step   
   if s is empty  we must have ebi   vi   let e be the set of all variables appearing in the
explanations for each eliminated value 
   if e     return failure  otherwise  let  j  vj   be the last entry in p such that j   e  
remove  j  vj   from p and  for each variable k assigned a value after j   remove from
ek any eliminating explanation that involves j   set

ej   ej    p  j     f vj   e   p  g
   
so that vj is eliminated as a value for j because of the values taken by variables in
e   p   the inclusion of the term  p  j   incorporates new information from variables
that have been assigned values since the original assignment of vj to j   now set i   j
and return to step   

theorem     dynamic backtracking always terminates and is complete  it continues to

satisfy proposition     and can be expected to expand fewer nodes than backjumping provided
that the goal nodes are distributed randomly in the search space 
  

figinsberg

the essential difference between dynamic and dependency directed backtracking is that
the structure of our eliminating explanations means that we only save nogood information
based on the current values of assigned variables  if a nogood depends on outdated information  we drop it  by doing this  we avoid the need to retain an exponential amount of
nogood information  what makes this technique valuable is that  as stated in the theorem 
termination is still guaranteed 
there is one trivial modification that we can make to algorithm     that is quite useful
in practice  after removing the current value for the backtrack variable j   algorithm    
immediately replaces it with another  but there is no real reason to do this  we could
instead pick a value for an entirely different variable 

algorithm      dynamic backtracking  given as inputs a constraint satisfaction problem and an elimination mechanism  
   set p   ei    for each i   i  
   if p   i   return p   otherwise  select a variable i   i   p   set ei   ei    p  i  
   set s   vi   ebi  if s is nonempty  choose an element v   s   add  i  v   to p and
return to step   
   if s is empty  we must have ebi   vi   let e be the set of all variables appearing in the
explanations for each eliminated value 
   if e     return failure  otherwise  let  j  vj   be the last entry in p that binds a
variable appearing in e   remove  j  vj   from p and  for each variable k assigned
a value after j   remove from ek any eliminating explanation that involves j   add
 vj   e   p   to ej and return to step   

   an example
in order to make algorithm     a bit clearer  suppose that we consider a small mapcoloring problem in detail  the map is shown in figure   and consists of five countries 
albania  bulgaria  czechoslovakia  denmark and england  we will assume  wrongly   that
the countries border each other as shown in the figure  where countries are denoted by nodes
and border one another if and only if there is an arc connecting them 
in coloring the map  we can use the three colors red  yellow and blue  we will typically
abbreviate the country names to single letters in the obvious way 
we begin our search with albania  deciding  say  to color it red  when we now look at
bulgaria  no colors are eliminated because albania and bulgaria do not share a border  we
decide to color bulgaria yellow   this is a mistake  
we now go on to consider czechoslovakia  since it borders albania  the color red is
eliminated  we decide to color czechoslovakia blue and the situation is now this 
  

fidynamic backtracking

denmark
s

s

czechoslovakia

    
 
  
 
 
 
 
  
 
albanias 
  sbulgaria
  
 
 
  
 
 
 
 
    
  s
england

figure    a small map coloring problem
country
color red yellow blue
albania
red
bulgaria
yellow
czechoslovakia blue a
denmark
england
for each country  we indicate its current color and the eliminating explanations that mean
it cannot be colored each of the three colors  when such explanations exist   we now look
at denmark 
denmark cannot be colored red because of its border with albania and cannot be colored
yellow because of its border with bulgaria  it must therefore be colored blue  but now
england cannot be colored any color at all because of its borders with albania  bulgaria
and denmark  and we therefore need to backtrack to one of these three countries  at this
point  the elimination lists are as follows 
country
color red yellow blue
albania
red
bulgaria
yellow
czechoslovakia blue a
denmark
blue a
b
england
a
b
d
we backtrack to denmark because it is the most recent of the three possibilities  and
begin by removing any eliminating explanation involving denmark from the above table to
get 
  

figinsberg

color red yellow blue
country
albania
red
bulgaria
yellow
czechoslovakia blue a
denmark
a
b
england
a
b
next  we add to denmark s elimination list the pair
 blue  fa  b g 
this indicates correctly that because of the current colors for albania and bulgaria  denmark cannot be colored blue  because of the subsequent dead end at england   since every
color is now eliminated  we must backtrack to a country in the set fa  b g  changing
czechoslovakia s color won t help and we must deal with bulgaria instead  the elimination
lists are now 
country
color red yellow blue
albania
red
bulgaria
czechoslovakia blue a
denmark
a
b a b
england
a
b
we remove the eliminating explanations involving bulgaria and also add to bulgaria s elimination list the pair
 yellow  a 
indicating correctly that bulgaria cannot be colored yellow because of the current choice of
color for albania  red  
the situation is now 
color red yellow blue
country
albania
red
czechoslovakia blue a
bulgaria
a
denmark
a
england
a
we have moved bulgaria past czechoslovakia to reect the search reordering in the algorithm  we can now complete the problem by coloring bulgaria red  denmark either yellow
or blue  and england the color not used for denmark 
this example is almost trivially simple  of course  the thing to note is that when we
changed the color for bulgaria  we retained both the blue color for czechoslovakia and the
information indicating that none of czechoslovakia  denmark and england could be red 
in more complex examples  this information may be very hard won and retaining it may
save us a great deal of subsequent search effort 
another feature of this specific example  and of the example of the introduction as
well  is that the computational benefits of dynamic backtracking are a consequence of
  

fidynamic backtracking

the automatic realization that the problem splits into disjoint subproblems  other authors
have also discussed the idea of applying divide and conquer techniques to csps  seidel       
zabih         but their methods suffer from the disadvantage that they constrain the order in
which unassigned variables are assigned values  perhaps at odds with the common heuristic
of assigning values first to those variables that are most tightly constrained  dynamic
backtracking can also be expected to be of use in situations where the problem in question
does not split into two or more disjoint subproblems  

   experimentation

dynamic backtracking has been incorporated into the crossword puzzle generation program
described in  ginsberg  frank  halpin    torrance         and leads to significant performance improvements in that restricted domain  more specifically  the method was tested
on the problem of generating    puzzles of sizes ranging from      to         each puzzle
was attempted     times using both dynamic backtracking and simple backjumping  the
dictionary was shued between solution attempts and a maximum of      backtracks were
permitted before the program was deemed to have failed 
in both cases  the algorithms were extended to include iterative broadening  ginsberg
  harvey         the cheapest first heuristic and forward checking  cheapest first has
also been called  most constrained first  and selects for instantiation that variable with
the fewest number of remaining possibilities  i e   that variable for which it is cheapest to
enumerate the possible values  smith   genesereth          forward checking prunes the
set of possibilities for crossing words whenever a new word is entered and constitutes our
experimental choice of elimination mechanism  at any point  words for which there is no legal
crossing word are eliminated  this ensures that no word will be entered into the crossword
if the word has no potential crossing words at some point  the cheapest first heuristic
would identify the problem at the next step in the search  but forward checking reduces
the number of backtracks substantially  the  least constraining  heuristic  ginsberg et al  
      was not used  this heuristic suggests that each word slot be filled with the word that
minimally constrains the subsequent search  the heuristic was not used because it would
invalidate the technique of shuing the dictionary between solution attempts in order to
gather useful statistics 
the table in figure   indicates the number of successful solution attempts  out of     
for each of the two methods on each of the    crossword frames  dynamic backtracking is
more successful in six cases and less successful in none 
with regard to the number of nodes expanded by the two methods  consider the data
presented in figure    where we graph the average number of backtracks needed by the
two methods   although initially comparable  dynamic backtracking provides increasing
computational savings as the problems become more dicult  a somewhat broader set of
experiments is described in  jonsson   ginsberg        and leads to similar conclusions 
there are some examples in  jonsson   ginsberg        where dynamic backtracking
leads to performance degradation  however  a typical case appears in figure     in this
   i am indebted to david mcallester for these observations 
   only    points are shown because no point is plotted where backjumping was unable to solve the problem 
   the worst performance degradation observed was a factor of approximately   

  

figinsberg

dynamic
dynamic
frame backtracking backjumping frame backtracking backjumping
 
   
   
  
   
  
   
   
  
   
   
 
 
   
   
  
   
   
   
   
  
   
   
 
 
   
   
  
  
  
   
   
  
   
  
 
 
   
   
  
   
  
   
   
  
  
 
 
 
   
   
  
  
 
  
   
   
figure    number of problems solved successfully

   
r
r

dynamic    
backtracking

r
r

r rr
rrr
rr

r
r

rr

   

   
   
backjumping

figure    number of backtracks needed

  

   

    

fidynamic backtracking

region
 
s

  
 
 
 
 
 
b
sa
s 
  
a aaaa
aaa
aaa   
aaa  
aa a
 a s

region  

figure    a dicult problem for dynamic backtracking
figure  we first color a  then b   then the countries in region    and then get stuck in region
  
we now presumably backtrack directly to b   leaving the coloring of region   alone  but
this may well be a mistake   the colors in region   will restrict our choices for b   perhaps
making the subproblem consisting of a  b and region   more dicult than it might be  if
region   were easy to color  we would have been better off erasing it even though we didn t
need to 
this analysis suggests that dependency directed backtracking should also fare worse
on those coloring problems where dynamic backtracking has trouble  and we are currently
extending the experiments of  jonsson   ginsberg        to confirm this  if this conjecture
is borne out  a variety of solutions come to mind  we might  for example  record how
many backtracks are made to a node such as b in the above figure  and then use this to
determine that exibility at b is more important than retaining the choices made in region
   the diculty of finding a coloring for region   can also be determined from the number
of backtracks involved in the search 

   summary
    why it works
there are two separate ideas that we have exploited in the development of algorithm    
and the others leading up to it  the first  and easily the most important  is the notion
that it is possible to modify variable order on the y in a way that allows us to retain the
results of earlier work when backtracking to a variable that was assigned a value early in
the search 
  

figinsberg

this reordering should not be confused with the work of authors who have suggested a
dynamic choice among the variables that remain to be assigned values  dechter   meiri 
      ginsberg et al         p  purdom   robertson        zabih   mcallester         we
are instead reordering the variables that have been assigned values in the search thus far 
another way to look at this idea is that we have found a way to  erase  the value given
to a variable directly as opposed to backtracking to it  this idea has also been explored
by minton et al  in  minton  johnston  philips    laird        and by selman et al  in
 selman  levesque    mitchell         these authors also directly replace values assigned
to variables in satisfiability problems  unfortunately  the heuristic repair method used is
incomplete because no dependency information is retained from one state of the problem
solver to the next 
there is a third way to view this as well  the space that we are examining is really a
graph  as opposed to a tree  we reach the same point by coloring albania blue and then
bulgaria red as if we color them in the opposite order  when we decide to backjump from a
particular node in the search space  we know that we need to back up until some particular
property of that node ceases to hold   and the key idea is that by backtracking along a
path other than the one by which the node was generated  we may be able to backtrack
only slightly when we would otherwise need to retreat a great deal  this observation is
interesting because it may well apply to problems other than csps  unfortunately  it is not
clear how to guarantee completeness for a search that discovers a node using one path and
backtracks using another 
the other idea is less novel  as we have already remarked  our use of eliminating
explanations is quite similar to the use of nogoods in the atms community  the principal
difference is that we attach the explanations to the variables they impact and drop them
when they cease to be relevant   they might become relevant again later  of course   this
avoids the prohibitive space requirements of systems that permanently cache the results of
their nogood calculations  this observation also may be extensible beyond the domain of
csps specifically  again  there are other ways to view this   gashnig s notion of backmarking
 gaschnig        records similar information about the reason that particular portions of a
search space are known not to contain solutions 

    future work
there are a variety of ways in which the techniques we have presented can be extended  in
this section  we sketch a few of the more obvious ones 
      backtracking to older culprits

one extension to our work involves lifting the restriction in algorithm     that the variable
erased always be the most recently assigned member of the set e  
in general  we cannot do this while retaining the completeness of the search  consider
the following example 
imagine that our csp involves three variables  x  y and z   that can each take the value  
or    further  suppose that this csp has no solutions  in that after we pick any two values
for x and for y   we realize that there is no suitable choice for z  
  

fidynamic backtracking

we begin by taking x   y      when we realize the need to backtrack  we introduce the
nogood
x      y     
   
and replace the value for y with y     
this fails  too  but now suppose that we were to decide to backtrack to x  introducing
the new nogood
y      x     
   
we change x s value to   and erase     
this also fails  we decide that y is the problem and change its value to    introducing
the nogood
x      y     
but erasing      and when this fails  we are in danger of returning to x   y      which we
eliminated at the beginning of the example  this loop may cause a modified version of the
dynamic backtracking algorithm to fail to terminate 
in terms of the proof of theorem      the nogoods discovered already include information
about all assigned variables  so there is no difference between     and      when we drop
    in favor of      we are no longer in a position to recover     
we can deal with this by placing conditions on the variables to which we choose to
backtrack  the conditions need to be defined so that the proof of theorem     continues to
hold   experimentation indicates that loops of the form we have described are extremely
rare in practice  it may also be possible to detect them directly and thereby retain more
substantial freedom in the choice of backtrack point 
this freedom of backtrack raises an important question that has not yet been addressed
in the literature  when backtracking to avoid a diculty of some sort  to where should one
backtrack 
previous work has been constrained to backtrack no further than the most recent choice
that might impact the problem in question  any other decision would be both incomplete and
inecient  although an extension of algorithm     need not operate under this restriction 
we have given no indication of how the backtrack point should be selected 
there are several easily identified factors that can be expected to bear on this choice 
the first is that there remains a reason to expect backtracking to chronologically recent
choices to be the most effective   these choices can be expected to have contributed to
the fewest eliminating explanations  and there is obvious advantage to retaining as many
eliminating explanations as possible from one point in the search to the next  it is possible  however  to simply identify that backtrack point that affects the fewest number of
eliminating explanations and to use that 
alternatively  it might be important to backtrack to the choice point for which there
will be as many new choices as possible  as an extreme example  if there is a variable i
for which every value other than its current one has already been eliminated for other
reasons  backtracking to i is guaranteed to generate another backtrack immediately and
should probably be avoided if possible 
   another solution appears in  mcallester        

  

figinsberg

finally  there is some measure of the  directness  with which a variable bears on a
problem  if we are unable to find a value for a particular variable i  it is probably sensible
to backtrack to a second variable that shares a constraint with i itself  as opposed to some
variable that affects i only indirectly 
how are these competing considerations to be weighed  i have no idea  but the framework we have developed is interesting because it allows us to work on this question  in
more basic terms  we can now  debug  partial solutions to csps directly  moving laterally
through the search space in an attempt to remain as close to a solution as possible  this
sort of lateral movement seems central to human solution of dicult search problems  and
it is encouraging to begin to understand it in a formal way 
      dependency pruning

it is often the case that when one value for a variable is eliminated while solving a csp 
others are eliminated as well  as an example  in solving a scheduling problem a particular
choice of time  say t       may be eliminated for a task a because there then isn t enough
time between a and a subsequent task b   in this case  all later times can obviously be
eliminated for a as well 
formalizing this can be subtle  after all  a later time for a isn t uniformly worse than an
earlier time because there may be other tasks that need to precede a and making a later
makes that part of the schedule easier  it s the problem with b alone that forces a to be
earlier  once again  the analysis depends on the ability to maintain dependency information
as the search proceeds 
we can formalize this as follows  given a csp  i  v     suppose that the value v has
been assigned to some i   i   now we can construct a new csp  i    v        involving the
remaining variables i     i  fig  where the new set v   need not mention the possible values
vi for i  and where   is generated from  by modifying the constraints to indicate that i
has been assigned the value v   we also make the following definition 

definition     given a csp  suppose that i is a variable that has two possible values u and

v  we will say that v is stricter than u if every constraint in the csp induced by assigning
u to i is also a constraint in the csp induced by assigning i the value v 
the point  of course  is that if v is stricter than u is  there is no point to trying a
solution involving v once u has been eliminated  after all  finding such a solution would
involve satisfying all of the constraints in the v restriction  these are a superset of those in
the u restriction  and we were unable to satisfy the constraints in the u restriction originally 
the example with which we began this section now generalizes to the following 

proposition     suppose that a csp involves a set s of variables  and that we have a
partial solution that assigns values to the variables in some subset p  s   suppose further
that if we extend this partial solution by assigning the value u to a variable i    p   there is
no further extension to a solution of the entire csp  now consider the csp involving the
variables in s   p that is induced by the choices of values for variables in p   if v is stricter
than u as a choice of value for i in this problem  the original csp has no solution that both
assigns v to i and extends the given partial solution on p  
  

fidynamic backtracking

this proposition isn t quite enough  in the earlier example  the choice of t      for a
will not be stricter than t      if there is any task that needs to be scheduled before a is 
we need to record the fact that b  which is no longer assigned a value  is the source of the
diculty  to do this  we need to augment the dependency information with which we are
working 
more precisely  when we say that a set of variables fxi g eliminates a value v for a variable
x  we mean that our search to date has allowed us to conclude that
 v    x           vk   xk    v    x
where the vi are the current choices for the xi   we can obviously rewrite this as
 v    x            vk   xk      v   x   f
   
where f indicates that the csp in question has no solution 
let s be more specific still  indicating in     exactly which csp has no solution 
 v    x            vk   xk      v   x   f  i  
   
where i is the set of variables in the complete csp 
now we can address the example with which we began this section  the csp that is
known to fail in an expression such as     is not the entire problem  but only a subset of it 
in the example  we are considering  the subproblem involves only the two tasks a and b  
in general  we can augment our nogoods to include information about the subproblems on
which they fail  and then measure strictness with respect to these restricted subproblems
only  in our example  this will indeed allow us to eliminate t      from consideration as a
possible time for a 
the additional information stored with the nogoods doubles their size  we have to store a
second subset of the variables in the csp   and the variable sets involved can be manipulated
easily as the search proceeds  the cost involved in employing this technique is therefore that
of the strictness computation  this may be substantial given the data structures currently
used to represent csps  which typically support the need to check if a constraint has been
violated but little more   but it seems likely that compile time modifications to these data
structures can be used to make the strictness question easier to answer  in scheduling
problems  preliminary experimental work shows that the idea is an important one  here 
too  there is much to be done 
the basic lesson of dynamic backtracking is that by retaining only those nogoods that
are still relevant given the partial solution with which we are working  the storage diculties
encountered by full dependency directed methods can be alleviated  this is what makes
all of the ideas we have proposed possible   erasing values  selecting alternate backtrack
points  and dependency pruning  there are surely many other effective uses for a practical
dependency maintenance system as well 

acknowledgements
this work has been supported by the air force oce of scientific research under grant
number         and by darpa rome labs under grant number f         c       i
  

figinsberg

would like to thank rina dechter  mark fox  don geddis  will harvey  vipin kumar 
scott roy and narinder singh for helpful comments on these ideas  ari jonsson and
david mcallester provided me invaluable assistance with the experimentation and proofs
respectively 

a  proofs
lemma     let  be a complete elimination mechanism for a csp  let p be a partial solution

to this csp and let i    p   now if p can be successfully extended to a complete solution after
assigning i the value v   then v    b p  i  

proof  suppose otherwise  so that  v  e      p  i   it follows directly from the completeness
of  that

e    p   p      

a contradiction 

lemma     at any point in the execution of algorithm      if the last element of the partial

solution p assigns a value to the variable i  then the unexplored siblings of the current node
are those that assign to i the values in vi   ei  

proof  we first note that when we decide to assign a value to a new variable i in step  

of the algorithm  we take ei   b p  i  so that vi   ei is the set of allowed values for this
variable  the lemma therefore holds in this case  the fact that it continues to hold through
each repetition of the loop in steps   and   is now a simple induction  at each point  we
add to ei the node that has just failed as a possible value to be assigned to i 

proposition     algorithm     is equivalent to depth first search and therefore complete 
proof  this is an easy consequence of the lemma  partial solutions correspond to nodes

in the search space 
lemma     let p be a partial solution obtained during the execution of algorithm      and
let i   p be a variable assigned a value by p   now if p    p can be successfully extended
to a complete solution after assigning i the value v but  v  e     ei   we must have

e    p   p       

proof  as in the proof of lemma      we show that no step of algorithm     can cause
lemma     to become false 
that the lemma holds after step    where the search is extended to consider a new
variable  is an immediate consequence of the assumption that the elimination mechanism
is complete 
in step    when we add  vj   e   fj g  to the set of eliminating explanations for j   we
are simply recording the fact that the search for a solution with j set to vj failed because
we were unable to extend the solution to i  it is a consequence of the inductive hypothesis
that as long as no variable in e   fj g changes  this conclusion will remain valid 
proposition     backjumping is complete and always expands fewer nodes than does depthfirst search 

  

fidynamic backtracking

proof  that fewer nodes are examined is clear  for completeness  it follows from lemma
    that the backtrack to some element of e in step   will always be necessary if a solution
is to be found 
proposition     the amount of space needed by backjumping is o i v   where i   ji j is
the number of variables in the problem and v is the number of values for that variable with
the largest value set vi  
proof  the amount of space needed is dominated by the storage requirements of the elimination sets ej   there are i of these  each one might refer to each of the possible values for
a particular variable j   the space needed to store the reason that the value j is eliminated
is at most ji j  since the reason is simply a list of variables that have been assigned values 
there will never be two eliminating explanations for the same variable  since  is concise
and we never rebind a variable to a value that has been eliminated 
theorem     dynamic backtracking always terminates and is complete  it continues to

satisfy proposition     and can be expected to expand fewer nodes than backjumping provided
that the goal nodes are distributed randomly in the search space 

proof  there are four things we need to show  that dynamic backtracking needs o i v 

space  that it is complete  that it can be expected to expand fewer nodes than backjumping 
and that it terminates  we prove things in this order 
space this is clear  the amount of space needed continues to be bounded by the structure
of the eliminating explanations 
completeness this is also clear  since by lemma      all of the eliminating explanations
retained in the algorithm are obviously still valid  the new explanations added in     are
also obviously correct  since they indicate that j cannot take the value vj as in backjumping
and that j also cannot take any values that are eliminated by the variables being backjumped
over 
eciency to see that we expect to expand fewer nodes  suppose that the subproblem
involving only the variables being jumped over has s solutions in total  one of which is given
by the existing variable assignments  assuming that the solutions are distributed randomly
in the search space  there is at least a   s chance that this particular solution leads to a
solution of the entire csp  if so  the reordered search   which considers this solution earlier
than the other   will save the expense of either assigning new values to these variables or
repeating the search that led to the existing choices  the reordered search will also benefit
from the information in the nogoods that have been retained for the variables being jumped
over 
termination this is the most dicult part of the proof 
as we work through the algorithm  we will be generating  and then discarding  a variety
of eliminating explanations  suppose that e is such an explanation  saying that j cannot
take the value vj because of the values currently taken by the variables in some set ev  
we will denote the variables in ev by x            xk and their current values by v           vk   in
declarative terms  the eliminating explanation is telling us that
 x    v           xk   vk    j    vj
  

   

figinsberg

dependency directed backtracking would have us accumulate all of these nogoods  dynamic
backtracking allows us to drop any particular instance of     for which the antecedent is no
longer valid 
the reason that dependency directed backtracking is guaranteed to terminate is that
the set of accumulated nogoods eliminates a monotonically increasing amount of the search
space  each nogood eliminates a new section of the search space because the nature of the
search process is such that any node examined is consistent with the nogoods that have been
accumulated thus far  the process is monotonic because all nogoods are retained throughout
the search  these arguments cannot be applied to dynamic backtracking  since nogoods are
forgotten as the search proceeds  but we can make an analogous argument 
to do this  suppose that when we discover a nogood like      we record with it all of the
variables that precede the variable j in the partial order  together with the values currently
assigned to these variables  thus an eliminating explanation becomes essentially a nogood
n of the form     together with a set s of variable value pairs 
we now define a mapping  n  s   that changes the antecedent of     to include assumptions about all the variables bound in s   so that if s   fsi   vi g 

 n  s       s    v           sl   vl   j    vj  

   

at any point in the execution of the algorithm  we denote by n the conjunction of the
modified nogoods of the form     
we now make the following claims 
   for any eliminating explanation  n  s    n j   n  s   so that  n  s   is valid for the
problem at hand 
   for any new eliminating explanation  n  s     n  s   is not a consequence of n  
   the deductive consequences of n grow monotonically as the dynamic backtracking
algorithm proceeds 
the theorem will follow from these three observations  since we will know that n is a valid
set of conclusions for our search problem and that we are once again making monotonic
progress toward eliminating the entire search space and concluding that the problem is
unsolvable 
that  n  s   is a consequence of  n  s   is clear  since the modification used to obtain
    from     involves strengthening that antecedent of      it is also clear that  n  s   is
not a consequence of the nogoods already obtained  since we have added to the antecedent
only conditions that hold for the node of the search space currently under examination  if
 n  s   were a consequence of the nogoods we had obtained thus far  this node would not
be being considered 
the last observation depends on the following lemma 

lemma a   suppose that x is a variable assigned a value by our partial solution and that

x appears in the antecedent of the nogood n in the pair  n  s    then if s   is the set of
variables assigned values no later than x  s    s  
  

fidynamic backtracking

proof  consider a y   s    and suppose that it were not in s   we cannot have y   x  since

y would then be mentioned in the nogood n and therefore in s   so we can suppose that
y is actually assigned a value earlier than x is  now when  n  s   was added to the set of
eliminating explanations  it must have been the case that x was assigned a value  since it
appears in the antecedent of n  but that y was not  but we also know that there was a
later time when y was assigned a value but x was not  since y precedes x in the current
partial solution  this means that x must have changed value at some point after  n  s   was
added to the set of eliminating explanations   but  n  s   would have been deleted when this
happened  this contradiction completes the proof 
returning to the proof the theorem      suppose that we eventually drop  n  s   from
our collection of nogoods and that when we do so  the new nogood being added is  n   s     it
follows from the lemma that s    s   since xi   vi is a clause in the antecedent of  n  s    it
follows that  n    s    will imply the negation of the antecedent of  n  s   and will therefore
imply  n  s   itself  although we drop  n  s   when we drop the nogood  n  s     n  s  
continues to be entailed by the modified set n   the consequences of which are seen to be
growing monotonically 

references

bruynooghe  m          solving combinatorial search problems by intelligent backtracking 
information processing letters                
de kleer  j          an assumption based truth maintenance system  artificial intelligence 
            
dechter  r     meiri  i          experimental evaluation of preprocessing techniques in
constraint satisfaction problems  in proceedings of the eleventh international joint
conference on artificial intelligence  pp          
gaschnig  j          performance measurement and analysis of certain search algorithms 
tech  rep  cmu cs         carnegie mellon university 
ginsberg  m  l   frank  m   halpin  m  p     torrance  m  c          search lessons learned
from crossword puzzles  in proceedings of the eighth national conference on artificial
intelligence  pp          
ginsberg  m  l     harvey  w  d          iterative broadening  artificial intelligence     
        
jonsson  a  k     ginsberg  m  l          experimenting with new systematic and nonsystematic search techniques  in proceedings of the aaai spring symposium on ai
and np hard problems stanford  california 
mcallester  d  a          partial order backtracking  journal of artificial intelligence
research     submitted 
minton  s   johnston  m  d   philips  a  b     laird  p          solving large scale constraint satisfaction and scheduling problems using a heuristic repair method  in proceedings of the eighth national conference on artificial intelligence  pp        
  

figinsberg

p  purdom  c  b     robertson  e          backtracking with multi level dynamic search
rearrangement  acta informatica             
seidel  r          a new method for solving constraint satisfaction problems  in proceedings
of the seventh international joint conference on artificial intelligence  pp          
selman  b   levesque  h     mitchell  d          a new method for solving hard satisfiability
problems  in proceedings of the tenth national conference on artificial intelligence 
smith  d  e     genesereth  m  r          ordering conjunctive queries  artificial intelligence                  
stallman  r  m     sussman  g  j          forward reasoning and dependency directed
backtracking in a system for computer aided circuit analysis  artificial intelligence 
               
zabih  r          some applications of graph bandwidth to constraint satisfaction problems 
in proceedings of the eighth national conference on artificial intelligence  pp        
zabih  r     mcallester  d  a          a rearrangement search strategy for determining
propositional satisfiability  in proceedings of the seventh national conference on
artificial intelligence  pp          

  

fi