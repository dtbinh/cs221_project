journal of artificial intelligence research               

submitted       published     

space efficiency of propositional knowledge representation
formalisms
marco cadoli

cadoli dis uniroma  it

dipartimento di informatica e sistemistica
universita di roma la sapienza
via salaria      i        roma  italy

francesco m  donini

donini dis uniroma  it

politecnico di bari
dipartimento di di elettrotecnica ed elettronica
via orabona    i        bari  italy

paolo liberatore
marco schaerf

liberato dis uniroma  it
schaerf dis uniroma  it

dipartimento di informatica e sistemistica
universita di roma la sapienza
via salaria      i        roma  italy

abstract
we investigate the space efficiency of a propositional knowledge representation  pkr 
formalism  intuitively  the space efficiency of a formalism f in representing a certain piece
of knowledge   is the size of the shortest formula of f that represents   in this paper we
assume that knowledge is either a set of propositional interpretations  models  or a set of
propositional formulae  theorems   we provide a formal way of talking about the relative
ability of pkr formalisms to compactly represent a set of models or a set of theorems  we
introduce two new compactness measures  the corresponding classes  and show that the
relative space efficiency of a pkr formalism in representing models theorems is directly
related to such classes  in particular  we consider formalisms for nonmonotonic reasoning 
such as circumscription and default logic  as well as belief revision operators and the stable
model semantics for logic programs with negation  one interesting result is that formalisms
with the same time complexity do not necessarily belong to the same space efficiency class 

   introduction
during the last years a large number of formalisms for knowledge representation  kr  have
been proposed in the literature  such formalisms have been studied from several perspectives  including semantical properties  and computational complexity  here we investigate
space efficiency  a property that has to do with the minimal size needed to represent a certain piece of knowledge in a given formalism  this study is motivated by the fact that the
same piece of knowledge can be represented by two formalisms using a different amount of
space  therefore  all else remaining the same  a formalism could be preferred over another
one because it needs less space to store information 
the definition of space efficiency  however  is not simple  indeed  a formalism may allow
several different ways to represent the same piece of knowledge  for example  let us assume
that we want to represent the piece of knowledge today is monday  in propositional

c
    
ai access foundation and morgan kaufmann publishers  all rights reserved 

ficadoli  donini  liberatore    schaerf

logic we may decide to use a single propositional variable monday  the fact that today is
monday can be represented by the formula monday  but also by the formula monday 
as well as monday   rain  rain   because all formulae of the propositional logic that
are logically equivalent to monday represent exactly the same information 
in propositional logic  we should consider the shortest of the equivalent formulae used
to represent the information we have  the same principle can be applied to a generic
formalism  if it allows several formulae to represent the same information  then we only take
into account the shortest one  therefore  we say that the space efficiency of a formalism f
in representing a certain piece of knowledge  is the size of the shortest formula of f that
represents   space efficiency also called succinctness or compactness of a formalism
is a measure of its ability in representing knowledge in a small amount of space 
in this paper we focus on propositional kr  pkr  formalisms  we do not give a
formal definition of which formalisms are propositional and which one are not  intuitively 
in a propositional formalism  quantifications are not allowed  and thus the formulae are
syntactically bounded to be formed only using propositional connectives  plus some other
kind of nonclassical connectives  for instance  negation in logic programs  etc   
so far  we have not discussed what knowledge represents  a possible way to think of a
piece of knowledge is that it represents all facts that can be inferred from it  in other words 
knowing something is the same as knowing everything that can be logically implied  the
second way  which is in some cases more natural  is to think of a piece of knowledge
as the set of states of the world that we consider possible 
in a more formal way  we say that knowledge is represented either by a set of propositional interpretations  those describing states of the world we consider plausible  or a set
of formulae  those implied from what we know   consequently  we focus on both reasoning
problems of model checking and theorem proving  the following example shows that we
can really think of knowledge in both ways 
example   we want to eat in a fast food  and want to have either a sandwich or a salad
 but not both   and either water or coke  but not both  
in propositional logic  each choice can be represented as a model  and the following
models represent all possible choices  models are represented by writing down only the letters
mapped to true  
a     sandwich  water    sandwich  coke    salad  water    salad  coke  
for representing the set of choices we can use formulae instead of models  in this case 
we write down a set of formulae whose models represent exactly the allowed choices  as
follows 
c    sandwich  salad    sandwich  salad    sandwich  salad  
 water  coke    water  coke    coke  water 

actually  we can get rid of redundancies  and end up with the following formula 
f    sandwich  salad    sandwich  salad    water  coke    water  coke 
 

fispace efficiency of propositional knowledge representation formalisms

more formally  f represents the set of models a  because for each interpretation i  i  a
holds if and only if i    f   the formula f also represents the set of formulae c  because
cn f     cn c   where cn    is the function that gives the set of all conclusions that can
be drawn from a propositional formula 
    state of the art
a question that has been deeply investigated  and is related to space efficiency  is the
possibility of translating a formula expressed in one formalism into a formula expressed in
another formalism  under the assumption  of course  that these formulae represent the same
knowledge  
in most cases  the analysis is about the possibility of translating formulae from different
formalisms to propositional logic  pl   for example  ben eliyahu and dechter             
proposed a translation from default logic to pl  and a translation from disjunctive logic
programs to pl  while winslett        introduced a translation from revised knowledge
bases to pl  and gelfond  przymusinska  and przymusinskyi        defined a translation
from circumscription to pl 
all the above translations  as well as many other ones in the literature  lead to an
exponential increase of the size of the formula  in the worst case  when the best known
translation yields a formula in the target formalism which has exponential size w r t  the
formula in the source formalism  a natural question arising is whether such exponential
blow up is due to the specific translation  or is intrinsic of the problem  for example 
although all proposed translations from default logic to pl lead to the exponential blow
up  we cannot conclude that all possible translations suffer from this problem  it could be
that a polynomial translation exists  but it has not discovered so far 
some works have focussed on the question of whether this kind of exponential increase
in the size is intrinsic or not  cadoli  donini  and schaerf        have shown that many interesting fragments of default logic and circumscription cannot be expressed by polynomialtime fragments of pl without super polynomially increasing the size of formulae  it has
been proved that such a super polynomial increase of size is necessary when translating
unrestricted propositional circumscription  cadoli  donini  schaerf    silvestri        and
most operators for belief revision into pl  cadoli  donini  liberatore    schaerf       
liberatore        
gogic and collegues        analyzed the relative succinctness of several pkr formalisms
in representing sets of models  among other results  they showed that skeptical default logic
can represent sets of models more succinctly than circumscription 
kautz  kearns  and selman        and khardon and roth              considered
representations of knowledge bases based on the notion of characteristic model  comparing
them to other representations  e g   based on clauses  they showed that the representation of
knowledge bases with their characteristic models is sometimes exponentially more compact
than other ones  and that the converse is true in other cases 
however  all the above results are based on specific proofs  tailored to a specific reduction  and do not help us to define equivalence classes for the space efficiency of kr
formalisms  in a recent paper  cadoli  donini  liberatore    schaerf      b   a new complexity measure for decision problems  called compilability  has been introduced  in the

 

ficadoli  donini  liberatore    schaerf

present paper we show how this new measure can be directly used to characterize the space
efficiency of pkr formalisms  we emphasize methodological aspects  expressing in a more
general context many of the results presented before 
    goal
the notion of polynomial time complexity has a great importance in kr  as well as many
other fields of computer science   as problems that can be solved in polynomial time are to
be considered easy  from a computational point of view 
the notion of polynomial many one reducibility also has a very intuitive meaning when
applied to kr  if there exists a polynomial many one reduction from one formalism to
another one  then the time complexity of reasoning in the two formalisms is comparable 
this allows to say  e g   that inference in pl is conp complete  i e  it is one of the hardest
problems among those in the complexity class conp 
as a result  we have a formal tool for comparing the difficulty of reasoning in two
formalisms  what is missing is a way for saying that one formalism is able to represent the
same information in less space 
example   we consider again the lunch scenario of the previous example  we show that
we can reduce the size of the representation using circumscription instead of propositional
logic  in pl  the knowledge of the previous example was represented by the formula f  
f    sandwich  salad    sandwich  salad    water  coke    water  coke 
the set of models of this formula is a  and the models of a are exactly the minimal
models of the formula fc defined as follows 
fc    sandwich  salad    water  coke 
by the definition of circumscription  mccarthy        it holds that f is equivalent to
circ fc    sandwich  salad  water  coke        note that fc is shorter than f   if this result
can be proved to hold for arbitrary sets of models  we may conclude that circumscription is
more space efficient than propositional logic in representing knowledge expressed as sets of
models 
our goal is to provide a formal way of talking about the relative ability of pkr formalisms to compactly represent information  where the information is either a set of models
or a set of theorems  in particular  we would like to be able to say that a specific pkr
formalism provides one of the most compact ways to represent models theorems among
the pkr formalisms of a specific class 
    results
we introduce two new compactness measures  model and theorem compactness  and the
corresponding classes  model c and thm c  where c is a complexity class like p  np  conp 
etc    such classes form two hierarchies that are isomorphic to the polynomial time hierarchy
 stockmeyer         we show that the relative space efficiency of a pkr formalism is
 

fispace efficiency of propositional knowledge representation formalisms

directly related to such classes  in particular  the ability of a pkr formalism to compactly
represent sets of models theorems is directly related to the class of the model theorem
hierarchy it belongs to  problems higher up in the model theorem hierarchy can represent
sets of models theorems more compactly than formalisms that are in lower classes 
this classification is obtained through a general framework and not by making direct
comparisons and specific translations between the various pkr formalisms  furthermore 
our approach also allows for a simple and intuitive notion of completeness for both model
and theorem hierarchies  this notion precisely characterizes both the relation between
formalisms at different levels  and the relations between formalisms at the same level  an
interesting result is that two pkr formalisms in which model checking or inference belong
to the same time complexity class may belong to different compactness classes  this may
suggest a criterion for choosing between two pkr formalisms in which reasoning has the
same time complexitynamely  choose the more compact one  also  two pkr formalisms
may belong to the same theorem compactness class  yet to different model compactness
classes  this stresses the importance of clarifying whether one wants to represent models
or theorems when choosing a pkr formalism 
    outline
in the next section we introduce the notation and the assumptions that we adopt in this
work  in section    compilability  we briefly recall some notions on non uniform computation that are important for what follows and we recall the basic definitions of compilability
classes  cadoli et al       b   in section    reductions  we describe the constraints we
impose on reductions  while in section    space efficiency  we introduce our compactness
classes  in section    applications  we actually compare many known pkr formalisms
using our framework  finally  in section    related work and conclusions  we compare
our work with other proposals presented in the literature and draw some conclusions 

   notations and assumptions
in this section we define what knowledge bases and formalisms are  since we want to
consider formalisms that are very different both in syntax and in semantics  we need very
general definitions  let us consider  as a base case  the formalism of propositional calculus 
formally  we can assume that it is composed of three parts 
   a syntax  which is used to define the well formed formulae 
   a proof theory  which allows for saying when a formula follows from another one  and
   a model theoretic semantics  which establishes when a model satisfies a formula 
the syntax is defined from a finite alphabet of propositional symbols l    a  b  c         
possibly with subscripts  and the usual set of propositional connectives      
in terms of knowledge representation  the proof theory can be seen as a way for extracting knowledge from a knowledge base  for example  if our knowledge base is a  c  then the
fact a  b holds  we can thus say that the formula a  b is part of the knowledge represented
by a  c 
 

ficadoli  donini  liberatore    schaerf

in some cases  we want knowledge bases to represent models rather than sets of formulas 
an interpretation for an alphabet of propositional variables l is a mapping from l in
 true  false   the model theoretic semantics of the propositional calculus is the usual way
of extending an interpretation for l to well formed formulas 
let us now extend such definition to generic formalisms  a formalism is composed of a
syntax  a proof theory  and a model theoretic semantics 
we remark that each formalism has its own syntax  for instance  default logic includes
a ternary connective   for denoting default rules  while logic programming has a special
unary connective not    and so on  a knowledge base of a formalism f is simply a wellformed formula  according to the syntax of the formalism 
each formalism has its own proof theory as well  the proof theory of a formalism f is a
binary relation  f on the set of knowledge bases and formulae  intuitively  f b  f  means
that  is a consequence of the knowledge base kb  according to the rules of the formalism
f   as a result  the set of formulae  that are implied by a knowledge base kb is exactly
the knowledge represented by kb 
the base of a comparison between two different formalisms is a concept of equivalence 
allowing for saying that two knowledge bases  of two different formalisms  represent the
same piece of knowledge  since the knowledge represented by a knowledge base is the set
of formulas it implies  we have to assume that the syntax of these formulae is the same
for all formalisms  namely  we always assume that the formulae implied by a knowledge
base are well formed formulae of the propositional calculus  in other words  each formalism
has a syntax for the knowledge bases  however  we assume that the proof theory relates
knowledge bases  formulae in the syntax of the formalism  with propositional formulae  so 
while writing kb  f   we assume that kb is a knowledge base in the syntax of f   while
 is a propositional formula 
this allows for saying that two knowledge bases kb  and kb    expressed in two different formalisms f  and f    represent the same piece of knowledge  this is true when  for
any propositional formula  it holds kb   f   if and only if kb   f   
the model theoreric semantics of a formalism is a relation   f between propositional
models and knowledge bases  in this case  we assume a fixed alphabet l  thus the set of
all interpretations is common to all formalisms  when a model m and a knowledge base
kb are in the relation  we write m   f kb  intuitively  this means that the model m
supports the piece of knowledge represented by kb 
we remark that some formalisms  e g  credolous default logic  reiter         have a
proof theory  but do not have a model theoretic semantics  it is also possible to conceive
formalisms with a model theoretic semantics but no proof theory  when both of them are
defined  we assume that they are related by the following formula 
kb  f 

iff

i   i    kb implies i    

regarding the proof theory of formalisms  we only consider formulae that are shorter
than the knowledge base  that is  we assume that the knowledge represented by a knowlegde
base kb is the set of formulae  such that kb  f   and the size of  is at most the size
of kb  this is done for two reasons  first  formulas that are larger than kb are likely to

 

fispace efficiency of propositional knowledge representation formalisms

contain large parts that are actually independent from kb  second  we can give technicals
result in a very simple way by using the compilability classes introduced in the next section 
assumption   we consider only formulae whose size is less than or equal to that of the
knowledge base 
all formalisms we consider satisfy the right hand side distruibutivity of conjunction 
that is  kb  f    if and only if kb  f  and kb  f   the assumption on the size
of  is not restrictive in this case  if  is a cnf formula 

   compilability classes
we assume the reader is familiar with basic complexity classes  such as p  np and  uniform 
classes of the polynomial hierarchy  stockmeyer        garey   johnson         here we
just briefly introduce non uniform classes  johnson         in the sequel  c  c    etc  denote
arbitrary classes of the polynomial hierarchy 
we assume that the input instances of problems are strings built over an alphabet  
we denote with  the empty string and assume that the alphabet  contains a special
symbol   to denote blanks  the length of a string x   is denoted by  x  
definition   an advice a is a function that takes an integer and returns a string 
advices are important in complexity theory because definitions and results are often
based on special turing machines that can determine the result of an oracle for free  that
is  in constant time 
definition   an advice taking turing machine is a turing machine enhanced with the
possibility to determine a  x   in constant time  where x is the input string 
of course  the fact that a  x   can be determined in constant time  while a can be
an intractable or even undecidable function  makes all definitions based on advice taking
turing machine different from the same ones based on regular turing machine  for example 
an advice taking turing machine can calculate in polynomial time many functions that a
regular turing machine cannot  including some untractable ones  
note that the advice is only a function of the size of the input  not of the input itself 
hence  advice taking turing machines are closely related to non uniform families of circuits
 boppana   sipser         clearly  if the advice were allowed to access the whole instance 
it would be able to determine the solution of any problem in constant time 
definition   an advice taking turing machine uses polynomial advice if there exists a
polynomial p such that the advice oracle a satisfies  a n    p n  for any nonnegative
integers n 
the non uniform complexity classes are based on advice taking turing machines  in
this paper we consider a simplified definition  based on classes of the polynomial hierarchy 

 

ficadoli  donini  liberatore    schaerf

definition   if c is a class of the polynomial hierarchy  then c poly is the class of languages defined by turing machines with the same time bounds as c  augmented by polynomial advice 
any class c poly is also known as non uniform c  where non uniformity is due to the
presence of the advice  non uniform and uniform complexity classes are related  karp and
lipton        proved that if np  p poly then p    p    ph  i e   the polynomial hierarchy collapses at the second level  while yap        generalized their results  in particular
by showing that if np  conp poly then p    p    ph  i e   the polynomial hierarchy
collapses at the third level  an inprovement of this results has been given by kobler and
watanabe         they proved that kp  pk  poly implies that the polynomial hierarchy collapses to zpp pk      the collapse of the polynomial hierarchy is considered very
unlikely by most researchers in structural complexity 
we now summarize some definitions and results proposed to formalize the compilability
of problems  cadoli et al       b   adapting them to the context and terminology of pkr
formalisms  we remark that it is not the aim of this paper to give a formalization of
compilability of problems  or to analyze problems from this point of view  rather  we show
how to use the compilability classes as a technical tool for proving results on the relative
efficiency of formalisms in representing knowledge in little space 
several papers in the literature focus on the problem of reducing the complexity of
problems via a preprocessing phase  kautz   selman        kautz et al         khardon
  roth         this motivates the introduction of a measure of complexity of problems
assuming that such preprocessing is allowed  following the intuition that a knowledge base
is known well before questions are posed to it  we divide a reasoning problem into two parts 
one part is fixed or accessible off line  the knowledge base   and the second one is varying  or
accessible on line  the interpretation formula   compilability aims at capturing the on line
complexity of solving a problem composed of such inputs  i e   complexity with respect to
the second input when the first one can be preprocessed in an arbitrary way  in the next
section we show the close connection between compilability and the space efficiency of pkr
formalisms 
a function f is called poly size if there exists a polynomial p such that for all strings
x it holds  f  x    p  x    an exception to this definition is when x represents a number 
in this case  we impose  f  x    p x   as a result  we can say that the function a used in
advice taking turing machine is a polysize function 
a function g is called poly time if there exists a polynomial q such that for all x  g x 
can be computed in time less than or equal to q  x    these definitions easily extend to
binary functions as usual 
we define a language of pairs s as a subset of      this is necessary to represent
the two inputs to a pkr reasoning problem  i e   the knowledge base  kb   and the formula
or interpretation  as an example  the problem of inference in propositional logic  pli  is
defined as follows 
pli    hx  yi   x is a set of propositional formulae  the kb   y is a formula  and x   y 
it is well known that pli is conp complete  i e   it is one of the hardest problems
among those belonging to conp  our goal is to prove that pli is the hardest theorem 

fispace efficiency of propositional knowledge representation formalisms

proving problem among those in conp that can be solved by preprocessing the first input
in an arbitrary way  i e   the kb  to this end  we introduce a new hierarchy of classes  the
non uniform compilability classes  denoted as k c  where c is a generic uniform complexity
class  such as p  np  conp  or p   
definition    k c classes  a language of pairs s     belongs to k c iff there
exists a binary poly size function f and a language of pairs s    c such that for all hx  yi  s
it holds 
hf  x   y    yi  s   iff hx  yi  s
notice that the poly size function f takes as input both x  the kb  and the size of y
 either the formula or the interpretation   this is done for technical reason  that is  such
assumption allows obtaining results that are impossible to prove if the function f only
takes x as input  cadoli et al       b   such assuption is useful for proving negative results 
that is  theorems of impossibility of compilation  indeed  if it is impossible to reduce the
complexity of a problem using a function that takes both x and  y  as input  then such
reduction is also impossible using a function taking x only as its argument 
theorem    cadoli  donini  liberatore    schaerf        theorem    let c be
a class in the polynomial hierarchy and s       a problem s belongs to k c if
and only if there exists a poly size function f and a language of pairs s     such that for all
hx  yi     it holds that 
   for all y such that  y   k  hf  x  k   yi  s   if and only if hx  yi  s 
   s    c 
clearly  any problem whose time complexity is in c is also in k c  just take f  x   y     x
and s     s  what is interesting is that some problem in c may belong to k c  with
c   c  e g    some problems in np are in k p  this is true for example for some problems
in belief revision  cadoli et al          in the rest of this paper  however  we mainly focus
on complete problems  defined below  a pictorial representation of the class k c is in
figure    where we assume that s    c 
for the problem pli no method proving that it belongs to k p is known  in order
to show that it  probably  does not belong to k p  we define a notion of reduction and
completeness 
definition    non uniform comp reducibility  given two problems a and b  a is
non uniformly comp reducible to b  denoted as a nucomp b  iff there exist two poly size
binary functions f  and f    and a polynomial time binary function g such that for every
pair hx  yi it holds that hx  yi  a if and only if hf   x   y    g f   x   y    y i  b 
the nucomp reductions can be represented as depicted in figure    such reductions
satisfy all important properties of a reduction 
theorem    cadoli et al       b  theorem    the reductions nucomp satisfy transitivity and are compatible  johnson        with the class k c for every complexity class c 
 

ficadoli  donini  liberatore    schaerf

f
 
  

x

       y 
y

 

hx  yi  s
 

s 

 

figure    a representation of k c 
x
 y 
  
y

  f 
  f 

 

 x

 

g
 

 y

 

 

figure    the nu comp c reductions 

therefore  it is possible to define the notions of hardness and completeness for k c for
every complexity class c 
definition    k c completeness  let s be a language of pairs and c a complexity class 
s is k c hard iff for all problems a  k c we have that a nucomp s  moreover  s is
k c complete if s is in k c and is k c hard 
we now have the right complexity class to completely characterize the problem pli  in
fact pli is k conp complete  cadoli et al       b  theorem     furthermore  the hierarchy
formed by the compilability classes is proper if and only if the polynomial hierarchy is
proper  cadoli et al       b  karp   lipton        yap         a fact widely conjectured
to be true 
informally  we may say that k np hard problems are not compilable to p  as from
the above considerations we know that if there exists a preprocessing of their fixed part that
makes them on line solvable in polynomial time  then the polynomial hierarchy collapses 
the same holds for k conp hard problems  in general  a problem which is k c complete
for a class c can be regarded as the toughest problem in c  even after arbitrary preprocessing of the fixed part  on the other hand  a problem in k c is a problem that  after
preprocessing of the fixed part  becomes a problem in c  i e   it is compilable to c  
we close the section by giving another example of use of the compilability classes through
the well known formalism of circumscription  mccarthy         let x be any propositional
formula  the minimal models of x are the truth assignments satisfying x having as few
positive values as possible  w r t  set containment   the problem we consider is  check
whether a given model is a minimal model of a propositional formula  this problem  called
minimal model checking  mmc   can be reformulated as the problem of model checking in
circumscription  which is known to be co np complete  cadoli        
  

fispace efficiency of propositional knowledge representation formalisms

if we consider the knowledge base x as given off line  and the truth assignment y as
given on line  we obtain the following definition 
mmc    hx  yi   y is a minimal model of x  
this problem can be shown to be k conp complete  cadoli et al       b  theorem     
hence  it is very unlikely that it can be in k p  that is  it is very unlikely that there exists
some off line processing of the knowledge base  yielding  say  some data structure x    such
that given y  it can now checked in polynomial time whether y is a minimal model of x 
this  of course  unless x  has exponential size  this observation applies also when x  is a
knowledge base in propositional logic  and led to the interpretation that circumscription
is more compact  or succint  than pl  cadoli  donini    schaerf        gogic et al         
our framework allows to generalize these results for all pkr formalisms  as shown in the
sequel 

   reductions among kr formalisms
we now define the forms of reduction between pkr formalisms that we analyze in the
following sections  a formula can always be represented as a string over an alphabet  
hence from now on we consider translations as functions transforming strings 
let f  and f  be two pkr formalisms  there exists a poly size reduction from f  to
f    denoted as f   f    f    if f is a poly size function such that for any given knowledge
base kb in f    f  kb  is a knowledge base in f    clearly  reductions should be restricted
to produce a meaningful output  in particular  we now discuss reductions that preserve the
models of the original theory 
the semantic approach by gogic and collegues        is that the models of the two
knowledge bases must be exactly the same  in other words  if a knowledge base kb of the
formalism f  is translated into a knowledge base kb   of the formalism f    then m   f  kb
if and only if m   f  kb     this approach can be summarized by  a reduction between
formalisms f  and f  is a way to translate knowledge bases of f  into knowledge bases of f   
preserving their sets of models  while this semantics is intuitively grounded  it is very easy
to show examples in which two formalisms that we consider equally space efficient cannot be
translated to each other  let us consider for instance a variant of the propositional calculus
in which the syntax is that formulas must be of the form x   f   where f is a regular
formula over the variables x           clearly  this formalism is able to represent knowledge
in the same space than the propositional calculus  apart a polynomial factor   however 
according to the definition  this formalism cannot be translated to propositional calculus 
there is no knowledge base that is equivalent to kb   x    indeed  the only model of
kb is   while any model of any consistent knowledge base of the modified propositional
calculus contains x   
we propose a more general approach that can deal also with functions f that change
the language of the kb  to this end  we allow for a translation gkb from models of kb to
models of f  kb   we stress that  to be as general as possible  the translation may depend
on kb  i e   different knowledge bases may have different translations of their models 
we want this translation easy to compute  since otherwise the computation of gkb could
hide the complexity of reasoning in the formalism  however  observe that to this end  it is
  

ficadoli  donini  liberatore    schaerf

not sufficient to impose that gkb is computable in polynomial time  in fact  once kb is
fixed  its models could be trivially translated to models of f  kb  in constant time  using
a lookup table  this table would be exponentially large  though  and this is what we want
to forbid  hence  we impose that gkb is a circuit of polynomial size wrt kb  we still use
a functional notation gkb  m   to denote the result of applying a model m to the circuit
gkb   a formal definition follows 
definition    model preservation  a poly size reduction f   f    f  satisfies modelpreservation if there exists a polynomial p such that  for each knowledge base kb in f  there
exists a circuit gkb whose size is bounded by p  kb    and such that for every interpretation
m of the variables of kb it holds that m   f  kb iff gkb  m     f  f  kb  
the rationale of model preserving reduction is that the knowledge base kb of the first
formalism f  can be converted into a knowledge base f  kb  in the second one f    and this
reduction should be such that each model m in f  can be easily translated into a model
gkb  m   in f   
we require g to depend on kb  because the transformation f   in general  could take
the actual form of kb into account  this happens in the following example of a modelpreserving translation 
example   we reduce a fragment of skeptical default logic  kautz   selman        to
circumscription with varying letters  using the transformation introduced by etherington
        let hd  w i be a prerequisite free normal  pfn  default theory  i e   all defaults
are of the form     where  is a generic formula  let z be the set of letters occurring in
hd  w i  define pd as the set of letters  a      d   the function f can be defined in
the following way  f  hd  w i    circ t   pd   z   where t   w   a   a  pd   
pd are the letters to be minimized  and z  the set of letters occurring in hd  w i  are
varying letters  we show that f is a model preserving poly size reduction  in fact  given
a set of pfn defaults d let gd be a function such that for each interpretation m for z 
gd  m     m   a  pd  m       clearly  f is poly size  gd can be realized by a circuit
whose size is polynomial in  d   and m is a model of at least one extension of hd  w i iff
gd  m      circ t   pd   z   the dependence of g only on d stresses the fact that  in this
case  the circuit g does not depend on the whole knowledge base hd  w i  but just on d 
clearly  when models are preserved  theorems are preserved as well  a weaker form of
reduction is the following one  where only theorems are preserved  also in this case we
allow theorems of kb to be translated by a simple circuit gkb to theorems of kb 
definition    theorem preservation  a poly size reduction f   f    f  satisfies theorempreservation if there exists a polynomial p such that  for each knowledge base kb in f   
there exists a circuit gkb whose size is bounded by p  kb    and such that for every formula
 on the variables of kb  it holds that kb  f   iff f  kb   f  gkb    
the theorem preserving reduction has a property similar to that of the model preserving
reduction  when the knowledge bases are used to represent theorems rather than models 
namely  a knowledge base kb is translated into another knowledge base f  kb  which can
  

fispace efficiency of propositional knowledge representation formalisms

be used to represent the same set of theorems  more precisely  we have that each theorem
 of kb is represented by a theorem gkb    of f  kb  
winslett        has shown an example of a reduction from updated knowledge bases to
pl that is theorem preserving but not model preserving  using winsletts reduction  one
could use the same machinery for propositional reasoning in the kb  both before and after
the update  plus the reduction   also the reduction shown in the previous example   is
theorem preserving  this time g being the identity circuit 
we remark that our definitions of reduction are more general than those proposed by
gogic and collegues         in fact  these authors consider only a notion analogous to
definition    and only for the case when g is the identity  i e   models in the two formalisms
should be identical  by allowing a simple translation g between models definition   covers
more general forms of reductions preserving models  like the one of example   

   comparing the space efficiency of pkr formalisms
in this section we show how to use the compilability classes defined in section   to compare
the succinctness of pkr formalisms 
let f  and f  be two formalisms representing sets of models  we prove that any
knowledge base  in f  can be reduced  via a poly size reduction  to a knowledge base 
in f  satisfying model preservation if and only if the compilability class of the problem of
model checking  first input  kb  second input  interpretation  in f  is higher than or equal
to the compilability class of the problem of model checking in f   
similarly  we prove that theorem preserving poly size reductions exist if and only if the
compilability class of the problem of inference  first input  kb  second input  formula  cf 
definition of the problem pli  in f  is higher than or equal to the compilability class of the
problem of inference in f   
in order to simplify the presentation and proof of the theorems we introduce some
definitions 
definition     model hardness completeness  let f be a pkr formalism and c be
a complexity class  if the problem of model checking for f belongs to the compilability class
k c  where the model is the varying part of the instances  we say that f is in model c 
similarly  if model checking is k c complete  hard   we say that f is model c complete
 hard  
definition     theorem hardness completeness  let f be a pkr formalism and
c be a complexity class  if the problem of inference for the formalism f belongs to the
compilability class k c  whenever the formula is the varying part of the instance  we say
that f is in thm c  similarly  if inference is k c complete  hard   we say that f is thmc complete  hard  
these definitions implicitly define two hierarchies  which parallel the polynomial hierarchy  stockmeyer         the model hierarchy  model p model np model p   etc   and the
theorem hierarchy  thm p thm np thm  p  etc    the higher a formalism is in the model
hierarchy  the more its efficiency in representing models is  and analogously for theorems 
as an example  cadoli et al         thm      we characterize model and theorem classes of
propositional logic 
  

ficadoli  donini  liberatore    schaerf

theorem   pl is in model p and it is thm conp complete 
we can now formally establish the connection between succinctness of representations
and compilability classes  in the following theorems  the complexity classes c  c    c  belong
to the polynomial hierarchy  stockmeyer         in theorems   and   we assume that the
polynomial hierarchy does not collapse 
we start by showing that the existence of model preserving reductions from a formalism
to another one can be easily obtained if their levels in the model hierarchy satisfy a simple
condition 
theorem   let f  and f  be two pkr formalisms  if f  is in model c and f  is modelc hard  then there exists a poly size reduction f   f    f  satisfying model preservation 
proof  recall that since f  is in model c  model checking in f  is in k c  and since f  is
model c hard  model checking in f  is non uniformly comp reducible to model checking in
f    that is   adapting def     there exist two poly size binary functions f  and f    and a
polynomial time binary function g such that for every pair hkb  m i it holds that
m   f  kb if and only if g f   kb   m     m     f  f   kb   m   
 note that g is the poly time function appearing in def     different from gkb which is the
poly size circuit appearing in def     
now observe that  m   can be computed from kb by simply counting the letters appearing in kb  let f  be such a counting function  i e    m     f   kb   clearly  f  is poly size 
define the reduction f as f  kb    f   kb  f   kb    since poly size functions are closed
under composition  f is poly size  now we show that f is a model preserving reduction  by
definition    we need to prove that there exists a polynomial p such that for each knowledge
base kb in f    there exists a poly size circuit gkb such that for every interpretation m of
the variables of kb it holds that m   f  kb iff gkb  m     f  f  kb  
we proceed as follows  given a kb in f    we compute z   f   kb   m      f   kb  f   kb   
since f  and f  are poly size  z has size polynomial with respect to  kb   define the circuit
gkb  m   as the one computing g z  m     g f   kb  f   kb    m    since g is a poly time
function over both inputs  and z is poly size in kb  there exists a representation of g z  m  
as a circuit gkb whose size is polynomial wrt kb  from this construction  m   f  kb iff
gkb  m     f  f  kb   hence  the thesis follows 
the following theorem  instead  gives a simple method to prove that there is no modelpreserving reduction from one formalism to another one 

theorem   let f  and f  be two pkr formalisms  if the polynomial hierarchy does not
collapse  f  is model c   hard  f  is in model c    and c   c    then there is no poly size
reduction f   f    f  satisfying model preservation 
proof  we show that if such a reduction exists  then c   poly  c   poly which implies that
the polynomial hierarchy collapses at some level  yap         let a be a complete problem
for class c   e g   if c  is p  then a may be validity of  quantified boolean formulae
 stockmeyer         define the problem a as follows 
a    hx  yi   x     the empty string  and y  a 
  

fispace efficiency of propositional knowledge representation formalisms

we already proved  cadoli et al       b  thm     that a is k c   complete  since model
checking in f  is model c   hard  a is non uniformly comp reducible to model checking in
f    that is   adapting def     there exist two poly size binary functions f  and f    and
a polynomial time binary function g such that for every pair h  yi  it holds h  yi  a if
and only if g f      y    y    f  f      y    let  y    n  clearly  the knowledge base f      y  
depends only on n  i e   there is exactly one knowledge base for each integer  call it kbn  
moreover  f      y     f     n  also depends on n only  call it on  for oracle   observe that
both kbn and on have polynomial size with respect to n 
if there exists a poly size reduction f   f    f  satisfying model preservation  then given
the knowledge base kbn there exists a poly size circuit hn such that g on   y    f  kbn if
and only if hn  g on   y     f  f  kbn   
therefore  the k c   complete problem a can be non uniformly reduced to a problem
in k c  as follows  given y  from its size  y    n one obtains  with a preprocessing 
f  kbn   and on   then one checks whether the interpretation hn  g on   y    computable in
polynomial time given n  y and on   is a model in f  for f  kbn    from the fact that model
checking in f  is in k c    we have that k c   k c    we proved in a previous paper
that such result implies that c   poly  c   poly  cadoli et al       b  thm      which in
turns implies that the polynomial hierarchy collapses  yap        
the above theorems show that the hierarchy of classes model c exactly characterizes
the space efficiency of a formalism in representing sets of models  in fact  two formalisms
at the same level in the model hierarchy can be reduced into each other via a poly size
reduction  theorem     while there is no poly size reduction from a formalism  f    higher
up in the hierarchy into one  f    in a lower class  theorem     in the latter case we say
that f  is more space efficient than f   
analogous results  with similar proofs  hold for poly size reductions preserving theorems 
namely  the next theorem shows how to infer the existence of theorem preserving reductions 
while the other one gives a way to prove that there is no theorem preserving reduction from
one formalism to another one 
theorem   let f  and f  be two pkr formalisms  if f  is in thm c and f  is thm chard  then there exists a poly size reduction f   f    f  satisfying theorem preservation 
proof  recall that since f  is in thm c  inference in f  is in k c  and since f  is thm chard  inference in f  is non uniformly comp reducible to inference in f    that is   adapting
def     there exist two poly size binary functions f  and f    and a polynomial time binary
function g  such that for every pair hkb  i it holds that
kb  f   if and only if f   kb       f  g f   kb        
 here we distinguish the poly time function g appearing in def    and the poly size circuit
gkb appearing in def     
using theorem   we can replace    with an upper bound in the above formula  from
assumption    we know that the size of  is less than or equal to the size of kb  therefore
we replace    with  kb   the above formula now becomes
kb  f   if and only if f   kb   kb    f  g f   kb   kb     
  

ficadoli  donini  liberatore    schaerf

define the reduction f as f  kb    f   kb  f   kb    where f  is the poly size function
that computes the size of its input  since poly size functions are closed under composition 
f is poly size 
now  we show that f is a theorem preserving reduction  i e  f satisfies def     this
amounts to proving that for each knowledge base kb in f  there exists a circuit gkb  
whose size is poynomial wrt kb  such that for every formula  on the variables of kb it
holds that kb  f   iff f  kb   f  gkb    
we proceed as in the proof of theorem    given a kb in f    let z   f   kb  f   kb   
since f  and f  are poly size  z has polynomial size with respect to  kb   define gkb     
g z      g f   kb  f   kb       clearly  gkb can be represented by a circuit of polynomial
size wrt kb  from this construction  kb  f   iff f  kb   f  gkb     hence  the claim
follows 
theorem   let f  and f  be two pkr formalisms  if the polynomial hierarchy does not
collapse  f  is thm c   hard  f  is in thm c    and c   c    then there is no poly size
reduction f   f    f  satisfying theorem preservation 
proof  we show that if such a reduction exists  then c   poly  c   poly and the polynomial
hierarchy collapses at some level  yap         let a be a complete problem for class c   
define the problem a as in the proof of theorem    this problem is k c   complete  cadoli
et al       b  thm      since inference in f  is thm c   hard  a is non uniformly compreducible to inference in f    that is   adapting def     there exist two poly size binary
functions f  and f    and a polynomial time binary function g such that for every pair h  yi 
h  yi  a if and only if f      y    f  g f      y    y   let  y    n  clearly  the knowledge
base f      y   depends just on n  i e   there is one knowledge base for each integer  call
it kbn   moreover  also f      y     f     n  depends just on n  call it on  for oracle  
observe that both kbn and on have polynomial size with respect to n 
if there exists a poly size reduction f   f    f  satisfying theorem preservation  then
given the knowledge base kbn there exists a poly time function hn such that kbn  f 
g on   y  if and only if f  kbn    f  hn  g on   y   
therefore  the k c   complete problem a can be non uniformly reduced to a problem in
k c  as follows  given y  from its size  y    n one obtains  with an arbitrary preprocessing 
f  kbn   and on   then one checks whether the formula hn  g on   y    computable in polytime given y and on   is a theorem in f  of f  kbn    from the fact that inference in f  is
in k c    we have that k c   k c    it follows that c   poly  c   poly  cadoli et al  
    b  thm      which implies that the polynomial hierarchy collapses  yap        
theorems     show that compilability classes characterize very precisely the relative
capability of pkr formalisms to represent sets of models or sets of theorems  for example 
as a consequence of theorems   and   there is no poly size reduction from pl to the
syntactic restriction of pl allowing only horn clauses that preserves the theorems  unless
the polynomial hierarchy collapses  kautz and selman        proved non existence of such
a reduction for a problem strictly related to pli using a specific proof 

  

fispace efficiency of propositional knowledge representation formalisms

   applications
this section is devoted to the application of the theorems presented in the previous section 
using theorems     and results previously known from the literature  we are able to asses
model  and theorem compactness of some pkr formalisms 
we assume that definitions of propositional logic  default logic  reiter         and
circumscription  mccarthy        are known  definitions of widtio  sbr  gcwa  and
stable model semantics are in the appropriate subsections 
in the following proofs we refer to the problem  qbf  that is  the problem of verifying
whether a quantified boolean formula xy f is valid  where x and y are disjoint sets of
variables  and f is a set of clauses on the alphabet x  y   each composed of three literals 
as an example  a simple formula belonging to this class is  x    x  y    y    x   y    
 x   x   y      y   x   y      x   x     
the problem of deciding validity of a  qbf is complete for the class p    as a consequence  the corresponding problem  qbf  that is deciding whether an input composed
of any string    as the fixed part and a quantified boolean formula xy f as the varying
one  is complete for the class k  p  liberatore         notice that in most of the hardness
proofs we show in the sequel we use problems without any meaningful fixed part 
    stable model semantics
stable model semantics  sm  was introduced by gelfond and lifschitz        as a tool to
provide a semantics for logic programs with negation  their original proposal is now one
of the standard semantics for logic programs  we now recall the definition of propositional
stable model 
let p be a propositional  general logic program  let m be a subset  i e   an interpretation  of the atoms of p   let p m be the program obtained from p in the following way  if a
clause c of p contains in its body a negated atom a such that a  m then c is deleted 
if a body of a clause contains a negated atom a such that a   m then a is deleted from
the body of the clause  if m is a least herbrand model of p m then m is a stable model of
p 
for the formalism sm  we consider the program p as the knowledge base  we write
p   sm q to denote that query q is implied by a logic program p under stable model
semantics 
in order to prove our result  we need to define the kernel of a graph 
definition     kernel  let g    v  e  be a graph  a kernel of g is a set k  v such
that  denoting h   v  k  it holds 
   h is a vertex cover of g
   for all j  h  there exists an i  k such that  i  j   e 
we can now state the theorem on the compilability class of inference in the stable model
semantics  and the corresponding theorem compactness class 
theorem   the problem of inference for the stable model semantics is k conp complete 
thus stable model semantics is thm conpcomplete 
  

ficadoli  donini  liberatore    schaerf

proof  membership in the class follows from the fact that the problem is conp complete
 marek   truszczynski         for the hardness  we adapt the proof of marek and
truszczynski        showing that deciding whether a query is true in all stable models
is conp hard 
let kernel be the language    g  such that g is a graph with at least one kernel 
let  g    n  and observe that g cannot have more vertices than its size n 
we show that for each n  there exists a logic program pn such that for every graph g
with at most n vertices  there exists a query qg such that g has a kernel iff pn    sm qg  
let the alphabet of pn be composed by the following  n    n propositional letters 
 ai  i      n      rij   sij  i  j      n    
the program pn is defined as 
aj
sij
rij

 
 
 



ai   rij 

rij
for i  j      n 


sij

given a graph g    v  e   the query qg is defined as
qg    

 

 i j e

rij     

 

rij  

 i j  e

the reduction from kernel to sm is defined as  f   x  n    pn   i e   f  depends only on
its second argument  f   x  n      i e   f  is a constant function  and g   qy   i e   given a
graph g  the circuit g computes the query qg  
as a result  this is a k  reduction  we now show that this reduction is correct  i e  
h  gi  kernel  g has a kernel  iff pn    sm qg  
if part  suppose pn    sm qg   then  there exists a stable model m of pn such that
m    qg   observe that qg is equivalent to the conjunction of all rij such that  i  j   e 
and all rij such that  i  j    e  simplifying pn with qg we obtain the clauses 
aj   ai   for  i  j   e

   

observe that m contains all sij such that  i  j    e  and in order to be stable   i e   to
support atoms rij such that  i  j   e  m contains no atom sij such that  i  j   e 
let h    j aj  m    k    i ai   m    now h is a vertex cover of g  since for each
edge  i  j   e  m should satisfy the corresponding clause     aj    ai   hence either
ai  m   or aj  m   moreover  for each j in h  the atom aj is in m   and since m is a
stable model  there exists a clause aj   ai such that ai   m   that is  i  k  therefore 
k is a kernel of g 
only if part  suppose g    v  e  has a kernel k  and let h   v  k  let m be the
interpretation
m    rij   i  j   e    sij   i  j    e    aj  j  h 

obviously  m     qg   we now show that m is a stable model of pn   i e   m is a least
herbrand model of pnm   in fact  pnm contains the following clauses 
sij
rij
aj

  rij

for  i  j    e

   

for i  k

   

for  i  j   e

  

   

fispace efficiency of propositional knowledge representation formalisms

clauses in the last line are obtained from clauses in pn of the form aj   ai   rij   where the
clauses such that i  h  hence ai  m   are deleted  while in the other clauses the negated
atom ai is deleted  since i  k  hence ai   m   now for each aj  m   the vertex j is in h 
hence there is an edge  i  j   e  and i  k  hence clauses     and     are in pnm   hence in
the least herbrand model of pnm there are exactly all aj such that j  h 
    minimal model reasoning
one of the most successful form of non monotonic reasoning is based on the selection of
minimal models  among the various formalisms based on minimal model semantics we consider here circumscription  mccarthy        and the generalized closed world assumption
 gcwa   minker         which is a formalism to represent knowledge in a closed world 
we assume that the reader is familiar with circumscription  we briefly present the
definition of gcwa  the model semantics for gcwa is defined as  a is a letter  
m   gcw a kb iff m    kb a   for any positive clause   if kb     then kb      a 
we can now present the results for these two formalisms 
theorem   the problem of model checking for circumscription is k conp complete  thus
circumscription is model conp complete 
this result is a trivial corollary of a theorem already proved  cadoli et al         theorem     in fact  that proof implicitly shows that model checking for circumscription is
k conp complete 
theorem    the problem of model checking for gcwa is in k p  thus gcwa is in
model p 
proof  as already pointed out  cadoli et al          it is possible to rewrite gcw a t  
into a propositional formula f such that  for any given model m   m    gcw a t   if and
only if m    f   moreover  the size of f is polynomially bounded by the size of t   as a
consequence  the model compactness for gcwa is in the same class of pl  by theorem  
the thesis follows 
theorem    the problem of inference for circumscription is k p   complete  thus circumscription is thm p   complete 
this result is a trivial corollary of a theorem published in a previous paper  cadoli
et al         theorem    which implicitly shows that inference for circumscription is k  p complete 
theorem    the problem of inference for gcwa is k conp complete  thus gcwa is
thm conp complete 
proof  as already pointed out in the proof of theorem     it is possible to rewrite
gcw a t   into a formula f that is equivalent to it  as a consequence  a formula  is
a theorem of gcw a t   if and only if it is a theorem of f   thus  gcwa has at most the
theorem compexity of pl  since gcwa is a generalization of pl  it follows that gcwa is
in the same theorem compactness class of pl  hence  gcwa is thm conp complete 
  

ficadoli  donini  liberatore    schaerf

    default logic
in this subsection we present the results for default logic  in its two variants  credulous
and skeptical   for more details on these two main variants of default logic  we refer the
reader to the paper by kautz and selman         notice that model compactness is only
applicable to skeptical default logic 
theorem    the problem of model checking for skeptical default logic is k p  complete 
thus skeptical default logic is model p  complete 
proof  the proof of membership is straightforward  since model checking for skeptical
default logic is in p   liberatore   schaerf         it follows that it is also in k p   
the proof of k p   hardness is similar to the proof of p   hardness  liberatore   schaerf 
       the reduction is from the problem  qbf  let h  i be an instance of  qbf 
where    xy f represents a valid  qbf formula  and  is any string 
let n be the size of the formula f   this implies that the variables in the formula are at
most n  let                 k   be the set of all the clauses of three literals over this alphabet 
the number of clauses of three literals over an alphabet of n variables is less than o n    
thus bounded by a polynomial in n 
we prove that xy f is valid if and only if m is a model of some extension of hw  di 
where
  

w

d  

     ci

i 

ci

  ci
 
ci

   ci   i  f  

m





     w   w  xi     w   w  xi   

 

w  xi

xi x

w  xi



 

 w

v

i  ci

w

 i

the set  ci      i  k  is a set of new variables  one to one with the elements of  
note that w and d only depends on the size n of f   while m depends on f   as a result 
this is a nucomp reduction 
we now prove that the formula is valid if and only if m is a model of some extension
of the default theory hw  di  this is similar to an already published proof  liberatore  
schaerf         consider an evaluation c  of the variables  ci   and an evaluation x  of the
variables x  let d  be the following set of defaults 
 

d  

     ci       ci 

ci c 

ci

ci  c 

ci



     w   w  xi   

w  xi

xi x 

 

xi x 



  w   w  xi  
w  xi



this set of defaults has been chosen so that the set r of its consequences corresponds
to the sets c  and x    namely  we have 
ci  c  iff r    ci

ci   c  iff r    ci

xi  x  iff r    w  xi

xi   x  iff r    w  xi
  

 

fispace efficiency of propositional knowledge representation formalisms

now  we prove that the consequences of this set of defaults are an extension of the
default theory if and only if the qbf formula is valid  since all defaults are semi normal 
we have to prove that 
   the set of consequences of d  is consistent  and
   no other default is applicable  that is  there is no other default whose precondition is
consistent with r 
consistency of r follows by construction  assigning ci to true for each ci  c    etc   we
obtain a model of r 
 ci
we have then to prove that no other default is applicable  if ci  c    the default c
i
 ci
is not applicable  and vice versa  if ci  c    then ci is not applicable  moreover  none

i 
  is applicable if xi   x    because in this case w  xi  r  thus
of the defaults  w wx
wxi
w would follow  while w is a justification of the default   a similar statement holds for
 w wxi  
if xi  x   
wxi

v

 w

ci i

i 
as a result  the only applicable default may be the last one 
 recall that
w
f is negated   this default is applicable if and only if  for the given evaluation of the ci s
and xi s  the set of clauses is satisfiable  this amount to say  there is an extension in
which the last default is not applicable if and only if the qbf formula is valid  now 
if the last default is applicable  then m is not a model of the extension because w is the
consequence of the last default while w     m   the converse also holds  if the last default is
not applicable then m is a model of the default theory 
as a result  the qbf is valid if and only if m is a model of the given default theory 

theorem    the inference problem for skeptical default logic is k p  complete  thus skeptical default logic is thm  p complete 
proof  since inference in skeptical default logic is in p    it is also in k p    k p   hardness
comes from a simple reduction from circumscription  indeed  the circumscription of a
formula t is equivalent to the conjunction of the extensions of the default theory ht  di 
where  etherington        
d 

     xi 

xi

as a result  circ t      q if and only if q is implied by ht  di under skeptical semantics  since ht  di only depends on t  and not on q  this is a nucomp reduction  since
inference for circumscription is k  p  complete  see theorem      it follows that skeptical
default logic is k  p  hard 
theorem    the inference problem for credulous default logic is k p  complete  thus
credulous default logic is thm p  complete 

  

ficadoli  donini  liberatore    schaerf

proof  the proof is very similar to the proof for model checking of skeptical default logic 
indeed  both problems are k p  complete  since the problem is in p    as proved by gottlob
        it is also in k p    thus  what we have to prove is that is hard for that class 
we prove that the  qbf problem can be reduced to the problem of verifying whether
a formula is implied by some extensions of a default theory  that is  inference in credulous
default logic  
namely  a formula xy f is valid if and only if q is derived by some extension of
the default theory hd  w i  where w and d are defined as follows   is the set of all the
clauses of three literals over the alphabet of f   and c is a set of new variables  one to one
with   
w

  

d  

     ci

ci

ci c

q  

 

i f

ci 

  ci
 
ci

 

i  f





     xi

xi x

xi

  xi
 
xi





 

v

 

ci c ci

w

 i    

 

ci  w

informally  the proof goes as follows  for each truth evaluation of the variables in c
and x there is a set of defaults which are both justified and consistent  a simple necessary
and sufficient condition for the consequences of this set of defaults to be an extension is the
following  if  in this evaluation  the formula


 

i

ci  true

is valid  then the last default is applicable  thus the extension also contains w  the converse
also holds  if the formula is not valid in the evaluation  then the variable w is not in the
extension 
as a result  there exists an extension in which q holds if and only if there exists an
extension in which each ci is true if and only if i  f   and such that w also holds  when
the variables ci have the given value  the above formula is equivalent to f   as a result 
such an extension exists if and only if there exists a truth evaluation of the variables x in
which f is valid 
    belief revision
many formalisms for belief revision have been proposed in the literature  here we focus on
two of them  widtio  when in doubt throw it out  and sbr  skeptical belief revision  
let k be a set of propositional formulae  representing an agents knowledge about the world 
when a new formula a is added to k  the problem of the possible inconsistency between k
and a arises  the first step is to define the set of sets of formulae w  k  a  in the following
way 
w  k  a     k   k   is a maximal consistent subset of k   a  containing a  
  

fispace efficiency of propositional knowledge representation formalisms

any set of formulae k    w  k  a  is a maximal choice of formulae in k that are
consistent with a and  therefore  we may retain when incorporating a  the definition of
this set leads to two different revision operators  sbr and widtio 
sbr skeptical belief revision  fagin  ullman    vardi        ginsberg         the revised
 
theory is defined as a set of theories  k  a    k     k    w  k  a    inference in the
revised theory is defined as inference in each of the theories 
k  a  sbr q iff

for all k    w  k  a    we have that k     q

the model semantics is defined as 
m   sbr k  a iff

there exists a k    w  k  a  such that m    k  

widtio when in doubt throw it out  winslett         a simpler  but somewhat
drastical  approach is the so called widtio  where we retain only the formulae of k
that belong to all sets of w  k  a   thus  inference is defined as 
k  a  w idt io q iff

t

w  k  a    q

the model semantics of this formalism is defined as 
m   w idt io k  a

iff

m   

 

w  k  a 

the results on model compactness have been shown by liberatore and schaerf        
here we recall them 
theorem     liberatore   schaerf        theorem     the problem of model checking for widtio is in k p  thus widtio is in model p 
theorem     liberatore   schaerf        theorem    the problem of model checking for skeptical belief revision is k conp complete  thus skeptical belief revision is
model conp complete 
the results on theorem compactness are quite simple and we provide here the proofs 
theorem    the problem of inference for widtio is k conp complete  thus widtio
is thm conp complete 
proof  membership in the class thm conp immediately follows from the definition  in fact 
we can rewrite k  a into a propositional formula by computing the set w  k  a  and then
constructing their intersection  by construction their intersection has size less than or equal
to the size of k  a  as a consequence  after preprocessing  deciding whether a formula q
follows from k  a is a problem in conp  hardness follows from the obvious fact that pl
can be reduced to widtio and pl is thm conp complete  see theorem    
theorem    the problem of inference for skeptical belief revision is k p   complete 
thus skeptical belief revision is thm p   complete 
  

ficadoli  donini  liberatore    schaerf

propositional
logic
widtio
skeptical
belief revision
circumscription
gcwa

skeptical
default reasoning
credulous
default reasoning
stable model
semantics

time complexity
p

p   complete
 liberatore   schaerf       
conp complete
 liberatore   schaerf       
conp complete
 cadoli       
conp hard 
in p   log n 
 eiter   gottlob       
p   complete
 liberatore   schaerf       
n a

space efficiency
model p

model p
th    
model conp complete
th    
model conp complete
th   
model p
th    

p


model p


model p   complete
th    
n a

table    complexity of model checking and space efficiency of model representations
proof  membership follows from the complexity results of eiter and gottlob         where
they show that deciding whether k  a  sbr q is a p   complete problem  hardness
follows easily from theorem     in fact  m   sbr k  a iff k  a   sbr f orm m    where
f orm m   is the formula that represents the model m   as a consequence  model checking
can be reduced to the complement of inference  thus inference is k p   complete 
    discussion
tables   and   summarize the results on space efficiency of pkr formalisms and where they
were proved  a dash  denotes a folklore result  
first of all  notice that space efficiency is not always related to time complexity  as an
example  we compare in detail widtio and circumscription  from the table it follows that
model checking is harder for widtio than for circumscription  and that inference has the
same complexity in both cases  nevertheless  since circumscription is thm p   complete and
widtio is thm conp complete  and thus in thm p     there exists a poly size reduction
from widtio to circumscription satisfying theorem preservation  the converse does not
hold  since circumscription is thm  p  complete and widtio is thm conp  unless the polynomial hierarchy does not collapse there is no theorem preserving poly size reduction from
the former formalism to the latter  hence  circumscription is a more compact formalism
than widtio to represent theorems  analogous considerations can be done for models 
intuitively  this is due to the fact that for widtio both model checking and inference
require a lot of work on the revised knowledge base alonecomputing the intersection of

  

fispace efficiency of propositional knowledge representation formalisms

propositional
logic
widtio
skeptical
belief revision
circumscription
gcwa
skeptical
default reasoning
credulous
default reasoning
stable model
semantics

time complexity
conp complete
 cook       
p   complete
 eiter   gottlob           nebel       
p   complete
 eiter   gottlob       
p   complete
 eiter   gottlob       
p   complete
 eiter   gottlob           nebel       
p   complete
 gottlob       
p   complete
 gottlob       
conp complete
 marek   truszczynski       

space efficiency
thm conp complete
 cadoli et al        
thm conp complete
th    
thm p   complete
th    
thm p   complete
th    
thm conp complete
th    
thm p   complete
th    
thm p   complete
th    
thm conp complete
th   

table    complexity of inference and space efficiency of theorem representations
all elements of w  k  a   once this is done  one is left with model checking and inference in
pl  hence  widtio has the same space efficiency as pl  which is below circumscription 
figures   and   contain the same information of tables   and    but highlight existing reductions  each figure contains two diagrams  the left one showing the existence of
polynomial time reductions among formalisms  the right one showing the existence of polysize reductions  an arrow from a formalism to another denotes that the former can be
reduced to the latter one  we use a bidirectional arrow to denote arrows in both directions
and a dashed box to enclose formalisms that can be reduced one into another  note that
some formalisms are more appropriate in representing sets of models  while others perform
better on sets of formulae  an interesting relation exists between skeptical default reasoning
and circumscription  while there is no model preserving poly size reduction from circumscription to skeptical default reasoning  gogic et al          a theorem preserving poly size
reduction exists  as shown by theorem    

   related work and conclusions
the idea of comparing the compactness of kr formalisms in representing information is not
novel in ai  it is well known that first order circumscription can be represented in secondorder logic  schlipf         kolaitis and papadimitriou        discuss several computational
aspects of circumscription  among many interesting results they show a reduction from a
restricted form of first order circumscription into first order logic  the proposed reduction
will increase the size of the original formula by an exponential factor  it is left as an open
problem to show whether this increase is intrinsic  because of the different compactness
properties of the two formalisms  or there exists a more space efficient reduction  when a

  

ficadoli  donini  liberatore    schaerf

  skeptical

widtio 

default

skeptical default

 

 

gcwa
 

sbr    circumscription

sbr    circumscription

 

 

 

pl    stable model

pl    widtio 

a  time complexity

  gcwa    stable
model

b  space efficiency

figure    complexity of model checking vs  space efficiency of model representation

widtio   gcwa

 

 
skeptical
sbr    circum    default
s
o
s
pl  

credulous
default



sbr   circum 



skeptical
default

ak
a

stable
model

credulous
default






stable
pl  widtio   gcwa   model

a  time complexity

b  space efficiency

figure    complexity of inference vs  space efficiency of theorem representation

  

fispace efficiency of propositional knowledge representation formalisms

first order language is used  more results on compactness and existence of reductions are
reported by schlipf        
khardon and roth               and kautz  kearns and selman        propose modelbased representations of a kb in propositional logic  and compare it with formula based
representations  although their results are significant for comparing representations within
pl  they refer only to this formalism  hence they are not applicable to our comparison between different pkr formalisms  the same comment applies also to the idea of representing
a kb with an efficient basis by moses and tennenholz         since it refers only to one
pkr formalism  namely  pl 
an active area of research studies the connections of the various non monotonic logics 
in particular  there are several papers discussing the existence of translations that are polynomial in time and satisfy other intuitive requirements such as modularity and faithfulness 
janhunen         improving on results of imielinski        and gottlob         shows that
default logic is the most expressive  among the non monotonic logics examined  since both
circumscription and autoepistemic logic can be modularly and faithfully embedded in default logic  but not the other way around  while these results are of interest and help to
fully understand the relation among many knowledge representation formalisms  they are
not directly related to ours  in fact  we allow for translations that are more general than
polynomial time  while in all of the above papers they only consider translations that use
polynomial time and also satisfy additional requirements 
the first result on compactness of representations for a propositional language is presented  to the best of our knowledge  by kautz and selman         they show that  unless
there is a collapse in the polynomial hierarchy  the size of the smallest representation of
the least horn upper bound of a propositional theory is superpolynomial in the size of the
original theory  these results are also presented in a different form in the more comprehensive paper  selman   kautz         the technique used in the proof has been then
used by us and other researchers to prove several other results on the relative complexity of
propositional knowledge representation formalisms  cadoli et al                     gogic
et al         
in a recent paper  cadoli et al       b  we introduced a new complexity measure  i e  
compilability  in this paper we have shown how this measure is inherently related to the
succinctness of pkr formalisms  we analyzed pkr formalisms with respect to two succinctness measures  succinctness in representing sets of models and succinctness in representing
sets of theorems 
the main advantage of our framework is the machinery necessary for a formal way of
talking about the relative ability of pkr formalisms to compactly represent information  in
particular  we were able to formalize the intuition that a specific pkr formalism provides
one of the most compact ways to represent models theorems among the pkr formalisms
of a specific class 
in our opinion  the proposed framework improves over the state of the art in two different
aspects 
   all the proofs presented in the previous papers only compare pairs of pkr formalisms  for example propositional circumscription and propositional logic  cadoli
et al          these results do not allow for a precise classification of the level of
  

ficadoli  donini  liberatore    schaerf

compactness of the considered formalisms  rephrasing and adapting these results
in our framework allows us to infer that circumscription is model conp complete and
thm p   complete  as a consequence  we also have that it is more space efficient of the
widtio belief revision formalism in representing sets of models or sets of theorems 
   using the proposed framework it is now possible to find criteria for adapting existent
polynomial reductions showing c hardness into reductions that show model c or thmc hardness  where c is a class in the polynomial hierarchy  liberatore        

acknowledgments
this paper is an extended and revised version of a paper by the same authors appeared
in the proceedings of the fifth international conference on the principles of knowledge representation and reasoning  kr     cadoli  donini  liberatore    schaerf      a   partial
supported has been given by asi  italian space agency  and cnr  national research
council of italy  

references
ben eliyahu  r     dechter  r          default logic  propositional logic and constraints 
in proceedings of the ninth national conference on artificial intelligence  aaai    
pp         
ben eliyahu  r     dechter  r          propositional semantics for disjunctive logic programs  annals of mathematics and artificial intelligence           
boppana  r     sipser  m          the complexity of finite functions  in van leeuwen  j 
 ed    handbook of theoretical computer science  vol  a  chap      elsevier science
publishers  north holland   amsterdam 
cadoli  m          the complexity of model checking for circumscriptive formulae  information processing letters             
cadoli  m   donini  f   liberatore  p     schaerf  m       a   comparing space efficiency
of propositional knowledge representation formalisms  in proceedings of the fifth international conference on the principles of knowledge representation and reasoning
 kr     pp         
cadoli  m   donini  f  m   liberatore  p     schaerf  m       b   feasibility and unfeasibility of off line processing  in proceedings of the fourth israeli symposium on theory
of computing and systems  istcs     pp          ieee computer society press 
url   ftp   ftp dis uniroma  it pub ai papers cado etal    ps gz 
cadoli  m   donini  f  m   liberatore  p     schaerf  m         
preprocessing of intractable problems 
tech  rep  dis        dipartimento di
url  
informatica e sistemistica  universita di roma la sapienza 
http   ftp dis uniroma  it pub ai papers cado etal    d revised ps gz 
  

fispace efficiency of propositional knowledge representation formalisms

cadoli  m   donini  f  m   liberatore  p     schaerf  m          the size of a revised
knowledge base  artificial intelligence                
cadoli  m   donini  f  m     schaerf  m          on compact representations of propositional circumscription  in proceedings of the twelfth symposium on theoretical aspects of computer science  stacs     pp          extended version as rap      
dis  univ  of roma la sapienza  july      
cadoli  m   donini  f  m     schaerf  m          is intractability of non monotonic reasoning
a real drawback   artificial intelligence                  
cadoli  m   donini  f  m   schaerf  m     silvestri  r          on compact representations
of propositional circumscription  theoretical computer science              
cook  s  a          the complexity of theorem proving procedures  in proceedings of the
third acm symposium on theory of computing  stoc     pp         
eiter  t     gottlob  g          on the complexity of propositional knowledge base revision 
updates and counterfactuals  artificial intelligence             
eiter  t     gottlob  g          propositional circumscription and extended closed world
reasoning are  p  complete  theoretical computer science              
etherington  d  v          reasoning with incomplete information  morgan kaufmann 
los altos  los altos  ca 
fagin  r   ullman  j  d     vardi  m  y          on the semantics of updates in databases 
in proceedings of the second acm sigact sigmod symposium on principles of
database systems  pods     pp         
garey  m  r     johnson  d  s          computers and intractability  a guide to the
theory of np completeness  w h  freeman and company  san francisco  ca 
gelfond  m     lifschitz  v          the stable model semantics for logic programming 
in proceedings of the fifth logic programming symposium  pp            the mit
press 
gelfond  m   przymusinska  h     przymusinsky  t          on the relationship between
circumscription and negation as failure  artificial intelligence           
ginsberg  m  l          conterfactuals  artificial intelligence           
gogic  g   kautz  h  a   papadimitriou  c     selman  b          the comparative linguistics of knowledge representation  in proceedings of the fourteenth international
joint conference on artificial intelligence  ijcai     pp         
gottlob  g          complexity results for nonmonotonic logics  journal of logic and
computation            
gottlob  g          translating default logic into standard autoepistemic logic  journal of
the acm             
  

ficadoli  donini  liberatore    schaerf

imielinski  t          results on translating defaults to circumscription  artificial intelligence             
janhunen  t          on the intertranslatability of autoepistemic  default and priority
logics  and parallel circumscription  in proceedings of the sixth european workshop
on logics in artificial intelligence  jelia     no       in lecture notes in artificial
intelligence  pp          springer verlag 
johnson  d  s          a catalog of complexity classes  in van leeuwen  j   ed    handbook
of theoretical computer science  vol  a  chap     elsevier science publishers  northholland   amsterdam 
karp  r  m     lipton  r  j          some connections between non uniform and uniform
complexity classes  in proceedings of the twelfth acm symposium on theory of
computing  stoc     pp         
kautz  h  a   kearns  m  j     selman  b          horn approximations of empirical data 
artificial intelligence             
kautz  h  a     selman  b          hard problems for simple default logics  artificial
intelligence             
kautz  h  a     selman  b          forming concepts for fast inference  in proceedings of
the tenth national conference on artificial intelligence  aaai     pp         
khardon  r     roth  d          reasoning with models  artificial intelligence         
    
khardon  r     roth  d          defaults and relevance in model based reasoning  artificial
intelligence             
kobler  j     watanabe  o          new collapse consequences of np having small circuits 
siam journal on computing                 
kolaitis  p  g     papadimitriou  c  h          some computational aspects of circumscription  journal of the acm              
liberatore  p          compact representation of revision of horn clauses  in yao  x   ed   
proceedings of the eighth australian joint artificial intelligence conference  ai    
pp          world scientific 
liberatore  p          compilation of intractable problems and its application to artificial
intelligence 
ph d 
thesis 
dipartimento di informatica e sistemistica  universita di roma la sapienza  url  
ftp   ftp dis uniroma  it pub ai papers libe    c ps gz 
liberatore  p     schaerf  m          the complexity of model checking for belief revision and update  in proceedings of the thirteenth national conference on artificial
intelligence  aaai     pp         

  

fispace efficiency of propositional knowledge representation formalisms

liberatore  p     schaerf  m          the complexity of model checking for propositional
default logics  in proceedings of the thirteenth european conference on artificial
intelligence  ecai     pp       
liberatore  p     schaerf  m          the compactness of belief revision and update operators  tech  rep   dipartimento di informatica e sistemistica  universita di roma la
sapienza 
marek  w     truszczynski  m          autoepistemic logic  journal of the acm         
       
mccarthy  j          circumscription   a form of non monotonic reasoning  artificial
intelligence           
minker  j          on indefinite databases and the closed world assumption  in proceedings
of the sixth international conference on automated deduction  cade     pp     
    
moses  y     tennenholtz  m          off line reasoning for on line efficiency  knowledge
bases  artificial intelligence             
nebel  b          how hard is it to revise a belief base   in dubois  d     prade  h   eds   
belief change   handbook of defeasible reasoning and uncertainty management systems  vol     kluwer academic 
reiter  r          a logic for default reasoning  artificial intelligence            
schlipf  j  s          decidability and definability with circumscription  annals of pure
and applied logic             
schlipf  j  s          a survey of complexity and undecidability results for logic programming  annals of mathematics and artificial intelligence             
selman  b     kautz  h  a          knowledge compilation and theory approximation 
journal of the acm             
stockmeyer  l  j          the polynomial time hierarchy  theoretical computer science 
       
winslett  m          sometimes updates are circumscription  in proceedings of the eleventh
international joint conference on artificial intelligence  ijcai     pp         
winslett  m          updating logical databases  cambridge university press 
yap  c  k          some consequences of non uniform conditions on uniform classes  theoretical computer science             

  

fi