journal of artificial intelligence research                  

submitted       published      

ais bn  an adaptive importance sampling algorithm for
evidential reasoning in large bayesian networks
jian cheng
marek j  druzdzel

jcheng sis pitt edu
marek sis pitt edu

decision systems laboratory
school of information sciences and intelligent systems program
university of pittsburgh  pittsburgh  pa       usa

abstract
stochastic sampling algorithms  while an attractive alternative to exact algorithms in
very large bayesian network models  have been observed to perform poorly in evidential
reasoning with extremely unlikely evidence  to address this problem  we propose an adaptive importance sampling algorithm  ais bn  that shows promising convergence rates
even under extreme conditions and seems to outperform the existing sampling algorithms
consistently  three sources of this performance improvement are     two heuristics for
initialization of the importance function that are based on the theoretical properties of importance sampling in finite dimensional integrals and the structural advantages of bayesian
networks      a smooth learning method for the importance function  and     a dynamic
weighting function for combining samples from different stages of the algorithm 
we tested the performance of the ais bn algorithm along with two state of the art
general purpose sampling algorithms  likelihood weighting  fung   chang        shachter
  peot        and self importance sampling  shachter   peot         we used in our
tests three large real bayesian network models available to the scientific community  the
cpcs network  pradhan et al          the pathfinder network  heckerman  horvitz 
  nathwani         and the andes network  conati  gertner  vanlehn    druzdzel 
       with evidence as unlikely as        while the ais bn algorithm always performed
better than the other two algorithms  in the majority of the test cases it achieved orders of
magnitude improvement in precision of the results  improvement in speed given a desired
precision is even more dramatic  although we are unable to report numerical results here 
as the other algorithms almost never achieved the precision reached even by the first few
iterations of the ais bn algorithm 

   introduction
bayesian networks  pearl        are increasingly popular tools for modeling uncertainty in
intelligent systems  with practical models reaching the size of several hundreds of variables
 e g   pradhan et al         conati et al          it becomes increasingly important to address the problem of feasibility of probabilistic inference  even though several ingenious
exact algorithms have been proposed  in very large models they all stumble on the theoretically demonstrated np hardness of inference  cooper         the significance of this
result can be observed in practice  exact algorithms applied to large  densely connected
practical networks require either a prohibitive amount of memory or a prohibitive amount
of computation and are unable to complete  while approximating inference to any desired
precision has been shown to be np hard as well  dagum   luby         it is for very comc
    
ai access foundation and morgan kaufmann publishers  all rights reserved 

ficheng   druzdzel

plex networks the only alternative that will produce any result at all  furthermore  while
obtaining the result is crucial in all applications  precision guarantees may not be critical
for some types of problems and can be traded off against the speed of computation 
a prominent subclass of approximate algorithms is the family of stochastic sampling
algorithms  also called stochastic simulation or monte carlo algorithms   the precision
obtained by stochastic sampling generally increases with the number of samples generated
and is fairly unaffected by the network size  execution time is fairly independent of the
topology of the network and is linear in the number of samples  computation can be
interrupted at any time  yielding an anytime property of the algorithms  important in timecritical applications 
while stochastic sampling performs very well in predictive inference  diagnostic reasoning  i e   reasoning from observed evidence nodes to their ancestors in the network often
exhibits poor convergence  when the number of observations increases  especially if these
observations are unlikely a priori  stochastic sampling often fails to converge to reasonable estimates of the posterior probabilities  although this problem has been known since
the very first sampling algorithm was proposed by henrion         little has been done
to address it effectively  furthermore  various sampling algorithms proposed were tested
on simple and small networks  or networks with special topology  without the presence of
extremely unlikely evidence and the practical significance of this problem has been underestimated  given a typical number of samples used in real time that are feasible on
todays hardware  say     samples  the behavior of a stochastic sampling algorithm will be
drastically different for different size networks  while in a network consisting of    nodes
and a few observations  it may be possible to converge to exact probabilities  in very large
networks only a negligibly small fraction of the total sample space will be probed  one of
the practical bayesian network models that we used in our tests  a subset of the cpcs
network  pradhan et al          consists of     nodes  its total sample space is larger than
       with     samples  we can sample only      fraction of the sample space 
we believe that it is crucial     to study the feasibility and convergence properties of
sampling algorithms on very large practical networks  and     to develop sampling algorithms that will show good convergence under extreme  yet practical conditions  such as
evidential reasoning given extremely unlikely evidence  after all  small networks can be
updated using any of the existing exact algorithms  it is precisely the very large networks
where stochastic sampling can be most useful  as to the likelihood of evidence  we know
that stochastic sampling will generally perform well when it is high  henrion         so  it
is important to look at those cases in which evidence is very unlikely  in this paper  we test
two existing state of the art stochastic sampling algorithms for bayesian networks  likelihood weighting  fung   chang        shachter   peot        and self importance sampling
 shachter   peot         on a subset of the cpcs network with extremely unlikely evidence  we show that they both exhibit similarly poor convergence rates  we propose a new
sampling algorithm  that we call the adaptive importance sampling for bayesian networks
 ais bn   which is suitable for evidential reasoning in large multiply connected bayesian
networks  the ais bn algorithm is based on importance sampling  which is a widely
applied method for variance reduction in simulation that has also been applied in bayesian networks  e g   shachter   peot         we demonstrate empirically on three large
practical bayesian network models that the ais bn algorithm consistently outperforms
   

fiadaptive importance sampling in bayesian networks

the other two algorithms  in the majority of the test cases  it achieved over two orders of
magnitude improvement in convergence  improvement in speed given a desired precision
is even more dramatic  although we are unable to report numerical results here  as the
other algorithms never achieved the precision reached even by the first few iterations of
the ais bn algorithm  the main sources of improvement are      two heuristics for the
initialization of the importance function that are based on the theoretical properties of importance sampling in finite dimensional integrals and the structural advantages of bayesian
networks      a smooth learning method for updating the importance function  and     a
dynamic weighting function for combining samples from different stages of the algorithm 
we study the value of the two heuristics used in the ais bn algorithm      initialization
of the probability distributions of parents of evidence nodes to uniform distribution and
    adjusting very small probabilities in the conditional probability tables  and show that
they both play an important role in the ais bn algorithm but only a moderate role in the
existing algorithms 
the remainder of this paper is structured as follows  section   first gives a general
introduction to importance sampling in the domain of finite dimensional integrals  where it
was originally proposed  we show how importance sampling can be used to compute probabilities in bayesian networks and how it can draw additional benefits from the graphical
structure of the network  then we develop a generalized sampling scheme that will aid us
in reviewing the previously proposed sampling algorithms and in describing the ais bn
algorithm  section   describes the ais bn algorithm  we propose two heuristics for initialization of the importance function and discuss their theoretical foundations  we describe
a smooth learning method for the importance function and a dynamic weighting function
for combining samples from different stages of the algorithm  section   describes the empirical evaluation of the ais bn algorithm  finally  section   suggests several possible
improvements to the ais bn algorithm  possible applications of our learning scheme  and
directions for future work 

   importance sampling algorithms for bayesian networks
we feel that it is useful to go back to the theoretical roots of importance sampling in order
to be able to understand the source of speedup of the ais bn algorithm relative to the
existing state of the art importance sampling algorithms for bayesian networks  we first
review the general idea of importance sampling in finite dimensional integrals and how it
can reduce the sampling variance  we then discuss the application of importance sampling
to bayesian networks  readers interested in more details are directed to literature on
monte carlo methods in computation of finite integrals  such as the excellent exposition by
rubinstein        that we are essentially following in the first section 
    mathematical foundations
let g x  be a function of m variables x    x         xm   over a domain   rm   such that
computing g x  for any x is feasible  consider the problem of approximate computation
of the integral
z
i 

g x  dx  


   

   

ficheng   druzdzel

importance sampling approaches this problem by writing the integral     as
z

i 


g x 
f  x  dx  
f  x 

where f  x   often referred to as the importance function  is a probability density function
over   f  x  can be used in importance sampling if there exists an algorithm for generating
samples from f  x  and if the importance function is zero only when the original function
is zero  i e   g x         f  x       
after we have independently sampled n points s    s            sn   si    according to the
probability density function f  x   we can estimate the integral i by
n
 x
g si  
in  
n i   f  si  

   

and estimate the variance of in by
b  in    

 

n
x
 
g si   
 in
n   n     i   f  si  



 

 

   

it is straightforward to show that this estimator has the following properties 
   e in     i
   limn in   i

n
   n   in  i   normal    f  x     where
f  x 


z 

 


g x 
i
f  x 

 

f  x  dx

   



b    in         in     f   x   n
   e 

the variance of in is proportional to f  x  and inversely proportional to the number of
samples  to minimize the variance of in   we can either increase the number of samples or
try to decrease f  x    with respect to the latter  rubinstein        reports the following
useful theorem and corollary 
theorem   the minimum of f  x  is equal to
f  x 

 

z

 g x   dx

 

 i 



and occurs when x is distributed according to the following probability density function
f  x    r

 g x  
 
  g x   dx

   

fiadaptive importance sampling in bayesian networks

corollary   if g x      then the optimal probability density function is
f  x   

g x 
i

and f  x      
although in practice sampling from precisely f  x    g x  i will occur rarely  we expect
that functions that are close enough to it can still reduce the variance effectively  usually 
the closer the shape of the function f  x  is to the shape of the function g x   the smaller
is f  x    in high dimensional integrals  selection of the importance function  f  x   is far
more critical than increasing the number of samples  since the former can dramatically
affect f  x    it seems prudent to put more energy in choosing an importance function
whose shape is as close as possible to that of g x  than to apply the brute force method of
increasing the number of samples 
it is worth noting here that if f  x  is uniform  importance sampling becomes a general
monte carlo sampling  another noteworthy property of importance sampling that can be
derived from equation   is that we should avoid f  x    g x   i  f  x   in any part
of the domain of sampling  even if f  x  matches well g x  i in important regions  if
f  x    g x   i  f  x    the variance can become very large or even infinite  we can
avoid this by adjusting f  x  to be larger in unimportant regions of the domain of x 
while in this section we discussed importance sampling for continuous variables  the
results stated are valid for discrete variables as well  in which case integration should be
substituted by summation 
    a generic importance sampling algorithm for bayesian networks
in the following discussion  all random variables used are multiple valued  discrete variables 
capital letters  such as a  b  or c  denote random variables  bold capital letters  such as
a  b  or c  denote sets of variables  bold capital letter e will usually be used to denote
the set of evidence variables  lower case letters a  b  c denote particular instantiations
of variables a  b  and c respectively  bold lower case letters  such as a  b  c  denote
particular instantiations of sets a  b  and c respectively  bold lower case letter e  in
particular  will be used to denote the observations  i e   instantiations of the set of evidence
variables e  anc a  denotes the set of ancestors of node a  pa a  denotes the set of
parents  direct ancestors  of node a  pa a  denotes a particular instantiation of pa a    
denotes set difference  pa a  e e denotes that we use the extended vertical bar to indicate
substitution of e for e in a 
we know that the joint probability distribution over all variables of a bayesian network model  pr x   is the product of the probability distributions over each of the nodes
conditional on their parents  i e  
pr x   

n
y

pr xi  pa xi     

   

i  

in order to calculate pr e   e   we need to sum over all pr x e  e   e  
pr e   e   

x

pr x e  e   e 

x e

   

   

ficheng   druzdzel

we can see that equation   is almost identical to equation   except that integration is
replaced by summation and the domain  is replaced by x e  the theoretical results
derived for the importance sampling that we reviewed in the previous section can thus be
directly applied to computing probabilities in bayesian networks 
while there has been previous work on importance sampling based algorithms for bayesian networks  we will postpone the discussion of this work until the next section  here
we will present a generic stochastic sampling algorithm that will help us in both reviewing
the prior work and in presenting our algorithm 
the posterior probability pr a e  can be obtained by first computing pr a  e  and pr e 
and then combining these based on the definition of conditional probability
pr a e   

pr a  e 
 
pr e 

   

in order to increase the accuracy of results of importance sampling in computing the posterior probabilities over different network variables given evidence  we should in general use
different importance functions for pr a  e  and for pr e   doing so increases the computation time only linearly while the gain in accuracy may be significant given that obtaining
a desired accuracy is exponential in nature  very often  it is a common practice to use the
same importance function  usually for pr e   to sample both probabilities  if the difference
   order the nodes according to their topological order 
   initialize importance function pr   x e   the desired number of samples
m  the updating interval l  and the score arrays for every node 
   k     t  
   for i    to m do
  

if  i mod l       then

  

k k  

  

update importance function prk  x e  based on t  
end if

  

si  generate a sample according to prk  x e 

  

t  t   si  

   

calculate score si   pr x e  e   prk  x e   and add it to the corresponding entry of every score array according to the instantiated states 
end for

    normalize the score arrays for every node 
figure    a generic importance sampling algorithm 
   

fiadaptive importance sampling in bayesian networks

between the optimal importance functions for these two quantities is large  the perforc
c
mance may deteriorate significantly  although pr a 
e  and pr e 
are unbiased estimators
c
according to property    section       pr a e 
obtained by means of equation   is not an
unbiased estimator  however  as the number of samples increases  the bias decreases and
can be ignored altogether when the sample size is large enough  fishman        
figure   presents a generic stochastic sampling algorithm that captures most of the
existing sampling algorithms  without the loss of generality  we restrict ourselves in our
description to so called forward sampling  i e   generation of samples in the topological
order of the nodes in the network  the forward sampling order is accomplished by the
initialization performed in step    where parents of each node are placed before the node
itself  in forward sampling  step   of the algorithm  the actual generation of samples  works
as follows   i  each evidence node is instantiated to its observed state and is further omitted
from sample generation   ii  each root node is randomly instantiated to one of its possible
states  according to the importance prior probability of this node  which can be derived
from prk  x e    iii  each node whose parents are instantiated is randomly instantiated to
one of its possible states  according to the importance conditional probability distribution
of this node given the values of the parents  which can also be derived from prk  x e    iv 
this procedure is followed until all nodes are instantiated  a complete instantiation si of the
network based on this method is one sample of the joint importance probability distribution
prk  x e  over all variables of the network  the scoring of step    amounts to calculating
pr si   e  prk  si    as required by equation    the ratio between the total score sum and the
number of samples is an unbiased estimator of pr e   in step     if we also count the score
sum under the condition a   a  i e   that some unobserved variables a have the values a 
the ratio between this score sum and the number of samples is an unbiased estimator of
pr a  e  
most existing algorithms focus on the posterior probability distributions of individual
nodes  as we mentioned above  for the sake of efficiency they count the score sum corresponding to pr a   a  e   a  x e  and record it in an score array for node a  each
entry of this array corresponds to a specified state of a  this method introduces additional
variance  as opposed to using the importance function derived from prk  x e  to sample
pr a   a  e   a  x e  directly 
    existing importance sampling algorithms for bayesian networks
the main difference between various stochastic sampling algorithms is in how they process
steps       and   in the generic importance sampling algorithm of figure   
probabilistic logic sampling  henrion        is the simplest and the first proposed sampling algorithm for bayesian networks  the importance function is initialized in step   to
pr x  and never updated  step   is null   without evidence  pr x  is the optimal importance function for the evidence set  which is empty anyway  it escapes most authors
that pr x  may be not the optimal importance function for pr a   a   a  x  when a
is not a root node  a mismatch between the optimal and the actually used importance
function may result in a large variance  the sampling process with evidence is the same
as without evidence except that in step    we do not count the scores for those samples
that are inconsistent with the observed evidence  which amounts to discarding them  when
   

ficheng   druzdzel

the evidence is very unlikely  there is a large difference between pr x  and the optimal
importance function  effectively  most samples are discarded and the performance of logic
sampling deteriorates badly 
likelihood weighting  lw   fung   chang        shachter   peot        enhances the
logic sampling in that it never discards samples  in likelihood weighting  the importance
function in step   is
fi
fi
fi
pr x e   
pr xi  pa xi   fifi
fi
xi e
 
y

 
e e

likelihood weighting does not update the importance function in step    although likelihood weighting is an improvement on logic sampling  its convergence rate can be still very
slow when there is large difference between the optimal importance function and pr x e  
again especially in situations when evidence is very unlikely  because of its simplicity  the
likelihood weighting algorithm has been the most commonly used simulation method for
bayesian network inference  it often matches the performance of other  more sophisticated
schemes because it is simple and able to increase its precision by generating more samples
than other algorithms in the same amount of time 
backward sampling  fung   del favero        changes step   of our generic algorithm
and allows for generating samples from evidence nodes in the direction that is opposite to
the topological order of nodes in the network  in step    backward sampling uses the likelihood of some of the observed evidence and some instantiated nodes to calculate pr   x e  
although fung and del favero mentioned the possibility of dynamic node ordering  they
did not propose any scheme for updating the importance function in step    backward
sampling suffers from problems that are similar to those of likelihood weighting  i e   a possible mismatch between its importance function and the optimal importance function can
lead to poor convergence 
importance sampling  shachter   peot        is the same as our generic sampling algorithm  shachter and peot introduced two variants of importance sampling  self importance
 sis  and heuristic importance  the importance function used in the first step of the
self importance algorithm is
fi
fi
fi
 
pr  x e   
pr xi  pa xi   fifi
fi
xi e
 
y

 
e e

this function is updated in step    the algorithm tries to revise the conditional probability
tables  cpts  periodically in order to make the sampling distribution gradually approach
the posterior distribution  since the same data are used to update the importance function
and to compute the estimator  this process introduces bias in the estimator  heuristic
importance first removes edges from the network until it becomes a polytree  and then
uses a modified version of the polytree algorithm  pearl        to compute the likelihood
functions for each of the unobserved nodes  pr   x e  is a combination of these likelihood
functions with pr x e  e   in step   heuristic importance does not update prk  x e   as
shachter and peot        point out  this heuristic importance function can still lead to a
bad approximation of the optimal importance function  there exist also other algorithms
such as a combination of self importance and heuristic importance  shachter   peot       
   

fiadaptive importance sampling in bayesian networks

shwe   cooper         although some researchers suggested that this may be a promising
direction for the work on sampling algorithms  we have not seen any results that would
follow up on this 
a separate group of stochastic sampling methods is formed by so called markov chain
monte carlo  mcmc  methods that are divided into gibbs sampling  metropolis sampling 
and hybrid monte carlo sampling  geman   geman        gilks  richardson    spiegelhalter        mackay         roughly speaking  these methods draw random samples from
an unknown target distribution f  x  by biasing the search for this distribution towards
higher probability regions  when applied to bayesian networks  pearl        chavez  
cooper        this approach determines the sampling distribution of a variable from its
previous sample given its markov blanket  pearl         this corresponds to updating
prk  x e  when sampling every node  prk  x e  will converge to the optimal importance
function for pr e  if pr   x e  satisfies some ergodic properties  york         since the
convergence to the limiting distribution is very slow and calculating updates of the sampling distribution is costly  these algorithms are not used in practice as often as the simple
likelihood weighting scheme 
there are also some other simulation algorithms  such as bounded variance algorithm
 dagum   luby        and the aa algorithm  dagum et al          which are essentially
based on the lw algorithm and the stopping rule theorem  dagum et al          cano
et al         proposed another importance sampling algorithm that performed somewhat
better than lw in cases with extreme probability distributions  but  as the authors state  in
general cases it produced similar results to the likelihood weighting algorithm  hernandez
et al         also applied importance sampling and reported a moderate improvement on
likelihood weighting 
    practical performance of the existing sampling algorithms
the largest network that has been tested using sampling algorithms is qmr dt  quick
medical reference  decision theoretic   shwe et al         shwe   cooper         which
contains     adult diseases and       findings  with        arcs depicting disease to finding
dependencies  the qmr dt network belongs to a class of special bipartite networks
and its structure is often referred to as bn o  henrion         because of its two layer
composition  disease nodes in the top layer and finding nodes in the bottom layer  shwe
and colleagues used an algorithm combining self importance and heuristic importance and
tested its convergence properties on the qmr dt network  but since the heuristic method
iterative tabular bayes  itb  that makes use of a version of bayes rule is designed for
the bn o networks  it cannot be generalized to arbitrary networks  although shwe and
colleagues concluded that markov blanket scoring and self importance sampling significantly
improve the convergence rate in their model  we cannot extend this conclusion to general
networks  the computation of markov blanket scoring is more complex in a general multiconnected network than in a bn o network  also  the experiments conducted lacked a
gold standard posterior probability distribution that could serve to judge the convergence
rate 
pradhan and dagum        tested an efficient version of the lw algorithm  bounded
variance algorithm  dagum   luby        and the aa algorithm  dagum et al         on
   

ficheng   druzdzel

a     node  multiply connected medical diagnostic bayesian network  one limitation in
their tests is that the probability of evidence in the cases selected for testing was rather
high  although over     of the cases had the probability of evidence on the order of
    or smaller  a simple calculation based on the reported mean         number of
evidence nodes  shows that the average probability of an observed state of an evidence node
conditional on its direct predecessors was on the order of                     given that
their algorithm is essentially based on the lw algorithm  based on our tests we suspect
that the performance will deteriorate on cases where the evidence is very unlikely  both
algorithms focus on the marginal probability of one hypothesis node  if there are many
queried nodes  the efficiency may deteriorate 
we have tested the algorithms discussed in section     on several large networks  our
experimental results show that in cases with very unlikely evidence  none of these algorithms
converges to reasonable estimates of the posterior probabilities within a reasonable amount
of time  the convergence becomes worse as the number of evidence nodes increases  thus 
when using these algorithms in very large networks  we simply cannot trust the results  we
will present results of tests of the lw and sis algorithms in more detail in section   

   ais bn  adaptive importance sampling for bayesian networks
the main reason why the existing stochastic sampling algorithms converge so slowly is that
they fail to learn a good importance function during the sampling process and  effectively 
fail to reduce the sampling variance  when the importance function is optimal  such as
in probabilistic logic sampling without any evidence  each of the algorithms is capable
of converging to fairly good estimates of the posterior probabilities within relatively few
samples  for example  assuming that the posterior probabilities are not extreme  i e   larger
than say        as few as       samples may be sufficient to obtain good estimates  in this
section  we present the adaptive importance sampling algorithm for bayesian networks
 ais bn  that  as we will demonstrate in the next section  performs very well on most
tests  we will first describe the details of the algorithm and prove two theorems that are
useful in learning the optimal importance sampling function 
    basic algorithm  ais bn
compared with importance sampling used in normal finite dimensional integrals  importance sampling used in bayesian networks has several significant advantages  first  the
network joint probability distribution pr x  is decomposable and can be factored into
component parts  second  the network has a clear structure  which represents many conditional independence relationships  these properties are very helpful in estimating the
optimal importance function 
the basic ais bn algorithm is presented in figure    the main differences between
the ais bn algorithm and the basic importance sampling algorithm in figure   is that
we introduce a monotonically increasing weight function wk and two effective heuristic
initialization methods in step    we also introduce a special learning component in step  
to let the updating process run more smoothly  avoiding oscillation of the parameters  the
   

fiadaptive importance sampling in bayesian networks

   order the nodes according to their topological order 
   initialize importance function pr   x e  using some heuristic methods  initialize weight w    set the desired number of samples m and the updating
interval l  initialize the score arrays for every node 
   k     t    wt score     wsum   
   for i    to m do
  

if  i mod l       then

  

k k  

  

update the importance function prk  x e  and wk based on t  
end if

  

si  generate a sample according to prk  x e 

  

t  t   si  

   

wiscore  score  si   pr x e  e   prk  x e   wk  

   

wt score  wt score   wiscore
 optional  add wiscore to the corresponding entry of every score array 

   

wsum  wsum   wk
end for

    output estimate of pr e  as wt score  wsum
 optional  normalize the score arrays for every node 

figure    the adaptive importance sampling for bayesian networks  ais bn  algorithm 
score processing in step    is
pr si   e 
wiscore   wk k
 
pr  si  
note that in this respect the algorithm in figure   becomes a special case of ais bn
when wk      the reason why we use wk is that we want to give different weights to
the sampling results obtained at different stages of the algorithm  as each stage updates
the importance function  they will all have different distance from the optimal importance
b k   where 
b k is the standard deviation estimated in
function  we recommend that wk    
 
k
stage k using equation    in order to keep w monotonically increasing  if wk is smaller
than wk    we adjust its value to wk    this weighting scheme may introduce bias into
   a similar weighting scheme based on variance was apparently developed independently by ortiz and
kaelbling         who recommend the weight wk     
bk     

   

ficheng   druzdzel

the final result  since the initial importance sampling functions are often inefficient and
introduce big variance into the results  we also recommend that wk     in the first few
stages of the algorithm  we have designed this weighting scheme to reflect the fact that in
practice estimates with very small estimated variance are usually good estimates 
    modifying the sampling distribution in ais bn
based on the theoretical considerations of section      we know that the crucial element of
the algorithm is converging on a good approximation of the optimal importance function 
in what follows  we first give the optimal importance function for calculating pr e   e 
and then discuss how to use the structural advantages of bayesian networks to approximate
this function  in the sequel  we will use the symbol  to denote the importance sampling
function and  to denote the optimal importance sampling function 
since pr x e  e   e       from corollary   we have
 x e   

pr x e  e   e 
  pr x e   e   
pr e   e 

the following corollary captures this result 
corollary   the optimal importance sampling function   x e  for calculating pr e   e 
in equation   is pr x e   e  
although we know the mathematical expression for the optimal importance sampling
function  it is difficult to obtain this function exactly  in our algorithm  we use the following
importance sampling function
 x e   

n
y

pr xi  pa xi    e   

   

i  

this function partially considers the effect of all the evidence on every node during the
sampling process  when the network structure is the same as that of the network which
has absorbed the evidence  this function is the optimal importance sampling function  it
is easy to learn and  as our experimental results show  it is a good approximation to the
optimal importance sampling function  theoretically  when the posterior structure of the
model changes drastically as the result of observed evidence  this importance sampling
function may perform poorly  we have tried to find practical networks where this would
happen  but to the day have not encountered a drastic example of this effect 
from section      we know that the score sums corresponding to  xi   pa xi    e  can
yield an unbiased estimator of pr xi   pa xi    e   according to the definition of conditional
probability  we can get an estimator of pr   xi  pa xi    e   this can be achieved by maintaining an updating table for every node  the structure of which mimicks the structure of
the cpt  such tables allow us to decompose the above importance function into components that can be learned individually  we will call these tables the importance conditional
probability tables  icpt  
definition   an importance conditional probability table  icpt  of a node x is a table
of posterior probabilities pr x pa x   e   e  conditional on the evidence and indexed by
its immediate predecessors  pa x  
   

fiadaptive importance sampling in bayesian networks

the icpt tables will be modified during the process of learning the importance function 
now we will prove a useful theorem that will lead to considerable savings in the learning
process 
theorem  
xi  x  xi 
  anc e   pr xi  pa xi    e    pr xi  pa xi     

   

proof  suppose we have set the values of all the parents of node xi to pa xi    node xi is
dependent on evidence e given pa xi   only when xi is d connecting with e given pa xi  
 pearl         according to the definition of d connectivity  this happens only when there
exists a member of xi s descendants that belongs to the set of evidence nodes e  in other
words xi 
  anc e  
 
theorem   is very important for the ais bn algorithm  it states essentially that
the icpt tables of those nodes that are not ancestors of the evidence nodes are equal to
the cpt tables throughout the learning process  we only need to learn the icpt tables
for the ancestors of the evidence nodes  very often this can lead to significant savings in
computation  if  for example  all evidence nodes are root nodes  we have our icpt tables for
every node already and the ais bn algorithm becomes identical to the likelihood weighting
algorithm  without evidence  the ais bn algorithm becomes identical to the probabilistic
logic sampling algorithm 
it is worth pointing out that for some xi   pr xi  pa  xi    e   i e   the icpt table for
xi    can be easily calculated using exact methods  for example  when xi is the only parent
of an evidence node ej and ej is the only child of xi   the posterior probability distribution
of xi is straightforward to compute exactly  since the focus of the current paper is on
input  initialized importance function pr   x e   learning rate  k  
output  an estimated importance function prs  x e  
for stage k    to s do
   sample l points sk    sk            skl independently according to the current importance function prk  x e  
   for every node xi such that xi  x e and xi 
  anc e  count score sums
corresponding to  xi   pa xi    e  and estimate pr   xi  pa xi    e  based on sk   
sk            skl  
   update prk  x e  according to the following formula 
prk    xi  pa xi    e   




prk  xi  pa xi    e     k   pr   xi  pa xi    e   prk  xi  pa xi    e 
end for

figure    the ais bn algorithm for learning the optimal importance function 
   

ficheng   druzdzel

sampling  the test results reported in this paper do not include this improvement of the
ais bn algorithm 
figure   lists an algorithm that implements step   of the basic ais bn algorithm listed
in figure    when we estimate pr   xi  pa xi    e   we only use the samples obtained at the
current stage  one reason for this is that the information obtained in previous stages has
been absorbed by prk  x e   the other reason is that in principle  each successive iteration
is more accurate than the previous one and the importance function is closer to the optimal
importance function  thus  the samples generated by prk    x e  are better than those
generated by prk  x e   pr   xi  pa xi    e   prk  xi  pa xi    e  corresponds to the vector
of first partial derivatives in the direction of the maximum decrease in the error   k  is
a positive function that determines the learning rate  when  k       lower bound   we
do not update our importance function  when  k       upper bound   at each stage we
discard the old function  the convergence speed is directly related to  k   if it is small 
the convergence will be very slow due to the large number of updating steps needed to
reach a local minimum  on the other hand  if it is large  convergence rate will be initially
very fast  but the algorithm will eventually start to oscillate and thus may not reach a
minimum  there are many papers in the field of neural network learning that discuss how
to choose the learning rate and let estimated importance function converge quickly to the
destination function  any method that can improve learning rate should be applicable to
this algorithm  currently  we use the following function proposed by ritter et al        
 k kmax

 k    a

b
a

 

    

where a is the initial learning rate and b is the learning rate in the last step  this function
has been reported to perform well in neural network learning  ritter et al         
    heuristic initialization in ais bn
the dimensionality of the problem of bayesian network inference is equal to the number of
variables in a network  which in the networks considered in this paper can be very high 
as a result  the learning space of the optimal importance function is very large  choice of
the initial importance function pr   x e  is an important factor affecting the learning 
an initial value of the importance function that is close to the optimal importance function
can greatly affect the speed of convergence  in this section  we present two heuristics that
help to achieve this goal 
due to their explicit encoding of the structure of a decomposable joint probability distribution  bayesian networks offer computational advantages compared to finite dimensional
integrals  a possible first approximation of the optimal importance function is the prior
probability distribution over the network variables  pr x   we propose an improvement on
this initialization  we know that the effect of evidence nodes on a node will be attenuated
as the path length of that node to evidence nodes is increased  henrion        and the
most affected nodes are the direct ancestors of the evidence nodes  initializing the icpt
tables of the parents of the evidence nodes to uniform distributions in our experience improves the convergence rate  furthermore  the cpt tables of the parents of an evidence
node e may be not favorable to the observed state e if the probability of e   e without
   

fiadaptive importance sampling in bayesian networks

any condition is less than a small value  such as pr e   e          ne    where ne is the
number of outcomes of node e  based on this observation  we change the cpt tables of
the parents of an evidence node e to uniform distributions in our experiment only when
pr e   e          ne    otherwise we leave them unchanged  this kind of initialization
involves the knowledge of pr e   e   the marginal probability without evidence  probabilistic logic sampling  henrion        enhanced by latin hypercube sampling  cheng  
druzdzel      b  or quasi monte carlo methods  cheng   druzdzel      a  will produce a
very good estimate of pr e   e   this is an one time effort that can be made at the model
building stage and is worth pursuing to any desired precision 
another serious problem related to sampling are extremely small probabilities  suppose
there exists a root node with a state s that has the prior probability pr s            let
the posterior probability of this state given evidence be pr s e         a simple calculation
shows that if we update the importance function every        samples  we can expect to
hit s only once every    updates  thus ss convergence rate will be very slow  we can
overcome this problem by setting a threshold  and replacing every probability p    in the
network by    at the same time  we subtract    p  from the largest probability in the
same conditional probability distribution  for example  the value of       l  where l is
the updating interval  will allow us to sample    times more often in the first stage of the
algorithm  if this state turns out to be more likely  having a large weight   we can increase
its probability even more in order to converge to the correct answer faster  considering
that we should avoid f  x    g x   i  f  x   in an unimportant region as discussed in
section      we need to make this threshold larger  we have found that the convergence
rate is quite sensitive to this threshold  based on our empirical tests  we suggest to use
        in networks whose maximum number of outcomes per node does not exceed five 
a smaller threshold might lead to fast convergence in some cases but slow convergence in
others  if one threshold does not work  changing it in a specific network will usually improve
convergence rate 
    selection of parameters
there are several tunable parameters in the ais bn algorithm  we base the choice of
these parameters on the central limit theorem  clt   according to clt  if z    z           
zn are independent and identically distributed random variables with e zi     z and
var zi     z    i           n  then z    z       zn   n is approximately normally distributed
when n is sufficiently large  thus 
lim p  

n

fi
fi
fi
fi
fiz  z fi

z


z 
 
z   n
 
ex    dx  
 t    

z
  t

    

although this approximation holds when n approaches infinity  clt is known to be very
robust and lead to excellent approximations even for small n  the formula of equation   
is an  r     relative approximation  which is an estimate  of  that satisfies
p 

    
 r      


   this initialization heuristic was apparently developed independently by ortiz and kaelbling        

   

ficheng   druzdzel

if  has been fixed 


z   n

r  
  
z     
z
 

where z  z       z ex    dx  since in our sampling problem  z  corresponding to

pr e  in figure    has been fixed  setting r to a smaller value amounts to letting z   n

be smaller  so  we can adjust the parameters based on z   n  which can be estimated
bk
using equation    it is also the theoretical intuition behind our recommendation wk    
in section      while we expect that this should work well in most networks  no guarantees
can be given here  there exist always some extreme cases in sampling algorithms in which
no good estimate of variance can be obtained 
r

 

    a generalization of ais bn  the problem of estimating pr a e 
a typical focus of systems based on bayesian networks is the posterior probability of various
outcomes of individual variables given evidence  pr a e   this can be generalized to the
computation of the posterior probability of a particular instantiation of a set of variables
given evidence  i e   pr a   a e   there are two methods that are capable of performing
this computation  the first method is very efficient at the expense of precision  the second
method is less efficient  but offers in general better convergence rates  both methods are
based on equation   
the first method reuses the samples generated to estimate pr e  in estimating pr a  e  
estimation of pr a  e  amounts to counting the scored sum under the condition a   a 
the main advantage of this method is its efficiency  we can use the same set of samples
to estimate the posterior probability of any state of a subset of the network given evidence 
its main disadvantage is that the variance of the estimated pr a  e  can be large  especially
when the numerical value of pr a e  is extreme  this method is the most widely used
approach in the existing stochastic sampling algorithms 
the second method  used much more rarely  e g   cano et al         pradhan   dagum 
      dagum   luby         calls for estimating pr e  and pr a  e  separately  after
estimating pr e   an additional call to the algorithm is made for each instantiation a of
the set of variables of interest a  pr a  e  is estimated by sampling the network with the
set of observations e extended by a   a  the main advantage of this method is that it
is much better at reducing variance than the first method  its main disadvantage is the
computational cost associated with sampling for possibly many combinations of states of
nodes of interest 
cano et al         suggested a modified version of the second method  suppose that we
are interested in the posterior distribution pr ai  e  for all possible values ai of a  i     
           k  we can estimate pr ai   e  for each i              k separately  and use the value
pk
i   pr ai   e  as an estimate for pr e   the assumption behind this approach is that the
estimate of pr e  will be very accurate because of the large sample from which it is drawn 
however  even if we can guarantee small variance in every pr ai   e   we cannot guarantee
that their sum will also have a small variance  so  in the ais bn algorithm we only use
the pure form of each of the methods  the algorithm listed in figure   is based on the first
method when the optional computations in steps    and    are performed  an algorithm
   

fiadaptive importance sampling in bayesian networks

corresponding to the second method skips the optional steps and calls the basic ais bn
algorithm twice to estimate pr e  and pr a  e  separately 
the first method is very attractive because of its simplicity and possible computational
efficiency  however  as we have shown in section      the performance of a sampling algorithm that uses just one set of samples  as in the first method above  to estimate pr a e 
will deteriorate if the difference between the optimal importance functions for pr a e  and
pr e  is large  if the main focus of the computation is high accuracy of the posterior probability distribution of a small number of nodes  we strongly recommend to use the algorithm
based on the second method  also  this algorithm can be easily used to estimate confidence
intervals of the solution 

   experimental results
in this section  we first describe the experimental method used in our tests  our tests focus
on the cpcs network  which is one of the largest and most realistic networks available
and for which we know precisely which nodes are observable  we were  therefore  able
to generate very realistic test cases  since the ais bn algorithm uses two initialization
heuristics  we designed an experiment that studies the contribution of each of these two
heuristics to the performance of the algorithm  to probe the extent of ais bn algorithms
excellent performance  we test it on several real and large networks 
    experimental method
we performed empirical tests comparing the ais bn algorithm to the likelihood weighting
 lw  and the self importance sampling  sis  algorithms  the two algorithms are basically
the state of the art general purpose belief updating algorithms  the aa  dagum et al  
      and the bounded variance  dagum   luby        algorithms  which were suggested
by a reviewer  are essentially enhanced special purpose versions of the basic lw algorithm 
our implementation of the three algorithms relied on essentially the same code with separate
functions only when the algorithms differed  it is fair to assume  therefore  that the observed
differences are purely due to the theoretical differences among the algorithms and not due to
the efficiency of implementation  in order to make the comparison of the ais bn algorithm
to lw and sis fair  we used the first method of computation  section       i e   one that
relies on single sampling rather than calling the basic ais bn algorithm twice 
we measured the accuracy of approximation achieved by the simulation in terms of the
mean square error  mse   i e   square root of the sum of square differences between pr   xij  
and pr xij    the sampled and the exact marginal probabilities of state j  j                 ni  
of node i  such that xi 
  e  more precisely 
v
u
u
mse   t p

 

xi n e ni

x

ni
x

 pr   xij    pr xij      

xi n e j  

where n is the set of all nodes  e is the set of evidence nodes  and ni is the number of
outcomes of node i  in all diagrams  the reported mse is averaged over    runs  we used
the clustering algorithm  lauritzen   spiegelhalter        to compute the gold standard
   

ficheng   druzdzel

results for our comparisons of the mean square error  we performed all experiments on a
pentium ii      mhz windows computer 
while mse is not perfect  it is the simplest way of capturing error that lends itself to
further theoretical analysis  for example  it is possible to derive analytically the idealized
convergence rate in terms of mse  which  in turn  can be used to judge the quality of the
algorithm  mse has been used in virtually all previous tests of sampling algorithms  which
allows interested readers to tie the current results to the past studies  a reviewer offered
an interesting suggestion of using cross entropy or some other technique that weights small
changes near zero much more strongly than the equivalent size change in the middle of
the        interval  such measure would penalize the algorithm for imprecisions of possibly
several orders of magnitude in very small probabilities  while this idea is interesting  we
are not aware of any theoretical reasons as to why this measure would make a difference in
comparisons between ais bn  lw and sis algorithms  the mse  as we mentioned above 
will allow us to compare the empirically determined convergence rate to the theoretically
derived ideal convergence rate  theoretically  the mse is inversely proportional to the
square root of the sample size 
since there are several tunable parameters used in the ais bn algorithm  we list the
values of the parameters used in our test  l           wk     for k    and wk    
otherwise  we stopped the updating process in step   of figure   after k      in other
words  we used only the samples collected in the last step of the algorithm  the learning
parameters used in our algorithm are kmax       a        and b         see equation     
we used an empirically determined value of the threshold          section       we only
change the cpt tables of the parents of a special evidence node a to uniform distributions
when pr a   a          na    some of the parameters are a matter of design decision
 e g   the number of samples in our tests   others were chosen empirically  although we
have found that these parameters may have different optimal values for different bayesian
networks  we used the above values in all our tests of the ais bn algorithm described in
this paper  since the same set of parameters led to spectacular improvement in accuracy
in all tested networks  it is fair to say that the superiority of the ais bn algorithm to the
other algorithms is not too sensitive to the values of the parameters 
for the sis algorithm  wk     by the design of the algorithm  we used l           the
updating function in step   of figure   is that of  shwe et al         cousins  chen   
frisse        
prknew  xi  pa xi    e   

c
pr xi  pa xi      k  pr
current  xi  pa xi    e   
  k

c
where pr xi  pa xi    is the original sampling distribution  pr
current  xi  pa xi    e  is an
equivalent of our icpt tables estimator based on all currently available information  and
k is the updating step 

    results for the cpcs network
the main network used in our tests is a subset of the cpcs  computer based patient case
study  model  pradhan et al          a large multiply connected multi layer network consisting of     multi valued nodes and covering a subset of the domain of internal medicine 
   

fiadaptive importance sampling in bayesian networks

among the     nodes     nodes describe diseases     nodes describe history and risk factors  and the remaining     nodes describe various findings related to the diseases  the
cpcs network is among the largest real networks available to the research community at
the present time  the cpcs network contains many extreme probabilities  typically on
the order of       our analysis is based on a subset of     nodes of the cpcs network 
created by max henrion and malcolm pradhan  we used this smaller version in order to
be able to compute the exact solution for the purpose of measuring approximation error in
the sampling algorithms 
the ais bn algorithm has some learning overhead  the following comparison of execution time vs  number of samples may give the reader an idea of this overhead  updating
the cpcs network with    evidence nodes on our system takes the ais bn algorithm a
total of     seconds to learn  it generates subsequently       samples per second  while the
sis algorithm generates       samples per second  and the lw algorithm generates      
samples per second  in order to remain conservative towards the ais bn algorithm  in all
our experiments we fixed the execution time of the algorithms  our limit was    seconds 
rather than the number of samples  in the cpcs network with    evidence nodes  in   
seconds  ais bn generates about         samples  sis generates about         samples
and lw generates about         samples 

  
    
   

  

   

frequency

 

   
   

 

   
   

 
   
   

 

   
 

  
 e   

 e   

 e   

 e   

 e   

 e   

probability of evidence

figure    the probability distribution of evidence pr e   e  in our experiments 
we generated a total of    test cases consisting of five sequences of    test cases each  we
ran each test case    times  each time with a different setting of the random number seed 
each sequence had a progressively higher number of evidence nodes                  and
   evidence nodes respectively  the evidence nodes were chosen randomly  equiprobable
sampling without replacement  from those nodes that described various plausible medical
   

ficheng   druzdzel

findings  almost all of these nodes were leaf nodes in the network  we believe that this
constituted very realistic test cases for the algorithms  the distribution of the prior probability of evidence  pr e   e   across all test runs of our experiments is shown in figure   
the least likely evidence was              the most likely evidence was             and
the median was          

    

ais bn

sis

lw

mean square error

    

    

    

    

    

    
  

  

  

  

  

  

   

   

   

   

sample time  seconds 

figure    a typical plot of convergence of the tested sampling algorithms in our experiments
 mean square error as a function of the execution time for a subset of the
cpcs network with    evidence nodes chosen randomly among plausible medical
observations  pr e   e               in this particular case  for the ais bn 
the sis  and the lw algorithms  the curve for the ais bn algorithm is very
close to the horizontal axis 

figures   and   show a typical plot of convergence of the tested sampling algorithms in
our experiments  the case illustrated involves updating the cpcs network with    evidence
nodes  we plot the mse after the initial    seconds during which the algorithms start
converging  in particular  the learning step of the ais bn algorithm is usually completed
within the first   seconds  we ran the three algorithms in this case for     seconds rather
than the    seconds in the actual experiment in order to be able to observe a wider range of
convergence  the plot of the mse for the ais bn algorithm almost touches the x axis in
figure    figure   shows the same plot in a finer scale in order to show more detail in the
ais bn convergence curve  it is clear that the ais bn algorithm dramatically improves
the convergence rate  we can also see that the results of ais bn converge to exact results
very fast as the sampling time increases  in the case captured in figures   and    a tenfold
increase in the sampling time  after subtracting the overhead for the ais bn algorithm  it
   

fiadaptive importance sampling in bayesian networks

      

ais bn

mean square error

      

      

      

      

      
  

  

  

  

  

  

   

   

   

   

sample time  seconds 

figure    the lower part of the plot of figure   showing the convergence of the ais bn
algorithm to correct posterior probabilities 

corresponds to a      fold increase in the number of samples  results in a      fold decrease
of the mse  to mse           the observed convergence of both sis and lw algorithms
was poor  a tenfold increase in sampling time had practically no effect on accuracy  please
note that this is a very typical case observed in our experiments 

absent
mild
moderate
severe

original cpt
       
       
       
       

exact icpt
      
      
      
      

learned icpt
     
     
     
     

table    a fragment of the conditional probability table of a node of the cpcs network
 node gasacute  parents hepacute mild and wbctottho false  in figure   

figure   illustrates the icpt learning process of the ais bn algorithm for the sample
case shown in figure    the displayed conditional probabilities belong to the node gasacute
which is a parent of two evidence nodes  difinfgasmuc and abdpaiexamea  the node
gasacute has four states  absent  mild  moderate  and severe  and two parents 
we randomly chose a combination of its parents states as our displayed configuration  the
original cpt for this configuration without evidence  the exact icpt with evidence and
the learned icpt with evidence are summarized numerically in table    figure   illustrates
   

ficheng   druzdzel

   

absent

mild

moderate

severe

   

probability

   
   
   
   
   
   
 
 

 

 

 

 

 

 

 

 

 

  

updating step

figure    convergence of the conditional probabilities during the example run of the aisbn algorithm captured in figure    the displayed fragment of the conditional
probability table belongs to node gasacute which is a parent of one of the evidence
nodes 

that the learned importance conditional probabilities begin to converge to the exact results
stably after three updating steps  the learned probabilities in step    are close to the
exact results  in this example  the difference between pr xi  pa xi    e  and pr xi  pa xi    is
very large  sampling from pr xi  pa xi    instead of pr xi  pa xi    e  would introduce large
variance into our results 



min
median
max

ais bn
       
       
       
       
       

sis
     
     
      
     
     

lw
     
     
      
     
     

table    summary of the simulation results for all of the    simulation cases on the cpcs
network  figure   shows each of the    cases graphically 

figure   shows the mse for all    test cases in our experiments with the summary
statistics in table    a paired one tailed t test resulted in statistically highly significant
differences between the ais bn and sis algorithms  p                and also between
   

fiadaptive importance sampling in bayesian networks

 

ais bn

sis

lw

mean square error

   

    

     

      
   e       e       e       e       e       e       e       e   

probability of evidence

figure    performance of the ais bn  sis  and lw algorithms  mean square error for
each of the    individual test cases plotted against the probability of evidence 
the sampling time is    seconds 

the sis and lw algorithms  p               as far as the magnitude of difference is
concerned  ais bn was significantly better than sis  sis was better than lw  but the
difference was small  the mean mses of sis and lw algorithms were both greater than
     which suggests that neither of these algorithms is suitable for large bayesian networks 
the graph in figure   shows the mse ratio between the ais bn and sis algorithms 
we can see that the percentage of the cases whose ratio was greater than      two orders
of magnitude improvement   is      in other words  we obtained two orders of magnitude
improvement in mse in more than half of the cases  in     cases  the ratio was greater
than     the smallest ratio in our experiments was       which happened when posterior
probabilities were dominated by the prior probabilities  in that case  even though the lw
and sis algorithms converged very fast  their mse was still far larger than that of ais bn 
our next experiment aimed at showing how close the ais bn algorithm can approach
the best possible sampling results  if we know the optimal importance sampling function 
the convergence of the ais bn algorithm should be the same as that of forward sampling
without evidence  in other words  the results of the probabilistic logic sampling algorithm
without evidence approach the limit of how well stochastic sampling can perform  we ran
the logic sampling algorithm on the cpcs network without evidence mimicking the test
runs of the ais bn algorithm  i e     blocks of    runs  each repeated    times with a
different random number seed  the number of samples generated was equal to the average
number of samples generated by the ais bn algorithm for each series of    test runs 
   

ficheng   druzdzel

  

    

  

   
   

  

   

frequency

  

   
  
   
 
   
 

   

 

   

 
 

   
 

 
 fffiff ffff   

  

the ratio of mse between sis and ais bn

figure    the ratio of mse between sis and ais bn versus percentage 

we obtained the average mse             with              min            and
max            the best results should be around this range  from table    we can
see that the minimum mse for the ais bn algorithm was          within the range of
the optimal result  the mean mse in ais bn is          not too far from the optimal
results  the standard deviation    is significantly larger in the ais bn algorithm  but
this is understandable given that the process of learning the optimal importance function is
heuristic in nature  it is not difficult to understand that there exist a difference between the
ais bn results and the optimal results  first  the ais bn algorithm in our tests updated
the sampling distribution only    times  which may be too few times to let it converge
to the optimal importance distribution  second  even if the algorithm has converged to
the optimal importance distribution  the sampling algorithm will still let the parameter
oscillate around this distribution and there will be always small differences between the two
distributions 
figure    shows the convergence rate for all tested cases for a four fold increase in
sampling time  between    and    seconds   we adjusted the convergence ratio of the
ais bn algorithm by dividing it by a constant  according to equation    the theoretically
expected convergence ratio for a four fold increase in the number of samples should be
around two  there are about     cases among the ais bn runs whose ratio lays in
the interval               in a sharp contrast to     and     cases in the sis and lw
algorithms  the ratios of the remaining    cases in ais bn lay in the interval             
in the sis and lw algorithms  the percentage of cases whose ratio were smaller than    
was     and     respectively  less than     means that the number of samples was too
small to estimate variance and the results cannot be trusted  the ratio greater than     
   

fiadaptive importance sampling in bayesian networks

   

ais bn

sis

lw
   

   

frequency

   

   

   

   
   

   
   

   

   
   

   

    

   
  

  
  

    

  
  

  

  

  

  

  

  

  
                                                                                                             

more

convergence rate

figure     the distribution of the convergence ratio of the ais bn  sis  and lw algorithms when the number of samples increases four times 

means possibly that    seconds was long enough to estimate the variance  but    seconds
was too short 
    the role of ais bn heuristics in performance improvement
from the above experimental results we can see that the ais bn algorithm can improve
the sampling performance significantly  our next series of tests focused on studying the role
of the two ais bn initialization heuristics  the first is initializing the icpt tables of the
parents of evidence to uniform distributions  denoted by u  the second is adjusting small
probabilities  denoted by s  we denote ais bn without any heuristic initialization method
to be the ais algorithm  ais u s equals ais bn  we compared the following versions
of the algorithms  sis  ais  sis u  ais u  sis s  ais s  sis u s  ais u s  all
algorithms with sis used the same number of samples as sis  all algorithms with ais used
the same number of samples as ais bn  we tested these algorithms on the same    test
cases used in the previous experiment  figure    shows the mse for each of the sampling
algorithms with the summary statistics in table    even though the ais algorithm is better
than the sis algorithm  the difference is not as large as in case of the ais u  ais s  and
ais bn algorithms  it seems that heuristic initialization methods help much  the results
for the sis s  sis u  sis u s algorithms suggest that although heuristic initialization
methods can improve performance  they alone cannot improve too much  it is fair to say
that significant performance improvement in the ais bn algorithm is coming from the
combination of ais with heuristic methods  not any method alone  it is not difficult to
   

ficheng   druzdzel

understand that  as only with good heuristic initialization methods is it possible to let the
learning process quickly exit oscillation areas  although both s and u methods alone can
improve the performance  the improvement is moderate compared to the combination of
the two 

    

     

mean square error

    

     

    

     
    

     

     

    

    

     
       
    

   

  
fi  ff     
fi  ff

  ff     fiff

       
     ff        ff

different algorithms

figure     a comparison of different algorithms in the cpcs network  each bar is based
on    test cases  the dotted bar shows the mse for the sis algorithm while
the gray bar shows the mse for the ais algorithm 



min
median
max

sis
     
     
      
     
     

ais
     
     
       
     
     

sis u
     
     
      
     
     

ais u
      
     
       
      
     

sis s
     
     
       
     
     

ais s
      
      
       
       
      

sis u s
     
     
       
     
     

ais bn
       
       
       
       
      

table    summary of the simulation results for different algorithms in the cpcs network 

    results for other networks
in order to make sure that the ais bn algorithm performs well in general  we tested it on
two other large networks 
the first network that we used in our tests is the pathfinder network  heckerman
et al          which is the core element of an expert system that assists surgical pathologists
   

fiadaptive importance sampling in bayesian networks

with the diagnosis of lymph node diseases  there are two versions of this network  we used
the larger version  consisting of     nodes  in contrast to the cpcs network  pathfinder
contains many conditional probabilities that are equal to    which reflects deterministic
relationships in certain settings  to make the sampling challenging  we randomly selected
   evidence nodes from among the leaf nodes  each of these was an observable node  david
heckerman  personal communication   we verified in each case that the probability of so
selected evidence was not equal to zero 
we fixed the execution time of the algorithms to be    seconds  the learning overhead
for the ais bn algorithm in the pathfinder network was about     seconds  in   
seconds  ais bn generated about         samples  sis generated about         samples
and lw generated about           samples  the reason why lw could generate more than
   times as many samples as sis within the same amount of time is that the lw algorithm
terminates sample generation at a very early stage in many samples  when the weight of a
sample becomes zero  this is a result of determinism in the probability tables  mentioned
above  we will see that lw benefits greatly from generating more samples  the other
parameters used in ais bn were the same as those used in the cpcs network 
we tested    cases  each with randomly selected    evidence nodes  the reported mse
for each case was averaged over    runs  some of the runs of the sis and lw algorithms did
not manage to generate any effective samples  the weight score sum was equal to zero   sis
had only     effective runs and lw had only     effective runs  which means that in some
runs sis and lw were unable to yield any information about the posterior distributions 
in all those cases  we discarded the run and only averaged over the effective runs  all
runs in the ais bn algorithm were effective  we report our experimental results with the
summary statistics in table    from these data  we can see that the ais bn algorithm
is still significantly better than the sis and lw algorithms  since the lw algorithm can
generate more than ten times the number of samples than the sis algorithm  its performance
is better than that of the sis algorithm 



min
median
max
effective runs

ais bn
       
       
       
       
      
   

sis
     
     
       
     
     
   

lw
     
      
       
      
     
   

table    summary of the simulation results for all of the    simulation cases on the
pathfinder network 

the second network that we tested was one of the andes networks  conati et al  
       andes is an intelligent tutoring system for classical newtonian physics that is
being developed by a team of researchers at the learning research and development center
at the university of pittsburgh and researchers at the united states naval academy  the
student model in andes uses a bayesian network to do longterm knowledge assessment 
   

ficheng   druzdzel

plan recognition  and prediction of students actions during problem solving  we selected
the largest andes network that was available to us  consisting of     nodes 
in contrast to the previous two networks  the depth of the andes network was significantly larger and so was its connectivity  there were only    leaf nodes  it is quite
predictable that this kind of networks will pose difficulties to learning  we selected   
evidence nodes randomly from the potential evidence nodes and tested    cases  all parameters were the same as those used in the cpcs network  we fixed the execution time
of the algorithms to be    seconds  the learning overhead for the ais bn algorithm in
the andes network was      seconds  in    seconds  ais bn generated about        
samples  sis generated about        samples and lw generated about         samples 
in this network  lw still can generate almost two times the number of samples generated
by the sis algorithm 
we report our experimental results with the summary statistics in table    the results
show that also in the andes network the ais bn algorithm was significantly better than
the sis and lw algorithms  since lw generated almost two times the number of samples
that were generated by the sis algorithm  its performance was better than that of the sis
algorithm 



min
median
max

ais bn
      
      
      
      
      

sis
      
     
      
      
     

lw
      
      
      
      
     

table    summary of the simulation results for all of the    simulation cases on the andes
network 

while the ais bn algorithm is on the average an order of magnitude more precise
than the other two algorithms  the performance improvement is smaller than in the other
two networks  the reason why the performance improvement of the ais bn algorithm
over the sis and lw algorithms in the andes network is smaller compared to that in
the cpcs and pathfinder networks is that      the andes network used in our tests
was apparently not challenging enough for sampling algorithms in general  in the andes
network  sis and lw also can perform well in some cases  the minimum mse of sis and
lw in our tested cases is almost the same as that of ais bn      the number of samples
generated by ais bn in this network is significantly smaller than that in the previous
two networks and ais bn needs more time to learn  although increasing the number of
samples will improve the performance of all three algorithms  it improves the performance
of ais bn more since the convergence ratio of the ais bn algorithm is usually larger than
that of sis and lw  see figure          the parameters that we used in this network were
tuned for the cpcs network      the large depth and fewer leaf nodes of the andes
network pose some difficulties to learning 
   

fiadaptive importance sampling in bayesian networks

   discussion
there is a fundamental trade off in the ais bn algorithm between the time spent on
learning the importance function and the time spent on sampling  our current approach 
which we believe to be reasonable  is to stop learning at the point when the importance
function is good enough  in our experiments we stopped learning after    iterations 
there are several ways of improving the initialization of the conditional probability
tables at the outset of the ais bn algorithm  in the current version of the algorithm  we
initialize the icpt table of every parent n of an evidence node e  n  pa e   e  e 
to the uniform distribution when pr e   e          ne    this can be improved further 
we can extend the initialization to those nodes that are severely affected by the evidence 
they can be identified by examining the network structure and local cpts 
we can view the learning process of the ais bn algorithm as a network rebuilding
process  the algorithm constructs a new network whose structure is the same as the original
network  except that we delete the evidence nodes and corresponding arcs   the constructed
network models the joint probability distribution  x e  in equation    which approaches
the optimal importance function  we use the learned   to approximate this distribution 
if   approximates pr x e  accurately enough  we can use this new network to solve other
approximate tasks  such as the problem of computing the maximum a posterior assignment
 map   pearl         finding k most likely scenarios  seroussi   golmard         etc  a
large advantage of this approach is that we can solve each of these problems as if the network
had no evidence nodes 
we know that markov blanket scoring can improve convergence rates in some sampling
algorithms  shwe   cooper         it may also be applied to the ais bn algorithm to
improve its convergence rate  according to property    section       any technique that can
 
c
reduce the variance pr
will reduce the variance of pr e 
and correspondingly improve
 e 
the sampling performance  since the variance of stratified sampling  rubinstein        is
never much worse than that of random sampling  and can be much better  it can improve the
convergence rate  we expect some other variance reduction methods in statistics  such as 
 i  the expected value of a random variable   ii  antithetic variants correlations  stratified
sampling  latin hypercube sampling  etc    and  iii  systematic sampling  will also improve
the sampling performance 
current learning algorithm used a simple approach  some heuristic learning methods 
such as adjusting learning rates according to changes of the error  jacobs         should
also be applicable to our algorithm  there are several tunable parameters in the ais bn
algorithm  finding the optimal values of these parameters for any given network is another
interesting research topic 
it is worth observing that the plots presented in figure   are fairly flat  in other words 
in our tests the convergence of the sampling algorithms did not depend too strongly on the
probability of evidence  this seems to contradict the common belief that forward sampling
schemes suffer from unlikely evidence  ais bn for one shows a fairly flat plot  the
convergence of the sis and lw algorithms seems to decrease slightly with unlikely evidence 
it is possible that all three algorithms will perform much worse when the probability of
evidence drops below some threshold value  which our tests failed to approach  until this
   

ficheng   druzdzel

relationship has been studied carefully  we conjecture that the probability of evidence is not
a good measure of difficulty of approximate inference 
given that the problem of approximating probabilistic inference is np hard  there exist
networks that will be challenging for any algorithm and we have no doubt that even the
ais bn algorithm will perform poorly on them  to the day  we have not found such
networks  there is one characteristic of networks that may be challenging to the ais bn
algorithm  in general  when the number of parameters that need to be learned by the aisbn algorithm increases  its performance will deteriorate  nodes with many parents  for
example  are challenging to the ais bn learning algorithm  as it has to update the icpt
tables under all combinations of the parent nodes  it is possible that conditional probability
distributions with causal independence properties  such as noisy or distributions  pearl 
      henrion        diez        srinivas        heckerman   breese         common in
very large practical networks  can be treated differently and lead to considerable savings in
the learning time 
one direction of testing approximate algorithms  suggested to us by a reviewer  is to use
very large networks for which exact solution cannot be computed at all  in this case  one
can try to infer from the difference in variance at various stages of the algorithm whether
it is converging or not  this is a very interesting idea that is worth exploring  especially
when combined with theoretical work on stopping criteria in the line of the work of dagum
and luby        

   conclusion
computational complexity remains a major problem in application of probability theory
and decision theory in knowledge based systems  it is important to develop schemes that
improve the performance of updating algorithms  even though the theoretically demonstrated worst case will remain nphard  many practical cases may become tractable 
in this paper  we studied importance sampling in bayesian networks  after reviewing
the most important theoretical results related to importance sampling in finite dimensional
integrals  we proposed a new algorithm for importance sampling in bayesian networks that
we call adaptive importance sampling  ais bn   while the process of learning the optimal
importance function for the ais bn algorithm is computationally intractable  based on the
theory of importance sampling in finite dimensional integrals we proposed several heuristics
that seem to work very well in practice  we proposed heuristic methods for initializing the
importance function that we have shown to accelerate the learning process  a smooth learning method for updating importance function using the structural advantages of bayesian
networks  and a dynamic weighting function for combining samples from different stages
of the algorithm  all these methods help the ais bn algorithm to get fairly accurate
estimates of the posterior probabilities in a limited time  of the two applied heuristics 
adjustment of small probabilities  seems to lead to the largest improvement in performance 
although the largest decrease in mse is achieved by a combination of the two heuristics
with the ais bn algorithm 
the ais bn algorithm can lead to a dramatic improvement in the convergence rates in
large bayesian networks with evidence compared to the existing state of the art algorithms 
we compared the performance of the ais bn algorithm to the performance of likelihood
   

fiadaptive importance sampling in bayesian networks

weighting and self importance sampling on a large practical model  the cpcs network 
with evidence as unlikely as            and typically            in our experiments  we
observed that the ais bn algorithm was always better than likelihood weighting and selfimportance sampling and in over     of the cases it reached over two orders of magnitude
improvement in accuracy  tests performed on the other two networks  pathfinder and
andes  yielded similar results 
although there may exist other approximate algorithms that will prove superior to aisbn in networks with special structure or distribution  the ais bn algorithm is simple
and robust for general evidential reasoning problems in large multiply connected bayesian
networks 

acknowledgments
we thank anonymous referees for several insightful comments that led to a substantial
improvement of the paper  this research was supported by the national science foundation
under faculty early career development  career  program  grant iri         and by
the air force office of scientific research grants f             and f        
      an earlier version of this paper has received the      school of information sciences
robert r  korfhage award  university of pittsburgh  malcolm pradhan and max henrion
of the institute for decision systems research shared with us the cpcs network with a kind
permission from the developers of the internist system at the university of pittsburgh  we
thank david heckerman for the pathfinder network and abigail gerner for the andes
network used in our tests  all experimental data have been obtained using smile  a
bayesian inference engine developed at the decision systems laboratory and available at
http   www  sis pitt edu genie 

references
cano  j  e   hernandez  l  d     moral  s          importance sampling algorithms for the
propagation of probabilities in belief networks  international journal of approximate
reasoning           
chavez  m  r     cooper  g  f          a randomized approximation algorithm for probabilistic inference on bayesian belief networks  networks                 
cheng  j     druzdzel  m  j       a   computational investigations of low discrepancy
sequences in simulation algorithms for bayesian networks  in proceedings of the sixteenth annual conference on uncertainty in artificial intelligence  uai       pp 
     san francisco  ca  morgan kaufmann publishers 
cheng  j     druzdzel  m  j       b   latin hypercube sampling in bayesian networks  in
proceedings of the   th international florida artificial intelligence research symposium conference  flairs        pp         orlando  florida 
conati  c   gertner  a  s   vanlehn  k     druzdzel  m  j          on line student modeling
for coached problem solving using bayesian networks  in proceedings of the sixth
   

ficheng   druzdzel

international conference on user modeling  um     pp         vienna  new york 
springer verlag 
cooper  g  f          the computational complexity of probabilistic inference using bayesian belief networks  artificial intelligence                  
cousins  s  b   chen  w     frisse  m  e          a tutorial introduction to stochastic
simulation algorithm for belief networks  in artificial intelligence in medicine  chap    
pp          elsevier science publishers b v 
dagum  p   karp  r   luby  m     ross  s          an optimal algorithm for monte
carlo estimation  extended abstract   in proceedings of the   th ieee symposium
on foundations of computer science  pp         portland  oregon 
dagum  p     luby  m          approximating probabilistic inference in bayesian belief
networks is np hard  artificial intelligence                 
dagum  p     luby  m          an optimal approximation algorithm for bayesian inference 
artificial intelligence          
diez  f  j          parameter adjustment in bayes networks  the generalized noisy orgate  in proceedings of the ninth annual conference on uncertainty in artificial
intelligence  uai     pp        san francisco  ca  morgan kaufmann publishers 
fishman  g  s          monte carlo  concepts  algorithms  and applications  springerverlag 
fung  r     chang  k  c          weighing and integrating evidence for stochastic simulation in bayesian networks  in uncertainty in artificial intelligence    pp        
new york  n  y  elsevier science publishing company  inc 
fung  r     del favero  b          backward simulation in bayesian networks  in proceedings
of the tenth annual conference on uncertainty in artificial intelligence  uai    
pp         san francisco  ca  morgan kaufmann publishers 
geman  s     geman  d          stochastic relaxations  gibbs distributions and the bayesian restoration of images  ieee transactions on pattern analysis and machine
intelligence                
gilks  w   richardson  s     spiegelhalter  d          markov chain monte carlo in practice  chapman and hall 
heckerman  d     breese  j  s          a new look at causal independence  in proceedings
of the tenth annual conference on uncertainty in artificial intelligence  uai    
pp         san mateo  ca  morgan kaufmann publishers  inc 
heckerman  d  e   horvitz  e  j     nathwani  b  n          toward normative expert
systems  the pathfinder project  tech  rep  ksl      medical computer science
group  section on medical informatics  stanford university  stanford  ca 
   

fiadaptive importance sampling in bayesian networks

henrion  m          propagating uncertainty in bayesian networks by probabilistic logic
sampling  in uncertainty in artificial intellgience    pp         new york  n  y 
elsevier science publishing company  inc 
henrion  m          some practical issues in constructing belief networks  in kanal  l  
levitt  t     lemmer  j   eds    uncertainty in artificial intelligence    pp         
elsevier science publishers b v   north holland 
henrion  m          search based methods to bound diagnostic probabilities in very large
belief nets  in proceedings of the seventh annual conference on uncertainty in artificial intelligence  uai     pp         san mateo  california  morgan kaufmann
publishers 
hernandez  l  d   moral  s     antonio  s          a monte carlo algorithm for probabilistic
propagation in belief networks based on importance sampling and stratified simulation
techniques  international journal of approximate reasoning           
jacobs  r  a          increased rates of convergence through learning rate adaptation 
neural networks            
lauritzen  s  l     spiegelhalter  d  j          local computations with probabilities on
graphical structures and their application to expert systems  journal of the royal
statistical society  series b  methodological                  
mackay  d          intro to monte carlo methods  in jordan  m  i   ed    learning in
graphical models  the mit press  cambridge  massachusetts 
ortiz  l  e     kaelbling  l  p          adaptive importance sampling for estimation in
structured domains  in proceedings of the sixteenth annual conference on uncertainty in artificial intelligence  uai       pp         san francisco  ca  morgan
kaufmann publishers 
pearl  j          fusion  propagation  and structuring in belief networks  artificial intelligence                 
pearl  j          evidential reasoning using stochastic simulation of causal models  artifical
intelligence             
pearl  j          probabilistic reasoning in intelligent systems  networks of plausible
inference  morgan kaufmann publishers  inc   san mateo  ca 
pradhan  m     dagum  p          optimal monte carlo inference  in proceedings of the
twelfth annual conference on uncertainty in artificial intelligence  uai     pp 
       san francisco  ca  morgan kaufmann publishers 
pradhan  m   provan  g   middleton  b     henrion  m          knowledge engineering
for large belief networks  in proceedings of the tenth annual conference on uncertainty in artificial intelligence  uai     pp         san francisco  ca  morgan
kaufmann publishers 
   

ficheng   druzdzel

ritter  h   martinetz  t     schulten  k          neuronale netze  addison wesley 
munchen 
rubinstein  r  y          simulation and the monte carlo method  john wiley   sons 
seroussi  b     golmard  j  l          an algorithm directly finding the k most probable
configurations in bayesian networks  international journal of approximate reasoning 
           
shachter  r  d     peot  m  a          simulation approaches to general probabilistic
inference on belief networks  in uncertainty in artificial intelligence    pp        
new york  n  y  elsevier science publishing company  inc 
shwe  m  a     cooper  g  f          an empirical analysis of likelihood weighting simulation on a large  multiply connected medical belief network  computers and biomedical
research                 
shwe  m   middleton  b   heckerman  d   henrion  m   horvitz  e     lehmann  h         
probabilistic diagnosis using a reformulation of the internist  qmr knowledge
base  i  the probabilistic model and inference algorithms  methods of information in
medicine                 
srinivas  s          a generalization of the noisy or model  in proceedings of the ninth
annual conference on uncertainty in artificial intelligence  uai     pp        
san francisco  ca  morgan kaufmann publishers 
york  j          use of the gibbs sampler in expert systems  artificial intelligence     
       

   

fi