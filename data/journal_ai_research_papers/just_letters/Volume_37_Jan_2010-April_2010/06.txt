journal of artificial intelligence research                  

submitted        published      

context based word acquisition for situated dialogue in a
virtual world

shaolin qu
joyce y  chai

qushaoli cse msu edu
jchai cse msu edu

department of computer science and engineering
michigan state university
east lansing  mi       usa

abstract
to tackle the vocabulary problem in conversational systems  previous work has applied
unsupervised learning approaches on co occurring speech and eye gaze during interaction to
automatically acquire new words  although these approaches have shown promise  several
issues related to human language behavior and human machine conversation have not been
addressed  first  psycholinguistic studies have shown certain temporal regularities between
human eye movement and language production  while these regularities can potentially
guide the acquisition process  they have not been incorporated in the previous unsupervised approaches  second  conversational systems generally have an existing knowledge
base about the domain and vocabulary  while the existing knowledge can potentially
help bootstrap and constrain the acquired new words  it has not been incorporated in the
previous models  third  eye gaze could serve different functions in human machine conversation  some gaze streams may not be closely coupled with speech stream  and thus
are potentially detrimental to word acquisition  automated recognition of closely coupled
speech gaze streams based on conversation context is important  to address these issues 
we developed new approaches that incorporate user language behavior  domain knowledge 
and conversation context in word acquisition  we evaluated these approaches in the context of situated dialogue in a virtual world  our experimental results have shown that
incorporating the above three types of contextual information significantly improves word
acquisition performance 

   introduction
one major bottleneck in human machine conversation is robust language interpretation 
when the encountered vocabulary is outside of the systems knowledge  the system tends
to fail  as conversational interfaces have become increasingly important in many applications such as remote interaction with robots  lemon  gruenstein    peters        fong
  nourbakhsh        and automated training and education  traum   rickel         the
ability to automatically acquire new words during online conversation becomes essential 
different from traditional telephony based spoken dialogue systems  in conversational interfaces users can look at a graphic display or a virtual world while interacting with artificial
agents using natural speech  this unique setting provides an opportunity for automated
vocabulary acquisition  during interaction  users visual perception  e g   as indicated by
eye gaze  provides a potential channel for the system to automatically learn new words 
c
    
ai access foundation  all rights reserved 

fiqu   chai

the idea  as shown in previous work  yu   ballard        liu  chai    jin         is that
the parallel data of visual perception and spoken utterances can be used by unsupervised
approaches to automatically identify the mappings between words and visual entities and
thus acquire new words  while previous approaches provide a promising direction  they
mainly rely on the co occurrence between words and visual entities in a completely unsupervised manner  however  in human machine conversation  there are different types of
extra information related to human language behaviors and characteristics of conversation
systems  although this extra information can potentially provide supervision to guide the
word acquisition process and improve performance  it has not been systematically explored
in previous work 
first  a large body of psycholinguistic studies have shown that eye gaze is tightly linked
to human language processing  this is evident in both language comprehension  tanenhaus  spivey knowiton  eberhard    sedivy        eberhard  spivey knowiton  sedivy   
tanenhaus        allopenna  magnuson    tanenhaus        dahan   tanenhaus       
spivey  tanenhaus  eberhard    sedivy        and language production  meyer  sleiderink 
  levelt        rayner        griffin   bock        bock  irwin  davidson    leveltb       
brown schmidt   tanenhaus        griffin         specifically in human language production  which is directly relevant to automated computer interpretation of human language 
studies have found significant temporal regularities between the mentioned objects and the
corresponding words  meyer et al         rayner        griffin   bock         in object
naming tasks  the onset of a word begins approximately one second after a speaker has
looked at the corresponding visual referent  griffin         and gazes are longer the more
difficult the name of the referent is to retrieve  meyer et al         griffin         about
        ms after the articulation of the object name begins  the eyes move to the next object relevant to the task  meyer et al          all these findings suggest that eyes move to
the mentioned objects before the corresponding words are uttered  although this language
behavior can be used to constrain the mapping between words and visual objects  it has
not been incorporated in the previous approaches 
second  practical conversational systems always have existing knowledge about their application domains and vocabularies  this knowledge base is acquired at their development
time  either authored by the domain experts or automatically learned from available data 
although the existing knowledge can be rather limited and is desired to be enhanced automatically online  e g   through automated vocabulary acquisition   it provides important
information about the structure of the domain and the existing vocabularies  which can
further bootstrap and constrain new word acquisition  this type of domain knowledge has
not been utilized in previous approaches 
third  although psycholinguistic studies provide us with a sound empirical basis for
assuming that eye movements are predictive of speech  the gaze behavior in an interactive
setting can be much more complex  there are different types of eye movements  kahneman 
       the naturally occurring eye gaze during speech production may serve different
functions  for example  to engage in the conversation or to manage turn taking  nakano 
reinstein  stocky    cassell         furthermore  while interacting with a graphic display 
a user could be talking about objects that were previously seen on the display or something
completely unrelated to any object the user is looking at  therefore using all the speechgaze pairs for word acquisition can be detrimental  the type of gaze that is mostly useful
   

ficontext based word acquisition for situated dialogue in a virtual world

for word acquisition is the kind that reflects the underlying attention and tightly links to the
content of the co occurring speech  thus  automatically recognizing closely coupled speech
and gaze streams during online conversation for word acquisition is important  however  it
has not been examined in previous work 
to address the above three issues  we have developed new approaches to automatic word
acquisition that     incorporate findings on user language behavior from psycholinguistic
studies  in particular the temporal alignment between spoken words and eye gaze      utilize
the existing domain knowledge  and     automatically identify closely coupled speech and
gaze streams based on conversation context  we evaluated these approaches in the context of
situated dialogue in a virtual world  our experimental results have shown that incorporating
the above three types of contextual information significantly improves word acquisition
performance  our simulation studies further demonstrate the effect of automatic online
word acquisition on improving language understanding in human machine conversation 
in the following sections  we first introduce the domain and data collection in our investigation  we then describe the enhanced models for word acquisition that incorporate
additional contextual information  e g   language behavior between spoken words and eye
gaze  domain knowledge  conversation context   finally  we present the empirical evaluation
of our enhanced models and demonstrate the effect of online word acquisition on spoken
language understanding during human machine conversation 

   related work
our work is motivated by previous work on grounded language acquisition and eye gaze in
multimodal human computer interaction 
grounded language acquisition is to learn the meaning of language by connecting the
language to the perception of the world  language acquisition by grounding words to the
visual perceptions of objects has been studied in various language learning systems  for
example  given speech paired with video images of single objects  mutual information between audio and visual signals was used to learn words by associating acoustic phoneme
sequences with the visual prototypes  e g   color  size  shape  of objects  roy   pentland 
      roy         generative models were developed to learn words by associating words
with image regions given parallel data of pictures and description text  barnard  duygulu 
de freitas  forsyth  blei    jordan         given pairs of spoken instructions containing
object names and the corresponding objects  an utterance object joint probability model
was used to learn object names by identifying object name phonemes and associating them
with the objects  taguchi  iwahashi  nose  funakoshi    nakano         given sequences
of utterances paired with scene representations  an incremental translation model was developed to learn word meaning by associating words with the semantic representations of
the referents in the scene  fazly  alishahi    stevenson         in addition to grounding
individual words  previous work has also investigated grounding phrases  referring expressions  to visual objects through semantic decomposition  for example using context free
grammar that connects linguistic structures with underlying visual properties  gorniak  
roy        
besides visual objects  approaches have also been developed to ground words to meaning representations of events  for example  event logic was applied to ground verbs to
   

fiqu   chai

motion events that were represented by force dynamics encoding the support  contact  and
attachment relations between objects in video images  siskind         in a video game
domain  a translation model was used to ground words to the semantic roles of user actions  fleischman   roy         in a simulated robocup soccer domain  given textual game
commentaries paired with the symbolic descriptions of game events  approaches based on
statistical parsing and learning were developed to ground the commentary text to game
events  chen   mooney         in a less restricted data setting  generative models were
developed to simultaneously segment the text into utterances and map the utterances to
meaning representations of event states  liang  jordan    klein         different from
the above previous work  in our work  the visual perception is indicated by eye gaze  eye
gaze  on one hand  is indicative of human attention  which provides opportunities to link
language and perception  on the other hand  is an implicit and subconscious input  which
could bring additional challenge in word acquisition 
eye gaze has long been explored in human computer interaction for direct manipulation interfaces as a pointing device  jacob        wang        zhai  morimoto    ihde 
       eye gaze as a modality in multimodal interaction goes beyond the function of
pointing  in different speech and eye gaze systems  eye gaze has been explored for the
purpose of mutual disambiguation  tanaka        zhang  imamiya  go    mao         as a
complement to the speech channel for reference resolution  campana  baldridge  dowding 
hockey  remington    stone        kaur  termaine  huang  wilder  gacovski  flippo 
  mantravadi        prasov   chai        byron  mampilly  sharma    xu        and
speech recognition  cooke        qu   chai         and for managing human computer
dialogue  qvarfordt   zhai        
eye gaze has been explored recently for word acquisition  for example  yu and ballard
       proposed an embodied multimodal learning interface for word acquisition  especially
through eye movement  in this work  given speech paired with eye gaze information and
video images  a translation model was applied to acquire words by associating acoustic
phone sequences with visual representations of objects and actions  this work has inspired
our research and is mostly related to our effort here  the difference between our work
and the work by yu and ballard lies in two aspects  first  the learning environment is
different  while yu and ballard focuses on the narrative descriptions of actions  e g  
making a sandwich  pouring some drinks  etc   from human subjects  our focus is on
interactive conversation  in conversation  a human participant can take both a speaker
role and an addressee role  this represents a new scenario where word acquisition based
on eye movement may have new implications  second  in the work by yu and ballard 
the ibm translation model   was applied to word acquisition  in our work  we further
incorporate other types of information such as user language behavior  domain knowledge 
and conversation context in the translation models 
in our previous work  we have experimented the application of ibm translation model
  in vocabulary acquisition through gaze modeling in a conversation setting  liu et al  
       we have reported our initial investigation on incorporating temporal information
and domain knowledge in translation models  qu   chai        as well as automatically
identifying closely coupled speech and gaze streams  qu   chai         this paper extends
our previous work and provides a comprehensive evaluation on incorporating knowledge and
interactivity in word acquisition in a much richer application domain  we further examine
   

ficontext based word acquisition for situated dialogue in a virtual world

how word acquisition is affected by automated speech recognition and what is the effect of
online word acquisition on language understanding in human machine conversation 

   domain and data
to facilitate our work on word acquisition  we collected data based on situated dialogue
in a virtual world  this data set is different from the data set used in our previous investigation  qu   chai         the difference lies in two aspects     this dataset was
collected during mixed initiative human machine conversation whereas the data in our previous investigation was based only on question and answering     user studies in this work
were conducted in the context of situated dialogue  where human users are immersed in a
complex virtual world and can move around in the virtual environment 
    domain

figure    treasure hunting domain
the application of our virtual world is for treasure hunting  a human user is immersed
in a virtual world  i e   a castle    and is able to move around to look for hidden treasures 
the castle contains      d objects  the user needs to consult with a remote expert  i e  
the artificial agent  for advice on finding the treasures  the expert has some knowledge
about the environment and the treasures but cannot see where the user is in the castle  so
the user needs to describe to the expert where he is and what he sees in order to get advice
on where to go and what to look for 
figure   shows a snapshot of our virtual world  figure   shows an excerpt of the dialog
between a user and the expert in finding one of the treasures  to focus our investigation on
word acquisition  we conducted wizard of oz studies to collect data     more specifically  a set
of response templates corresponding to different types of responses are predefined  at each
   the virtual world was developed based on the irrlicht game engine http   irrlicht sourceforge net  
   woz studies allow the observation of a user interacting with a fully functional system  where some
or all of system functions are supplemented by a hidden human wizard  users are led to believe they
are interacting with a real system  klemmer  sinha  chen  landay  aboobaker    wang         this
technology  which permits the experimentally controlled study of human computer interaction behavior
without exposing users to unpredicted responses  has been used widely in earlier research on speech
interfaces and multimodal systems 

   

fiqu   chai

s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 
u 
s 

tell me what you see 
i see a golden tomb or sarcophagus 
describe it 
it appears to be made of gold and there are egyptian decorations on it 
what else do you see 
i see a carving hanging on the wall appears to be african 
go back 
im back by the sarcophagus  there appears to be lava surrounding it or fire 
i couldnt understand you 
the room that the sarcophagus is in is surrounded by lava or fire 
do you see a statue 
should i try to open the sarcophagus 
no 
i see a statue 
describe 
it appears to be a stone statue of an egyptian 
what else do you see 
i see a small vase a pottery vase decorated with flowers 
the treasure is near 
should i try to move the vase 
yes 
i cant move the vase 
do you see another one 
yes  theres a wooden table with a pottery jug and a purple vase on it  should i try to move
the purple vase 
do you see a statue 
yes  i see a stone statue 
do you see another one 
yes  i see a gold and black statue of an egyptian sitting 
compare these objects 
the stone statue is in very bad shape  and the golden statue appears to be in good shape  it
has a golden crown  it is sitting in a wooden chair 
try moving it 
i move the head off the statue and now i see a scroll  should i take the scroll 
describe 
it is a white scroll with a red seal 
take it 
i took the scroll 
good 

figure    the dialog between a user and the system in finding one of the treasures

system turn  the system automatically determines what kind of responses  i e   template 
should be provided  for example  whether to ask for clarification  provide confirmation 
or ask more information about a particular object  such decision is made based on a
distribution to simulate different types of system acceptance and rejection  this distribution
can be modified according to different needs of the experiments  based on the chosen
template  the human wizard then serves as a language understanding component and fills
in this template with the specific information related to the user input  the filled template is
   

ficontext based word acquisition for situated dialogue in a virtual world

used to automatically generate natural language which is further processed by the microsoft
text to speech engine to generate speech responses  during the experiments  the users
speech was recorded  and the users eye gaze was captured by a tobii eye tracker 
    data preprocessing
from    users experiments  we collected      utterances with accompanying gaze fixations 
we transcribed the collected speech  the vocabulary size of the speech transcript is      
among which     are nouns adjectives  the users speech was also automatically recognized
online by the microsoft speech recognizer with a word error rate  wer  of       for the
  best recognition  the vocabulary size of the   best speech recognition is       among
which      are nouns adjectives  the nouns and adjectives in the transcriptions and the
recognized   best hypotheses were automatically identified by the stanford part of speech
tagger  toutanova   manning        toutanova  klein  manning    singer        
theres

a

purple

vase

in

an

orange

face
speech str eam

gaze fixation

ts
 table vase   vase purple 

gaze str eam

te

 vase greek    vase greek  

 vase greek  

 vase greek  

 fixated entity 

figure    accompanying gaze fixations and the   best recognition of a users utterance
theres a purple vase and an orange vase   there are two incorrectly recognized
words in and face in the   best recognition 

the collected speech and gaze streams were automatically paired together by the system 
each time the system detected a sentence boundary of the users speech  it paired the
recognized speech with the gaze fixations that the system had been accumulating since the
previously detected sentence boundary  figure   shows a stream pair of a users speech and
its accompanying gaze fixations  in the speech stream  each spoken word was timestamped
by the speech recognizer  in the gaze stream  each gaze fixation has a starting timestamp
ts and an ending timestamp te provided by the eye tracker  each gaze fixation results in a
fixated entity   d object   when multiple entities are fixated by one gaze fixation due to the
overlapping of the entities  the foremost one is chosen  in the gaze stream  the neighboring
gaze fixations that fixate the same entity are merged 
given the paired speech and gaze streams  we build a set of parallel word sequences and
gaze fixated entity sequences   w  e   for the task of word acquisition  the word sequence
w consists of only nouns and adjectives from the   best recognition of the spoken utterance 
the entity sequence e contains the entities fixated by the gaze fixations  for the parallel
speech and gaze streams shown in figure    the resulting word sequence is w    purple vase
orange face  and the resulting entity sequence is e    table vase vase purple vase greek    
   

fiqu   chai

   translation models for word acquisition
since we are working on conversational systems where users interact with a visual scene 
we consider the task of word acquisition as associating words with visual entities in the
domain  given the parallel speech and gaze fixated entities   w  e    we formulate word
acquisition as a translation problem and use translation models to estimate word entity
association probabilities p w e   the words with the highest association probabilities are
chosen as acquired words for entity e 
    base model i
using the translation model i  brown  pietra  pietra    mercer         where each word is
equally likely to be aligned with each entity  we have
m x
l
y
 
p w e   
p wj  ei  
 l     m

   

j   i  

where l and m are the lengths of the entity and word sequences respectively  we refer to
this model as model   
    base model ii
using the translation model ii  brown et al          where alignments are dependent on
word entity positions and word entity sequence lengths  we have
p w e   

m x
l
y

p aj   i j  m  l p wj  ei  

   

j   i  

where aj   i means that wj is aligned with ei   when aj      wj is not aligned with any
entity  e  represents a null entity   we refer to this model as model   
compared to model    model   considers the ordering of words and entities in word
acquisition  em algorithms are used to estimate the probabilities p w e  in the translation
models 

   incorporating user language behavior in word acquisition
in model    word entity alignments are estimated from co occurring word and entity sequences in an unsupervised way  the estimated alignments are dependent on where the
words entities appear in the word entity sequences  not on when those words and gaze
fixated entities actually occur  motivated by the findings that users move their eyes to
the mentioned object directly before speaking a word  griffin   bock         we make the
word entity alignments dependent on their temporal relation in a new model  referred as
model  t  
m x
l
y
p w e   
pt  aj   i j  e  w p wj  ei  
   
j   i  

   

ficontext based word acquisition for situated dialogue in a virtual world

where pt  aj   i j  e  w  is the temporal alignment probability computed based on the temporal distance between entity ei and word wj  
we define the temporal distance between ei and wj as

ts  ei    ts  wj    te  ei  
  
te  ei    ts  wj   ts  wj     te  ei  
d ei   wj    
   

ts  ei    ts  wj   ts  wj     ts  ei  
where ts  wj   is the starting timestamp  ms  of word wj   ts  ei   and te  ei   are the starting
and ending timestamps  ms  of gaze fixation on entity ei  
the alignment of word wj and entity ei is decided by their temporal distance d ei   wj   
based on the psycholinguistic finding that eye gaze happens before a spoken word  wj is not
allowed to be aligned with ei when wj happens earlier than ei  i e   d ei   wj         when wj
happens no earlier than ei  i e   d ei   wj        the closer they are  the more likely they are
aligned  specifically  the temporal alignment probability of wj and ei in each co occurring
instance  w  e  is computed as

 
d ei   wj      



 exp   d ei   wj   
d ei   wj     
l
pt  aj   i j  e  w   
   
x


exp   d ei   wj   


i  

where  is a constant for scaling d ei   wj   
an em algorithm is used to estimate probabilities p w e  and  in model  t  it is
worthwhile to mention that  findings from psycholinguistic studies have provided specific
offsets in terms of how eye gaze corresponds to speech production  for example  it shows
that speakers look at an object about a second before they say it  but about         ms
after articulation of the object name begins  the eyes move to the next object relevant to
the task  meyer et al          since the conversation setting in our study is much more
complex than the simple settings in psycholinguistic research  we found larger variations on
the offset  liu et al         in our data  therefore we chose not to use any offset in the
alignment model here 

   incorporating domain knowledge in word acquisition
speech gaze temporal alignment and occurrence statistics sometimes are not sufficient to
associate words to entities correctly  for example  suppose a user says there is a lamp on the
dresser  while looking at a lamp object on a table object  due to their co occurrence with
the lamp object  the words dresser and lamp are both likely to be associated with the lamp
object in the translation models  as a result  the word dresser is likely to be incorrectly
acquired for the lamp object  for the same reason  the word lamp could be acquired
incorrectly for the table object  to solve this type of association problem  the semantic
knowledge about the domain and words can be helpful  for example  the knowledge that
the word lamp is more semantically related to the object lamp can help the system avoid
associating the word dresser to the lamp object  specifically  we solve this type of wordentity association by utilizing the domain knowledge present in the system and external
lexical semantic resources 
   

fiqu   chai

on one hand  each conversational system has a domain model  which is the knowledge
representation about its domain such as the types of objects and their properties and relations  the task structures  etc  this domain model is usually acquired at the development
stage before the deployment of the system  the domain model provides an important resource to enable domain reasoning and language interpretation  devault   stone        
on the other hand  there are available resources about domain independent lexical knowledge  e g   wordnet  see fellbaum         the idea is that if the domain model can be
linked to the external lexical resources either manually or automatically at the development
state  then the external knowledge source can be used to help constrain the acquired words 
in the following sections  we first describe our domain modeling  then define the semantic
relatedness of word and entity based on domain modeling and wordnet semantic lexicon 
and finally describe different ways of using the semantic relatedness of word and entity to
help word acquisition 
    domain modeling
we model the treasure hunting domain as shown in figure    the domain model contains
all domain related semantic concepts  for practical conversational systems  this domain
modeling is typically acquired at the development stage either through manual authoring
by the domain experts or automated learning based on annotated data  in our current work 
all properties of the domain entities are represented by domain concepts  the entity properties include  semantic type  color  size  shape  and material  we use wordnet synsets to
represent the domain concepts  i e   synsets in the format of word part of speech senseid   the sense id here represents the specific wordnet sense associated with the word in
representing the concept  for example  the domain concepts sem plate and color of
the entity plate are represented by the synsets plate n   and color n   in wordnet 
note that the link between domain concepts and wordnet synsets can be automatically acquired given the existing vocabularies  here  to illustrate the idea  we simplify the problem
and directly connect domain concepts to synsets 
note that in the domain model  the domain concepts are not specific to a certain entity 
they are general concepts for a certain type of entity  multiple entities of the same type
have the same properties and share the same set of domain concepts  therefore  properties
such as color and size of an entity have general concepts color n   and size n  
instead of more specific concepts like yellow a   and big a    so their concepts can
be shared by other entities of the same type  but with different colors and sizes 
    semantic relatedness of word and entity
we compute the semantic relatedness of a word w and an entity e based on the semantic
similarity between w and the properties of e using the domain model as a bridge  specifically 
semantic relatedness sr e  w  is defined as
sr e  w    max sim s cie    sj  w  
i j

   

where cie is the i th property of entity e  s cie   is the synset of property cie as in domain model 
sj  w  is the j th synset of word w as defined in wordnet  and sim     is the similarity
score of two synsets 
   

ficontext based word acquisition for situated dialogue in a virtual world

do m a i n m o d e l

entities 

domain
concepts 

pharaoh

plate

sem plate

color

sem pharaoh

color

size

color n  

wordnet
concepts 

pharaoh n  

plate n  

picture n  

size n  

figure    domain model with domain concepts represented by wordnet synsets

we computed the similarity score of two synsets based on the path length between them 
the similarity score is inversely proportional to the number of nodes along the shortest path
between the synsets as defined in wordnet  when the two synsets are the same  they have
the maximal similarity score of    the wordnet similarity tool  pedersen  patwardhan   
michelizzi        was used for the synset similarity computation 
    word acquisition with word entity semantic relatedness
we can use the semantic relatedness of word and entity to help the system acquire semantically compatible words for each entity  and therefore improve word acquisition performance 
the semantic relatedness can be applied for word acquisition in two ways  post process the
learned word entity association probabilities by rescoring them with semantic relatedness 
or directly affect the learning of word entity associations by constraining the alignment of
word and entity in the translation models 
      rescoring with semantic relatedness
in the acquired word list for an entity ei   each word wj has an association probability p wj  ei  
that is learned from a translation model  we use the semantic relatedness sr ei   wj   to
redistribute the probability mass for each wj   the new association probability is given by 

p wj  ei  sr ei   wj  
p   wj  ei     x
p wj  ei  sr ei   wj  
j

   

   

fiqu   chai

      semantic alignment constraint in translation model
when used to constrain the word entity alignment in the translation model  semantic relatedness can be used alone or used together with speech gaze temporal information to decide
the alignment probability of word and entity  qu   chai        
 using only semantic relatedness to constrain word entity alignments in model  s  we
have
m x
l
y
p w e   
ps  aj   i j  e  w p wj  ei  
   
j   i  

where ps  aj   i j  e  w  is the alignment probability based on semantic relatedness 
sr ei   wj  
ps  aj   i j  e  w    x
sr ei   wj  

   

i

 using semantic relatedness and temporal information to constrain word entity alignments in model  ts  we have
p w e   

m x
l
y

pts  aj   i j  e  w p wj  ei  

    

j   i  

where pts  aj   i j  e  w  is the alignment probability that is decided by both temporal
relation and semantic relatedness of ei and wj  
ps  aj   i j  e  w pt  aj   i j  e  w 
pts  aj   i j  e  w    x
ps  aj   i j  e  w pt  aj   i j  e  w 

    

i

where ps  aj   i j  e  w  is the semantic alignment probability in equation      and
pt  aj   i j  e  w  is the temporal alignment probability given in equation     
em algorithms are used to estimate p w e  in model  s and model  ts 

   incorporating conversation context in word acquisition
as mentioned earlier  not all speech gaze pairs are useful for word acquisition  in a speechgaze pair  if the speech does not have any word that relates to any of the gaze fixated
entities  this instance only adds noise to word acquisition  therefore  we should identify
the closely coupled speech gaze pairs and only use them for word acquisition 
in this section  we first describe the feature extraction based on conversation interactivity  then describe the use of a logistic regression classifier to predict whether a speech gaze
pair is a closely coupled speech gaze instance  an instance where at least one noun
or adjective in the speech stream is referring to some gaze fixated entity in the gaze stream 
for the training of the classifier for speech gaze prediction  we manually labeled each instance whether it is a closely coupled speech gaze instance based on the speech transcript
and gaze fixations 
   

ficontext based word acquisition for situated dialogue in a virtual world

    features extraction
for a parallel speech gaze instance  the following sets of features are automatically extracted 
      speech features  s feat 
let cw be the count of nouns and adjectives in the utterance  and ls be the temporal length
of the speech  the following features are extracted from speech 
 cw  count of nouns and adjectives 
more nouns and adjectives are expected in the users utterance describing entities 
 cw  ls  normalized noun adjective count 
the effect of speech length ls on cw is considered 
      gaze features  g feat 
for each fixated entity ei   let lei be its fixation temporal length  note that several gaze
fixations may have the same fixated entity  lei is the total length of all the gaze fixations
that fixate on entity ei   we extract the following features from gaze stream 
 ce  count of different gaze fixated entities 
less fixated entities are expected when the user is describing entities while looking at
them 
 ce  ls  normalized entity count 
the effect of speech temporal length ls on ce is considered 
 maxi  lei    maximal fixation length 
at least one fixated entitys fixation is expected to be long enough when the user is
describing entities while looking at them 
 mean lei    average fixation length 
the average gaze fixation length is expected to be longer when the user is describing
entities while looking at them 
 var lei    variance of fixation lengths 
the variance of the fixation lengths is expected to be smaller when the user is describing entities while looking at them 
the number of gaze fixated entities is not only decided by the users eye gaze  it is also
affected by the visual scene  let cse be the count of all the entities that have been visible
during the length of the gaze stream  we also extract the following scene related feature 
 ce  cse  scene normalized fixated entity count 
the effect of the visual scene on ce is considered 
   

fiqu   chai

      user activity features  ua feat 
while interacting with the system  the users activity can also be helpful in determining
whether the users eye gaze is tightly linked to the content of the speech  the following
features are extracted from the users activities 
 maximal distance of the users movements  the maximal change of user position   d
coordinates  during the speech length 
the user is expected to move within a smaller range while looking at entities and
describing them 
 variance of the users positions
the user is expected to move less frequently while looking at entities and describing
them 
      conversation context features  cc feat 
while talking to the system  i e   the expert   the users language and gaze behavior
are influenced by the state of the conversation  for each speech gaze instance  we use the
previous system response type as a nominal feature to predict whether this is a closely
coupled speech gaze instance 
in our treasure hunting domain  there are eight types of system responses in two categories 
system initiative responses 
 specific see  the system asks whether the user sees a certain entity  e g   do you see
another couch  
 nonspecific see  the system asks whether the user sees anything  e g   do you see
anything else   tell me what you see 
 previous see  the system asks whether the user previously sees something  e g   have
you previously seen a similar object  
 describe  the system asks the user to describe in detail what the user sees  e g  
describe it  tell me more about it 
 compare  the system asks the user to compare what the user sees  e g   compare
these objects 
 clarify  the system asks the user to make clarification  e g   i did not understand
that  please repeat that 
 action request  the system asks the user to take action  e g   go back  try moving
it 
user initiative responses 
 misc  the system hands the initiative back to the user without specifying further
requirements  e g   i dont know  yes 
   

ficontext based word acquisition for situated dialogue in a virtual world

    logistic regression model
given the extracted feature x and the closely coupled label y of each instance in the
training set  we train a ridge logistic regression model  cessie   houwelingen        to
predict whether an instance is a closely coupled instance  y      or not  y      
in the logistic regression model  the probability that yi      given the feature xi  
 xi    xi            xim    is modeled by
p
i
exp  m
j   j xj  
p
p yi  xi    
i
    exp  m
j   j xj  
where j are the features weights to be learned 
the log likelihood l of the data  x  y  is
x
l    
 yi log p yi  xi         yi   log    p yi  xi    
i

in ridge logistic regression  parameters j are estimated by maximizing a regularized loglikelihood
l      l         
where  is the ridge parameter that is introduced to achieve more stable parameter estimation 
    evaluation of speech gaze identification
since the goal of identifying closely coupled speech gaze instances is to improve word acquisition and we are only interested in acquiring nouns and adjectives  only the instances with
recognized nouns adjectives are used for training the logistic regression classifier  among
the      instances with recognized nouns adjectives and gaze fixations               instances are labeled as closely coupled  the speech gaze prediction was evaluated by a    fold
cross validation 
table   shows the prediction precision and recall when different sets of features are used 
as seen in the table  as more features are used  the prediction precision goes up and the
recall goes down  it is important to note that prediction precision is more critical than
recall for word acquisition when sufficient amount of data is available  noisy instances
where the gaze does not link to the speech content will only hurt word acquisition since
they will guide the translation models to ground words to the wrong entities  although
higher recall can be helpful  its effect is expected to become less when co occurrences can
already be established 
the results show that speech features  s feat  and conversation context features  ccfeat   when used alone  do not improve prediction precision much compared to the baseline
of predicting all instances closely coupled with a precision of        when used alone 
gaze features  g feat  and user activity features  ua feat  are the two most useful feature
sets for increasing prediction precision  when they are used together  the prediction precision is further increased  adding either speech features or conversation context features
to gaze and user activity features  g feat   ua feat   s feat cc feat  increases the
prediction precision more  using all four sets of features  g feat   ua feat   s feat  
   

fiqu   chai

feature sets
null  baseline 
s feat
g feat
ua feat
cc feat
g feat   ua feat
g feat   ua feat   s feat
g feat   ua feat   cc feat
g feat   ua feat   s feat   cc feat

precision
     
     
     
     
     
     
     
     
     

recall
 
     
     
     
     
     
     
     
     

table    speech gaze prediction performances with different feature sets

cc feat  achieves the highest prediction precision  mcnemar tests have shown that this is a
significant change compared to using g feat   ua feat   s feat           p          and
all other feature configurations                   p            therefore  we choose to
use all feature sets to identify the closely coupled speech gaze instances for word acquisition 

   evaluation of word acquisition
each practical conversational system starts with an initial knowledge base  vocabulary   we
assume that the system already has one default word for each entity in its default vocabulary 
the default word of an entity indicates the semantic type of the entity  for example  the
word barrel is the default word for the entity barrel  among the acquired words  we only
evaluate those new words that are not in the systems vocabulary  for example  the word
barrel would be excluded from the candidate words acquired for the entity barrel 
    grounding words to domain concepts
based on the translation models for word acquisition  sections         we can obtain the
word entity association probability p w e   this probability provides a means to ground
words to entities  in conversational systems  one important goal of word acquisition is to
make the system understand the semantic meaning of new words  word acquisition by
grounding words to objects is not always sufficient for identifying their semantic meanings 
suppose the word green is grounded to a green chair object  so is the word chair  although
the system is aware that green is some word describing the green chair  it does not know
that the word green refers to the chairs color while the word chair refers to the chairs
semantic type  thus  after learning the word entity associations p w e  by the translation
models  we need to further ground words to domain concepts of entity properties 
based on the domain model discussed earlier  section       we apply wordnet to ground
words to domain concepts  for each entity e  based on association probabilities p w e   we
can choose the n best words as acquired words for e  those n best words have the n highest
association probabilities  for each word w acquired for e  the grounded concept ce for w is
   

ficontext based word acquisition for situated dialogue in a virtual world

chosen as the one that has the highest semantic relatedness with w 
ce   arg max max sim s cie    sj  w   
i

j

    

where sim s cie    sj  w   is the semantic similarity score defined in equation     
to evaluate the acquired words for the domain concepts  we manually compile a set of
gold standard words from all users speech transcripts and gaze fixations  those gold
standard words are the words that the users have used to refer to the entities and their
properties  e g   color  size  shape  during the interaction with the system  the automatically acquired words are evaluated against those gold standard words 
    evaluation metrics
following the standard evaluation on information retrieval  the following metrics are used
to evaluate the words acquired for domain concepts  i e   entity properties   ce   
 precision

p

ce

 recall

  words correctly acquired for ce
p
ce   words acquired for ce

p
ce   words correctly acquired for ce
p
ce   gold standard words of ce

 mean average precision  map 

map  

x pnw p  r   rel r 
r  
ne
e
 e

where ne is the number of the gold standard words of all the properties ce of entity
e  nw is the vocabulary size  p  r  is the acquisition precision at a given cut off rank r 
rel r  is a binary function indicating whether the word at rank r is a gold standard
word for some property ce of entity e 
    evaluation results
to investigate the effects of speech gaze temporal information and domain semantic knowledge on word acquisition  we compare the word acquisition performances of the following
models 
 model    base model i without word entity alignment  equation      
 model   r  model   with semantic relatedness rescoring of word entity association 
 model    base model ii with positional alignment  equation      
 model  s  enhanced model with semantic alignment  equation      
 model  t  enhanced model with temporal alignment  equation      
   

fiqu   chai

 model  ts  enhanced model with both temporal and semantic alignment  equation       
 model  t r  model  t with semantic relatedness rescoring of word entity association 
      results of using speech gaze temporal information
 

   

model  
model  
model  t

   

    
mean average precision

   

precision

   
   
   
   
   
   

    
    
   
    
    

   
 

    

 

   

   

   

   

   

   

   

   

   

 

    
m  

m  

m  t

recall

 a  precision vs recall

 b  mean average precision

figure    word acquisition performance when speech gaze temporal information is used
figure   shows the interpolated precision recall curves and mean average precisions
 maps  of model  t and the baseline models model   and model    as shown in the figure 
model   does not improve word acquisition compared to model    this result shows that
it is not helpful to consider the index based positional alignment of word and entity for
word acquisition  by incorporating speech gaze temporal alignment  model  t consistently
achieves higher precisions than model   at different recalls  in terms of map  model  t
significantly increases map  t         p          compared to model    this means that
the use of speech gaze temporal alignment improves word acquisition 
      results of using domain semantic relatedness
figure   shows the results of using domain semantic relatedness in word acquisition  as
shown in the figure  compared to the baseline of using no extra knowledge  model    
using domain semantic relatedness improves word acquisition no matter when it is used to
rescore word entity association  model   r  or to constrain word entity alignment  model s   compared to model    the map is significantly improved by model   r  t         p  
       and model  s  t         p          
domain semantic relatedness can also be used together with speech gaze temporal information to improve word acquisition  compared to model    the map is significantly increased by model  ts  t         p          that uses semantic relatedness together with temporal information to constrain word entity alignments and model  t r  t         p          
where semantic relatedness is used to rescore the word entity associations learned by model t 
   

ficontext based word acquisition for situated dialogue in a virtual world

 

   

model  
model   r
model  s
model  ts
model  t r

   

precision

   

    
mean average precision

   

   
   
   
   
   

    
    
   
    
    

   
 

    

 

   

   

   

   

   

   

   

   

   

 

    
m  

m   r

m  s

m  ts

m  t r

recall

 a  precision vs recall

 b  mean average precision

figure    word acquisition performance when domain semantic relatedness is used
comparing the two ways of using semantic relatedness for word acquisition  it is found
that rescoring word entity association with semantic relatedness works better  model  t r
achieve higher map  t         p          than model  ts 
it is also verified that using both speech gaze temporal alignment and domain semantic
relatedness rescoring works better than using either one alone  with temporal alignment
and semantic relatedness rescoring  model  t r significantly increases map when compared
to model   r  t         p          where only semantic relatedness rescoring is used and
model  t  t         p          where only temporal alignment is used 
      results based on identified closely coupled speech gaze streams
we have shown that model  t r  where both speech gaze temporal alignment and domain
semantic relatedness rescoring are incorporated  achieves the best word acquisition performance  therefore  model  t r is used to evaluate the word acquisition based on the
identified closely coupled speech gaze data  since model  t r requires linking domain models with external knowledge source  e g   wordnet  which may not be available for some
applications  we also evaluate the effect of the identification of closely coupled speech gaze
streams on word acquisition with model  t  where only speech gaze temporal alignment is
incorporated 
we evaluate the effect of automatic identification of closely coupled speech gaze instances
on word acquisition through a    fold cross validation  in each fold      of the data set
was used to train the logistic regression classifier for predicting closely coupled speechgaze instances  then all instances  predicted closely coupled instances  and true  manually
labeled  closely coupled instances of the other     of the data set were used for word
acquisition respectively  figures       show the averaged interpolated precision recall curves
and maps achieved by model  t and model  t r using all instances  all    only predicted
closely coupled instances  predicted    and true closely coupled instances  true  
when words are acquired by model  t  as shown in figure    using predicted closely
coupled instances achieves better performance than using all instances  the map is significantly increased  t         p          by acquiring words from predicted closely coupled
   

fiqu   chai

 

    

all
predicted
true

   

   
mean average precision

   

precision

   
   
   
   
   
   

    

    

    

   
 

 

   

   

   

   

   

   

   

   

   

    

 

all

predicted

true

recall

 a  precision vs recall

 b  mean average precision

figure    word acquisition performance by model  t on different data set

 

    

all
predicted
true

   

   
mean average precision

   

precision

   
   
   
   
   
   

    

    

    

   
 

 

   

   

   

   

   

   

   

   

   

 

    
all

predicted

true

recall

 a  precision vs recall

 b  mean average precision

figure    word acquisition performance by model  t r on different data set

instances  the result shows that the identification of closely coupled speech gaze instances
helps word acquisition  when the true closely coupled speech gaze instances are used for
word acquisition  the acquisition performance is further improved  this means that better
identification of closely coupled speech gaze instances can lead to better word acquisition
performance 
when words are acquired by model  t r  as shown in figure    using predicted closely
coupled instances improves acquisition performance compared to using all instances  by
acquiring words from predicted closely coupled speech gaze instances  the map is increased
 t         p          although this improvement is less significant than the one with model t 
   

ficontext based word acquisition for situated dialogue in a virtual world

 

    

all   best
all transcript
predicted   best
predicted transcript

   

    
mean average precision

   

precision

   
   
   
   
   
   

  best
transcript

    

    

   

    

   
 

 

   

   

   

   

   

   

   

   

   

    

 

all

predicted

recall

 a  precision vs recall

 b  mean average precision

figure    word acquisition performance by model  t on speech recognition and transcript
 

    

all   best
all transcript
predicted   best
predicted transcript

   

    
mean average precision

   

precision

   
   
   
   
   
   

  best
transcript

    

    

   

    

   
 

 

   

   

   

   

   

   

   

   

   

 

    
all

predicted

recall

 a  precision vs recall

 b  mean average precision

figure     word acquisition performance by model  t r on speech recognition and transcript

      comparison of results based on speech recognition and transcript
to show the effect of speech recognition quality on word acquisition  we also compare the
acquisition performances based on speech transcript and the   best recognition  when word
acquisition is based on speech transcript  the word sequence in the parallel speech gaze data
set contains nouns and adjectives in the speech transcript  accordingly  the speech feature
used for coupled speech gaze identification is extracted from the speech transcript 
figures        show the word acquisition performances of model  t and model  t r using
all instances and using only predicted coupled instances based on speech transcript and the
  best recognition respectively  as shown in the figures  the quality of speech recognition is
critical to word acquisition performance  as expected  word acquisition performance based
on speech transcript is much better than on recognized speech 
   

fiqu   chai

   examples
table   shows the    best candidate words acquired for the entity couch by model    model t  and model  t r based on all speech gaze instances and model  t r based on predicted
closely coupled instances  the probabilities of these candidate words are also given in the
table  across all these models  although the same four words  shown in bold font  are
acquired by each model  the ranking of the acquired words achieves the best by model  t r
based on predicted closely coupled instances 
table   shows another example of the    best candidate words acquired for the entity
stool by the four different models  model   acquires four correct words in the    best list 
although model  t also acquires four correct words in the    best list  the rankings of
these words are higher  with both speech gaze temporal alignment and domain semantic
relatedness rescoring  model  t r acquires seven correct words in the    best list  the
rankings of these correct words are also improved  compared to using all instances with
model  t r  although using the predicted coupled instances with model  t r results in the
same seven correct words with the same ranks in the    best list  the probabilities of these
correctly acquired words are higher  this means that the results based on the predicted
coupled instances are more confident 
model
rank  
rank  
rank  
rank  
rank  
rank  
rank  
rank  
rank  
rank   

model  
couch        
bedroom        
chair        
bad        
room        
wooden        
bench        
small        
yellow        
couple        

model  t
couch        
chair        
bed        
small        
room        
bad        
yellow        
bench        
lot        
wooden        

model  t r
couch        
chair        
bench        
bed        
small        
bad        
room        
lot        
yellow        
couple        

model  t r predicted 
couch        
chair        
bench         
bed        
small        
bad        
room        
yellow        
couple        
lot        

table    n best candidate words acquired for the entity couch by different models

model
rank  
rank  
rank  
rank  
rank  
rank  
rank  
rank  
rank  
rank   

model  
plant        
room        
little        
flower        
stairs        
call        
square        
footstool        
brown        
short        

model  t
plant        
room        
little        
flower        
square        
small        
next        
stool        
brown        
stairs        

model  t r
stool        
little        
small        
footstool        
ottoman        
ground        
media        
chair        
plant        
square        

model  t r predicted 
stool        
little        
small        
footstool        
ottoman        
ground        
media        
chair        
plant        
square        

table    n best candidate words acquired for the entity stool by different models

   

ficontext based word acquisition for situated dialogue in a virtual world

    the effect of online word acquisition on language understanding
one important goal of word acquisition is to use the acquired new words to help language
understanding in subsequent conversation  to demonstrate the effect of online word acquisition on language understanding  we conduct simulation studies based on our collected
data  in these simulations  the system starts with an initial knowledge base  a vocabulary
of words associated to domain concepts  the system continuously enhances its knowledge
base by acquiring words from users with model  t r that incorporates both speech gaze
temporal information and domain semantic relatedness  the enhanced knowledge base is
used to understand the language of new users 
we evaluate language understanding performance on concept identification rate  cir  
cir  

 correctly identified concepts in the   best speech recognition
 concepts in the speech transcript

we simulate the process of online word acquisition and evaluate its effect on language
understanding for two situations     the system starts with no training data but with a
small initial vocabulary  and    the system starts with some training data 
     simulation    when the system starts with no training data
to build conversational systems  one approach is that domain experts provide domain vocabulary to the system at design time  our first simulation follows this practice  the
system is provided with a default vocabulary to start without training data  the default
vocabulary contains one seed word for each domain concept 
using the collected data of    users  the simulation process goes through the following
steps 
 for user index i                    
 evaluate cir of the i th users utterances    best speech recognition  with the
current system vocabulary 
 acquire words from all the instances  with   best speech recognition  of users
     i 
 among the    best acquired words  add verified new words to the system vocabulary 
in the above process  the language understanding performance on each individual user
depends on the users own language as well as the users position in the user sequence 
to reduce the effect of user ordering on language understanding performance  the above
simulation process is repeated      times with randomly ordered users  the average of the
cirs in these simulations is shown in figure    
figure    also shows the cirs when the system is with a static knowledge base  vocabulary   the curve is drawn in the same way as the curve with a dynamic knowledge
base  except without word acquisition in the random simulation processes  as we can see in
the figure  when the system doest not have word acquisition capability  its language understanding performance does not change after more users have communicated to the system 
with the capability of automatic word acquisition  the systems language understanding
performance becomes better after more users have talked to the system 
   

fiqu   chai

   
static knowledge base
dynamic knowledge base

    
   

cir

    
   
    
   
    
   
    

 

 

 

 

 

 

 

 

                                  
user index

figure     cir of user language achieved by the system starting with no training data
     simulation    when the system starts with training data
many conversational systems use real user data to derive domain vocabulary  to follow this
practice  the second simulation provides the system with some training data  the training
data serves two purposes     build an initial vocabulary of the system     train a classifier
to predict the closely coupled speech gaze instances of new users data 
using the collected data of    users  the simulation process goes through the following
steps 
 using the first m users data as training data  acquire words from the training instances
 with speech transcript   add the verified    best words to the systems vocabulary as
seed words  build a classifier with the training data for prediction of closely coupled
speech gaze instances 
 evaluate the effect of incremental word acquisition on cir of the remaining     m 
users data  for user index i                     m  
 evaluate cir of the i th users utterances    best speech recognition  
 predict closely coupled speech gaze instances of the i th users data 
 acquire words from the m training users true coupled instances  with speech
transcript  and the predicted coupled instances  with   best speech recognition 
of users      i 
 among the    best acquired words  add verified new words to the system vocabulary 
the above simulation process is repeated      times with randomly ordered users to
reduce the effect of user ordering on the language understanding performance  figure   
shows the averaged language understanding performance of these random simulations 
the language understanding performance of the system with a static knowledge base
is also shown in figure     the curve is drawn by the same random simulations without
the steps of word acquisition  we can observe a general trend in the figure that  with word
acquisition  the systems language understanding becomes better after more users have
   

ficontext based word acquisition for situated dialogue in a virtual world

   
static knowledge base
dynamic knowledge base
    

cir

    

    

    

    

 

 

 

 

 

 

 

 

 

  

user index

figure     cir of user language achieved by the system starting with training data of   
users

communicated to the system  without word acquisition capability  the systems language
understanding performance does not increase after more users have conversed with the
system 
the simulations show that automatic vocabulary acquisition is beneficial to the systems
language understanding performance when training data is available  when training data
is not available  vocabulary acquisition could be more important and beneficial to robust
language understanding 
     the effect of speech recognition on online word acquisition and
language understanding
the simulation results in figures         are based on the   best recognized speech hypotheses with a relatively high wer          with better speech recognition  the system
will have better concept identification performance  to show the effect of speech recognition
quality on online word acquisition and language understanding  we also perform simulation   and simulation   based on speech transcript  the simulation processes are the same
as the ones based on the   best speech recognition except that word acquisition is based on
speech transcript and cir is evaluated also on speech transcript in the new simulations 
figure    shows the cir curves based on speech transcript during online conversation 
with word acquisition  the systems language understanding becomes better after more
users have communicated to the system  this is consistent with the cir curves based on
the   best speech recognition  however  the cirs based on speech transcript is much higher
the cirs based on the   best speech recognition  which verifies that speech recognition
quality is critical to language understanding performance 

    discussion and future work
our experimental results have shown that incorporating extra information improves word
acquisition compared to completely unsupervised approaches  however  our current ap   

fiqu   chai

 

    
static knowledge base
dynamic knowledge base

static knowledge base
dynamic knowledge base

   

    
cir

    

cir

   

   

    

   

    

   

 

 

 

 

 

 

 

 

   

                                  
user index

 a  simulation    with no training data

 

 

 

 

 

 

 

 

 

  

user index

 b  simulation    with training data of    users

figure     cir of user language  transcript  achieved by the system during online conversation

proaches have several limitations  first  the incorporation of domain knowledge through
semantic relatedness based on wordnet will restrict the acquired words to those appear in
wordnet  this is certainly not desirable  but this limitation can be readily addressed by
changing the way how the word probability distribution is tailored by semantic relatedness
 in section       and section         for example  one simple way is to keep the probability
mass for those words not in wordnet and only tailor the distribution from those words that
occur in wordnet based on their semantic relatedness with the object 
second  in our current approach  acquired words are limited to the words that are
recognized by the speech recognizer  as shown in section        the speech recognition
performance is rather poor in our experiments  this is partly due to the lack of language
models specifically trained for this domain  approaches to improve speech recognition 
for example  based on a referential semantic language model described in  schuler  wu   
schwartz        will potentially improve acquisition performance  furthermore  the set of
acquired words is bounded by the vocabulary of the speech recognizer  any new words that
are not in the dictionary will not be acquired  to break this barrier  inspired by previous
work  yu   ballard        taguchi et al          we are currently extending our approach
to incorporate grounding acoustic phoneme sequences to domain concepts 
another limitation of our current approaches is that they are incapable of acquiring
multiword expressions  they can only map single words to domain concepts  however 
we did observe multiword expressions  e g   rubiks cube  in our data  we will examine
this issue in our future work by incorporating more linguistic knowledge and by modeling
fertility of entities  for example  as in ibm model   and   
the simplicity of our current models also limits word acquisition performance  for
example  the alignment model based on temporal information directly incorporates findings
from psycholinguistic studies  these studies were generally conducted in a much simpler
settings without interaction  the recent work by fang  chai  and ferreira        has shown
correlations between intensity of gaze fixations and objects denoted by linguistic centers
   

ficontext based word acquisition for situated dialogue in a virtual world

 e g   forward looking centers based on centering theory  grosz  joshi    weinstein        
we plan to incorporate these results to improve alignment modeling in the future 
to further improve performance  another interesting direction is to take into consideration of the interactive nature of conversation  for example  by combining dialog management
to solicit user feedback on the acquired words  however  it will be important to identify
strategies to balance the trade off between explicit feedback solicitation  and thus lengthening the interaction  and the quality of the acquired words  reinforcement learning can
be a potential approach to address this problem 

    conclusions
motivated by the psycholinguistic findings  we investigate the use of eye gaze for automatic word acquisition in multimodal conversational systems  this paper presents several
enhanced models that incorporate user language behavior  domain knowledge  and conversation context in word acquisition  our experiments have shown that these enhanced
models significantly improve word acquisition performance 
recent advancement in eye tracking technology has made available non intrusive eye
tracking devices that can tolerate head motion and provide high tracking quality  integrating eye tracking with conversational interfaces is no longer beyond reach  we believe that
incorporating eye gaze with automatic word acquisition provides another potential approach
to improve the robustness of human machine conversation 

acknowledgments
this work was supported by iis         and iis         from the national science foundation  we would like to thank anonymous reviewers for their valuable comments and
suggestions 

references
allopenna  p  d   magnuson  j  s     tanenhaus  m  k          tracking the time course
of spoken word recognition using eye movements  evidence for continuous mapping
models  journal of memory   language             
barnard  k   duygulu  p   de freitas  n   forsyth  d   blei  d     jordan  m          matching words and pictures  journal of machine learning research              
bock  k   irwin  d  e   davidson  d  j     leveltb  w          minding the clock  journal
of memory and language             
brown  p  f   pietra  s  d   pietra  v  j  d     mercer  r  l          the mathematic
of statistical machine translation  parameter estimation  computational linguistics 
               
brown schmidt  s     tanenhaus  m  k          watching the eyes when talking about size 
an investigation of message formulation and utterance planning  journal of memory
and language             
   

fiqu   chai

byron  d   mampilly  t   sharma  v     xu  t          utilizing visual attention for
cross modal coreference interpretation  in proceedings of the fifth international and
interdisciplinary conference on modeling and using context  context      pp 
     
campana  e   baldridge  j   dowding  j   hockey  b   remington  r     stone  l         
using eye movements to determine referents in a spoken dialogue system  in proceedings of the workshop on perceptive user interface 
cessie  s  l     houwelingen  j  v          ridge estimators in logistic regression  applied
statistics                 
chen  d  l     mooney  r  j          learning to sportscast  a test of grounded language
acquisition  in proceedings of   th international conference on machine learning
 icml  
cooke  n  j          gaze contigent automatic speech recognition  ph d  thesis  university
of birminham 
dahan  d     tanenhaus  m  k          looking at the rope when looking for the snake 
conceptually mediated eye movements during spoken word recognition  psychonomic
bulletin   review                 
devault  d     stone  m          domain inference in incremental interpretation  in
proceedings of icos 
eberhard  k   spivey knowiton  m   sedivy  j     tanenhaus  m          eye movements as
a window into real time spoken language comprehension in natural contexts  journal
of psycholinguistic research             
fang  r   chai  j  y     ferreira  f          between linguistic attention and gaze fixations
inmultimodal conversational interfaces  in proceedings of the international conference
on multimodal interfaces  icmi   pp         
fazly  a   alishahi  a     stevenson  s          a probabilistic incremental model of word
learning in the presence of referential uncertainty  in proceedings of the   th annual
conference of the cognitive science society 
fellbaum  c   ed            wordnet  an electronic lexical database  mit press 
fleischman  m     roy  d          intentional context in situated language learning 
in proceedings of the  th conference on computational natural language learning
 conll  
fong  t  w     nourbakhsh  i          interaction challenges in human robot space exploration  interactions               
gorniak  p     roy  d          grounded semantic composition for visual scenes  journal
of artificial intelligence research             
griffin  z     bock  k          what the eyes say about speaking  psychological science 
           
griffin  z  m          gaze durations during speech reflect word selection and phonological
encoding  cognition      b b   
   

ficontext based word acquisition for situated dialogue in a virtual world

griffin  z  m          why look  reasons for eye movements related to language production 
in henderson  j     ferreira  f   eds    the interface of language  vision  and action 
eye movements and the visual world  pp          taylor and francis 
grosz  b  j   joshi  a  k     weinstein  s          centering  a framework for modeling
the local coherence of discourse  computational linguistics                 
jacob  r  j  k          the use of eye movements in human computer interaction techniques 
what you look at is what you get  acm transactions on information systems        
       
kahneman  d          attention and effort  prentice hall  inc   englewood cliffs 
kaur  m   termaine  m   huang  n   wilder  j   gacovski  z   flippo  f     mantravadi 
c  s          where is it  event synchronization in gaze speech input systems  in
proceedings of the international conference on multimodal interfaces  icmi  
klemmer  s   sinha  a   chen  j   landay  j   aboobaker  n     wang  a          suede 
a wizard of oz prototyping tool for speech user interfaces  in proceedings of acm
symposium on user interface software and technology  pp      
lemon  o   gruenstein  a     peters  s          collaborative activities and multitasking
in dialogue systems  traitement automatique des langues                 
liang  p   jordan  m  i     klein  d          learning semantic correspondences with
less supervision  in proceedings of the   th annual meeting of the association for
computational linguistics  acl  
liu  y   chai  j     jin  r          automated vocabulary acquisition and interpretation
in multimodal conversational systems  in proceedings of the   th annual meeting of
the association of computational linguistics  acl  
meyer  a   sleiderink  a     levelt  w          viewing and naming objects  eye movements
during noun phrase production  cognition                
nakano  y   reinstein  g   stocky  t     cassell  j          towards a model of face to face
grounding  in proceedings of the annual meeting of the association for computational
linguistics  acl  
pedersen  t   patwardhan  s     michelizzi  j          wordnet  similarity   measuring
the relatedness of concepts  in proceedings of the nineteenth national conference on
artificial intelligence  aaai  
prasov  z     chai  j  y          whats in a gaze  the role of eye gaze in reference resolution
in multimodal conversational interfaces  in proceedings of acm   th international
conference on intelligent user interfaces  iui  
qu  s     chai  j  y          an exploration of eye gaze in spoken language processing for
multimodal conversational interfaces  in proceedings of the human language technology conference of the north american chapter of the association for computational
linguistics  hlt naacl   pp         
qu  s     chai  j  y          incorporating temporal and semantic information with eye gaze
for automatic word acquisition in multimodal conversational systems  in proceedings
   

fiqu   chai

of the conference on empirical methods in natural language processing  emnlp  
pp         
qu  s     chai  j  y          the role of interactivity in human machine conversation for
automatic word acquisition  in proceedings of the   th annual meeting of the special
interest group on discourse and dialogue  sigdial   pp         
qvarfordt  p     zhai  s          conversing with the user based on eye gaze patterns  in
proceedings of the conference on human factors in computing systems  chi  
rayner  k          eye movements in reading and information processing      years of
research  psychological bulletin                  
roy  d          learning visually grounded words and syntax for a scene description task 
computer speech and language                 
roy  d     pentland  a          learning words from sights and sounds  a computational
model  cognitive science                 
schuler  w   wu  s     schwartz  l          a framework for fast incremental interpretation
during speech decoding  computational linguistics                 
siskind  j  m          grounding the lexical semantics of verbs in visual perception using
force dynamics and event logic  journal of artificial intelligence research           
spivey  m  j   tanenhaus  m  k   eberhard  k  m     sedivy  j  c          eye movements
and spoken language comprehension  effects of visual context on syntactic ambiguity
resolution  cognitive psychology             
taguchi  r   iwahashi  n   nose  t   funakoshi  k     nakano  m          learning lexicons from spoken utterances based on statistical model selection  in proceedings of
interspeech 
tanaka  k          a robust selection system using real time multi modal user agent interactions  in proceedings of the international conference on intelligent user interfaces
 iui  
tanenhaus  m   spivey knowiton  m   eberhard  k     sedivy  j          integration of
visual and linguistic information in spoken language comprehension  science      
         
toutanova  k   klein  d   manning  c     singer  y          feature rich part of speech
tagging with a cyclic dependency network  in proceedings of the human language
technology conference of the north american chapter of the association for computational linguistics  hlt naacl   pp         
toutanova  k     manning  c  d          enriching the knowledge sources used in a maximum entropy part of speech tagger  in proceedings of the joint sigdat conference on empirical methods in natural language processing and very large corpora
 emnlp vlc   pp       
traum  d     rickel  j          embodied agents for multiparty dialogue in immersive
virtual worlds  in proceedings of the  st international joint conference on autonomous
agents and multi agent systems 
   

ficontext based word acquisition for situated dialogue in a virtual world

wang  j          integration of eye gaze  voice and manual response in multimodal user
interfaces  in proceedings of ieee international conference on systems  man and
cybernetics  pp           
yu  c     ballard  d          a multimodal learning interface for grounding spoken language
in sensory perceptions  acm transactions on applied perceptions              
zhai  s   morimoto  c     ihde  s          manual and gaze input cascaded  magic 
pointing  in proceedings of the conference on human factors in computing systems
 chi   pp         
zhang  q   imamiya  a   go  k     mao  x          overriding errors in a speech and gaze
multimodal architecture  in proceedings of the international conference on intelligent
user interfaces  iui  

   

fi