journal of artificial intelligence research                  

submitted          published       

first order decision diagrams for relational mdps
chenggang wang
saket joshi
roni khardon

cwan cs tufts edu
sjoshi   cs tufts edu
roni cs tufts edu

department of computer science  tufts university
    college avenue  medford  ma        usa

abstract
markov decision processes capture sequential decision making under uncertainty  where
an agent must choose actions so as to optimize long term reward  the paper studies efficient reasoning mechanisms for relational markov decision processes  rmdp  where
world states have an internal relational structure that can be naturally described in terms
of objects and relations among them  two contributions are presented  first  the paper
develops first order decision diagrams  fodd   a new compact representation for functions over relational structures  together with a set of operators to combine fodds  and
novel reduction techniques to keep the representation small  second  the paper shows how
fodds can be used to develop solutions for rmdps  where reasoning is performed at the
abstract level and the resulting optimal policy is independent of domain size  number of
objects  or instantiation  in particular  a variant of the value iteration algorithm is developed by using special operations over fodds  and the algorithm is shown to converge to
the optimal policy 

   introduction
many real world problems can be cast as sequential decision making under uncertainty 
consider a simple example in a logistics domain where an agent delivers boxes  the agent
can take three types of actions  to load a box on a truck  to unload a box from a truck  and
to drive a truck to a city  however the effects of actions may not be perfectly predictable 
for example its gripper may be slippery so load actions may not succeed  or its navigation
module may not be reliable and it may end up in a wrong location  this uncertainty
compounds the already complex problem of planning a course of action to achieve some
goals or maximize rewards 
markov decision processes  mdp  have become the standard model for sequential decision making under uncertainty  boutilier  dean    hanks         these models also provide
a general framework for artificial intelligence  ai  planning  where an agent has to achieve
or maintain a well defined goal  mdps model an agent interacting with the world  the
agent can fully observe the state of the world and takes actions so as to change the state 
in doing that  the agent tries to optimize a measure of the long term reward it can obtain
using such actions 
the classical representation and algorithms for mdps  puterman        require enumeration of the state space  for more complex situations we can specify the state space
in terms of a set of propositional variables called state attributes  these state attributes
together determine the world state  consider a very simple logistics problem that has only
c
    
ai access foundation  all rights reserved 

fiwang  joshi    khardon

one box and one truck  then we can have state attributes such as truck in paris  tp   box
in paris  bp   box in boston  bb   etc  if we let the state space be represented by n binary
state attributes then the total number of states would be  n   for some problems  however 
the domain dynamics and resulting solutions have a simple structure that can be described
compactly using the state attributes  and previous work known as the propositionally factored approach has developed a suite of algorithms that take advantage of such structure
and avoid state enumeration  for example  one can use dynamic bayesian networks  decision trees  and algebraic decision diagrams to concisely represent the mdp model  this
line of work showed substantial speedup for propositionally factored domains  boutilier 
dearden    goldszmidt        boutilier  dean    goldszmidt        hoey  st aubin  hu 
  boutilier        
the logistics example presented above is very small  any realistic problem will have
a large number of objects and corresponding relations among them  consider a problem
with four trucks  three boxes  and where the goal is to have a box in paris  but it does not
matter which box is in paris  with the propositionally factored approach  we need to have
one propositional variable for every possible instantiation of the relations in the domain 
e g   box   in paris  box   in paris  box   on truck    box   on truck    and so on  and
the action space expands in the same way  the goal becomes a ground disjunction over
different instances stating box   in paris  or box   in paris  or box   in paris  or box   in
paris  thus we get a very large mdp and at the same time we lose the structure implicit
in the relations and the potential benefits of this structure in terms of computation 
this is the main motivation behind relational or first order mdps  rmdp     a first
order representation of mdps can describe domain objects and relations among them  and
can use quantification in specifying objectives  in the logistics example  we can introduce three predicates to capture the relations among domain objects  i e   bin box  city  
t in t ruck  city   and on box  t ruck  with their obvious meaning  we have three parameterized actions  i e   load box  t ruck   unload box  t ruck   and drive t ruck  city   now
domain dynamics  reward  and solutions can be described compactly and abstractly using
the relational notation  for example  we can define the goal using existential quantification 
i e   b  bin b  p aris   using this goal one can identify an abstract policy  which is optimal
for every possible instance of the domain  intuitively when there are   steps to go  the
agent will be rewarded if there is any box in paris  when there is one step to go and there
is no box in paris yet  the agent can take one action to help achieve the goal  if there is a
box  say b    on a truck  say t    and the truck is in paris  then the agent can execute the
action unload b    t     which may make bin b    p aris  true  thus the goal will be achieved 
when there are two steps to go  if there is a box on a truck that is in paris  the agent
can take the unload action twice  to increase the probability of successful unloading of the
box   or if there is a box on a truck that is not in paris  the agent can first take the action
drive followed by unload  the preferred plan will depend on the success probability of the
different actions  the goal of this paper is to develop efficient solutions for such problems
using a relational approach  which performs general reasoning in solving problems and does
not propositionalize the domain  as a result the complexity of our algorithms does not
   sanner and boutilier        make a distinction between first order mdps that can utilize the full power
of first order logic to describe a problem and relational mdps that are less expressive  we follow this in
calling our language rmdp 

   

fifirst order decision diagrams for relational mdps

change when the number of domain objects changes  also the solutions obtained are good
for any domain of any size  even infinite ones  simultaneously  such an abstraction is not
possible within the propositional approach 
several approaches for solving rmdps were developed over the last few years  much
of this work was devoted to developing techniques to approximate rmdp solutions using
different representation languages and algorithms  guestrin  koller  gearhart    kanodia 
    a  fern  yoon    givan        gretton   thiebaux        sanner   boutilier       
       for example  dzeroski  de raedt  and driessens        and driessens  ramon  and
gartner        use reinforcement learning techniques with relational representations  fern 
yoon  and givan        and gretton and thiebaux        use inductive learning methods
to learn a value map or policy from solutions or simulations of small instances  sanner and
boutilier              develop an approach to approximate value iteration that does not need
to propositionalize the domain  they represent value functions as a linear combination of
first order basis functions and obtain the weights by lifting the propositional approximate
linear programming techniques  schuurmans   patrascu        guestrin  koller  par   
venktaraman      b  to handle the first order case 
there has also been work on exact solutions such as symbolic dynamic programming
 sdp   boutilier  reiter    price         the relational bellman algorithm  rebel   kersting  otterlo    de raedt         and first order value iteration  fovia   gromann 
holldobler    skvortsova        hoolldobler  karabaev    skvortsova         there is no
working implementation of sdp because it is hard to keep the state formulas consistent and
of manageable size in the context of the situation calculus  compared with sdp  rebel and
fovia provide more practical solutions  they both use restricted languages to represent
rmdps  so that reasoning over formulas is easier to perform  in this paper we develop a
representation that combines the strong points of these approaches 
our work is inspired by the successful application of algebraic decision diagrams  add 
 bryant        mcmillan        bahar  frohm  gaona  hachtel  macii  pardo    somenzi 
      in solving propositionally factored mdps and pomdps  hoey et al         st aubin 
hoey    boutilier        hansen   feng        feng   hansen         the intuition
behind this idea is that the add representation allows information sharing  e g   sharing
the value of all states that belong to an abstract state  so that algorithms can consider
many states together and do not need to resort to state enumeration  if there is sufficient
regularity in the model  adds can be very compact  allowing problems to be represented
and solved efficiently  we provide a generalization of this approach by lifting adds to
handle relational structure and adapting the mdp algorithms  the main difficulty in lifting
the propositional solution  is that in relational domains the transition function specifies a
set of schemas for conditional probabilities  the propositional solution uses the concrete
conditional probability to calculate the regression function  but this is not possible with
schemas  one way around this problem is to first ground the domain and problem at hand
and only then perform the reasoning  see for example sanghai  domingos    weld        
however this does not allow for solutions abstracting over domains and problems  like
sdp  rebel  and fovia  our constructions do perform general reasoning 
first order decision trees and even decision diagrams have already been considered in
the literature  blockeel   de raedt        groote   tveretina        and several semantics
for such diagrams are possible  blockeel and de raedt        lift propositional decision
   

fiwang  joshi    khardon

trees to handle relational structure in the context of learning from relational datasets 
groote and tveretina        provide a notation for first order binary decision diagrams
 bdd  that can capture formulas in skolemized conjunctive normal form and then provide
a theorem proving algorithm based on this representation  the paper investigates both
approaches and identifies the approach of groote and tveretina        as better suited
for the operations of the value iteration algorithm  therefore we adapt and extend their
approach to handle rmdps  in particular  our first order decision diagrams  fodd  are
defined by modifying first order bdds to capture existential quantification as well as realvalued functions through the use of an aggregation over different valuations for a diagram 
this allows us to capture mdp value functions using algebraic diagrams in a natural way 
we also provide additional reduction transformations for algebraic diagrams that help keep
their size small  and allow the use of background knowledge in reductions  we then develop
appropriate representations and algorithms showing how value iteration can be performed
using fodds  at the core of this algorithm we introduce a novel diagram based algorithm
for goal regression where  given a diagram representing the current value function  each
node in this diagram is replaced with a small diagram capturing its truth value before the
action  this offers a modular and efficient form of regression that accounts for all potential
effects of an action simultaneously  we show that our version of abstract value iteration is
correct and hence it converges to optimal value function and policy 
to summarize  the contributions of the paper are as follows  the paper identifies the
multiple path semantics  extending groote   tveretina        as a useful representation for
rmdps and contrasts it with the single path semantics of blockeel and de raedt        
the paper develops fodds and algorithms to manipulate them in general and in the
context of rmdps  the paper also develops novel weak reduction operations for first order
decision diagrams and shows their relevance to solving relational mdps  finally the paper
presents a version of the relational value iteration algorithm using fodds and shows that
it is correct and thus converges to the optimal value function and policy  while relational
value iteration was developed and specified in previous work  boutilier et al          to our
knowledge this is the first detailed proof of correctness and convergence for the algorithm 
this section has briefly summarized the research background  motivation  and our approach  the rest of the paper is organized as follows  section   provides background on
mdps and rmdps  section   introduces the syntax and the semantics of first order decision diagrams  fodd   and section   develops reduction operators for fodds  sections
  and   present a representation of rmdps using fodds  the relational value iteration
algorithm  and its proof of correctness and convergence  the last two sections conclude the
paper with a discussion of the results and future work 

   relational markov decision processes
we assume familiarity with standard notions of mdps and value iteration  see for example
bellman        puterman         in the following we introduce some of the notions  we
also introduce relational mdps and discuss some of the previous work on solving them 
markov decision processes  mdps  provide a mathematical model of sequential optimization problems with stochastic actions  a mdp can be characterized by a state space
s  an action space a  a state transition function p r sj  si   a  denoting the probability of
   

fifirst order decision diagrams for relational mdps

transition to state sj given state si and action a  and an immediate reward function r s  
specifying the immediate utility of being in state s  a solution to a mdp is an optimal
policy that maximizes expected discounted total reward as defined by the bellman equation 
v   s    maxaa  r s    

x

p r s   s  a v   s    

s  s

where v  represents the optimal state value function  the value iteration algorithm  vi 
uses the bellman equation to iteratively refine an estimate of the value function 
vn    s    maxaa  r s    

x

p r s   s  a vn  s    

   

s  s

where vn  s  represents our current estimate of the value function and vn    s  is the next
estimate  if we initialize this process with v  as the reward function  vn captures the optimal
value function when we have n steps to go  as discussed further below the algorithm is
known to converge to the optimal value function 
boutilier et al         used the situation calculus to formalize first order mdps and a
structured form of the value iteration algorithm  one of the useful restrictions introduced
in their work is that stochastic actions are specified as a randomized choice among deterministic alternatives  for example  action unload in the logistics example can succeed or
fail  therefore there are two alternatives for this action  unloads  unload success  and
unloadf  unload failure   the formulation and algorithms support any number of action
alternatives  the randomness in the domain is captured by a random choice specifying
which action alternative  unloads or unloadf   gets executed when the agent attempts an
action  unload   the choice is determined by a state dependent probability distribution
characterizing the dynamics of the world  in this way one can separate the regression over
effects of action alternatives  which is now deterministic  from the probabilistic choice of
action  this considerably simplifies the reasoning required since there is no need to perform
probabilistic goal regression directly  most of the work on rmdps has used this assumption  and we use this assumption as well  sanner and boutilier        investigate a model
going beyond this assumption 
thus relational mdps are specified by the set of predicates in the domain  the set of
probabilistic actions in the domain  and the reward function  for each probabilistic action 
we specify the deterministic action alternatives and their effects  and the probabilistic choice
among these alternatives  a relational mdp captures a family of mdps that is generated
by choosing an instantiation of the state space  thus the logistics example corresponds to
all possible instantiations with   boxes or with   boxes and so on  we only get a concrete
mdp by choosing such an instantiation   yet our algorithms will attempt to solve the entire
mdp family simultaneously 
boutilier et al         introduce the case notation to represent probabilities and rewards
compactly  the expression t   case     t         n   tn    where i is a logical formula  is
equivalent to      t   t           n   t   tn     in other words  t equals ti when i is
   one could define a single mdp including all possible instances at the same time  e g  it will include some
states with   boxes  some states with   boxes and some with an infinite number of boxes  but obviously
subsets of these states form separate mdps that are disjoint  we thus prefer the view of a rmdp as a
family of mdps 

   

fiwang  joshi    khardon

true  in general  the i s are not constrained but some steps in the vi algorithm require
that the i s are disjoint and partition the state space  in this case  exactly one i is
true in any state  each i denotes an abstract state whose member states have the same
value for that probability or reward  for example  the reward function for the logistics
domain  discussed above and illustrated on the right side of figure    can be captured as
case b  bin b  p aris       b  bin b  p aris       we also have the following notation for
operations over function defined by case expressions  the operators  and  are defined
by taking a cross product of the partitions and adding or multiplying the case values 
case i   ti   i  n   case j   vj   j  m    case i  j   ti   vj   i  n  j  m 
case i   ti   i  n   case j   vj   j  m    case i  j   ti  vj   i  n  j  m  
in each iteration of the vi algorithm  the value of a stochastic action a  x  parameterized
with free variables  x is determined in the following manner 
qa  x   s    rcase s      j  pcase nj   x   s   regr nj   x   vcase do nj   x   s         
where rcase s  and vcase s  denote reward and value functions in case notation  n j   x 
denotes the possible outcomes of the action a  x   and pcase nj   x   s  the choice probabilities for nj   x   note that we can replace a sum over possible next states s  in the standard
value iteration  equation    with a finite sum over the action alternatives j  reflected in  j
in equation     since different next states arise only through different action alternatives 
regr  capturing goal regression  determines what states one must be in before an action
in order to reach a particular state after the action  figure   illustrates the regression of
b  bin b  p aris  in the reward function r through the action alternative unloads b    t   
b  bin b  p aris  will be true after the action unloads b   t   if it was true before or box
b was on truck t and truck t was in paris  notice how the reward function r partitions
the state space into two regions or abstract states  each of which may include an infinite
number of complete world states  e g   when we have an infinite number of domain objects  
also notice how we get another set of abstract states after the regression step  in this
way first order regression ensures that we can work on abstract states and never need to
propositionalize the domain 
after the regression  we get a parameterized q function which accounts for all possible
instances of the action  we need to maximize over the action parameters of the q function
to get the maximum value that could be achieved by using an instance of this action  to
illustrate this step  consider the logistics example where we have two boxes b   and b    and
b  is on truck t    which is in paris  that is  on b    t    and t in t    p aris    while b  is in
boston  bin b    boston    for the action schema unload b   t    we can instantiate b and
t with b  and t  respectively  which will help us achieve the goal  or we can instantiate b
and t with b  and t  respectively  which will have no effect  therefore we need to perform
maximization over action parameters to get the best instance of an action  yet  we must
perform this maximization generically  without knowledge of the actual state  in sdp  this
is done in several steps  first  we add existential quantifiers over action parameters  which
leads to non disjoint partitions   then we sort the abstract states in q a  x  by the value in
decreasing order and include the negated conditions for the first n abstract states in the
formula for the  n     th   ensuring mutual exclusion  notice how this step leads to complex
   

fifirst order decision diagrams for relational mdps

r
 b   bin   b   paris  

 b   bin   b   paris  

  

 b   bin   b   paris  
 

on   b    t   
 tin   t    paris  

figure    an example illustrating regression over the action alternative unloads b    t   

description of the resulting state partitions in sdp  this process is performed for every
action separately  we call this step object maximization and denote it with obj max q a  x    
finally  to get the next value function we maximize over the q functions of different
actions  these three steps provide one iteration of the vi algorithm which repeats the
update until convergence 
the solutions of rebel  kersting et al         and fovia  gromann et al        
hoolldobler et al         follow the same outline but use a simpler logical language for representing rmdps  an abstract state in rebel is captured using an existentially quantified
conjunction  fovia  gromann et al         hoolldobler et al         has a more complex
representation allowing a conjunction that must hold in a state and a set of conjunctions
that must be violated  an important feature in rebel is the use of decision list  rivest 
      style representations for value functions and policies  the decision list gives us an
implicit maximization operator since rules higher on the list are evaluated first  as a result
the object maximization step is very simple in rebel  each state partition is represented
implicitly by the negation of all rules above it  and explicitly by the conjunction in the rule 
on the other hand  regression in rebel requires that one enumerate all possible matches
between a subset of a conjunctive goal  or state partition  and action effects  and reason
about each of these separately  so this step can potentially be improved 
in the following section we introduce a new representation  first order decision diagrams  fodd   fodds allow for sharing of parts of partitions  leading to space and time
saving  more importantly the value iteration algorithm based on fodds has both simple
regression and simple object maximization 
   

fiwang  joshi    khardon

   first order decision diagrams
a decision diagram is a graphical representation for functions over propositional  boolean 
variables  the function is represented as a labeled rooted directed acyclic graph where each
non leaf node is labeled with a propositional variable and has exactly two children  the
outgoing edges are marked with values true and false  leaves are labeled with numerical
values  given an assignment of truth values to the propositional variables  we can traverse
the graph where in each node we follow the outgoing edge corresponding to its truth value 
this gives a mapping from any assignment to a leaf of the diagram and in turn to its
value  if the leaves are marked with values in        then we can interpret the graph as
representing a boolean function over the propositional variables  equivalently  the graph
can be seen as representing a logical expression which is satisfied if and only if the   leaf is
reached  the case with        leaves is known as binary decision diagrams  bdds  and the
case with numerical leaves  or more general algebraic expressions  is known as algebraic
decision diagrams  adds   decision diagrams are particularly interesting if we impose
an order over propositional variables and require that node labels respect this order on
every path in the diagram  this case is known as ordered decision diagrams  odd   in
this case every function has a unique canonical representation that serves as a normal form
for the function  this property means that propositional theorem proving is easy for odd
representations  for example  if a formula is contradictory then this fact is evident when
we represent it as a bdd  since the normal form for a contradiction is a single leaf valued
   this property together with efficient manipulation algorithms for odd representations
have led to successful applications  e g   in vlsi design and verification  bryant       
mcmillan        bahar et al         as well as mdps  hoey et al         st aubin et al  
       in the following we generalize this representation for relational problems 
    syntax of first order decision diagrams
there are various ways to generalize adds to capture relational structure  one could
use closed or open formulas in the nodes  and in the latter case we must interpret the
quantification over the variables  in the process of developing the ideas in this paper we
have considered several possibilities including explicit quantifiers but these did not lead to
useful solutions  we therefore focus on the following syntactic definition which does not
have any explicit quantifiers 
for this representation  we assume a fixed set of predicates and constant symbols  and
an enumerable set of variables  we also allow using an equality between any pair of terms
 constants or variables  
definition   first order decision diagram
   a first order decision diagram  fodd  is a labeled rooted directed acyclic graph 
where each non leaf node has exactly two children  the outgoing edges are marked
with values true and false 
   each non leaf node is labeled with  an atom p  t            tn   or an equality t    t  where
each ti is a variable or a constant 
   leaves are labeled with numerical values 
   

fifirst order decision diagrams for relational mdps

p  x 
q  x 
 

h  y 

   

 

figure    a simple fodd 

figure   shows a fodd with binary leaves  left going edges represent true branches 
to simplify diagrams in the paper we draw multiple copies of the leaves   and    and
occasionally other values or small sub diagrams  but they represent the same node in the
fodd 
we use the following notation  for a node n  nt denotes the true branch of n  and nf
the false branch of n  na is an outgoing edge from n  where a can be true or false  for
an edge e  source e  is the node that edge e issues from  and target e  is the node that edge e
points to  let e  and e  be two edges  we have e    sibling e    iff source e      source e    
in the following we will slightly abuse the notation and let na mean either an edge or
the sub fodd this edge points to  we will also use na and target e    interchangeably
where n   source e    and a can be true or false depending on whether e  lies in the
true or false branch of n 
    semantics of first order decision diagrams
we use a fodd to represent a function that assigns values to states in a relational mdp 
for example  in the logistics domain  we might want to assign values to different states in
such a way that if there is a box in paris  then the state is assigned a value of     if there is
no box in paris but there is a box on a truck that is in paris and it is raining  this state is
assigned a value of      and so on   the question is how to define the semantics of fodds
in order to have the intended meaning 
the semantics of first order formulas are given relative to interpretations  an interpretation has a domain of elements  a mapping of constants to domain elements and  for
each predicate  a relation over the domain elements which specifies when the predicate is
true  in the mdp context  a state can be captured by an interpretation  for example in
the logistics domain  a state includes objects such as boxes  trucks  and cities  and relations
among them  such as box   on truck    on b    t      box   in paris  bin b    p aris   and so
on  there is more than one way to define the meaning of fodd b on interpretation i  in
the following we discuss two possibilities 
      semantics based on a single path
a semantics for relational decision trees is given by blockeel and de raedt        and it can
be adapted to fodds  the semantics define a unique path that is followed when traversing
   this is a result of regression in the logistics domain cf  figure    l  

   

fiwang  joshi    khardon

b relative to i  all variables are existential and a node is evaluated relative to the path
leading to it 
in particular  when we reach a node some of its variables have been seen before on the
path and some are new  consider a node n with label l n  and the path leading to it from
the root  and let c be the conjunction of all labels of nodes that are exited on the true
branch on the path  then in the node n we evaluate  x  c  l n   where  x includes all the
variables in c and l n   if this formula is satisfied in i then we follow the true branch 
otherwise we follow the false branch  this process defines a unique path from the root
to a leaf and its value 
for example  if we evaluate the diagram in figure   on the interpretation i   with
domain           and where the only true atoms are  p     q     h     then we follow the
true branch at the root since x  p x  is satisfied  but we follow the false branch at q x 
since x  p x   q x  is not satisfied  since the leaf is labeled with   we say that b does not
satisfy i  this is an attractive approach  because it partitions the set of interpretations into
mutually exclusive sets and this can be used to create abstract state partitions in the mdp
context  however  for reasons we discuss later  this semantics leads to various complications
for the value iteration algorithm  and it is therefore not used in the paper 
      semantics based on multiple paths
the second alternative builds on work by groote and tveretina        who defined semantics based on multiple paths  following this work  we define the semantics first relative to a
variable valuation   given a fodd b over variables  x and an interpretation i  a valuation
 maps each variable in  x to a domain element in i  once this is done  each node predicate
evaluates either to true or false and we can traverse a single path to a leaf  the value
of this leaf is denoted by mapb  i    
different valuations may give different values  but recall that we use fodds to represent
a function over states  and each state must be assigned a single value  therefore  we next
define
mapb  i    aggregate  mapb  i    
for some aggregation function  that is  we consider all possible valuations   and for each
valuation we calculate mapb  i     we then aggregate over all these values  in the special
case of groote and tveretina        leaf labels are in        and variables are universally
quantified  this is easily captured in our formulation by using minimum as the aggregation
function  in this paper we use maximum as the aggregation function  this corresponds
to existential quantification in the binary case  if there is a valuation leading to value   
then the value assigned will be    and gives useful maximization for value functions in the
general case  we therefore define 
mapb  i    max mapb  i     


using this definition b assigns every i a unique value v   mapb  i  so b defines a function
from interpretations to real values  we later refer to this function as the map of b 
consider evaluating the diagram in figure   on the interpretation i  given above where
the only true atoms are  p     q     h      the valuation where x is mapped to   and y is
   

fifirst order decision diagrams for relational mdps

mapped to   denoted  x    y    leads to a leaf with value   so the maximum is    when leaf
labels are in        we can interpret the diagram as a logical formula  when map b  i      
as in our example  we say that i satisfies b and when mapb  i      we say that i falsifies
b 
we define node formulas  nf  and edge formulas  ef  recursively as follows  for a node
n labeled l n  with incoming edges e            ek   the node formula nf n     i ef ei     the
edge formula for the true outgoing edge of n is ef nt     nf n   l n   the edge formula
for the false outgoing edge of n is ef nf     nf n   l n   these formulas  where all
variables are existentially quantified  capture the conditions under which a node or edge are
reached 
    basic reduction of fodds
groote and tveretina        define several operators that reduce a diagram into normal
form  a total order over node labels is assumed  we describe these operators briefly and
give their main properties 
 r   neglect operator  if both children of a node p in the fodd lead to the same node q
then we remove p and link all parents of p to q directly 
 r   join operator  if two nodes p  q have the same label and point to the same two
children then we can join p and q  remove q and link qs parents to p  
 r   merge operator  if a node and its child have the same label then the parent can point
directly to the grandchild 
 r   sort operator  if a node p is a parent of q but the label ordering is violated  l p   
l q   then we can reorder the nodes locally using two copies of p and q such that labels
of the nodes do not violate the ordering 
define a fodd to be reduced if none of the four operators can be applied  we have the
following 
theorem    groote   tveretina       
    let o   neglect  join  merge  sort  be an operator and o b  the result of applying o
to fodd b  then for any b  i  and   mapb  i      mapo b   i    
    if b    b  are reduced and satisfy   mapb   i      mapb   i    then they are identical 
property     gives soundness  and property     shows that reducing a fodd gives a normal
form  however  this only holds if the maps are identical for every  and this condition is
stronger than normal equivalence  this normal form suffices for groote and tveretina
       who use it to provide a theorem prover for first order logic  but it is not strong
enough for our purposes  figure   shows two pairs of reduced fodds  with respect to r r   such that mapb   i    mapb   i  but   mapb   i       mapb   i     in this case
although the maps are the same the fodds are not reduced to the same form  consider
first the pair in part  a  of the figure  an interpretation where p a  is false but p b  is
true and a substitution  x a  y b  leads to value of   in b  while b  always evaluates to
   but the diagrams are equivalent  for any interpretation  if p c  is true for any object
   

fiwang  joshi    khardon

b 

b 

p  x 

 a 

 

 

p  y 
 

 

p  x  y 
 b 

p  y  z 
 

p  x  y 

 

p  z  x 

 

 

 

 

figure    examples illustrating weakness of normal form 

c then mapb   i      through the substitution  x c   if p c  is false for any object c
then mapb   i      through the substitution  x c  y c   thus the map is always   for
b  as well  in section     we show that with the additional reduction operators we have
developed  b  in the first pair is reduced to    thus the diagrams in  a  have the same form
after reduction  however  our reductions do not resolve the second pair given in part  b 
of the figure  notice that both functions capture a path of two edges labeled p in a graph
 we just change the order of two nodes and rename variables  so the diagrams evaluate to
  if and only if the interpretation has such a path  even though b  and b  are logically
equivalent  they cannot be reduced to the same form using r  r  or our new operators  to
identify a unique minimal syntactic form one may have to consider all possible renamings
of variables and the sorted diagrams they produce  but this is an expensive operation  a
discussion of normal form for conjunctions that uses such an operation is given by garriga 
khardon  and de raedt        
    combining fodds
given two algebraic diagrams we may need to add the corresponding functions  take the
maximum or use any other binary operation  op  over the values represented by the functions  here we adopt the solution from the propositional case  bryant        in the form
of the procedure apply b   b   op  where b  and b  are algebraic diagrams  let p and q
be the roots of b  and b  respectively  this procedure chooses a new root label  the lower
among labels of p  q  and recursively combines the corresponding sub diagrams  according
to the relation between the two labels       or    in order to make sure the result is
reduced in the propositional sense one can use dynamic programming to avoid generating
nodes for which either neglect or join operators   r   and  r   above  would be applicable 
figure   illustrates this process  in this example  we assume predicate ordering as
p   p    and parameter ordering x   x    non leaf nodes are annotated with numbers and
numerical leaves are underlined for identification during the execution trace  for example 
   

fifirst order decision diagrams for relational mdps

 
p   x  
 
p   x  
  



 
p   x  
 

 

 

   
p   x  
 

   
p   x  

   

    
p   x  
  

  

p   x  
 

 

figure    a simple example of adding two fodds 

the top level call adds the functions corresponding to nodes   and    since p   x    is the
smaller label it is picked as the label for the root of the result  then we must add both
left and right child of node   to node    these calls are performed recursively  it is easy
to see that the size of the result may be the product of sizes of input diagrams  however 
much pruning will occur with shared variables and further pruning is made possible by weak
reductions presented later 
since for any interpretation i and any fixed valuation  the fodd is propositional  we
have the following lemma  we later refer to this property as the correctness of apply 
lemma   let c   apply a  b  op   then for any i and   mapa  i    op mapb  i     
mapc  i    
proof  first we introduce some terminology  let  nodes x  refer to the set of all nodes
in a fodd x  let the root nodes of a and b be aroot and broot respectively  let the
fodds rooted at aroott   arootf   broott   brootf   croott   and crootf be al   ar   b l   b r  
c l and c r respectively 
the proof is by induction on n     nodes a       nodes b    the lemma is true for
n      because in this case both aroot and broot have to be single leaves and an operation
on them is the same as an operation on two real numbers  for the inductive step we need
to consider two cases 
case    aroot   broot   since the root nodes are equal  if a valuation  reaches al  
then it will also reach b l and if  reaches ar   then it will also reach b r   also  by the
definition of apply  in this case c l   apply al   b l   op  and c r   apply ar   b r   op   therefore the statement of the lemma is true if mapal  i    op mapb l  i      mapc l  i    and
mapar  i    op mapb r  i      mapc r  i    for any  and i  now  since   nodes al    
 nodes b l      n and   nodes ar      nodes b r      n  this is guaranteed by the induction
hypothesis 
case    aroot    broot   without loss of generality let us assume that aroot  broot  
by the definition of apply  c l   apply al   b  op  and c r   apply ar   b  op   therefore
the statement of the lemma is true if mapal  i    op mapb  i      mapc l  i    and
mapar  i    op mapb  i      mapc r  i    for any  and i  again this is guaranteed by
the induction hypothesis 
 
   

fiwang  joshi    khardon

    order of labels
the syntax of fodds allows for two types of objects  constants and variables  any
argument of a predicate can be a constant or a variable  we assume a complete ordering
on predicates  constants  and variables  the ordering  between two labels is given by the
following rules 
   p  x         xn    p    x          x m   if p  p  
   p  x         xn    p  x          x n   if there exists i such that xj   x j for all j   i  and
type xi    type x i    where type can be constant or variable  or type xi     type x i  
and xi  x i  
while the predicate order can be set arbitrarily it appears useful to assign the equality
predicate as the first in the predicate ordering so that equalities are at the top of the
diagrams  during reductions we often encounter situations where one side of the equality
can be completely removed leading to substantial space savings  it may also be useful to
order the argument types so that constant  variables  this ordering may be helpful for
reductions  intuitively  a variable appearing lower in the diagram can be bound to the
value of a constant that appears above it  these are only heuristic guidelines and the best
ordering may well be problem dependent  we later introduce other forms of arguments 
predicate parameters and action parameters  the ordering for these is discussed in section   

   additional reduction operators
in our context  especially for algebraic fodds  we may want to reduce the diagrams further 
we distinguish strong reductions that preserve mapb  i    for all  and weak reductions
that only preserve mapb  i   theorem   shows that r  r  given above are strong reductions  the details of our relational vi algorithm do not directly depend on the reductions
used  readers more interested in rmdp details can skip to section   which can be read
independently  except where reductions are illustrated in examples  
all the reduction operators below can incorporate existing knowledge on relationships
between predicates in the domain  we denote this background knowledge by b  for example
in the blocks world we may know that if there is a block on block y then it is not clear 
x  y   on x  y   clear y   
in the following when we define conditions for reduction operators  there are two types
of conditions  the reachability condition and the value condition  we name reachability
conditions by starting with p  for path condition  and the reduction operator number  we
name conditions on values by starting with v and the reduction operator number 
     r   strong reduction for implied branches
consider any node n such that whenever n is reached then the true branch is followed  in
this case we can remove n and connect its parents directly to the true branch  we first
present the condition  followed by the lemma regarding this operator 
 p     b     x   nf n   l n   where  x are the variables in ef nt   
   

fifirst order decision diagrams for relational mdps

let r  n  denote the operator that removes node n and connects its parents directly
to the true branch  notice that this is a generalization of r   it is easy to see that the
following lemma is true 
lemma   let b be a fodd  n a node for which condition p  holds  and b   the result
of r  n   then for any interpretation i and any valuation  we have map b  i     
mapb    i    
a similar reduction can be formulated for the false branch  i e   if b     x   nf n  
l n   then whenever node n is reached then the false branch is followed  in this case we
can remove n and connect its parents directly to the false branch 
implied branches may simply be a result of equalities along a path  for example  x  
y   p x   p y  so we may prune p y  if  x   y  and p x  are known to be true  implied
branches may also be a result of background knowledge  for example in the blocks world
if on x  y  is guaranteed to be true when we reach a node labeled clear y  then we can
remove clear y  and connect its parent to clear y f  
     r   weak reduction removing dominated edges
consider any two edges e  and e  in a fodd whose formulas satisfy that if we can follow
e  using some valuation then we can also follow e  using a possibly different valuation  if
e  gives better value than e  then intuitively e  never determines the value of the diagram
and is therefore redundant  we formalize this as reduction operator r    
let p   source e     q   source e     e    pa   and e    qb   where a and b can be true
or false  we first present all the conditions for the operator and then follow with the
definition of the operator 
 p       b      x  ef e        y   ef e     where  x are the variables in ef e    and  y the
variables in ef e    
 p       b     u    w 
  ef e        v   ef e      where  u are the variables that appear in
both target e    and target e      v the variables that appear in ef e    but are not in  u  and
w
  the variables that appear in ef e    but are not in  u  this condition requires that for
every valuation   that reaches e  there is a valuation   that reaches e  such that   and
  agree on all variables that appear in both target e    and target e    
 p       b     r     s  ef e        t  ef e      where  r are the variables that appear in both
target e    and target sibling e       t the variables that appear in ef e    but are not in  r 
and  s the variables that appear in ef e    but are not in  r  this condition requires that for
every valuation   that reaches e  there is a valuation   that reaches e  such that   and
  agree on all variables that appear in both target e    and target sibling e     
 v       min target e      max target e     where min target e     is the minimum leaf
value in target e     and max target e     the maximum leaf value in target e     in this case
regardless of the valuation we know that it is better to follow e  and not e   
 v       min target e      max target sibling e      
 v       all leaves in d   target e      target e    have non negative values  denoted as
d     in this case for any fixed valuation it is better to follow e  instead of e   
   we use r  and skip the notation r  for consistency with earlier versions of this paper  see further
discussion in section       

   

fiwang  joshi    khardon

 v       all leaves in g   target e      target sibling e     have non negative values 
we define the operators r  replace b  e    e    as replacing target e    with a constant b
that is between   and min target e      we may write it as r  replace e    e    if b      
and r  drop e    e    as dropping the node q   source e    and connecting its parents to
target sibling e     
we need one more safety condition to guarantee that the reduction is correct 
 s     nf source e     and the sub fodd of target e    remain the same before and after
r  replace and r  drop  this condition says that we must not harm the value promised
by target e     in other words  we must guarantee that p   source e    is reachable just as
before and the sub fodd of target e    is not modified after replacing a branch with    the
condition is violated if q is in the sub fodd of pa   or if p is in the sub fodd of qb   but
it holds in all other cases  that is when p and q are unrelated  one is not the descendant of
the other   or q is in the sub fodd of pa   or p is in the sub fodd of qb   where a  b are
the negations of a  b 
lemma   let b be a fodd  e  and e  edges for which conditions p     v     and s 
hold  and b   the result of r  replace b  e    e     where    b  min target e      then for any
interpretation i we have mapb  i    mapb    i  
proof  consider any valuation   that reaches target e     then according to p    
there is another valuation reaching target e    and by v    it gives a higher value  therefore  mapb  i  will never be determined by target e    so we can replace target e    with a
constant between   and min target e     without changing the map 
 
lemma   let b be a fodd  e  and e  edges for which conditions p     v     and s 
hold  and b   the result of r  replace b  e    e     where    b  min target e      then for any
interpretation i we have mapb  i    mapb    i  
proof  consider any valuation   that reaches target e     by p    there is another
valuation   reaching target e    and   and   agree on all variables that appear in both
target e    and target e     therefore  by v    it achieves a higher value  otherwise  there
must be a branch in d   target e    target e    with a negative value   therefore according
to maximum aggregation the value of mapb  i  will never be determined by target e     and
we can replace it with a constant as described above 
 
note that the conditions in the previous two lemmas are not comparable since p   
 p    and v     v     intuitively when we relax the conditions on values  we need
to strengthen the conditions on reachability  the subtraction operation d   target e      
target e    is propositional  so the test in v    implicitly assumes that the common variables in the operands are the same and p    does not check this  figure   illustrates
that the reachability condition p    together with v     i e   combining the weaker portions of conditions from lemma   and lemma    cannot guarantee that we can replace
a branch with a constant  consider an interpretation i with domain              and relations  h        q        p      in addition assume domain knowledge b    x  y  h x  y  
z  w  q z  w    so p    and v    hold for e     q x  y  t and e     h z  y t    we have
mapb   i      and mapb   i       it is therefore not possible to replace h z  y t with   
   

fifirst order decision diagrams for relational mdps

q x y 
p y 

q x y 

h z y 
  p y   

 

 

 
b 

 

p y 
 

 

 
b 

figure    an example illustrating the subtraction condition in r  

  

b 

b 

p x 

p x 

q y 
 

  

p y 

  

h y 

    

h y 
 

 

figure    an example illustrating the condition for removing a node in r  

sometimes we can drop the node q completely with r  drop  intuitively  when we
remove a node  we must guarantee that we do not gain extra value  the conditions for
r  replace can only guarantee that we will not lose any value  but if we remove the node
q  a valuation that was supposed to reach e  may reach a better value in e  s sibling  this
would change the map  as illustrated in figure    notice that the conditions p    and
v    hold for e     p x  t and e     p y  t so we can replace  p y  t with a constant 
consider an interpretation i with domain        and relations  q     p     h      we have
mapb   i       via valuation  x    and mapb   i       via valuation  x    y     thus
removing p y  is not correct 
therefore we need the additional condition to guarantee that we will not gain extra value
with node dropping  this condition can be stated as  for any valuation   that reaches e 
and thus will be redirected to reach a value v  in sibling e    when q is removed  there is a
valuation   that reaches a leaf with value v   v    however  this condition is too complex
to test in practice  in the following we identify two stronger conditions 
lemma   let b be a fodd  e  and e  edges for which condition v    hold in addition to
the conditions for replacing target e    with a constant  and b   the result of r  drop e    e    
then for any interpretation i we have mapb  i    mapb    i  
proof  consider any valuation reaching target e     as above its true value is dominated
by another valuation reaching target e     when we remove q   source e    the valuation
will reach target sibling e     and by v    the value produced is smaller than the value from
target e     so again the map is preserved 
 
   

fiwang  joshi    khardon

lemma   let b be a fodd  e  and e  edges for which p    and v    hold in addition
to conditions for replacing target e    with a constant  and b   the result of r  drop e    e    
then for any interpretation i we have mapb  i    mapb    i  
proof  consider any valuation   reaching target e     as above its value is dominated
by another valuation reaching target e     when we remove q   source e    the valuation
will reach target sibling e     and by the conditions p    and v     the valuation   will
reach leaf of greater value in target e    otherwise there will be a branch in g leading to a
negative value   so under maximum aggregation the map is not changed 
 
to summarize if p    and v    and s  hold or p    and v    and s  hold then we can
replace target e    with a constant  if we can replace and v    or both p    and v    hold
then we can drop q   source e    completely 
in the following we provide a more detailed analysis of applicability and variants of r  
      r   a special case of r 
we have a special case of r  when p   q  i e   e  and e  are siblings  in this context r 
can be considered to focus on a single node n instead of two edges  assuming that e     nt
and e    nf   we can rewrite the conditions in r  as follows 
 p       b      x  nf n      x   y   ef nt     this condition requires that if n is reachable
then nt is reachable 
 p       b     r    v   nf n      v   w 
  ef nt    where  r are the variables that appear in
both nt and nf    v the variables that appear in nf n  but not in  r  and w
  the variables
in l n  and not in  r or  v  
 p       b     u    v   nf n      v   w 
  ef nt    where  u are the variables that appear in
nt  since sibling e      e      v the variables that appear in nf n  but not in  u  and w
  the
variables in l n  and not in  u or  v  
 v       min nt    max nf   
 v       nt is a constant 
 v       all leaves in the diagram d   nt   nf have non negative values 
conditions s  and v    are always true  we have previously analyzed this special case
as a separate reduction operator named r   wang  joshi    khardon         while this is
a special case  it may still be useful to check for it separately before applying the generalized
case of r   as it provides large reductions and seems to occur frequently in example domains 
an important special case of r  occurs when l n  is an equality t    y where y is a
variable that does not occur in the fodd above node n  in this case  the condition p   
holds since we can choose the value of y  we can also enforce the equality in the subdiagram of nt   therefore if v    holds we can remove the node n connecting its parents to
nt and substituting t  for y in the diagram nt    note that we may need to make copies of
nodes when doing this   in section     we introduce a more elaborate reduction to handle
equalities by taking a maximum over the left and the right children 
      application order
in some cases several instances of r  are applicable  it turns out that the order in which
we apply them is important  in the following  the first example shows that the order affects
   

fifirst order decision diagrams for relational mdps

p x  y  
q x  

p x  y  
q x  
  

p x  y  

q x  
 

   
 a 

p x  y  

  

 

q x  
 

q x    

q x  
  

 

 b 

 

q x  

p x  y  
  q x  
 
 d 

 c 

p x  y  

p x  y  
  

 

 

 

q x  
  

p x  y  
 

 

 

 e 

figure    an example illustrating the effect of application order for r  

the number of steps needed to reduce the diagram  the second example shows that the
order affects the final result 
consider the fodd in figure   a   r  is applicable to edges e     p x    y    t and
e     p x    y    t   and e      q x    t and e      q x    t   if we reduce in a top down
manner  i e   first apply r  on the pair  p x    y    t and  p x    y    t   we will get the fodd
in figure   b   and then we apply r  again on  q x    t and  q x    t   and we will get the
fodd in figure   c   however  if we apply r  first on  q x    t and  q x    t thus getting
figure   d   r  cannot be applied to  p x    y    t and  p x    y    t because  p x    y    t  
 p x    y    t will have negative leaves  in this case  the diagram can still be reduced  we can
reduce by comparing  q x    t and  q x    t that is in the right part of fodd  we can first
remove q x    and get a fodd shown in figure   e   and then use the neglect operator to
remove p x    y     as we see in this example applying one instance of r  may render other
instances not applicable or may introduce more possibilities for reductions so in general
we must apply the reductions sequentially  wang        develops conditions under which
several instances of r  can be applied simultaneously 
one might hope that repeated application of r  will lead to a unique reduced result but
this is not true  in fact  the final result depends on the choice of operators and the order of
application  consider figure   a   r  is applicable to edges e     p x  t and e     p y  t  
and e      q x  t and e      q y  t   if we reduce in a top down manner  i e   first apply
r  on the pair  p x  t and  p y  t   we will get the fodd in figure   b   which cannot be
reduced using existing reduction operators  including the operator r  introduced below  
however  if we apply r  first on  q x  t and  q y  t we will get figure   c   then we can
apply r  again on e     p x  t and e     p y  t and get the final result figure   d   which
is clearly more compact than figure   b   it is interesting that the first example seems to
   

fiwang  joshi    khardon

p x 
  

p x 
  

p y 

   q x 
  

   q y 
 

q y 
 

 

 

 a 

 b 

p x 
  

q x 

p x 
   q x 

p y 

    

   q x 
    

 d 

 c 

figure    an example illustrating that the final result of r  reductions is order dependent 
suggest applying r  in a top down manner  since it takes fewer steps   while the second
seems to suggest the opposite  since the final result is more compact   more research is
needed to develop useful heuristics to guide the choice of reductions and the application
order and in general develop a more complete set of reductions 
note that we could also consider generalizing r   in figure   b   if we can reach  q y   t
then clearly we can reach  p x  t or  q x  t   since both  p x  t and  q x  t give better values  we can safely replace  q y  t with    thus obtaining the final result figure   d   in theory we can generalize p    as b      x  ef e       y     ef e            y n   ef e n    where
 x are the variables in ef e    and y i the variables in ef e i   where    i  n  and generalize
the corresponding value condition v    as i      n   min target e i     max target e     
we can generalize other reachability and value conditions similarly  however the resulting
conditions are too expensive to test in practice 
      relaxation of reachability conditions
the conditions p    and p    are sufficient  but not necessary to guarantee correct reductions  sometimes valuations just need to agree on a smaller set of variables than the
intersection of variables  to see this  consider the example as shown in figure    where
a   b     and the intersection is  x  y  z   however  to guarantee a   b     we just need
to agree on either  x  y  or  x  z   intuitively we have to agree on the variable x to avoid
the situation when two paths p x  y   q x  and p x  y   q x   h z  can co exist  in order
to prevent the co existence of two paths p x  y   h z  and p x  y   q x   h z   either y
or z has to be the same as well  now if we change this example a little bit and replace each
   

fifirst order decision diagrams for relational mdps

h z  with h z  v   then we have two minimal sets of variables of different size  one is  x  y  
and the other is  x  z  v   as a result we cannot identify a minimum set of variables for the
subtraction and must either choose the intersection or heuristically identify a minimal set 
for example  using a greedy procedure 

a

b

p x  y 

p x  y 

q x 
 

h z 
   

q x 
 

   

h z 
 

h z 
 

 

figure    an example illustrating that the minimal set of variables for subtraction is not
unique 
     r   weak reduction by unification
consider a fodd b  let  v denote its variables  and let  x and  y be disjoint subsets of  v  
which are of the same cardinality  we define the operator r  b   x   y   as replacing variables
in  x by the corresponding variables in  y   we denote the resulting fodd by b  x  y   so the
result has variables in  v   x  we have the following condition for the correctness of r  
 v     all leaves in b  x  y     b are non negative 
lemma   let b be a fodd  b   the result of r  b   x   y   for which v  holds  then for any
interpretation i we have mapb  i    mapb    i  
proof  consider any valuation   to  v in b  by v   b  x  y   gives a better value on the
same valuation  therefore we do not lose any value by this operator  we also do not gain
any extra value  consider any valuation   to variables in b   reaching a leaf node with value
v  we can construct a valuation   to  v in b with all variables in  x taking the corresponding
value in  y   and it will reach a leaf node in b with the same value  therefore the map will
not be changed by unification 
 
figure    illustrates that in some cases r  is applicable where r  is not  we can apply
r  with  x   x    to get a fodd as shown in figure    b   since  b     a       b  becomes
the result after reduction  note that if we unify in the other way  i e   x   x     we will get
figure    c   it is isomorphic to figure    b   but we cannot reduce the original fodd to
this result  because  c   a       this phenomenon happens since the subtraction operation
 implemented by apply  used in the reductions is propositional and therefore sensitive to
variable names 
     r   equality reduction
consider a fodd b with an equality node n labeled t   x  sometimes we can drop n and
connect its parents to a sub fodd that is the result of taking the maximum of the left and
   

fiwang  joshi    khardon

p x  
p x  
p x  

 

x    x 

q x  
  

q x    
  
 a 

 

 

 
 b 

x   x 

p x  
q x  
  

 

 
 c 

figure     an example illustrating r  

the right children of n  for this reduction to be applicable b has to satisfy the following
condition 
 e       for an equality node n labeled t   x at least one of t and x is a variable and it
appears neither in nf nor in the node formula for n  to simplify the description of the
reduction procedure below  we assume that x is that variable 
additionally we make the following assumption about the domain 
 d       the domain contains more than one object 
the above assumption guarantees that valuations reaching the right child of equality
nodes exist  this fact is needed in proving correctness of the equality reduction operator 
first we describe the reduction procedure for r  n   let bn denote the fodd rooted at
node n in fodd b  we extract a copy of bnt  and name it bnt  copy   and a copy of
bnf  bnf  copy  from b  in bnt  copy  we rename the variable x to t to produce diagram
bn  t  copy  let bn    apply bn  t  copy  bnf  copy  max   finally we drop the node n in b
and connect its parents to the root of bn  to obtain the final result b     an example is shown
in figure    
informally  we are extracting the parts of the fodd rooted at node n  one where x   t
 and renaming x to t in that part  and one where x    t  the condition e    and the
assumption d    guarantee that regardless of the value of t  we have valuations reaching
both parts  since by the definition of map  we maximize over the valuations  in this case
we can maximize over the diagram structure itself  we do this by calculating the function
which is the maximum of the two functions corresponding to the two children of n  using
apply  and replacing the old sub diagram rooted at node n by the new combined diagram 
theorem   proves that this does not affect the map of b 
one concern for implementation is that we simply replace the old sub diagram by the
new sub diagram  which may result in a diagram where strong reductions are applicable 
while this is not a problem semantically  we can avoid the need for strong reductions by
using apply that implicitly performs strong reductions r  neglect  and r  join  as follows 
   

fifirst order decision diagrams for relational mdps

let ba denote the fodd resulting from replacing node n in b with    and bb the
fodd resulting from replacing node n with   and all leaves other than node n by    we
have the final result b     ba  bb  where bb    bb  bn    by correctness of apply the two
forms of calculating b   give the same map 

b x
 

p y 
q x 

x y
p y 
 

q x 

  

q x 

q x 
  

p x 
 

  

 b 

 

 a 

 c 
b x

q x 
 

 

 
 d 

 

p x 
q x 

  

q x 
 

 

 e 

figure     an example of the equality reduction   a  the fodd before reduction  the
node x   y satisfies condition e    for variable y   b  bnt  copy  nt extracted  
 c  bnt  copy renamed to produce bn  t  copy   d  bnf  copy   e  final result
with node n replaced by apply bn  t  copy  bnf  copy  max 
in the following we prove that for any node n where equality condition e    holds in b
we can perform the equality reduction r  without changing the map for any interpretation
satisfying d     we start with properties of fodds defined above  e g   b a   bb   and bb    let
n denote the set of all valuations reaching node n and let m denote the set of all valuations
not reaching node n in b  from the basic definition of map we have the following 
claim
 a   
 b   
 c   
 d   

  for any interpretation i 
 m   mapba  i      mapb  i    
 n   mapba  i        
 m   mapbb  i        
 n   mapbb  i        

from claim   and the definition of map  we have 
claim   for any interpretation i 
 a     m   mapbb   i        
 b     n   mapbb   i      mapbn   i    
from claim    claim    and the definition of map we have 

   

fiwang  joshi    khardon

claim   for any interpretation i 
 a     m   mapb    i      mapb  i    
 b     n   mapb    i      mapbn   i    
next we prove the main property of this reduction stating that for all valuations reaching
node n in b  the old sub fodd rooted at n and the new  combined  sub fodd produce
the same map 
lemma   let n be the set of valuations reaching node n in fodd b  for any interpretation i satisfying d     maxn mapbn  i      maxn mapbn   i    
proof  by condition e     the variable x does not appear in n f  n  and hence its value
in   n is not constrained  we can therefore partition the valuations in n into disjoint
sets  n        is a valuation to variables other than x   where in  variables other
than x are fixed to their value in  and x can take any value in the domain of i  assumption
d    guarantees that every  contains at least one valuation reaching bnt and at least one
valuation reaching bnf in b  note that if a valuation  reaches bnt then t   x is satisfied
by  thus mapbnt  i      mapbn   copy  i     since x does not appear in bnf we also
t
have that mapbn   copy  i    is constant for all      therefore by the correctness of
f
apply we have max mapbn  i      max mapbn   i    
finally  by the definition of map  maxn mapbn  i      max max mapbn  i   
  max max mapbn   i      maxn mapbn  i    
 
lemma   let b be a fodd  n a node for which condition e    holds  and b   be the result
of r  n   then for any interpretation i satisfying d     map b  i    mapb    i  
proof  let x   maxm mapb    i    and y   maxn mapb    i     by the definition of map  mapb    i    max x  y    however  by claim    x   maxm mapb  i   
and by claim   and lemma    y   maxn mapbn   i      maxn mapbn  i     thus
 
max x  y     mapb  i    mapb    i  
while lemma   guarantees correctness  when applying it in practice it may be important
to avoid violations of the sorting order  which would require expensive re sorting of the
diagram   if both x and t are variables we can sometimes replace both with a new variable
name so the resulting diagram is sorted  however this is not always possible  when such a
violation is unavoidable  there is a tradeoff between performing the reduction and sorting
the diagram and ignoring the potential reduction 
to summarize  this section introduced several new reductions that can compress diagrams significantly  the first  r   is a generic strong reduction that removes implied
branches in a diagram  the other three  r   r   r   are weak reductions that do not alter
the overall map of the diagram but do alter the map for specific valuations  the three
reductions are complementary since they capture different opportunities for space saving 

   decision diagrams for mdps
in this section we show how fodds can be used to capture a rmdp  we therefore use
fodds to represent the domain dynamics of deterministic action alternatives  the probabilistic choice of action alternatives  the reward function  and value functions 
   

fifirst order decision diagrams for relational mdps

    example domain
we first give a concrete formulation of the logistics problem discussed in the introduction  this example follows exactly the details given by boutilier et al          and is used
to illustrate our constructions for mdps  the domain includes boxes  trucks and cities 
and predicates are bin box  city   t in t ruck  city   and on box  t ruck   following
boutilier et al          we assume that on b  t  and bin b  c  are mutually exclusive  so a
box on a truck is not in a city and vice versa  that is  our background knowledge includes
statements b  c  t  on b  t   bin b  c  and b  c  t  bin b  c   on b  t   the reward
function  capturing a planning goal  awards a reward of    if the formula b  bin b  p aris 
is true  that is if there is any box in paris  thus the reward is allowed to include constants
but need not be completely ground 
the domain includes   actions load  unload  and drive  actions have no effect if their
preconditions are not met  actions can also fail with some probability  when attempting
load  a successful version loads is executed with probability       and an unsuccessful version loadf  effectively a no operation  with probability       the drive action is executed
deterministically  when attempting unload  the probabilities depend on whether it is raining or not  if it is not raining then a successful version unloads is executed with probability
     and unloadf with probability      if it is raining unloads is executed with probability
     and unloadf with probability     
    the domain dynamics
we follow boutilier et al         and specify stochastic actions as a randomized choice
among deterministic alternatives  the domain dynamics are defined by truth value diagrams  tvds   for every action schema a  a  and each predicate schema p  x  the tvd
t  a  a   p  x   is a fodd with        leaves  the tvd gives the truth value of p  x  in
the next state when a  a  has been performed in the current state  we call  a action parameters  and  x predicate parameters  no other variables are allowed in the tvd  the
reasoning behind this restriction is explained in section      the restriction can be sometimes sidestepped by introducing more action parameters instead of the variables 
the truth value of a tvd is valid when we fix a valuation of the parameters  the
tvd simultaneously captures the truth values of all instances of p  x  in the next state 
notice that tvds for different predicates are separate  this can be safely done even if an
action has coordinated effects  not conditionally independent  since the action alternatives
are deterministic 
since we allow both action parameters and predicate parameters  the effects of an action
are not restricted to predicates over action arguments so tvd are more expressive than
simple strips based schemas  for example  tvds can easily express universal effects of
an action  to see this note that if p  x  is true for all  x after action a  a  then the tvd
t  a  a   p  x   can be captured by a leaf valued    other universal conditional effects can be
captured similarly  on the other hand  since we do not have explicit universal quantifiers 
tvds cannot capture universal preconditions 
for any domain  a tvd for predicate p  x  can be defined generically as in figure    
the idea is that the predicate is true if it was true before and is not undone by the action
or was false before and is brought about by the action  tvds for the logistics domain
   

fiwang  joshi    khardon

p  x  
bring
about

undo
 

 

 

figure     a template for the tvd

bin  b  c 
 

on  b  t 

on  b  t  

b  b 

t  t 
 

tin  t   c 
 

 

b  b 

b  b 

bin  b  c 
 

 

c  c 
 

 
 b 

bin  b  c  
 

tin  t  c  

 c 

c c 
 

 d 

t  t 
c  c 

 
 e 

 

 

 

tin  t  c 
t  t 

b  b 
t  t 

tin  t   c 

 
 a 

on  b  t 

 

rain
   

bin  b  paris 

   

  

 f 

 
 g 

figure     fodds for logistics domain  tvds  action choice  and reward function   a  b  the tvds for bin b  c  and on b  t   under action choice
unloads b   t     c  d  the tvds for bin b  c  and on b  t   under action
choice loads b   t   c    note that c must be an action parameter so that  d 
is a valid tvd   e  the tvd for t in t  c  under action choice drives t   c   
 f  the probability fodd for the action choice unloads b   t     g  the reward
function 

   

fifirst order decision diagrams for relational mdps

in our running example are given in figure     all the tvds omitted in the figure are
trivial in the sense that the predicate is not affected by the action  in order to simplify the
presentation we give the tvds in their generic form and did not sort the diagrams using
the order proposed in section      the tvds are consistent with the ordering bin   
 on  t in  rain  notice that the tvds capture the implicit assumption usually taken
in such planning based domains that if the preconditions of the action are not satisfied then
the action has no effect 
notice how we utilize the multiple path semantics with maximum aggregation  a predicate is true if it is true according to one of the paths specified so we get a disjunction
over the conditions for free  if we use the single path semantics of blockeel and de raedt
       the corresponding notion of tvd is significantly more complicated since a single
path must capture all possibilities for a predicate to become true  to capture that  we must
test sequentially for different conditions and then take a union of the substitutions from
different tests and in turn this requires additional annotation on fodds with appropriate
semantics  similarly an or operation would require union of substitutions  thus complicating the representation  we explain these issues in more detail in section     after we
introduce the first order value iteration algorithm 
    probabilistic action choice
one can consider modeling arbitrary conditions described by formulas over the state to
control natures probabilistic choice of action  here the multiple path semantics makes it
hard to specify mutually exclusive conditions using existentially quantified variables and in
this way specify a distribution  we therefore restrict the conditions to be either propositional
or depend directly on the action parameters  under this condition any interpretation follows
exactly one path  since there are no variables and thus only the empty valuation  thus the
aggregation function does not interact with the probabilities assigned  a diagram showing
action choice for unloads in our logistics example is given in figure     in this example 
the condition is propositional  the condition can also depend on action parameters  for
example  if we assume that the result is also affected by whether the box is big or not  we
can have a diagram as in figure    specifying the action choice probability 
big b  
rain

   

       

figure     an example showing that the choice probability can depend on action parameters 
note that a probability usually depends on the current state  it can depend on arbitrary properties of the state  with the restriction stated as above   e g   rain and big b    
as shown in figure     we allow arbitrary conditions that depend on predicates with arguments restricted to action parameters so the dependence can be complex  however  we
do not allow any free variables in the probability choice diagram  for example  we cannot
model a probabilistic choice of unloads b   t   that depends on other boxes on the truck t  
   

fiwang  joshi    khardon

e g   b  on b  t    b    b        otherwise       while we can write a fodd to capture this
condition  the semantics of fodd means that a path to     will be selected by max aggregation so the distribution cannot be modeled in this way  while this is clearly a restriction 
the conditions based on action arguments still give a substantial modeling power 
    reward and value functions
reward and value functions can be represented directly using algebraic fodds  the reward
function for our logistics domain example is given in figure    

   value iteration with fodds
following boutilier et al         we define the first order value iteration algorithm as follows 
given the reward function r and the action model as input  we set v    r  n     and repeat
the procedure rel greedy until termination 
procedure   rel greedy
   for each action type a  x   compute 
a  
x 

qv n

  r     j  prob aj   x    regr vn   aj   x    

   

a  
x 

   qa
vn   obj max qvn   
   vn     maxa qa
vn  
the notation and steps of this procedure were discussed in section   except that now 
and  work on fodds instead of case statements  note that since the reward function does
not depend on actions  we can move the object maximization step forward before adding
the reward function  i e   we first have
a  
x 

tv n

  j  prob aj   x    regr vn   aj   x    

followed by
a  
x 

qa
vn   r    obj max tvn   
later we will see that the object maximization step makes more reductions possible  therefore by moving this step forward we get some savings in computation  we compute the
updated value function in this way in the comprehensive example of value iteration given
later in section     
 puterman         in our case we
value iteration terminates when kvi    vi k     
 
need to test that the values achieved by the two diagrams is within    
   
some formulations of goal based planning problems use an absorbing state with zero
additional reward once the goal is reached  we can handle this formulation when there is
only one non zero leaf in r  in this case  we can replace equation   with
a  
x 

qv n

  max r    j  prob aj   x    regr vn   aj   x    

to see why this is correct  note that due to discounting the max value is always  r  if r
is satisfied in a state we do not care about the action  max would be r  and if r is   in a
state we get the value of the discounted future reward 
   

fifirst order decision diagrams for relational mdps

note that we can only do this in goal based domains  i e   there is only one non zero
leaf  this does not mean that we cannot have disjunctive goals  but it means that we must
value each goal condition equally 
    regressing deterministic action alternatives
we first describe the calculation of regr vn   aj   x   using a simple idea we call block replacement  we then proceed to discuss how to obtain the result efficiently 
consider vn and the nodes in its fodd  for each such node take a copy of the corresponding tvd  where predicate parameters are renamed so that they correspond to the
nodes arguments and action parameters are unmodified  br regress v n   a  x   is the fodd
resulting from replacing each node in vn with the corresponding tvd  with outgoing edges
connected to the      leaves of the tvd 
recall that a rmdp represents a family of concrete mdps each generated by choosing a
concrete instantiation of the state space  typically represented by the number of objects and
their types   the formal properties of our algorithms hold for any concrete instantiation 
fix any concrete instantiation of the state space  let s denote a state resulting from
executing an action a  x  in state s  notice that vn and br regress vn   a  x   have exactly
the same variables  we have the following lemma 
lemma    let  be any valuation to the variables of vn  and thus also the variables of
br regress vn   a  x     then mapvn  s      mapbrregress vn  a  x    s    
proof  consider the paths p  p followed under the valuation  in the two diagrams  by the
definition of tvds  the sub paths of p applied to s guarantee that the corresponding nodes
in p take the same truth values in s  so p  p reach the same leaf and the same value is
obtained 
 
a naive implementation of block replacement may not be efficient  if we use block
replacement for regression then the resulting fodd is not necessarily reduced and moreover 
since the different blocks are sorted to start with the result is not even sorted  reducing
and sorting the results may be an expensive operation  instead we calculate the result as
follows  for any fodd vn we traverse br regress vn   a  x   using postorder traversal in
terms of blocks and combine the blocks  at any step we have to combine up to   fodds
such that the parent block has not yet been processed  so it is a tvd with binary leaves 
and the two children have been processed  so they are general fodds   if we call the parent
bn   the true branch child bt and the false branch child bf then we can represent their
combination as  bn  bt          bn    bf   
lemma    let b be a fodd where bt and bf are fodds  and bn is a fodd with       
leaves  let b be the result of using apply to calculate the diagram  bn bt      bn  bf   
then for any interpretation i and valuation  we have mapb  i      mapb  i    
proof  this is true since by fixing the valuation we effectively ground the fodd and all
paths are mutually exclusive  in other words the fodd becomes propositional and clearly
the combination using propositional apply is correct 
 
a high level description of the algorithm to calculate br regress v n   a  x   by block
combination is as follows 
   

fiwang  joshi    khardon

procedure   block combination for br regress vn   a  x  
   perform a topological sort on vn nodes  see for example cormen  leiserson  rivest 
  stein        
   in reverse order  for each non leaf node n  its children bt and bf have already been
processed   let bn be a copy of the corresponding tvd  calculate  bn  bt         
bn    bf   
   return the fodd corresponding to the root 
notice that different blocks share variables so we cannot perform weak reductions during
this process  however  we can perform strong reductions in intermediate steps since they
do not change the map for any valuation  after the process is completed we can perform
any combination of weak and strong reductions since this does not change the map of the
regressed value function 
blue  b 

on  b  t 
 

big t 
on b t 
 

 

b  b 

big t 
on  b  t 

t  t 

 
 a 

blue  b 

 

bin  b  c 
tin  t  c 

 

b  b 
t  t 

 

 
 b 

bin  b  c 
tin  t  c 
 

 
 c 

figure     an example illustrating why variables are not allowed in tvds 
we can now explain why we cannot have variables in tvds through an example illustrated in figure     suppose we have a value function as defined in figure    a   saying
that if there is a blue block and a big truck such that the block is not on the truck then
value   is assigned  figure    b  gives the tvd for on b  t   under action loads  in
which c is a variable instead of an action parameter  figure    c  gives the result after
block replacement  consider an interpretation s with domain  b    t    c    c    and relations
 blue b     big t     bin b    c     t in t    c      after the action loads b    t    we will reach the
state s    blue b     big t     on b    t     t in t    c      which gives us a value of    but figure    c  with b   b    t   t  evaluated in s gives value of   by valuation  b b    c c    t t    
here the choice c c  makes sure the precondition is violated  by making c an action parameter  applying the action must explicitly choose a valuation and this leads to a correct
value function  object maximization turns action parameters into variables and allows us
to choose the argument so as to maximize the value 
   

fifirst order decision diagrams for relational mdps

    regressing probabilistic actions
to regress a probabilistic action we must regress all its deterministic alternatives and combine each with its choice probability as in equation    as discussed in section    due to
the restriction in the rmdp model that explicitly specifies a finite number of deterministic
action alternatives  we can replace the potentially infinite sum of equation   with the finite
sum of equation    if this is done correctly for every state then the result of equation   is
correct  in the following we specify how this can be done with fodds 
recall that prob aj   x   is restricted to include only action parameters and cannot include variables  we can therefore calculate prob aj   x  regr vn   aj   x   in step     directly
using apply  however  the different regression results are independent functions so that in
the sum j  prob aj   x    regr vn   aj   x    we must standardize apart the different regression results before adding the functions  note that action parameters are still considered
constants at this stage   the same holds for the addition of the reward function  the need
to standardize apart complicates the diagrams and often introduces structure that can be
reduced  when performing these operations we first use the propositional apply procedure
and then follow with weak and strong reductions 

v 

asucc x  
q  x 

p  x 
  

p  a 
 

 

a x 

 

q  a 
 

 a 

 
 b 
q  x  

q  x  
p  x      
x   x 

q  x  
 

p  x      
 

q  x  
 

 



q  x  
p  x  

 

x   x 
q  x  

 
 c 

   

figure     an example illustrating the need to standardize apart 
figure    illustrates why we need to standardize apart different action outcomes  action
a can succeed  denoted as asucc  or fail  denoted as af ail  effectively a no operation  
and each is chosen with probability      part  a  gives the value function v     part  b  gives
the tvd for p  a  under the action choice asucc x    all other tvds are trivial  part
 c  shows part of the result of adding the two outcomes for a after standardizing apart
 to simplify the presentation the diagrams are not sorted   consider an interpretation with
domain        and relations  q     p      as can be seen from  c   by choosing x       i e 
   

fiwang  joshi    khardon

action a     the valuation x       x      gives a value of     after the action  without
considering the discount factor   obviously if we do not standardize apart  i e x     x    
there is no leaf with value     and we get a wrong value  intuitively the contribution of
asucc to the value comes from the bring about portion of the diagram and af ails
contribution uses bindings from the not undo portion and the two portions can refer to
different objects  standardizing apart allows us to capture both simultaneously 
from lemma    and    and the discussion so far we have 
lemma    consider any concrete instantiation of a rmdp  let vn be a value function
for the corresponding mdp  and let a  x  be a probabilistic action in the domain  then
a  
x 
qvn as calculated by equation   is correct  that is  for any state s  mapqa  x   s  is the
vn

expected value of executing a  x  in s and then receiving the terminal value v n  
    observations for single path semantics

section     suggested that the single path semantics of blockeel and de raedt        does
not support value iteration as well as the multiple path semantics  now with the explanation
of regression  we can use an example to illustrate this  suppose we have a value function
as defined in figure    a   saying that if we have a red block in a big city then value   is
assigned  figure    b  gives the result after block replacement under action unloads b    t   
however this is not correct  consider an interpretation s with domain  b     b    t    c    and
relations  red b     blue b     big c     bin b    c     t in t    c     on b    t      note that we use
the single path semantics  we follow the true branch at the root since b  c  bin b  c  is true
with  b b    c c     but we follow the false branch at red b  since b  c  bin b  c   red b 
is not satisfied  therefore we get a value of    clearly  we should get a value of   instead
with  b b    c c     but it is impossible to achieve this value in figure    b  with the single
path semantics  the reason block replacement fails is that the top node decides on the true
branch based on one instance of the predicate but we really need all true instances of the
predicate to filter into the true leaf of the tvd 
to correct the problem  we want to capture all instances that were true before and
not undone and all instances that are made true on one path  figure    c  gives one
possible way to do it  here  means variable renaming  and  stands for union operator 
which takes a union of all substitutions  both can be treated as edge operations  note
that  is a coordinated operation  i e   instead of taking the union of the substitutions for
b  and b     c  and c   separately we need to take the union of the substitutions for  b    c   
and  b     c      this approach may be possible but it clearly leads to complicated diagrams 
similar complications arise in the context of object maximization  finally if we are to use
this representation then all our procedures will need to handle edge marking and unions of
substitutions so this approach does not look promising 
    object maximization
notice that since we are handling different probabilistic alternatives of the same action
separately we must keep action parameters fixed during the regression process and until
they are added in step   of the algorithm  in step   we maximize over the choice of action
parameters  as mentioned above we get this maximization for free  we simply rename
   

fifirst order decision diagrams for relational mdps

bin b  c  

bin b   c  

bin b  c 

b  b 

red b 

bin b  c  

on b   t  

b  b 

tin t  c  

big c 
 

 
 a 

red b  
big c  
 

red b  

on b  t  
 

 

 

on b  t  
tin t  c  

tin t  c    b c 
 b  c  
 b c 
 b  c   
 b  c  

big c  
 

b  b 

 b c 
 b  c  

 

red b 
big c 

 b 

 

 

 c 

figure     an example illustrating union or 

the action parameters using new variable names  to avoid repetition between iterations 
and consider them as variables  the aggregation semantics provides the maximization and
by definition this selects the best instance of the action  since constants are turned into
variables additional reduction is typically possible at this stage  any combination of weak
and strong reductions can be used  from the discussion we have the following lemma 
lemma    consider any concrete instantiation of a rmdp  let vn be a value function
for the corresponding mdp  and let a  x  be a probabilistic action in the domain  then
qa
vn as calculated by object maximization in step   of the algorithm is correct  that is  for
any state s  mapqa  s  is the maximum over expected values achievable by executing an
vn
instance of a  x  in s and then receiving the terminal value vn  
a potential criticism of our object maximization is that we are essentially adding more
variables to the diagram and thus future evaluation of the diagram in any state becomes
more expensive  since more substitutions need to be considered   however  this is only true
if the diagram remains unchanged after object maximization  in fact  as illustrated in the
example given below  these variables may be pruned from the diagram in the process of
reduction  thus as long as the final value function is compact the evaluation is efficient and
there is no such hidden cost 
    maximizing over actions
the maximization vn     maxa qa
n   in step     combines independent functions  therefore as above we must first standardize apart the different diagrams  then we can follow
with the propositional apply procedure and finally follow with weak and strong reductions 
this clearly maintains correctness for any concrete instantiation of the state space 
   

fiwang  joshi    khardon

    order over argument types
we can now resume the discussion of ordering of argument types and extend it to predicate
and action parameters  as above  some structure is suggested by the operations of the
algorithm  section     already suggested that we order constants before variables 
action parameters are special constants before object maximization but they become
variables during object maximization  thus their position should allow them to behave as
variables  we should therefore also order constants before action parameters 
note that predicate parameters only exist inside tvds  and will be replaced with domain
constants or variables during regression  thus we only need to decide on the relative
order between predicate parameters and action parameters  if we put action parameters
before predicate parameters and the latter is replaced with a constant then we get an order
violation  so this order is not useful  on the other hand  if we put predicate parameters
before action parameters then both instantiations of predicate parameters are possible 
notice that when substituting a predicate parameter with a variable  action parameters
still need to be larger than the variable  as they were in the tvd   therefore  we also order
action parameters after variables 
to summarize  the ordering  constants  variables  predicate parameters in case of
tvds   action parameters  is suggested by heuristic considerations for orders that maximize the potential for reductions  and avoid the need for re sorting diagrams 
finally  note that if we want to maintain the diagram sorted at all times  we need
to maintain variant versions of each tvd capturing possible ordering of replacements of
predicate parameters  consider a tvd in figure    a   if we rename predicate parameters
x and y to be x  and x  respectively  and if x   x    then the resulting sub fodd as
shown in figure    b  violates the order  to solve this problem we have to define another
tvd corresponding to the case where the substitution of x  the substitution of y   as
shown in figure    c   in the case of replacing x with x  and y with x    we use the tvd
in figure    c  instead of the one in figure    a  

on x  y 

on x   x  

on x  y 

p x 

p x  

p y 

p x  

p y 
 

 
 a 

 

p x 
 

 b 

 

 
 c 

figure     an example illustrating the necessity to maintain multiple tvds 

    convergence and complexity
since each step of procedure   is correct we have the following theorem 

   

fifirst order decision diagrams for relational mdps

theorem   consider any concrete instantiation of a rmdp  let vn be the value function
for the corresponding mdp when there are n steps to go  then the value of vn   calculated
by procedure   correctly captures the value function when there are n     steps to go  that
is  for any state s  mapvn    s  is the maximum expected value achievable in s in n    
steps 
note that for rmdps some problems require an infinite number of state partitions 
thus we cannot converge to v  in a finite number of steps  however  since our algorithm
implements vi exactly  standard results about approximating optimal value functions and
policies still hold  in particular the following standard result  puterman        holds for
our algorithm  and our stopping criterion guarantees approximating optimal value functions
and policies 
theorem   let v  be the optimal value function and let vk be the value function calculated
by the relational vi algorithm 
    if r s   m for all s then kvn  v  k   for n 
    if kvn    vn k 

   
 

 m
 
log     

log  

 

then kvn    v  k   

while the algorithm maintains compact diagrams  reduction of diagrams is not guaranteed for all domains  therefore we can only provide trivial upper bounds in terms of
worst case time complexity  notice first that every time we use the apply procedure the
size of the output diagram may be as large as the product of the size of its inputs  we
must also consider the size of the fodd giving the regressed value function  while block
replacement is o n   where n is the size of the current value function  it is not sorted
and sorting may require both exponential time and space in the worst case  for example 
bryant        illustrates how ordering may affect the size of a diagram  for a function of
 n arguments  the function x   x    x   x         x n   x n only requires a diagram of
 n     nodes  while the function x   xn     x   xn          xn  x n requires  n   nodes 
notice that these two functions only differ by a permutation of their arguments  now if
x   x    x   x         x n   x n is the result of block replacement then clearly sorting
requires exponential time and space  the same is true for our block combination procedure
or any other method of calculating the result  simply because the output is of exponential
size  in such a case heuristics that change variable ordering  as in propositional adds
 bryant         would probably be very useful 
assuming tvds  reward function  and probabilities all have size  c  each action
has  m action alternatives  the current value function vn has n nodes  and worst case
space expansion for regression and all apply operations  the overall size of the result and
 
the time complexity for one iteration are o c m  n        however note that this is the
worst case analysis and does not take reductions into account  while our method is not
guaranteed to always work efficiently  the alternative of grounding the mdp will have an
unmanageable number of states to deal with  so despite the high worst case complexity our
method provides a potential improvement  as the next example illustrates  reductions can
substantially decrease diagram size and therefore save considerable time in computation 
   

fiwang  joshi    khardon

    a comprehensive example of value iteration
figure    traces steps in the application of value iteration to the logistics domain  the
tvds  action choice probabilities  and reward function for this domain are given in figure     to simplify the presentation  we continue using the predicate ordering bin   
 on  t in  rain introduced earlier  
given v    r as shown in figure    a   figure    b  gives the result of regression of
v  through unloads b   t   by block replacement  denoted as regr v    unloads b   t    
figure    c  gives the result of multiplying regr v    unloads b   t    with the choice
probability of unloads p r unloads b   t    
figure    d  gives the result of p r unloadf  b   t     regr v    unloadf  b   t     notice that this diagram is simpler since unloadf does not change the state and the tvds
for it are trivial 
figure    e  gives the unreduced result of adding two outcomes for unload b   t    i e  
the result of adding  p r unloads b   t   regr v    unloads b   t     to  p r unloadf  b   t   
regr v    unloadf  b   t      note that we first standardize apart diagrams for unloads b    t  
and unloadf  b   t   by respectively renaming b as b  and b    action parameters b and t
at this stage are considered as constants and we do not change them  also note that the
recursive part of apply  addition   has performed some reductions  i e   removing the node
rain when both of its children lead to value    
in figure    e   we can apply r  to node bin b    p aris  in the left branch  the
conditions
p      b    bin b    p aris     b    b    bin b    p aris   bin b    p aris   
v     min bin b    p aris t         max bin b    p aris f       
v     bin b    p aris t is a constant
hold  according to lemma   and lemma   we can drop node bin b    p aris  and connect its
parent bin b    p aris  to its true branch  figure    f   gives the result after this reduction 
next  consider the true child of bin b    p aris  and the true child of the root  the
conditions
p      b    b    bin b    p aris   bin b    p aris     b    bin b    p aris   
v     min bin b    p aris t         max bin b    p aris t        
v     min bin b    p aris t         max bin b    p aris f      
hold  according to lemma   and lemma    we can drop the node bin b    p aris  and
connect its parent bin b    p aris  to bin b    p aris f   figure    g  gives the result after
unload b  t  
this reduction and now we get a fully reduced diagram  this is tv 
 
in the next step we perform object maximization to maximize over action parameters
b and t and get the best instance of the action unload  note that b and t have now
become variables  and we can perform one more reduction  we can drop the equality on
the right branch by r   figure    h  gives the result after object maximization  i e  
unload b  t  
obj max tv 
   note that we have renamed the action parameters to avoid the
repetition between iterations 
unload b  t  
figure    i  gives the reduced result of multiplying figure    h   obj max tv 
  
by         and adding the reward function  this result is qunload
 
 
   the details do not change substantially if we use the order suggested in section      where equality is
first  

   

fifirst order decision diagrams for relational mdps

bin  b  paris 

v 

  

bin  b  paris 
  

b  b 

b  b 
on  b  t  

tin  t   paris 

tin  t   paris 

  

 

 

 

 

 

 d 

 c 

bin  b   paris 
  

 

rain

 

rain

 b 

bin  b   paris 

bin  b  paris 

on  b  t  

 
 a 

bin  b  paris 

bin  b   paris 
  

bin  b   paris 

bin  b   paris 

rain
b   b 
 
on  b   t  

 

tin  t   paris 
  

rain

b   b 

b   b 
on  b   t  

on  b   t  

     

on  b   t  

tin  t   paris 

tin  t   paris 
 

rain

b   b 

  

tin  t   paris 

rain

 

     

 

 e 

 f 

bin  b   paris 
  

bin  b   paris 

b   b 
on  b   t  

 

q unload

on  b   t  

  

 

       
 h 

v 

       
 l 

 

bin  b  paris 

 

  

tin  t  paris 

on  b  t  

 

tin  t   paris 

rain

q

 i 

b  b 

on  b  t 

tin  t  paris 

 j 

 

 k 

bin  b  paris 

bin  b  paris 
  

 

drive
 

rain

 
 g 

  

tin  t  paris 

 

 

bin  b  paris 

on  b  t 

  

rain
 

q load

bin  b  paris 

tin  t   paris 

tin  t   paris 
rain

 

rain

tin  t  paris 

t  t 
 

 

on b  t 

tin  t  paris 
 

rain
       

 

rain
       



b b 

  



 



 

 
 

tin  t  paris 
 

rain
       
 n 

 m 

figure     an example of value iteration in the logistics domain 

   

fiwang  joshi    khardon

we can calculate qload
and q drive in the same way and results are shown in figure    j 
 
and figure    k  respectively  for drive the tvds are trivial and the calculation is
relatively simple  for load  the potential loading of a box already in paris is dropped from
the diagram by the reduction operators in the process of object maximization 
figure    l  gives v    the result after maximizing over qunload
  qload
and qdrive
  here
 
 
 
again we standardized apart the diagrams  maximized over them  and then reduced the
result  in this case the diagram for unload dominates the other actions  therefore q unload
 
becomes v    the value function after the first iteration 
now we can start the second iteration  i e   computing v  from v    figure    m  gives
the result of block replacement in regression of v   through action alternative unloads b   t   
note that we have sorted the tvd for on b  t   so that it obeys the ordering we have chosen 
however  the diagram resulting from block replacement is not sorted 
to address this we use the block combination algorithm to combine blocks bottom
up  figure    n  illustrates how we combine blocks t in t  p aris   which is a tvd  and
its two children  which have been processed and are general fodds  after we combine
t in t  p aris  and its two children  on b  t t has been processed  since on b  t f     
now we can combine on b  t  and its two children in the next step of block combination 
continuing this process we get a sorted representation of regr v    unloads b   t    
    extracting optimal policies
there is more than one way to represent policies with fodds  here we simply note that
a policy can be represented implicitly by a set of regressed value functions  after the value
iteration terminates  we can perform one more iteration and compute the set of q functions
using equation   
then  given a state s  we can compute the maximizing action as follows 
   for each q function qa  x    compute mapqa  x   s   where  x are considered as variables 
   for the maximum map obtained  record the action name and action parameters  from
the valuation  to obtain the maximizing action 
this clearly implements the policy represented by the value function  an alternative
approach that represents the policy explicitly was developed in the context of a policy
iteration algorithm  wang   khardon        

   discussion
adds have been used successfully to solve propositional factored mdps  our work gives one
proposal of lifting these ideas to rmdps  while the general steps are similar  the technical
details are significantly more involved than the propositional case  our decision diagram
representation combines the strong points of the sdp and rebel approaches to rmdp  on
the one hand we get simple regression algorithms directly manipulating the diagrams  on
the other hand we get object maximization for free as in rebel  we also get space saving
since different state partitions can share structure in the diagrams  a possible disadvantage
compared to rebel is that the reasoning required for reduction operators might be complex 
   

fifirst order decision diagrams for relational mdps

in terms of expressiveness  our approach can easily capture probabilistic strips style
formulations as in rebel  allowing for more flexibility since we can use fodds to capture
rewards and transitions  for example  our representation can capture universal effects of
actions  on the other hand  it is more limited than sdp since we cannot use arbitrary
formulas for rewards  transitions  and probabilistic choice  for example we cannot express
universal quantification using maximum aggregation  so these cannot be used in reward
functions or in action preconditions  our approach can also capture grid world rl domains
with state based reward  which are propositional  in factored form since the reward can be
described as a function of location 
by contrasting the single path semantics with the multiple path semantics we see an
interesting tension between the choice of representation and task  the multiple path method
does not directly support state partitions  which makes it awkward to specify distributions
and policies  since values and actions must both be specified at leaves   however  this
semantics simplifies many steps by easily supporting disjunction and maximization over
valuations which are crucial for for value iteration so it is likely to lead to significant saving
in space and time 
an implementation and empirical evaluation are in progress  the precise choice of
reduction operators and their application will be crucial to obtain an effective system  since
in general there is a tradeoff between run time needed for reductions and the size of resulting
fodds  we can apply complex reduction operators to get the maximally reduced fodds 
but it takes longer to perform the reasoning required  this optimization is still an open issue
both theoretically and empirically  additionally  our implementation can easily incorporate
the idea of approximation by combining leaves with similar values to control the size of
fodds  st aubin et al          this gives a simple way of trading off efficiency against
accuracy of the value functions 
there are many open issues concerning the current representation  our results for
fodds give a first step toward a complete generalization of adds  crucially we do not
yet have a semantically appropriate normal form that is important in simplifying reasoning 
while one can define a normal form  cf   garriga et al         for a treatment of conjunctions 
it is not clear if this can be calculated incrementally using local operations as in adds  it
would be interesting to investigate conditions that guarantee a normal form for a useful set
of reduction operators for fodds 
another possible improvement is that the representation can be modified to allow further
compression  for example we can allow edges to rename variables when they are traversed
so as to compress isomorphic sub fodds as illustrated above in figure    c   another
interesting possibility is a copy operator that evaluates several copies of a predicate  with
different variables  in the same node as illustrated in figure     for such constructs to be
usable one must modify the fodd and mdp algorithmic steps to handle diagrams with
the new syntactic notation 

   conclusion
the paper makes two main contributions  first  we introduce fodds  a generalization of
adds  for relational domains that may be useful in various applications  we have developed
calculus of fodds and reduction operators to minimize their size but there are many open
   

fiwang  joshi    khardon

p  x   p  y 

p  x 
q  x 

 

q  x 

p  y   

f  y   

f  y   
 

 

 

 

 

figure     example illustrating the copy operator 

issues regarding the best choice of operators and reductions  the second contribution is
in developing a fodd based value iteration algorithm for rmdps that has the potential
for significant improvement over previous approaches  the algorithm performs general
relational probabilistic reasoning without ever grounding the domains and it is proved to
converge to the abstract optimal value function when such a solution exists 

references
bahar  r  i   frohm  e  a   gaona  c  m   hachtel  g  d   macii  e   pardo  a     somenzi 
f          algebraic decision diagrams and their applications  in proceedings of the
international conference on computer aided design  pp         
bellman  r  e          dynamic programming  princeton university press 
blockeel  h     de raedt  l          top down induction of first order logical decision trees 
artificial intelligence              
boutilier  c   dean  t     goldszmidt  m          stochastic dynamic programming with
factored representations  artificial intelligence                
boutilier  c   dean  t     hanks  s          decision theoretic planning  structural assumptions and computational leverage  journal of artificial intelligence research 
        
boutilier  c   dearden  r     goldszmidt  m          exploiting structure in policy construction  in proceedings of the international joint conference of artificial intelligence 
pp           
boutilier  c   reiter  r     price  b          symbolic dynamic programming for first order
mdps  in proceedings of the international joint conference of artificial intelligence 
pp         
bryant  r  e          graph based algorithms for boolean function manipulation  ieee
transactions on computers  c                
bryant  r  e          symbolic boolean manipulation with ordered binary decision diagrams  acm computing surveys                 
cormen  t  h   leiserson  c  e   rivest  r  l     stein  c          introduction to algorithms  mit press 
   

fifirst order decision diagrams for relational mdps

driessens  k   ramon  j     gartner  t          graph kernels and gaussian processes for
relational reinforcement learning  machine learning                  
dzeroski  s   de raedt  l     driessens  k          relational reinforcement learning 
machine learning          
feng  z     hansen  e  a          symbolic heuristic search for factored markov decision
processes  in proceedings of the national conference on artificial intelligence  pp 
       
fern  a   yoon  s     givan  r          approximate policy iteration with a policy language
bias  in international conference on neural information processing systems 
fern  a   yoon  s     givan  r          approximate policy iteration with a policy language
bias  solving relational markov decision processes  journal of artificial intelligence
research            
garriga  g   khardon  r     de raedt  l          on mining closed sets in multi relational
data  in proceedings of the international joint conference of artificial intelligence 
pp         
gretton  c     thiebaux  s          exploiting first order regression in inductive policy
selection  in proceedings of the conference on uncertainty in artificial intelligence 
pp         
groote  j  f     tveretina  o          binary decision diagrams for first order predicate
logic  the journal of logic and algebraic programming          
gromann  a   holldobler  s     skvortsova  o          symbolic dynamic programming
within the fluent calculus  in proceedings of the iasted international conference
on artificial and computational intelligence 
guestrin  c   koller  d   gearhart  c     kanodia  n       a   generalizing plans to new
environments in relational mdps  in proceedings of the international joint conference
of artificial intelligence  pp           
guestrin  c   koller  d   par  r     venktaraman  s       b   efficient solution algorithms
for factored mdps  journal of artificial intelligence research             
hansen  e  a     feng  z          dynamic programming for pomdps using a factored
state representation  in proceedings of the international conference on artificial
intelligence planning systems  pp         
hoey  j   st aubin  r   hu  a     boutilier  c          spudd  stochastic planning using decision diagrams  in proceedings of the conference on uncertainty in artificial
intelligence  pp         
hoolldobler  s   karabaev  e     skvortsova  o          flucap  a heuristic search planner
for first order mdps  journal of artificial intelligence research             
kersting  k   otterlo  m  v     de raedt  l          bellman goes relational  in proceedings
of the international conference on machine learning 
mcmillan  k  l          symbolic model checking  kluwer academic publishers 
   

fiwang  joshi    khardon

puterman  m  l          markov decision processes  discrete stochastic dynamic programming  wiley 
rivest  r  l          learning decision lists  machine learning                
sanghai  s   domingos  p     weld  d          relational dynamic bayesian networks 
journal of artificial intelligence research             
sanner  s     boutilier  c          approximate linear programming for first order mdps 
in proceedings of the conference on uncertainty in artificial intelligence 
sanner  s     boutilier  c          practical linear value approximation techniques for firstorder mdps  in proceedings of the conference on uncertainty in artificial intelligence 
sanner  s     boutilier  c          approximate solution techniques for factored first order
mdps  in proceedings of the international conference on automated planning and
scheduling 
schuurmans  d     patrascu  r          direct value approximation for factored mdps  in
international conference on neural information processing systems  pp           
st aubin  r   hoey  j     boutilier  c          apricodd  approximate policy construction using decision diagrams  in international conference on neural information
processing systems  pp           
wang  c          first order markov decision processes  tech  rep  tr         computer
science department  tufts university 
wang  c   joshi  s     khardon  r          first order decision diagrams for relational
mdps  in proceedings of the international joint conference of artificial intelligence 
pp           
wang  c     khardon  r          policy iteration for relational mdps  in proceedings of
the conference on uncertainty in artificial intelligence 

   

fi