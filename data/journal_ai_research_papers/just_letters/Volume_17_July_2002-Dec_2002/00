journal artificial intelligence research               

submitted       published     

critical assessment
benchmark comparison planning
adele e  howe
eric dahlman

computer science department
colorado state university  fort collins  co      

howe cs colostate edu
dahlman cs colostate edu

abstract
recent trends planning research led empirical comparison becoming commonplace  field started settle methodology comparisons 
obvious practical reasons requires running subset planners subset problems 
paper  characterize methodology examine eight implicit assumptions
problems  planners metrics used many comparisons  problem assumptions are  pr   performance general purpose planner
penalized biased executed sampling problems domains  pr   minor syntactic
differences representation affect performance  pr   problems solvable strips capable planners unless require adl  planner assumptions are 
pl   latest version planner best one use  pl   default parameter settings
approximate good performance  pl   time cut offs unduly bias outcome 
metrics assumptions are  m   performance degrades similarly planner run
degraded runtime environments  e g   machine platform  m   number plan
steps distinguishes performance  find assumptions supported
empirically  particular  planners affected differently assumptions 
conclude call community devote research resources improving state
practice especially enhancing available benchmark problems 

   introduction
recent years  comparative evaluation become increasingly common demonstrating
capabilities new planners  planners directly compared
problems taken set domains  result  recent advances planning
translated dramatic increases size problems solved  weld 
       empirical comparison highlighted improvements 
comparative evaluation planning significantly uenced expedited
artificial intelligence planning scheduling  aips  conference competitions 
competitions dual effect highlighting progress field providing
relatively unbiased comparison state of the art planners  individual researchers
compare planners others  include fewer planners fewer test problems
time constraints 
support first competition       mcdermott         drew mcdermott defined 
contributions organizing committee  shared problem domain definition
language  pddl  mcdermott et al          planning domain definition language   using

c      ai access foundation morgan kaufmann publishers  rights reserved 

fihowe   dahlman

common language means planners  performance directly compared  without
entailing hand translation factoring different representational capabilities 
second benefit  lack translation  or least human accomplished translation  meant performance could compared large number problems
domains   fact  five competition planners given large number problems
     problems adl track     strips track  within seven domains 
including one domain planner developers never seen prior competition 
first competition generated large collection benchmarks  seven domains used
competition plus    considered use     domains available
ftp   ftp cs yale edu pub mcdermott domains   second competition added three
novel domains set 
third major benefit competitions appear motivated researchers develop systems others use  number entrants went five
first competition    second  additionally       competitors six
sixteen      competitors made code available web sites  thus  others
perform comparisons 
paper  describe current practice comparative evaluation evolved
since aips competitions critically examine underlying assumptions
practice  summarize existing evidence assumptions describe
experimental tests others previously considered  assumptions
organized three groups concerning critical decisions experiment design 
problems tested  planners included performance metrics collected 
comparisons  as part competitions specific researchers  proven enormously useful motivating progress field  goal understand assumptions
readers know far comparative results generalized  contrast
competitions  community cannot legislate fairness individual researcher s comparative evaluations  readers may able identify cases results viewed
either skeptically confidence  thus  conclude paper observations
call considerably research new problems  metrics methodologies
support planner evaluation 
contrast competitions  goal declare winner  goal
critique individual studies  consequently  draw attention away
possible interpretation  whenever possible  report results using letter designators
assigned randomly planners 

   planning competitions direct comparisons

recently  aips competitions spurred considerable interest comparative evaluation  roots comparative planner evaluation go back considerably further  however 
although researchers able run side by side comparisons planners
   solve particular planning problem  i e   construct sequence actions transform initial state
goal state   planners require domain theory problem description  domain theory represents
abstract actions executed environment  typically  domain descriptions include
variables instantiated specific objects values  multiple problems defined
domain  problem descriptions require initial state description  goal state association
domain 

 

fia critical assessment benchmark comparison planning

others  able demonstrate performance planner well known problems  could viewed de facto benchmarks  sussman s anomaly  sussman       
blocksworld premier planning benchmark problem domain many years 
every planner needed  cut teeth  it 
researchers tired blocksworld  many called additional benchmark problems
environments  mark drummond  leslie kaelbling stanley rosenschein organized
workshop benchmarks metrics  drummond  kaelbling    rosenschein        
testbed environments  martha pollack s tileworld  pollack   ringuette       
steve hanks s truckworld  hanks  nguyen    thomas         used comparing
algorithms within planners        ucpop  penberthy   weld        distributed
large set problems      problems    domains  demonstration purposes 
      barry fox mark ringer set planning scheduling benchmarks web page
 http   www newosoft com  benchmrx   collect problem definitions  emphasis
manufacturing applications  recently  planet  a coordinating organization european planning scheduling researchers  proposed planning benchmark collection
initiative  http   planet dfki de  
clearly  benchmark problems become well established means demonstrating
planner performance  however  practice known benefits pitfalls  hanks  pollack
cohen        discuss detail context agent architecture design 
benefits include providing metrics comparison supporting experimental control 
pitfalls include lack generality results potential benchmarks
unduly uence next generation solutions  words  researchers construct
solutions excel benchmarks  regardless whether benchmarks accurately
represent desired real applications 
obtain benefits listed benchmarks  problems often idealized
simplified versions real problems  cohen        points   research papers
ai  least aaai conference  exploit benchmark problems  yet relate
benchmarks target tasks  may significant problem  example  study
owshop scheduling  benchmarks  found performance standard benchmark set generalize performance problems realistic structure  watson 
barbulescu  howe    whitley         study blocksworld problems found
best known blocksworld benchmark problems atypical require short
plans solution optimal solutions easy find  slaney   thiebaux        
spite diculties  benchmark problems aips competitions considerably uenced comparative planner evaluations  example  aips      conference proceedings  chien  kambhampati    knoblock         papers improvements classical planning        papers conference  relied heavily
comparative evaluation using benchmark problems  papers concerned scheduling 
specific applications  theoretical analyses special extensions standard paradigm
 e g   pomdp  sensing      classical papers  six used problems aips  
competition benchmark set  six used problems kautz selman s distribution
problems blackbox  kautz        three added problems
well  paper showed results subset problems benchmark distributions
   scheduling area related planning actions already known  sequence still
needs determined  flowshop scheduling type manufacturing scheduling problem 

 

fihowe   dahlman

 e g   drew mcdermott s first competition  logistics  blocksworld  rocket
gripper domains popular  used            papers  respectively   availability planners competition exploited  eight papers compared
systems aips   planners  blackbox  stan  ipp hsp  in          
papers  respectively  

   assumptions direct comparison
canonical planner evaluation experiment follows procedure table    procedure
designed compare performance new planner previous state art
highlight superior performance set cases new planner  exact form
experiment depends purpose  e g   showing superiority class problem
highlighting effect design decision 
   select and or construct subset planner domains
   construct problem set by 
running large set benchmark problems
selecting problems desirable features
varying facet problem increase diculty  e g   number blocks 
   select planners are 
representative state art problems
similar distinct new planner  depending point comparison advance new planner
available able parse problems
   run problems planners using default parameters setting upper limit
time allowed
   record problems solved  many plan steps actions solution
much cpu time required either solve problem  fail time
table    canonical comparative planner evaluation experiment 
protocol depends three selections  problems  planners evaluation metrics 
simply practical even desirable run available planners available
problems  thus  one needs make informed decisions select  purpose
paper examine assumptions underlying decisions help make
informed  every planner comparison adopt every one assumptions 
assumptions ones commonly found planner comparisons  example 
comparisons designed specific purpose  e g   show scale up certain problems
suitability planner logistics problems  carefully select particular types
problems benchmark sets 
 

fia critical assessment benchmark comparison planning

problems many planning systems developed solve particular type planning
problem explore specific type algorithmic variation  consequently  one would expect
perform better problems developed  even
designed specific purpose  test set used development may
subtly biased development  community knows planner performance depends
problem features  general  how  why  researchers tend design
planners general purpose  consequently  comparisons assume
performance general purpose planner penalized biased
executed sampling problems domains  problem assumption    

community knows problem representation uences planner performance 
example  benchmark problem sets include many versions blocksworld problems  designed different planner developers  versions vary problem representation 
minor apparently syntactic changes  e g   clauses ordered within operators 
initial conditions goals  whether information extraneous  changes ecting addition domain knowledge  e g   constraints included whether
variables typed   consequently  comparisons assume
syntactic representational modifications either matter affect planner equally  problem assumption    

pddl includes field   requirements  capabilities required planner solve
problem  pddl    defined    values  requirements field  base default requirement  strips  meaning strips derived add delete sets action effects   adl
 from pednault s action description language  requires variable typing  disjunctive preconditions  equality built in predicate  quantified preconditions conditional effects
addition  strips capability  yet  many planners either ignore  requirements
field reject problem specifies  adl  ignoring many requirements
could cause trouble   thus  comparisons assume
problems benchmark set solvable strips planner unless
require  adl  problem assumption    

planners wonderful trend making planners publicly available led dilemma
determining use configure them  problem compounded
longevity planner projects  projects produced multiple versions 
consequently  comparisons tend assume
latest version planner best  planner assumption    

planners may include parameters  example  blackbox planner allows
user define strategy applying different solution methods  researchers expect
parameters affect performance  consequently  comparisons assume
default parameter settings approximate good performance  planner assumption
   
 

fihowe   dahlman

experiments invariably use time cut offs concluding planning yet found
solution declared failure  many planners would need exhaustively search large space
declare failure  practical reasons  time threshold set determine
halt planner  failure declared time out reached  thus  comparisons
assume
one picks suciently high time out threshold  highly unlikely
solution would found slightly time granted  planner
assumption    

metrics ideally  performance would measured based well planner

job  i e   constructing  best  possible plan solve problem  eciently
so  planner shown solve possible problems  basic
metric performance number percentage problems actually solved within
allowed time  metric commonly reported competitions  however  research
papers tend report directly typically test relatively small number
problems 
eciency clearly function memory effort  memory size limited
hardware  effort measured cpu time  preferably always platform
language  problems cpu time well known  programmer skill
varies  research code designed fast prototyping fast execution  numbers
literature cannot compared newer numbers due processor speed improvements 
however  cpu times regenerated experimenter s environment one assumes

performance degrades similarly reductions capabilities runtime
environment  e g   cpu speed  memory size   metric assumption    

words  experimenter user system expect code
optimized particular compiler operating system hardware configuration 
perform similarly moved another compatible environment 
commonly reported comparison metric computation time  second
number steps actions  for planners allow parallel execution  plan  although
planning seeks solutions achieving goals  goals defined terms states
world  lend well general measures quality  fact  quality likely
problem dependent  e g   resource cost  amount time execute  robustness  
number plan steps favored  comparisons assume
number steps resulting plan varies planner solutions approximates quality  metric assumption    

comparison  competitions especially  unenviable task determining
trade off combine three metrics  number solved  time  number steps   thus 
number steps matter  comparison could simplified 
converted assumption testable question  either summarized
literature question ran experiment test it 
 

fia critical assessment benchmark comparison planning

    experimental setup
key issues examined previously  directly indirectly  those 
simply summarize results subsections follow  however  open
questions  those  ran seven well known planners large set      benchmark
problems  planners accept pddl representation  although built in
translators pddl internal representation others rely translators
added  several versions planner available  included  for total
   planners   basic problem set comprises ucpop benchmarks  aips  
     competition test sets additional problem set developed specific application 
exception permuted problems  see section problem assumption
  specifics   problems run     mhz ultrasparc   s     megabytes
memory running sunos      whenever possible  versions compiled developers
used  source code available  compiled systems according
developers  instructions  planners written common lisp run allegro
common lisp version        planners compiled gcc  egcs version
          planner given    minute limit wall clock time  find solution 
however  times reported run times returned operating system 
      planners

planners called primitive action planners  wilkins   desjardins 
       planners require relatively limited domain knowledge construct plans
simple action descriptions  aips   competition required planners accept
pddl  majority planners used study competition entrants later
versions thereof     common language facilitated comparison planners without address effects translation step  two exceptions ucpop
prodigy  however  representations similar pddl translated automatically  planners represent five different approaches planning  plan graph analysis 
planning satisfiability  planning heuristic search  state space planning learning
partial order planning  possible  used multiple versions planner 
necessarily recent  conducted study period time  almost     years   froze set early on  comparing performance declare
winner think lack recent versions undermined results
testing assumptions 

ipp  koehler  nebel  hoffmann    dimopoulos        extends graphplan  blum  

furst        algorithm accept richer plan description language  early versions 
language subset adl extends strips formalism graphplan
allow conditional universally quantified effects operators  version     
negation handled via introduction new predicates negated preconditions
   used actual time lightly loaded machines occasionally system would thrash due
inadequate memory resulting little progress considerable time 
   used bus system manager running planners  howe  dahlman  hansen  scheetz   
von mayrhauser         implemented aips   competition planners  facilitated
running many different planners  somewhat bias included 

 

fihowe   dahlman

corresponding mutual exclusion rules  subsequent versions handle directly  koehler 
       used aips   version ipp well later     version 
sgp  sensory graph plan   weld  anderson    smith        extends graphplan
richer domain description language  primarily focusing uncertainty sensing 
ipp  transformation performed using expansion techniques remove
quantification  sgp directly supports negated preconditions conditional effects 
sgp tends slower  it implemented common lisp instead c 
graphplan based planners  used sgp version    b 
stan  state analysis   fox   long        extends graphplan algorithm part
adding preprocessor  called tim  infer type information problem domain 
information used within planning algorithm reduce size search
space graphplan algorithm would search  stan incorporated optimized data
structures  bit vectors planning graph  help avoid many redundant calculations performed graphplan  additionally  stan maintains wave front graph
construction track remaining goals limit graph construction  subsequent versions
incorporated analyses  e g   symmetry exploitation  additional simpler planning engine  four versions stan tested  aips   competition version  version
     version    s development snapshot version     
blackbox  kautz   selman        converts planning problems boolean satisfiability
problems  solved using variety different techniques  user indicates
techniques tried order  constructing satisfiability problem 
blackbox uses planning graph constructed graphplan  blackbox  used
version     version    b 
hsp  heuristic search planner   bonet   geffner        based heuristic search 
planner uses variation hill climbing random restarts solve planning problems 
heuristic based using graphplan algorithm solve relaxed form
planning problem  study  used version      algorithmic refinement
version entered aips   competition  version     
prodigy    the prodigy research group        combines state space planning backward chaining goal state  plan construction consists head plan
totally ordered actions starting initial state tail plan partially ordered
actions related goal state  although ocially entered competition  informal results presented aips   competition suggested prodigy performed well
comparison entrants  used prodigy version     
ucpop  barrett  golden  penberthy    weld        partial order causal link
planner  decision include ucpop based several factors  first 
expand quantifiers negated preconditions  domains  expansion
grounding operators great make problem insolvable  second  ucpop
based significantly different algorithm interest recently resurfaced 
used ucpop version     
   thank eugene fink code translates pddl prodigy 

 

fia critical assessment benchmark comparison planning

source
  domains   problems
benchmarks
  
   
aips     
 
   
aips     
 
   
developers
 
  
application
 
  
table    summary problems testing set  source problems  number
domains problems within domains 
      test problems

following standard practice  experiments require planners solve commonly available
benchmark problems aips competition problems  addition  test assumptions uence domains  assumption pr   representations problems
 assumption pr    include permuted benchmark problems application problems  section describes set problems domains study 
focusing source composition 
problems require strips capabilities  i e   add delete lists   chose
least common denominator several reasons  first  capable planners still handle
strips requirements  thus  maximized number planners could included
experiment  also  surprisingly  problems type available  second 
examining assumptions evaluation  including effect required capabilities
performance  propose duplicate effort competitions singling
planners distinction  rather  purpose determine factors differentially
affect planners 
bulk problems came aips   aips      problem sets
set problems distributed pddl specification  remaining problems
solicited several sources  source counts problems domains
summarized table   
benchmark problems preponderance problems planning test sets  toy
problems   well known synthetic problems designed test attribute planners 
blocksworld domain long included evaluation well known 
subgoal interactions supports constructing increasingly complex problems
 e g   towers blocks   benchmark problems simplified versions realistic
planning problems  e g   tire  refrigerator repair logistics domains  used
set included ucpop planner  problems contributed large number
people include multiple encodings problems domains  especially blocksworld 
aips competitions            first aips competition  drew mcdermott solicited problems competitors well constructing own 
mystery domain  semantically useless names objects operators 
problems generated domain automatically  competition included    
problems six domains  robot movement grid  gripper balls
 

fihowe   dahlman

moved rooms robot two grippers  logistics transporting packages  organizing snacks movie watching  two mystery domains  disguised logistics
problems 
format      competition required entrants execute     problems
first round  problems     could solved planner  round two 
planners executed    new problems three domains  one included
first round 
     competition attracted    competitors three tracks  strips  adl
hand tailored track  required performance problems five domains  logistics 
blocksworld  parts machining  freecell  a card game   miconic    elevator control 
domains determined organizing committee  fahiem bacchus
chair  represented somewhat broader range  chose problems untyped
strips track set 
scientific standpoint  one interesting conclusions competitions observed trade offs performance  planners appeared excel different
problems  either solving set finding solution faster        ipp solved
problems found shorter plans round two  stan solved problems fastest 
hsp solved problems round one  blackbox solved problems fastest
round one        awards given two groups distinguished planners across
different categories planners  strips  adl hand tailored   according
judges   it impossible say one planner best  bacchus        
talplanner highest distinguished planner group  graphs performance show differences computation time relative planners problem
scale up  however  planner failed solve problems  makes trends
harder interpret  the computation time graphs gaps  
purpose competitions showcase planner technology
succeeded admirably  planners solved much harder problems could
accomplished years past  trend planners handling increasingly dicult
problems  competition test sets may become historical interest tracking field s
progress 
problems solicited planner developers asked planner developers
problems used development  one developer  maria fox  sent us domain
 sodor  logistics application  set problems used  would
included domains problems received others 
applications miconic elevator domain aips     competition
derived actual planning application  domain problems extremely
simplified  e g   removing arithmetic  
add another realistic problem comparison  included one planning application set test domains  generating cases test software interface 
similarities software interface test cases plans  developed system 
several years ago  automatically generating interface test cases using ai planner 
system designed generate test cases user interface storage technology s robot tape library  howe  von mayrhauser    mraz         interface  i e  
commands interface  coded domain theory  example  mount com  

fia critical assessment benchmark comparison planning

mand action s description required drive empty effect changing
position tape mounted changing status tape drive  problems
described initial states tape library  e g   tapes resident 
status devices software controller  goal states human operator might
wish achieve 
time  found simplest problems could generated using
planners available  included application part knew would
challenge  part test set  include three domain theories  different ways
coding application involving      operators  twenty four problems domain 
included    wanted include enough problems see effect 
many overly bias results  problems relatively simple  requiring
movement one tape coupled status changes 
still dicult could solved original system 

    problem assumptions
general purpose planners exhibit differential capabilities domains sometimes even
problems within domain  thus  selection problem set would seem critical
evaluation  example  many problems benchmark sets variants logistics
problems  thus  general purpose planner actually tailored logistics may appear
better overall current benchmarks  section  empirically examine
possible problem set factors may uence performance results 

problem assumption    extent performance general purpose
planners biased toward particular problems domains  although planners
developed general purpose  competitions previous studies shown
planners excel different domains problems  unfortunately  community yet
good understanding planner well particular domain  studied
impact problem selection performance two ways 
first  assessed whether performance might positively biased toward problems
tested development  developer  asked indicate domains used
development  compared planner s performance development
problems  i e   development set  problems remaining complete test set
 rest   ran  x    tests comparing number problems solved versus failed
development test sets  included number solved failed analysis
timed out problems made difference results  
results analysis summarized table    figure   graphically displays
ratio successes failures development problems  planners
except c performed significantly better development problems  suggests
planners tailored  intentionally not  particular types problems
tend better test sets biased accordingly  example  one
   decided studying planners way representations
development problems pddl 
   one planner exception rule  one case  planner timed far frequently
non development problems 

  

fihowe   dahlman

development
planner sol  fail

  
  
b
  
  
c
  
 
g
  
  
h
  
 

   
  
j
   
  
k
  
  
l
  
  

rest
sol  fail
 
p
                    
                   
      
          
                   
                   
                    
                    
                   
                   

table      results comparing outcome development versus problems 
planners set  stan  designed emphasis logistics problems  fox  
long        

figure    histogram ratios success failures development problems
planners 
analysis introduces variety biases  developers tended give us short
lists probably really representative actually used  set used
moving target  rather stationary suggests  set problems included
experimentation publication may different still  consequently  second
part  broadened question determine effect different subsets problems
  

fia critical assessment benchmark comparison planning

n
 
  
  
  

 
 
 
 
 

 
 
 
 
 

 
 
 
 
 

 
 
 
 
 

rank dominance
       
        
        
       
       

       total pairs
        
  
       
  
       
  
      
  

table    rank dominance counts    samples domains domain sizes  n  five
   
performance     trials  randomly selected n domains  and companion
problems  form problem set  counted many problems could
solved planner ranked relative performance planner  thus 
value n  obtained    planner rankings  focused rankings problems
solved two reasons  first  domain includes different number problems  making
count problems variable across trials  second  relative ranking gets
heart whether one planner might considered improvement another 
tested values              n     half domains disposal  
give sense variability size  n      problems solved trial
varied        assess changes rankings across trials  computed rank
dominance pairs planners  rank dominance defined number trials
planner x s rank lower planner y s  note  ties would count toward neither
planner      planners study resulted    dominance pairings  relative
ranking two planners stable  one would expect one always dominate
other  i e   rank dominance    
table   shows number pairs value        rank dominance
four values n  given pair  used highest number rank dominance
pair  e g   one always lower rank  pair s rank dominance   
five  five  ties  maximum less five 
data suggest even picking half domains  rankings completely
stable      pairings  one always dominates          greater chance
switching relative ranking  values degrade n decreases     always
dominating n     

problem assumption    syntactic representation differences affect
performance  although well known planners  performance depends

representation  joslin   pollack        srinivasan   howe         two recent developments
planner research suggest effect needs better understood  first  common
representation  i e   pddl  may bias performance  planners rely pre processing
step convert pddl native representation  step usually requires making
arbitrary choices ordering coding  second  advantage planners based
graphplan supposed less vulnerable minor changes representa  

fihowe   dahlman

planner

b
c

e
f
g
h

j
k
l


none subset
      
  
      
  
      
  
       
  
       
   
       
   
      
  
      
  
       
   
       
   
      
  
       
  
       
  

table    number problems planners able solve all  none
subset permutations 
tion  although reasoning claim sound  exigencies implementation may
require re introduction representation sensitivity 
evaluate sensitivity representation  ten permutations problem
aips     set generated  resulting      permuted problems  permutations
constructed randomly reordering preconditions operator definitions
order definitions operators within domain definition 
limited number problems study ten permutations problems would prohibitive  selected aips     problems attention
recently developed benchmark set  even within set  domains
permuted would result different domains transformation used  purposes investigation  limited set modifications
permutations preconditions operators known affect planners practical considerations limited number permutations could
executed  finally  expediency  ran permutations smaller number faster
platforms expedited throughput computation time factor
study 
analyze data  divided performance permutations problems
three groups based whether planner able solve permutations 
none permutations subset permutations  planner insensitive
minor representational changes  subset count zero  results
table    see planners affected permutation operation 
susceptibility permuting problem strongly planner dependent              
p            demonstrating planners vulnerable others 
examining number subset column  one assess degree susceptibility  planners sensitive reorderings  even relied graphplan
  

fia critical assessment benchmark comparison planning

 
 
   
   
   
   
 
 
   
   
 
  
   

  
 
   
   
   
   
 
  
   
   
 
  
   

 
 
   
   
   
   
 
 
   
   
 
  
   

 
 
 
 
 
 
 
 
 
 
 
 
 

   
   
   
   
   
   
   
   
   
   
   
   
   

 
 
   
   
   
   
 
  
   
   
 
  
   

pre 
 

 
 
   
   
   
   
 
 
   
   
 
  
   

pre 
safety
strips
typing

 
 
 
 
 
 
 
 
 
 
 
 
 

 


b
c

e
f
g
h

j
k
l


feature

axioms
cond  eff 
dis  pre 
equality

planner

 
 
   
   
   
   
 
 
   
   
 
  
   

table    number problems claiming require pddl feature solved
planner 

methodology  sensitive e  f  j  which included graphplan based
planners     problems mixed results permutations  c
l least sensitive       affected  

problem assumption    performance depend pddl requirements
features  planners intended handle strips problems 

problems test set claim require features strips  one would expect
planners would able handle problems  addition 
planners claim able handle given feature may well planners 
table   shows effects feature requirements ability solve problems  data
table based features specified  requirements list pddl
definition domain 
verify requirements accurate necessary  thus  problem
may solvable ignoring part pddl syntax understood 
problem may mislabeled designer  evident cases planner
support given feature still appears able solve corresponding
problem  planners  e g   older versions stan  reject problem requires
strips without trying solve it  adl problem makes use
strips features would attempted 
guidance planner use when  results must viewed
skepticism  example  would appear based results planner might
  

fihowe   dahlman

good choice problems conditional effects able solve many
problems  would mistake  since planner cannot actually handle types
problems  cases  problems claim require adl  fact  make
use strips subset 
clearly  certain problems solved specific planners  instance  c
planners able handle safety constraints  based data 
c  e appear handle domain axioms  half planners trouble
typed problems  gaps appear due problems translation
native representation 

    planners

publicly available  general purpose planners tend large programs developed
period years enhanced include additional features time  thus  several versions
likely available  versions likely features turned
on off via parameter settings 
authors release later versions planning systems  general assumption
newer versions outperform predecessors  however  may
case practice  instance  planner could better optimized toward specific class
problem turn hurts performance problems  also  advanced
capabilities  even unused  may incur overhead solution problems 
comparison purposes  one use latest version  first  tested
question study comparing multiple versions four planners  second 
planner relies parameter settings tune performance  some  blackbox 
many parameters  others none  comparisons tend use default published
parameter settings people usually understand effects parameters
tuning extremely time consuming  practice undermine fair
comparison 
planner assumption    latest version best  study  compared
performance multiple versions four planners  labeled section w  x 
z  larger version numbers indicating subsequent versions   considered two criteria
improvement  outcome planning computation time solved problems 
outcome planning one of  solved  failed timed out  criterion  statistically
analyzed data superior performance one versions  outcome results
planners summarized table    table shows  rarely new version
result problems solved  z improved number test problems
solved subsequent versions 
check whether differences outcome significant  ran  x    tests
planner version independent variable outcome dependent  table   summarizes
results   analysis  z  compared version successor only 
differences significant except transition z      this expected
two versions extremely similar  
another planner performance metric  evaluated  speed solution 
analysis  limited comparison problems solved
versions planner  classified problem whether later version solved
  

fia critical assessment benchmark comparison planning

planner version solved failed timeout solved 
w
 
   
   
   
w
 
   
    
   
 
x
 
   
   
 
x
 
   
   
   
 

 
   
   
   

 
   
   
   
 
z
 
   
    
   
z
 
   
   
   
 
z
 
   
   
   
 
z
 
   
   
   
 
table    version performance  counts outcome change number solved 
old
new
planner version version  
p
w
 
 
            
x
 
 
           

 
 
   
   
z
 
 
          
z
 
 
         
z
 
 
           
table      results comparing versions planner 
problem faster  slower  time preceding version  results
table    see planners improved average speed solution
subsequent versions  exception z  transition     versions   however 
z increase number problems solved versions 
planner old new faster slower total
w
 
 
   
  
  
   
x
 
 
   
   
 
   

 
 
   
  
  
   
z
 
 
  
   
  
   
z
 
 
   
  
  
   
z
 
 
   
  
  
   
table    improvements execution speed across versions  faster column counts
number cases new version solved problem faster  slower specifies
cases new version took longer solve given problem 
  

fihowe   dahlman

planner assumption    parameter settings matter fair comparison 

planner set  three obvious  easily manipulable parameters  blackbox  hsp
ucpop  blackbox extensive set parameters control everything
much trace information print sequence solver applications  hsp s function
varied include  or not  loop detection  change search heuristic vary
number paths expand  ucpop  user change strategies governing node
orderings aw selection 
run experiments assumption planners
parameters clear literature parameters matter 
blackbox relies heavily random restarts trying alternative sat solvers  kautz
selman         authors blackbox carefully study aspects blackbox s design
demonstrate differential performance using different sat solvers  propose hypotheses
performance differences working better models performance variation 
heart hsp heuristic search  thus  performance varies depending
heuristics  experiments hsp  a planner builds ideas
hsp  shown importance heuristic selection search space expansion 
computation time problem scale  haslum   geffner        hoffmann   nebel 
      
hsp  heuristic search critical ucpop s performance  set studies
explored alternative settings aw selection heuristics employed ucpop  joslin  
pollack        srinivasan   howe        genevini   schubert         producing dramatic
improvements domains heuristics  pollack et al         confirmed 
good default strategy could derived  performance best
circumstances 
thus  parameters control fundamental aspects algorithms 
search strategies  role parameters comparisons cannot easily dismissed 

planner assumption    time cut offs unfair  planners often admit

failure  instead  planner stops used allotted time found
solution  setting time threshold requirement planner execution 
comparison  one might always wonder whether enough time allotted fair  
perhaps solution almost found execution terminated 
determine whether cut off    minutes fair  examined distribution
times declared successes failures   across planners problem set 
found distributions skewed  approximately log normal long right tails 
planners quick declare success failure  going so 
table    shows max  mean  median standard deviation success failure times
planners  differences mean median indicate distribution
skew  low standard deviations relative observed max times  max time
shows rare occasions planners might make decision within   minutes
cut off 
   separated two usually observed significant difference distributions time
succeed time fail   half planners quick succeed slow fail  half
reversed relationship 

  

fia critical assessment benchmark comparison planning

planner

b
c

e
f
g
h

j
k
l


successes
max mean median
          
   
           
   
           
   
          
   
         
   
           
   
           
   
           
   
            
   
           
   
           
    
           
   
           
    

sd
    
     
     
    
     
     
     
    
     
     
     
     
     

failures
max mean median
           
   
           
    
   
   
    
          
   
            
     
           
   
           
    
           
   
    
   
   
         
    
           
    
           
    
   
   
   

sd
     
    
   
     
     
     
    
     
   
    
    
     
   

table     max  mean  median standard deviations  sd  computation times
success failure planner 

table show  observed distributions show 
values greater half time cut off  figures     display
distributions planner f  means middle set planners
quite typical distributions  consequently  least problems  cut off   
minutes      seconds  would significantly change results 

   

   

   

 
 

                                                  
success time

figure    histogram times  seconds  planner f succeed 
  

fihowe   dahlman

   

   

   

 
 

  

                                             
fail time

figure    histogram times  seconds  planner f fail 

    performance metrics

comparisons emphasize number problems solved cpu time completion metrics  often  problems organized increasing diculty show scale up 
comparing based metrics leaves lot open interpretation  example 
planners designed find optimal plan  measured number steps either
parallel sequential plan  consequently  planners may require computation 
thus  ignoring plan quality  planners may unfairly judged  hypothesize
hardware software platform tests vary results  planner
developed machine  gb memory  likely performance degrade
less  key issue whether effect less uniform across set planners 
section  examine two issues  execution platform effect plan
quality 

metric assumption    performance vary planners run
different hardware platforms  often planner run competition

someone else s lab  hardware software platforms differ platform used
development  clearly  slowing processor speed slow planning 
requiring higher cut offs  reduction memory may well change set problems
solved increase processing time due increased swapping  changing
hardware configuration may change way memory cached organized  favoring
planners  internal representations others  changing compilers could affect
amount type optimizations code  exact effects probably unknown 
assumption changes affect planners less equally 
test this  ran planners less powerful  lower memory machine compared
results two platforms  base sun ultrasparc           mb memory
ultrasparc          mb memory  operating system compilers
versions machines  problems run platforms 
followed much methodology comparison planner versions  comparing
number problems solved time solution  table    shows results
measured problems solved  failed timed out planner two platforms 
  

fia critical assessment benchmark comparison planning

planner platform solved failed timed out  
p   reduction

ultra  
  
   
  
ultra   
  
   
           
 
b
ultra  
   
   
  
ultra   
   
   
           
 
c
ultra  
   
 
   
ultra   
   
 
            
 

ultra  
   
  
   
ultra   
   
  
             
   
e
ultra  
   
   
  
ultra   
   
   
           
 
f
ultra  
   
   
  
ultra   
   
   
           
 
g
ultra  
   
   
  
ultra   
   
   
           
 
h
ultra  
   
   
  
ultra   
   
   
           
 

ultra  
   
   
  
ultra   
   
   
           
 
j
ultra  
   
   
 
ultra   
   
   
          
 
k
ultra  
   
   
  
ultra   
   
   
           
 
l
ultra  
   
   
  
ultra   
   
   
           
 

ultra  
   
  
   
ultra   
   
  
            
 
table     number problems solved  failed timed out planner two
hardware platforms  last column percentage reduction number
solved faster slower platforms 

  

fihowe   dahlman

planner

b
c

e
f
g
h

j
k
l


faster
  mean
  
    
   
    
   
     
   
     
   
    
   
     
   
    
   
    
   
     
   
     
   
     
   
     
   
     

slower
sd   mean
       
       
         
    
        
    
       
       
       
       
        
        
       
       
         
    

sd
    
    

    

total
 
 
 
 
 
 
 
 
 
 
 
 
 

  
   
   
   
   
   
   
   
   
   
   
   
   

table     improvements execution speed moving slower faster platform  counts
problems solved platforms  faster slower 
mean standard deviation  sd  difference provided 
before  looked change time solution  table    shows time
solution changes planner  surprisingly  faster processor memory
nearly always lead better performance  somewhat surprisingly  difference far less
doubling might expected  mean differences much less
mean times faster processor  see table    mean solution times  
also  effect seems vary planners  based counts  lisp based
planners appear less susceptible trend  the ones sometimes faster
slower platform   however  advantages small  affecting primarily
smaller problems  think effect due need load lisp image
startup centralized server  thus  computation time small problems
dominated network delay  older versions planners appear less sensitive
switch platform 
study  platforms make little difference results  despite
doubling processor speed doubling memory  however  two platforms
underpowered compared development platforms planners 
chose platforms differed characteristics  processor speed
memory amount  access    identically configured machines 
really observe difference   gb  memory may needed 
recent trends planning technology exploited cheap memory  translations
propositional representations  compilation problems built in caching memory
management techniques  thus  planners designed trade off memory time 
   propose figure amount requested participants aips     
planning competition 

  

fia critical assessment benchmark comparison planning

planners understandably affected memory limitations problems 
given results study  considered performing careful study memory
artificially limiting memory planners
access enough suciently large machines likely make difference could
devise scheme fairly across planners  which implemented
different languages require different software run time environments  
another important factor may memory architecture management  planners
include memory managers  map better hardware platforms
others  e g   hsp uses linear organization appears fit well intel s memory
architecture  

metric assumption    number plan steps vary  several researchers

examined issue measuring plan quality directing planning based it  e g  
 perez        estlin   mooney        rabideau  englehardt    chien         number
steps plan rather weak measure plan quality  far  one
widely used primitive action planning 
expect planners sacrifice quality  as measured plan length  speed 
thus  ignoring even measure plan quality may unfair planners 
check whether appears factor problem set  counted plan length
plans returned output compared lengths across planners 
planners construct parallel plans  adopted general definition 
sequential plan length  compared plan lengths returned planner
every successfully solved problem 
found     problems solved one planner  not necessarily
one   planners found equal length solutions     remained     
problems   calculated standard deviation  sd  plan length solutions
problem analyzed sds  found minimum observed sd      
maximum        mean      standard deviation       thirteen
cases showed sds higher     obviously  cases involved fairly long plans  up
    steps   cases problems logistics gripper domains 
check whether planners favored minimal lengths  counted number
cases planner found shortest length plan  ties attributed
planners  variance plan length  table    lists results 
planners find shortest length plans one third problems  planner f
designed optimize plan length  shows results  one exception 
older planners rarely find shortest plans 

   interpretation results recommendations
previous section presented summarization analysis planner runs 
section  ect results mean empirical comparison planners 
summarize results recommend partial solutions  possible guarantee
fairness propose magic formula performing evaluations  state
practice general certainly improved  propose three general recommendations
   recommendations targeted specific assumptions 
  

fihowe   dahlman

planner count

   
b
   
c
 

   
e
 
f
   
g
   
h
   

   
j
 
k
   
l
   

   
table     number plans planner found shortest plan  data
include problems different length plans found 
many targeted recommendations amount requesting problem planner developers precise requirements expectations contributions 
planners extremely complex time consuming build  documentation may inadequate determine subsequent version differs previous
conditions  e g   parameter settings  problem types  planner fairly
compared  current positive trend making planners available  behooves
developer include information distribution system 
sweeping recommendation shift research focus away developing
best general purpose planner  even competitions  planners identified
superior ones designed specific classes problems  e g   ipp 
competitions done great job exciting interest encouraging development
public availability planners incorporate representation 
however  advance research  informative comparative evaluations
designed specific purpose   test hypothesis prediction
performance planner    experimental hypothesis focuses analysis often
leads naturally justified design decisions experiment itself  example  hoffmann nebel  authors fast forward  ff  system  state introduction
jair paper ff s development motivated specific set benchmark
domains  system heuristic  designed heuristics fit expectations needs domains  hoffmann   nebel         additionally  part
evaluation  compare specific system system commonalities
point various advantages disadvantages design decisions specific
    paul cohen advocated experimental methodology artificial intelligence based
hypotheses  predictions models considerable detail  see cohen              

  

fia critical assessment benchmark comparison planning

problems  follow up work researchers comparing systems
well defined starting point comparison 

recommendation    experiments driven hypotheses  re 

searchers precisely articulate advance experiments expectations new planner augmentations existing planner add
state art  expectations turn justify selection
problems  planners metrics form core comparative
evaluation 
general issue whether results accurate  reported results
output planners  planner stated output successful 
took face value  however  examining output  determined
claims successful solution erroneous   proposed solution would work 
way ensure output correct solution checker  drew mcdermott
used solution checker aips   competition  however  planners
provide output compatible format checker  thus  another concern
comparative evaluation output needs cross checked 
declaring winner  i e   planner exhibited superior performance   think
lack solution checker casts serious doubt results  part 
concerned factors cause observed success rates change 

recommendation    input standardized pddl  output
standardized  least format returned plans 

another general issue whether benchmark sets representative space
interesting planning problems  test directly  in fact  sure
one could so   clustering results observations others planning
community suggest set biased toward logistics problems  additionally  many
problems getting dated longer distinguish performance  researchers
begun formally analyze problem set  either service building improved
planners  e g   hoffmann   nebel        better understand planning problems 
example  related area scheduling  group identified distinctive patterns
topology search spaces different types classical scheduling problems
related topology performance algorithms  watson  beck  barbulescu  whitley   
howe         within planning  hoffmann examined topology local search spaces
small problems benchmark collection found simple structure
respect well known relaxations  hoffmann         additionally  worked
partial taxonomy  based three characteristics  analyzed domains  helmert
analyzed computational complexity subclass benchmarks  transportation
problems  identified key features affect diculty problems  helmert 
      

recommendation    benchmark problem sets eval 

uated over hauled  problems easily solved removed 
researchers study benchmark problems domains classify
  

fihowe   dahlman

problem types key characteristics  developers contribute application problems realistic versions evolving set 
remainder section describes recommendations improving state
art planner comparisons 

problem assumption    general purpose planners biased toward particular problems domains  set problems planner developed
strong effect performance planner  either effect
unintentional over specialization result concerted effort part
developers optimize system solve specific problem  one exception  every
planner fared better tailored subset problems  training set   consequently 
must conclude choice subset problems may well affect outcome
comparison 
fair planner comparison must account likely biases problem set  good
performance certain class problems imply good performance general 
large performance differential planners targeted problem domain  i e   well
focus problems poorly others  may well indicate developers
succeeded optimizing performance planner 
recommendation    problem sets constructed highlight
designers  expectations superior performance planner 
specific selection criteria 
hand  goal demonstrate across board performance 
results randomly selecting domains suggests biases mitigated 
recommendation    highlighting performance  general  problems
goal  problem set selected randomly benchmark
domains 

problem assumption    syntactic representation differences affect
performance  many studies  including this  shown planners may sensitive

representational features  representations translated automatically
mean performance unaffected  algorithm
theoretically insensitive factor mean practice is 
planners showed sensitivity permuted problems  degree sensitivity varied 
outcome suggests translators even minor variations problem descriptions
impact outcome used care  especially sensitivity
focus study planner vulnerable effect 
recommendation    representation translators avoided using
native versions problems testing multiple versions problems necessary 
many planner developers participating aips competitions  become
less issue 
importantly  researchers explicitly testing effect alternative phrasings planning problems determine sensitivity performance separate
effects advice tuning essence problem 
  

fia critical assessment benchmark comparison planning

recommendation    studies consider role minor syntactic vari 

ations performance include permuted problems  i e   initial conditions 
goals  preconditions actions  problem sets demonstrate robustness  provide opportunity learning protect developers
accidentally over fitting algorithm set test problems 

problem assumption    performance depend pddl requirements
features  planners perform quite advertised expected given

problem features  discrepancy could many possible causes  problems incorrectly
specified  planners less sensitivity thought  solutions correct  etc 
example  many problems benchmark set designed competitions
even intended widely used may specified carefully enough 

recommendation    problems contributed benchmark set 
developers verify requirements stated description
problem correctly ect subset features needed  planner evaluators
use problems match planner s capabilities 

depending cause  results skewed  e g   planner may unfairly
maligned unable solve problem specifically designed solve 
recommendation addresses gaps specification problem set 
mismatches capabilities specifiable pddl planners possess
remain 

recommendation    planner developers develop vocabulary
planner s capabilities  pddl ags  specify expected
capabilities planner s distribution 

planner assumption    latest version best  results suggest

new versions run faster  often solve problems  thus  newest version may
represent  best   depending definition  performance class planner 
competitions fields  e g   automatic theorem proving community  require
previous year s best performer compete well  advantage establishing
baseline performance well allowing comparison focus may shift
time 

recommendation     primary evaluation metric speed  newer

version may best competition  number problems solved one
wishes establish progress made  may worth running
older version well  recommendation   followed 
evaluators select version based guidance 

planner assumption    effect parameter settings  perfor 

mance planners vary parameter settings  unfortunately  often
dicult figure set parameters properly  changing settings makes
dicult compare results across experiments  generally  issue
  

fihowe   dahlman

developers users tend rely default parameter settings  unfortunately 
sometimes developers exploit alternative settings experiments  complicating
later comparison 

recommendation     planner includes parameters  developer
guide users settings  not  default settings
used developers others experiments facilitate comparison 

planner assumption    time cut offs unfair  found little benefit
increasing time cut offs beyond    minutes problems 

recommendation     total computation time bottleneck  run

problems separate batches  incrementally increasing time cut off
runs including unresolved problems subsequent runs 
additional problems solved run  stop 

metric assumption    alternative platforms lead different performance  experiments  performance vary much expected 
result suggests researchers general developing specific hardware software
configurations  recent trends suggest otherwise  least regards memory  again 
systems research prototypes  behooves developer clear
his her expectations anyone subsequently using system accommodate requests studies 

recommendation     factors planner design  researchers

must clearly state hardware software requirements planners 
design based platform assumptions  additionally  careful study memory versus time trade offs undertaken  given recent trends memory exploitation 

metric assumption    number plan steps vary  certainly can 

one neglects quality measures  planners penalized efforts declare
best planner 

recommendation     expedite generalizing across studies  reports
describe performance terms solved  how many types  
much time required quality solutions  tradeoffs reported  possible  e g       increase computation time
    decrease plan length  additionally  design goal find
optimal solution  compare planners design goal 

good metrics plan quality sorely needed  latest specification pddl
specification supports definition problem specific metrics  fox   long        
metrics indicate whether total time  a new concept supported specification action
durations  specified functions minimized maximized  addition
excellent start  general metrics plan length total time
needed expedite comparisons across problems 
  

fia critical assessment benchmark comparison planning

recommendation     developing good metrics valuable research contri 

bution  researchers consider worthwhile project  conference organizers reviewers encourage papers topic  planner developers
implement planners responsive new quality metrics  i e  
support tunable heuristics evaluation criteria  

   conclusions

fair evaluation comparison planners hard  many apparently benign factors exert
significant effects performance  superior performance one planner another
problem neither intentionally designed solve may explained minor
representational features  however  comparative analysis general problems practical
importance practical create specialized solution every problem 
analyzed effects experiment design decisions empirical comparison
planners made recommendations ameliorating effects decisions 
recommendations common sense suggestions improving current
methodology 
expand beyond current methodology require least two substantive changes 
first  field needs question whether trying show performance
planning problems general  shift general comparisons focused comparisons  on
problem class mechanism hypothesis testing  could produce significant advances
understanding planning 
second  benchmark problem sets require attention  many problems
discarded simple show much  domains far removed
real applications  may time revisit testbeds  example  several researchers
robotics constructed interactive testbed comparing motion planning algorithms
 piccinocchi  ceccarelli  piloni    bicchi         testbed consists user interface
defining new problems  collection well known algorithms simulator testing
algorithms specific problems  thus  user design his her problems compare performance various algorithms  including own  via web site 
testbed affords several advantages current paradigm static benchmark problems
developer conducted comparisons  particular  replicability extendability
test set  alternatively  challenging problem sets developed modifying deployed
applications  wilkins   desjardins        engelhardt  chien  barrett  willis    wilklow 
      
recent years  planning community significantly improved size planning
problems solved reasonable time advanced state art
empirical comparison systems  interpret results empirical comparisons
understand motivate development planning  community
needs understand effects empirical methodology itself  purpose
paper understanding initiate dialogue methodology
used 

  

fihowe   dahlman

acknowledgments
research partially supported career award national science
foundation iri         grant air force oce scientific research f                u s  government authorized reproduce distribute reprints
governmental purposes notwithstanding copyright notation thereon 
grateful reviewers careful reading well considered comments
submitted version  hope done justice suggestions 

references

bacchus 
f 
       
aips     
planning
competition 
http   www cs toronto edu aips     selfcontainedaips      ppt 
barrett  a   golden  k   penberthy  s     weld  d          ucpop user s manual  dept 
computer science engineering  university washington  seattle  wa  tr
         
blum  a  l     furst  m  l          fast planning planning graph analysis  artificial
intelligence journal                    
bonet  b     geffner  h          planning heuristic search  new results  proceedings
fifth european conference planning  ecp     durham  uk 
chien  s   kambhampati  s     knoblock  c  a   eds          proceedings fifth
international conference artificial intelligence planning scheduling  aips
       aaai press  breckenridge  co 
cohen  p  r          survey eighth national conference artificial intelligence 
pulling together pulling apart  ai magazine                
cohen  p  r          empirical methods artificial intelligence  mit press 
drummond  m  e   kaelbling  l  p     rosenschein  s  j          collected notes
benchmarks metrics workshop  artificial intelligence branch fia        nasa
ames research center 
engelhardt  b   chien  s   barrett  t   willis  j     wilklow  c          data chaser
citizen explorer benchmark problem sets  proceedings sixth european
conference planning  ecp     toledo  spain 
estlin  t  a     mooney  r  j          learning improve ecicency quality
planning  proceedings fifteenth international joint conference artificial
intelligence  pp             nagoya  japan 
fox  m     long  d          ecient implementation plan graph stan 
journal artificial intelligence research             
fox  m     long  d          pddl     extension pddl expressing temporal
planning domains  available http   www dur ac uk d p long pddl  ps gz 
  

fia critical assessment benchmark comparison planning

genevini  a     schubert  l          accelerating partial order planners  techniques
effective search control pruning  journal artificial intelligence research    
       
hanks  s   nguyen  d     thomas  c          beginner s guide truckworld simulator  dept  computer science engineering uw cse tr           university
washington 
hanks  s   pollack  m  e     cohen  p  r          benchmarks  test beds  controlled
experimentation design agent architectures  ai magazine        
haslum  p     geffner  h          admissible heuristics optimal planning  proceedings fifth international conference artificial intelligence planning
scheduling  aips        pp           breckenridge  co  aaai press 
helmert  m          complexity planning transportation domains   th
european conference planning  ecp      lecture notes artificial intelligence 
new york  springer verlag 
hoffmann  j          local search topology planning benchmarks  empirical analysis 
proceedings   th international joint conference artificial intelligence
seattle  wa  usa 
hoffmann  j     nebel  b          planning system  fast plan generation
heuristic search  journal artificial intelligence research              
howe  a  e   dahlman  e   hansen  c   scheetz  m     von mayrhauser  a          exploiting competitive planner performance  proceedings fifth european conference
planning  durham  uk 
howe  a  e   von mayrhauser  a     mraz  r  t          test case generation ai
planning problem  automated software engineering                
joslin  d     pollack  m          least cost aw repair  plan refinement strategy
partial order planning  proceedings twelfth national conference artificial
intelligence  pp             seattle  wa 
kautz  h     selman  b          blackbox  new approach application
theorem proving problem solving  working notes aips   workshop
planning combinatorial search  pittsburgh  pa 
kautz 
h 
blackbox 
sat technology planning system 
http   www cs washington edu homes kautz blackbox index html 
kautz  h     selman  b          unifying sat based graph based planning  proceedings sixteenth international joint conference artificial intelligence  stockholm  sweden 
koehler  j          handling conditional effects negative goals ipp  tech  rep 
     institute computer science  albert ludwigs university  freiburg  germany 
  

fihowe   dahlman

koehler  j   nebel  b   hoffmann  j     dimopoulos  y          extending planning graphs
adl subset  proceedings fourth european conference planning 
mcdermott  d   ghallab  m   howe  a   knoblock  c   ram  a   veloso  m   weld  d    
wilkins  d          planning domain definition language 
mcdermott  d               ai planning systems competition  ai magazine         
      
penberthy  j  s     weld  d  s          ucpop  sound  complete  partial order planner
adl  proceedings third international conference knowledge representation reasoning  pp          
perez  m  a          learning search control knowledge improve plan quality  ph d 
thesis  carnegie mellon university 
piccinocchi  s   ceccarelli  m   piloni  f     bicchi  a          interactive benchmark
planning algorithms web  proceedings ieee international conference
robotics automation 
pollack  m  e     ringuette  m          introducing tileworld  experimentally evaluating agent architectures  proceedings eight national conference artificial
intelligence  pp           boston  ma 
pollack  m   joslin  d     paolucci  m          flaw selection strategies partial order
planning  journal artificial intelligence research             
rabideau  g   englehardt  b     chien  s          using generic prferences incrementally
improve plan quality  proceedings fifth international conference artificial
intelligence planning scheduling  aips        breckenridge  co 
slaney  j     thiebaux  s          blocks world revisited  artificial intelligence journal 
                   
srinivasan  r     howe  a  e          comparison methods improving search eciency
partial order planner  proceedings   th international joint conference
artificial intelligence  pp             montreal  canada 
sussman  g  a          computational model skill acquisition  tech  rep  memo no 
ai tr      mit ai lab 
prodigy research group         prodigy      manual tutorial  school
computer science         carnegie mellon university 
watson  j   barbulescu  l   howe  a     whitley  l  d          algorithm performance
problem structure ow shop scheduling  proceedings sixteenth national
conference artificial intelligence  aaai      orlando  fl 
watson  j   beck  j   barbulescu  l   whitley  l  d     howe  a          toward descriptive model local search cost job shop scheduling  proceedings sixth
european conference planning  ecp      toledo  spain 
  

fia critical assessment benchmark comparison planning

weld  d   anderson  c     smith  d          extending graphplan handle uncertainty
sensing actions  proceedings fifteenth national conference artificial
intelligence madison  wi 
weld  d  s          recent advances ai planning  ai magazine                 
wilkins  d  e     desjardins  m          call knowledge based planning  ai magazine 
               

  


