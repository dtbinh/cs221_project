journal artificial intelligence research                  

submitted       published     

towards adjustable autonomy real world
scerri isi edu
pynadath isi edu
tambe usc edu

paul scerri
david v  pynadath
milind tambe
information sciences institute computer science department
university southern california
     admiralty way  marina del rey  ca       usa

abstract

adjustable autonomy refers entities dynamically varying autonomy  transferring decision making control entities  typically agents transferring control
human users  key situations  determining whether transfers of control
occur arguably fundamental research problem adjustable autonomy  previous work investigated various approaches addressing problem often
focused individual agent human interactions  unfortunately  domains requiring collaboration teams agents humans reveal two key shortcomings previous
approaches  first  approaches use rigid one shot transfers control result
unacceptable coordination failures multiagent settings  second  ignore costs  e g  
terms time delays effects actions  agent s team due transfers ofcontrol 
remedy problems  article presents novel approach adjustable autonomy  based notion transfer of control strategy  transfer of control strategy
consists conditional sequence two types actions   i  actions transfer decisionmaking control  e g   agent user vice versa   ii  actions change
agent s pre specified coordination constraints team members  aimed minimizing
miscoordination costs  goal high quality individual decisions made
minimal disruption coordination team  present mathematical model
transfer of control strategies  model guides informs operationalization
strategies using markov decision processes  select optimal strategy  given
uncertain environment costs individuals teams  approach
carefully evaluated  including via use real world  deployed multi agent system
assists research group daily activities 
  

introduction

exciting  emerging application areas ranging intelligent homes  lesser et al         
routine organizational coordination  pynadath et al          electronic commerce  collins
et al       a   long term space missions  dorais et al         utilize decision making
skills agents humans  new applications brought forth increasing
interest agents  adjustable autonomy  aa   i e   entities dynamically adjusting
level autonomy based situation  mulsiner   pell         many exciting
applications deployed unless reliable aa reasoning central component 
aa  entity need make decisions autonomously  rather choose reduce
autonomy transfer decision making control users agents 
c      ai access foundation morgan kaufmann publishers  rights reserved 

fiscerri  pynadath   tambe
expected net benefit  dorais et al         barber  goel    martin      a 
hexmoor   kortenkamp        
central problem aa determine whether transfers decision making
control occur  key challenge balance two potentially con icting goals 
one hand  ensure highest quality decisions made  agent transfer control human user  or another agent  whenever user superior decision making
expertise   hand  interrupting user high costs user may
unable make communicate decision  thus transfers of control minimized  previous work examined several different techniques attempt balance
two con icting goals thus address transfer of control problem  example 
one technique suggests decision making control transferred expected
utility higher expected utility making autonomous decision
 horvitz  jacobs    hovel         second technique uses uncertainty sole rationale
deciding control  forcing agent relinquish control user
whenever uncertainty high  gunderson   martin         yet techniques transfer
control user erroneous autonomous decision could cause significant harm  dorais
et al         agent lacks capability make decision  ferguson  allen   
miller        
unfortunately  previous approaches transfer of control reasoning indeed
previous work aa  focused domains involving single agent single
user  isolated interactions entities  applied interacting teams
agents humans  interaction agent human impacts interaction entities  techniques lead dramatic failures  particular 
presence entities team members introduces third goal maintaining coordination  in addition two goals already mentioned above   previous
techniques fail address  failures occur two reasons  firstly  previous techniques
ignore team related factors  costs team due incorrect decisions due
delays decisions transfers of control  secondly  and importantly  
techniques use one shot transfers of control  rigidly committing one two choices   i 
transfer control wait input  choice h    ii  act autonomously  choice a   however 
given interacting teams agents humans  either choice lead costly failures
entity control fails make report decision way maintains coordination 
instance  human user might unable provide required input due temporary communication failure  may cause agent fail part joint action 
joint action may dependent user s input  hand  forcing
less capable entity make decision simply avoid miscoordination lead poor
decisions significant consequences  indeed  seen section      applied
rigid transfer of control decision making domain involving teams agents users 
failed dramatically 
yet  many emerging applications involve multiple agents multiple humans acting
cooperatively towards joint goals  address shortcomings previous aa work
domains  article introduces notion transfer of control strategy  transfer ofcontrol strategy consists pre defined  conditional sequence two types actions   i 
   aa problem general involves transferring control one entity another  paper 
typically focus interactions involving autonomous agents human users 

   

fitowards adjustable autonomy real world
actions transfer decision making control  e g   agent user vice versa  
 ii  actions change agent s pre specified coordination constraints team members 
rearranging activities needed  e g   reordering tasks buy time make decision  
agent executes strategy performing actions order  transferring control
specified entity changing coordination required  point time
entity currently control exercises control makes decision  thus  previous
choices h two many different possibly complex transfer ofcontrol strategies  instance  adah strategy implies agent initially attempts
make autonomous decision  agent makes decision autonomously strategy
execution ends there  however  chance unable make decision
timely manner  perhaps computational resources busy higher
priority tasks  avoid miscoordination agent executes action changes
coordination constraints activity  example  action could inform
agents coordinated action delayed  thus incurring cost inconvenience
others buying time make decision  still cannot make decision 
eventually take action h   transferring decision making control user waiting
response  general  strategies involve available entities contain many
actions change coordination constraints  strategies may useful singleagent single human settings  particularly critical general multiagent settings 
discussed below 
transfer of control strategies provide exible approach aa complex systems
many actors  enabling multiple transfers of control two  or more  entities 
rather rigidly committing one entity  i e   h    strategy attempts provide
highest quality decision  avoiding coordination failures  particular  multiagent
setting often uncertainty whether entity make decision
so  e g   user may fail respond  agent may able make decision
expected communication channel may fail  strategy addresses uncertainty
planning multiple transfers control cover contingencies  instance 
adh strategy  agent ultimately transfers control human attempt ensure
response provided case agent unable act  furthermore  explicit
coordination change actions  i e   actions  reduce miscoordination effects  cost 
better decisions made  finally  since utility transferring control changing
coordination dependent actions taken afterwards  agent must plan strategy
advance find sequence actions maximizes team benefits  example 
reacting current situation repeatedly taking giving control strategy
adhadh       may costly planning ahead  making bigger coordination
change  using shorter adh strategy  developed decision theoretic model
strategies  allows expected utility strategy calculated and  hence 
strategies compared 
thus  key aa problem select right strategy  i e   one provides
benefit high quality decisions without risking significant costs interrupting user
miscoordination team  furthermore  agent must select right strategy despite
significant uncertainty  markov decision processes  mdps   puterman        natural
choice implementing reasoning explicitly represent costs  benefits
uncertainty well lookahead examine potential consequences sequences
   

fiscerri  pynadath   tambe
actions  section    general reward function presented mdp results
agent carefully balancing risks incorrect autonomous decisions  potential miscoordination
costs due changing coordination team members  detailed experiments
performed mdp  key results follows  relative importance
central factors  cost miscoordination  varied resulting mdp policies
varied desirable way  i e   agent made decisions autonomously cost
transferring control entities increased  experiments reveal phenomenon
reported literature  agent may act autonomously coordination
change costs either low high   middle  range  agent tends act
less autonomously 
research conducted context real world multi agent system 
called electric elves  e elves   chalupsky  gil  knoblock  lerman  oh  pynadath  russ 
  tambe        pynadath et al          used six months
university southern california  information sciences institute  e elves assists
group researchers project assistant daily activities  providing exciting
opportunity test aa ideas real environment  individual user proxy agents called
friday  from robinson crusoe s servant friday  act team assist rescheduling
meetings  ordering meals  finding presenters day to day activities  course
several months  mdp based aa reasoning used around clock e elves 
making many thousands autonomy decisions  despite unpredictability user s
behavior agent s limited sensing abilities  mdp consistently made sensible
aa decisions  moreover  many times agent performed several transfers of control
cope contingencies user responding  one lesson learned actually
deploying system sometimes users wished uence aa reasoning  e g  
ensure control transferred particular circumstances  allow users
uence aa reasoning  safety constraints introduced allow users prevent
agents taking particular actions ensuring take particular actions 
safety constraints provide guarantees behavior aa reasoning  making
basic approach generally applicable and  particular  making applicable
domains mistakes serious consequences 
rest article organized follows  section   gives detailed description
aa problem presents electric elves motivating example application  section
  presents formal model transfer of control strategies aa   readers interested
mathematical details may wish skip section     operationalization
strategies via mdps described section    section    results detailed
experiments presented  section   looks related work  including earlier aa work
analyzed within strategies framework  section   gives summary article 
finally  section   outlines areas work could extended make applicable
applications 
  

adjustable autonomy   problem

general aa problem previously formally defined literature  particularly multiagent context  following  formal definition problem given
clearly define task aa reasoning  team  may consist entirely
   

fitowards adjustable autonomy real world
agents include humans  joint activity  ff  entity team works
cooperatively joint activity  agent  a  role    team  depending
specific task  roles need performed successfully order
joint activity succeed  primary goal agent success
pursues performing   performing requires one non trivial decisions
made  make decision  d  agent draw upon n entities set
e   fe        en g  typically includes agent itself  entity e  e g   human
user  capable making decision d  entities e necessarily part
team performing ff  different agents users differing abilities make decisions
due available computational resources  access relevant information  etc  coordination
constraints    exist roles members team  example 
various roles might need executed simultaneously certain order
combined quality total cost  critical facet successful completion joint task
ff  given jointness  ensure coordination team members maintained 
i e   violated  thus  describe aa problem instance tuple 
ha  ff      d  e i 
aa perspective  agent take two types actions decision  d 
first  transfer control entity e capable making decision  general 
restrictions when  often long decision making control
transferred particular entity  typically  agent transfer decision making
control itself  general  assume agent transfers control 
guarantee exact time response exact quality decision made
entity control transferred  fact  cases know whether
entity able make decision even whether entity know
decision making control  e g   control transferred via email  agent may know
user actually read email 
second type action agent take request changes coordination constraints    team members  coordination change gives agent
possibility changing requirements surrounding decision made  e g  
required timing  cost quality decision  may allow better fulfill responsibilities  coordination change might involve reordering delaying tasks may
involve changing roles  may dramatic change team pursues
completely different way  changing coordination cost  may better
incur cost violate coordination constraints  i e   incur miscoordination costs 
miscoordination team members occur many reasons  e g   constraint
limits total cost joint task might violated one team member incurs higher
expected cost team members reduce costs  article 
primarily concerned constraints related timing roles  e g   ordering constraints requirements simultaneous execution  turn  usually requires
agent guards delayed decisions although require decision
made soon 
thus  aa problem agent  given problem instance  ha  ff      d  e i 
choose transfer of control coordination change actions maximizes overall
expected utility team  remainder section describe concrete  real   

fiscerri  pynadath   tambe
world domain aa  section      initial failed approach motivates solution
 section      

    electric elves
research initiated response issues arose real application
resulting approach extensively tested day to day running application 
electric elves  e elves  project usc isi deploy agent organization
support daily activities human organization  pynadath et al         chalupsky
et al          believe application fairly typical future generation applications involving teams agents humans  operation human organization
requires performance many everyday tasks ensure coherence organizational
activities  e g   monitoring status activities  gathering information keeping everyone informed changes activities  teams software agents aid organizations
accomplishing tasks  facilitating coherent functioning rapid  exible response
crises  number underlying ai technologies support e elves  e g   technologies
devoted agent human interactions  agent coordination  accessing multiple heterogeneous
information sources  dynamic assignment organizational tasks  deriving information
organization members  chalupsky et al          technologies useful 
aa fundamental effective integration e elves day to day running
real organization and  hence  focus paper 
basic design e elves shown figure   a   agent proxy called
friday  after robinson crusoes  man servant friday  acts behalf user
agent team  design friday proxies discussed detail  tambe  pynadath 
chauvat  das    kaminka         where referred teamcore proxies  
currently  friday perform several tasks user  user delayed meeting 
friday reschedule meeting  informing fridays  turn inform users 
research presentation slot open  friday may respond invitation present
behalf user  friday order user s meals  see figure   a   track
user s location  posting web page  friday communicates users using wireless
devices  personal digital assistants  palm viis  wap enabled mobile phones 
via user workstations  figure   b  shows palm vii connected global positioning
service  gps  device  tracking users  locations enabling wireless communication
friday user  friday s team behavior based teamwork model 
called steam  tambe         steam encodes enforces constraints roles
required success joint activity  e g   meeting attendees arrive
meeting simultaneously  role within team needs filled  steam requires
team member assigned responsibility role  find best suited person 
team auctions role  allowing consider combination factors assign
best suited user  friday bid behalf user  indicating whether user
capable and or willing fill particular role  figure   b  shows tool allows users
view auctions progress intervene desire  auction progress  jay
modi s friday bid jay capable giving presentation  unwilling
so  paul scerri s agent highest bid eventually allocated role 

   

fitowards adjustable autonomy real world

friday

friday

friday

friday

 a 

 b 

figure     a  overall e elves architecture  showing friday agents interacting users 
 b palm vii communicating users gps device detecting
location 

   

fiscerri  pynadath   tambe
aa critical success e elves since  despite range sensing devices 
friday considerable uncertainty user s intentions even location  hence 
friday always appropriate information make correct decisions 
hand  user required information  friday cannot continually ask
user input  since interruptions disruptive time consuming  four
decisions e elves aa reasoning applied   i  whether user attend
meeting time   ii  whether close auction role   iii  whether user willing
perform open team role   iv  order lunch  paper 
focus aa reasoning two decisions  whether user attend meeting
time whether close auction role  decision whether user
attend meeting time often used dicult decisions friday
faces  brie describe decision close auction later show insight
provided model strategies led significant reduction amount code
required implement aa reasoning decision  decision volunteer user
meeting similar earlier decisions  omitted brevity  decision order
lunch currently implemented simpler fashion  at least yet  illustrative
full set complexities 
central decision friday  describe terms problem formulation 
ha  ff      d  e i  whether user attend meeting currently scheduled meeting time  case  friday agent  a  joint activity  ff  meeting
attendees attend meeting simultaneously  friday acts proxy user  hence
role    ensure user arrives currently scheduled meeting time 
coordination constraint    friday s role roles fridays
occur simultaneously  i e   users must attend currently scheduled time 
attendee arrives late  all  time attendees wasted 
hand  delaying meeting disruptive users  schedules  decision  d  whether
user attend meeting could made either friday user  i e  
e   fuser  fridayg  clearly  user often better placed make decision 
however  friday transfers control user decision  must guard miscoordination  i e   attendees wait  waiting user response 
decisions potentially costly  e g   incorrectly telling attendees user
attend  friday avoid taking autonomously  buy time
user make decision gather information  friday could change
coordination constraints action  friday several different actions disposal  including delaying meeting different lengths time  well able
cancel meeting entirely  user request action  e g   via dialog box
figure   a   buy time make meeting  user decides required 
friday conduit fridays  and hence users  informed 
friday must select sequence actions  either transferring control user  delaying
cancelling meeting autonomously announcing user attend 
maximize utility team 
second aa decision look decision close auction open
role assign user role   case  joint activity  ff  group research
   roles submitting bids auction aa decisions simpler  hence
focus here 

   

fitowards adjustable autonomy real world

 a 

 b 

figure     a  friday transferring control user decision whether order lunch 
 b  e elves auction monitoring tool 
meeting role    auctioneer  users always submit bids
role immediately  fact  bids may spread several days  users might
bid all  specific decision  d  focus whether close auction
assign role continue waiting incoming bids  individual team members
provide bids  auctioneer agent human team leader decides presenter based
input  e   fuser  auctioneer agentg   team expects willing presenter
high quality research presentation  means presenter need time
prepare  thus  coordination constraint  capable  willing user must
allocated role enough time prepare presentation  despite individually
responsible actions  agent team may reach highly undesirable decision  e g   assigning
user week week  hence advantage getting human team leader s
input  agent faces uncertainty  e g   better bids come in    costs  i e   later
assignment  less time presenter prepare   needs consider
possibility human team leader special preference
presentation particular meeting  transferring control  agent allows
human team leader make assignment  decision  coordination change action 
d  would reschedule research meeting  however  relative cost cancelling
meeting  cost rescheduling high rescheduling useful action 

    decision tree approach
one logical avenue attack aa problem e elves apply approach
used previously reported  successful meeting scheduling system  particular cap
 mitchell  caruana  freitag  mcdermott    zabowski         cap  friday learned
user preferences using c    decision tree learning  quinlan         friday recorded values
dozen carefully selected attributes user s preferred action  identified asking
   

fiscerri  pynadath   tambe
user  whenever make decision  friday used data learn decision
tree encoded autonomous decision making  aa  friday asked user
wanted decisions taken autonomously future  responses  friday
used c    learn second decision tree encoded rules transferring control 
thus  second decision tree indicated friday act autonomously  would
take action suggested first decision tree  initial tests c    approach
promising  tambe et al          key problem soon became apparent 
friday encountered decision learned transfer control user 
would wait indefinitely user make decision  even though inaction caused
miscoordination teammates  particular  team members would arrive
meeting location  waiting response user s friday  would end
completely wasting time response arrived  address problem  user
respond within fixed time limit  five minutes   friday took autonomous action 
although performance improved  resulting system deployed      led
dramatic failures  including 
   example    tambe s  a user  friday incorrectly cancelled meeting division
director friday over generalized training examples 
   example    pynadath s  another user  friday incorrectly cancelled group s weekly
research meeting time out forced choice  incorrect  autonomous
action 
   example    friday delayed meeting almost    times  time   minutes 
correctly applying learned rule ignoring nuisance rest
meeting participants 
   example    tambe s friday automatically volunteered presentation 
actually unwilling  friday over generalized examples
timeout occurred took undesirable autonomous action 
clearly  team context  rigidly transferring control one agent  user  failed  furthermore  using time out rigidly transferred control back agent 
capable making high quality decision  failed  particular  agent needed
better avoid taking risky decisions explicitly considering costs  example    
take lower cost actions delay meetings buy user time respond  example  
    furthermore  example   showed  agent needed plan ahead  avoid taking
costly sequences actions could replaced single less costly action  example
    theory  using c    friday might eventually able learn rules would
successfully balance costs deal uncertainty handle special cases
on  large amount training data would required 
  

strategies adjustable autonomy

avoid rigid one shot transfers control allow team costs considered 
introduce notion transfer of control strategy  defined follows 
   

fitowards adjustable autonomy real world
definition     transfer of control strategy pre defined  conditional sequence two

types actions   i  actions transfer decision making control  e g   agent
user agents  vice versa   ii  actions change agent s pre specified
coordination constraints team members  aimed minimizing miscoordination costs 

agent executes transfer of control strategy performing specified actions
sequence  transferring control specified entity changing coordination required 
point time entity currently control exercises control
makes decision  considering multi step strategies allows agent exploit decisionmaking sources considered risky exploit without possibility retaking control 
example  control could transferred capable always available decision
maker taken back decision made serious miscoordination occurred 
complex strategies  potentially involving several coordination changes  give agent
option try several decision making sources exible getting input
high quality decision makers  result  transfer of control strategies specifically allow
agent avoid costly errors  enumerated previous section  
given aa problem instance  ha  ff      d  e   agent transfer decision making
control decision entity ei   e   denote transfer of control
action symbol representing entity  i e   transferring control ei denoted
ei   agent transfers decision making control  may stipulate limit time
wait response entity  capture additional stipulation 
denote transfer of control actions time limit  e g   ei  t  represents ei
decision making control maximum time t  action two possible outcomes 
either ei responds time makes decision  respond decision
remains unmade time t  addition  agent mechanism
change coordination constraints  denoted d  change expected timing
decision  action changes coordination constraints    team members 
action associated value  dvalue   specifies magnitude  i e   much
alleviated temporal pressure   cost  dcost   specifies price paid
making change  concatenate actions specify complete transferof control strategy  instance  strategy h    a would specify agent first
relinquishes control asks entity h  denoting h uman user   user responds
decision within five minutes  need go further  not 
agent proceeds next transfer of control action sequence  example 
next action  a  specifies agent make decision complete task 
transfers control occur case  define space possible
strategies following regular expression 

   e r   e r    d 

   

 e r  possible combinations entity maximum time 
readability  frequently omit time specifications transfer ofcontrol actions instead write order agent transfers control among
   domains  may make sense attempt get input one entity once  hence
requiring strategies actions might executed parallel  however  work  first
step  consider strategies  furthermore  relevant domains hand 

   

fiscerri  pynadath   tambe
entities executes ds  e g   often write ha instead h    a   time
specifications omitted  assume transfers happen optimal times   i e  
times lead highest expected utility  consider strategies
sequence actions different timings strategy  agent o je jk  
possible strategies select from  k maximum length strategy je j
number entities  thus  agent wide range options  even practical
considerations lead reasonable upper bound k je j  agent must select
strategy maximizes overall expected utility ff 
rest section  present mathematical model transfer of control strategies aa use model guide search solution  moreover  model
provides tool predicting performance various strategies  justifying use
explaining observed phenomena use  section     presents model aa
strategies detail  section     reveals key properties complex strategies  including dominance relationships among strategies  section     examines e elves application
light model  make specific predictions properties successful
aa approach reasoning application class have  predictions shape
operationalization strategies section   

    mathematical model strategies
transfer of control model presented section allows calculation expected
utility  eu  individual strategies  thus allowing strategies compared  calculation strategy s eu considers four elements  likely relative quality different
entities  decisions  probability getting response entity particular time 
cost delaying decision  costs benefits changing coordination constraints  parameters might modeled similar manner  experience
e elves aa work suggests parameters critical ones
across wide range joint activities 
first element model expected quality entity s decision  general 
capture quality entity s decision time functions eq   feqde  t   
r   rg  quality decision ects probability entity make
 appropriate  decision costs incurred decision wrong  expected quality
decision calculated decision theoretic way  multiplying probability
outcome  i e   decision  utility decision  i e   cost benefit
decision  example  higher probability entity make mistake 
lower quality  even lower mistakes might costly  quality decision
entity make vary time information available changes
time  think   second element model probability entity
make decision control transferred it  functions  p   fp e  t    r         g 
represent continuous probability distributions time
entity e respond 
r t  ei
is  probability ei respond time t    p   t dt 
third element model representation cost inappropriate timing
decision  general  making decision particular point time incurs
   best time transfer control found  e g   differentiating expected utility equation
section     solving   

   

fitowards adjustable autonomy real world
cost function time  t  coordination constraints   
team members  stated earlier  focus cases constraint violations due delays
making decisions  thus  cost due violation constraints caused
making decision point time  write wait cost function  
w   f    t  returns cost making decision particular point time
given coordination constraints    miscoordination cost fundamental aspect
model given emphasis multiagent domains  called  wait cost  models
miscoordination arises team  waits  entity make ultimate
decision  domains e elves  team incurs wait costs situations  for
example  meeting attendees assembled meeting room time
meeting  kept waiting without input decision friday  potentially
cannot provide high quality decision  get input user   notice
different roles lead different wait cost functions  since delays performance
different roles different effects team  assume
point time    costs accrue  i e   f    t    f      
deadline    maximum cost due inappropriate timing decision
incurred  finally  assume that  general    wait cost function nondecreasing  ecting idea bigger violations constraints lead higher wait costs 
final element model coordination change action  d  moves agent
away deadline hence reduces wait costs incurred 
model effect letting w function dvalue  rather t 
action fixed cost  dcost   incurred immediately upon execution 
example  e elves domain  suppose time meeting  friday delays
meeting    minutes  d action   then  following time period  incur
relatively low cost making decision    minutes meeting  t dvalue   
rather relatively high cost making decision time meeting 
other  possibly complex  models action could used 
use four elements compute eu arbitrary strategy  s  utility
derived decision made time entity control quality
entity s decision minus costs incurred waiting t  i e   euedc  t    eqdec  t 
w  t   coordination change action taken effect utility 
coordination change value dvalue taken time   incurred wait cost
w     then  t  wait cost incurred w  t dvalue   w   dvalue   
thus  action taken time cost dcost value dvalue  
utility decision time  t     is  euedc  t    eqdec  t  w    w   dvalue    
w  t dvalue  dcost  calculate eu entire strategy  multiply response
probability mass function s value instant eu receiving response
instant  integrate products  hence  eu strategy given
problem instance  ha  ff      d  e   is 
z  
h
a ff  

 d e

eus
 
p  t euedc  t   dt
   
   
strategy involves several actions  need ensure probability response
function wait cost calculation ect control situation point
strategy  example  user  h   control time t  p   t  ect h s
   

fiscerri  pynadath   tambe

w    

euad   eqda    
eued

euea

 

 



z

 
z

 

eueddea  

p  t   eqde  t 
p  t   eqde  t 

w  t   dt  
w  t   dt  

 
p  t   eqde  t 


z

 

z



r

   

w  d   dt    

p  t  dt  eqda  t  

w  t       


 
  p   t  eqe  t  w  t   dt  

p  t  eqe  t  w      w   dvalue   w  t dvalue   dcost   dt  
r 

p   t  eqa  t  w      w   dvalue   w  t dvalue   dcost   dt

   

rt

table    general aa eu equations sample transfer control strategies 
probability responding t  i e   p h  t     end  break integral
equation   separate terms  term representing one segment strategy 
e g   strategy ua would one term u control another
control 
using basic technique writing eu calculations  write
specific equations arbitrary transfer of control strategies  equations     table  
show eu equations strategies a  e   ea e dea respectively  equations
assume agent  a  make decision instantaneously  or least  delay
significant enough affect overall value decision   equations created
writing integral segments strategy  described above 
time agent takes control e   time occurs 
one write equations complex strategies way  notice
equations make assumptions particular functions 
given eu strategy calculated  aa problem agent reduces
finding following transfer of control strategy maximize eu  formally 
agent s problem is 

axiom     problem ha  ff      d  e   agent must select    s   
s  s     s  eusha ff   d e eush a ff   d e

   

fitowards adjustable autonomy real world

 
 
  
   

w    

   

   

   
   p

figure    graph comparing eu two strategies  h da  solid line  h  dashed line 
given particular instantiation model constant expected decisionmaking quality  exponentially rising wait costs  markovian response probabilities  p parameter p  t  function  higher p meaning longer
expected response time  w parameter w  t  function higher w
meaning rapidly accruing wait costs 

    dominance relationships among strategies
agent could potentially find strategy highest eu examining
every strategy s  computing eu  selecting strategy highest value 
example  consider problem domains constant expected decision making quality 
exponentially rising wait costs  markovian response probabilities  figure   shows
graph eu two strategies  h da h   given particular model instantiation 
notice that  different response probabilities rates wait cost accrual  one strategy
outperforms other  neither strategy dominant entire parameter space 
eu strategy dependent timing transfers control  turn
depend relative quality entities  decision making  appendix provides
detailed analysis 
fortunately  evaluate compare every candidate
exhaustive search find optimal strategy  instead use analytical methods
draw general conclusions relative values different candidate strategies 
particular  present three lemmas show domain level conditions
particular strategy types superior others  lemmas lead us the  perhaps
surprising  conclusion complex strategies necessarily superior single shot
strategies  even multi agent context  fact  particular strategy dominates
strategies across domains 
let us first consider aa subproblem whether agent ever take back
control another entity  show that  certain conditions  agent
always eventually take back control  strategy selection process ignore
strategies agent  i e   strategies ending a   agent s
goal strike right balance waiting indefinitely user response
   

fiscerri  pynadath   tambe
taking risky autonomous action  informally  agent reasons eventually
make decision expected cost continued waiting exceeds difference
user s decision quality own  formally  agent eventually take back
decision making control iff  time t 
z
p   t   w  t    dt  w  t    eqdu  t  eqda  t 
   


left hand side calculates future expected wait costs right hand side
calculates extra utility gained getting response user  result
leads following general conclusion strategies end giving control back
agent 
lemma      isra strategy ending e   e   s  sa  eusd    eusd iff
 e   e   t   p  t   w  t    dt  w  t    eqde  t  eqda t 
lemma   says if  point time  expected cost indefinitely leaving
control hands user exceeds difference quality agent s
user s decisions  strategies ultimately give agent control dominate
not  thus  rate wait cost accrual increases difference
relative quality decision making abilities decreases user s probability response
decreases  strategies agent eventually takes back control dominate 
key consequence lemma  in opposite direction  that  rate costs accrue
accelerate  probability response stays constant  i e   markovian  
agent indefinitely leave control user  if user originally
given control   since expected wait cost change time  hence  even
agent faced situation potentially high total wait costs  optimal strategy
may one shot strategy handing control waiting indefinitely 
expected future wait costs point time relatively low  thus  lemma   isolates
condition consider appending transfer of control action
strategy 
perform similar analysis identify conditions
include action strategy  agent incentive changing coordination
constraints via action due additional time made available getting highquality response entity  however  overall value action depends
number factors  e g   cost taking action timing subsequent
transfers control   calculate expected value comparing eu
strategy without d  useful increased expected value
strategy greater cost  dcost  
lemma    sr  s  included eusd    eusd iff
r
p   t   w  t  dt 
p  t   w  tjd  dt    dcost
illustrate consequences lemma   considering specific problem model
appendix  i e   p   t    exp   w  t      exp t   eqde  t    c  candidate strategies
iff        exp         exp  dvalue    
ea e da   case  euedda   euea
dcost  figure   plots value action vary rate wait cost accumulation 
w  parameter markovian response probability function  p  graph shows
   

fitowards adjustable autonomy real world

value
    
    
    
    
 
     
       
w           

 
    
    p
    

figure    value action particular model  p   t    exp
eqde  t    c  

 

w  t      exp t  

benefit highest probability response neither low
high  probability response low  user unlikely respond 
even given extra time  hence  agent incurred dcost benefit 
little value probability response high  user likely
respond shortly d  meaning little effect  the effect
wait costs action taken   overall  according lemma    points
graph goes dcost   agent include action  and  points 
not  figure   demonstrates value action specific subclass problem
domains  extend conclusion general case well  instance 
specific model exponential wait costs  models wait costs grow
slowly  fewer situations lemma   s criterion holds  i e  
useful   thus  lemma   allows us eliminate strategies consideration  based
evaluation criterion particular domain interest 
given lemma   s evaluation adding single action strategy  natural
ask whether second  third  etc  action would increase eu even further  words 
complex strategy better simple one  even complex strategy even
better  answer  not necessarily  

 k   n   w   w   p   p   eq   eq optimal strategy
actions 
informally  lemma   says cannot fix single  optimal number actions 
every possible number actions  potential domain  i e   combination
lemma   

k

wait cost  response probability  expected quality functions  number
actions justified optimal  consider situation cost
function number ds date  i e   cost k th f  k     example 
e elves  meeting case  cost delaying meeting third time much
higher cost first delay  since delay successively annoying
meeting participants  hence  test usefulness k th strategy 
   

fiscerri  pynadath   tambe
given specific model appendix i  is 

 

exp exp   
   
f  k       exp dvalue       exp


depending nature f  k    equation   hold number ds  so 
k   conditions strategy k ds optimal  instance 
section      show maximum length optimal strategy random
configuration    entities usually less eight actions 
equation   illustrates value additional limited changing dcost  
lemma   shows us factors affect value additional d 
example  even constant dcost   value additional depends many
actions agent performs  figure   shows value depends
rate wait costs accrue  rate wait cost accrual accelerates time  e g  
exponential model   action slows acceleration  rendering second action
less useful  since wait costs accruing slowly   notice ds become
valueless deadline  wait costs stop accruing 
taken together  lemmas     show particular transfer of control strategy dominates others across domains  moreover  different strategies  single shot
strategies arbitrarily complex strategies  appropriate different situations  although
range situations particular transfer of control action provides benefit
quite narrow  since strategy might low eu set parameters  choosing
wrong strategy lead poor results  hand  understand
parameter configuration intended application domain  lemmas     provide useful
tools focusing search optimal transfer of control strategy  lemmas
used off line substantially reduce space strategies need searched
find optimal strategy  however  general may many strategies finding
optimal strategy may possible feasible 

    model predictions e elves
section  use model predict properties successful approach aa
e elves  using approximate functions probability response  wait cost 
expected decision quality  calculate eu various strategies determine
types strategies going useful  armed knowledge  predict
key properties successful implementation 
key feature e elves user mobile  moves around environment  probability responding requests decisions changes drastically  e g  
likely respond workstation  calculate eu different strategies 
need know p  t   means need estimate response probabilities
model change user moves around  friday communicates via
workstation dialog box  user respond  average  five minutes  however 
friday communicates via palm pilot average user response time hour  users
generally take longer decide whether want present research meeting  taking
approximately two days average  so  function p  t  average value
  minutes user oce  average one hour user contacted
via palm pilot average two days decision whether present
   

fitowards adjustable autonomy real world
research meeting  necessary estimate relative quality user  eqdu  t  
friday s decision making  eqda  t   assume user s decision making eqdu  t 
high respect friday s  eqda  t   uncertainty user intentions makes
hard friday consistently make correct decisions time user
arrive meetings  although sensors  e g   gps device  give indication
user s location  dealing important meetings  cost friday s errors
higher  thus  cases  decision making quality user friday
similar  i e   equd  t  eqad  t   cases  order magnitude
difference  i e   equd  t     eqad  t   wait cost function  w  t   much larger
big meetings small increase rapidly attendees wait longer meeting
room  finally  cost delays  i e   dcost   vary order magnitude 
particular  cost rescheduling meetings varies greatly  e g   cost rescheduling
small informal meetings colleagues far less rescheduling full lecture room
  pm friday 
parameters laid show parameters vary decision decision 
specific decision  use markovian response probabilities  e g   user
oce  average response time five minutes   exponentially increasing wait costs 
constant decision making quality  though changes decision decision  calculate
eu interesting strategies  calculating eu different strategies using values
different parameters shown allows us draw following conclusions  table  
section     presents quantitative illustration predictions  

strategy e used  since combinations user location
meeting importance eu strategy low 

multiple strategies required  since different user locations meeting importance different strategies optimal 

since quite different strategies required user different locations 
aa reasoning need change strategies user changes location 

strategy reasonable eu possible parameter instantiations  hence always
using strategy occasionally cause dramatic failures 

decisions  strategies end agent taking decision  since strategies
ending user control generally low eu 

predictions provide important guidance successful solution aa
e elves  particular  make clear approach must exibly choose
different strategies adjust depending meeting type user location 
section     described unsuccessful c    approach aa e elves identified
several reasons mistakes occurred  particular  rigidly transferring control
one entity ignoring potential team costs involved agent s decision highlighted
reasons dramatic mistakes friday s autonomy reasoning  reviewing c   
approach light notion strategies  see friday learned one strategy
stuck strategy  particular  originally  friday would wait indefinitely user
response  i e   would follow strategy e   learned transfer control  shown later
   

fiscerri  pynadath   tambe
table    strategy low eu  fixed length timeout introduced 
friday would follow strategy e    a  strategy high eu equd  t  eqad  t 
low eu equd  t     eqad  t   thus  model explains phenomenon
observed practice 
hand  use model understand c    s failure case
mean never useful aa  different strategies required
certain parameters  like probability response wait cost  change significantly 
applications parameters change dramatically decision decision 
one particular strategy may always appropriate  applications  c    might learn
right strategy small amount training data perform acceptably well 
  

operationalizing strategies mdps

formalized problem aa selection transfer of control strategy highest eu  need operational mechanism allows agent
perform selection  one major conclusion previous section different
strategies dominate different situations  applications e elves require mechanism s  selecting strategies situation sensitive fashion  particular 
mechanism must exibly change strategies situation changes  required mechanism must represent utility function specified expected decision qualities 
eq  costs violating coordination constraints  w  coordination change cost 
dcost  finally  mechanism must represent uncertainty entity responses
look ahead possible responses  or lack thereof  may occur future 
mdps natural means performing decision theoretic planning required find
best transfer of control strategy  mdp policies provide mapping agent s
state optimal transfer control strategy  encoding parameters model
aa strategies mdp  mdp effectively becomes detailed implementation
model and  hence  assumes properties  use standard algorithms  puterman 
      find optimal mdp policy and  hence  optimal strategies follow
state 
simplify exposition  well illustrate generality resulting mdp 
section describes mapping aa strategies mdp four subsections 
particular  section     provides direct mapping strategies abstract mdp  section
    fills state features enable concrete realization reward function 
still maintaining domain independent view  thus  section completely defines general
mdp aa potentially reusable across broad class domains  section     illustrates
implemented instantiation mdp e elves  section     addresses practical
issues operationalizing mdps domains e elves 

    abstract mdp representation aa problem
mdp representation s fundamental state features capture state control 

controlling entity entity currently decision making control 
ei  response response ei made agent s requests input 
   

fitowards adjustable autonomy real world
original state action
destination state
ectrl time
ectrl ei  response
time
ej
tk
ei
ei
yes
tk  
ej
tk
ei
ei

tk  
ei
tk
wait
ei
yes
tk  
ei
tk
wait
ei

tk  
ei
tk

ei

tk dvalue

probability
 
 

r tk   ei
tkr p   t dt
tk   ei
tk p   t dt
r tk  
ei
tkr p   t dt
tk   ei
tk p   t dt

 

table    transition probability function aa mdp  ectrl controlling entity 



time current time  typically discretized ranging   deadline 
  i e   set ft       t    t            tn   g 

ei  response null time     agent terminal state  former
case  decision value ei  response 
specify set actions mdp representation   e  fd  waitg 
set actions subsumes set entities  e   since agent transfer decision making
control one entities  action coordination change action
changes coordination constraints  discussed earlier   wait  action puts transferring control making autonomous decision  without changing coordination
team  agent reason  wait  best action when  time  situation
likely change put agent position improved autonomous decision
transfer of control  without significant harm  example  e elves domain  times
closer meeting  users generally make accurate determinations whether
arrive time  hence sometimes useful wait meeting long
time off 
transition probabilities  specified table    represent effects actions
distribution effects  i e   ensuing state world   if  state
time   tk   agent chooses action transfers decision making control entity 
ei   agent itself  outcome state controlling entity   ei
time   tk     two possible outcomes ei  response  either entity responds
decision transition  producing terminal state   not 
derive probability distribution two p   wait  action similar
branch  except controlling entity remains unchanged  finally  action occurs
instantaneously  time controlling entity respond  resulting
state effectively moves earlier time  e g   tk tk dvalue   
derive reward function mdp straightforward fashion
strategy model  table   presents complete specification reward function 
transitions take time  i e   transferring control receiving response
 table    row     wait   table    row     agent incurs wait cost interval 
transitions agent performs d  agent incurs cost action  table   
row     terminal states response ei   agent derives expected quality
entity s decision  table    row     policy maximizes reward agent
expects receive according aa mdp model correspond exactly optimal
   

fiscerri  pynadath   tambe
controlling entity time ei  response action
ej
tk

ei
ei
tk

wait
ei
tk


ei
tk
yes

reward

w  k      w  k 
w  k      w  k 
dcost
eqdei  tk  

table    reward function aa mdp 
transfer of control strategy  note reward function described abstract
fashion for example  specify compute agent s expected quality
decision  eqad  t  

    mdp representation aa problem within team context
given high level description mdp implementing notion
transfer of control strategies aa  remainder section provides detailed
look mdp broad class aa domains  including e elves  agent
acts behalf user filling role    within context team activity  ff 
reward function compares eu different strategies  finding optimal one
current state  facilitate calculation  need represent parameters used
model  introduce following state features capture aspects aa
problem team context 

team orig expect  team originally expected fulfilling  
team expect  team s current expectations fulfilling role implies 
agent expect  agent s  probabilistic  estimation fulfilled 
 other attributes  encapsulate aspects joint activity affected
decision 

add specific features generic aa state features already
presented  overall state  within mdp representation decision d  tuple 

hcontrolling entity  team orig expect   team expect   agent expect   ff status 
ei  response  time  attributesi
example  meeting scenario  team orig expect  could  meet  pm   teamexpect  could  meet     pm  user requested delay  agent expect  could
 meet     pm  agent believes user make rescheduled meeting 
transition probability function aa mdp team context includes
underlying aa transition probabilities table    must include probabilities
new state features  particular  addition temporal effect
action described section      additional effect coordination ff 
action changes value team expect  feature  in domain dependent
   

fitowards adjustable autonomy real world
deterministic way   actions affect team s expectations  team orig expect 
feature change  include simplify definition reward function 
transition probabilities agent expect  ff specific features domain specific 
provide example transition probabilities section     
final part mdp representation reward function  team aa mdp
framework uses reward function breaks function table   follows 

r s  a    f  team orig expect  s   team expect   s   agent expect   s  
ff status  s   time s   a 
x
 
eqde  time s   e  response

   

e  e nfag

  f   k team orig expect   s  team expect   s  k 
   f    time s  
   f    k team expect  s  agent expect  s  k 
   f   ff status  s       f   a 

    

first component reward function captures value getting response
decision making entity agent itself  notice one entity actually
respond  one e  response non zero  corresponds eqed  t  function
used model bottom row table    f  function ects inherent
value performing role team originally expected  hence deterring agent
taking costly coordination changes unless gain indirect value
so  corresponds dcost mathematical model third row table   
f   corresponds second row table    represents wait cost function 
w  t   model  component encourages agent keep team members
informed role s status  e g   making decision taking explicit action  
rather causing wait without information  functions f   f  represent
quality agent s decision  represented qad  t   standard mdp algorithms
compute expectation agent s reward  expectation quality
produce desired eqad  t  fourth row table    first quality function  f    
ects value keeping team s understanding role performed
accordance agent expects user actually perform role  agent
receives reward role performed exactly team expects 
uncertainty agent s expectation  errors possible  f   represents costs
come errors  second quality component  f    uences overall reward based
successful completion joint activity  encourages agent take actions
maximize likelihood joint activity succeeds  desire joint
task succeed implicit mathematical model must explicitly represented
mdp  component  f    augments first row table   account additional
costs transfer of control actions  particular  f  broken follows 
 

f   a   

q e     e
 
otherwise
   

    

fiscerri  pynadath   tambe
function q e   represents cost transferring control particular entity  e g  
cost wap phone message user  notice  detailed  domain specific costs
appear directly model 
given mdp s state space  actions  transition probabilities  reward function 
agent use value iteration generate policy p     specifies optimal
action state  puterman         agent executes policy taking
action policy dictates every state finds itself  policy
may include several transfers control coordination change actions  particular
series actions depends activities user  interpret policy
contingent combination many transfer of control strategies  strategy follow
chosen depending user s status  i e   agent expect   

    example  e elves mdps
example aa mdp generic delay mdp  instantiated
meeting friday may act behalf user  recall decision  d  whether
let meeting attendees wait user begin meeting  joint activity 
ff  meeting agent role    ensuring user attends
meeting scheduled time  coordination constraints    attendees
arrive meeting location simultaneously effect action delay
cancel meeting 
delay mdp s state representation  team orig expect  originally scheduledmeeting time  since attendance originally scheduled meeting time team
originally expects user best possible outcome  team expect  timerelative to meeting  may increase meeting delayed  ff status becomes statusof meeting  agent expect  represented explicitly  instead  user location used
observable heuristic user likely attend meeting  example 
user away department shortly meeting begin unlikely
attending time  all  state features  total state space contains
     states individual meeting  large number states arising
fine grained discretization time 
general reward function mapped delay mdp reward function following way 
 

g n  ff  n    
    
 
otherwise
n number times meeting rescheduled g function takes
account factors number meeting attendees  size meeting delay
time originally scheduled meeting time  function effectively forbids
agent ever performing   actions 
delay mdp  functions  f   f     correspond cost making
meeting attendees wait  merge single function  f    expect
consolidation possible similar domains team s expectations relate
f   

   

fitowards adjustable autonomy real world
temporal aspect role performance 
 

f   

h late  ff  late    
 
otherwise

    

late difference scheduled meeting time time user
arrives meeting room  late probabilistically calculated mdp based
user s current location model user s behavior 
 
 
 

rff   ruser user attends
f      rff
meeting takes place  user attend
   
otherwise

    

value  rff   models inherent value ff  value ruser models user s
individual value ff 
f  given previously equation     cost communicating user
depends medium used communicate  example  higher cost
communicating via wap phone via workstation dialog box 
users asked input  assumed that  respond  response
 correct   i e   user says delay meeting    minutes  assume
user arrive time re scheduled meeting  user asked front
his her workstation  dialog one shown figure   popped up  allowing user
select action taken  expected quality agent s decision calculated
considering agent s proposed decision possible outcomes decision 
example  agent proposes delaying meeting    minutes  calculation
decision quality includes probability benefits user actually arrive
   minutes originally scheduled meeting time  probability costs
user arrives originally scheduled meeting time  etc 

 a 

 b 

figure     a  dialog box delaying meetings   b  small portion delay mdp 
delay mdp represents probabilities change user location  e g  
oce meeting location  occur given time interval  figure   b  shows portion
   

fiscerri  pynadath   tambe
state space  showing user response  user location features  transition
labeled  delay n  corresponds action  delay n minutes   figure shows
multiple transitions due  ask   i e   transfer control user   wait  actions 
relative probability outcome represented thickness arrow 
state transitions correspond uncertainty associated user s response  e g  
agent performs  ask  action  user may respond specific information may
respond all  leaving agent effectively  wait    one possible policy produced
delay mdp  subclass meetings  specifies  ask  state s  figure   b 
 i e   agent gives autonomy   world reaches state s   policy specifies
 wait   however  agent reaches state s   policy chooses  delay     
agent executes autonomously  terms strategies  sequence actions
h d 
earlier  described another aa decision e elves  namely whether close
auction open team role  here  brie describe key aspects mapping
decision mdp  auction must closed time user prepare
meeting  sucient time given interested users submit bids
human team leader choose particular user  team orig expect   s  highquality presenter selected enough time prepare  action  hence
team expect   s    team orig expect   s   agent expect  s  whether agent believes
high quality bid believes bid arrive time user allocated
role  agent s decision quality  eqda  t   function number bids
submitted quality bids  e g   team members submitted
bids one user s bid stands out  agent confidently choose user
presentation  thus  ff status primarily quality best bid far difference
quality bid second best bid  critical component
reward function equation      component  gives reward agent
fulfills users  expectation willing presenter high quality presentation 

    user specified constraints
standard mdp algorithms provide agent optimal policies subject encoded probabilities reward function  thus  agent designer access correct
models entities   e g   human users e elves  decision qualities probabilities response  agent select best possible transfer of control strategy 
however  possible entities accurate information
abilities agent designer  exploit knowledge  entity could
communicate model quality decision probability response directly
agent designer  unfortunately  typical entity unlikely able express
knowledge form mdp reward function transition probabilities  agent
could potentially learn additional knowledge interactions
entities domain  however  learning may require arbitrarily large number
interactions  take place without benefit entities  inside
knowledge 
alternative  provide language constraints allows entities
directly immediately communicate inside information agent  constraint
   

fitowards adjustable autonomy real world

figure    screenshot tool entering constraints  constraint displayed forbids
transferring control  i e   forces transfer  five minutes meeting
teammates previously given information user s attendance
meeting 
language provides entities simple way inform agent specific properties
needs  entity use constraint forbid agent entering specific states
performing specific actions specific states  constraints directly communicated
user via tool shown figure    instance  figure shown user
forbidding agent autonomous action five minutes meeting  define
forbidden action constraints set  cfa   element constraint
boolean function  cfa    ft  f g  similarly  define forbidden state constraints
set  cfs   elements  cfs    ft  f g  constraint returns particular domain
element  either state state action pair  appropriate   constraint applies
given element  example  forbidden action constraint  cfa   forbids action
performed state cfa  s  a    t 
provide probabilistic semantics  suitable mdp context  first provide
notation  denote probability agent ever arrive state sf following
jp    then  define semantics
policy  p   initial state si pr si  
f
jp        semantics given
forbidden state constraint cfs requiring pr si  
f
 p  s   ajp      
forbidden action constraint  cfa   bit complex  requiring pr si 
f
f
 i e   cfa forbids agent entering state sf performing action a  
cases  aggregation constraints may forbid actions state sf   case 
conjunction allows agent still satisfy forbidden action constraints avoiding sf
 i e   state sf becomes forbidden   state  sf   becomes indirectly forbidden
fashion  action potentially leads agent ancestor state
sf likewise becomes forbidden  hence  effect forbidding constraints propagate
backward state space  affecting state action pairs beyond cause
immediate violations 
   

fiscerri  pynadath   tambe
forbidding constraints powerful enough entity communicate wide
range knowledge decision quality probability response agent 
instance  e elves users forbidden agents rescheduling meetings
lunch time  so  users provide feature specification states want
forbid  meeting time     pm  specification generates forbidden state
constraint  cfs   true state  s  meeting time     pm s  constraint
effectively forbids agent performing action would result state
meeting time    pm  similarly  users forbidden autonomous actions certain
states providing specification actions want forbid  e g   action    ask  
generates forbidden action constraint  cfa   true state action pair 
 s  a      ask   example  user might specify constraint states
oce  time meeting know
always make decisions case  users easily create complicated constraints
specifying values multiple features  well using comparison functions
   e g          
analogous forbidding constraints  introduce required state requiredaction constraints  defined sets  crs cra   respectively  interpretation provided
required state constraint symmetric  opposite forbidden state
jp        thus  state  agent must eventually reach
constraint  pr si  
f
 p  s   ajp       
required state  sf   similarly  required action constraint  pr si 
f
f
users specify constraints forbidding counterparts  i e   specifying values relevant state features action  appropriate   addition 
requiring constraints propagate backward  informally  forbidden constraints focus
locally specific states actions  required constraints express global properties
states 
resulting language allows agent exploit synergistic interactions
initial model transfer of control strategies entity specified constraints  example 
forbidden action constraint prevents agent taking autonomous action
particular state equivalent user specifying agent must transfer control
user state  aa terms  user instructs agent consider transferof control strategies violate constraint  exploit pruning strategy
space user  extended standard value iteration consider constraint
satisfaction generating optimal strategies  appendix ii provides description
novel algorithm finds optimal policies respecting user constraints  appendix
includes proof algorithm s correctness 
   experimental results

section presents experimental results aimed validating claims made previous sections  particular  experiments aim show utility complex transfer ofcontrol strategies effectiveness mdps technique operationalization 
section     details use e elves daily activities section     discusses
pros cons living working assistance fridays  section     shows
characteristics strategies type domain  in particular  different strategies
   

fitowards adjustable autonomy real world
used practice   finally  section     describes detailed experiments illustrate
characteristics aa mdp 

    e elves daily use
e elves system heavily used ten users research group isi  june
     december        friday agents ran continuously  around clock  seven
days week  exact number agents running varied period execution 
usually five ten friday agents individual users  capability matcher  with proxy  
interest matcher  with proxy   occasionally  temporary friday agents operated
behalf special guests short term visitors 
daily counts exchanged messages
no  messages

   
   
   
   
   
  
 
jun jul aug sep oct nov dec
date

figure    number daily coordination messages exchanged proxies seven month
period 
figure   plots number daily messages exchanged fridays seven months
 june december         size daily counts ects large amount
coordination necessary manage various activities  high variability illustrates
dynamic nature domain  note low periods vacations final exams  
figure   a  illustrates number meetings monitored user  seven
months  nearly     meetings monitored  users fewer    meetings 
others      users     meetings delayed  this includes
regularly scheduled meetings cancelled  instance due travel   figure   b 
shows usually     delayed meetings autonomously delayed 
graph  repeated delays single meeting counted once  graphs show
   user base system greatly reduced period due personnel relocations
student graduations  remains use smaller number users 

   

fiuser delays vs  autonomous delays

meetings monitored vs  meetings delayed
   
   
   
   
   
   
   
  
 

   

number meetings

ito

ramanan

tambe

nair

scerri

modi

pynadath

jungh

total delays
human delays

   

monitored
delayed

kulkarni

number meetings

scerri  pynadath   tambe

   
  
  
  
  
 
 

users

 

 

 

 

 

 

 

users

 a 

 b 

figure     a  monitored vs  delayed meetings per user   b  meetings delayed autonomously
vs  hand 
agents acting autonomously large number instances  but  equally importantly 
humans often intervening  indicating critical importance adjustable autonomy
friday agents 
seven month period  presenter usc isi s teamcore research group
presentations decided using auctions  table   shows summary auction results 
column     date   shows dates research presentations  column     no 
bids   shows total number bids received decision  key feature
auction decisions made without   users entering bids  fact  one case 
  bids received  column     best bid   shows winning bid  winner typically
bid           i e   indicating user represents capable willing
presentation   high quality bid  interestingly  winner july    made
bid           i e   capable willing  team able settle winner
despite bid highest possible  illustrating exibility  finally  columns
    winner       method   show auction outcome   h  column   indicates
auction decided human   a  indicates decided autonomously  five
seven auctions  user automatically selected presenter  two manual
assignments due exceptional circumstances group  e g   first time visitor  
illustrating need aa 
date
no  bids best bid winner method
jul        
 
   
scerri
h
jul         
 
   
scerri

jul         
 
   
kulkarni

aug        
 
   
nair

aug        
 
   
tambe

sept         
 
  visitor
h
oct         
 
   
tambe

table    results auctioning research presentation slot 
   

fitowards adjustable autonomy real world
    evaluating pros cons e elves use
general effectiveness e elves shown several observations 
e elves  operation  group members exchanged email messages announce
meeting delays  instead  fridays autonomously informed users delays  thus reducing
overhead waiting delayed members  second  overhead sending emails recruit
announce presenter research meetings assumed agent run auctions  third 
web page  friday agents post users  location  commonly used avoid
overhead trying track users manually  fourth  mobile devices kept users
informed remotely changes schedules  enabling remotely delay
meetings  volunteer presentations  order meals  etc  users began relying friday
heavily order lunch one local  subway  restaurant owner even suggested        
computers getting order food      might think marketing
them     notice daily use e elves number different users occurred
mdp implementation aa replaced unreliable c    implementation 
however  agents ensured users spent less time daily coordination  and
miscoordination   price paid  one issue users felt
less privacy location continually posted web monitored
agent  another issue security private information credit card numbers
used ordering lunch  users adjusted agents monitor daily activities 
users adjusted behavior around agent  one example
behavior users preferring minute two early meeting lest
agent decide late delay meeting  general  since agents never made
catastrophically bad decisions users felt comfortable using agent frequently
took advantage services 
emphatic evidence success mdp approach that  since replacing
c    implementation  agents never repeated catastrophic mistakes
enumerated section      particular  friday avoids errors error   section
    selecting strategy single  large action  higher eu
strategy many small ds  e g   dddd   friday avoids error    large cost
associated erroneous cancel action significantly penalizes eu cancellation 
friday instead chooses higher eu strategy first transfers control user
taking action autonomously  friday avoids errors errors     selecting
strategies situation sensitive manner  instance  agent s decision making
quality low  i e   high risk   agent perform coordination change action
allow time user response agent get information 
words  exibly uses strategies e dea  rather always using e    a strategy
discussed section      indicates reasonably appropriate strategy chosen
situation  although current agents occasionally make mistakes  errors
typically order transferring control user minutes earlier may
necessary  thus  agents  decisions reasonable  though always optimal  
   inherent subjectivity user feedback makes determination optimality dicult 

   

fiscerri  pynadath   tambe
    strategy evaluation
previous section looked application mdp approach e elves
address strategies particular  section  specifically examine strategies
e elves  show fridays indeed follow strategies strategies followed
ones predicted model  show model led insight that 
turn  led dramatic simplification one part implementation  finally  show
use strategies limited e elves application showing empirically
that  random configurations entities  optimal strategy one
transfer of control action     cases 
figure   shows frequency distribution number actions taken per meeting
 this graph omits  wait  actions   number actions taken meeting corresponds
length part strategy followed  the strategy may longer 
decision made actions taken   graph shows mdp
followed complex strategies real world followed different strategies
different times  graph bears model s predictions different strategies would
required good solution aa problem e elves domain 
table   shows eu values computed model strategy selected
mdp  recall mdp explicitly models users  movements locations 
model assumes users move  hence  order accurate
comparison model mdp s results  focus cases
user s location change  i e   probability response constant  
eu values calculated using parameter values set section      notice 
mdp often perform ds transferring control buy time reduce
uncertainty  model abstraction domain  actions  changes
user location  captured  except slight discrepancy first case
match mdp s behavior model s predictions exact  provided
ignore actions beginning mdp strategies  thus  despite model
considerably abstracted domain high correlation mdp
policies model s suggested strategies  moreover  general properties policies
predicted model borne exactly  particular  recall model
predicted different strategies would required  strategy e would used 
generally strategies ending would best   properties mdp policies 
model predicts parameters vary greatly sucient find
single optimal strategy follow strategy situation  mdp
decision close auction instance e elves  pattern
behavior followed every time open role needs filled team  consistency
arises wait cost  since meetings same 
pattern incoming bids reasonably consistent  variations individuals  behavior
cancel look team whole   model predicts
parameters change  find optimal strategy parameters
execute strategy every time  however  since mdp worked effectively
meeting aa  mdp chosen implementing auction aa 
realized parameters vary greatly  concluded mdp could replaced
simple implementation optimal strategy  verify hypothesis  replaced
   

fitowards adjustable autonomy real world

no  meetings

no  actions per meeting
   
   
   
   
   
   
  
  
  
  
 
 

 

 
 
 
no  actions

  

  

figure    frequency distribution number steps taken aa strategy
meeting scenario  actions taken meeting  meeting
cancelled friday started aa reasoning 

location

e
ea e da mdp
small meeting  active participant
oce
                     dde da
  dept         e            ddea
  meet loc         e           
ea
large meeting  passive participant
oce
       e               ddea
  dept         e           
ddea
  meet loc         e            
ea
table    eu values simple strategies calculated model  last column
shows strategy actually followed mdp 

   

fiscerri  pynadath   tambe
date no  bids mdp ea
       
 
       
       
 
       
      
 
       
table    auction results   mdp  column shows percentage available auction
time remaining mdp chose close auction   ea  column
shows percentage available auction time remaining strategy ea 
eqde  t  proportional number bids received   no  bids  column  
would closed auction 

general mdp code three simple lines code implementing ea strategy 
determined optimal particular parameters problem  using log files
recorded actual auctions reported  scerri  pynadath    tambe        
experimentally verified mdp ea strategy produced result 
table   shows percentage available auction time remaining  e g   auction
opened four days role performed  closing auction one day
would correspond      mdp version ea version code closed
auction  number bids used estimate agent s expected decision quality 
timing auction closing close  certainly within hours  result
precisely mdp strategy implementations  mdp
implementation reactive incoming bids strategy implementation 
confirm need strategies phenomenon unique particular
settings e elves  experiment run randomly generated configurations
entities  wait cost configuration increased exponentially  rate
accrual varying configuration configuration  configurations contained
     entities  randomly chosen markovian response probabilities randomly
chosen  constant  decision making quality  cost value action
randomly selected  configuration  agent could respond instantly 
lower decision quality entities  configuration 
optimal transfer of control strategy found  figure    a  shows percentage optimal
strategies  z axis  length  y axis  jopt  strat j    separated according
rate wait costs accrued  x axis   wait cost param    figure shows
rate wait cost accrues low  optimal strategies length
one  agent handing control entity highest decision making
quality  rate wait cost accrual high  strategies length two 
agent brie giving best decision maker opportunity make decision
taking back control acting wait costs became high  intermediate
values wait cost parameter  considerably variation length
optimal strategy  figure    b  shows percentage optimal strategies length
wait cost parameter       i e   slice figure    a    hence  strategies
often contained several transfers control several coordination changes  thus 
experiment shows complex transfer of control strategies useful  e elves 
   

fitowards adjustable autonomy real world
range domains  especially wait costs neither negligible
accruing fast 
strategy lengths w       
  

  opt  strats 

  
  
  opt  strats 

   
  
  
  
  
  
  
  
  
  
  

 

  
  
  

 

 opt  strat  

 

 

 

 

   

        
        
        
   
wait
cost
param
    

 
 
 

 a 

 

 

 
 
 opt  strat  

 

 

 

 b 

figure      a  percentage optimal strategies certain length  broken according fast wait costs accruing   b  percentage optimal strategies
certain length wait cost parameter        
thus  shown mdp produces strategies friday follows
strategies practice  moreover  strategies followed ones predicted model 
practical use  followed prediction model  i e   mdp
required auctions  able substantially reduce complexity one part
system  finally  showed need strategies specifically phenomenon
e elves domain 

    mdp experiments
experience using mdp approach aa e elves indicates effective
making reasonable aa decisions  however  order determine whether mdps
generally useful tool aa reasoning  systematic experiments required 
section  present systematic experiments determine important properties
mdps aa  mdp reward function designed result optimal strategy
followed state 
experiments  vary one parameters weights
different factors equation     mdp instantiated range values
parameter policy produced value  case  total policy
defined      states  policy analyzed determine basic properties
policy  particular  counted number states policy specifies ask 
delay  say user attending say user attending  statistics
show broadly policy changes parameters change  e g   whether friday gives
autonomy less cost coordination change increased  first
aim experiments simply confirm policies change desired expected
way parameters reward function changed  instance  friday s expected
decision quality increased  states makes autonomous
   

fiscerri  pynadath   tambe
decision  secondly  practical perspective critical understand sensitive
mdp policies small variations parameters  sensitivity would mean
small variations parameter values significantly impact mdp performance 
finally  experiments reveal interesting phenomena 
first experiment looks effect   parameter equation     represented delay mdp implementation team repair cost  function g equation
     policies produced delay mdp  parameter determines averse friday changing coordination constraints  figure    shows properties
policy change team repair cost value varied  x axis gives value
team repair cost  y axis gives number times action appears
policy  figure    a  shows number times friday ask user input 
number times transfer control exhibits interesting phenomenon  number
asks maximum intermediate value parameter  low values 
friday  confidently   i e   decision quality high  make decisions autonomously 
since cost errors low  hence less value relinquishing autonomy 
high team repair costs  friday  confidently  decide autonomously make
coordination change  intermediate region friday uncertain needs
call user s decision making often  furthermore  cost delaying
meeting increases  friday delay meeting less  figure    b   tell team
user attending often  figure    d    so  friday gives user less time
arrive meeting  choosing instead announce user attending 
essentially  friday s decision quality become close enough user s decision quality
asking user worth risk respond cost asking
input  except jump value zero non zero value 
number times friday says user attending change  figure    c   
delay mdp use e elves team repair cost parameter set two  around
value policy changes little  hence slight changes parameter lead
large changes policy 
second experiment  vary   parameter equation     implemented
delay mdp variable team wait cost  function h equation     
factor determines heavily friday weigh differences
team expects user fulfill role user actually fulfill role 
particular  determines cost team members wait meeting room
user  figure    shows changes policy parameter varied  again
x axis shows value parameter y axis shows number times
action appears policy   graph number times agent asks
policy  figure    a    exhibits phenomena   parameter varied 
i e   increasing decreasing parameter increases  graphs show that 
cost teammates  time increases  friday acts autonomously often  figure    bd    friday asks whenever potential costs asking lower potential costs
errors makes   cost time waiting user decision increases  balance
tips towards acting  notice phenomenon number asks increasing
decreasing occurs way   parameter  however  occurs
slightly different reason  case  waiting costs low  friday s decision making
quality high acts autonomously  waiting costs high  friday cannot
   

fitowards adjustable autonomy real world

number delays policy

  
  
  
  
  
  
  
  
  
  
  

  delays

  asks

number asks policy

 

 
 
 
 
 team repair cost  weight

   
   
   
   
   
  
  
  
  
  
  
  

  

 

 a 

number attending messages policy
  attending

  attending

   
   
   
   
   
   
   
   
   
  
  
 
 
 
 
 team repair cost  weight

  

 b 

number attending messages policy

 

 
 
 
 
 team repair cost  weight

  

  
  
  
  
  
  
  
 
 

 c 

 
 
 
 
 team repair cost  weight

 d 

figure     properties mdp policy team repair cost varied 

   

  

fiscerri  pynadath   tambe
afford risk user respond quickly  acts autonomously  despite
decision quality low   figure    b  shows number delay actions taken
friday increases  states meeting already delayed twice 
indicates normally expensive third delay meeting starts
become worthwhile cost teammates wait meeting room high 
delay mdp  value   used     decision transfer control  i e   ask 
particularly sensitive changes parameter around value again  slight
changes significant impact 
number asks policy

number delays policy

  
  delays

  asks

  
  
  

   
  
  
  
  
 

  
 

 

 

 

 

  

 

 cost teammates time  weight

 

 

 

  

 b 

number attending messages policy
  
  attending

number attending messages policy
   
   
   
   
   
   
   
   
   
  
 

 

 cost teammates time  weight

 a 

  attending

total
 st delay
 nd delay
 rd delay

   

  

 
 
 
 
  
 cost teammates time  weight

  
  
  
  
 
 
 

 c 

 
 
 
 
  
 cost teammates time  weight

 d 

figure     properties mdp policy teammate time cost varied   b  shows
number times meeting delayed states yet
delayed  delayed already  delayed
twice already 
third experiment  value     weight joint task  varied
 figure      e elves  value joint task includes value user
meeting value meeting without user  experiment  value
   

fitowards adjustable autonomy real world
meeting without user varied  figure    shows policy changes value
meeting without user changes  again x axis shows value parameter
y axis shows number times action appears policy   graphs
show significantly instability values  large changes
result simultaneous change utility taking key actions expected
quality friday s decision making  e g   utility saying user attending much
higher meeting low value without user  current delay mdp 
value set       part graph insensitive small changes
parameter 
three experiments above  specific e elves parameters regions
graph small changes parameter lead significant changes policy 
however  regions graphs policy change dramatically small
changes parameter  indicates domains  parameters different
e elves  policies sensitive small changes parameters 

   
   
   
   
   
  
  
  
  
 
   

number delays policy
   
   
  delays

  asks

number asks policy

  
  
  

  

  
  
  
 
joint activity weight

  
   

 

  

 a 

number attending messages policy
  
  attending

  attending

   
   
   
   
  

  
  
  
 
joint activity weight

 

 b 

number attending messages policy
   

   
   

  
  
  
 
joint activity weight

  
  
 
 
   

 

 c 

  

  
  
  
joint activity weight

 

 

 d 

figure     properties mdp policy importance successful joint task
varied 
   

fiscerri  pynadath   tambe
experiments show three important properties mdp approach aa 
first  changing parameters reward function generally lead changes
policy expected desired  second  value parameters uenced
policy  effect aa reasoning often reasonably small  suggesting small
errors model affect users greatly  finally  interesting phenomena
number asks reaching peak intermediate values parameters revealed 
three previous experiments examined behavior mdp changes
parameters reward function changed  another experiment  central
domain level parameter affecting behavior mdp  i e   probability getting
user response cost getting response  corresponding f     varied  figure
   shows number times friday chooses ask  y axis  varies
expected time get user response  x axis  cost  each line
graph represents different cost   mdp performs expected  choosing ask
often cost low and or likely get prompt response  notice
that  cost low enough  friday sometimes choose ask user even
long expected response time  conversely  expected response time suciently
high  friday assume complete autonomy  graph shows distinct
change number asks point  depending cost   outside change
point graphs relatively at  key reason fairly rapid change number
asks often difference quality friday s user s decision
making fairly small range  mean response time increases  expected wait
costs increase  eventually becoming high enough friday decide act autonomously
instead asking 

  asks

number asks policy
  
  
  
  
  
  
  
 
    

cost         
cost      
cost      

   
 
  
mean response time

   

figure     number ask actions policy mean response time  in minutes  varied 
x axis uses logarithmic scale 
conclude section quantitative illustration impact constraints
strategy selection  experiment  merged user specified constraints
e elves users  resulting set    distinct constraints  started unconstrained
   

fitowards adjustable autonomy real world

figure      a  number possible strategies  logarithmic    b  time required strategy
generation 
instance delay mdp added constraints one time  counting strategies
satisfied applied constraints  repeated experiments expanded
instances delay mdp  increased initial state space increasing
frequency decisions  i e   adding values time relative to meeting feature  
expansion results three new delay mdps  artificial  uenced
real delay mdp  figure   a displays results  on logarithmic scale   line
corresponds original delay mdp       states   lines b       states   c      
states         states  correspond expanded instances  data point
mean five different orderings constraint addition  four mdps  constraints
substantially reduce space possible agent behaviors  instance  original
delay mdp  applying    constraints eliminated           original states
consideration  reduced mean number viable actions per acceptable state
             end result     reduction size  log     strategy space 
hand  constraints alone provide complete strategy  since
plots stay well    even    constraints  since none individual users
able willing provide    constraints  cannot expect anyone add enough constraints
completely specify entire strategy  thus  mdp representation associated
policy selection algorithms still far redundant 
constraints  elimination behaviors decreases time required strategy
selection  figure   b plots total time constraint propagation value iteration
four mdps figure   a  averaged five constraint orderings  
data point mean five separate iterations  total    iterations
per data point  values zero constraint case correspond standard value iteration without constraints  savings value iteration restricted strategy space
dramatically outweigh cost pre propagating additional constraints  addition 
savings increase size mdp  original delay mdp  a  
    reduction policy generation time  largest mdp  d      
reduction  thus  introduction constraints provide dramatic acceleration
agent s strategy selection 

   

fiscerri  pynadath   tambe
  

related work

discussed related work section    section adds discussion 
section      examine two representative aa systems   detailed experimental
results presented   explain results via model  illustrates
potential applicability model systems  section      examine aa
systems areas related work  meta reasoning  conditional planning
anytime algorithms 

    analyzing aa work using strategy model
goodrich  olsen  crandall  palmer        report tele operated teams robots 
user s high level reasoning robots  low level skills required
achieve task  within domain  examined effect user neglect
robot performance  idea user neglect similar idea entities taking time
make decisions  case  user  neglects  robot  joint task takes longer
perform  domain  coordination constraint user input must arrive
robot work low level actions needs perform  four control systems
tested robot  giving different amount autonomy robot 
performance measured user neglect varied 
although quite distinct e elves system  mapping goodrich s team robots
aa problem formulation provides interesting insights  system
interesting feature entity robot call decision  i e   user 
part team  changing autonomy robot effectively changes nature
coordination constraints user robot  figure    shows performance
 y axis  four control policies amount user neglect increased  x axis  
experiments showed higher robot autonomy allowed operator  neglect 
robot without serious impact performance 
notion transfer of control strategies used qualitatively predict
behavior observed practice  even though goodrich et al         use
notion strategies  lowest autonomy control policy used goodrich et al        
pure tele operation one  since robot cannot resort decision making 
represent control policy strategy u   i e   control indefinitely hands
user  second control policy allows user specify waypoints on board
intelligence works details getting waypoints  since robot highlevel decision making ability  strategy simply give control user  however 
since coordination robot user abstract  i e   coordination
constraints looser  wait cost function less severe  human giving less
detailed guidance fully tele operated case  which good according
 goodrich et al           hence use lower value expected quality user
decision  denote approach uw p distinguish fully tele operated case 
next control policy allows robot choose waypoints given user
inputs regions interest  robot accept waypoints user  ability
robot calculate waypoints modeled d  since effectively changes
coordination entities  removing user s need give waypoints  model
control policy strategy u du   final control policy full autonomy  i e   a 
   

fitowards adjustable autonomy real world
performance



udu
u wp

u

neglect

 a 
goodrich robot operation eu
  
  
eu

  
 
   
   
   
 

   

 b 

 
p

   

 

figure     goodrich al s various control strategies plotted neglect   a  experimental results  thinner lines represent control systems intelligence
autonomy   b  results theoretically derived model strategies presented article  p parameter probability response function  
robot decision making inferior user  hence robot s decision quality less
user s  graphs four strategies  plotted probability response
parameter  getting smaller right  match  neglect  goodrich et al graph 
shown figure     notice shape graph theoretically derived model 
shown figure    b   qualitatively shape experimentally derived
graph  figure    a   hence  theory predicted qualitatively performance
found experimentation 
common assumption earlier aa work entity asked
decision make decision promptly  hence strategies handling contingency
   

fiscerri  pynadath   tambe
lack response required  example  horvitz s        work using
decision theory aimed developing general  theoretical models aa reasoning
user workstation  prototype system  called lookout  helping users manage
calendars implemented test ideas  horvitz         although systems
distinctly different e elves  mapping problem formulation allows us
analyze utility approaches across range domains without implement
approach domains 
critical difference horvitz s work work lookout
address possibility receiving  timely  response  thus  complex strategies
required  typical case lookout  agent three options  take
action  take action  engage dialog  central factor uencing
decision whether user particular goal action would aid  i e   user
goal  action useful  he she goal  action
disruptive  choosing act act corresponds pursuing strategy a   choosing
seek user input corresponds strategy u   figure    a  shows graph different
options plotted probability user goal  corresponds figure  
horvitz          agent s expected decision quality  eqda  t  derived equation
  horvitz          in words  horvitz s model performs detailed calculations
expected decision quality   model predicts selection strategies
horvitz does  i e   choosing strategy eqda  t  low  u otherwise  assuming
two strategies available   however  model predicts something
horvitz consider  i e   rate wait costs accrue becomes
non negligible choice simple  figure    b  shows eu two
strategies changes rate wait costs accruing increased  fact optimal
strategy varies wait cost suggests horvitz s approach would immediately
appropriate domain wait costs non negligible  e g   would need
modified many multi agent settings 

    approaches aa
several different approaches taken core problem whether
transfer decision making control  example  hexmoor examines much time agent
aa reasoning  hexmoor         similarly  dynamic adaptive autonomy
framework  group agents allocates votes amongst themselves  hence defining amount
uence agent decision thus  definition  autonomy
agent respect decision  barber  martin    mckay      b   related
application meeting scheduling cesta  collia  d aloisi        taken approach
providing powerful tools users constrain monitor behavior proxy
agents  agents explicitly reason relinquishing control user 
least work done multiagent context  possibility multiple
transfers control considered 
complementing work  researchers focused issues architectures
aa  instance  aa interface  t architecture  bonasso  firby  gat  kortenkamp 
   consider choosing act autonomous decision  hence categorize way autonomous action

   

fitowards adjustable autonomy real world

horvitzs eu calculations wait cost
 

eu

 
  
  
 

   
   
   
   
probability user goal

 

 a 

horvitzs eu calculations wait cost
   

eu

   
 
    
    
    
 

                          

 b 

w

figure     eu different agent options  solid  darkest  line shows eu taking
autonomous action  dashed  medium dark  line shows eu autonomously deciding act dotted line shows eu transferring
control user   a  plotted probability user goal 
wait cost   b  plotted wait cost  fixed probability user goal 
miller    slack        implemented solve human machine interaction problems
experienced number nasa projects  brann  thurman    mitchell        
experiences showed interaction system required way
deliberative layer detailed control actuators  aa controls layers
encapsulated referred  t s fourth layer   interaction layer
   

fiscerri  pynadath   tambe
 schreckenghost         similar area aa technology required safety critical
intelligent software  controlling nuclear power plants oil refineries  musliner
  krebsbach         work resulted system called aegis  abnormal event
guidance information system  combines human agent capabilities rapid
reaction emergencies petro chemical refining plant  aegis features shared task
representation users intelligent system work  goldman 
guerlain  miller    musliner         key hypothesis work model needs
multiple levels abstraction user interact level see fit 
interesting work fong  thorpe  baur        extended idea tele operated
robotics re defining relationship robot user collaborative one 
rather traditional master slave configuration  particular  robot treats
human resource perform perceptual cognitive functions robot
determines cannot adequately perform  however  yet work looked
possibility user available provide input required  would require
robot perform complex transfer of control reasoning 
previous work aa ignored complex strategies aa  work
research fields potentially relevant  example  research issues addressed fields mixed initiative decision making  collins  bilot  gini    mobasher 
    b   anytime algorithms  zilberstein         multi processor scheduling  stankovic  ramamritham    cheng         meta reasoning  russell   wefald         game theory  fudenberg   tirole         contingency plans  draper  hanks    weld        peot  
smith        have  least superficial  similarities aa problem  however 
turns core assumptions focus research areas different
enough algorithms developed related fields directly applicable
aa problem 
mixed initiative decision making human user assumed continually available
 collins et al       b  ferguson   allen         negating need reasoning
likelihood response  furthermore  often little time pressure coordination
constraints  thus  basic problem transferring control human
agent common mixed initiative decision making aa  assumptions
quite different leading distinct solutions  likewise  related research fields make
distinctly different assumptions lead distinctly different solutions  instance 
contingency planning  draper et al         peot   smith        deals problem
creating plans deal critical developments environment  strategies related
contingency planning plans deal specific contingency
entity making decision manner maintains coordination  however  contingency planning  key diculty creating plans  contrast  aa  creating
strategies straightforward key diculty choosing strategies 
contribution recognizing need strategies addressing aa problem  instantiating strategies via mdps  development general  domain independent
reward function leads mdp choosing optimal strategy particular situation 
similarly  another related research area meta reasoning  russell   wefald        
meta reasoning work looks online reasoning computation  type meta reasoning 
closely related aa  chooses sequences computations different ex   

fitowards adjustable autonomy real world
pected quality running time  subject constraint choosing highest quality
sequence computations possible  because takes long   russell   wefald 
       idea treat computations actions  meta reason  eu
certain combinations computation  base level  actions  output metareasoning sequence computations executed sequence  aa parallels metareasoning consider reasoning transferring control entities reasoning
selecting computations  i e   think entities computations  however  aa 
aim one entity make high quality decision  meta reasoning  aim
sequence computations high quality  moreover  meta reasoning
assumption computations guaranteed return timely result executed 
apply aa  finally  meta reasoning looks sequence computations use
fixed amount time  aa reasons trading extra time better decision
 possibly buying time action   thus  algorithms developed meta reasoning
applicable aa 
another research area conceptual similarity aa field anytime algorithms  zilberstein         anytime algorithm quickly finds initial solution
incrementally tries improve solution stopped  aa problem similar
assume agent make immediate decision  problem
property solution always available  an important property anytime
algorithm   however  case general  i e   agent always
answer  furthermore  anytime algorithms generally need deal multiple 
distributed entities  opportunity change coordination  i e   using
action  
multi processor scheduling looks assigning tasks nodes order meet certain
time constraints  stankovic et al          entities thought  nodes   aa
assigning tasks nodes  multiprocessor scheduling  quality
computation performed nodes usually assumed equal  i e   nodes
homogeneous  thus  reasoning trades quality time required 
aa  moreover  deadlines externally imposed multi processor scheduling algorithms 
rather exibly reasoned aa  multi processor scheduling algorithms
sometimes deal node rejecting task cannot fulfill time constraints
network failures  however  aa problem focuses failure get response
central issue load balancing auxiliary issue  multi processor scheduling
opposite focus  difference focus leads algorithms developed
multiprocessor scheduling community well suited aa  and vice versa  
  

conclusions

adjustable autonomy critical success real world agent systems allows
agent leverage skills  resources decision making abilities entities 
human agent  previous work addressed aa context single agent
single human scenarios  solutions scale increasingly complex multiagent systems  particular  previous work used rigid  one shot transfers control
consider team costs and  importantly  consider possibility costly

   

fiscerri  pynadath   tambe
miscoordination team members  indeed  applied rigid transfer of control
approach multi agent context  failed dramatically 
article makes three key contributions enable application aa
complex multiagent domains  first  article introduces notion transfer of control
strategy  transfer of control strategy consists conditional sequence two types
actions   i  actions transfer decision making control  ii  actions change
agent s pre specified coordination constraints team members  aimed minimizing
miscoordination costs  strategies allow agents plan sequences transfer of control
actions  thus  strategy allows agent transfer control entities best able make
decisions  buy time decisions made still avoid miscoordination   even
entity control transferred fails make decision  additionally 
introduced idea changing coordination constraints mechanism giving
agent opportunity provide high quality decisions  showed changes
can  cases  effective way increasing team s expected utility 
second contribution article mathematical model aa strategies
allows us calculate expected utility strategies  model shows
complex strategies indeed better single shot strategies situations 
always superior  fact  analysis showed particular strategy dominates
whole space aa decisions  instead  different strategies optimal different
situations 
third contribution article operationalization notion transferof control strategies via markov decision processes general reward function
leads mdp find optimal strategies multiagent context  general  domainindependent reward function allow approach potentially applied
multi agent domains  implemented  applied  tested mdp approach aa reasoning real world application supporting researchers daily activities  daily use
showed mdp approach effective balancing need avoid risky autonomous
decisions potential costly miscoordination  furthermore  detailed experiments
showed policies produced mdps desirable properties  transferring control user less often probability getting timely response low 
finally  practical experience system revealed users require ability manipulate aa reasoning agents  end  introduced constraint language
allows user limit range behavior mdp exhibit  presented
algorithm processing constraints  showed desirable property
reducing time takes find optimal policies 
  

future work

model aa presented article suciently rich model wide variety
interesting applications  however  key factors modeled
current formulation required domains  one key issue allow agent
factor aa reasoning agents aa reasoning  instance 
elves domain  one agent likely decide delay meeting  another agent may
wait decision avoid asking user  conversely  agent take
back control decision knows another agent going continue waiting user input 
   

fitowards adjustable autonomy real world
might continue wait input  interactions substantially increase
complexity reasoning agent needs perform  article  assumed
agent finding transfer of control strategy single  isolated decision 
general  many decisions made agent able
ignore interactions decisions  example  transferring control many
decisions user  reduces probability getting prompt response them 
reasoning interactions add complexity required reasoning
agent 
another focus future work generalizing aa decision making allow
types constraints   coordination constraints   taken account 
would turn require generalization concept action include types
stop gap actions may lead different types strategies agent could pursue 
additionally  transfer of control actions could generalized allow parts decision
transferred  e g   allow input received user without transferring total
control him her  allow actions could performed collaboratively  similarly 
actions reversible  agent could make decision allow user reverse
it  hope generalizations would improve applicability adjustable
autonomy research complex domains 
acknowledgments

research supported darpa award no  f                 effort
managed air force research labs rome site  article unifies  generalizes  significantly extends approaches described previous conference papers  scerri et al        
scerri  pynadath    tambe        pynadath   tambe         thank colleagues 
especially  craig knoblock  yolanda gil  hans chalupsky tom russ collaborating
electric elves project  would thank jair reviewers
useful comments 

   

fiscerri  pynadath   tambe
appendix a  example instantiation model

appendix  present detailed look one possible instantiation aa model 
use instantiation calculate eu commonly used strategies show
eu varies parameters rate wait cost accrual time
transfers control performed  instantiation  agent  a  one entity
call decision  i e   user u    hence e   fa  u g  w  t   use following
function 
 

 t
w  t       exp
exp  otherwise

    

exponential wait cost function ects idea big delay much worse
small one  polynomial similar function could used exponential
used since makes mathematics cleaner  probability response use 
p  t    exp   markovian response probability ects entity likely
respond next point time previous point  users moving around dynamic environment  turns reasonable approximation 
entities  decision making quality constant time  particular  eqda  t   
eqdu  t      assuming constant decision making quality always accurate
dynamic environment since information available entity may change  hence uencing
ability make decision  however  decisions involving static facts preferences
decision making quality relatively constant  functions coarse approximation range interesting applications  including e elves  table   shows resulting
instantiated equations simple strategies  for convenience let       figures
   a   b  show graphically eu ea strategy varies along different axes  w
parameter wait cost function  higher w means faster accruing wait costs
p parameter response probability function  higher p means faster response  
notice eu depends transfer time  t  much  the user s
decision quality   figure    d  shows value  as discussed earlier  
figure    c  compares eu e dea e strategies  complex
transfer of control strategy  i e   transfers control makes   atter
eu graph plotted wait cost  w  response probability  p  parameters 
particular  fall off wait costs high probability response low
dramatic complex strategy 

appendix b  constraint propagation algorithm correctness

section      examined need user specified constraints conjunction
mdp based approach strategies  must thus extend standard mdp policy
evaluation algorithms support evaluation strategies accounting
standard quantitative reward function new qualitative constraints  appendix
provides novel algorithm developed evaluate strategies accounting
   

fitowards adjustable autonomy real world

 
   
 
   
 
 

  
  
  
 
 
  

   
   

w    

   

   

  p

 

  

 a 

t  

  

  

 b 
value
    
    
    
    
 
     

 
 
  
   

w    

   

 

  
  
  
beta
 

   

   
   p

       
w           

 c 

 
    
    p
    

 d 

figure     equation     i e   strategy ea plotted  a     i e   w  rate
wait costs accrue   i e   p likelihood response   b   transfer
time and beta  the user s decision quality    c  comparing strategies e dea
e  dotted line e     d  value d 

   

fiscerri  pynadath   tambe


eued   exp   

    exp
euea

 

     exp



  

 
 fi


 ff

fi 

    

 
 fi


    

eueddeat  
    
 

value
   exp         exp       exp
 exp exp    


 dcost   exp exp       exp   exp  dvalue    exp exp  
exp  dcost     exp  exp   dvalue     exp  t dvalue     
table    instantiated aa eu equations simple transfer control strategies 
both  present detailed proof algorithm s output correct strategy
 i e   strategy highest expected utility  subject user specified constraints  
standard mdp value iteration algorithm  value strategy particular
state single number  expected utility u   addition two types
constraints  value tuple hf  n  u i  f represents strategy s ability satisfy
forbidding constraints  therefore  boolean indicating whether state forbidden
not  n represents strategy s ability satisfy necessary constraints  therefore 
set requiring constraints satisfied  traditional value iteration 
u expected reward  instance  value state  v  s    htrue  fcrs g     i 
executing policy state achieve expected value     satisfy
required state constraint crs   however  guaranteed satisfy requiredstate  required action  constraints  addition  forbidden  nonzero
probability violating forbidden action forbidden state constraint  record
forbidding constraints policy violates  since violating one equally
bad  record requiring constraints policy satisfies  since satisfying
constraints preferable satisfying them  therefore  size
value function grows linearly number requiring constraints  independent
number forbidding constraints 
following form standard value iteration  initialize value function
states considering immediate value strategy given state  without
lookahead  precisely 

v    s 

 

 

c cfs

 

c s   fc   crs jc s g   rs  s 

    

thus  state forbidden forbidden state constraints immediately apply 
satisfies required state constraints immediately apply  standard value
iteration  expected utility value reward function state 
   

fitowards adjustable autonomy real world
value iteration  must define updated value function v t   refinement
previous iteration s value function  v   states become forbidden v t  
violate constraints directly successors forbidden according v  
states satisfy requirements satisfy directly successors satisfy
requirement  simplify following expressions  define   set
successors  fs    jmssa      g  following expression provides precise definition
iterative step 
 

 
 
 
max
c s   
c s  a   
f   
a a c c

 
 
 
c cfa v  s   hf  n  u   i s   s  
fs
 
fc   crsjc s g   fc   cra jc s  a g   n   
v  s    hf    n    u   i s   s  
 
x
rs  s    r s  a    mssa   u  
    
v  s    hf    n    u   i s   s  
standard value iteration  iterative step specifies maximization possible choices action  however  two additional components represent value
strategy respect constraints  longer obvious comparison
function use evaluating candidate actions  therefore  perform maximization
using following preference ordering  x means preferable x 
ht  n  u

f  n    u  ff
hf  n  u
f  n   n  uff 
hf  n  u f  n  u     u

v t    s 

words  satisfying forbidden constraint takes highest priority  satisfying
requiring constraints second  increasing expected value last  define optimal
action  p  s   action  a  final v  s  expression maximized 
despite various set operations equation     time complexity iteration
step exceeds standard value iteration linear factor  namely number
constraints  jcfs j   jcfa j   jcrsj   jcra j  eciency derives fact
constraints satisfied violated independently other  determination whether
single constraint satisfied violated requires time standard value
iteration  hence overall linear increase time complexity 
expected value lowest priority  separate iterative step
equation    two phases  constraint propagation value iteration 
constraint propagation phase  compute first two components value function  hf  n  i  value iteration phase computes third component  h    u i 
standard value iteration  however  ignore state action pairs that  according
results constraint propagation  violate forbidding constraint  ht  n  i  requiring constraint  hf  n crs   cra   i   component wise independence
equation     two phase algorithm computes identical value function original 
single phase version  over state action pairs satisfy constraints  
rest appendix provide proof correctness modified value
iteration policy  given policy  p   constructed according algorithm  must
   

fiscerri  pynadath   tambe
show agent following p obey constraints specified user  agent
begins state      must prove satisfy constraints
v  s    hf  cra   crs   u i  prove results forbidding requiring constraints
separately 

theorem   agent following policy  p   value function  v   generated section      state   violate forbidding constraint probability zero
v  s    hf  n  u  for u n   
proof  prove theorem induction subspaces states  classified

 close  violating forbidding constraint  precisely  partition
state space    subsets  sk   defined contain states violate forbidding
constraint minimum k state transitions  words  s  contains states
violate forbidding constraint directly  s  contains states violate
forbidding constraints themselves  successor state  following transition
probability function  p    i e   successor state s     s  contains states
violate forbidding constraints  successors do 
least one successor state successor state  i e   successor state
s     etc  js j nonempty subsets mutually exclusive sequence 
make partition exhaustive  special subset  s    contains states
agent never violate forbidding constraint following p   first show  induction
k   s   sk    k js j   v  s    ht  n  u i  required theorem 
basis step  s    definition  agent violate forbidding constraint   s   
therefore  either  c   cfs c s     c   cfa c s  p  s     t 
know  equation     v  s    ht  n  u i 
inductive step  sk     k js j   assume  induction hypothesis   s   
sk     v  s      ht  n     u   i  definition sk   state    sk   least one
successor state  s    sk     then  according equation     v  s    ht  n  u i 
disjunction   must include s    f     t 
therefore  induction  know   sk    k js j   v  s    ht  n  u i 
show  s   s    v  s    hf  n  u i  prove  induction t  that 
state    s   v  s    hf  n  u i 
basis step  v      definition   
s    thereff cannot exist c   cfs
c s    t  then  equation     v    s    f  n     u    
inductive step  v         assume 
inductive
hypothesis  that  s    s   

v    s      hf  n     u   i  know v  s    f  n   u three disjunctions
equation    false  first false  described basis step  second term
similarly false  since  definition s   cannot exist c   cfa
c s  p  s     t  evaluating third term  first note   s   words 
successor states s   if successor s    sk finite k 
  sk     since successors s    know  inductive hypothesis 
disjunction v   successors
fffalse  therefore  three disjunctive


terms equation    false  v  s    f  n   u  
therefore  induction  know   s    v  s    hf  n  u i  definition
state partition  two results prove theorem required   
   

fitowards adjustable autonomy real world
theorem   agent following policy  p   value function  v   generated described
section      state   satisfy every requiring constraint
probability one v  s    hf  cra   crs   u  for u f   
proof sketch  proof parallels theorem    state partition  sk  
k corresponds maximum number transitions satisfying requiring
constraint  however  here  states s  violate constraint  rather

satisfy it  cycles state space prevent guarantee satisfying requiring
constraint within fixed number transitions  although probability satisfaction
limit may    current constraint semantics  decided
situation fails satisfy constraint  algorithm behaves accordingly  cycles
effect handling forbidding constraints  where  saw theorem   
need consider minimum  length trajectory   
proofs two theorems operate independently  policy specified action
satisfy constraints  action exists  precedence forbidding constraints
requiring ones effect optimal action states  however 
con icting forbidding requiring constraints state  preference ordering
causes agent choose policy satisfies forbidding constraint violates
requiring constraint  agent make opposite choice simply change
preference ordering section      regardless choice  theorems     
agent use value function  v   identify existence violation
notify user violation possible constraint con ict 
references

barber  k   goel  a     martin  c       a   dynamic adaptive autonomy multi agent
systems  journal experimental theoretical artificial intelligence              
    
barber  k  s   martin  c     mckay  r       b   communication protocol supporting
dynamic autonomy agreements  proceedings pricai      workshop teams
adjustable autonomy  pp        melbourne  australia 
bonasso  r   firby  r   gat  e   kortenkamp  d   miller  d     slack  m          experiences architecture intelligent reactive agents  journal experimental
theorectical artificial intelligence                 
brann  d   thurman  d     mitchell  c          human interaction lights out automation  field study  proceedings      symposium human interaction
complex systems  pp           dayton  usa 
cesta  a   collia  m     d aloisi  d          tailorable interactive agents scheduling
meetings  lecture notes ai  proceedings aimsa     no        pp          
springer verlag 
chalupsky  h   gil  y   knoblock  c   lerman  k   oh  j   pynadath  d   russ  t     tambe 
m          electric elves  applying agent technology support human organizations 
international conference innovative applications ai  pp        
   

fiscerri  pynadath   tambe
collins  j   bilot  c   gini  m     mobasher  b       a   mixed initiative decision support
agent based automated contracting  proceedings international conference
autonomous agents  agents       
collins  j   bilot  c   gini  m     mobasher  b       b   mixed initiative decision support
agent based automated contracting  proceedings international conference
autonomous agents  agents        pp          
dorais  g   bonasso  r   kortenkamp  d   pell  b     schreckenghost  d          adjustable
autonomy human centered autonomous systems mars  proceedings
first international conference mars society  pp          
draper  d   hanks  s     weld  d          probabilistic planning information gathering
contingent execution  hammond  k   ed    proc  second international conference artificial intelligence planning systems  pp         university chicago 
illinois  aaai press 
ferguson  g   allen  j     miller  b          trains      towards mixed initiative
planning assistant  proceedings third conference artificial intelligence
planning systems  pp        
ferguson  g     allen  j          trips   intelligent integrated problem solving assistant  proceedings fifteenth national conference artificial intelligence aaai     pp           madison  wi  usa 
fong  t   thorpe  c     baur  c          robot partner  vehicle teleoperation collaborative control  workshop multi robot systems  naval research laboratory 
washington  d c 
fudenberg  d     tirole  j          game theory  mit press  cambridge  massachusetts 
goldman  r   guerlain  s   miller  c     musliner  d          integrated task representation indirect interaction  working notes aaai spring symposium
computational models mixed initiative interaction 
goodrich  m   olsen  d   crandall  j     palmer  t          experiments adjustable
autonomy  hexmoor  h   castelfranchi  c   falcone  r     cox  m   eds    proceedings ijcai workshop autonomy  delegation control  interacting
intelligent agents 
gunderson  j     martin  w          effects uncertainty variable autonomy maintainance robots  agents    workshop autonomy control software  pp        
hexmoor  h          cognitive model situated autonomy  proceedings pricai      workshop teams adjustable autonomy  pp         melbourne  australia 
hexmoor  h     kortenkamp  d          introduction autonomy control software  journal
experiemental theoretical artificial intelligence                  
horvitz  e          principles mixed initiative user interfaces  proceedings acm
sigchi conference human factors computing systems  chi      pp          
pittsburgh  pa 
   

fitowards adjustable autonomy real world
horvitz  e   jacobs  a     hovel  d          attention sensitive alerting  proceedings
conference uncertainty artificial intelligence  uai      pp           stockholm  sweden 
lesser  v   atighetchi  m   benyo  b   horling  b   raja  a   vincent  r   wagner  t   xuan 
p     zhang  s          umass intelligent home project  proceedings
third annual conference autonomous agents  pp           seattle  usa 
mitchell  t   caruana  r   freitag  d   mcdermott  j     zabowski  d          experience
learning personal assistant  communications acm                
mulsiner  d     pell  b          call papers  aaai spring symposium adjustable
autonomy  www aaai org 
musliner  d     krebsbach  k          adjustable autonomy procedural control
refineries  aaai spring symposium agents adjustable autonomy  pp 
       stanford  california 
peot  m  a     smith  d  e          conditional nonlinear planning  hendler  j   ed   
proc  first international conference artificial intelligence planning systems  pp 
         college park  maryland  morgan kaufmann 
puterman  m  l          markov decision processes  john wiley   sons 
pynadath  d   tambe  m   arens  y   chalupsky  h   gil  y   knoblock  c   lee  h   lerman 
k   oh  j   kamachandran  s   rosenbloom  p     russ  t          electric elves 
immersing agent organization human organization  proceedings
aaai fall symposium socially intelligent agents   human loop 
pynadath  d     tambe  m          revisiting asimov s first law  response call
arms  intelligent agents viii proceedings international workshop agents 
theories  architectures languages  atal     
quinlan  j  r          c     programs machine learning  morgan kaufmann  san
mateo  ca 
russell  s  j     wefald  e          principles metareasoning  brachman  r  j  
levesque  h  j     reiter  r   eds    kr     principles knowledge representation
reasoning  pp           morgan kaufmann  san mateo  california 
scerri  p   pynadath  d     tambe  m          adjustable autonomy real world multiagent environments  proceedings fifth international conference autonomous agents  agents      pp          
scerri  p   pynadath  d     tambe  m          elf acted autonomously  towards
theory adjustable autonomy  first international joint conference autonomous agents multi agent systems  aamas     
schreckenghost  d          human interaction control software supporting adjustable
autonomy  musliner  d     pell  b   eds    agents adjustable autonomy 
aaai      spring symposium series  pp          
stankovic  j   ramamritham  k     cheng  s          evaluation exible task scheduling algorithm distributed hard real time system  ieee transactions computers                     
   

fiscerri  pynadath   tambe
tambe  m          towards exible teamwork  journal artificial intelligence research
 jair             
tambe  m   pynadath  d  v   chauvat  n   das  a     kaminka  g  a          adaptive
agent integration architectures heterogeneous team members  proceedings
international conference multiagent systems  pp          
zilberstein  s          using anytime algorithms intelligent systems  ai magazine         
      

   


