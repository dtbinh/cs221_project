journal of artificial intelligence research                 

submitted       published      

storing and indexing plan derivations through
explanation based analysis of retrieval failures
laurie h  ihrig
subbarao kambhampati

department of computer science and engineering
arizona state university
tempe  az           

ihrig asu edu
rao asu edu

abstract

case based planning  cbp  provides a way of scaling up domain independent planning
to solve large problems in complex domains  it replaces the detailed and lengthy search
for a solution with the retrieval and adaptation of previous planning experiences  in general  cbp has been demonstrated to improve performance over generative  from scratch 
planning  however  the performance improvements it provides are dependent on adequate
judgements as to problem similarity  in particular  although cbp may substantially reduce planning effort overall  it is subject to a mis retrieval problem  the success of cbp
depends on these retrieval errors being relatively rare  this paper describes the design and
implementation of a replay framework for the case based planner dersnlp ebl  dersnlp ebl extends current cbp methodology by incorporating explanation based learning
techniques that allow it to explain and learn from the retrieval failures it encounters  these
techniques are used to refine judgements about case similarity in response to feedback when
a wrong decision has been made  the same failure analysis is used in building the case
library  through the addition of repairing cases  large problems are split and stored as
single goal subproblems  multi goal problems are stored only when these smaller cases fail
to be merged into a full solution  an empirical evaluation of this approach demonstrates
the advantage of learning from experienced retrieval failure 

   introduction
case based planning improves the eciency of plan generation by taking advantage of previous problem solving experiences  it has been shown to be an effective method for scaling
up domain independent planning to solve large problems in complex domains  kambhampati   hendler        veloso         cbp involves storing information about the particular
planning episodes in which problems are successfully solved  this information may include
the goals that were achieved  the world state conditions which were found to be relevant
to their achievement  the final plan and the decisions that were taken in arriving at this
plan  whenever a new problem is encountered  a judgment is made about its similarity to
these previous experiences  similar cases are then reused and extended in the search for a
solution to the new problem  for example  the previous plan may be transformed into a
skeletal plan which is then further refined into a new solution  friedland   iwasaki       
kambhampati   hendler        hanks   weld         multiple cases  each corresponding
to a small subproblem  may be combined and extended in solving a single larger problem
 redmond        ram   francis         alternatively  plan derivations may be replayed
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fiihrig   kambhampati

to provide guidance to a new search process  veloso        ihrig   kambhampati      a  
cbp improves problem solving in that problems are solved in less time in comparison to
generative planning 
one of the most challenging tasks in cbp is in determining which cases to store and how
to match these cases to a new problem solving context  in a complex domain  it is unlikely
that the same problem will be seen more than once  moreover  if every problem solved
is stored  the library will be large and the cost associated with retrieval may overshadow
any gains that it provides  koehler        francis   ram         ultimately  we would
like to retain in the library a minimum number of cases such that all new problems are
solved through the ecient retrieval and adaptation of the cases that are stored  smyth  
keane         however  in complex domains  the planner s theory of problem similarity is
incomplete  barletta   mark         it does not have information about all of the relevant
features of a new situation which determine if a stored case will be applicable  sometimes
a new problem will contain extra goals and or changed initial state conditions  these
changes may mean that a solution cannot be found which is consistent with the earlier
planning decisions made in a stored episode  if the planner cannot predict ahead of time
that these previous choices are wrong for the current situation  it will experience a retrieval
error 
in this paper  we introduce dersnlp ebl  derivational systematic nonlinear planner
  explanation based learning   a cbp system which like priar  kambhampati   hendler 
      and spa  hanks   weld        is based on a sound and complete domain independent
planner  dersnlp ebl deals with the mis retrieval problem by allowing the planner to
learn from its planning failures so that it may anticipate future errors  failure explanations
are automatically generated from the search process which is used in extending the case to
the new problem solving situation  these are used in building the case library through the
addition of repairing cases 
although earlier systems such as chef  hammond        have exploited ebl techniques  their use is restricted to reasoning about the correctness of the plans generated by
the case based planner  in contrast  dersnlp ebl starts with a sound and complete plan
synthesis strategy  the emphasis here is on improving the performance of the base level
planner through the guidance of the retrieved cases  this guidance is considered to succeed
if it leads the planner down a search path leading to a solution to the new problem  a
retrieval error occurs when the planner is directed down a wrong path in its search for a
solution  that is  a path that does not lead to a solution  dersnlp ebl extends current
cbp methodology through ebl techniques which are employed in the automatic generation of reasons for a retrieval failure  analytical failures that occur in the leaf nodes of
the search tree are explained in terms of subsets of conicting plan constraints  these leaf
node failure explanations are regressed up the failing search paths to form a reason for the
retrieval failure 
dersnlp ebl builds and indexes the case library based on this failure analysis  the
failure reason is used in the construction of a new repairing case  for example  if a retrieved
case fails due to the presence of an extra interacting goal which is not covered in the retrieved
episodes  an explanation for the failure is formed which identifies the subset of new input
goals which are negatively interacting  the failure reason is used to construct a new case
which solves those goals alone  the same failure analysis is also employed in refining the
   

fistoring and indexing plan derivations

retriever

library

cases problem

planning
problem

storer

plan derivation
case failure reason

case based planner
replay extension recovery 

problem
solution

domain operators

figure    a schematic diagram illustrating the approach of dersnlp ebl 
indexing in the case library to both censor the retrieval of the failing case whenever the
interacting goals are present again  and to direct the retriever to a new repairing case which
avoids the failure 
dersnlp ebl s failure based storage strategy limits the size of the case library  library
size is reduced by splitting problems into single goal subproblems  and storing these separately  large problems are then solved through the retrieval and adaptation of multiple
instances of these smaller cases  multi goal problems are stored only when the retrieved
cases fail to be merged and extended into a full solution  we will describe empirical studies
which demonstrate substantial improvements in performance with this novel approach to
multi case adaptation 
the remainder of the paper is organized as follows  section   describes how dersnlp ebl learns from case failure to improve its case retrieval  it also reports some
preliminary experiments testing this learning component  section   provides ecient techniques used to store  retrieve and adapt multiple cases  it describes experiments to test
dersnlp ebl s method of plan merging  section   describes an evaluation of the full dersnlp ebl system when solving large problems drawn from a complex domain  section  
relates our work to previous case based planners  including chef and prodigy analogy 
section   provides a summary 

   learning from case failure
as stated earlier  dersnlp ebl is based on a complete and correct domain independent
planning strategy  like priar  kambhampati   hendler        and spa  hanks   weld 
       it is implemented on a partial order planner  in this aspect it differs from statespace systems such as prodigy analogy  veloso   carbonell      a  veloso        and
paris  bergmann   wilke         like prodigy analogy  it employs the case adaptation
strategy  derivational replay which stores planning experience in the form of successful plan
derivations  previous decisions made in earlier planning episodes become instructions to
guide the search process in solving the new problem  derivational replay includes all of the
following elements  as illustrated in figure    veloso        veloso   carbonell      a   a
facility within the underlying planner to generate a trace of the derivation of a plan  the
   

fiihrig   kambhampati

null
plan

skeletal
plan
e 

final
plan

x
e  x e  x
                                       depth limit
x

figure    multiple derivation traces  each a sequence of decisions shown in the figure as
rectangles  are used to guide the new search process  in the figure  a solution
could be reached only by backtracking over the skeletal plan  which now lies
outside the new plan derivation  shown as filled circles  
indexing and storage of the derivation trace in a library of previous cases  the retrieval of
multiple cases in preparation for solving a new problem  and finally  a replay mechanism
by which the planner employs the retrieved plan derivations as a sequence of instructions
to guide the new search process 
dersnlp ebl s methodology depends on aspects that it has in common with molgen
 friedland   iwasaki        and priar  kambhampati   hendler         it requires an
eager case adaptation strategy  so that a skeletal plan will be constructed which contains
all of the constraints added on the advice of the retrieved cases  and only those constraints 
this is to separate the failure resulting from the previous guidance from any subsequent
planning effort  in eager case adaptation  the planning decisions which are encapsulated
in the retrieved cases are greedily adopted before these decisions are extended to solve any
extra goals not covered  multiple retrieved plan derivations are replayed in sequence to
produce the skeletal plan which then contains all of the recommended plan constraints 
the planner returns to from scratch planning only after all of the previous decisions in
the retrieved cases have been visited  the skeletal plan is then further refined to achieve
any goals left open  previous work has demonstrated the effectiveness of this approach to
plan space replay as well as its advantage over state space replay  ihrig   kambhampati 
    a      b  
eager case adaptation can also be described as extension first  the skeletal plan is
first extended in the search for a solution  and  only after this extension fails  is the plan
backtracked over  discarding the plan constraints which were added on the advice of previous
episodes  the general approach to case adaptation therefore involves three distinct phases 
case replay  case extension  and  if extension fails  recovery  during the search process
employed in extending the skeletal plan  the planner constructs an explanation for the
plan s failure which becomes a reason for the case retrieval failure  explanations are formed
for the analytical failures that occur in the leaf nodes directly under the skeletal plan  see
figure     an analytical failure is explained by a set of inconsistent plan constraints  these
failure explanations are immediately regressed up the search paths as they are encountered 
the regressed explanations are collected at the root of the tree to form a reason for the
   

fistoring and indexing plan derivations

l 

l 

ob 

ld

ld

lp

lp

l 

ob 

l 

 b  new problem with extra
goal

 a  previous plan

figure     a  a plan to accomplish the transport of a single package  ob   to the destination
airport ld    b  a new problem contains an extra goal which involves the additional
transport to ld of a second package  ob  
retrieval error  dersnlp ebl detects that a retrieval error has occurred when all ways
of refining the skeletal plan have been tried  and the planner is forced to backtrack over
this plan  at this point the failure reason is fully constructed  performing skeletal plan
extension as a separate process prior to recovery allows the planner to identify the retrieval
error in terms of the failure of the skeletal plan  and to construct a reason for the failure 
this reason is then communicated to the storer to be used in augmenting the library with
a new repairing case 
consider a simple example illustrated in figure   which is taken from the logistics
transportation domain shown in figure    the goal is to have package ob  located at the
destination location ld  the package is initially at location l    there is a plane located at
lp which can be used to transport the package  figure  a illustrates a previous plan which
contains steps that determine the plane s route to the destination airport as well as steps
which accomplish the loading of the package at the right place along this route  eagerly
replaying these earlier step addition decisions for a new problem in which there is an extra
package to transport produces a skeletal plan which may readily be extended to include
the loading and unloading of the extra package as long as this package lies along the same
route  however  if the new package is off the old route  the planner may not be able to
solve the extra goal without backtracking over some of its previous step addition decisions 
 see figure  b  
a case failure reason is shown in figure    it gives the conditions under which a future
replay of the case will again result in failure  these conditions refer to the presence in
the new problem of a set  c   of negatively interacting goals  as well as some initial state
conditions  contained in e   a summary of the information content of the failure reason is 
there is an extra package to transport to the same destination location  and that package
is not at the destination location  is not inside the plane  and is not located on the plane s
route 
   

fiihrig   kambhampati

action
precond
add
delete

 load truck  o  t  l 
 at ob  o  l 
 at tr  t  l 
 inside tr  o  t 
 at ob  o  l 

action
precond
add
delete

 load plane  o  p  l 
 at ob  o  l 
 at pl  p  l 
 inside pl  o  p 
 at ob  o  l 

action
precond
add
delete

 unload truck  o  t  l 
 inside tr  o  t 
 at tr  t  l 
 at ob  o  l 
 inside tr  o  t 

action
precond
add
delete

 unload plane  o  p  li 
 inside pl  o  a 
 at pl  p  li 
 at ob  o  li 
 inside pl  o  a 

action
precond
add
delete
equals

 drive truck  t  li  lg 
 at tr  t  li 
 same city  li  lg 
 at tr  t  lg 
 at tr  t  li 
 not   li  lg  

action
precond
add
delete
equals

 fly plane  p  li  lg 
 is a airport  lg 
 at pl  p  li  
 at pl  p  lg 
 at pl  p  li 
 not   li  lg  

figure    the specification of the logistics transportation domain adapted for our experiments
subsequent to backtracking over the skeletal plan  the planner continues its search  and
will go on to find a solution to the full problem if one exists  this new solution achieves
all of the negatively interacting goals identified in the failure reason  moreover  since these
goals represent a subset of the problem goals  the new derivation may be used to construct
a case covering these goals alone  dersnlp ebl stores the new case directly beneath the
failing case so as to censor its retrieval  this is to ensure that whenever the failure reason
holds  for example  whenever there is an extra package which is off the plane s route   the
retriever is directed away from the failing case and toward the case that repairs the failure 
we are now in a position to describe in more detail dersnlp ebl s eager derivation
replay strategy  as well as how it learns the reasons underlying a case failure 

    eager derivation replay

the derivation trace contains a sequence of instructions representing the choices that lie
along the derivation path leading from the root of the search tree to the final plan in the leaf
node  the trace is fitted to the context of the new search process by validating each choice
in the new context  and replaying the decision if valid  in order to understand the validation
process  we must first describe the decision steps that the planner takes in arriving at a
solution to a planning problem  a planning problem is a   tuple hi  g  ai  where i is a
complete description of the initial state  g is the description of the goal state  and a is
the set of operators in strips representation  fikes   nilsson         a ground operator
sequence is said to be a solution for a planning problem if it can be executed from the initial
state  and the resulting state of the world satisfies the goal 
dersnlp ebl is a refinement planner that solves a planning problem by navigating a
space of potential solutions  each represented as a partly constructed plan    syntactically  a
   for a more formal development of the refinement search semantics of partial plans  we refer the reader
to the work of kambhampati  knoblock  and yang        

   

fistoring and indexing plan derivations

case failure explanation 
c   f h at ob ob  ld   tg i  h at ob ob  ld   tg i g
e   f hti     at ob ob  ld i  hti     inside pl ob   pl  i 
hti     at ob ob  l  i  hti     at ob ob  lp i g

figure    an example of a case failure reason
plan in this space p can be seen as a set of constraints  see below   semantically  a partial
plan is a shorthand notation for the set of ground operator sequences that are consistent
with its constraints  the latter is called the candidate set of the partial plan  and is denoted
by hhpii  in particular  a partial plan is represented as a   tuple  hs   o  b  l  e   ci  where
   s is the set of actions  step names  in the plan  each of which is mapped onto an
operator in the domain theory  s contains two dummy steps  ti whose effects are the
initial state conditions  and tg whose preconditions are the input goals  g 
   b is a set of codesignation  binding  and non codesignation  prohibited binding  constraints on the variables appearing in the preconditions and post conditions of the
operators which are represented in the plan steps  s  
   o is a partial ordering relation on s   representing the ordering constraints over the
steps in s  
   l is a set of causal links of the form hs  p  s  i where s  s    s  
   e contains step effects  represented as hs  ei  where s   s  
   c is a set of open conditions of the partial plan  each of which is a tuple hp  si such
that p is a precondition of step s and there is no link supporting p at s in l 
planning consists of starting with a null plan  denoted by p     whose candidate set
corresponds to all possible ground operator sequences  and successively refining the plan by
adding constraints until a solution is reached  each planning decision represents a choice as
to how to resolve an existing aw in the plan  which is either an open condition  unachieved
goal  or a threat to a causal link  to understand how these choices are validated during
the replay process it is useful to think of a planning decision as an operator acting on
a partly constructed plan  the possible choices available to dersnlp ebl are shown in
figure   
planning decisions have preconditions which are based on the existence of a aw in
the current active plan and have effects which alter the constraints so as to eliminate the
aw  for example  the precondition of an establishment choice is specified in terms of the
existence of an unachieved subgoal  the effect is the addition of a causal link that achieves
this open condition  the precondition of a resolution decision is a threat in that one step
is clobbering an existing causal link  a threat is resolved by adding a step ordering which
either promotes or demotes the clobberer relative to the causal link 
   

fiihrig   kambhampati

type   establishment
kind   new step
preconditions
 
hp    s  i   c
effects
 
s      s   fsg  
o    o   fs  s g  
b     b   unify p   p  
l   l   fhs  p s ig
e    e   effects
 s 
c   c   fhp    s  ig
  preconditions s 

type   establishment
kind   new link
preconditions
 
hp    s  i   c
effects
 
o     o   fs  s  g  
b     b   unify p   p  
l    l   fhs p 
s ig
c   c   fhp    s  ig

type   resolution
kind   promotion
preconditions
 
 
 

hs  p   s i   l
ht   p i   e
ft  sg  fs  tg    o
effects  
o   o   ft  sg
 

 

 

type   resolution
kind   demotion
preconditions
 
 
 

hs  p   s i   l
ht   p i   e
ft  sg  fs  tg    o
effects  
o   o   fs  tg
 

 

 

 

figure    planning decisions are based on the active plan hs   o  b  l  e   ci and have effects which alter the constraints so as to produce the new current active plan
hs     o    b    l    e     c   i 
before a decision is replayed  it is first compared with the current active plan to determine whether its precondition holds in the new context  invalid decisions  those whose
preconditions don t match  are skipped  establishment decisions are ignored if the goals
they achieve are not present as open conditions in the current active plan  threat resolutions are skipped if the threat is not present  previous choices which are justified in the
current situation are used as guidance to direct the new search process  replaying a valid
decision involves selecting a match for that decision from the children of the current active
plan  and making this child the next plan refinement 
dersnlp ebl s eager derivation replay strategy replays all of the applicable decisions
in the trace in sequence  this replay strategy can be contrasted with that of
prodigy analogy  veloso        where replay is alternated with from scratch planning
for extra goals not covered by a case  in eager derivation replay each previous decision
is eagerly adopted if justified in the current context  since invalid instructions have been
skipped  the skeletal plan which is the end result of replay is comparable to the product of
the fitting phase in plan reuse  kambhampati   hendler        hanks   weld         in
contrast to plan reuse  derivation replay does not alter the underlying planning strategy 
replay merely provides search control  directing the search as to which node to visit next 
this means that dersnlp ebl inherits all of the properties of snlp  including soundness 
completeness  and systematicity 
a sample trace of snlp s decision process is shown in figure    the trace corresponds
to a simple problem from the logistics transportation domain of  veloso        adapted for
snlp as in figure    this problem contains the goal of getting a single package  ob   to a
designated airport  ld   the derivation trace contains the choices that were made along the
path from the root of the search tree to the final plan in the leaf node  instructions contain
a description of both the decision taken and its basis for justification in a new context 

    eager case extension and recovery
the decisions in the trace that are skipped during replay are only those that are known a
priori to be unjustified  this does not guarantee that the skeletal plan which is left will
   

fistoring and indexing plan derivations

goal    at ob ob  ld  
initial     is a airport ld    is a airport li   
 is a airport lp    at pl pl  lp  
 at ob ob  li      
name   g 
name   g 
type   start node
type   establishment
name   g 
kind   new link
type   establishment
new link      is a airport ld     
kind   new step
open cond    is a airport ld     
new step   unload pl ob   p  ld  
name   g 
new link      at ob ob  ld   goal 
type   establishment
open cond    at ob ob  ld   goal 
kind   new step
name   g 
new step   load pl ob  pl   a  
type   establishment
new link      inside pl ob  pl     
kind   new step
open cond    inside pl ob  pl     
new step   fly pl  p   a  ld  
name   g 
new link      at pl  p  ld     
type   establishment
open cond    at pl  p  ld     
kind   new link
name   g 
new link      at pl pl  li     
type   establishment
open cond    at pl pl   a     
kind   new step
name   g  
new step   fly pl  p   a   a  
type   resolution
new link      at pl  p   a     
kind   promotion
open cond    at pl  p   a     
unsafe link        at pl pl  li     
name   g 
effect       at pl pl  li   
type   establishment
name   g  
kind   new link
type   establishment
new link      at pl pl  lp     
kind   new link
open cond    at pl  p   a     
new link      at ob ob  li     
name   g 
open cond    at ob ob  li     
type   establishment
key to abbreviations 
kind   new link
pl   plane
new link      is a airport li     
ob   object
open cond    is a airport  a     
final plan   fly pl pl  lp li   created  
 load pl ob  pl  li   created  
 fly pl pl  li ld   created  
 unload pl ob  pl  ld   created  
ordering of steps                                           

figure    an example solution trace for dersnlp ebl

   

fiihrig   kambhampati

  dms    
 affi precond   fii  pff g add   fgig delete   fij jj   ig 
 afii precond   fii pfi g add   fgig delete   fij jj   ig 
 aff precond   fg add   fgff g delete   fpfi g   fgij ig 

figure    the specification of barrett and weld s transformed dm s  domain
ultimately be refined into a solution for the current problem  without actually completing
the search there is no way of predicting whether the constraints that are left in the skeletal
plan are consistent with a complete solution  whenever the skeletal plan is not complete
 whenever there are extra goals or unsatisfied initial state conditions  the planner must
undergo further planning effort to extend the plan and there is a possibility that this effort
may fail  necessitating a recovery phase 
for dersnlp ebl  the skeletal plan is extended first  prior to recovery  this plan is
backtracked over only after the search process fails to refine it into a full solution to the new
problem  this strategy requires a depth limit to be placed on the search tree    otherwise
skeletal plan extension may continue indefinitely  and the planning algorithm becomes incomplete  an eager extension strategy is not  however  linked to a particular search method 
for example  it may be used with best first  depth first or iterative deepening search  these
different search methods are used in the exploration of the subtree under the skeletal plan 
prior to backtracking over this plan  once the skeletal plan is found to fail  the recovery
phase that is initiated merely involves exploring the siblings of the replayed path  like
extension  recovery is not linked to a particular search strategy 

    analyzing the failure of case extension

in order for the skeletal plan to be successfully extended to achieve any conditions left open 
the sequence of decisions that were adopted through the guidance of a previous trace must
be concatenated with further choices to arrive at a solution  for this to occur  the replayed
path must be decision sequencable with respect to the new problem  which is defined as
follows 

definition    decision sequencable search path  a search path which contains a sequence of decisions d is decision sequencable with respect to a new problem  hi     g    ai   if
and only if there exist two decision sequences e and e   such that e  d  e    where    is
the decision sequencing operator  will produce a plan which is correct for hi     g    ai 
one of the primary reasons a replayed path may not be decision sequencable is the goal
interactions that occur between the input goals of the new problem  in particular  the extra
goals not achieved by a case may interact with those that are covered  making the retrieved
case inapplicable  it has long been recognized that the relative diculty of problem solving
is linked to the level of interaction between the various input goals of the problem  korf 
      joslin   roach        barrett   weld        veloso   blythe        kambhampati 
   in practice  this limit is actually a bound placed on the number of steps contained in the plan 

   

fistoring and indexing plan derivations

ihrig    srivastava      a   goal interaction has been formalized by korf        in terms
of the problem search space  barrett and weld        extend korf s analysis into plan
space  for the plan space planner  the order in which goals are achieved is not as crucial 
goals that are laboriously serializable for a state space planner  in that there exist few goal
orderings for which the goals may be solved in sequence  may be trivially serializable for a
plan space planner  meaning that the goals can be solved in any order  
however  goals are not always trivially serializable for the plan space planner  veloso  
blythe         for example  consider the  dm s   domain  barrett   weld        shown
in figure    notice that if gff is one of a set of problem goals  and it is not true initially 
then any other goal  gi   that is present in the set must be achieved by the operator affi  and
not by afii   this means that any time a case is replayed that previously solved a goal  gi  
through an action afii   and gff is an extra goal not covered by the case  replay will fail 
in cbp  however  we are not so much concerned with the general properties of the
domain  as we are with properties of the particular search paths which are stored in the
case library  it is not required that the input goals of every problem be trivially serializable
for cbp to be beneficial to planning performance  if it were  there would be very few
domains in which cbp was effective  trivial serializability is not a requirement since it
is not necessary that every plan for every subset of the input goals be consistent with a
solution to the full problem  it is only the particular plans that are retrieved from the
library that we are concerned with 
even if the goals of the problem are not trivially serializable  replay may be decision
sequencable  depending on which cases are actually retrieved from the library  in the
  dm s   domain  if the single goal cases that are retrieved solve gi through the action afii  
then these will not be decision sequencable with any new multi goal problem which contains
the goal gff   however if the stored cases are solved through affi   then replay of these cases
will be sequencable  in fact  the aim of the dersnlp ebl s learning component is to achieve
an indexing within the case library such that all of the new problems encountered by the
planner may be solved through sequenced replay of the cases retrieved from that library 
the next section describes how dersnlp ebl is able to work towards this objective through
its learning component which learns from replay failures 

    constructing reasons for retrieval failure
dersnlp ebl constructs explanations for retrieval failures through the use of explanationbased learning techniques which allow the planner to explain the failures of individual plans
in the planner s search space  a leaf node plan represents an analytical failure when it
contains a set of inconsistent constraints which prevent the plan from being further refined
into a solution  an analytical failure is explained in terms of these constraints  kambhampati  katukam    qu      b   leaf node failure explanations identify a minimal set of
constraints in the plan which are together inconsistent  dersnlp ebl forms explanations
for each of the analytical failures that occur in the subtree directly under the skeletal plan 
these are regressed up the failing search paths and are collected at the root of the tree to
form a reason for the retrieval failure  see figure  a   the regressed explanation is in terms
of the new problem specification  it contains a subset of interacting goals  as well as initial
state conditions relevant to those goals 

   

fiihrig   kambhampati

null
plan

e  

   at ob ob  ld   tg  
 ti     at ob ob  ld    

e f  
df  
e f
df
e 

null
plan

   at ob ob  ld   tg  
 ti     at ob ob  ld   

skeletal
plan

df  
df

skeletal
plan

x

x
e 

x

e 

x

  ti    at ob ob  ld    tg  
  ti     at ob ob  ld   

 a  the regression process

 b  a detailed example

figure    the path failure explanation at the root of the tree is computed as e     d      d     
   d f   e        
since a plan failure is explained by a subset of its constraints  failure explanations are
represented in the same manner as the plan itself  recall that dersnlp ebl represents
its plans as a   tuple  hs   o  b  l  e   ci  see section     the explanation for the failure
occurring at a leaf node contains only the constraints which contribute to an inconsistency 
these inconsistencies appear when new constraints are added which conict with existing
constraints  as discussed in section    dersnlp ebl makes two types of decisions  establishment and resolution  each type of decision may result in a plan failure  an establishment
decision represents a choice as to a method of achieving an open condition  either through
a new existing step  or by adding a causal link from the initial state  when an attempt is
made to achieve a condition by linking to an initial state effect  and this condition is not
satisfied in the initial state  the plan then contains a contradiction  an explanation for the
failure is constructed which identifies the two conicting constraints 

h         fhti   p  sig  fhti    pig   i

the precondition of a resolution decision is a threat to a causal link  dersnlp ebl
uses two methods of resolving a threat  promotion and demotion  each of which adds a step
ordering to the plan  when either decision adds an ordering which conicts with an existing
ordering  an explanation of the failure identifies the conict 

h   fs  s    s   sg            i

each of the conicting constraints in the failure explanation is regressed through the final
decision  and the results are sorted according to type to form the new regressed explanation 
this process is illustrated graphically in figure  b  in this example  a new link from the
initial state results in a failure  the explanation  e  is 
h         fhti    at ob ob   ld    tg ig  fhti     at ob ob   ld ig   i
   

fistoring and indexing plan derivations

when e  is regressed through the final decision  df   to obtain a new explanation  the initial
state effect regresses to itself  however  since the link in the explanation was added by the
decision  df   this link regresses to the open condition which was a precondition of adding
the link  the new explanation  ef    is therefore

h            fhti     at ob ob   ld ig  fh at ob ob   ld    tg igi

the regression process continues up the failing path until it reaches the root of the search
tree  when all of the paths in the subtree underneath the skeletal plan have failed  the
failure reason at the root of the tree provides the reason for the failure of the retrieved
cases  it represents a combined explanation for all of the path failures  the case failure
reason contains only the aspects of the new problem which were responsible for the failure 
it may contain only a subset of the problem goals  also  any of the initial state effects that
are present in a leaf node explanation  are also present in the reason for case failure   

    an empirical evaluation of the utility of case failure analysis

a preliminary study was conducted with the aim of demonstrating the advantage of storing
and retrieving cases on the basis of experienced retrieval failure  domains were chosen in
which randomly generated problems contained negatively interacting goals  and planning
performance was tested when dersnlp ebl was solving multi goal problems from scratch
and through replay of single cases covering a smaller subset of goals  replay performance
was tested both with and without case failure information 
      domains

experiments were run on problems drawn from two domains  the first was the artificial
domain    dms    originally described in  barrett   weld        and shown in figure   
testing was done on problems which were randomly generated from this domain with the
restriction that they always contain the goal gff   the logistics transportation domain of
 veloso        was adopted for the second set of experiments  eight packages and one
airplane were randomly distributed over four cities  problem goals represented the task of
getting one or more packages to a single destination airport   the fly operator was augmented with a delete condition which prevented planes from visiting the same airport more
than once  this meant that replay failed if there was an extra package to be transported
which was off the previous route taken by the plane 
      retrieval strategy

cases were initially retrieved on the basis of a static similarity metric which takes into
account the goals that are covered by the case as well as all of their relevant initial state
conditions  kambhampati        veloso         prior studies show it to be a reasonably
   dersnlp ebl s ebl component explains only analytical failures  depth limit failures are ignored  this
means that the failure explanations that are formed are not sound in the case of a depth limit failure 
and that the retriever may reject a case when it is applicable  rejecting an applicable case may lead to
the storage of duplicate cases and a larger library size  however  our empirical work has not shown this
to be of practical importance for reasons outlined in section       
   for a more comprehensive evaluation over an unbiased problem set see section   

   

fiihrig   kambhampati

effective metric  in learning mode  cases were also retrieved on the same basis  however 
in this mode  the failure reasons attached to the case were used to censor its retrieval 
each time that a case was retrieved in learning mode  these failure conditions were also
tested  if each failure reason was not satisfied in the new problem specification  the retrieval
mechanism returned the case for replay  if  on the other hand  a failure reason was found to
be true in the new problem context  then the case that repaired the failure was retrieved 
following retrieval  the problem was solved both by replay of the retrieved case as well as
by planning from scratch 
      experimental setup

each experiment consisted of three phases  each phase corresponding to an increase in
problem size  goals were randomly selected for each problem  and  in the case of the
logistics domain  the initial state was also randomly varied between problems  in an initial
training session that took place at the start of each phase n     n goal problems were solved
from scratch  and each derivation trace was stored in the library  following training  the
testing session consisted of generating problems in the same manner but with an additional
goal  each time that a new  n     goal problem was tried  an attempt was made to retrieve
a similar n goal problem from the library  if during the testing session  a case that was
similar to the new problem was found which had previously failed  then the problem was
solved in learning  static and from scratch modes  and it became part of the    problem
set  with this method  we were able to evaluate the improvements provided by failurebased retrieval when retrieval on the static metric alone was ineffective  and when failure
conditions were available 
      experimental results

the results of the experiments are shown in tables   and    each table entry represents
cumulative results obtained from the sequence of    problems corresponding to one phase of
the experiment  the first row of table   shows the percentage of problems correctly solved
within the time limit      seconds   the average solution length is shown in parentheses
for the logistics domain  solution length was omitted in   dms   since all of the problems
generated within a phase have the same solution length   the second and third rows of
table   contain respectively the total number of search nodes visited for all of the    test
problems  and the total cpu time  including case retrieval time  
these results are also summarized in figure     dersnlp ebl in learning mode was
able to solve as many of the multi goal problems as in the other two modes and did so
in substantially less time  case retrieval based on case failure resulted in performance
improvements which increased with problem size  comparable improvements were not
found when retrieval was based on the static similarity metric alone  this should not be
surprising since cases were retrieved that had experienced at least one earlier failure  this
meant that testing was done on cases that had some likelihood of failing if retrieval was
based on the static metric 
table   records three different measures which reect the effectiveness of replay  the first
is the percentage of sequenced replay  recall that replay of a trace is considered here to be
sequenced if the skeletal plan is further refined to reach a solution to the new problem  the
   

fistoring and indexing plan derivations

  dms  

static

scratch

learning

logistics
static

scratch

    
  
 

    
   
 

    
   
 

          
    
  

          
    
  

          
    
  

  solved
nodes
time sec 

    
   
 

    
   
  

    
   
 

          
    
   

          
     
   

          
     
   

  solved
nodes
time sec 

    
   
 

    
    
  

    
    
  

           
   
  

           
     
   

           
      
    

phase

learning

 solved
nodes
time sec 

    two goal

    three goal

    four goal

table    performance statistics in   dms   and logistics transportation domain  average
solution length is shown in parentheses next to  solved for the logistics domain
only 

 a   dm s  

 b  logistics

figure     replay performance in the   dms  and logistics transportation domain 
   

fiihrig   kambhampati

  dms  

logistics
learning
static

phase

learning

static

  seq
  der
  rep

    
   
    

  
  
  

   
   
   

   
   
   

  seq
  der
  rep

    
   
    

  
  
  

   
   
   

   
   
   

  seq
  der
  rep

    
   
    

  
  
  

    
   
    

   
   
   

two goal

three goal

four goal

table    measures of effectiveness of replay 
results point to the greater eciency of replay in learning mode  in the   dm s   domain 
replay was entirely sequenced in this mode  in the transportation domain  retrieval based
on failure did not always result in sequenced replay  but did so more often than in static
mode 
the greater effectiveness of replay in learning mode is also indicated by the two other
measures contained in the subsequent two rows of table    these are respectively  the percentage of plan refinements on the final derivation path that were formed through guidance
from replay    der   and the percentage of the total number of plans created through replay that remain in the final derivation path    rep   the case based planner in learning
mode showed as much or greater improvements according to these measures  demonstrating the relative effectiveness of guiding retrieval through a learning component based on
replay failures  these results indicate that dersnlp ebl s integration of cbp and ebl is
a promising approach when extra interacting goals hinder the success of replay 
in section   we report on a more thorough evaluation of dersnlp ebl s learning component  this was conducted with the purpose of investigating if learning from case failure
is of benefit for a planner solving random problems in a complex domain  for this evaluation we implemented the full case based planning system along with novel case storage
and adaptation strategies  in the next section  we describe the storage strategy that was
developed for this evaluation 

   improving case storage and adaptation
the aim of case based planning is to eciently solve large problems in complex domains 
a complex domain means a great variety in the problems encountered  when problem size
 measured in terms of the number of goals  n  is large  it is unlikely that the same n goal
problem will have been seen before  it is therefore an advantage to be able to store cases
covering smaller subsets of goals  and to retrieve and adapt multiple cases in solving a single
large problem 
   

fistoring and indexing plan derivations

before implementing this strategy  decisions had to be made as to which goal combinations to store  in previous work within state space planning veloso        has developed an
approach to reducing the size of the library by first transforming a totally ordered plan into
a partially ordered graph  separating out connected components of the graph  and storing
these subplans individually  goals which interact in that their respective plans must be
interleaved in order to form a complete solution are stored together as a single case  when
replay is based on a plan space planner such as snlp  a component subplan may be further
subdivided  since the planner has the ability to first piece plans together  and later add step
orderings to interleave these subplans  kambhampati   chen        ihrig   kambhampati 
    a   replay of these smaller cases will be sequenced as long as their individual subplans
may be interleaved by the addition of step orderings to form a full solution  the plan space
planner therefore has a greater capability of reducing the size of the problems stored in the
library  and  as a consequence  the number of cases stored 
dersnlp ebl s storage strategy makes use of the plan space planners  ability to piece
small plans together  then add step orderings to interleave these plans  as in earlier approaches  such as priar  kambhampati   hendler         prodigy analogy  veloso 
      and caplan  munoz avilla   weberskirch         the cases that are stored cover
smaller subsets of the original set of input goals achieved in the successful problem solving
episode  dersnlp ebl differs from these earlier approaches in that the division into goal
subsets is not based on the structure of the final plan alone  but on the sequence of events
making up the problem solving episode  a new repairing case is stored if the cases which
were retrieved from the library in solving the new problem fail to be extended into a new
solution  the storer constructs a new case based on the failure explanation which was obtained through the extension phase as well as the new successful plan derivation obtained
during recovery 
the failure explanation identifies the set of negatively interacting goals responsible for
the failure  these goals form a subset of the input goals which are achieved in the new
solution  before the repairing case is stored  the new plan derivation is stripped of any
decisions that are irrelevant to the achievement of these interacting goals  the new case
then covers only the negatively interacting goals 
note that we define negative interaction based on the failure of the skeletal plan  an
interaction occurs when a set of input goals cannot be solved by refining the skeletal plan 
causing the planner to have to backtrack over this plan  moreover  we cannot determine
whether two goals are negatively interacting merely by analyzing the final solution  it does
not include information about the planning failures which were encountered in generating
the solution  in particular  the final solution does not tell us whether an additional goal was
achieved by extending the replayed path  or by backtracking over that path  approaches
to case storage which determine goal interaction from the final plan alone  veloso       
munoz avilla   weberskirch        therefore ignore the retrieval failures that have been
encountered during the planning episode 
retrieval failures provide important guidance as to how the library may be improved to
avoid similar failures  for dersnlp ebl  they are used to dynamically improve the storage
in the library through the addition of new goal combinations  multi goal problems are
stored when retrieved cases corresponding to single goal subproblems fail to be merged and
   

fiihrig   kambhampati

case failure explanation 

c   fhgff  tg i  hg    tg ig
e   fhti   i  i  hti   pfi ig
figure     an example of a case failure reason
extended into a new solution  repairing cases are constructed which achieve the negatively
interacting goals which are responsible and which are identified in the failure explanation 

    an example of a negative interaction
figure    provides an example of an explanation for failure encountered when solving a
problem from barrett and weld s  dm s   domain shown in figure    the problem contains
three goals  gff   g  and g    and has been attempted through replay of a case which solves
two of these goals  gff and g    and a second case  which achieves only g    in the latter 
the goal was achieved through the action afi  which represents an incorrect operator choice
when the input goals of the problem include the goal gff  
the failure explanation shown in figure    identifies a subset of interacting goals  made
up of g  and gff   note that this interaction is not evident in the final plan shown in figure    
in this plan  the three input goals of the problem are achieved through the same connected
component  if we base storage solely on the plan graph represented by the successful plan 
then all three input goals will be stored in a single case  moreover  each new problem
representing a novel combination of goals will be stored in the library  causing the library
size to increase exponentially with problem size  for example  suppose the domain includes
the goals  fgi j    i   ng and gff   then the number of problems of size three will be the
number of   goal subsets of these n     goals  dersnlp ebl s strategy of storing cases
based on explanations of retrieval failure will result in a maximum of  n     cases stored 
each goal fgi j    i   ng appears in only two cases  one representing the single goal problem
and one representing a two goal problem which also achieves gff  
storing only negatively interacting goals as multi goal problems may therefore result
in a substantial reduction in the size of the case library  it also represents a tradeoff  as
the replayed cases must be extended by from scratch planning to solve conicts between
the individual plans recommended by separate cases  moreover  in more complex domains 
there may be goals which interact positively in that they may be solved through common
steps  ihrig   kambhampati        munoz avilla   weberskirch         if these goals are
stored as separate cases  then replay may result in unnecessary redundancy in the plan 
in dersnlp ebl  these positive interactions are handled through the replay process itself 
which merges the subplans provided by multiple cases  in section     we describe how
this merging is accomplished  the next section provides more detail as to the case storage
strategy which has been implemented for our empirical study 
   

fistoring and indexing plan derivations

ti

   a

   a

   a

tg

figure     a solution to the example problem 

    building the case library
the following deliberative strategy was adopted for building the case library  when a new
problem contains n goals  the first goal is attempted  and  if solved  the case covering this
goal alone is stored in the library  problem solving continues by increasing the problem size
by one goal at a time  for example  if the problem just attempted contained the goal set 
g   hg    g         gi i and was solved through a decision sequence di then a second decision
sequence  di     is stored whenever di cannot be replayed and extended to achieve the next
goal gi     whenever the replayed derivation path fails  and the recovery phase is successful
in producing a new solution  the explanation for the case retrieval failure is used to identify
a subset of negatively interacting input goals  n   hgj    gj  m i  that are responsible for the
failure  if the replayed path fails to be extended  and is backtracked over to reach a solution
to the new problem  then the new successful derivation is passed to the storer along with
the failure explanation  the explanation is used to delete from the derivation any decisions
which are not relevant to the set of negatively interacting goals  n   this reduced derivation
is then stored in the library as the repairing case  alternatively  whenever the next goal
in the set is solved through simple extension of the previous decision sequence  no case is
stored which includes that goal 
this storage strategy entails two important properties      each new case corresponds to
either a new single goal problem or to a multi goal problem containing negatively interacting
goals      all of the plan derivations arising from a single problem solving episode are
different in that no decision sequence stored in the library is a prefix of another stored case 
this is because no case is added to the library when a new problem is solved by extending
a retrieved case  new cases are stored only when some of the previous decisions need to be
backtracked over in the search for a new solution 
dersnlp ebl s strategy of restricting multi goal cases to those with goals which are
negatively interacting serves to ameliorate the mis retrieval problem  the more experience
that the planner has in problem solving  the more of these interactions are discovered  and
the less likely it is that the planner has to backtrack over its replayed paths  the aim is
to eventually have in the library a minimal number of cases such that all of the problems
encountered may be achieved by successfully merging multiple instances of stored cases  the
approach is therefore to retain cases based on their competence as well as their performance
 smyth   keane        
      an example of dersnlp ebl s storage strategy

as an example of how a multi goal problem is stored  consider the problem contained in
figure    where three packages  ob   ob  and ob   are to be transported to the same
destination location  ld   initially the goal set contains the goal of transporting ob  alone 
represented as  at ob ob  ld    and the successful derivation is stored as case a  the
second goal is then added to the set  since the problem just attempted achieves the first
   

fiihrig   kambhampati

ob 

a

ob 

a b
b

ld

b
lp

ob 

l 

figure     a logistics transportation example illustrating multi case storage  the figure
shows two plans produced by two stored derivations  case a achieves the goal
of having a single packages  ob   transported to the destination airport  ld   case
b achieves the goal of having ob  and ob  located at the same airport 
goal through a decision sequence which has to be backtracked over in order to solve the
additional goal  a second derivation  case b   is stored  this new derivation then solves
the mutually interacting goals   at ob ob  ld   and  at ob ob  ld    problem solving then
continues with the addition of the third goal  this goal is solved through simple extension of
the previous decision sequence  no case is stored which includes this goal  this means that
we have two cases stored in the library  case a corresponding to a single goal problem and
case b corresponding to a multi goal problem containing two negatively interacting goals 
multi goal problems are stored only when the problem goals are mutually interacting  that
is  only when their individual derivations cannot be sequenced and extended to solve the
full problem 
with dersnlp ebl s storage strategy  the size of the library is limited by the amount of
interaction in the domain  for example  if there is no negative interaction  then only single
goal cases will be stored  in the logistics transportation domain  there is a potential for all
problem goals to interact negatively  however  since there are also a significant percentage
of non interacting goals  this strategy reduces the size of the library in comparison to one in
which all of the multi goal problems which are successfully solved are stored  this storage
strategy also represents a tradeoff since effort must be expended in merging the retrieved
cases into a full solution  see section      
      indexing on the basis of replay failure

multi goal cases are stored in the library so as to censor the retrieval of their corresponding
single goal subproblems  this library organization differs from earlier work which stores
all cases in a common fashion on a single level  first indexing each case by all of the goals 
then by all of the success conditions relevant to these goals  veloso        munoz avilla  
weberskirch         in contrast  dersnlp ebl indexes its cases through a discrimination
net similar to the one depicted in figure     this figure shows one fragment of the case
library which includes all of the cases which solve a single input goal  individual planning
episodes which achieve this goal are represented one level lower in the net  each is labeled by
   

fistoring and indexing plan derivations

g 
input goals 

initial conditions 

 at ob ob  ld  
 at pl pl  lp 

 at ob ob  l  

g 

g 

derivation  
r 

failure reasons 

 at pl pl  lq 

derivation  
r 

g 

g 

derivation  

derivation  

figure     a library fragment indexing stored cases which solve a single input goal   at ob
ob  ld   
its relevant initial state conditions  otherwise known as the footprinted initial state  veloso 
       together  the goal and initial state conditions make up the static success conditions
on which cases are first retrieved  when one of these cases is retrieved for replay and replay
fails  the derivation corresponding to the extra interacting goals is added to the library
and indexed directly under the failing case  on future retrievals of the case  the failure
conditions are checked to see whether the extra goals responsible for the failure are present
under the same conditions  if so  the retrieval process returns the repairing case which
achieves these conicting goals  the case failure reason is thus used to direct retrieval away
from the case which will repeat a known failure  and towards the case that avoids it 
one might question this hierarchical organization in instances where failures are due to
interacting goals alone  why not just store all cases on a single level first indexing each
case by all of its goals  then by the conditions relevant to all of these goals  the answer
lies in the need to censor cases when failure conditions are satisfied  this type of error will
be found when retrieving multiple cases  as an example  consider that our new problem
contains three goals  g    g  and g    suppose further that the goal g  negatively interacts
with both g  and g    if a case is retrieved from the library which achieves both g  and g   
then one goal  g    is left open  however  if a case is then retrieved which solves g  alone  it
will fail because of the presence of g    this type of retrieval error is handled by prioritizing
cases  a repairing case is stored as a subclass of the case that failed  failing cases are
annotated with the failure reason which directs the retriever to the case that avoids the
failure 
prioritizing cases on the basis of negatively interacting goals alone is not sucient to
capture all of the retrieval failures that may be encountered  if cases are retrieved on the
basis of a partial match of the relevant initial state conditions  then retrieval errors may
occur because of unmatched conditions  veloso         for example  just as a failure might
occur in our logistics transportation example if there is an extra package off the plane s
route  a similar failure will occur if a package is moved off the plane s route  the strategy
that is adopted to deal with both types of failure information is to annotate the case with
   

fiihrig   kambhampati

ob 

ob 

a

l 
ld

a b b
b

b

b
lp

ob 

b

l 

figure     a logistics transportation example illustrating multi case retrieval 
the failure reason  whether it is an extra goal or an unmatched initial state condition  and
use the failure reasons to prioritize cases  the ebl techniques that we have employed in
the construction of failure explanations may be used for both types of failures 
dersnlp ebl s method of storing multi goal cases only when goals are negatively interacting limits the size of the case library  other aspects of dersnlp ebl s storage strategy
also serve to lower library size  the planner always uses its current library in solving new
problems  new derivations are stored only when there is no applicable case  or when the
retrieved cases fail  this strategy avoids the storage of duplicate cases  but may not be
entirely effective since the soundness of failure explanations is not guaranteed  if failure
explanations are not sound  pointers to repairing cases may eventually lead to a duplicate
case  causing the library to continue to grow indefinitely  however  this is easily checked
by putting a depth limit on the number of repairing cases in the discrimination net  also 
failures which are due to interacting goals will not result in unchecked growth of the library
since the number of interacting goals is limited by the maximum problem size 
      a detailed example of case retrieval

an example of case retrieval is illustrated in figure     the figure contains three subplans
corresponding to two separate cases stored in the library  case a achieves the goal of having
a single package  ob   located at destination ld   case b achieves the goal of having both
ob  and ob  located at ld 
assume that a new problem which is to be attempted through replay contains three
goals   at ob ob  ld    at ob ob  ld    and  at ob ob  ld    the second goal negatively
interacts with both of the other goals  the retriever will first attempt to find a case that
solves the first goal alone  case a solves this goal  however  this case is annotated with a
failure reason which is satisfied in the new problem situation  and a is therefore censored
in favor of the repairing case  case b   once the retriever returns case b   it will then have
one open goal not covered  that is   at ob ob  ld    it will seek out a case which solves
this goal alone  and will again find case a  however  a s failure reason is again satisfied
in the new problem state and will be rejected in favor of a second copy of b  which we
now call case b     which solves the problem of transporting both ob  and ob   there will
then be two instances of case b that will be retrieved to solve the three goal problem 
case b and case b     together they cover the new problem goals  dersnlp ebl replays
   

fistoring and indexing plan derivations

figure     new linking opportunities indicated by an increase in the number of siblings of
the step addition decision 
both copies of b in sequence to obtain a solution to the full problem  thereby merging their
respective subplans  notice  however  that the union of these plans will contain redundant
steps  for example  both plans have the plane y to location l    section     describes how
dersnlp ebl deals with these positive goal interactions 

    multi case merging

we say that two plans are mergeable with respect to a problem  hi    g    ai  if there exists
a solution to the problem which contains all of their combined constraints 

definition    mergeability  a plan p  for achieving goal g  is mergeable with a plan p 
for the goal g  with respect to a problem  hi     g    ai   if there is a plan p   which is correct
for hi    g    ai and hhp  ii  hhp ii hhp  ii   thus syntactically  p   contains all the constraints
of p  and p    

multi case replay accomplishes plan merging  but may result in lower quality plans if
care is not taken to avoid redundant step additions  ihrig   kambhampati        munozavilla   weberskirch         these occur when goals covered by separate cases positively
interact in that they may be solved through common steps  replaying each case in sequence
then results in unneeded steps in the plan   
in multi case replay  if an open condition is the only justification for adding a new step 
some steps may be added which already exist in the plan due to the earlier replay of another
case  when the first retrieved derivation is replayed  none of its replayed step additions
will result in redundancy  however  when subsequent goals are solved through replay of
additional cases  some step additions may be unnecessary in that there are opportunities
for linking the open conditions they achieve to earlier established steps  the planner has
no way of determining a priori that these steps may be represented by a single step in the
plan   
dersnlp ebl s replay framework handles redundant step additions by skipping over
step addition establishments whenever the open condition may be achieved by a new link 
it thus strengthens or increases the justification for replaying step addition decisions in that
the open condition is no longer the only basis for validating the decision  the justification for replay is strengthened to add the condition that no new linking opportunities are
   an analogous decrease in plan quality occurs in state space plan reuse  when sequencing macro operators
results state loops  minton      a  
   consider  for example  a domain in which the plane may transport two packages in one trip  or not 
depending on its capacity 

   

fiihrig   kambhampati

dersnlp ebl

dersnlp ebl ij

             
    
    

              
    
    

replay
 solved
time sec 

scratch

replay

scratch

table    percentage problems solved  total cpu time in seconds on all    problems for
problems in the logistics transportation domain  average solution length is
shown in parentheses next to  solved 
present  these may be detected as an increase in the number of siblings of the prescribed
step addition choice  see figure      the siblings of the stored step addition decision are
recorded as annotations on the derivation trace  when new links are available which are
not contained within these siblings  the step addition decision is skipped  after replay 
the alternative new links are explored through the normal course of plan refinement  this
means that the same step may eventually be added if the new links fail 
increasing the justification for the step addition decisions improves the quality of plans
in terms of the number of steps they contain  for example  case b and b   would normally
produce subplans which are shown in figure     when these cases are replayed in sequence
in solving a single problem  their plans are merged so that the plane moves to each city
only once  plan merging through increasing the justification for replay accomplishes the
retracting out of redundant action sequences  which may cause a planning failure  it thus
deals with the action merging interactions defined in  yang  nau    hendler         in
the next section we describe an empirical study testing the effectiveness of this merging
strategy 
      an empirical test of dersnlp ebl s plan merging strategy

a preliminary study was conducted to test the effectiveness of dersnlp ebl s method
of plan merging through replay  this experiment compared dersnlp ebl both with and
without increasing the justification for replay  the experimental setup consisted of training
dersnlp ebl on a set of    randomly generated   goal training problems  and testing on
a different set of      goal test problems  the initial state of each problem contained   
locations    post oces and   airports  and    transport devices    planes and   trucks   in
the training phase  the planner solved problems and stored the successful plan derivations
in the case library  during the testing phase  the planner retrieved multiple stored plan
derivations and used these as guidance in solving the test problems  dersnlp ebl was
tested on the same    problems in both replay and from scratch modes  replay was either
with  dersnlp ebl  or without  dersnlp ebl ij  increased justification  the results are
shown in table   
although overall performance was poorer  the quality of plans in terms of number of
steps improved with dersnlp ebl s strategy of increasing the justification for step addition  this result suggests that that dersnlp ebl s method of plan merging serves to reduce
   

fistoring and indexing plan derivations

the redundancy in the plans produced through multi case replay  recently  munoz avilla
and weberskirch        have tested this non redundant merging strategy in a process planning domain and have found a similar improvements in plan size  the next section describes
an evaluation of the full dersnlp ebl system 

   experimental evaluation of the complete system

the experiments reported in this section tested the full dersnlp ebl system using the
dynamic multi case storage and retrieval strategy described in section    the aim was to
evaluate the replay system in a more complex domain  our hypothesis was that performance
would improve over problem solving experience as more negative interactions are discovered
and stored  in addition  we predicted that dersnlp ebl s method of storage would result
in a low library size and low retrieval costs 
the logistics transportation domain  veloso        has become somewhat of a benchmark in the cbp literature  a scaled up version was therefore chosen for this purpose  we
tested large multi goal problems drawn from the domain shown in figure   scaled up to
first   and then    cities  this size of domain is unusual in the current literature 

    experimental setup

the experiment was run in phases  each phase corresponding to an increase in problem
size  thirty test problems of each size were randomly generated  since it is not possible
to obtain a truly random distribution within a nonartificial domain  the following strategy
was adopted for problem generation  first  the initial state was constructed by fixing the
number objects of each type contained in the domain description  for example  in the first
experiment  there were six cities     locations within cities   six planes  and six trucks  the
initial state of each problem was constructed by first including filter conditions  nonachievable conditions   these defined the layout of the cities  for example  the condition  is a
airport ap   identified ap  as an airport  the condition  same city ap  po   indicated
that ap  and po  were located in the same city  second  the achievable  non filter  conditions that are present in the add clauses of the domain operators were varied for each
problem by choosing object constants randomly from those available with the restriction
that no two initial state conditions were inconsistent  for example  each plane and package
was assigned to a single randomly chosen location  goals were chosen from among these
achievable conditions in the same manner  although no attempt was made to create interacting goals  goal interaction was common in the multi goal problems  this was because
a limit was imposed on the number of steps in the plan  it meant that multi goal problems often could not be solved by concatenating subplans for individual subgoals  in these
instances  the planner could take advantage of linking opportunities and achieve multiple
goals through common steps  it also meant that often the planner had to backtrack over a
derivation for one goal in order to solve an additional goal 
the first experiment used the   city domain and was run in   phases  the size of the
test problems  which ranged from   to   goals  was increased for each phase  prior to each
phase n of the experiment  the case library was emptied and the planner was retrained
on randomly generated problems of size n  training problems were solved by attempting
single goal subproblems from scratch  storing a trace of the derivation of the solution to the
   

fiihrig   kambhampati

phase

 

  

 solved
time sec 

       
  

  solved
time sec 

logistics  best first

cpu limit     sec 
  
   

  

  

       
      

       
      

       
     

       
      

       
      

       
      

      
    

      
        

       
       

       
      

       
       

       
       

       
       

  solved
time sec 

      
    

      
      
      
              
                                                

       
        

  solved
time sec 

      
    

       
        

       
        

       
        

       
       

       
       

       
       

  solved
time sec 

  
     

       
       

       
       

       
       

       
       

                
              

  solved
time sec 

  
     

       
       

       
       

       
       

       
       

       
       

one goal

two goal

three goal

four goal

five goal

six goal

   

       
       

table    performance statistics in logistics transportation domain  average solution
length is shown in parentheses next to  solved  case retrieval time is shown
in parentheses next to cpu time 
problem if one was not already present in the library  and then successively adding an extra
goal  multi goal problems were stored only when retrieved cases used in solving the problem
failed  whenever a problem could not be solved through sequenced replay of previous cases 
the negatively interacting goals contained in the failure reason were identified and a new
case achieving these goals alone was stored in the library  in each phase of the experiment 
the planner was tested on the same    randomly generated test problems after varying
amounts of training  the problems were solved both in from scratch mode and with replay
of multiple cases retrieved from the library which had been constructed during training 
a second experiment which tested the planner on a more complex    city domain employed a stable case library formed when dersnlp ebl was trained on        city    goal 
logistics transportation problems  this library of smaller problems was then used when the
planner was tested on the larger     city  problems ranging from   to    goals 

    experimental results

in the first experiment on the   city domain dersnlp ebl showed substantial improvements with multi case replay as evident from the results in table    moreover  replay
performance improved with problem solving experience  the plans that were produced
showed only a slight increase in number of steps over the solutions which were obtained
in from scratch mode  the same results are plotted in figure    which graphs cumulative
cpu time on all test problems over the six experiments  this figure illustrates how cpu
time decreased with the number of training problems solved  the insert shows total cpu
   

fistoring and indexing plan derivations

figure     replay performance in the logistics transportation domain with increasing
amounts of training  thirty problems were tested for each problem size    to
  goals   the amount of time needed to solve all test problems up to that size
 including case retrieval time  is shown when problems were solved from scratch
 level    and with replay after increasing levels of training  after solving       
    randomly generated problems   the insert shows the amount of time taken
to solve all test problems after increasing amounts of training  a time limit of
    seconds was placed on problem solving 

   

fiihrig   kambhampati

figure     replay performance in the logistics transportation domain scaled up to   
cities  a case library was formed as     training problems    cities    goals 
were solved  this library was then used in solving test sets containing larger
problems     cities    to    goals   none of the problems were solved within the
time limit      sec  in from scratch mode  for replay mode  average solution
length is shown in parentheses next to problem size 

figure     replay performance in the logistics transportation  the percentage of test problems solved within the time limit      sec  is plotted against number of training
problems solved  percentage solved is shown for problems of increasing size    
   and   goals  

   

fistoring and indexing plan derivations

figure     figure shows the size of the case library with increased number of training
problems solved  library size increases with training problem size        and  
goals      shows the number of single goal subproblems contained in the   goal
training problems 
time  including case retrieval time  for all of the test problems in the six experiments  as
evident in this insert  planning performance improves with increased experience on random
problems  however  relatively little experience     problems solved  was enough to show
significant performance improvements 
replay raised the problem solving horizon  as illustrated in figure     it is more effective
with larger problem size  when from scratch planning tends to exceed the time limit imposed
on problem solving  figure    shows the increase in the size of the library with increasing
amounts of training  this figure also indicates that library size is determined more by the
amount of interaction in the domain  as opposed to the number of training problems solved 
the rate at which the case library grows tapers off and is higher when the planner is trained
on larger problems   
in the second experiment  a library formed over the course of training on   goal problems
was used to solve larger problems    to    goals  in a more complex domain     cities   see
figure      none of the larger problems were solved in from scratch mode within the time
limit of     sec     the planner continued to maximum time on all problems  indicated in
the figure by the linear increase in cpu time  its performance was substantially better
with replay  however  since library size was relatively small  the improvements in planning
performance more than offset the cost of retrieving and adapting previous cases  this finding
suggests that the replay strategy employed in these experiments represents an effective
method for improving planning performance in complex domains 
   there is more opportunity for interaction in larger problems  for example  a   goal problem could
contain   goals that mutually interact  whereas a   goal problem has a maximum of   interacting goals 
   dersnlp ebl in from scratch mode used a best first strategy  in replay  this best first strategy is biased
so that the subtree under the replayed path is explored first  before the siblings of this path 

   

fiihrig   kambhampati

action  put on  x  y  z 
precond  on  x  z 
 clear  x 
 clear  y 
add
 on  x  y 
 clear  z 
delete  on  x  z 
 clear  y 

action  new tower  x  z 
precond  on  x  z 
 clear  x 
add
delete

 on  x table 
 clear  z 
 on  x  z 

figure     the specification of the blocks world domain adapted for our experiments 

    an empirical comparison of dersnlp ebl with rule based ebl
case based planning and explanation based learning offer two differing approaches to improving the performance of a planner  prior research  kambhampati        has analyzed
their tradeoffs  the hybrid learning approach of dersnlp ebl is designed to alleviate
the drawbacks associated with both pure case based planning  and rule based ebl  prior
to this work  ebl has been used to construct generalized search control rules which may
be applied to each new problem solving situation  these rules are matched at each choice
point in the search process  dejong   mooney        minton      b  mostow   bhatnagar 
      kambhampati et al       b   this approach is known to exhibit a utility problem since
the rule base grows rapidly with increasing problem solving experience and even a small
number of rules may result in a high total match cost  minton      b  tambe  newell   
rosenbloom        kambhampati        francis   ram         in contrast  the empirical
results discussed here  see table    indicate that dersnlp ebl has a low case retrieval and
match cost 
to demonstrate how dersnlp ebl reduces match cost  we conducted an empirical study
which compared its performance with ucpop ebl  a rule based search control learning
framework  kambhampati et al       b   this framework constructs reasons for planning
failures in a manner similar to dersnlp ebl  however  its approach is similar to that of
minton      b  in that it employs these explanations in the construction of search control
rules which are matched at each node in the search tree  the planners were tested on a
set of problems ranging from   to   goals which were randomly generated from the blocks
domain shown in figure     testing was performed on the same set of thirty problems after
increasing amounts of training 
as illustrated in figure     dersnlp ebl improved its performance after only    training problems solved  ucpop ebl failed to improve significantly  the reason is evident
in ucpop ebl s match time  ucpop match  also graphed in figure     for ucpop ebl 
time spent in matching rules increases with training  wiping out any improvements that
may have been gained through the use of those rules  when rules are matched at each
choice point in the search tree  a small number of rules is sucient to substantially increase
the total match cost 
   

fistoring and indexing plan derivations

figure     total cpu time on    blocks world problems after increased amounts of training 
it is also possible to improve the performance of rule based ebl by reducing the number
of rules through the use of utility monitoring strategies  gratch   dejong         or by
using a more sophisticated match algorithm  doorenbos         for example  doorenbos
       employs an improved rule matcher based on the rete algorithm  dersnlp ebl  on
the other hand  aims at alleviating the utility problem by reducing the number of times rules
are matched  similar to rule based ebl  its learning component is employed to generate
rules  however  the rules that are generated govern the retrieval of the cases stored in
the library  these are compiled into its indexing structure  dersnlp ebl exhibits low
match cost by applying retrieval rules at only one point in the search process  specifically 
it retrieves cases only at the start of problem solving  each case represents a sequence of
choices  a derivation path  thus providing global control as opposed to local  the results
shown in table   indicate that the cost of retrieving cases is significantly lower in comparison
to time spent in problem solving 

   related work and discussion
dersnlp ebl s storage strategy relies on the capability of the case based planner to replay
multiple cases  each covering a small subset of goals  and then add step orderings to interleave their respective plans  this strategy differs from earlier approaches such as priar
 kambhampati   hendler         prodigy analogy  veloso         paris  bergmann
  wilke         and caplan  munoz avilla   weberskirch         in that the division
into goal subsets is not based on the structure of the final plan alone  but on the sequence
of events making up the problem solving episode  retrieval failures are treated as an opportunity by which the planner stores a new repairing case  in this aspect it is similar
to hammond s chef  hammond        which also learns to improve its retrieval strategy
based on failures  despite this surface similarity  there are important differences in our

   

fiihrig   kambhampati

transformational
priar
spa
mpa
plan space

state space
dersnlp

prodigy analogy
paris

derivational

figure     some different approaches to case based planning where case adaptation is accomplished by an underlying generative planner 
approach  dersnlp ebl learns from case extension failures  whereas chef concentrates on
learning from execution failures  specifically  chef assumes an incomplete domain model 
consisting of stored cases  and a domain specific modification theory of patches  given a
new problem  chef retrieves a previous case  and modifies the retrieved plan using domain
specific modification rules to generate a candidate solution for the current problem  the
correctness of this solution is then tested with respect to an external causal simulator of the
domain  if the solution is found to be incorrect  the explanation of incorrectness  supplied
by the simulator  is used to modify the case library to censor the retrieval of the case in
similar situations in the future  this in effect improves the correctness of chef s domain
theory  in contrast  dersnlp ebl assumes complete knowledge of the domain  in the form
of domain operators  it also has access to a sound and complete plan synthesis strategy 
the aim of case based reasoning in dersnlp ebl is to improve the performance of the
base level planner  to this end  dersnlp ebl analyzes case extension failures to predict
when a case cannot be extended to solve a new problem 
fox and leake        have taken an approach similar to that of chef  but use introspective reasoning to explain failures and find repairing cases  similar to chef  introspective
reasoning is used to revise indexing in the case library  fox   leake        ram   cox 
       other approaches employ domain specific techniques to improve storage and retrieval from a case library  munoz avilla   weberskirch        smyth   keane        
dersnlp ebl differs in that it automatically generates new indices through a well defined
and domain independent methodology  kambhampati et al       b  which is incorporated
into the underlying planning strategy 
since ebl is employed in explaining case failure as well as success  dersnlp ebl complements and extends earlier approaches to case retrieval  barletta   mark        kambhampati   hendler        hendler  stoffel    mulvehill        veloso        bergmann
  wilke        munoz avilla   weberskirch        ram   francis         although it
   

fistoring and indexing plan derivations

exhibits low retrieval and match cost  as with any cbp system  this eciency may degrade with larger domain size  dersnlp ebl s approach is compatible with others aimed
at improving match cost  doorenbos        ram   francis        hendler et al         
for example  mpa  ram   francis        is built around a retrieval engine which performs
asynchronous memory retrieval  caper  hendler et al         uses a structure matching
algorithm which parallelizes the process by which the plan s success conditions represented
as a retrieval probe are matched with a large knowledge base of world facts  this process
expands binary predicates which match the success conditions into a larger structure containing implicitly specified relations in the knowledge base  this structure acts as a filter 
eliminating matches which fail to line up with the probe 
dersnlp ebl is similar to case based systems which employ a complete and correct
domain independent planner to generate cases to be stored  hanks   weld        kambhampati   hendler        koehler        veloso        ram   francis         in surveying
this literature  it is possible to distinguish these approaches on two orthogonal scales as
shown in figure     in the horizontal direction  the cbp frameworks are ranked as to
how the underlying planning strategy falls on a continuum whose end extremes represent
the state space vs plan space dichotomy  towards the state space end of the spectrum is
prodigy analogy  which employs the means ends analysis  mea  planner  nolimit  to
extend a previous case  nolimit is here classed as a state space planner since it applies
actions to the plan based on the current world state and thereby advances the world state 
the priar framework  kambhampati   hendler        kambhampati        is based
within nonlin  tate         nonlin creates its plans through hierarchical task reduction 
it is also a partial order  plan space  planner which constructs plans by protecting their underlying causal structure  like dersnlp ebl  it extends a case through the normal course
of plan refinement defined by an underlying plan space strategy  however  dersnlp ebl is
implemented within the partial order  causal link planner  snlp  mcallester   rosenblitt 
      barrett   weld         in this aspect it is similar to the spa system developed by
hanks and weld        
the different cbp systems may also be distinguished according to their case adaptation strategy  these can be roughly categorized as either transformational or derivational
 carbonell        veloso   carbonell      b   according to whether they transform a previous plan or replay a previous plan derivation  in the transformational strategies of priar
and spa  the final plan which is the product of the planning episode is stored in the case
library  when a case is retrieved this plan is fitted to adapt to the new problem solving situation by retracting the irrelevant or redundant subparts  early cbp systems  carbonell 
      hammond        also employ transformational techniques to adapt a previous solution  causal link planners such as snlp are ready made for plan reuse since the causal
structure which is employed in plan adaptation is a part of the plan itself  priar and spa
use the plan s causal structure both in fitting the plan to the new problem context  and
in extending the fitted plan to solve the new problem  priar differs from spa in that it
employs an extension first strategy  the skeletal plan is first refined through the addition
of plan constraints before undertaking any further retraction of constraints  spa  on the
other hand  alternates the retraction of the plan constraints with the further addition of
new constraints  mpa  ram   francis        extends spa s transformational strategy to
accomplish multi case retrieval and adaptation 
   

fiihrig   kambhampati

as mentioned earlier  derivational analogy is a case based planning technique which
was introduced by carbonell  veloso   carbonell      b   this model was developed by
veloso in prodigy analogy  veloso         which employed the case fitting strategy called
derivational replay  case fitting based on replay is similar to fitting in plan reuse  in that
it is based on the plan s underlying causal structure  the justification for each planning
decision which is stored in the derivation trace reects the causal dependencies between plan
steps  only justified choices are replayed in solving the new problem  replay thus serves
the same purpose as retraction in plan reuse  replay may have an advantage in multi case
reuse since it allows the planner to readily merge small subplans to solve large problems 
dersnlp can be contrasted to prodigy analogy in that it employs a case fitting
methodology called eager derivation replay  ihrig   kambhampati      a         with
this replay strategy  the applicable cases are replayed in sequence before returning to fromscratch planning  eager replay simplifies the replay process by avoiding the decision as to
how to alternate replay of multiple cases  the effectiveness of this approach is dependent
on the underlying plan space planning strategy  ihrig   kambhampati      a   dersnlp s
eager case adaptation strategy allows case failure to be defined in terms of the failure of
a single node in the search tree  in particular  case failure is defined as the failure of the
skeletal plan  which contains all of the constraints that have been adopted on the advice
of the previous cases  eager case adaptation means that explanations of case failure may
be constructed through the use of ebl techniques which have been developed to explain
analytical failures occurring in the planner s search space 

   summary and conclusion
in this paper we have described the design and implementation of the case based planner 
dersnlp ebl  the dersnlp ebl framework represents an integration of eager case adaptation with failure based ebl  ebl techniques are employed in building the case library
on the basis of experienced retrieval failures  this approach improves on earlier treatments of case retrieval  barletta   mark        kambhampati   hendler        ihrig  
kambhampati      a  veloso   carbonell      a   as a partial order case based planner 
dersnlp has the ability to solve large problems by retrieving multiple instances of smaller
subproblems and merging these cases through sequenced replay  ihrig   kambhampati 
    a   the dersnlp ebl framework extends this approach through the use of new ebl
techniques which are employed in the construction of the case library  these techniques are
used to explain a plan merging failure and to identify a set of negatively interacting goals 
the library is then augmented with a new repairing case covering these interacting goals 
dersnlp ebl s method of storing multi goal cases only when goals are negatively interacting results in a small library size and low retrieval costs  however  multi case adaptation
also involves a tradeoff since effort is expended in merging multiple instances of stored cases 
dersnlp ebl accomplishes this merging by increasing the justification for replay of step addition decisions  this strategy avoids the addition of redundant steps when goals positively
interact  dersnlp ebl is therefore aimed at domains such as the logistics transportation
domain where there is a significant amount positive interaction  it is also aimed at domains
where there is negative interaction  it is of course futile to spend effort in explaining case
failure if none are encountered 
   

fistoring and indexing plan derivations

section   describes an evaluation of the overall eciency of this storage and retrieval
strategy when solving large problems in a complex domain  dersnlp ebl shows an improvement in planning performance which more than offsets the added cost entailed in
retrieving on failure conditions  the amount of improvement provided by replay shown in
these experiments should be seen as a lower bound since a random problem distribution
may mean less problem similarity than is found in real world problems 
in conclusion  this paper has described a novel approach to integrating explanationbased learning techniques into case based planning  this approach has been aimed at issues
associated with both pure case based planning  and with rule based ebl  in particular  it
addresses the mis retrieval problem of cbp  as well as the utility problem  the results
demonstrate that eager case adaptation when combined with dersnlp ebl s dynamic case
retrieval is an effective method of improving planning performance 

acknowledgements
the authors wish to thank amol d  mali  eric lambrecht  eric parker  and the anonymous
reviewers for their helpful comments on earlier versions of this paper  thanks are due
to terry zimmerman for providing insight into ucpop ebl  this research is supported
in part by nsf research initiation award iri          nsf young investigator award
iri          and the arpa planning initiative grants f         c       phase ii  and
f         c       phase iii  

references

barletta  r     mark  w          explanation based indexing of cases  in proceedings
aaai    
barrett  a     weld  d          partial order planning  evaluating possible eciency gains 
artificial intelligence             
bergmann  r     wilke  w          building and refining abstract planning cases by change
of representation language   journal of artificial intelligence research            
carbonell  j          learning by analogy  formulating and generalizing plans from past
experience  in michalski  r   carbonell  j     mitchell  t   eds    machine learning 
an artificial intelligence approach  vol     palo alto  ca  tioga press 
dejong  g     mooney  r          explanation based learning  an alternative view  machine learning                 
doorenbos  r          production matching for large learning systems  ph d  thesis 
computer science department  carnegie mellon university 
fikes  r     nilsson  n          a new approach to the application of theorem proving to
problem solving  artificial intelligence             
fox  s     leake  d          using introspective reasoning to refine indexing  in proceedings
ijcai    
   

fiihrig   kambhampati

francis  a     ram  s          a comparative utility analysis of case based reasoning
and control rule learning systems  in proceedings of the  th european conference on
machine learning  ecml    
friedland  p     iwasaki  y          the concept and implementation of skeletal plans 
journal of automated reasoning                 
gratch  j     dejong  g          composer  a probabilistic solution to the utility problem
in speed up learning  in proceedings aaai    
hammond  k          explaining and repairing plans that fail  artificial intelligence     
        
hanks  s     weld  d          a domain independent algorithm for plan adaptation  journal
of artificial intelligence research             
hendler  j   stoffel  k     mulvehill  a          high performance support for case based
planning applications  in technological achievements of the arpa rome laboratory
planning initiative  advanced planning technology  aaai press 
ihrig  l     kambhampati  s       a   derivation replay for partial order planning  in
proceedings aaai    
ihrig  l     kambhampati  s       b   plan space vs state space planning in reuse and
replay  tech  rep          department of computer science and engineering  arizona
state university  also available at http   rakaposhi eas asu edu yochan html 
ihrig  l     kambhampati  s          design and implementation of a replay framework
based on a partial order planner  in proceedings aaai    
joslin  d     roach  j          a theoretical analysis of conjunctive goal problems  artificial
intelligence             
kambhampati  s          utility tradeoffs in incremental modification and reuse of plans  in
proceedings aaai spring symposium on computational considerations in supporting
incremental modification and reuse 
kambhampati  s          exploiting causal structure to control retrieval and refitting
during plan reuse  computational intelligence     
kambhampati  s     chen  j          relative utility of ebg based plan reuse in partial ordering vs total ordering planning  in proceedings aaai     pp           washington 
d c 
kambhampati  s     hendler  j  a          a validation structure based theory of plan
modification and reuse  artificial intelligence              
kambhampati  s   ihrig  l     srivastava  b       a   a candidate set based analysis of
subgoal interactions in conjunctive goal planning  in proceedings of the  rd intl  conf 
on ai planning systems 
   

fistoring and indexing plan derivations

kambhampati  s   katukam  s     qu  y       b   failure driven dynamic search control
for partial order planners  an explanation based approach  artificial intelligence     
        
kambhampati  s   knoblock  c     yang  q          planning as refinement search  a
unified framework for evaluating design tradeoffs in partial order planning  artificial
intelligence              
koehler  j          avoiding pitfalls in case based planning  in proceedings of the  nd intl 
conf  on ai planning systems 
korf  r          planning as search  a qualitative approach  artificial intelligence     
      
mcallester  d     rosenblitt  d          systematic nonlinear planning  in proceedings
aaai    
minton  s       a   issues in the design of operator composition systems  in proceedings of
the international conference on machine learning 
minton  s       b   quantitative results concerning the utility of explanation based learning  artificial intelligence              
mostow  j     bhatnagar  n          failsafe  a oor planner that uses ebg to learn from
its failures  in proceedings ijcai    
munoz avilla  h     weberskirch  f          planning for manufacturing workpieces by
storing  indexing and replaying planning decisions  in proceedings of the  rd intl 
conf  on ai planning systems  aaai press 
munoz avilla  h     weberskirch  f          a case study on mergeability of cases with a
partial order planner  in proceedings of the  th european conf  on planning 
ram  a     cox  m          introspecive reasoning using meta explanations for multistrategy learning  in michalski  r     tecuci  g   eds    machine learning  a multistrategy
approach vol  iv  morgan kaufmann 
ram  s     francis  a          multi plan retrieval and adaptation in an experience based
agent  in leake  d  b   ed    case based reasoning  experiences  lessons  and future
directions  aaai press the mit press 
redmond  m          distributed cases for case based reasoning facilitating use of multiple
cases  in proceedings aaai    
smyth  b     keane  m          remembering to forget  a competence preserving deletion
policy for cbr  in proceedings ijcai    
tambe  n   newell  a     rosenbloom  p          the problem of expensive chunks and its
solution by restricting expressiveness  machine learning             
tate  a          generating project networks  in proceedings ijcai    
   

fiihrig   kambhampati

veloso  m          planning and learning by analogical reasoning  springer verlag  number
    in lecture notes in artificial intelligence 
veloso  m     blythe  j          linkability  examining causal link commitments in partialorder planning  in proceedings of the  nd intl  conf  on ai planning systems 
veloso  m     carbonell  j       a   derivational analogy in prodigy  automating case
acquisition  storage and utilization  machine learning              
veloso  m     carbonell  j       b   toward scaling up machine learning  a case study with
derivational analogy in prodigy  in minton  s   ed    machine learning methods for
planning  morgan kaufmann 
yang  q   nau  d     hendler  j          merging separately generated plans with restricted
interactions  computational intelligence                 

   

fi