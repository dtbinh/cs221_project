journal artificial intelligence research                 

submitted       published     

technical paper recommendation  study combining
multiple information sources
chumki basu

cbasu cs rutgers edu

haym hirsh

hirsh cs rutgers edu

department computer science  rutgers university      frelinghuysen road 
piscataway nj           
telcordia technologies  inc       south street 
morristown nj           
department computer science  rutgers university      frelinghuysen road 
piscataway nj           

william w  cohen

wcohen whizbang com

craig nevill manning

nevill cs rutgers edu

whizbang  labs  whizbang labs   east       henry street 
pittsburgh pa      

department computer science  rutgers university      frelinghuysen road 
piscataway nj           

abstract

growing need manage exploit proliferation online data sources opening new opportunities bringing people closer resources need  instance 
consider recommendation service researchers receive daily pointers
journal papers fields interest  survey known approaches
problem technical paper recommendation ask extended deal
multiple information sources  specifically  focus variant problem
  recommending conference paper submissions reviewing committee members  
offers us testbed try different approaches  using whirl   information integration system   able implement different recommendation algorithms derived
information retrieval principles  use novel autonomous procedure gathering
reviewer interest information web  evaluate approach compare
methods using preference data provided members aaai    conference
reviewing committee along data actual submissions 

   introduction
define paper recommendation problem follows 
given representation interests  find relevant papers 

fact  replace papers definition name artifact
choice  yet another instantiation recommendation problem 
makes paper recommendation interesting 
   

fibasu  hirsh  cohen    nevill manning

ability automatically filter large set papers find
aligned one s research interests advantages  growing number
publications  many online  dicult keep latest research  even
it s within one s field  timeliness information becoming critical 
desirable paper reach target audience minimal latency  although
straightforward approach finding relevant papers may look close matches
person s interests paper s content  less clear represent
interests researchers contents papers 
another feature sets paper recommendation apart variant problem
must dealt regular basis numerous conference chairs  conferences
offer venue large number fairly specific papers must distributed smaller
number reviewers  within tight timeframe  even scope problem
constrained degree topic  conference organizers and or reviewers still must
expend great deal time effort begin reviewing process 
would suggest real value finding ways automating filtering process
would make less burdensome potential consumers 
consider algorithms recommending focused sets technical papers  use
conference reviewing platform explore series questions relating recommendation process  new interest ai community problem
recently since proposed  challenge  task ijcai     geller         focus
conference reviewing turns natural choice since obtain data
set papers  i e   conference submissions  obtain information
preferences set reviewers submissions  following section  discuss related work addresses conference reviewing problem  consider
work area recommender systems   e g   recommending articles newsgroup
readers recommending web pages web site visitors   contribute task 
however  focus varying sources information data representations 
thereby allowing us formulate different recommendation algorithms based recombine sources computing similarity  show indeed difference
performance vary amount source data  compared baseline
using single source information data representations  compare
recommendation algorithms other  collaborative filtering 
random assignment papers reviewers  apply methods experimental data
involving reviewer preferences conference abstracts aaai    conference   

   know paper recommendation
already know recommending papers reviewers  generally 
arbitrary researcher  trying selective choosing papers ultimately reach consumer based relevance interests expertise  however  finding
papers conference reviewers necessarily complex task  since papers may
assigned reviewers based criteria  instance  reviewer load balancing
con ict resolution reviewer author aliations may two criteria  addition 
   data obtained permission aaai  aaai reviewers  appropriate 
authors submitted papers 

   

fitechnical paper recommendation  study combining multiple information sources

reviewer s reviewing preferences may uenced considerations paper s
readability novelty  example  preference novelty may lead reviewer choose
paper simply relevant interests 
methods suited address latter issues number reasons  first 
confidentiality purposes  lack information related author identity aliation
submitted conference papers  secondly  since constraint satisfaction main
concern   primarily interested finding best papers person without
regard whether multiple people receive paper   incorporate
criteria selection procedure  way represent  novelty 
paper respect consumer  thereby means recognizing
it  finally  methods distinguish notion interest expertise
respect reviewers  general recommendation problem  researcher
may want retrieve papers areas outside expertise  case separate
representation would needed 
previous work area assigning conference papers reviewers approached
problem one content based information retrieval  dumais nielsen        used
data provided    members reviewing committee hypertext     conference  reviewers submitted abstracts papers and or interests 
provided complete relevance assessments     papers submitted conference 
using information retrieval method known latent semantic indexing  lsi   compared reviewer abstracts submissions  ranking submissions
least similar reviewer  results  noticed  based performance
metric evaluates number relevant articles returned top    
could achieve average     improvement using automated methods compared
random assignment articles reviewers 
results encouraging  believe widespread availability online
resources introduces opportunities exploring new issues  reviewers
weren t asked supply interest information  process gleaning reviewer interest
data automated simple methods  well retrieving relevant papers
using  approximation  reviewer interests  automatic collection reviewer
interest information web  effectively removes reviewer loop 
novel aspect research 
yarowsky florian        attempted similar task acl    conference  however  primary focus classification   assignment every paper exactly
one six conference committees  used    papers submitted acl
conference electronic form requested committee members provide representative papers  number papers returned members insucient 
augmented collection papers downloaded online sources  used
content based retrieval  within context vector space model  salton         one
routing strategies  main algorithm first computed centroid reviewer
based representative papers computed centroid committee
sum reviewer centroids  then  paper classified  assigned committee 
computing cosine similarity committee centroids choosing one
highest rank  amongst approaches  experimented naive bayes classifier
assessment similarity reviewing committee members authors cited
   

fibasu  hirsh  cohen    nevill manning

papers  based system performance relative human judges
task  evaluated actual assignments provided program chair conference   extrapolated automated methods could effective human judges 
especially cases judges may less experienced 
dealing large conferences several hundred papers covering variety areas  information load even greater conference organizers reviewers
alike  cases  getting evaluative relevance judgments submitted  or even accepted  papers reviewers feasible   as example  aaai conference 
reviewers even state preferences papers potentially
review  instead  stop scanning list soon filled quota
 bids   papers expressed interest reviewing   therefore  focus building
extensible framework recommendation   defining process whereby systematically incorporate information formulating recommendation algorithms 
purpose generating better recommendations 
content based information retrieval  known content based filtering  popular
recommendation method  consider systems recommend web pages syskill  
webert  pazzani   billsus         number systems webwatcher
fab content based filtering  mainly part hybrid approach
involves collaborative filtering  whereas content based filtering looks contents
artifact  e g   words web page   collaborative filtering consider
opinions like minded people respect artifacts  collaborative filtering
used recommend netnews articles  konstan  miller  maltz  herlocker  gordon 
  riedl         movies  hill  stead  rosenstein    furnas        basu  hirsh    cohen 
       music  cohen   fan        shardanand   maes         even jokes  gupta 
digiovanni  narita    goldberg         since content based collaborative methods
use data orthogonal one another  opportunities come hybrid
approaches use combinations data  work movie recommendation
provides another example design hybrid system  hybrid systems exploit data
multiple sources expectation better compensating
limiting factor data sparseness associated single source 
current study  would identify different sources information describe
papers reviewers  expectation individual pieces themselves  along
knowledge combine them  make difference recommendations 
although share common goal combining data multiple sources
hybrid recommendation approaches  algorithms develop strictly contentbased  evaluative purposes  compare algorithms results
applying collaborative filtering methods set reviewer preferences 

   representing papers reviewers
approach recommendation represent entity using variety information
sources  enumerate different combinations sources  evaluate effectiveness combinations using ranked retrieval methods  paper recommendation
problem  two types entities   papers consumers  reviewers 
case   entity  represent salient features entity sequence
   

fitechnical paper recommendation  study combining multiple information sources

one information sources  addition  need another type information
source relates reviewer paper  namely  reviewers  actual preferences
papers  begin discussion choice information sources  
choices based data typically used assign papers reviewers 
usually provided explicitly papers  authors  choices rely implicit
knowledge mined semi structured data available web 

    paper information sources

experiments based compilation submitted abstracts obtained
aaai aaai    conference      papers submitted conference 
aaai gave us collection     papers use experiments   abstracts    
accepted papers abstracts     papers rejected whose authors
granted aaai permission provide abstract work  excluded
papers authored authors paper 
submission obtained title  abstract  set user assigned keywords
prespecified list  therefore  paper associated set three information sources provided papers  authors  although one may consider
body paper another source  information available reviewers
 nor us   use source 

    reviewer information sources

far  seen example entity paper represented
multiple information sources mainly composed distinct units title 
abstract  etc  however  another case may want multiply represent
entity  consider trying automatically compose representation reviewer s interests 
may try first go reviewer s home page  there  may decide look
around reviewer s papers  sources offer different point of view
reviewer s interests  therefore  considered separate unit  focus
sources   reviewer s entry level home page papers referenced
home page   substitute asking reviewer provide interest information 
believe home pages online papers credible information sources since
likely fair number conference reviewers stated research interests
either sources  since one paper information sources paper abstract 
decided represent reviewer  abstract interests   case home
pages  entire text reviewers s entry level home page taken abstract
reviewer s interests  case postscript files  define abstract first
    words extracted paper 
extracted information web using pre existing utilities  find
reviewers  home pages  fed names aliations members review
committee ahoy   home page finding engine  shakes  langheinrich    etzioni        
ahoy returned least one match  supplied url starting point
w mir   http service retrieves files contents web sites  used
   http   ahoy cs washington edu      
   http   www math uio no janl w mir 

   

fibasu  hirsh  cohen    nevill manning

w mir download html files postscript files accessible entry level
home page residing site   since person s papers may directly
available one site  additionally retrieved cross references sites
contained postscript files  using w mir  postscript files converted
ascii using prescript  nevill manning  reed    witten        
postscript files retrieved reviewer treated uniformly  although would
desirable attempt future work  make attempt determine
timeliness paper  especially respect reviewer s current interests 
distinguish journal papers  conference papers  even lecture notes 
reason attempt detailed analysis contents
files  e g   automatically extract titles  abstracts  etc    instead  rely heuristics
looking first n words approximate paper s abstract  although detailed
analysis likely valuable paper recommendation process  immediate goal
obtain gross sense usability various sources semi structured information 

    reviewer preferences
evaluate queries need  ground truth    set data specifying
papers reviewer selected suitable review  information 
evaluate different approaches perform making choices  note
approximation full set abstracts reviewer might liked
  reviewing process requires reviewer find minimum quota papers 
quota reached  reviewer need look papers find more 
view optimistically yielding close approximation reviewer s full set
preferences would be  since reviewers able peruse abstracts keywords often
attempt inspect least subset papers labeled keywords areas
knowledgeable 
experiments ground truth comes actual preferences stated      of
     aaai    reviewers gave aaai permission release preference information papers considered work  point data ects
reviewers  initial preferences reviewing  data papers
reviewers actually received following aaai reviewer assignment process 
course  one potential limitation data based portion data
may representative entire data conference  example 
preference data approximately half reviewers predicting preferences
collection papers whose distribution skewed towards accepted papers 
issue whether aaai researchers representative much larger community
researchers large   we ask similar question user populations
conferences well   however  consider acceptable limitations resulting
use conference reviewing platform paper recommendation 
   moment  focus postscript convenience  reason limit
one file format  main constraint able extract words document 

   

fitechnical paper recommendation  study combining multiple information sources

   recommendation methodology

section  examine collaborative content based methods recommendation  methods allow us explore use different subsets data described
previous section 

    recommending reviewer paper information sources

following sections  outline content based recommendation framework uses
data describing papers well data describing reviewers make recommendations  reviewer preference data used evaluation purposes  input
recommendation process 
order locate papers closely match reviewer interest data rely ad hoc
similarity metrics commonly used information retrieval community  describe
methods section whirl  brief  reviewer compare
given reviewer representation appropriate paper information source s  
comparisons implemented query returns rank ordered list
papers  consequently compute precision top n   proportion papers
returned actually preferred reviewer  query  final score
query average value  computed subset    reviewers  from
larger set reviewers gave us permission  
recommendation algorithms take different paper reviewer information sources
inputs  since data plotted along two dimensions  let reviewer set
information sources describing reviewers paper set information sources describing
papers  construct reviewer paper matrix entry matrix
score measuring effectiveness using respective sources   reviewer   paper   
compute similarity reviewers papers performing ranked retrieval 
instance  given paper reviewer representations described  construct
    matrix  gives us   possible evaluations scores  refer matrix
recommendation sources matrix 
conceptually  extend recommendation sources matrix along dimension 
considering combinations rows columns  refer augmented matrix
source combinations matrix  define recommendation algorithm
combination method procedure applied one rows columns source
combinations matrix  introduces another dimension comparison   combination
method   consider looking replicates source combinations matrix 
now  pose following questions experimental analysis 


j

recommendation algorithms incorporate information lead better performance 
so  method combining data used algorithm make difference 
      whirl

queries  use whirl  system specifically designed informationintegration tasks  cohen      b  cohen   hirsh         tasks  often necessary manipulate general way information obtained many heterogeneous online
   

fibasu  hirsh  cohen    nevill manning

sources  potentially data organization terminology  particular 
whirl makes possible integrate information decomposed represented
clean  modular way  example  would information home pages
postscript papers represented separately  using information integration tool
resolve sources information 
whirl conventional dbms extended use ad hoc similarity metrics
developed information retrieval community  using metrics  reason
pieces text culled heterogeneous sources based similarity values rather
strict equality  whirl computes similarity using  vector space  representation
model text  salton         text object represented vector term weights
 where terms stemmed using porter s algorithm  porter         based
tfidf weighting scheme  similarity two vectors computed using cosine
similarity metric  answers query presented rank ordering generated
tuples  tuples similar pairs attribute fields appearing first 
example  using whirl  pose following query 
select reviewer name  paper id
paper reviewer
reviewer descriptor sim paper abstract

query return list reviewer names paper ids papers whose abstracts
similar reviewer s interest descriptor  rather returning tuples
descriptor abstract fields identical  would performed traditional
database join  query returns name id pairs tuples whose fields contain
similar terms  ordered according decreasing value similarity  advantage
ad hoc joins without requiring textual fields identical one another important
text comes multiple sources thereby may use different terminology 
important perspective comparing relative importance different fields
one another ecient way 
use whirl data must stored form whirl relations 
data constructed two relations  one representing different information sources 
conference submission  form paper relation containing id  abstract  keywords 
title  every reviewer  form reviewer relation contains single tuple
attributes representing reviewer s name representation reviewer s
interests  for example  based reviewer s home page  
far  discussed use whirl formulate queries involving single
information source reviewers papers  however  advantage whirl
approach lies simplicity extend queries incorporate multiple sources  primary advantage using whirl work ease
measure impact conjunctive queries incorporating data multiple sources 
form conjunctive queries adding multiple conditions clause 
select reviewer name  paper id
paper reviewer
reviewer descriptor sim paper abstract
reviewer descriptor sim paper keywords
   

fitechnical paper recommendation  study combining multiple information sources

whirl clause contains multiple conditions  similarity scores
individual conjuncts combined taking product though
independent probabilities  since similarity scores independent probabilities 
use convenient way combine scores  albeit one offers straightforward
approach combination previously studied  cohen      a  
query  whirl would assign score ects similarity submitted
paper s abstract reviewer s descriptor  well similarity submitted
paper s keywords reviewer s descriptor 
      combining information sources query expansion

mean recommendation algorithm combine data multiple information sources  means enumerating information sources used possible
inputs algorithm  defining way use sources compute similarity 
instance  suppose look   reviewer source   paper sources given collection
reviewers papers  decide whether paper likely interest reviewer 
compute similarity reviewer source paper sources
combine two similarity scores  alternatively  compute single similarity score
first combining two paper sources single representation computing
similarity respect reviewer source 
idea combining two sources single representation implemeted
appending terms sources  information retrieval  terms relevant sources
often appended baseline representation query process query
reformulation  usually referred query expansion  since methods bear
resemblance query expansion  make analogy  expansion methods
described following sections  course  prior knowledge
relevance sources  sense  differ information retrieval
implementation query expansion 
compare relative performance recommendation algorithms 
multiple dimensions along compare results  differentiate results
based methods used combine data compute similarity differentiate results based information sources used comparison 
words  set inputs  one method query expansion perform
better another  want compare merit single source  consider
two groups algorithms   include given source input algorithm 
exclude source  simply count number times algorithms
include source outperform algorithms exclude it  determine relative
merit source 
      concatenation method

one way  add  information new data source append terms appearing
source original whirl query  type query  always single
whirl conjunct textual fields appearing conjunct  grow 
addition new terms  call method  queryconcat 
   

fibasu  hirsh  cohen    nevill manning

suppose  example  start base query previous section
compares reviewer descriptors paper abstracts  now  suppose want compare
reviewer descriptors paper abstracts paper keywords  one
way use queryconcat method  form new field representing
union words appearing paper abstract paper keywords fields
substitute original query  let paper descriptor   paper abstract   paper keywords 
new query is 
select reviewer name  paper id
paper reviewer
reviewer descriptor sim paper descriptor

similarly  replace paper descriptor clause represent different
combinations fields  paper abstract  paper keywords paper title using union
operator 
      conjunction method

previously stated  important motivation using whirl ability execute
conjunctive queries  use combine information sources recommendation process  type query  instead adding terms particular text field 
add conjuncts original where  refer method reformulating queries
queryconjunct 
enumerate query combinations considered queryconjunct follows 
using sources queryconcat  begin queries before 
select reviewer name  paper id
paper reviewer


now  replacing body clause following 
a  reviewer descriptor sim paper abstract
k  reviewer descriptor sim paper keywords
t  reviewer descriptor sim paper title
ak  reviewer descriptor sim paper abstract
reviewer descriptor sim paper keywords
at  reviewer descriptor sim paper abstract
reviewer descriptor sim paper title
kt  reviewer descriptor sim paper keywords
reviewer descriptor sim paper title
akt  reviewer descriptor sim paper abstract
reviewer descriptor sim paper keywords
reviewer descriptor sim paper title

assign labels   abstract   k  keywords    title  queries identify
paper sources used   we use labels comparable fashion queryconcat
method  representing information sources concatenated together  
   

fitechnical paper recommendation  study combining multiple information sources

queries  vary source data used represent
reviewers  first variant accounts case reviewer s descriptor contains
words reviewer s home page  second accounts case descriptor
contains union first     words extracted postscript file obtained
reviewer s web pages 
decided try yet another combination see whether using representations
reviewers would improve performance  simplicity  chose test hypothesis
expanded conjunctive query involving single extra conjunct  constructed
reviewer table contains two attributes  papers  consisting abstracts
reviewer s postscript papers  homepage  consisting reviewer s home page  
ran queries  additional conjunct appearing
clause 
reviewer homepage sim paper keywords

chose use keywords paper descriptor based intuitions paper s
keywords reviewer s homepage would greater number words common 

    recommending reviewer preferences

since evaluations reviewers common set papers  one approach
recommending papers would take information use collaborative
filtering  note actual conference reviewing problem  collaborative filtering
method assigning papers may practical  although benefit
using preferences set reviewers study  information generally
available reviewers making selections  thereby making
dicult base predictions preferences others  nevertheless  worthwhile
measure impact using reviewer preferences purpose recommending papers 
recommendation methodology collaborative filtering approaches implemented follows  reviewer presented recommended paper online
manner  paper presented reviewer tells system paper relevant  was  paper assigned rating   paper said rated
positively  paper relevant  assigned rating   said rated
negatively  let rating  r  p   represent rating assigned paper p
reviewer r  paper relevant  reviewer provides single relevant
paper positive example order condition future recommendations  since know
papers liked reviewers  simulate process data
have  experiment two collaborative filtering algorithms  knn  hill et al        
cohen   fan        extended direct bayes  cohen   fan         let p   p       p   
represent papers previously rated reviewer     trials 
knn algorithm uses following distance metric locate reviewers  r   closest
current reviewer respect papers already rated 




dist r  r     jrating  r  p     rating  r   p  j         jrating  r  p       rating  r   p    j




compute score arbitrary paper  p   respect ratings
k closest reviewers  r      r   follows 
k

   

fibasu  hirsh  cohen    nevill manning

score p     rating  r   p           rating  r   p  
k

according methodology  highest scoring paper presented
reviewer next recommendation 
extended direct bayes viewed ad hoc extension direct bayesian approach recommendation  define r p   p   represent laplace corrected estimate
prior probability reviewer give p positive rating   r p   p  
thought measuring  relatedness  two papers   consider arbitrary
trial let p   p      p    represent papers rated positively
reviewer previous trials consider arbitrary trial t 
use following scoring function rank paper p  


j

j



j



score p               r p  p             r p  p      


subtrahend expression represents probability p related
p  assuming p  s independent  




    evaluation methodology

following sections  evaluate performance recommendation algorithms 
collaborative filtering  compute recommendations reviewer run
positive examples use feedback  reviewer s list recommendations 
measure precision top n   gives us proportion items returned
top n given reviewer actually preferred reviewer  although
possible use evaluation metrics  compute precision different levels papers
returned since well suited conference reviewing task  since reviewer may get
list    papers review  would simulate recommending top
   papers returned methods  computing precision  measure percentage
papers list would matched reviewer s preferences  metric
commonly used literature  instance  dumais nielsen        mostly used
measure  i e   number relevant articles top     reporting results
since constituted reasonable reviewer load  additionally report results precision
top     knn algorithm  set k      experiments 
recommendation algorithms seen choice query expansion method
crossed choice input data sources  methods queryconjunct
queryconcat  ran     queries detailed previous section  resulted   
runs per reviewer  per method  run returned ordered list paper ids  run 
measure precision top n  for n      n        discussion 
refer run using abstracts based reviewer s papers p run  similarly  h runs
based reviewer s home page  finally  ph runs combine sources information
 using extra conjunct   results report represent precision values averaged
across reviewers  order us compare performance across different information
sources  need evaluation using population reviewers 
reviewers provided preference data home pages and or papers available online 
therefore  performed set runs using    reviewers randomly chosen set
   

fitechnical paper recommendation  study combining multiple information sources

source s 
p top   
h top   
ph top   
p top   
h top   
ph top   


     
     
     
     
     
     

k
     
     
     
     
     
     


     
     
     
     
     
     

ak
     
     
     
     
     
     


     
     
     
     
     
     

kt
     
     
     
     
     
     

akt
     
     
     
     
     
     

table    average precision scores top    top    papers returned using queryconjunct 
reviewers home pages papers available online  report results averaged
across    reviewers 
mentioned earlier  reviewer choices may uenced variety factors
ranging person s curiosity paper s readability  many factors dicult
model  furthermore  human judges may assign papers reviewers according criteria
relevance paper contents reviewer interests  individual opinions
may vary  therefore  highly unlikely proposed methods achieve     
precision  unfortunately  given nature problem  able get
assessment human judges would done task  nevertheless 
evaluate recommendation framework built content based information retrieval
principles compare relative performance reasonable baseline approaches 

   results
number questions would keep mind analyze results 
course experiments vary amount information input
algorithms method query expansion used algorithms  one questions
would answer algorithm set algorithms suited task
hand  ask whether choice inputs results measurable differences
performance  tabulation results provides basis analyzing contentbased algorithms presented table   table    baseline method
compare algorithms random assignment  method assigns reviewer random
collection papers  method  expect precision       words 
means select papers randomly  average  reviewer would
fewer      papers selected 
table   table   replicates source combinations matrix discussed
earlier  since ran two trials top n papers returned  table actually
concatenated representation matrices top    top    experiments 
first three rows table   table    report precision figures top   
papers returned queryconjunct method queryconcat method  respectively 
   

fibasu  hirsh  cohen    nevill manning

precision top    top   
   
compare dat
x

    
    
    
queryconjunct method

    
   
    
    
    
    
   
    
    
    

   

    
   
queryconcat method

    

   

figure    comparison two query methods
similarly  show results top    papers returned bottom three rows
tables  since view rows representing reviewer sources used query
columns representing paper sources  measure impact adding data
two ways  reading across row  across groups columns representing n information
sources  gauge results vary paper data included queries 
similarly  reading column  gauge differences results
reviewer data included queries 
given information  say performance recommendation
algorithms used different methods query expansion  compare relative
performance two methods queryconjunct queryconcat based values listed
table   table    note cases performance methods exceeds
random selection  accuracies factor     times better  figure   
record information data point every query uses two sources
information  since methods differ combine data two sources 
meaningless plot points refer queries using single source   figure 
x axis represents queries expanded using queryconcat method y axis represents
queries expanded using queryconjunct method  point falls x   line 
two methods yielded performance query using information
sources  points fall area x   line mark queries
queryconjunct higher precision queryconcat  data reveal almost
cases  queryconjunct higher precision queryconcat  thereby making queryconjunct
dominant two query expansion methods preferred method two
task hand 
expectation increase source data notice increase
precision  specifically  note queryconjunct  query uses
information paper submission majority cases performs statistically significantly
   

fitechnical paper recommendation  study combining multiple information sources

source s 
p top   
h top   
ph top   
p top   
h top   
ph top   


     
     
     
     
     
     

k
     
     
     
     
     
     


     
     
     
     
     
     

ak
     
     
     
     
     
     


     
     
     
     
     
     

kt
     
     
     
     
     
     

akt
     
     
     
     
     
     

table    average precision scores top    top    papers returned using queryconcat 
better  queries use less information case performs statistically significantly worse 
note adding information always lead monotonically better
results  notice queryconjunct  case top    papers returned  hkt indistinguishable hakt  note pht performs better  though statistically
significantly better  phkt  similar cases queryconcat  explain gaps  indeed gaps  i e   true statistical differences 
may consider explanation adding information may increasing amount
noise representations  consider  example  keywords fixed list
often poor match real subject matter paper  special cases  use
keywords source could lead degradation retrieval performance 
analogous analysis paper sources  examine column
table   table   measure effect adding information reviewer representation  queryconjunct  majority time  find queries incorporating
information  ph entries  perform statistically significantly better single source
queries  p h entries  
far  illustrated move across groups columns blocks
rows source combinations matrix  adding sources queries
improvement  significant gains realize this  focusing
queryconjunct  every reviewer source  consider queries contained data
single paper source lowest precision  pair queries
corresponding query row matrix made use paper sources
report resulting improvement precision table    top    results 
note best case  gain improvement precision     going
single source multi source query  top    results  gain improvement
   comparisons two queries qi qj made using two tailed sign test  specifically 
consider set rij reviewers r precision qi   r     precision qj   r  estimate
probability
pij   p rob precision qi   r     precision qj   r   j r   rij  
consider difference statistically significant one reject confidence        null
hypothesis pij generated j rij j independent ips fair coin 

   

fibasu  hirsh  cohen    nevill manning

single source queries improvement adding two sources
pt top    
   
ha top    
   
phk top    
   
pt top    
   
ha top    
   
phk top    
   

table    comparision single source vs  multi source queries 
methods s 

top    top   
knn
           
extendeddirectbayes            

table    average precision scores top    top    papers returned using collaborative filtering methods 
     results support intuitions incorporating information
queries  quality retrieval results improves  since different paper
source single source queries row table    note impact
given paper source dependent reviewer representation use 
still come assessment sources significant conference reviewing task  queryconjunct  present series figures  figure   figure   
illustrate impact source plotting precision values queries exclude
source along x axis precision values queries include source along
y axis  for n      n        point falls x   line  queries
exactly performance   choice source irrelevant  points fall
area x   line mark queries higher precision compared
query counterparts contain source 
simply counting number times queries include source outperform
queries include source  one way ranking sources
decreasing order importance  case  queries include abstract source
papers home page source reviewers highest rates success  when
compared information sources papers reviewers  respectively  
now  natural question ask whether trends noticed queryconjunct
hold queryconcat  answer no  means queryconcat
give us definitive answer question whether information really better 
noticed query performance linked reviewer paper
sources  find linked query expansion method 
   

fitechnical paper recommendation  study combining multiple information sources

precision top    top   
   
a dat
x

    
    
    

queries abstract

    
   
    
    
    
    
   
    
    
    

   

    
   
queries without abstract

    

   

figure    role abstract information source

precision top    top   
   
k dat
x

    
    

queries keywords

    
    
   
    
    
    
    
   
    
    
    

   

    
   
queries without keywords

    

   

figure    role keywords information source

   

fibasu  hirsh  cohen    nevill manning

precision top    top   
   
t dat
x

    
    
    

queries titles

    
   
    
    
    
    
   
    
    
    

   

    
   
queries without titles

    

   

figure    role title information source

precision top    top   
   
p dat
x

    
    

queries reviewer papers

    
    
   
    
    
    
    
   
    
    
    

   

    
   
queries without reviewer papers

    

   

figure    role papers information source

   

fitechnical paper recommendation  study combining multiple information sources

precision top    top   
   
h dat
x

    

queries reviewer homepages

    
    
    
   
    
    
    
    
   
    
    
    

   

    
   
queries without reviewer homepages

    

   

figure    role homepage information source
table    show results collaborative filtering runs  report averages
precision values computed top n  for n     n      papers returned
based reviewer recommendation lists  since stop recommending
exhausted set positive examples reviewer  reviewer recommendation lists
varying lengths  cases size list less n   still compute
precision top n   assuming remaining items incorrect predictions  methods
collaborative filtering exceed random selection significant margin 
top    papers returned  collaborative recommendation methods competitive best performance queryconcat  already interesting observation 
since methods differ  method using different data make recommendations  state use queryconjunct information
sources recommend    papers  average almost four papers coincide reviewer s
preferences  compared random selection  collaborative filtering  queryconcat 
method yields papers interest reviewers 
summary  learned experiments  found within
context peer reviewing papers  make recommendation process less
 people intensive   recommendation systems require users provide samples
preferences used extrapolate future behaviors  collaborative
methods go even using preference information across multiple users predict
preferences single user  automatically collecting reviewer interest information
web sources precomputing similarities profiles paper content 
require less input reviewers  furthermore  content based retrieval methods
exceed performance collaborative methods task 
believe recommendation framework provides extensible way
formulating queries provides control information content queries 
control much information include queries
incorporate information  new data become available  evaluate data
   

fibasu  hirsh  cohen    nevill manning

sources and or combinations effective  thereby fine tuning query formulation
process 

   related work query reformulation

since work expanding queries using whirl viewed type query
reformulation  review related work information retrieval community
topic  salton        describes process query reformulation  moving 
given query towards relevant items away nonrelevant ones  context
vector space model retrieval  means given query expression form
 salton        
q      q     q          qt 

q number     representing weight assigned term   want
arrive new query expression 




q      q     q          qt 
 

 

 

 

weights adjusted new terms introduced vector
representation  terms effectively removed reducing respective
weights   
harman        describes operational procedure underlying process merging document query vectors  specifically  means query terms
original query appearing relevant documents added initial query
expression  expansion occurs using positive negative weights  depending
whether terms appears relevant non relevant document 
description assumes relevance judgments documents
system return  practically speaking  type information hard come by 
therefore  people seeking compensate lack information expanding
queries using variety techniques use thesauri relevance feedback 
latter case  query reformulation part iterative interactive process whereby
users presented results retrieval asked supply feedback regarding
relative importance results 
comparing approach methods query reformulation  make couple
observations  first  query reformulation driven knowledge precomputed
data colection  given entities papers abstracts  keywords 
titles  make sense vary amount information queries 
equivalent table   collection  table lookup run time determine
formulations promising 
note way construct queries queryconjunct method combines
aspects boolean vector space models query formulation hybrid approach  case boolean queries  relevance feedback lead new query expressions
consisting term conjuncts  salton        
 term term term  
notice replace term vector expression 
query expression formulated according queryconjunct method 


j



k



   

fitechnical paper recommendation  study combining multiple information sources

   conclusions

paper  shown collect information reviewers automatically
web  use part recommendation framework route papers
reviewers  treat problem one decomposing reviewer interest paper
contents information sources  combining information sources using
different query formulations  experiments  compared two ways formulating
queries using content based information retrieval one collaborative approach 
found recommendation algorithm using conjunctive queries outperforms
approaches  looked using different subsets information sources
algorithms  case optimal algorithm  found using information
generally lead better performance 
practical setting  recommendation method choice likely depend
number factors ranging availability information ease use  one
hand  framework provides exible alternative simple keyword based searches
less intrusive alternative collaborative methods  hand  methods
assume obtain data reliable  accurate  timely  based results 
optimistic web provide credible information sources used
successfully recommendation process 

   acknowledgments

extend thanks aaai  aaai reviewers  aaai paper authors  members
rutgers machine learning research group  reviewers paper
inputs work 
note following property respective companies listed 
whirl  at t labs   research   lsi  telcordia technologies  inc   

references

basu  c   hirsh  h     cohen  w          recommendation classification  using social
content based information recommendation  proceedings aaai    
cohen  w       a   integration heterogeneous databases without common domains using
queries based textual similarity  proceedings acm sigmod    
cohen  w       b   whirl approach information integration  ieee intelligent
systems  ieee press 
cohen  w     fan  w          web collaborative filtering  recommending music crawling web  proceedings www      
cohen  w     hirsh  h          joins generalize  text classification using whirl 
proceedings kdd    
dillon  m     desper  j          automatic relevance feedback boolean retrieval systems 
journal documentation     
   

fibasu  hirsh  cohen    nevill manning

dumais  s     nielsen  j          automating assignment submitted manuscripts
reviewers  proceedings acm sigir    
geller  j          challenge  ijcai      prove value ai using ai 
proceedings ijcai    
gupta  d   digiovanni  m   narita  h     goldberg  k          jester      new lineartime collaborative filtering algorithm applied jokes  workshop recommender
systems acm sigir    
harman  d          relevance feedback revisited  proceedings acm sigir    
hill  w   stead  l   rosenstein  m     furnas  g          recommending evaluating
choices virtual community use  proceedings chi    
konstan  j   miller  b   maltz  d   herlocker  l   gordon  l     riedl  j          grouplens 
applying collaborative filtering usenet news   vol     
nevill manning  c   reed  t     witten  i          extracting text postscript  software
practice experience         
pazzani  m     billsus  d          learning revising user profiles  identification
interesting web sites  machine learning              
porter  m          algorithm sux stripping  program              
salton  g          automatic text processing  addison wesley 
salton  g          improving retrieval performance relevance feedback  readings
information retrieval 
shakes  j   langheinrich  m     etzioni  o          dynamic reference sifting  case study
homepage domain  proceedings www    
shardanand  u     maes  p          social information filtering  algorithms automating
 word mouth   proceedings chi    
yarowsky  d     florian  r          taking load conference chairs  towards
digital paper routing assistant  proceedings      joint sigdat conference
empirical methods nlp very large corpora 

   


