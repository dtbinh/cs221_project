journal of artificial intelligence research                  

submitted        published     

abstract reasoning for planning and coordination
bradley j  clement

brad   clement   jpl   nasa   gov

jet propulsion laboratory  mail stop          
pasadena  ca       usa

edmund h  durfee

durfee   umich   edu

university of michigan  eecs department ann arbor  mi       usa

anthony c  barrett

tony  barrett   jpl   nasa   gov

jet propulsion laboratory  mail stop          
pasadena  ca       usa

abstract
the judicious use of abstraction can help planning agents to identify key interactions between
actions  and resolve them  without getting bogged down in details  however  ignoring the wrong
details can lead agents into building plans that do not work  or into costly backtracking and replanning once overlooked interdependencies come to light  we claim that associating systematicallygenerated summary information with plans abstract operators can ensure plan correctness  even for
asynchronously executed plans that must be coordinated across multiple agents  while still achieving valuable efficiency gains  in this paper  we formally characterize hierarchical plans whose
actions have temporal extent  and describe a principled method for deriving summarized state and
metric resource information for such actions  we provide sound and complete algorithms  along
with heuristics  to exploit summary information during hierarchical refinement planning and plan
coordination  our analyses and experiments show that  under clearcut and reasonable conditions 
using summary information can speed planning as much as doubly exponentially even for plans
involving interacting subproblems 

   introduction
abstraction is a powerful tool for solving large scale planning and scheduling problems  by abstracting away less critical details when looking at a large problem  an agent can find an overall solution to the problem more easily  then  with the skeleton of the overall solution in place  the agent
can work additional details into the solution  sacerdoti        tsuneto  hendler    nau        
further  when interdependencies are fully resolved at abstract levels  then one or more agents can
flesh out sub pieces of the abstract solution into their full details independently  even in parallel  in
a divide and conquer approach  korf        lansky        knoblock        
unfortunately  it is not always obvious how best to abstract large  complex problems to achieve
these efficiency improvements  an agent solving a complicated  many step planning problem  for
example  might not be able to identify which of the details in earlier parts will be critical for later
ones until after it has tried to generate plans or schedules and seen what interdependencies end up
arising  even worse  if multiple agents are trying to plan or schedule their activities in a shared
environment  then unless they have a lot of prior knowledge about each other  it can be extremely
difficult for one agent to anticipate which aspects of its own planned activities are likely to affect 
and be affected by  other agents 

c
    
ai access foundation  all rights reserved 

fic lement  d urfee     barrett

in this paper  we describe a strategy that balances the benefits and risks of abstraction in largescale single agent and multi agent planning problems  our approach avoids the danger of ignoring
important details that can lead to incorrect plans  whose execution will fail due to overlooked interdependencies  or to substantial backtracking when abstract decisions cannot be consistently refined 
meanwhile  our approach still achieves many of the computational benefits of abstraction so long
as one or more of a number of reasonable conditions  listed later  holds 
the key idea behind our strategy is to annotate each abstract operator in a plan hierarchy with
summary information about all of its potential needs and effects under all of its potential refinements  while this might sound contrary to the purpose of abstraction as reducing the number of
details  in fact we show that it strikes a good balance  specifically  because all of the possibly
relevant conditions and effects are modeled  the agent or agents that are reasoning with abstract
operators can be absolutely sure that important details cannot be overlooked  however  because
the summary information abstracts away details about under which refinement choices conditions
and effects will or will not be manifested  and information about the relative timing of when conditions are needed and effects achieved  it still often results in an exponential reduction in information
compared to a flat representation 
based on the concept of summary information  this paper extends the prior work summarized
below and in section   to make the following contributions 
a formal model of hierarchical plans with temporal extent  and of their execution  while
many planning systems have sophisticated temporal models  e g   laborie   ghallab        muscettola        and some additionally use hierarchical representations of alternative courses of action
 allen  kautz  pelavin    tenenberg        currie   tate        chien  knight  stechert  sherwood    rabideau      a  castillo  fdez olivares  garca perez    palao         we know of no
other work that extends the hierarchical task network  htn  formalization  erol  hendler    nau 
    a  erol  nau    hendler      b  to include temporal extent  we need such a formalism in order
to clarify the semantics of summary information and concurrently executing agents 
algorithms for deriving summary information about propositional and metric resource conditions and effects  and for using such information to determine potential and definite interactions between abstract tasks  we prove that our summarization techniques are guaranteed to
correctly capture all of the conditions and effects associated with an abstract operator appropriately  augmented with modal information about whether conditions must or may hold and whether
they hold during the entire operation or only for some of the time  because summary information
captures all conditions and effects  our algorithms can reason with operators at different levels of
abstraction to predict and often resolve operator interactions without fully detailing task hierarchies 
even for operators that are executing asynchronously at different agents 
sound and complete algorithms for hierarchical refinement planning and centralized plan coordination for actions with temporal extent  supporting flexible plan execution systems  an
agent can reduce backtracking during planning by selectively interleaving the refinement of its plan
with predicting and resolving potential interdependencies between its evolving plan and the plans
that will be asynchronously executed by other agents  other research has also found benefit in
guiding refinement with conditions specified at higher levels in the plan hierarchy to guide refinement  sacerdoti        young  pollack    moore        tsuneto et al          we show that our
algorithms improve on these capabilities by exploiting the hierarchical structure using summary

   

fia bstract r easoning for p lanning and c oordination

information to more efficiently converge on coordinated plans  which can then be further refined
individually and in parallel by the participating agents 
this ability to coordinate at abstract levels rather than over detailed plans allows each of the
agents to retain some local flexibility to refine its operators as best suits its current or expected
circumstances without jeopardizing coordination or triggering new rounds of renegotiation  in this
way  summary information supports robust execution systems such as prs  georgeff   lansky 
       umprs  lee  huber  durfee    kenny         raps  firby         jam  huber         etc 
that interleave the refinement of abstract plan operators with execution 
our approach also extends plan coordination  plan merging  techniques  georgeff        lansky        ephrati   rosenschein        by utilizing plan hierarchies and a more expressive temporal model  prior techniques assume that actions are atomic  meaning that an action either executes
before  after  or at exactly the same time as another  in contrast  we use interval point algebra  vilain   kautz        to represent the possibility of several actions of one agent executing during
the execution of one action of another agent  because our algorithms can choose from alternative
refinements in the htn dynamically in the midst of plan coordination  they support interleaved local
planning  multiagent coordination  and concurrent execution 
search techniques and heuristics  including choose fewest threats first  cftf  and expandmost threats first  emtf   that take advantage of summary information to prune the search
space  when interdependencies run more deeply in agents plans  resolving them at abstract levels  if possible at all  can lead to unacceptable losses in parallel activity  fortunately  even when
agents need to delve into the details of their plans to tease out interdependencies  summary information can still enable exponential speedups by guiding decomposition and by pruning refinement
choices  the search efficiency of using summary information comes from ignoring irrelevant information  which in a distributed planning system also reduces communication overhead exponentially 
complexity analyses and experiments showing potential doubly exponential speedups in refinement and local search planning scheduling using summary information  our algorithms
demonstrate that exploiting summary information to guide hierarchical planning and scheduling can
achieve exponential speedups  and resolving interdependencies at abstract levels can improve the
performance of plan coordination algorithms doubly exponentially  while others have shown that
abstraction can exponentially reduce search space size  korf        knoblock        when subproblem independence properties hold  we show that our techniques lead to exponential improvements
if any of these broader conditions hold for the problem 
 solutions can be found at abstract levels 
 the amount of summary information is less at higher levels than at lower levels  or
 choices of decompositions lead to varying numbers of plan threats 
when none of these conditions hold  we show that generating and using summary information
provides no benefit and can increase computation and communication overhead  thus  care must be
taken when deciding to use summary information  though it has proven to be extremely worthwhile
in the types of problem domains we have examined  an example of which we next describe 

   

fic lement  d urfee     barrett

m 

m 
d
e

transport 

transport 

a

b

c

tool

bin 

bin 

bin 

bin 

dock

figure    a simple example of a manufacturing domain
produce h
produce g

produce h from g

produce g
on m 

produce g
on m 

move a b
to m 
move a to m 

move g
to m 
build h

move h
to bin 

build g

move b to m 

figure    the production managers hierarchical plan
    manufacturing example
as a running example to motivate this work  consider a manufacturing plant where a production
manager  a facilities manager  and an inventory manager each have their own goals with separately
constructed hierarchical plans to achieve them  however  they still need to coordinate over the use
of equipment  the availability of parts used in the manufacturing of other parts  storage for the parts 
and the use of transports for moving parts around  the state of the factory is shown in figure    in
this domain  agents can produce parts using machines m  and m   service the machines with a tool 
and move parts to and from the shipping dock and storage bins on the shop floor using transports 
initially  machines m  and m  are free for use  and the transports  transport  and transport    the
tool  and all of the parts  a through e  shown in their storage locations are available 
the production manager is responsible for creating a part h using machines m  and m   either m  and m  can consume parts a and b to produce g  and m  can produce h from g  the
production managers hierarchical plan for manufacturing h involves using the transports to move
the needed parts from storage to the input trays of the machines  manufacturing g and h  and transporting h back to storage  this plan is shown in figure    arcs through subplan branches mean
that all subplans must be executed  branches without arcs denote alternative choices to achieving
the parents goal  the decomposition of produce g on m  is similar to that of produce g on m  
the facilities manager services each machine by equipping it with a tool and then calibrating it 
the machines are unavailable for production while being serviced  the facilities managers hierarchical plan branches into choices of servicing the machines in different orders and uses the transports

   

fia bstract r easoning for p lanning and c oordination

maintenance
service m  m 

service m 

service m 

service m  m 

move tool
to dock

move tool equip m  tool calibrate m 
to m 

figure    the facilities managers hierarchical plan
move parts
move c to dock

move d e

move d to bin 

move e to bin 

figure    the inventory managers hierarchical plan
for getting the tool from storage to the machines  figure     the decomposition of service m m 
is similar to that of service m m  
the parts must be available on the space limited shop floor in order for an agent to use them 
whenever an agent moves or uses a part  it becomes unavailable  the inventory managers goal is
just to move part c to the dock and move d and e into bins on the shop floor  shown in figure    
to accelerate the coordination of their plans  each factory manager can analyze his hierarchical
plan to derive summary information on how each abstract plan operator can affect the world  this
information includes the summary pre   post   and in conditions that intuitively correspond to the
externally required preconditions  externally effective postconditions  and the internally required
conditions  respectively  of the plan based on its potential refinements  summary conditions augment state conditions with modal information about whether the conditions must or may hold and
when they are in effect  examples are given at the end of section     
once summary information is computed  the production and inventory managers each could
send this information for their top level plan to the facilities manager  the facilities manager could
then reason about the top level summary information for each of their plans to determine that if
the facilities manager serviced all of the machines before the production manager started producing
parts  and the production manager finished before the inventory manager began moving parts on and
off the dock  then all of their plans can be executed  refined  in any way  or cananyway  then the
facilities manager could instruct the others to add communication actions to their plans so that they
synchronize their actions appropriately 
this top level solution maximizes robustness in that the choices in the production and facilities managers plans are preserved  but the solution is inefficient because there is no concurrent
activityonly one manager is executing its plan at any time  the production manager might not
want to wait for the facilities manager to finish maintenance and could negotiate for a solution with
more concurrency  in that case  the facilities manager could determine that they could not overlap

   

fic lement  d urfee     barrett

their plans in any way without risking conflict  cananyway   however  the summary information
could tell them that there might be some way to overlap their plans  mightsomeway   suggesting
that a search for a solution with more concurrency  at the cost of perhaps committing to specific
refinement choices  has hope of success  in this case  the facilities manager could request the production manager for the summary information of each of produce hs subplans  reason about the
interactions of lower level actions in the same way  and find a way to synchronize the subplans for
a more fine grained solution where the plans are executed more concurrently  we give an algorithm
for finding such solutions in section   
    overview
we first formally define a model of a concurrent hierarchical plan  its execution  and its interactions
 section     next  we describe summary information for propositional states and metric resources 
mechanisms determining whether particular interactions must or may hold based on this information  and algorithms for deriving the information  section     built upon these algorithms are others
for using summary information to determine whether a set of chips must or might execute successfully under a set of ordering constraints  section     these in turn are used within a sound and
complete multilevel planning coordination algorithm that employs search techniques and heuristics
to efficiently navigate and prune the search space during refinement  section     we then show how
planning  scheduling  or coordinating at abstract levels can exponentially improve the performance
of search and execution  section     we provide experimental results demonstrating that the search
techniques also greatly reduce the search for optimal solutions  section     finally  in section   we
differentiate our approach from related work that we did not mention elsewhere and conclude 

   a model of hierarchical plans and their concurrent execution
a representation of temporal extent in an htn is important not only for modeling concurrently
executing agents but also for performing abstract reasoning with summary information  if an agent
is scheduling abstract actions and can only sequentially order them  it will be severely restricted
in the kinds of solutions it can find  for example  the agent may prefer solutions with shorter
makespans  and should seek plans with subthreads that can be carried out concurrently 
in this section we define concurrent hierarchical plans  chips   how the state changes over time
based on their executions  and concepts of success and failure of executions in a possible world  or
history  because we later define summary information and abstract plan interactions in terms of the
definitions and semantics given in this section  the treatment here is fairly detailed  though for an
even more comprehensive treatment  see clement         however  we begin by summarizing the
main concepts and notation introduced  to give the reader the basic gist 
    overview
a chip  or plan p  is mainly differentiated from an htn by including in its definition inconditions 
in p    sometimes called during conditions  that affect  or assert a condition on  the state just after
the start time of p  ts  p   and must hold throughout the duration of p  preconditions  pre p   must
hold at the start  and postconditions  post p   are asserted at the finish time of p  t f  p    metric
resource  res  consumption  usage p  res   is instantaneous at the start time and  if the resource is
defined as non consumable  is instantaneously restored at the end  the decompositions of p  d p  

   

fia bstract r easoning for p lanning and c oordination

is in the style of and or tree  having either a partial ordering  order p   or a choice of child tasks
that each can have their own conditions 
an execution e of p is an instantiation of its start time  end time  and decomposition  that is  an
execution nails down exactly what is done and when  in order to reason about plan interactions  we
can quantify over possible histories  where each history corresponds to a combination of possible
executions of the concurrently executing chips for a partial ordering over their activities and in the
context of an initial state  a run  r h t   specifies the state at time t for history h 
achieve  clobber  and undo interactions are defined in terms of when the executions of some
plans assert a positive literal   or negative literal   relative to when   is required by another plans
execution for a history  by looking at the literals achieved  clobbered  and undone in the set of
executions in a history  we can identify the conditions that must hold prior to the executions in the
history as external preconditions and those that must hold after all of the executions in the history
as external postconditions 
the value of a metric resource at time t  r res  h t   is calculated by subtracting from the prior
state value the usage of all plans that start executing at t and  if non consumable  adding back usages
of all that end at t  an execution e of p fails if a condition that is required or asserted at time t is not
in the state r h t  at t  or if the value of a resource  r res  h t   used by the plan is over or under its
limits during the execution 
in the remainder of this section  we give more careful  detailed descriptions of the concepts
above  to ground these definitions in firm semantics  the more casual reader can skim over these
details if desired  it is also important to note that  rather than starting from scratch  our formalization
weaves together  and when necessary augments  appropriate aspects of other theories  including
allens temporal plans         georgeffs theory for multiagent plans         and fagin et al s
theory for multiagent reasoning about knowledge        
   

ch i p s

a concurrent hierarchical plan p is a tuple hpre  in  post  usage  type  subplans  orderi  pre p  
in p   and post p  are sets of literals  v or v for some propositional variable v  representing the
preconditions  inconditions  and postconditions defined for plan p  
we borrow an existing model of metric resources  chien  rabideu  knight  sherwood  engelhardt  mutz  estlin  smith  fisher  barrett  stebbins    tran      b  laborie   ghallab        
a plans usage is a function mapping from resource variables to an amount used  we write
usage p  res  to indicate the amount p uses of resource res and sometimes treat usage p  as a set
of pairs  res  amount   a metric resource res is a tuple hmin value  max value  typei  the min
and max values can be integer or real values representing bounds on the capacity or amount available  the type of the resource is either consumable or non consumable  for example  fuel and
battery energy are consumable resources because  after use  they are depleted by some amount  a
non consumable resource is available after use  e g  vehicles  computers  power  
domain modelers typically only specify state conditions and resource usage for primitive actions in a hierarchy  thus  the conditions and usage of a chip are used to derive summary conditions 
as we describe in section      so that algorithms can reason about any action in the hierarchy  in
order to reason about plan hierarchies as and or trees of actions  the type of plan p  or type p   is
   functions such as pre p  are used for referential convenience throughout this paper  here  pre and pre p  are the
same  and pre p  is read as the preconditions of p 

   

fic lement  d urfee     barrett

given a value of either primitive  and  or or  an and plan is a non primitive plan that is accomplished by carrying out all of its subplans  an or plan is a non primitive plan that is accomplished
by carrying out exactly one of its subplans  so  subplans is a set of plans  and a primitive plans
subplans is the empty set  order p  is only defined for an and plan p and is a consistent set of
temporal relations  allen        over pairs of subplans  plans left unordered with respect to each
other are interpreted to potentially execute concurrently 
the decomposition of a chip is in the same style as that of an htn as described by erol et al 
     a   an and plan is a task network  and an or plan is an extra construct representing a set of all
methods that accomplish the same goal or compound task  a network of tasks corresponds to the
subplans of a plan 
for the example in figure    the production managers highest level plan produce h  figure   
is the tuple
h                and   produce g  produce h f rom g    be f ore       i 
in be f ore         and   are indices of the subplans in the decomposition referring to produce g and
produce h f rom g respectively  there are no conditions defined because produce h can rely on
the conditions defined for the primitive plans in its refinement  the plan for moving part a from
bin  to the first input tray of m  using transport  is the tuple
h                and   start move  f inish move    meets       i 
this plan decomposes into two half moves which help capture important intermediate effects  the
parent orders its children with the meets relation to bind them together into a single move  the
start move plan is
h at a  bin    available a   f ree transport     f ull m  tray    
 at a  bin    available a    f ull bin     f ull m  tray    f ree transport    
 at a  bin    available a    f ree transport     f ull bin     f ull m  tray    
    primitive        i 
the f inish move plan is
h at a  bin    available a    f ree transport     f ull bin     f ull m  tray    
 at a  bin    available a    f ree transport     f ull bin    f ull m  tray    
 at a  bin    at a  m  tray    available a   f ree transport     f ull bin    f ull m  tray    
    primitive        i 
we split the move plan into these two parts in order to ensure that no other action that executes
concurrently with this one can use transport   part a  or the input tray to m   it would be incorrect
to instead specify  f ree transport   as an incondition to a single plan because another agent could 
for instance  use transport  at the same time because its  f ree transport   incondition would agree
with the  f ree transport   incondition of this move action  however  the specification here is still
insufficient since two pairs of  start move  f inish move  actions could start and end at the same
time without conflict  we can get around this by only allowing the planner to reason about the
move plan and its parent plans  in effect  hiding the transition between the start and finish actions 
so  by representing the transition from f ree to  f ree without knowing when that transition will
   

fia bstract r easoning for p lanning and c oordination

take place the modeler ensures that another move plan that tries to use transport  concurrently with
this one will cause a conflict  
a postcondition is required for each incondition to specify whether the incondition changes 
this clarifies the semantics of inconditions as conditions that hold only during plan execution
whether because they are caused by the action or because they are necessary conditions for successful execution 
    executions
informally  an execution of a chip is recursively defined as an instance of a decomposition and an
ordering of its subplans executions  intuitively  when executing a plan  an agent chooses the plans
start time and how it is refined  determining at what points in time its conditions must hold  and
then witnesses a finish time  the formalism helps us reason about the outcomes of different ways
to execute a group of plans  describe state transitions  and define summary information 
an execution e of chip p is a tuple hd ts  t f i  ts  e  and t f  e  are positive  non zero real numbers
representing the start and finish times of execution e  and ts   t f   thus  instantaneous actions are not
explicitly represented  d e  is a set of subplan executions representing the decomposition of plan p
under this execution e  specifically  if p is an and plan  then it contains exactly one execution from
each of the subplans  if it is an or plan  then it contains only one execution of one of the subplans 
and it is empty if it is primitive  in addition  for all subplan executions  e   d  ts  e    and t f  e    must
be consistent with the relations specified in order p   also  the first subplan s  to start must start
at the same time as p  ts  e      ts  e   and the last subplan s  to finish must finish at the same time
as p  t f  e      t f  e   the possible executions of a plan p is the set e  p  that includes all possible
instantiations of an execution of p  meaning all possible values of the tuple hd ts  t f i  obeying the
rules just stated 
for the example in section      an execution for the production managers top level plan
produce h would be some e  e  produce h   e might be h e    e              i where e  
e  produce g   and e   e  produce h f rom g   this means that the execution of produce h
begins at time     and ends at time     
for convenience  the subexecutions of an execution e  or subex e   is defined recursively as the
set of subplan executions in es decomposition unioned with their subexecutions 
    histories and runs
an agent reasoning about summary information to make planning decisions at abstract levels needs
to first be able to reason about chips  in this section we complete the semantics of chips by
describing how they affect the state over time  because an agent can execute a plan in many different
ways and in different contexts  we need to be able to quantify over possible worlds  or histories 
where agents fulfill their plans in different ways  after defining a history  we define a run as the
transformation of state over time as a result of the history of executions  the formalization of
histories and runs follows closely to that of fagin et al         in describing multiagent execution 
a state of a world  s  is a truth assignment to a set of propositions  each representing an aspect
of the environment  we will refer to the state as the set of true propositional variables  a history 
   using universal quantification  weld        a single plan could have a agent  agent    productionmanager 
using transport   agent  condition that would exclude concurrent access to the transport  we could have also
simply specified transport  as a non consumable resource with maximum capacity of one 

   

fic lement  d urfee     barrett

h  is a tuple he  si i  e is the set of all plan executions of all agents occurring in h  and si is the
initial state of h before any plan begins executing  so  a history h is a hypothetical world that begins
with si as the initial state and where only executions in e h  occur  in particular  a history for the
manufacturing domain might have an initial state as shown in figure   where all parts and machines
are available  and both transports are free  the set of executions e would contain the execution of
produce h  maintenance  move parts  and their subexecutions 
a run  r  is a function mapping a history and time point to states  it gives a complete description
of how the state of the world evolves over time  where time ranges over the positive real numbers 
axiom  
r h       si
axiom  
v  r h t       v  r h t   
p  e p  e h    v  in p   ts  e p     t      v  post p   t f  e p     t  
   p    e p   e h    v  in p     ts  e p      t      v  post p     t f  e p      t  
axiom   states that the world is in the initial state at time zero  axiom   states that a predicate
v is true at time t if it was already true beforehand  or a plan asserts v with an incondition or
postcondition at t  but  in either case  no plan asserts v at t  if a plan starts at t  then its inconditions
are asserted right after the start  t    where  is a small positive real number  axiom   also indicates
that both inconditions and postconditions are effects 
the state of a resource is a level value  integer or real   for consumable resource usage  a task
that depletes a resource is modeled to instantaneously deplete the resource  subtract usage from the
current state  at the start of the task by the full amount  for non consumable resource usage  a task
also depletes the usage amount at the start of the task  but the usage is restored  added back to the
resource state  at the end of execution  a task can replenish a resource by having a negative usage 
we will refer to the level of a resource res at time t in a history h as r res  h t   axioms   and  
describe these calculations for consumable and non consumable resources  respectively 
axiom  
r consumable res  h t    r consumable res  h t     e p e h  ts  e p   t usage p  consumable res 
axiom  
r nonconsumable res  h t   r nonconsumable res  h t   
e p e h  ts  e p   t usage p  nonconsumable res  
e p e h  t f  e p   t usage p  nonconsumable res 
now that we have described how chips change the state  we can specify the conditions under
which an execution succeeds or fails  as stated formally in definition    an execution succeeds if 
the plans preconditions are met at the start  the postconditions are met at the end  the inconditions
are met throughout the duration  not including the start or end   all used resources stay within their
value limits throughout the duration  and all executions in the decomposition succeed  otherwise 
the execution fails 
   

fia bstract r easoning for p lanning and c oordination

definition  
succeeds e p   h  pre p   r h ts  e p   
post p   r h t f  e p   
t  res ts  e p     t   t f  e p    usage p  res       
in p   r h t 
min value res     r res  h t     max value res 
e  d e p    succeeds e  h 
    asserting  clobbering  achieving  and undoing
conventional planning literature often speaks of clobbering and achieving preconditions of plans
 weld         in chips  these notions are slightly different since inconditions can clobber and
be clobbered  as seen in the previous section  formalizing these concepts and another  undoing
postconditions  helps us define summary conditions  in section       however  it will be convenient
to define first what it means to assert a condition  figure   gives examples of executions involved
in these interactions  and we define these terms as follows 
definition  
asserts e p     t  h   e p  e h  
    in p   t   ts  e p     
   post p   t   t f  e p   
 r t  h      
definition   states that an execution e p in a history h asserts a literal at time t if that literal is an
effect of p that holds in the state at t  note that that from this point on  beginning in definition    we
use brackets     as a shorthand when defining similar terms and procedures  for example  saying  a 
b  implies  c  d  means a implies c  and b implies d  this shorthand will help us avoid repetition 
at the cost of slightly more difficult parsing 
definition  
 achieves  clobbers  precondition e p      e p   t  h  
e p   e p   e h 
asserts e p          t  h      pre p     t   ts  e p   
  e p    t       asserts e p       t      h   asserts e p       t      h    t   t     ts  e p   
definition  
clobbers  in  post condition e p      e p   t  h  
e p   e p   e h 
asserts e p     t  h       in p     post p       ts  e p      t   ts  e p    t   t f  e p    
definition  
undoes e p      e p   t  h  
e p   e p   e h 
asserts e p     t  h      post p     t f  e p      t
  e p    t       asserts e p       t      h   asserts e p       t      h    t f  e p     t      t
   

fic lement  d urfee     barrett

figure    interval interactions of plan steps
so  an execution achieves or clobbers a precondition if it is the last  or one of the last  to assert
the condition or its negation  respectively  before it is required  likewise  an execution undoes a
postcondition if it is the first  or one of the first  to assert the negation of the condition after the
condition is asserted  an execution e clobbers an incondition or postcondition of e  if e asserts the
negation of the condition during or at the end  respectively  of e    achieving effects  inconditions
and postconditions  does not make sense for this formalism  so it is not defined  figure   shows
different ways an execution e achieves  clobbers  and undoes an execution e      and   point to
where they are asserted or required to be met 
    external conditions
as recognized by tsuneto et al          external conditions are important for reasoning about potential refinements of abstract plans  although the basic idea is the same  we define them a little
differently and call them external preconditions to differentiate them from other conditions that we
call external postconditions  intuitively  an external precondition of a group of partially ordered
plans is a precondition of one of the plans that is not achieved by another in the group and must
be met external to the group  external postconditions  similarly  are those that are not undone by
plans in the group and are net effects of the group  definition   states that   is an external  pre 
post condition of an execution e p if   is a  pre  post condition of a subplan for which it is not
 achieved  undone  by some other subplan 
definition  
external  pre  post condition    e p   
h  e h     e p    subex e p   
 e p   e h       pre p     post p    
  e p    e h  t  achieves pre  undoes post condition e p        e p   t  h  

   

fia bstract r easoning for p lanning and c oordination

for the example in figure    available g  is not an external precondition because  although g
must exist to produce h  g is supplied by the execution of the produce g plan  thus  available g 
is met internally  making available g  an internal condition  available m   is an external precondition  an internal condition  and an external postcondition because it is needed externally and
internally  it is an effect of produce g on m  which releases m  when it is finished  and no other
plan in the decomposition undoes this effect 

   plan summary information
summary information can be used to find abstract solutions that are guaranteed to succeed no matter
how they are refined because the information describes all potential conditions of the underlying
decomposition  thus  some commitments to particular plan choices  whether for a single agent or
between agents  can be made based on summary information without worrying that deeper details
lurk beneath that will doom the commitments  while htn planners have used abstract conditions
to guide search  e g   sacerdoti        tsuneto et al          they rely on a user defined subset of
constraints that can only help detect some potential conflicts  in contrast  summary information can
be used to identify all potential conflicts 
having the formalisms of the previous section  we can now define summary information and
describe a method for computing it for non primitive plans  in section       because there are
many detailed definitions and algorithms in this section  we follow the same structure here as in the
previous section  where we first give a more informal overview of the key concepts and notation 
into which we then subsequently delve more systematically 
    overview
the summary information of plan p consists of summary pre   in   and postconditions  presum  p  
insum  p   postsum  p    summary resource usage  usagesum  p  res   for each resource res  and whether
the plan can be executed in any way successfully  consistent  
a summary condition  whether pre  post  or in  specifies not only a positive or negated literal 
but additional modal information  each summary condition has an associated existence  whose
value is either must or may depending on whether it must hold for all possible decompositions of
the abstract operator or just may hold depending on which decomposition is chosen  the timing of
a summary condition is either f irst  last  always  or sometimes  specifying when the condition must
hold in the plans interval of execution  a plan p  must  achieve  clobber  summary precondition
c  of p  if the execution of p   or that of any plan with the same summary information  would
 achieve  clobber  a condition summarized by c   or any plan with the same summary information
as p    
the algorithm for deriving summary conditions for plan p takes as input the summary conditions of the immediate subplans of p and the conditions defined for the chip p  the pre   in   and
postconditions of p become must first  must always  and must last summary conditions  respectively  the algorithm retains the existence and timing of subplan summary conditions in the parent
depending on whether the conditions are achieved  clobbered  or undone by siblings  whether the
decomposition is and or or  whether the subplan is ordered first or last  and whether all subplans
share the same condition  subplan first  always  and last conditions can become sometimes conditions in the parent  the parent is computed as consistent as long as all subplans are consistent 

   

fic lement  d urfee     barrett

no subplan may clobber a summary condition of another  and summarized resources do not violate
limits 
we represent summary resource usage as three value ranges  hlocal min  local max  persisti 
where the resources local usage occurs within the tasks execution  and the persistent usage represents the usage that lasts after the task terminates for depletable resources  the summarization
algorithm for an abstract task takes the summary resource usages of its subtasks  considers all legal orderings of the subtasks  and all possible usages for all subintervals within the interval of the
abstract task  to build multiple usage profiles  these profiles are combined with algorithms for
computing parallel  sequential  and disjunctive usages to give the summary usage of the parent task 
    summary conditions
the summary information for a plan p  psum   is a tuple hpresum   insum   postsum   usagesum   consistenti 
whose members are sets of summary conditions  summarized resource usage  and a consistent flag
indicating whether the plan will execute consistently internally  presum  p  and postsum  p  are summary pre  and postconditions  which are the external pre  and postconditions of p  respectively  the
summary inconditions of p  insum  p   contain all conditions that must hold within some execution
of p for it to be successful  a condition c in one of these sets is a tuple h   existence timingi    c 
is the literal of c  the existence of c can be must or may  if existence c    must  then c is called a
must condition because   must hold for every successful plan execution  for convenience we usually
write must c   c is a may condition  may c  is true  if   c  must hold for some successful execution 
the timing of a summary condition c can either be always  sometimes  f irst  or last  timing c 
is always for c  insum if   c  is an incondition that must hold throughout all potential executions of p
   holds always   otherwise  timing c    sometimes meaning   c  holds at one point  at least  within
an execution of p  so  an always condition is must  and we do not define may always inconditions
because whether it is may because of existence or timing  it is not significantly different from may
sometimes in how a planner reasons about it  whether a condition is may always  however defined 
or may sometimes  another plan can only have a may clobber relationship with the condition  as
defined in section       note also that the incondition of a chip has the restricted meaning of a
must always summary incondition  the timing is f irst for c  presum if   c  holds at the beginning
of an execution of p  otherwise  timing   sometimes  similarly  timing is last for c  postsum if   c 
is asserted at the end of a successful execution of p  otherwise  it is sometimes  although existence
and timing syntactically only take one value  semantically must c   may c   and always c  
sometimes c  
we considered using modal logic operators to describe these concepts  while a mix of existing
temporal logic and dynamic logic  pratt        notation could be forced to work  we found that
using our own terminology made definitions much simpler  we discuss this more at the end of
section   
definitions       and   give the formal semantics of existence and timing for a few representative
condition types  summary conditions of a plan are defined recursively in that they depend on the
summary conditions of the plans immediate subplans instead of its complete decomposition  because a single description of summary information could represent many different plan hierarchies 
we quantify over plans p    whose subplans have the same summary information as those of the
plan p being summarized  we could have defined the existence and timing properties of conditions
based on the entire hierarchy  but in doing so  deriving summary conditions would be as expensive

   

fia bstract r easoning for p lanning and c oordination

as solving the planning problem  and one of the main purposes of summary information is to reduce
the computation of the planning problem  the reason why it would be so expensive is that in the
worst case all legal orderings of all plan steps must be explored to determine whether a condition is
must or may  we will discuss an example of this at the end of this subsection 
definition  
 must  may  f irst precondition    p  
p    hpre p   in p   post p      type p   subplans p     order p i
summary in f ormation o f subplans p      summary in f ormation f or subplans p  
h e p    e h     e p     subex e p      true  external precondition    e p     
e p    e h  ts  e p       ts  e p        pre p    

definition  
must always incondition    p  
p    hpre p   in p   post p      type p   subplans p     order p i
summary in f ormation o f subplans p      summary in f ormation f or subplans p  
h  e p   e h     e p     subex e p    t ts  e p      t   t f  e p    
e p    e h  ts  e p       t   t f  e p         in p    

definition  
 must  may  sometimes incondition    p  
    p    hpre p   in p   post p      type p   subplans p     order p i
summary in f ormation o f subplans p      summary in f ormation f or subplans p      
    h  e p   e h     e p     subex e p     t ts  e p      t   t f  e p       
e p    e h   t   ts  e p         pre p    
ts  e p       t   t f  e p         in p    
t   t f  e p         post p    
definition   states that a f irst precondition of p is an external precondition that is always required at the beginning of the execution of any p  that has the same conditions as p and the same
summary information and ordering for its subplans as p  a last postcondition is always asserted at
the end of the execution  substitute pre with post and ts with t f in the last two lines of definition     a  must may  sometimes precondition is a  must may  external precondition that is not a
f irst precondition  a sometimes postcondition is defined similarly  definition   states that a literal
  is a must  always incondition of a plan p if at any time during any isolated execution of any p 
with the same summary information as p  some executing plan p   has incondition    definition  
states that a  must  may  sometimes incondition of plan p is a condition that is required during  any 
some  execution of  any  some  plan p  that has the same summary information and ordering for its
subplans as p 
the consistent flag is a boolean indicating whether the plan  or any plan with the same summary information and ordering for subplans  would execute successfully no matter how it was decomposed and no matter when its subplans were executed  definition    says that all possible
   

fic lement  d urfee     barrett

executions will succeed for a consistent plan  this is very similar to the cananyway relation that
will be defined in section    we do not include whether the plan will definitely not succeed in the
summary information because it requires an exponential computation to see whether all conflicts in
the subplans can be resolved  this computation can wait to be done during planning after summary
information is fully derived 
definition   
consistent p  
p    hpre p   in p   post p   usage p  type p   subplans p     order p i
summary in f ormation o f subplans p      summary in f ormation f or subplans p  
h  e p   e  p     e p  succeeds
we show a subset of the summary conditions for the production managers top level plan  of
figure    below  following each literal are modal tags for existence and timing information  mu
is must  ma is may  f is f irst  l is last  s is sometimes  and a is always 
production managers produce h plan 
summary preconditions 
available a muf  available m  mas  available m  mas
summary inconditions 
available a mus  available m  mas  available m  mus  available g mus 
available a mus  available m  mas  available m  mus  available g mus 
available h mus  available h mus
summary postconditions 
available a mus  available m  mas  available m  mus  available g mus 
available h mul

the available m   summary precondition is a may condition because the production manager
may end up not using m  if it chooses to use m  instead to produce g  available a  is a f irst summary precondition because part a must be used at the beginning of execution when it is transported
to one of the machines  because the machines are needed sometime after the parts are transported 
they are sometimes  and not first  conditions  they are needed at some point in time after the beginning of execution 
because the production manager may use m  to produce g  available m   is a summary
incondition of produce h  having both available m   and available m   as inconditions is
consistent because they are sometimes conditions  implying that they hold at different times during
the plans execution  in contrast  these conditions would conflict if they were both must and always
 meaning that they must always hold throughout every possible execution of the plan  
the summary condition available a  is a must postcondition of the top level plan because a
will definitely be consumed by make g and is not produced by some other plan in the decomposition
of produce h f rom g  even though available g  is an effect of produce g  it is not an external
postcondition of produce h because it is undone by produce h f rom g  which consumes g to
make h  available h  is a last summary postcondition because the production manager releases
h at the very end of execution  available m   is not last because the manager finishes using m 
before moving h into storage 
notice that available m   is a may summary precondition  however  no matter how the hierarchy is decomposed  m  must be used to produce h  so available m   must be established
   

fia bstract r easoning for p lanning and c oordination

externally to the production managers plan  because summary information is defined in terms of
the summary information of the immediate subplans  in the subplans of produce h  we only see
that produce g has an available m  mas precondition and an available m  mas postcondition
that would achieve the available m  muf precondition of produce h f rom g  this summary
information does not tell us that the precondition of produce g exists only when the postcondition
exists  a necessary condition to determine that the derived precondition of produce h is a must
condition  thus  it is may  if we augmented summary information with which subsets of conditions
existed together  hunting through combinations and temporal orderings of condition subsets among
subplans to derive summary conditions would basically be an adaptation of an htn planning algorithm  which summary information is intended to improve  instead  we derive summary information
in polynomial time and then use it to improve htn planning exponentially as we explain in section    this is the tradeoff we made at the beginning of this section in defining summary conditions
in terms of just the immediate subplans instead of the entire hierarchy  abstraction involves loss of
information  and this loss enables computational gains 
    summary condition relationships and algorithms
in order to derive summary conditions according to their definitions  we need to be able to recognize
achieve  clobber  and undo relationships based on summary conditions as we did for basic chip
conditions  we give definitions and algorithms for these  which build on constructs and algorithms
for reasoning about temporal relationships  described in appendix a 
achieving and clobbering are very similar  so we define them together  definition    states that
plan p  must  achieve  clobber  summary precondition c  of p  if and only if for all executions of
any two plans  p   and p     with the same summary information and ordering constraints as p  and
p    the execution of p   or one of its subexecutions would  achieve  clobber  an external precondition
  c    of p    
definition   
must  achieve  clobber  precondition p    c    p    psum   order  
h h psum   order   p     p     e p     e p    
 p   and p   have same summary and ordering in f ormation as p  and p    
t e p     subex e p      e p     subex e p     
 achieve  clobber  precondition e p        c     e p     t  h  
external precondition   c     e p    
achieving and clobbering in  and postconditions are defined the same as definition    but substituting in and post for pre and removing the last line for inconditions  additionally substituting  for  gives the definitions of may achieve and clobber  furthermore  the definitions of
must may undo are obtained by substituting post for pre and undo for achieve in definition     note that  as mentioned in section      achieving inconditions and postconditions does not
make sense for this formalism 
algorithms for these interactions are given in figure   and figure    these algorithms build
on others  detailed in appendix b  that use interval point algebra to determine whether a plan must
or may assert a summary condition before  at  or during the time another plan requires a summary
condition to hold  similar to definition   of must achieve for chip conditions  figure   says that p 
   

fic lement  d urfee     barrett

algorithm  must  achieve  clobber 
input  plan p    summary condition c of plan p  psum   and order
output  true or f alse  whether p  must  achieve  clobber  c
begin function
for each c   in p     post p   
if   c        c     c    must c    then
if c  insum  p   p  must assert c  in c then return  unde f ined  true 
if c  postsum  p   p  must assert c  when c then return  unde f ined  true 
if c  presum  p   p  must assert c  by c then
set assertion inbetween   f alse
for each c    in p      post p      p    psum while assertion inbetween   f alse
if  p  may assert c  before c   
p   may assert c   by c 
  c         c     c    
 p  must assert c  before c   
p   must assert c   by c 
  c         c     c    must c      then
set assertion inbetween   true
if assertion inbetween then return true
return f alse
end function

figure    algorithm for whether a plan must achieve or clobber a summary condition
achieves summary condition c if it must asserts the condition before it must hold  and there are no
other plans that may assert the condition or its negative in between  the algorithm for may achieve
 in figure    mainly differs in that p  may assert the condition beforehand  and there is no plan that
must assert in between  the undo algorithms are the same as those for achieve after swapping c and
c  in all must may assert lines 
the complexity of determining must may clobber for inconditions and postconditions is simply
o c  to check c conditions in p    if the conditions are hashed  then the algorithm is constant time 
for the rest of the algorithm cases  the complexity of walking through the summary conditions
checking for p   and c   is o nc  for a maximum of c summary conditions for each of n plans
represented in psum   in the worst case  all summary conditions summarize the same propositional
variable  and all o nc  conditions must be visited 
lets look at some examples of these relationships  in figure  a  p    equip m  tool mayclobber c   available m  mas in the summary preconditions of p   produce g because there is
some history where equip m  tool ends before produce g starts  and calibrate m  starts after
produce g starts  in figure  b  p    build h must achieve c   available h muf in the summary preconditions of p   move h  here  c  is available h mul in the summary postconditions
of build h  in all histories  build h attempts to assert c  before the move h requires c to be
met  and there is no other plan execution that attempts to assert a condition on the availability
of h  equip m  tool does not may clobber c   available m  muf in the summary preconditions
of build h even though equip m  tool asserts c    available m  mul before c is required to
be met  this is because calibrate m  must assert available m  mua between the time that
equip m  tool asserts c  and when c is required  thus  calibrate m  must undo equip m  tool s

   

fia bstract r easoning for p lanning and c oordination

algorithm  may  achieve  clobber 
input  plan p    summary condition c of plan p
output  true or f alse  whether p  may  achieve  clobber  c
begin function
for each c   in p     post p   
if   c        c     c   then
if c  insum  p   p  may assert c  in c then return  unde f ined  true 
if c  postsum  p   p  may assert c  when c then return  unde f ined  true 
if c  presum  p   p  may assert c  by c then
set assertion inbetween   f alse
for each c    in p      post p      p    psum while assertion inbetween   f alse
if p  must assert c  before c   
p   must assert c   by c 
  c        c  or   c   must c      then
set assertion inbetween   true
if assertion inbetween then return true
return f alse
end function

figure    algorithm for whether a plan may achieve or clobber a summary condition
a 

produce h
produce g

produce h from g
move g

build h

move h

service m 
move

equip m 

tool

calibrate m 

tool

b 

produce h
produce h from g

produce g

move g
 
move
tool

build h

move h

service m 

equip m 

calibrate m 

tool

figure    the production and facilities managers plans partially expanded  a  the managers plans
unordered with respect to each other  b  equip m  tool must clobber available m  mal
of produce g  and calibrate m  must clobber available m  muf of build h 

summary postcondition  because calibrate m  cannot assert its postcondition available m  mul
before build h requires available m  muf  calibrate m  must clobber the summary precondition 

   

fic lement  d urfee     barrett

    deriving summary conditions
now that we have algorithms that determine interactions of abstract plans based on their summary
conditions  we can create an algorithm that derives summary conditions according to their definitions in section      figure   shows pseudocode for the algorithm  the method for deriving the
summary conditions of a plan p is recursive  first  summary information is derived for each of ps
subplans  then conditions are added based on ps own conditions  most of the rest of the algorithm
derives summary conditions from those of ps subplans  whether p is consistent depends on the
consistency of its subplans and whether its own summary conditions and resource usages are in
conflict  the braces     used here have slightly different semantics than used before with the
brackets  an expression  x y  can be interpreted simply as  x or y  respectively  
definitions and algorithms for temporal relationships such as always  f irst and covers are in
appendix a  when the algorithm adds or copies a condition to a set  only one condition can exist
for any literal  so a conditions information may be overwritten if it has the same literal  in all cases 
must overwrites may  and f irst  last  and always overwrite sometimes  but  not vice versa  further 
because it uses recursion  this procedure is assumed to work on plans whose expansion is finite 
    summary resource usage
in this section  we define a representation for capturing ranges of usage both local to the task interval and the depleted usage lasting after the end of the interval  based on this we introduce a
summarization algorithm that captures in these ranges the uncertainty represented by decomposition choices in or plans and partial temporal orderings of and plan subtasks  this representation
allows a coordinator or planner to reason about the potential for conflicts for a set of tasks  we will
discuss this reasoning later in section      although referred to as resources  these variables could
be durations or additive costs or rewards 
      r epresentation
we start with a new example for simplicity that motivates our choice of representation  consider
the task of coordinating a collection of rovers as they explore the environment around a lander on
mars  this exploration takes the form of visiting different locations and making observations  each
traversal between locations follows established paths to minimize effort and risk  these paths combine to form a network like the one mapped out in figure     where vertices denote distinguished
locations  and edges denote allowed paths  thinner edges are harder to traverse  and labeled points
have associated observation goals  while some paths are over hard ground  others are over loose
sand where traversal is harder since a rover can slip 
figure    gives an example of an abstract task  imagine a rover that wants to make an early
morning trip from point a to point b on the example map  during this trip the sun slowly rises
above the horizon giving the rover the ability to progressively use soak rays tasks to provide more
solar power  a non consumable resource    to motors in the wheels  in addition to collecting photons 
the morning traverse moves the rover  and the resultant go tasks require path dependent amounts of
power  while a rover traveling from point a to point b can take any number of paths  the shortest
three involve following one  two  or three steps 
   it is important not to confuse power with battery energy  a power source  e g  battery  solar panels  makes a fixed
amount of power in watts available at any point in time  a batterys energy  in watt hours  is reduced by the integral
of the total use of this power over time 

   

fia bstract r easoning for p lanning and c oordination

algorithm  derive summary information
input  plan p
output  psum
begin function
derive summary information
for each p   d p 
v
set consistent p    p  d p  consistent p   
for each    pre p  add h   must  f irsti to presum  p 
for each    in p  add h   must  alwaysi to insum  p 
for each    post p  add h   must  lasti to postsum  p 
for each summary condition c  of p   d p 
set c   c 
if c    presum  p    postsum  p     and
c  is not must  achieved undone  or must clobbered within d p   then
if type p    and and  p  is always not the   f irst last 
temporally ordered subplan according to order p  or
there is a sometimes    f irst last  subplan p  that
does not have a   f irst  last    c    condition in  presum  p    postsum  p       then
set timing c    sometimes
if c  is may  achieved undone  or may clobbered by each of p  d p  and
not all p    p have a must   c    condition in  presum  p     postsum  p       then
set existence c    may
copy c to  presum  p  postsum  p  
if c   insum  p    or p  is not always   f irst last  according to order p   then
if must c    and c  is always not    f irst last  according to order p   then
set existence c    must
set p     
set allalways   true
for each p    d p   c    insum  p    
if   c        c 
if always c     then add p   to p
else set allalways   f alse
else allalways   f alse
if always c  and   type p    and and p covers p according to order p   or
 type p    or and allalways    then
set timing c    always
add c to insum  p 
if c  is may clobbered  then set consistent   f alse
usagesum  p    summarizeresourceusage p   in section       
if consistent usagesum  p     f alse  then set consistent p    f alse
end function

figure    algorithm for deriving summary information
a summarized resource usage consists of ranges of potential resource usage amounts during
and after performing an abstract task  and we represent this summary information for a plan p on a
resource res using the structure
usagesum  p  res    hlocal min p  res   local max p  res   persist p  res i 

   

fic lement  d urfee     barrett

a

d
b
c
f
e

figure     example map of established paths between points in a rover domain
morning activities
move a b 
soak rays soak rays soak rays
use   w use   w use   w
   min
   min
   min
go a   
use  w
   min

take low path

go     
use  w
   min

high path
middle path
go a b 
go   b  use  w go a    go   b 
use  w    min use  w use  w
   min
   min    min

figure     and or tree defining a rovers tasks and their resource usages
where the resources local usage occurs within ps execution  and the persistent usage represents
the usage that lasts after the execution terminates for consumable resources 
definition   
usagesum  p  res  
h minhh e p e h   mints  e p   t t f  e p    r res  h t     maxhh e p e h   mints  e p   t t f  e p    r res  h t    
 minhh e p e h   maxts  e p   t t f  e p    r res  h t     maxhh e p e h   maxts  e p   t t f  e p    r res  h t    
 minhh e p e h   r res  h t f  e p     
maxhh e p e h   r res  h t f  e p     
i
the context for definition    is the set of all histories h where the value of res is   in the initial
state  and e h  only contains the execution of p and its subexecutions  thus  the r res  h t  term
is the combined usage of res at time t of all executions in the hierarchy as defined in section      so 
the maximum of the local min is the highest among all histories of the lowest point of usage during
ps execution  the usage ranges capture the multiple possible usage profiles of a task with multiple
decomposition choices and timing choices among loosely constrained subtasks  for example  the
high path task has a h                 i summary power use over a    minute interval  in this case
the ranges are single points due to no uncertainty  the task simply uses   watts for    minutes
followed by   watts for    minutes  the move a b  task provides a slightly more complex example
due to its decompositional uncertainty  this task has a h                 i summary power use over
a    minute interval  in both cases the persist is       because solar power is a non consumable
resource 
as an example of reasoning with resource usage summaries  suppose that only   watts of power
were available during a move a b  task  given the       local max  we know that there is not
enough power no matter how the task is decomposed  raising the available power to   watts makes
the task executable depending on how it gets decomposed and scheduled  and raising to   or more
watts makes the task executable for all possible decompositions 
   

fia bstract r easoning for p lanning and c oordination

this representation of abstract  or uncertain  metric resource usage can be seen as an extension
of tracking optimistic and pessimistic resource levels  drabble   tate         computing only
the upper and lower bounds on resource usage for an abstract plan gives some information about
whether lower or upper bound constraints on a resource may  must  or must not be violated  but
it is not complete  by representing upper and lower bounds as ranges of these bounds over all
potential histories  we can certainly know whether bounds may  must  or must not be violated over
all histories  for the example above  if we only tracked one range for the local usage         we
would not know that there is definitely a conflict when only   watts are available  knowing this
extra information can avoid exploration of an infeasible search space 
      r esource s ummarization a lgorithm
the state summarization algorithm in section     recursively propagates summary conditions upwards from an and or hierarchys leaves  and the algorithm for resource summarization takes the
same approach  starting at the leaves  the algorithm finds primitive tasks that use constant amounts
of a resource  the resource summary of a task using x units of a resource is h x x   x x       i or
h x x   x x   x x i over the tasks duration for non consumable or consumable resources respectively 
moving up the and or tree  the summarization algorithm either comes to an and or an or branch 
for an or branch the combined summary usage comes from the or computation
h  mincchildren  lb local min c     maxcchildren  ub local min c     
 mincchildren  lb local max c     maxcchildren  ub local max c     
 mincchildren  lb persist c    
maxcchildren  ub persist c    
i 

where lb   and ub   extract the lower bound and upper bound of a range respectively  the children
denote the branchs children with their durations extended to the length of the longest child  this
duration extension alters a childs resource summary information because the childs usage profile
has a zero resource usage during the extension  for instance  in determining the resource usage
for move a b   the algorithm combines two    minute tasks with a    minute task  the resulting
summary information describes a    minute abstract task whose profile might have a zero watt
power usage for    minutes  this extension is why move a b  has a       for a local min instead
of        planners that reason about variable durations could use       for a duration ranging from
   to    
computing an and branchs summary information is a bit more complicated due to timing
choices among loosely constrained subtasks  the take x path examples illustrate the simplest subcase  where subtasks are tightly constrained to execute serially  here profiles are appended together 
and the resulting summary usage information comes from the serial and computation
h  mincchildren  lb local min c     lb  c    mincchildren  ub local min c     ub  c    
pre
pre
 maxcchildren  lb local max c     lb  c    maxcchildren  ub local max c     ub  c    
 cchildren  lb persist c    
cchildren  ub persist c    
i 
pre

pre

pre
pre
where lb
 c  and ub
 c  are the respective lower and upper bounds on the cumulative persistent usages of children that execute before c  these computations have the same form as the 
computations for the final persist 
the case where all subtasks execute in parallel and have identical durations is slightly simpler 
here the usage profiles add together  and the branchs resultant summary usage comes from the

   

fic lement  d urfee     barrett

move a b 
soak rays
                       

                   

soak rays
                       

soak rays
                       

figure     possible task ordering for a rovers morning activities  with resulting subintervals 
parallel and computation
h  cchildren  lb local min c    
maxcchildren  ub local min c     non
ub  c    
non
 mincchildren  lb local max c     lb  c    cchildren  ub local max c     
 cchildren  lb persist c    
cchildren  ub persist c    
i 
non
where non
ub  c  and lb  c  are the respective sums of the local max upper bounds and the local min
lower bounds for all children except c 
to handle and tasks with loose temporal constraints  we consider all legal orderings of child
task endpoints  for example  in the rovers early morning tasks  there are three serial solar energy collection subtasks running in parallel with a subtask to drive to location b  figure    shows
one possible ordering of the subtask endpoints  which breaks move a b  into three pieces  and
two of the soak rays children in half  given an ordering  the summarization algorithm can    
use the endpoints of the children to determine subintervals      compute summary information for
each child task subinterval combination      combine the parallel subinterval summaries using the
parallel and computation  and then     chain the subintervals together using the serialand computation  finally  the and tasks summary is computed by combining the summaries for
all possible orderings using an or computation 
here we describe how step     generates different summary resource usages for the subintervals
of a child task  a child task with summary resource usage h a b   c d   e  f  i contributes one of two
summary resource usages to each intersecting subinterval   

h a  b    c  d         i  h a  d    a  d         i 

while the first usage has the tighter  a b   c d  local ranges  the second has looser  a d   a d  local
ranges  since the b and c bounds only apply to the subintervals containing the subtasks minimum
and maximum usages  the tighter ranges apply to one of a subtasks intersecting subintervals  while
the minimum and maximum usages may not occur in the same subinterval  symmetry arguments
let us connect them in the computation  thus one subinterval has tighter local ranges and all other
intersecting subintervals get the looser local ranges  and the extra complexity comes from having
to investigate all subtask subinterval assignment options  for instance  there are three subintervals
intersecting move a b  in figure     and three different assignments of summary resource usages
to the subintervals  placing             in one subinterval with             in the other two  these
placement options result in a subtask with n subintervals having n possible subinterval assignments 
so if there are m child tasks each with n alternate assignments  then there are nm combinations
of potential subtask subinterval summary resource usage assignments  thus propagating summary
information through an and branch is exponential in the number of subtasks with multiple internal
   for summary resource usages of the last interval intersecting the child task  we replace        with  e  f   in the persist 

   

fia bstract r easoning for p lanning and c oordination

subintervals  however since the number of subtasks is controlled by the domain modeler and is
usually bounded by a constant  this computation is tractable  in addition  summary information can
often be derived offline for a domain  the propagation algorithm takes on the form 
 for each consistent ordering of endpoints 
 for each consistent subtask subinterval summary usage assignment 
 use parallel and computations to combine subtask subinterval summary
usages by subinterval 
 use a serial and computation on the subintervals combined summary usages
to get a consistent summary usage 
 use or computation to combine all consistent summary usages to get and tasks summary
usage 
now that we have described how to derive summary information  we can discuss how to use it 

   identifying abstract solutions
up to this point  we have detailed algorithms for deriving summary conditions and for reasoning
about potential  may  and definite  must  interactions between tasks based on their summary information  in addition  we have outlined algorithms for deriving summarized resource usage but
have not yet discussed how to identify solutions at abstract levels  in this section  we show how
the interactions of summary conditions and summarized metric resource usages identify potentially
resolvable threats and unresolvable conflicts among the plans of a group of agents 
    threats on summary conditions
agents can attempt to resolve conflicts among their plans by considering commitments to particular
decompositions and ordering constraints  in order to do this  the agents must be able to identify
remaining conflicts  threats  among their plans  here we present simple algorithms for reasoning
about threats between abstract plans and their required conditions 
formally  for a set of chips p with ordering constraints order  a threat between an abstract plan
p  p and a summary condition c  of another plan p   p exists iff p may clobber c    we say that the
threat is unresolvable if p must clobber c  and must c    because there are no decomposition choices
or ordering constraints that could be added to resolve the threat 
so  a simple algorithm for identifying threats is to check to see if each of the o nc  summary
conditions of n plans in psum is must  or may clobbered by any other plan  since the complexity
of checking to see if a particular condition is must  or may clobbered is o nc   this algorithms
complexity is o n  c    
in many coordination tasks  if agents could determine that under certain temporal constraints
their plans can be decomposed in any way  cananyway  or that under those constraints there is
no way they can be successfully decomposed  mightsomeway   then they can make coordination
decisions at abstract levels without entering a potentially costly search for valid plan merges at lower
levels  here are the formal definitions of cananyway and mightsomeway 

   

fic lement  d urfee     barrett

a 

produce h

b 

maintenance

produce h
maintenance
move parts

move parts
c 

produce h
produce g

produce h from g
maintenance
service m  m 
service

service

m 

m 

move
tool

move parts

figure     the top level plans of each of the managers for the manufacturing domain
definition   
 cananyway  mightsomeway  order  psum   
    h  p with summary in f ormation   psum  h  h p  order  
    e  e h   succeeds e  h 
definition    states that the plans with summary information psum under ordering constraints
can execute in any way if and only if all sets of plans p that have summary information psum
will execute successfully in any history  mightsomeway is true if there is some set of plans
that could possibly execute successfully  we could also describe cansomeway order psum   and
mightanyway rel psum   in the same fashion  but it is not obvious how their addition could further
influence search  exploring these relations may be an interesting topic for future research 
in figure   a  the three top level plans of the managers are unordered with respect to each other 
the leaf plans of the partially expanded hierarchies comprise psum   arrows represent the constraints
in order  cananyway     produce g  maintenance  move parts   is false because there are several conflicts over the use of machines and transports that could occur for certain executions of
the plans as described in section     for figure    however  mightsomeway      produce g 
maintenance  move parts   is true because the plans might in some way execute successfully
as shown in figure   b  with the ordering constraints in figure   b  cananyway  before      
before        produce g  maintenance  move parts   is true because the plans can execute in any
way consistent with these ordering constraints without conflict  figure  b is an example where
mightsomeway is false because calibrate m  must clobber the available m  muf summary precondition of build h 
as shown in figure     the algorithm for determining cananyway for summary conditions
is simple in that it only needs to check for threats  mightsomeway is more complicated because
just checking for an unresolvable threat is not enough  as shown in figure     it is not the case
that plan p must clobber p  because p   could come between and achieve the precondition   of p   
thus  p may clobbers   in p and in p     however  obviously p will clobber one or the other  so
   

fia bstract r easoning for p lanning and c oordination

algorithm   cananyway  mightsomeway 
input  order  psum
output  true or f alse
begin function
for each psum  psum
if  consistent psum    f alse  then return f alse
for each p sum  psum
for each summary condition c of psum
if p   may clobber  must clobber  c  and
c is  may or must  must   then
return f alse
for each resource res
if  cananyway  mightsomeway  order  psum   res   see section      then
return false
return true
end function

figure     algorithm determining whether plans with the given summary information cananyway
or mightsomeway execute successfully 
p
l

p
 l

l

l

p
l

l

l

figure     mightsomeway is false even though there is no must clobber relationship 
mightsomeway is false  in order to determine mightsomeway is f alse  an agent must exhaustively
search through an exponential number of schedules to see if not all conflicts can be resolved  instead
of performing an exponential search to determine mightsomeway  we use the simple algorithm in
figure    that just checks for must clobber relationships  in section     we describe a more flexible
search to find conflict free abstract plans than just scheduling at an abstract level 
thus  while the cananyway algorithm is sound and complete  the mightsomeway algorithm
is complete but not sound  this also means that determining mightsomeway is sound but not
complete  we will still make use of both of these algorithms in a sound and complete planning coordination algorithm in section      the complexity of these algorithms is o n  c    since
the o nc  procedures for determining must may clobber must be run for each of nc conditions  c
summary conditions in each of n plans represented by psum   
    summary resource usage threats
planners detect threats on resource constraints in different ways  if the planner reasons about partially ordered actions  it must consider which combinations of actions can overlap and together
exceed  or fall below  the resources maximum value  or minimum value   a polynomial algorithm

   

fic lement  d urfee     barrett

does this for the ixtet planner  laborie   ghallab         other planners that consider total order plans can more simply project the levels of the resource from the initial state through the plan 
summing overlapping usages  to see if there are conflicts  e g   chien et al       b  
finding conflicts involving summarized resource usages can work in the same way  for the
partial order planner  the resultant usage of clusters of actions are tested using the paralleland algorithm in section      for the total order planner  the level of the resource is represented
as a summarized usage  initially h x  x    x  x    x  x i for a consumable resource with an initial level
x and h x  x    x  x         i for a non consumable resource  then  for each subinterval between
start and end times of the schedule of tasks  the summary usage for each is computed using the
parallel and algorithm  then the level of the resource is computed for each subinterval while
propagating persistent usages using the serial and algorithm 
we can decide cananyway and mightsomeway as defined in section      in terms of the summary usage values resulting from invocations of parallel and and serial and in the propagation algorithm at the end of section        cananyway order  psum   res  is true if and only if
there are no potential threats  these algorithms discover a threat if they ever compute an interval i
such that
lb local min i     min value res   lb persist i     min value res  
ub local max i     max value res   ub persist i     max value res  

mightsomeway order  psum   res  is true if and only if there is a possible run with potentially no
threats  serial and discovers such a run if it returns a summary usage where
ub local min i    min value res   lb persist i    min value res  
lb local max i    max value res   ub persist i    max value res  

now that we have mechanisms for deriving summary information and evaluating plans based
on their summarizations  we will discuss how to exploit them in a planning coordination algorithm 

   hierarchical planning and coordination algorithm
with the earlier defined algorithms for reasoning about a group of agents plans at multiple levels
of abstraction  we now describe how agents can efficiently plan and coordinate based on summary
information  we describe a coordination algorithm that searches for ways to restrict the decomposition and ordering of the collective actions of the agent s  in order to resolve conflicts while
maximizing the utilities of the individual agents or the global utility of the group 
our approach starts by making planning decisions at the most abstract level and  as needed 
decomposes the agents plans in a top down fashion  the idea is to introduce only the information that is needed  introducing irrelevant details complicates search and increases communication 
after describing the top down planning coordination algorithm  we describe search techniques and
heuristics that the algorithm can use to further exploit summary information 
    top down hierarchical planning and coordination
the formalism of summary conditions culminated in section   in algorithms that determine if a set
of plans  abstract or primitive  under a partial set of ordering constraints is definitely conflict free
 cananyway  or has unresolvable conflicts  mightsomeway   here we integrate these algorithms
into one that searches for a consistent plan for one or more agents  the particular algorithm we
describe here is shown to be sound and complete  clement         the search starts out with
the top level plans of each agent  a solution is one where there are no possible conflicts among the
   

fia bstract r easoning for p lanning and c oordination

agents plans  the algorithm tries to find a solution at this top level and then expands the hierarchies
deeper and deeper until the optimal solution is found or the search space has been exhausted  a
pseudocode description of the algorithm is given in figure    
a state of the search is a partially elaborated plan that we represent as a set of and plans  one for
each agent   a set of temporal constraints  and a set of blocked plans  the subplans of the and plans
are the leaves of the partially expanded hierarchies of the agents  the set of temporal constraints
includes synchronization constraints added during the search in addition to those dictated by the
agents individual hierarchical plans  blocked subplans keep track of pruned or subplans 
decisions can be made during search in a decentralized fashion  the agents can negotiate over
ordering constraints to adopt  over choices of subplans to accomplish higher level plans  and over
which decompositions to explore first  while the algorithm described here does not specify  or
commit to  any negotiation technique  it does provide the mechanisms for identifying the choices
over which the agents can negotiate  although agents can make search decisions in a decentralized fashion  we describe the algorithm given here as a centralized process that requests summary
information from the agents being coordinated 
in the pseudocode in figure     the coordinating agent collects summary information about the
other agents plans as it decomposes them  the queue keeps track of expanded search states  if the
cananyway relation holds for the search state  the dominates function determines if the current
solutions are better for every agent than the solution represented by the current search state and
keeps it if the solution is not dominated  if mightsomeway is false  then the search space rooted at
the current search state can be pruned  otherwise  the coordinator applies operators to generate new
search states 
the operators for generating successor search states are expanding non primitive plans  blocking or subplans  and adding temporal constraints on pairs of plans  when an agent expands one
of its plans  each of the plans summary conditions are replaced with only the original conditions
of the parent plan  then the subplans summary information and ordering constraints are added to
the search state  a subplan of an or plan is added  or selected  only when all other subplans are
blocked  when applyoperator is called for the select and block operators  search states are
generated for each selectable and blockable subplan  respectively  blocking an or subplan can be
effective in resolving a constraint in which the other or subplans are not involved  for example  if
the inventory manager plans to only use transport   the production manager could block subplans
using transport   leaving subplans using transport  that do not conflict with the inventory managers
plan  this can lead to least commitment abstract solutions that leave the agents flexibility in selecting among the multiple applicable remaining subplans  the agents can take another approach by
selecting a subplan  effectively blocking all of the others  to investigate a preferred choice or one
that more likely avoids conflicts 
when the operator is to add a temporal constraint  a new search state is created for each alternative temporal constraint that could be added  these successor states are enqueued so that if
backtracking is needed  each alternative can be tried  adding temporal constraints should only generate new search states when the ordering is consistent with the other global and local constraints 
in our implementation  we only add constraints that will help resolve threats as determined by the
must may achieves and clobbers algorithms  when a plan is expanded or selected  the ordering
constraints must be updated for the subplans that are added 
the soundness and completeness of the coordination algorithm depends on the soundness and
completeness of identifying solutions and the complete exploration of the search space  soundness
   

fic lement  d urfee     barrett

concurrent hierarchical coordination algorithm
input  set of top level plans  initial state
output  set of solutions  each a pair of order constraints and blocked plan choices
begin function
summarized plans     
for each plan p  plans
p    get summary information for plan p
summarized plans   summarized plans    p   
end for
threats      p  p      p  p   summarized plans  mayclobber p  p     
    
  threats   
queue        
solutions     
loop
if queue      
return solutions
 order  blocked  threats    pop queue 
if cananyway initial state  summarized plans  order  blocked 
solution    order  blocked 
solutions   solutions   solution 
for each sol  and sol  in solutions
if dominates sol    sol   
solutions   solutions     sol   
if mightsomeway initial state  summarized plans  order  blocked 
operator   choose  expand  select  block  constrain  
queue   queue  applyoperator operator  summarized plans  order  blocked 
return solutions
end function

figure     a concurrent hierarchical coordination algorithm 
and completeness is not defined with respect to achieving particular goal predicates but resolving
conflicts in the plan hierarchies  a domain modeler may represent goals as abstract chips that
decompose into possible plans that accomplish them or as a series of actions for an agent to execute
successfully 
consider how the algorithm would find coordinated plans for the manufacturing agents  at the
beginning of the search  a coordinating agent gathers the summary information for the top level
plans of the three agents in plans  at first  there are no ordering constraints  so order is empty
in the first search state  shown in figure   a  popped from the queue  cananyway is false  and
mightsomeway is true for this state as described earlier in this section  so the coordinator chooses
an operator to apply to the search state  it could choose constrain and order the maintenance
plan before produce h to resolve all conflicts between those two plans  the order is updated with
the new constraint  and the new search state is inserted into the queue by according to some ranking
function  on the next iteration of the loop  the only search state in the queue that was just inserted
is popped  the coordinator again finds that cananyway is false  and mightsomeway is true since
move parts may still conflict with other plans over the use of transports  it can choose to constrain
produce h before move parts to resolve the remaining conflicts  this is detected on the next cycle
of the search loop where cananyway is found to be true for this search state  shown in figure   b  

   

fia bstract r easoning for p lanning and c oordination

the plans  the two constraints in order  and the empty set of blocked plans are added as a solution
since there is no previously found solution that dominates it  the dominates function uses domain
specific criteria for determining when a solution has value as an alternative and should be kept or
is inferior compared to another and should be dropped  in this manufacturing domain  one solution
dominates another if the finish time for at least one agent is earlier and no finish times are later for
any agents  the search then continues to find alternative or superior solutions  although the agents
may decide to terminate the search in the interest of time 
    search techniques and heuristics
although summary information is valuable for finding conflict free or coordinated plans at abstract
levels  this information can also be valuable in directing the search to avoid branches in the search
space that lead to inconsistent or suboptimal coordinated plans  a coordinator can prune away
inconsistent coordinated plans at the abstract level by doing a quick check to see if mightsomeway
is false  for example  if the search somehow reached the state shown in figure  b  the coordinator
could backtrack before expanding the hierarchies further and avoid reasoning about details of the
plans where they must fail 
another strategy is to first expand plans involved in the most threats  for the sake of completeness  the order of plan expansions does not matter as long as they are all expanded at some point
when the search trail cannot be pruned  but  employing this expand on most threats first  emtf 
heuristic aims at driving the search down through the hierarchy to find the subplan s  causing conflicts with others so that they can be resolved more quickly  this is similar to a most constrained
variable heuristic often employed in constraint satisfaction problems  for example  if the facilities
and inventory managers wished to execute their plans concurrently as shown in figure   a  at the
most abstract level  the coordinator would find that there are conflicts over the use of transports for
moving parts  instead of decomposing produce h and reasoning about plan details where there
are no conflicts  the emtf heuristic would choose to decompose either maintenance or move parts
which have the most conflicts  by decomposing maintenance the agents can resolve the remaining
conflicts and still execute concurrently 
another heuristic that a coordinator can use in parallel with emtf is choose fewest threats
first  cftf   here the search orders states in the search queue by ascending numbers of threats
left to resolve  in effect  this is a least constraining value heuristic used in constraint satisfaction
approaches  as mentioned in section      threats are identified by the cananyway algorithm  by
trying to resolve the threats of coordinated plan search states with fewer conflicts  it is hoped that
solutions can be found more quickly  so  emtf is a heuristic for ordering and subplans to expand 
and cftf  in effect  orders or subplan choices  for example  if the production manager chooses to
use machine m  instead of m  to produce g  the coordinator is likely closer to a solution because
there are fewer conflicts to resolve  this heuristic can be applied not only to selecting or subplan
choices but also to choosing temporal constraints and variable bindings or any search operator from
the entire set of operators 
in addition  in trying to find optimal solutions in the style of a branch and bound search  the
coordinator can use the cost of abstract solutions to prune away branches of the search space whose
minimum cost is greater than the maximum cost of the current best solution  this is the role of the
dominates function in the description of the coordination algorithm in section      this usually

   

fic lement  d urfee     barrett

a 

maintenance
produce h
move parts

b 

maintenance
service m  m 
service

service

m 

m 

move
tool

produce h

move parts

figure    

emtf

heuristic resolving conflicts by decomposing the maintenance plan

assumes that cost utility information is decomposable over the hierarchy of actions  or the cost of
any abstract action is a function of its decompositions 

   complexity analyses
even though the planner or coordinator can use the search techniques described in the section     to
prune the search space  just being able to find solutions at multiple levels of abstraction can reduce
the computation as much as doubly exponentially  in this section  we give an example of this and
then analyze the complexity of planning and scheduling to characterize this cost reduction and the
conditions under which it occurs 
an agent that interleaves execution with planning coordination often must limit the total computation and execution cost required to achieve its goals  the planning algorithm described in section
    is able to search for solutions at different levels of abstraction  for the manufacturing example 
our implementation of a centralized coordinator uses this algorithm to find in     cpu seconds a solution at the top level of the agents plans as shown in figure   b  if we define the cost of execution
as the makespan  completion time  of the coordinated plan  the cost of this solution is     where the
makespan of the production managers plan is     the facilities managers is     and the inventory
managers is     for the solution in figure   c  the coordinator required     cpu seconds  and
the makespan of the coordinated plan is      another solution is found at an intermediate level of
abstraction  taking    cpu seconds and having a makespan of      so  with a little more effort 
the algorithm expanded the hierarchy to an intermediate level where the cost of the solution was
reduced by     thus  overall cost can be reduced by coordinating at intermediate levels 
for this problem  coordinating at higher levels of abstraction is less costly because there are
fewer plan steps  but  even though there are fewer plans at higher levels  those plans may have
greater numbers of summary conditions to reason about because they are collected from the much
greater set of plans below  here we argue that even in the worst case where the number of summary
conditions per plan increases exponentially up the hierarchy  finding solutions at abstract levels is
expected to be exponentially cheaper than at lower levels  we first analyze the complexity of the
   

fia bstract r easoning for p lanning and c oordination

summarization algorithm to help the reader understand how the summary conditions can collect in
greater sets at higher levels 
    complexity of summarization
consider a hierarchy with n total plans  b subplans for each non primitive plan  and depth d  starting
with zero at the root  as shown in figure     the procedure for deriving summary conditions works
by basically propagating the conditions from the primitives up the hierarchy to the most abstract
plans  because the conditions of any non primitive plan depend only on those of its immediate subplans  deriving summary conditions can be done quickly if the number of subplans is not large  the
derivation algorithm mainly involves checking for achieve  clobber  and undo interactions among
subplans for all possible total orderings of the subplans  as described in section       checking for
one of these relations for one summary condition of one subplan is o bs  for b subplans  each with
s summary conditions  as discussed in section       since there are o bs  conditions that must be
checked in the set of subplans  deriving the summary conditions of one plan from its subplans is
o b  s    
however  the maximum number of summary conditions for a subplan grows exponentially up
the hierarchy since  in the worst case  no summary conditions merge during summarization  this
happens when the conditions of each subplan are on completely different propositions variables
than those of any sibling subplan  in this case  a separate summary condition will be generated for
each summary condition of each subplan  if the children share conditions on the same variable  this
information is collapsed into a single summary condition in the parent plan 
as shown in the third column of the table in figure     a plan at the lowest level d has s   c
summary conditions derived from its c pre   in   and postconditions  a plan at level d    derives c
summary conditions from its own conditions and c from each of its b subplans giving c   bc summary conditions  or s   o bc   so  in this worst case s   o bdi c  for a plan at level i in a hierarchy
for which each plan has c  non summary  conditions  thus  the complexity of summarizing a plan
at level i  with subplans at level i      is o b  b  d i     c      o b  di  c     there are bi plans at
level i  second column in the figure   so the complexity of summarizing the set of plans at level i is
o bi b  di  c      o b di c    as shown in the fourth column in the figure  thus  the complexity of
i   di  c     in this summation i    
summarizing the entire hierarchy of plans would be o d 
i   b b
 d
 
dominates  so the complexity can be simplified to o b c    if there are n   o bd   plans in the
hierarchy  we can write this simply as o n  c     which is the square of the size of the hierarchy 
in the best case where all conditions are on the same variable  each plan will have c summary
i    
conditions  thus  the complexity for summarizing the hierarchy will be o d 
i   b b c    which
simplifies to o bd   c      o nbc     in any case  the summarization of conditions is tractable  and
as we discussed in section        the summarization of resources is also tractable 
    complexity of finding abstract solutions
in order to resolve conflicts  and potentially arrive at a solution  at a particular level of expansion
of the hierarchy  the coordination algorithm checks for threats between the plans under particular
ordering constraints at that level  checking for threats involves finding clobber relations among the
plans and their summary conditions  the complexity of finding threats among n plans each with s
summary conditions is o n  s    as shown in section     for the mightsomeway algorithm  for a
hierarchy expanded to level i  there are n   o bi   plans at the frontier of expansion  and each plan
   

fic lement  d urfee     barrett

level  plans  conds    operations to  test operations   solution
plan derive summ  info  solution candidate space

 

 

   

b

      
                                 
          
            
 

 

   

b

 

 

   

b

       

 

 

o bdc 

o b  bd  c   
  o b dc  

o   

 

 

b

o bd  c 

o bb  bd  c   
  o b d  c  

o b  b d   c   
  o b dc  

o kb 

 

b 

o bd  c  o b b  bd  c   
  o b d  c  

o b  b d   c   
  o b dc  

o kb  

d  

bd  

o b c 

o bd  b  bc   
  o bd  c  

o b  d    b c    o kb  
  o b dc  

d  

bd  

 c b c
  o bc 

o bd  b c  
  o bd  c  

o b  d    bc    o kb  
  o b dc  

d

bd

 c

o   

o b dc  

o kb  

i

bi

o bd ic 

o b d ic  

o b dc  

o kbi 

 

d  

d  

d

figure     complexity of threat identification and resolution at abstract levels
has s   o bdi c  summary conditions  so  as shown in the fifth column of the table in figure    
the worst case complexity of checking for threats for one synchronization of a set of plans at level i
is o b i  bdi c       o b d c     notice that i drops out of the formula  meaning that the complexity
of checking a candidate solution is independent of the depth level  in the best case where summary
conditions fully merge  each plan has s   c summary conditions  so the complexity of checking a
candidate solution is o b i c     a factor of o b  di   faster than the worst case 
however  the algorithm may check many synchronizations at a particular level before finding
a solution or exhausting the search space  in fact this search complexity grows exponentially with
the number of plans   thus  as shown in the last column of the table in figure     the search space
i
is o kb   for bi plans at level i and constant k   thus  the search space grows doubly exponentially
down the hierarchy based on the number of plan steps 
in our refinement coordination and planning algorithm  the conflict detection is a basic operation
that is done for resolving conflicts  so  to also include the effect of the size of conditions  in
addition to plan steps  on the complexity of the planning coordination algorithm  we must multiply
i
by the complexity to check threats  thus  the complexity is o kb b d c    when summary information
i
does not merge at all and o kb b i c    when summary information fully merges  the complexity
d
of resolving conflicts at the primitive level is o kb b d c     so resolving conflicts at an abstract
d
i
level speeds search doubly exponentially  a factor of o kb b   even when summary information
does not merge during summarization  now  if it completely merges  the speedup is a factor of
d
i
o kb b b  di    
   in fact  it is np complete  clement        
   this is why georgeff chose to cluster multiple operators into critical regions and synchronize the  fewer  regions
since there would be many fewer interleavings to check         by exploiting the hierarchical structure of plans  we
use the clusters predefined in the hierarchy to this kind of advantage without needing to cluster from the bottom
up 

   

fia bstract r easoning for p lanning and c oordination

level
 
 
d

branching
factor b

   
 

 

n
c constraints
per hierarchy

v
variables

figure     schedule of n task hierarchies each with c constraints on v variables
there are only and plans in this analysis  in the case that there are or plans  being able to prune
branches at higher levels based on summary information will also greatly improve the search despite
the overhead of deriving and using summary conditions  pruning effectively reduces the branching
factor since the branch is eliminated before investigating its details  thus  the complexity based on
d
the number of plan steps becomes o k bp    when a fraction of p b branches can be pruned  thus 
pruning can also create an exponential reduction in search 
    scheduling complexity
a local search planner  e g  aspen  chien et al       b  does not backtrack  but the problem to be
solved is the same  so one might expect that complexity advantages are the same as for the refinement planner  however  the search operations for the local search planner can be very different  a
previous study of a technique called aggregation eliminates search inefficiencies at lower levels of
detail in task hierarchies by operating on hierarchies as single tasks  knight  rabideau    chien 
       thus  it is not immediately clear what additional improvements a scheduler could obtained
using summary information  we will show that the improvements are significant  but first we must
provide more background on aggregation 
moving tasks is a central scheduling operation in iterative repair planners  a planner can more
effectively schedule tasks by moving related groups of tasks to preserve constraints among them 
hierarchical task representations are a common way of representing these groups and their constraints  aggregation involves moving a fully detailed abstract task hierarchy while preserving the
temporal ordering constraints among the subtasks  moving individual tasks independently of their
parent  siblings  and subtasks is shown to be much less efficient  knight et al          valid placements of the task hierarchy in the schedule are computed from the state and resource usage profiles
for the hierarchy and for the other tasks in the context of the movement  a hierarchys profile represents one instantiation of the decomposition and temporal ordering of the most abstract task in the
hierarchy 
consider a schedule of n task hierarchies with a maximum branching factor b expanded to a
maximum depth of d as shown in figure     suppose each hierarchy has c constraints on each of v
variables  states or metric resources   to move a hierarchy of tasks using aggregation  the scheduler

   

fic lement  d urfee     barrett

must compute valid intervals for each resource variable affected by the hierarchy   the scheduler
then intersects these intervals to get valid placements for the abstract tasks and their children  the
complexity of computing the set of valid intervals for a resource is o cc  where c is the number
of constraints  usages  an abstract task has with its children for the variable  and c is the number
of constraints of other tasks in the schedule on the variable  knight et al          with n similar
task hierarchies in the entire schedule  then c    n    c  and the complexity of computing valid
intervals is o nc     but this computation is done for each of v resource variables  often constant for
a domain   so moving a task will have a complexity of o vnc     the intersection of valid intervals
across variables does not increase the complexity  its complexity is o tnr  because there can be at
most nr valid intervals for each timeline  intersecting intervals for a pair of timelines is linear with
the number of intervals  and only t   pairs of timelines need to be intersected to get the intersection
of the set 
the summary information of an abstract task represents all of the constraints of its children  but
if the children share constraints over the same resource  this information is collapsed into a single
summary resource usage in the abstract task  therefore  when moving an abstract task  the number
of different constraints involved may be far fewer depending on the domain  if the scheduler is
trying to place a summarized abstract task among other summarized tasks  the computation of valid
placement intervals can be greatly reduced because the c in o vnc    is smaller  we now consider
the two extreme cases where constraints can be fully collapsed and where they cannot be collapsed
at all 
in the case that all tasks in a hierarchy have constraints on the same variable  the number of
constraints in a hierarchy is o bd   for a hierarchy of depth d and branching factor  number of child
tasks per parent  b  in aggregation  where hierarchies are fully detailed first  this means that the
complexity of moving a task is o vnb d   because c   o bd    now consider using aggregation
for moving a partially expanded hierarchy where the leaves are summarized abstract tasks  if all
hierarchies in the schedule are decomposed to level i  there are o bi   tasks in a hierarchy  each with
one summarized constraint representing those of all of the yet undetailed subtasks beneath it for
each constraint variable  so c   o bi    and the complexity of moving the task is o vnb i    thus 
moving an abstract task using summary information can be a factor of o b  di    times faster than
for aggregation  because the worst case number of conflicts increases with the number of plan
steps  just as with the refinement planner   the worst case complexity of resolving conflicts based
i
on the number of plan steps at level i is o kb    thus  as with refinement planning  using summary
di
information can make speedups of o kb b  di    when summary information fully collapses 
the other extreme is when all of the tasks place constraints on different variables  in this case 
c     because any hierarchy can only have one constraint per variable  fully detailed hierarchies
contain v   o bd   different variables  so the complexity of moving a task in this case is o nbd   
if moving a summarized abstract task where all tasks in the schedule are decomposed to level i  v
is the same because the abstract task summarizes all constraints for each subtask in the hierarchy
beneath it  and each of those constraints are on different variables such that no constraints combine
when summarized  thus  the complexity for moving a partially expanded hierarchy is the same as
for a fully expanded one  in this case  the number of conflicts also does not change with the depth of
the hierarchy because the conflicts are always between pairs of the n hierarchies  so  for this other
   the analysis also applies to state constraints  but we restrict the discussion to resource usage constraints for simplicity 

   

fia bstract r easoning for p lanning and c oordination

extreme case  summary information does not reduce the complexity of scheduling and would only
incur unnecessary overhead 
other complexity analyses have shown that different forms of hierarchical problem solving  if
they do not need to backtrack from lower to higher levels because there are no interacting subproblems  can reduce the size of the search space by an exponential factor  korf        knoblock        
a planner or scheduler using summary information can witness exponential improvements without
this assumption  backtracking across abstraction levels occurs within the planner coordinator described in section     when the current search state is mightsomeway and another or subplan
on the same or higher level can be selected  we demonstrated that the search space grows doubly
exponentially down the hierarchy because the number of plans grows exponentially  and resolving
conflicts grows exponentially with the number of plans  thus  as long as the planner or coordinator does not have to fully expand all abstract plans to the primitive level and summary information
d
i
merges at higher levels  the search complexity is reduced at least by a factor of kb b where i is the
level where the search completed  and d is the depth of the hierarchy  yang        also suggests
ways exponential speedups can be obtained when subplans interact based on hierarchy structure 
our speedups are complementary to these because summary information limits the decomposition
of task hierarchies and compresses the information manipulated by a planner or scheduler 

   experiments
now we experimentally evaluate the use of summary information in planning and coordination for
three different domains  an evacuation domain  the manufacturing domain described in section     
and a multi rover domain  in these domains  we define performance in different ways to show a
range of benefits that abstract reasoning offers 
we evaluate the algorithm described in section      our implementation orders search states
in the queue such that those generated by synchronization operators precede those generated by
expansion and selection operators  thus  before going deeper into a part of the hierarchy  the implementation of the algorithm explores all orderings of the agents plans before digging deeper into
the hierarchy  investigating heuristics for choosing between synchronization and decomposition
operators is a topic for future research 
in the next section we report experiments for an evacuation domain that show how abstract
reasoning using summary information can find optimal coordination solutions more quickly than
conventional search strategies  optimal solutions in the evacuation domain have minimal global execution times because evacuees must be transported to safety as quickly as possible  in section     
we show that summary information improves local search performance significantly when tasks
within the same hierarchy have constraints over the same resource  and when solutions are found at
some level of abstraction  we also evaluate the benefits of using the cftf and emtf heuristics for
iterative repair and show where summary information can slow search 
in some domains  computation time may be insignificant to communication costs  these costs
could be in terms of privacy for self interested agents  security for sensitive information that could
obtained by malicious agents  or simply communication delay  in section      we show how multilevel coordination fails to reduce communication delay for the manufacturing domain example but 
for other domains  can be expected to reduce communication overhead exponentially 

   

fic lement  d urfee     barrett

 
s 

 

 

 

s 
t 

t 
 

 

figure     evacuation problem
    coordinated planning experiments
in this section  we describe experiments that evaluate the use of summary information in coordinating a group of evacuation transports that must together retrieve evacuees from a number of locations
with constraints on the routes  in comparing the emtf and cftf search techniques described in section     against conventional htn approaches  the experiments show that reasoning about summary
information finds optimally coordinated plans much more quickly than prior htn techniques 
we compare different techniques for ordering the expansion of subplans of both and and or
plans to direct the decomposition of plan hierarchies in the search for optimal solutions  these
expansion techniques are the expand  for and subplans  and select  for or subplans  operators of
the algorithm described in section     
we compare emtfs expansion of and plans to the excon heuristic and to a random selection
heuristic  the excon heuristic  tsuneto et al         first selects plans that can achieve an external
precondition  or if there are no such plans  it selects one that threatens the external precondition 
in the case that there are neither achieving or threatening plans  it chooses randomly  note that
emtf will additionally choose to expand plans with only threatened external preconditions but has
no preference as to whether the plan achieves  threatens  or is threatened  for the expansion of or
plans  we compare cftf to a depth first  dfs  and a random heuristic 
we also compare the combination of cftf and emtf to an faf  fewest alternatives first 
heuristic and to the combination of dfs and excon  the faf heuristic does not employ summary
information but rather chooses to expand and and select or plans that have the fewest subplans
 currie   tate        tsuneto  hendler    nau         since no summary information is used 
threats are only resolved at primitive levels  while it has been shown that the faf heuristic can
be effectively used by an htn planner  tsuneto et al          the combination of dfs and excon
has been shown to make great improvements over faf in a domain with more task interactions
 tsuneto et al          we show in one such domain that the cftf and emtf heuristics can together
outperform combinations of faf  dfs  and excon 
the problems were generated for an evacuation domain where transports are responsible for
visiting certain locations along restricted routes to pick up evacuees and bring them back to safety
points  transports are allowed to be at the same location at the same time  but the coordinator must
ensure that transports avoid collisions along the single lane routes  in addition  in order to avoid the
risk of oncoming danger  from a typhoon or enemy attack   the transports must accomplish their
goals as quickly as possible 
suppose there are two transports  t  and t   located at safety points s  and s  respectively  and
they must visit the locations       and   and       and   respectively and bring evacuees back to safe
   

fia bstract r easoning for p lanning and c oordination

evacuate
move s   

make rounds

one switch

no switch
clockwise

first route

cw   

second route

cw   

move    

counterclockwise

ccw   

ccw   

go back

ccw   

goto safe loc

no move

move   s 

move   s 

move    

figure     the plan hierarchy for transport t 
locations as shown in figure     because of overlap in the locations they must visit  the coordinator
must synchronize their actions in order to avoid collision  the coordinators goal network includes
two unordered tasks  one for each transport to evacuate the locations for which it is responsible 
as shown in figure     the high level task for t   evacuate  decomposes into a primitive action of
moving to location   on the ring and an abstract plan to traverse the ring  make rounds   t  can
travel in one direction around the ring without switching directions  or it can switch directions once 
t  can then either go clockwise or counterclockwise and  if switching  can switch directions at any
location   f irst route  and travel to the farthest location it needs to visit from where it switched
 second route   once it has visited all the locations  it continues around until it reaches the first
safety point in its path  go back and goto sa f e loc   the no move plan is for the case where t  is
already at location    the task for t  can be refined similarly 
suppose the coordinator gathers summary information for the plan hierarchy and attempts to
resolve conflicts  looking just at the summary information one level from the top  the coordinator
can determine that if t  finishes evacuating before t  even begins  then there will be no conflicts
since the external conditions of t s evacuate plan are that none of the routes are being traversed 
this solution has a makespan  total completion time  of    steps  the optimal solution is a plan of
duration seven where t  moves clockwise until it reaches location s   and t  starts out clockwise 
switches directions at location    and then winds up at s   for this solution t  waits at location   for
one time step to avoid a collision on the route from location   to location   
we generated problems with four  six  eight  and twelve locations  with two  three and four
transports  and with no  some  and complete overlap in the locations the transports visit  performance was measured as the number of search states expanded to find the optimal solution or  if the
compared heuristics did not both find the optimal solution  as the number of states each expanded
to find solutions of highest common quality within memory and time bounds  we chose this instead of cpu time as the measure of performance in order to avoid fairness issues with respect to
implementation details of the various approaches 

   

fic lement  d urfee     barrett

search states expanded
      

cftf rand

     
    
   
  
 
 

  

   

            e   

cftf emtf

figure     comparing emtf to random expansion in searching for optimal solutions

figure     comparing emtf to excon in searching for optimal solutions
the scatter plot in figure    shows the relative performance of the combination of cftf and
and the combination of cftf and random and expansion  cftf rand   we
chose scatterplots to compare results because they capture the results more simply than trying to
plot against three dimensions of problem size complexity  note that for all scatter plots  the axes are
scaled logarithmically  points above the diagonal line mean that emtf  x axis  is performing better
than rand  y axis  because fewer search states were required to find the optimal solution  while
performance is similar for most problems  there are a few cases where cftf emtf outperformed
cftf  rand by an order of magnitude or more  figure    exhibits a similar effect for cftf   emtf
and cftf excon  note that runs were terminated after the expansion of       search states  data
points at        the ones forming a horizontal line at the top  indicate that no solution was found
within memory and time constraints  while performance is similar for most problems  there are four
points along the top where cftf excon finds no solution  thus  although emtf does not greatly
emtf   cftf   emtf  

   

fia bstract r easoning for p lanning and c oordination

figure     comparing cftf and dfs in searching for optimal solutions
improve performance for many problems  it rarely performs much worse  and almost always avoids
getting stuck in fruitless areas of the search space compared to the excon and the random heuristic 
this is to be expected since emtf focuses on resolving conflicts among the most problematic plans
first and avoids spending a lot of time reasoning about the details of less problematic plans 
the combination of cftf with emtf  pruning inconsistent abstract plan spaces  and branchand bound pruning of more costly abstract plan spaces  all described in section      much more
dramatically outperforms techniques that do not reason at abstract levels  figure    shows dfsrand expanding between one and three orders of magnitude more states than cftf rand  runs
were terminated after the expansion of        search states  data points at         forming the
horizontal line at the top  indicate that no solution was found within memory and time constraints 
by avoiding search spaces with greater numbers conflicts  cftf finds optimal or near optimal solutions much more quickly  in figures    and     cftf emtf outperforms faf faf  faf for both
selecting and and or plans  and dfs excon by one to two orders of magnitude for most problems 
these last two comparisons especially emphasize the importance of abstract reasoning for finding
optimal solutions  within a maximum of       expanded search states  the lowest cutoff point in
the experiments   cftf emtf and cftf rand found optimal solutions for    of the    problems 
cftf  excon and faf  faf found     and dfs  excon and dfs  rand only found three 
a surprising result is that faf faf performs much better than dfs excon for the evacuation
problems contrary to the results given by tsuneto et al         that show dfs excon dominating
for problems with more goal interactions  we believe that this result was not reproduced here
because those experiments involved hierarchies with no or plans  the experiments show that the
selection of or subplans more greatly affects performance than the order of and subplans to expand 
so  we believe dfs excon performed worse than faf faf not because faf is better at choosing
and subplans than excon but because faf is stronger at selecting or subplans than dfs 
however  the main point of this section is that each of the heuristic combinations that use summary information to find solutions and prune the search space at abstract levels  cftf emtf  cftfexcon  and cftf rand  greatly outperform all of those that do not  faf faf  dfs excon  and
dfs  rand  when searching for optimal solutions 

   

fic lement  d urfee     barrett

figure     comparing the use of summary information to the faf heuristic

figure     comparing the use of summary information to the algorithm using external conditions
    scheduling experiments
the experiments we describe here show that summary information improves performance significantly when tasks within the same hierarchy have constraints over the same resource  and solutions
are found at some level of abstraction  at the same time  there are cases where abstract reasoning
incurs significant overhead when solutions are only found at deeper levels  however  in domains
where decomposition choices are critical  we show that this overhead is insignificant because the
cftf heuristic chooses decompositions that more quickly lead to solutions at deeper levels  these
experiments also show that the emtf heuristic outperforms a simpler heuristic depending on the
decomposition rate  raising new research questions  we use the aspen planning system  chien
et al       b  to coordinate a rover team for the problem described next 

   

fia bstract r easoning for p lanning and c oordination

figure     randomly generated rectangular field of triangulated waypoints

figure     randomly generated waypoints along corridors
      p roblem d omains
the domain involves a team of rovers that must resolve conflicts over shared resources  we generate
two classes of maps within which the rovers move  for one  we randomly generate a map of triangulated waypoints  figure      for the other  we generate corridor paths from a circle of locations
with three paths from the center to points on the circle to represent narrow paths around obstacles
 figure      this corridor map is used to evaluate the cftf heuristic  we then select a subset of
the points as science locations  where the rovers study rocks soil  and use a simple multiple traveling salesman algorithm to assign routes for the rovers to traverse and perform experiments  the
idea is that a map of the area around a lander is constructed from an image taken upon landing on
mars 
paths between waypoints are assigned random capacities such that either one  two  or three
rovers can traverse a path simultaneously  only one rover can be at any waypoint  and rovers may
not traverse paths in opposite directions at the same time  these constraints are modeled as metric
resources  state variables are also used to ensure rovers are at locations from which they are about
to leave  in addition  rovers must communicate with the lander for telemetry using a shared channel
of fixed bandwidth  metric resource   depending on the terrain between waypoints  the required
bandwidth varies     problems were generated for two to five rovers  three to six science locations
per rover  and   to     waypoints  in general  problems that contain fewer waypoints and more
science goals are more difficult because there are more interactions among the rovers 
schedules consist of an abstract task for each rover that have an and decomposition into tasks for
visiting each assigned science location  those tasks have an or decomposition into the three shortest
paths through the waypoints to the target science location  the paths have an and decomposition
into movements between waypoints  additional levels of hierarchy were introduced for longer paths
in order to keep the offline resource summarization tractable  schedules ranged from     to     
tasks 

   

fic lement  d urfee     barrett

      e mpirical r esults for m ars rovers
we compare aspen using aggregation with and without summarization for three variations of the
rectangular field domain  when using summary information  aspen also uses the emtf and cftf
decomposition heuristics  one domain excludes the communications channel resource  no channel  
one excludes the path capacity restrictions  channel only   and the other excludes neither  mixed  
since all of the movement tasks reserve the channel resource  greater improvement in performance
is expected when using summary information according to the complexity analyses in section     
this is because constraints on the channel resource collapse in the summary information derived
at higher levels such that any task in a hierarchy only has one constraint on the resource  when
aspen does not use summary information  the hierarchies must be fully expanded  and the number
of constraints on the channel resource is equivalent to the number of leaf movement tasks 
however  tasks within a rovers hierarchy rarely place constraints on the other path variables
more than once  so the no channel domain corresponds to the worst case where summarization
collapses no constraints  here the complexity of moving an abstract task is the same without summary information for the fully expanded hierarchy as it is with summary information for a partially
expanded hierarchy 
figure     top  exhibits two distributions of problems for the no channel domain  in most of the
cases  points above the x y diagonal   aspen with summary information finds a solution quickly at
some level of abstraction  however  in many cases  summary information performs notably worse
 points below the x y diagonal   we discovered that for these problems finding a solution requires
the planner to dig deeply into the rovers hierarchies  and once it decomposes the hierarchies to
the level of the solution  the difference in the additional time to find a solution between the two
approaches is negligible  unless the use of summary information found a solution at a slightly higher
level of abstraction more quickly   thus  the time spent reasoning about summary information at
higher levels incurred unnecessary overhead 
but this is the worst case in the analysis in section     where we showed that summary information had no advantage even if it found abstract solutions  so  why did summary information perform
better when abstract solutions were found  it was not because of the cftf heuristic since or branch
choices result in small differences in numbers of conflicts  it actually results from the stochastic nature of aspens iterative repair  although moving the most abstract tasks using aggregation without
summary information would have enabled aspen to find solutions more quickly for fully expanded
hierarchies  aspen must sometimes move lower level tasks independently of their parents and siblings in order to resolve conflicts at lower levels  the problem is that aspen has no heuristic to tell
it at what level it needs to move activities  and it sometimes chooses to move activities at detailed
levels unnecessarily  this search at lower levels is where the search space explodes  using summary
information to search at higher levels below lower levels of abstraction better protects aspen from
unnecessary search 
figure     middle  shows significant improvement for summary information in the mixed domain compared to the no channel domain  adding the channel resource rarely affects the use of
summary information because the collapse in summary constraints incurs insignificant additional
complexity  however  the channel resource makes the scheduling task noticeably more difficult for
aspen when not using summary information  in the channel only domain  figure    bottom   summary information finds solutions at the abstract level almost immediately  but the problems are still
complicated when aspen does not use summary information  these results support the complexity

   

fia bstract r easoning for p lanning and c oordination

a 

b 

c 
figure     plots for the a  no channel  b  mixed  and c  channel only domains
analysis in section     that argues that summary information exponentially improves performance
when tasks within the same hierarchy have constraints over the same resource and when solutions
are found at some level of abstraction 
because summary information is generated offline  the domain modeler knows up front whether
or not constraints are significantly collapsed  thus  an obvious approach to avoiding cases where
reasoning about summary information causes unnecessary overhead is to fully expand at the start
of scheduling the hierarchies of tasks where summary information does not collapse  because the
complexity of moving a task hierarchy is the same in this case whether fully expanded or not  aspen
does not waste time by duplicating its efforts at each level of expansion before reaching the level at
which it finds a solution  evaluating this approach is a subject of future work 
earlier we mentioned that the cftf heuristic is not effective for the rectangular field problems 
this is because the choice among different paths to a science location usually does not make a

   

fic lement  d urfee     barrett

figure     performance using the cftf heuristic

significant difference in the number of conflicts encounteredif the rovers cross paths  all path
choices usually still lead to conflict  for the set of corridor problems  path choices always lead
down a different corridor to get to the target location  so there is usually a path that avoids a conflict
and a path that causes one depending on the path choices of the other rovers  when aspen uses the
cftf heuristic  the performance dominates that of when it chooses decompositions randomly for all
but two problems  figure      this reflects experiments for the coordination algorithm in section  
that show that cftf is crucial for reducing the search time required to find solutions 
in order to evaluate the emtf heuristic for iterative repair planning  we compared it to a simple
alternative  this alternative strategy  that we refer to as level decomposition  is to interleave repair
with decomposition as separate steps  step    the planner repairs the current schedule until the
number of conflicts cannot be reduced  step    it decomposes all abstract tasks one level down
and returns to step    by only spending enough time at a particular level of expansion that appears
effective  the planner attempts to find the highest decomposition level where solutions exist without
wasting time at any level  the time spent searching for a solution at any level of expansion is
controlled by the rate at which abstract tasks are decomposed  the emtf heuristic is implemented
as a repair method to give priority to detailing plans that are involved in more conflicts 
figure    shows the performance of emtf vs  level decomposition for different rates of decomposition for three problems from the set with varied performance  the plotted points are averages
over ten runs for each problem  depending on the choice of rate of decomposition  the probability
that a task will decompose when a conflict is encountered   performance varies significantly  however  the best decomposition rate can vary from problem to problem making it potentially difficult
for the domain expert to choose  for example  for problem a in the figure  all tested decomposition
rates for emtf outperformed the use of level decomposition  at the same time  for problem c using
either decomposition technique did not make a significant difference while for problem b choosing
the rate for emtf made a big difference in whether to use emtf or level decomposition  although
these examples show varied performance  results for most other problems showed that a decompo 

   

fia bstract r easoning for p lanning and c oordination

    

a
a level decomp
    

b
b level decomp
c

cpu seconds

   

c level decomp
   

   

   

 
 

 

  

  

  

  

  

  

emtf decomposition rate

figure     performance of emtf vs  level decomposition heuristics
sition rate of around     was most successful  this suggests that a domain modeler may be able to
choose a generally successful decomposition rate by running performance experiments for a set of
example problems  
we have demonstrated many of the results of the complexity analyses in section    scheduling
with summary information gains speedups  over aggregation  by resolving conflicts at appropriate levels of abstraction  when summary information collapses  the scheduler gains exponential
speedups  in addition  the cftf heuristic enables exponential speedups when or decomposition
choices have varying numbers of conflicts 
    communication overhead
here we show that  depending on bandwidth  latency  and how summary information is communicated among the agents  delays due to communication overhead vary  if only communication costs
are a concern  then at one extreme where message delay dominates cost  sending the plan hierarchy
without summary information makes the most sense  at the other extreme where bandwidth costs
dominate  it makes sense to send the summary information for each task in a separate message as
each is requested  still  there are cases when sending the summary information for tasks in groups
makes the most sense  this section will explain how a system designer can choose how much
summary information to send at a time in order to reduce communication overhead exponentially 
consider a simple protocol where agents request coordination from a central coordinating agent 
during the search for a feasible solution  whenever it decomposes a task  the coordinator requests
summary information for the subtasks that it has not yet received  for the manufacturing domain 
the coordinator may already have summary information for a task to move a part  but if it encounters
a different instantiation of the same task schema  it still must request the parameters for the new task 
if a coordinator needs the subplans of an or plan  the client agent sends the required information for
all subplans  specifying its preferences for each  the coordinator then chooses the most preferred
   for other experiments  we used a decomposition rate of     since it seemed to work well 

   

fic lement  d urfee     barrett

a 

b 

figure     delay of communicating different granularities of summary information with varying a 
latency and b  bandwidth

subplan  and in the case it must backtrack  it chooses the next most preferred subplan  once the
coordinator finds a feasible solution  it sends modifications to each agent specifying which or subplans are blocked and where the agent must send and wait for synchronization messages  an agent
can choose to send summary information for some number of levels of expansion of the requested
tasks hierarchy 
for the manufacturing problem described in section      communication data in terms of numbers of messages and the size of each was collected up to the point that the coordinator found the
solution in figure   c  this data was collected for cases where agents sent summary information
for tasks in their hierarchies  one at a time  two levels at a time  and all at once  the two levels
include the requested task and its immediate subplans  the following table below summarizes the
numbers and total sizes of messages sent for each granularity level of information 

one task at a time
two levels at a time
all at once

number of messages
 
 
 

total size  bytes 
    
     
     

assuming that the coordinator must wait for requested information before continuing its search
and can request only one task of one agent at a time  the coordination will be delayed for an amount
of time depending on the bandwidth and latency of message passing  the total delay can be calculated as  n        s b  where n is the number of messages sent    is the latency in seconds  s is the
total size of all messages  and b is the bandwidth in bytes per second  we use n    instead of n
because we assume that the agents all transmit their first top level summary information message at
the same time  so three messages actually only incur a delay of   instead of    
figure   a shows how the communication delay varies for the three granularities of information
for a fixed bandwidth of     bytes second   we will address the lack of realism in this example
shortly   when the latency is less than   seconds  sending summary information for each task in
separate messages results in the smallest communication overhead  for latencies greater than   
seconds  sending the entire hierarchy is best  and in between sending summary information two
levels at a time is best  if the latency is fixed at     seconds  then the communication delay varies
   

fia bstract r easoning for p lanning and c oordination

a 

b 

figure     delay with varying a  latency and b  bandwidth for hypothetical example
with bandwidth as shown in figure   b  when the bandwidth is less than   bytes second  sending
one at a time is best  sending it all at once is best for bandwidths greater than    bytes second  and
sending two levels at a time is best for bandwidths in between 
admittedly  these values are unrealistic for the manufacturing domain  the manufacturing problem itself is very simple and provided mainly as an interesting domain for coordination  more realistic problems involving the manufacturing domain could have much larger hierarchies and require
much larger scales of data to be sent  in that case more realistic bandwidth and latency values would
exhibit similar tradeoffs 
to see this  suppose that the manufacturing managers hierarchies had a common branching
factor b and depth d  if tasks generally had reservations on similar resources throughout the hierarchies  the amount of total summary information at a particular level would grow exponentially
down the hierarchy just as would the number of tasks  if the agents agreed on a feasible solution at
depth level i in the hierarchy  then the table for messages and size would appear as follows 

one task at a time
two levels at a time
all at once

number of messages
o bi  
 i  
 

total size
o bi  
o bi  
o bd  

now suppose that the branching factor b is    the depth d is     the solution is found at level
i      and the summary information for any task is   kbyte  then the table would look like this 

one task at a time
two levels at a time
all at once

number of messages
   
 
 

total size  kbytes 
    
    
      

now  if we fixed the bandwidth at     kbyte second and varied the latency  more realistic
tradeoffs are seen in figure   a  here  we see that unless the latency is very small  sending summary
information two levels at a time is best  as shown in figure   b  if we fix latency to be one second
and vary the bandwidth  for all realistic bandwidths sending summary information two levels at a
time is again best 

   

fic lement  d urfee     barrett

this simple protocol illustrates how communication can be minimized by sending summary
information at a particular granularity  if the agents chose not to send summary information but
the unsummarized hierarchies instead  they would need to send their entire hierarchies  as the
experiment shows  as hierarchies grow large  sending the entire hierarchy  all at once  would take
a long time  even with a high bandwidth  thus  using summary information  as opposed to not using
it  can reduce communication exponentially when solutions can be found at abstract levels 
at the other extreme  if the agents sent summary information one task at a time  the latency
for sending so many messages can grow large for larger task hierarchies  if solutions could only
be found at primitive levels  then sending summary information one task at a time would cause an
exponential latency overhead compared to sending the entire hierarchy at once  but  if solutions
can be found at intermediate levels  being able to send summary information at some intermediate
granularity can minimize total delay 
however  this argument assumes that summary information collapses at higher levels in the hierarchy  otherwise  sending summary information at some intermediate level could be almost as
expensive as sending the entire hierarchy and cause unnecessary overhead  for the actual manufacturing domain  tasks in the agents hierarchies mostly have constraints on different resources  and
summarization is not able to reduce summary information significantly because constraints do not
collapse  the result is that it is better  in this case  to send the entire hierarchy at once to minimize
delay  unless there are unusual bandwidth and latency constraints  as shown in the experiment  
even so  the coordination agent can still summarize the hierarchies itself to take advantage of the
computational advantages of abstract reasoning 
this section showed how a domain modeler can minimize communication overhead by communicating summary information at the proper level of granularity  if bandwidth  latency  and a
common depth for coordination solutions is known  the domain modeler can perform a hypothetical
experiment like the one above for varying granularities of summary information to determine which
granularity is optimal  if summary information collapses up the hierarchy  and solutions can be
found at intermediate levels  then communication can be exponentially reduced in this manner 

   other related work
the approach we have taken for abstract reasoning was originally inspired by earlier work involving
a hierarchical behavior space search where agents represent their planned behaviors at multiple
levels of abstraction  durfee   montgomery         distributed protocols are used to decide at what
level of abstraction coordination is needed and to resolve conflicts there  this approach capitalizes
on domains where resources can be abstracted naturally  this earlier work can be viewed as a very
limited  special case of the work presented here  it is justified only intuitively and with limited
experiments and analyses 
corkill studied interleaved planning and merging in a distributed version of the noah planner
        he recognized that  while most of the conditions affected by an abstract plan operator
might be unknown until further refinement  those that deal with the overall effects and preconditions
that hold no matter how the operator is refined can be captured and used to identify and resolve
some conflicts  he recognized that further choices of refinement or synchronization choices at
more abstract levels could lead to unresolvable conflicts at deeper levels  and backtracking could be
necessary  our work is directed toward avoiding such backtracking by using summary information
to guide search 

   

fia bstract r easoning for p lanning and c oordination

in closer relation to our approach  pappachan shows how to interleave hierarchical plan coordination with plan execution for cooperative agents using an online iterative constraint relaxation
 oicr  algorithm  pappachan         like our approach  coordination can be achieved at higher
levels of abstraction for more flexible execution  or the agents can decompose their tasks to lower
levels for tighter coordination that can improve plan quality  the oicr approach is tailored toward
interleaving coordination and flexible execution at the price of completeness while the coordination
algorithm presented here is aimed at complete interleaved coordination and planning at the price of
potentially delaying execution due to backtracking 
in planning research  hierarchical plans have often been represented as hierarchical task networks  htns  erol et al       a   which planners such as noah  sacerdoti         nonlin  tate 
       sipe    wilkins         o plan  currie   tate         umcp  erol et al       b   and shop  
 nau  au  ilghami  kuter  murdock  wu    yaman        use to search through combinations of
alternative courses of action to achieve goals within a particular context  these actions may be partially ordered  giving timing flexibility during execution  wilkins        currie   tate         our
ch i p representation extends htn s to include temporal extent and partial orderings can be expressed
as constraints on the starting and ending timepoints of the action 
yang presented a method  similar to our summarization  for preprocessing a plan hierarchy in
order to be able to detect unresolvable conflicts at an abstract level so that the planner could backtrack from inconsistent search spaces  yang         this corresponds to the use of mightsomeway
in section      however  his approach requires that the decomposition hierarchy be modeled so that
each abstract operator have a unique main subaction that has the same preconditions and effects as
the parent  we avoid this restriction by analyzing the subplans conditions and ordering constraints
to automatically compute the parents summary conditions 
while our approach has focused on resolving conflicts among agents  cox and durfee       
have used summary information to exploit synergistic interactions  the idea is that using summary information to identify overlapping effects can help agents skip actions whose effects are
achieved by others  thangarajah  padgham  and winikoff        have used summary information
in rescheduling during execution  their representations are actually subsumed by ours  and their
work significantly postdates our first reporting of work in this paper  clement   durfee        
dsipe  desjardins   wolverton        is a distributed version of the sipe     wilkins       
hierarchical planning system  in the same way agents can use summary information to reduce
communication to just those states for which they have common constraints  dsipe filters conditions
communicated among planners using irrelevance reasoning  wolverton   desjardins        
the dpocl  decompositional partial order causal link  planner  young et al         adds
action decomposition to snlp  mcallester   rosenblitt         like other htn planners  preconditions and high level effects can be added to abstract tasks in order to help the planner resolve
conflicts during decomposition  in addition  causal links can be specified in decomposition schemas
to isolate external preconditions that dpocl must satisfy  however  because these conditions and
causal links do not necessarily capture all of the external conditions of abstract tasks  the planner
does not find solutions at abstract levels and requires that all tasks be completely decomposed  in addition  dpocl cannot determine that an abstract plan has unresolvable conflicts  mightsomeway 
because there may be effects hidden in the decompositions of yet undetailed tasks that could achieve
open preconditions  by deriving summary conditions automatically and using algorithms for determining causal link information  e g  must achieve   our planning coordination algorithm can find

   

fic lement  d urfee     barrett

and reject abstract plans during search without adding burden to the domain expert to specify redundant conditions or causal links for abstract tasks 
like dpocl  tms  a framework for task analysis  environment modeling  and simulation 
allows the domain modeler to specify a wide range of task relationships  decker         this
work offers quantitative methods for analyzing and simulating agents as well as their interactions 
while only some of these interactions can be represented and discovered using summary conditions 
we discover this information through analysis rather than depending on the model developer to
predefine the interactions 
groszs shared plans model of collaboration        presents a theory for modeling multiagent
belief and intention  while the shared plans work is directed toward cooperative agents  it represents
action hierarchies and provides mental models at a higher level than represented in this article 
however  our use and analysis of summary information complements groszs work by providing a
way to automatically represent and efficiently reason about the intentions of agents at multiple levels
of abstraction  future work is needed to understand how summary information can be bridged with
mental states of agents to exploit the techniques employed in shared plans and other work based on
bdi  belief desire intention  models of agents  rao   georgeff        
an analysis of hierarchical planning  yang        explains that  in the case of interacting subgoals  certain structures of the hierarchy that minimize these interactions can reduce worst case
planning complexity exponentially  however  the complexity analyses in section   explain how using summary information can achieve exponential performance gains in addition to those achieved
by restructuring plan hierarchies according to yangs analysis by limiting the decomposition of task
hierarchies and compressing the information manipulated by a coordinator  planner  or scheduler 
shop    nau et al         is an htn planner that uses a domain translation technique to reason
about durative action  this however does not express temporal extent in the same way as the planner
given here  our model differs in that it supports ordering relationships on endpoints as well as
conditions and effects during an actions execution  while there may be some domain translation
that could achieve the expression of similar constraints and solutions for other systems  ours is the
only formal model of such expressions in htn planning 
siadex  castillo et al         is another htn planner that handles temporal extent in the use
of more expressive simple temporal networks  dechter  meiri    pearl         the performance
improvement techniques reported for siadex are in temporal reasoning and not specific to htns 
thus  this work is complementary to ours  however  more work is needed to understand how
summary information can be exploited in conjunction with the forward expansion approach that
both shop   and siadex use to perform competitively on planning competition problems 
another class of hierarchical planners based on abstrips  sacerdoti        introduces conditions at different levels of abstraction so that more critical conflicts are handled at higher levels
of abstraction and less important  or easier  conflicts are resolved later at lower levels  while this
approach similarly resolves conflicts at abstract levels  the planning decisions may not be consistent
with conditions at lower levels resulting in backtracking  summary information provides a means
to make sound and complete decisions at abstract levels without the need to decompose and check
consistency with lower levels  however  resolving conflicts based on criticality can still improve
performance in complement to our approach 
allens temporal planner        uses hierarchical representations of tasks and could be applied
to reasoning about the concurrent actions of multiple agents  however  it does not exploit hierarchy
by reasoning about abstraction levels separately and generates a plan by proving the consistency of
   

fia bstract r easoning for p lanning and c oordination

the collective constraints  allens model of temporal plans        and subsequent work on interval
point algebra  vilain   kautz        strongly influenced our hierarchical task representation and
algorithms that reason about them 
there are also many  many models and theories of concurrency  some older examples include
automata representations  petri nets and hoares theory of communicating sequential processes
 glabbeek         there are also many temporal logics such as computational tree logic  ctl 
emerson   halpern        that allow modal expressions about a proposition holding in some or all
possible worlds some of the time  all of the time  in the next state  eventually  or until some other
proposition holds  another language for specifying manufacturing processes has been in the process
of being standardized over    years  bock        schlenoff  knutilla    ray         many of these
logics could have been used to define summary conditions and relations like mightsomeway  however  we found that these logics were awkward for representing inconditions and defining summary
conditions and that the terminology used in this article simplifies the definitions 
model checking uses temporal logics to verify different properties of system models  software 
and hardware  such as correctness  deadlock free  and convergence   in fact  model checking
and planning algorithms can be used interchangeably on the same problems  e g   giunchiglia  
traverso         in the context of model checking  summary information is a set of properties
 akin to those specifiable in ctl  of a system model  as a planning domain  that summarize system
variable requirements  conditions  and assignments  effects   thus  a model checking algorithm
could use this summary information to efficiently identify and resolve potential requirement violations bugs  condition conflicts  or deadlock  resource conflicts  in a system model or its operation
 planning scheduling problem instantiations  

   conclusion
this article provides a formalization of hierarchical task network planning that  unlike the umcp
formalism  erol et al       b   includes actions with temporal extent  we introduce a sound and
complete algorithm that can be used to generate a plan  coordinate a group of agents with hierarchical plans  and interleave planning and coordination 
the algorithms for summarizing propositional state and metric resource conditions and effects
at abstract levels and the mechanisms that reason about this summary information can facilitate the
construction of other planning and coordination systems that reason about plans at multiple levels
of abstraction  these mechanisms for reasoning about summary information determine whether a
task  at any level of abstraction  must or may achieve  clobber  or undo a condition of another task
under partial order constraints on endpoints of tasks  built on these mechanisms  other mechanisms
determine whether a group of agents can decompose and execute a set of partially ordered abstract
tasks in any way  cananyway   might decompose and execute them in some way  mightsomeway  
or cannot execute them consistently in any way  mightsomeway  
these algorithms enable a planning system to find solutions at multiple levels of abstraction
without needing to fully detail the task hierarchy  these abstract solutions support flexible execution
by remaining uncommitted about which of the alternative methods will be selected at runtime  based
on the circumstances  to achieve plan subgoals 
our complexity analyses and experiments in different problem domains have quantified the benefits of using summary information for a refinement planning and local search scheduling algorithm 
d
i
there is a potential doubly exponential speedup of o kb b b  di    for k ways to resolve a conflict 

   

fic lement  d urfee     barrett

a hierarchy branching factor b  a depth of the hierarchy d  and an abstract solution depth i  an exponential speedup is obtained if abstract solutions are found  if there are fewer summary conditions
at abstract levels  or if alternative decomposition choices lead to varying numbers of threats  these
conditions for exponential improvement are a significant relaxation compared to prior work  and the
performance improvement is greater 
a domain modeler can run the summarization algorithms offline for a library of plan hierarchies
so that summary information is available for the coordination and planning of any set of goal tasks
supported by the library  using algorithms for reasoning about summary information  agents can
discover with whom they should coordinate and over which states and resources they must coordinate negotiate  communicating summary information at different levels of abstraction reduces
communication costs exponentially under conditions similar to those reducing computation time 
the use of summary information in a local search planner  like aspen  section      is another
contribution of this work  the strength of local search algorithms is their ability to efficiently reason
about large numbers of tasks with constraints on metric resources  state variables  and other complex
resource classes  by integrating algorithms for reasoning about summarized propositional state and
metric resource constraints into a heuristic local search planner scheduler  we enable such scalable
planning systems to scale to even larger problem domains  this use of summary information in
a different style of planner demonstrates the applicability of abstract reasoning in improving the
performance of different kinds of planning  and plan coordination  systems 
future work is needed to evaluate the use of summary information in other planning and
scheduling systems and for wider classes of problems requiring more expressive representations
for resources and temporal constraints  already  an approach for exploiting cooperative action
among agents based on summary information has been developed  cox   durfee         other
promising approaches include abstracting other plan information  such as probabilistic conditions
and effects and classes of resources and states  e g  location regions and sub regions   more work
is also needed to understand how and when to communicate summary information in a distributed
planning system 

acknowledgments
the authors wish to thank pradeep pappachan  gregg rabideau  and russell knight for help with
implementation  we also thank our anonymous reviewers for their many valuable suggestions  this
work was performed at the jet propulsion laboratory  california institute of technology  under
contract with the national aeronautics and space administration  and at the university of michigan
supported in part by darpa  f                 

appendix a  algorithms for computing interval relations
the algorithms for determining whether the defined relations hold between summary conditions
for plans in p use a point algebra constraint table  vilain   kautz         this point algebra
table is constructed for the interval endpoints corresponding to the executions of the plans in p 
a row and column for both p  ts  e   start endpoint of execution e of p  and p   t f  e   finish
endpoint  are added for each plan p  p  each cell of the table gives a time point constraint of
the row to the column that can be                       or empty      means that the

   

fia bstract r easoning for p lanning and c oordination

p
p 
p  
p   

p
 
 
 
 

p 
 
 
 
 

p  
 
 
 
 

p   
 
 
 
 

table    point algebra table for p contains p 
p
p 
p  
p   

p
 
 

 

p 
 
 
   
   

p  

   
 
 

p   
 
   
 
 

table    point algebra table for p before or at p  
points are unconstrained  if a cell is empty  then there are no allowed temporal relations  indicating
inconsistency  table   shows a point algebra table for plans p and p  where they are constrained such
that ps execution contains that of p    table   shows a table where just the start of p is constrained
to be earlier than the start of p    both are transitive closures of these constraint relations  table  
can be computed from table   by constraining p    p     by putting   in the cell of row p  and
column p      and then computing the transitive closure  an o n    algorithm for n points  vilain  
kautz         after the transitive closure is computed  the constraints of any point on any other
point can be looked up in constant time 
similarly  the constraints in order for p can be added to the table  and the transitive closure can
be computed to get all constraints entailed from those in order  this only needs to be done once for
any p and order to determine achieve and clobber relationships defined in the next section 
we determine that a plan q in ps subplans is temporally ordered always   f irst last  if and only
if  q   q    is constrained  before  after  or equal to all other points in the point algebra table for
ps subplans  this is done by looking at each entry in the row for  q   q    and checking to see
that the constraint is            or       if this is not the case  then q is not always   f irst last  
q is always not   f irst last  if and only if in the row for  q   q    there is an entry with the       
constraint  otherwise  it is sometimes   f irst last  
an interval i  is covered by a set of intervals i    i    i            ik   if and only no interval can be
found that intersects i  and intersects nothing in i  our particular covering problem describes the
intervals in terms of a partial order over endpoints  so we represent these intervals in a point algebra
table  an algorithm for the covering problem is to check to see if i  is covered by looking at all
pairs of intervals to see if they overlap  i  is not covered if     either no intervals in i meet either
 
i
  or i        there are any intervals that have an endpoint that is contained only by i  and do not
meet the opposite endpoint of another interval in i or an endpoint of i    or     there are no intervals
overlapping i    otherwise  i  is covered  examples are given in figure    

   

fic lement  d urfee     barrett

a 
 

 

b

 
c

c 

e

b 

a

f
 
g

d

h

i

figure     a  interval a is covered by b  c  and d  b  e is not covered by f  g  and h  c  i is not
covered 

appendix b  algorithms for must may asserting summary conditions
here we describe algorithms for determining temporal plan relationships based on summary information  they are used to build other algorithms that determine whether plan must or may achieve 
clobber  or undo the condition of another under particular ordering constraints 
the definitions and algorithms throughout this section are given within the context of a set of
plans p with a corresponding set of summary information psum   a set of ordering constraints order 
and a set of histories h including all histories where e h  only includes an execution e of each
plan in p and es subexecutions  and e h  satisfies all constraints in order  they are all concerned
with the ordering of plan execution intervals and the timing of conditions  by themselves  they do
not have anything to do with whether conditions may need to be met or must be met for a plan
execution 
first  in order to determine whether abstract plan executions can achieve  clobber  or undo
conditions of others  an agent needs to be able to reason about how summary conditions are asserted
and required to be met  ultimately  the agent needs to be able to determine whether a partial ordering
of abstract plans can succeed  so it may be the case that an agents action fails to assert a summary
condition that is required by the action of another agent  therefore  we formalize what it means
for an action to attempt to assert a summary condition and to require that a summary condition be
met  these definitions rely on linking the summary condition of a plan to the chip conditions it
summarizes in the subplans of the plans decompositions  thus  we first define what it means for a
summary condition to summarize these conditions 
definition   
a summary condition c summarizes a condition   in condition set conds
of plan p iff c was added by the procedure for deriving summary information to a
summary condition set of p          c   and either c was added for   in a condition
set conds of p   p    or c was added for a summary condition of a subplan of p  that
summarizes   in conds of p 
for example  at bin   a  is a precondition of the start move plan for moving part a from bin 
to machine m   as given in section       when deriving the summary conditions for start move 

   

fia bstract r easoning for p lanning and c oordination

at bin   a  is added to the summary preconditions  thus  the summary precondition at bin  
a muf summarizes at bin   a  in the preconditions of start move 
definition   
an execution e of p requires a summary condition c to be met at t iff c is
a summary condition in ps summary information  there is a condition   in a condition
set conds of p  that is summarized by c  if f irst c   t   ts  e   if last c   t   t f  e  
if always c   t is within  ts  e  t f  e    and if sometimes c   there is an execution of
a subplan of p in d e  that requires a summary condition c  to be met at t  and c 
summarizes   in conds of p   
so  basically  an execution requires a summary condition to be met whenever the conditions it
summarizes are required  the execution of build g has a summary precondition at a m  tray   
this execution requires this summary condition to be met at ts  build g  because at a  m  tray   is
a precondition of build gs first subplan that is summarized by build gs summary precondition 
definition   
an execution e of p attempts to assert a summary condition c at t iff c is
a summary condition in ps summary information  there is a condition   in a condition
set conds of p  that is summarized by c   f irst c   if always c   t is in the smallest
interval after ts  e  and before the start or end of any other execution that follows ts  e  
if last c   t   t f  e   and if sometimes c   there is an execution of a subplan of p in d e 
that attempts to assert a summary condition c  at t  and c  summarizes   in conds of p   
we say that an execution attempts to assert a summary condition because asserting a condition
can fail due to a simultaneous assertion of the negation of the condition  like the example above
for requiring a summary condition  the executions of build g  produce g on m   and produce h
all assert summary postconditions that m  becomes available at t f  build g  
in order for agents to determine potential interactions among their abstract plans  such as clobbering or achieving   they need to reason about when a summary condition is asserted by one plan in
relation to when it is asserted or required by another  based on interval or point algebra constraints
over a set of abstract plans  an agent specifically would need to be able to determine whether a plan
would assert a summary condition before or by the time another plan requires or asserts a summary
condition on the same state variable  in addition  to reason about clobbering inconditions  an agent
would need to determine if a summary condition would be asserted during the time a summary incondition c was required  asserted in c   agents also need to detect when a summary postcondition
would be asserted at the same time as another summary postcondition c  asserted when c  
we do not consider cases where executions attempt to assert a summary in  or postcondition
at the same time an incondition is asserted because in these cases  clobber relations are already
detected because executions always require the summary inconditions that they attempt to assert 
for example  if equip m  attempted to assert the incondition that m  was unavailable at the same
time that build g attempted to assert the postcondition that m  was available  the incondition would
be clobbered by the postcondition 
in the case that the ordering constraints allow for alternative synchronizations of the abstract
plans  the assertions of summary conditions may come in different orders  therefore  we formalize
must assert and may assert to determine when these relationships must or may occur respectively 
as mentioned at the beginning of section    this use of must and may is based only on disjunctive orderings and not on the existence of summary conditions in different decompositions  for
   

fic lement  d urfee     barrett

 
 
 
 

 
 
 

 
 

  
  

  
  
  
  

  
  
  
  

c   post p   
last
t
t
f
 
c   in p   
always
t
t
f
c   post p   
last
t
f
c   in p   
always
t
f
c   post p   
last
t
t
f
f
c   in p   
always
t
t
f
f

p  must assert c  by c
order must impose
these constraints

p  must assert c  before c
order must impose
these constraints

p     p
p     p
p     p
p     p

p      p
p      p
p      p
p      p

t
f
 
c  in p 
always
 
 

p     p
p    p
f alse

p     p
p    p
f alse

p     p
p     p

p     p
p     p

 
 
c  post p 
last
t
f
t
f

p    p
f alse

p     p
f alse

p     p 
p     p
p     p 
p     p

p      p 
p     p
p     p 
p     p

t
f
t
f

p     p 
p    p
f alse
f alse

p     p 
p    p
f alse
f alse

c  pre p 
f irst
t
f
 
 

table    table for must assert by before algorithm
the following definitions and algorithms of must  and may assert  we assume c and c  are summary
conditions of plans in p 
definition   
p   p must assert c   by  before  c iff for all histories h  h and all t
where e is the top level execution in e h  of some p  p that requires c to be met at t 
and e  is the top level execution of p  in e h   there is a t   where e  attempts to assert c 
at t     and  t    t  t     t  
the must assert algorithm is described in table    p  must assert c  by c iff order entails the
relationship given for the row corresponding to the type and timing of the two conditions  rows of
the table indicate the timing of both summary conditions and the constraints that order must dictate
for must assert to be true  t and f in the table indicate whether the timing in the column is true
or false for the condition    means that timing doesnt matter for that condition in this case  for
example  row   says that for the case where c  is a sometimes  last  postcondition of p    and c is
an incondition of p with any timing  order must require that the end of p  be before or at the start
of p in order for p  to must assert c  by the time c is asserted or required 

   

fia bstract r easoning for p lanning and c oordination

 
 
 
 

 
 

 
 
 
  

  
  

  
  
  
  

  
  

c   post p   
last
t
t
f
f
c   in p   
always
 
 
c   post p   
last
t
t
f
f
c   in p   
always
 
 
c   post p   
last
t
t
f
f
c   in p   
always
 
 

p  may assert c  by c
order cannot impose
these constraints

p  may assert c  before c
order cannot impose
these constraints

p      p
p     p 
p    p
p    p 

p     p
p     p 
p    p
p    p 

t
f
c  in p 
always
t
f
t
f

p    p
p    p 

p    p
p    p 

p      p
p     p 
p    p
p    p 

p      p
p     p 
p    p
p    p 

t
f
c  post p 
last
t
f
t
f

p     p
p    p 

p    p
p    p 

p      p 
p     p 
p    p 
p    p 

p     p 
p     p 
p    p 
p    p 

t
f

p    p 
p    p 

p    p 
p    p 

c  pre p 
f irst
t
f
t
f

table    table for may assert by before algorithm

 
 
 
 

 
 
 
 

c   post p   
last
t
t
f
f
c   in p   
always
t
t
f
f

p  must assert c  in c
order must impose
these constraints

c  in p 
always
t
f
t
f

p      p and p      p 
f alse
p    p and p     p 
f alse

t
f
t
f

p    p and p     p 
f alse
f alse
f alse

c   post p   
last
t
t
f
f
c   in p   
always
t
t
f
f

c  in p 
always
t
f
t
f

p     p
p     p
p     p
p     p

or
or
or
or

p     p 
p     p 
p    p 
p    p 

t
f
t
f

p     p
p     p
p     p
p     p

or
or
or
or

p    p 
p    p 
p    p 
p    p 

table    table for must may assert in algorithm

   

p  may assert c  in c
order cannot impose
these constraints

fic lement  d urfee     barrett

 
 
 
 

c   post p   
last
t
t
f
f

c  post p 
last
t
f
t
f

p  must assert c  when c
order must impose
these constraints
p      p 
f alse
f alse
f alse

c   post p   
last
t
t
f
f

c  post p 
last
t
f
t
f

p  may assert c  when c
order cannot impose
these constraints
p       p 
 p or p     p 
p     p  or p    p 
p     p or p    p 
p   

table    table for must may assert when algorithm
the definitions and algorithms for the other assert relationships are similar  tables     describe
the logic for the other algorithms  for may relationships  the algorithm returns true iff none of the
corresponding ordering constraints in the table are imposed by  can be deduced from  order 
we illustrate these relationships for the example in figure    in figure  a the agents plans
are unordered with respect to each other  part g is produced either on machine m  or m  depending on potential decompositions of the produce g plan  produce g must assert c    must 
last available g  before c   must  f irst available g  in the summary preconditions of move g
because no matter how the plans are decomposed  for all executions and all histories of the plans
under the ordering constraints in the figure   the execution of produce g attempts to assert c  before the execution of move g requires c to be met  the algorithm verifies this by finding that the
end of produce g is ordered before the start of move g  row   in table     it is also the case that
equip m  tool may assert c    must  last available m   by c   may  sometimes available m  
in the summary preconditions of produce g because the two plans are unordered with respect to
each other  and in some history equip m  tool can precede produce g  the algorithm finds that
this is true since equip m  is not constrained to start after the start of produce g  row   in table    
in figure  b  move tool may assert c    must  last f ree transport   in c   may  sometimes
 f ree transport   in produce gs summary inconditions because in some history move tool attempts to assert c  during the time that produce g is using transport  to move part a to machine
m   in addition  equip m  tool must assert c    must  last available m   when c   may  last
available m   in produce gs summary postconditions because equip m  tool attempts to assert
c  at the same time that produce g requires c to be met  the end of section     gives other examples 

references
allen  j   kautz  h   pelavin  r     tenenberg  j          reasoning about plans  morgan kaufmann 
allen  j  f          maintaining knowledge about temporal intervals  communications of the acm 
               
allen  j  f     koomen  j  a          planning using a temporal world model  in proceedings of
the international joint conference on artificial intelligence  pp         
bock  c          unified process specification language  requirements for modeling process  tech 
rep  nistir       national institute of standards and technology 
castillo  l   fdez olivares  j   garca perez  o     palao  f          efficiently handling temporal
knowledge in an htn planner  in   th international conference on automated planning and
   

fia bstract r easoning for p lanning and c oordination

scheduling  icaps      pp        aaai 
chien  s   knight  r   stechert  a   sherwood  r     rabideau  g       a   using iterative repair to
improve the responsiveness of planning and scheduling  in proceedings of the international
conference on ai planning and scheduling  pp         
chien  s   rabideu  g   knight  r   sherwood  r   engelhardt  b   mutz  d   estlin  t   smith  b  
fisher  f   barrett  t   stebbins  g     tran  d       b   automating space mission operations
using automated planning and scheduling  in proc  spaceops 
clement  b          abstract reasoning for multiagent coordination and planning  ph d  thesis 
university of michigan  ann arbor 
clement  b     durfee  e          top down search for coordinating the hierarchical plans of
multiple agents  in proceedings of the international conference on autonomous agents 
corkill  d          hierarchical planning in a distributed environment  in proceedings of the
international joint conference on artificial intelligence  pp         
cox  j  s     durfee  e  h          discovering and exploiting synergy between hierarchical planning agents  in proceedings of the international joint conference on autonomous agents and
multiagent systems  pp         
currie  k     tate  a          o plan  the open planning architecture  artificial intelligence     
     
dechter  r   meiri  i     pearl  j          temporal constraint networks  artificial intelligence     
     
decker  k          environment centered analysis and design of coordination mechanisms  ph d 
thesis  university of massachusetts 
desjardins  m     wolverton  m          coordinating a distributed planning system  ai magazine 
            
drabble  b     tate  a          the use of optimistic and pessimistic resource profiles to inform
search in an activity based planner  in artificial intelligence planning systems  pp         
durfee  e  h     montgomery  t  a          coordination as distributed search in a hierarchical
behavior space  ieee transactions of systems  man and cybernetics                  
emerson  e     halpern  j  y          decision procedures and expressiveness in the temporal logic
of branching time  journal of computer and system sciences             
ephrati  e     rosenschein  j          divide and conquer in multi agent planning  in proceedings
of the national conference on artificial intelligence  pp         
erol  k   hendler  j     nau  d       a   semantics for hierarchical task network planning  tech 
rep  cs tr       university of maryland 
erol  k   nau  d     hendler  j       b   umcp  a sound and complete planning procedure for
hierarchical task network planning   in proceedings of the international conference on ai
planning and scheduling 
fagin  r   halpern  j   moses  y     vardi  m          reasoning about knowledge  mit press 
firby  j          adaptive execution in complex dynamic domains  ph d  thesis  yale university 
   

fic lement  d urfee     barrett

georgeff  m  p          communication and interaction in multiagent planning  in proceedings of
the national conference on artificial intelligence  pp         
georgeff  m  p          a theory of action for multiagent planning  in proceedings of the national
conference on artificial intelligence  pp         
georgeff  m  p     lansky  a          procedural knowledge  proceedings of ieee              
     
giunchiglia  f     traverso  p          planning as model checking  in proceedings of the  th
european conference on planning  pp       london  uk  springer verlag 
glabbeek  r  v          notes on the methodology of ccs and csp  theoretical computer science 
                originally appeared as report cs r      cwi  amsterdam       
grosz  b     kraus  s          collaborative plans for complex group action  artificial intelligence 
           
huber  m          jam  a bdi theoretic mobile agent architecture  in proceedings of the international conference on autonomous agents  pp         
knight  r   rabideau  g     chien  s          computing valid intervals for collections of activities with shared states and resources  in proceedings of the international conference on ai
planning and scheduling  pp         
knoblock  c          search reduction in hierarchical problem solving  in proceedings of the
national conference on artificial intelligence  pp         
korf  r          planning as search  a quantitative approach  artificial intelligence           
laborie  p     ghallab  m          planning with sharable resource constraints  in proceedings of
the international joint conference on artificial intelligence  pp           
lansky  a          localized search for controlling automated reasoning  in proceedings of the
darpa workshop on innovative approaches to planning  scheduling and control  pp     
    
lee  j   huber  m  j   durfee  e  h     kenny  p  g          umprs  an implementation of the
procedural reasoning system for multirobot applications  in proceedings of the aiaa nasa
conference on intelligent robotics in field  factory  service  and space  pp         
mcallester  d     rosenblitt  d          systematic nonlinear planning  in proceedings of the
national conference on artificial intelligence  pp         
muscettola  n          hsts  integrating planning scheduling  intelligent scheduling         
nau  d   au  t   ilghami  o   kuter  u   murdock  j   wu  d     yaman  f          shop   an
htn planning system  journal of artificial intelligence research             
pappachan  p          coordinating plan execution in dynamic multiagent environments  ph d 
thesis  university of michigan  ann arbor 
pratt  v  r          semantical considerations on floyd hoare logic  in   th annual ieee symposium on foundations of computer science  pp         
rao  a  s     georgeff  m  p          bdi agents  from theory to practice  in proceedings of the
international conference on multi agent systems  san francisco 
   

fia bstract r easoning for p lanning and c oordination

sacerdoti  e          planning in a hierarchy of abstraction spaces  artificial intelligence       
       
sacerdoti  e  d          a structure for plans and behavior  elsevier north holland 
schlenoff  c   knutilla  a     ray  s          interprocess communication in the process specification language  tech  rep  nistir       national institute of standards and technology 
tate  a          generating project networks  in proceedings of the international joint conference
on artificial intelligence  pp         
thangarajah  j   padgham  l     winikoff  m          detecting   avoiding interference between
goals in intelligent agents  in proceedings of the international joint conference on artificial
intelligence  pp         
tsuneto  r   hendler  j     nau  d          space size minimization in refinement planning  in
proceedings of the european conference on planning 
tsuneto  r   hendler  j     nau  d          analyzing external conditions to improve the efficiency
of htn planning  in proceedings of the national conference on artificial intelligence  pp 
       
vilain    kautz  h          constraint propagation algorithms for temporal reasoning  in proceedings of the national conference on artificial intelligence  pp         
weld  d          an introduction to least commitment planning  ai magazine              
wilkins  d  e          can ai planners solve practical problems   computational intelligence 
             
wolverton  m     desjardins  m          controlling communication in distributed planning using
irrelevance reasoning  in proceedings of the national conference on artificial intelligence 
pp         
yang  q          formalizing planning knowledge for hierarchical planning  computational intelligence             
yang  q   ed            intelligent planning  a decomposition and abstraction based approach 
springer 
young  m   pollack  m     moore  j          decomposition and causality in partial order planning 
in proceedings of the international conference on ai planning and scheduling  pp         

   

fi