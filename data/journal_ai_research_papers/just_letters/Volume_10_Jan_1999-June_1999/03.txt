journal of artificial intelligence research                  

submitted       published     

ecient heuristic hypothesis ranking
steve chien jpl nasa gov
andre stechert jpl nasa gov
darren mutz jpl nasa gov

steve chien
andre stechert
darren mutz
jet propulsion laboratory
california institute of technology
     oak grove drive  m s        
pasadena  ca           

abstract

this paper considers the problem of learning the ranking of a set of stochastic alternatives based upon incomplete information  i e   a limited number of samples   we describe
a system that  at each decision cycle  outputs either a complete ordering on the hypotheses
or decides to gather additional information  i e   observations  at some cost  the ranking
problem is a generalization of the previously studied hypothesis selection problem in selection  an algorithm must select the single best hypothesis  while in ranking  an algorithm
must order all the hypotheses 
the central problem we address is achieving the desired ranking quality while minimizing the cost of acquiring additional samples  we describe two algorithms for hypothesis
ranking and their application for the probably approximately correct  pac  and expected
loss  el  learning criteria  empirical results are provided to demonstrate the effectiveness
of these ranking procedures on both synthetic and real world datasets 
   introduction

in many applications  the cost of information can be quite high  imposing a requirement
that learning algorithms glean as much usable information as possible with a minimum of
data  for example 



data may be scarce  making learning the most possible from limited training data
key 



in speedup learning  minimizing processing time is critical  here  reducing the number
of necessary training examples is key since the expense of processing each example
can be significant  tadepalli        



in decision tree learning  the cost of using all available training examples when evaluating potential attributes for partitioning can be computationally expensive  musick 
catlett    russell        



in evaluating medical treatment policies  acquiring additional training examples might
imply that human subjects are exposed to an experimental treatment for a longer
period than is necessary 

when one wishes some sort of guarantee on the quality of a solution  a statistical decision
theoretic framework is useful  the framework answers the questions  how much information

c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fichien  stechert    mutz
is enough  at what point do we have adequate information to rank the alternatives with
some requested confidence 
this paper focuses on parametric ranking problems  a general class of statistical machine learning problems in which the goal is to rank a set of alternative hypotheses where
the goodness of a hypothesis is a function of a set of parameters whose values are unknown
 e g   chien  stechert    mutz        gratch        greiner   jurisica        kaelbling 
      moore   lee        musick et al          the learning system determines and refines estimates of these parameters by using training examples  with a secondary goal of
minimizing learning cost 
the principal contributions of this paper are 



we define two families of hypothesis ranking algorithms  based on recursive selection
and adjacency  respectively  we provide specific details on how to apply them using
the probably approximately correct  pac  and expected loss  el  decision criteria 



we provide empirical results demonstrating the effectiveness of these algorithms at
achieving the requested decision criteria on synthetic data 



we provide empirical results showing that these algorithms significantly outperform
existing statistical methods on real world data from spacecraft design optimization
and image compression applications 

the remainder of this paper is structured as follows  first  we describe the hypothesis ranking problem more formally  including definitions for the probably approximately
correct  pac  and expected loss  el  decision criteria  we then define two algorithms for
establishing these criteria for the hypothesis ranking problem a recursive hypothesis selection algorithm and an adjacent comparison algorithm  next  we describe empirical tests
demonstrating the effectiveness of these algorithms as well as documenting their improved
performance over a standard algorithm from the statistical ranking literature  finally  we
describe related work and future extensions to the algorithms 
   hypothesis ranking problems

hypothesis ranking problems are an abstract class of learning problems where an algorithm
is given a set of hypotheses to rank  the ranking desired is that which orders the hypotheses
by their expected utility  which is determined by the hypothesis  underlying probability
distribution  these expected utilities are unknown to the algorithm and must be estimated
from the training data 
hypothesis ranking problems are an extension of hypothesis selection problems  chien 
gratch    burl         in which a learning system attempts to select the best alternative
from a set of hypotheses  the distinction between hypothesis ranking and hypothesis selection is that in selection the learning algorithm is interested in a single best hypothesis  while
in ranking the learning algorithm must determine the relative order of all of the hypotheses   
hypothesis selection and ranking is an important aspect of many machine learning
problems  for example  the utility problem in speedup learning can be viewed as a selection
   the algorithms and results described in this paper extend in a straightforward fashion to hybrid rankingselection problems in which the system must select and rank the top m out of n hypotheses 

   

fiefficient heuristic hypothesis ranking
problem where a single problem solving heuristic or strategy is chosen from a larger set of
candidates  in this case  the expected utility is typically defined as the average time to solve
a problem  gratch        greiner   jurisica        minton         the attribute selection
problem in machine learning can also be viewed as a hypothesis selection problem in which
one must select the best attribute split from a set of possible attribute splits and utility
is often measured by information gain  musick et al          in reinforcement learning  a
system must learn the appropriate action for each context  where utility is interpreted as
expected reward  kaelbling         
a key observation regarding each of these problems  and all learning problems  in general  is that each of them could be viewed as an optimization problem  where the utility
is the function being optimized  then  the application of traditional  or non traditional 
optimization methods will yield good results within the guarantees provided by the algorithm and depending on the features of the landscape being optimized  however  with the
addition of a model of sampling cost  a new degree of freedom is added to the problem 
where the cost of samples is very high  traditional optimization algorithms will fare poorly 
additionally  while in many of the mentioned applications the system chooses a single
alternative and never revisits the decision  there are also many cases for which a system
will want to investigate several prioritized options  either serially or in parallel   and hence
a ranking is useful  motivation is provided by the following scenarios 



upper and lower bounds  span  minimax search algorithms can use metaknowledge

 such as upper and lower bounds of a node  for pruning other parts of the tree  also 
there are times when knowing the span of the expected utilities of the candidate set is
useful  e g   when checking for convergence conditions in an adaptive algorithm such
as a ga  



augmenting external knowledge  another area in which hypothesis ranking may have



the entire ranking  in some cases  the entire ranking is significant  for instance 

important applications is hypothesis selection with human supervision  when the
stochastic objective function  i e   the hypothesis  represents only a part of the problem  the ranking can be used to augment external knowledge of the problem  for
example  engineering simulations usually capture the physical properties of the candidate designs  but usually choose to forego the details of manufacturing  logistics  and
economics 
in evolutionary algorithms  the individuals to be propagated to future generations
are often selected with likelihood that is proportionate to their rank in the current
generation  goldberg         another example arises in the case of search algorithms
that take advantage of node ordering heuristics  such as beam search or iterative
broadening  ginsberg   harvey        

in any hypothesis evaluation problem  always achieving a correct ranking is impossible
in practice  because the exact underlying probability distributions are unknown  thus 
there is always a  perhaps vanishingly  small chance that the algorithms will be unlucky
   note that the analogous reinforcement learning problem is the one in which we are learning the appropriate action with immediate feedback rather than delayed feedback 

   

fichien  stechert    mutz
because only a finite number of samples can be taken  consequently  rather than always
requiring an algorithm to output a correct ranking  we impose probabilistic criteria on the
rankings to be produced  while several families of such requirements exist  in this paper
we examine two criteria  the probably approximately correct  pac  model for selecting
a hypothesis function that approximates well a target function  valiant        and the
expected loss  el  requirement frequently used in decision theory and gaming problems
 russell   wefald         informally  to satisfy the pac requirement  an algorithm must
produce a result that with high probability is close to correct  e g   incorrect orderings will
be most likely to occur between hypotheses with similar expected utilities   the satisfy the
el requirement  on the other hand  a bound must be established on the expected loss of
the result  where loss is the difference in utilities between two incorrectly ordered hypothese
in an incorrect ranking 
the expected utility of a hypothesis can be estimated by observing its values over a
finite set of training examples  however  to satisfy the decision criteria  an algorithm must
also be able to reason about the potential difference between the estimated and true utilities
of each hypotheses  let ui denote the true expected utility of hypothesis i and let u i be
the estimated expected utility of hypothesis i  without loss of generality  let us presume
that the proposed ranking of hypotheses is u    u            uk     uk  
the pac requirement states that  for some user specified   with probability    
k  

  ui       max  ui          uk   

   

i  

in the context of the pac criterion  the number  is called the indifference interval and

 is the overall ranking error or total error rate   

the issue of how to allocate the overall ranking error among the many possible pairwise
comparisons of hypotheses is discussed in the next section 
correspondingly  when selecting a hypothesis h  to be the best from a set of k hypotheses h         hk   let the selection loss l be as follows 
l h    fh         hk g    max     max  u         uk  

u   

   

then  the ranking loss rl of a ranking h         hk would be 
rl h         hk    

k  
x

l hi   fhi          hk g 

   

i  

   the distinction betwen the true means and the estimated means  for which we use the sample means 
is a confusing one  when assessing the validity of a ranking produced by an algorithm  one would use
the true means of the distributions  if available  as in test distributions  or the most accurate estimation
possible  such as from an edxtremely large sampling of the distribution   however  a ranking algorithm
uses the estimated parameters  including sample mean  to estimate the error  for estimation of a single
mean the estimate of the mean is normally distributed around the true mean so that this usage is
justified  however  we have not proven  and indeed are unsure  whether using the estimate in more
complex ranking and selection contexts is guaranteed correct  see later section on the heuristic nture of
our algorithms  

   

fiefficient heuristic hypothesis ranking
a hypothesis ranking algorithm which obeys the expected loss requirement must produce
rankings that on average have less ranking loss than the requested expected loss bound  the
policy for loss allocation is also discussed in the next section 
as an example  consider ranking the hypotheses with expected utilities  u         u   
      u          the ranking u    u    u  is a valid pac ranking for the indifference
interval         but not for         and the observed ranking loss is                 
however  while the confidence in a pairwise comparison between two hypotheses is well
understood to be the complement of the probability of the comparison s result being in
error  it is less clear how to define and ensure that a desired confidence is met in the set of
comparisons required for a selection or the even more complex set of comparisons required
for a ranking  equation   defines the confidence that ui      uj   when the utilities are
normally distributed with unknown and unequal variances 

pn 



     u i

j    
 

si

   

j

where  represents the cumulative standard normal distribution function  and n  u i j  
and s i j are the size  sample mean  and sample standard deviation of the blocked differential
distribution   respectively 
likewise  computation of the expected loss for asserting an ordering between a pair of
hypotheses is well understood  but the estimation of expected loss for an entire ranking is
less clear  equation   defines the expected loss for drawing the conclusion ui   uj   again
under the assumption of normality  see chien et al         for further details  
el ui   uj    

s i

je

u i j  
 
j

   n   
si

p

 n

 

u i

p

j

 

z

 

u i j pn
s i j

e

   z  

dz

   

in the next two subsections  we describe two interpretations for estimating the likelihood
that an overall ranking satisfies the pac or el requirements by estimating and combining
pairwise pac errors or el estimates  each of these interpretations lends itself directly to
an algorithmic implementation as described below 
    ranking as recursive selection

one obvious way to determine a ranking h         hk is to view ranking as recursive selection
from the set of remaining candidate hypotheses  in this view  the overall ranking error 
as specified by the desired confidence in pac algorithms and the loss threshold in el
algorithms  is first distributed among k   selection errors which are then further subdivided
into pairwise comparison errors  figure     data is then sampled until the estimates of the
pairwise comparison error  as dictated by equation   or    satisfy the bounds set by the
algorithm 
   note that in our approach we block  or match  examples to further reduce sampling complexity  blocking
makes estimates by using the difference in utility between competing hypotheses on each observed example  blocking can significantly reduce the variance in the data when the hypotheses are not independent 
the differential distribution is formed by taking the differences of the blocked individual samples to form
a new distribution  it is trivial to modify the formulas to address the cases in which it is not possible to
block data  see moore   lee        chien et al         for further details  

   

fichien  stechert    mutz

h 

h 

h 

h 

h 

h 

h 

h 

h 

h 

h 

h 

h 

h 


 

figure    computing the overall error of a recursive ranking  the per comparison errors
are summed at each level in the recursion  and the overall sum  across all levels 
is compared with the specified total error     

thus  another degree of freedom in the design of recursive ranking algorithms is the
method by which the overall ranking error is ultimately distributed among individual pairwise comparisons between hypotheses  two factors inuence the way in which we compute
error distribution  first  our model of error combination determines how the error allocated
for individual comparisons or selections combines into overall ranking error and therefore
how many candidates are available for the distribution of error 
using bonferroni s inequality  which asserts that the probability of a union of events is
no greater than the sum of the probabilities of the individual events    one would be inclined
to combine the errors additively  however  following a more conservative approach  one
can assert that because the predicted  best  hypothesis may change during sampling in the
worst case  the conclusion might dependon all possible pairwise comparisons and that the
error should be distributed among all n  pairs of hypotheses  
second  our policy with respect to allocation of error among the candidate comparisons
or selections determines how samples will be distributed  for example  in some contexts  the
consequences of early selections far outweigh those of later selections  for these scenarios 
we have implemented ranking algorithms that divide overall ranking error unequally in
   note that this is only the simplest of the bonferonni inequalities  which fall into clean correspondence
with the terms of the expansion of the probability of a union of events according to the principle of
inclusion and exclusion in a natural way 
   for a discussion of this issue  see pp        of  gratch        

   

fiefficient heuristic hypothesis ranking
favor of earlier selections   also  it is possible to divide selection error into pairwise error
unequally based on estimates of hypothesis parameters in order to reduce sampling cost
 for example  gratch  chien    dejong        allocates error rationally  
within the scope of this paper  we only consider algorithms that   i  combine pairwise
error into selection error additively   ii  combine selection error into overall ranking error
additively  and  iii  allocate error equally at each level 
one disadvantage of recursive selection is that once a hypothesis has been selected  it is
removed from the pool of candidate hypotheses  this is an issue in rare cases when  while
sampling to increase the confidence of some later selection  the estimate for a hypothesis 
mean changes enough that some previously selected hypothesis no longer dominates it 
however  it remains that the original hypotheses were shown to dominate the others with
a specified level of certainty     
these assumptions result in the following formulations  where  u   fu         uk g  is
used to denote the error due to the action of selecting hypothesis   under equation  
from the set fh         hk g and  u   fu         uk g  denotes the error due to selection loss in
situations where equation   applies  
rec  u    u          uk    

rec  u    u          uk  
   u   fu         uk g 

   

where rec  uk        the base case for the recursion  and the selection error is as defined
in  chien et al         
  u   fu         uk g   

k
x

  i

   

i  

using equation   to compute pairwise confidence 

algorithmically  we implement this with the following pseudo code 

ensure there are n  samples per hypothesis
distribute the error to individual selections
while  stopping criteria has not been met 
take more samples
if  means are ordered differently than ranking 
restart the algorithm
an analogous recursive selection algorithm based on expected loss is defined as follows
elrec  u    u          uk    

elrec  u    u          uk  
 el u   fu         uk g 

   

where elrec uk       and the selection el is as defined in  chien et al         
el u   fu         uk g   

k
x
i  

   space constraints preclude their description here 

   

el u    ui  

   

fichien  stechert    mutz

 



   

h 

   

h 

k   k

h 

hk  



hk

figure    computing the overall error in an adjacent ranking  per comparison errors between neighboring hypotheses in the proposed ranking are summed and compared
with the required total error     

    ranking by adjacency comparison

another interpretation of ranking confidence  or loss  is that only adjacent elements in the
ranking need be compared  in this case  the overall ranking error is divided directly into
k   pairwise comparison errors  figure     this leads to the following confidence equation
for the pac criteria 
adj  u    u          uk    

k  
x

i i  

    

i  

and the following equation for the el criteria 
eladj  u    u          uk    

k  
x

el ui   ui    

    

i  

because ranking by comparison of adjacent hypotheses does not establish dominance
or loss bounds between non adjacent hypotheses  where the hypotheses are ordered by
observed mean utility   it has the advantage of requiring fewer comparisons than recursive
selection  and thus may require fewer samples than recursive selection   however  for the
same reason  adjacency algorithms may be less likely than the recursive selection algorithms
to bound the probability of a correct ranking  or average loss  correctly  in the case of the
pac algorithms  this is because  dominance is not necessarily transitive  in the case of the
el algorithms  it is because expected loss is not necessarily additive when considering two
hypothesis comparisons sharing a common hypothesis  
   an example where ranking loss between non adjacent hypotheses exceeds the desired loss bound for
the ranking  even though the sum of the adjacent losses does not  occurs when the blocked differential
distribution induced by two non adjacent hypotheses has high variance relative to an hypothesis adjacent

   

fiefficient heuristic hypothesis ranking
    the heuristic nature of the algorithms

both the recusrsive selection and adjacency algorithms are heuristic in the sense that they
are not proven to statistically meet the specified decision criteria  i e   for the pac criteria
select a ranking that satisfies equation     with probability    and similarly for the el
criteria average a ranking loss specified by equation     less than the requested bound 
indeed  several aspects of these algorithms make it extremely dicult to prove that they
would  probabilistically  achieve the corresponding decision criteria  these aspects include 



sharing of samples  in order to have n  samples for a differential distribution  i e 



heuristic error combination  both the recursive selection and adjacency error com 



ignorance of lead switches and multiple comparison paths  during the sampling pro 



blocking  for h  and h    it takes n  samples of h  and n  samples on the the same
problems for h    our algorithms further reduce the sampling cost by reusing these
samples in differential distributions comparing h  to other hypotheses and h  to
other hypotheses  this makes the errors derived from these samples not independent 
hence we have traded accuracy and ease of analysis of the algorithms for heuristic
eciency  particularly in the recursive selection approach  samples for the lowest
ranking hypothesis would have been used in k   differential comparisons 
bination models are heuristic means of combining pairwise errors  this is because
the pairwise errors are not independent  see above   empirically we have observed
that the pairwise errors tend to be overestimated but the error combination function
tends to under combine  overall empirically the combined error estimates tend to be
reasonably accurate  as the remaining sections show 
cess  the ordering of the hypotheses may change  e g   the ordering of sample means
may change   this means that implicitly  the decision depended on an additional
pairwise comparison that may not be reected in the final set of comparisons contributing a pairwise error  this complexity could be avoided by fixing the order of the
hypotheses after n  samples  however  this would require more samples as is would
involve showing  dominance of a hypothesis over a higher sample mean hypothesis
 indeed  it may never converge   we choose to ignore this complexity and base the
combined error used in the stopping condition on the final ordering 

use on non normal distributions  in many of the applications described in the re 

mainder of this article  the real world data is distributed in a manner not very simlar
to normal distributions  we further investigate this issue later in the article   the
algorithms we describe are heuristic in that they presume that the data is normally
distributed even though this is not the case 

to both  i e   currently ranked between them   the variance of the differential distribution makes its
maximum contribution when the sample set is small  so  e g   with                   n        
                  and n         there exists a configuration for which                   the
expected losses are el h    h            el h    h            but el h    h                  

   

fichien  stechert    mutz
    other relevant approaches

most standard statistical ranking selection approaches make strong assumptions about the
form of the problem  e g   the variances associated with underlying utility distribution of
the hypotheses might be assumed known and equal   among these  the method of turnbull
and weiss  turnbull   weiss        is most comparable to our pac based approach  
turnbull and weiss  algorithm is a sequential interval based procedure for selecting
the member of a population with the largest mean  they treat hypotheses as normally
distributed random variables of unknown mean that have unknown and possibly unequal
variance  their algorithm also carries the additional stipulation that the hypotheses be
independent  the procedure consists of taking an initial sample of n  observations on each
of the hypotheses and then taking samples sequentially according to their stopping criteria 
when the stopping criteria has been satisfied  the hypothesis with the highest sample mean
 
is chosen  the stopping criteria is that the inequality snii  n  is satisfied  where si and
ni are the sample mean and the number of samples of the ith hypothesis and n is chosen
 
according to the indifference
interval  and the confidence level     in particular  n   d 
r 
and d is chosen to satisfy    f  y   d  k  f  y dy     where f  y  and f  y  are the cumulative
distribution function and probability density function of the standard normal distribution 
while it is still reasonable to use this approach when the candidate hypotheses are not
independent  excessive statistical error or unnecessarily large training set sizes may result  in
the case that the hypotheses are truly independent  turnbull and weiss  technique should
be able to exploit this knowledge and outperform our methods which do not adopt this
assumption 
   empirical performance evaluation

we now turn to empirical evaluation of the hypothesis ranking techniques on both synthetic
and real world datasets  this evaluation serves three purposes  first  it demonstrates that
the techniques perform as predicted  in terms of bounding the probability of incorrect selection or expected loss   second  it validates the performance of the techniques as compared
to standard algorithms from the statistical literature  third  the evaluation demonstrates
the robustness of the new approaches to real world hypothesis ranking problems 
an experimental trial consists of solving a hypothesis ranking problem with a given
technique and a given set of problem and control parameters  we measure performance
by     how well the algorithms satisfy their respective criteria  and     the number of
samples taken or  alternatively  the cost  in seconds  of executing the algorithm  since the
performance of these statistical algorithms on any single trial provides little information
about its overall behavior  each trial is repeated multiple times and the results are averaged
across trials  synthetic experimental trials were repeated     times  while trials on the
real world data were repeated     times  because the pac and expected loss criteria are
not directly comparable  the approaches are analyzed separately 
   pac based approaches have been investigated extensively in the statistical ranking and selection literature under the topic of confidence interval based algorithms  see haseeb        for a review of the recent
literature  

   

fiefficient heuristic hypothesis ranking
hk

h 

h 

h 

h 

  k   

  

  

 



utility

figure    the stepped means hypothesis configuration 
    evaluation on synthetic datasets

evaluation on synthetic data is used to show that      the techniques correctly bound probability of incorrect ranking and expected loss as predicted when the underlying assumptions
are valid even when the underlying utility distributions are inherently hard to rank      and
    that the pac techniques compare favorably to the algorithm of turnbull and weiss in
a wide variety of circumstances 
for the synthetic datasets  the utility distributions of the hypotheses were modeled as
random variables defined on some underlying parameterized distribution  thus  characterizing a ranking problem consists of choosing some number of hypotheses to rank and then
assigning values for parameters representing each utility distributions for these hypotheses  in our case  we model the utilities as independent normal random variables with some
mean and standard deviation  thus  if we let k be the number of hypotheses  then each hypothesis ranking problem is described by the  k parameters specifying the expected utility
and utility standard deviation for each hypothesis  in general  while several more parameters may be required to characterize a ranking problem fully    the number of hypotheses
and the choices for the parameters of the utility distributions underlying these hypotheses
characterize the overall diculty of the ranking problem 
the statistical ranking and selection community uses a standard family of selection
problems with known diculty to analyze the performance of hypothesis selection strategies 
the method  called the least favorable configuration  lfc  of the population means is that
assignment of the parameters to distributions which is most likely to cause a technique to
choose a wrong hypothesis and thus provides the most severe test of the technique s abilities 
under this configuration  all utilities are independent normally distributed variables of equal
variance  k   of the hypotheses have utilities with equal expectation    and the remaining
hypothesis has expected utility     
because we are interested in hypothesis ranking problems rather than selection problems 
we use a generalization of the lfc that we call stepped means  in this configuration  one
of the hypotheses is assigned expected utility  and successive hypotheses are assigned
expected utility  i for i from         k    figure    
in general  problems based on the least favorable configuration become more dicult
 i e   require more samples  when the number of hypotheses k increases  the common utility
variance   increases  or the difference in the means of the utility distributions decreases  in
the standard methodology  a technique is evaluated by its ability to achieve a confidence of
    configurations that contain hypotheses with high variance relative to the separation between their means
are more dicult to rank 
    for instance  when samples are allocated rationally in  chien et al          it becomes necessary to assign
parameters to a cost distribution as well  or if only a few of the candidate hypotheses were to be ranked 
the number of hypotheses to rank would be another problem parameter 

   

fichien  stechert    mutz
correct selection   using several settings for k and    this last ratio combines  and  into
a single quantity which  as it increases  makes the problem more dicult  this methodology
extends to stepped means directly 
the hypothesis ranking strategies themselves have algorithm control parameters that
govern how they attack a problem  the pac techniques have three control parameters  an
initial sample size n    a desired confidence of correct ranking   and an indifference setting
     the expected loss techniques have two control parameters  an initial sample size n 
and a loss threshold h   
the observed number of samples required and achieved accuracy of the pac techniques
on the stepped means configuration are shown in table      the results indicate that all
systems are roughly comparable in the number of examples required to choose a hypotheses 
as expected  the number of examples increases with k      and    the p acadj algorithm
required the least number of samples but was inconsistent in meeting the desired accuracy
bound  as indicated by its failure to meet the prescribed error bound in several cases   it is
interesting that the turnbull and weiss method did not significantly outperform the pac
techniques despite the fact that the algorithm assumes that the hypotheses are independent
 as is the case in the stepped means configuration   while the pac approaches do not make
this assumption  in this comparison  the principal performance metric is the number of
samples required to achieve the requested ranking  both methods were effective at achieving
the requested accuracy 
in the expected loss experiments  we ran the expected loss hypothesis ranking algorithms
on the same stepped means configurations described above with a range of expected loss
bounds  table     shows the results of this experiment  displaying the number of samples
required to produce a ranking and the average observed loss for each configuration  these
results show that the elrec algorithm correctly bounded the loss and that the eladj algorithm required less samples than the elrec algorithm  but did not correctly bound the
expected loss  since the observed loss was greater than the loss bound h     
    evaluation on real datasets

the test of real world applicability is based on data drawn from several datasets relating
to spacecraft design and the processing of science data gathered in the context of planetary
exploration  the first two datasets we investigate relate to spacecraft design optimization
problems in which the hypotheses we wish to rank are candidate solutions to the design
problem  the third and last dataset we examine involves ranking various lossless image
compression approaches based on their performance on a large set of terrestrial images collected by the spacecraft galileo  cost of evaluation is given in seconds for all empirical data
    note that in our formulation of the stepped means test for the pac approaches   is both the difference
in the expected mean of successive hypotheses and the indifference interval of the algorithm  thus  
plays the roles of both problem parameter and control parameter here 
    one confusing point is that for identical hypothesis and ranking algorithm settings  one can observe a
lower loss when ranking a larger number of hypotheses  this is because the algorithm first divides the
loss over the number of pirwise comparisons  thus  for the same overall error  or expected loss bound  
with more hypotheses  the pairwise expected error  or loss  will be smaller if there are more hypotheses 
the ranking loss is defined previously  thus  it is possible for the observed loss to increase or decrease
compared to the same settings with fewer hypotheses 

   

fiefficient heuristic hypothesis ranking

k
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
  
  
  



    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    




 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

turnbull
         
          
         
          
          
          
          
          
          
          
          
          
          
            
          
            
          
            

p acrec

         
          
         
          
          
          
          
          
          
          
          
          
          
            
          
            
          
            

p acadj

         
         
         
         
         
          
          
          
          
          
          
          
          
          
          
          
          
            

table    estimated expected total number of observations by pac algorithms in the
stepped means configuration  achieved probability of correct ranking is shown
in parenthesis 

parameters
k  h
       
        
       
        
       
        
       
        
        
         
        
         

elrec

samples
  
   
   
   
   
   
   
   
     
     
     
     

loss
   
   
   
   
   
   
   
   
   
   
   
   

eladj

samples
  
  
  
   
   
   
   
   
   
   
   
     

loss
   
   
   
   
   
   
   
   
   
   
   
   

table    estimated expected total number of observations of el algorithms in stepped
means configuration  observed average loss of produced rankings 

   

fichien  stechert    mutz
because  unlike the synthetic problems  the cost of sampling a hypothesis is not constant in
these domains  table   gives a summary of the three ranking problems we considered 
dataset
ds   penetrator

fixed parameters
penetrator diameter
penetrator length

ds   aeroshell

fore body overlap
nose cone angle
bluntness ratio
fillet radius
outer diameter
tail geometry
compression method

lossless image comp 

random variables
impact orientation
impact velocity
soil density
stagnation pressure coef 

optimization criteria
maximize penetration probability
maximize penetration depth

randomly selected test image

maximize compression ratio

minimize weight
achieve target entry velocity

table    description of datasets used for algorithm evaluation 

      ds   penetrator

the goal of the new millennium deep space two  ds    mission is to deliver a pair of
microprobes to the planet mars for scientific study of the martian soil  the probes will
be released from orbit  travel through the martian atmosphere  and embed themselves in
the soil near the southern polar ice cap  the primary science objectives for the mission are
 balacuit         





to determine if ice is present below the surface of mars 
to measure the local atmospheric pressure 
and to characterize the thermal properties of the martian subsurface soil 

the goal of this spacecraft design problem is to determine a good set of physical dimensions for the penetrator a small  robust probe designed to impact the surface at extremely
high velocity and to operate in the extreme cold  specifically  we use design and simulation
data from the ds   mission penetrator design 
for our casting of the design problem  we hold the shape of the penetrator constant and
generate design candidates based on different values for the variables of penetrator diameter
and length  for a specific design a sample is taken by acquiring impact orientation  impact
velocity  and soil density from a parameterized multivariate distribution and then calling a
complex physical simulation to determine if and to what depth the penetrator bored into
the martian surface  the goal of the penetrator design problem is to determine the physical
dimensions of the penetrator that maximize the probability of penetration  and in cases of
penetration  maximize penetration depth 
tables   and   show the results of applying the pac based  turnbull  and expected loss
algorithms to a ranking problem in which the system is requested to rank    penetrator
designs    in this problem the utility function is the depth of penetration of the penetrator 
     true  expected utility values were computed by performing        samples and using the sample mean
for this large sample as ground truth  these expected utilities were then used to compute pac  validity
of rankings and observed loss using the provided definitions 

   

fiefficient heuristic hypothesis ranking
with those cases in which the penetrator does not penetrate being assigned zero utility  as
shown in table    both pac algorithms significantly outperformed the turnbull algorithm 
which is to be expected because the hypotheses are somewhat correlated  via impact orientations and soil densities   table   shows that the elrec expected loss algorithm effectively
bounded actual loss but the eladj algorithm was inconsistent 
k
  
  
  



    
    
    




 
 
 

turnbull
          
          
          

p acrec

          
          
          

p acadj

         
         
          

table    estimated expected total number of observations to rank ds   spacecraft designs 
achieved probability of correct ranking is shown in parenthesis 

parameters
k
h
  
    
  
    
  
    

elrec

samples
   
   
   

loss
    
    
    

eladj

samples
  
  
   

loss
    
    
    

table    estimated expected total number of observations and expected loss of an incorrect
ranking of ds   penetrator designs 

      ds   aeroshell design ranking

the objective of this problem is to design an aeroshell for the soil penetrator described in
the previous section that gives the appropriate entry velocity with minimum weight  design
candidates are defined by six continuous variables that represent various geometric quantities  the extent to which the fore body overlaps the aftbody  nose cone angle  bluntness
ratio  fillet radius  outer diameter  and the tail geometry  candidate designs  hypotheses 
are evaluated by running a simple physical simulation of the aeroshell s behavior  such a
sample is taken by running the simulation with the fixed design variables of the hypothesis
and a value for the stagnation pressure coecient taken from a normal distribution  the
simulation computes values for the achieved entry velocity and the mass of the aeroshell 
then the weighted sum of the reciprocals of these values is maximized 
we give the results of ranking three  five  and ten hypotheses using the turnbull  pac 
and expected loss algorithms in tables   and     
as in the previous experiment  the pac based algorithms outperformed the turnbull
algorithm in all cases  while the p acadj algorithm represents a significant increase in
    again  deep sampling      samples  was performed to obtain the  correct  ranking  against which these
algorithms are compared 

   

fichien  stechert    mutz
performance here  we note that it did not achieve the desired level of confidence in all cases 
both the turnbull and p acrec algorithms did achieve the required confidence 

k
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
  
  
  



    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    




 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

turnbull
          
           
           
           
           
           
           
           
           
           
           
            
           
            
            
            
            
            

p acrec

          
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
            

p acadj

          
          
          
          
          
          
           
           
           
           
           
           
           
           
           
           
           
           

table    estimated expected cost  in seconds  to rank aeroshell designs  achieved probability of correct ranking is shown in parenthesis 

parameters
k
h
 
  
 
  
 
  
 
  
 
  
 
  
  
  
  
  
  
  

elrec

execution cost
   
   
   
    
    
    
    
    
    

loss
   
   
   
   
    
   
   
   
    

eladj

execution cost
   
   
   
   
   
    
    
    
    

loss
   
   
   
   
    
   
   
   
   

table    estimated expected cost  in seconds  and expected loss of an incorrect ranking of
ds   aeroshell designs 

   

fiefficient heuristic hypothesis ranking
      lossless image compression on galileo image data

this problem utilizes a large set of raw image data acquired by the galileo spacecraft  each
of the images is     by     in size and is made up of greyscale pixels ranging from   to     in
intensity  the goal is to select the lossless compression method   that performs best on this
class of images  the performance of an image compression algorithm on a particular image
could be measured in a number of ways  for example  execution time  compression ratio 
and image quality  in the case where lossy compression methods are being considered  could
define algorithm performance  in our tests we chose to consider only the compression ratio
achieved by a given compression method as our utility function  to sample each method
 hypothesis   an image is randomly selected  the method is applied to that image  and the
achieved compression ratio is recorded 
given below  tables   and    are the results of ranking three  five  and seven hypotheses
using the turnbull  pac  and expected loss algorithms  ranking correctness was determined
by comparison to a  correct  ranking established by sampling each compression method on
a set of      distinct images 
we again note the substantial performance improvement the pac based algorithms
have over the turnbull algorithm  although both the turnbull algorithm and the pac
algorithms  table    achieved the desired confidence level  the adjacent version of the el
algorithm  table    failed to bound the loss to the specified level in over half the cases 
it is interesting to consider the results presented in this section in light of the fact that
each of the statistical techniques being used makes some form of normality assumption  in
fact  all three of the problem domains we investigate have some number of hypotheses whose
utility functions are not normally distributed  from past experience it is known that utility
functions in the ds   penetrator domain  section        are highly non normal  figure  
illustrates the difference between data that is normally distributed and data that is not 
    

    

    
   
    
    
    

    

    

    
    
    
    
    

 
   

 
   

   

   

   

   

   

 

  

   

   

   

   

   

   

   

   

   

figure    a comparison of  a  data that is normally distributed with high likelihood and  b 
data that is very likely not normally distributed  in each case  the histogram of
experimental data is shown in solid boxes  data drawn from a normal distribution
with the same mean and standard deviation is shown with dashed lines 
to determine the extent to which the utilities of hypotheses in the remaining two domains are normally distributed we applied the kolmogorov smirnov test  see appendix a
    the seven compression methods we considered were  calic  lossless jpeg  gif  tiff  pack  gzip  and
compress 

   

fichien  stechert    mutz

k
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 



    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    




 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

turnbull
           
            
           
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            

p acrec

           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           

p acadj

           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           

table    estimated expected cost  in seconds  to rank lossless image compression approaches on galileo image data  achieved probability of correct ranking is shown
in parenthesis 

parameters
k
h
 
  
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 

elrec

execution cost
    
    
    
    
    
     
    
     
     

loss
   
   
   
   
   
   
   
   
   

eladj

execution cost
    
    
    
    
    
    
    
    
    

loss
   
   
   
    
    
    
    
    
    

table    estimated expected cost  in seconds  and expected loss of an incorrect ranking of
ds   penetrator designs 

   

fiefficient heuristic hypothesis ranking
for details   the test determined that none of the ten hypotheses from the ds   aeroshell
domain  section        had normally distributed utility  additionally  only two of the seven
hypotheses from the image compression domain  section        were shown to have greater
than     likelihood of having normally distributed utility functions    for these reasons 
evaluating the ranking strategies on these datasets provides a particularly strong test of the
applicability of the techniques 
we draw the reader s attention to the particularly large disparity in performance between
the turnbull algorithm and the pac based algorithms in the image compression domain 
especially apparent when the number of hypotheses  and the confidence level  are high 
additionally  this problem domain has two hypotheses with normally distributed utility
and five that are non normal  these observations suggest that the pac based algorithms
perform better  in relative terms  when faced with a domain that violates the assumption
of normality 
   discussion and conclusions

there are a number of areas of related work  first  there has been considerable analysis of
hypothesis selection problems  selection problems have been formalized using a bayesian
framework  moore   lee        rivest   sloan        that does not require an initial
sample  but uses a rigorous encoding of prior knowledge  howard  howard        also
details a bayesian framework for analyzing learning cost for selection problems  if one
uses a hypothesis selection framework for ranking  allocation of pairwise errors can be
performed rationally  gratch et al          reinforcement learning work  kaelbling       
with immediate feedback can also be viewed as a hypothesis selection problem 
the framework presented invites future work in a number of directions  currently  the
stopping criteria used are relaxations of the ranking requirement  another approach that
could be used is to bound the resources available for ranking  limiting the number of
samples where sample cost is high and limiting the time of computation  so that we have
an anytime algorithm  are two straightforward application areas 
another area for future work is discovery of composite strategies or hypotheses  thus
far we have examined ranking  and in other articles  selection  of a hypothesis with highest expected value over an entire distribution  for example  learning a scheduling control
strategy that will do well over a distribution of problems  however  it is likely that for
most distributions of problems  there exists a composite strategy which would outperform
any single strategy  for example  a single strategy might be to apply method a to solve
a problem  a composite strategy would be  test the problem for feature x  if x true apply method a  else apply method b  these composite strategies correspond to algorithm
portfolios as named in operations research  indeed the results of applying methods could
also be viewed as strategies  one might have the composite strategy of trying method a
for    cpu seconds  then if that fails trying method b  of course  in all these composition and portfolio approaches  the diculty iseciently proposing and evaluating plausible
compositions  for even a small set of base strategies the number of copositions is enormous 
    for reference  the data in figure    a  was normally distributed with       likelihood  according to the
kolmogorov smirnov test 

   

fichien  stechert    mutz
in summary  this paper has described the hypothesis ranking problem  an extension to
the hypothesis selection problem  we defined the application of two decision criteria  probably approximately correct and expected loss  to this problem  we then defined two families of
algorithms  recursive selection and adjacency  for solution of hypothesis ranking problems 
finally  we demonstrated the effectiveness of these algorithms on both synthetic and realworld datasets  documenting improved performance over existing statistical approaches 
acknowledgments

this work was performed by the jet propulsion laboratory  california institute of technology  under contract with the national aeronautics and space administration 
appendix a  applying the k s test to real datasets

the kolmogorov smirnov test is a statistical means of accepting  with a certain level of
confidence  the hypothesis that some sampleset fits a parametric distribution with a given
set of parameters  the method compares the cdf generated by the empirical distribution
to that of the corresponding parametric distribution  i e   with estimated parameters   the
k s test gives a confidence based on the maximum  d  of the discrepancies between these
two cdfs 
d   maxjf   x 

f   x j

for our purposes we wish to determine  for each hypothesis in a given domain  whether
the values of the utility function are normally distributed or not  in each case  half of the
utility samples taken are used to compute the mean and standard deviation of the normal 
the remaining half are used to compute the cdf 
a   ds   penetrator

      samples taken 
design number
 
 
 
 
 
 
 
 
 
  

maxjf   x 

f   x j
      
      
      
      
      
      
      
      
      
      

   

normally distributed 
     likely
     likely
     likely
     likely
     likely
     likely
     likely
     likely
     likely
     likely

fiefficient heuristic hypothesis ranking
a   ds   aeroshell design ranking

    samples taken 
design number
 
 
 
 
 
 
 
 
 
  

maxjf   x 

f   x j

    
    
    
    
    
    
    
    
    
    

normally distributed 
      likely
      likely
      likely
      likely
      likely
      likely
      likely
      likely
      likely
      likely

a   lossless image compression on galileo image data

    samples taken 
compression method
gif
compress
calic
gzip
jpegls
pack
tiff

maxjf   x 

f   x j

    
    
    
    
    
    
    

normally distributed 
    likely
      likely
     likely
      likely
     likely
      likely
      likely

references

balacuit   c  p          deep space     mars microprobe home page  mission objectives
statement   tech  rep  http   nmp jpl nasa gov ds   nasa jpl 
chien  s  a   gratch  j  m     burl  m  c          on the ecient allocation of resources
for hypothesis evaluation  a statistical approach  ieee trans  pattern analysis
and machine intelligence                  
chien  s  a   stechert  a  d     mutz  d  h          ecient heuristic ranking of hypotheses  in advances in neural information processing systems     jordan  kearns 
and solla eds    pp          denver  colorado  nips 
ginsberg  m     harvey  w          iterative broadening  artificial intelligence journal 
            
   

fichien  stechert    mutz
goldberg  d          genetic algorithms in search  optimization  and machine learning 
addison wesley 
gratch  j          composer  a probabilistic solution to the utility problem in speed up
learning  in proceedings of the tenth national conference on artificial intelligence 
pp          san jose  ca  aaai 
gratch  j          composer  a decision theoretic approach to adaptive problem solving  tech  rep  uiucdcs r          department of computer science  university of
illinois 
gratch  j   chien  s     dejong  g          improving learning performance through
rational resource allocation  in proceedings of the twelfth national conference on
artificial intelligence  pp          seattle  wa  aaai 
greiner  r     jurisica  i          a statistical approach to solving the ebl utility
problem  in proceedings of the tenth national conference on artificial intelligence 
pp          san jose  ca  aaai 
haseeb  r  m          modern statistical selection  american sciences press  columbus 
oh 
howard  r  a          decision analysis  perspectives on inference  decision  and experimentation  proceedings of the ieee                  
kaelbling  l  p          learning in embedded systems  mit press  cambridge  ma 
minton  s          learning search control knowledge  an explanation based approach 
kluwer academic publishers  norwell  ma 
moore  a  w     lee  m  s          ecient algorithms for minimizing cross validation
error  in proceedings of the international conference on machine learning new
brunswick  ma 
musick  r   catlett  j     russell  s          decision theoretic subsampling for induction on large databases  in proceedings of the international conference on machine
learning  pp          amherst  ma 
rivest  r  l     sloan  r          a new model for inductive inference  in proceedings of
the second conference on theoretical aspects of reasoning about knowledge 
russell  s     wefald  e          do the right thing  studies in limited rationality  mit
press  cambridge  ma 
tadepalli  p          a theory of unsupervised speedup learning  in proc  of the tenth
national conference on artificial intelligence  pp          san jose  ca  aaai 
turnbull  b  w     weiss  l  i          a class of sequential procedures for k sample
problems concerning normal means with unknown equal variances  in santner 
t  j     tamhane  a  c   eds    design of experiments  ranking and selection  pp 
         marcel dekker 
   

fiefficient heuristic hypothesis ranking
valiant  l  g          a theory of the learnable  communications of the acm     
          

   

fi