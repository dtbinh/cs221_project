journal of artificial intelligence research               

submitted       published     

the divide and conquer subgoal ordering algorithm
for speeding up logic inference
oleg ledeniov
shaul markovitch

olleg cs technion ac il
shaulm cs technion ac il

computer science department
technion   israel institute of technology
haifa        israel

abstract

it is common to view programs as a combination of logic and control  the logic part
defines what the program must do  the control part   how to do it  the logic programming paradigm was developed with the intention of separating the logic from the control 
recently  extensive research has been conducted on automatic generation of control for
logic programs  only a few of these works considered the issue of automatic generation of
control for improving the eciency of logic programs  in this paper we present a novel algorithm for automatic finding of lowest cost subgoal orderings  the algorithm works using
the divide and conquer strategy  the given set of subgoals is partitioned into smaller sets 
based on co occurrence of free variables  the subsets are ordered recursively and merged 
yielding a provably optimal order  we experimentally demonstrate the utility of the algorithm by testing it in several domains  and discuss the possibilities of its cooperation with
other existing methods 

   introduction
it is common to view programs as a combination of logic and control  kowalski         the
logic part defines what the program must do  the control part   how to do it  traditional
programming languages require that the programmers supply both components  the logic
programming paradigm was developed with the intention of separating the logic from the
control  lloyd         the goal of the paradigm is that the programmer specifies the logic
without bothering about the control  which should be supplied by the interpreter 
initially  most practical logic programming languages  such as prolog  clocksin   mellish        sterling   shapiro         did not include the means for automatic generation of
control  as a result  a prolog programmer had to implicitly define the control by the order of
clauses and of subgoals within the clauses  recently  extensive research has been conducted
on automatic generation of control for logic programs  a major part of this research is concerned with control that affects correctness and termination of logic programs  de schreye
  decorte        somogyi  henderson    conway      b  cortesi  le charlier    rossi 
       only a few of these works consider the issue of automatic generation of control for
improving the eciency of logic programs  finding a good ordering that leads to ecient
execution requires a deep understanding of the logic inference mechanism  hence  in many
cases  only expert programmers are able to generate ecient programs  the problem intensifies with the recent development of the field of inductive logic programming  muggleton
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

filedeniov   markovitch

  de raedt         there  logic programs are automatically induced by learning  such
learning algorithms are commonly built with the aim of speeding up the induction process
without considering the eciency of resulting programs 
the goal of the research described in this paper is to design algorithms that automatically find ecient orderings of subgoal sequences  several researchers have explored the
problem of automatic reordering of subgoals in logic programs  warren        naish      b 
smith   genesereth        natarajan        markovitch   scott         the general subgoal ordering problem is known to be np hard  ullman        ullman   vardi        
smith and genesereth        and markovitch and scott        present search algorithms
for finding optimal orderings  these algorithms are general and carry exponential costs for
non trivial sets of subgoals  natarajan        describes an ecient algorithm for the special
case where subgoals in the set do not share free variables 
in this paper we present a novel algorithm for subgoal ordering  we call two subgoals
that share a free variable dependent  unlike natarajan s approach  which can only handle
subgoal sets that are completely independent  our algorithm can deal with any subgoal
set  while making maximal use of the existing dependencies for acceleration of the ordering
process  in the worst case the algorithm   like that of smith and genesereth   is exponential 
still  in most practical cases  our algorithm exploits subgoal dependencies and finds optimal
orderings in polynomial time 
we start with an analysis of the ordering problem and demonstrate its importance
through examples  we then show how to compute the cost of a given ordering based on
the cost and the number of solutions of the individual subgoals  we describe the algorithm
of natarajan and the algorithm of smith and genesereth and show how the two can be
combined into an algorithm that is more ecient and general than each of the two  we
show drawbacks of the combined algorithm and introduce the new algorithm  which avoids
these drawbacks  we call it the divide and conquer algorithm  dac algorithm   we prove
the correctness of the algorithm  discuss its complexity and compare it to the combined
algorithm  the dac algorithm assumes knowledge of the cost and the number of solutions
of the subgoals  this knowledge can be obtained by machine learning techniques such as
those employed by markovitch and scott         finally  we test the utility of our algorithm
by running a set of experiments on artificial and real domains 
the dac algorithm for subgoal ordering can be combined with many existing methods
in logic programming  such as program transformation  compilation  termination control 
correctness verification  and others  we discuss the possibilities of such combinations in the
concluding section 
section   states the ordering problem  section   describes existing ordering algorithms
and their combination  section   presents the new algorithm  section   discusses the
acquisition of the control knowledge  section   contains experimental results  section  
contains a discussion of practical issues  comparison with other works and conclusions 

   background  automatic ordering of subgoals
we start by describing the conventions and assumptions accepted in this paper  then we
demonstrate the importance of subgoal ordering and discuss its validity  finally  we present
a classification of ordering methods and discuss related work 
  

fithe divide and conquer subgoal ordering algorithm

    conventions and assumptions

all constant  function and predicate symbols in programs begin with lower case letters 
while capital letters are reserved for variables  braces are used to denote unordered sets
 e g   fa  b  cg   and angle brackets are used for ordered sequences  e g   ha  b  ci   parallel
lines  k  denote concatenations of ordered sequences of subgoals  when speaking about
abstract subgoals  and not named predicates of concrete programs   we denote separate
subgoals by capital letters  a  b         ordered sequences of subgoals by capitalized vectors
  o  s         and sets of subgoals by calligraphic capitals  b  s           s   denotes the set of
 b 
all permutations of s  
we assume that the programs we work with are written in pure prolog  i e   without cut
operators  meta logical or extra logical predicates  alternatively  we can assume that only
pure prolog sub sequences of subgoals are subject to ordering  for example  given a rule of
the form
a b    b   b      b   b   b  
only its final part fb    b   b g can be ordered  without affecting the solution set  
in this work we focus upon the task of finding all the solutions to a set of subgoals 

    ordering of subgoals in logic programs
a logic program is a set of clauses 

a

b    b           bn  

 n    

where a  b           bn are literals  predicates with arguments   to use such a clause for
proving a goal that matches a  we must prove that all b  s hold simultaneously  under
consistent bindings of the free variables  a solution is such a set of variable bindings  the
solution set of a goal is the bag of all its solutions created by its program 
a computation rule defines which subgoal will be proved next  in prolog  the computation rule always selects the leftmost subgoal in a goal  if a subgoal fails  backtracking is
performed   the proof of the previous subgoal is re entered to generate another solution 
for a detailed definition of the logic inference process  see lloyd        

theorem   the solution set of a set of subgoals does not depend on the order of their

execution 

proof  when we are looking for all solutions  the solution set does not depend on the

computation rule chosen  theorems     and      in lloyd         since a transposition of
subgoals in an ordered sequence can be regarded as a change of the computation rule  the
subgoals are selected in different order   such transposition does not change the solution
set 
 
this theorem implies that we may reorder subgoals during the proof derivation  yet the
eciency of the derivation strongly depends on the chosen order of subgoals  the following
example illustrates how two different orders can lead to a large difference in execution
eciency 
  

filedeniov   markovitch

parent abraham isaac  
parent sarah isaac  
parent abraham ishmael  
parent isaac esav  
parent isaac jakov  

    more parent clauses    

male abraham  
male isaac  
male ishmael  
male jakov  
male esav  

    more male clauses    

brother x y 
male x   parent w x   parent w y   x   y 
father x y 
male x   parent x y  
uncle x y 
parent z y   brother x z  

    more rules of relations    

figure    a small fragment of a biblical database describing family relationships 

example  
consider a biblical family database such as the one listed in figure    a similar database
appears in the book by sterling   shapiro         the body of the rule defining the
uncle nephew  or uncle niece  relation can be ordered in two ways 
   uncle x y  brother x z   parent z y  
   uncle x y  parent z y   brother x z  
to prove the goal uncle ishmael y  using the first version of the rule  the interpreter will
first look for ishmael s siblings  and find isaac  and then for the siblings  children  esav
and jacov   the left part of figure   shows the associated proof tree with a total of   
nodes  if we use the second version of the rule  the interpreter will create all the parentchild pairs available in the database  and will test for each parent whether he  or she  is
ishmael s sibling  the right part of figure   shows the associated proof tree with a total
of   n                    n     nodes  where n is the number of parent child pairs in the
database  the tree contains two success branches and n     failure branches  in the figure
we show one example of each  while the two versions of the rule yield identical solution
sets  the first version leads to a much smaller tree and to a faster execution 
note that this result is true only for the given mode  bound free  of the head literal 
for the mode  free bound   as in uncle x jacov   the outcome is the contrary  the second
version of the rule yields a smaller tree 

    categories of subgoal ordering methods

assume that the current conjunctive goal  the current resolvent  is fa   a g  assume that
we use the rule  a  a    a     to reduce a    according to theorem    the produced
resolvent  fa     a    a g  can be executed in any order  we call ordering methods that
allow any permutation of the resolvent interleaving ordering methods  since they permit
  

fithe divide and conquer subgoal ordering algorithm

uncle x y 

brother x z   parent z y   uncle x y 

uncle ishmael y 

uncle ishmael y 

parent z y   brother ishmael z 

brother ishmael z   parent z y 

z adam 
y cain

male ishmael   parent w ishmael   parent w z  
ishmael     z  parent z y 

brother ishmael adam 
parent w ishmael   parent w z  
ishmael     z  parent z y 
w abraham
parent abraham z   ishmael   z  parent z y 
z ishmael
z isaac
ishmael     ishmael 
parent ishmael y 

isaac     ishmael 
parent isaac y 

parent z y   brother x z  

z isaac 
y jacov

other
parent child
pairs

male ishmael   parent w ishmael  
parent w adam   ishmael     adam
parent w ishmael   parent w adam  
ishmael     adam
w abraham
parent abraham adam   ishmael    adam

parent isaac y 
y esav
y jacov

brother ishmael isaac 

male ishmael   parent w ishmael  
parent w isaac   ishmael   isaac
parent w ishmael   parent w isaac  
ishmael     isaac
w abraham
parent abraham isaac   ishmael   isaac
ishmael     isaac

figure    two proof trees obtained with different orderings of a single rule in example   
interleaving of subgoals from different rule bodies  when ordering is performed only on
rule bodies before using them for reduction  the method is non interleaving  in the above
example  interleaving methods will consider all   permutations of the resolvent  while noninterleaving methods will consider only two orderings  ha     a    a i and ha    a    a i 
interleaving ordering methods deal with significantly more possible orderings than noninterleaving methods  that means that they can find more ecient orderings  on the
other hand  the space of possible orderings may become prohibitively large  requiring too
many computational resources 
subgoal ordering can take place at various stages of the proof process  we divide all
subgoal ordering methods into static  semi dynamic and dynamic 

 static ordering  the rule bodies are ordered before the execution starts  no ordering takes place during the execution 

 semi dynamic ordering  whenever a rule is selected for reduction  its body is
ordered  the order of its subgoals does not change after the reduction takes place 

 dynamic ordering  the ordering decision is made at each inference step 
static methods add no overhead to the execution time  however  the optimal ordering
of a rule often depends on a particular binding of a variable  which can be known only at
run time  for instance  in example   we saw that the first ordering of the rule is better
for proving the goal uncle ishmael y   and yet  for the goal uncle x jacov   it is the
second ordering that yields more ecient execution  to handle such cases statically  we
must compute the optimal ordering for each possible binding 
  

filedeniov   markovitch

obviously  static ordering can only be non interleaving  the dynamic method is more
exible  since it can use more updated knowledge about variable bindings  but it also carries
the largest runtime overhead  since it is invoked several times for each use of a rule body 
the semi dynamic method is a compromise between the two  it is more powerful than the
static method  because it can dynamically propose different orderings for different instances
of the same rule  it also carries less overhead than the dynamic method  because it is invoked
only once for each use of a rule body 
the total time of proving a goal is the sum of the ordering time and the inference time 
interleaving and dynamic methods have the best potential for reducing the inference time 
but may significantly augment the ordering time  static methods do not devote time to
ordering  it is done off line   but have a limited potential for reducing the inference time 
the algorithms described in this paper can be used for all categories of ordering methods 
although in the experiments described in section   we have only implemented semi dynamic 
non interleaving ordering methods  on each reduction  the rule body is ordered and added
to the left end of the resolvent  and then the leftmost literal of the resolvent is selected for
the next reduction step 

    related work

the problem of computational ineciency of logic inference was the subject of extensive
research  the most obvious aspect of this ineciency is the possible non termination of
a proof  several researchers developed compile time and run time techniques to detect
and avoid infinite computations  de schreye   decorte         a certain success was
achieved in providing more advanced control through employment of co routining for interpredicate synchronization purposes  clark   mccabe        porto        naish        
also  infinite computations can be avoided by pruning infinite branches that do not contain
solutions  vasak   potter        smith  genesereth    ginsberg        bol  apt    klop 
       in the nail  system  morris        subgoals are automatically reordered to avoid
nontermination 
still  even when the proof is finite  it is desirable to make it more ecient  several
researchers studied the problem of clause ordering  smith        cohen        etzioni 
      laird        mooney   zelle        greiner   orponen         if we are looking for
all the solutions of a goal  then the eciency does not depend on the clause order  assuming
no cuts   indeed  if some predicate has m clauses  and for some argument bindings these
clauses produce all their solutions in times t    t       tm   then all solutions of the predicate
under these bindings are obtained in time t    t            tm   regardless of the order in
which the clauses are applied  different clause orderings correspond to different orders in
which branches are selected in a proof tree  if we traverse the entire tree  then the number
of traversal steps does not depend on the order of branch selection  though the order of
solutions found does depend on it 
subgoal ordering  as was demonstrated in example    can significantly affect the eciency of proving a goal  there are two major approaches to subgoal ordering  the first
approach uses various heuristics to order subgoals  for example 

 choose a subgoal whose predicate has the smallest number of matching clauses  minker 
      

  

fithe divide and conquer subgoal ordering algorithm

 prefer a subgoal with more constants  minker        
 choose a subgoal with the largest size  where the size is defined as the number of
occurrences of predicate symbols  function symbols  and variables  nie   plaisted 
      

 choose a subgoal with the largest mass  where the mass of a subgoal depends on
the frequency of its arguments and sub arguments in the entire goal  nie   plaisted 
      

 choose a subgoal with the least number of solutions  warren        nie   plaisted 
      

 apply  tests  before  generators   naish      a  
 prefer calls that fail quickly  naish      b  
the heuristic methods usually execute quickly  but may yield suboptimal orderings 
the second approach  which is adopted in this paper  aims at finding optimal orderings  smith   genesereth        natarajan        markovitch   scott         natarajan
proposed an ecient way to order a special sort of subgoal set  where all subgoals are independent   while smith and genesereth proposed a general  but inecient algorithm  in
the following section we build a unifying framework for dealing with subgoal ordering and
describe variations on natarajan s and smith and genesereth s algorithms  we also show
how the two can be combined for increased eciency 

   algorithms for subgoal ordering in logic programs
the goal of the work presented here is to order subgoals for speeding up logic programs  this
section starts with an analysis of the cost of executing a sequence of subgoals  the resulting
formula is the basis for the subsequent ordering algorithms  then we discuss dependence
of subgoals and present existing ordering algorithms for independent and dependent sets of
subgoals  finally  we combine these algorithms into a more general and ecient one 

    the cost of executing a sequence of subgoals

in this subsection we analyze the cost of executing a sequence of subgoals  the analysis
builds mainly on the work of smith and genesereth        
let s   fa   a        ak g be a set of subgoals and b be a binding  we denote sols s   to
be the solution set of s   and define sols      f g  we denote ai jb to be ai whose variables
are bound according to b  ai j    ai    finally  we denote cost ai jb   to be the amount of
resources needed for proving ai jb   cost ai jb   should reect the time complexity of proving
ai under binding b  for example  the number of unification steps is a natural measure of
complexity for logic programs  itai   makowsky        
to obtain the cost of finding all the solutions of an ordered sequence of subgoals

s    ha   a   a        ani 
  

   

filedeniov   markovitch

we note that the proof tree of a  is traversed only once  the tree of a  is traversed once
for each solution generated by a    the tree of a    once for each solution of fa   a g  etc 
consequently  the total cost of proving equation   is

cost ha        an i    cost a    
 

x

cost a jb           

b sols fa  g 

n
x

x

cost an jb    

b sols fa      an   g 

x

cost aijb  
i   b sols fa      ai   g 

   

to compute equation   one must know the cost and the solution set for each subgoal
under each binding  to reduce the amount of information needed  we derive an equivalent
formula  which uses average cost and average number of solutions 

definition  let b be a set of subgoals  a a subgoal  define cost a jb to be the average
cost of a over all solutions of b and nsols a jb to be its average number of solutions over
all solutions of b 
 
 
p  a   cost ajb  b    
  cost
b
cost a jb     b sols
  b 
     sols b      
j
sols b j
  undefined 
b       sols b     
   

 
 
j 
b  
  jpsols fagj sols
 
f
a
j
g
 
j
b
b
nsols a jb     b solsjsols
  b 
     sols b      
  undefined   b j
b       sols b     
   

from the first definition  it follows that 

x

cost aijb     jsols fa        ai   g j  cost ai jfa     ai  g  
 

b sols fa      ai   g 

 

   

if we apply the second definition recursively  we obtain

jsols fa        aig j  
 
 

x

jsols faijbg j
b sols fa      ai   g 
jsols fa        ai   g j  nsols ai jfa     ai  g
yi
        nsols aj  jfa    aj   g 
j   

   

note that we defined sols      f g  thus  these equations hold also for i      incorporation
of equations   and   into equation   yields

cost ha   a        an i   

  i  
n
x
   y
i  

j   

 
 
nsols aj  jfa    aj  ga  cost ai  jfa    ai  g   
 

  

 

 

 

   

fithe divide and conquer subgoal ordering algorithm

for each subgoal ai   its average cost is multiplied by the total number of solutions of
all the preceding subgoals  we can define average cost and number of solutions for every
continuous sub sequence of equation     k    k      k   k   n 
cost ha        ak i j    cost ha        ak    i j 
   
cost hak        ak i jfa     ak   g  
   nsols ha        ak    i  j 
 
 

 

 

 

 

 

 

 

k
i  
x
   y
 

i k 

j  k 

 

nsols aj  jfa     aj  g a  cost ai  jfa     ai  g  
 

 

 

 

k
y
nsols ha        ak i j 
nsols hak        ak i jfa     ak   g  
 
nsols ai jfa     ai  g
nsols ha        ak    i j  i k
 

 

 

 

 

 

 

 

 

 

   

 

the values of cost ai   and nsols ai   depend on the position of ai in the ordered sequence  for example  assume that we want to find abraham s sons  using the domain of
example    the unordered conjunctive goal is fmale y  parent abraham y g  let there
be n males in the database  two of them  isaac and ishmael  are abraham s sons  
nsols male y  j    n
nsols parent abraham y  j     
nsols male y  jfparent abraham y g     nsols parent abraham y  jfmale y g     n
note that nsols hmale y  parent abraham y i        nsols hparent abraham y  male y i  
exactly as theorem   predicts 
having defined the cost of a sequence of subgoals  we can now define the objective of
our ordering algorithms 

definition  let s be a set of subgoals  define  s   to be set of all permutations of
s   o  s    s   is a minimal ordering of s  denoted min o  s   s     if its cost according to
equation   is minimal over all possible permutations of s  
min o  s   s       os      s     cost o  s    cost os    
the total execution time is the sum of the time which is spent on ordering  and the
inference time spent by the interpreter on the ordered sequence  in this paper we focus
upon developing algorithms for minimizing the inference time  elsewhere  ledeniov  
markovitch      a      b  we present algorithms that attempt to reduce the total execution
time 
the values of cost and number of solutions can be obtained in various ways  by exact
computation  by estimation and bounds  and by learning  let us assume at the moment
that there exists a mechanism that returns the average cost and number of solutions of a
subgoal in time    in section   we show how this control knowledge can be obtained by
inductive learning 

    ordering of independent sets of subgoals

the general subgoal ordering problem is np hard  ullman   vardi         however  there
is a special case where ordering can be performed eciently  if all the subgoals in the
  

filedeniov   markovitch

given set are independent  i e  do not share free variables  this section begins with the
definition of subgoal dependence and related concepts  we then show an ordering algorithm
for independent sets and prove its correctness 
      dependence of subgoals

definition  let s and b be sets of subgoals  b is called the binding set of s    a pair of
subgoals in s is directly dependent under b  if they share a free variable not bound by a
subgoal of b 
a pair of subgoals is indirectly dependent with respect to s and b if there exists a third
subgoal in s which is directly dependent on one of them under b  and dependent  directly
or indirectly  on the other one under b  a pair of subgoals of s is independent under b if
it is not dependent under b  either directly or indirectly   a subgoal is independent of s
under b if it is independent of all members of s under b 
two subsets s   s and s   s are mutually independent under the binding set b if
every pair of subgoals  a   a    such that a    s  and a    s   is independent under b 
the entire set s is called independent under the binding set b if all its subgoal pairs
are independent under b  and is called dependent otherwise  a dependent set of subgoals
is called indivisible if all its subgoal pairs are dependent under b  and divisible otherwise 
a divisibility partition of s under b  dpart s   b   is a partition of s into subsets that
are mutually independent and indivisible under b  except at most one subset which contains
all the subgoals independent of s under b  it is easy to show that dpart s   b  is unique 
for example  let s    fa  b x    c y    d x  y    e z    f  z  v    h w  g  with respect to
s  and an empty binding set  the pair fb x    d x  y  g is directly dependent  fb x    c y  g
is indirectly dependent and fb x    e z  g is independent  if we represent a set of subgoals

as a graph  where subgoals are vertices and directly dependent subgoals are connected by
edges  then dependence is equivalent to connectivity and indivisible subsets are equivalent
to connected components of size greater than    the divisibility partition is the partition
of a graph into connected components  with all the  lonely  vertices collected together  in
a special component  figure   shows an example of such a graph for the set s  and for
an empty binding set  the whole set is divisible into four mutually independent subsets 
the subsets fe z    f  z  v  g and fb x    c y    d x  y  g are indivisible  elements of the
divisibility partition dpart s       are shown by dotted lines 
if a subgoal is independent of the set  then its average cost and number of solutions do
not depend on its position within the ordered sequence 
p
cost ajb  jsols b j  cost a 
 
  cost a  
cost a jb   b sols b 
jsols b j
jsols b j

p

b sols b  jsols fajbg j

  jsols b j  jsols fag j   jsols fag j 
jsols b j
in this case we can omit the binding information and write cost ai   instead of cost ai jfa    ai  g  
and nsols ai   instead of nsols ai  jfa    ai  g 
in practice  program rule bodies rarely feature independent sets of literals  an example
is the following clause  which states that children like candy 
nsols a jb  

jsols b j

 

 

 

  

 

fithe divide and conquer subgoal ordering algorithm

fa 

b x   c y   d x y   e z   f z v   h w 

a
h w 

b x 

e z 
f z v 

g 

c y 

d x y 

figure    an example of a graph representing a set of subgoals  directly dependent subgoals

are connected by edges  independent subgoals and indivisible subsets are equivalent to
connected components  surrounded by dashed lines   the divisibility partition  under
the empty binding set  is shown by dotted lines 
likes x y 

child x   candy y  

more often  independent rule bodies appear not because they are written as such in the
program text  but because some variables are bound in  initially dependent  rule bodies  as
a result of clause head unification  for example  if the rule
father x y 

male x   parent x y  

is used to reduce father abraham w   then x is bound to abraham  and the rule body
becomes independent  rule bodies often become independent after substitutions are performed in the course of the inference process 
      algorithm for ordering independent sets by sorting

let s  be an ordered sub sequence of subgoals  b a set of subgoals  we denote
 
cn s   jb   nsols s  jb      
cost s  jb
the name  cn  reects the participation of cost and nsols in the definition  when the subsequence s  is independent of other subgoals  the binding information  jb   can be omitted 
together  the average cost  average number of solutions  and cn value of a subgoal will be
called the control values of this subgoal 
for independent sets  there exists an ecient ordering algorithm  listed in figure    the
complexity of this algorithm is o n    log n    o n     to obtain the control values of n
subgoals  and o n log n  to perform the sorting  knuth         to enable the division  we
must define the cost so that cost ai   is always positive  if we define the cost as the number
of unifications performed  then always cost ai       under a reasonable assumption that
predicates of all rule body subgoals are defined in the program   in this case  at least one
unification is performed for each subgoal   similar algorithms were proposed by simon and
kadane        and natarajan        
example   let the set of independent subgoals be fp  q  rg  with the following control values 
  

filedeniov   markovitch

algorithm  
let s   fa   a        an g be a set of subgoals 
 ai    
sort s using cn ai     nsols
cost ai   as the key for ai   and return the result 
figure    the algorithm for ordering subgoals by sorting 
p q
r
cost      
 
nsols    
   
cn
           
we compute the costs of all possible orderings  using equation   

cost hp  q  ri                             
cost hp  r  q i                               
cost hq  p  ri                             
cost hq  r  pi                               
cost hr  p  q i                                
cost hr  q  pi                                 
the minimal ordering is hr  p  q i  and this is exactly the ordering which is found much
more quickly by algorithm   for the set fp  q  rg  r has the smallest cn value         then
goes p with cn p       and finally q with cn q         
note that the sorting algorithm reects a well known principle  the best implementations of generate and test programs are obtained with the tests placed as early as possible
in the rule body and the generations as late as possible  naish      a   of course  the
cheap tests should come first  while the expensive ones should come last  if one looks at
the cn measure  one quickly realizes that tests should be put in front  because nsols     
so cn       while generator subgoals should move towards the end  nsols      so cn      
the weakness of the  test first  principle is in the fact that not every subgoal can be easily
tagged as a test or a generator  if one subgoal has nsols     and another one has nsols     
then their order is obvious even without looking at the costs  because their cn values have
different signs   but if both subgoals have nsols      or both have nsols      then the
decision is not so simple  sorting by cn can correctly handle all the possible cases 
      correctness proof of the sorting algorithm for independent sets

we saw that algorithm   found a minimal ordering in example    we are now going to
prove that algorithm   always finds a minimal ordering for independent sets  first we
show an important lemma which will also be used in further discussion  this lemma states
  

fithe divide and conquer subgoal ordering algorithm

that substitution of a sub sequence by its cheaper permutation makes the entire sequence
cheaper 

lemma  
let s    a  kb  kc    s      a  kb    kc    where b  and b    are permutations of one another  and a 
either is empty or has nsols a         then

cost s      cost s         cost b   ja    cost b     ja   
cost s      cost s         cost b   ja    cost b     ja   

proof  if a  and c  are not empty 
cost s      cost s        cost a  kb  kc      cost a  kb    kc     


   
  cost a   j    nsols a   j   cost b   ja    nsols a  kb   j   cost c   ja  kb   
  

cost a j    nsols a   j   cost b     ja    nsols a  kb     j   cost c   ja  kb     

by theorem    b  and b    produce the same solution sets  hence  the third terms in the
parentheses above are equal  and





cost s      cost s       nsols a   j   cost b   ja    cost b     ja   
since nsols a         the sign of cost s      cost s      coincides with the sign of cost b   ja   
cost b     ja   
if a  or c  is empty  the proof is similar 
 
definition  let s    a  kb   kc  kb   kd  be an ordered sequence of subgoals  a   c  and d  may
be empty sequences   with respect to s    the pair hb      b   i is

 cn ordered  if cn b    ja   cn b    ja  b   c 
 

 cn inverted  if cn b    ja    cn b    ja  b   c 
 

we now show that two adjacent mutually independent sequences of subgoals in a minimal
ordering must be cn ordered 

lemma  
let s    a  kb    kb    kc    s      a  kb    kb    kc    where b      b    are mutually independent under a   
let a  either be empty or have nsols a         then

cost s      cost s        cn b    ja    cn b    ja   
cost s      cost s        cn b    ja    cn b    ja   
  

filedeniov   markovitch

proof 
cost s      cost s     lemma
     cost b   kb    ja    cost b   kb    ja 
   cost b    ja    nsols b    ja  cost b    ja  b   
cost b     ja    nsols b     ja  cost b     ja  b 
indep fb      b   g
  
cost b     ja    nsols b     ja  cost b     ja   
cost b     ja    nsols b     ja  cost b     ja 
   nsols b    ja   cost b    ja    cost b    ja   
nsols b     ja   cost b     ja    cost b     ja 
cost b  i  ja     nsols b     ja      nsols b     ja     
  
 
cost b     ja 
cost b     ja 
   cn b    ja    cn b    ja 
 
 

cost s      cost s    

  

cn b     ja    cn b    ja    similar 

 

in an independent set  all subgoal pairs are independent  in particular all adjacent pairs 
so  in a minimal ordering of an independent set  all adjacent subgoal pairs must be cnordered  otherwise  the cost of the sequence can be reduced by a transposition of such pair 
this conclusion is expressed in the following theorem 

theorem  
let s be an independent set  let s  be an ordering of s   s  is minimal iff all the subgoals in
s  are sorted in non decreasing order by their cn values 

proof 

   let s  be a minimal ordering of s   if s  contains a cn inverted adjacent pair of subgoals 
then transposition of this pair reduces the cost of s   lemma     contradicting the
minimality of s   

   let s  be some ordering of s   whose subgoals are sorted in non decreasing order by
cn  let s    be a minimal ordering of s   according to item    s    is also sorted by
cn  the only possible difference between the two sequences is the internal ordering
of sub sequences with equal cn values  the ordering of each such sub sequence in
s  can be transformed to the ordering of its counterpart sub sequence in s    by a
finite number of transpositions of adjacent subgoals  by lemma    transpositions of
adjacent independent subgoals with equal cn values cannot change the cost of the
sequence  therefore  cost s      cost s      and s  is a minimal ordering of s  since s   
is minimal  
 

corollary   algorithm   finds a minimal ordering of an independent set of subgoals 
  

fithe divide and conquer subgoal ordering algorithm

    ordering of dependent sets of subgoals

algorithm   does not guarantee finding a minimal ordering when the given set of subgoals
is dependent  as the following proposition shows 

proposition   when the given set of subgoals is dependent  then 
   the result of algorithm   on it is not always defined 
   even when the result is defined  it is not always a minimal ordering of the set 

proof  both claims are proved by counter examples 
   we show a set of subgoals that cannot be ordered by sorting 
the program 
control values 
a x  j  a x  jfb x  g b x  j  b x  jfa x  g
a c   
b c   
cost
 
 
 
 
a c   
b c   
nsols
 
 
 
 
 
 
cn
 
 
 
 

the set fa x   b x g has two possible orderings  ha x    b x  i and hb x    a x  i 
both orderings have minimal cost  though neither one is sorted by cn  each ordering
has cn      for its first subgoal  and cn     for the second one  sorting by cn is
impossible here  when we transpose subgoals  their cn values are changed  and the
pair becomes cn inverted again 
   we show a set of subgoals that can be ordered by sorting  but its sorted ordering is
not minimal 
the program 
control values 
a x  j  a x  jfb x  g b x  j  b x  jfa x  g
a c   
cost
 
 
 
 
a c   
 
 
 
 
nsols
b c   
 
 
cn
 
 
b c  
a c    a c   
 
 
let the unordered set of subgoals be fa x   b x g  its ordering hb x    a x  i is sorted
by cn  while ha x    b x  i is not  but ha x    b x  i is cheaper than hb x    a x  i 
cost ha x    b x  i                

cost hb x    a x  i                 

 
since sorting cannot guarantee minimal ordering for dependent subgoals  we now consider alternative ordering algorithms  the simplest algorithm checks every possible permutation of the set and returns the one with the minimal cost  the listing for this algorithm
is shown in figure   
this algorithm runs in o   n   time  where  is the time it takes to compute the control
values for one subgoal  and n is the number of subgoals 
the following observation can help to reduce the ordering time at the expense of additional space  ordered sequences can be constructed incrementally  by adding subgoals to
  

filedeniov   markovitch

algorithm  
for each permutation of subgoals  find its cost according to equation   
store the currently cheapest permutation and update it when a cheaper
one is found 
finally  return the cheapest permutation 

figure    the algorithm for subgoal ordering by an exhaustive check of all permutations 

algorithm  
order s  
let p  f g  n jsj
loop for kn    tofi n
o
pk  np  kb fifi p fi   pk    b h  s n p 
io
  p        cost p     cost p     
pk p    pk  fifi  p      pk    permutation p 
return the single member of pn  
figure    the ordering algorithm which checks permutations of ordered prefixes 
the right ends of ordered prefixes  by lemma    if a cheaper permutation of a prefix exists 
then this prefix cannot belong to a minimal ordering  the ordering algorithm can build
prefixes with increasing lengths  at each step adding to the right end of each prefix one of
the subgoals that do not appear in it already  and for each subset keeping only its cheapest
permutation  if several permutations have equal cost  any one of them can be chosen   the
listing for this algorithm is shown in figure    at each step k  pk  stores the set of prefixes
from step k     extended by every subgoal not appearing there already  pk  pk    and
in pk each subset of subgoals is represented only by its cheapest permutation  obviously 
jpk j    nk   one prefix is kept for every subset of s of size k   for each prefix of length k     
there are n    k      possible continuations of length k  the size of pk  is as follows 
 
k
n 
n
jpk  j    k n   n  k        n    k  n     
k        n  k       k   n   k   k         k  k   
for each prefix  we compute its cost in  time  the permutation test can be completed
in o n  time  by using  for example  a trie structure  aho et al          where subgoals in
prefixes are sorted lexicographically  each step k takes o  n       k   nk    time  and the
  

fithe divide and conquer subgoal ordering algorithm

whole algorithm runs in
n
x

k  

o  n       k   nk      o n   n      

n
x
n
k  

 k      o n   n        n   

if    o n   this makes o n    n   
smith and genesereth        and natarajan        point out that in a minimal ordered
sequence every adjacent pair of subgoals must satisfy an adjacency restriction  the most
general form of such a restriction in our notation says that two adjacent subgoals ak and
ak   in a minimal ordering ha   a       ani must satisfy
cost hak   ak  i jfa    ak  g  cost hak     ak i jfa    ak  g 
 

 

 

 

   

the restriction follows immediately from lemma    however  it can only help to find a
locally minimal ordering  i e   an ordering that cannot be improved by transpositions of
adjacent subgoals  it is possible that all adjacent subgoal pairs satisfy equation    but the
ordering is still not minimal  the following example illustrates this statement 

example   let the unordered set be fp x    q x    r x  g  where the predicates are defined
by the following program 

p c   
q  c   
r c   
p c   f  q  c   
r c   
q  c   f 
f fails after    unifications 
the ordering hp x    q  x    r x  i satisfies the adjacency restriction  equation    
cost q  x    r x   jp x      
cost p x    q  x   j      
cost q  x    p x   j       
cost r x    q  x   jp x      
but it is not minimal 

cost hp x    q x    r x  i      
cost hr x    p x    q  x  i      

to find a globally minimal ordering  it seems beneficial to combine the prefix algorithm
with the adjacency restriction  if a prefix does not satisfy the adjacency restriction  then
there is a cheaper permutation of this prefix  the adjacency test can be performed faster
than the permutation test  since it must only consider the two last subgoals of each prefix  nevertheless  the number of prefixes remaining after each step of algorithm   is not
reduced  if a prefix is rejected due to a violation of the adjacency restriction  it would have
also been rejected by the permutation test  furthermore  if the adjacency restriction test
does not fail  we should still perform the permutation test to avoid local minima  as in
example     the adjacency test succeeds in at least half of the cases  if we examine a
prefix ha         ak   b   b  i  we shall also examine ha        ak   b    b i  and the adjacency test
cannot fail in both  consequently  addition of the adjacency test can only halve the total
running time of the ordering algorithm  leaving it o n    n   in the worst case 
  

filedeniov   markovitch

smith and genesereth propose performing a best first search in the space of ordered
prefixes  preferring prefixes with lower cost  the best first search can be combined with
the permutation test and the adjacency restriction  in addition  when the subgoals not
in a prefix are independent under its binding  they can be sorted  and the sorted result
concatenated to the prefix  by lemma   and corollary    this produces the cheapest
completion of this prefix  when we perform completion  there is no need to perform the
adjacency or permutation test  if a complete sequence is not minimal  it will never be chosen
as the cheapest prefix  even if it is added to the list of prefixes  it will never be extracted
therefrom  the resulting algorithm is shown in figure   

algorithm  
order s  

let prefix list    prefix    rest s
loop until empty rest 
if independent restjprefix 
then
let completion prefixksort by cn restjprefix 
insert by cost completion  prefix list 
else
loop for subgoal   rest
let extension prefixksubgoal
if adjacency restriction test extension 
and permutation test extension 
then
insert by cost extension  prefix list 
prefix cheapest prefix list 
remove from list prefix  prefix list 
rest snprefix
return prefix

figure    an algorithm for subgoal ordering  incorporating the ideas of earlier researchers 
the advantage of using best first search is that it avoids expanding prefixes whose cost
is higher than the cost of the minimal ordering  the policy used by the algorithm may 
however  be suboptimal or even harmful  it often happens that the best completion of a
cheaper prefix is much more expensive than the best completion of a more expensive prefix 
when the number of solutions is large  it is better to place subgoals with high costs closer
to the beginning of the ordering to reduce the number of times that their cost is multiplied 
for example  let the set be fa x    b x  g  with cost a x          cost b x      nsols a x   
  nsols b x         then a minimal ordering starts with the most expensive prefix 
cost ha x    b x  i                  
  

fithe divide and conquer subgoal ordering algorithm

cost hb x    a x  i                  
if there are many prefixes whose cost is higher than the cost of the minimal ordering  then
best first search saves time  but if the number of such prefixes is small  using best first
search can increase the total time  due to the need to perform insertion of a prefix into a
priority queue  according to its cost 
a sample run of algorithm   will be shown later  in section      

   the divide and conquer subgoal ordering algorithm

algorithm   presented in section     is very ecient  but is applicable only when the entire
set of subgoals is independent  algorithm   can handle a dependent set of subgoals but is
very inecient  algorithm    a combination of the two  can exploit independence of subgoals for better eciency  however  the obtained benefit is quite limited  in this section 
we present the divide and conquer  dac  algorithm  which is able to exploit subgoal independence in a more elaborate way  the algorithm divides the set of subgoals into smaller
subsets  orders these subsets recursively and combines the results 

    divisibility trees of subgoal sets

in this subsection we define a structure that represents all the ways of breaking a subgoal
set into independent parts  our algorithm will work by traversing this structure 
definition  let s and b be sets of subgoals  the divisibility tree of s under b  dtree s   b  
is an and or tree defined as follows 
  leaf s   b 
  s is independent under b
 
 

 
 
dtree s   b      or s   b  fdtree s n fbi g  b   fbi g  j bi   sg    s is indivisible under b
 
  and s   b  fdtree si  b  j si   dpart s   b g    s is divisible under b

each node n in the tree dtree s   b   has an associated set of subgoals s  n    s  and
an associated binding set b n    b   for the root node  s  n     s   b n     b    if the
binding set of the root is not specified explicitly  we assume it to be empty  for and nodes
and or nodes we also define the sets of children 

 if s  n   is independent under b n    then n is a leaf 
 if s  n   is indivisible under b n    then n is an or node  each subgoal bi in s  n  
defines a child node whose set of subgoals is s  n   n fbi g and the binding set is
b n     fbi g  we call bi the binder of the generated child  note that the binding
set of every node in a divisibility tree is the union of the binders of all its indivisible
ancestors and of the root s binding set 

 if s  n   is divisible under b n    then n is an and node  each subset si in the
divisibility partition dpart s  n    b n    defines a child node with associated set of
subgoals si and binding set b n    divisibility partition was defined in section       
  

filedeniov   markovitch

   a  b  c x   d x   e x  
n  s n  
b n     o

s n      a  b 
b n     o

n 

s n      c x   d x   e x  

n  b n     o

s n      d x   e x  
s n      c x   d x  
n 
n  b n      e x  
b n      c x   n 
s n      c x   e x  
b n      d x  

figure    the divisibility tree of fa  b  c x    d x    e x  g under empty initial binding set  the set
associated with node n  is divisible  and is represented by an and node  its children
correspond to its divisibility subsets   one independent  s  n     fa  bg  and one indivisible  s  n     fc x    d x    e x  g  n  is an or node  whose children correspond to its
three subgoals  each subgoal serves as a binder in one of the children   the sets s  n   
s  n    s  n   and s  n   are independent under their respective binding sets  and their
nodes are leaves  here we assumed that the subgoals c x    d x   and e x   bind x as a
result of their proof 

it is easy to show that the divisibility tree of a set of subgoals is unique up to the order of
children of each node  figure   shows the divisibility tree of the set fa  b  c x    d x    e x  g
under empty initial binding set  the associated sets and binding sets are written next to
the nodes 
the following lemma expresses an important property of divisibility trees  subgoals of
each node are independent of the rest of subgoals under the binding set of the node 

lemma   let s  be a set of subgoals  then for every node n in dtree s       for every
subgoal a   s  n    and for every subgoal y   s  n  s  n    b n     a and y are independent
under b n   
proof  by induction on the depth of n in the divisibility tree 
inductive base  n is the root node  s  n s  n   is empty  and no such y exists 
inductive hypothesis  the lemma holds for m   the parent node of n  
inductive step  let a   s  n    y   s  n  s  n     b n     a   s  m    and for m the
lemma holds  thus either a and y are independent under b m    or y   s  m   
if a and y are independent under b m    then they are also independent under b n   
since b m    b n    otherwise  a and y are dependent under b m    and y   s  m   
  

fithe divide and conquer subgoal ordering algorithm

 if m is an and node  and a and y are dependent under b m    then a and
y belong to the same element of dpart s  m    b m     and y   s  n     a

contradiction 
 if m is an or node and y   s  m   n s  n    then y must be the binder of n  
but then b n     b m     fy g and y   b n     a contradiction again 
 
the lemma relates to subgoal independence inside divisibility trees  we shall sometimes
need to argue about independence inside ordered sequences of subgoals  the following
corollary provides the necessary connecting link 

corollary   let s  be a set of subgoals  n be a node in the divisibility tree of s   s  an
ordering of s   s    s   ks    where b n    s   and s  n    s     then s  n   is mutually
independent of s   n s  n   under s   
proof  let a   s  n    y   s   n s  n    a and y are independent under b n    by the
preceding lemma  since b n    s     a and y are independent under s    every subgoal of
s  n   is independent of every subgoal of s   ns  n   under s    therefore  s  n   and s   ns  n  
are mutually independent under s    

 

    valid orderings in divisibility trees

the aim of our ordering algorithm is to find a minimal ordering of a given set of subgoals 
we construct orderings following a divide and conquer policy  larger sets are split into
smaller ones  and orderings of the smaller sets are combined to produce an ordering of the
larger set  to implement this policy  we perform a post order traversal of the divisibility
tree corresponding to the given set of subgoals under an empty initial binding set  when
orderings of child nodes are combined to produce an ordering of the parent node  the inner
order of their subgoals is not changed  smaller orderings are consistent with larger orderings 

definition  let s and g  s be sets of subgoals  an ordering o  g of g and an ordering
o  s of s are consistent  denoted cons o  g  o  s     if the order of subgoals of g in o  g and in
o  s is the same 

the divide and conquer process described above seems analogous to merge sort  knuth 
       there  the set of numbers is split into two  or more  subsets  each subset is independently ordered to a sequence consistent with the global order  and these sequences are
merged  is it possible to use a similar method for subgoal ordering  assume that a set
of subgoals is partitioned into two mutually independent subsets  a and b  can we build
an algorithm that  given a  produces its ordering consistent with a minimal ordering of
a   b  independently of b  unfortunately  the answer is negative  an ordering of a may
be consistent with a minimal ordering of a   b  but at the same time not be consistent
with a minimal ordering of a   b  for some b     b  
for example  let a   fa  x    a  x  g  b    fbg  b    fdg and the control values be as
specified in figure    the single minimal ordering of a   b  is ha  x    b  a  x  i  while the
single minimal ordering of a b  is hd  a  x    a  x  i  there is no ordering of a consistent
with both these minimal global orderings 
  

filedeniov   markovitch

the program 
a  c   
a  c   
a  c   
a  c   
a  c  

b
b
d 

a  x  
d 

a  c   

the control values 
a  x  j  a  x  jfa  x  g a  x  j  a  x  jfa  x  g b d
cost
 
 
 
 
   
nsols
 
 
 
 
   

cost b  a  x    a  x                             
cost b  a  x    a  x                             
cost a  x    b  a  x                             
cost a  x    a  x    b                           
cost a  x    b  a  x                             
cost a  x    a  x    b                           

cost d  a  x    a  x                            
cost d  a  x    a  x                             
cost a  x    d  a  x                             
cost a  x    a  x    d                           
cost a  x    d  a  x                             
cost a  x    a  x    d                           

figure    we show a small program and the control values it defines  then we compute costs of all
permutations of the sets fb  a  x    a  x  g and fd  a  x    a  x  g  different orderings of
fa  x    a  x  g are consistent with minimal orderings of these sets 
since  unlike the case of merge sort  we cannot always identify a single ordering of the
subset consistent with a minimal ordering of the whole set  our algorithm will deal with
sets of candidate orderings  our requirement from such a set is that it contain at least
one local ordering consistent with a global minimal ordering  if such a local ordering exists
  local  ordering is an ordering of the set of the node   global  ordering is an ordering of
the set of the root   such a set will be called valid  the following definition defines valid
sets formally  together with several other concepts 
definition  let s  be a set of subgoals and n be a node in the divisibility tree of s  
recall that   s   denotes the set of all permutations of s  
   o  s     s   is binder consistent with o  n     s  n     denoted bcn  o  n   o  s     if they
are consistent  and all subgoals of b n   appear in o  s before all subgoals of o  n  
bcn  o  n   o  s       o  b    b n      cons o  b ko  n   o  s   
o  s    s   is binder consistent with the node n  denoted bcn  o  s     if it is binderconsistent with some ordering of s  n   
bcn  o  s       o  n    s  n      bcn  o  n   o  s   
   o  n     s  n    is min consistent with o  s     s    denoted mcn s  o  n   o  s     if they
are binder consistent  and o  s is minimal 
mcn s  o  n   o  s      bcn  o  n   o  s     min o  s   s   
o  n    s  n    is min consistent  denoted mcn s  o  n     if it is min consistent with
some ordering of s  
mcn s  o  n       o  s    s     mcn s  o  n   o  s   
 

 

 

 

 

  

fithe divide and conquer subgoal ordering algorithm

   an ordering o  n     s  n    is mc contradicting  if it is not min consistent 
mccn s  o  n       mcn s  o  n   
 

 

   two orderings o     o        s  n    are mc equivalent  if one of them is min consistent
iff the other one is 
mcen s  o     o         mcn s  o        mcn s  o      
 

 

 

   a set of orderings cn    s  n    is valid  if cn contains a min consistent ordering
 when at least one min consistent ordering of s  n   exists  

v alidn s  cn        o  n      s  n      mcn s  o  n         o  n   cn   mcn s  o  n    
 

 

 

an important property of valid sets is that a valid set of orderings of the root of

dtree s      must contain a minimal ordering of s   indeed  in the root s  n     s  
and consistency becomes identity  also  b n        so that binder consistency becomes

consistency  and min consistency becomes minimality  since there always exists a minimal
ordering of s    a valid set of orderings of the root must contain a minimal ordering of s  

    the outline of the divide and conquer algorithm

we propose an algorithm that is based on producing valid sets of orderings  each node in
a divisibility tree produces a valid set for its associated set of subgoals  and passes it to
its parent node  after the valid set of the root node is found  we compare costs of all its
members  and return the cheapest one 
the set of orderings produced by the algorithm for a node n is called a candidate set
of n   its members are called candidate orderings of n   or simply candidates  to find
a candidate set of n   we first consider the set of all possible orderings of s  n   that are
consistent with candidates of n  s children  this set is called the consistency set of n  
given the candidate sets of n  s children  the consistency set of n is defined uniquely  a
candidate set of n is usually not unique 
definition  let n be a node in a divisibility tree of s   the consistency set of n   denoted
consset n    and the candidate set of n   denoted candset n    are defined recursively 

 if n is a leaf  its consistency set contains all permutations of s  n   
consset n      s  n    

 if n is an and node  and its child nodes are n   n        nk   we define the consistency
set of n as the set of all possible orderings of s  n   consistent with candidates of
n   n        nk  

fi
n
o
consset n     o  n    s  n    fifi  i     i  k    o  i   candset ni    cons o  i   o  n    
  

filedeniov   markovitch

 if n is an or node  and its child node corresponding to every binder a   s  n   is

na   then the consistency set of n is obtained by adding binders as the first elements
to the candidates of the children 
fi
n
o
consset n     ako  a fifi a   s  n    o  a   candset na   

 a candidate set of n is any set of orderings produced by removing mc contradicting

and mc equivalent orderings out of the consistency set of n   while keeping at least
one representative for each group of mc equivalent orderings 
candset n    consset n   
 on    consset n   n candset n      mccn s  o  n    
h  
i
 o  n   candset n     mcen s  o  n   o  n     
 

 

 in other words  if some ordering is rejected  it is either mc contradicting  or mcequivalent to some other ordering  which is not rejected  
there are two kinds of orderings which can be removed from consset n   while retaining its validity  mc contradicting and mc equivalent orderings  removal of an mccontradicting ordering cannot change the number of min consistent orderings in the set  if
we remove an mc equivalent ordering  then even if it is min consistent  some other minconsistent ordering is retained in the set  if there exists a min consistent ordering of the set
of the node  then its candidate set must contain a min consistent ordering  and therefore
the candidate set is valid 
note that when our algorithm treats an or node  the binder of each child is always
placed as the first subgoal of the produced ordering of this node  on higher levels the inner
order of subgoals in the ordering does not change  consistency is preserved   therefore 
our algorithm can only produce binder consistent orderings  this explains the choice of
the names  binder  and  binding set   the subgoals of b n   bind some common variables
of s  n    since they stand to the left of them in any global ordering that our algorithm
produces  in particular  if s  n   is independent under b n    then the subgoals of b n  
bind all the shared free variables of s  n   
to implement the dpart function  we can use the union find data structure  cormen 
leiserson    rivest        chapter      where subgoals are elements  and indivisible sets
are groups  in the beginning  every subgoal constitutes a group by itself  whenever we
discover that two subgoals share a free variable not bound by subgoals of the binding set 
we unite their groups into one  to complete the procedure  we need a way to determine
which variables are bound by the given binding set  section     contains a discussion of
this problem and proposes some practical solutions  finally  we collect all the indivisible
subgoals into a separate group  these operations can be implemented in o nff n  n   amortized time  where ff n  n  is the inverse ackermann function  which can be considered o   
for all values of n that can appear in realistic logic programs  thus  the whole process of
finding the divisibility partition of n subgoals can be performed in o n  average time 
the formal listing of the ordering algorithm discussed above is shown in figure    
the algorithm does not specify explicitly how candidate sets are created from consistency sets  to complete this algorithm  we must provide the three filtering procedures
  

fithe divide and conquer subgoal ordering algorithm

algorithm  
order s  

rootcandset

candidateset s      

return the cheapest member of rootcandset

candidateset s   b 
case  s under b 

independent 
let conssetn   s  
let candsetn validleaffilter conssetn  
divisible 
let fs   s         sk g dpart s   b 
loop for i     to k
let ci candidateset
 si   b 
n 
o
let conssetn
on    s  n    j  i          k   o  i   ci   cons o  i  o  n  
let candsetn validandfilter conssetn   fs         sk g  fc         ck g 
indivisible 
loop for a   s
let c  a  candidateset
n      s n foag  b   fag 
 
let c  a 
askoa j oa   c  a 
 
let conssetn
a s c  a 
let candsetn validorfilter conssetn  
return candsetn

figure     the skeleton of the dac ordering algorithm  for each type of node in a divisibility tree 

a consistency set is created and refined through validity filters  the produced candidate
set of the root is valid  hence  its cheapest member is a minimal ordering of the given
set 

  validleaffilter   validandfilter and validorfilter   trivially  we can define them
all as null filters that return the sets they receive unchanged  in this case the candidate
set of every node will contain all the permutations of its subgoals  and will surely be valid 
this will  however  greatly increase the ordering time  our intention is to reduce the sizes
of candidate sets as far as possible  while keeping them valid 
in the following two subsections we discuss the filtering procedures  section     discusses detection of mc contradicting orderings  and section     discusses detection of mcequivalent orderings  finally  in section     we present the complete ordering algorithm 
incorporating the filters into the skeleton of algorithm   
  

filedeniov   markovitch

    detection of mc contradicting orderings

in this subsection we show sucient conditions for an ordering to be mc contradicting 
such orderings can be safely discarded  leaving the set of orderings valid  but reducing its
size  the subsection is divided into three parts  one for each type of node in a divisibility
tree 
      detection of mc contradicting orderings in leaves

the following lemma shows that subgoals in a min consistent ordering of a leaf node must
be sorted by cn 

lemma  
let s  be a set of subgoals  n be a leaf in the divisibility tree of s   let o  n be an ordering of
s  n    if the subgoals of o  n are not sorted by cn under b n    then o  n is mc contradicting 
proof  let o  s be any ordering of s   binder consistent with o  n   we show that o  s cannot
be a minimal ordering of s   thus o  n is not min consistent 
o  n is not sorted by cn  i e   it contains an adjacent cn inverted pair of subgoals ha   a i 

 recall that a pair is cn inverted if the first element has a larger cn value than the second
one   section         since o  s is consistent with o  n   we can write o  s   x  ka  ky  ka kz   
where x    y  and z  are  possibly empty  sequences of subgoals  since o  s is binder consistent
with o  n   b n    x   
if y  is empty  then a  and a  are adjacent in o  s   since b n    x    a  and a  are
independent under x    therefore  the cost of the whole ordered sequence can be reduced
by transposing a  and a    according to lemma    they are adjacent  independent and
cn inverted  
if y  is not empty  then no subgoal of y  belongs to s  n    since otherwise it would appear
in o  n between a  and a    by corollary    y  is mutually independent of both a  and a 
under x   

 if cn y   jx    cn a  jx  then  by lemma    a transposition of y  with a  produces an
ordering with lower cost 
 otherwise  cn y   jx   cn a  jx    since the pair ha   a i is cn inverted  cn a  jx   
cn a  jx    hence  cn y   jx    cn a  jx    and transposition of y  with a  reduces the
cost  by lemma   
in either case  there is a way to reduce the cost of o  s   therefore  o  s cannot be minimal 
and o  n is mc contradicting 
 
      detection of mc contradicting orderings in and nodes

every member of the consistency set of an and node is consistent with some combination
of candidates of its child nodes  if there are k child nodes  and for each child ni the sizes
of subgoal and candidate sets are js  ni j   ni and jcandset ni j   ci   then the total
number of possible consistent orderings is c   c        ck   nn  nn          nnk  k      fortunately  most
of these orderings are mc contradicting and can be discarded from the candidate set  the
 

 

 

  

 

fithe divide and conquer subgoal ordering algorithm

following lemma states that it is forbidden to insert other subgoals between two cn inverted
sub sequences  if such insertion takes place  the ordering is mc contradicting and can be
safely discarded 

lemma  
let s  be a set of subgoals  n a node in the divisibility tree of s    and o  s an ordering of
s   binder consistent with an ordering o  n of s  n   
if o  n contains an adjacent cn inverted pair of sub sequences ha      a   i  a    and a    appear

in o  s not mixed with other subgoals  and a    and a    are not adjacent in o  s   then o  s is
not minimal 

proof  let o  s be such an ordering of s   binder consistent with o  n  
o  s   x  ka   ky  ka   kz   
where y  is not empty  no subgoal of y  belongs to s  n    since otherwise it would stand
in o  n between a    and a      o  s is binder consistent with o  n   therefore  b n    x    by
corollary    y  must be mutually independent of both a    and a    under x    and by lemma  
a transposition of y  with either a    or a    reduces the cost   exactly as in the proof of
lemma   
 

if a pair of adjacent subgoals hai   ai  i is cn inverted  then by the previous lemma any
attempt to insert subgoals inside it results in a non minimal global ordering  thereupon
we may join ai and ai   into a block ai i     which can further participate in a larger block 
the formal recursive definition of a block follows  for convenience  we consider separate
subgoals to be blocks of length   

definition 

   a sub sequence a  of an ordered sequence of subgoals is a block if it is either a single
subgoal  or a    a    ka     where ha     a   i is a cn inverted pair of blocks 
   a block is maximal  max block  if it is not a sub sequence of a larger block 
   let n be a node in a divisibility tree  m be some descendant of n   o  n     s  n   
and o  m     s  m    be two consistent orderings of these nodes  a block a  of o  m is
violated in o  n if there are two adjacent subgoals in a  that are not adjacent in o  n  in
other words  alien subgoals are inserted between the subgoals of the block  
   let n be a node  m be its descendant  o  n     s  n    and o  m     s  m    be two
consistent orderings of these nodes  o  m is called the projection of o  n on m   we
shall usually speak about projection of an ordering on a child node 
the concept of max block is similar to the maximal indivisible block introduced by simon
and kadane        in the context of satisficing search  the following corollary presents the
result of lemma   in a more convenient way 

corollary   let n be a node in a divisibility tree  m be one of its children  o  n be an

ordering of n   and o  m be the projection of o  n on m   if o  m contains a block that is
violated in o  n   then o  n is mc contradicting 
  

filedeniov   markovitch

proof  let a  be the smallest block of o  m violated in o  n   according to the definition
of a block  a    a    ka      where a    and a    are not violated in o  n   and the pair ha     a   i

is cn inverted  let o  s be any ordering of the root node binder consistent with o  n   o  s
violates a    since o  n violates a    to show that o  n is mc contradicting  we must prove that
o  s is not minimal 
 if a   and a    are not violated in o  s   then they are not adjacent in o  s   and o  s is not
minimal  by lemma   
 otherwise  a    or a   is violated in o  s   without loss of generality  let it be a    let a  
be the smallest sub block of a    violated in o  s   according to the definition of a block 
a      a    ka       where the pair ha      a    i is cn inverted  a    and a    are not violated and
not adjacent in o  s   by lemma    o  s is not minimal 
 
for example  if control values of subgoals are as shown in figure    then ha  x    a  x  i
is a block  since cn a  x   j                 cn a  x   jfa  x  g                as one can see from
the figure  insertion of b or d inside this block results in a non minimal ordering 
as was already noted above  the consistency set of an and node can be large  in
many of its orderings  however  blocks of projections are violated  and we can discard
these orderings as mc contradicting  in the remaining orderings  no block of a projection
is violated  and each such ordering can be represented as a sequence of max blocks of the
projections  in each projection  its max blocks stand in cn ascending order  otherwise  there
is an adjacent cn inverted pair of blocks  and a larger block can be formed  which contradicts
their maximality   as the following lemma states  in the parent and node these blocks
must also be ordered by their cn values  otherwise  the ordering is mc contradicting 
lemma   if an ordering of an and node contains an adjacent cn inverted pair of maxblocks of its projections on the children  then this ordering is mc contradicting 
proof  if these blocks are violated in the binder consistent global ordering  the global
ordering is not minimal by corollary    if the blocks are not violated  the proof is similar
to the proof of lemma   
 
the two sucient conditions for detection of mc contradicting orderings expressed in
corollary   and lemma   allow us to reduce the size of the candidate set significantly 
assume  for example  that the set of our current node n is split into two mutually independent subsets whose candidates are ha   a i and hb   b i  one candidate for each child   there
are six possible orderings of s  n    all shown in figure     assume that both ha   a i and
hb   b i are blocks  and cn ha   a i jb n     cn hb   b i jb n    out of six consistent orderings 
four       can be rejected due to block violation  and one of the remaining two  number   
puts the blocks in the wrong order  so  only one ordering  number    can be left in the candidate set of n   even if neither ha   a i nor hb   b i are blocks  lemma   dictates a unique
interleaving of their elements  max blocks   assuming that cn a   jb n      cn a   jb n   fa g
   cn b  jb n      cn b  jb n   fb g 
 

 

      detection of mc contradicting orderings in or nodes

the following lemma states that if a block has a cheaper permutation  then the ordering is
mc contradicting  and can be discarded from the candidate set  
  

fithe divide and conquer subgoal ordering algorithm

  

a  a 

b  b 

  

a  a 

b  b 

  

a  a 

  

b  b 

a  a 

b  b 

  

a  a 

b  b 

  

a  a 

b  b 

figure     the possible ways to combine ha   a  i and hb   b i

lemma   let n be a node in the divisibility tree of s    o  n    s  n     let a  be a leading
block of o  n   o  n   a  kr    if there is a permutation of a    a      such that cost a     jb n    
cost a   jb n    then o  n is mc contradicting 
proof  let o  s    s    be binder consistent with o  n   if a  is violated in o  s   o  s cannot

be minimal  corollary     otherwise  a  occupies a continuous segment in o  s   and its
replacement by a cheaper permutation reduces the cost of the global ordering  lemma    
thus  o  s cannot be minimal 
 
this check should be done only for leading blocks of or nodes 

 every ordering of a leaf node that has not been rejected due to lemma   must be

sorted by cn  consequently  it contains no cn inverted adjacent pair of subgoals  and
no block of size    can be formed 

 every ordering of an and node that has not been rejected due to corollary   or
lemma   must have its blocks unbroken and in cn ascending order  consequently 
new blocks cannot be formed here either 

 in or nodes  new blocks can be formed when we add a binder as the first element of
an ordering  if the cn value of the binder is greater than that of the subsequent block 
all new blocks start from the binder  and we must perform the permutation test only
on the leading max block of an ordering 

    detection of mc equivalent orderings

in the previous subsection we presented sucient conditions for detecting mc contradicting
orderings  in this subsection we specify sucient conditions for identifying mc equivalent
orderings  recall that two orderings of a node are mc equivalent if minimal consistency
of one implies minimal consistency of the other  finding such sucient conditions will
allow us to eliminate orderings without loss of validity of the candidate set  we start
with defining a specialization of the mc equivalence relation  blockwise equivalence  we
then show that orderings whose max blocks are sorted by cn are blockwise equivalent  and
therefore mc equivalent 
  

filedeniov   markovitch

definition  let s  be a set of subgoals and n be a node in the divisibility tree of s   let
o    and o    be two orderings of s  n   with an equal number of max blocks  let o  s be an
ordering of s    binder consistent with o     where blocks of o    are not violated 
o  s joo   is the ordering obtained by replacing in o  s every max block of o    with a max 

block of o     while preserving the order of max blocks  the i th max block of o    is replaced
by the i th max block of o     
o    and o    are blockwise equivalent if the following condition holds  o    is min consistent
with o  s iff o    is min consistent with o  s joo    
as can be easily seen  if two orderings are blockwise equivalent  then they are mcequivalent  now we show that a transposition of adjacent  mutually independent cn equal
max blocks in an ordering of a node produces a blockwise equivalent ordering  the proof
of the following lemma is found in appendix a 
 

 
 

lemma  
let s  be a set of subgoals  n be a node in the divisibility tree of s   o  n   q  ka    ka   kr  be
an ordering of s  n    where a    and a    are max blocks  mutually independent and cn equal
under the bindings of b n     q    then o  n is blockwise equivalent with o  n    q  ka    ka   kr   
corollary   all sorted by cn orderings of a leaf node are blockwise equivalent 
for example  if s  n     fa  b  c  dg  cn a jb n          cn b  jb n     cn c  jb n         
cn d jb n          then the orderings ha  b  c  di and ha  c  b  di are blockwise equivalent 
and we can remove from the candidate set any one of them  but not both  

corollary   all orderings of an and node  where blocks of projections are not violated

and adjacent max blocks from different children projections are cn ordered  are blockwiseequivalent 

  b 
  c    d  are
for example  if the candidates of the children are a  kb  and c  kd    where a 
max blocks  cn a   jb n          cn b   jb n   a    cn c   jb n         and cn d   jb n   c        
then the orderings a  kb  kc  kd  and a  kc  kb  kd  are blockwise equivalent  and we can remove
from the candidate set any one of them  but not both  
to prove both corollaries   and    we note that in each case one of the mentioned
orderings can be obtained from the other by a finite number of transpositions of adjacent 
mutually independent and cn equal max blocks  according to lemma    each such transposition yields a blockwise equivalent ordering  it is easy to show that blockwise equivalence
is transitive 
the following corollary states that subgoals within a block can be permuted  provided
that the cost of the block is not changed 

corollary   all orderings of a node  identical up to cost preserving permutations of subgoals inside blocks  are blockwise equivalent 

the proof of the corollary follows immediately from lemma    for example  if the set
is fa x    b x  g  and the control values are as in the first counter example of proposition   
  

fithe divide and conquer subgoal ordering algorithm

node set
mc contradicting
leaf independent subgoals not sorted by cn
  lemma  
contains violated blocks
and divisible
  corollary  
max blocks not sorted by cn
  lemma  
the leading max block has
or indivisible a cheaper permutation
  lemma  

blockwise equivalent
subgoals sorted by cn
  corollary  
max blocks not violated 
sorted by cn
  corollary  
cost preserving permutations
of blocks
  corollary  

table    summary of sucient conditions for detection of mc contradicting and blockwiseequivalent orderings 

i e  cn a x  j     cn b x  j          and cn a x  jfb x  g    cn b x  jfa x  g       then in both
possible orderings  ha x    b x  i and hb x    a x  i  the two subgoals are united into a block 
and these blocks have equal cost  in any global ordering containing the block ha x    b x  i 
we can replace this block with hb x    a x  i without changing the total cost  therefore
ha x    b x  i is blockwise equivalent to hb x    a x  i 
the sucient condition expressed in corollary   should be checked only in or nodes 
since in leaves and and nodes no new blocks are created  as was argued in section       

    the revised ordering algorithm

in the two preceding subsections we saw several sucient conditions of mc contradiction
and mc equivalence  summarized in table    these results permit us to close the gaps
in algorithm   by providing the necessary validity filters  each filter tests the sucient
conditions of mc contradiction and mc equivalence on every ordering in the consistency
set  if some of these sucient conditions hold  the ordering is rejected  the formal listing
of these procedures is shown in figure    
while the generate and test approach described above served us well for methodological
purposes  it is obviously not practical because of its computational limitations  for example 
for an independent set of size n  the algorithm creates n  orderings  then rejects n     
and keeps only one  this process takes o n   n  time and produces an ordering which
is sorted by cn  the same result could be obtained in just o n log n  time  by a single
sorting  so  instead of uncontrolled creation of orderings and selective rejection  we want to
perform a selective creation of orderings  in other words  we want to revise our algorithm to
deal directly with candidate sets  instead of generating large consistency sets  the revised
algorithm produces the candidate set of a node n as follows 
 if n is a leaf  the subgoals of s  n   are sorted by cn under the bindings of b n    and
the produced ordering is the sole candidate of n  
 if n is an and node  then for each combination of its children s candidates a candidate of n is created  where the max blocks of the children s candidates are ordered
  

filedeniov   markovitch

validleaffilter conssetn  
let candsetn  
loop for o  n   conssetn

if o  n is sorted by cn
and there is no o  n    candsetn which is sorted by cn
then candsetn candsetn   fo  n g
return candsetn

validandfilter conssetn   fs         sk g  fc         ck g 
let candsetn  
loop for o  n   conssetn

loop for i     to k
let o  i be the projection of o  n on si
if  i o  i   ci
and max blocks of o  i  s are not violated in o  n  
and max blocks of o  i  s are ordered by cn in o  n  
and there is no o  n    candsetn consistent with all o  i s 
then candsetn candsetn   fo  n g
return candsetn

validorfilter conssetn  
let candsetn  
loop for o  n   conssetn

if o  n does not start with a block having a cheaper permutation 
and there is no o  n    candsetn   identical to o  n up to
cost preserving permutations in blocks 
then candsetn candsetn   fo  n g
return candsetn

figure     the three filter procedures that convert a consistency set into a candidate set  together
with algorithm    they form a complete ordering algorithm  the eciency of the
algorithm can be improved  as we shall see in algorithm   

by cn  the candidate is produced by merging  moving in parallel on the candidates
of the children and extracting max blocks that are minimal by cn 

 if n is an or node  then for each candidate of its child an ordering of n is created
by adding the binder to the left end of the child candidate  if this results in creation
of a block that has a cheaper permutation  the ordering is rejected  otherwise  it is
added to the candidate set  it suces to check only the leading max block 
  

fithe divide and conquer subgoal ordering algorithm

note that the revised algorithm does not include a test for cost preserving permutations
of blocks in different orderings  expressed in corollary     because of the high expense of
such a test 
the revised algorithm described above contains manipulations of blocks  for this purpose  we need an easy and ecient way to detect blocks in orderings  since we do not
permit block violation  by corollary     we can unite all the subgoals of a max block into
one entity  and treat it as an ordinary subgoal  the procedure of joining subgoals into
blocks is called folding  and the resulting sequence of max blocks   a folded sequence  after
subgoals are folded into a block  there is no need to unfold this block back to separate
subgoals  on upper levels of the tree  these subgoals will again be joined into a block  unless
the block is violated  the unfolding operation is carried out only once before returning the
cheapest ordering of the set  of the root node   the candidate sets of the nodes are now
defined as sets of folded orderings 
as was already stated  new blocks can only be created in the candidates of or nodes 
when the binder is added as the first element of the ordering  if the cn value of the binder
is greater than the cn value of the first max block of the child projection  therefore  in the
revised algorithm we only build new blocks that start from the binder  the max blocks in
the rest of the ordering remain from the child s candidate  first we try to make a block
out of the binder and the first max block of the child s candidate  if they are cn ordered 
we stop the folding  if they are cn inverted  we unite them into a larger block  and try
to unite it with the second max block of the child s candidate  and so on  the produced
folded ordering contains only maximal blocks  the first block is maximal  since we could not
expand it further to the right  and the other blocks are maximal  since they were maximal
in the child s candidate 
lemma   states that an ordering whose leading max block has a cheaper permutation
is mc contradicting  one way to detect such a block is to exhaustively test all its permutations  computing and comparing their costs  this procedure is very expensive  instead 
in our revised algorithm we employ the adjacency restriction test  equation     the test is
applied to every pair of adjacent subgoals of a block  and if some adjacent pair has a cheaper
transposition  then the whole block has a cheaper permutation  by lemma    since blocks
are created by concatenation of smaller blocks  it suces to test the adjacency restriction
only at the points where blocks are joined  for other adjacent pairs of subgoals  the tests
were performed on the lower levels  when smaller blocks were formed   the adjacency restriction test does not guarantee detection of all not cheapest permutations  as was shown
in example     but it detects such blocks in many cases  and works in linear time 
the final version of the dac subgoal ordering algorithm is presented in figure     the
complete correctness proof of algorithm   is found in appendix b 

    sample run and comparison of ordering algorithms
we illustrate the work of the dac algorithm  using the subgoal set shown in figure   
s    fa  b  c x    d x    e x  g  after proving c x    d x   or e x    we can assume that x is
bound  let the control values for the subgoals be as shown in table    the column c free 
contains control values for the subgoal c x   when x is not yet bound by the preceding
subgoals  i e   the binding set does not contain d x   or e x     the column c bound 
  

filedeniov   markovitch

algorithm     the divide and conquer algorithm
order s  
let rootcandset candidateset s      
return unfold the cheapest element of rootcandset 
candidateset s   b 
let fs   s         sk g dpart s   b 
case

 k      shared vars s        s is independent under b  
return fsort by cn s   b g
 k      shared vars s         s is indivisible under b  
loop for a   s
let c  a  candidateset
 s fin fag  b   faog 
n
 
 
let c  a 
fold
 akoa   b  fifi o  a   c  a 
s
return a s c   a 
 k      s is divisible under b  
loop for i     to k
let cin candidateset si   b 
return merge fo     o           o  k g  b 

fifi
o
fi o      c   o      c         o  k   ck

merge fo     o           o  k g  b 

let min cn candidate o  i that minimizes cn first max block o  i   jb      i  k
let min cn block first max block min cn candidate 
remove first max block min cn candidate 
return min cn blockkmerge fo     o           o  k g  b   min cn block 

fold ha   a       ak i  b 
if k    or cn a  jb  cn a  jbka
then return ha   a       ak i

 

else
if the last subgoal of a  and the first subgoal of a  satisfy the adjacency restriction
then
let a  block a    a  
return fold ha    a       ak i  b 
else return  

figure     the revised version of the dac algorithm  the candidate sets are built selectively 

without explicit creation of consistency sets  candidate sets contain folded orderings 
and unfolding is performed only on the returned global ordering  the code of the
unfold and sort by cn procedures is not listed  due to its straightforwardness  the
merging procedure recursively extracts from the given folded orderings max blocks that
are minimal by cn  the folding procedure joins two leading blocks into a larger one  as
long as they are cn inverted 
  

fithe divide and conquer subgoal ordering algorithm

a
b c free  c bound  d free  d bound  e free  e bound 
cost
    
 
 
  
 
  
  
nsols      
 
   
 
 
   
   
cn
             
    
   
 
     
     
table    control values for the sample runs of the ordering algorithms 
contains cost values of c x   when d x   or e x   have already bound x   for example 
cost c x   jfa d x  g   cost c bound        the dac algorithm traverses the divisibility tree
of s  as follows   the names of the nodes are as in figure    
   the root of the divisibility tree  n   has empty binding set b n        and the
associated subgoal set s  n     fa  b  c x    d x    e x  g  the set s  n   is partitioned into two subsets under b n    one independent   fa  bg  and one indivisible  
fc x    d x    e x  g  these two subsets correspond to two child nodes of the andnode n   n  and n   both with empty binding sets 
   s  n   is independent under b n    therefore  n  is a leaf  and its sole candidate
ordering is obtained by sorting its subgoals by cn under b n    cn a j          
cn b j         thus candset n     fha  big 
   s  n   is indivisible under b n    therefore  n  is an or node  and its three children
are created   one for each subgoal of s  n   serving as the binder 

 binder c x   yields the child node n  with the associated set s  n     fd x    e x  g
and the binding set b n     fc x  g  s  n   is independent under b n    there 

fore  n  is a leaf  and its sole candidate is obtained by sorting its subgoals by
cn 
cn d x   jfc x g      cn e x   jfc x  g         
thus  the candidate of n  is he x    d x  i 
 binder d x   yields the child node n  with the associated set s  n     fc x    e x  g
and the binding set b n     fd x  g  s  n   is independent under b n    and its
sorting by cn produces the candidate hc x    e x  i 
 binder e x   yields the child node n  with the associated set s  n     fc x    d x  g
and the binding set b n     fe x  g  s  n   is independent under b n    and its
sorting by cn produces the candidate hc x    d x  i 
   we now add each binder to its corresponding child s candidate and obtain three orderings of the or node n   hc x    e x    d x  i  hd x    c x    e x  i  he x    c x    d x  i 
   we now perform folding of these orderings and check violations of the adjacency
restriction  in order to determine whether a block has a cheaper permutation 
  

filedeniov   markovitch

 first  we perform the folding of hc x    e x    d x  i  the pair hc x    e x  i is
cn inverted  cn c x   j         cn e x   jfc x  g          we thus unite it into a
block  this block does not pass the adjacency restriction test  equation    
cost hc x    e x  i j                   
cost he x    c x  i j                     

therefore  this ordering is mc contradicting and can be discarded 
 we perform the folding of hd x    c x    e x  i  cn d x   j         cn c x   jfd x  g  
      the pair is cn inverted  and we unite it into a block  this block does not
pass the adjacency restriction test 
cost hd x    c x  i j                   
cost hc x    d x  i j                  

this ordering is rejected too  even before its folding is finished  if we continue
the folding process  we shall see that the subgoal e x   must also be added to this
block  since cn hd x    c x  i j                       and cn e x   jhd x   c x  i  
      
 we perform the folding of he x    c x    d x  i  cn e x   j           cn c x   jfe x g
        the pair is cn inverted  and we form a block ec x     he x    c x  i  which
passes the adjacency restriction test 
cost he x    c x  i j                     
cost hc x    e x  i j                   

we compute the control values of the new block 
cost ec x   j                    
nsols ec x   j                  
cn ec x   j                         
cn d x   jfec x  g      thus the pair hec x    d x  i is cn ordered  no more folding
is needed  and we add the folded candidate hec x    d x  i to the candidate set
of n  

   we now perform merging of the candidate set of n   fha  big  with the candidate set
of n   fhec x    d x  ig  in the resulting sequence max blocks must be sorted by cn 

cn a           cn b         cn ec x   j                cn d x   jfec x  g     
the merged ordering  hec x    a  d x    bi  is added to the candidate set of n  
   we compare the costs of all candidates of n   and output the cheapest one  in our case 
there is only one candidate  hec x    a  d x    bi  the algorithm returns this candidate
unfolded  he x    c x    a  d x    bi 
  

fithe divide and conquer subgoal ordering algorithm

extension completion
cost
h ai
  
hbi
 
hc x  i
 
hd x  i
  
he x  i
  
hbi
hb  ai
the adjacency restriction test fails
hb  c x  i
             
hb  d x  i
              
hb  e x  i
the adjacency restriction test fails
hc x  i
hc x    e x    a  d x    bi
                                          
hai
ha  bi
                
ha  c x  i
                
ha  d x  i
                 
ha  e x  i
the adjacency restriction test fails
hd x  i
hd x    c x    e x    a  bi                                              
ha  bi
ha  b  c x  i
                   
ha  b  d x  i
                    
ha  b  e x  i
the adjacency restriction test fails
ha  c x  i
ha  c x    e x    d x    bi
                                      
hb  c x  i
hb  c x    e x    a  d x  i
                                       
ha  d x  i
ha  d x    c x    e x    bi
                                        
he x  i
he x    c x    a  d x    bi                                             
ha  b  c x  i
ha  b  c x    e x    d x  i
                                  
hb  d x  i
hb  d x    c x    e x    ai
                                      
he x    c x    a  d x    bi complete ordering

 

cheapest prefix

table    a trace of a sample run of algorithm   on the set of figure    the left column shows the
cheapest prefix extracted from the list on each step  the middle column   its extensions
or completions that are added to the list  and the right column   their associated costs 

for comparison  we now show how the same task is performed by algorithm    the
algorithm maintains a list of prefixes  sorted by their cost values  and which initially contains
an empty sequence  on each step the algorithm extracts from the list its cheapest element 
and adds to the list the extensions or completions of this prefix  extensions are created when
the set of remaining subgoals is dependent  by appending each of the remaining subgoals
to the end of the prefix  completions are created when the set of remaining subgoals is
independent  by sorting them and appending the entire resulting sequence to the prefix  an
extension is added to the list only when the adjacency restriction test succeeds on its two
last subgoals  to make the list operations faster  we can implement it as a heap structure
 cormen et al         
the trace of algorithm   on the set s  is shown in table    the left column shows the
cheapest prefix extracted from the list on each step  the middle column   its extensions or
completions that are added to the list  and the right column   their associated costs 
it looks as if the dac algorithm orders the given set s  more eciently than algorithm   
we can compare several discrete measurements to show this  for example  algorithm  
  

filedeniov   markovitch

p  x  x  x  x  
p  x  x  x  x  
p  x  x  x  x   
p  x  x  x  x  
p  x  x  x  x   

figure     an example of the worst case for ordering  when all variables are initially free  every

subset of subgoals is indivisible under the binding of the rest of subgoals  and the overall
complexity of ordering by algorithm   is o n   

performs   sorting sessions  each one with   elements  while algorithm   performs   sortings
with   elements  and   sortings with   elements  the adjacency restriction is tested only  
times by algorithm    and    times by algorithm    algorithm   creates totally   different
ordered sub sequences  with total length     while algorithm   creates    ordered prefixes 
with total length    

    complexity analysis

both algorithm   and algorithm   find a minimal ordering  and both sort independent
subsets of subgoals whenever possible  algorithm    however  offers several advantages due
to its divide and conquer strategy 
let n be the number of subgoals in the initial set  for convenience  we assume that
the time of computing the control values for one subgoal is o     otherwise  if this time
is    all the complexities below must be multiplied by    the worst case complexity of
algorithm   is o n    figure    shows an example of such a case for n      in this set
every two subgoals share a variable that does not appear in other subgoals  thus  other
subgoals cannot bind it  the set of the root is indivisible  and no matter which binder is
chosen  the sets of the children are indivisible  so  in each child of the root  we must select
every remaining subgoal as the binder  and so on  the overall complexity of this execution
is o n    this is indeed the worst case complexity  presence of and nodes in the tree can
only reduce it 
note that even when n is small  such a complex rule body with  n    free variables is
very improbable in practical programs  also  the worst case complexity can be reduced
to o n    n    if we move from divisibility trees to divisibility graphs  dags   where all
identical nodes of a divisibility tree  same subgoal set  same binding set  are represented
by a single vertex  the equivalence test of the tree nodes can be performed eciently with
the help of trie structures  aho et al          where subgoals are sorted lexicographically 
let there be n subgoals  with v shared variables appearing in m subgoals  as was
already noted in section      the partition of subgoals into subsets can be performed in
  

fithe divide and conquer subgoal ordering algorithm

o n  average time  using a union find data structure  cormen et al         chapter     

in the worst possible case  there are no and nodes in the divisibility tree  apart from the
root node  whose set is divisible into a dependent set of size m and an independent set of
size n   m   the overall complexity of the dac algorithm in such a case is
t  n  m  v     o n 
  divisibility partition
  o  nq  m  log n   m  
  ordering of independent subgoals
k
  o   i  
ordering of dependent subgoals
q   m   mi    i  log m   k    
  o m q ki  
  folding
    m   i  
  o n  ki  
  merging
where k is the maximal possible number of bindings performed before the remaining subset
is independent  if we assume that every subgoal binds all its free variables  which happens
very frequently in practical logic programs   then k   minfv  m    g  otherwise k   m     
k is equal to the maximal number of or nodes on a path from the root to a leaf of the
divisibility tree  therefore  the height of the divisibility tree is limited by k      actually 
the tree can be shallower  since some binders can bind more than one shared variable each 
this means that the number of shared variables can decrease by more than   in each ornode  below we simplify the above formula for several common cases  when k is small and
when the abovementioned assumption holds  every subgoal binds all its free variables after
its proof terminates  
 if v   m  n  t  n  m  v    o n  mv   n  log n 
 if m  v  n  t  n  m  v    o n  mm     n  log n 
 if v  m   n  t  n  m  v    o nv    log n 
 if m  v   n  t  n  m  v    o n  m    n  log n 
generally  for a small number v of shared variables  the complexity of the algorithm is
roughly bounded by o nv    log n   in particular  if all subgoals are independent  v      
the complexity is o n log n   in most practical cases  the number of shared free variables
in a rule body is relatively small  and every subgoal binds all its free variables  therefore 
the algorithm has polynomial complexity  note that even if a rule body in the program
text contains many free variables  most of them usually become bound after the rule head
unification is performed  i e   before we start the ordering of the instantiated body  

   learning control knowledge for ordering

the ordering algorithms described in the previous sections assume the availability of correct
values of average cost and number of solutions for various predicates under various argument
bindings  in this section we discuss how this control knowledge can be obtained by learning 
instead of static exploration of the program text  debray   lin        etzioni        
we adopt the approach of markovitch and scott        and learn the control knowledge
by collecting statistics on the literals that were proved in the past  this learning can be
performed on line or off line  in the latter case  the ordering system first works with a
training set of queries  while collecting statistics  this training set can be built on the
  

filedeniov   markovitch

distribution of user queries seen in the past  we assume that the distribution of queries
received by the system does not change significantly with time  hence  the past distribution
directs the system to learn relevant knowledge for the future queries 
while proving queries  the learning component accumulates information about the control values  average cost and number of solutions  of various literals  storing a separate
value for each literal is not practical  for two reasons  the first is the large space required
by this approach  the second is the lack of generalization  the ordering algorithm is quite
likely to encounter literals which have not been seen before  and whose control values are
unknown  recall that when we transformed equation   into equation    we moved from
control values of single literals to average control values over sets of literals  to obtain the
precise averages for these sets  we still needed the control values of individual literals  here 
we take a different approach  that of learning and using control values for more general
classes of literals  the estimated cost  nsols  value of a class can be defined as the average
real cost  nsols  value of all examples of this class that were proved in the past 
the more refined the classes  the smaller the variance of real control values inside each
class  the more precise the cost and nsols estimations that the classes assign to their members  and the better orderings we obtain  one easy way to define classes is by modes
or binding patterns  debray   warren        ullman   vardi         for each argument we denote whether it is free or bound  for example  for the predicate father the
possible classes are father free free   father bound free   father free bound  and
father bound bound   now  if we receive a literal  for example  father abraham x   
we can easily determine its binding pattern  in this case  father bound free   and retrieve the control information stored for this class  of course  to find the binding pattern
of a subgoal with a given binding set  we need a method to determine which variables are
bound by the subgoals of the binding set  the same problem arose in dpart computation
 section       we shall discuss some practical ways to solve this problem in section     
for the purpose of class definition we can also use regression trees   a type of decision tree
that classifies to continuous numeric values and not to discrete classes  breiman et al        
quinlan         two separate regression trees can be stored for every program predicate 
one for its cost values  and one for the nsols  the tests in the tree nodes can be defined
in various ways  if we only use the test  is argument i bound    then the classes of literals
defined by regression trees coincide with the classes defined by binding patterns  but we
can also apply more sophisticated tests  both syntactic  e g    is the third argument a term
with functor f    and semantic  e g    is the third argument female     which leads to
more refined classes and better estimations  a possible regression tree for estimating the of
number of solutions for predicate father is shown in figure    
semantic tests about the arguments require logic inference  in the example of figure   
  invoking the predicate female on the first argument of the literal   therefore  they must
be as ecient as possible  otherwise the retrieval of control values will take too much time 
the problem of ecient learning of control values is further considered elsewhere  ledeniov
  markovitch      a  
several researchers applied machine learning techniques for accelerating logic inference
 cohen        dejong   mooney        langley        markovitch   scott        minton 
      mitchell  keller    kedar cabelli        mooney   zelle        prieditis   mostow 
       some of these works used explanation based learning or generalized caching tech  

fithe divide and conquer subgoal ordering algorithm

average        
test  bound arg   

yes

no

average     
test  female arg   

yes
average     

average   
test  bound arg   

no

yes

average     
test  bound arg   

average      

yes

no

average        

average     

no
average    

figure     a regression tree that estimates the number of solutions for father arg  arg   
niques to avoid repeated computation  others utilized the acquired knowledge for the problem of clause selection  none of these works  however  dealt with the problem of subgoal
reordering 

   experimentation
to test the effectiveness of our ordering algorithm  we experimented with it on various
domains  and compared its performance to other ordering algorithms  most experiments
were performed on randomly created artificial domains  we also tested the performance of
the system on several real domains 

    experimental methodology
all experiments described below consist of a training session  followed by a testing session 
training and testing sets of queries are randomly drawn from a fixed distribution  in the
training session we collect the control knowledge for literal classes  in the testing session we
prove the queries of the testing set using different ordering algorithms  and compare their
performance using various measurements 
the goal of ordering is to reduce the time spent by the prolog interpreter when it
proves queries of the testing set  this time is the sum of the time spent by the ordering
procedure  ordering time  and the time spent by the interpreter  inference time   since the
cpu time is known to be very sensitive to irrelevant factors such as hardware  software
and programming quality  we also show two alternative discrete measurements  the total
number of clause unifications  and the total number of clause reductions performed  the
number of reductions reects the size of the proof tree 
for experimentation we used a new version of the lassy system  markovitch   scott 
       using regression trees for learning  and the ordering algorithms discussed in this
paper 
  

filedeniov   markovitch

    experiments with artificial domains

in order to ensure the statistical significance of the results of comparing different ordering
algorithms  we experimented with many different domains  for this purpose  we created a
set of     artificial domains  each with a small fixed set of predicates  but with a random
number of clauses in each predicate  and with random rule lengths  predicates in the
rule bodies  and arguments in both rule heads and bodies are randomly drawn from fixed
distributions  each domain has its own training and testing sets  these two sets do not
intersect  
the more training examples are fed into the system on the learning phase  the better
estimations of control values it produces  on the other hand  the learning time must be limited  because after seeing a certain number of training examples  new examples do not bring
much new information  and additional learning becomes wasteful  we have experimentally
built a learning curve which shows the dependence of the quality of the control knowledge
on the amount of training  the curve suggests that after control values were learned for
approximately     literals  there is no significant improvement in the quality of ordering
with new training examples  therefore  in the subsequent experiments we stopped training
after     cost values were learned  the training time was always small  one learned cost
value corresponds to a complete proof of a literal  thus  if every predicate in a program has
four clauses that define it  then     cost values are learned after      unifications  which is
a very small time 
the control values were learned by means of regression trees  section     with simple
syntactic tests that only checked whether some argument is bound or whether some argument is a term with a certain functor  the list of functors was created automatically when
the domain was loaded   however  as we shall see  even these simple tests succeeded in
making good estimations of control values 
we tested the following ordering methods 
 random  the subgoals are permuted randomly and the control knowledge is not
used 
 algorithm    building ordered prefixes  out of all prefixes that are permutation of
one another  only the cheapest one is retained 
 algorithm  a  as algorithm    but with best first search method used to define the
next processed prefix  a similar algorithm was used in the lassy system of markovitch
and scott        
 algorithm  b  as algorithm  a  but with adjacency restriction test added  a
similar algorithm was described by smith and genesereth        
 algorithm    as algorithm  b  but whenever all the subgoals that are not in the
prefix are independent  under the binding of the prefix   they are sorted and the result
is appended to the prefix as one unit 
 algorithm    the dac algorithm 
in our experiments we always used the bubble sort algorithm to sort literals in independent sets  this algorithm is easy to implement  and it is known to be ecient for small
  

fithe divide and conquer subgoal ordering algorithm

ordering
method
random
algorithm  
algorithm   a
algorithm   b
algorithm  
algorithm  

unifications reductions ordering inference total ord time
time
time time reductions
        
        
      
                     
       
              
                  
       
              
                  
       
              
                  
       
      
      
                 
       
      
      
                  

table    the effect of ordering on the tree sizes and the cpu time  mean results over     artificial
domains  

sets  when the elements are already ordered  or nearly ordered  in practice  programmers
order most program rules optimally  and the sorting stops early 
since the non deterministic nature of the random method introduces additional noise 
we performed on each artificial domain    experiments with this method  and the table
presents the average values of these measurements 
table   shows the obtained results over     domains  the rows correspond to the ordering
methods used  and the columns to the measurements taken  the rightmost column shows
the ratio of the ordering time and the number of reductions performed  which reects the
average ordering time of one rule body  the inference time was not measured separately 
but was set as the difference of the total time and the ordering time 
several observations can be made 
   using the dac ordering algorithm helps to reduce the total time of proving the testing
set of queries by a factor of     compared to the random ordering  the inference time
is reduced by a factor of    
   all deterministic ordering methods have similar number of unifications and reductions 
and similar inference time  which is predictable  since they all find minimal orderings 
small uctuations of these values can be explained by the fact that some rules have
several minimal orderings under the existing control knowledge  and different ordering
algorithms select different minimal orderings  since the control knowledge is not
absolutely precise  the real execution costs of these orderings may be different  which
leads to the differences  the random ordering method builds much larger trees  with
larger inference time 
   when we compare the performance of the deterministic algorithms          we see
that the dac algorithm performs much better than the algorithms that build ordered
prefixes  in the latter ones  the ordering is expensive  and smaller inference time
cannot compensate for the increase in ordering time  only algorithm    a combination
of several ideas of previous researchers  has total time comparable with the time of
the random method  though still greater  
  

filedeniov   markovitch

   it may seem strange that the simple random ordering method has larger ordering time
than the sophisticated algorithm    to explain this  note that the random method
creates much larger proof trees  on average   therefore the number of ordered rules
increases  and even the cheap operations  like random ordering of a rule  sum up to
a considerable time  the average time spent on ordering of one rule is shown in the
last column of table    this value is very small in the random method 

    experiments with real domains

we tested our ordering algorithm also on real domains obtained from various sources  these
domains allow us to compare orderings performed by our algorithm with orderings performed by human programmers 
the following domains were used 
 moral reasoner  taken from the machine learning repository at the university
of california  irvine    the domain qualitatively simulates moral reasoning  whether
a person can be considered guilty  given various aspects of his character and of the
crime performed 
 depth first planner  program       from the book  the art of prolog   sterling
  shapiro         the program implements a simple planner for the blocks world 
 biblical family database  a database similar to that described in example   
 appletalk  a domain describing the physical layout of a local computer network
 markovitch        
 benchmark  a prolog benchmark taken from the cmu artificial intelligence repository   the predicate names are not informative  it is an example of a program where
manual ordering is dicult 
 slow reverse  another benchmark program from the same source 
 geography  also a benchmark program from the cmu repository  the domain
contains many geographical facts about countries 
table   shows the results obtained  for ordering we used the dac algorithm  with literal
classes defined by binding patterns  it can be seen that the dac algorithm was able to speed
up the logic inference in real domains as well  note that in the slow reverse domain the
programmer s ordering was already optimal  thus  applying the ordering algorithm did not
reduce the tree sizes  still  the overhead of the ordering is not significant 

   discussion

in this concluding section we discuss several issues concerning the practical implementation
of the dac algorithm and several ways to increase its eciency  then we survey some
related areas of logic programming and propose the use of the dac algorithm there 
   url  http   www ics uci edu  mlearn mlrepository html
   url  http   www cs cmu edu afs cs cmu edu project ai repository ai html air html

  

fithe divide and conquer subgoal ordering algorithm

domain

without ordering
with ordering
gain ratio
unifications seconds unifications seconds  time time 
moral reasoner
            
           
   
depth first planner
           
          
    
biblical family
             
            
   
appletalk
               
             
   
benchmark
            
            
   
slow reverse
          
          
   
geography
             
            
   
table    experiments on real domains 

    practical issues

in this subsection we would like to address several issues related to implementation and
applications of the dac algorithm 
the computation of the dpart function  section        requires a procedure for computing the set of variables bound by a given binding set of subgoals  the same procedure
is needed for computing control values  section     there are several possible ways to
implement such a procedure  for example 
   the easiest way is to assume that every subgoal binds all the variables appearing in its
arguments  this simplistic assumption is sucient for many domains  especially the
database oriented ones  however  it is not appropriate when logic programs are used
to manipulate complex data structures containing free variables  such as difference
lists   this assumption was used for the experiments described in section   
   some dialects of prolog and other logic languages support mode declarations provided
by the user  somogyi et al       b   when such declarations are available  it is easy
to infer the binding status of each variable upon exiting a subgoal 
   even when the user did not supply enough mode declarations  they can often be
inferred from the structure of the program by means of static analysis  debray  
warren         note  however  that as was pointed out by somogyi et al       b  
no one has yet demonstrated a mode inference algorithm that is guaranteed to find
accurate mode information for every predicate in the program 
   we can learn the sets of variables bound by classes of subgoals using methods similar
to those described in section   for learning control values 
several researchers advocate user declarations of available  permitted  modes  such
declarations can be elegantly incorporated into our algorithm to prune branches that violate
available modes  when we fix a binder in an or node  we compute the set of variables
that become bound by it  if this results in a violation of an available mode for one of the
subgoals of the corresponding child  then the whole subtree of this child is pruned  note
that we can detect violations even when the mode of the subgoal is partially unknown
  

filedeniov   markovitch

candidateset s   b 
let fs   s         sk g dpart s   b 
case

   
 k      shared vars s         s is indivisible under b  
loop for a   s
if b   fag does not violate available modes
in any subgoal of s n fag
then
let c  a  candidateset
 s fin fag  b   faog 
n
 
let c  a 
fold ako  a  b  fifi o  a   c  a 
else let
c   a     don t enter the branch 
s
return a s c    a 

figure     changes to algorithm   that make use of available mode declarations 
the rest of the algorithm remains unchanged 

at the moment  for example  if all the available modes require that the first argument
be unbound  then binding of the argument by the or node binder will trigger pruning 
even if the binding status of the other arguments is not yet known  figure    shows how
algorithm   can be changed in order to incorporate declarations of available modes  any
other correctness requirement can be treated in a similar manner  a candidate ordering will
be rejected whenever we see that it violates the requirement 
the experiments described in section   were performed with a prolog interpreter  is
it possible to combine the dac algorithm with a prolog compiler  there are several ways
to achieve this goal  one way is to allow the compiler to insert code for on line learning 
the compiled code will contain procedures for accumulating control values and for the dac
algorithm  alternatively  off line learning can be implemented  with training as a part of
the compilation process 
another method for combining our algorithm with existing prolog compilers is to use
it for program transformation  and to process the transformed program by a standard
compiler  elsewhere  ledeniov   markovitch      a  we describe the method for classifying
the orderings produced by the dac algorithm  for each rule we build a classification tree 
where classes are the different orderings of the rule body  and the tests are applied to the
rule head arguments  these are the same type of tests described in section   for learning
control values  figure    shows two examples of such trees 
given such a classification tree  we can write a set of prolog rules  where each rule has
the same head as the original rule  and has a body built of all the tests on the path from
the tree root to a leaf node followed by the ordering at the leaf  for example  the second
tree in figure    yields the following set of rules 
  

fithe divide and conquer subgoal ordering algorithm

a classification tree for the rule
uncle x y  of example   

nonvar y   
yes

no

 parent z y  brother z x  
 brother z x  parent z y  
nonvar x   
yes

a possible classification tree for the rule
head x y 

male x   

p  x   p  y   p  x y  

yes
 p  x  p  x y  p  y  

no

nonvar y   

no

yes

no

 p  y  p  x y  p  x  

 p  x  p  y  p  x y  

 p  x y  p  x  p  y  

figure     examples of classification trees that learn rule body orderings 

head x y 
head x y 
head x y 
head x y 

nonvar x   male x   p  x   p  x y   p  y  
nonvar x   not male x    p  x   p  y   p  x y  
var x   nonvar y   p  y   p  x y   p  x  
var x   var y   p  x y   p  x   p  y  

from table   we can see that while the dac algorithm helped to reduce the inference
time by a factor of     the total time was reduced only by a factor of     this difference
is caused by the additional computation of the ordering procedure  there is a danger that
the benefit obtained by ordering will be outweighed by the cost of the ordering process 
this is a manifestation of the so called utility problem  minton        markovitch   scott 
       in systems that are strongly moded  such as mercury   somogyi et al       b  we can
employ the dac algorithm statically at compilation time for each one of the available modes 
thus reducing the run time ordering time to zero  the mode based approach performs only
syntactic tests of the subgoal arguments  the classification tree method  described above 
is a generalization of the mode based approach  allowing semantic tests as well 
due to insucient learning experience or lack of meaningful semantic tests  it is quite
possible that the classification trees contain leaves with large degrees of error  in such cases
we still need to perform the ordering dynamically  to reduce the harmfulness of the utility
problem in the case of dynamic ordering  we can use a cost sensitive variation of the dac
algorithm  ledeniov   markovitch      a      b   this modified algorithm deals with the
problem by explicit reasoning about the economy of the control process  the algorithm is
anytime  that is  it can be stopped at any moment and return its currently best ordering
 boddy   dean         we learn a resource investment function to compute the expected
return in speedup time for additional control time  this function is used to determine a
stopping condition for the anytime procedure  we have implemented this framework and
found that indeed we have succeeded in reducing ordering time  without significant increase
of inference time 
  

filedeniov   markovitch

    relationship to other works

the work described in this paper is a continuation of the line of research initiated by smith
and genesereth        and continued by natarajan        and markovitch and scott        
this line of research aims at finding the most ecient ordering of a set of subgoals  the
search for minimal cost ordering is based on cost analysis that utilizes available information
about the cost and number of solutions of individual subgoals 
smith and genesereth        performed an exhaustive search over the space of all
permutations of the given set of subgoals  using the adjacency restriction to reduce the
size of the search space  equation     this restriction was applied on pairs of adjacent
subgoals in the global ordering of the entire set  when applied to an independent set of
subgoals  the adjacency restriction is easily transformed into the sorting restriction  the
subgoals in a minimal ordering must be sorted by their cn values  natarajan        arrived
at this conclusion and presented an ecient ordering algorithm for independent sets 
the dac algorithm uses subgoal dependence to break the set into smaller subsets  independent subsets are sorted  dependent subsets are recursively ordered  and the resulting
orderings are merged using a generalization of the adjacency restriction that manipulates
blocks of subgoals  therefore the dac algorithm is a generalization of both algorithms 
during the last decade  a significant research effort went into static analysis  sa  of
logic programs  there are three types of sa that can be exploited by the dac algorithm to
reduce the ordering time 
a major part of the sa research deals with program termination  de schreye   decorte 
       the dac algorithm solves the termination problem  as a special case of the eciency
problem  it always finds a terminating ordering  if such orderings exist   during learning 
we set limits on the computation resources available for subgoal execution  if a subgoal is
non terminating  in a certain mode   the learning module will associate a very high cost
with this particular mode  consequently  the dac algorithm will not allow orderings with
this mode of the subgoal  nevertheless  while the use of static termination analysis is
not mandatory for a proper operation of the dac algorithm  we can exploit such analysis
to increase the eciency of both the learning process and the ordering process  during
learning  the limit that we set on the computation resources devoted to the execution of
a subgoal must be high  to increase the reliability of the cost estimation  however  such
a high limit can lead to a significant increase in learning time when many subgoals are
non terminating  if termination information obtained by sa is available  we can use it to
avoid entering infinite branches of proof trees  during ordering  termination information can
serve to reduce the size of space of orderings searched by the algorithm  if the termination
information comes in the form of allowed modes  somogyi et al       b   orderings that
violate these modes are filtered out  as in the modified algorithm shown in figure     if the
termination information comes in the form of a partial order between subgoals  orderings
that violate this partial order can be filtered out in a similar manner 
the second type of sa research that can be combined with the dac algorithm is correctness analysis  where the program is tested against specifications given by the user 
the folon environment  henrard   le charlier        was designed to support the
methodology for logic program construction that aims at reconciling the declarative semantics with an ecient implementation  deville         the construction process starts with
  

fithe divide and conquer subgoal ordering algorithm

a specification  converts it into a logic description and finally  into a prolog program  if
the rules of the program are not correct with respect to the initial specification  the system performs transformations such as reordering literals in a clause  adding type checking
literals and so on  de boeck and le charlier        mention this reordering  but do not
specify an ordering algorithm different from the simple generate and test method  cortesi 
le charlier  and rossi        present an analyzer for verifying the correctness of a prolog
program relative to a specification which provides a list of input output annotations for the
arguments and parameters that can be used to establish program termination  again  no
ordering algorithm is given explicitly  the purpose of the dac algorithm is complementary
to the purpose of folon  and it could serve as an auxiliary aid to make the resulting prolog
program more ecient 
recently  the mercury language was developed at the university of melbourne  somogyi
et al       a      b   mercury is a strongly typed and strongly moded language  type and
mode declarations should be supplied by the programmer  though recent releases of the
mercury system already support partial inference of types and modes   somogyi et al  
    a   the compiler checks that mode declarations for all predicates are satisfied  if
necessary  it reorders subgoals in the rule body to ensure mode correctness  and rejects the
program if neither ordering satisfies the mode declaration constraints   when the compiler
performs this reordering  it does not consider the eciency issue  it often happens that
several orderings of a rule body satisfy the mode declaration constraints  in such cases
the mercury compiler could call the static version of the dac algorithm to select the most
ecient ordering  another alternative is to augment the dac algorithm by mode declaration
checks  as was shown in figure    
note that mercury is a purely declarative logic programming language  and is therefore
more suitable for subgoal reordering than prolog  it has no non logical constructs that
could destroy the declarative semantics which give logic programs their power  in mercury
even i o is declarative 
the third type of relevant sa is the cost analysis of logic programs  debray   lin 
      braem et al         debray et al          cortesi et al         describe a cost formula
similar to equation   to select a lowest cost ordering  however  they used a generate andtest approach which can sometimes be prohibitively expensive  static analysis of cost and
number of solutions can be used to obtain the control values  instead of learning them 
the eciency of logic programs can also be increased by methods of program transformation  pettorossi   proietti               one of the most popular approaches is the
 rules strategies  approach  which consists in starting from an initial program and then
applying one or more elementary transformation rules  transformation strategies are metarules which prescribe suitable sequences of applications of transformation rules 
one of the possible transformation rules is the goal rearrangement rule which transforms
a program by transposing two adjacent subgoals in a rule body  obviously  any ordering
of a rule body can be transformed into any other ordering by a finite number of such
transpositions  thus  static subgoal ordering can be considered a special case of program
transformation where only the goal rearrangement rule is used  on the other hand  dynamic
and semi dynamic ordering methods cannot be represented by simple transformation rules 
since they make use of run time information  expressed in bindings that rule body subgoals
  

filedeniov   markovitch

obtain through unifications of rule heads   and may order the same rule body differently
under different circumstances 
a program transformation technique called compiling control  bruynooghe  de schreye 
  krekels        pettorossi   proietti        follows an approach different from that of
trying to improve the control strategy of logic programs  instead of enhancing the naive
prolog evaluator using a better  and often more complex  computation rule  the program is
transformed so that the derived program behaves under the naive evaluator exactly as the
initial program would behave under an enhanced evaluator  most forms of compiling control
first translate the initial program into some standard representation  for example  into an
unfolding tree   while the complex computation rule is used  and then the new program is
constructed from this representation  with the naive computation rule in mind 
reordering of rule body subgoals can be regarded as moving to a complex computation
rule which selects subgoals in the order dictated by the ordering algorithm  in the case of
the dac algorithm  this computation rule may be too complex for simple use of compiling
control methods  nevertheless  it can be easily incorporated into a special compiling control
method  in section     we described a method of program rewriting which first builds
classification trees based on the orderings that were performed in the past  and then uses
these classification trees for constructing clauses of a derived program  the derived program
can be eciently executed under the naive computation rule of prolog  this technique is
in fact a kind of compiling control  its important property is the use of knowledge collected
from experience  the orderings that were made in the past  
one transformation method that can significantly benefit from the dac algorithm is
unfolding  tamaki   sato         during the unfolding process subgoals are replaced by
their associated rule bodies  even if the initial rules were ordered optimally by a human
programmer or a static ordering procedure  the resulting combined sequence may be far from
optimal  therefore it could be very advantageous to use the dac algorithm for reordering
of the unfolded rule  as the rules become longer  the potential benefit of ordering grows 
the danger of high complexity of the ordering procedure can be overcome by using the
cost sensitive version of the dac algorithm  section      

    conclusions
in this work we study the problem of subgoal ordering in logic programs  we present both a
theoretical base and a practical implementation of the ideas  and show empirical results that
confirm our theoretical predictions  we combine the ideas of smith and genesereth        
simon and kadane        and natarajan        into a novel algorithm for ordering of
conjunctive goals  the algorithm is aimed at minimizing the time which the logic interpreter
spends on the proof of the given conjunctive goal 
the main algorithm described in this paper is the dac algorithm  algorithm    section       it works by dividing the sets of subgoals into smaller sets  producing candidate
sets of orderings for the smaller sets  and combining these candidate sets to obtain orderings
of the larger sets  we prove that the algorithm finds a minimal ordering of the given set
of subgoals  and we show its eciency under practical assumptions  the algorithm can
be employed statically  to reorder rule bodies in the program text before the execution
  

fithe divide and conquer subgoal ordering algorithm

starts   semi dynamically  to reorder the rule body before the reduction is performed  or
dynamically  to reorder the resolvent after every reduction of a subgoal by a rule body  
several researchers  minker        warren        naish      a      b  nie   plaisted 
      proposed various heuristics for subgoal ordering  though fast  these methods do
not guarantee finding minimal cost orderings  our algorithm provably finds a minimal cost
ordering  though the ordering itself may take more time than with the heuristic methods  in
the future it seems promising to incorporate heuristics into the dac algorithm  for example 
heuristics can be used to grade binders in or nodes  rather than exhaustively trying all
subgoals as binders  we could try just one  or several binders  thus reducing the ordering
time  also  the current version of our ordering algorithm is suitable only for finding all
solutions to a conjunctive goal  we would like to extend it to the problem of finding one
solution  or a fixed number of solutions 
another interesting issue for further research is the adaptation of the dac algorithm to
interleaving ordering methods  section       there  if subgoals of a rule body are added
to an ordered resolvent  it seems wasteful to start a complete ordering process  we should
use the information stored in the existing ordering of the resolvent  perhaps the whole
divisibility tree of the resolvent should be stored  and its nodes updated when subgoals of
a rule body are added to the resolvent 
the ordering algorithm needs control knowledge for its work  this control knowledge is
the average cost and number of solutions of literals  and it can be learned by training and
collecting statistics  we make an assumption that the distribution of queries received by
the system does not change with time  thus  if the training set is based on the distribution
seen in the past  the system learns relevant knowledge for future queries  we consider the
issue of learning control values more thoroughly in another paper  ledeniov   markovitch 
    a   together with other issues concerning the dac algorithm  such as minimizing the
total time  instead of minimizing the inference time only  
ullman and vardi        showed that the problem of ordering subgoals to obtain termination is inherently exponential in time  the problem we work with is substantially
harder  we must not only find an order whose execution terminates in finite time  but one
that terminates in minimal finite time  it is impossible to find an ecient algorithm for
all cases  the dac algorithm  however  is ecient in most practical cases  when the graph
representing the subgoal dependence  figure    is sparsely connected 
we have implemented the dac algorithm and tested it on artificial and real domains 
the experiments show a speedup factor of up to    compared with random ordering  and
up to    compared with some alternative ordering algorithms 
the dac algorithm can be useful for many practical applications  formal hardware
verification has become extremely important in the semiconductor industry  while model
checking is currently the most widely used technique  it is generally agreed that coping with
the increasing complexity of vlsi design requires methods based on theorem proving  the
main obstacle preventing the use of automatic theorem proving is its high computational
demands  the dac algorithm may be used for speeding up logic inference  making the use
of automatic theorem provers more practical 
logic has gained increasing popularity for representation of common sense knowledge 
it has several advantages  including exibility and well understood semantics  indeed  the
cyc project  lenat        has recently moved from frame based representation to logic  

filedeniov   markovitch

based representation  however  the large scale of such knowledge bases is likely to present
significant eciency problems to the inference engines  using automatic subgoal ordering
techniques  such as those described here  may help to solve these problems 
the issue of subgoal ordering obtains a new significance with the development of inductive logic programming  lavrac   dzeroski        muggleton   de raedt         systems
using this approach  such as foil  quinlan   cameron jones         try to build correct
programs as fast as possible  without considering the eciency of the produced programs 
combining the dac algorithm with inductive logic programming and other techniques for
the synthesis of logic programs  such as the deductive and the constructive approaches 
looks like a promising direction 

appendix a  proof of lemma  

in this appendix we present the proof of a lemma which was omitted from the main text of
the paper for reasons of compactness  before we prove it we show two auxiliary lemmas 

lemma  

let a    and a    be two ordered sequences of subgoals  and b a set of subgoals  the value of
cn a   ka   jb lies between the values cn a    jb and cn a    jb a   
 

proof 

denote c    cost a    jb
n    nsols a   jb
cn    cn a   jb
c    cost a    jb a  n    nsols a   jb a  cn    cn a   jb  a 
c      cost a   ka    jb n      nsols a   ka     jb cn      cn a    ka    jb
cn   n          n  n         n         n   n        
 

   

 

 

c   

c   
c   
n
n
    
    
c
 n c
    c  c     c    c  cn   c n  c cn    cc   cn    nc  c   cn 
   
   
   
   
n
c
  c 
 
so  cn    always lies between cn  and cn   because c    and c    are positive and
to     more exactly  the point cn    divides the segment  cn   cn   with ratio

sum

 cn      cn       cn    cn        n  c    c  

in other words  cn    is a weighted average of cn  and cn    note that c  is the amount
of resources spent in the proof tree of b      n  c    the resources spent in the tree of b      and
c    is their sum  so  the more time  relatively  we dedicate to the proof of b      the closer
cn    is to cn   this conclusion can be generalized to a larger number of components in a
concatenation  the proof is by induction  
cost a     jb
cn a    ka    k       a  k  jb  
 cn a     jb  
cost a    ka    k       a  k  jb
nsols a     jb  cost a     jb a   
 
 cn a     jb a             
cost a    ka   k       a  k  jb
nsols a    ka    k       a  k   jb  cost a  k  jb a        a  k  
 
 cn a  k  jb a        a  k  
cost a   ka    k       a  k  jb
  

fithe divide and conquer subgoal ordering algorithm

 

lemma   
let s  be a set of subgoals and n be a node in the divisibility tree of s   let o  n  
q  ka   ka   kr  be an ordering of s  n    where a    and a    are cn equal max blocks  cn a     jb n   q   
cn a    jb n   q   a   
let m be an ancestor of n and o  m be an ordering of s  m   consistent with o  n   where
 

a    and a    are not violated  then either a    and a    are both max blocks in o  m and all
max blocks that stand between them are cn equal to them  or a    and a    belong to the same
max block in o  m   or o  m is mc contradicting 
proof  by induction on the distance between n and m   if m   n   then a   and a  
are max blocks  and the lemma holds  let m    n   and let m   be the child of m whose
  be the
descendant is n   by inductive hypothesis  the lemma holds for n and m     let o  m
 
 
 
 
 
 
projection of om on m   a  and a  are not violated in om   since they are not violated in
o  m  
 if a    and a   are both max blocks in o  m    then by the inductive hypothesis all maxblocks that stand between them are cn equal to them  if m is an or node  no new
subgoals can enter between a    and a      if m is an and node  the insertion of new

subgoals is possible  but if it violates blocks  or places max blocks not ordered by cn 
then o  m is mc contradicting  by corollary   or lemma    so  if o  m is not mccontradicting  then all new max blocks inserted between a    and a    must be cn equal
to them both 
assume that a    and a    are not both max blocks in o  m   without loss of generality 
let a    be member of a larger max block in o  m   we show that a    must also participate
in the same max block 
since a    joined a larger block  there must exist another block  b    adjacent to a    
such that their pair is cn inverted  let b  stand to the left of a     in the opposite case 
  a   i is cn inverted  i e  
the proof is similar   o  m   x  kb  ka   ky  ka    kz    the pair hb 
 
 
 
 
cn b  jb m   x    cn a  jb m   x   b    from lemma    cn b ka  jb m   x    cn a    jb m   x   b   
and we must add to the block b  ka    all blocks from y    because they are all cn equal
to a      also  cn a    jb m   x   b    cn a     jb m   x   b   a    and a    must also be added
to the block  thus  a    and a    belong to the same max block in o  m  
 if a   and a    belong to the same max block in o  m    then this block is either violated
in o  m   or not  in the former case  o  m is mc contradicting  by corollary    in the
latter case  a    and a    belong to the same max block in o  m  
 if o  m  is mc contradicting  then o  m is mc contradicting too  the proof is easy    
 

now we can prove lemma   

lemma  
let s  be a set of subgoals  n be a node in the divisibility tree of s  and o  n   q  ka    ka   kr 
  

filedeniov   markovitch

be an ordering of s  n    where a    and a    are max blocks  mutually independent and
cn equal under the bindings of b n     q    then o  n is blockwise equivalent with o  n   
q  ka   ka   kr   

proof 

let s  be a minimal ordering of s  binder consistent with o  n   by corollary    s  does not
  
violate the blocks of o  n   in particular a    and a      s    x  ka   ky  ka    kz    let s      s  joo  nn  
x  ka    ky  ka    kz    we must show that s    is minimal  which implies blockwise equivalence of
o  n and o  n   
if y  is empty  then cost s      cost s      by lemma    a    and a    are adjacent  mutually
independent and cn equal  thus  their transposition does not change the cost  
if y  is not empty  then by corollary   y  is mutually independent of both a    and a   
 s  is binder consistent with o  n   therefore b n    x    and consequently y    b n        
y  can be divided into several blocks  each one of them cn equal to a    and a     since s 
is minimal  o  n cannot be mc contradicting  and the claim follows from lemma     by
lemma    cn y   jx    cn a     jx    cn a    jx    by lemma   

cost s      cost x  ka   ky  ka   kz   
  cost x  ka   ka    ky  kz   
  cost x  ka   ka    ky  kz   
  cost x  ka   ky  ka   kz   

 
 
 
 

   swap y  a  
   swap a   a   
   swap a   y  
cost s     

minimality of s    implies blockwise equivalence of o  n and o  n   

 

appendix b  correctness of the dac algorithm

in this section we show that the dac algorithm is correct  i e   given a set of subgoals s  
it returns its minimal ordering  it suces to show that the candidate set of the root node
of dtree s      is valid  in such a case  as follows from the definition of valid sets  it must
contain a minimal ordering  the algorithm returns one of the cheapest candidates of the
root  therefore  if the candidate set of the root is valid  the dac algorithm must return a
minimal ordering of s  
we start by defining strong validity of sets of orderings  we then prove that strong
validity implies validity  finally  we use induction to prove a theorem  showing that the
candidate set produced for each node in the divisibility tree is strongly valid 
definition  let s  be a set of subgoals  n be a node in the divisibility tree of s   the set
cn   s  n    is strongly valid  if every ordering in  s  n    ncn is either mc contradicting
or blockwise equivalent to some member of cn   unless no ordering of s  n   is min consistent 

stronglyv alidn s  cn     
  o  n      s  n      mcn s  o  n        o  n     s  n    n cn   mccn s  o  n   
  o  n     cn   mcen s  o  n   o  n      
 

 

 

 

lemma    a strongly valid set of orderings is valid 
  

fithe divide and conquer subgoal ordering algorithm

proof  let s  be a set of subgoals  n be a node in the divisibility tree of s   c  n   be a
strongly valid set of orderings of n  
if there is no min consistent ordering of n   then c  n   is valid  by the definition of a
valid set  section      
otherwise  there exists at least one minimal ordering of s   binder consistent with n  
every ordering in   s  n    n c  n   is either mc contradicting or blockwise equivalent to
some member of c  n    to prove that c  n   is valid  we must show that it contains an
ordering o  n   which is binder consistent with some minimal ordering s  of s   
let s    be a minimal ordering of s   binder consistent with n   let o  n  be the projection
of s    on n   if o  n    c  n    we are done  o  n   o  n    s    s      otherwise  o  n      s  n    n
c  n    o  n  cannot be mc contradicting  it is min consistent to s      therefore it must be
blockwise equivalent to some o  n     c  n    blocks of o  n  are not violated in s     since s    is
    
minimal  corollary     therefore the substitution s       s   joo  n  is well defined  s     is minimal 
n
since s    is minimal and o  n  and o  n   are blockwise equivalent  s     is binder consistent with
o  n     since s    was binder consistent with o  n    thereupon s     and o  n   satisfy the requirements
of validity  o  n   o  n     s    s      
 
theorem  
let s  be a set of subgoals  for each node n of the divisibility tree of s   algorithm  
creates a strongly valid candidate set of orderings 

proof  by induction on the height of n  s subtree 
inductive base  n is a leaf node  which means that s  n   is independent under b n   

the candidate set of n contains one element  whose subgoals are sorted by cn  all
orderings that belong to   s  n    n candset n   are either not sorted by cn  and
hence are mc contradicting  lemma     or are sorted by cn  and hence are blockwiseequivalent to the candidate  corollary     consequently  candset n   is strongly
valid 
inductive hypothesis  for all children of n   algorithm   produces strongly valid candidate sets 
inductive step  an internal node in a divisibility tree is either an and node or an ornode 
   n is an and node  let n   n        nk be the children of n   first we show that
consset n   is strongly valid 
let o  n     s  n    n consset n    for all    i  k  let o  i be the projection of
o  n on ni  the set of projections fo     o           o  k g can belong to one of the three
following types  with regard to o  n  
 a  the sets of the first type contain at least one mc contradicting projection  in
such a case o  n is mc contradicting too  assume the contrary  there exists
a minimal ordering s  of s   binder consistent with o  n   let o  i be an mccontradicting projection  since o  i is consistent with o  n   it is also consistent
  

filedeniov   markovitch

with s    since b ni     b n    all subgoals of b ni  appear in s  before
subgoals of s  ni    therefore  o  i is binder consistent with s    and since s  is
minimal  o  i is min consistent and not mc contradicting   a contradiction 
 b  the sets of the second type do not contain mc contradicting projections  but
in o  n some block of some projection is violated  or max blocks from different
projections are not ordered by cn  in such a case  o  n is mc contradicting 
by corollary   and lemma   
 c  the sets of the third type do not contain mc contradicting projections  and
max blocks of the projections are not violated in o  n and are sorted by cn 
every projection o  i either belongs to candset ni   or not  if o  i    candset ni  
then there exists o  i    candset ni  such that o  i is blockwise equivalent to
o  i   because candset ni  is strongly valid by the inductive hypothesis  and
o  i is not mc contradicting   if o  i   candset ni   we can set o  i    o  i 
  
     
let o  n    o  n joo  joo        joo  kk   this substitution is well defined  since each o  i
has the same number of max blocks as o  i    and max blocks of the projections
are not violated in o  n   let s  be a minimal ordering of s   binder consistent
with o  n   since s  is minimal  blocks of o    are not violated in s    since o   
  
is blockwise equivalent to o       the ordering s     s  joo  is well defined and
minimal  in s   the positions of the subgoals from b n   did not change 
thus  o    is min consistent with s    and blockwise equivalence of o    and o    
  
     
entails minimality of the ordering s     s   joo    s  joo  joo    we continue with
  
     
other o  i  s  and finally obtain that s      s  joo  joo        joo  kk is minimal  from the
  
definition of o  n    s      s  joo  nn  note that we introduced blockwise equivalence
and strong validity only to be able to perform this transition   s    is minimal 
therefore o  n is blockwise equivalent to o  n    o  n    consset n    since all its
projections are candidates of the child nodes  thereupon  o  n is blockwiseequivalent to a member of consset n   
so  consset n   is strongly valid  to prove that candset n   is strongly valid 
it suces to show that all the members of consset n   that are not included in
candset n   by algorithm    are either mc contradicting or blockwise equivalent
to members of candset n    such orderings can be of three types 
 a  orderings that violate blocks of the children projections  they are mccontradicting by corollary   
 b  orderings that do not violate blocks  but where max blocks of children projections are not ordered by cn  they are mc contradicting by lemma   
 c  orderings that do not violate blocks and have them sorted by cn  for each
combination of projections  one consistent ordering of n is retained in the
candidate set  and all the other are rejected  by corollary    the rejected
orderings are blockwise equivalent to the retained candidate 
consequently  candset n   is strongly valid 
 

 

 

 

 
 

  

 

 

 

 

 

 

 

 

 

 

fithe divide and conquer subgoal ordering algorithm

   n is an or node  again  we start with showing that consset n   is strongly
valid 
let o  n     s  n    n consset n    o  n is constructed from a binder h and a
 tail  sequence t    o  n   h kt    let nh be the child of n that corresponds
to the binder h   by the inductive hypothesis  candset nh   is strongly valid 
t     candset nh    since otherwise o  n   consset n    therefore  t  is either mc contradicting  or blockwise equivalent to some t      candset nh   
if t  is mc contradicting  o  n is mc contradicting too  proof by contradiction  as for and nodes   if t  is blockwise equivalent to t      then o  n   h kt 
is blockwise equivalent to h kt      consset n    the proof is easy   hence 
consset n   is strongly valid  the only orderings of consset n   that are not included in candset n   by the dac algorithm have cheaper permutations of their
leading max blocks  and therefore are mc contradicting  by lemma    hence 
candset n   is strongly valid 
 

corollary   the candidate set found by algorithm   for the root node is valid 
corollary   algorithm   finds a minimal ordering of the given set of subgoals 

references

aho  a  v   hopcroft  j  e     ullman  j  d          data structures and algorithms 
addison wesley 
boddy  m     dean  t          solving time dependent planning problems  in sridharan  n  s   ed    proceedings of the   th international joint conference on artificial
intelligence  pp           detroit  mi  usa  morgan kaufmann 
bol  r  n   apt  k  r     klop  j  w          an analysis of loop checking mechanisms for
logic programs  theoretical computer science                
braem  c   le charlier  b   modar  s     van hentenryck  p          cardinality analysis
of prolog  in bruynooghe  m   ed    logic programming   proceedings of the     
international symposium  pp           massachusetts institute of technology  the
mit press 
breiman  l   friedman  j  h   olshen  r  a     stone  c  j          classification and
regression trees  wadsworth international group  belmont  ca 
bruynooghe  m   de schreye  d     krekels  b          compiling control  the journal of
logic programming             
clark  k  l     mccabe  f          the control facilities of ic prolog  in michie  d   ed   
expert systems in the microelectronic age   pp           university of edinburgh 
scotland 
clocksin  w  f     mellish  c  s          programming in prolog  third edition   springerverlag  new york 
  

filedeniov   markovitch

cohen  w  w          learning approximate control rules of high utility  in proceedings of
the seventh international machine learning workshop  pp           austin  texas 
morgan kaufmann 
cormen  t  h   leiserson  c  e     rivest  r  l          introduction to algorithms  mit
press  cambridge  mass 
cortesi  a   le charlier  b     rossi  s          specification based automatic verification
of prolog programs  in gallagher  j   ed    proceedings of the  th international workshop on logic program synthesis and transformation  vol       of lncs  pp        
stockholm  sweden  springer verlag 
de boeck  p     le charlier  b          static type analysis of prolog procedures for ensuring
correctness  in deransart  p     maluszynski  j   eds    programming languages
implementation and logic programming  vol      of lncs  pp           linkoping 
sweden  springer verlag 
de schreye  d     decorte  s          termination of logic programs  the never ending
story  the journal of logic programming                   
debray  s   lopez garca  p   hermenegildo  m     lin  n  w          lower bound cost
estimation for logic programs  in maluszynski  j   ed    proceedings of the international symposium on logic programming  ilps      pp           cambridge  mit
press 
debray  s  k     lin  n  w          cost analysis of logic programs  acm transactions
on programming languages and systems                  
debray  s  k     warren  d  s          automatic mode inference for logic programs  the
journal of logic programming             
dejong  g     mooney  r          explanation based learning  an alternative view  machine learning             
deville  y          logic programming  systematic program development  international
series in logic programming  addison wesley 
etzioni  o          static  a problem space compiler for prodigy  in dean  thomas
l   mckeown  k   ed    proceedings of the  th national conference on artificial
intelligence  pp           anaheim  california  mit press 
etzioni  o          acquiring search control knowledge via static analysis  artificial intelligence              
greiner  r     orponen  p          probably approximately optimal satisficing strategies 
artificial intelligence                  
henrard  j     le charlier  b          folon  an environment for declarative construction
of logic programs  in bruynooghe  m     wirsing  m   eds    proceedings of the fourth
international symposium on programming language implementation and logic programming  vol      of lncs  pp           leuven  belgium  springer verlag 
  

fithe divide and conquer subgoal ordering algorithm

itai  a     makowsky  j  a          unification as a complexity measure for logic programming  the journal of logic programming             
knuth  d  e          the art of computer programming  vol     addison wesley  reading 
mass 
kowalski  r  a          algorithm   logic   control  communications of the acm        
        
laird  p  d          ecient dynamic optimization of logic programs  in proceedings of
the ml   workshop on knowledge compilation and speedup learning aberdeen 
scotland 
langley  p          learning to search  from weak methods to domain specific heuristics 
cognitive science             
lavrac  n     dzeroski  s          inductive logic programming  techniques and applications  artificial intelligence  ellis harwood  new york 
ledeniov  o     markovitch  s       a   controlled utilization of control knowledge for
speeding up logic inference  tech  rep  cis      technion  haifa  israel 
ledeniov  o     markovitch  s       b   learning investment functions for controlling the
utility of control knowledge  in proceedings of the fifteenth national conference on
artificial intelligence  pp           madison  wisconsin  morgan kaufmann 
lenat  d  b          cyc  a large scale investment in knowledge infrastructure  communications of the acm                 
lloyd  j  w          foundations of logic programming  second edition   springer verlag 
berlin 
markovitch  s     scott  p  d          automatic ordering of subgoals   a machine learning
approach  in lusk  e  l     overbeek  r  a   eds    proceedings of the north american
conference on logic programming  pp           cleveland  ohio  mit press 
markovitch  s          information filtering  selection mechanisms in learning systems 
ph d  thesis  eecs department  university of michigan 
markovitch  s     scott  p  d          information filtering  selection mechanisms in
learning systems  machine learning              
minker  j          search strategy and selection function for an inferential relational system 
in acm transactions on database systems  vol     pp       
minton  s          learning search control knowledge  an explanation based approach 
kluwer  boston  ma 
mitchell  t  m   keller  r  m     kedar cabelli  s  t          explanation based generalization  a unifying view  machine learning           
  

filedeniov   markovitch

mooney  r  j     zelle  j  m          combining foil and ebg to speed up logic programs 
in bajcsy  r   ed    proceedings of the thirteenth international joint conference for
artificial intelligence  pp             chambery  france  morgan kaufmann 
morris  k  a          an algorithm for ordering subgoals in nail   in proceedings of the
seventh acm sigact sigmod symposium on principles of database systems  pp 
       austin  tx  acm press  new york 
muggleton  s     de raedt  l          inductive logic programming  theory and methods 
the journal of logic programming                   
naish  l          mu prolog    db reference manual  dept  of computer science  univ 
of melbourne 
naish  l       a   automatic control for logic programs  the journal of logic programming 
           
naish  l       b   prolog control rules  in joshi  a   ed    proceedings of the  th international joint conference on artificial intelligence  pp           los angeles  ca 
morgan kaufmann 
natarajan  k  s          optimizing backtrack search for all solutions to conjunctive problems  in mcdermott  j   ed    proceedings of the   th international joint conference
on artificial intelligence  pp           milan  italy  morgan kaufmann 
nie  x     plaisted  d  a          experimental results on subgoal ordering  in ieee
transactions on computers  vol      pp          
pettorossi  a     proietti  m          transformation of logic programs  foundations and
techniques  the journal of logic programming                   
pettorossi  a     proietti  m          rules and strategies for transforming functional and
logic programs  acm computing surveys                  
porto  a          epilog  a language for extended programming  in campbell  j   ed   
implementations of prolog  ellis harwood 
prieditis  a  e     mostow  j          prolearn  towards a prolog interpreter that
learns  in forbus  kenneth  shrobe  h   ed    proceedings of the  th national conference on artificial intelligence  pp           seattle  wa  morgan kaufmann 
quinlan  j  r          induction of decision trees  machine learning            
quinlan  j  r     cameron jones  r  m          induction of logic programs  foil and
related systems  new generation computing  special issue on inductive logic programming                    
simon  h  a     kadane  j  b          optimal problem solving search  all or none solutions  artificial intelligence             
smith  d  e          controlling backward inference  artificial intelligence                  
  

fithe divide and conquer subgoal ordering algorithm

smith  d  e     genesereth  m  r          ordering conjunctive queries  artificial intelligence              
smith  d  e   genesereth  m  r     ginsberg  m  l          controlling recursive inference 
artificial intelligence                  
somogyi  z   henderson  f   conway  t   bromage  a   dowd  t   jeffery  d     al       a  
status of the mercury system  in proc  of the jicslp     workshop on parallelism
and implementation technology for  constraint  logic programming languages  pp 
         bonn  germany 
somogyi  z   henderson  f     conway  t       b   the execution algorithm of mercury 
an ecient purely declarative logic programming language  journal of logic programming                  
sterling  l     shapiro  e          the art of prolog  second edition   mit press  cambridge  ma 
tamaki  h     sato  t          unfold fold transformation of logic programs  in tarnlund 
s  
a   ed    proceedings of the second international conference on logic programming  pp           uppsala  sweden 
ullman  j  d     vardi  m  y          the complexity of ordering subgoals  in proceedings of
the seventh acm sigact sigmod symposium on principles of database systems 
pp         austin  tx  acm press  new york 
ullman  j  d          principles of database systems  computer science press  rockville 
md 
vasak  t     potter  j          metalogical control for logic programs  journal of logic
programming                 
warren  d  h  d          ecient processing of interactive relational database queries
expressed in logic  in zaniola    delobel  eds    proceedings of the  th international
conference on very large data bases  pp           cannes  france  ieee computer
society press 

  

fi