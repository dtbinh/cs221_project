journal of artificial intelligence research                 

submitted       published      

antnet  distributed stigmergetic control for
communications networks
gianni di caro
marco dorigo

iridia  universite libre de bruxelles
    av  f  roosevelt  cp               brussels  belgium

gdicaro iridia ulb ac be
mdorigo ulb ac be

abstract

this paper introduces antnet  a novel approach to the adaptive learning of routing
tables in communications networks  antnet is a distributed  mobile agents based monte
carlo system that was inspired by recent work on the ant colony metaphor for solving
optimization problems  antnet s agents concurrently explore the network and exchange
collected information  the communication among the agents is indirect and asynchronous 
mediated by the network itself  this form of communication is typical of social insects
and is called stigmergy  we compare our algorithm with six state of the art routing algorithms coming from the telecommunications and machine learning fields  the algorithms 
performance is evaluated over a set of realistic testbeds  we run many experiments over
real and artificial ip datagram networks with increasing number of nodes and under several paradigmatic spatial and temporal trac distributions  results are very encouraging 
antnet showed superior performance under all the experimental conditions with respect
to its competitors  we analyze the main characteristics of the algorithm and try to explain
the reasons for its superiority 

   introduction
worldwide demand and supply of communications networks services are growing exponentially  techniques for network control  i e   online and off line monitoring and management
of the network resources  play a fundamental role in best exploiting the new transmission
and switching technologies to meet user s requests 
routing is at the core of the whole network control system  routing  in conjunction
with the admission  ow  and congestion control components  determines the overall network
performance in terms of both quality and quantity of delivered service  walrand   varaiya 
       routing refers to the distributed activity of building and using routing tables  one
for each node in the network  which tell incoming data packets which outgoing link to use
to continue their travel towards the destination node 
routing protocols and policies have to accommodate conicting objectives and constraints imposed by technologies and user requirements rapidly evolving under commercial
and scientific pressures  novel routing approaches are required to eciently manage distributed multimedia services  mobile users and networks  heterogeneous inter networking 
service guarantees  point to multipoint communications  etc   sandick   crawley       
the atm forum        
the adaptive and distributed routing algorithm we propose in this paper is a mobileagent based  online monte carlo technique inspired by previous work on artificial ant
c      ai access foundation and morgan kaufmann publishers  all rights reserved 

fidi caro   dorigo

colonies and  more generally  by the notion of stigmergy  grasse         that is  the indirect communication taking place among individuals through modifications induced in
their environment 
algorithms that take inspiration from real ants  behavior in finding shortest paths  goss 
aron  deneubourg    pasteels        beckers  deneubourg    goss        using as information only the trail of a chemical substance  called pheromone  deposited by other ants 
have recently been successfully applied to several discrete optimization problems  dorigo 
maniezzo    colorni        dorigo        dorigo  maniezzo    colorni        dorigo  
gambardella        schoonderwoerd  holland  bruten    rothkrantz        schoonderwoerd  holland    bruten        costa   hertz         in all these algorithms a set of artificial
ants collectively solve the problem under consideration through a cooperative effort  this
effort is mediated by indirect communication of information on the problem structure the
ants concurrently collect while building solutions by using a stochastic policy  similarly 
in antnet  the algorithm we propose in this paper  a set of concurrent distributed agents
collectively solve the adaptive routing problem  agents adaptively build routing tables and
local models of the network status by using indirect and non coordinated communication
of information they collect while exploring the network 
to ensure a meaningful validation of our algorithm performance we devised a realistic
simulation environment in terms of network characteristics  communications protocol and
trac patterns  we focus on ip  internet protocol  datagram networks with irregular
topology and consider three real and artificial topologies with an increasing number of
nodes and several paradigmatic temporal and spatial trac distributions  we report on
the behavior of antnet as compared to some effective static and adaptive state of the art
routing algorithms  vector distance and link state shortest paths algorithms  steenstrup 
       and recently introduced algorithms based on machine learning techniques  
antnet shows the best performance and the most stable behavior for all the considered
situations  in many experiments its superiority is striking  we discuss the results and the
main properties of our algorithm  as compared with its competitors 
the paper is organized as follows  in section   the definition  taxonomy and characteristics of the routing problem are reported  in section   we describe the communication
network model we used  section   describes in detail antnet  our novel routing algorithm 
while in section   we briey describe the algorithms with which we compared antnet  in
section    the experimental settings are reported in terms of trac  networks and algorithm
parameters  section   reports several experimental results  in section   we discuss these
results and try to explain antnet s superior performance  finally  in section    we discuss
related work  and in section     we draw some conclusions and outline directions for future
research 

   routing  definition and characteristics
routing in distributed systems can be characterized as follows  let g    v  e   be a directed
weighted graph  where each node in the set v represents a processing queuing and or forwarding unit and each edge is a transmission system  the main task of a routing algorithm
is to direct data ow from source to destination nodes maximizing network performance 
   

fiantnet  distributed stigmergetic control for communications networks

in the problems we are interested in  the data ow is not statically assigned and it follows
a stochastic profile that is very hard to model 
in the specific case of communications networks  steenstrup        bertsekas   gallager 
       the routing algorithm has to manage a set of basic functionalities and it tightly
interacts with the congestion and admission control algorithms  with the links  queuing
policy  and with the user generated trac  the core of the routing functions is  i  the
acquisition  organization and distribution of information about user generated trac and
network states   ii  the use of this information to generate feasible routes maximizing the
performance objectives  and  iii  the forwarding of user trac along the selected routes 
the way the above three functionalities are implemented strongly depends on the underlying network switching and transmission technology  and on the features of the other
interacting software layers  concerning point  iii   two main forwarding paradigms are in
use  circuit and packet switching  also indicated with the terms connection oriented and
connection less   in the circuit switching approach  a setup phase looks for and reserves the
resources that will be assigned to each incoming session  in this case  all the data packets
belonging to the same session will follow the same path  routers are required to keep state
information about active sessions  in the packet switching approach  there is no reservation
phase  no state information is maintained at routers and data packets can follow different
paths  in each intermediate node an autonomous decision is taken concerning the node s
outgoing link that has to be used to forward the data packet toward its destination 
in the work described in this paper  we focus on the packet switching paradigm  but
the technique developed here can be used also to manage circuit switching and we expect
to have qualitatively similar results 

    a broad taxonomy

a common feature of all the routing algorithms is the presence in every network node of
a data structure  called routing table  holding all the information used by the algorithm to
make the local forwarding decisions  the routing table is both a local database and a local
model of the global network status  the type of information it contains and the way this
information is used and updated strongly depends on the algorithm s characteristics  a
broad classification of routing algorithms is the following 
 centralized versus distributed 
 static versus adaptive 
in centralized algorithms  a main controller is responsible for updating all the node s
routing tables and or to make every routing decision  centralized algorithms can be used
only in particular cases and for small networks  in general  the delays necessary to gather
information about the network status and to broadcast the decisions updates make them
infeasible in practice  moreover  centralized systems are not fault tolerant  in this work 
we will consider exclusively distributed routing 
in distributed routing systems  the computation of routes is shared among the network
nodes  which exchange the necessary information  the distributed paradigm is currently
used in the majority of network systems 
in static  or oblivious  routing systems  the path taken by a packet is determined only
on the basis of its source and destination  without regard to the current network state  this
   

fidi caro   dorigo

path is usually chosen as the shortest one according to some cost criterion  and it can be
changed only to account for faulty links or nodes 
adaptive routers are  in principle  more attractive  because they can adapt the routing policy to time and spatially varying trac conditions  as a drawback  they can cause
oscillations in selected paths  this fact can cause circular paths  as well as large uctuations in measured performance  in addition  adaptive routing can lead more easily to
inconsistent situations  associated with node or link failures or local topological changes 
these stability and inconsistency problems are more evident for connection less than for
connection oriented networks  bertsekas   gallager        
another interesting way of looking at routing algorithms is from an optimization perspective  in this case the main paradigms are 
 minimal routing versus non minimal routing 
 optimal routing versus shortest path routing 
minimal routers allow packets to choose only minimal cost paths  while non minimal
algorithms allow choices among all the available paths following some heuristic strategies
 bolding  fulgham    snyder        
optimal routing has a network wide perspective and its objective is to optimize a function of all individual link ows  usually this function is a sum of link costs assigned on the
basis of average packet delays   bertsekas   gallager        
shortest path routing has a source destination pair perspective  there is no global cost
function to optimize  its objective is to determine the shortest path  minimum cost  between
two nodes  where the link costs are computed  statically or adaptively  following some
statistical description of the link states  this strategy is based on individual rather than
group rationality  wang   crowcroft         considering the different content stored in
each routing table  shortest path algorithms can be further subdivided into two classes
called distance vector and link state  steenstrup        
optimal routing is static  it can be seen as the solution of a multicommodity ow problem  and requires the knowledge of all the trac characteristics  shortest paths algorithms
are more exible  they don t require a priori knowledge about the trac patterns and they
are the most widely used routing algorithms 
in appendix a  a more detailed description of the properties of optimal and shortest
path routing algorithms is reported 
in section    we introduce a novel distributed adaptive method  antnet  that shares the
same optimization perspective as  minimal or non minimal  shortest path algorithms but
not their usual implementation paradigms  as depicted in appendix a  

    main characteristics of the routing problem

the main characteristics of the routing problem in communications networks can be summarized in the following way 

 intrinsically distributed with strong real time constraints  in fact  the database and

the decision system are completely distributed over all the network nodes  and failures
and status information propagation delays are not negligible with respect to the user s
   

fiantnet  distributed stigmergetic control for communications networks

trac patterns  it is impossible to get complete and up to date knowledge of the distributed state  that remains hidden  at each decision node  the routing algorithm can
only make use of local  up to date information  and of non local  delayed information
coming from the other nodes 
 stochastic and time varying  the session arrival and data generation process is  in
the general case  non stationary and stochastic  moreover  this stochastic process
interacts recursively with the routing decisions making it infeasible to build a working model of the whole system  to be used for example in a dynamic programming
framework  
 multi objective  several conicting performance measures are usually taken into account  the most common are throughput  bit sec  and average packet delay  sec  
the former measures the quantity of service that the network has been able to offer
in a certain amount of time  amount of correctly delivered bits per time unit   while
the latter defines the quality of service produced at the same time  citing bertsekas
and gallager         page       the effect of good routing is to increase throughput
for the same value of average delay per packet under high offered load conditions and
to decrease average delay per packet under low and moderate offered load conditions  
other performance measures consider the impact of the routing algorithm on the network resources in terms of memory  bandwidth and computation  and the algorithm
simplicity  exibility  etc 
 multi constraint  constraints are imposed by the underlying network technology  the
network services provided and the user services requested  in general  users ask for
low cost  high quality  reliable  distributed multimedia services available across heterogeneous static and mobile networks  evaluating technological and commercial factors 
network builders and service providers try to accommodate these requests while maximizing some profit criteria  moreover  a high level of fault tolerance and reliability is
requested in modern high speed networks  where user sessions can formulate precise
requests for network resources  in this case  once the session has been accepted  the
system should be able to guarantee that the session gets the resources it needs  under
any recoverable fault event 
it is interesting to note that the above characteristics make the problem of routing belong
to the class of reinforcement learning problems with hidden state  bertsekas   tsitsiklis 
      kaelbling  littman    moore        mccallum         a distributed system of agents 
the components of the routing algorithm in each node  determine a continual and online
learning of the best routing table values with respect to network s performance criteria  an
exact measure of evaluation that scores forwarding decisions is not available  neither online
nor in the form of a training set  moreover  because of the distributed nature of the problem
and of its constraints  the complete state of the network is hidden to each agent 

   the communication network model

in this paper  we focus on irregular topology connection less networks with an ip like network layer  in the iso osi terminology  and a very simple transport layer  in particular 
we focus on wide area networks  wan   in these cases  hierarchical organization schemes
   

fidi caro   dorigo

are adopted   roughly speaking  sub networks are seen as single host nodes connected to
interface nodes called gateways  gateways perform fairly sophisticated network layer tasks 
including routing  groups of gateways  connected by an arbitrary topology  define logical
areas  inside each area  all the gateways are at the same hierarchical level and  at  routing
is performed among them  areas communicate only by means of area border gateways  in
this way  the computational complexity of the routing problem  as seen by each gateway  is
much reduced  e g   in the internet  ospf areas typically group    to     gateways   while
the complexity of the design and management of the routing protocol is much increased 
the instance of our communication network is mapped on a directed weighted graph
with n processing forwarding nodes  all the links are viewed as bit pipes characterized
by a bandwidth  bit sec  and a transmission delay  sec   and are accessed following a
statistical multiplexing scheme  for this purpose  every node  of type store and forward 
holds a buffer space where the incoming and the outgoing packets are stored  this buffer
is a shared resource among all the queues attached to every incoming and outgoing link of
the node  all the traveling packets are subdivided in two classes  data and routing packets 
all the packets in the same class have the same priority  so they are queued and served on
the basis of a first in first out policy  but routing packets have a greater priority than data
packets  the workload is defined in terms of applications whose arrival rate is dictated by
a selected probabilistic model  by application  or session  or connection in the following  
we mean a process sending data packets from an origin node to a destination node  the
number of packets to send  their sizes and the intervals between them are assigned according
to some defined stochastic process  we didn t make any distinction among nodes  they act
at the same time as hosts  session end points  and gateways routers  forwarding elements  
the adopted workload model incorporates a simple ow control mechanism implemented
by using a fixed production window for the session s packets generation  the window
determines the maximum number of data packets waiting to be sent  once sent  a packet is
considered to be acknowledged  this means that the transport layer neither manages error
control  nor packet sequencing  nor acknowledgements and retransmissions  
for each incoming packet  the node s routing component uses the information stored in
the local routing table to assign the outgoing link to be used to forward the packet toward
its target node  when the link resources are available  they are reserved and the transfer
is set up  the time it takes to move a packet from one node to a neighboring one depends
on the packet size and on the link transmission characteristics  if  on a packet s arrival 
there is not enough buffer space to hold it  the packet is discarded  otherwise  a service
time is stochastically generated for the newly arrived packet  this time represents the delay
between the packet arrival time and the time when it will be put in the buffer queue of the
outgoing link the local routing component has selected for it 
situations causing a temporary or steady alteration of the network topology or of its
physical characteristics are not taken into account  link or node failure  adding or deleting
of network components  etc   
   a hierarchical structure is adopted on the internet  organized in hierarchical autonomous systems and
multiple routing areas inside each autonomous system  moy        
   this choice is the same as in the  simple trac  model in the mars network simulator  alaettinoglu 
shankar  dussa zieger    matta         it can be seen as a very basic form of file transfer protocol
 ftp  

   

fiantnet  distributed stigmergetic control for communications networks

we developed a complete network simulator in c    it is a discrete event simulator
using as its main data structure an event list  which holds the next future events  the
simulation time is a continuous variable and is set by the currently scheduled event  the aim
of the simulator is to closely mirror the essential features of the concurrent and distributed
behavior of a generic communication network without sacrificing eciency and exibility
in code development 
we end this section with some remarks concerning two features of the model 
first  we chose not to implement a  real  transport layer for a proper management
of error  ow  and congestion control  in fact  each additional control component has a
considerable impact on the network performance   making very dicult to evaluate and to
study the properties of each control algorithm without taking in consideration the complex
way it interacts with all the other control components  therefore  we chose to test the
behavior of our algorithm and of its competitors in conditions such that the number of
interacting components is minimal and the routing component can be evaluated in isolation 
allowing a better understanding of its properties  to study routing in conjunction with error 
ow and congestion control  all these components should be designed at the same time  to
allow a good match among their characteristics to produce a synergetic effect 
second  we chose to work with connection less and not with connection oriented networks because connection oriented schemes are mainly used in networks able to deliver
quality of service  qos   crawley  nair  rajagopalan    sandick          in this case 
suitable admission control algorithms have to be introduced  taking into account many
economic and technological factors  sandick   crawley         but  again  as a first step
we think that it is more reasonable to try to check the validity of a routing algorithm by
reducing the number of components heavily inuencing the network behavior 

   antnet  an adaptive agent based routing algorithm
the characteristics of the routing problem  discussed in section      make it well suited
to be solved by a mobile multi agent approach  stone   veloso        gray  kotz  nog 
rus    cybenko         this processing paradigm is a good match for the distributed and
non stationary  in topology and trac patterns  nature of the problem  presents a high
level of redundancy and fault tolerance  and can handle multiple objectives and constraints
in a exible way 
antnet  the routing algorithm we propose in this paper  is a mobile agents system showing some essential features of parallel replicated monte carlo systems  streltsov   vakili 
       antnet takes inspiration from previous work on artificial ant colonies techniques to
solve combinatorial optimization problems  dorigo et al         dorigo        dorigo et al  
      dorigo   gambardella        and telephone network routing  schoonderwoerd et al  
   as an example  some authors reported an improvement ranging from   to     in various performance
measures for real internet trac  danzig  liu    yan        by changing from the reno version to the
vegas version of the tcp  peterson   davie         the current internet transport control protocol  
and other authors even claimed improvements ranging from    to      brakmo  o malley    peterson 
      
   this is not the case for the current internet  where the ip bearer service is of  best effort  type  meaning
that it does the best it can do but no guarantees of service quality in terms of delay or bandwidth or
jitter  etc   can be assured 

   

fidi caro   dorigo

             the core ideas of these techniques  for a review see dorigo  di caro  and
gambardella        are  i  the use of repeated and concurrent simulations carried out by a
population of artificial agents called  ants  to generate new solutions to the problem   ii 
the use by the agents of stochastic local search to build the solutions in an incremental way 
and  iii  the use of information collected during past simulations to direct future search for
better solutions 
in the artificial ant colony approach  following an iterative process  each ant builds a
solution by using two types of information locally accessible  problem specific information
 for example  distance among cities in a traveling salesman problem   and information added
by ants during previous iterations of the algorithm  in fact  while building a solution  each
ant collects information on the problem characteristics and on its own performance  and
uses this information to modify the representation of the problem  as seen locally by the
other ants  the representation of the problem is modified in such a way that information
contained in past good solutions can be exploited to build new better solutions  this form
of indirect communication mediated by the environment is called stigmergy  and is typical
of social insects  grasse        
in antnet  we retain the core ideas of the artificial ant colony paradigm  and we apply
them to solve in an adaptive way the routing problem in datagram networks 
informally  the antnet algorithm and its main characteristics can be summarized as
follows 

 at regular intervals  and concurrently with the data trac  from each network node








mobile agents are asynchronously launched towards randomly selected destination
nodes 
agents act concurrently and independently  and communicate in an indirect way 
through the information they read and write locally to the nodes 
each agent searches for a minimum cost path joining its source and destination nodes 
each agent moves step by step towards its destination node  at each intermediate
node a greedy stochastic policy is applied to choose the next node to move to  the
policy makes use of  i  local agent generated and maintained information   ii  local
problem dependent heuristic information  and  iii  agent private information 
while moving  the agents collect information about the time length  the congestion
status and the node identifiers of the followed path 
once they have arrived at the destination  the agents go back to their source nodes
by moving along the same path as before but in the opposite direction 
during this backward travel  local models of the network status and the local routing
table of each visited node are modified by the agents as a function of the path they
followed and of its goodness 
once they have returned to their source node  the agents die 

in the following subsections the above scheme is explained  all its components are explicated and discussed  and a more detailed description of the algorithm is given 
   

fiantnet  distributed stigmergetic control for communications networks

    algorithm description and characteristics

antnet is conveniently described in terms of two sets of homogeneous mobile agents  stone
  veloso         called in the following forward and backward ants  agents  in each set
possess the same structure  but they are differently situated in the environment  that is 
they can sense different inputs and they can produce different  independent outputs  they
can be broadly classified as deliberative agents  because they behave reactively retrieving a
pre compiled set of behaviors  and at the same time they maintain a complete internal state
description  agents communicate in an indirect way  according to the stigmergy paradigm 
through the information they concurrently read and write in two data structures stored in
each network node k  see figure    
outgoing links

network nodes

routing table
network
node

local

p   

p   

        

p  n

p   

p   

        

p  n

pl  

pl  

        

pl n

traffic
statistics

network nodes
stat    

stat    

stat n 

figure    node structures used by mobile agents in antnet for the case of a node with
l neighbors and a network with n nodes  the routing table is organized as in
vector distance algorithms  but the entries are probabilistic values  the structure
containing statistics about the local trac plays the role of a local adaptive model
for the trac toward each possible destination 
i  a routing table tk   organized as in vector distance algorithms  see appendix a  
but with probabilistic entries  tk defines the probabilistic routing policy currently
adopted at node k  for each possible destination d and for each neighbor node n  tk
stores a probability value pnd expressing the goodness  desirability   under the current
network wide routing policy  of choosing n as next node when the destination node
is d 
x
pnd      d       n    nk   fneighbors k g 
ii 

n nk
an array mk  d   d     wd    of data structures defining a simple parametric statistical

model for the trac distribution over the network as seen by the local node k  the
model is adaptive and described by sample means and variances computed over the
trip times experienced by the mobile agents  and by a moving observation window wd
used to store the best value wbestd of the agents  trip time 

   in the following  we will use interchangeably the terms ant and agent 

   

fidi caro   dorigo

for each destination d in the network  an estimated mean and variance  d and d    
give a representation of the expected time to go and of its stability  we used arithmetic  exponential and windowed strategies to compute the statistics  changing strategy does not affect performance much  but we observed the best results using the
exponential model  
d
d    ok d   d   
 
d
d       ok d   d      d     
   
where ok d is the new observed agent s trip time from node k to destination d  
the moving observation window wd is used to compute the value wbestd of the best
agents  trip time towards destination d as observed in the last w samples  after each
new sample  w is incremented modulus jwjmax   and jwjmax is the maximum allowed
size of the observation window  the value wbestd represents a short term memory
expressing a moving empirical lower bound of the estimate of the time to go to node
d from the current node 
t and m can be seen as memories local to nodes capturing different aspects of the
network dynamics  the model m maintains absolute distance time estimates to all the
nodes  while the routing table gives relative probabilistic goodness measures for each linkdestination pair under the current routing policy implemented over all the network 
the antnet algorithm is described as follows 
   at regular intervals t from every network node s  a mobile agent  forward ant  fs d
is launched toward a destination node d to discover a feasible  low cost path to that
node and to investigate the load status of the network  forward ants share the same
queues as data packets  so that they experience the same trac loads  destinations are
locally selected according to the data trac patterns generated by the local workload 
if fsd is a measure  in bits or in number of packets  of the data ow s   d  then the
probability of creating at node s a forward ant with node d as destination is
f
pd   n sd  
x
fsd 

   

d    

in this way  ants adapt their exploration activity to the varying data trac distribution 
   while traveling toward their destination nodes  the agents keep memory of their paths
and of the trac conditions found  the identifier of every visited node k and the time
elapsed since the launching time to arrive at this k th node are pushed onto a memory
stack ss d  k  
   this is the same model as used by the jacobson karels algorithm to estimate retransmission timeouts
in the internet tcp peterson   davie        
   the factor  weights the number of most recent samples that will really affect the average  the weight
of the ti  th sample used to estimate the value of d after j samplings  with j   i  is        j i   in
this way  for example  if         approximately only the latest    observations will really inuence the
estimate  for          the latest      and so on  therefore  the number of effective observations is
       

   

fiantnet  distributed stigmergetic control for communications networks

   at each node k  each traveling agent headed towards its destination d selects the node
n to move to choosing among the neighbors it did not already visit  or over all the
neighbors in case all of them had been previously visited  the neighbor n is selected
  computed as the normalized sum of the probabilistic
with a probability  goodness  pnd
entry pnd of the routing table with a heuristic correction factor ln taking into account
the state  the length  of the n th link queue of the current node k 
   
pnd

pnd   ffln
    ff jnk j       

   

the heuristic correction ln is a       normalized value proportional to the length qn
 in bits waiting to be sent  of the queue of the link connecting the node k with its
neighbor n 
q
ln       jn jn  
k
x
qn 

   

n    

the value of ff weights the importance of the heuristic correction with respect to the
probability values stored in the routing table  ln reects the instantaneous state of the
node s queues  and assuming that the queue s consuming process is almost stationary
or slowly varying  ln gives a quantitative measure associated with the queue waiting
time  the routing tables values  on the other hand  are the outcome of a continual
learning process and capture both the current and the past status of the whole network
as seen by the local node  correcting these values with the values of l allows the
system to be more  reactive   at the same time avoiding following all the network
uctuations  agent s decisions are taken on the basis of a combination of a long term
learning process and an instantaneous heuristic prediction 
in all the experiments we ran  we observed that the introduced correction is a very
effective mechanism  depending on the characteristics of the problem  the best value
to assign to the weight ff can vary  but if ff ranges between     and      performance
doesn t change appreciably  for lower values  the effect of l is vanishing  while for
higher values the resulting routing tables oscillate and  in both cases  performance
degrades 
   if a cycle is detected  that is  if an ant is forced to return to an already visited node 
the cycle s nodes are popped from the ant s stack and all the memory about them is
destroyed  if the cycle lasted longer than the lifetime of the ant before entering the
cycle   that is  if the cycle is greater than half the ant s age  the ant is destroyed  in
fact  in this case the agent wasted a lot of time probably because of a wrong sequence
of decisions and not because of congestion states  therefore  the agent is carrying an
old and misleading memory of the network state and it is counterproductive to use it
to update the routing tables  see below  
   when the destination node d is reached  the agent fs d generates another agent
 backward ant  bd s   transfers to it all of its memory  and dies 
   

fidi caro   dorigo

   the backward ant takes the same path as that of its corresponding forward ant  but
in the opposite direction   at each node k along the path it pops its stack ss d k  to
know the next hop node  backward ants do not share the same link queues as data
packets  they use higher priority queues  because their task is to quickly propagate to
the routing tables the information accumulated by the forward ants 
   arriving at a node k coming from a neighbor node f   the backward ant updates the
two main data structures of the node  the local model of the trac mk and the routing table tk   for all the entries corresponding to the  forward ant  destination node
d  with some precautions  updates are performed also on the entries corresponding
to every node k    sk d  k     d on the  sub paths  followed by ant fs d after visiting the current node k  in fact  if the elapsed trip time of a sub path is statistically
 good   i e   it is less than    i       where i is an estimate of a confidence interval
for    then the time value is used to update the corresponding statistics and the
routing table  on the contrary  trip times of sub paths not deemed good  in the same
statistical sense as defined above  are not used because they don t give a correct idea
of the time to go toward the sub destination node  in fact  all the forward ant routing
decisions were made only as a function of the destination node  in this perspective 
sub paths are side effects  and they are intrinsically sub optimal because of the local
variations in the trac load  we can t reason with the same perspective as in dynamic
programming  because of the non stationarity of the problem representation   obviously  in case of a good sub path we can use it  the ant discovered  at zero cost  an
additional good route  in the following two items the way m and t are updated is
described with respect to a generic  destination  node d    sk d 
i  mk is updated with the values stored in the stack memory ss d k   the time
elapsed to arrive  for the forward ant  to the destination node d  starting from
the current node is used to update the mean and variance estimates  d  and d     
and the best value over the observation window wd    in this way  a parametric
model of the traveling time to destination d  is maintained  the mean value of
this time and its dispersion can vary strongly  depending on the trac conditions 
a poor time  path  under low trac load can be a very good one under heavy
trac load  the statistical model has to be able to capture this variability
and to follow in a robust way the uctuations of the trac  this model plays a
critical role in the routing table updating process  see item  ii  below   therefore 
we investigated several ways to build effective and computationally inexpensive
models  as described in the following section     
ii  the routing table tk is changed by incrementing the probability pfd   i e   the
probability of choosing neighbor f when destination is d    and decrementing  by
normalization  the other probabilities pnd    the amount of the variation in the
probabilities depends on a measure of goodness we associate with the trip time
tk d  experienced by the forward ant  and is given below  this time represents
the only available explicit feedback signal to score paths  it gives a clear indication about the goodness r of the followed route because it is proportional to its
   this assumption requires that all the links in the network are bi directional  in modern networks this is
a reasonable assumption 

   

fiantnet  distributed stigmergetic control for communications networks

length from a physical point of view  number of hops  transmission capacity of the
used links  processing speed of the crossed nodes  and from a trac congestion
point of view  the forward ants share the same queues as data packets  
the time measure t   composed by all the sub paths elapsed times  cannot be
associated with an exact error measure  given that we don t know the  optimal 
trip times  which depend on the whole network load status   therefore  t can
only be used as a reinforcement signal  this gives rise to a credit assignment
problem typical of the reinforcement learning field  bertsekas   tsitsiklis       
kaelbling et al          we define the reinforcement r  r t  mk   to be a
function of the goodness of the observed trip time as estimated on the basis of
the local trac model  r is a dimensionless value  r           used by the current
node k as a positive reinforcement for the node f the backward ant bd s comes
from  r takes into account some average of the so far observed values and of
their dispersion to score the goodness of the trip time t   such that the smaller t
is  the higher r is  the exact definition of r is discussed in the next subsection  
the probability pfd  is increased by the reinforcement value as follows 
pfd 

pfd    r     pfd    

   

in this way  the probability pfd  will be increased by a value proportional to the
reinforcement received and to the previous value of the node probability  that is 
given a same reinforcement  small probability values are increased proportionally
more than big probability values  favoring in this way a quick exploitation of new 
and good  discovered paths  
probabilities pnd  for destination d  of the other neighboring nodes n implicitly
receive a negative reinforcement by normalization  that is  their values are
reduced so that the sum of probabilities will still be   
pnd 

pnd    rpnd    n   nk   n    f 

   

it is important to remark that every discovered path receives a positive reinforcement in its selection probability  and the reinforcement is  in general  a non linear
function of the goodness of the path  as estimated using the associated trip time 
in this way  not only the  explicit  assigned value r plays a role  but also the
 implicit  ant s arrival rate  this strategy is based on trusting paths that receive
either high reinforcements  independent of their frequency  or low and frequent
reinforcements  in fact  for any trac load condition  a path receives one or more
high reinforcements only if it is much better than previously explored paths  on
the other hand  during a transient phase after a sudden increase in network load
all paths will likely have high traversing times with respect to those learned by
the model m in the preceding  low congestion  situation  therefore  in this case
good paths can only be differentiated by the frequency of ants  arrivals 
   when the network is in a congested state  all the trip times will score poorly with respect to the times
observed in low load situations  nevertheless  a path with a high trip time should be scored as a good
path if its trip time is significantly lower than the other trip times observed in the same congested
situation 

   

fidi caro   dorigo

assigning always a positive  but low  reinforcement value in the case of paths
with high traversal time allows the implementation of the above mechanism based
on the frequency of the reinforcements  while  at the same time  avoids giving
excessive credit to paths with high traversal time due to their poor quality 
the use of probabilistic entries is very specific to antnet and we observed it
to be effective  improving the performance  in some cases  even by         
routing tables are used in a probabilistic way not only by the ants but also
by the data packets  this has been observed to improve antnet performance 
which means that the way the routing tables are built in antnet is well matched
with a probabilistic distribution of the data packets over all the good paths 
data packets are prevented from choosing links with very low probability by remapping the t  s entries by means of a power function f  p    pff   ff      which
emphasizes high probability values and reduces lower ones  in our experiments
we set ff to      
figure   gives a high level description of the algorithm in pseudo code  while figure
  illustrates a simple example of the algorithm behavior  a detailed discussion of the
characteristics of the algorithm is postponed to section    after the performance of the
algorithm has been analyzed with respect to a set of competitor algorithms  in this way 
the characteristics of antnet can be meaningfully evaluated and compared to those of other
state of the art algorithms 

    how to score the goodness of the ant s trip time

the reinforcement r is a critical quantity that has to be assigned by considering three main
aspects   i  paths should receive an increment in their selection probability proportional
to their goodness   ii  the goodness is a relative measure  which depends on the trac
conditions  that can be estimated by means of the model m  and  iii  it is important not to
follow all the trac uctuations  this last aspect is particularly important  uncontrolled
oscillations in the routing tables are one of the main problems in shortest paths routing
 wang   crowcroft         it is very important to be able to set the best trade off between
stability and adaptivity 
we investigated several ways to assign the r values trying to take into account the above
three requirements 

 the simplest way is to set r   constant  independently of the ant s  experiment

outcomes   the discovered paths are all rewarded in the same way  in this simple but
meaningful case  what is at work is the implicit reinforcement mechanism due to the
differentiation in the ant arrival rates  ants traveling along faster paths will arrive
at a higher rate than other ants  hence their paths will receive a higher cumulative
reward    the obvious problem of this approach lies in the fact that  although ants
following longer paths arrive delayed  they will nevertheless have the same effect on
the routing tables as the ants who followed shorter paths 

    in this case  the core of the algorithm is based on the capability of  real  ants to discover shortest paths
communicating by means of pheromone trails  goss et al         beckers et al         

   

fiantnet  distributed stigmergetic control for communications networks

t    current time 
tend    time length of the simulation 
t    time interval between ants generation 
foreach  node     concurrent activity over the network   
m   local trac model 
t   node routing table 
while   t  tend  
in parallel    concurrent activity on each node   
if   t mod t     
destination node    selectdestinationnode data trac distribution  
launchforwardant destination node  source node  
end if
foreach  activeforwardant  source node  current
while  current node    destination node 

node  destination node  

next hop node    selectlink current node  destination node t   link queues  
putantonlinkqueue current node  next hop node  
waitondatalinkqueue current node  next hop node  
crossthelink current node  next hop node  
pushonthestack next hop node  elapsed time  
current node    next hop node 

end while

launchbackwardant destination node  source node  stack data  
die   

end foreach
foreach  activebackwardant  source node  current
while  current node    destination node 

node  destination node  

next hop node    popthestack   
waitonhighprioritylinkqueue current node  next hop node  
crossthelink current node  next hop node  
updatelocaltracmodel m  current node  source node  stack data  
reinforcement    getreinforcement current node  source node  stack data  m  
updatelocalroutingtable t   current node  source node  reinforcement  

end while
end foreach
end in parallel
end while
end foreach

figure    antnet s top level description in pseudo code  all the described actions take place
in a completely distributed and concurrent way over the network nodes  while  in
the text  antnet has been described from an individual ant s perspective   all the
constructs at the same level of indentation inside the context of the statement
in parallel are executed concurrently  the processes of data generation and
forwarding are not described  but they can be thought as acting concurrently
with the ants 
   

fidi caro   dorigo

forward ant   

  

 

 

 
  

 
   backward ant

figure    example of antnet behavior  the forward ant  f      moves along the path
              and  arrived at node    launches the backward ant b    that
will travel in the opposite direction  at each node k  k                 the backward
ant will use the stack contents s     k  to update the values for mk            w    
and  in case of good sub paths  to update also the values for mk  i   i     wi    i  
k                 at the same time the routing table will be updated by incrementing
the goodness pj     j   k      of the last node k     the ant b    came from 
for the case of node i   k                as destination node  and decrementing the
values of p for the other neighbors  here not shown   the increment will be a
function of the trip time experienced by the forward ant going from node k to
destination node i  as for m  the routing table is always updated for the case of
node   as destination  while the other nodes i    k                on the sub paths
are taken in consideration as destination nodes only if the trip time associated to
the corresponding sub path of the forward ant is statistically good 
in the experiments we ran with this strategy  the algorithm showed moderately good
performance  these results suggest that the  implicit  component of the algorithm 
based on the ant arrival rate  plays a very important role  of course  to compete with
state of the art algorithms  the available information about path costs has to be used 
 more elaborate approaches define r as a function of the ant s trip time t   and of the
parameters of the local statistical model m  we tested several alternatives  by using
different linear  quadratic and hyperbolic combinations of the t and m values  in
the following we limit the discussion to the functional form that gave the best results 
and that we used in the reported experiments 
r   c 

w

best

t







  c   i   iisup    iinf
 t   iinf    
sup inf

   

in equation    wbest is the best trip time experienced by the ants traveling toward
the destination d  over the last observation window w   the maximum size of the window
 the maximum number of considered samples before resetting the wbest value  is assigned
on the basis of the coecient  of equation    as we said   weights the number of
samples effectively giving a contribution to the value of the  estimate  defining a sort of
moving exponential window  following the expression for the number of effective samples
as reported in footnote    we set jwjmax     c    with c      in this way  the longterm exponential mean and the short term windowing are referring to a comparable set of
observations  with the short term mean evaluated over a fraction c of the samples used for
   

fiantnet  distributed stigmergetic control for communications networks

the long term one  isup and iinf are convenient estimates of the limits of
p an approximate
jwj   with z  
confidence
interval
for

 
i
is
set
to
w
 
while
i
 

 
z
 
 
sup
inf
best
p
  
           where  gives the selected confidence level  there is some level of arbitrariness
in our computation of the confidence interval  because we set it in an asymmetric way and
 and  are not arithmetic estimates  anyway  what we need is a quick  raw estimate of the
mean value and of the dispersion of the values  for example  a local bootstrap procedure
could have been applied to extract a meaningful confidence interval  but such a choice is
not reasonable from a cpu time consuming perspective  
the first term in equation   simply evaluates the ratio between the current trip time and
the best trip time observed over the current observation window  this term is corrected
by the second one  that evaluates how far the value t is from iinf in relation to the
extension of the confidence interval  that is  considering the stability in the latest trip
times  the coecients c  and c  weight the importance of each term  the first term is the
most important one  while the second term plays the role of a correction  in the current
implementation of the algorithm we set c        and c         we observed that c  shouldn t
be too big       is an upper limit   otherwise performance starts to degrade appreciably 
the behavior of the algorithm is quite stable for c  values in the range      to      but
setting c  below      slightly degrades performance  the algorithm is very robust to changes
in    which defines the confidence level  varying the confidence level in the range from    
to     changes performance little  the best results have been obtained for values around
        we observed that the algorithm is very robust to its internal parameter settings
and we didn t try to  adapt  the set of parameters to the problem instance  all the different
experiments were carried out with the same  reasonable  settings  we could surely improve
the performance by means of a finer tuning of the parameters  but we didn t because we
were interested in implementing a robust system  considering that the world of networks is
incredibly varied in terms of trac  topologies  switch and transmission characteristics  etc 
the value r obtained from equation   is finally transformed by means of a squash
function s x  

 a     
 
s x        exp
xjn j
k

r

s r 
 
s   

x           a   r   

   
   

squashing the r values allows the system to be more sensitive in rewarding good  high 
values of r  while having the tendency to saturate the rewards for bad  near to zero  r
values  the scale is compressed for lower values and expanded in the upper part  in such a
way an emphasis is put on good results  while bad results play a minor role 
    the expression is obtained by using the tchebycheff inequality that allows the definition of a confidence
interval for a random variable following any distribution  papoulis        usually  for specific probability
densities the tchebycheff bound is too high  but here we can conveniently use it because  i  we want
to avoid to make assumptions on the distribution of  and   ii  we need only a raw estimate of the
confidence interval 

   

fidi caro   dorigo

 

   
  neighbors
  neighbors
  neighbors
  neighbors

   
s r  s   

the coecient a jnk j determines a
parametric dependence of the squashed
reinforcement value on the number
jnk j of neighbors of the reinforced node
k  the greater the number of neighbors 
the higher the reinforcement  see figure     the reason to do this is that we
want to have a similar  strong  effect of
good results on the probabilistic routing tables  independent of the number
of neighbor nodes 

   

   

 
 

   

   

   

   

 

r

figure    examples of squash functions with a
variable number of node neighbors 

   routing algorithms used for comparison

to evaluate the performance of antnet  we compared it with state of the art routing algorithms from the telecommunications and machine learning fields  the following algorithms 
belonging to the various possible combinations of static and adaptive  distance vector and
link state classes  see appendix a   have been implemented and used to run comparisons 

ospf  static  link state   is our implementation of the current interior gateway pro 

tocol  igp  of internet  moy         being interested in studying routing under the
assumptions described in section    the routing protocol we implemented does not
mirror the real ospf protocol in all its details  it only retains the basic features of
ospf  link costs are statically assigned on the basis of their physical characteristics
and routing tables are set as the result of the shortest  minimum time  path computation for a sample data packet of size     bytes  it is worth remarking that this
choice penalizes our version of ospf with respect to the real one  in fact  in the real
internet link costs are set by network administrators who can use additional heuristic
and on field knowledge they have about trac workloads 

spf  adaptive  link state   is the prototype of link state algorithms with dynamic met 

ric for link costs evaluations  a similar algorithm was implemented in the second
version of arpanet  mcquillan  richer    rosen        and in its successive revisions  khanna   zinky         our implementation uses the same ooding algorithm 
while link costs are assigned over a discrete scale of    values by using the arpanet
hop normalized delay metric    khanna   zinky        and the the statistical window average method described in  shankar  alaettinoglu  dussa zieger    matta 
    a   link costs are computed as weighted averages between short and long term
real valued statistics reecting the delay  e g   utilization  queueing and or transmis 

    the transmitting node monitors the average packet delay d  queuing and transmission  and the average
packet transmission time t over fix observation windows  from these measures  assuming an m m  
queueing model  bertsekas   gallager         a link utilization cost measure is calculated as     t d 

   

fiantnet  distributed stigmergetic control for communications networks

sion delay  etc   over fixed time intervals  obtained values are rescaled and saturated
by a linear function  we tried several additional discrete and real valued metrics but
the discretized hop normalized delay gave the best results in terms of performance
and stability  using a discretized scale reduces the sensitivity of the algorithm but at
the same time reduces also undesirable oscillations 

bf  adaptive  distance vector   is an implementation of the asynchronous distributed
bellman ford algorithm with dynamic metrics  bertsekas   gallager        shankar
et al       a   the algorithm has been implemented following the guidelines of appendix a  while link costs are assigned in the same way as described for spf above 
vector distance bellman ford like algorithms are today in use mainly for intra domain
routing  because they are used in the routing information protocol  rip   malkin
  steenstrup        supplied with the bsd version of unix  several enhanced versions of the basic adaptive bellman ford algorithm can be found in the literature  for
example the merlin segall  merlin   segall        and the extended bellman ford
 cheng  riley  kumar    garcia luna aceves        algorithms   they focus mainly
on reducing the information dissemination time in case of link failures  when link
failures are not a major issue  as in this paper  their behavior is in general equivalent
to that of the basic adaptive bellman ford 

q r  adaptive  distance vector   is the q routing algorithm as proposed by boyan

and littman         this is an online asynchronous version of the bellman ford
algorithm  q r learns online the values qk  d  n   which are estimates of the time
to reach node d from node k via the neighbor node n  upon sending a packet p
from k to neighbor node n with destination d  a back packet pback is immediately
generated from n to k  pback carries the information about the current time estimate
tn d   minn   nn qn  d  n    held at node n about the time to go for destination d  and
the sum tpk n of the queuing and transmission time experienced by p since its arrival
at node k  the sum qnew  d  n    tn d   tpk n is used to compute the variation
qk  d  n     qnew  d  n    qk  d  n   of the q learning like value qk  d  n  

pq r  adaptive  distance vector   is the predictive q routing algorithm  choi   ye 

ung         an extension of q routing  in q routing the best link  i e   the one with
the lowest qk  d  n   is deterministically chosen by packets  therefore  a link that
happens to have a high expected qk  d  n   for example because of a temporary load
condition  will never be used again until all the other links exiting from the same node
have a worse  that is higher  qk  d  n   pq r learns a model of the rate of variation of
links  queues  called the recovery rate  and uses it to probe those links that  although
not having the lowest qk  d  n   have a high recovery rate 

daemon  adaptive  optimal routing   is an approximation of an ideal algorithm  it

defines an empirical bound on the achievable performance  it gives some information about how much improvement is still possible  in the absence of any a priori
assumption on trac statistics  the empirical bound can be defined by an algorithm
possessing a  daemon  able to read in every instant the state of all the queues in the
network and then calculating instantaneous  real  costs for all the links and assigning
   

fidi caro   dorigo

paths on the basis of a network wide shortest paths re calculation for every packet
hop  links costs used in shortest paths calculations are the following 
s
s
s
cl   dl   p        ff  q l    ff q l   
b
b
b
l

l

l

where dl is the transmission delay for link l  bl is its bandwidth  sp is the size  in
bits  of the data packet doing the hop  sq l  is the size  in bits  of the queue of link
l  sq l  is the exponential mean of the size of links queue and it is a correction to the
actual size of the link queue on the basis of what observed until that moment  this
correction is weighted by the ff value set to      of course  given the arbitrariness
we introduced in calculating cl   it could be possible to define an even better daemon
algorithm 

   experimental settings
the functioning of a communication network is governed by many components  which may
interact in nonlinear and unpredictable ways  therefore  the choice of a meaningful testbed
to compare competing algorithms is no easy task 
a limited set of classes of tunable components is defined and for each class our choices
are explained 

    topology and physical properties of the net

topology can be defined on the basis of a real net instance or it can defined by hand  to
better analyze the inuence of important topological features  like diameter  connectivity 
etc   
nodes are mainly characterized by their buffering and processing capacity  whereas links
are characterized by their propagation delay  bandwidth and streams multiplexing scheme 
for both  fault probability distributions should be defined 
in our experiments  we used three significant net instances with increasing numbers
of nodes  for all of them we describe the main characteristics and we summarize the
topological properties by means of a triple of numbers      n   indicating respectively the
mean shortest path distance  in terms of hops  between all pairs of nodes  the variance of
this average  and the total number of nodes  from these three numbers we can get an idea
about the degree of connectivity and balancing of the network  the diculty of the routing
problem roughly increases with the value of these numbers 

 simplenet               is a small network specifically designed to study some aspects

of the behavior of the algorithms we compare  experiments with simplenet were
designed to closely study how the different algorithms manage to distribute the load
on the different possible paths  simplenet is composed of   nodes and   bi directional
links with a bandwidth of    mbit s and propagation delay of   msec  the topology
is shown in figure   
 nsfnet                is the old usa t  backbone         nsfnet is a wan
composed of    nodes and    bi directional links with a bandwidth of     mbit s  its
   

fiantnet  distributed stigmergetic control for communications networks

 

 

 

 

 
 

 

 

figure    simplenet  numbers within circles are node identifiers  shaded nodes have a
special interpretation in our experiments  described later  each edge in the graph
represents a pair of directed links  link bandwidth is    mbit sec  propagation
delay is   msec 
topology is shown in figure    propagation delays range from   to    msec  nsfnet
is a well balanced network 

figure    nsfnet  each edge in the graph represents a pair of directed links  link bandwidth is     mbit sec  propagation delays range from   to    msec 

 nttnet                is the major japanese backbone  nttnet is the ntt  nippon

telephone and telegraph company  fiber optic corporate backbone  nttnet is a
   nodes      bi directional links network  link bandwidth is of   mbit sec  while
propagation delays range around   to   msec  the topology is shown in figure   
nttnet is not a well balanced network 

figure    nttnet  each edge in the graph represents a pair of directed links  link bandwidth is   mbit sec  propagation delays range from   to   msec 
   

fidi caro   dorigo

all the networks are simulated with zero link fault and node fault probabilities  local
node buffers of   gbit capacity  and data packets maximum time to live  ttl  set to   
sec 

    trac patterns

trac is defined in terms of open sessions between pairs of different nodes  trac patterns
can show a huge variety of forms  depending on the characteristics of each session and on
their distribution from geographical and temporal points of view 
each single session is characterized by the number of transmitted packets  and by their
size and inter arrival time distributions  more generally  priority  costs and requested quality
of service should be used to completely characterize a session 
sessions over the network can be characterized by their inter arrival time distribution
and by their geographical distribution  the latter is controlled by the probability assigned
to each node to be selected as a session start or end point 
we considered three basic patterns for the temporal distribution of the sessions  and
three for their spatial distribution 
temporal distributions 
 poisson  p   for each node a poisson process is defined which regulates the arrival of
new sessions  i e   sessions inter arrival times are negative exponentially distributed 
 fixed  f   at the beginning of the simulation  for each node  a fixed number of oneto all sessions is set up and left constant for the remainder of the simulation 
 temporary  tmphs   a temporary  heavy load  trac condition is generated turning
on some nodes that act like hot spots  see below  
spatial distributions 
 uniform  u   the assigned temporal characteristics for session arrivals are set identically for all the network nodes 
 random  r   in this case  the assigned temporal characteristics for session arrivals are
set in a random way over the network nodes 
 hot spots  hs   some nodes behave as hot spots  concentrating a high rate of input output trac  a fixed number of sessions are opened from the hot spots to all
the other nodes 
general trac patterns have been obtained combining the above temporal and spatial
characteristics  therefore  for example  up trac means that  for each node  an identical
poisson process is regulating the arrival of new sessions  while in the rp case the process is
different for each node  and up hs means that a hot spots trac model is superimposed
to a up trac 
concerning the shape of the bit stream generated by each session  we consider two basic
types 
 constant bit rate  cbr   the per session bit rate is maintained fixed  examples of
applications of cbr streams are the voice signal in a telephone network  which is
converted into a stream of bits with a constant rate of    kbit sec  and the mpeg 
compression standard  which converts a video signal in a stream of     mbit sec 
   

fiantnet  distributed stigmergetic control for communications networks

 generic variable bit rate  gvbr   the per session generated bit rate is time varying 

the term gvbr is a broad generalization of the vbr term normally used to designate
a bit stream with a variable bit rate but with known average characteristics and
expected admitted uctuations    here  a gvbr session generates packets whose
sizes and inter arrival times are variable and follow a negative exponential distribution 
the information about these characteristics is never directly used by the routing
algorithms  like in ip based networks 
the values we used in the experiments to shape trac patterns are  reasonable  values
for session generations and data packet production taking into consideration current network
usage and computing power  the mean of the packet size distribution has been set to     
bits in all the experiments  basic temporal and spatial distributions have been chosen to
be representative of a wide class of possible situations that can be arbitrarily composed to
generate a meaningful subset of real trac patterns 

    metrics for performance evaluation

depending on the type of services delivered on the network and on their associated costs 
many performance metrics could be defined  we focused on standard metrics for performance evaluation  considering only sessions with equal costs  benefits and priority and
without the possibility of requests for special services like real time  in this framework  the
measures we are interested in are  throughput  correctly delivered bits sec   delay distribution for data packets  sec   and network capacity usage  for data and routing packets  
expressed as the sum of the used link capacities divided by the total available link capacity 

    routing algorithms parameters

all the algorithms used have a collection of parameters to be set  common parameters
are routing packet size and elaboration time  settings for these parameters are shown
in table    these parameters have been assigned to values used in previous simulation
packet size  byte 
packet elaboration time  msec 

antnet ospf   spf
bf
q r   pq r
      nh       jnn j        n
  
 
 
 
 

table    routing packets characteristics for the implemented algorithms  except for the
daemon algorithm  which does not generate routing packets   nh is the incremental number of hops made by the forward ant  jnn j is the number of neighbors of
node n  and n is the number of network nodes 
works  alaettinoglu et al         and or on the basis of heuristic evaluations taking into
    the knowledge about the characteristics of the incoming cbr or vbr bit streams is of fundamental
importance in networks able to deliver quality of service  it is only on the basis of this knowledge that
the network can accept refuse the session requests  and  in case of acceptance  allocate reserve necessary
resources 

   

fidi caro   dorigo

consideration information encoding schemes and currently available computing power  e g  
the size for forward ants has been determined as the same size of a bf packet plus   bytes for
each hop to store the information about the node address and the elapsed time   concerning
the other main parameters  specific for each algorithm  for the antnet competitors we used
the best settings we could find in the literature and or we tried to tune the parameters
as much as possible to obtain better results  for ospf  spf  and bf  the length of the
time interval between consecutive routing information broadcasts and the length of the time
window to average link costs are the same  and they are set to     or   seconds  depending on
the experiment for spf and bf  and to    seconds for ospf  link costs inside each window
are assigned as the weighted sum between the arithmetic average over the window and the
exponential average with decay factor equal to      the obtained values are discretized
over a linear scale saturated between   and     with slope set to    and maximum admitted
variation equal to    for q r and pq r the transmission of routing information is totally
data driven  the learning and adaptation rate we used were the same as used by the
algorithm s authors  boyan   littman        choi   yeung        
concerning antnet  we observed that the algorithm is very robust to internal parameters
tuning  we did not finely tune the parameter set  and we used the same set of values for all
the different experiments we ran  most of the settings we used have been previously given
in the text at the moment the parameter was discussed and they are not reported in this
section  the ant generation interval at each node was set to     seconds  in section    
it will be shown the robustness of antnet with respect to this parameter  regarding the
parameters of the statistical model  the value of   weighting the number of the samples
considered in the model  equation     has been set to        the c factor for the expression
of jwjmax  sect       has been put equal to      and the confidence level factor z  sect      
equal to       meaning a confidence level of approximately      

   results

experiments reported in this section compare antnet with the competing routing algorithms described in section    we studied the performance of the algorithms for increasing
trac load  examining the evolution of the network status toward a saturation condition 
and for temporary saturation conditions 
 under low load conditions  all algorithms tested have similar performance  in this
case  also considering the huge variability in the possible trac patterns  it is very
hard to assess whether an algorithm is significantly better than another or not 
 under high  near saturation  loads  all the tested algorithms are able to deliver the
offered throughput in a quite similar way  that is  in most of the cases all the generated trac is routed without big losses  on the contrary  the study of packet delay
distributions shows remarkable differences among the different algorithms  to present
simulation results regarding packet delays we decided either to report the whole empirical distribution or to use the    th percentile statistic  which allows one to compare
the algorithms on the basis of the upper value of delay they were able to keep the    
of the correctly delivered packets  in fact  packet delays can be spread over a wide
range of values  this is an intrinsic characteristics of data networks  packet delays
can range from very low values for sessions open between adjacent nodes connected by
   

fiantnet  distributed stigmergetic control for communications networks

fast links  to much higher values in the case of sessions involving nodes very far apart
connected by many slow links  because of this  very often the empirical distribution
of packet delays cannot be meaningfully parametrized in terms of mean and variance 
and the    th percentile statistic  or still better the whole empirical distribution  are
much more meaningful 
 under saturation there are packet losses and or packet delays that become too big 
cause all the network operations to slow down  therefore  saturation has to be only
a temporary situation  if it is not  structural changes to the network characteristics 
like adding new and faster connection lines  rather than improvements of the routing
algorithm  should be in order  for these reasons  we studied the responsiveness of the
algorithms to trac loads causing only a temporary saturation 
all reported data are averaged over    trials lasting      virtual seconds of simulation
time  one thousand seconds represents a time interval long enough to expire all transients
and to get enough statistical data to evaluate the behavior of the routing algorithm  before
being fed with data trac  the algorithms are given     preliminary simulation seconds with
no data trac to build initial routing tables  in this way  each algorithm builds the routing
tables according to its own  vision  about minimum cost paths  results for throughput
are reported as average values without an associated measure of variance  the inter trial
variability is in fact always very low  a few percent of the average value 
parameter values for trac characteristics are given in the figure captions with the
following meaning  see also previous section   msia is the mean of the sessions inter arrival
time distribution for the poisson  p  case  mpia stands for the mean of the packet interarrival time distribution  in the cbr case  mpia indicates the fixed packet production
rate  hs is the number of hot spots nodes and mpia hs is the equivalent of mpia for the
hot spot sessions  in the following  when not otherwise explicitly stated  the shape of the
session bit streams is assumed to be of gvbr type 
results for throughput and packet delays for all the considered network topologies are
described in the three following subsections  results concerning the network resources
utilization are reported in section     

    simplenet

experiments with simplenet were designed to study how the different algorithms manage
to distribute the load on the different possible paths  in these experiments  all the trac 
of f cbr type  is directed from node   to node    see figure     and the trac load has
been set to a value higher than the capacity of a single link  so that it cannot be routed
eciently on a single path 
results regarding throughput  figure  a  in this case strongly discriminate among the
algorithms  the type of the trac workload and the small number of nodes determined
significant differences in throughput  antnet is the only algorithm able to deliver almost
all the generated data trac  its throughput after a short transient phase approaches very
closely the level of that delivered by the daemon algorithm  pq r attains a steady value
approximately     inferior to that obtained by antnet  the other algorithms behave very
poorly  stabilizing on values of about     inferior to those provided by antnet  in this
   

fidi caro   dorigo

case  it is rather clear that antnet is the only algorithm able to exploit at best all the three
available paths                               to distribute the data trac without inducing
counterproductive oscillations  the utilization of the routing tables in a probabilistic way
also by data packets in this case plays a fundamental role in achieving higher quality results  results for throughput are confirmed by those for packet delays  reported in the
graph of figure  b  the differences in the empirical distributions for packet delays reect
approximatively the same proportions as evidenced in the throughput case 
    

   

    

throughput      bit sec 

    
    

   
empirical distribution

ospf
spf
bf
q r
pq r
antnet
daemon

    

    
    
    

   

   

ospf
spf
bf
q r
pq r
antnet
daemon

   

    
   

   
 

   

   

   

   

   

   

   

   

   

    

simulation time  sec 

 

    

   

    

   

packet delay  sec 

 a 

 b 

figure    simplenet  comparison of algorithms for f cbr trac directed from node   to node  
 mpia          sec    a  throughput  and  b  packet delays empirical distribution 

    nsfnet

we carried out a wide range of experiments on nsfnet using up  rp  up hs and tmphsup trac patterns  in all the cases considered  differences in throughput are of minor
importance with respect to those shown by packet delays  for each one of the up  rp
and up hs cases we ran five distinct groups of ten trial experiments  gradually increasing
the generated workload  in terms of reducing the session inter arrival time   as explained
above  we studied the behavior of the algorithms when moving the trac load towards a
saturation region 
in the up case  differences in throughput  figure  a  are small  the best performing
algorithms are bf and spf  which can attain performance of only about     inferior to
those of daemon and of the same amount better than those of antnet  q r and pq r   
while ospf behaves slightly better than these last ones  concerning delays  figure  b  the
    it is worth remarking that in these and in some of the experiments presented in the following  pq r s
performance is slightly worse than that of q r  this seems to be in contrast with the results presented
by the pq r s authors in the article where they introduced pq r  choi   yeung         we think that
this behavior is due to the fact that  i  their link recovery rate matches a discrete time system while
in our simulator time is a continuous variable  and  ii  the experimental and simulation conditions are
rather different  in their article it is not specified the way they produced trac patterns and they did
not implement a realistic network simulator  

   

fiantnet  distributed stigmergetic control for communications networks

antnet

   

ospf

   

spf

   

bf

   

q r

 

pq r

daemon

   
   
   
   
   
   
   
   
   
   
antnet

ospf

   

spf

   

 b 

   

bf

   

q r

 

pq r

daemon

situation is rather different  as can be seen by the fact that all the algorithms but antnet
have been able to produce a slightly higher throughput at the expenses of much worse
results for packet delays  this trend in packet delays was confirmed by all the experiments
we ran  ospf  q r and pq r show really poor results  delays of order   or more seconds
are very high values  even if we are considering the    th percentile of the distribution  
while bf and spf behave in a similar way with performance of order     worse than those
obtained by antnet and of order     worse than daemon 
  
  
  
  

 

  

 
 
 
 

 a 

   th percentile of packet delays  sec 

   

in the rp case  figure   a   throughputs generated by antnet  spf and bf are very
similar  although antnet has a slightly better performance  ospf and pq r behave only
slightly worse while q r is the worst algorithm  daemon is able to obtain only slightly
better results than antnet  again  looking at packet delays results  figure   b  ospf 
q r and pq r perform very badly  while spf shows results a bit better than those of bf
but of order     worse than those of antnet  daemon is in this case far better  which
indicates that the testbed was very dicult 
for the case of up hs load  throughputs  figure   a  for antnet  spf  bf  q r and
daemon are very similar  while ospf and pq r clearly show much worse results  again
 figure   b   packet delays results for ospf  q r and pq r are much worse than those
of the other algorithms  they are so much worse that they do not fit in the scale chosen
to make clear differences among the other algorithms   antnet is still the best performing
algorithm  in this case  differences with spf are of order     and of     with respect to
bf  daemon performs about     better than antnet and scales much better than antnet 
which  again  indicates the testbed was rather dicult 
the last graph for nsfnet shows how the algorithms behave in the case of a tmphsup situation  figure      at time t       four hot spots are turned on and superimposed
to the existing light up trac  the transient is kept on for     seconds  in this case  only
one  typical  situation is reported in detail to show the answer curves  reported values

figure    nsfnet  comparison of algorithms for increasing load for up trac  the load is
increased reducing the msia value from     to   seconds  mpia         sec    a 
throughput  and  b     th percentile of the packet delays empirical distribution 

throughput      bit sec 

fi  

  

 

 

 

 

 
antnet

   

ospf

   

spf

 a 

   

bf

   

q r

   

daemon

   
   
   
   
   
   
   
   
   
antnet

di caro   dorigo

pq r

   th percentile of packet delays  sec 

  
  
  
  
  
 
 
 
 
 
antnet

ospf

   

spf

   

bf

   

q r

   

pq r

 

 a 

daemon

   

   

   

   

   

   

   
antnet

ospf

   

spf

   

ospf

   

spf

   

bf

   

 b 

 b 

   

bf

   

q r

   

q r

   

 

pq r

pq r

daemon

daemon

are the  instantaneous  values for throughput and packet delays computed as the average
over   seconds moving windows  all algorithms have a similar very good performance as
far as throughput is concerned  except for ospf and pq r  which lose a few percent of
the packets during the transitory period  the graph of packet delays confirms previous
results  spf and bf have a similar behavior  about     worse than antnet and    
worse than daemon  the other three algorithms show a big out of scale jump  being not
able to properly dump the sudden load increase 

figure     nsfnet  comparison of algorithms for increasing load for up hs trac  the load is
increased reducing the msia value from     to     seconds  mpia       sec  hs     
mpia hs        sec    a  throughput  and  b     th percentile of the packet delays
empirical distribution 

   th percentile of packet delays  sec 

figure     nsfnet  comparison of algorithms for increasing load for rp trac  the load is
increased reducing the msia value from     to     seconds  mpia         sec    a 
throughput  and  b     th percentile of the packet delays empirical distribution 

throughput      bit sec 
throughput      bit sec 

fithroughput      bit sec 

antnet  distributed stigmergetic control for communications networks

    
    
    
    
   
   

packet delay  sec 

    
ospf
spf
bf
q r
pq r
antnet
daemon

    

    

    
   

   

   

   

   

   

   

   

    

simulation time  sec 

figure     nsfnet  comparison of algorithms for transient saturation conditions with
tmphs up trac  msia       sec  mpia       sec  hs      mpia hs  
        a  throughput  and  b  packet delays averaged over   seconds moving
windows 

    nttnet
the same set of experiments run on the nsfnet have been repeated on nttnet  in this
case the results are even sharper than those obtained with nsfnet  antnet performance
is much better that of all its competitors 
for the up  rp and up hs cases  differences in throughput are not significant  figures
  a    a and   a   all the algorithms  with the ospf exception  practically behave in
the same way as the daemon algorithm  concerning delays  figures   b    b and   b  
differences between antnet and each of its competitors are of one order of magnitude 
antnet keeps delays at low values  very close to those obtained by daemon  while spf 
bf  q r and pq r perform poorly and ospf completely collapses 
in the up and rp cases  figures   b and   b  spf and bf performs similarly  even if spf
shows slightly better results  and about     better than q r and pq r 
in the up hs case  again  spf and bf show similar results  while q r performs comparably but in a much more irregular way and pq r can keep delays about     lower  ospf 
which is the worse algorithm in this case  shows an interesting behavior  the increase in the
generated data throughput determines a decrease or a very slow increase in the delivered
throughput while delays decrease  figure   a and   b   in this case the load was too high
for the algorithm and the balance between the two  conicting  objectives  throughput and
   

fi  
  
  
  
  
  
  
  
 
 
antnet

   

ospf

 

spf

bf

   

 a 

   

q r

   

daemon

   

   

   

   

   

   

   

   

   

   

    

di caro   dorigo

pq r

   th percentile of packet delays  sec 

  
  
  
  
  
  
  
  
 
 
antnet

ospf

   

spf

 

bf

   

 a 

   

q r

   

pq r

daemon

   

    
   
   
   
   
   
   
   
   
   
   

antnet

antnet

ospf

   

spf

 

   

 b 

ospf

   

spf

 

   

 b 

bf

bf

   

   

q r

q r

   

   

pq r

pq r

daemon

daemon

packet delays  showed an inverse dynamics  having a lot of packet losses made it possible
for the surviving packets to obtain lower trip delays 
the tmphs up experiment  figure      concerning sudden load variation  confirms
the previous results  ospf is not able to follow properly the variation both for throughput
and delays  all the other algorithms are able to follow the sudden increase in the offered
throughput  but only antnet  and daemon  show a very regular behavior  differences in
packet delays are striking  antnet performance is very close to those obtained by daemon
 the curves are practically superimposed at the scale used in the figure   among the other
algorithms  spf and bf are the best ones  although their response is rather irregular and 
in any case  much worse than antnet s  ospf and q r are out of scale and show a very
delayed recovering curve  pq r  after a huge jump  which takes the graph out of scale in

figure     nttnet  comparison of algorithms for increasing load for rp trac  the load is
increased reducing the msia value from     to     seconds  mpia         sec    a 
throughput  and  b     th percentile of the packet delays empirical distribution 

   th percentile of packet delays  sec 

figure     nttnet  comparison of algorithms for increasing load for up trac  the load is
increased reducing the msia value from     to     seconds  mpia         sec    a 
throughput  and  b     th percentile of the packet delays empirical distribution 

throughput      bit sec 
throughput      bit sec 

fiantnet  distributed stigmergetic control for communications networks

 

   

   

   

   th percentile of packet delays  sec 

   
  

throughput      bit sec 

  
  
  
  
  
  
  
  
 
 
antnet

ospf

spf

bf

q r

pq r

daemon

   

 

   

   

   

   
   
   
   
   
   
   
   
antnet

ospf

 a 

spf

bf

q r

pq r

daemon

 b 

figure     nttnet  comparison of algorithms for increasing load for up hs trac  the load is

increased reducing the msia value from     to     seconds  mpia       sec  hs     
mpia hs        sec    a  throughput  and  b     th percentile of the packet delays
empirical distribution 

throughput      bit sec 

the first    seconds after hot spots are turned on  shows a trend approaching those of bf
and spf 
    
    
    
    
    

packet delay  sec 

   
ospf
spf
bf
q r
pq r
antnet
daemon

   
   
   
   
   

   

   

   

   

   

   

   

    

simulation time  sec 

figure     nttnet  comparison of algorithms for transient saturation conditions with
tmphs up trac  msia       sec  mpia       sec  hs      mpia hs  
        a  throughput  and  b  packet delays averaged over   seconds moving
windows 
   

fidi caro   dorigo

    routing overhead

table   reports results concerning the overhead generated by routing packets  for each
algorithm the network load generated by the routing packets is reported as the ratio between
the bandwidth occupied by the routing packets and the total available network bandwidth 
each row in the table refers to a previously discussed experiment  figs    to    and   
to      routing overhead is computed for the experiment with the heaviest load in the
increasing load series 
simplenet   f cbr
nsfnet   up
nsfnet   rp
nsfnet   up hs
nttnet   up
nttnet   rp
nttnet   up hs

antnet ospf spf bf q r pq r
    
                        
    
                        
    
                        
    
                        
    
                        
    
                        
    
                        

table    routing overhead  ratio between the bandwidth occupied by the routing packets
and the total available network bandwidth  all data are scaled by a factor of       
all data are scaled by a factor of        the data in the table show that the routing
overhead is negligible for all the algorithms with respect to the available bandwidth  among
the adaptive algorithms  bf shows the lowest overhead  closely followed by spf  antnet
generates a slightly bigger consumption of network resources  but this is widely compensated
by the much higher performance it provides  q r and pq r produce an overhead a bit
higher than that of antnet  the routing load caused by the different algorithms is a function
of many factors  specific of each algorithm  q r and pq r are data driven algorithms  if
the number of data packets and or the length of the followed paths  because of topology
or bad routing  grows  so will the number of generated routing packets  bf  spf and
ospf have a more predictable behavior  the generated overhead is mainly function of the
topological properties of the network and of the generation rate of the routing information
packets  antnet produces a routing overhead depending on the ants generation rate and
on the length of the paths they travel 
the ant trac can be roughly characterized as a collection of additional trac sources 
one for each network node  producing very small packets  and related acknowledgement
packets  at constant bit rate with destinations matching the offered data trac  on average
ants will travel over rather  short  paths and their size will grow of only   bytes at each hop 
therefore  each  ant routing trac source  represents a very light additional trac source
with respect to network resources when the ant launching rate is not excessively high  in
figure     the sensitivity of antnet with respect to the ant launching rate is reported 
for a sample case of a up data trac model on nsfnet  previously studied in figure
   the interval g between two consecutive ant generations is progressively decreased  g
is the same for all nodes   g values are sampled at constant intervals over a logarithmic
scale ranging from about       to    seconds  the lower  dashed  curve interpolates the
   

fiantnet  distributed stigmergetic control for communications networks

antnet normalized power vs  routing overhead

   

   
normalized power
routing overhead
   

   

   

   
     

    

   

 

  

   

interval g between two consecutive ants generations  sec 

figure     antnet normalized power vs  routing overhead  power is defined as the ratio
between delivered throughput and packet delay 
generated routing overhead expressed  as before  as the fraction of the available network
bandwidth used by routing packets  the upper  solid  curve plots the data for the obtained
power normalized to its highest value  where the power is defined as the ratio between the
delivered throughput and the packet delay  the value used for delivered throughput is the
throughput value at time      averaged over ten trials  while for packet delay we used the
   th percentile of the empirical distribution 
in the figure  we can see how an excessively small g causes an excessive growth of the
routing overhead  with consequent reduction of the algorithm power  similarly  when g
is too big  the power slowly diminishes and tends toward a plateau because the number of
ants is not enough to generate and maintain up to date statistics of the network status  in
the middle of these two extreme regions a wide range of g intervals gives raise to similar 
very good power values  while  at the same time  the routing overhead quickly falls down
toward negligible values  this figure strongly confirms our previous assertion about the
robustness of antnet s internal parameter settings 

   discussion
in antnet  the continual on line construction of the routing tables is the emergent result
of a collective learning process  in fact  each forward backward agent pair is complex
enough to find a good route and to adapt the routing tables for a single source destination
path  but it cannot solve the global routing optimization problem  it is the interaction
between the agents that determines the emergence of a global effective behavior from the
network performance point of view  ants cooperate in their problem solving activity by
communicating in an indirect and non coordinated way  each agent acts independently 
good routes are discovered by applying a policy that is a function of the information
   

fidi caro   dorigo

accessed through the network nodes visited  and the information collected about the route
is eventually released on the same nodes  therefore  the inter agent communication is
mediated in an explicit and implicit way by the  environment   that is  by the node s data
structures and by the trac patterns recursively generated by the data packets  utilization
of the routing tables  this communication paradigm  called stigmergy  matches well the
intrinsically distributed nature of the routing problem  cooperation among agents goes
on at two levels   a  by modifications of the routing tables  and  b  by modifications of
local models that determine the way the ants  performance is evaluated  modifications of
the routing tables directly affect the routing decisions of following ants towards the same
destination  as well as the routing of data  which  in turn  inuences the rate of arrival
of other ants towards any destination  it is interesting to remark that the used stigmergy
paradigm makes the antnet s mobile agents very exible from a software engineering point
of view  in this perspective  once the interface with the node s data structure is defined 
the internal policy of the agents can be transparently updated  also  the agents could be
exploited to carry out multiple concurrent tasks  e g   collecting information for distributed
network management using an snmp like protocol or for web data mining tasks  
as shown in the previous section  the results we obtained with the above stigmergetic
model of computation are excellent  in terms of throughput and average delay  antnet
performs better than both classical and recently proposed routing algorithms on a wide
range of experimental conditions  although this is very interesting per se  in the following
we try to justify antnet superior performance by highlighting some of its characteristics
and by comparing them with those of the competing algorithms  we focus on the following
main aspects 

 antnet can be seen as a particular instance of a parallel monte carlo simulation






system with biased exploration  all the other algorithms either do not explore the
net or their exploration is local and tightly connected to the ux of data packets 
the information antnet maintains at each node is more complete and organized in a
less critical way than that managed by the other algorithms 
antnet does not propagate local estimates to other nodes  while all its competitors
do  this mechanism makes the algorithm more robust to locally wrong estimates 
antnet uses probabilistic routing tables  which have the triple positive effect of better redistributing data trac on alternative routes  of providing ants with a built in
exploration mechanism and of allowing the exploitation of the ants  arrival rate to
assign cumulative reinforcements 
it was experimentally observed that antnet is much more robust than its competitors
to the frequency with which routing tables are updated 
the structure of antnet allows one to draw some parallels with some well known
reinforcement learning  rl  algorithms  the characteristics of the routing problem 
that can be seen as a distributed time varying rl problem  see sect        determines
a departure of antnet from the structure of classical rl algorithms 

these aspects of antnet are discussed in more detail in the following 
   

fiantnet  distributed stigmergetic control for communications networks

    antnet as an on line monte carlo system with biased exploration
the antnet routing system can be seen as a collection of mobile agents collecting data
about the network status by concurrently performing on line monte carlo simulations  rubistein        streltsov   vakili         in monte carlo methods  repeated experiments
with stochastic transition components are run to collect data about the statistics of interest  similarly  in antnet ants explore the network by performing random experiments
 i e   building paths from source to destination nodes using a stochastic policy dependent
on the past and current network states   and collect on line information on the network
status  a built in variance reduction effect is determined  i  by the way ants  destinations
are assigned  biased by the most frequently observed data s destinations  and  ii  by the way
the ants  policy makes use of current and past trac information  that is  inspection of the
local queues  status and probabilistic routing tables   in this way  the explored paths match
the most interesting paths from a data trac point of view  which results in a very ecient
variance reduction effect in the stochastic sampling of the paths  differently from usual
off line monte carlo systems  in antnet the state space sampling is performed on line  that
is  the sampling of the statistics and the controlling of the non stationary trac process are
performed concurrently 
this way of exploring the network concurrently with data trac is very different from
what happens in the other algorithms where  either there is no exploration at all  ospf 
spf and bf   or exploration is both tightly coupled to data trac and of a local nature
 q r and pq r   conveniently  as was shown in section      the extra trac generated by
exploring ants is negligible for a wide range of values  allowing very good performance 

    information management at each network node
key characteristics of routing algorithms are the type of information used to build update
routing tables and the way this information is propagated  all the algorithms  except the
static ospf  make use at each node of two main components  a local model m of some
cost measures and a routing table t   spf and bf use m to estimate smoothed averages
of the local link costs  that is  of the distances to the neighbor nodes  in this case  m is
a local model maintaining estimates of only local components  in q r the local model is
fictitious because the raw transition time is directly used as a value to update t   pq r
uses a slightly more sophisticated model with respect to q r  storing also a measure of the
link utilization  all these algorithms propagate part of their local information to the other
nodes  which  in turn  make use of it to update their routing tables and to build a global
view of the network  in spf and bf the content of each t is updated  at regular intervals 
by a  memoryless strategy   the new entries do not depend on the old values  that are
discarded  therefore  the whole adaptive component of the routing system is represented
by the model m  otherwise  in q r and pq r the adaptive content of m is almost
negligible and the adaptive component of the algorithm is represented by the smoothed
average carried out by the q learning like rule  antnet shows characteristics rather different
from its competitors  its model m contains a memory based local perspective of the global
status of the network  the content of m allow the reinforcements to be weighted on the
basis of a rich statistical description of the network dynamics as seen by the local node 
these reinforcements are used to update the routing table  the other adaptive component
   

fidi caro   dorigo

maintained at the node  the t updates are carried out in an asynchronous way and as a
function of their previous values  moreover  while t is used in a straightforward probabilistic
way by the data packets  traveling ants select the next node by using both t   that is  an
adaptive representation of the past policy  and a model of the current local link queues 
that is  an instantaneous representation of the node status  it is evident that antnet builds
and uses more information than its competitors  two different memory based components
and an instantaneous predictor are used and combined at different levels  moreover  in this
way antnet robustly redistributes among these completely local components the criticality
of all the estimates and decisions 

    antnet s robustness to wrong estimates

as remarked above  antnet  differently from its competitors  does not propagate local
estimates to other nodes  each node routing table is updated independently  by using
local information and the ants  experienced trip time  moreover   i  each ant experiment
affects only one entry in the routing table of the visited nodes  the one relative to the ant s
destination  and   ii  the local information is built from the  global  information collected
by traveling ants  implicitly reducing in this way the variance in the estimates  these
characteristics make antnet particularly robust to wrong estimates  on the contrary  in
all the other algorithms a locally wrong estimate will be propagated to all other nodes and
will be used to compute estimates to many different destinations  how bad this is for the
algorithm performance depends on how long the wrong estimate effect lasts  in particular 
this will be a function of the time window over which estimates are computed for spf and
bf  and of the learning parameters for q r and pq r 

    antnet s probabilistic use of routing tables to route data packets

all the tested algorithms but antnet use deterministic routing tables    in these algorithms 
entries in the routing tables contain distance time estimates to the destinations  these
estimates can provide misleading information if the algorithm is not fast enough to follow
the trac uctuations  as can be the case under heavy load conditions  instead  antnet
routing tables have probabilistic entries that  although reecting the goodness of a particular
path choice with respect to the others available  do not force the data packets to choose
the perceived best path  this has the positive effect of allowing a better balancing of
the trac load on different paths  with a resulting better utilization of the resources  as
was shown in particular in the experiments with the simplenet   as remarked at the
end of section      the intrinsic probabilistic structure of the routing tables and the way
they are updated allow antnet to exploit the ant s arrival rate as a way to assign implicit
 cumulative  reinforcements to discovered paths  it is not obvious how the same effect
could be obtained by using routing tables containing distance time estimates and using
this estimates in a probabilistic way  in fact  in this case each new trip time sample would
    singh  jaakkola  and jordan        showed that stochastic policies can yield higher performance than
deterministic policies in the case of an incomplete access to the state information of the environment  in
 jaakkola  singh    jordan         the same authors developed a monte carlo based stochastic policy
evaluation algorithm  confirming the usefulness of the monte carlo approach  used in antnet too  to
deal with incomplete information problems 

   

fiantnet  distributed stigmergetic control for communications networks

modify the statistical estimate that would simply oscillate around its expected value without
inducing an arrival dependent cumulative effect 
probabilistic routing tables provide some remarkable additional benefits   a  they give to
the ants a built in exploration method in discovering new  possibly better  paths  and  b 
since ants and data routing are independent in antnet  the exploration of new routes
can continue while  at the same time  data packets can exploit previously learned  reliable
information  it is interesting to note that the use of probabilistic routing tables whose entries
are learned in an adaptive way by changing on positive feedback and ignoring negative
feedback  is reminiscent of older automata approaches to routing in telecommunications
networks  in these approaches  a learning automaton is usually placed on each network
node  an automaton is defined by a set of possible actions and a vector of associated
probabilities  a continuous set of inputs and a learning algorithm to learn input output
associations  automata are connected in a feedback configuration with the environment
 the whole network   and a set of penalty signals from the environment to the actions is
defined  routing choices and modifications to the learning strategy are carried out in a
probabilistic way and according to the network conditions  see for example  nedzelnitsky
  narendra        narendra   thathachar          the main difference lies in the fact
that in antnet the ants are part of the environment itself  and they actively direct the
learning process towards the most interesting regions of the search space  that is  the
whole environment plays a key  active role in learning good state action pairs 

    antnet robustness to routing table update frequency

in bf and spf the broadcast frequency of routing information plays a critical role  particularly so for bf  which has only a local representation of the network status  this frequency
is unfortunately problem dependent  and there is no easy way to make it adaptive  while 
at the same time  avoiding large oscillations  in q r and pq r  routing tables updating
is data driven  only those q values belonging to pairs  i  j   of neighbor nodes visited by
packets are updated  although this is a reasonable strategy given that the exploration of
new routes could cause undesired delays to data packets  it causes delays in discovering new
good routes  and is a great handicap in a domain where good routes could change all the
time  in ospf  in which routing tables are not updated  we set static link costs on the
basis of their physical characteristics  this lack of an adaptive metric is the main reason
of the poor performance of ospf  as remarked in section    we slightly penalized ospf
with respect to its real implementations  where additional heuristic knowledge about trac
patterns is used by network administrators to set link costs   in antnet  we experimentally
observed the robustness to changes in the ants  generation rate  for a wide range of generation rates  rather independent of the network size  the algorithm performance is very good
and the routing overhead is negligible  see section      

    antnet and reinforcement learning

the characteristics of the routing problem allow one to interpret it as a distributed  stochastic time varying rl problem  this fact  as well as the structure of antnet  make it natural
to draw some parallels between antnet and classical rl approaches  it is worth remarking
that those rl problems that have been most studied  and for which algorithms have been de   

fidi caro   dorigo

veloped  are problems where  unlike routing  assumptions like markovianity or stationarity
of the process considered are satisfied  the characteristics of the adaptive routing problem
make it very dicult and not well suited to be solved with usual rl algorithms  this fact 
as we explain below  determines a departure of antnet from classical rl algorithms 
a first way to relate the structure of antnet to that of a  general  rl algorithm is
connected to the way the outcomes of the experiments  the trip times tk d   are processed 
the transformation from the raw values tk d to the more refined reinforcements r are
reminiscent of what happens in actor critic systems  barto  sutton    anderson        
the raw reinforcement signal is processed by a critic module  which is learning a model  the
node s component m  of the underlying process  and then is fed to the learning system  the
routing table t   transformed into an evaluation of the policy followed by the ants  in our
case  the critic is both adaptive  to take into account the variability of the trac process 
and rather simple  to meet computational requirements 
another way of seeing antnet as a classical rl system is related to its interpretation as
a parallel replicated monte carlo  mc  system  as was shown by singh and sutton        
a first visit mc  only the first visit to a state is used to estimate its value during a trial 
simulation system is equivalent to a batch temporal difference  td  method with replacing
traces and decay parameter     although antnet is a first visit mc simulation system 
there are some important differences with the type of mc used by singh and sutton  and
in other rl works   mainly due to the differences in the considered class of problems  in
antnet  outcomes of experiments are both used to update local models able to capture
the variability of the whole network status  only partially observable  and to generate a
sequence of stochastic policies  on the contrary  in the mc system considered by singh and
sutton  outcomes of the experiments are used to compute  reduced  maximum likelihood
estimates of the expected mean and variance of the states  returns  i e   the total reward
following a visit of a state  of a markov chain  in spite of these differences  the weak parallel
with td   methods is rather interesting  and allows to highlight an important difference
between antnet and its competitors  and general td methods   in antnet  following the
generation of a stochastic transition chain by the forward ant  there is no back chaining
of the information from one state  i e   a triple fcurrent node  destination node  next hop
nodeg  to its predecessors  each state is rewarded only on the basis of the ant s trip time
information strictly relevant to it  this approach is completely different from that followed
by  td methods  q r  pq r  bf and  in a different perspective  by spf  in fact  these
algorithms build the distance estimates at each node by using the predictions made at other
nodes  in particular  q r and pq r  which propagate the estimation information only one
step back  are precisely distributed versions of the td    class of algorithms  they could be
transformed into generic td             by transmitting backward to all the previously
visited nodes the information collected by the routing packet generated after each data hop 
of course  this would greatly increase the routing trac generated  because it has to be
done after each hop of each data packet  making the approach at least very costly  if feasible
at all 
in general  using temporal differences methods in the context of routing presents an important problem  the key condition of the method  the self consistency between the estimates
of successive states   may not be strictly satisfied in the general case  this is due to the
    for instance  the prediction made at node k about the time to go to the destination node d should be

   

fiantnet  distributed stigmergetic control for communications networks

fact that  i  the dynamics at each node are related in a highly non linear way to the dynamics of all its neighbors   ii  the trac process evolves concurrently over all the nodes 
and  iii  there is a recursive interaction between the trac patterns and the control actions
 that is  the modifications of the routing tables   this aspect can explain in part the poor
performance of the pure td    algorithms q r and pq r 

   related work
algorithms based on the ant colony metaphor were inspired by the ant colony foraging
behavior  beckers et al          these were first proposed by dorigo         colorni et
al         and dorigo et al               and were applied to the traveling salesman
problem  tsp   apart from the natural metaphor  the idea behind that first application
was similar to the one presented in this paper  a set of agents that repeatedly run monte
carlo experiments whose outcomes are used to change the estimates of some variables used
by subsequent ants to build solutions  in ant cycle  one of the first ant based algorithms 
a value called  pheromone trail  is associated to each edge of the graph representing the
tsp  each ant builds a tour by exploiting the pheromone trail information as follows 
when in node i an ant chooses the next node j to move to among those not visited yet
with a probability pij that is a function of the amount of pheromone trail on the edge
connecting i to j  as well as of a local heuristic function  the interested reader can find a
detailed description of ant cycle elsewhere  dorigo        dorigo et al           the value
of the pheromone trails is updated once all ants have built their tours  each ant adds
to all visited edges a quantity of pheromone trail proportional to the quality of the tour
generated  the shorter the tour  the higher the quantity of pheromone trail added   this
has an effect very similar to antnet s increase of routing tables probabilities  since a higher
pheromone trail on a particular edge will increase its probability of being chosen in the
future  there are obviously many differences between ant cycle and antnet  mostly due
to the very different types of problems to which they have been applied  a combinatorial
optimization problem versus a distributed  stochastic  time varying  real time problem 
though the majority of previous applications of ant colony inspired algorithms concern combinatorial optimization problems  there have been recent applications to routing 
schoonderwoerd et al               were the first to consider routing as a possible application domain for ant colony algorithms  their ant based control  abc  approach  which is
applied to routing in telephone networks  differs from antnet in many respects  the main
differences are a direct consequence of the different network model they considered  which
has the following characteristics  see figure       i  connection links potentially carry an
infinite number of full duplex  fixed bandwidth channels  and  ii  transmission nodes are
crossbar switches with limited connectivity  that is  there is no necessity for queue management in the nodes   in such a model  bottlenecks are put on the nodes  and the congestion
degree of a network can be expressed in terms of connections still available at each switch 
as a result  the network is cost symmetric  the congestion status over available paths is
completely bi directional  the path n    n    n            nk connecting n  and nk will exhibit the
additively related to the prediction for the same destination from each one of k s neighbors  being each
neighbor one of the ways to go to d 

   

fidi caro   dorigo

same level of congestion in both directions because the congestion depends only on the state
of the nodes in the path  moreover  dealing with telephone networks  each call occupies
exactly one physical channel across the path 
therefore   calls  are not multiplexed over the
link  
links  but they can be accepted or refused  depending on the possibility of reserving a physical
n bidirectional channels
circuit connecting the caller and the receiver  all
link  
of these modeling assumptions make the problink  
lem of schoonderwoerd et al  very different from
the cost asymmetric routing problem for data
networks we presented in this paper  this difn    n possible connections
ference is reected in many algorithmic differences between abc and antnet  the most imfigure     network node in the portant of which is that in abc ants update
telecommunications network pheromone trails after each step  without waiting
model of schoonderwoerd et for the completion of an experiment as done in
antnet  this choice  which is reminiscent of the
al         
pheromone trail updating strategy implemented
in ant density  another of the first ant colony based algorithms  dorigo et al         dorigo 
      colorni et al          makes abc behavior closer to real ants   and was made possible
by the cost symmetry assumption made by the authors 
other differences are that abc does not use local models to score the ants trip times 
nor local heuristic information and ant private memory to improve the ants decision policies 
also  it does not recover from cycles and does not use the information contained in all the
ant sub paths 
because of the different network model used and of the many implementation details
tightly bound to the network model  it was impossible for us to re implement and compare
the abc algorithm with antnet 
subramanian  druschel  and chen        have proposed an ant based algorithm for
packet switched nets  their algorithm is a straightforward extension of schoonderwoerd
et al  system by adding so called uniform ants  an additional exploration mechanism that
should avoid a rapid sub optimal convergence of the algorithm  a limitation of subramanian
et al  work is that  although the algorithm they propose is based on the same cost symmetry
hypothesis as abc  they apply it to packet switched networks where this requirement is
very often not met 
link  

    conclusions and future work
in this paper  we have introduced antnet  a novel distributed approach to routing in packetswitched communications networks  we compared antnet with   state of the art routing
algorithms on a variety of realistic testbeds  antnet showed superior performance and
robustness to internal parameter settings for almost all the experiments  antnet s most
innovative aspect is the use of stigmergetic communication to coordinate the actions of a
set of agents that cooperate to build adaptive routing tables  although this is not the
first application of stigmergy related concepts to optimization problems  e g   dorigo et al  
   

fiantnet  distributed stigmergetic control for communications networks

      dorigo        dorigo et al         bonabeau  dorigo    theraulaz         the application presented here is unique in many respects  first  in antnet  stigmergy based control
is coupled to a model building activity  information collected by ants is used not only to
modify routing tables  but also to build local models of the network status to be used to
better direct the routing table modifications  second  this is the first attempt to evaluate
stigmergy based control on a realistic simulator of communications networks  the used simulator retains many of the basic components of a real routing system  an interesting step
forward  in the direction of testing the applicability of the idea presented to real networks 
would be to rerun the experiments presented here using a complete internet simulator 
third  this is also the first attempt to evaluate stigmergy based control by comparing a
stigmergetic algorithm to state of the art algorithms on a realistic set of benchmark problems  it is very promising that antnet turned out to be the best performing in all the
tested conditions 
there are obviously a number of directions in which the current work could be extended 
which are listed below 
   a first  natural  extension of the current work would consider the inclusion in the
simulator of ow and congestion control components  with re transmissions and error management   this inclusion will require a paired tuning of the routing and ow congestion
components  to select the best matching between their dynamics 
   in antnet  each forward ant makes a random experiment  it builds a path from a
source node s to a destination node d  the path is built exploiting the information contained
in the probabilistic routing tables and the status of the queues of the visited nodes  while
building the path  the ant collects information on the status of the network  this is done
by sharing link queues with data packets  and by measuring waiting times of queues and
traversal times that will be used as raw reinforcements by backward ants  since forward
ants share queues with data packets  the time required to run an experiment depends on
the network load  and is approximately the same as the time ts d required for a packet to
go from the same source node s to the same destination node d  this delays the moment
the information collected by forward ants can be distributed by backward ants  and makes
it less up to date than it could be  a possible improvement in this schema would be to
add a model of link queue depletion to nodes  and to let forward ants use high priority
queues to reach their destinations without storing crossing times  for a first step in this
direction see di caro   dorigo         backward ants would then make the same path  in
the opposite direction  as forward ants  but use the queue local models they find on their
way to estimate local  virtual  queueing and crossing times  raw reinforcements  used to
update the routing tables  are then computed using these estimates  clearly  here there is a
trade off between delayed but real information and more recent but estimated information 
it will be interesting to see which scheme works better  although we are confident that the
local queue models should allow the backward ants to build estimates accurate enough to
make the improved system more effective than the current antnet  at a cost of a little
increase in computational complexity at the nodes 
   as we discussed in section    antnet is missing one of the main components of classical
rl td algorithms  there is no back chaining of information from a state to previous ones 
each node policy is learned by using a complete local perspective  an obvious extension
of our work would therefore be to study versions of antnet closer to td   algorithms 
   

fidi caro   dorigo

in this case each node should maintain q values expressing the estimate of the distance
to each destination via each neighbor  these estimates should be updated by using both
the ant trip time outcome and the estimates coming from successive nodes  closer to the
destination node  that could be also carried by the backward ant 
   in this paper we applied antnet to routing in datagram communications networks  it
is reasonable to think that antnet could be easily adapted to be used for the generation of
real time car route guidance in dynamic trac assignment  dta  systems  see for example
yang         dta systems exploit currently available and emerging computer  communication  and vehicle sensing technologies to monitor  manage and control the transportation
system  the attention is now focused mainly on highway systems  and to provide various
levels of information and advice to system users so that they can make timely and informed
travel decisions  therefore  adaptive routing of vehicle trac presents very similar features
to the routing of data packets in communications networks  moreover  vehicle trac control
systems have the interesting property of a very simplified  transport  layer  in fact  many
activities that interfere with routing and that are implemented in the transport layer of
communications networks do not exist  or exist only to a limited extent  in vehicles trac
control algorithms  for example  typical transport layer activities like data acknowledgement and retransmission cannot be implemented with real vehicles  other activities  like
ow control  have strong constraints  e g   people would not be happy to be forbidden to
leave their oces for  say  one hour on the grounds that there are already too many cars on
the streets    this makes antnet still more interesting since it can express its full potential
as a routing algorithm 
   in antnet  whenever an ant uses a link its desirability  probability  is incremented 
although this strategy  which finds its roots in the ant colony biological metaphor that
inspired our work  allowed us to obtain excellent results  it would be interesting to investigate
the use of negative reinforcements  even if it can potentially lead to stability problems  as
observed by people working on older automata systems  as discussed before  antnet differs
from automata systems because of the active role played by the ants  therefore  the use
of negative reinforcements could show itself to be effective  for example  in reducing the
probability of choosing a given link if the ant that used it performed very badly 

acknowledgements
this work was supported by a madame curie fellowship awarded to gianni di caro  cectmr contract n  erbfmbict          marco dorigo is a research associate with the
fnrs  we gratefully acknowledge the help received from tony bagnall  nick bradshaw and
george smith  who proofread and commented an earlier draft of this paper  as well as the
many useful comments provided by the three anonymous referees and by craig boutilier 
the associate editor who managed the review process 

appendix a  optimal and shortest path routing
in this appendix  the characteristics of the two most used routing paradigms  optimal and
shortest path routing  introduced in section      are summarized 
   

fiantnet  distributed stigmergetic control for communications networks

a   optimal routing
optimal routing  bertsekas   gallager        has a network wide perspective and its objective is to optimize a function of all individual link ows 
optimal routing models are also called ow models because they try to optimize the total
mean ow on the network  they can be characterized as multicommodity ow problems 
where the commodities are the trac ows between the sources and the destinations  and
the cost to be optimized is a function of the ows  subject to the constraints of ow conservation at each node and positive ow on every link  it is worth observing that the ow
conservation constraint can be explicitly stated only if the trac arrival rate is known 
the routing policy consists of splitting any source target trac pair at strategic points 
then shifting trac gradually among alternative routes  this often results in the use of
multiple paths for a same trac ow between an origin destination pair 
implicit in optimal routing is the assumption that the main statistical characteristics of the
trac are known and not time varying  therefore  optimal routing can be used for static
and centralized decentralized routing  it is evident that this kind of solution suffers all the
problems of static routers 

a   shortest path routing
shortest path routing  wang   crowcroft        has a source destination pair perspective 
as opposed to optimal routing  there is no global cost function to be optimized  instead 
the route between each node pair is considered by itself and no a priori knowledge about
the trac process is required  although of course such knowledge could be fruitfully used  
if costs are assigned in a dynamic way  based on statistical measures of the link congestion
state  a strong feedback effect is introduced between the routing policies and the trac
patterns  this can lead to undesirable oscillations  as has been theoretically predicted and
observed in practice  bertsekas   gallager        wang   crowcroft         some very
popular cost metrics take into account queuing and transmission delays  link usage  link
capacity and various combination of these measures  the way costs are updated usually
involves attempting to reduce big variations considering both long term and short term
statistics of link congestion states  khanna   zinky        shankar  alaettinoglu  dussazieger    matta      b  
on the other hand  if the costs are static  they will reect both some measure of the
expected wished trac load over the links and their transmission capacity  of course 
serious loss of eciency could arise in case of non stationary conditions or when the a priori
assumptions about the trac patterns are strongly violated in practice 
considering the different content stored in each routing table  shortest path algorithms can
be further subdivided in two classes called distance vector and link state  steenstrup       
shankar et al       b   the common behavior of most shortest path algorithms can be
depicted as follows 
   each node assigns a cost to each of its outgoing links  this cost can be static or
dynamic  in the latter case  it is updated in presence of a link failure or on the basis
of some observed link trac statistics averaged over a defined time window 
   

fidi caro   dorigo

   periodically and without a required inter node synchronization  each node sends to all
of its neighbors a packet of information describing its current estimates about some
quantities  link costs  distance from all the other nodes  etc   
   each node  upon receiving the information packet  updates its local routing table and
executes some class specific actions 
   routing decisions can be made in a deterministic way  choosing the best path indicated
by the information stored in the routing table  or adopting a more exible strategy
which uses all the information stored in the table to choose some randomized or
alternative path 
in the following  the main features specific to each class are described 

a     distance vector
distance vector algorithms make use of routing tables consisting of a set of triples of the
form  destination  estimated distance  next hop   defined for all the destinations in the
network and for all the neighbor nodes of the considered switch    in this case  the required
topological information is represented by the list of the reachable nodes identifiers  the
average per node memory occupation is of order o nn   where n is the number of nodes in
the network and n is the average connectivity degree  i e   the average number of neighbor
nodes considered over all the nodes  
the algorithm works in an iterative  asynchronous and distributed way  the information
that every node sends to its neighbors is the list of its last estimates of the distances from
itself to all the other nodes in the network  after receiving this information from a neighbor
node j   the receiving node i updates its table of distance estimates overwriting the entry
corresponding to node j with the received values 
routing decisions at node i are made choosing as next hop node the one satisfying the
relationship 
arg min fdij   dj g
j  n
i

where dij is the assigned cost to the link connecting node i with its neighbor j and dj is
the estimated shortest distance from node j to the destination 
it can be shown that this process converges in finite time to the shortest paths with
respect to the used metric if no link cost changes after a given time  bertsekas   gallager 
      
the above briey described algorithm is known in literature as distributed
bellman ford  bellman        ford   fulkerson        bertsekas   gallager        and it
is based on the principles of dynamic programming  bellman        bertsekas         it
is the prototype and the ancestor of a wider class of distance vector algorithms  malkin
  steenstrup        developed with the aim of reducing the risk of circular loops and of
accelerating the convergence in case of rapid changes in link costs 
    in some cases  only the best estimates are kept at nodes  therefore  the above triples are defined for all
the destinations only 

   

fiantnet  distributed stigmergetic control for communications networks

a     link state

link state algorithms make use of routing tables containing much more information than
that used in vector distance algorithms  in fact  at the core of link state algorithms there is a
distributed and replicated database  this database is essentially a dynamic map of the whole
network  describing the details of all its components and their current interconnections 
using this database as input  each node calculates its best paths using an appropriate
algorithm like dijkstra s        algorithm  a wide variety of alternative ecient algorithms
are available  as described for example in cherkassky  goldberg    radzik         the
memory requirements for each node in this case are o n     
in the most common form of link state algorithm  each node acts autonomously  broadcasting information about its link costs and states and computing shortest paths from itself
to all the destinations on the basis of its local link costs estimates and of the estimates
received from other nodes  each routing information packet is broadcast to all the neighbor
nodes that in turn send the packet to their neighbors and so on  a distributed ooding
mechanism  bertsekas   gallager        supervises this information transmission trying to
minimize the number of re transmissions 
as in the case of vector distance  the described algorithm is a general template and a
variety of different versions have been implemented to make the algorithm behavior more
robust and ecient  moy        

references

alaettinoglu  c   shankar  a  u   dussa zieger  k     matta  i          design and implementation of mars  a routing testbed  tech  rep  umiacs tr         cs tr      
institute for advanced computer studies and department of computer science  university of maryland  college park  md  
barto  a  g   sutton  r  s     anderson  c  w          neuronlike adaptive elements that
can solve dicult learning control problems  ieee transaction on systems  man and
cybernetics  smc             
beckers  r   deneubourg  j  l     goss  s          trails and u turns in the selection of the
shortest path by the ant lasius niger  journal of theoretical biology               
bellman  r          dynamic programming  princeton university press 
bellman  r          on a routing problem  quarterly of applied mathematics                
bertsekas  d          dynamic programming and optimal control  athena scientific 
bertsekas  d     gallager  r          data networks  prentice hall 
bertsekas  d     tsitsiklis  j          neuro dynamic programming  athena scientific 
bolding  k   fulgham  m  l     snyder  l          the case for chaotic adaptive routing 
tech  rep  cse           department of computer science  university of washington 
seattle 
   

fidi caro   dorigo

bonabeau  e   dorigo  m     theraulaz  g          from natural to artificial swarm
intelligence  oxford university press 
boyan  j     littman  m          packet routing in dinamically changing networks  a reinforcement learning approach  in advances in neural information processing systems
   nips    pp           san francisco  ca morgan kaufmann 
brakmo  l  s   o malley  s  w     peterson  l  l          tcp vegas  new techniques for
congestion detection and avoidance  acm computer communication review  sigcomm             
cheng  c   riley  r   kumar  s  p  r     garcia luna aceves  j  j          a loop free
extended bellman ford routing protocol without bouncing effect  acm computer
communication review  sigcomm                       
cherkassky  b  v   goldberg  a  v     radzik  t          shortest paths algorithms  theory
and experimental evaluation  in sleator  d  d   ed    proceedings of the  th annual
acm siam symposium on discrete algorithms  soda      pp          arlington 
va  acm press 
choi  s     yeung  d  y          predictive q routing  a memory based reinforcement
learning approach to adaptive trac control  in advances in neural information
processing systems    nips    pp           mit press 
colorni  a   dorigo  m     maniezzo  v          distributed optimization by ant colonies 
in proceedings of the european conference on artificial life  ecal      pp          
elsevier 
costa  d     hertz  a          ants can colour graphs  journal of the operational research
society              
crawley  e   nair  r   rajagopalan  b     sandick  h          a framework for qos based
routing in the internet  internet draft  expired in september        draft ietf qosrframework     internet engineering task force  ieft  
danzig  p  b   liu  z     yan  l          an evaluation of tcp vegas by live emulation 
tech  rep  ucs cs         computer science department  university of southern
california  los angeles 
di caro  g     dorigo  m          two ant colony algorithms for best effort routing
in datagram networks  in proceedings of the tenth iasted international conference on parallel and distributed computing and systems  pdcs      pp          
iasted acta press 
dijkstra  e  w          a note on two problems in connection with graphs  numer  math  
           
dorigo  m          optimization  learning and natural algorithms  in italian   ph d 
thesis  dipartimento di elettronica e informazione  politecnico di milano  it 
   

fiantnet  distributed stigmergetic control for communications networks

dorigo  m   di caro  g     gambardella  l  m          ant algorithms for distributed
discrete optimization  tech  rep         iridia  universite libre de bruxelles  submitted to artificial life 
dorigo  m     gambardella  l  m          ant colony system  a cooperative learning
approach to the traveling salesman problem  ieee transactions on evolutionary
computation               
dorigo  m   maniezzo  v     colorni  a          positive feedback as a search strategy 
tech  rep          dipartimento di elettronica  politecnico di milano  it 
dorigo  m   maniezzo  v     colorni  a          the ant system  optimization by a colony
of cooperating agents  ieee transactions on systems  man  and cybernetics part
b                
ford  l     fulkerson  d          flows in networks  prentice hall 
goss  s   aron  s   deneubourg  j  l     pasteels  j  m          self organized shortcuts in
the argentine ant  naturwissenschaften              
grasse  p  p          la reconstruction du nid et les coordinations interindividuelles
chez bellicositermes natalensis et cubitermes sp  la theorie de la stigmergie  essai
d interpretation du comportement des termites constructeurs  insectes sociaux    
      
gray  r   kotz  d   nog  s   rus  d     cybenko  g          mobile agents  the next
generation in distributed computing  in proceedings of the second aizu international
symposium on parallel algorithms architectures synthesis  pas       pp        ieee
computer society press 
jaakkola  t   singh  s  p     jordan  m  i          reinforcement learning algorithm for
partially observable markov decision problems  in advances in neural information
processing systems    pp           mit press 
kaelbling  l  p   littman  m  l     moore  a  w          reinforcement learning  a survey 
journal of artificial intelligence research             
khanna  a     zinky  j          the revised arpanet routing metric  acm sigcomm
computer communication review                
malkin  g  s     steenstrup  m  e          distance vector routing  in steenstrup  m  e 
 ed    routing in communications networks  chap     pp         prentice hall 
mccallum  a  k          reinforcement learning with selective perception and hidden state 
ph d  thesis  department of computer science  university of rochester  rochester
 ny  
mcquillan  j  m   richer  i     rosen  e  c          the new routing algorithm for the
arpanet  ieee transactions on communications              
   

fidi caro   dorigo

merlin  p     segall  a          a failsafe distributed routing protocol  ieee transactions
on communications  com                   
moy  j  t          ospf anatomy of an internet routing protocol  addison wesley 
narendra  k  s     thathachar  m  a          on the behavior of a learning automaton in a changing environment with application to telephone trac routing  ieee
transactions on systems  man  and cybernetics  smc                 
nedzelnitsky  o  v     narendra  k  s          nonstationary models of learning automata
routing in data communication networks  ieee transactions on systems  man  and
cybernetics  smc               
papoulis  a          probability  random variables and stochastic process  third edition  
mcgraw hill 
peterson  l  l     davie  b          computer networks  a system approach  morgan
kaufmann 
rubistein  r  y          simulation and the monte carlo method  john wiley   sons 
sandick  h     crawley  e          qos routing  qosr  working group report  internet
draft  internet engineering task force  ieft  
schoonderwoerd  r   holland  o     bruten  j          ant like agents for load balancing
in telecommunications networks  in proceedings of the first international conference
on autonomous agents  pp           acm press 
schoonderwoerd  r   holland  o   bruten  j     rothkrantz  l          ant based load
balancing in telecommunications networks  adaptive behavior                 
shankar  a  u   alaettinoglu  c   dussa zieger  k     matta  i       a   performance
comparison of routing protocols under dynamic and static file transfer connections 
acm computer communication review                
shankar  a  u   alaettinoglu  c   dussa zieger  k     matta  i       b   transient and
steady state performance of routing protocols  distance vector versus link state  tech 
rep  umiacs tr        cs tr       institute for advanced computer studies and
department of computer science  university of maryland  college park  md  
singh  s  p     sutton  r  s          reinforcement learning with replacing eligibility traces 
machine learning              
singh  s  p   jaakkola  t     jordan  m  i          learning without state estimation
in partially observable markovian decision processes  in proceedings of the eleventh
machine learning conference  pp           new brunswick  nj  morgan kaufmann 
steenstrup  m  e   ed            routing in communications networks  prentice hall 
stone  p     veloso  m  m          multiagent systems  a survey from a machine learning
persective  tech  rep  cmu cs         carnegie mellon university  pittsburgh  pa 
   

fiantnet  distributed stigmergetic control for communications networks

streltsov  s     vakili  p          variance reduction algorithms for parallel replicated
simulation of uniformized markov chains  discrete event dynamic systems  theory
and applications             
subramanian  d   druschel  p     chen  j          ants and reinforcement learning  a
case study in routing in dynamic networks  in proceedings of ijcai     international
joint conference on artificial intelligence  pp           morgan kaufmann 
the atm forum         private network network interface specification  version     
walrand  j     varaiya  p          high performance communication networks  morgan
kaufmann 
wang  z     crowcroft  j          analysis of shortest path routing algorithms in a dynamic
network environment  acm computer communication review         
yang  q          a simulation laboratory for evaluation of dynamic trac management systems  ph d  thesis  department of civil and environmental engineering 
massachusetts institute of technology  mit  

   

fi