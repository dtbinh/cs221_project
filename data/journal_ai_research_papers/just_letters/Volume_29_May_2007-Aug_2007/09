journal artificial intelligence research                  

submitted       published     

learning symbolic models stochastic domains
hanna m  pasula
luke s  zettlemoyer
leslie pack kaelbling

pasula csail mit edu
lsz csail mit edu
lpk csail mit edu

mit csail
cambridge       

abstract
article  work towards goal developing agents learn act
complex worlds  develop probabilistic  relational planning rule representation
compactly models noisy  nondeterministic action effects  show rules
effectively learned  experiments simple planning domains  d simulated
blocks world realistic physics  demonstrate learning algorithm allows
agents effectively model world dynamics 

   introduction
one goals artificial intelligence build systems act complex environments effectively humans do  perform everyday human tasks  making breakfast
unpacking putting away contents office  many tasks involve manipulating objects  pile things up  put objects boxes drawers  arrange
shelves  requires understanding world works  depending
objects pile arranged made of  pile sometimes slips falls
over  pulling drawer usually opens it  sometimes drawer sticks  moving box
typically break items inside it 
building agents perform common tasks challenging problem  work 
approach problem developing rule based representation agents use
model  learn  effects acting environment  learning allows agents
adapt new environments without requiring humans hand craft models  something
humans notoriously bad at  especially numeric parametrization required 
representation use probabilistic relational  includes additional logical
concepts  present supervised learning algorithm uses representation language
build model action effects given set example action executions  optimizing
tradeoff maximizing likelihood examples minimizing complexity
current hypothesis  algorithm effectively selects relational model structure 
set model parameters  language new relational concepts together provide
compact  yet highly accurate description action effects 
agent hopes act real world must integrated system perceives
environment  understands  commands motors effect changes it  unfortunately 
current state art reasoning  planning  learning  perception  locomotion 
manipulation far removed human level abilities  cannot yet contemplate
c
    
ai access foundation  rights reserved 

fipasula  zettlemoyer    pack kaelbling

figure    three dimensional blocks world simulation  world consists table  several cubes
roughly uniform density varying size  robotic gripper moved
simulated motors 

working actual domain interest  instead  choose work domains
almost ridiculously simplified proxies  
one popular proxy  used since beginning work ai planning  fikes  
nilsson        world stacking blocks  typically formalized version
logic  using predicates on a  b  clear  a  describe relationships blocks
one another  blocks always neatly stacked  dont fall jumbles 
article  present work context slightly less ridiculous version blocks
world  one constructed using three dimensional rigid body dynamics simulator  ode 
       example world configuration shown figure    simulated blocks
world  blocks vary size colour  piles always tidy  may sometimes fall
over  gripper works medium sized blocks  unreliable even there 
approach capable enabling effective behavior domain must handle noisy 
nondeterministic nature  nontrivial dynamics  able handle
domains similar characteristics 
one strategy formulating approach learn models worlds dynamics
use planning different courses action based goals may change
time  another strategy assume fixed goal reward function  learn
policy optimizes reward function  worlds complexity imagining 
would impossible establish  advance  appropriate reaction every possible
situation  addition  expect agent overall control architecture
hierarchical  individual level hierarchy changing goals 
reasons  learn model world dynamics  use make plans
achieve goals hand 
begin paper describing assumptions underlie modeling decisions 
describe syntax semantics modeling language give algorithm
   reasonable alternative approach  advocated brooks         working real world 
natural complexity  solving problems almost ridiculously simplified proxies
problems interest 

   

filearning symbolic models stochastic world dynamics

learning models language  validate models  introduce simple planning
algorithm provide empirical results demonstrating utility learned models
showing plan them  finally  survey relevant previous work 
draw conclusions 

   structured stochastic worlds
agent introduced novel world must find best possible explanation
worlds dynamics within space possible models represent  defined
agents representation language  ideal language would able compactly model
every action effect agent might encounter  others  extra modeling capacity
wasted complicate learning  since agent consider larger space
possible models  likely overfit experience  choosing good representation
language provides strong bias algorithm learn models language 
languages used describe deterministic planning models are 
least surface  first order  is  abstract particular identities objects  describing effects actions terms properties relations among
objects   they accomplish letting action take arguments  representing
arguments variables   representational capacity crucial reasons compactness generalization  usually grossly inefficient describe behavior
individual objects 
much original work probabilistic planning uses formalism markov decision processes  represents states world individually atomically  puterman         recently  propositional  factored  representations dynamics
employed  boyen   koller        guestrin  koller  parr    venkataraman        
first order representations developed  including probabilistic rules  blum   langford         equivalence classes  draper  hanks    weld         situation calculus
approach boutilier  reiter  price         representations make easy
articulate take direct advantage two useful assumptions world dynamics 
frame assumption  states that  agent takes action world  anything
explicitly changed stays same  outcome assumption  states
action affects world small number distinct ways  possible effect causes
set changes world happen together single outcome 
take point departure probabilistic first order representations world
dynamics  representations traditionally applied domains logistics
planning traditional  abstract blocks world  idealized symbolic abstractions
underlying domain  goal learn models realistic worlds  requires
us adapt modeling language accommodate additional uncertainty complexity 
by 
allowing rules refer objects mentioned argument list action 
relaxing frame assumption  allowing unmodeled noise changes world 
extending language  allowing complex forms quantification construction new concepts 
   

fipasula  zettlemoyer    pack kaelbling

action parameterization traditional representations action dynamics  objects
whose properties may changed result action must named argument
list action  instead  define actions parameters describe
objects free parameters action  example  block picked up 
object currently held block placed  however  actions change
properties objects  ones parameter list  models
way determining objects affected  paper 
introduce use deictic references identify objects  deictic references  agre
  chapman        identify objects relative agent action performed 
example  refer objects thing block picked up 
currently held object  table block accidentally falls onto  use deictic
references mechanism adding new logical variables models  much
way benson        
modeling noise complex domains  actions affect world variety ways 
must learn model circumstances reasonable effects 
behavior unusual situations  complicates dynamics  makes
learning difficult  also  actions executed physical world 
guaranteed small number simple effects  result may violate
outcomes assumption  blocks world happen  example  stack
knocked over  develop simple noise mechanism allows us partially model
action effects  ignoring ones rare complicated model explicitly 
language extension traditional symbolic domains  rules constructed using
predefined set observable predicates  however  sometimes useful define additional
predicates whose truth values computed based predefined ones 
found essential modeling certain advanced planning domains  edelkamp  
hoffman        
traditional blocks worlds  example  usual set predicates contains on  clear
inhand  working realistic  noisy blocks world  found
predicates would sufficient allow agent learn accurate model 
example  would difficult state putting block tall stack likely cause
stack topple without concept stack height  state attempting
pick block clear usually picks block top stack without
way describing block top stack 
could simply add additional predicates seem useful perceptual
language  hand engineering appropriate language every time tackle new problem
difficult  time consuming  error prone  state of the art planning representations
pddl  edelkamp   hoffman        use concept language define new predicates
concepts terms previous  simpler ones  paper  show concepts
learned  much predicates invented ilp  khan  muggleton    parson        
see  traditional blocks world predicates  including inhand clear 
well useful concepts height  easily defined terms given simple
concept language  yoon  fern    givan        
   

filearning symbolic models stochastic world dynamics

   state action representation
goal learn model state transition dynamics world  so  need
able represent set possible states world set possible
actions agent take  represent components using subset
relatively standard first order logic equality  representation states actions
ground inference  learning  planning 
begin defining primitive language includes set constants c  set
predicates   set functions   three types functions   traditional
functions  range objects  discrete valued functions  range predefined
discrete set values  integer valued functions  range finite subset
integers  primitives observed directly world   in work 
assume environment completely observable  is  agent able
perceive unambiguous correct description current state     constants
c assumed intrinsic meaning  viewed meaningless markers
assigned perceptual system  described detail below 
    state representation
states describe possible different configurations properties relations
objects  state describes particular configuration values
objects world  individual objects denoted using constants 
limit number objects world configuration  though current
formalism mechanism creation deletion objects result
world dynamics 
formally  state descriptions conjunctive sentences form 
 

 

tg c m   

 

   t 

 

 t     

tg c m   

m x  arity predicate function x  c set c        cn constants  g x  a 
set length lists elements x     indicates predicates may
optionally negated  indicates functions assigned value
range  manner  states list truth values possible groundings
predicates functions terms  sentence gives complete specification 
vocabulary   properties interrelations  c  objects present
world   note predicate function arguments always constants  never
terms made using function symbols  descriptions always finite given finite
language  
rest section  describe two approaches denoting objects using
constants c  illustrate example conjunctive state sentences 
      intrinsic constants
first approach state descriptions refers objects using intrinsic constants 
intrinsic constant associated particular object consistently used denote
   strong  ultimately indefensible assumption  one highest priorities future
work extend case environment partially observable 

   

fipasula  zettlemoyer    pack kaelbling

object  constants useful perceptual system unique way
identify perceived objects independent attributes relations one another 
example  internet software agent might access universal identifiers
distinguish objects perceives 
example  let us consider representing states simple blocks world  using
language contains predicates on  clear  inhand  inhand nil  block  table 
integer valued function height  objects world include blocks block a block b 
table table  gripper  blocks blocks table  block
nothing clear  gripper hold one block empty  sentence
inhand nil on block a  block b  on block b  table  on block b  block a 
on block a  table  on table  block a  on table  block b  on table  table 
on block a  block a  on block b  block b  table table  table block a 
   
table block b  block block a  block block b  block table  clear block a 
clear block b  clear table  inhand block a  inhand block b 
inhand table  height block a      height block b      height table     
represents blocks world gripper holds nothing two blocks single
stack table  block block a top stack  block b block a
table table 
encoding  sentence contains meaningful information objects
identities  used learning world dynamics 
      skolem constants
alternatively  states denote objects using skolem constants  skolem constants
arbitrary identifiers associated objects world inherent
meaning beyond used state description   constants useful
perceptual system way assigning meaningful identifiers objects
observes  example  consider robot might build state description room
finds in  assume robot observe objects present 
properties  relationships other  however  naming objects 
reason choose particular name specific object  instead  creates
arbitrary identifiers  skolem constants  uses build state 
using skolem constants  rewrite sentence   as 
inhand nil on c     c     on c     c     on c     c    
on c     c     on c     c     on c     c     on c     c    
on c     c     on c     c     table c     table c    
table c     block c     block c     block c     clear c    
clear c     clear c     inhand c     inhand c    
inhand c     height c         height c         height c        
here  perceptual system describes table two blocks using arbitrary
constants c     c     c    
   skolem constants interpreted skolemizations existential variables 

   

filearning symbolic models stochastic world dynamics

perspective  states world isomorphic interpretations
logical language  since might many interpretations satisfy particular statespecification sentence  interpretations permutation
objects constants refer to  occurs objects distinguishable based
properties relations objects 
techniques develop paper generally applicable representing
learning dynamics worlds intrinsic constants skolem constants 
highlight cases true presented  see
use skolem constants perceptually plausible forces us
create new learning algorithms abstract object identity aggressively previous
work improve quality learned models 
    action representation
actions represented positive literals whose predicates drawn special set   
whose terms drawn set constants c associated world
action executed 
example  simulated blocks world  contains pickup    action picking
blocks  puton    action putting blocks  action literal pickup block a 
could represent action gripper attempts pickup block block a
state represented sentence   

   world dynamics representation
learning probabilistic transition dynamics world  viewed
conditional probability distribution pr s   s  a   s  s  a  represent
dynamics rules constructed basic logic described section    using
logical variables abstract identities particular objects world 
section  begin describing traditional representation deterministic world
dynamics  next  present probabilistic case  finally  extend ways
mentioned section    permitting rules refer objects mentioned
action description  adding noise  extending language allow
construction new concepts 
dynamic rule action z form
x  x  z x     x   
meaning that  vector terms x context holds
current time step  taking action z x  cause formula   hold terms
next step  action z x  must contain every xi x  constrain  
conjunctions literals constructed primitive predicates terms xi x 
functions applied terms set equal value range  addition 
allowed contain literals constructed integer valued functions term related
integer range greater than less than predicates 
say rule covers state action exists substitution
mapping variables x c  note may fewer variables x constants
   

fipasula  zettlemoyer    pack kaelbling

c       x     z  x    is  substitution constants
variables that  applied context  x   grounds entailed
state and  applied rule action z x   makes equal action a 
now  given rule covers a  say subsequent state s   
first  rule directly specifies     x   holds next step  may
incomplete specification state  use frame assumption fill rest 
s        x  

 

 

l s     x  

   t  tg c m    pos     x    



 

 

l s     x    

   t  tg c m    funct     x    

l s  y  t  stands literal predicate function argument
list t  pos     set literals   negations ignored  funct     set
ground functions   extracted equality assignments  say
every literal would needed make complete description state
included     x   retrieved  associated truth value equality assignment 
s 
general set rules action  require contexts
mutually exclusive  given state action pair covered one rule 
covered none  assume nothing changes    example  consider
small set rules picking blocks 
pickup x  y    inhand nil  on x  y   block y   height y      
inhand x   on x  y   clear y  
pickup x  y    inhand nil  on x  y   table y 
inhand x   on x  y  
top line rule shows action followed context  next line describes
effects  outcome  according two rules  executing pickup x  y  changes
world hand empty x y  exact set changes depends
whether table  block height nine less 
    probabilistic rules
deterministic dynamics rules described allow generalization objects
exploitation frame assumption  well suited use highly
stochastic domains  order apply domains extend
describe probability distribution resulting states  pr s   s  a   probabilistic strips
operators  blum   langford        model agents actions affect world around
describing actions alter properties relationships objects
world  rule specifies small number simple action outcomessets changes
occur tandem 
   without restriction  would need define method choosing possibly conflicting predictions different covering rules  simplest way would involve picking one
rules  perhaps specific one  one confident of   rule confidence scores
would estimated  

   

filearning symbolic models stochastic world dynamics

see probabilistic rules form


p 

    x 
x  x  z x             

p
 
n n  x 

 

p        pn positive numbers summing    representing probability distribution            n formulas describing subsequent state  s   
given state action a  compute coverage deterministic
case  now  however  given covering substitution  x   probabilistic rules longer predict
unique successor state  instead            n used construct new state 
single   deterministic case  n possible subsequent
states  s i   occur associated probability pi  
probability rule r assigns moving state state s  action
taken  pr s   s  a  r   calculated as 

p  s   s  a  r   

x

p  s     i  s  a  r 

 i r

 

x

p  s    i   s  a  r p   i  s  a  r 

   

 i r

p   i  s  a  r  pi   outcome distribution p  s    i   s  a  r  deterministic
distribution assigns mass relevant s    p  s    i   s  a  r         is 
s  state would constructed given rule outcome  say
outcome  i covers s   
general  possible  representation  subsequent state s  covered
one rules outcomes  case  probability s  occurring
sum probabilities relevant outcomes  consider rule painting blocks 

paint x    inhand x   block x 
 



     painted x   wet
     change 

rule used model transition caused action paint a  initial
state contains wet painted a   one possible successor state  one
change occurs  wet painted a  remain true  outcomes describe
one successor state  must sum probabilities recover states total
probability 
set rules specifies complete conditional probability distribution pr s   s  a 
following way  current state action covered exactly one rule 
distribution subsequent states prescribed rule  not  s  predicted
probability     
   

fipasula  zettlemoyer    pack kaelbling

example  probabilistic set rules picking blocks might look follows 
pickup x  y    inhand nil  on x  y   block y   height y      
 



     inhand x   on x  y   clear y 
     change

pickup x  y    inhand nil  on x  y   table y 
 



     inhand x   on x  y 
     change

top line rule still shows action followed context  bracket surrounds
outcomes distribution  outcomes before 
small chance occur 
    deictic reference
standard relational representations action dynamics  variable denoting object
whose properties may changed result action must named argument
list action  result awkwardness even deterministic situations  example  abstract action picking block must take two arguments  pickup x  y  
x block picked block picked up 
relationship encoded added condition on x  y  rules context  condition restrict applicability rule  exists guarantee bound
appropriate object  restriction adopted means that  given
grounding action  variables rule bound  necessary
search substitutions would allow rule cover state  however  complicate planning because  many cases  ground instances operator considered 
even though eventually rejected due violations preconditions 
example  would reject instances violating on x  y  relation context 
complex domains  requirement even awkward  depending
circumstances  taking action may affect different  varied sets objects  blocks worlds
block may several others  pickup action may affect properties
blocks  model without additional mechanism referring objects 
might increase  even vary  number arguments pickup takes 
handle gracefully  extend rule formalism include deictic references
objects  rule may augmented list  d  deictic references  deictic
reference consists variable vi restriction set literals define
vi respect variables x action vj j   i 
restrictions supposed pick single  unique object  notif pick
several  nonethe rule fails apply  so  handle pickup action described above 
action would single argument  pickup x   rule would contain deictic
variable v constraint on x  v  
use rules deictic references  must extend procedure computing rule
coverage ensure deictic references resolved  deictic variables
may bound simply starting bindings x working sequentially
deictic variables  using restrictions determine unique bindings  point
   

filearning symbolic models stochastic world dynamics

binding deictic variable unique  fails refer  rule fails cover
stateaction pair 
formulation means extra variables need included action specification  reduces number operator instances  yet  requirement
unique designation  substitution still quickly discovered testing coverage 
so  example  denote red block table v   assuming
one table one block  would use following deictic references 
v    table v   
v    color  v      red block  v    on v    v     
several  no  tables world  then  rule semantics  first
reference would fail  similarly  second reference would fail number red blocks
unique table represented v  one 
give action oriented example  denoting block top block
touched  touch z  action  would use following deictic reference 
v    on v    z  block  v     
set deictic probabilistic rules picking blocks might look follows 
pickup x   

n

  inhand y   z   table z 



empty context
 



     inhand nil  inhand y   on y  z 
     change

pickup x   

n

  block y   on x  y 



inhand nil  height y      
 



     inhand x   on x  y   clear y 
     change

pickup x   

n

  table y   on x  y 



inhand nil
 
     inhand x   on x  y 

     change
top line rule shows action followed deictic variables 
variable annotated restriction  next line context  outcomes
distribution follow  first rule applies situations something
gripper  states probability     action cause gripped
object fall table  nothing change otherwise  second rule applies
situations object picked another block  states
probability success      third rule applies situations object
picked table describes slightly higher success probability       note
different objects affected  depending state world 
   

fipasula  zettlemoyer    pack kaelbling

    adding noise
probability models type seen thus far  ones small set possible
outcomes  sufficiently flexible handle noise real world  may
large number possible outcomes highly unlikely  reasonably hard model 
example  configurations may result tall stack blocks topples 
would inappropriate model outcomes impossible  dont space
inclination model individual outcome 
so  allow rule representation account results noise  definition  noise able represent outcomes whose probability havent quantified 
thus  allowing noise  lose precision true probability distribution
next states 
handle noise  must change rules two ways  first  rule
additional noise outcome  noise   associated probability p   noise  s  a  r   now 
set outcome probabilities must sum     include p   noise  s  a  r  well
p      s  a  r        p   n  s  a  r   however   noise associated list literals 
since declining model detail happens world cases 
second  create additional default rule  empty context two outcomes  empty outcome  which  combination frame assumption  models
situations nothing changes   and  again  noise outcome  modeling situations   rule allows noise occur situations specific rule applies 
probability assigned noise outcome default rule specifies kind background
noise level 
since explicitly modeling effects noise  longer calculate
transition probability pr s   s  a  r  using equation    lack required distribution
p  s    i   s  a  r  noise outcome  instead  substitute worst case constant bound
pmin p  s    noise   s  a  r   allows us bound transition probability
p  s   s  a  r    pmin p   noise  s  a  r   

x

p  s    i   s  a  r p   i  s  a  r 

 i r

p  s   s  a  r  

   

intuitively  pmin assigns small amount probability mass every possible next state
note take value higher true minimum  approximation 
however  ensure probability model remains well defined  pmin times number
possible states exceed     
way  create partial model allows us ignore unlikely overly complex
state transitions still learning acting effectively   
since rules include noise deictic references  call noisy deictic rules
 ndrs   rather stochastic world  set ndrs picking blocks might
s   

   p  s    noise   s  a  r  could modeled using well defined probability distribution describing noise
world  would give us full distribution next states  premise
might difficult specify distributionin domain  would ensure
distribution assign probability worlds impossible  worlds blocks
floating midair  long events unlikely enough would want consider
planning  reasonable model directly 

   

filearning symbolic models stochastic world dynamics

look follows 
pickup x   

n

  inhand y   z   table z 



empty context


     inhand nil  inhand y   on y  z 
     change


     noise
pickup x   

n

  block y   on x  y 



inhand nil  height y      




     inhand x   on x  y   clear y 

     change


     noise
n

pickup x   

  table y   on x  y 



inhand nil


     inhand x   on x  y 
     change


     noise
default  rule 
     change

     noise
format rules before  section      except rule
includes explicit noise outcome  first three rules similar old versions 
difference model noise  final rule default rule  states
that  rule applies  probability observing change     
together rules provide complete example type rule set learn
section      however  written fixed modeling language functions
predicates  next section describes concepts used extend language 
    concept definitions
addition observed primitive predicates  often useful background
knowledge defines additional predicates whose truth values computed based
observations  found essential modeling certain planning
domains  edelkamp   hoffman        
background knowledge consists definitions additional concept predicates
functions  work  express concept definitions using concept language
includes conjunction  existential quantification  universal quantification  transitive closure  counting  quantification used defining concepts inhand x    
block x  y on x     transitive closure included language via kleene star
operator defines concepts above x        x     finally  counting included using special quantifier   returns number objects formula
true  useful defining integer valued functions height x      y above x    
   

fipasula  zettlemoyer    pack kaelbling

defined  concepts enable us simplify context deictic variable definitions  well restrict ways cannot described using simple conjunctions 
note  however  need track concept values outcomes  since
always computed primitives  therefore  rule contexts use language
enriched concepts  outcomes contain primitives 
example  deictic noisy rule attempting pick block x  side
side background knowledge necessary primitive predicates
table 

pickup x   




  topstack y  x  


z   on y  z  

  table t 




inhand nil  height y     


      on y  z 


      on y  z   on y  t 


      change



      noise

clear x 

   y on y  x 

inhand x     block x  y on x  y 
inhand nil    y inhand y 
above x  y 

    x  y 

   

topstack x  y     clear x  above x  y 
height x      y above x  y 

rule complicated example rules given thus far  deals
situation block picked up  x  middle stack  deictic variable
identifies  unique  block top stack  deictic variable zthe object
  deictic variable tthe table  might expected  gripper succeeds
lifting high probability 
concept definitions include clear x   defined exists object
x  inhand x   defined x block object  inhand nil  defined
exists object hand  above x  y   defined transitive
closure on x  y   topstack x  y   defined x y  clear  height x  
defined number objects x using chain ons  explained
above  concepts used context deictic variable definitions 
outcomes track primitive predicates  fact  appears outcomes  since
value table predicates never changes 
    action models
combine set concept definitions set rules define action model 
best action models represent rule set using ndrs  but  comparison purposes 
experiments involve rule sets use simpler representations  without
noise deictic references  moreover  rule sets differ whether allowed
contain constants  rules presented far contained none  neither
context outcomes  reasonable setup states contain skolem
constants  constants inherent meaning names assigned
general repeated  however  states intrinsic constants  perfectly
acceptable include constants action models  all  constants used
uniquely identify objects world 
develop learning algorithm next section  assume general
constants allowed action model  show simple restrictions within
   

filearning symbolic models stochastic world dynamics

algorithm ensure learned models contain any  show 
section    learning action models restricted free constants provides
useful bias improve generalization training small data sets 

   learning action models
defined rule action models  describe may constructed
using learning algorithm attempts return action model best explains set
example actions results  formally  algorithm takes training set e 
example  s  a  s    triple  searches action model maximizes
likelihood action effects seen e  subject penalty complexity 
finding involves two distinct problems  defining set concept predicates 
constructing rule set r using language contains predicates together
directly observable primitive predicates  section  first discuss second problem 
rule set learning  assuming fixed set predicates provided learner  then 
present simple algorithm discovers new  useful concept predicates 
    learning rule sets
problem learning rule sets is  general  np hard  zettlemoyer  pasula    kaelbling 
       here  address problem using greedy search  structure search
hierarchically identifying two self contained subproblems  outcome learning 
subproblem general rule set search  parameter estimation  subproblem
outcome learning  thus  overall algorithm involves three levels greedy search 
outermost level  learnrules  searches space rule sets  often
constructing new rules  altering existing ones  middle level  induceoutcomes which 
given incomplete rule consisting context  action  set deictic references  fills
rest rule  innermost level  learnparameters  takes slightly
complete rule  lacking distribution outcomes  finds distribution
optimizes likelihood examples covered rule  present three
levels starting inside out  subroutine described one
depends it  since three subroutines attempt maximize scoring metric 
begin introducing metric 
      scoring metric
greedy search algorithm must judge parts search space desirable 
here  done help scoring metric rule sets 
s r   

x

log p  s   s  a  r s a    

 s a s   e

x

p en  r 

   

rr

r s a  rule governing transition occurring performed s 
scaling parameter  p en  r  complexity penalty applied rule r  thus  s r 
favors rule sets maximize likelihood bound data penalizes rule sets
overly complex 
ideally  p would likelihood example  however  rules noise outcomes
cannot assign exact likelihood so  case  use lower bound defined equa   

fipasula  zettlemoyer    pack kaelbling

tion   instead  p en  r  defined simply total number literals r  chose
penalty simplicity  performed worse penalty
term tested informal experiments  scaling parameter set     experiments  could set using cross validation hold out dataset
principled technique  metric puts pressure model explain examples using
non noise outcomes  increases p   opposing pressure complexity  via
p en  r  
assume state action pair  s  a  covered one rule  which 
finite set examples  enforced simply ensuring examples stateaction pair covered one rule  rewrite metric terms rules rather
examples  give
s r   

x

x

rr

 s a s   er

log p  s   s  a  r   p en  r 

   

er set examples covered r  thus  rules contribution s r 
calculated independently others 
      learning parameters
first algorithms described section  learnparameters  takes incomplete
rule r consisting action  set deictic references  context  set outcomes 
learns distribution p maximizes rs score examples er covered it 
since procedure allowed alter number literals rule  therefore
cannot affect complexity penalty term  optimal distribution simply one
maximizes log likelihood er   case rules noise outcomes
log p  s   s  a  r  

x

l  

 s a s   er



 



log pmin p   noise  s  a  r   

x

x

p  s    i   s  a  r p   i  s  a  r   

   

 i r

 s a s   er

non noise outcome  p  s    i   s  a  r  one  i covers  s  a  s    zero otherwise 
 in case rules without noise outcomes  sum slightly simpler 
pmin p   noise  s  a  r  term missing  
every example covered unique outcome  ls maximum expressed
closed form  let set examples covered outcome   e    add
lagrange multiplier enforce constraint p   i  s  a  r  distributions must sum
     get


l  

x
 s a s   er

 

x
e 

log


x

p  s    i   s  a  r p   i  s  a  r     

x

 i r

 i

 e    log p   i  s  a  r     


x

p   i  s  a  r        

 i

   

p   i  s  a  r      

filearning symbolic models stochastic world dynamics

then  partial derivative l respect p   i  s  a  r   e    p   i  s  a  r 
   e   p   i  s  a  r     e i    e   thus  parameters estimated
calculating percentage examples outcome covers 
however  seen section      possible example covered
one outcome  indeed  noise outcome  covers examples 
always case  situation  sum examples cannot rewritten
simple sum terms representing different outcomes containing single
relevant probability  probabilities overlapping outcomes remain tied together 
general closed form solution exists  estimating maximum likelihood parameters
nonlinear programming problem  fortunately  instance well studied problem
maximizing concave function  the log likelihood presented equation    probability simplex  several gradient ascent algorithms known problem  bertsekas 
       since function concave  guaranteed converge global maximum 
learnparameters uses conditional gradient method  works by  iteration 
moving along parameter axis maximal partial derivative  step sizes
chosen using armijo rule  with parameters                       
search converges improvement l small  less       chose
algorithm easy implement converged quickly experiments
tried  however  problems found method converges slowly  one
many nonlinear optimization methods  constrained newtons method 
could directly applied 
      inducing outcomes
given learnparameters  algorithm learning distribution outcomes 
consider problem taking incomplete rule r consisting context  action 
perhaps set deictic references  finding optimal way fill rest
rulethat is  set outcomes            n   associated distribution p
maximize score
s r   

x

log p  s   s  a  r   p eno  r  

 s a s   er

er set examples covered r  p eno  r  total number literals
outcomes r   s r  factor scoring metric equation   due
rule r  without aspects p en  r  fixed purposes subroutine 
number literals context  
general  outcome induction np hard  zettlemoyer  pasula    kaelbling         induceoutcomes uses greedy search restricted subset possible outcome sets 
proper training examples  outcome set proper every outcome
covers least one training example  two operators  described below  move
space immediate moves improve rule score  set
outcomes considers  induceoutcomes calls learnparameters supply best p can 
initial set outcomes created by  example  writing set
atoms changed truth values result action  creating outcome
describe every set changes observed way 
   

fipasula  zettlemoyer    pack kaelbling

e 
e 
e 
e 

  
  
  
  

  t c    h c   h c    h c  
  h c    t c   h c    h c  
  h c    h c   t c    t c  
  h c    h c   h c    h c  
 a 

   h c   
   h c   
   t c    t c   
   no change 
 b 

figure     a  possible training data learning set outcomes   b  initial set
outcomes would created data  a  picking smallest
outcome describes change 

example  consider coins domain  coins world contains n coins 
showing either heads tails  action flip coupled  takes arguments 
flips coins  half time heads  otherwise tails  set training
data learning outcomes two coins might look part  a  figure   h c 
stands heads c   t c  stands heads c   s  part  s  a  s    example
  flip coupled  suppose suggested rule flip coupled
context deictic references  given data  initial set outcomes four
entries part  b  figure   
rule contained variables  either abstract action arguments deictic
references  induceoutcomes would introduce variables appropriate places
outcome set  variable introduction achieved applying inverse action
substitution examples set changes computing initial set outcomes   
so  given deictic reference c   red c  always found refer c   red
coin  example set outcomes would contain c wherever currently contains c  
finally  disallow use constants rules  variables become way
outcomes refer objects whose properties changed  then  changes containing
constant referred variable cannot expressed  corresponding
example covered noise outcome 
outcome search operators

induceoutcomes uses two search operators  first add operator  picks
pair non contradictory outcomes set creates new outcome
conjunction  example  might pick       combine them  adding new
outcome       h c    h c    set  second remove operator drops
outcome set  outcomes dropped overlapping
outcomes every example cover  otherwise outcome set would remain proper 
 of course  outcome set contains noise outcome  every outcome
dropped  since examples covered noise outcome   whenever operator
adds removes outcome  learnparameters called find optimal distribution
   thus  induceoutcomes introduces variables aggressively wherever possible  based intuition
corresponding objects would better described constant  become apparent
training example 

   

filearning symbolic models stochastic world dynamics

new outcome set  used calculate maximum log likelihood
data respect new outcome set 
sometimes  learnparameters return zero probabilities outcomes 
outcomes removed outcome set  since contribute nothing
likelihood  add complexity  optimization improves efficiency
search 
outcomes figure       dropped since covers e   
covered         new outcome created conjoining
existing ones       h c    h c     covers e    e    e    thus     added 
      dropped  adding    dropping              creates outcome
set             optimal set outcomes training examples figure   
notice outcome always equal union sets literals change
training examples covers  fact ensures every proper outcome made
merging outcomes initial outcome set  induceoutcomes can  theory  find
set outcomes 
      learning rules
know fill incomplete rules  describe learnrules  outermost
level learning algorithm  takes set examples e fixed language
primitive derived predicates  performs greedy search space rule
sets  precisely  searches space proper rule sets  rule set r
defined proper respect data set e includes one rule
applicable every example e e change occurs  include
rules applicable examples 
search proceeds described pseudocode figure    starts rule set
contains default rule  every step  takes current rule set applies
search operators obtain set new rule sets  selects rule set r
maximizes scoring metric s r  defined equation    ties s r  broken
randomly 
begin explaining search initialized  go describe
operators used  finish working simple example shows learnrules
action 
rule set search initialization

learnrules initialized proper rule set  paper  always initialize
set noisy default rule  treats action effects training set
noise  search progresses  search operators introduce rules explain action
effects explicitly  chose initial starting point simplicity  worked
well informal experiments  another strategy would start specific rule
set  describing detail examples  bottom up methods advantage
data driven  help search reach good parts search space
easily  however  show  several search operators used algorithm
presented guided training examples  algorithm already
desirable property  moreover  bottom up method bad complexity properties
   

fipasula  zettlemoyer    pack kaelbling

learnruleset e 
inputs 
training examples e
computation 
initialize rule set r contain default rule
better rules sets found
search operator
create new rule sets o  ro   o r  e 
rule set r  ro
score improves  s r      s r  
update new best rule set  r   r 
output 
final rule set r

figure    learnruleset pseudocode  algorithm performs greedy search space
rule sets  step set search operators propose set new rule sets 
highest scoring rule set selected used next iteration 

situations large data set described using relatively simple set rules 
case interested in 
rule set search operators

rule set search  learnrules repeatedly finds applies operator
increase score current rule set most 
search operators work creating new rule set rules  usually
altering existing rule  integrating new rules rule set way
ensures rule set remains proper  rule creation involves picking action z 
set deictic references d  context   calling induceoutcomes
learning algorithm complete rule filling  i pi s   if new rule covers
examples  attempt abandoned  since adding rule cannot help scoring
metric   integration rule set involves adding new rules  removing
old rules cover examples  increase number examples
covered default rule 
      search operators
search operator takes input rule set r set training examples e 
creates set new rule sets ro evaluated greedy search loop  eleven
search operators  first describe complex operator  explainexamples  followed
simple one  droprules  then  present remaining nine operators 
share common computational framework outlined figure   
together  operators provide many different ways moving space
possible rule sets  algorithm adapted learn different types rule sets  for
example  without constants  restricting set search operators used 
   

filearning symbolic models stochastic world dynamics

operatortemplate r  e 
inputs 
rule set r
training examples e
computation 
repeatedly select rule r r
create copy input rule set r    r
create new set rules  n   making changes r
new rule r  n covers examples
estimate new outcomes r  induceoutcomes
add r  r  remove rules r  cover
examples r  covers
recompute set examples default rule r 
covers parameters default rule
add r  return rule sets ro
output 
set rules sets  ro

figure    operatortemplate pseudocode  algorithm basic framework used
six different search operators  operator repeatedly selects rule  uses make n
new rules  integrates rules original rule set create new rule set 

explainexamples takes input training set e rule set r creates new 
alternative rule sets contain additional rules modeling training examples
covered default rule r  figure   shows pseudocode
algorithm  considers training example e covered default
rule r  executes three step procedure  first step builds large
specific rule r  describes example  second step attempts trim rule 
generalize maximize score  still ensuring covers e 
third step creates new rule set r  copying r integrating new
rule r  new rule set 
illustration  let us consider steps     explainexamples might
applied training example  s  a  s        on a  t   on b  a    pickup b    on a  t    
background knowledge defined rule   section     constants
allowed 
step   builds rule r  creates new variable x represent object b
action  then  action substitution becomes    x b   action r
set pickup x   context r set conjunction inhand nil  inhand x  
clear x   height x       on x  x   above x  x   topstack x  x   then  step
     explainexamples attempts create deictic references name constants
whose properties changed example  already action substitution  case  changed literal on b  a   b substitution 
c    a   new deictic variable created restricted  extended
   

fipasula  zettlemoyer    pack kaelbling

explainexamples r  e 
inputs 
rule set r
training set e
computation 
example  s  a  s    e covered default rule r
step    create new rule r
step      create action context r
create new variables represent arguments
use create new action substitution
set rs action    a 
set rs context conjunction boolean equality literals
formed using variables available functions predicates
 primitive derived  entailed
step      create deictic references r
collect set constants c whose properties changed s   

c c
create new variable v extend map v c
create   conjunction literals containing v formed using
available variables  functions  predicates  entailed
create deictic reference variable v restriction     
uniquely refers c s  add r
step      complete rule
call induceoutcomes create rules outcomes 
step    trim literals r
create rule set r  containing r default rule
greedily trim literals r  ensuring r still covers  s  a  s    filling
outcomes using induceoutcomes r  score stops improving
step    create new rule set containing r
create new rule set r    r
add r r  remove rules r  cover examples r covers
recompute set examples default rule r  covers parameters
default rule
add r  return rule sets ro
output 
set rule sets  ro

figure    explainexamples pseudocode  algorithm attempts augment rule set new
rules covering examples currently handled default rule 

   

filearning symbolic models stochastic world dynamics

 x b  a   finally  step      outcome set created  assuming
examples context applies  nine ten end x lifted 
rest falling onto table  resulting rule r  looks follows 


inhand y    clear y   on x  y   table y 

pickup x      above x  y   topstack x  y   above y  y 


topstack y  y   on y  y   height y     
inhand nil  inhand x   clear x   table x   height x       on x  x  
above x 
x   topstack x  x 

      on x  y 

      noise

 the falls table outcome modeled noise  since absence constants
rule way referring table  
step    explainexamples trims rule remove literals always true
training examples  on x  x   table  s  redundant ones 
inhand    clear y   perhaps one heights  give


pickup x      on x  y 
inhand nil 
clear x   height x     

      on x  y 

      noise

rules context describes starting example concisely  explain examples
consider dropping remaining literals  thereby generalizing rule
applies examples different starting states  however  generalizations
necessarily improve score  smaller contexts  might end
creating outcomes describe new examples  penalty term
guaranteed improve  change likelihood term depend whether
new examples higher likelihood new rule default rule 
whether old examples higher likelihood old distribution
new one  quite frequently  need cover new examples
give new rule distribution closer random before  usually
lead decrease likelihood large overcome improvement
penalty  given likelihood penalty trade off 
let us assume that  case  predicate dropped without worsening
likelihood  rule integrated rule set is 
droprules cycles rules current rule set  removes one
turn set  returns set rule sets  one missing different rule 
remaining operators create new rule sets input rule set r repeatedly
choosing rule r r making changes create one new rules  new
rules integrated r  explainexamples  create new rule set r   
figure   shows general pseudocode done  operators vary
way select rules changes make them  variations described
   

fipasula  zettlemoyer    pack kaelbling

operator below   note operators  deal deictic
references constants  applicable action model representation allows
features  
droplits selects every rule r r n times  n number literals
context r  words  selects r literal context 
creates new rule r  removing literal rs context  n figure  
simply set containing r   
so  example pickup rule created explainexamples would selected three times 
inhand nil  clear x   one height x       would create
three new rules  each different literal missing   three singleton n sets 
three candidate new rule sets r    since newly created r  generalizations r 
certain cover rs examples  r removed
r  s 
changes suggested droplits therefore exactly suggested trimming search explainexamples  one crucial difference 
droplits attempts integrate new rule full rule set  instead making quick comparison default rule step   explainexamples 
explainexamples used trimming search relatively cheap  local
heuristic allowing decide rule size  droplits uses search globally
space rule sets  comparing contributions various conflicting rules 
droprefs operator used deictic references permitted  selects
rule r r deictic reference r  creates new rule r 
removing deictic reference r  n is  again  set containing r   
applying operator  pickup rule would selected once  reference
describing   one new rule set would returned  one containing rule
without  
generalizeequality selects rule r r twice equality literal context
create two new rules  one equality replaced   one
replaced   rule integrated rule set r 
resulting two r  returned  again  generalized rules certain cover
rs examples  r  contain r 
context pickup rule contains one equality literal  height x       generalizeequality attempt replace literal height x    height x    
domain containing two blocks  would likely yield interesting
generalizations 
changeranges selects rule r r n times equality inequality literal
context  n total number values range literal 
time selects r creates new rule r  replacing numeric value chosen
 in equality another possible value range  note quite possible
new rules cover examples  abandoned 
remaining rules integrated new copies rule set usual 
   

filearning symbolic models stochastic world dynamics

thus  f    ranges          n   changerange would  applied rule containing inequality f      i  construct rule sets replaced
integers          n  
pickup rule contains one equality literal  height x       two block domain
 s  a  s    example drawn  height   take values         
rule will  again  selected thrice  new rules created containing
new equalities  since rule constrains x something  new rule containing
height x      never cover examples certainly abandoned 
splitonlits selects rule r r n times  n number literals
absent rules context deictic references   the set absent literals
obtained applying available functions predicatesboth primitive
derivedto terms present rule  removing literals already present
rule resulting set   constructs set new rules  case
predicate inequality literals  creates one rule positive version
literal inserted context  one negative version 
case equality literals  constructs rule every possible value equality could
take  either case  rules cover examples dropped  remaining
rules corresponding one literal placed n   integrated
rule set simultaneously 
note newly created rules will  them  cover examples
start covered original rule others  examples
split them 
list literals may added pickup rule consists inhand x  
inhand y   table x   table y   clear y   on y  x   on y  y   on x  x   height y     
possible applications topstack  literals make
interesting examples  adding context create rules either
cover examples all  abandoned  cover set
examples original rule  rejected likelihood
worse penalty  however  illustrate process  attempting add
height y     predicate result creation three new rules height y    n
context  one n            rules would added rule set
once 
addlits selects rule r r  n times  n number predicate based
literals absent rules context deictic references    reflects fact literal may considered positive negative form 
constructs new rule literal inserting literal earliest place
rule variables well defined  literal contains deictic
variables  context  otherwise restriction last
deictic variable mentioned literal   so  v  v  deictic variables v 
appears first  on v    v    would inserted restriction v     resulting
rule integrated rule set 
list literals may added pickup rule much splitonlits 
without height y      again  process lead anything interesting
   

fipasula  zettlemoyer    pack kaelbling

example  reason  illustration  inhand y  would
chosen twice  inhand y   added context case  since
context already contains inhand nil  adding inhand y  redundant  adding
inhand y  produce contradiction  neither rule seriously considered 
addrefs operator used deictic references permitted  selects
rule r r n times  n number literals constructed
using available predicates  variables r  new variable v  case 
creates new deictic reference v  using current literal define restriction 
adds deictic reference antecendent r construct new rule 
integrated rule set 
supposing v new variable  list literals would constructed
pickup rule consists inhand v   clear v   on v  x   on x  v   table v   on v  y  
on y  v   on v  v   possible applications topstack  which
mirror on   used create deictic references v   table v  
 a useful reference here  allows rule describe falls table outcomes
explicitly  operator likely accepted point search  
raiseconstants operator used constants permitted  selects
rule r r n times  n number constants among arguments rs
action  constant c  constructs new rule creating new variable
replacing every occurrence c it  integrates new rule rule
set 
splitvariables operator used constants permitted  selects
rule r r n times  n number variables among arguments rs
action  variable v  goes examples covered rule r
collects constants v binds to  then  creates rule constants
replacing every occurrence v constant  rules corresponding one
variable v combined set n integrated old rule set together 
found operators consistently used learning 
set operators heuristic  complete sense every rule set
constructed initial rule setalthough  course  guarantee
scoring metric lead greedy search global maximum 
learnruless search strategy one large drawback  set learned rules
guaranteed proper training set testing data  new test examples
could covered one rule  happens  employ alternative
rule selection semantics  return default rule model situation  way 
essentially saying dont know happen  however 
significant problem  problematic test examples always added future training
set used learn better models  given sufficiently large training set  failures
rare 

   

filearning symbolic models stochastic world dynamics

e  

b 

b 
b 

puton b  

b 
b 

puton b  

b 
b 

b 

e  

r   

r   

puton x 
 
 
 
  inhand y 
  table t 
empty
context

       on y  t 
       on y  x 


       noise

r   

puton x 
 
n

  inhand y 
clear x 
n
      on y  x 

b 

b 

e  

b 

puton x 
 
 
 
  inhand y 
z   on z  x 
empty
  context
      on y  z 

      noise

b 

b 
puton b  

b  b 

b 
b  b 

figure    three training examples three blocks world  example paired initial
rule explainexamples might create model it  example  agent trying
put block b  onto block b  

example rule set learning

example  consider learnruleset might learn set rules model three
training examples figure    given settings complexity penalty noise bound
later used experiments        pmin              pmin low
three block domain  since    different states  use consistency 
initialization  rule set contains default rule  changes occur
examples modeled noise  since examples include change  default rule
noise probability      describe path greedy search takes 
first round search explainexamples operator suggests adding new
rules describe examples  general  explainexamples tries construct rules
compact  cover many examples  assign relatively high probability
covered example   the latter means noise outcomes avoided whenever
possible   one reasonable set rules suggested shown right hand side
figure    notice r  deterministic  high probability relatively compact 
e  unique initial state  explainexamples take advantage this  meanwhile 
   

fipasula  zettlemoyer    pack kaelbling

e  e  starting state  rules explaining must cover
others examples  thus  noise outcomes unavoidable rules  since lack
necessary deictic references   deictic variables created describe objects
whose state changes example explained  
now  consider adding one rules  guarantee
constitute improvement  since high complexity penalty would make rule
look bad  high pmin would make default rule look good  determine
best move is  algorithm compares scores rule sets containing
proposed rules score initial rule set containing default rule  let us
calculate scores example  starting rule set consisting rule r   
covers e  e    default rule rd   covers remaining example 
therefore noise probability      use equation    let rules
complexity number literals body  so  case r    three  get 
s r    rd    

x

log p  s   s  a  r s a    

 s a s   e

x

p en  r 

rr

  log           pmin     log     pmin     log pmin   p en  r    p en  rd  
  log               log               log                       
                   
        
so  rule set containing r  score         similar calculations show
rule sets containing r  r  scores             respectively  since
initial rule set score     new rule sets improvements  one
containing r  best  picked greedy search  new rule set now 


puton x      inhand y     table t 
empty context

       on y  t 
       on y  x 


       noise
default
rule 
      change

      noise

notice training examples covered non default rule  situation 
default rule cover examples probability assigned noise
outcome 
next step  search decide altering existing rule  introducing another rule describe example currently covered default rule  since
default rule covers examples  altering single rule rule set option 
operators likely score highly get rid noise outcome 
rule means referring block x e   
appropriate operator therefore addrefs  introduce new deictic reference describing block  course  increases size rule  complexity 
   

filearning symbolic models stochastic world dynamics

addition means rule longer applies e    leaving example
handled default rule  however  new rule set raises probabilities
examples enough compensate increase complexity  ends
score         clear improvement         highest score
obtainable step  algorithm alters rule set get 
puton x   



  inhand y     table t   z   on z  x 



empty context

      on y  z 

      on y  t 
default
rule 
      change

      noise

default rule covers e    explainexamples something work again 
adding r  get rid noise  yield much improved score        again 
biggest improvement made  rule set becomes 
puton x   



  inhand y     table t   z   on z  x 



empty context

      on y  z 

      on y  t 


puton x      inhand y 
clear x 

      on y  x 
default
rule 
      change

      noise

note rule could added earlier e  covered
first rule added  r    specialized  thus  adding r  rule set containing r 
would knocked r  out  caused examples e  e  explained noise
default rule  would reduced overall score   it is  however  possible rule
knock another yet improve score  requires complicated set
examples  
learning continues search  attempts apply rule altering operators
current rules either make bigger without changing likelihood  lead
creation noise outcomes  dropping either rule add noise probability
default rule lower score  since extra examples explained 
operator improve score  search stops rule set  seems
reasonable rule set domain  one rule covers happens try puton
clear block  one describes try puton block another block it 
ideally  would first rule generalize blocks something them 
instead on  notice would need examples containing higher stacks 
   

fipasula  zettlemoyer    pack kaelbling

      different versions algorithm
making small variations learnruleset algorithm  learn different types
rule sets  important evaluating algorithm 
explore effects constants rules  evaluate three different versions
rule learning  propositional  relational  deictic  propositional rule learning  explainexamples creates initial trimmed rules constants never introduces variables 
none search operators introduce variables used  thus  learned rules
guaranteed propositionalthey cannot generalize across identities specific
objects  relational rule learning  variables allowed rule action arguments
search operators allowed introduce deictic references  explainexamples creates
rules constants name objects  long constants already
variable action argument list mapped them  finally  deictic rule learning 
constants allowed  see deictic learning provides strong bias
improve generalization 
demonstrate addition noise deictic references result better
rules  learn action models enhancements  again 
done changing algorithm minor ways  disallow noise  set rule noise
probability zero  means must constrain outcome sets contain
outcome every example change observed  rules cannot express
changes abandoned  disallow deictic references  disable operators
introduce them  explainexamples create empty deictic reference set 
    learning concepts
contexts deictic references ndrs make use concept predicates functions well primitive ones  concepts specified hand  learned using
rather simple algorithm  learnconcepts  uses learnruleset subprocedure
testing concept usefulness  algorithm works constructing increasingly complex concepts  running learnruleset checking concepts appear learned
rules  first set created applying operators figure   literals built
original language  subsequent sets concepts constructed using literals
proved useful latest run  concepts tried before  always
true always false across examples  discarded  search ends none
new concepts prove useful 
example  consider predicate topstack simple blocks world  could
discovered follows  first round learning  literal on x    x    used define
new predicate n y    y        y    y     true y  stacked y   
assuming new predicate appears learned rules  used second
round learning  define  among others  m z    z       n z    z    clear z     ensuring
z  clear  predicate true z  highest block stack
containing z    notion topstack used determining happen
gripper tries pick z    descends above  likely grasp
block top stack instead 
since concept language quite rich  overfitting  e g   learning concepts
used identify individual examples  serious problem  handle
   

filearning symbolic models stochastic world dynamics

p x  n    qy p y  
p x    x    n y       qy   p y    y   
p x    x    n y       qy   p y    y   
p x    x    n y    y       p  y    y   
p x    x    n y    y       p   y    y   
p   x     p   x    n y       p   y    p   y   
p   x     p   x    x    n y    y       p   y    p   y    y   
p   x     p   x    x    n y    y       p   y    p   y    y   
p   x    x     p   x    x    n y    y       p   y    y    p   y    y   
p   x    x     p   x    x    n y    y       p   y    y    p   y    y   
p   x    x     p   x    x    n y    y       p   y    y    p   y    y   
p   x    x     p   x    x    n y    y       p   y    y    p   y    y   
f  x    c n       y f  y     c
f  x  c n       y f  y   c
f  x  c n       y f  y   c
figure    operators used invent new predicate n  operator takes input one
literals  listed left  ps represent old predicates  f represents old function 
q refer   c numerical constant  operator takes literal
returns concept definition  operators applied literals used
rules rule set create new predicates 

expected way  introducing penalty term    c r   create new scoring metric
   r    s r    c r 
c r  number distinct concepts used rule set r   scaling
parameter  new metric   used learnruleset  avoids overfitting favoring
rule sets use fewer derived predicates   note fact   cannot factored
rule  was  matter  since factoring used induceoutcomes
learnparameters  neither change number concepts used relevant
rule  outcomes contain primitive predicates  
    discussion
rule set learning challenge addressed section complicated need learn
structure rules  numeric parameters associated outcome distributions 
definitions derived predicates modeling language  learnconcepts
   

fipasula  zettlemoyer    pack kaelbling

algorithm conceptually simple  performs simultaneous learning effectively 
see experiments section     
large number possible search operators might cause concern overall
computational complexity learnruleset algorithm  although algorithm expensive  set search operators designed control complexity attempting
keep number rules current set small possible 
step search  number new rule sets considered depends
current set rules  explainexamples operator creates new rule sets 
number examples covered default rule  since search starts rule set
containing default rule  initially equal number training examples 
however  explainexamples designed introduce rules cover many examples 
practice grows small quickly  operators create o rm  new rule sets 
r number rules current set depends specific operator 
example  could number literals dropped context
rule droplits operator  although large  r stays small practice
search starts default rule complexity penalty favors small rule
sets 
ensure score increases search step  algorithm guaranteed converge  usually local  optimum  not  however  guarantee
quickly get there  practice  found algorithm converged quickly
test domains  learnruleset algorithm never took    steps
learnconcepts outer loop never cycled   times  entire algorithm never took
six hours run single processor  although significant effort made
cache intermediate computations final implementation 
spite this  realize that  scale complex domains  approach
eventually become prohibitively expensive  plan handle problem developing new algorithms learn concepts  rules  rule parameters online manner 
directed search operators  however  leave complex approach
future work 

   planning
experiments section     involve learning models complex actions
true models dynamics  level relational rules  available evaluation 
instead  learned models evaluated planning executing actions 
many possible ways plan  work  explore mdp planning 
mdp  puterman          tuple  s  a  t  r   set possible states 
set possible actions  distribution encodes transition dynamics
world   s   s  a   finally  r reward signal maps every state real value 
policy plan  possibly stochastic  mapping states actions  expected
amount reward achieved executing starting called value
p

defined v  s    e 
i   r si      si states reached
time i  discount factor       favors immediate rewards  goal
mdp planning find policy achieve reward time 
   

filearning symbolic models stochastic world dynamics

optimal policy found solving set bellman equations 
s  v  s    r s   

x

 s   s   a  v  s    

   

s 

application  action set state set defined world
modeling  rule set r defines transition model reward function r defined
hand 
planning large domains  difficult solve bellman
equations exactly  approximation  implemented simple planner based
sparse sampling algorithm  kearns  mansour    ng         given state s  creates tree
states  of predefined depth branching factor  sampling forward using transition
model  computes value node using bellman equation  selects action
highest value 
adapt algorithm handle noisy outcomes  predict next state 
estimating value unknown next state fraction value staying
state  i e   sample forward stayed state scale
value obtain  scaling factor       depth branching factor
four 
scaling method guess value unknown next state might
be  noisy rules partial models  way compute value explicitly 
future  would explore methods learn associate values noise
outcomes  example  value outcome tower blocks falls
different goal build tall stack blocks goal put
blocks table 
algorithm solve hard combinatorial planning problems  allow
us choose actions maximize relatively simple reward functions  see
next section  enough distinguish good models poor ones  moreover 
development first order planning techniques active field research  aips        

   evaluation
section  demonstrate rule learning algorithm robust variety lownoise domains  show works intrinsically noisy simulated blocks world
domain  begin describing test domains  report series experiments 
    domains
experiments performed involve learning rules domains briefly
described following sections 
      slippery gripper
slippery gripper domain  inspired work draper et al          abstract 
symbolic blocks world simulated robotic arm  used move blocks
around table  nozzle  used paint blocks  painting block
might cause gripper become wet  makes likely fail
manipulate blocks successfully  fortunately  wet gripper dried 
   

fipasula  zettlemoyer    pack kaelbling

pickup x      on x     clear x  
inhand nil  block x   block y    wet 



pickup x      on x     clear x  
inhand nil  block x   block y    wet




inhand x   clear x   inhand nil 

    
on x     clear y  


     on x  table   on x   
     change

inhand x   clear x   inhand nil 

     
on x     clear y  


      on x  table   on x   
      change

pickup x      on x     clear x  
inhand nil  block x   table y    wet
pickup x      on x     clear x  
inhand nil  block x   table y    wet

 


 


inhand x   clear x   inhand nil 
on x   
     change

    

inhand x   clear x   inhand nil 
on x   
     change

    


inhand nil  clear y   inhand x  


    


on x  y   clear x 

puton x  y    clear y   inhand x  
on x  table   clear x   inhand nil 

block y 

     inhand x 


     change

 
puton x  table    inhand x 

 

     painted x 
     painted x   wet
     change



     wet
     change

paint x    block x 

dry   context

on x  table   clear x   inhand nil 
inhand x 
     change
    

figure    eight relational planning rules model slippery gripper domain 

figure   shows set rules model domain  individual states represent
world objects intrinsic constants experimental data generated sampling
rules  section        explore learning algorithms section   compare
number training examples scaled single complex world 
      trucks drivers
trucks drivers logistics domain  adapted      aips international planning
competition  aips         four types constants  trucks  drivers  locations 
objects  trucks  drivers objects locations  locations
connected paths links  drivers board trucks  exit trucks  drive trucks
locations linked  drivers walk  without truck  locations
connected paths  finally  objects loaded unloaded trucks 
set rules shown figure    actions simple rules succeed
fail change world  however  walk action interesting twist  drivers
try walk one location another  succeed time 
   

filearning symbolic models stochastic world dynamics

load o  t  l   

at t  l   at o  l 



     at o  l   in o   
     change

unload o  t  l   

in o     at t  l 



     at o  l   in o   
     change

board d  t  l   

at t  l   at d  l   empty t  



     at d  l   driving d     empty t  
     change

disembark d  t  l   

at t  l   driving d   



     driving d     at d  l   empty t  
     change

drive t  f l  l  d   

driving d     at t  f l   link f l  l 



     at t  l   at t  f l 
     change


     at d  l   at d  f l 

walk d  f l  l   

at d  f l   path f l  l 
     pick x s t  path f l  x 
at d  x   at d  f l 

figure    six rules encode world dynamics trucks drivers domain 
time arrive randomly chosen location connected path
origin location 
representation presented cannot encode action efficiently  best rule
set rule origin location  outcomes every location origin
linked to  extending representation allow actions walk represented
single rule interesting area future work 
slippery gripper domain  individual states represent world objects intrinsic
constants experimental data generated sampling rules  trucks
drivers dynamics difficult learn but  see section        learned
enough training data 
      simulated blocks world
validate rule extensions paper  section     presents experiments rigid
body  simulated physics blocks world  section describes logical interface
simulated world  description extra complexities inherent learning dynamics
world presented section   
define interface symbolic representation use describe
action dynamics physical domain simulated blocks world  perceptual
system produces states contain skolem constants  logical language includes
binary predicate on x  y   defined x exerts downward force obtained
querying internal state simulator  unary typing predicates table block 
actuation system translates actions sequences motor commands simulator 
actions always execute  regardless state world  define two actions 
parameters allow agent specify objects intends manipulate 
pickup x  action centers gripper x  lowers hits something  grasps 
raises gripper  analogously  puton x  action centers gripper x  lowers
encounters pressure  opens it  raises it 
   

fipasula  zettlemoyer    pack kaelbling

using simulator sidestepping difficult pixels to predicates problem
occurs whenever agent map domain observations internal representation 
primitive predicates defined terms internal state simulation simpler
cleaner observations real world would be  make domain completely
observable  prerequisite learning planning algorithms  choosing set
predicates observe important  make rule learning problem easy
hard  difficulty making choice magnified richer settings  limited
language described balances extremes providing on  would difficult
derive means  providing predicates inhand clear 
learned 
    experiments
section describes two sets experiments  first  compare learning deictic 
relational  propositional rules slippery gripper trucks drivers data 
domains modeled planning rules  contain intrinsic constants  noisy 
thus allow us explore effect deictic references constants rules directly 
then  describe set experiments learns rules model data simulated
blocks world  data inherently noisy contains skolem constants  result 
focus evaluating full algorithm performing ablation studies demonstrate
deictic references  noise outcomes  concepts required effective learning 
experiments use examples   s  a  s    e  generated randomly constructing
state s  randomly picking arguments action a  executing action
state generate s    distribution used construct biased guarantee that 
approximately half examples  chance change state  method
data generation designed ensure learning algorithms always data
representative entire model learn  thus  experiments
ignore problems agent would face generate data exploring world 
      learning rule sets noise
know model used generate data  evaluate model respect
set similarly generated test examples e calculating average variational distance
true model p estimate p  
v d p  p    

  x
 p  e  p  e    
 e  ee

variational distance suitable measure clearly favors similar distributions 
yet well defined zero probability event observed   as happen
non noisy rule learned sparse data many outcomes
should  
comparisons performed four actions  first two  paint pickup 
slippery gripper domain  second two  drive walk 
trucks drivers domain  action presents different challenges learning  paint
simple action one outcome lead successor state  as
described section       pickup complex action must represented
   

filearning symbolic models stochastic world dynamics

paint action
   
    

pickup action
    

propositional
relational
deictic

variational distance

variational distance

    

   
    
   
    
 

   
    
   
    
   
    
 

                                       
training set size

                                       
training set size

walk action
   
    

drive action
   

propositional
relational
deictic

variational distance

variational distance

    

propositional
relational
deictic

   
    
   
    
 

    

propositional
relational
deictic

   
    
 

                                   
training set size

                                   
training set size

figure     variational distance function number training examples propositional  relational  deictic rules  results averaged ten trials
experiment  test set size     examples 

one planning rule  drive simple action four arguments  finally  walk
complicated action uses path connectivity world noise model lost
pedestrians  slippery gripper actions performed world four blocks 
trucks driver actions performed world two trucks  two drivers  two
objects  four locations 
compare three versions algorithm  deictic  includes full rules language allow constants  relational  allows variables constants
deictic references  propositional  constants variables  figure   
shows results  relational learning consistently outperforms propositional learning 
implies variable abstractions useful  cases except walk action 
deictic learner outperforms relational learner  result implies forcing
rules contain variables preventing overfitting learning better models 
results walk action interesting  here  deictic learner cannot actually
represent optimal rule  requires noise model complex  deictic learner
quickly learns best rule can  relational propositional learners eventually
   

fipasula  zettlemoyer    pack kaelbling

learning simulated blocksworld
  

learned concepts
hand engineered concepts
without noise outcomes
restricted language

total reward

  
  
  
  
 
 
   

   

   

   
   
   
training set size

   

   

    

figure     performance various action model variants function number training
examples  data points averaged five planning trials three
rule sets learned different training data sets  comparison  average reward
performing actions      reward obtained human directed
gripper averaged      

learn better rule sets use constants accurately model walkers
moving random locations 
experiments  see variable abstraction helps learn less data 
deictic rules  abstract aggressively  perform best  long
represent model learned  next section  consider deictic
rules  since working domain simulated perception
access objects identities names using skolem constants 
      learning blocks world simulator
final experiment demonstrates noise outcomes complicated concepts
necessary learn good action models blocks world simulator 
true model known  evaluate learned model using plan
estimating average reward gets  reward function used simulated blocks
world average height blocks world  breadth depth
search sampling planner four  learning  set     pmin
          
tested four action model variants  varying training set size  results
shown figure     curve labeled learned concepts represents full algorithm
presented paper  performance approaches obtained human expert 
comparable algorithm labeled hand engineered concepts
   

filearning symbolic models stochastic world dynamics

concept learning  was  instead  provided hand coded versions concepts
clear  inhand  inhand nil  above  topstack  height  concept learner discovered
these  well useful predicates  e g   p x  y     clear y  on y  x  
call onclear  could action models outperformed hand engineered ones
slightly small training sets  domains less well studied blocks world  might
less obvious useful concepts are  concept discovery technique presented
prove helpful 
remaining two model variants obtained rewards comparable reward
nothing all   the planner attempt act experiments 
poor job   one variant  used full set predefined concepts rules
could noise outcomes  requirement explain every action effect led
significant overfitting decrease performance  rule set given
traditional blocks world language  include above  topstack  height 
allowed learn rules noise outcomes  tried full language variant noise
outcomes allowed  deictic references not  resulting rule sets contained
noisy rules  planner attempt act all  poor performance
ablated versions representation shows three extensions
essential modeling simulated blocks world domain 
human agent commanding gripper solve problem received average
total reward       theoretical maximum due unexpected action
outcomes  thus  nd rules performing near human levels  suggesting
representation reasonable one problem  suggests planning
approximations learning bounds limiting performance  traditional rules 
face challenge modeling transitions seen data  much larger
hypothesis space consider learning  surprising generalize poorly
consistently out performed ndrs 
informally  report ndr algorithms execute significantly faster
traditional ones  one standard desktop pc  learning ndrs takes minutes learning
traditional rules take hours  noisy deictic action models generally
compact traditional ones  they contain fewer rules fewer outcomes  planning
much faster well 
get better feel types rules learned  two interesting rules produced
full algorithm 

pickup x   

  onclear x  y   z   on y  z  
  table t 



inhand nil  size x     

      on y  z 
      on x  y 


      on x  y   on y  t   on y  z 

rule applies empty gripper asked pick small block x sits
top another block y  gripper grabs high probability 

   

fipasula  zettlemoyer    pack kaelbling


puton x   

  topstack y  x   z   inhand z  
  table t 

size y     


     

     

     



     



on z  y 
on z  t 
on z  t   on y  t   on y  x 
noise

rule applies gripper asked put contents  z  block x
inside stack topped small block y  placing things small block chancy 
reasonable probability z fall table  small probability
follow 

   discussion
paper  developed probabilistic action model representation rich enough
used learn models planning physically simulated blocks world 
first step towards defining representations algorithms enable learning
complex worlds 
    related work
problem learning deterministic action models well studied  work
area  shen   simon        gil              wang        focused incrementally
learning planning operators interacting simulated worlds  however  work
assumes learned models completely deterministic 
oates cohen        earliest work learning probabilistic planning operators  rules factored apply parallel  however  representation
strictly propositional  allows rule contain single outcome 
previous work  developed algorithms learning probabilistic relational planning operators  pasula  zettlemoyer    kaelbling         unfortunately  neither probabilistic
algorithms robust enough learn complex  noisy environments simulated
blocks world 
one previous system comes close goal trail learner  benson        
trail learns extended version horn clauses noisy environments applying inductive logic programming  ilp  learning techniques robust noise  trail
introduced deictic references name objects based functional relationships
arguments actions  deictic references  exists unique quantification
semantics  generalization bensons original work  moreover  trail models continuous actions real valued fluents  allows represent complex
models date  including knowledge required pilot realistic flight simulator  however  rules trail learns limited probabilistic representation
represent possible transition distributions  trail include mechanisms
learning new predicates 
   

filearning symbolic models stochastic world dynamics

work action model learning used different versions greedy search
rule structure learning  closely related inspired learning version
spaces mitchell        later ilp work  lavrac   dzeroski         paper 
explore  first time  new way moving space rule sets
using noise rule initial rule set  found approach works well
practice  avoiding need hand selected initial rule set allowing algorithm
learn significantly complex environments 
far know  work learning action models explored learning concepts 
ilp literature  recent work  assche  vens  blockeel    dzeroski        shown
adding concept learning decision tree learning algorithms improves classification
performance 
outside action learning  exists much related research learning probabilistic
models relational logical structure  complete discussion beyond scope
paper  present highlights  work learns representations
relational extension bayesian networks  comprehensive example  see work getoor
        work extends research ilp incorporating probabilistic dependencies 
example  see wide range techniques presented kersting         additionally 
recent work learning markov logic networks  richardson   domingos        kok
  domingos         log linear models features defined first order
logical formulae  action models action model learning algorithms paper
designed represent action effects  special case general approaches listed
above  discussed section    tailoring representation match
model learnt  simplify learning 
finally  let us consider work related ndr action model representation 
relevant approach ppddl  representation language probabilistic planning operators
problem domains  younes   littman         ndr representation partially
inspired ppddl operators includes restrictions make easier learn extensions  noise outcomes  required effectively model simulated blocks
world  future  algorithms paper could extended learn full ppddl
rules  also  ppddl planning algorithms  for examples  see papers recent planning
competitions  could adapted improve simple planning presented section   
general sense  ndrs related probabilistic relational representations
designed model dependencies across time  examples  see work relational
dynamic bayesian networks  sanghai  domingos    weld         specialization prms  logical hidden markov models  kersting  raedt    raiko        
come ilp research tradition  approaches make different set modeling
assumptions closely tied planning representations ndr models
extend 
    future ongoing work
remains much done context learning probabilistic planning rules 
first all  likely work applied additional domains  such
realistic robotic applications dialogue systems  representation need
adapted  search operators adjusted accordingly  possible changes mentioned
   

fipasula  zettlemoyer    pack kaelbling

article include allowing rules apply parallel  different rules could apply
different aspects state  extending outcomes include quantifiers  actions
walk  trucks drivers domain section        could described using
single rule  significant change intend pursue expanding approach
handle partial observability  possibly incorporating techniques work
deterministic learning  amir         hope make changes make
using rules easier  associating values noise outcomes help planner
decide whether avoided 
second research direction involves development new algorithms learn probabilistic operators incremental  online manner  similar learning setup
deterministic case  shen   simon        gil        wang         potential
scale approach larger domains  make applicable even situations
difficult obtain set training examples contains reasonable sampling worlds
likely relevant agent  line work require development
techniques effectively exploring world learning model  much done
reinforcement learning  longer term  would online algorithms learn
operators concept predicates  useful primitive predicates motor
actions 

acknowledgments
material based upon work supported part defense advanced research
projects agency  darpa   department interior  nbc  acquisition
services division  contract no  nbchd        part darpa grant no 
hr                

references
agre  p     chapman  d          pengi  implementation theory activity 
proceedings sixth national conference artificial intelligence  aaai  
aips         international planning competition  http   www dur ac uk d p long competition html 
aips         international planning competition  http   www ldc usb ve bonet ipc   
amir  e          learning partially observable deterministic action models  proceedings
nineteenth international joint conference artificial intelligence  ijcai  
assche  a  v   vens  c   blockeel  h     dzeroski  s          random forest approach
relational learning  proceedings icml workshop statistical relational
learning connections fields 
benson  s          learning action models reactive autonomous agents  ph d  thesis 
stanford university 
bertsekas  d  p          nonlinear programming  athena scientific 
blum  a     langford  j          probabilistic planning graphplan framework 
proceedings fifth european conference planning  ecp  
   

filearning symbolic models stochastic world dynamics

boutilier  c   reiter  r     price  b          symbolic dynamic programming first order
mdps  proceedings seventeenth international joint conference artificial
intelligence  ijcai  
boyen  x     koller  d          tractable inference complex stochastic processes 
proceedings fourteenth annual conference uncertainty ai  uai  
brooks  r  a          intelligence without representation  artificial intelligence     
draper  d   hanks  s     weld  d          probabilistic planning information gathering
contingent execution  proceedings second international conference
ai planning systems  aips  
edelkamp  s     hoffman  j          pddl     language classical part  th
international planning competition  technical report      albert ludwigs universitat 
freiburg  germany 
fikes  r  e     nilsson  n  j          strips  new approach application theorem
proving problem solving  artificial intelligence       
getoor  l          learning statistical models relational data  ph d  thesis  stanford 
gil  y          efficient domain independent experimentation  proceedings tenth
international conference machine learning  icml  
gil  y          learning experimentation  incremental refinement incomplete planning domains  proceedings eleventh international conference machine
learning  icml  
guestrin  c   koller  d   parr  r     venkataraman  s          efficient solution algorithms
factored mdps  journal artificial intelligence research  jair      
kearns  m   mansour  y     ng  a          sparse sampling algorithm near optimal
planning large markov decision processes  machine learning  ml         
kersting  k          inductive logic programming approach statistical relational
learning  ios press 
kersting  k   raedt  l  d     raiko  t          logical hidden markov models  journal
artificial intelligence research  jair      
khan  k   muggleton  s     parson  r          repeat learning using predicate invention 
international workshop inductive logic programming  ilp  
kok  s     domingos  p          learning structure markov logic networks  proceedings twenty second international conference machine learning  icml  
lavrac  n     dzeroski  s          inductive logic programming techniques applications  ellis horwood 
mitchell  t  m          generalization search  artificial intelligence        
oates  t     cohen  p  r          searching planning operators context dependent
probabilistic effects  proceedings thirteenth national conference
artificial intelligence  aaai  
ode         open dynamics engine toolkit   http   opende sourceforge net 
   

fipasula  zettlemoyer    pack kaelbling

pasula  h   zettlemoyer  l     kaelbling  l          learning probabilistic relational planning rules  proceedings fourteenth international conference automated
planning scheduling  icaps  
puterman  m  l          markov decision processes  john wiley sons  new york 
richardson  m     domingos  p          markov logic networks  machine learning  ml  
   
sanghai  s   domingos  p     weld  d          relational dynamic bayesian networks 
journal artificial intelligence research  jair      
shen  w  m     simon  h  a          rule creation rule learning environmental exploration  proceedings eleventh international joint conference
artificial intelligence  ijcai  
wang  x          learning observation practice  incremental approach planning operator acquisition  proceedings twelfth international conference
machine learning  icml  
yoon  s   fern  a     givan  r          inductive policy selection first order markov
decision processes  proceedings eighteenth conference uncertainty
artificial intelligence  uai  
younes  h  l  s     littman  m  l          ppddl     extension pddl expressing
planning domains probabilistic effects  school computer science  carnegie
mellon university  technical report cmu cs        
zettlemoyer  l   pasula  h     kaelbling  l          learning probabilistic relational planning rules  mit tech report 

   


