journal artificial intelligence research                  

submitted        published      

generalized a  architecture
pedro f  felzenszwalb

pff cs uchicago edu

department computer science
university chicago
chicago  il      

david mcallester

mcallester tti c org

toyota technological institute chicago
chicago  il      

abstract
consider problem computing lightest derivation global structure using
set weighted rules  large variety inference problems ai formulated
framework  generalize a  search heuristics derived abstractions
broad class lightest derivation problems  describe new algorithm searches
lightest derivations using hierarchy abstractions  generalization a  gives
new algorithm searching and or graphs bottom up fashion 
discuss algorithms described provide general architecture addressing pipeline problem problem passing information back forth
various stages processing perceptual system  consider examples computer vision natural language processing  apply hierarchical search algorithm
problem estimating boundaries convex objects grayscale images compare
search methods  second set experiments demonstrate use new
compositional model finding salient curves images 

   introduction
consider class problems defined set weighted rules composing structures
larger structures  goal problems find lightest  least cost  derivation
global structure derivable given rules  large variety classical inference
problems ai expressed within framework  example global structure
might parse tree  match deformable object model image  assignment
values variables markov random field 
define lightest derivation problem terms set statements  set weighted
rules deriving statements using statements special goal statement 
case looking lightest derivation goal statement  usually express
lightest derivation problem using rule schemas implicitly represent large set
rules terms small number rules variables  lightest derivation problems
formally equivalent search and or graphs  nilsson         find
formulation natural applications interested in 
one goals research construction algorithms global optimization
across many levels processing perceptual system  described algorithms
used integrate multiple stages processing pipeline single global optimization problem solved efficiently 
c
    
ai access foundation  rights reserved 

fifelzenszwalb   mcallester

dynamic programming fundamental technique designing efficient inference algorithms  good examples viterbi algorithm hidden markov models  rabiner 
      chart parsing methods stochastic context free grammars  charniak        
algorithms described used speed solution problems normally
solved using dynamic programming  demonstrate specific problem 
goal estimate boundary convex object cluttered image  second set
experiments show algorithms used find salient curves images 
describe new model salient curves based compositional rule enforces
long range shape constraints  leads problem large solved using
classical dynamic programming methods 
algorithms consider related dijkstras shortest paths algorithm  dsp 
 dijkstra        a  search  hart  nilsson    raphael         dsp a 
used find shortest path cyclic graph  use priority queue define order
nodes expanded worst case running time o m log n   n
number nodes graph number edges  dsp a 
expansion node v involves generating nodes u edge v u 
difference two methods a  uses heuristic function avoid
expanding non promising nodes 
knuth gave generalization dsp used solve lightest derivation
problem cyclic rules  knuth         call knuths lightest derivation algorithm
 kld   analogy dijkstras algorithm  kld uses priority queue define order
statements expanded  expansion statement v involves generating
conclusions derived single step using v statements already
expanded  long rule bounded number antecedents kld worst
case running time o m log n   n number statements problem
number rules  nilssons ao  algorithm        used solve
lightest derivation problems  although ao  use heuristic function  true
generalization a  use priority queue  handles acyclic rules 
require o m n   time even applied shortest path problem   particular  ao 
variants use backward chaining technique starts goal repeatedly
refines subgoals  a  forward chaining algorithm  
klein manning        described a  parsing algorithm similar kld
use heuristic function  one contributions generalization algorithm
arbitrary lightest derivation problems  call algorithm a  lightest derivation
 a ld   method forward chaining  uses priority queue control order
statements expanded  handles cyclic rules worst case running time
o m log n   problems rule small number antecedents  a ld
seen true generalization a  lightest derivation problems  lightest derivation
problem comes shortest path problem a ld identical a  
course running times seen practice often well predicted worst case
analysis  specially true problems large defined implicitly 
example  use dynamic programming solve shortest path problem acyclic
graph o m   time  better o m log n   bound dsp  implicit
   extensions handle cyclic rules  jimenez   torras        
   ao  backward chaining terms inference rules defining lightest derivation problem 

   

fithe generalized a  architecture

graphs dsp much efficient since expands nodes best first order 
searching shortest path source goal  dsp expand nodes v
d v  w   d v  length shortest path source v  w
length shortest path source goal  case a  monotone
admissible heuristic function  h v   possible obtain similar bound searching
implicit graphs  a  expand nodes v d v    h v  w  
running time kld a ld expressed similar way  solving
lightest derivation problem  kld expand statements v d v  w   d v 
weight lightest derivation v  w weight lightest derivation
goal statement  furthermore  a ld expand statements v d v    h v  w  
heuristic function  h v   gives estimate additional weight necessary
deriving goal statement using derivation v  heuristic values used a ld
analogous distance node goal graph search problem  the notion
used a    note heuristic values significantly different ones
used ao   case ao  heuristic function  h v   would estimate weight
lightest derivation v 
important difference a ld ao  a ld computes derivations
bottom up fashion  ao  uses top down approach  method advantages  depending type problem solved  example  classical problem
computer vision involves grouping pixels long smooth curves  formulate
problem terms finding smooth curves pairs pixels far apart 
image n pixels  n    pairs  straight forward implementation
top down algorithm would start considering  n    possibilities  bottomup algorithm would start o n  pairs nearby pixels  case expect
bottom up grouping method would efficient top down method 
classical ao  algorithm requires set rules acyclic  jimenez torras
       extended method handle cyclic rules  another top down algorithm
handle cyclic rules described bonet geffner         hansen zilberstein       
described search algorithm problems optimal solutions
cyclic  algorithms described paper handle problems cyclic rules
require optimal solutions acyclic  note ao  handle rules
non superior weight functions  as defined section    kld requires superior weight
functions  a ld replaces requirement requirement heuristic function 
well known method defining heuristics a  consider abstract relaxed
search problem  example  consider problem solving rubiks cube small
number moves  suppose ignore edge center pieces solve corners 
example problem abstraction  number moves necessary put
corners good configuration lower bound number moves necessary solve
original problem  fewer corner configurations full configurations
makes easier solve abstract problem  general  shortest paths
goal abstract problem used define admissible monotone heuristic
function solving original problem a  
show abstractions used define heuristic functions a ld 
lightest derivation problem notion shortest path goal replaced
notion lightest context  context statement v derivation
   

fifelzenszwalb   mcallester

goal hole filled derivation v  computation lightest
abstract contexts lightest derivation problem 
abstractions related problem relaxations defined pearl         abstractions often lead small problems solved search  relaxations lead
problems still large state space may simple enough solved closed
form  definition abstractions use lightest derivation problems includes
relaxations special case 
another contribution work hierarchical search method call ha ld 
algorithm effectively use hierarchy abstractions solve lightest derivation
problem  algorithm novel even case classical search  shortest paths  problem  ha ld searches lightest derivations contexts every level abstraction
simultaneously  specifically  level abstraction set statements
rules  search lightest derivations contexts level controlled
single priority queue  understand running time ha ld  let w weight
lightest derivation goal original  not abstracted  problem  statement v
abstraction hierarchy let d v  weight lightest derivation v level
abstraction  let h v  weight lightest context abstraction v  defined
one level v hierarchy   let k total number statements
hierarchy d v    h v  w   hal d expands  k statements solving
original problem  factor two comes fact algorithm computes
derivations contexts level abstraction 
previous algorithms use abstractions solving search problems include methods based pattern databases  culberson   schaeffer        korf        korf   felner 
       hierarchical a   ha   hida    holte  perez  zimmer    macdonald        holte 
grajkowski    tanner        coarse to fine dynamic programming  cfdp   raphael 
       pattern databases made possible compute solutions impressively large
search problems  methods construct lookup table shortest paths node
goal abstract states  practice approach limited tables remain
fixed different problem instances  relatively small tables heuristic must
recomputed instance  example  rubiks cube precompute
number moves necessary solve every corner configuration  table used
define heuristic function solving full configuration rubiks cube 
ha  hida  use hierarchy abstractions avoid searching nodes
level hierarchy  hand  directed graphs methods may still
expand abstract nodes arbitrarily large heuristic values  clear
generalize ha  hida  lightest derivation problems rules
one antecedent  finally  cfdp related ao  repeatedly solves ever
refined problems using dynamic programming  leads worst case running time
o n    discuss relationships ha ld hierarchical
methods detail section   
note a  search related algorithms previously used solve
number problems classical state space search problems  includes
traveling salesman problem  zhang   korf         planning  edelkamp         multiple
sequence alignment  korf  zhang  thayer    hohwald         combinatorial problems
graphs  felner        parsing using context free grammars  klein   manning        
   

fithe generalized a  architecture

work bulitko  sturtevant  lu  yau        uses hierarchy state space abstractions real time search 
    pipeline problem
major problem artificial intelligence integration multiple processing stages
form complete perceptual system  call pipeline problem  general
concatenation systems stage feeds information next  vision 
example  might edge detector feeding information boundary finding system 
turn feeds information object recognition system 
computational constraints need build modules clean interfaces
pipelines often make hard decisions module boundaries  example  edge detector
typically constructs boolean array indicates weather edge detected
image location  general recognition presence edge
certain location depend context around it  people often see edges places
image gradient small if  higher cognitive level  clear actually
object boundary location  speech recognition systems try address problem
returning n best lists  may may contain actual utterance  would
speech recognition system able take high level information account
avoid hard decision exactly strings output n best list 
processing pipeline specified describing stages terms rules
constructing structures using structures produced previous stage  vision system
one stage could rules grouping edges smooth curves next stage could
rules grouping smooth curves objects  case construct single
lightest derivation problem representing entire system  moreover  hierarchical set
abstractions applied entire pipeline  using ha ld compute lightest
derivations complete scene interpretation derived one level abstraction guides
processing stages concrete level  provides mechanism enables coarse
high level processing guide low level computation  believe important
property implementing efficient perceptual pipelines avoid making hard decisions
processing stages 
note formulation complete computer vision system lightest derivation problem related work geman  potter  chi         tu  chen  yuille 
zhu        jin geman         papers image understanding posed
parsing problem  goal explain image terms set objects
formed  possibly recursive  composition generic parts  tu et al         use
data driven mcmc compute optimal parses geman et al         jin
geman        use bottom up algorithm building compositions greedy fashion 
neither methods guaranteed compute optimal scene interpretation 
hope ha ld provide principled computational technique solving large
parsing problems defined compositional models 
    overview
begin formally defining lightest derivation problems section    section
discusses dynamic programming relationship lightest derivation problems
   

fifelzenszwalb   mcallester

and or graphs  section   describe knuths lightest derivation algorithm 
section   describe a ld prove correctness  section   shows abstractions
used define mechanically constructed heuristic functions a ld  describe
ha ld section   discuss use solving pipeline problem section    section   discusses relationship ha ld hierarchical search methods 
sections      present experimental results  conclude section    

   lightest derivation problems
let set statements r set inference rules following form 
a    w 
  
 
  wn
c   g w            wn  
antecedents ai conclusion c statements   weights wi
non negative real valued variables g non negative real valued weight function 
rule antecedents function g simply non negative real value  throughout
paper use a            g c denote inference rule type 
derivation c finite tree rooted rule a            g c n children 
i th child derivation ai   leaves tree rules antecedents 
every derivation weight value obtained recursive application
functions g along derivation tree  figure   illustrates derivation tree 
intuitively rule a            g c says derive antecedents ai
weights wi derive conclusion c weight g w            wn    problem
interested compute lightest derivation special goal statement 
algorithms discussed paper assume weight functions g associated lightest derivation problem non decreasing variable 
fundamental property ensuring lightest derivations optimal substructure property  case lightest derivations constructed lightest derivations 
facilitate runtime analysis algorithms assume every rule small
number antecedents  use n denote number statements lightest derivation
problem  denotes number rules  problems interested
n large problem implicitly defined compact way 
using small number rules variables examples below  assume
n since statements conclusion rule clearly
derivable ignored 
    dynamic programming
say set rules acyclic ordering statements
rule conclusion c antecedents statements come c
ordering  dynamic programming used solve lightest derivation problem
   

fithe generalized a  architecture

a 
a 
a 
c

derivation
a 

derivation
a 

derivation
a 

figure    derivation c tree rules rooted rule r conclusion c 
children root derivations antecedents r  leafs tree
rules antecedents 

functions g rule non decreasing set rules acyclic  case
lightest derivations computed sequentially terms acyclic ordering o 
i th step lightest derivation i th statement obtained minimizing rules
used derive statement  method takes o m   time compute
lightest derivation statement  
note cyclic rules sometimes possible compute lightest derivations
taking multiple passes statements  note authors would refer
dijkstras algorithm  and kld  dynamic programming method  paper
use term referring algorithms compute lightest derivations fixed
order independent solutions computed along way  this includes recursive
implementations use memoization  
    examples
rules computing shortest paths single source weighted graph shown
figure    assume given weighted graph g    v  e   wxy
non negative weight edge  x  y  e distinguished start node  first
rule states path weight zero start node s  second set rules
state path node x extend path edge x
obtain appropriately weighted path node y  rule type
edge graph  lightest derivation path x  corresponds shortest path
x  note general graphs rules cyclic  figure   illustrates graph
   

fifelzenszwalb   mcallester

   

path s     
     x  y  e 
path x    w
path y    w   wxy
figure    rules computing shortest paths graph 

b

c

path d    w

path c    w

path b    w   wdb

path b    w   wcb

path s    w

path e    w

path d    w   wsd

path c    w   wec



e

path s    w
path s     
path e    w   wse

path s     

figure    graph two highlighted paths b corresponding derivations
using rules figure   

two different derivations path b  using rules described  corresponds
two different paths b 
rules chart parsing shown figure    assume given weighted
context free grammar chomsky normal form  charniak         i e   weighted set
productions form x x z x  z nonterminal symbols
terminal symbol  input string given sequence terminals  s            sn   
   

fithe generalized a  architecture

    production x si  

phrase x  i         w x si  
    production x z     j   k n     
phrase y  i  j    w 
phrase z  j  k    w 
phrase x  i  k    w    w    w x z 
figure    rules parsing context free grammar 
first set rules state grammar contains production x si
phrase type x generating i th entry input weight w x si    second
set rules state grammar contains production x z phrase
type j phrase type z j k an  appropriately
weighted  phrase type x k  let start symbol grammar 
goal parsing find lightest derivation phrase s     n       rules acyclic
phrases composed together form longer phrases 
    and or graphs
lightest derivation problems closely related and or graphs  let r set
statements rules defining lightest derivation problem  convert problem
and or graph representation build graph disjunction node
statement conjunction node rule r  edge statement rule deriving statement  edge rule antecedents 
leaves and or graph rules antecedents  derivations
statement using rules r represented solutions rooted statement
corresponding and or graph  conversely  possible represent and or
graph search problem lightest derivation problem  case view node
graph statement build appropriate set rules r 

   knuths lightest derivation
knuth        described generalization dijkstras shortest paths algorithm call
knuths lightest derivation  kld   knuths algorithm used solve large class
lightest derivation problems  algorithm allows rules cyclic requires
weight functions associated rule non decreasing superior  specifically
require following two properties weight function g rule 
non decreasing 
superior 

wi  wi g w            wi            wn   g w            wi           wn  
g w            wn   wi
   

fifelzenszwalb   mcallester

example 
g x            xn     x      xn
g x            xn     max x            xn  
non decreasing superior functions 
knuths algorithm computes lightest derivations non decreasing weight order  since
interested lightest derivation special goal statement often stop
algorithm computing lightest derivation every statement 
weight assignment expression form  b   w  b statement
w non negative real value  say weight assignment  b   w  derivable
derivation b weight w  set rules r  statement b  weight
w write r    b   w  rules r used derive  b   w   let   b  r 
infimum set weights derivable b 
  b  r    inf w   r    b   w   
given set rules r statement goal interested computing derivation
goal weight   goal   r  
define bottom up logic programming language easily express
algorithms wish discuss throughout rest paper  algorithm defined
set rules priorities  encode priority rule writing along
line separating antecedents conclusion follows 
a    w 
  
 
  wn
p w            wn  
c   g w            wn  
call rule form prioritized rule  execution set prioritized rules
p defined procedure figure    procedure keeps track set
priority queue q weight assignments form  b   w   initially empty q
contains weight assignments defined rules antecedents priorities given
rules  iteratively remove lowest priority assignment  b   w  q  b
already assigned weight new assignment ignored  otherwise add
new assignment expand every assignment derivable  b   w 
assignments already using rule p added q priority specified
rule  procedure stops queue empty 
result executing set prioritized rules set weight assignments  moreover 
procedure implicitly keep track derivations remembering assignments
used derive item inserted queue 
lemma    execution finite set prioritized rules p derives every statement
derivable rules p  
proof  rule causes one item inserted queue  thus eventually q
empty algorithm terminates  q empty every statement derivable
   

fithe generalized a  architecture

procedure run p  
  
   initialize q assignments defined rules antecedents priorities
   q empty
  
remove lowest priority element  b   w  q
  
b assigned weight
  
  b   w  
  
insert assignments derivable  b   w  assignments using
rule p q priority specified rule
   return
figure    running set prioritized rules 
single rule using antecedents weight already weight s  implies
every derivable statement weight s 
ready define knuths lightest derivation algorithm  algorithm
easily described terms prioritized rules 
definition    knuths lightest derivation   let r finite set non decreasing
superior rules  define set prioritized rules k r  setting priority rule
r weight conclusion  kld given execution k r  
show running k r    b   w  added w     b  r  
means assignments represent lightest derivations  show
assignments inserted non decreasing weight order  stop algorithm
soon insert weight assignment goal expand statements b
  b  r      goal   r  statements b   b  r      goal   r  
properties follow general result described next section 
    implementation
algorithm figure   implemented run o m log n   time  n
refer size problem defined prioritized rules p  
practice set prioritized rules p often specified implicitly  terms small
number rules variables  case problem executing p closely related
work logical algorithms described mcallester        
main difficulty devising efficient implementation procedure figure  
step    step need find weight assignments combined
 b   w  derive new weight assignments  logical algorithms work shows
set inference rules variables transformed new set rules 
every rule two antecedents particularly simple form  moreover 
transformation increase number rules much  rules
transformed execution implemented efficiently using hashtable represent
s  heap represent q indexing tables allow us perform step   quickly 
   

fifelzenszwalb   mcallester

consider second set rules parsing figure    represented
single rule variables  moreover rule two antecedents  executing
parsing rules keep track table mapping value j statements phrase y  i  j 
weight s  using table quickly find statements weight
combined statement form phrase z  j  k   similarly keep
track table mapping value j statements phrase z  j  k  weight
s  second table lets us quickly find statements combined statement
form phrase y  i  j   refer reader  mcallester        details 

   a  lightest derivation
a  lightest derivation algorithm  a ld  generalization a  search lightest
derivation problems subsumes a  parsing  algorithm similar kld
use heuristic function speed computation  consider lightest derivation problem
rules r goal statement goal   knuths algorithm expand statement b
  b  r      goal   r   using heuristic function a ld avoid expanding
statements light derivations part light derivation goal  
let r set rules statements   h heuristic function assigning
weight statement  h b  estimate additional weight required
derive goal using derivation b  note case shortest path problem
weight exactly distance node goal  value   b  r    h b  provides
figure merit statement b  a  lightest derivation algorithm expands
statements order figure merit 
say heuristic function monotone every rule a            g c r
derivable weight assignments  ai   wi   have 
wi   h ai   g w            wn     h c  

   

definition agrees standard notion monotone heuristic function rules
come shortest path problem  show h monotone h goal      
h admissible appropriate notion admissibility  correctness
a ld  however  required h monotone h goal   finite 
case monotonicity implies heuristic value every statement c appears
derivation goal finite  assume h c  finite every statement  h c 
finite ignore c every rule derives c 
definition    a  lightest derivation   let r finite set non decreasing rules h
monotone heuristic function r  define set prioritized rules a r  setting
priority rule r weight conclusion plus heuristic value 
g w            wn     h c   a ld given execution a r  
show execution a r  correctly computes lightest derivations
expands statements order figure merit values 
theorem    execution a r    b   w  w     b  r  
proof  proof induction size s  statement trivial    
suppose statement true right algorithm removed  b   wb   q
   

fithe generalized a  architecture

added s  fact  b   wb   q implies weight assignment derivable
thus wb   b  r  
suppose derivation b weight wb    wb   consider moment right
algorithm removed  b   wb   q added s  let a            g c
rule antecedents ai weight conclusion c not 
let wc   g   a    r             an   r    induction hypothesis weight ai
  ai   r   thus  c   wc   q priority wc   h c   let wc  weight assigns
c  since g non decreasing know wc wc    since h monotone wc   h c  wb   h b  
follows using monotonicity condition along path c b  
note wc   h c    wb   h b  turn implies  b   wb   weight
assignment q minimum priority 
theorem    execution a r  statements expanded order figure
merit value   b  r    h b  
proof  first show minimum priority q decrease throughout
execution algorithm  suppose  b   w  element q minimum priority 
removing  b   w  q decrease minimum priority  suppose add
 b   w  insert assignments derivable  b   w  q  since h monotone
priority every assignment derivable  b   w  least priority  b   w  
weight assignment  b   w  expanded removed q added s 
last theorem w     b  r  definition a r  weight assignment
queued priority   b  r    h b   since removed  b   w  q must
minimum priority queue  minimum priority decrease time
must expand statements order figure merit value 
accurate heuristic functions a ld much efficient kld 
consider situation perfect heuristic function  is  suppose h b 
exactly additional weight required derive goal using derivation b 
figure merit   b  r    h b  equals weight lightest derivation goal uses
b  case a ld derive goal expanding statements part
lightest derivation goal  
correctness kld follows correctness a ld  set non decreasing
superior rules consider trivial heuristic function h b       fact
rules superior imply heuristic monotone  theorems imply
knuths algorithm correctly computes lightest derivations expands statements
order lightest derivable weights 

   heuristics derived abstractions
consider case additive rules rules weight conclusion
sum weights antecedents plus non negative value v called weight
rule  denote rule a            v c  weight derivation using
additive rules sum weights rules appear derivation tree 
context statement b finite tree rules add derivation
b tree get derivation goal   intuitively context b derivation goal
hole filled derivation b  see figure    
   

fifelzenszwalb   mcallester

   
   
goal

a 
a 
a 
context c

c

context a 

derivation
a 

derivation
a 

derivation
a 

figure    derivation goal defines contexts statements appear derivation tree  note context c together rule a    a    a  c
derivations a  a  define context a   

additive rules  context weight sum weights rules it 
let r set additive rules statements   b define   context b   r 
weight lightest context b  value   b  r      context b   r 
weight lightest derivation goal uses b 
contexts derived using rules r together context rules c r  defined
follows  first  goal empty context weight zero  captured rule
antecedents   context goal    rule a            v c r put n rules
c r   rules capture notion context c derivations aj j   
define context ai  
context c   a            ai    ai             v context ai   
figure   illustrates context c together derivations a  a  rule
a    a    a  c define context a   
   

fithe generalized a  architecture

say heuristic function h admissible h b    context b   r   admissible
heuristic functions never over estimate weight deriving goal using derivation
particular statement  heuristic function perfect h b      context b   r  
show obtain admissible monotone heuristic functions abstractions 
    abstractions
let    r  lightest derivation problem statements rules r  abstraction
   r  given problem      r    map abs       every rule
a            v c r rule abs a             abs an   v  abs c  r  v   v 
show abstraction used define monotone admissible heuristic
function original problem 
usually think abs defining coarsening mapping several statements
abstract statement  example  parser abs might map lexicalized
nonterminal n phouse nonlexicalized nonterminal n p   case abstraction
defines smaller problem abstract statements  abstractions often defined
mechanical way starting map abs set abstract statements
    project rules r   using abs get set abstract
rules  typically several rules r map abstract rule  need
keep one copy abstract rule  weight lower bound weight
concrete rules mapping it 
every derivation    r  maps abstract derivation   abs c   r   
  c  r   let goal abstract problem abs goal   every context    r 
maps abstract context see   context abs c    r      context c   r  
means lightest abstract context weights form admissible heuristic function 
h c      context abs c    r    
show heuristic function monotone 
consider rule a            v c r let  ai   wi   weight assignments derivable
using r  case rule abs a             abs an   v  abs c  r  v   v
 abs ai     wi    derivable using r  wi  wi   definition contexts  in
abstract problem  have 
x
  context abs ai     r    v    
wj      context abs c    r    
j  i

since v   v wj  wj have 
  context abs ai     r    v  

x

wj     context abs c    r    

j  i

plugging heuristic function h adding wi sides 
x
wi   h ai   v  
wj   h c  
j

exactly monotonicity condition equation     additive rule 
   

fifelzenszwalb   mcallester

abstract problem defined      r    relatively small efficiently compute
lightest context weights every statement   using dynamic programming kld 
store weights pattern database  a lookup table  serve heuristic
function solving concrete problem using a ld  heuristic may able stop
a ld exploring lot non promising structures  exactly approach
used culberson schaeffer        korf        solving large search
problems  results section show pattern databases used
general setting lightest derivations problems  experiments section    demonstrate
technique specific application 

   hierarchical a  lightest derivation
main disadvantage using pattern databases precompute context
weights every abstract statement  often take lot time space 
define hierarchical algorithm  ha ld  searches lightest derivations contexts
entire abstraction hierarchy simultaneously  algorithm often solve
concrete problem without fully computing context weights level abstraction 
level abstraction behavior ha ld similar behavior a ld
using abstraction derived heuristic function  hierarchical algorithm queues
derivations statement c priority depends lightest abstract context
c  abstract contexts computed advance  instead  abstract contexts
computed time computing derivations  abstract context
c  derivations c stalled  captured addition context abs c  
antecedent rule derives c 
define abstraction hierarchy levels sequence lightest derivation problems additive rules  k   rk     k   single abstraction
function abs    k     abstraction function maps k onto k     require  k     rk     abstraction  k   rk   defined previous section 
a            v c rk exists rule abs a             abs an   v  abs c 
rk   v   v  hierarchical algorithm computes lightest derivations statements
k using contexts k   define heuristic values  extend abs maps
m  abstract set statements containing single element   since abs
onto  k    k      is  number statements decrease go
abstraction hierarchy  denote abs k abstraction function   k obtained
composing abs k times 
interested computing lightest derivation goal statement goal     let
goal k   abs k  goal   goal level abstraction  hierarchical algorithm
defined set prioritized rules h figure    rules labeled compute derivations
statements one level abstraction using context weights level define
priorities  rules labeled base compute contexts one level abstraction
using derivation weights level define priorities  rules labeled start 
start  start inference handling abstract level 
execution h starts computing derivation context start 
start   continues deriving statements m  using rules 
lightest derivation goal m  found algorithm derives context goal m 
   

fithe generalized a  architecture

 

start  
  

start  

 
context      

base 

goal k   w
w
context goal k      

up 

context abs c     wc
a    w 
  
 
  wn
v   w      wn   wc
c   v   w      wn

down 

context c    wc
a    w 
  
 
  wn
v   wc   w      wn
context ai     v   wc   w      wn wi

figure    prioritized rules h defining ha ld  base rules defined   k   
rules defined rule a            v c rk
  k   

base rule starts computing contexts statements m  using rules 
general ha ld interleaves computation derivations contexts level
abstraction since execution h uses single priority queue 
note computation happens given level abstraction lightest derivation goal found level above  means structure
abstraction hierarchy defined dynamically  example  cfdp algorithm 
could define set statements level abstraction refining statements
appear lightest derivation goal level above  assume static
abstraction hierarchy 
statement c k   k   use   c  denote weight
lightest derivation c using rk   context c   denotes weight lightest
context c using rk   abstract level define         context        
   

fifelzenszwalb   mcallester

show ha ld correctly computes lightest derivations lightest contexts
every level abstraction  moreover  order derivations contexts
expanded controlled heuristic function defined follows  c k   k
  define heuristic value c using contexts level heuristic value
context c  using derivations level 
h c      context abs c    
h context c       c  
abstract level define h     h context         let generalized statement
either element k   k expression form context c 
c k   define intrinsic priority follows 
p           h   
c k   p context c   weight lightest derivation goal k
uses c  p c  lower bound weight 
results sections     cannot used directly show correctness
ha ld  rules figure   generate heuristic values time
generate derivations depend heuristic values  intuitively must show
execution prioritized rules h  heuristic value available
appropriate point time  next lemma shows rules h satisfy monotonicity
property respect intrinsic priority generalized statements  theorem   proves
correctness hierarchical algorithm 
lemma    monotonicity   rule             hierarchical algorithm 
weight antecedent   i   weight conclusion
 a  priority rule   h   
 b    h   p i   
proof  rules start  start  result follows fact rules
antecedents h     h context        
consider rule labeled base w     goal k    see  a  note always zero
priority rule w   h context goal k      b  note p goal k    
  goal k   equals priority rule 
consider rule labeled wc     context abs c    wi     ai   i 
part  a  note priority rule   wc h c    wc   part  b  consider
first antecedent rule  h context abs c        abs c     c   
p context abs c      wc   h context abs c      wc   consider antecedent
ai   abs ai     p ai     wi   wc   abs ai      show
h ai       context abs ai     wc   wi   implies p ai     wi   h ai     wc  
finally consider rule labeled wc     context c   wj     aj  
j  part  a  note priority rule   wi h context ai      wi  
ppart
 b  consider first antecedent rule  h context c       c  v   j wj
see p context c     wc   h c    wi   consider antecedent aj  
abs aj     h aj       p aj     wj   wi   abs aj      show
h aj     wi wj   hence p aj     wj   h aj     wi  
   

fithe generalized a  architecture

theorem    execution h maintains following invariants 
       w  w       
       w  q priority w   h   
   p     p q          
p q  denotes smallest priority q 
proof  initial state algorithm empty q contains       
 context        priority    initial state invariant   true since empty 
invariant   follows definition h   h context     invariant   follows
fact p q      p       let q denote state
algorithm immediately prior iteration loop figure   suppose
invariants true  let   q  denote state algorithm iteration 
first prove invariant       let     w  element removed q
iteration  soundness rules w      w       clearly
invariant   holds     w       invariant   implies p q    w  h         h  
invariant   know contains           case     s 
invariant   q  follows invariant   q  invariant       part  a 
monotonicity lemma 
finally  consider invariant     q    proof reverse induction
abstraction level   say level k k form context c 
c k   reverse induction  base case considers level m  initially
algorithm inserts         context        queue priority    p q       
  must contain         context         hence invariant   holds   q 
level m 
assume invariant   holds   q  levels greater k
consider level k  first consider statements c k   since rules rk additive 
every statement c derivable rk lightest derivation  a derivation weight
  c    follows correctness knuths algorithm  moreover  additive
rules  subtrees lightest derivations lightest derivations  show structural
induction lightest derivation conclusion c p c    p q   
 c     c       consider lightest derivation rk conclusion c
p c    p q     final rule derivation a            v c corresponds rule
add antecedent context abs c    part  b  monotonicity lemma
antecedents rule intrinsic priority less p q     induction
hypothesis lightest derivations  ai     ai        since invariant   holds
statements levels greater k  context abs c       context abs c        
implies point rule used derive  c     c   priority p c  
p c    p q    hence item must removed queue  therefore
  must contain  c   w  w and  invariant    w     c  
consider form context c  c k   see c rk  
additive thus every statement derivable c rk   lightest derivation subtrees
lightest derivations lightest derivations themselves  prove structural induction
   

fifelzenszwalb   mcallester

lightest derivation conclusion context c  p context c    
p q     context c      context c        suppose last rule form 
context c   a            ai    ai             v context ai   
rule corresponds rule add antecedent ai   part  b 
monotonicity lemma antecedents rule intrinsic priority less
p q     invariant   statements k induction hypothesis lightest
derivations using c rk    antecedents rule lightest weight
    point  context ai       context ai     derived priority p ai   
p ai     p q    implies item removed queue and  invariant   
 context ai       context ai        
suppose last  and only  rule   context goal k    rule corresponds base rule add goal k antecedent  note p goal k    
  goal k     p context goal k    hence p goal k     p q     invariant   statements
k  goal k     goal k      point base rule used queue
 context goal k       context goal k     priority p context goal k     previous cases
p context goal k      p q    implies  context goal k       context goal k        
last theorem implies generalized statements expanded order
intrinsic priority  let k number statements c entire abstraction hierarchy
p c  p goal       goal    every statement c p c  p context c   
conclude ha ld expands  k generalized statements computing
lightest derivation goal  
    example
consider execution ha ld specific example  example illustrates
ha ld interleaves computation structures different levels abstraction 
consider following abstraction hierarchy   levels 
     x            xn   y            yn   z            zn   goal           x  y  z  goal     




  x 
xi  

















y 


 


 

xi   yj ij goal    
x    goal    
  r   
 
r   








z 
 


z
 
x 


x




 







 
z   goal    
zi goal    
abs xi     x  abs yi       abs zi     z abs goal      goal   
   initially   q            context        priority    
          comes queue gets put nothing else happens 
    context        comes queue gets put s  statements  
abstract context s  causes rules come rules r 
antecedents fire  putting  x       y      q priority   
   

fithe generalized a  architecture

    x       y      come queue get put s  causing two
rules fire  putting  goal        priority    z      priority   queue 
   have 
            context          x        y      
q     goal        priority     z      priority   
   point  goal        comes queue goes s  base rule fires
putting  context goal          queue priority   
    context goal          comes queue  base case contexts     two
rules use  context goal            x       y      put  context x      
 context y        q priority   
    context x       comes queue gets put s  abstract
context xi     rules put  xi   i  q priority     
    context y        comes queue goes s  previous step
rules put  yi   i  q priority     
    have 
            context          x        y        goal        
 context goal            context x         context y        
q     xi   i   yi   i  priority       n   z      priority   
    next  x        y       come queue go s  causes
rule put  goal        queue priority   
     goal        comes queue goes s  algorithm stop since
derivation concrete goal 
note ha ld terminates fully computing abstract derivations contexts 
particular  z      q z never expanded  moreover context z  even
queue  keep running algorithm would eventually derive context z  
would allow zi derived 

   perception pipeline
figure   shows hypothetical run hierarchical algorithm processing pipeline
vision system  system weighted statements edges used derive
weighted statements contours provide input later stages ultimately resulting
statements recognized objects 
well known subjective presence edges particular image location
depend context given image patch appears  interpreted
perception pipeline stating higher level processes later pipeline
influence low level interpretations  kind influence happens naturally lightest
   

fifelzenszwalb   mcallester

m 

edges

contours

recognition

 

edges

contours

recognition

 

edges

contours

recognition

figure    vision system several levels processing  forward arrows represent
normal flow information one stage processing next  backward
arrows represent computation contexts  downward arrows represent
influence contexts 

derivation problem  example  lightest derivation complete scene analysis might
require presence edge locally apparent  implementing whole
system single lightest derivation problem avoid need make hard decisions
stages pipeline 
influence late pipeline stages guiding earlier stages pronounced use
ha ld compute lightest derivations  case influence apparent
structure optimal solution flow information across different
stages processing  ha ld complete interpretation derived one level abstraction
guides processing stages concrete level  structures derived late stages
pipeline guide earlier stages abstract context weights  allows early
processing stages concentrate computational efforts constructing structures
likely part globally optimal solution 
emphasized use admissible heuristics  note a  architecture  including ha ld  used inadmissible heuristic functions  of course
would break optimality guarantees   inadmissible heuristics important
admissible heuristics tend force first stages processing pipeline generate
many derivations  derivations composed weights increase causes
large number derivations generated first stages processing
first derivation reaches end pipeline  inadmissible heuristics produce behavior
similar beam search derivations generated first stage pipeline flow
whole pipeline quickly  natural way construct inadmissible heuristics
simply scale up admissible heuristic ones obtained abstractions 
possible construct hierarchical algorithm inadmissible heuristics obtained
one level abstraction used guide search level below 

   hierarchical methods
section compare ha ld hierarchical search methods 
   

fithe generalized a  architecture

    coarse to fine dynamic programming
ha ld related coarse to fine dynamic programming  cfdp  method described
raphael         understand relationship consider problem finding shortest
path trellis graph one shown figure   a   k columns
n nodes every node one column connected constant number nodes
next column  standard dynamic programming used find shortest path
o kn  time  cfdp ha ld often find shortest path much faster 
hand worst case behavior algorithms different describe
below  cfdp taking significantly time ha ld 
cfdp algorithm works coarsening graph  grouping nodes column
small number supernodes illustrated figure   b   weight edge
two supernodes b minimum weight nodes b b 
algorithm starts using dynamic programming find shortest path p
coarse graph  shown bold figure   b   supernodes along p
partitioned define finer graph shown figure   c  procedure repeated 
eventually shortest path p go supernodes size one  corresponding
path original graph  point know p must shortest path
original graph  best case optimal path iteration
refinement optimal path previous iteration  would result o log n 
shortest paths computations  fairly coarse graphs  hand  worst
case cfdp take  n  iterations refine whole graph  many iterations
involve finding shortest paths large graphs  case cfdp takes  kn    time
much worst standard dynamic programming approach 
suppose use ha ld find shortest path graph
one figure   a   build abstraction hierarchy o log n  levels
supernode level contains  i nodes one column original graph  coarse
graph figure   b  represents highest level abstraction hierarchy  note
ha ld consider small number  o log n   predefined graphs cfdp end
considering much larger number   n   graphs  best case scenario ha ld
expand nodes shortest path level
hierarchy  worst case ha ld compute lightest path context every
node hierarchy  here context node v path v t   i th
abstraction level graph o kn  i   nodes edges  ha ld spend
o kn log kn   i   time computing paths contexts level i  summing levels
get o kn log kn   time total  much worst o kn  time
taken standard dynamic programming approach 
    hierarchical heuristic search
hierarchical method related ha  hida  algorithms described
holte et al         holte et al          methods restricted shortest paths
problems use hierarchy abstractions  heuristic function defined
level abstraction using shortest paths goal level above  main
idea run a  ida  compute shortest path computing heuristic values ondemand  let abs map node abstraction let g goal node concrete
   

fifelzenszwalb   mcallester





 a 







 b 



 c 

figure     a  original dynamic programming graph   b  coarse graph shortest path
shown bold   c  refinement coarse graph along shortest path 

graph  whenever heuristic value concrete node v needed call algorithm
recursively find shortest path abs v  abs g   recursive call uses heuristic
values defined abstraction  computed deeper recursive calls 
clear generalize ha  hida  lightest derivation problems
rules multiple antecedents  another disadvantage methods
potentially stall case directed graphs  example  suppose using
ha  hida  expand node two successors x y  x close goal
far  point need heuristic value x y  might
spend long time computing shortest path abs y  abs g   hand 
ha ld would wait shortest path fully computed  intuitively ha ld
would compute shortest paths abs x  abs y  abs g  simultaneously  soon
shortest path abs x  abs g  found start exploring path x
g  independent long would take compute path abs y  abs g  
   

fithe generalized a  architecture

r 
r 

r 

r 
r 
r 
r 

r 

figure     convex set specified hypothesis  r            r    

   convex object detection
consider application ha ld problem detecting convex objects
images  pose problem using formulation similar one described raphael
        optimal convex object around point found solving shortest
path problem  compare ha ld search methods  including cfdp a 
pattern databases  results indicate ha ld performs better
methods wide range inputs 
let x reference point inside convex object  represent object boundary
using polar coordinates respect coordinate system centered x  case
object described periodic function r   specifying distance x object
boundary function angle   specify r   finite number angles
             n     assume boundary straight line segment sample points 
assume object contained ball radius r around x r  
integer  thus object parametrized  r            rn     ri     r     example
n     angles shown figure    
every hypothesis  r            rn     specifies convex object  hypothesis describes
convex set exactly object boundary turns left sample point  i   ri  
increases  let c ri    ri   ri     boolean function indicating three sequential
values r   define boundary locally convex i  hypothesis  r            rn    
convex locally convex i  
throughout section assume reference point x fixed advance 
goal find optimal convex object around given reference point  practice
reference locations found using variety methods hough transform 
   parametrization convex objects similar identical one used raphael        

   

fifelzenszwalb   mcallester

let d i  ri   ri     image data cost measuring evidence boundary segment
 i   ri    i     ri      consider problem finding convex object
sum data costs along whole boundary minimal  is  look
convex hypothesis minimizing following energy function 
e r            rn      

n
 
x

d i  ri   ri     

i  

data costs precomputed specified lookup table o n r    entries 
experiments use data cost based integral image gradient along
boundary segment  another approach would use data term described
raphael        cost depends contrast inside outside
object measured within pie slice defined i    
optimal convex object found using standard dynamic programming techniques  let b i  r    r    ri    ri   cost optimal partial convex object starting
r  r  ending ri  ri   keep track last two boundary points
enforce convexity constraint extend partial objects  keep track
first two boundary points enforce rn   r  convexity constraint r   
compute b using recursive formula 
b    r    r    r    r      d    r    r    
b i      r    r    ri   ri       min b i  r    r    ri    ri     d i  ri   ri     
ri 

minimization choices ri  c ri    ri   ri       true 
cost optimal object given minimum value b n  r    r    rn     r   
c rn     r    r      true  optimal object found tracing back typical dynamic programming algorithms  main problem approach dynamic
programming table o n r    entries takes o r  time compute entry 
overall algorithm runs o n r    time quite slow 
show optimal convex objects defined terms lightest derivation
problem  let convex  i  r    r    ri    ri   denote partial convex object starting r  r 
ending ri  ri   corresponds entry dynamic programming table
described above  define set statements 
   convex  i  a  b  c  d        n    a  b  c      r      goal   
optimal convex object corresponds lightest derivations goal using rules
figure     first set rules specify cost partial object r  r   
second set rules specify object ending ri  ri extended
choice ri   boundary locally convex ri   last set rules specify
complete convex object partial object r  rn rn   r 
boundary locally convex r   
construct abstraction hierarchy define l nested partitions radius space
    r    ranges integers  abstract statement instead specifying integer
value r   specify range r   contained  simplify notation
   

fithe generalized a  architecture

    r    r      r    

convex     r    r    r    r      d    r    r   
    r    r    ri    ri   ri       r    c ri    ri   ri       true 
convex  i  r    r    ri    ri     w
convex  i      r    r    ri   ri       w   d i  ri   ri    
    r    r    rn       r    c rn     r    r      true 
convex  n  r    r    rn     r      w
goal   w
figure     rules finding optimal convex object 
assume r power two  k th partition p k contains r  k ranges 
 k consecutive integers  j th range p k given  j  k    j       k    
statements abstraction hierarchy are 
k    convex  i  a  b  c  d        n    a  b  c  p k    goal k   
k     l     range p   contains single integer       let f map range
p k range p k   containing it  statements level k   l   define
abstraction function 
abs convex  i  a  b  c  d     convex  i  f  a   f  b   f  c   f  d   
abs goal k     goal k    
abstract rules use bounds data costs boundary segments  i   si  
 i     si     si si   ranges p k  
dk  i  si   si      

min
d i  ri   ri     
ri si
ri   si  

since range p k union two ranges p k  one entry dk computed
quickly  in constant time  dk  computed  bounds levels computed o n r    time total  need abstract versions convexity constraints 
si    si   si   p k   let c k  si    si   si       true exist integers ri    ri ri  
si    si si   respectively c ri    ri   ri       true  value c k
defined closed form evaluated quickly using simple geometry 
rules abstraction hierarchy almost identical rules figure    
rules level k obtained original rules simply replacing instance
    r    p k   c c k dk  
   

fifelzenszwalb   mcallester

standard dp
cfdp
ha ld
a  pattern database  
a  pattern database  

       seconds
     seconds
    seconds
     seconds
     seconds

table    running time comparison example figure    
    experimental results
figure    shows example image set reference locations selected manually
optimal convex object found around reference point     reference
locations used n      r      parametrize object  table   compares
running time different optimization algorithms implemented problem 
line shows time took solve    problems contained example image using
particular search algorithm  standard dp algorithm uses dynamic programming
solution outlined above  cfdp method based algorithm raphael       
modified representation convex objects  hierarchical a  algorithm uses
abstraction hierarchy described here  a  pattern databases used dynamic
programming compute pattern database particular level abstraction 
used database provide heuristic values a   note problem described
pattern database depends input  running times listed include time
took compute pattern database case 
see cfdp  ha ld a  pattern databases much efficient
standard dynamic programming algorithm use abstractions  ha ld
slightly faster methods example  note running time
varies algorithm algorithm output every method find
globally optimum objects 
quantitative evaluation different search algorithms created large set
problems varying difficulty size follows  given value r generated square
images width height   r      image circle radius less r near
center pixels image corrupted independent gaussian noise 
difficulty problem controlled standard deviation    noise  figure   
shows example images optimal convex object found around centers 
graph figure    shows running time  in seconds  different search
algorithms function noise level problem size fixed r       
sample point indicates average running time     random inputs  graph
shows running times point circles reliably detected 
compared ha ld cfdp a  using pattern databases  pd  pd    pd 
pd  refer a  pattern database defined     respectively  since
pattern database needs recomputed input trade off amount
time spent computing database accuracy heuristic provides 
see easy problems better use smaller database  defined higher level
abstraction  harder problems worth spending time computing bigger
database  ha ld outperforms methods every situation captured here 
   

fithe generalized a  architecture

 a 

 b 
figure      a  reference locations   b  optimal convex objects 

   

fifelzenszwalb   mcallester

figure     random images circles optimal convex object around center
one  with n      r         noise level images      

figure    shows running time different methods function problem
size r  problems fixed noise level        sample point
indicates average running time taken     random inputs  see running
time pattern database approach grows quickly problem size increases 
computing database fixed level abstraction takes o n r    time 
hand running time cfdp ha ld grows much slower 
cfdp performed essentially well ha ld experiment  graph figure   
shows ha ld performs better difficulty problem increases 

    finding salient curves images
classical problem computer vision involves finding salient curves images  intuitively
goal find long smooth curves go along paths high image gradient 
standard way pose problem define saliency score search curves
optimizing score  methods use score defined simple combination local
terms  example  score usually depends curvature image gradient
point curve  type score often optimized efficiently using dynamic
programming shortest paths algorithms  montanari        shashua   ullman       
basri   alter        williams   jacobs        
consider new compositional model finding salient curves  important
aspect model capture global shape constraints  particular  looks
curves almost straight  something done using local constraints
alone  local constraints enforce small curvature point curve 
   

fithe generalized a  architecture

figure     running time different search algorithms function noise level
input  sample point indicates average running time taken    
random inputs  case n      r        see text discussion 

enough prevent curves turning twisting around long distances 
problem finding salient curve image compositional model defined
solved using dynamic programming  approach slow practical
use  shortest paths algorithms applicable compositional nature
model  instead use a ld heuristic function derived abstraction
 a pattern database  
let c  curve endpoints b c  curve endpoints b c 
two curves composed form curve c c  define weight
composition sum weights c  c  plus shape cost depends
geometric arrangement points  a  b  c   figure    illustrates idea shape
costs use  note c  c  long  arrangement endpoints reflect
non local geometric properties  general consider composing c  c  angle
formed ab bc least    lengths c  c  approximately equal 
constraints reduce total number compositions play important role
abstract problem defined below 
besides compositional rule say b nearby locations 
short curve endpoints b  forms base case creating longer curves 
   

fifelzenszwalb   mcallester

figure     running time different search algorithms function problem size r 
sample point indicates average running time taken     random
inputs  case n             see text discussion 

b




c

figure     curve endpoints  a  c  formed composing curves endpoints
 a  b   b  c   assume     cost composition
proportional sin   t   cost scale invariant encourages curves
relatively straight 

assume short curves straight  weight depends image
data along line segment b  use data term  seg a  b   zero
image gradient along pixels ab perpendicular ab  higher otherwise 
figure    gives formal definition two rules model  constants k 
k  specify minimum maximum length base case curves  l constant
   

fithe generalized a  architecture

    pixels a  b  c angle ab bc least      l 
curve a  b  i    w 
curve b  c  i    w 
curve a  c         w    w    shape a  b  c 
    pixels a  b k    a b   k   

curve a  b       seg a  b 
figure     rules finding almost straight curves pair endpoints  l 
k  k  constants  shape a  b  c  function measuring cost
composition 

controlling maximum depth derivations  derivation curve a  b  i  encodes curve
b  value seen approximate measure arclength  derivation
curve a  b  i  full binary tree depth encodes curve length
 i k   i k    let k     k  allow curves length 
rules figure    define good measure saliency
always prefer short curves long ones  define saliency curve
terms weight minus arclength  salient curves light long  let
positive constant  consider finding lightest derivation goal using 
curve a  b  i    w
goal   w  i
n n image  n    statements form curve a  c  i   moreover 
c far apart  n  choices midpoint b defining two curves
composed lightest derivation curve a  c  i   makes dynamic programming
solution lightest derivation problem impractical  tried using kld even
small images algorithm runs memory minutes  describe
abstraction used define heuristic function a ld 
consider hierarchical set partitions image boxes  i th partition
defined tiling image boxes  i  i pixels  partitions form pyramid
boxes different sizes level  box level union   boxes level
it  boxes level   pixels themselves  let  a  box containing
i th level pyramid  define
abs curve a  b  i     curve fi  a    b   i  
   

fifelzenszwalb   mcallester


b


b

c


c

figure     abstraction maps curve statement statement curves
boxes    j curve a  b  i  gets coarsened curve c  d  j   since
light curves almost straight    j usually implies   a b       c d   

figure    illustrates map selects pyramid level abstract statement  intuitively abs defines adaptive coarsening criteria  b far other 
curve b must long  turn implies map b boxes
coarse partition image  creates abstract problem small number
statements without losing much information 
define abstract problem need define set abstract rules  recall
every concrete rule r need corresponding abstract rule r  weight
r  weight r  small number rules antecedents
figure     concrete rule seg a b  curve a  b     define corresponding abstract
rule  seg a b  abs curve a  b       compositional rules figure    lead abstract
rules composing curves boxes 
curve a  b  i   curve b  c  i  v curve a    c          
a  b c boxes i th pyramid level a  c   boxes
level     containing c respectively  weight v shape a  b  c 
a  b c arbitrary pixels a  b c respectively  compute value
v bounding orientations line segments ab bc boxes 
   

fithe generalized a  architecture

        pixels  running time     seconds           

        pixels  running time     seconds           

        pixels  running time     seconds           
figure     salient curve different images  running time sum
time spent computing pattern database time spent solving
concrete problem 

   

fifelzenszwalb   mcallester

figure     example salient curve goes locations essentially
local evidence curve locations 

abstract problem defined relatively small even large images 
use pattern database approach outlined section      input image use
kld compute lightest context weights every abstract statement  use
weights heuristic values solving concrete problem a ld  figure    illustrates
results obtained using method  seems abstract problem
able capture short curves extended salient curve  took
one minute find salient curve images  figure    lists
dimensions image running time case 
note algorithm rely initial binary edge detection stage  instead
base case rules allow salient curves go pixel  even local
evidence boundary particular location  figure    shows example
happens  case small part horse back blends background
consider local properties alone 
curve finding algorithm described section would difficult formulate
without a ld general notion heuristics derived abstractions lightest
derivation problems  however  using framework introduced paper becomes
relatively easy specify algorithm 
future plan compose rules computing salient curves rules
computing complex structures  basic idea using pyramid boxes defining
abstract problem applicable variety problems computer vision 
   

fithe generalized a  architecture

    conclusion
although presented preliminary results last two sections  view
main contribution paper providing general architecture perceptual inference 
dijkstras shortest paths algorithm a  search fundamental algorithms
many applications  knuth noted generalization dijkstras algorithm general
problems defined set recursive rules  paper given similar generalizations a  search heuristics derived abstractions  described
new method solving lightest derivation problems using hierarchy abstractions 
finally  outlined approach using generalizations construction
processing pipelines perceptual inference 

acknowledgments
material based upon work supported national science foundation
grant no                  

references
basri  r     alter  t          extracting salient curves images  analysis
saliency network  ieee conference computer vision pattern recognition 
bonet  b     geffner  h          algorithm better ao   proceedings
national conference artificial intelligence 
bulitko  v   sturtevant  n   lu  j     yau  t          state abstraction real time heuristic
search  technical report  university alberta  department computer science 
charniak  e          statistical language learning  mit press 
culberson  j     schaeffer  j          pattern databases  computational intelligence         
       
dijkstra  e          note two problems connection graphs  numerical mathematics            
edelkamp  s          symbolic pattern databases heuristic search panning  international conference ai planning scheduling 
felner  a          finding optimal solutions graph partitioning problem heuristic
search  annals mathematics artificial intelligence                   
geman  s   potter  d     chi  z          composition systems  quarterly applied
mathematics         
hansen  e     zilberstein  s          lao   heuristic search algorithm finds solutions
loops  artificial intelligence            
hart  p   nilsson  n     raphael  b          formal basis heuristic determination
minimal cost paths  ieee transactions systems science cybernetics        
       
holte  r   grajkowski  j     tanner  b          hierarchical heuristic search revisited 
symposium abstraction  reformulation approximation 
   

fifelzenszwalb   mcallester

holte  r   perez  m   zimmer  r     macdonald  a          hierarchical a   searching abstraction hierarchies efficiently  proceedings national conference artificial
intelligence 
jimenez  p     torras  c          efficient algorithm searching implicit and or
graphs cycles  artificial intelligence           
jin  y     geman  s          context hierarchy probabilistic image model 
ieee conference computer vision pattern recognition 
klein  d     manning  c          a  parsing  fast exact viterbi parse selection  proceedings hlt naacl 
knuth  d          generalization dijkstras algorithm  information processing letters 
          
korf  r          finding optimal solutions rubiks cube using pattern databases 
proceedings national conference artificial intelligence 
korf  r     felner  a          disjoint pattern database heuristics  artificial intelligence 
         
korf  r   zhang  w   thayer  i     hohwald  h          frontier search  journal
acm                 
mcallester  d          complexity analysis static analyses  journal acm 
               
montanari  u          optimal detection curves noisy pictures  communications
acm         
nilsson  n          principles artificial intelligence  morgan kaufmann 
pearl  j          heuristics  intelligent search strategies computer problem solving 
addison wesley 
rabiner  l          tutorial hidden markov models selected applications speech
recognition  proceedings ieee                 
raphael  c          coarse to fine dynamic programming  ieee transactions pattern
analysis machine intelligence                    
shashua  a     ullman  s          structural saliency  detection globally salient
structures using locally connected network  ieee international conference
computer vision 
tu  z   chen  x   yuille  a     zhu  s          image parsing  unifying segmentation 
detection  recognition  international journal computer vision             
    
williams  l     jacobs  d          local parallel computation stochastic completion
fields  ieee conference computer vision pattern recognition 
zhang  w     korf  r          study complexity transitions asymmetric traveling
salesman problem  artificial intelligence         

   


