journal of artificial intelligence research               

submitted        published      

solution guided multi point constructive search for job
shop scheduling
j  christopher beck

jcb mie utoronto ca

department of mechanical   industrial engineering
university of toronto  canada

abstract
solution guided multi point constructive search  sgmpcs  is a novel constructive
search technique that performs a series of resource limited tree searches where each search
begins either from an empty solution  as in randomized restart  or from a solution that has
been encountered during the search  a small number of these elite solutions is maintained
during the search  we introduce the technique and perform three sets of experiments on
the job shop scheduling problem  first  a systematic  fully crossed study of sgmpcs is
carried out to evaluate the performance impact of various parameter settings  second  we
inquire into the diversity of the elite solution set  showing  contrary to expectations  that
a less diverse set leads to stronger performance  finally  we compare the best parameter
setting of sgmpcs from the first two experiments to chronological backtracking  limited
discrepancy search  randomized restart  and a sophisticated tabu search algorithm on a set
of well known benchmark problems  results demonstrate that sgmpcs is significantly
better than the other constructive techniques tested  though lags behind the tabu search 

   introduction
a number of metaheuristic and evolutionary approaches to optimization can be described
as being solution guided  multi point searches  for example  in genetic and mimetic algorithms  a population of solutions is maintained and used as a basis for search  each new
generation is created by combining aspects of the current generation  search is therefore
guided by existing solutions  as the population contains a number of individual solutions 
the search makes use of multiple points in the search space  traditional single point metaheuristics  such as tabu search  have been augmented in a similar way  the tsab tabu
search  nowicki   smutnicki        maintains an elite pool consisting of a small number
of the best solutions found so far during the search  whenever the basic search reaches a
threshold number of moves without finding a new best solution  search is restarted from one
of the elite solutions  again  the higher level search is guided by multiple existing solutions 
though the guidance is somewhat different than in genetic algorithms 
solution guided multi point constructive search  sgmpcs    is a framework designed
to allow constructive search to be guided by multiple existing  suboptimal  solutions to
a problem instance  as with randomized restart techniques  gomes  selman    kautz 
       the framework consists of a series of tree searches restricted by some resource limit 
   in previous conference and workshop publications  sgmpcs is referred to simply as multi point constructive search  beck        heckman   beck        beck      a      b   empirical evidence of
the importance of solution guidance motivated this change to a name more reflective of the important
differences between this work and existing tree search techniques 
c
    
ai access foundation  all rights reserved 

fibeck

typically a maximum number of fails  when the resource limit is reached  search restarts 
the difference with randomized restart is that sgmpcs keeps track of a small set of elite
solutions  the best solutions it has found  when search is restarted  it starts from an
empty solution  as in randomized restart  or from one of the elite solutions 
in this paper  we undertake the first fully crossed systematic empirical study of sgmpcs  in particular  in section   we investigate the different parameter settings and their impact on search performance for the makespan minimization variant of the job shop scheduling problem  results indicate that guidance with elite solutions contributes significantly
to algorithm performance but  somewhat unexpectedly  that smaller elite set size results
in better performance  indeed  an elite set size of one showed the best performance  this
result motivates subsequent experimentation on the diversity of the elite set in section   
we show  again contrary to expectation but consistent with an elite set size of one  that the
less diverse the elite set  the stronger the performance  as discussed in depth in section
   these two sets of experiments call into question the extent to which the exploitation
of multiple points in the search space is important for the performance of sgmpcs  a
final experiment  section    compares the best parameter settings found in the first two
experiments with chronological backtracking  limited discrepancy search  harvey        
randomized restart  and a state of the art tabu search  watson  howe    whitley       
on a set of well known benchmarks  these results show that sgmpcs significantly outperforms the other constructive search methods but does not perform as well as the tabu
search 
the contributions of this paper are as follows 
   the introduction and systematic experimental evaluation of solution guided multipoint constructive search  sgmpcs  
   the investigation of the importance of the diversity of the elite set to the performance
of sgmpcs 
   the demonstration that sgmpcs significantly out performs chronological backtracking  limited discrepancy search  and randomized restart on a benchmark set of job
shop scheduling problems 

   solution guided multi point constructive search
pseudocode for the basic solution guided multi point constructive search algorithm is
shown in algorithm    the algorithm initializes a set  e  of elite solutions and then enters
a while loop  in each iteration  with probability p  search is started from an empty solution
 line    or from a randomly selected elite solution  line      in the former case  if the
best solution found during the search  s  is better than the worst elite solution  s replaces
the worst elite solution  in the latter case  s replaces the starting elite solution  r  if s is
better than r  each individual search is limited by a maximum number of fails that can
be incurred  when an optimal solution is found and proved or when some overall bound
on the computational resources  e g   cpu time  number of fails  is reached  the best elite
solution is returned 
the elite solutions can be initialized by any search technique  in this paper  we use   
independent runs of the same randomized texture based heuristic that is employed in the
  

fisolution guided multi point constructive search

sgmpcs   
 
 
 
 
 
 
 
 

 
  
  
  
  
  

  

initialize elite solution set e
while termination criteria unmet do
if rand         p then
set upper bound on cost function
set fail limit  l
s    search   l 
if s     and s is better than worst e  then
replace worst e  with s
end
else
r    randomly chosen element of e
set upper bound on cost function
set fail limit  l
s    search r  l 
if s     and s is better than r then
replace r with s
end
end
end
return best e 
algorithm    sgmpcs  solution guided multi point constructive search

main search  see section       no backtracking is done and no upper bound is placed on the
cost function  without an upper bound  each run will find a solution  though probably one
of quite low quality  from this initial set of    solutions  the  e  best solutions are inserted
into the elite set  the primary goal for the initialization is to quickly populate the elite set 
previous work  beck        has shown that while spending more effort in each run to find
good starting solutions  e g   via backtracking search  does not significantly improve overall
performance  the number of runs does have an impact  when the variance in quality among
the initial solutions is high  the best starting solution of a large elite set will be much better
than that of a small elite set  this difference alone was sufficient to skew experiments that
measured the impact of different elite set sizes on overall performance  to mitigate this
effect we generate a fixed number of elite solution candidates  i e       and then choose the
 e  best  an interesting direction for future work is to adaptively determine the best time
to transition from the elite pool generation to the main search 
    search
in lines   and    the search r  l  function is a standard tree search with some randomization 
limited by the number of fails  l  and  when r      guided by solution r  the search function
returns the best solution found  if any  and an indication as to whether the search space has
been exhausted  given a large enough fail limit  an individual search can completely search
the space  therefore  the completeness of this approach depends on the policy for setting
and increasing the fail limit  as we will see in experiment    section     sgmpcs is able
  

fibeck

to find optimal solutions and prove their optimality  we place no other restrictions on the
search  allowing any tree traversal technique to be used  in particular  we experiment with
both chronological backtracking and limited discrepancy search  harvey        
when r      the search is guided by the reference solution  r  the guiding solution
is simply used as the value ordering heuristic  we search using any  randomized  variable
ordering heuristic and by specifying that the value assigned to a variable is the one in the
reference solution  provided it is still in the domain of the variable 
a search tree is created by asserting a series of choice points of the form  hv i   xihvi   
xi  where vi is a variable and x is the value assigned to v i   given the importance of variable
ordering heuristics in constructive search  we expect that the order of these choice points will
have an impact on search performance  sgmpcs can  therefore  use any variable ordering
heuristic to choose the next variable to assign  the choice point is formed using the value
assigned in the reference solution or  if the value in the reference solution is inconsistent 
a heuristically chosen value  more formally  let a reference solution  r  be a set of variable
assignments   hv    x  i  hv    x  i          hvm   xm i   m  n  where n is the number of
variables  the variable ordering heuristic has complete freedom to choose a variable  v i   to
be assigned  if xi  dom vi    where hvi   xi i  r  the choice point is made with x   x i  
otherwise  if xi 
  dom vi    any value ordering heuristic can be used to choose x  dom v i   
we need to account for the possibility that x i 
  dom vi   because the reference solution
is not necessarily a valid solution later in the sgmpcs search process  to take a simple
example  if the reference solution has a cost of     and we constrain the search to find a
better solution  we will not reach the reference solution  rather  via constraint propagation 
we will reach a dead end or different solution 
this technique for starting constructive search from a reference solution is quite general 
existing high performance variable ordering heuristics can be exploited and  by addressing
the case of xi 
  dom vi    we make no assumptions about changes to the constraint model
that may have been made after the reference solution was originally found  in particular 
this means that an elite solution could be the solution to a relaxation of the full problem 
    setting the bounds on the cost function
before each individual search  lines   and      we place an upper bound on the cost function 
the bound has an impact on the set of solutions and  therefore  on the solutions that may
enter the elite set  intuitions from constructive search and metaheuristics differ on the
appropriate choice of an upper bound  in standard tree search for optimization with a
discrete cost function  the usual approach is to use c     as the upper bound  where c is
the best solution found so far  using a higher bound would only expand the search space
without providing any heuristic benefit  in contrast  in a standard metaheuristic approach 
search is not usually restricted by enforcing an upper bound on the cost of acceptable states 
the search is allowed to travel through worse states in order to  hopefully  find better ones 
as a consequence  it is common to replace an elite solution when a better  but not necessarily
best known  solution is found  since the elite solutions are used to heuristically guide search 
even solutions which are not the best known can provide heuristic guidance 
these two perspectives result in two policies 
   global bound  always set the upper bound on the search cost to c     
  

fisolution guided multi point constructive search

   local bound  when starting from an empty solution  set the upper bound to be
equal to one less than the cost of the worst elite solution  when starting from an elite
solution  set the upper bound to be one less than the cost of the starting solution 

in constraint programming  back propagation is the extent to which placing a bound on
the cost function results in domain reductions for decision variables  previous experiments
with sgmpcs on optimization problems with strong back propagation  such as job shop
scheduling with the objective of minimizing makespan  show that the global bound policy
is superior  beck         for problems with weaker back propagation and for satisfaction
problems  where there is no back propagation   the local bound approach performs better
 beck        heckman   beck         based on these results  we use the global bound
policy here 
    related work
sgmpcs is most directly inspired by the tsab tabu search algorithm  nowicki   smutnicki        noted above  in tsab  an elite pool consisting of a small number of the best
solutions found is maintained during the search  whenever the basic tabu search stagnates 
that is  when it reaches a threshold number of moves without finding a new best solution 
search is restarted from one of the elite solutions  the tabu list is modified so that when
search is restarted  it will follow a different search path  this is the basic mechanism 
adapted for constructive search  that is used in sgmpcs  for a number of years  tsab
was the state of the art algorithm for job shop scheduling problems  it has recently been
over taken by i tsab  an algorithm based on tsab that makes a more sophisticated use
of the elite pool  nowicki   smutnicki         for an in depth analysis of i tsab see the
work of watson  howe  and whitley        
sgmpcs performs a series of resource limited tree searches  it is clear that such behaviour is related to the extensive work on randomized restart  gomes et al         horvitz 
ruan  gomes  kautz  selman    chickering        kautz  horvitz  ruan  gomes    selman        gomes  fernandez  selman    bessiere        hulubei   osullivan        
indeed  setting p  the probability of searching from an empty solution  to   results in a
randomized restart technique  it has been observed that search effort for chronological
backtracking and a given variable ordering forms a heavy tailed distribution  intuitively 
this means that a randomly chosen variable ordering has a non trivial chance of resulting
in either a small or a large cost to find a solution to a problem instance  if no solution is
found after some threshold amount of effort  it is beneficial to restart search with a different
variable ordering as the new ordering has a non trivial probability of quickly leading to a
solution 
there are a number of other techniques that make use of randomized or heuristic backtracking  prestwich        jussien   lhomme        dilkina  duan    havens        to
form a hybrid of local search and tree search and allow an exploration of the search space
that is not as constrained as standard tree search  these approaches differ from sgmpcs
at the fundamental level  they do not use  multiple  existing solutions to guide search 
  

fibeck

   experiment    parameter settings
the primary purpose of this experiment is to understand the impact of the different parameter settings on the performance of sgmpcs algorithms  we present a fully crossed
experiment to evaluate the impact of varying the parameters of sgmpcs 
    sgmpcs parameters
elite set size the number of elite solutions that are maintained during the search is
a key parameter controlling the extent to which multiple points in the search space are
exploited by sgmpcs  while there does not seem to have been significant experimentation
with the elite set size in the metaheuristic community  anecdotally  a hybrid tabu search
with an elite set smaller than six performs much worse than larger elite sets on job shop
scheduling problems   in this paper  we experiment with elite set sizes of                       
the proportion of searches from an empty solution the p parameter controls
the probability of searching from an empty solution versus searching from one of the elite
solutions  a high p value will result in algorithm behaviour similar to randomized restart
and indeed  p     is a randomized restart algorithm  one reason that the p parameter was
included in sgmpcs was the intuition that it also has an impact on the diversity of the
elite pool  the higher the p value the more diverse the elite pool will be because solutions
unrelated to the current elite solutions are more likely to enter the pool  as we will see
in experiment    this intuition is contradicted by our empirical results  here  we study
p                           
the fail limit sequence the resource limit sets the number of fails allowed for each
tree search  rather than have a constant limit and be faced with the problem of tuning the
limit  gomes et al          following the work of kautz  horvitz  ruan  gomes  and selman
        we adopt a dynamic restart policy where the limit on the number of fails changes
during the problem solving  we look at two simple fail limit sequences  seq  
 luby   the fail limit sequence is the optimal sequence for satisfaction problems under the condition of no knowledge about the solution distribution  luby  sinclair   
zuckerman         the sequence is as follows                                              
     that is  the fail limit for the first and second searches is   fail  for the third search
is   fails  and so on  the sequence is independent of the outcome of the searches and
of whether the search is from an empty solution or guided by an elite solution 
 polynomial  poly    the fail limit is initialized to    and reset to    whenever a new
best solution is found  whenever a search fails to find a new best solution  the bound
grows polynomially by adding    to the fail limit  the value    was chosen to give a
reasonable increase in the fail limit on each iteration  no tuning was done to determine
the value of     as with the luby limit  the poly fail limit is independent of the choice
to search from an empty solution or from an elite solution 
   jean paul watson  personal communication 

  

fisolution guided multi point constructive search

backtrack method finally  as noted above  the style of an individual tree search is not
limited to chronological backtracking  whether search begins from an empty solution or an
elite solution  we have a choice as to how the search should be performed  in particular  our
backtracking  bt  factor is either standard chronological backtracking or limited discrepancy
search  lds   harvey         in either case  the search is limited by the fail limit as
described above 
    experimental details
our experimental problems are job shop scheduling problem  jsp  instances  an n  m job
shop scheduling problem consists of a set of n jobs  each consisting of a complete ordering
of m activities  each activity has a duration and a specified resource on which it must
execute  the ordering of activities in a job represents a chain of precedence constraints  an
activity cannot start until the preceding activity in the job has completed  once an activity
begins execution  it must execute for its complete duration  i e   no pre emption is allowed  
there are m unary capacity resources  meaning that each resource can be used by only one
activity at a time  an optimal solution to a jsp is a sequence of the activities on each
resource such that the union of the job sequences and resource sequences is acyclic  and the
makespan  the time between the start of the earliest job and the end of the latest job  is
minimized  the jsp is np hard  garey   johnson        and has received extensive study
in both the operations research and the artificial intelligence literature  jain   meeran 
      
the experimental instances are twenty        problem instances generated using an
existing generator  watson  barbulescu  whitley    howe         the durations of the
activities are independently drawn with uniform probability from          the machine
routings are generated to create work flow problems where each job visits the first    machines before any of the second    machines  within the two machine sets  the routings are
generated randomly with uniform probability  work flow jsps are used as they have been
shown to be more difficult than jsps with random machine routings  watson        
each algorithm run has a    cpu minute time out  and each problem instance is solved
   times independently for a given parameter configuration  all algorithms are implemented
in ilog scheduler     and run on a  ghz dual core amd opteron     with  gb ram
running red hat enterprise linux   
for this experiment  the dependent variable is mean relative error  mre  relative to
the best solution known for the problem instance  the mre is the arithmetic mean of the
relative error over each run of each problem instance 
mre  a  k  r   

  x x c a  k  r   c  k 
 r  k 
c  k 

   

rr kk

where k is a set of problem instances  r is a set of independent runs with different random
seeds  c a  k  r  is the lowest cost found by algorithm a on instance k in run r  and c   k  is
the lowest cost known for k  as these problem instances were generated for this experiment 
the best known solution was found either by the algorithms tested here or by variations used
in preliminary experiments  
   problem instances and best known solutions are available from the author 

  

fibeck

the variable ordering heuristic chooses a pair of activities on the same resource to
sequence  texture based heuristics  beck   fox        are used to identify a resource and
time point with maximum contention among the activities and to then choose a pair of
unordered activities  branching on the two possible orders  the heuristic is randomized by
specifying that the hresource  time pointi pair is chosen with uniform probability from the
top     most critical pairs  when starting search from an elite solution  the same heuristic
is used to choose a pair of activities to be sequenced  and the ordering found in this solution
is asserted  the standard constraint propagation techniques for scheduling  nuijten       
laborie        le pape        are used for all algorithms 
    results
a fully crossed experimental design was implemented  consisting of four factors   e   p  seq 
bt  with a total of     cells               each cell is the result of    runs of each of
   problem instances  with a time limit on each run of    minutes  these results were
generated in about     cpu days 
analysis of variance  anova  on the mre at      seconds shows that all factors and
all interactions are significant at p         the anova is shown in table   
factor s 
e
p
bt
seq
e p
e bt
p bt
e seq
p seq
bt seq
e p bt
e p seq
e bt seq
p bt seq
e p bt seq
residuals

df
 
 
 
 
  
 
 
 
 
 
  
  
 
 
  
     

sum sq
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      

mean sq
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

f value
         
          
         
         
        
        
        
        
        
       
       
       
      
       
      

pr  f 
     e   
     e   
     e   
     e   
     e   
     e   
     e   
     e   
     e   
     e   
     e   
     e   
         
     e   
     e   

table    summary of the analysis of variance found using the r statistical package  r
development core team         all factors and all interactions are significant at
p        

to attain a more detailed view of the results  a tukey hsd test  r development core
team        was performed for each of the factors  the tukey hsd allows for the comparison of multiple means while controlling for the problems of multiple testing  table   shows
that  at significance level p        
 smaller  e  is significantly better than larger  e  
  

fisolution guided multi point constructive search

 p     and p        are not significantly different  however  they both result in
significantly lower mre than p         for p         a smaller value of p is better 
 the luby fail limit sequence is significantly better than the poly sequence 
 chronological backtracking is significantly better than lds 
 e 
p
seq
bt

                        
                              
luby   poly
chron   lds

table    the results of independent tukey hsd tests on each factor  significance level of
the test on each parameter is p         a   b means that a incurs a lower mre
than b  and the difference in mre values is statistically significant  parenthesis
 i e       indicate no statistically significant difference in mre 
finally  table   presents the five best and five worst parameter settings as determined
by the mre at      cpu seconds  it is interesting to note that the five worst settings all
have p         which corresponds to a pure randomized restart algorithm 
 e 

p
bt
seq 
mre
five best parameter settings
       chron luby           
       chron luby           
       chron poly           
       chron luby           
       chron poly           
five worst parameter setting
       chron poly           
        chron poly           
       chron poly           
        chron poly           
       chron poly           

table    the best and worst parameter combinations in experiment   based on mre 
a graphical representation of all results from this experiment is impractical  however 
the statistical analysis is based on the performance of each set of parameter values at     
seconds  and so the evolution of performance over time is not reflected in these results 
given the arbitrariness of the      second time limit  it is a valid question to wonder if
the results would change given a different limit  to address this concern and to provide
a graphical sense of the results  we present graphs of the experimental results where one
parameter is varied and the others are held at their best values  for the parameters with
only two values  i e   seq and bt  we display the results for two different values of  e  as well 
elite set size   e  figure   shows the results of varying the elite set size with the other
parameter settings as follows  p         seq   luby  bt   chron  the differences between
  

fibeck

the various levels of  e  and the conclusion that lower  e  results in better performance can
be seen to hold for all time limits less than      seconds  in fact  the superiority of the
algorithms with small  e  is most visible early in the search  after about     seconds  the
gaps among the algorithms begin to narrow 
   

sgmpcs  e      p       seq luby  bt chron 
sgmpcs  e      p       seq luby  bt chron 
sgmpcs  e      p       seq luby  bt chron 
sgmpcs  e     p       seq luby  bt chron 
sgmpcs  e     p       seq luby  bt chron 
sgmpcs  e     p       seq luby  bt chron 

mean relative error

    

   

    

 

 

   

   

   
time  secs 

   

    

    

figure    the mean relative error for sgmpcs on a set of makespan jsps as the size of
the elite set is varied 
given the importance of diversity for elite solution sets within the metaheuristic literature  the performance of the algorithms with an elite size of   is somewhat surprising
and seems to contradict some of our original intuitions and motivations for sgmpcs  we
return to this point in experiment   
the probability of search from an empty solution  p figure   displays the results
of varying p while holding the other parameter values constant at  e       seq   luby  and
bt   chron  the most dramatic result is the performance of p         which is a pure
randomized restart technique  all the other settings of p result in performance that is more
than an order of magnitude  better than p        
unlike in the experiments with the  e  values  we do observe a change in the relative
strengths of the different parameter settings with different time limits  while p       
results in the best performance for all time limits  for low limits p     appears to out perform
p        and p         later  the latter two parameter values result in better performance
than p      note that this apparent contradiction of the statistical significance findings in
   the mre value achieved by p        at      seconds is achieved by all other p values at less than    
seconds 

  

fisolution guided multi point constructive search

   

sgmpcs p        e     seq luby  bt chron 
sgmpcs p        e     seq luby  bt chron 
sgmpcs p        e     seq luby  bt chron 
sgmpcs p        e     seq luby  bt chron 
sgmpcs p        e     seq luby  bt chron 

mean relative error

    

   

    

 

 

   

   

   
time  secs 

   

    

    

figure    the mean relative error for varying p values for sgmpcs on makespan jsps 
table   can be explained by the fact that there is interaction among the parameters and
p     performs better with other values of the rest of the parameters 
fail sequence  seq plots comparing the two different fail sequences are shown in figure
  with p         bt   chron  and with two different  e  values   e      and  e       for
run times less than about     cpu seconds  the poly fail sequence performs better than
the luby sequence in both conditions  after that threshold  luby performs better 
backtracking method  bt finally  figure   displays the result of varying the backtracking method under the parameters of p         seq   luby  and  e      or  e       using
chronological backtracking for these problems clearly results in superior performance at all
time limits when compared to lds 
    summary
this experiment demonstrates that for job shop scheduling with makespan minimization 
the best performing parameter settings for sgmpcs are  a small elite set  a relatively low
probability of starting search from an empty solution  the luby fail limit sequence  and
chronological backtracking  in general  these results are robust to changes in the time limit
placed on the runs 
one should be careful in interpreting these results for a number of reasons 
   as shown by the anova  all the parameters have statistically significant interactions 
and this was directly seen in the performance of p       e      in figure   
  

fibeck

   

sgmpcs poly   e     p       bt chron 
sgmpcs luby   e     p       bt chron 
sgmpcs poly   e     p       bt chron 
sgmpcs luby   e     p       bt chron 

mean relative error

    

   

    

 

 

   

   

   
time  secs 

   

    

    

figure    the mean relative error on makespan jsps for the two different fail sequences for
 e      and  e      

   while there is a statistically significant effect for all factors  with the exception of the
very poor performance of p         the performance of different parameter settings
displayed in the graphs are not wildly varying  while the differences among the
levels of different factors may be statistically significant  they may not be practically
significant  this is an advantage for sgmpcs as it suggests that fine tuning of
parameters is not really necessary  sgmpcs is somewhat robust in the sense that
small changes in parameters result in small changes in performance  again  with the
exception of p         
   the results presented here are based on a single problem  job shop scheduling with
makespan minimization  we comment on the applicability of these results to other
problems in section     

   experiment    the impact of elite set diversity
sgmpcs was designed with a number of intuitions about the impact of diversity on performance and on the likely effect of different parameter settings on performance  in particular 
we test the following intuitions 
 a higher  e  will tend to result in a higher diversity  this is not a strict relationship
as it is possible that all solutions in e are identical 
  

fisolution guided multi point constructive search

   

sgmpcs lds   e     p       seq luby 
sgmpcs lds   e     p       seq luby 
sgmpcs chron   e     p       seq luby 
sgmpcs chron   e     p       seq luby 

mean relative error

    

   

    

 

 

   

   

   
time  secs 

   

    

    

figure    the mean relative error using the luby fail limit and either chronological backtracking or lds on the makespan jsps 

 a higher p value will tend to increase diversity  since a higher p increases the proportion of searches from an empty solution  it will lead to a wider exploration of the
search space and therefore a more diverse elite set 
 the extent to which exploitation of multiple points in the search space is important
for sgmpcs should be reflected in the performance of sets with different levels of
diversity  that is  if it is important to simultaneously share search effort among a
number of regions in the search space  we would expect that higher levels of diversity
would out perform lower levels up to some threshold of diminishing returns 
    measuring diversity
the disjunctive graph  pinedo        is a standard representation of a job shop scheduling
problem where each activity is a node and the precedence constraints relating the activities
in the same job are directed  conjunctive arcs  for each pair of activities in different jobs
but on the same resource  there is a disjunctive arc  an arc that can be directed either
way  in a solution  each disjunctive arc must be oriented in one direction so that the graph
 which now contains only conjunctive arcs  is acyclic 
following the work of watson  beck  howe  and whitley         we measure the diversity
of the elite pool by the mean pair wise disjunctive graph distance  a binary variable is
introduced for each disjunctive constraint where one value represents one orientation of the
arc and the other value  the opposite orientation  a solution to the problem can therefore
  

fibeck

be represented by an assignment to these disjunctive graph variables  the distance between
a pair of solutions is then simply the hamming distance between the disjunctive graph
variable assignments  for a given elite set  we take the mean pair wise distance as a measure
of diversity 
clearly  this measure is not well formed for  e       we assume that the diversity of an
elite set of size   is   
    initial evaluation of diversity
our initial evaluation of diversity is simply to measure the diversity for the problem instances and a subset of the parameter values used in experiment    the sgmpcs solver
was instrumented to calculated the pair wise hamming distance whenever a new solution
was inserted into the elite set 
figure   displays the diversity of the elite set over time for different elite set sizes  as
expected  a higher elite set size results in a higher diversity  however  it is interesting to
note the stability of the diversity  after the first     seconds  the diversity of the set changes
very little  while the quality of solutions  see figure    continues to improve 
    

mean pair wise hamming distance

    

   

sgmpcs  e        p       seq luby  bt chron 
sgmpcs  e        p       seq luby  bt chron 
sgmpcs  e        p       seq luby  bt chron 
sgmpcs  e       p       seq luby  bt chron 
sgmpcs  e       p       seq luby  bt chron 

   

   

   

 

 

   

   

   
time  secs 

   

    

    

figure    the diversity measured by mean pair wise hamming distance among the solutions
in elite set for different elite set sizes 
figure   shows the diversity with changing p values  contrary to our expectations 
higher p values exhibit lower diversity  further analysis shows that the primary cause of
this pattern is the way in which elite solutions are replaced  when search starts from
an elite solution  an improved solution replaces the starting solution  because the fail
limit is relatively low  the starting solution is  with very high probability  also the closest
  

fisolution guided multi point constructive search

elite solution to the improved solution  therefore  replacing the starting elite solution has
a relatively small impact on the overall diversity  in contrast  when search starts from
an empty solution  the worst elite solution is replaced by an improved solution  as we
demonstrate below  this difference in replacement policy results in a significantly lower elite
pool diversity when more searches start from an empty solution  diversity decreases with
increasing p 
    

mean pair wise hamming distance

    

   

   
sgmpcs p          e     seq luby  bt chron 
sgmpcs p          e     seq luby  bt chron 
sgmpcs p          e     seq luby  bt chron 
sgmpcs p          e     seq luby  bt chron 
sgmpcs p          e     seq luby  bt chron 

   

   

 

 

   

   

   
time  secs 

   

    

    

figure    the diversity measured by mean pair wise hamming distance among the solutions
in elite set for values of p 

    manipulating diversity
motivated by our interpretation of the results in figure    in this section we experiment with
the manipulation of the diversity by changing the elite solution replacement rule  three
levels of diversity are defined as follows 
 low diversity  regardless of whether search starts from an elite solution or an empty
solution  an improved solution replaces the worst elite one  no distance based criteria
is used  in the initialization phase  we follow the same approach as used above    
elite solutions are independently generated without constraining the makespan  and
the  e  best solutions inserted into the elite set 
 medium diversity  the standard elite set replacement rules used in experiment   and
defined in section   are used 
  

fibeck

 high diversity  when search starts from an empty solution  the closest elite solution
is replaced if an improving solution is found  when search starts from an elite solution  the starting solution replaced  as noted above  this latter rule results in the
replacement of the closest solution with high probability  therefore  these two rules
are almost always equivalent to replacing the closest solution  during the initialization
phase   e  solutions are generated and inserted into the elite pool  then  an additional
     e  solutions are generated and  if one of these solutions is better than the worst
elite solution  the new solution is inserted into the elite set  replacing the closest elite
solution 
to verify that our manipulations do indeed affect the diversity of the elite set as expected 
we conduct an initial experiment over a subset of the parameter space  using the problem
instances from experiment   and the same hardware and software configurations  we solved
each problem instance    times under each diversity condition while varying  e  and p 
rather than doing a fully crossed experiment  we set  e      and varied p from   to    and
set p        and varied  e  from   to    
figures   and   demonstrate that the above manipulations affect the diversity of the
elite set as expected  they show the different diversity levels with only two  e  values and
two p values as displaying all the data was impractical  it is interesting to note that for the
high and low diversity conditions  the effect on diversity of the other parameters disappears 
there is little variation in the diversity when  e  and p are varied under those two diversity
conditions 
    

mean pair wise hamming distance

    

   

high   e       p       seq luby  bt chron 
high   e       p       seq luby  bt chron 
medium   e       p       seq luby  bt chron 
medium   e       p       seq luby  bt chron 
low   e       p       seq luby  bt chron 
low   e       p       seq luby  bt chron 

   

   

   

 

 

   

   

   
time  secs 

   

    

    

figure    the diversity measured by mean pair wise hamming distance among the solutions
in the elite set for different diversity levels for  e      and  e      

  

fisolution guided multi point constructive search

    

mean pair wise hamming distance

    

   
high  p          e     seq luby  bt chron 
high  p          e     seq luby  bt chron 
medium  p          e     seq luby  bt chron 
medium  p          e     seq luby  bt chron 
low  p          e     seq luby  bt chron 
low  p          e     seq luby  bt chron 

   

   

   

 

 

   

   

   
time  secs 

   

    

    

figure    the diversity measured by mean pair wise hamming distance among the solutions
in the elite set for different diversity levels for p     and p        

    experimental details
having verified that we do indeed have three different diversity settings  we can now test
the impact of different diversity levels on the performance of sgmpcs  we perform a fully
crossed experiment with three independent variables   e  which  as above  takes the values
                       p which  as above  takes the values                          and diversity
 div  taking the values low  medium  and high corresponding to the manipulations described
above  in all conditions  we use chronological backtracking and the luby fail limit sequence 
the other experimental details including the problem instances  hardware and software 
the      cpu second time limit  heuristics and propagators  and our evaluation criteria
 mre  are the same as in experiment    see section      
    results
the fully crossed experimental design results in    cells            each cell is the result
of    runs of each of the    problem instances with a    minute time limit  these results
were generated in about     cpu days 
the summary of the analysis of variance is shown in table    these results demonstrate
that all factors and all interactions are significant at p         a tukey hsd test  r
development core team        with significance level p        was done on each of the
factors  and the results are summarized in table    the tukey hsd results indicate that 
  

fibeck

 as with experiment    lower  e  is better  though in this case there is no significant
difference between  e      and  e      
 p     is significantly worse than p        which in turn is significantly worse than
p         recall that in experiment    p     was not significantly different from
p        
 lower diversity is better than medium which in turn is better than high diversity 
factor s 
e
p
div
e p
e div
p div
e p div
residuals

df
 
 
 
  
  
 
  
     

sum sq
      
       
      
      
      
      
      
      

mean sq
      
      
      
      
      
      
      
      

f value
       
          
        
       
       
       
      

pr  f 
     e   
     e   
     e   
     e   
     e   
     e   
     e   

table    summary of the analysis of variance found using the r statistical package  r
development core team         all factors and all interactions are significant at
p        

 e 
p
div

                          
                             
low   medium   high

table    the results of independent tukey tests on each factor in the diversity experiment 
significance level of the test on each parameter is p        
finally  table   presents the parameter values that result in the five lowest and five
highest mre results  note that the previous best set of parameter values   e       p        
div   med  now incurs a slightly worse mre than  e       p         div   low 
    summary
our experiment with diversity has addressed a number of our intuitions 
 as expected  a larger elite set results in a higher elite set diversity 
 contrary to our expectations  a higher probability of searching from an empty solution
decreases diversity  we were able to show that this impact was not directly due to
the p value but rather to the different elite set replacement rules 
 finally  and most importantly  it appears that the diversity of the elite set is negatively
correlated with performance  the lower the diversity  the higher the performance 
  

fisolution guided multi point constructive search

 e 
p
div
mre
five best parameter settings
       low
          
       med           
       low
          
        low
          
        low
          
five worst parameter setting
        med           
       low
          
       low
          
        med           
        low
          

table    best and worst parameters for the diversity experiments 
this result calls into question the extent to which sgmpcs performance is based on
exploiting multiple points in the search space  if such exploitation were important
for performance  we would expect higher diversity to out perform lower diversity  we
return to this question in section   

   experiment    benchmark comparison with other techniques
our first two experiments concentrated on providing basic data on the performance of the
different parameter settings of sgmpcs and an initial inquiry into the reasons underlying
sgmpcs performance  in this experiment  we turn to comparisons of sgmpcs with
existing heuristic search techniques 
    experimental details
we use three sets of well known jsp benchmark problem instances  taillard         each
set contains    instances  and the different sets have problems of different size         
        and         the problems are numbered from    though       these instances
were not used during the development of sgmpcs 
five algorithms are tested 
 standard chronological backtracking  chron   a non randomized version of the same
texture based heuristic employed above is used together with the same global constraint propagators  as the heuristic is not randomized  one run is done for each
problem instance 
 limited discrepancy search  lds   this is an identical algorithm to chron except
the backtracking is lds 
   see http   ina  eivd ch collaborateurs etd problemes dir ordonnancement dir ordonnancement html
for the benchmark instances  the best known upper and lower bounds are from the latest summary
file on the same website  dated          

  

fibeck

 randomized restart  restart   this is a randomized restart algorithm using the
same randomized texture based heuristic and global constraint propagators used in
experiment   and    the backtracking between restarts is chronological and the fail
limit used is the luby limit  each problem instance is solved    times 
 solution guided multi point constructive search  sgmpcs   we take the best parameters from experiments   and     e       p         seq   luby  bt   chron  and
div   low  with these parameter settings  the sole difference between sgmpcs and
restart is the use of the elite set and the fact that some searches are guided by an elite
solution  in particular  they use the same heuristics  propagators  fail limit sequence 
and type of backtracking  each problem instance is solved    times 
 iterated simple tabu search  i sts   the i sts algorithm is a sophisticated multiphase tabu search built to model the state of the art i tsab  nowicki   smutnicki 
      but with the goal of simplifying it in order to study how its various components
contribute to the overall performance  watson et al          on the taillard benchmarks  i sts only slightly under performs i tsab in terms of solution quality given
an equal number of iterations   we use the parameters recommended  for the taillard
instances   e       xa          xb         pi   pd        for a full definition of
these parameters  see the work of watson et al         
the time limit for each run is      cpu seconds  the other experimental details 
including hardware and software for the first four algorithms  and the evaluation criteria
are the same as in experiment    see section       the i sts algorithm is watson et al s
c   implementation run on the same hardware as the other algorithms  meaning that
direct run time comparison is meaningful 
for all the constructive search based approaches  i e   all algorithms tested here except
i sts   the global bound policy is followed  see section       whenever a new best solution
is found  the global upper bound on the cost function is modified to be one less than this
new best cost  in particular  this means that restart benefits from the back propagation of
the cost constraint in exactly same way that sgmpcs does 
    results
the mean and best makespan found for each problem set are shown in tables   through   
table    shows the performance in terms of finding and proving the optimal makespan for
those problems for which the optimal solution is known 
      comparing constructive search algorithms
on the        problems  table     sgmpcs dominates the other constructive algorithms 
finding the lowest makespan  as judged by the mean makespan   for all but one instance
 instance      in particular  on all problem instances the mean sgmpcs solution is better
than the best solution found by restart  in terms of mean relative error  sgmpcs outperforms each of the other constructive algorithms by a factor of about   to   
   as with the previous experiments  here we use a cpu time limit  it is estimated that i sts is about  
to   times slower than i tsab 
   jean paul watson  personal communication 

  

fisolution guided multi point constructive search

prob 
  
  
  
  
  
  
  
  
  
  
mre

lb ub
         
         
         
    
         
         
    
         
         
         
 vs  ub 

chron
    
    
    
    
    
    
    
    
    
    
      

lds
    
    
    
    
    
    
    
    
    
    
      

restart
mean
best
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
             

sgmpcs
mean
best
      
    
      
    
      
    
           
      
    
      
    
      
    
      
    
      
    
      
    
             

i sts
mean
best
      
    
      
    
      
    
    
    
      
    
      
    
      
    
      
    
      
    
      
    
             

table    results for taillards        instances  bold entries indicate the best performance
across the five algorithms on each instance  for restart  sgmpcs  and i sts 
we use the mean makespan as the performance measure  we also include the best
makespan found by the algorithms that solve an instance multiple times  the
 indicates that the optimal makespan was found and proved for the problem
instance  the final row shows the mean relative error  relative to the best known
upper bound  for each algorithm 

it is interesting to note the similar performance of lds and restart  we observe that
when using a dynamic variable ordering  lds performs partial restarts when jumping to
the top of the tree to introduce a discrepancy  this suggests that some of the performance
of lds with dynamic variable orderings may be due to an exploitation of the heavy tails
phenomenon  the similar results here and on the other jsp instances in this section support
this idea  to our knowledge this relationship has not been commented on before 

prob 
  
  
  
  
  
  
  
  
  
  
mre

lb ub
         
         
         
         
         
         
         
         
         
         
 vs  ub 

chron
    
    
    
    
    
    
    
    
    
    
      

lds
    
    
    
    
    
    
    
    
    
    
      

restart
mean
best
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
             

sgmpcs
mean
best
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
             

i sts
mean
best
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
             

table    results for taillards        instances  see the caption of table   
table   displays the results for the        problems  again  sgmpcs dominates
the other constructive algorithms  finding a mean makespan that is better than the best
makespan found by any of the other constructive techniques  sgmpcs was unable to find
  

fibeck

solutions as good as the best known upper bound for any of these instances  in terms of
mre  sgmpcs out performs the other algorithms by a factor of   to   

prob 
  
  
  
  
  
  
  
  
  
  
mre

lb ub
    
         
         
         
    
    
    
    
    
         
 vs  ub 

chron
    
    
    
    
    
    
    
    
    
    
     

lds
    
    
    
    
    
    
    
    
    
    
      

restart
mean
best
      
    
      
    
      
    
      
    
           
      
    
      
    
      
    
      
    
      
    
             

sgmpcs
mean
best
      
    
      
    
      
    
      
    
           
           
      
    
      
    
           
      
    
             

i sts
mean
best
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
             

table    results for taillards        instances  see the caption of table   
table   displays the results on the largest problem instances           on all instances
but one  the mean solution found by sgmpcs is better than the best solution from each
of the other constructive algorithms  for instance     sgmpcs equals the performance of
lds and restart in finding  and  in some cases  proving  the optimal solution  overall 
sgmpcs is a factor of   to    better in terms of mre 
prob 
  
  
  
  
  
  
  
  

opt 
    
    
    
    
    
    
    
    

chron
    
    
    
    
    
    
    
    

lds
      
    
    
     
    
    
    
    

restart
    
    
    
     
    
    
    
    

sgmpcs
    
    
    
     
    
    
    
    

i sts
     
    
      
     
    
    
    
    

table     results for the taillard instances for which the optimal solution is known  the
first two columns are the problem index and optimal makespan respectively  the
rest of the columns are the number of runs for which each algorithm found an
optimal solution and  in parenthesis  the number of times that it proved optimality  recall that both chron and lds are run once per instance because they are
not stochastic  however  to provide a fair basis of comparison  we present their
results assuming they produced identical results in each of ten runs per instance 
while i sts is not a complete algorithm  there are some structural characteristics of a solution that imply optimality  nowicki   smutnicki         when a
solution with such a characteristic is found  i sts is able to prove optimality as
shown in two instances  tai   and tai   

  

fisolution guided multi point constructive search

finally  table    presents the number of runs for which each algorithm was able to find
and prove the optimal solutions for those problem instances with known optimal  sgmpcs
finds the optimal solution at least once for five instances and proves the optimality at least
once for four of those instances  chron is unable to find or prove optimality for any instances 
while restart only does so for one instance  and lds is able to find an optimal solution for
two instances and prove it for one 
      sgmpcs vs  i sts
on almost all instances in tables   and   i sts performs substantially better than sgmpcs  in many cases  the mean solution found by i sts is better than the best found by
sgmpcs  however  on seven of the ten smallest instances  table     the best solution
found by sgmpcs is as good or better than that found by i sts  and sgmpcs is strictly
better on five instances  as with the larger problems  however  the mean makespan found
by i sts is better than that found by sgmpcs on all instances 
recall that each algorithm was run for      cpu seconds  while we do not include
graphs of the run time distributions  we have observed that the performance gap in terms
of mre between sgmpcs and i sts at      seconds is present at all time points from   
seconds  in other words  i sts substantially out performs sgmpcs in the first    seconds
and thereafter both algorithms find better solutions at about the same rate 
table    shows that the one area that sgmpcs is clearly superior to i sts is in
proving the optimality of solutions  while i sts is not a complete algorithm  it can identify
solutions with a particular structure as optimal  nowicki   smutnicki         sgmpcs is
able to find and prove optimality within the time limit on four instances in at least one run
while i sts can only do so for two instances 
    summary
of the    problem instances used in this experiment  the mean solution found by sgmpcs
was better than the best solution found by any of the other constructive techniques in   
instances  of the remaining instances  sgmpcs performs as well as lds and restart
for instance    and slightly worse than lds on instance     overall  in terms of mean
relative error  sgmpcs is between   and    times better than the other constructive search
algorithms on the different problem sets 
sgmpcs does not perform as well as i sts in terms of mean makespan  however  on
the smaller problems the best solution it is able to find is better than that of i sts on five
instances 

   discussion and future work
this paper demonstrates that solution guided multi point constructive search can significantly out perform existing constructive search techniques in solving hard combinatorial
search problems but trails behind the state of the art in metaheuristic search  in this section  we present some preliminary ideas regarding the reasons for the observed performance 
a discussion of the generality of sgmpcs  and some directions for extensions of sgmpcs 
  

fibeck

    why does sgmpcs work 
to the extent that sgmpcs out performs existing constructive search approaches for solving hard combinatorial search problems  the most interesting question arising from the
above experiments is understanding the reasons for this strong performance  we speculate
that there are three  non mutually exclusive  candidates  the exploitation of heavy tails  the
impact of revisiting previous high quality solutions  and the use of multiple elite solutions 
      exploiting heavy tails
sgmpcs is a restart based algorithm  even with p      search periodically restarts  albeit
with a value ordering based on an elite solution  we believe that it is likely  therefore  that
sgmpcs exploits heavy tailed distributions in much the same way as randomized restart
 gomes et al         gomes   shmoys        
one way to test this idea is to reproduce gomes et al s original experiment for sgmpcs
as follows  for a random variable ordering  solve a problem instance to optimality starting
from a given sub optimal solution  s  and record the search effort involved  repeat for k different random variable orderings for a large k  and finally observe the frequency distribution
of search effort  the whole experiment can then be repeated for different starting solutions 
if the resulting distributions exhibit heavy tailed behaviour  the reasons that randomized
restart is able to take advantage of heavy tailed distributions may be shared by sgmpcs 
we are currently pursuing such an experiment 
      revisiting solutions
while we believe it likely that the experiment suggested in section       will demonstrate
that sgmpcs takes advantage of heavy tailed distributions  the significant performance
advantage of sgmpcs over restart in experiment   as well as the very poor performance
of the p     parameter setting in experiments   and    lead us to expect that there are
additional factors needed to account for the performance of sgmpcs 
we believe that a leading candidate for one of these additional factors is the impact
of revisiting high quality solutions using a different variable ordering  each time an elite
solution is revisited with a different variable ordering  a different search tree is created  a
resource limited chronological search will only visit nodes deep in the tree before the resource
limit is reached  however  a different variable ordering results in a different set of nodes that
are deep in the tree and that are  therefore  within reach of the search    the strong results of
sgmpcs with  e      may be an indication that the mechanism responsible for the strong
performance is the sampling of solutions close to an elite solution in different search trees 
our primary direction for future research is to formalize the meaning of close within a
search tree to provide a firm empirical foundation on which to investigate the impact of
revisiting solutions  we hope to adapt the significant work on fitness distance correlation
 hoos   stuzle        in the local search literature to constructive search 

   similar reasoning applies to the use of lds 

  

fisolution guided multi point constructive search

      exploiting multiple points in the search space
the use of multiple solutions and  more specifically  the balance between intensification
and diversification is viewed as very important in the metaheuristic literature  rochat
  taillard         intensification suggests searching in the region of good solutions while
diversification suggests searching in areas that have not been searched before  furthermore 
one of the important aspects of the metaheuristics based on elite solutions is how the
diversity of the elite set is maintained  watson        
however  the experiments presented here suggest that increased diversity is not an
important factor for performance of sgmpcs  the best performance was achieved with
very small elite set sizes and even  in experiment    an elite set size of    based on such
results  the original motivations for sgmpcs are  to say the least  suspect 
our results may be due to idiosyncrasies of the makespan jsp problem  while experiments on some other problems  see below  have not directly manipulated diversity  the
results have indicated better relative performance for larger elite set sizes than was observed
here  this may be an indication that on other problems we will see a positive contribution
of maintaining multiple viewpoints 
on a speculative note  a closer look at figure   may show that diversity does play a
role in search performance  that figure shows that the greatest differences in performance
from different elite set sizes comes early in the search  where it is relatively easy to find an
improving solution  later in search  the performance difference narrows  though does not
close completely within the time limit  one interpretation of this pattern is that  early in
the search  when it is relatively easy to improve upon existing elite solutions  a large elite
pool distracts the search by guiding it with an elite solution that is significantly worse
than the best elite solution  the narrowing of the performance gap may be simply due to
the fact that  with better solutions  it is harder to improve upon them and so regardless
of the size of the elite set  the rate of improvement will decrease  since the algorithms
with lower  e  have better solutions  their rate slows earlier  an alternative explanation
is that maintaining multiple elite solutions has a positive influence only after the initial
easy phase of search  when better solutions are harder to find  having a diverse elite set
may help the search as the probability that at least one of the elite solutions has a better
solution in its vicinity rises with the elite set size    further experimentation is required to
investigate these intuitions 
    generality
sgmpcs is a general technique for conducting constructive search  nothing in the sgmpcs
framework is specific to scheduling or constraint programming  however  in this paper only
one type of problem was used to evaluate sgmpcs and therefore the question of its practical
utility and generality should be addressed 
existing work shows that sgmpcs can be effectively applied to other optimization and
satisfaction problems such as quasigroup with holes completion  beck      b  heckman  
beck         job shop scheduling with the objective to minimize weighted tardiness  beck 
       and multi dimensional knapsack optimization  heckman   beck         in addi   if this explanation is accurate  an adaptive strategy with  e  growing during the search might be worth
investigating 

  

fibeck

tion  recent work by sellmann and ansotegui        demonstrates good performance of
a closely related technique on diagonally ordered magic squares and some sat instances 
however  sgmpcs performs worse than randomized restart  though better than chronological backtracking  on magic square instances  and both randomized restart and sgmpcs
perform much worse than chronological backtracking on a satisfaction version of the multidimensional knapsack problem  heckman   beck        
the application of sgmpcs to such a variety of problems demonstrates that it is indeed
a general technique whose impact can be applied beyond job shop scheduling  at the same
time  the negative results on some problems point to our lack of understanding as to the
mechanisms behind sgmpcs performance and motivates our future work 
    extending sgmpcs
while the immediate focus of our future work is on understanding the reasons for its performance  there are a number of ways in which the framework can be extended 
first  as implied by our speculations regarding the impact of diversity in section       
dynamic parameter learning  horvitz et al         would appear very useful to the sgmpcs
framework  for example  one could imagine adapting p during the search depending on the
relative success of searching from an empty solution versus searching from an elite solution 
second  given that the metaheuristics community has been working with elite solutions
for a number of years  there are a number of techniques which may fruitfully extend sgmpcs  for example  in path relinking  glover  laguna    marti        a pair of elite solutions
is taken as end points of a local search trajectory  path relinking has an elegant counterpart
in sgmpcs  two elite solutions are chosen  the variable assignments they have in common
are fixed  defining a sub space of the variable assignments in which the two solutions differ 
unlike in path relinking for local search  in constructive search one can perform a complete search of this sub space and then post a no good removing that sub space from future
consideration  some preliminary experiments with such an approach appear promising 
third  clause learning techniques  which originated as conflict learning in constraint
programming  prosser         are widely used with restart in state of the art satisfiability
solvers  huang         it seems natural to investigate combining conflict learning and
solution guidance  these techniques may have an interesting relationship as the former tries
to learn the mistakes that led to a dead end while the latter attempts to heuristically
identify the correct decisions that were made 
finally  work on loosely coupled hybrid search techniques that share single solutions
 carchrae   beck        is easily generalizable to share a set of solutions  to date  rather
than being able to exploit a full solution shared by some other technique  constructive search
is only able to use the bound on the cost function  therefore  the revisiting of solutions
provides a way to exploit the much richer information  i e   full solutions  that is available
in a hybrid search technique 

   conclusion
this paper presents the first fully crossed study of solution guided multi point constructive search  using a set of job shop scheduling problems  we varied the sgmpcs parameter
settings to control the size of the elite set  the probability of searching from an empty so  

fisolution guided multi point constructive search

lution  the fail sequence  the form of backtracking  and the diversity level of the elite set 
experiments indicated that low elite set sizes  low probability of searching from an empty
solution  the luby fail sequence  chronological backtracking  and low diversity lead to the
best performance  we then compared the best sgmpcs parameters found to existing constructive search techniques and to a state of the art tabu search algorithm on a well known
set of benchmark problems  the results demonstrated that sgmpcs significantly outperforms chronological backtracking  limited discrepancy search  and randomized restart while
being out performed by the tabu search algorithm 
the primary contribution of this paper is the introduction of a new search framework
and the demonstration that it can significantly out perform existing constructive search
techniques  secondary contributions include the demonstration that the impact of elite set
diversity on performance is the opposite of what was expected  i e   low diversity leads to
higher performance  and the identification of research directions into the reasons underlying
the performance of sgmpcs by focusing on the quantification of the effects of heavy tails 
of the impact of revisiting solutions with different variable orderings  and of the exploitation
of multiple points in the search space 

acknowledgments
this research was supported in part by the natural sciences and engineering research
council and ilog  s a  thanks to jean paul watson  daria terekhov  tom carchrae 
ivan heckman  and lei duan for comments on early versions of the paper  a preliminary
version of parts of this work has been previously published  beck        

references
beck  j  c       a   multi point constructive search  in proceedings of the eleventh international conference on principles and practice of constraint programming  cp    
pp         
beck  j  c       b   multi point constructive search  extended remix  in proceedings of the
cp     workshop on local search techniques for constraint satisfaction  pp       
beck  j  c          an empirical study of multi point constructive search for constraintbased scheduling  in proceedings of the sixteenth international on automated planning
and scheduling  icaps     pp         
beck  j  c     fox  m  s          dynamic problem structure analysis as a basis for
constraint directed scheduling heuristics  artificial intelligence                
carchrae  t     beck  j  c          applying machine learning to low knowledge control of
optimization algorithms  computational intelligence                 
dilkina  b   duan  l     havens  w          extending systematic local search for job
shop scheduling problems  in proceedings of eleventh international conference on
principles and practice of constraint programming  cp     pp         
garey  m  r     johnson  d  s          computers and intractability  a guide to the theory
of np completeness  w h  freeman and company  new york 
  

fibeck

glover  f   laguna  m     marti  r          scatter search and path relinking  advances
and applications  in onwubolu  g     babu  b   eds    new optimization techniques
in engineering  springer 
gomes  c  p   selman  b     kautz  h          boosting combinatorial search through
randomization  in proceedings of the fifteenth national conference on artificial intelligence  aaai      pp         
gomes  c  p   fernandez  c   selman  b     bessiere  c          statistical regimes across
constrainedness regions  constraints                 
gomes  c     shmoys  d          completing quasigroups or latin squares  a structured
graph coloring problem  in proceedings of the computational symposium on graph
coloring and generalizations 
harvey  w  d          nonsystematic backtracking search  ph d  thesis  department of
computer science  stanford university 
heckman  i     beck  j  c          an empirical study of multi point constructive search
for constraint satisfaction  in proceedings of the third international workshop on
local search techniques in constraint satisfaction 
heckman  i     beck  j  c          an empirical study of multi point constructive search
for constraint satisfaction  submitted to constraints 
hoos  h     stuzle  t          stochastic local search  foundations and applications 
morgan kaufmann 
horvitz  e   ruan  y   gomes  c   kautz  h   selman  b     chickering  m          a
bayesian approach to tacking hard computational problems  in proceedings of the
seventeenth conference on uncertainty and artificial intelligence  uai        pp 
       
huang  j          the effect of restarts on the efficiency of clause learning  in proceedings
of the twentieth international joint conference on artificial intelligence  ijcai    
pp           
hulubei  t     osullivan  b          the impact of search heuristics on heavy tailed
behaviour  constraints                  
jain  a  s     meeran  s          deterministic job shop scheduling  past  present and
future  european journal of operational research                  
jussien  n     lhomme  o          local search with constraint propagation and conflictbased heuristics  artificial intelligence            
kautz  h   horvitz  e   ruan  y   gomes  c     selman  b          dynamic restart policies 
in proceedings of the eighteenth national conference on artifiical intelligence  aaai     pp         
laborie  p          algorithms for propagating resource constraints in ai planning and
scheduling  existing approaches and new results  artificial intelligence              
le pape  c          implementation of resource constraints in ilog schedule  a library
for the development of constraint based scheduling systems  intelligent systems engineering              
  

fisolution guided multi point constructive search

luby  m   sinclair  a     zuckerman  d          optimal speedup of las vegas algorithms 
information processing letters             
nowicki  e     smutnicki  c          a fast taboo search algorithm for the job shop problem 
management science                 
nowicki  e     smutnicki  c          an advanced tabu algorithm for the job shop problem 
journal of scheduling            
nuijten  w  p  m          time and resource constrained scheduling  a constraint satisfaction approach  ph d  thesis  department of mathematics and computing science 
eindhoven university of technology 
pinedo  m          planning and scheduling in manufacturing and services  springer 
prestwich  s          combining the scalability of local search with the pruning techniques
of systematic search  annals of operations research            
prosser  p          hybrid algorithms for the constraint satisfaction problem  computational
intelligence                
r development core team         r  a language and environment for statistical computing  r foundation for statistical computing  vienna  austria  isbn               
rochat  y     taillard  e  d          probabilistic diversification and intensification in local
search for vehicle routing  journal of heuristics            
sellmann  m     ansotegui  c          disco novo gogo  integrating local search and complete saerch with restarts  in proceedings of the twenty first national conference on
artificial intelligence  aaai     pp           
taillard  e  d          benchmarks for basic scheduling problems  european journal of
operational research             
watson  j  p          empirical modeling and analysis of local search algorithms for the
job shop scheduling problem  ph d  thesis  dept  of computer science  colorado
state university 
watson  j  p          on metaheuristics failure modes  a case study in tabu search for jobshop scheduling  in proceedings of the fifth metaheuristics international conference 
watson  j  p   barbulescu  l   whitley  l  d     howe  a  e          contrasting structured
and random permutation flow shop scheduling problems  search space topology and
algorithm performance  informs journal on computing                
watson  j  p   beck  j  c   howe  a  e     whitley  l  d          problem difficulty for
tabu search in job shop scheduling  artificial intelligence                  
watson  j  p   howe  a  e     whitley  l  d          deconstructing nowicki and smutnickis i tsab tabu search algorithm for the job shop scheduling problem  computers
and operations research                   

  

fi