journal of artificial intelligence research                  

submitted        published      

on the practical use of variable elimination in constraint
optimization problems  still life as a case study
javier larrosa
enric morancho
david niso

larrosa lsi upc edu
enricm ac upc edu
niso   casal upc edu

universitat politecnica de catalunya
jordi girona            barcelona  spain

abstract
variable elimination is a general technique for constraint processing  it is often discarded because of its high space complexity  however  it can be extremely useful when
combined with other techniques  in this paper we study the applicability of variable elimination to the challenging problem of finding still lifes  we illustrate several alternatives 
variable elimination as a stand alone algorithm  interleaved with search  and as a source of
good quality lower bounds  we show that these techniques are the best known option both
theoretically and empirically  in our experiments we have been able to solve the n     
instance  which is far beyond reach with alternative approaches 

   introduction
many problems arising in domains such as resource allocation  cabon  de givry  lobjois 
schiex    warners         combinatorial auctions  sandholm         bioinformatics and
probabilistic reasoning  pearl        can be naturally modeled as constraint satisfaction
and optimization problems  the two main solving schemas are search and inference  search
algorithms constitute the usual solving approach  they transform a problem into a set of
subproblems by selecting one variable and instantiating it with its different alternatives 
subproblems are solved applying recursively the same transformation rule  the recursion
defines a search tree that is normally traversed in a depth first manner  which has the
benefit of requiring only polynomial space  the practical efficiency of search algorithms
greatly depends on their ability to detect and prune redundant subtrees  in the worst case 
search algorithms need to explore the whole search tree  nevertheless  pruning techniques
make them much more effective 
inference algorithms  also known as decomposition methods  solve a problem by a sequence of transformations that reduce the problem size  while preserving its optimal cost  a
well known example is bucket elimination  be  also known as variable elimination   bertele
  brioschi        dechter         the algorithm proceeds by selecting one variable at a
time and replacing it by a new constraint which summarizes the effect of the chosen variable  the main drawback of be is that new constraints may have large arities which require
exponentially time and space to process and store  however  a nice property of be is that
its worst case time and space complexities can be tightly bounded by a structural parameter called induced width  the exponential space complexity limits severely the algorithms
c
    
ai access foundation  all rights reserved 

filarrosa  morancho   niso

practical usefulness  thus  in the constraint satisfaction community variable elimination is
often disregarded 
in this paper we consider the challenging problem of finding still lifes which are stable
patterns of maximum density in the game of life  this academic problem has been recently
included in the csplib repository  and a dedicated web page  has been set to maintain
up to date results  in bosch and trick         the still life problem is solved using two
different approaches  integer programming and constraint programming  both of them based
on search  none of them could solve up to the n     problem within reasonable time  their
best results were obtained with a hybrid approach which combines the two techniques and
exploits the problem symmetries in order to reduce the search space  with their algorithm 
they solved the n      case in about   days of cpu  smith        proposed an interesting
alternative using pure constraint programming techniques  and solving the problem in its
dual form  in her work  smith could not improve the n      limit  although not explicitly
 
mentioned  these two works use algorithms with worst case time complexity o   n     
in this paper we show the usefulness of variable elimination techniques  first we apply
plain be  against what could be expected  we observe that be is competitive with stateof the art alternatives  next  we introduce a more sophisticated algorithm that combines
search and variable elimination  following the ideas of larrosa   dechter        and uses
a lower bound based on mini buckets  following the ideas of kask   dechter         with
our algorithm  we solve in one minute the n      instance  we have been able to solve up to
the n      instance  which was far beyond reach with previous techniques  for readability
reasons  we only describe the main ideas and omit algorithmic details  
the structure of the paper is the following  in the next section we give some preliminary
definitions  in section   we solve the problem with plain be  in section   we introduce the
hybrid algorithm with which we obtained the results reported in section    in section   we
discuss how the ideas explored in this article can be extended to other domains  besides 
we report additional experimental results  finally  section   gives some conclusions and
lines of future work 

   preliminaries
in this section we first define the still life problem  next  we define the weighted csp
framework and formulate the still life as a weighted csp  finally  we review the main
solving techniques for weighted csps 
    life and still life
the game of life  gardner        is played over an infinite checkerboard  where each square
is called a cell  each cell has eight neighbors  the eight cells that share one or two corners
with it  the only player places checkers on some cells  if there is a checker on it  the cell
is alive  else it is dead  the state of the board evolves iteratively according to the following
three rules      if a cell has exactly two living neighbors then its state remains the same
   www csplib org
   www ai sri com   nysmith life
   the interested reader can find an extended version  along with the source code of our implementation
in www lsi upc edu   larrosa publications

   

fion the practical use of variable elimination

 

 

 

 

 

 

 

xc

 

 

a

 

 

b

 

d

c

e

figure    a  a      still life  b  constraint graph of a simple wcsp instance with four
variables and three cost functions  c  the constraint graph after assigning variable
x    d  the constraint graph after clustering variables x  and x    e  the constraint
graph after eliminating variable x   

in the next iteration      if a cell has exactly three living neighbors then it is alive in the
next iteration and     if a cell has fewer than two or more than three living neighbors 
then it is dead in the next iteration  although defined in terms of extremely simple rules 
the game of life has proven mathematically rich and it has attracted the interest of both
mathematicians and computer scientists 
the still life problem sl n  consist on finding a nn stable pattern of maximum density
in the game of life  all cells outside the pattern are assumed to be dead  considering the
rules of the game  it is easy to see that each cell  i  j  must satisfy the following three
conditions      if the cell is alive  it must have exactly two or three living neighbors      if
the cell is dead  it must not have three living neighbors  and     if the cell is at the grid
boundary  i e  i     or i   n or j     or j   n   it cannot be part of a sequence of three
consecutive living cells along the boundary  the last condition is needed because three
consecutive living cells at a boundary would produce living cells outside the grid 
example   figure   a shows a solution to sl     it is easy to verify that all its cells
satisfy the previous conditions  hence it is stable  the pattern is optimal because it has  
living cells and no      stable pattern with more that   living cells exists 

    weighted csp
a weighted constraint satisfaction problem  wcsp   bistarelli  montanari    rossi       
is defined by a tuple  x  d  f   where x    x            xn   is a set of variables taking values
from their finite domains di  d  f is a set of weighted constraints  i e   cost functions  
each f  f is defined over a subset of variables  var f    called its scope  the objective
function is the sum of all functions in f 
f  

x

f

f f

and the goal is to find the instantiation of variables that minimizes the objective function 
example   consider a wcsp with four variables x    xi   i   with domains di         
and three cost functions  f   x    x      x    x    f   x    x      x  x  and f   x    x      x    x   
   

filarrosa  morancho   niso

the objective function is f  x    x    x    x      x    x    x  x    x    x    clearly  the optimal
cost is    which is obtained with every variable taking value   
constraints can be given explicitly by means of tables  or implicitly as mathematical
expressions or computing procedures  infeasible partial assignments are specified by constraints that assign cost  to them  the assignment of value a to variable xi is noted
xi   a  a partial assignment is a tuple t    xi    v    xi    v         xij   vj    the extension
of t to xi   a is noted t   xi   a   wcsps instances are graphically depicted by means
of their interaction or constraint graph  which has one node per variable and one edge connecting any two nodes that appear in the same scope of some cost function  for instance 
figure   b shows the constraint graph of the problem in the previous example 
    overview of some solving techniques
in this subsection we review some solving techniques widely used when reasoning with
constraints 
      search
wcsps are typically solved with depth first search  search algorithms can be defined in
terms of instantiating functions 
definition   let p    x  d  f  a wcsp instance  f a function in f  xi a variable in
var f    and v a value in di   instantiating f with xi   v is a new function with scope
var f     xi   which returns for each tuple t  f  t   xi   v    instantiating p with xi   v is
a new problem p  xi  v    x   xi    d   di    f      where f   is obtained by instantiating all
the functions in f that mention xi with xi   v 
for instance  instantiating the problem of example   with x       produces a new
problem with three variables  xi   i   and three cost functions  f   x    x         x      
f   x    x      x  x  and f   x    x         x       figure   c shows the corresponding
constraint graph  obtained from the original graph by removing the instantiated variable x 
and all adjacent edges  observe that the new graph depends on the instantiated variable 
but does not depend on the value assigned to it 
search algorithms transform the current problem p into a set of subproblems  usually
it is done by selecting one variable xi which is instantiated with its different domain values
 p  xi  v    p  xi  v         p  xi  vd    this transformation is called branching  in each subproblem the same process is recursively applied  which defines a tree of subproblems  search
algorithms expand subproblems until a trivial case is achieved  there is no variable left  or
a pruning condition is detected  in optimization problems  pruning conditions are usually
defined in terms of lower and upper bounds  search keeps the cost of the best solution so
far  which is an upper bound of the optimal cost  at each node  a lower bound of the best
cost obtainable underneath is computed  if the lower bound is greater than or equal to the
upper bound  it is safe to backtrack 
the size of the search tree is o dn    being d the size of the largest domain  which bounds
the time complexity  if the tree is traversed depth first  the space complexity is polynomial 
   

fion the practical use of variable elimination

      clustering
a well known technique for constraint processing is clustering  dechter   pearl         it
merges several variables into one meta variable  while preserving the problem semantics 
clustering variables xi and xj produces meta variable xk   whose domain is di  dj   cost
functions must be accordingly clustered  for instance  in the problem of example    clustering variables x  and x  produces variable xc with domain dc                                    
cost functions f  and f  are clustered into fc  x    xc     f    f    with the new variable
notation fc   x  xc       x    xc      where xc  i  denotes the i th component of xc   function
f  needs to be reformulated as f   x    xc     x    xc      the constraint graph of the resulting
problem is obtained by merging the clustered variables and connecting the meta node with
all nodes that were adjacent to some of the clustered variables  figure   d shows the constraint graph after the clustering of x  and x    the typical use of clustering is to transform
a cyclic constraint graph into an acyclic one  which can be solved efficiently thereafter 
      variable elimination
variable elimination is based on the following two operations 
definition   the sum of two functions f and g  noted  f   g   is a new function with
scope var f    var g  which returns for each tuple the sum of costs of f and g 
 f   g  t    f  t    g t 
definition   the elimination of variable xi from f   noted f  xi   is a new function with
scope var f     xi   which returns for each tuple t the cost of the best extension of t to xi  
 f  xi   t    min  f  t   xi   a   
adi

observe that when f is a unary function  i e   arity one   eliminating the only variable
in its scope produces a constant 
definition   let p    x  d  f  be a wcsp instance  let xi  x be an arbitrary variable
and let bi be the set of all cost functions having xi in their scope  bi is called the bucket of
xi    we define gi as
x
gi    
f    xi
f bi

the elimination of xi transforms p into a new problem p xi    x   xi    d   di     f 
bi     gi     in words  p xi is obtained by replacing xi and all the functions in its bucket
by gi  
p and p xi have the same optimal cost because  by construction  gi compensates the
absence of xi   the constraint graph of p xi is obtained by forming a clique with all the
nodes adjacent to node xi and then removing xi and all its adjacent edges  for example 
eliminating x  in the problem of example   produces a new problem with three variables
 xi   i   and two cost functions  f  and g    the scope of g  is  x    x    and it is defined as 
   

filarrosa  morancho   niso

g     f    f     x     x    x    x    x     x    x    x    figure   d shows the constraint
graph after the elimination 
in the previous example  the new function g  could be expressed as a mathematical expression  unfortunately  in general  the result of summing functions or eliminating variables
cannot be expressed intensionally  and new cost functions must be stored extensionally in
tables  consequently  the space complexity of computing p xi is proportional to the numq
ber of entries of gi   which is    xj var gi    dj     since xj  var gi   iff xj is adjacent to xi
q
in the constraint graph  the previous expression can be rewritten as   xj n  i gp    dj    
where gp is the constraint graph of p and n  i  gp   is the set of neighbors of xi in gp  
the time complexity of computing p xi is its space complexity multiplied by the cost of
computing each entry of gi  
bucket elimination  be  works in two phases  in the first phase  it eliminates variables
one at a time in reverse order  in the elimination of xi   the new gi function is computed
and added to the corresponding bucket  the elimination of x  produces an empty scope
function  i e   a constant  which is the optimal cost of the problem  in the second phase  be
considers variables in increasing order and generates the optimal assignment of variables 
the time and space complexity of be is exponential on a structural parameter from the
constraint graph  called induced width  which captures the maximum arity among all the
gi functions  without any additional overhead be can also compute the number of optimal
solutions  see dechter        for details  
      super buckets
in some cases  it may be convenient to eliminate a set of variables simultaneously  dechter
  fatah         the elimination of the set of variables y is performed by collecting in by
the set of functions mentioning at least one variable of y   variables in y and functions in
by are replaced by a new function gy defined as 
gy    

x

f   y

f by

the set by is called a super bucket  note that the elimination of y can be seen as the
clustering of its variables into a meta variable xy followed by its elimination 
      mini buckets
when the space complexity of be is too high  an approximation  called mini buckets
 dechter   rish         can be used  consider the elimination of xi   with its associated
bucket bi    fi            fik    be would compute 
gi    

x

f    xi

f bi

the time and space complexity of this computation depends on the arity of gi   if it is beyond
our available resources  we can partition bucket bi into so called mini buckets bi            bik
where the number of variables in the scopes of each mini bucket is bounded by a parameter 
then we can compute 
x
gij    
f    xi   j      k
f bij

   

fion the practical use of variable elimination

 

 

 

 

 

 
 
 

 
 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

 
 

 

a

b

c

d

figure    a constraint graph and its evolution over a sequence of variable eliminations and
instantiations 

where each gij has a bounded arity  since 
gij

gi

zx   

 

f bi

 

f    xi 

k z x   
x

 

 

f    xi

j   f bij

the elimination of variables using mini buckets yields a lower bound of the actual optimal
cost 
      combining search and variable elimination
when plain be is too costly in space  we can combine it with search  larrosa   dechter 
       consider a wcsp whose constraint graph is depicted in figure   a  suppose that
we want to eliminate a variable but we do not want to compute and store constraints with
arity higher than two  then we can only take into consideration variables connected to at
most two variables  in the example  variable x  is the only one that can be selected  its
elimination transforms the problem into another one whose constraint graph is depicted in
figure   b  now x  has its degree decreased to two  so it can also be eliminated  the
new constraint graph is depicted in figure   c  at this point  every variable has degree
greater than two  so we switch to a search schema which selects a variable  say x    branches
over its values and produces a set of subproblems  one for each value in its domain  all of
them have the same constraint graph  depicted in figure   d  for each subproblem  it is
possible to eliminate variable x  and x    after their elimination it is possible to eliminate
x  and x    and subsequently x  and x    eliminations after branching have to be done at
every subproblem since the new constraints with which the eliminated variables are replaced
differ from one subproblem to another  in the example  only one branching has been made 
therefore  the elimination of variables has reduced the search tree size from d  to d  where
d is the size of the domains  in the example  we bounded the arity of the new constraints
to two  but it can be generalized to an arbitrary value 

   solving still life with variable elimination
sl n  can be easily formulated as a wcsp  the most natural formulation associates one
variable xij with each cell  i  j   each variable has two domain values  if xij     the cell is
   

filarrosa  morancho   niso

x 
j  

j  

j

i  

j  

j  

x 

i  

x 

i

x 

i  

x 

i   

x 

b

a

figure    a  structure of the constraint graph of sl n   the node in the center  associated
to cell  i  j   is linked to all cells it interacts with  the shadowed area indicates
the scope of fij   b  left   constraint graph of sl    after clustering cells into
row variables  b  from left to right  evolution of the constraint graph during the
execution of be 

dead  if xij     it is alive  there is a cost function fij for each variable xij   the scope of
fij is xij and all its neighbors  it evaluates the stability of xij   if xij is unstable given its
neighbors  fij returns   else fij returns    xij    the objective function to be minimized
is 
f  

n x
n
x

fij

i   j  

if the instantiation x represents an unstable pattern  f  x  returns   else it returns the
number of dead cells  fij can be stored as a table with    entries and evaluated in constant
time 
figure   a illustrates the structure of the constraint graph of sl n   the picture shows
an arbitrary node xij linked to all the nodes it interacts with  for instance  there is an edge
between xij and xi j   because xi j   is a neighbor of xij in the grid and  consequently 
both variables are in the scope of fij   there is an edge between xij and xi  j  because
both cells are neighbors of xi  j  in the grid and  therefore  both appear in the scope of
fi  j    the shadowed area represents the scope of fij  namely  xij and all its neighbors  
the complete graph is obtained by extending this connectivity pattern to all nodes in the
graph 
for the sake of clarity  we use an equivalent but more compact sl n  formulation
that makes be easier to describe and implement  we cluster all variables of each row
into a single meta variable  thus  xi denotes the state of cells in the i th row  namely 
xi    xi    xi            xin   with xij           accordingly  it takes values over the sequences of
n bits or  equivalently  over the natural numbers in the interval      n      cost functions
are accordingly clustered  there is a cost function fi associated with each row i  defined as 
fi  

n
x

fij

j  

   recall that  as a wcsp  the task is to minimize the number of dead cells  therefore  we give cost   to
dead cells and cost   to living cells 

   

fion the practical use of variable elimination

for internal rows  the scope of fi is  xi    xi   xi      the cost function of the top row  f   
has scope  x    x     the cost function of the bottom row  fn   has scope  xn    xn    if there
is some unstable cell in xi   fi  xi    xi   xi         else  it returns the number of dead cells
in xi   evaluating fi is  n  because all the bits of the arguments need to be checked  the
new  equivalent  objective function is 
f  

n
x

fi

i  

figure   b  left  shows the constraint graph of sl    with this formulation  an arbitrary
variable xi is connected with the two variables above and the two variables below  the
sequential structure of the constraint graph makes be very intuitive  it eliminates variables
in decreasing orders  the elimination of xi produces a new function gi    fi    gi      xi
with scope  xi    xi     figure   b  from left to right  shows the evolution of the constraint
graph along the elimination of its variables  formally  be applies a recursion that transforms
subproblem p into p xi   where xi is the variable in p with the highest index  it satisfies
the following property 
property   let gi be the function added by be to replace xi   then gi  a  b  is the cost of
the best extension of  xi    a  xi    b  to the eliminated variables  xi           xn    formally 
gi  a  b   

min

vi di      vn dn

 fi   a  b  vi     fi  b  vi   vi      

 fi    vi   vi     vi            
 fn   vn    vn    vn     fn  vn    vn   
if gi  a  b      it means that the pattern a  b cannot be extended to the inferior rows
with a stable pattern  if gi  a  b    k  with k       it means that a  b can be extended and
the optimal extension has k dead cells from xi  to xn  
the space complexity of be  n    n    due to the space required to store n functions
gi extensionally   n   n entries each   regarding time  computing each entry of gi has
cost  n   n    finding the minimum of  n alternatives  the computation of each one is
 n    since each gi has   n entries  the total time complexity is  n     n    observe that
solving sl n  with be is an exponential improvement over search algorithms  which have
 
time complexity o  n   
table   reports some empirical results  they were obtained with a   ghz pentium iv
machine with   gb of memory  the first columns reports the problem size  the second
reports the optimal cost as the number of dead cells  in parenthesis  the number of living
cells   the third column reports the number of optimal solutions  we count as different
two solutions even if one can be transformed to the other through a problem symmetry 
the fourth column reports the cpu time of be in seconds  the fifth  sixth and seventh
columns report the results obtained with the three approaches tried by bosch and trick
         constraint programming  cp   integer programming  ip   and a more sophisticated
algorithm  cp ip  which combines cp and ip  and exploits the problem symmetries 
   the corresponding opl code is available at http   mat gsia cmu edu life 

   

filarrosa  morancho   niso

n
 
 
 
 
 
  
  
  
  
  
  

opt
     
      
      
      
      
      
      
      
      
       
        

n  sol 
 
  
 
 
  
    
  
      
    
  
 

be
 
 
 
 
 
  
   
    
     
   
 

cp
 
 
 
  
     
 
 
 
 
 
 

ip
 
 
 
  
     
 
 
 
 
 
 

cp ip
 
 
 
 
  
  
   
     
     
      
      

figure    experimental results of four different algorithms on the still life problem  times
are in seconds 

it can be observed that be clearly outperforms cp and ip by orders of magnitude 
the n      case is the largest instance that we could solve due to exhausting the available
space  comparing be with cp ip  we observe that there is no clear winner  an additional
observation is that be scales up very regularly  each execution requiring roughly eight times
more time and four times more space than the previous  which is in clear accordance with
the algorithm complexity 

   combining search and variable elimination
one way to overcome the high space complexity of be is to combine search and variable
elimination in a hybrid approach hyb  larrosa   schiex         the idea is to use search
 i e  instantiations  in order to break the problem into independent smaller parts where
variable elimination can be efficiently performed 
let us reformulate the problem in a more convenient way for the hybrid algorithm  for
the sake of simplicity and without loss of generality consider that n is even  we cluster
r
row variables into three meta variables  xc
i denotes the two central cells of row i  xi and
n
l
xi denote the      remaining cells on the right and left  respectively  see figure   a  
l
r
consequently  xc
i takes values in the range         xi and xi take values in the range
n
 
             cost functions are accordingly clustered 
n

fil

 

 
x

fir  

fij  

n
x
j  n
  
 

j  

the new  equivalent  objective function is 
f  

n
x

 fil   fir  

i  

   

fij

fion the practical use of variable elimination

left

x

l
 

center

x

c
 

right

x

left

r
 

center

right

x 

x 

x 
x

l
i

x

c
i

x

r
i

x 

x

l
n

x

c
n

x

x 

r
n

x 

b

a
left

center

right

left

center

right

x 
x 
x 
x 
x 
x 
x 
x 
x 
x 
x 
x 
c

d

figure    formulation of sl n  used by the hybrid algorithm  a  each row is clustered
into three variables  b  constraint graph of sl     c  constraint graph after
c
c
the assignment of xc
n   xn  and xn    d  constraint graph after the elimination
l
r
of xn and xn  

   

filarrosa  morancho   niso

c
l c
l
c
the scopes of internal row functions  fil and fir   are  xl
i    xi    xi   xi   xi     xi     and
c
r
c
r
c
r
l
r
l
c
c
 xi    xi    xi   xi   xi     xi      top functions f  and f  have scopes  x    x    xl
    x   
r c
r
l
r
l
c
l c
and  xc
    x    x    x     bottom functions fn and fn have scopes  xn    xn    xn   xn   and
r
c
r
c
 xn    xn    xn   xn    figure   b shows the corresponding constraint graph  the imporr
tance of this formulation is that xl
i and xi are independent  i e  there is no edge in the
constraint graph connecting left and right variables  

the hybrid algorithm hyb searches over the central variables and eliminates the lateral
variables  variables are considered in decreasing order of their index  thus  the algorithm
c
c
starts instantiating xc
n   xn  and xn    which produces a subproblem with the constraint
r
graph shown in figure   c  observe that variable xl
n  respectively  xn   is only connected
l
l
r
r
with variables xn  and xn   respectively  xn  and xn     then it is eliminated producing
l
r
r
r
a new function gnl with scope  xl
n    xn     respectively  gn with scope  xn    xn     
figure   d shows the resulting constraint graph  lateral variables have domains of size
n
n
        hence  their elimination is space   n   and time          it is important to note that
c
c
these eliminations are subject to the current assignment of xc
n   xn  and xn    therefore 
they have to be recomputed when their value change  after the elimination of xl
n and
c
xr
 
the
algorithm
would
assign
variable
x
which
will
make
possible
the
elimination
of
n
n 
l
r
c
xn  and xn    and so on  at an arbitrary level of search  the algorithm assigns xi   which
r
makes xl
i   and xi   independent of the central columns and only related to their two
l and
variables above  then  it eliminates them by replacing the variables by functions gi  
r with scopes  xl   xl   and  xr   xr    respectively  formally  hyb applies a recursion
gi  
i
i  
i
i  
that transforms subproblem p into   simpler subproblems    p  xc  v   xl   xr   v     it
i
i  
i  
satisfies the following property 

property   let gil be the function computed by hyb used to replace variable xl
i   then
l
gil  a  b  is the cost of the best extension of  xl
 
a 
x
 
b 
to
eliminated
variables
i 
i 
l
r
 xl
i           xn    conditioned to the current assignment  similarly  for the right side  gi  a  b 
r
r
r
is the cost of the best extension of  xi    a  xi    b  to eliminated variables  xi           xr
n   
conditioned to the current assignment 

l  a  b  among all coma consequence of the previous property is that the minimum gi  
binations of a and b is a lower bound of the best cost that can be obtained in the left
l  a  b    
part of the grid if we continue the current line of search  therefore  mina b  gi  
r
mina b  gi    a  b   is a valid lower bound of the current node and can be used for pruning
purposes 

the space complexity of the algorithm is  n   n    due to the gil and gir functions
which need to be explicitly stored  the time complexity is o n      n    because o  n  
nodes may be visited  n variables with domains of size    and the cost of processing each
n
node is  n         due to the variable eliminations 
thus  comparing with be  the time complexity increases from  n    n   to o n    n   
this is the prize hyb pays for the space decrement from  n    n   to  n   n   
   

fion the practical use of variable elimination

    refining the lower bound
it is well known that the average case efficiency of search algorithms depends greatly on
the lower bound that they use  our algorithm is using a poor lower bound based on the gil
and gir functions  only 
kask and dechter        proposed a general method to incorporate information from
yet unprocessed variables into the lower bound  roughly  the idea is to run mini buckets
 mb  prior search and save intermediate functions for future use  mb is executed using the
reverse order in which search will instantiate the variables  when the execution of mb is
completed  the search algorithm is executed  at each node  it uses mini bucket functions
as compiled look ahead information  in this subsection  we show how we have adapted this
idea to sl n  and how we have integrated it into hyb 
c
r
consider sl n  formulated in terms of left  central and right variables  xl
i   xi   xi   
l
c
r
the exact elimination of the first row variables  x    x    x    can be done using super bucket
b     f l   f r   f l   f r   and computing the function 
c
r
h     f l   f r   f l   f r     xl
    x    x   
c
r l c
r
the scope of h  is  xl
    x    x    x    x    x     using the mini buckets idea  we partition the
l
l
l
r
bucket into b     f    f    and b     f r   f r    then  we approximate h  by two smaller
r
functions hl
  and h   
l
l
l c
hl
     f    f      x    x   
r
r
c
r
hr
     f    f      x    x   
r
l c
l c
c
r c
r
the scopes of hl
  and h  are  x    x    x    x    and  x    x    x    x     respectively  the same
idea is repeated row by row in increasing order  in general  processing row i  yields two
functions 
l
l
l c
hl
i    hi    fi       xi   xi  
r
r
c
r
hr
i    hi    fi       xi   xi  
r
l
c
l
c
c
r
c
r
the scopes of hl
i and hi are  xi     xi     xi     xi     and  xi     xi     xi     xi      respecl
 
 
tively  by construction  hi  a  a   b  b   contains the cost of the best extension of a  a    b  b 
c
l c
to processed variables xl
i   xi           x    x  considering left functions only  we have the same
 
 
property for hr
i  a   a  b   b  and right functions 
the complexity of mb is space  n n   and time  n      n    since these complexities
are smaller than the complexity of hyb  running this pre process does not affect its overall
complexity 
r
after mb is executed  hyb can use the information recorded in the hl
i and hi functions 
l
r
consider an arbitrary node in which hyb assigns xc
i and eliminates xi   and xi     let a
l
l
l  a  b 
and b be domain values of variables xi and xi     from property   we have that gi  
contains the best extension of a  b that can be attained in the left part of rows i    
to n as long as the current assignment x c is maintained  additionally  we have that
c
c
hl
i   a  xi   b  xi     contains the best extension of a  b that can be attained in the left part
l  a  b    hl  a  xc   b  xc   is a lower bound for a  b and x c
of rows i to    therefore  gi  
i 
i
i  
of the left part of the grid  consequently 
l
c
c
mina b      n        gi  
 a  b    hl
i   a  xi   b  xi     

   

filarrosa  morancho   niso

is a lower bound of the left part of the grid for the current assignment  with the same
reasoning on the right part we have that 
l
c
c
mina b      n        gi  
 a  b    hl
i   a  xi   b  xi       
r
c
c
 mina b      n        gi  
 a  b    hr
i   xi   a  xi     b  

is a lower bound of the current assignment 
    refining the upper bound
the efficiency of the algorithm also depends on the initial value of the upper bound  a
good upper bound facilitates pruning earlier in the search tree  bosch and trick       
suggested to modify sl n  by adding the additional constraint of considering symmetric
patterns  only  since the space of solutions becomes considerably smaller  the problem is
presumably simpler  clearly  the cost of an optimal symmetric stable pattern is an upper
bound of the optimal cost of sl n   it has been observed that such upper bounds are very
tight 
since the motivation of our work is to use variable elimination techniques  we have
considered still lifes which are symmetric over a vertical reflection  because they can be
efficiently solved using be  the symmetric still life problem ssl n  consists on finding a
n  n stable pattern of maximum density in the game of life subject to a vertical reflection
symmetry  namely  the state of cells  i  j  and  i  n  j      must be the same  
adapting be to solve ssl n  is extremely simple  we only need to remove symmetrical
values from the domains  let us assume that n is an even number  the odd case is similar  
we represent a symmetric sequences of bits of length n by considering the left side of the
sequence  i e  the first n   bits   the right part is implicit in the left part  thus  we
n
represent symmetrical sequences of n bits as integers in the interval              reversing a
sequence of bits a is noted a  hence  if a is a sequence of n   bits  a  a is the corresponding
symmetrical sequence of n bits 
the complexity of be  when applied to ssl n  is time  n      n   and space  n n   
therefore  executing it prior hyb and setting the upper bound with its optimal cost does
not affect the overall complexity of the hybrid 
    further exploitation of symmetries
sl n  is a highly symmetric problem  for any stable pattern  it is possible to create an
equivalent pattern by   i  rotating the board by         or     degrees   ii  reflecting
the board horizontally  vertically or along one diagonal or  iii  doing any combination of
rotations and reflections 
symmetries can be exploited at very different algorithmic levels  in general  we can
save any computation whose outcome is equivalent to a previous computation due to a
symmetry if we have kept its outcome  for instance  in mb it is not necessary to compute
 
 
l
 
 
hr
i  a   a  b   b  because it is equal to hi  a  a   b  b   due to the vertical reflection symmetry 
c
c
another example occurs in hyb  let xn   vn   xc
n    vn            xi   vi be the current
   unlike smiths        work we cannot easily exploit a larger variety of symmetries such as rotations and
diagonal reflections 

   

fion the practical use of variable elimination

n
  
  
  
  
  
  
  
  
  
  
  
  

opt
      
       
        
        
        
        
        
        
 
 
 
 

opt ssl
  
  
   
   
   
   
   
   
   
   
   
   

cp ip
     
      
      
 
 
 
 
 
 
 
 
 

be
     
   
 
 
 
 
 
 
 
 
 
 

hyb
 
 
  
 
    
    
     
      
 
 
 
 

hyb no lb
    
    
      
      
 
 
 
 
 
 
 
 

hyb no ub
 
 
  
  
    
    
     
      
 
 
 
 

figure    experimental results of three different algorithms on the still life problem  times
are in seconds 

c
c
assignment  the reversed assignment xc
n   vn   xn    vn            xi   vi is equivalent due
to the vertical reflection symmetry  thus  if it has already been considered  the algorithm
can backtrack  our implementation uses these tricks and some others which we do not
report because it would require a much lower level description of the algorithms 

   experimental results
figure   shows the empirical performance of our hybrid algorithm  the first column contains
the problem size  the second column contains the optimal value as the number of dead
cells  in parenthesis the corresponding number of living cells   the third column contains
the optimal value of the symmetrical problem ssl n   obtained by executing be  it can
be observed that ssl n  provides very tight upper bounds to sl n   the fourth column
reports the time obtained with the cp ip algorithm  bosch   trick         the fifth
column reports times obtained with be  the sixth column contains times obtained with
our hybrid algorithm hyb  as it can be seen  the performance of hyb is spectacular  the
n      and n      instances  which require several days of cpu  are solved by hyb in a few
seconds  instances up to n      are solved in less than one hour  the largest instance that
we can solve is n       which requires about two days of cpu  figure   shows the optimal
n      and n      still lifes   regarding space  our computer can handle executions of
hyb up to n       however  neither the n      nor the n      instance could be solved
within a week of cpu  it may seem that solving the n      instance is a petty progress with
respect previous results on the problem  this is clearly not the case  the search space of
 
 
the n      and n      instances have size            and              respectively  thus 
we have been able to solve a problem with a search space      times larger than before 
since be scales up very regularly  we can accurately predict that it would require      gb
of memory and about   centuries to solve the n      instance 
   

filarrosa  morancho   niso

figure    maximum density still lifes for n      and n      

since hyb combines several techniques  it is interesting to assess the impact of each
one  the seventh column reports times obtained with hyb without using mini buckets
information in the lower bound  as can be seen  the algorithm is still better than plain be 
but it performance is dramatically affected  the information gathered during the preprocess
improves the quality of the lower bound and anticipates pruning  finally  the eighth column
reports times obtained with hyb without having the upper bound initialized to ssl n  
in this case we see that the importance of this technique is quite limited  the reason is
that hyb  even with a bad initial upper bound  finds the optimum very rapidly and  after
that moment  the quality of the initial upper bound becomes irrelevant 

   extension to other domains
the sl n  problem has a very well defined structure  and the hybrid algorithm that we
have proposed makes an ad hoc exploitation of it  it is easy to find the right variables to
instantiate and eliminate  it is also easy to find a variable order for which mini buckets
produces good quality lower bounds  a natural question is whether it is possible to apply
similar ideas to not so well structured problems  the answer is that it is often possible 
although we need to rely on more naive and consequently less efficient exploitation of the
problems structure  in this section we support our claim by reporting additional experimental results on different benchmarks  in particular  we consider spot  and dimacs
instances  spot  instances are optimization problems taken from the scheduling of an earth
observation satellite  bensana  lemaitre    verfaillie         the dimacs benchmark contains sat instances from several domain  since we are concerned with optimization tasks 
we have selected some unsatisfiable instances and solved the max sat task  i e  given an
unsatisfiable sat instance  find the maximum number of clauses that can be simultaneously
satisfied   which can be modeled as a wcsp  de givry  larrosa  meseguer    schiex        
we consider aim instances  artificially generated random   sat   pret  graph coloring   ssa
and bf  circuit fault analysis  
figure   shows the constraint graph of one instance of each domain  as visualized by
leda graph editor  it can be observed that these graphs do not have an obvious pattern
   

fion the practical use of variable elimination

figure    constraint graph of four wcsp instances  from the top left corner  clockwise 
aim         no    pret       ssa         and spot      

to be exploited  thus  we have to use variable elimination techniques in a more naive way 
we solve the problems with the generic wcsp solver toolbar   tb   it performs a depthfirst branch and bound search and it is enhanced with general purpose dynamic variable and
value ordering heuristics  we modified toolbar to combine search and variable elimination
as follows  at an arbitrary subproblem  every variable with degree less than   is eliminated 
only when all the variables have degree larger than or equal to    an unassigned variable is
heuristically selected and each of its domain values are heuristically ordered and sequentially
instantiated  the process is recursively applied to each of the subproblems  note that
this is a generic version of the hyb algorithm where the decision of which variables are
instantiated and which variables are eliminated is left to a heuristic  instead of establishing
   available at http   carlit toulouse inra fr cgi bin awki cgi softcsp 

   

filarrosa  morancho   niso

it by hand  we will refer to this implementation as tbhy b   toolbar offers a variety
of lower bounds based on different forms of local consistency  larrosa   schiex        
one of them  directional arc consistency  dac    is essentially equivalent to mini buckets
of size   and  therefore  similar in spirit to the lower bound computed by hyb  however 
unlike hyb where mini buckets are executed only once as a pre process  toolbar executes
dac  at every search state  subject to the current subproblem  it has been shown by kask
       that this approach is generally more efficient  the other main difference with respect
hyb  is that toolbar executes dac  subject to an arbitrary variable ordering  in hyb
a good order was identified from the problem structure   other lower bounds available
in toolbar are node consistency  nc   which is weaker than dac   and full directional
arc consistency  fdac   which can be seen as a  stronger  refinement of dac   we have
f dac
b
experimented with four algorithms  tbn c   tbdac   tbdac
hy b and tbhy b   where a
denotes algorithm a with lower bound b 
most spot  instances are too difficult for toolbar  therefore  we decreased their size
by letting toolbar make a sequence of k greedy assignments driven by its default variable
and value ordering heuristics  the result is a subproblem with k less variables  in the
following  ik denotes instance i where k variables have been greedily assigned by toolbar
with default parameters 
table   reports the result of these experiments  the first column indicates the instances
and subsequent columns indicate the cpu time  in seconds  required by the different algorithms  a time limit of      seconds was set up for each execution  it can be observed that
toolbar with the weakest lower bound  tbn c   is usually the most inefficient alternative 
it cannot solve any of the spot  instances and also fails with several aim and ssa instances 
when toolbar is enhanced with a mini buckets lower bound  tbdac   all spot  problems
are solved  in the other domains  the new lower bound does not produce a significant effect  when we further add variable elimination  tbdac
hy b   all the problems are solved  in
general  there is a clear speed up  the worst improvements are in the pret instances where
the time is divided by a factor of   and the best ones are obtained in the spot        and
ssa         instances which are solved instantly  typical speed ups range from   to    
dac   has a limited
finally  we observe that the addition of the stronger lower bound  tbfhy
b
effect in these problems  only the execution of instance ssa         is clearly accelerated 
therefore  from these experiments we can conclude that the main techniques that we used
to solve the still life problem can also be successfully applied to other domains 

   conclusions
in this paper we have studied the applicability of variable elimination to the problem of
finding still lifes  finding still lifes is a challenging problem and developing new solving
techniques is an interesting task per se  thus  the first contribution of this paper is the
observation that plain variable elimination  i e  be  is competitive in practice and provides
time complexity exponentially better than search based approaches  besides  we have developed an algorithm with which we have been able to solve up to the n      instance 
with which we clearly improved previous results  the second contribution of the paper
has a deeper insight  our algorithm uses recent techniques based on variable elimination 
since these techniques are little known and rarely applied in the constraints community 
   

fion the practical use of variable elimination

problem
spot      
spot        
spot        
spot        
spot       
spot        
spot        
spot        
aim         no  
aim         no  
aim         no  
aim         no  
aim         no  
aim         no  
aim         no  
aim         no  
bf        
pret     
pret     
ssa        
ssa        
ssa        
ssa        

t bn c
    
    
    
    
   
   
  
 

t bdac
   
   
   
    
   
    
   
   
    
   
   
    
   
   
  
 

dac
t bhy
b
  
  
  
   
 
  
  
   
    
   
    
    
   
   
   
   
    
  
  
 
   
  
 

f dac
t bhy
b
  
  
  
   
 
  
  
   
    
   
    
    
   
   
   
   
    
  
  
 
   
 
 

figure    experimental results in some wcsp instances with four different algorithms 
each column reports cpu time in seconds  symbol   indicates that a time limit
of      seconds has been reached 

the results presented in this paper add new evidence of their potential  we have also shown
that variable elimination can be used beyond the academic still life problem by providing
experimental results in some unstructured realistic problems from different domains 

acknowledgments
the authors are grateful to barbara smith  neil yorke smith and the anonymous reviewers
for their useful comments at different stages of the work reported in this article  marti
sanchez kindly made the plots in figure    this research has been funded by the spanish
cicyt under project tic           c      

references
bensana  e   lemaitre  m     verfaillie  g          earth observation satellite management 
constraints               
bertele  u     brioschi  f          nonserial dynamic programming  academic press 
   

filarrosa  morancho   niso

bistarelli  s   montanari  u     rossi  f          semiring based constraint satisfaction and
optimization  journal of the acm                 
bosch  r     trick  m          constraint programming and hybrid formulations for three
life designs  in proceedings of the international workshop on integration of ai and
or techniques in constraint programming for combinatorial optimization problems 
cp ai or    pp       
cabon  b   de givry  s   lobjois  l   schiex  t     warners  j          radio link frequency
assignment  constraints          
de givry  s   larrosa  j   meseguer  p     schiex  t          solving max sat as weighted
csp  in proc  of the  th cp  pp          kinsale  ireland  lncs       springer
verlag 
dechter  r          bucket elimination  a unifying framework for reasoning  artificial
intelligence            
dechter  r     pearl  j          tree clustering for constraint networks  artificial intelligence             
dechter  r     fatah  y  e          topological parameters for time space tradeoff  artificial
intelligence                  
dechter  r     rish  i          mini buckets  a general scheme for bounded inference 
journal of the acm                 
gardner  m          the fantastic combinations of john conways new solitary game  scientific american              
kask  k          new search heuristics for max csp  in proc  of the  th cp  pp         
singapore  lncs       springer verlag 
kask  k     dechter  r          a general scheme for automatic generation of search
heuristics from specification dependencies  artificial intelligence             
larrosa  j     dechter  r          boosting search with variable elimination in constraint
optimization and constraint satisfaction problems  constraints                
larrosa  j     schiex  t          in the quest of the best form of local consistency for
weighted csp  in proc  of the   th ijcai  acapulco  mexico 
pearl  j          probabilistic inference in intelligent systems  networks of plausible inference  morgan kaufmann  san mateo  ca 
sandholm  t          an algorithm for optimal winner determination in combinatorial
auctions  in ijcai     pp         
smith  b          a dual graph translation of a problem in life  in proc  of cp       pp 
    ithaca  usa  lncs  springer verlag 

   

fi