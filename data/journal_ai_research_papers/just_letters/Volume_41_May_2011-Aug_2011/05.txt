journal of artificial intelligence research                  

submitted        published      

analyzing search topology without running any search 
on the connection between causal graphs and h 
jorg hoffmann

joerg hoffmann inria fr

inria
nancy  france

abstract
the ignoring delete lists relaxation is of paramount importance for both satisficing and
optimal planning  in earlier work  it was observed that the optimal relaxation heuristic
h  has amazing qualities in many classical planning benchmarks  in particular pertaining
to the complete absence of local minima  the proofs of this are hand made  raising the
question whether such proofs can be lead automatically by domain analysis techniques 
in contrast to earlier disappointing results  the analysis method has exponential runtime
and succeeds only in two extremely simple benchmark domains  we herein answer this
question in the affirmative  we establish connections between causal graph structure and
h  topology  this results in low order polynomial time analysis methods  implemented in
a tool we call torchlight  of the    domains where the absence of local minima has been
proved  torchlight gives strong success guarantees in   domains  empirically  its analysis
exhibits strong performance in a further   of these domains  plus in   more domains where
local minima may exist but are rare  in this way  torchlight can distinguish easy domains
from hard ones  by summarizing structural reasons for analysis failure  torchlight also
provides diagnostic output indicating domain aspects that may cause local minima 

   introduction
the ignoring delete lists relaxation has been since a decade  and still is  of paramount
importance for effective satisficing planning  e g   mcdermott        bonet   geffner       
hoffmann   nebel      a  gerevini  saetti    serina        helmert        richter  
westphal         more recently  heuristics making this relaxation have also been shown
to boost optimal planning  karpas   domshlak        helmert   domshlak         the
planners using the relaxation approximate  in a variety of ways  the optimal relaxation
heuristic h  which itself is np hard to compute  bylander         as was observed in
earlier work  hoffmann         h  has some rather amazing qualities in many classical
planning benchmarks  figure   gives an overview of these results  
the results divide domains into classes along two dimensions  we herein ignore the horizontal dimension  pertaining to dead ends  for which domain analysis is already available 
easy to test powerful criteria implying that a task is undirected harmless are known
 e g   hoffmann         the vertical dimension divides the domains into three classes  with
respect to the behavior of exit distance  defined as d    where d is the distance to a state
with strictly smaller h  value  in the easiest bottom class  there exist constant upper
   we omit adl domains  and we add the more recent ipc benchmarks elevators and transport  without
action costs   for which these properties are trivial to prove based on the earlier results  blocksworld arm
is the classical blocksworld  blocksworld noarm is a variant allowing to move a from b to c directly 
c
    
ai access foundation  all rights reserved 

fihoffmann

pipesworldtank
pipesworldnotank
psr

rovers
opticaltelegraph

mystery
mprime
freecell
airport

hanoi    
blocksworldnoarm    
grid    
transport    
bench ed    c

local minima ed    c

blocksworldarm
depots
driverlog

elevators      
logistics      
ferry      
gripper      
undirected

tyreworld      
satellite      
zenotravel      
miconicstrips      
movie      
simpletsp      
harmless

diningphil         

recognized

unrecognized

figure    overview of h  topology  hoffmann        
bounds on exit distance from both  states on local minima and states on benches  flat regions   in the figure  the bounds are given in square brackets  for example  in logistics 
the bound for local minima is    meaning that no local minima exist at all  and the bound
for benches is    in the middle class  a bound exists only for local minima  that bound is
   no local minima at all  for all domains shown  in the hardest top class  both local
minima and benches may take arbitrarily many steps to escape 
the proofs underlying figure   are hand made  for dealing with unseen domains 
the question arises whether we can design domain analysis methods leading such proofs
automatically  the potential uses of such analysis methods are manifold  we discuss this at
the end of the paper  for now  note that addressing this question is a formidable challenge 
we are trying to automatically infer properties characterizing the informativeness  or lack
thereof   of a heuristic function  we wish to do this based on a static analysis  not actually
running any search  formally characterizing the informativeness of a heuristic function
is  in most cases  hardly possible even for experienced researchers  which explains perhaps
why no one so far has even attempted to do it automatically  the single exception  to
the best of the authors knowledge  is an analysis method mentioned on the side in the
authors earlier work  hoffmann         this analysis method builds an exponentially
large tree structure summarizing all ways in which relaxed plans may generate facts  the
tree size  and therewith the analysis runtime  explodes quickly with task size  worse  the
analysis succeeds only in movie and simple tsp  arguably the two most simplistic planning
benchmarks in existence  
by contrast  the torchlight tool developed herein has low order polynomial runtime and
usually terminates in split seconds  distinguishing between global  per task  and local  per
state  analysis  it proves the global absence of local minima in movie  simple tsp  logistics 
and miconic strips  it gives a strong guarantee for local analysis  to succeed in every state
 in ferry  gripper  elevators  and transport  taking the success rate to be the fraction of
states for which local analysis succeeds  torchlight empirically exhibits strong performance
 delivering high success rates  also in zenotravel  satellite  tyreworld  grid  driverlog  and
   simple tsp encodes tsp but on a fully connected graph with uniform edge cost  the domain was
introduced by fox and long        as a benchmark for symmetry detection 

   

fianalyzing search topology without running any search

rovers  thus torchlights success rates tend to be high in the easy domains of figure   
while they are low in the hard ones  serving to automatically distinguish between these two
groups   by summarizing structural reasons for analysis failure  torchlight finally provides
diagnostic output indicating problematic aspects of the domain  i e   operator effects that
potentially cause local minima under h   
what is the key to this performance boost  consider logistics and blocksworld arm 
at the level of their pddl domain descriptions  the difference is not evident  both have
delete effects  so why do those in blocksworld arm hurt and those in logistics dont 
what does the trick is to move to the finite domain variable representation  e g   jonsson  
backstrom        helmert              and to consider the associated structures  notably
the causal graph  e g   knoblock        jonsson   backstrom        domshlak   dinitz 
      helmert        capturing the precondition and effect dependencies between variables 
the causal graph of blocksworld arm contains cycles  that of logistics doesnt  looking
into this  it was surprisingly easy to derive the following basic result 
if the causal graph is acyclic  and every variable transition is invertible 
then there are no local minima under h   
this result is certainly interesting in that  for the first time  it establishes a connection
between causal graph structure and h  topology  however  by itself the result is much
too weak for domain analysis  of the considered benchmarks  it applies only in logistics  we devise generalizations and approximations yielding the analysis results described
above  aside from their significance for domain analysis  our techniques are also interesting
with respect to research on causal graphs  whereas traditional methods  e g   jonsson  
backstrom        brafman   domshlak        jonsson        gimenez   jonsson      a 
seek execution paths solving the overall task  we seek only execution paths decreasing the
value of h    in local analysis  this enables us to consider only small fragments of the causal
graph  creating the potential to successfully analyze states in tasks whose causal graphs are
otherwise arbitrarily complex 
the next section gives a brief background on planning with finite domain variables  and
the associated notions such as causal graphs and the definition of h  and its topology  section   then gives an illustrative example explaining our basic result  and section   provides
a synopsis of our full technical results relating causal graphs and h  topology  sections  
and   present these results in some detail  explaining first how we can analyze a state s
provided we are given an optimal relaxed plan for s as the input  and thereafter providing
criteria on causal graph structure implying that such analysis will always succeed  we evaluate the domain analysis technique by proving a number of domain specific performance
guarantees in section    and reporting on a large scale experiment with torchlight in section    we point to related work within its context where appropriate  and discuss details
in section    we close the paper with a discussion of future work in section     to improve
readability  the main text omits many technical details and only outlines the proofs  the
full details including proofs are in appendix a 
   to some extent  this particular result can also be achieved by simpler means  limited search probing  
we discuss this along with the experiments in section   

   

fihoffmann

   background
we adopt the terminology and notation of helmert         with a number of modifications
suiting our purposes  a  finite domain variable  planning task is a   tuple  x  si   sg   o   x
is a finite set of variables  where each x  x is associated with a finite domain dx   a partial
state over x is a function s on a subset xs of x  so that s x   dx for all x  xs   s is a state
if xs   x  the initial state si is a state  the goal sg is a partial state  o is a finite set of
operators  each o  o is a pair o    preo   eff o   of partial states  called its precondition and
effect  as simple non restricting sanity conditions  we assume that  dx       for all x  x 
and preo  x     eff o  x  for all o  o and x  xpreo  xeff o  
we identify partial states with sets of variable value pairs  which we will often refer to
as facts  the state space s of the task is the directed graph whose vertices are all states over
x  with an arc  s  s    iff there exists o  o such that preo  s  eff o  s    and s x    s   x 
for all x  x   xeff o   a plan is a path in s leading from si to a state s with sg  s 
we next define the two basic structures in our analysis  domain transition graphs and
causal graphs  for the former  we diverge from helmerts definition  only  in that we
introduce additional notations indicating the operator responsible for the transition  as well
as the side effects of the transition  i e   any other variable values set when executing the
responsible operator  in detail  let x  x  the domain transition graph dt gx of x is the
labeled directed graph with vertex set dx and the following arcs  for each o  o where
x  xpreo  xeff o with c    preo  x  and c     eff o  x   dt gx contains an arc  c  c    labeled
with responsible operator rop c  c       o  with conditions cond c  c       preo     x  c    and
with side effects seff c  c       eff o     x  c      for each o  o where x  xeff o   xpreo with
c     eff o  x   for every c  dx with c    c    dt gx contains an arc  c  c    labeled with
rop c  c       o  cond c  c       preo   and seff c  c       eff o     x  c     
the reader familiar with causal graphs may have wondered why we introduced a notion
of side effects  seeing as causal graphs can be acyclic only if all operators are unary  affect
only a single variable   the reason is that we do handle cases where operators are nonunary  the variant of causal graphs we use can still be acyclic in such cases  and indeed this
happens in some of our benchmark domains  specifically in simple tsp  movie  miconicstrips  and satellite  we define the support graph sg to be the directed graph with vertex
set x  and with an arc  x  y  iff dt gy has a relevant transition  c  c    so that
s x  xcond c c     
 
 
here  a transition  c  c   on variable x is called relevant iff  x  c    sg  oo preo  
our definition modifies the most commonly used one in that it uses relevant transitions
only  and that it does not introduce arcs between variables co occurring in the same operator
effect  unless these variables occur also in the precondition   transitions with side effects
are handled separately in our analysis  note that irrelevant transitions occur naturally  in
domains with non unary operators  for example  unstacking a block induces the irrelevant
transition making the arm non empty  and departing a passenger in miconic strips makes
the passenger not boarded  
consider now the definition of h    in the more common boolean variable setting of
pddl  this is defined as the length of a shortest plan solving the problem when ignoring
   we remark that relevant transitions correspond to what has been called requestable values in some
works   e g   jonsson   backstrom        haslum         in fast downwards implementation  the
causal graph includes only precondition effect arcs  similarly as the support graph defined here 

   

fianalyzing search topology without running any search

all delete lists  i e   the negative operator effects  bylander        mcdermott        bonet
  geffner         this raises the question what h  actually is  in finite domain variable
planning  where there are no delete lists  that question is easily answered  ignoring
deletes essentially means to act as if what was true once will remain true forever  in
the finite domain variable setting  this simply means to not over write any values that
the variables had previously  to our knowledge  this generalization was first described by
helmert         consider the directed graph s   whose vertices are all sets s  of variable 
 
value pairs over x  with an arc  s 
    s    iff there exists o  o such that preo  s  and
 
 
 
s    s   eff o   if s is a state  then a relaxed plan for s is a path in s leading from
s to s  with sg  s    by h   s  we denote the length of a shortest relaxed plan for s 
or h   s     if no such plan exists  it is easy to see that this definition corresponds to
the common boolean one  if we translate the finite domain variables into boolean ones by
creating one boolean variable is  x  c  true  for every fact  x  c   then standard h  in the
boolean task is identical to h  in the finite domain variable task 
bylander        proved that it is intractable to compute h    many state of the art
planners approximate h    in a variety of ways  e g   mcdermott        bonet   geffner 
      hoffmann   nebel      a  gerevini et al         helmert        richter  helmert 
  westphal        richter   westphal         a popular approximation in satisficing
planning  that gives no guarantees on the quality of the relaxed plan returned  is the
so called relaxed plan heuristic first proposed in the ff system  hoffmann   nebel      a  
which approximates h  in terms of the length of some not necessarily shortest relaxed plan 
such relaxed plans can be computed in low order polynomial time using techniques inspired
by graphplan  blum   furst        
we next introduce the relevant notations pertaining to search space topology under h   
let s  s be a state where     h   s      then an exit is a state s  reachable from s
in s  so that h   s      h   s  and there exists a neighbor s   of s  so that h   s       h   s   
 and thus h   s       h   s    the exit distance ed s  of s is the length of a shortest path to
an exit  or ed s     if no exit exists  a path in s is called monotone iff there exist no
two consecutive states s  and s  on it so that h   s      h   s     we say that s is a local
minimum if there exists no monotone path to an exit 
the topology definitions  adapted from the authors previous work  hoffmann        
are specific to h  only for the sake of simplicity  we will herein not consider any heuristics
other than h      states with infinite heuristic value are ignored because they are correctly
identified  by the heuristic  to be dead ends  relaxed plan based approximations like that
of ff do identify all these cases   if the heuristic value is   then we have already reached
the goal  so this case can also be safely ignored  note that we do not force exit paths to
be monotone  i e   we will also talk about exit distances in situations where s may be a
local minimum  this is necessary to capture the structure of domains like satellite and
zenotravel  where local minima exist but their exit distance is bounded  also  some of our
analysis methods guarantee an upper bound on the length of an exit path only  not that
the heuristic values on that path will decrease monotonically 
   we remark that the original definitions are significantly more involved  e g   defining local minima not
based on individual states but based on strongly connected sub graphs of the state space  none of these
complications is relevant to the results herein 

   

fihoffmann

finally  let us say a few words on domain analysis  generally speaking  domain analysis
aims at automatically obtaining non trivial information about a domain or planning task 
such analysis has a long tradition in planning  e g   nebel  dimopoulos    koehler       
fox   long        gerevini   schubert        edelkamp   helmert        rintanen 
       most often  the information sought pertains to reachability or relevance properties 
i e   which entities or combinations thereof are reachable from the initial state relevant to
the goal  a notable exception is the work of long and fox        which automatically
recognizes certain generic types of domains  like transportation  however  there exists no
prior work at all trying to automatically infer topological properties of a heuristic function 
the single exception are the aforementioned disappointing results reported  as an aside 
in the authors previous work  hoffmann         this method builds a structure called
fact generation tree  enumerating all ways in which facts may support each other in a
non redundant relaxed plan  if there is no conflict then h  is the exact solution distance 
clearly  this is a far too strong property to be applicable in any reasonably complex domain 
of the considered benchmarks  the property applies only in simple tsp  a slightly more
general property  also identified in this work  applies in movie as well as trivial logistics
tasks with   locations    truck  and   package 
it is worth noting that analyzing the topology of h  is computationally hard 
theorem    it is pspace complete to decide whether or not the state space of a given
planning task contains a local minimum  and given an integer k it is pspace complete to
decide whether or not for all states s we have ed s   k  further  it is pspace complete
to decide whether or not a given state s is a local minimum  and given an integer k it is
pspace complete to decide whether or not ed s   k 
these results are hardly surprising  but have not been stated anywhere yet  the membership results in theorem   are easy to prove based on guess and check arguments similar
as given by bylander         exploiting the fact that npspace pspace  the hardness results still hold when restricting the input to solvable tasks states  their proofs work
by reducing plan existence  respectively bounded plan existence  with a bound in non unary
representation   given a task whose plan existence we wish to decide  we flatten h  by a
new operator that can always achieve the goal but that has a fatal side effect  then we give
the planner the choice between solving this task  or solving a new alternative task  that latter task is designed so that a local minimum exists that the exit distance exceeds the bound
iff the planner must choose the alternative task  i e   iff the original task is unsolvable iff it
cannot be solved within a given number of steps  the full proof is in appendix a   
in practice  computational hardness here is particularly challenging because  in most
applications of domain analysis  we are not willing to run a worst case exponential search 
after all  the analysis will not actually solve the problem  consequently  in the present
research  we restrict ourselves to analysis methods with low order polynomial runtime 
the reader will have noticed the state specific analysis problems in theorem    we
distinguish between global analysis per task  and local analysis per state  more precisely 
we herein devise three kinds of analyses 
 i  guaranteed global analysis  taking as input the planning task description  this
analysis returns yes  d only if the state space does not contain any local minima
and the exit distance from any state is bounded by d 
   

fianalyzing search topology without running any search

 ii  guaranteed local analysis  taking as input the planning task description and a
state s  this analysis returns yes  d only if s is not a local minimum  and the exit
distance from s is bounded by d 
 iii  approximate local analysis  taking as input the planning task description and a
state s  this analysis returns yes  d to indicate that s is not a local minimum  and
that the exit distance from s is bounded by d  both may be wrong  i e   the analysis
is not guaranteed to be sound  compared to analysis  ii   this trades soundness for
the ability to successfully analyze more states 
domain analysis traditionally considers only the global variant  i   or even more generalizing
variants looking at only the pddl domain file  while global once and for all analysis is
also the holy grail in our work  local analysis has strong advantages  if a planning task
does contain local minima  which one would expect to typically be the case in interesting
domains  then analysis  i  is useless  it will simply answer no  by contrast  local analysis
 ii iii  may still detect some individual states  that we sample randomly in our experiments 
to not be local minima  the percentage of such states  which we refer to as the success rate 
can deliver useful information no matter what the structure of the planning task is  note
also that  while the contrast between a pspace hard problem and low order polynomial
analysis runtime necessarily implies that all analyses are incomplete  the local analyses have
a chance to ameliorate this by averaging their outcome over a set of sample states 

   an illustrative example
the basic connection we identify between causal graphs and h  topology  more precisely 
between support graphs  domain transition graphs  and h  topology  is quite simple  it
is instructive to understand this first  before delving into the full results  figure   shows
fragments of the domain transition graphs  dtgs  of three variables x    x    and x    all
dtg transitions here are assumed to be invertible  and to have no side effects 
t 

x 
g 
t 

t 

x 

l 

l 

l 

s  r 

r 

r 

x 
c 

c 

s 

figure    an example illustrating our basic result 
the imaginative reader is invited to think of x  as a car whose battery is currently
empty and that therefore requires the help of two people  x  and x    in order to push start
it  the people may  to solve different parts of the task  be required for other purposes too 
but here we consider only the sub problem of achieving the goal x    g    we wish to take
   

fihoffmann

the x  transition t    which has the two conditions c  and c    these conditions are currently
not fulfilled  in the state s at hand  x  is in s  and x  is in s    we must move to a different
state  s    in which x    c  and x    c    what will happen to h  along the way 
say that an optimal relaxed plan p    s  for s moves x  to c  along the path marked t   
and moves x  to c  along the path marked t   clearly  some such paths will have to be taken
by any p    s   key observation     is similar to a phenomenon known from transportation
benchmarks  when moving x  and x    whichever state s  we are in  as long as s  remains
within the boundaries of the values traversed by t  and t    we can construct a relaxed plan
p    s    for s  so that  p    s       p    s    namely  to obtain p    s     we simply replace the


respective move sequence 
o i in p    s   for i         with its inverse 
o i   for example  say


 
we got to s by o     hr   r   r i moving x  to c    as indicated in figure    then wlog
p    s  has the form hr   r   r i  p   we define p    s       hl   l   l i  p   the postfix p
of both relaxed plans is the same  at the end of the prefix  the set of values achieved for x   
namely s    c    and the two values in between  is also the same  thus p    s    is a relaxed

plan for s     this is true in general  i e   
o   is necessarily applicable in s    and will achieve 

 
 
within relaxed execution of p  s    the same set of facts as achieved by 
o   in p    s   thus
h   s     h   s  for any state s    including the state s  were after 
key observation     pertains to the leaf variable  x    say that x  moves only for its
own sake  i e   the car position is not important for any other goal  then executing t  in
s  does not delete anything needed anywhere else  thus we can remove rop t    from the
relaxed plan p    s    for s   constructed as per observation      to obtain a relaxed plan for
the state s  that results from executing t  in s    hence h   s      h   s   with observation
     the heuristic values along the path to s  are all  h   s   we know that at least one
state s   on the path has a heuristic value strictly smaller than h   s   this happens at the
latest in s     s    and may happen earlier on in case the relaxed plan p    s     as constructed
here is not optimal  cf  footnote     let s   be the earliest state with h   s       h   s  on
the path  and let s  be the state preceding s     then s  is an exit for s  and the path to that
exit is monotone  thus s is not a local minimum  as for the exit distance  in the worst
case we have s     s  and s    s    so ed s  is bounded by the length of the path up to s   
it is not difficult to imagine that the above works also if preconditions need to be
established recursively  as long as no cyclic dependencies exist  a third person may be
needed to first persuade x  and x    the third person may need to take a bus  and so on 
the length of the path to s  may grow exponentially  if x  depends on x  then each
move of x  may require several moves of x    and so forth  but we will still be able to
construct p    s    by inverting the moves of all variables individually  further  the inverting
transitions may have conditions  too  provided these conditions are the same as required
by the original moves  for example  in the above  the inverting operator l  may have an
arbitrary condition p if that condition is also required for r    this is because any conditions
that are required for the original moves  like p for r    are established in p    s   and thus
will be established in p    s    in time for the inverse moves  like l    
   note that p    s    may not be an optimal relaxed plan for s    if p    s  does not move x  for anything
other than attaining c    then the postfix p alone is a relaxed plan for s    there is no need to insert the
inverted prefix hl   l   l i  in cases like this  we obtain an exit state already on the path to s    we get
back to this below 

   

fianalyzing search topology without running any search

now  say that the support graph is acyclic  and that all transitions are invertible and
have no side effects  given any state s  unless s is already a goal state  some variable x 
moving only for its own sake necessarily exists  but then  within any optimal relaxed plan
for s  a situation as above exists  and therefore we have a monotone exit path  q e d  for
no local minima under h   
the execution path construction just discussed is not so different from known results
exploiting causal graph acyclicity and notions of connectedness or invertibility of domain
transition graphs  e g   jonsson   backstrom        williams   nayak         what is
new here is the connection to h   
we remark that the hand made analysis of h   hoffmann        uses a notion of operators respected by the relaxation  an operator o is respected by the relaxation iff 
whenever o starts an optimal plan for s  then o also starts an optimal relaxed plan for s  a
core property of many of the hand made proofs is that all operators are respected by the
relaxation  this motivated the speculation that recognizing this property automatically
could be key to domain analysis recognizing the absence of local minima under h    we do
not explore this option herein  however we note that even the basic result we just outlined
contains cases not covered by this property  even with acyclic support graph and invertible
transitions without side effects  there are examples where an operator is not respected by
the relaxation  we give such a construction in example    appendix a   

   synopsis of technical results
our technical results in what follows are structured in a way similar to the proof argument
outlined in the previous section  the results are structured into two parts   a  and  b  
in  a   section    we identify circumstances under which we can deduce from an optimal
relaxed plan that a monotone exit path exists  in  b   section    we devise support graph
based sufficient criteria implying that analysis  a  will always succeed  technique  b 
underlies torchlights conservative analysis methods  i e   guaranteed global analysis  i 
and guaranteed local analysis  ii  as described at the end of section    by feeding technique
 a  with the usual relaxed plans as computed  e g   by ffs heuristic function  we obtain
torchlights approximate local analysis  iii   that analysis does not give a guarantee 
because  and only because  ffs relaxed plans are not guaranteed to be optimal 
for ease of reading  we now give a brief synopsis of the results obtained in  a  and
 b   and how they provide the analysis methods  i  iii   the synopsis contains sufficient
information to understand the rest of the paper  so the reader may choose to skip sections  
and    moving directly to the evaluation 
each analysis method is based on a particular kind of sub graph of the support graph 
table   overviews these  their role in parts  a  and  b  is as follows 
 a  given an optimal relaxed plan p    s  for a state s  an optimal rplan dependency graph
odg  is a sub graph of sg with a single leaf variable x  with transition t  as in our
example  rop t    will be frequently referred to as o     an arc  x  x    is in odg  if
p    s  relies on x  to achieve the conditions of t    and p    s  relies on x for moving x   
we say that odg  is successful if it is acyclic  all involved transitions will be usable in
our exit path construction  e g   they have no harmful side effects   and the deletes of t 
   

fihoffmann

name
support graph

symbol
sg

analysis

approximate
local analysis  iii 
theorem  

optimal rplan
dependency graph

odg 

local
dependency graph

ldg

guaranteed
local analysis  ii 
theorem  

global
dependency graph

gdg

guaranteed
global analysis  i 
theorem  

leaves
all
single leaf x  s t  applying
t  does not affect the
remainder of p    s 
single leaf x   xsg  
s x       sg  x    and x  has
no transitive sg successor
with same property
single leaf x   xsg

arcs
all
 x  x    where x is used in
p    s  to support x  for
obtaining cond t   
 x  x    where
s x     cond t    x   and
 x  x    where x  is in ldg
and  x  x    is in sg
 x  x    where x    x    and
 x  x    where x  is in gdg
and  x  x    is in sg

table    overview of the different support graph sub graphs underlying our results 
are either not relevant to p    s  at all  or are being recovered inside p    s   the main
result  theorem    states that s is no local minimum if there exists a successful odg 
for s  it also derives an exit distance bound from odg    approximating theorem  
by applying it to a relaxed plan as computed by ffs heuristic yields analysis  iii  
 b  given a state s  a local dependency graph ldg is a sub graph of sg with a single leaf
variable x    whose goal value is yet unachieved  and all of whose transitive successors
in sg have already attained their goal values  in this setting  x  moves for its own
sake as in the example  the graph ldg simply includes all sg predecessors of x    the
single exception pertaining to arcs  x  x    into x  itself  which are not inserted if the
corresponding condition of t  is already satisfied in s  we say that ldg is successful if
it is acyclic  all involved transitions will be usable in our exit path construction  and t 
does not have any relevant deletes  this implies that there exists a successful odg 
contained in ldg  and thus we have theorem    stating that s is no local minimum
and giving a corresponding exit distance bound  this result underlies analysis  ii  
a global dependency graph gdg is a sub graph of sg that identifies any goal variable
x    and includes all sg predecessors of x    being successful is defined in the same
way as for ldgs  if all gdgs are successful  then theorem   will apply to every state
because each ldg is contained in a successful gdg  thus we have theorem    stating
that the state space does not contain any local minima  the exit distance bound is
obtained by maximizing over all gdgs  this result underlies analysis  i  
for understanding the practical performance of torchlight  it is important to note that
 a  is not only a minimal result that would suffice to prove  b   the cases identified by
theorem   are much richer than what we can actually infer from support graphs  for this
reason  analysis  iii   while not sound due to the use of potentially non optimal relaxed
plans  is able to analyze a much larger class of states than analysis  ii   in a little detail 
the difference between the two methods pertains to     whether p    s  relies on values
of x for moving x    and     whether the deletes of t  are being recovered inside p    s  
neither     nor     are visible in the support graph  because both rely on details of the
form of the relaxed plan p    s   for example  consider the gripper domain  notion    
is important because the support graph contains the arcs  carry ball b  free gripper 
 due to dropping ball b  and  free gripper  carry ball b   due to picking up ball b 
thus  looking only at sg  it seems that carry ball b may support itself  free the gripper
   

fianalyzing search topology without running any search

by dropping the ball we want to pick up   of course  that doesnt happen in an optimal
relaxed plan  notion     is important because some operators  picking up a ball  do have
harmful side effects  making the gripper hand non empty   but these side effects are always
recovered inside the relaxed plan  when dropping the ball again later on   it remains future
work to extend analyses  i ii  so that they can detect these kinds of phenomenona 

   analyzing optimal relaxed plans
we consider a state s and an optimal relaxed plan p    s  for s  to describe the circumstances
under which a monotone exit path is guaranteed to exist  we will need a number of notations
pertaining to properties of transitions etc  we will introduce these notations along the way 
rather than up front  in the hope that this makes them easier to digest 
 
 
given o   p    s   by p  
 s  and p  
 s  we denote the parts of p    s  in front of o 
 
and behind o    respectively  by p  s  x  we denote the sub sequence of p    s  affecting
x  we capture the dependencies between the variables used in p    s  for achieving the
precondition of o    as follows 
definition    let  x  si   sg   o  be a planning task  let s  s with     h   s      let
p    s  be an optimal relaxed plan for s  let x   x  and let o   p    s  be an operator
taking a relevant transition of the form t     s x     c  
an optimal rplan dependency graph for p    s   x  and o    or optimal rplan dependency
graph for p    s  in brief  is a graph odg     v  a  with unique leaf vertex x    and where
x  v and  x  x     a if either  x    x    x  xpreo   and preo   x     s x   or x    x  
 
 
 s  taking a relevant transition on x  so that x  xpreo
v    x    and there exists o  p  
and preo  x     s x  
for x  v    x     by odt g 
x we denote the sub graph of dt gx that includes only
 
 s  x   the relevant transitions t using an operator in
the values true at some point in p  
 
p    s  x   and at least one relevant inverse of such t where a relevant inverse exists  we
 
 s  x  transitions as original  and to the inverse transitions as induced 
refer to the p  
the transition t  with responsible operator o  will be our candidate for reaching the
exit state  like t  in figure    odg  collects all variables x connected to a variable x 
 
insofar as p  
 s  uses an operator preconditioned on x in order to move x    these are the
variables we will need to move  like x  and x  in figure    to obtain a state s  where t  can
be taken  for any such variable x  odt g 
x captures the domain transition graph fragment
 
that p  
 s  traverses and within which we will stay  like t  and t  in figure   
 
note that there is no need to consider the operators p  
 s  behind o    simply because
these operators are not used in order to establish o  s precondition  this is of paramount
importance in practice  an example is the gripper situation mentioned above  if o  picks
 
up a ball b in gripper  then p    s  will also contain  behind o    i e   in p  
 s   an
 
 
 
operator o dropping b  if we considered o in definition    then odg would contain the
mentioned cycle assuming that o  is used for making the gripper hand free for picking up b 
in torchlights approximate local analysis  whenever we consider an operator o    before we
build odg  we re order p    s  by moving operators behind o  if possible  this minimizes
 
p  
 s   and odg  thus indeed contains only the necessary variables and arcs 
   

fihoffmann

under which circumstances will t  actually do the job  the sufficient criterion we
identify is rather complex  to provide an overview of the criterion  we next state its definition  the items in this definition will be explained below 
definition    let  x  si   sg   o   s  p    s   x    o    t    and odg     v  a  be as in definition    we say that odg  is successful if all of the following holds 
    odg  is acyclic 
    we have that either 
 
 a  the odg   relevant deletes of t  are p  
 s  recoverable  or
 
 b  s x    is not odg  relevant  and t  has replaceable side effect deletes  or
 c  s x    is not odg   relevant  and t  has recoverable side effect deletes 

    for x  v    x     all odt g 
x transitions either have self irrelevant deletes  or are
invertible induced and have irrelevant side effect deletes and no side effects on v   x    
as already outlined  our exit path construction works by staying within the ranges of
odt g 
x   for x  v    x     until we have reached a state s  where the transition t  can be
taken  to make this a little more precise  consider a topological order xk           x  of v    x   
with respect to odg   such an order exists due to definition   condition       if there
are cycles  then moving a variable may involve moving itself in the first place  which is
not covered by our exit path construction   now consider  for    d  k  the d abstracted
task  this is like the original task except that  for every transition t of one of the graphs
odt g 
xi with i  d  we remove each condition  xj   c   cond t  where j   d  the exit
path construction can then be understood as an induction over d  proving the existence


of an execution path 
o at whose end t  can be taken  we construct 
o exclusively by
 
for
x

v
 
 x
  
for
the
base case  in the
operators responsible for transitions in odt g 
 
x
  abstracted task  t  is directly applicable  for the inductive case  if we have constructed


a suitable path 
o d for the d abstracted task  then a suitable path 
o d   for the d    
abstracted task can be constructed as follows  assume that o is an operator in 
o d   and


that o has a precondition  xd     c  that is not true in the current state  then  in o d     in
front of o we simply insert a path through odt g 
xd   that ends in c  note here that  by
construction   xd     c  is a condition of a transition t in odt g 
xi   for some i   d      if
 
 
t is taken in p  
 s  x   then  xd     c  must be achieved by p  
 s  and thus c is a node in
 
odt g 
xd     if t is an induced transition  inverting a transition taken in p    s  x   then
the same is the case unless the inverse may introduce new outside conditions  we thus need
to exclude this case  leading to the following definition of invertibility 
 let t    c  c    be a transition on variable x  we say that t is invertible iff there exists
a transition  c    c  in dt gx so that cond c    c   cond c  c    
a transition is invertible if we can go back without introducing any new conditions  e g  
driving trucks in logistics   there are subtle differences to previous definitions of invertible
operators  like the authors  hoffmann         we do not allow new conditions even if they

are actually established by the operator rop t  responsible for t  this is because  on 
o   we
do not necessarily execute t before executing its inverse  we may have got to the endpoint
of t via a different path in odt g 
x   on the other hand  our definition is also more generous
   

fianalyzing search topology without running any search

than common ones because  per se  it does not care about any side effects the inverse
transition may have  side effects are constrained separately as stated in definition    
consider definition   condition      apart from the constraints on conditions of induced


transitions  for the odt g 
x transitions taken by o   we must also make sure that there are
no harmful side effects  obviously  this is the case if  as in the example from section    the
transitions have no side effects at all  however  we can easily generalize this condition  let
t    c  c    be a transition on variable x 
 the context of t is the set ctx t  of all facts that may be deleted by side effects of t 
for each  y  d   seff t    y  cond t  y    ctx t  if a condition on y is defined  else all
dy values    d are inserted 
s
 we say that t has irrelevant side effect deletes iff ctx t    sg  oo preo      
s
 we say that t has self irrelevant side effect deletes iff ctx t    sg  rop t   oo preo    
 
 we say that tshas self irrelevant deletes iff it has self irrelevant side effect deletes and
 x  c    sg  rop t   oo preo  
irrelevant side effect deletes capture the case where no side effect delete occurs in the goal
or in the precondition of any operator  self irrelevant side effect deletes are slightly more
generous in that they allow to delete conditions needed only for the responsible operator
rop t  itself  self irrelevant deletes  finally  extend the latter notion also to ts own delete 
in a nutshell  we need to postulate irrelevant side effect deletes for transitions that may
be executed again  on our path  examples of irrelevant side effect deletes are transitions
with no side effects at all  or a move in simple tsp  whose side effect  when x   at 
deletes the target locations being not visited  an example of an operator with selfirrelevant side effect deletes  but no irrelevant side effect deletes  is departing a passenger
in miconic strips  whose side effect  when x   served  deletes boarded passenger 
which is used only for the purpose of this departure  in fact  this transition has selfirrelevant deletes because its own effect deletes not served passenger  which obviously is
irrelevant  another example of self irrelevant deletes is inflating a spare wheel in tyreworld
 the wheel is no longer not inflated 


clearly  if all odt g 
x transitions t we may be using on o have irrelevant side effect
deletes  then  as far as not invalidating any facts needed elsewhere is concerned  this is just
as good as having no side effects at all  to understand why we need to require that ts
side effect is not used to move another variable x   v    x     recall that  for the states s 

visited by 
o   we construct relaxed plans p    s    with  p    s       p    s   by inverting such
transitions t  now  say that ts side effect is used to move another variable x   v    x    
then we may have to invert both transitions separately  with different operators   and thus
we would have  p    s        p    s   
regarding the own delete of t  this may be important for two reasons  first  the deleted
fact may be needed in the relaxed plan for s    second  x may have to traverse odt g 
x several
times  and thus we may need to traverse the deleted value again later on  both are covered if
t is invertible  like we earlier on assumed for all transitions  now  what if t is not invertible 
this does not constitute a problem in case that t has self irrelevant deletes  in that case 
   

fihoffmann

all deletes of t are irrelevant except maybe for the responsible operator itself  therefore 
to obtain p    s     we can simply remove rop t  from the relaxed plan constructed for the
predecessor state s     thus  p    s        p    s   so we have reached an exit and there is no

need to continue the construction of 
o   for example  consider t that inflates a spare wheel
w in tyreworld  this deletes only not inflated w   and thus has self irrelevant deletes
 not inflated w  is irrelevant for the goal and any other operator   say that we are in a
state s   with relaxed plan p    s     constructed as described  we have  p    s        p    s   
we also have rop t   inflate w p    s      because inflate w p    s   and because
inflate w was not executed as yet on our path  and was hence not removed from the
relaxed plan  applying inflate w to s     we get to a state s  identical to s   except that w
is now inflated  clearly  the relaxed plan for s  no longer needs to apply inflate w  and
the rest of the relaxed plan p    s     still works unchanged  thus p    s    can be obtained by
removing inflate w from p    s      yielding  p    s        p    s   as desired 
consider now our endpoint transition t  and its responsible operator o    we previously
demanded that x  moves for its own sake  i e   that x  has a goal value and is not
important for achieving any other goal  this is unnecessarily restrictive  for example  in
miconic strips  if we board a passenger then h  decreases because we can remove the
boarding operator from the relaxed plan  however  boarding is only a means for serving
the passenger later on  so this variable x  has no own goal  in driverlog  a driver may
have its own goal and be needed to drive vehicles  and still t  moving the driver results in
decreased h  if the location moved away from is not actually needed anymore  the latter
example immediately leads to a definition capturing also the first one  all we want is that
any deletes of t  are not needed in the rest of the relaxed plan  we can then remove o 
from the relaxed plan for s    and have reached an exit as desired 
to make this precise  recall the situation we are addressing  we have reached a state s 
in which t     s x     c  can be applied  yielding a state s    we have a relaxed plan p    s   
for s  so that  p    s       p    s    where p    s    is constructed from p    s  by replacing
 
 s  with operators responsible for induced odt g 
some operators of p  
x transitions for
x  v    x     we construct p   by removing o  from p    s     and we need p   to be a
relaxed plan for s    what are the facts possibly needed in p     a safe approximation is
the union of sg   the precondition of any o     o  p    s   and any odt g 
x values needed
  denote that set with r    the values potentially deleted
by induced odt g 
transitions 
x
 
by t  are contained in c       x    s x       ctx t     thus if r    c     then we are
fine  simple examples for this have been given above already  in miconic strips  the
only delete of o  boarding passenger p is not boarded p   which is not contained in
any operator precondition or the goal and thus the intersection of r   with c     notboarded p   is empty  in driverlog  c     at d a   is the delete of o  moving driver
d away from location a  if that location is irrelevant to the rest of the task  then we
will have at d a   r   and thus  again  r    c     
s
we can sharpen this further  consider the set of facts f     s  op    s  eff o that
  

 
are true after relaxed execution of p  
 s   say that p   f    then p is not needed for

   to understand the latter two items  note first that operators preceding o  in p    s   i e   operators from
 
p  
 s   may still be contained in p   and thus it does not suffice to include the preconditions only of
 
 
operators o  p  
 s   as for odt g 
x values needed by induced odt gx transitions  these may be needed
 
 
in p  but not in p  
 s  

   

fianalyzing search topology without running any search

p   to be a relaxed plan for s    to see this  note first that p is not needed in the part of
 
 
p   pertaining to p  
 s   more precisely  p cannot be an operator precondition in p  
 s 
 
because this condition would not be satisfied in  relaxed  execution of p  s   also  p
cannot be the start value of an induced odt g 
x transition because  by definition  all such
 
values are added by operators in p    s   now  what about the part of p   pertaining to
 
 
p  
 s   assume that p is either a goal  or is an operator precondition in p  
 s   then 
 
 
since p   f  and p  s  is a relaxed plan  either o  or an operator in p    s  must establish
 
p  as for o    all its effects are true in s  anyway  as for p  
 s   this remains unchanged in
 
p  and thus this part is covered  too  altogether  it thus suffices if r    c   f      an
example where this helps is the satellite domain  say that o  switches on instrument i 
this deletes calibration  i e   calibrated i  c    the only purpose of switching i on
can be to take images with it  and thus calibrated i  r    c    however  the instrument
may not actually be calibrated in s  if that is so  then we need to switch i on before it
can be calibrated  because the calibration operator requires to have power in i  and
thus calibrated i  will be false in the relaxed execution of p    s   up to at least o    in
particular  we have calibrated i   f  and thus r    c   f     
even the condition r    c   f     can still be sharpened  say that there exists a


 
 s  so that 
o  is guaranteed to be applicable at
 possibly empty  sub sequence 
o  of p  


 
the start of p    and so that o  re achieves all facts in r    c   f   both are easy to

define and test   then moving 
o  to the start of p   does the job  we say in this case that
 
 
 s  recoverable  definition   condition   a   for
the odg  relevant deletes of t  are p  
example  consider o  that picks up a ball b in the gripper domain  this operator deletes a
fact p  free gripper which may be needed in the remainder of the relaxed plan  and thus

 
 s  will necessarily contain a sub sequence 
o  that moves
p  r    c   f    however  p  


 
to another room and then puts b down again  we can re order p  to put o  right at the
start  re achieving p  similar patterns occur in any transportation domain with capacity
constraints  or more generally in domains with renewable resources 
finally  we have identified two simple alternative sufficient conditions under which t 
is suitable  definition   conditions   b  and   c   for the sake of brevity  we only sketch
them here  both require that s x     i e   the start value of t    is not contained in r   as
defined above  we say in this case that s x    is not odg   relevant  note that  then 
r    c     unless t  has side effects  side effects do not hurt if t  has replaceable side
effect deletes  i e   if any operator whose precondition may be deleted can be replaced with
an alternative operator o  that is applicable and has the same effect  this happens  e g   in
simple tsp   another possibility is that where t  has recoverable side effect deletes  there
exists an operator o  that is necessarily applicable directly after execution of t    and that
recovers all relevant side effect deletes  this happens quite frequently  for example in rovers
where taking a rock soil sample fills a store  but we can free the store again simply by
emptying it anywhere  we can replace o  with o  to obtain a relaxed plan p   for s   and
thus h   s     h   s    then we can apply o    yielding a state s  which has h   s      h   s 
because we can obtain a relaxed plan for s  by removing o  from p    
what will the length of the exit path be  we have one move for x    each nonleaf variable x must provide a new value at most once for every move of a variable x 
depending on it  i e   where  x  x     a  the new value can be reached by a odt g 
x
traversal  denote the maximum length of such a traversal  i e   the diameter of odt g 
x 
   

fihoffmann

  now  we may have diam odt g      diam dt g   because odt g 
by diam odt g 
x
x   
x
x
removes not only vertices but also arcs  there may be short cuts not traversed by p    s  
under certain circumstances it is safe to take these short cuts  namely if 

    all odt g 
x transitions are invertible induced and have irrelevant side effect deletes
and no side effects on v    x     and all other dt gx transitions either are irrelevant  or
have empty conditions and irrelevant side effect deletes 
when traversing a short cut under this condition  as soon as we reach the end of the shortcut  we are back in the region of states s  where a relaxed plan p    s    can be constructed
as before  the rest of our exit path construction remains unaffected  thus 
denote by v 
p
the subset of v    x    for which     holds  we define costd  odg       xv costd  x  
where costd  x    

 



p
d  
diam odt g 
x 
x    x x   a cost  x  


 min diam odt g     diam dt g     p
x

x

x   x 
x    x    x   v 
x    x x   a cost

d  x   

x    x    x  v 

note that costd     is exponential in the depth of the graph  this is not an artifact of our
length estimation  it is easy to construct examples where exit distance is exponential in
that parameter  this is because  as hinted  a variable may have to move several times for
each value required by other variables depending on it  see example   in appendix a   for
such a construction  following an earlier construction in domshlak   dinitz        
that said  of course costd     may over estimate the length of a shortest exit path  it
assumes that  whenever a variable x  with  x  x     a makes a move  then x must move
through its entire odt g  respectively dt g  this is very conservative      it may be that
the move of x  does not actually have a condition on x      even if such a condition exists 
x may need less steps in order to reach it  one might be able to ameliorate     by making
more fine grained distinctions which part of costd  x    pertains to moves conditioned on
x  we leave this open for future work  for now  we note that the over estimation can be
exponential even just due to      i e   costd  odg    may be exponentially larger than the
length of a shortest exit path even if  for all  x  x     a  all moves of x  depend on x  this
can be shown by a simple variant of example    we discuss this in appendix a   
exit paths using short cuts in the described way may be non monotone  example  
in appendix a   contains a construction showing this  for an intuitive understanding 
imagine a line l            ln where our current task  to achieve the precondition of another
operator  is to move from l  to ln   say that all locations on the line need to be visited  in
the relaxed plan  e g  because we need to load or unload something at all of these locations 
say further that there is a shortcut via l  that needs not be visited  if we move to l  then h 
increases because we have made it   step more costly  for the relaxed plan  to reach all the
locations l            ln   for the same reason  costd  odg    is not an upper bound on the length
of a shortest monotone exit path  this is also shown in example    where we construct a
   more precisely  diam    is not the diameter of a graph but the maximum distance from vertex v to vertex
v   where there exists a path from v to v    

   

fianalyzing search topology without running any search

situation in which the shortest monotone exit path is longer than costd  odg      to obtain
a bound on monotone exit paths  we can simply set v      in the definition of costd  
if we have definition   condition   a  or   b   then the exit distance is bounded by
costd  odg       because costd  odg    counts the last step reducing h    if we have
definition   condition   c   then after that last step we need   additional operator to reduce
h    and so the exit distance is bounded by costd  odg     putting the pieces together yields
our main result of this section 
theorem    let  x  si   sg   o   s  p    s   and odg  be as in definition    if odg  is successful  then s is not a local minimum  and ed s   costd  odg     if we have definition  
condition   a  or   b   then ed s   costd  odg       
the full proof is in appendix a    as pointed out earlier  for approximate local analysis
 iii  we simply feed theorem   with the relaxed plans returned by ffs heuristic function
 hoffmann   nebel      a   it is important to note that  this way  we do not give any
guarantees  i e   theorem   does not hold if p    s  is not optimal  and even if p    s  is
non redundant and parallel optimal like those computed by ff  at the end of the exit
path we may obtain a relaxed plan shorter than p    s  but not shorter than h   s   in
a nutshell  the reason is that a parallel optimal relaxed plan  more generally  a relaxed
plan not minimizing the number of operators  may take very different decisions than a
sequentially optimal relaxed plan  thus constructing an exit path leading into the wrong
direction  example   in appendix a   gives a full construction proving this 
feeding theorem   with non optimal relaxed plans can of course also be imprecise in
the other direction  i e   theorem   may not apply although it does apply for an optimal
relaxed plan  thus good cases may go unrecognized  we demonstrate this with a simple
modification of example    explained below the example in appendix a    importantly  as
we will point out in section    our empirical results suggest that this weakness does not
tend to occur in practice  at least as far as represented by the benchmarks 

   conservative approximations
we now identify sufficient criteria guaranteeing that the prerequisites of theorem   hold
true  we consider both the local case where a particular state s is given  and the global
case where the criterion implies the prerequisites of theorem   for every state s in the task
at hand  we approximate optimal rplan dependency graphs as follows 
definition    let  x  si   sg   o  be a planning task  let s  s with     h   s      let
x   xsg   and let t     s x     c  be a relevant transition in dt gx  with o     rop t    
a local dependency graph for s  x    and o    or local dependency graph in brief  is a
graph ldg    v  a  with unique leaf vertex x    and where x  v and  x  x     a if either 
x    x    x  xpreo   and preo   x     s x   or x   v    x    and  x  x    is an arc in sg 
 
a global dependency graph for x  and o    or global dependency graph in brief  is a
graph gdg    v  a  with unique leaf vertex x    and where x  v and  x  x     a if either 
x    x  and x     x  xpreo   or x   v    x    and  x  x    is an arc in sg
 

   we remark that  due to the mentioned sources of over estimation in costd   constructing such an example
requires fairly awkward constructs that do not appear likely to occur in practice 

   

fihoffmann

if an optimal relaxed plan p    s  for s contains o    then odg  as per definition   will
be a sub graph of ldg and gdg as defined here  this is simply because any optimal rplan
dependency graph has only arcs  x  x    contained in the support graph of the task    as
previously indicated  the support graph may contain a lot more arcs than actually necessary 
sg captures what may ever support what else  not what will support what else in an optimal
relaxed plan  consider our earlier point that  when constructing odg    we take into account
only the operators in front of o  in p    s   this information is not contained in sg  thus
in gripper we get the aforementioned cycle dropping a ball to support free gripper for
picking up the same ball 
the reader who has waded through the cumbersome details in the previous section will
be delighted to hear that defining when an ldg respectively gdg is successful does not
involve any additional notation 
definition    let  x  si   sg   o   s  x    t    o    and g   ldg or g   gdg be as in
definition    we say that g    v  a  is successful if all of the following hold 
    g is acyclic 
    if g   ldg then sg  x       s x     and there exists no transitive successor x  of x  in
sg so that x   xsg and sg  x       s x    
    we have that t  either 
 a  has self irrelevant side effect deletes  or
 b  has replaceable side effect deletes  or
 c  has recoverable side effect deletes 
    for x  v    x     all dt gx transitions either are irrelevant  or have self irrelevant
deletes  or are invertible and have irrelevant side effect deletes and no side effects on
v    x    
consider first only local dependency graphs g   ldg  we will discuss g   gdg below 
assume that we have an optimal relaxed plan p    s  for s that contains o    and thus odg 
is a sub graph of ldg  then condition     obviously implies definition   condition     
condition     implies definition   condition     because odt g 
x does not contain any
irrelevant transitions  condition     implies that     s x    is not odg   relevant  i e   s x   
is not needed in the rest of the relaxed plan  this is simply because no other un achieved
goal depends on x    with      condition   a  implies definition   condition   a   because
r    c      in the notation introduced previously  conditions   b  and definition  
condition   b   respectively   c  and definition   condition   c   are equivalent given     
regarding exit distance  we do not know which parts of the domain transition graphs of
the variables x  v    x    will be traversed by p    s   an obvious bound on diam odt g 
x 
is the length maxpath dt gx   of a longest non redundant path through the graph  a path
visiting each vertex at most once   unfortunately  we cannot compute maxpath    efficiently  a hamiltonian path  garey   johnson        exists in a graph g    v  a  iff
    for gdg  note that preo   x     if defined  will be   s x    and thus x  does not need to be recorded as
its own predecessor 

   

fianalyzing search topology without running any search

maxpath g     v       thus the corresponding decision problem is np hard  torchlight over approximates maxpath g  simply by  v       however  we can sometimes use
diam dt gx   instead of maxpath dt gx    namely if we are certain that x is one of the
variables v  used in the definition of costd  odg     this is certain if 
     all dt gx transitions either are irrelevant  or are invertible and have empty
conditions  irrelevant side effect deletes  and no side effects on v    x    
note that this is a strictly stronger requirement than definition   condition      clearly  it
implies definition   condition     as well as condition     in sectionp   denote by v  the
subset of v    x    for which      holds  we define costd  g     xv costd  x   where
costd  x    

 
x   x 



p
d
 
maxpath dt gx    x    x x   a cost  x   x    x    x   v 


 diam dt g    p
costd  x   
x    x   x  v 
x

 

x    x x   a

because x  must move  to attain its own goal  every optimal relaxed plan must take
at least one transition leaving s x     thus  with theorem   and the above  we have that 
theorem    let  x  si   sg   o  be a planning task  and let s  s be a state with     h   s   
  say that x   x so that  for every o    rop s x     c  in dt gx  where  s x     c  is
relevant  ldgo  is a successful local dependency graph  then s is not a local minimum  and
ed s   maxo  costd  ldgo     if  for every ldgo    we have definition   condition   a  or
  b   then ed s   maxo  costd  ldgo       
theorem   is our tool for guaranteed local analysis  ii   for guaranteed global analysis
 i   we simply look at the set of all global dependency graphs gdg  requiring them to be
successful  in particular  all gdg are then acyclic  from which it is not difficult to deduce
that any non goal state s will have a variable x  fulfilling definition        for that x    we
can apply theorem   and thus get 
theorem    let  x  si   sg   o  be a planning task  say that all global dependency graphs
gdg are successful  then s does not contain any local minima and  for any state s  s with
    h   s      ed s   maxgdg costd  gdg   if  for every gdg  we have definition  
condition   a  or   b   then ed s   maxgdg costd  gdg     
the full proofs of theorems   and   are in appendix a    if sg is acyclic and all
transitions are invertible and have no side effects  then theorem   applies  whereby we have
now in particular proved our basic result  vice versa  note that  if theorem   applies  then
sg is acyclic  as far as local minima are concerned  one may thus reformulate theorem  
in simpler terms not relying on a notion of successful dependency graphs  apart from
allowing to also determine an exit distance bound  the present formulation already paves
the way for future research  a gdg is defined relative to a concrete variable x  and operator
o    and may thus allow for more accurate analysis of which other variables may actually
become important for x  and o    in an optimal relaxed plan 
the use of diam dt gx   instead of maxpath dt gx   in costd      for the variables
in v    has a rather significant effect on the quality of the bounds computed in many
   

fihoffmann

benchmarks  a typical example is a transportation domain where vehicle positions are leaf
variables in sg whose transitions have no side effects  such variables qualify for v    using
maxpath dt gx   instead  we would obtain exceedingly large bounds even for trivial road
maps  for example  consider logistics where the road map is fully connected  we have
diam dt gx       and thus costd     delivers the correct bound    using maxpath dt gx  
we instead get the bound n     n being the total number of locations in dt gx  
note that  within the scope of theorem    i e   the class of planning tasks to which
theorem   applies  plan existence is tractable  namely  there exists a plan for the task iff
there exists a relaxed plan for the initial state  this is because  starting from an optimal
relaxed plan  we are guaranteed to be able to construct an exit path  iterating this argument
gets us to the goal  in our view  this tractability is a weakness of this form of global
analysis  the analysis does not apply in intractable classes of tasks that do not contain
local minima  note that such classes do exist  cf  theorem    on the other hand  plan
existence is tractable in all known benchmark domains where local minima are absent  so in
practice this does not appear to be a major limitation  also  note that plan construction 
as well as optimal planning  are still intractable within the scope of theorem    plan
construction is intractable because the plans may be exponentially long  cf  example   in
appendix a    as for optimal planning  just consider logistics and miconic strips  we
will see shortly  proposition    next section  that these are fully covered by theorem   
however  in both of them  deciding bounded plan existence is np hard  helmert        
interestingly  the fact that theorem    and therewith indirectly also theorem    rely on
optimal relaxed plans is not a source of intractability of plan construction here  if theorem  
applies  then any non redundant relaxed plan p   has a successful odg    enabling us to
construct a path to a state where that particular relaxed plan  although not necessarily
an optimal relaxed plan  can be shortened  iterating this argument gives us a constructive
method for obtaining a plan  where the only worst case exponential behavior lies in the
length of the individual path segments  that said  of course the plan constructed in this
way may be highly non optimal  indeed  as is shown in example   in appendix a    this
plan may be exponentially longer than an optimal plan  thus  even if theorem   applies
and we do not need an optimality guarantee  running a planner still makes sense 
we will discuss the relation of the scope of theorem   to known tractable classes in
section    a basic fact is that one can construct local minima even in very small examples
involving only two variables and complying with our basic result except that either the
support graph is cyclic  example    appendix a     or there is a non invertible transition
whose own delete is relevant  example    appendix a     or there is a transition with a
relevant side effect delete  example    appendix a     these examples are contained in
many known tractable classes  thus underlining that the automatic analysis of h  topology
and the identification of tractable classes are different  although related  enterprises 

   benchmark performance guarantees
we now state some guarantees that our analyses  i  iii  give in benchmark domains 
the underlying finite domain variable formalizations are straightforward  and correspond
   

fianalyzing search topology without running any search

to formulations that can be found automatically by fast downward  they are listed in
appendix a    where we also give the proofs of the following two simple observations   
in four of our benchmark domains  guaranteed global analysis  i  will always succeed  
proposition    let  x  si   sg   o  be a planning task from the logistics  miconic strips 
movie  or simple tsp domain  then theorem   applies  and the bound delivered is at most
         and   respectively 
it follows trivially from proposition   that guaranteed local analysis  ii  succeeds in
these domains as well  if s is any state in one of the four listed domains  then theorem  
applies to s  and the bound delivered is as stated 
note that the bounds for logistics and movie are the correct ones  i e   they are tight 
for miconic strips  the over estimation of the actual bound  which is    not    arises
because the analysis does not realize that boarding a passenger can be used as the leaf
variable x    for simple tsp  the correct bound is    since h  is the exact goal distance  
the over estimation arises because  in every goal variable x   visited location   the gdg
includes also the variable at  not realizing that the value of at does not matter because
any location can be visited from any other one 
for the transportation benchmarks involving capacity constraints  approximate local
analysis  iii  will always succeed  if provided with suitable optimal relaxed plans 
proposition    let  x  si   sg   o  be a planning task from the elevators  ferry  gripper 
or transport domain  and let s  s  in ferry and gripper  for every optimal relaxed plan
p    s  there exists odg  so that theorem   applies  the bound being at most    in elevators
and transport  there exists at least one p    s  and odg  so that theorem   applies  the
bound being at most   in elevators and at most the road map diameter in transport 
the relevant deletes of t    in all these cases  are due to the effects decreasing the remaining vehicle capacity  like free gripper in the gripper domain  a decrease of capacity is
always due to a load type of operator  which is matched by an unload type of operator
later on inside the relaxed plan  thus these deletes are always recovered inside p    s   we
have definition   condition   a    further  relaxed plans never use an unload action to
free a capacity for loading the same object  thus the odg  s are cycle free  hence the
odg  s are successful  and theorem   applies  for elevators and transport  proposition  
is slightly weaker because a vehicle may have capacity      allowing  but not forcing 
relaxed plans to use unloading operators recovering a capacity not actually present 
we note that similar patterns are likely to occur in any domain with renewable resources 
and will be recognized by definition   condition   a  in the same way 
proposition   does not hold for theorems   and    i e   for ldgs and gdgs  this is due
to two deficiencies  cf  the discussion at the end of section     first  sg contains cycles
unloading an object in order to free the capacity for loading it  second  definition  
condition   a  is more restrictive than definition   condition   a   postulating the deletes
of t  to be entirely irrelevant  if we had a way of removing these deficiencies  then the
guaranteed analyses  i ii  would succeed in the four domains from proposition   
    we say can be found automatically here because fast downwards translator is not deterministic  i e  
it may return different finite domain variable encodings even when run several times on the same planning
task  some but not all of these encodings correspond to our domain formalizations  for elevators  we
do not give a full definition because  without action costs  this is merely a variant of transport 

   

fihoffmann

   experiments
we report on a large scale experiment with torchlight  we fill in a few details on torchlights implementation  and we describe a simple alternative analysis technique based on
search probing  we explain the experiments set up  report runtime results for the different
stages of torchlight  and describe torchlights analysis results on a per domain basis  we
assess the quality of that analysis in terms of its predictive capability  we finally summarize
the outcome of torchlights diagnosis facility in our benchmarks 
    torchlight
torchlight is implemented in c based on ff    torchlight currently handles strips only 
i e   no adl domains  it uses fast downwards translator  helmert        to find the finitedomain variables  establishing the correspondence between these variables  respectively
their values  and ffs internally used ground facts is mostly straightforward  there are a
few details to take care of  we omit these for brevity 
after parsing fast downwards variables  torchlight creates data structures representing the support graph and the domain transition graphs  it then enters a phase we refer
to as static analysis  where it determines fixed properties such as  for every transition t 
whether t is irrelevant  invertible  etc  the next step is guaranteed global analysis  i  
checking the preconditions of theorem   by enumerating all global dependency graphs and
testing whether they are successful  to be able to report the percentage of successful gdgs 
we do not stop at the first unsuccessful one 
the local analysis techniques  guaranteed local analysis  ii  using theorem   and
approximate local analysis  iii  using theorem    are run on a set ls of states comprising
the initial state as well as a number r of sample states obtained by random walks starting
in si   the set ls is identical for both analyses  and we run each technique on each state
s  ls regardless of what the outcome of running the respective other technique on s is 
given s  analysis  ii  checks theorem   by constructing the local dependency graph for
every suitable variable x  and every transition t  leaving s x     if we find a non successful
t    we stop considering x    we minimize exit distance bounds across different x   
analysis  iii  checks theorem   on a relaxed plan p    s  computed by ffs heuristic
function  in case that no relaxed plan exists for s  the analysis reports failure  otherwise 
the analysis proceeds over all operators o  in p    s   from start to end  and over all variables
x  affected by o    for each pair o    x  we build the optimal rplan dependency graph odg  as
per definition    we skip variables x  where eff o   x    is not actually used as a precondition
or goal  in the rest of p    s   if odg  is successful  we stop   relaxed plans can be big
in large examples  so continuing the analysis for exit bound minimization was sometimes
costly   as mentioned in section    before we build odg  we re order p    s  by moving
operators behind o  if possible  this is of paramount importance because it avoids including
unnecessary variables into odg    the re ordering process is straightforward  it starts at
the direct predecessor o of o    and tests whether p    s  is still a relaxed plan when moving
o directly behind o    if yes  this arrangement is kept  then we iterate to the predecessor
of o  and so forth  it is easy to see that  this way  odg  will contain exactly the variables
    the source code of torchlight is an online appendix to this paper  it is available for download also at
http   www loria fr  hoffmanj torchlight zip 

   

fianalyzing search topology without running any search

and transitions used in p    s  to achieve preo    finally  when we check whether the odg   
relevant deletes of t  are p  
 s  recoverable  we use a simple technique allowing to recognize
situations where failure due to one operator can be avoided by replacing with an alternative
operator  for example  if in transport o  is a loading operator reducing capacity level k to
k     then p    s  may still contain an unloading operator relying on level k  thus level k
will be contained in r    c    causing failure  however  the unloading can just as well be
performed based on capacity level k     removing this difficulty  we catch cases like this
during construction of r     whenever we find o whose precondition overlaps c    we test
whether we can replace o with a similar operator 
the local analyses return simple statistics  namely the minimum  mean  and maximal
exit distance bound found  as well as the success rate  i e   the fraction of sample states
where guaranteed local analysis  ii  approximate local analysis  iii  succeeded  analysis
 iii  success rates will be a main focus  because these turn out to be very informative 
we run r                    in the experiment  the length of each random walk is
chosen uniformly between   and    hff  si    i e     times the ff heuristic value for the
initial state  we do not play with the parameter    it is important  however  that this
parameter is not chosen too small  in domains with many dead ends  where one may do
things that are fatally wrong  it is likely that the bad things will happen only if doing
a sufficiently large number of random choices  consequently  the dead end rate  i e   the
fraction of sample states for which no relaxed plan exists  tends to be larger for longer
random walks  since analysis  iii  fails on states that have no relaxed plan  this exerts an
important influence on analysis  iii  success rates  we illustrate this below by comparing
some results for sampled states to results obtained using the initial states only 
    search probing
for approximate analysis of sample states  there exists a simple  and rather obvious  alternative to torchlights causal graph based technology  one can use search to determine
whether or not a given sample state s is a local minimum  and what its exit distance is  since
we cannot compute h  effectively  such a search based analysis is necessarily approximate 
the straightforward method is to replace h  with a relaxed plan based approximation 
herein  we replace h  with hff   i e   with ffs heuristic function  precisely  given a state
s  we run a single iteration of ffs enforced hill climbing  i e   a breadth first search for
a state with better heuristic value  in this search  like ff does  we use helpful actions
pruning to avoid huge search spaces  unlike ff  to focus on the detection of states not on
local minima  we allow only monotone paths  thus restricting the search space to states s 
where hff  s      hff  s    we refer to this technique as search probing  sp in brief  we also
experiment with a variant imposing a   second runtime cut off on the search  we refer to
this as limited search probing  sp s in brief  sp and sp s are run on the same set ls of
states as torchlights local analyses  ii iii  
as it turns out  empirically  in the present benchmarks  sp and sp s are very competitive with torchlights analysis  iii   since that analysis is a main focus of our experiments 
it is relevant to understand the commonalities and differences between these techniques 
as far as analysis quality guarantees are concerned  all   techniques  analysis  iii  
sp  sp s  have similar properties  there are no guarantees whatsoever  each may report
   

fihoffmann

success although s is a local minimum  false positives   and each may fail although s is
not a local minimum  false negatives   in all cases  false positives are due to the use of
non optimal relaxed plans  hff instead of h     false negatives are inherent in analysis  iii 
because this covers only certain special cases  they are inherent in sp s due to the search
limit  sp can have false negatives due to helpful actions pruning  however that could in
principle be turned off  the more fundamental source of false negatives are the non optimal
relaxed plans  these are also responsible for a lack of connections across the techniques 
the only implication is the trivial one that sp s success on a state s implies sp success on
s  in particular  if analysis  iii  correctly identifies s to not be a local minimum  then this
does not imply that sp will do so as well  the causal graph analysis may be less affected
by irregularities in the hff surface  this happens  for example  in the transport domain of
ipc       resulting in higher success rates for analysis  iii  
there are some obvious  but important  differences regarding runtime performance
and the danger of false negatives  sp runtime is worst case exponential in the size of the
 grounded  input  whereas analysis  iii  and sp s runtime is low order polynomial in that
size  for sp  decreasing the number r of sample states merely reduces the chance of hitting
a bad state  a sample state on a large flat region   whereas analysis  iii  and sp s scale
linearly in r  on the other hand  both analysis  iii  and sp s buy their efficiency with
incompleteness  i e   increased danger of false negatives  analysis  iii  simply recognizes
only special cases  sp s effectively bounds the lookahead depth  i e   the search depth in
which exit states can be detected 
as indicated  sp and sp s turn out to be competitive in the benchmarks  large search
spaces are rare for sp  the success rates of sp and sp s are similar  and as far as predictive
capability is concerned are similarly informative as those of analysis  iii   thus goodquality success rates can be obtained with much simpler techniques than torchlight   
this notwithstanding   a  torchlight has other functions  the guaranteed analyses  i ii 
as well as diagnosis  that cannot be simulated  and  b  results in benchmarks only ever
pertain to these examples  torchlights analysis  iii  offers unlimited lookahead depth at
low order polynomial cost  this does not appear to matter much in the present benchmarks 
but there are natural cases where it does matter  we get back to this below 
    experiments set up
we run experiments in a set of    domains  these include the domains investigated in
the hand made analysis of h  topology  hoffmann         as shown in figure    which
include all domains from the international planning competitions  ipc  up to ipc      
our remaining domains are the strips  versions of the  domains from ipc      and ipc
      except ipc      cyber security which we omit due to parsing difficulties    the test
instances were collected from the ipc collection s  where applicable  removing action cost
constructs from the ipc      domains   and randomly generated elsewhere  in total  our
test set contains      instances 
    in particular  search probing appears to be a rather useful technique  raising the question why such
techniques have not yet been used for performance prediction purposes  roberts and howe         for
example  use very simple features only  we get back to this in the conclusion 
    the instances are too large for ffs parser in its standard configuration  when tweaking bison to allow
larger parse trees  we obtained a segmentation fault even in the smallest instance of ipc      

   

fianalyzing search topology without running any search

tool phase
fd translator
sg dtg
static analysis
analysis  i 
sample states
analysis  ii 
analysis  iii 
torchlight total
torchlight  iii 
torchlight  iii  no fd
sp
sp total
sp s
sp s total
ff
lama

single shot r    
mean
max
    
      
    
    
    
     
    
     
    
    
    
    
    
    
    
      
    
      
    
     
    
     
    
     
    
    
    
    
      

      


r     
mean
max

    
    
    
    
    
    
    
    
    
    

    
    
    
      
      
     
      
      
    
    

r      
mean
max

    
    
    
    
    
    
    
    
    
    

     
    
     
      
      
      


     
      

r       
mean
max

    
    
    
     
     
     
     
     
    
     

      
     
      
       
       
      


      
      

table    summary of runtime data  mean max is over all instances of all domains  for
empty fields  the respective tool phase is single shot  i e   does not depend on r 
a dash means time out       seconds  which is inserted as the runtime for each respective instance into the mean computation  rows fd translator       analysis
 iii  time the different stages of torchlight  torchlight total is overall runtime  torchlight  iii  does not run analyses  ii  and  iii   torchlight  iii  no
fd is the latter when disregarding the translation costs  sp determines a success rate  fraction of sample states deemed to not be on local minima  via search
probing  i e   search around each sample state  sp s  imposes a   second time out
on these searches  sp total and sp s total include the time for generating the
sample states 
all experiments are run on a     ghz cpu  with a    minute runtime and   gb
memory cut off  we run   different planners tools  apart from torchlight  and sp sp s   
these include ff  hoffmann   nebel      a   and lama  richter et al         richter
  westphal         the purpose of running these planners is to assess to what extent
torchlights output  in particular analysis  iii  success rate  can predict planner success
or failure  to examine this also for a very plain planner  we also run a version of ff that uses
no goal ordering techniques  and that runs only enforced hill climbing  without resorting
to best first search if that fails  we will refer to this planner as ehc in what follows 
    runtime
our code is currently optimized much more for readability than for speed  still  torchlight
is fast  up to r        the bottleneck is fast downwards translator  with r              
the actual analysis takes at most as much time as the translator in                 and
       of the instances respectively  to assess this in more detail  consider table   which
gives the timing of the different stages of torchlight  and of the other planners tools 
the translation runtime sometimes hurts considerably  with a peak of        seconds
in the most costly instance of the scanalyzer domain  this is rather exceptional  however 
the second most costly domain is blocksworld noarm  with a peak of        seconds  in
   

fihoffmann

   of the    domains  the most costly instance is translated in less than    seconds  in
       of the instances  fast downwards translator takes at most   second 
for static analysis  the peak behavior of       seconds  also in scanalyzer  is even more
exceptional  in        of the instances  static analysis takes at most   second  the second
highest domain peak is      seconds in pipesworld tankage  similarly  while analysis  i 
takes a peak of       seconds  in blocksworld noarm  in        of the instances it
completes in at most   second  the only domain other than blocksworld noarm where the
peak instance takes more than    seconds is airport  with a peak of       seconds  the next
highest domain peaks are pipesworld tankage        scanalyzer         logistics         and
woodworking         in all other domains  analysis  i  always completes within a second 
turning focus on the local analyses  we see that they are even more effective  in particular  we will concentrate below mostly on approximate local analysis  iii   we will see
that r        does not offer advantages over r      as far as the information obtained
goes  so we will mostly concentrate on r       for r               analysis  iii  completes in at most   second for                        of the instances respectively  for
r        this still holds for        of the instances  the peak runtime of       seconds
for r       occurs in scanalyzer  the next highest domain peaks are blocksworld noarm
        pipesworld tankage         ferry        logistics         blocksworld arm        
optical telegraph         and airport         in all other    domains  analysis  iii  with
r       always completes within a second 
the bottleneck in local analysis is the generation of sample states  this can be costly
because it involves the repeated computation of applicable operators during the random
walks  its r      peak of       seconds is in the scanalyzer domain  however  once
again  this peak behavior is exceptional  with r               the sampling completes
within at most   second for                      of the instances respectively 
the main competitor of torchlight analysis  iii  success rates is search probing  i e  
sp and sp s   consider for the moment only the analysis methods themselves  i e   row
analysis  iii  vs  rows sp and sp s  in table    compared to sp s   analysis  iii  is
consistently in the advantage  except for maximum runtime with r       but the difference
is not dramatic  this is to be expected  given that sp s trades completeness against a small
fixed maximum runtime  compared to the complete search in sp  analysis  iii  consistently
has a significant advantage  however  for r     the mean runtime of sp is tolerable  and
even the maximum runtime is not too bad  further  bad runtime behavior is exceptional 
for r          sp completes in at most   second for        and        of the instances
respectively  in     r      respectively     r       of the    domains even the maximum
runtime is below   second  with r        sp has two time outs  both in blocksworld arm 
with r         there are    time outs  in blocksworld arm  blocksworld noarm  freecell 
and pipesworld notankage  with r        the maximum runtime is above    seconds in
  domains  with r         in     however  with r              sp still completes in at
most   second for        and        of the instances respectively  compared to       
and        for analysis  iii   cf  above  
neither analysis  iii  nor search probing are stand alone methods  the former requires
all of torchlight except analyses  i ii   the latter requires the sampling of random states 
the respective total data is given in rows torchlight  iii  and sp total  sp s total in
table    here the picture changes dramatically in favor of sp and especially sp s   it should
   

fianalyzing search topology without running any search

be noted  though  that this is mostly due to the overhead for the translation to finite domain
variables  this overhead is an artifact of the implementation  our approach is defined
for finite domain variables  while the benchmarks are not  even though the finite domain
representation is in most cases more natural than the boolean one  further  many planners
 notably fast downward and its quickly growing set of derivatives  use the translation
anyway  the runtimes without translation are given in the row torchlight  iii  no fd 
as one would hope and expect  the analysis methods are much faster than actual planners  lama has     time outs in our test suite  ff has     
    analyzing domains
we now discuss the actual analysis outcomes  on a per domain basis  we first consider
only torchlight  then give some details on the comparison of analysis  iii  success rates to
those obtained by search probing  before we begin  a few words are in order regarding the
comparison between sp and sp s   with r                     the success rates are identical
in                               of our      benchmark instances respectively  in        
                       of the instances  the success rates differ by at most     thus  a
small runtime cut off does not adversely affect the success rates of search probing  because
long searches are rare   this being so  we henceforth do not discuss the data for sp vs 
sp s separately  we compare torchlights analysis  iii  success rates to those of sp only 
the guarantees of proposition   are confirmed  i e   guaranteed global analysis  i  succeeds as described in logistics  miconic strips  movie  and simple tsp  it never succeeds
in any other domain  though  in some domains  fractions of the gdgs are successful  precisely  the maximum fraction of successful gdgs is     in satellite      in ferry         in
tpp         in driverlog      in depots         in tyreworld  and       in blocksworldarm  however  if the fraction is below      then nothing is proved  so this data may at
best be used to give an indication of which aspects of the domain are good natured 
guaranteed local analysis  ii  generally is not much more applicable than global analysis 
thus we now concentrate on approximate local analysis  iii  exclusively 
proposition   is backed up impressively  even with r         analysis  iii  succeeds
in every single sample state of ferry  gripper  elevators  and transport    this indicates
strongly that the potentially sub optimal relaxed plans do not result in a loss of information
here  indeed  the analysis yields high success rates in almost all domains where local minima
are non present or limited  this is not the case for the other domains  and thus torchlight
can distinguish domains with easy h  topology from the hard ones  consider figure   
showing mean analysis  iii  success rates per domain with r       the picture is similar
for r                  cf  table   below  
the domains whose h  topology is not known are shown separately on the right hand
side in figure    for the other domains  we see quite nicely that harder domains tend
to have lower success rates  in particular  the easiest domains in the bottom class all have
     success rates      in the case of zenotravel   whereas the hardest domains in the
top right corner only have around     or less  in the latter domains  to some extent the
    historically  this observation preceded proposition    as well as the h  topology categorization of elevators and transport as per figure    that is  these hand made analyses were motivated by observing
torchlights analysis outcome 

   

fihoffmann

pipestank     
pipesnotank     
psr     

rovers      
opttele    

mystery     
mprime     
freecell     
airport    

hanoi    
blocksnoarm     
grid     
transport        
bench ed    c

local minima ed    c

blocksarm     
depots     
driverlog      

elevators        
logistics        
ferry        
gripper        
undirected

woodwork     
trucks    
tpp     
storage     
sokoban     
scanalyzer     

tyreworld      
dinphil     
satellite      
zenotravel     
miconicstr        
movie        
simpletsp        
harmless

recognized

pegsol    
pathways     
parcprinter    
openstacks    
unrecognized

figure    overview of torchlight domain analysis results     guaranteed global analysis
 i  always succeeds     approximate local analysis  iii  always succeeds if
provided an optimal relaxed plan  numbers shown are mean success rates per
domain  for approximate local analysis  iii  with r      i e   when sampling a
single state per domain instance 
low success rates result from the recognition of dead ends by ffs heuristic function  for
example  if during random sampling we make random vehicle moves consuming fuel  like
in mystery and mprime  then of course chances are we will end up in a state where fuel
is so scarce that even a relaxed plan does not exist anymore  this is most pronounced in
airport  where all sample states here have infinite heuristic values  however  the capabilities
of the analysis go far beyond counting states on recognized dead ends  in blocksworld arm 
for example  there are no dead ends at all and still the success rate is only      clearly
indicating this as a domain with a difficult topology 
to some extent  based on the success rates we can even distinguish pipesworld tankage
from pipesworld notankage  and mprime from mystery  in mprime  fuel can be transferred
between locations   the relatively high success rate in depots probably relates to its transportation aspects  in grid  in     of cases our analysis is not strong enough to recognize
the reasons behind non existence of local minima  these reasons can be quite complicated
 hoffmann         dining philosophers does not really have a favorable h  topology  its
rather excessive bound    is due to the very particular domain structure where philosophers
behave in strictly symmetrical ways  hoffmann         apart from this  the only strong
outliers are driverlog  rovers  hanoi  and blocksworld noarm  all of these are more problems of the hand made analysis than of torchlights  in driverlog and rovers  deep local
minima do exist  but only in awkward situations that dont tend to arise in the ipc instances  thus the hand made analysis  which is of a worst case nature  is too pessimistic
here  the opposite happens in hanoi and blocksworld noarm  where the absence of local
minima is due to rather idiosyncratic reasons  for example  in hanoi the reason is that h 
is always equal to the number of discs not yet in goal position  in the relaxation  one can
always accomplish the remaining goals one by one  regardless of the constraints entailed
by their positioning  hanoi and blocksworld noarm are not actually easy to solve for
   

fianalyzing search topology without running any search

domain
airport
blocks arm
blocks noarm
depots
din phil
driverlog
elevators
ferry
freecell
grid
gripper
hanoi
logistics
miconic
movie
mprime
mystery
opt tele
pipes notank
pipes tank
psr
rovers
satellite
simple tsp
transport
tyreworld
zenotravel
openstacks
parc printer
pathways
peg sol
scanalyzer
sokoban
storage
tpp
trucks
woodworking

si
 iii 
    
    
    
   
   
   
   
   
    
    
   
   
   
   
   
    
    
 
    
    
    
   
  
   
   
   
  
   
   
   
 
 
    
   
   
    
   

r  
 iii 
sp
   
   
         
    
   
    
   
         
   
   
   
   
   
   
         
    
   
   
   
        
   
   
   
   
   
   
         
         
        
         
         
         
   
   
   
   
   
   
        
   
   
  
   
 
   
   
   
         
 
  
         
         
         
         
 
 
         

r     
 iii 
sp
   
   
         
    
   
         
         
    
   
   
   
   
   
         
         
   
   
         
   
   
   
   
   
   
         
         
   
   
         
         
         
        
    
   
   
   
        
    
   
         
         
   
   
   
   
         
         
         
         
         
   
   
         

r      
 iii 
sp
   
   
         
         
         
         
         
   
   
   
   
         
         
   
   
         
   
   
   
   
   
   
         
         
   
   
         
         
         
        
    
   
   
   
        
    
   
         
         
   
   
   
   
         
         
         
         
         
   
   
         

 iii 
   
    
    
    
    
    
   
   
    
    
   
    
   
   
   
    
    
   
    
    
    
   
    
   
   
    
    
    
   
   
    
    
    
    
    
   
    

r       
sp
   
    
    
    
    
    
   
   
    
    
   
    
   
   
   
    
    
   
    
    
    
    
    
   
    
   
    
    
   
   
    
    
    
    
    
   
    

de
    
 
 
 
    
 
 
 
    
 
 
 
 
 
 
   
    
    
 
   
 
 
 
 
 
 
 
    
    
    
    
 
    
 
    
    
    

table    mean success rates per domain  upper part  domains whose h  topology was previously examined by hand  hoffmann        or is trivial to examine based on these
results  lower part  ipc           domains where that is not the case  columns
si  show data for analyzing the initial state only  columns r                   
for analyzing the respective number of sample states  columns  iii  give data
for approximate local analysis  iii   columns sp give data for search probing 
column de gives dead end rates for r        
ff  and in that sense  from a practical perspective  the low success rates of torchlights
analysis  iii  provide the more accurate picture 
table   gives a complete account of per domain averaged success rates data  including
all domains  all values of r  the rates obtained on initial states  and using sp instead of
torchlight  this serves to answer three questions 
    is it important to sample random states  rather than only analyzing the initial state 
    is it important to sample many random states 
   

fihoffmann

    how competitive is analysis  iii  with respect to a search based analysis 
the answer to question     is a clear yes  most importantly  this pertains to domains
with dead ends  cf  our brief discussion above  it is clear from table   that  in such domains 
analyzing si results in a tendency to be too optimistic  to see this  just consider the entries
for airport  dining philosophers  freecell  mystery  openstacks  parc printer  pathways 
tpp  trucks  and woodworking  all these domains have dead ends  for a variety of reasons 
the dead ends do not occur frequently at initial state level  but do occur frequently during
random walks  cf  column de in table     interestingly  in a few domains  most notably
the two pipesworlds  the opposite happens  i e   success rates are lower for si than for the
sample states  it is not clear to us what causes this phenomenon  
if we simply compare the si column with the r        column for analysis  iii   then
we find that the result is a lot different  more than      in    of the    domains  to
some extent  this difference between initial states and sample states may be just due to the
way these benchmarks are designed  often  the initial states of every instance are similar
in certain ways  no package loaded yet  etc   on the other hand  it seems quite natural  at
least for offline problems  that the initial state is different from states deeper down in the
state space  consider transportation problems or card games  for example  
the answer to question     is a clear no  for example  compare the r     and
r        columns for analysis  iii   the difference is greater than     in only   of the
   domains  the peak difference is in openstacks  with       for r        vs     for
r      the average difference over all domains is        similarly  comparing the r    
and r        columns for sp results in only   of    domains where the difference is greater
than      the peak being again in openstacks        for r        vs       for r     
the average difference over all domains is      
the answer to question     is a bit more complicated  look at the columns for analysis
 iii  respectively sp with r         the number of domains where the difference is larger
than     is now    out of     with a peak of       difference in scanalyzer  on the one
hand  this still means that in    out of    domains the analysis result we get is very close
to that of search  average difference         without actually running any search  on the
other hand  what happens in the other    domains  in all of these  the success rate of sp is
higher than that of torchlight  this is not surprising  it basically means that torchlights
analysis is not strong enough here to recognize all states that are not on local minima 
interestingly  this weakness can turn into an unexpected advantage  of the    domains in
question    domains  blocksworld arm  depots  mprime  pipesworld tankage  pipesworldnotankage  psr  scanalyzer  and sokoban  do contain deep local minima    thus  in these
  domains  we would wish our analysis to return small success rates  torchlight grants this
wish much more than sp does  consider what happens when using sp instead of analysis
 iii  in figure    for mystery  psr  and sokoban  the change is not dramatic  however 
blocksworld arm is marked with average success rate    instead of     putting it almost
on par with the very simple topology domains in the bottom class  similarly  pipesworldtankage  pipesworld notankage  and scanalyzer are put almost on par with these  depots
    sokoban has unrecognized dead ends  in the relaxation  blocks can be pushed across each other  and
therefore local minima  in scanalyzer  analyzing plants misplaces them as a side effect  and bringing
them back to their start position  across a large circle of conveyor belts  may take arbitrarily many steps 
see figure   for the other   domains 

   

fianalyzing search topology without running any search

actually receives a      putting it exactly on par with them  thus the sp analysis outcome
actually looks quite a bit worse  in   of the domains 
what causes these undesirably high success rates for sp  the authors best guess is that 
in many domains  the chance of randomly finding a state on a local minimum is low  in
large scale experiments measuring statistics on the search space surface under ffs heuristic
function  hoffmann         it was observed that many sampled states were not local minima
themselves  but where contained in valleys  within a valley  there is no monotonically
decreasing path to a goal state  such a state may not be a local minimum because  and only
because  one can descend deeper into the valley  it seems that sp correctly identifies most
valley states to not be local minima  thus counting as good many states that actually are
located in difficult regions of the search space  this is a weakness not of sp  but of success
rate as a search space feature    why does this weakness not manifest itself as much in
analysis  iii   because that analysis is more picky  it takes as good only states that
qualify for particular special cases  these tend to not occur as often in the difficult domains 
of course  it is easy to construct examples turning the discussed strength into a real
weakness of torchlights analysis quality  this just does not seem to happen a lot in the
present benchmarks  now  having said that  the present benchmarks arent well suited to
bring out the theoretical advantage of analysis  iii  either  the analysis offers unlimited
lookahead depth at low order polynomial cost  however  even with r         in    of the   
domains the highest exit distance bound returned is    i e   every exit path identified consists
of a single operator  these cases could be handled with a much simpler variant of analysis
 iii   looking only at operators o  that are directly applicable in s  and thus removing the
entire machinery pertaining to sg predecessors of x    still  that machinery does matter in
cases that are quite natural  the highest exit distance bound returned is    in grid and   in
transport  more generally  in any transportation domain with a non trivial road map  it is
easy to construct relevant situations  for example  say the road map in transport forms n
cities  each with diameter d and at least one vehicle  distances between cities being large
relative to d  then  in a typical state  around n vehicle moves will be considered helpful
by ff  at least   per city since local vehicles will be preferred by the relaxed plan  all
successor states will have identical h  until a package can be loaded unloaded  the typical
number of steps required to do so will grow with d  if  for example  the vehicle is in the
outskirts and the packages are in the city center  then around d   steps are required 
and finding an exit takes runtime around n d     then small values of n and d already
render search probing either devoid of information  if the runtime cut off is too small   or
computationally infeasible  recall that the probing should be a quick pre process to the
actual planning   by contrast  analysis  iii  easily delivers the correct success rate      
    predicting planner performance
as a direct measure of the predictive quality of success rates  we conducted preliminary
experiments examining the behavior of primitive classifiers  and of runtime distributions
for large vs  small success rates  we consider first the classifiers  they predict  given a
planning task  whether ehc ff lama will succeed in solving the task  within the given
    note that we cannot use valley rate instead  in a cheap domain analysis  since determining whether
or not s lies on a valley implies finding a plan for s and thus solving the task as a side effect 

   

fihoffmann

time and memory limits  the classifiers answer yes iff the success rate is  a threshold
t in                     obviously  to do this  we need r      we consider in what follows only
r      and r       because  as shown above  r        can be costly 
for ehc  both torchlight analysis  iii  and sp deliver fairly good quality predictions 
considering that no actual machine learning is involved  the prediction quality of torchlight is just as good as  sometimes slightly better than  that of search  whether we use
r      or r       does not make a big difference  ehc solves        of the instances  so
that is the rate of correct predictions for a trivial baseline classifier always answering yes 
for r       the best rate of correct predictions is        for torchlight  with t      
and        for sp  with t        for r        these numbers are         t       and
        t         dead end rate is a very bad predictor  its best prediction is for the
baseline classifier t      and the second best classifier  t        is only        correct 
interestingly  there are major differences between the different sets of domains  on the
domains previously analyzed by hand  hoffmann        as in figure   but without elevators
and transport   the best prediction is        correct for torchlight with t       and
       correct for sp with t        vs  a baseline of         on the ipc      domains 
these numbers are        and        vs  baseline         and t      in both cases  i e  
the best classifier is very close to the baseline  ipc       on the other hand  appears to be
exceptionally good natured  the numbers being         t       and         t       vs 
baseline         it is not clear to us what causes these phenomena   
in summary  the quality of prediction is always clearly above the baseline  around    
when looking at all domains  and even up to     when looking at the ipc      domains
only  for comparison  using state of the art classification techniques but only simple features  roberts and howe        get        correctness vs  baseline      for saying no  
on unseen testing domains for ff  having said that  if setting t in the above is considered
to be the learning  then the above does not actually distinguish between learning data
and testing data  roberts and howes unseen testing domains are those of ipc       in
a different setting than ours including also all adl test suites   if we set t on only the
domains from before       figure   without elevators and transport   then we get the
best prediction at t      for torchlight and t       for sp  with this setting of t   the
prediction correctness on our ipc      suite is        respectively        only  vs  the
baseline         on the other hand  this seems to pertain only to ipc      specifically 
for ipc       t      respectively t       are good settings  giving        respectively
       correctness vs  the baseline        
importantly  roberts and howe are not predicting the performance of ehc but that of
ff  which is a more complex algorithm  for ff and lama  the prediction quality of both
torchlight and sp is rather bleak  using the described primitive classifiers  in all cases 
the best prediction correctness is obtained when always answering yes  the best that
can be said is that success rate still predicts much better than dead end rate  to give some
example data  with r      across all domains for ff  the baseline is        correct  with
t       this goes down to        for torchlight         for sp  and        for dead end
rate  for lama  the baseline is        correct  and with t      this goes down to       
    the bad prediction quality in ipc      domains might be related to the fact that these are fully grounded 
potentially impeding the ability of fast downwards translator to find useful finite domain variables 

   

fianalyzing search topology without running any search

for torchlight         for sp  and        for dead end rate  for both ff and lama 
with growing t the prediction quality decreases monotonically in all cases 
why is prediction quality so much worse for ff than for ehc  which after all is the
main building block of ff  whereas ehc typically fails on tasks whose h  topology is
not favorable  ffs and lamas complete search algorithms are able to solve many of
these cases  too  for example  with torchlight success rates and r       ehc solves only
       of the tasks with success rate    and solves less than     up to success rate     
by contrast  ff and lama solve        respectively        of the tasks with success rate
   and solve at least     for all success rates 
despite this  success rates are far from devoid of information for ff and lama  setting
the threshold t in                  we look at the distribution of planner runtime in the instance
subset  a  where success rate is   t   vs  instance subset  b  where success rate is  t  
taking the null hypothesis to be that the means of the two runtime distributions are the
same  we run the students t test for unequal sample sizes to determine the confidence with
which the null hypothesis can be rejected  that is  we determine the confidence with which
distribution  b  has a lower mean than distribution  a   using torchlights success rate on
ff runtimes  with both r      and r        and in all    settings of t   we get a confidence
of at least        the difference between the means in our data  i e   the mean runtime of
 a  minus the mean runtime of  b   tends to grow over t   it peaks at     respectively    
seconds for r      respectively r        the average difference over all values of t is    
respectively      likewise  for lama runtimes all settings of t and r yield a confidence of
       with average differences     respectively      the results for sp are comparable for
lama  they are slightly worse for ff  though  with r      the confidence is       only
for t           the confidence is     for all other values of t   the difference peaks at    
seconds  vs      for torchlight   with an average of     seconds  vs        with r       
thresholds t                   yield       confidence  the average difference being     
again perhaps a little surprisingly  for the simpler planner ehc the runtime distributions behave very differently  for torchlight success rates  we do get several cases with
confidence        and average differences of around    seconds  for sp  in most cases we
get a       confidence that the mean of  b  is larger than that of  a   again  the reason
is simple  on many tasks with unfavorable h  topology  enforced hill climbing quickly exhausts the space of states reachable by ffs helpful actions  ehc then gives up on solving
the task  although it has consumed only little runtime  a peculiar behavior that one would
certainly not expect from a planner trying to be competitive 
summing up  success rates as a planning task feature provide a very good coverage
predictor for ehc even without any significant learning  for ff and lama  things are
not that easy  however the consideration of runtime distributions clearly shows that the
feature is highly informative  exploiting this informativeness for predicting planner performance presumably requires combination with other features  and actual machine learning
techniques  along the lines of roberts and howe         this is a topic for future research 
    diagnosis
let us finally consider torchlights diagnosis facility  the idea behind this facility is to
summarize the reasons for analysis failure  testing sufficient criteria for the absence of local
   

fihoffmann

minima  such diagnosis is not guaranteed to identify domain features causing their presence 
still  at least for analysis using theorem    the diagnosis can be quite accurate 
the current diagnosis facility is merely a first shot implementation based on reporting
all pairs  operator o    variable x  that caused an odg  for o  to not be successful  that is 
we report the pair  o    x  if o  has an effect on x  and a context fact  x  c  of the transition
t  taken by o  is contained in r    c   f    and is not recoverable by a sub sequence
 
of p  
 s   in brief  we record  o    x  if o  has a harmful effect on x  we perform a test
whether the main effect of o    i e   that on x    is invertible  in this case we do not record
x  since the problem appear to be the side effects  to avoid redundancies in the reporting 
we record not the grounded operator o  but only the name of the action schema  load
instead of load package  truck     similarly  as an option we record not x but the name
of the predicate underlying the fact  x  c   in that configuration  the diagnosis comes in the
form of action name  predicate name  which has a direct match with the high level pddl
input files  to have some measure of which parts of the diagnosis are more important 
we associate each pair with a count of occurrences  and weigh the pairs by frequency 
in zenotravel  the diagnosis output always has the form fly  fuel level and zoom 
fuel level  indicating correctly that its the fuel consumption which is causing the local
minima  in mprime and mystery  the cause of local minima is the same  however the
diagnosis is not as reliable because of the specific structure of the domain  associating fuel
with locations instead of vehicles  this sometimes causes the diagnosis to conclude that it
is the effect changing locations which is causing the trouble  concretely  with r       
in mystery  fuel consumption is the top weighted diagnosis in    out of the    tasks  in
mprime  this happens in    out of the    tasks  in satellite and rovers  the diagnosis
always takes the form switch on  calibrated respectively take image  calibrated  thus
reporting the problem to be that switching on an instrument  respectively taking an image 
deletes calibration  this is precisely the only reason why local minima exist here    in
tyreworld  most often the diagnosis reports the problem to be that jacking up a hub results
in no longer having the jack  which is needed elsewhere  too   while this does not actually
cause local minima  there are none   it indeed appears to be a crucial aspect of the domain 
similarly  in grid the most frequent diagnosis is that picking up a key results in the arm
no longer being empty  again  not actually a cause of local minima  but a critical resource
in the domain  in blocksworld arm  the dominant diagnoses are that a block is no longer
clear if we stack something on top of it  and that the hand is no longer empty when picking
up a block  similarly  in freecell  the dominant diagnoses are send to free  cellspace and
send to new col  colspace 
one could make the above list much longer  however it seems clear already that this
diagnosis facility  although as yet primitive  has the potential to identify interesting aspects
of the domain  note that we are making use of only one of the information sources in
torchlight  there are many other things to be recorded  pertaining to other reasons for
analysis failure  like support graph cycles etc  and also to reasons for analysis success  like
successful gdgs and x    o  pairs yielding successful odg  s  it appears promising to try
to improve diagnosis by combining some of these information sources  a combination with
    since analysis failure is rare in these two domains  often diagnosis does not give any output at all  with
r         the output is non empty in    instances of satellite and in   instances of rovers  for r      
this reduces to   instances in satellite  and not a single one in rovers 

   

fianalyzing search topology without running any search

other domain analysis techniques  like landmarks or invariants extraction  could also be
useful  this is a direction for future work   

   related work
there is no prior work  other than the aforementioned one of the author  hoffmann       
 trying to automatically infer topological properties of a heuristic function  thus our work
does not relate strongly to other domain analysis techniques  the closest relation is to other
techniques relying on causal graphs  in what follows we discuss this in some detail  along
with some other connections arising in this context 
if local analysis succeeds  then we can construct a path to the exit identified  in this 
our work relates to work on macro actions  e g   botea  muller    schaeffer        vidal 
       its distinguishing feature is that this macro action is  would be  constructed in a
very targeted and analytical way  even giving a guarantee  in the conservative case  to make
progress towards the goal  the machinery behind the analysis is based on causal graphs  and
shares some similarities with known causal graph based execution path generation methods
 e g   jonsson   backstrom        williams   nayak        brafman   domshlak        
the distinguishing feature here is that we focus on h  and individual states rather than
the whole task  this allows us to consider small fragments of otherwise arbitrarily complex
planning tasks  we look at odg  instead of sg  note that this ability is quite powerful
as far as applicability goes  as we have seen in section    the success rate of  local 
approximate analysis  and therewith the fraction of states for which we would be able to
generate a macro action  is non zero in almost all benchmark domains  of course  this
broad applicability comes with a prize  while traditional causal graph methods guarantee to
reach the goal  in the worst case the macro actions may only lead into h  local minima  still 
it may be interesting to look into whether other  traditional  causal graph based methods
can be localized in this  or a similar  manner as well 
global analysis  where we focus on the whole planning task and thus the whole causal
graph  is even more closely related to research on causal graphs based tractability analysis 
the major difference between tractability analysis and h  topology analysis  in principle 
is that tractability and absence of local minima are orthogonal properties  in general 
neither one implies the other  now  as we pointed out at the end of section    our global
analysis does imply tractability  of plan existence   vice versa  do the restrictions made in
known tractable classes imply the absence of local minima  in many cases  we can answer
this question with a definite no  some interesting questions are open  in a single case 
corresponding to our basic result  the answer is yes 
example   in appendix a   shows that one can construct a local minimum with just  
variables of domain size      arc sg  unary operators  and strongly connected dtgs with a
single non invertible transition  this example  and various scaling extensions not breaking
the respective conditions  falls into a variety of known tractable classes  the example is in
    in particular  fast downwards translator is not always perfect in detecting the finite domain variables
underlying benchmarks  for example  in satellite it often does not detect that electricity is available
in exactly one of the instruments mounted on a satellite  this can lead to pointless diagnosis output 
which for now is handled using a simple notion of predicates exchanged by every operator  for doing
things like this in a more principled manner  further invariants analysis would be useful 

   

fihoffmann

the tractable class f
n identified by domshlak and dinitz         because every transition of
the dependent variable depends on the other variable  the example is in helmerts       
      sas     class with strongly connected dtgs  the example is solved  i e   reduced
to the empty task  by haslums        simplification techniques  also  these techniques
solve tasks from the satellite domain  which do contain local minima   the example has
a fork and inverted fork causal graph  with bounded domain size and   dependent actions
only  actions with at most   prevail condition   thus it qualifies for the tractable classes
identified by katz and domshlak      b   the examples causal graph is a chain  and
thus in particular a polytree with bounded indegree  corresponding to the tractable class
identified by brafman and domshlak        except that  there  variables are restricted to
be binary  domain size     it is an open question whether plan existence with chain causal
graphs and domain size   is tractable  the strongest known result is that it is np hard for
domain size    gimenez   jonsson      b     similarly  the example fits the prerequisites
stated by katz and domshlak      a  except that these are for binary variables only  it
is an open question whether local minima exist in the tractable classes identified there 
finally  the example  and a suitable scaling extension  obviously qualifies for two theorems
stated by chen and gimenez         their theorem      more precisely  the first part of
that theorem  requires only a constant bound on the size of the connected components in
the undirected graph induced by the causal graph  the first part of their theorem    
requires a constant bound on the size of the strongly connected components in the causal
graph  and pertains to a notion of reversible tasks requiring that we can always go back
to the initial state 
next  consider the line of works restricting not the causal graph but the dtgs of the
task  backstrom   klein        backstrom   nebel        jonsson   backstrom        
the simplest class identified here  contained in all other classes  is sas   pubs where each
fact is achieved by at most one operator  post unique  p   all operators are unary
 u   all variables are binary  b   and all variables have at most one value required in
the condition of a transition on any other variable  single valued  s   now  example  
in appendix a   shows a local minimum in an example that has the u and s properties 
the example has two variables  x and y  and the local minimum arises because a cyclic
dependency prevents y from attaining its goal value dn via the shortest path as taken by
an optimal relaxed plan  if we remove all but two values from the domain of y  and remove
the alternative way of reaching dn     then the example still contains a local minimum and
also has the p and b properties  we remark that the modified example is unsolvable  it
remains an open question whether solvable sas   pubs tasks with local minima exist  more
generally  this question is open even for the larger sas   pus class  and for the  yet larger 
sas   iao class identified by jonsson and backstrom        
another open question is whether the  s class of jonsson and backstrom       
contains local minima  the class works on binary variables only  it requires unary operators
and acyclic causal graphs  however it allows facts to be splitting instead of reversible  if
p is splitting then  intuitively  the task can be decomposed into three independent subtasks with respect to p  it is an open question whether local minima can be constructed
    although  of course  it is clear that  if the dtgs are strongly connected as in our case  then deciding
plan existence is tractable no matter what the domain size is 
    this modification is given in detail below the example in appendix a   

   

fianalyzing search topology without running any search

while satisfying this property  disallowing the splitting option in  s  we obtain the single
positive case  where a known tractable class does not contain any local minima  this
class corresponds to our basic result  acyclic causal graphs and invertible transitions 
except that the variables are restricted to be binary  williams and nayak        mention
restrictions  but do not make formal claims regarding tractability  corresponding exactly
to our basic result except that they allow irreversible repair actions  the latter actions
are defined relative to a specialized formal framework for control systems  but in spirit they
are similar to what we term transitions with self irrelevant deletes herein 
finally  it is easy to see that  of bylanders        three tractability criteria  those two
allowing several effects do not imply the absence of local minima  for his third criterion 
restricting action effects to a single literal and preconditions to positive literals  but allowing
negative goals   we leave it as an open question whether or not local minima exist  we
remark that this criterion does not apply in any benchmark we are aware of 
to close this section  while we certainly do not wish to claim the identification of
tractable classes to be a contribution of our work  we note that the scope of theorem   
which is a tractable class  cf  the above  is not covered by the known tractable classes   
the tractable cases identified by bylander        obviously do not cover any of logistics 
miconic strips  movie  and simple tsp  many causal graph based tractability results
require unary operators  jonsson   backstrom        domshlak   dinitz        brafman   domshlak        helmert              katz   domshlak      a      b  jonsson 
      gimenez   jonsson            a   which does not cover miconic strips  movie 
and simple tsp  in the work of chen and gimenez         theorem     requires reversibility which is not given in either of movie  miconic strips  or simple tsp  and
theorem     requires a constant bound on the size of the connected components in the
undirected graph induced by the causal graph  which is given in none of logistics  miconicstrips  and simple tsp  other known tractability results make very different restrictions
on the dtgs  backstrom   klein        backstrom   nebel        jonsson   backstrom 
       even the most general tractable class identified there  sas   iao  covers none of
miconic strips  logistics  and simple tsp  because vehicle variables are not acyclic
with respect to requestable values   and neither does it cover movie  because rewinding a
movie is neither unary nor irreplaceable  it has a side effect un setting the counter  while
not breaking the dtg of the counter into two disjoint components  
as far as coverage of the benchmarks goes  the strongest competitor of theorem   are
haslums        simplification techniques  these iteratively remove variables where all
paths relevant for attaining required conditions are free  i e   can be traversed using transitions that have neither conditions nor side effects  haslums theorem   states that such
removal can be done without jeopardizing solution existence  i e   a plan for the original
task can be reconstructed easily from a plan for the simplified task  in particular  if the
task is solved  simplified completely  to the empty task  then a plan can be constructed
in polynomial time  haslum combines this basic technique with a number of domain reformulation techniques  e g   replacing action sequences by macros under certain conditions 
the choice which combination of such techniques to apply is not fully automated  and parts
    this is not true of our basic result  which as just explained is essentially covered by the works of jonsson
and backstrom        and williams and nayak         formally  its prerequisites imply those of  the
first part of  theorem     in the work of chen and gimenez         namely  the postulated bound is   

   

fihoffmann

of these techniques are not fully described  making a comparison to theorem   difficult 
haslum reports his techniques to solve tasks from logistics  miconic strips  and movie 
plus gripper and satellite  haslum does not experiment with simple tsp  his theorem   
in its stated form  does not solve simple tsp  because there the transitions of the root
variable have side effects  with irrelevant deletes   extending the theorem to cover such
irrelevant deletes should be straightforward  a more subtle weakness of haslums theorem   relative to our theorem   pertains to reaching required values from externally caused
values  haslum requires these moves to be free  whereas  in the definition of recoverable
side effect deletes  theorem   allows the recovering operators to affect several variables and
to take their precondition from the prevails and effects of o   

    conclusion
we identified a connection between causal graphs and h    and devised a tool allowing to
analyze search space topology without actually running any search  the tool is not yet
an automatic hoffmann  but its analysis quality is impressive even when compared to
unlimited search probing 
at a very generic level  a conclusion of this work is that  sometimes  it is possible to
automatically infer topological properties of a heuristic function  an interesting question
for future work is whether this can also be done for heuristics other than h   cf  also the
comments regarding causal graph research below   methodologically  it is noteworthy that
the analysis is based on syntactic restrictions on the problem description  which has traditionally been used to identify tractable fragments  of planning and other computationally
hard problems   the present work showcases that very similar techniques can apply to the
analysis of the search spaces of general problem solvers 
a main open question is whether global analysis can more tightly approximate the scope
of theorem    as indicated  a good starting point appears to be trying to include  in a gdg
for operator o    only variable dependencies induced by operators o that may actually precede
o  in an optimal relaxed plan  an approach automatically recognizing such operators could
possibly be developed along the lines of hoffmann and nebel      b   or using a simplified
version of the aforementioned fact generation tree analysis technique  hoffmann        
additionally  it would be great to recognize situations in which harmful side effects of o 
 like making the hand non empty if we pick up a ball in gripper  will necessarily be
recovered inside the relaxed plan  possibly  such analysis could be based on a variant of
action landmarks  hoffmann  porteous    sebastia        karpas   domshlak        
another interesting line of research is to start from results given for individual states s
by local analysis  then extract the reasons for success on s  and generalize those reasons to
determine a generic property under which success is guaranteed  taken to the extreme  it
might be possible to automatically identify domain sub classes  i e   particular combinations
of initial state and goal state  in which the absence of local minima is proved 
this work highlights two new aspects of causal graph research  first  it shows that  in
certain situations  one can localize the causal graph analysis  and consider only the causal
graph fragment relevant for solving a particular state  second  one can use causal graphs
for constructing paths not to the global goal  but to a state where the value of a heuristic h
is decreased  the former enables the analysis to succeed in tasks whose causal graphs are
   

fianalyzing search topology without running any search

otherwise arbitrarily complex  and thus has the potential to greatly broaden the scope of
applicability  the latter is not necessarily limited to only h   as a simple example  it is
obvious that similar constructions can be made for the trivial heuristic counting the number
of unsatisfied goals  and thus opens up a completely new avenue of causal graph research 
another possibility is planner performance prediction  along the lines of roberts and
howe         our experimental results indicate that torchlights problem features  and
also those of search probing  are highly informative  this has the potential to significantly
improve the results of roberts and howe for unseen domains  they currently use only very
simple features  like counts of predicates and action schemes  that hardly capture a domainindependent structure relevant to planner performance  like limited search probing  sp s   
torchlight generates its features without jeopardizing runtime  thus enabling automatic
planner configuration  unlike for search probing  this may even work on line during search 
a single relaxed plan can already deliver interesting information  for example  one might
make the search more or less greedy  choosing a different search strategy  switching helpful
actions on or off  etc   depending on the outcome of checking theorem   
as mentioned in section    a direction worth trying is to use local analysis for generating
macro actions  in domains with high success rate  it seems likely that the macro actions
would lead to the goal with no search at all  it is a priori not clear  though  whether such
an approach would significantly strengthen  at least in the present benchmarks  existing
techniques for executing  parts of  a relaxed plan  e g   vidal        
one could use torchlights diagnosis facility as the basis of an abstraction technique
for deriving search guidance  much as is currently done with other relaxation abstraction
techniques  the diagnosis can pin point which operator effects are causing problems for
search  if we remove enough harmful effects to end up with a task to which theorem  
applies  then the abstracted problem is tractable  for example  in transportation domains 
this process could abstract away the fuel consumption  if we do not abstract that much 
then the information provided may still outweigh the effort for abstract planning  i e   for
using an actual planner inside the heuristic function  for example  in grid the abstract task
could be a problem variant allowing to carry several keys at once  one could also focus the
construction of different heuristics  not based on ignoring deletes  on the harmful effects 
finally  an interesting research line is domain reformulation  as is well known  the
domain formulation can make a huge difference for planner performance  however  it is
very difficult to choose a good formulation  for a given planner  this is a black art even if
the reformulation is done by the developer of the planner in question  the lack of guidance is
one of the main open problems identified by haslum        for his automatic reformulation
approach  the most frequent question the author has been asked by non expert users is
how to model a domain so that ff can handle it more easily 
torchlights diagnosis facility  pin pointing problematic effects  might be instrumental
for addressing these difficulties  for the case where the reformulation is done by a computer 
one possibility to use the analysis outcome could be to produce macro actions hiding
within them the operators having harmful effects  another possibility could be to precompose variable subsets touched by the harmful effects 
for the case where the reformulation is done by a human user  the sky is the limit 
to name just one example  the local minima in satellite could be removed by allowing
to switch on an instrument only when pointing in a direction where that instrument can
   

fihoffmann

be calibrated  more generally  note that end user pddl modeling  writing of pddl
by a non expert user wanting to solve her problem using off the shelf planners  is quite
different from the pddl modeling that planning experts do when developing benchmarks 
for example  if an expert models a transportation benchmark with fuel consumption  then
it may seem quite pointless for torchlight to determine that fuel consumption will hurt
planner performance  indeed this may be the reason why the fuel consumption was included
in the first place  by contrast  for an end user  a  this information may come as a surprise 
and  b  the user may actually choose to omit fuel consumption because this may yield a
better point in the trade off between planner performance and plan usability  generally
speaking  such an approach could give the user guidance in designing a natural hierarchy
of increasingly detailed  and increasingly problematic  domain formulations  this could
help making planning technology more accessible  and thus contribute to a challenge that
should be taken much more seriously by the planning community 

acknowledgments
i would like to thank the anonymous reviewers of both  the article at hand and the icaps
     short version  for their constructive comments  in particular  one of the reviewers
proved the completeness results in theorem    and another reviewer suggested the future
research line trying to generalize the reasons for success in local analysis 
i thank carmel domshlak for discussions  feedback on early stages of this work  contributing in particular the d abstracted task construction in the proof of lemma    and
an executive summary of the status quo of causal graph research 
a very special thanks goes to carlos areces and luciana benotti  for inspiring this
work in the first place  i had long ago given up on this problem  it was carlos and
lucianas insistence that finally made me see the connection to causal graphs  while trying
to convince them that an analysis like this is impossible 

appendix a  technical details and proofs
we give the full proofs and  where needed  fill in some technical definitions  we first
prove our complexity result  appendix a    theorem     then the result pertaining to the
analysis of optimal relaxed plans  appendix a    theorem     then the result pertaining to
conservative approximations  appendix a    theorems   and     we construct a number
of examples relevant to both kinds of analysis  appendix a     before giving the proofs of
domain specific performance guarantees  appendix a    propositions   and    
a   computational complexity
theorem    it is pspace complete to decide whether or not the state space of a given
planning task contains a local minimum  and given an integer k it is pspace complete to
decide whether or not for all states s we have ed s   k  further  it is pspace complete
to decide whether or not a given state s is a local minimum  and given an integer k it is
pspace complete to decide whether or not ed s   k 
   

fianalyzing search topology without running any search

proof  throughout the proof  since pspace is closed under complementation  we do not
distinguish the mentioned pspace complete decision problems from their complements 
the membership results are all easy to prove  note first that  given a state s  we can
compute h   s  within polynomial space  generate a potentially non optimal relaxed plan 
of length n  with the known methods  then iteratively decrement n and test for each value
whether a relaxed plan of that length still exists  stop when that test answers no  the
test for bounded relaxed plan existence is in np and thus in pspace  from here  we
can prove the membership results by simple modifications of the guess and check argument
showing that plansat  the problem of deciding whether a given planning task is solvable 
is in npspace and hence in pspace  bylander         that argument works by
starting in the initial state  guessing actions  and terminating successfully if a goal state
is reached  unsuccessful termination occurs if the guessed path is longer than the trivial
upper bound b    xx  dx   on the number of different states  to be able to check this
condition in polynomial space  the path length is maintained in a binary counter 
to decide whether a given state s is  not  a local minimum  we run this guess and check
algorithm from s  modified to  compute h  for each encountered state  to terminate unsuccessfully if the bound b is exceeded or if h  increases after an operator application  and
to terminate successfully if h  decreases after an operator application  to decide whether
ed s   k  we use the same algorithm except that the bound b is replaced by the bound k 
increases of h  are permitted  and success occurs if h  decreases from h   s  to h   s    to
decide whether the state space of an entire planning task contains local minima  or whether
all states s in the state space have ed s   k  we simply run bylanders guess and check
algorithm as a way of enumerating all reachable states  then for each individual state s we
run the modified guess and check algorithms just described  clearly  all these algorithms
run in non deterministic polynomial space  which shows this part of the claim 
we now show the pspace hardness results  we first consider the problem of deciding whether or not a given state s is a local minimum  the proof works by reducing
plansat  which is known to be pspace hard for propositional strips  bylander 
       from which it trivially follows that plansat is pspace hard also for the finitedomain variable planning tasks we use herein 
let  x  si   sg   o  be the planning task whose solvability we wish to decide  we design
a modified task  x     s i   s g   o    by starting with  x  si   sg   o  and making the following
modifications 
 add a new variable chooset ask to x     with
s i  chooset ask    nil  and s g  chooset ask  undefined 

domain

 nil  org  alt  

the role of this variable will be to give the planner a choice whether to solve the
original task  x  si   sg   o   or whether to solve an alternative task custom designed
for this proof 
 add a new variable distalt to x     with domain         s i  distalt       and
s g  distalt      
this variable simply serves to control the length of the solution of the alternative task 
that solution length will be   plus the number of steps needed to bring distalt from
   

fihoffmann

value   to its goal value   here  only   step will be needed for doing so  later on in
this proof  we will increase this distance  
 add two new operators oorg      chooset ask  nil      chooset ask  org    and
oalt      chooset ask  nil      chooset ask  alt    distalt       
this implements the choice of planning task  note that  if we choose the alternative
task  then distalt is set to    thus forcing the solution to bridge this distance  by
contrast  for the original task  this variable keeps residing in its goal value as was
already assigned by s i  distalt  
 add a new operator odistalt      chooset ask  alt    distalt         distalt       
this allows to bridge the distance intended for the solution of the alternative task 
 add a new operator osg alt      chooset ask  alt    distalt       sg   
this allows us to accomplish the original goal  as the final step in solving the alternative task 
 add  chooset ask  org  as a new precondition into all original operators  i e   those
taken from o 
this forces the planner to choose the original task  for executing any of its operators 
 add a new variable stillalive to x  with domain  yes  no   s i  stillalive    yes 
and sg  stillalive    yes  add a new operator osg dead      sg    stillalive  no    
the osg dead operator allows us to accomplish the original goal in a single step  no
matter which task we have chosen to solve  and also in the new initial state s i already 
however  the operator also sets the new variable stillalive to value no  whereas the
goal value of that variable is yes  that value cannot be re achieved  and thus the
operator leads into a dead end  its function in the proof is to flatten the value of
h  in the original task  and in s i   to be constantly   unless we are in a goal state 
this extreme flattening does not happen in the alternative task because  there  the
distance variable distalt also needs to be handled 
in summary   x     s i   s g   o    is designed by setting 
 x      x   chooset ask  distalt  stillalive 
 s i    si    chooset ask  nil    distalt       stillalive  yes  
 s g    sg    distalt       stillalive  yes  
 o       pre    chooset ask  org    eff     pre  eff   o    oorg   oalt   odistalt   osg alt  
osg dead  
now consider the new initial state s i   it has exactly three successor states  sdead produced by osg dead   sorg produced by oorg   and salt produced by oalt   we have h   sdead    
 because sdead  stillalive    no  we have h   s i     h   sorg       due to the relaxed
   

fianalyzing search topology without running any search

plan hosg dead i  finally  we have h   salt       because oalt sets the distalt variable to  
whereas its goal is    thus a shortest relaxed plan for salt is hodistalt   osg alt i 
from this  it clearly follows that s i is not a local minimum iff sorg has a monotone
path to a state s with h   s    h   sorg    since h   sorg        the latter is equivalent to
the existence of a monotone path from sorg to a goal state  i e   a path to a goal state on
which h  is constantly    since  for all states reachable from sorg   the single step sequence
hosg dead i is a relaxed plan  this is equivalent to the existence of a path from sorg to a goal
state  clearly  the latter is equivalent to solvability of the original task  x  si   sg   o   thus
s i is not a local minimum iff  x  si   sg   o  is solvable  which shows this part of the claim 
we next prove pspace hardness of deciding whether or not a given planning task
contains a local minimum  this follows easily from the above  observe that the alternative
task does not contain any local minima  as described  we have h   salt        if we apply
odistalt to salt   then we obtain a state saltdist where h   saltdist       because of the relaxed
plan hosg alt i  applying osg alt in saltdist yields a goal state  and thus both salt and saltdist
have better evaluated neighbors  any other states descending from salt must be produced
by osg dead and thus have h  value   so   x     s i   s g   o    contains a local minimum iff the
part of its state space descended from sorg does  since all those states have h  value   unless
they are goal states  cf  the above  the latter is equivalent to unsolvability of  x  si   sg   o 
which shows this part of the claim 
assume now that we are given an integer k and need to decide for an individual state s
whether or not ed s   k  we reduce bounded plansat  the problem of deciding whether
any given planning task is solvable within a given number of steps  bounded plansat
is known to be pspace complete if the bound is given in non unary representation  we
modify the task  x     s i   s g   o    given above  in a way that increases the solution length of
the alternative task to be k  we introduce a binary counter using dlog   k   e new binary
variables biti that are all at   in si   we introduce an operator for each bit  allowing to set
the bit to   if all the lower bits are already    and in effect setting all these lower bits back
to o  each such operator has the additional precondition  chooset ask  alt   but has no
effect other than modifying the bits  we then modify the operator odistalt by adding new
preconditions encoding counter position k    with this construction  clearly h   salt       
and the distance to goal of salt is k  a plan is to count up to k     then apply odistalt  
then apply osg alt   thus  the shortest exit path for si via oalt has length k      but then 
with the above  ed si    k iff  x  si   sg   o  has a plan of length at most k     which
concludes this part of the claim 
finally  say we need to decide whether or not  for all s  s  we have ed s   k  note
first that salt and all its successors necessarily have exit distance at most k  the goal can be
reached in at most that many steps   and that the exit distance of sorg and all its successors
is equal to the length of a shortest plan for the corresponding state in  x  si   sg   o   the
latter length may  for some states in  x  si   sg   o   be longer than k even if the shortest
plan for  x  si   sg   o   i e   for the original initial state  has length k  we thus introduce
another binary counter  this time counting up to k     conditioned on  chooset ask  org  
and with a new operator whose precondition demands the new counter to be at k    and
that achieves all goals  then  clearly  sorg and all its descendants have exit distance at most
k  thus the only state that may have exit distance greater than k is s i  precisely  we
   

fihoffmann

have ed s i     k     iff the new counter is the shortest plan for sorg   which obviously is the
case iff  x  si   sg   o  has no plan of length at most k    this concludes the argument 
a   analyzing optimal relaxed plans
we need to fill in some notations  for the sake of self containedness of this section  we first
re state the definitions given in section   
definition    let  x  si   sg   o  be a planning task  let s  s with     h   s      let
p    s  be an optimal relaxed plan for s  let x   x  and let o   p    s  be an operator taking
a relevant transition of the form t     s x     c  
an optimal rplan dependency graph for p    s   x  and o    or optimal rplan dependency
graph for p    s  in brief  is a graph odg     v  a  with unique leaf vertex x    and where
x  v and  x  x     a if either  x    x    x  xpreo   and preo   x     s x   or x    x  
 
 
 s  taking a relevant transition on x  so that x  xpreo
v    x    and there exists o  p  
and preo  x     s x  
for x  v    x     by odt g 
x we denote the sub graph of dt gx that includes only
 
 s  x   the relevant transitions t using an operator in
the values true at some point in p  
 
p    s  x   and at least one relevant inverse of such t where a relevant inverse exists  we
 
 s  x  transitions as original  and to the inverse transitions as induced 
refer to the p  
definition    let  x  si   sg   o   s  p    s   x    t    and odg     v  a  be as in definition   
we say that odg  is successful if all of the following holds 
    odg  is acyclic 
    we have that either 
 
 s  recoverable  or
 a  the odg   relevant deletes of t  are p  
 
 b  s x    is not odg  relevant  and t  has replaceable side effect deletes  or
 c  s x    is not odg   relevant  and t  has recoverable side effect deletes 

    for x  v    x     all odt g 
x transitions either have self irrelevant deletes  or are
invertible induced and have irrelevant side effect deletes and no side effects on v   x    
we next define two general notions that will be helpful to state our proofs 
 the prevail condition prevo of an operator o  o results from restricting preo to the
set of variables xpreo   xeff o  
 let x  x  let  c  c    be a transition in dt gx   and let  y  d   seff c  c    be a side
effect of the transition  the context of  y  d  in  c  c    is ctx c  c    y  d    
 
 y  prerop c c     y  
y  xprerop c c   
  y  d      d   dy   d     d  y   xprerop c c   
the context of  c  c    is the set ctx c  c    of all partial variable assignments  so that  for
every  y  d   seff c  c     y  x and  y   y    ctx c  c    y  d   we identify ctx c  c   
with the set of all facts that occur in any of its assignments 
   

fianalyzing search topology without running any search

note here that the definition of ctx c  c    over writes our previous one from section   
but only in the sense that we now also distinguish all possible tuples of context values 
rather than just collecting the overall set  we need the more fine grained definition to
precisely formulate definition   condition   c   i e   under which conditions a transition
has recoverable side effect deletes  namely  definition   conditions   b  and   c  are
formalized as follows 
 a transition  c  c    has replaceable side effect deletes iff ctx c  c   sg    and  for every
rop c  c       o  o where preo  ctx c  c        there exists o   o so that eff o    eff o
and preo   prevrop c c     eff rop c c     
 a transition  c  c    has recoverable side effect deletes iff the following two conditions
hold 
 either  c  c    has irrelevant side effect deletes or  for every   ctx c  c     there
exists a recovering
s operator o so that preo  prevrop c c     eff rop c c    and eff o   
eff o     sg  rop c c     o  o preo    
 every  y  d   seff c  c    is not in the goal and appears in no operator precondition
other than possibly those of the recovering operators 
if t  has replaceable side effect deletes  then upon its execution we can remove o  from
the relaxed plan because any operator relying on deleted facts can be replaced  if t  has
recoverable side effect deletes  then  due to the first clause of this definition  no matter what
the state s  in which we apply t  is  no matter which context  holds in s   we have a
recovering operator o that is applicable after t  and that re achieves all relevant facts  due
to the second clause  o will not delete any facts relevant elsewhere in the relaxed plan  note
here that anything deleted by o must have been a side effect of t    
finally  to formally define the notion used in definition   condition   a   the odg   
 s  recoverable  we now assume the surroundings pertaining
relevant deletes of t  are p  
to theorem    i e    x  si   sg   o  is a planning task  s is a state  p    s  is an optimal relaxed
plan for s  odg     v  a  is an optimal rplan dependency graph with leaf variable x  and
transition t     s x     c  with responsible operator o    we are considering a state s  where
t  can be executed  reaching a state s    and we are examining a relaxed plan p   for s 
 
constructed from p    s  by removing o    and by replacing some operators of p  
 s  with
 
operators responsible for induced odt gx transitions for x  v    x    
 by c       x    s x       ctx t    we denote the values potentially deleted by t   
 by r   we denote the union of sg   the precondition of any p    s  operator other than
o    and the precondition of any operator which is the responsible operator for an
induced transition in odt g 
x   with x  v    x     as discussed in section    this is a
super set of the facts possibly needed in p    
s
 by f     s  op    s  eff o we denote the set of facts true after the relaxed execution
  

 
of p  
 s  in s  as discussed in section    if p   f  then p is not needed in s  for p  
to be a relaxed plan 

   

fihoffmann

 by s  we denote the union of      prevo   eff o        the set of facts  x  c   s where
 
there exists no o such that x  xeff o and o is either o  or in p  
 s  or is the responsible
 
operator for an induced transition in odt gx   with x  v    x         the set f defined
as f      x  c     x  c   f    x  v    x     if xeff o    v    x         else f      here 
    and     are facts of which we are certain that they will be true in s        is a set of
facts that we will be able to achieve at the start of p     by appropriately re ordering
the operators 

   s   then the relaxed plan macro precondition
 if 
o   ho            on i is a sub sequence
of p s
sn
i 


 
of o is defined as pre
   i    preoi   j  
eff oj    the relaxed plan macro effect of

o s
n




 
o is defined as eff 
   i   eff oi   if o is empty then both sets default to the empty

o
set  these notions simply capture the outside needs and effects of a relaxed plan
sub sequence 
 
 
 s  recoverable iff p  
 s  contains a sub the odg   relevant deletes of t  are p  


 
 
 
sequence o  so that pre

s
and
eff

c

f
 
the
first condition here

r



 
 
 
 
o 
o 


ensures that o  will be applicable at the appropriate point within p     the second

o   
clause ensures that all facts relevant for p   will be re achieved by 

we now proceed with our exit path construction  in what follows  we first consider the
part of the path leading up to s    i e   where we move only the non leaf variables x  v   x    
we show how to construct the relaxed plans p    s    for the states s  visited on this path 
first  note that we can assume p    s  to be sorted according to the optimal rplan
dependency graph odg     v  a   precisely  let xk           x  be a topological ordering of
v    x    according to the arcs a  due to the construction of  v  a  as per definition   
and because previous values are never removed in the relaxed state space  we can re order
 
 
 s  x     p   that is  we can perform all moves
 s  xk        p  
p    s  to take the form p  
 
within each odt gx up front  in an order conforming with a  we will henceforth assume 
wlog  that p    s  has this form 
 
recall in what follows that original odt g 
x transitions are those taken by p    s  
whereas induced odt g 
x transitions are those included as the inverse of an original tran

sition  for a path 
p of invertible transitions traversing hc            cn i  the inverse path 
p


traverses hcn           c  i by replacing each transition with its inverse  by rop  p   we denote
the operator sequence responsible for the path 
we say that a state s   s is in the invertible surroundings of s according to odg  if s  is

reachable from s by executing a sequence 
o of responsible operators of invertible induced
 
transitions in odt gx for x  v    x     the adapted relaxed plan for such s    denoted
p    ss     is constructed as follows  let xk           x  be a topological ordering of v    x   
according to a  and denote p    s    p    s  xk        p    s  x     p   initialize p    ss      

p    s   then  for each xi  v    x     let 
p be a path of original invertible transitions in

 
 
odt gxi leading from s xi   to s  xi    clearly  such a path must exist  remove rop 
p   from


 
 
 
 
p  ss    and insert rop  p   at the start of p  ss   xi   
we next show that adapted relaxed plans indeed are relaxed plans  under restricting
conditions that are in correspondence with definition   condition     
lemma    let  x  si   sg   o  be a planning task  let s  s be a state with     h   s     
and let p    s  be an optimal relaxed plan for s  say that odg     v  a  is an optimal rplan
   

fianalyzing search topology without running any search

dependency graph for p    s  where  for every x  v    x     the invertible induced odt g 
x
transitions have irrelevant side effect deletes and no side effects on v    x     let s   s be
a state in the invertible surroundings of s according to odg    then p    ss    is a relaxed
plan for s    and  p    ss       p    s   
 
 
proof  by definition  we know that p    s  takes the form p  
 s  xk        p  
 s  x     p  
 
 
 
 
 
 
and that p  ss   takes the form p    s   xk        p    s   x     p   where xk           x  is a
topological ordering of v   and p is some operator sequence that is common to both  but
whose content will not be important for this proof  for simplicity  we denote in the rest of
the proof p    ss    as p    s     and we leave away the     subscripts 

consider first the  relaxed  execution of p    s  xk   and p    s    xk    say that 
p is the
   s     i e   a path of original invertible
path in odt g 
considered
in
the
definition
of
p
xk


 
transitions in odt g 
xi leading from s xk   to s  xk    clearly  ho            on i    rop  p   is a

sub sequence of p    s  xk    say that 
p visits the vertices s xk     c            cn   s   xk    denote
c     c            cn    assume wlog that p    s  xk   starts with ho            on i  note here that we
can re order p    s  xk    and relaxed plans in general  in any way we want as long as we
do not violate operator preconditions  the latter is not the case here because  ho            on i
constitutes a path in odt g 
xk   because all other operators depending on a value in c are

ordered to occur later on in p    s  xk    and because  since all transitions in 
p have no side
effects on v   x     by construction of  v  a  as per definition   the operators in ho            on i
do not support each other in any way  in p    s   other than by affecting the variable xk  
given the above  wlog p    s  xk   has the form ho            on i  p    by construction 



 
p  s    xk   has the form rop 
ps
   p     h
o
n           o  i  ps
    consider now the endpoints
n
 
 
 
of the prefixes  i e   s     s  i   eff oi and s     s   i n eff 
oi   clearly  since all the

transitions on 
p have irrelevant side effect deletes  we have that the relevant part of s is
contained in s    but then  as far as the variables outside v    x    xk   are concerned  the
 
relevant part of s 
  is contained in s    any relevant side effects of ho            on i are already
 
contained in s   the values c are obviously true in s 
    if the induced transitions have side


 
o
effects  then these can only increase the fact set s    further  the sequence h
n           o  i is
applicable in the relaxation  to see this  note first that the preconditions on xk itself are


satisfied by definition  because h
o
n           o  i constitutes a path in dt gxk   any side effects  if
they occur  are not harmful because old values are not over written in the relaxation  as for
preconditions on other variables  due to invertibility  the outside conditions of 
oi are contained in those of oi  those are a subset of those for ho            on i  hence  with definition  
and since xk has no incoming edges in odg    all these preconditions are satisfied in s  they
are then also satisfied in s  because  vk being a root of odg    these variables x are not
contained in v and hence s   x    s x  by prerequisite  note here that precondition facts
cannot have been deleted by the side effects whose deletes are irrelevant by prerequisite 
the above has shown that the relevant part of the outcome of relaxed execution of
p    s  xk   in s is contained in the outcome of relaxed execution of p    s    xk   in s    on all
variables outside v    x    xk    we can now iterate this argument  assume as induction
hypothesis that we have already shown that the relevant part of the outcome of relaxed
execution of p    s  xk          p    s  xi     in s is contained in the outcome of relaxed execution
of p    s    xk        p    s    xi     in s    on all variables outside v    x    xk           xi      now
consider p    s  xi   and p    s    xi    the only thing that changes with respect to xk above
is that there may be preconditions on variables xj that are not true in s  we have j   i

   

fihoffmann

because such preconditions must belong to predecessors of xi in odg  by definition   
since p    s    p    s  xk        p    s  x     p is a relaxed plan for s  those conditions are
established after relaxed execution of p    s  xk        p    s  xi     in s  given this  by
induction hypothesis the conditions  which are clearly not irrelevant  are established also
after relaxed execution of p    s    xk        p    s    xi     in s    which concludes the argument
for the inductive case  with i      it follows that the relevant part of the outcome of relaxed
execution of p    s  xk        p    s  x    in s is contained  on all variables  in the outcome of
relaxed execution of p    s    xk        p    s    x    in s    from this  the claim follows trivially
because p    s  is a relaxed plan for s  and the remainder p of both operator sequences is
identical 
the second part of the claim follows because  for any i    j  we have that the original
transitions we use for xi respectively xj have no operators in common  this is because  as
argued above  all the relevant operators have no side effects on v    x     since each of these
operators affects the variable xi   it cannot affect any other variable in v    x     thus  for
each inverse transition that we introduce via an inverse operator  p    s  contains a separate
operator  from this  obviously we get that  p    ss       p    s   
lemma   captures the second case of definition   condition      transitions that are
invertible induced and have irrelevant side effect deletes and no side effects on v    x    
the next lemma captures the first case of definition   condition     
lemma    let  x  si   sg   o  be a planning task  let s  s be a state with     h   s     
and let p    s  be an optimal relaxed plan for s  say that odg     v  a  is an optimal rplan
dependency graph for p    s  where  for every x  v    x     the invertible induced odt g 
x
transitions have irrelevant side effect deletes and no side effects on v    x     let s   s be a
state in the invertible surroundings of s according to odg    let s   be a state reached from
s  by a p    ss    x  operator o constituting a transition  c  c    for x  v   where s   x    c 
that has self irrelevant deletes  then removing o from p    ss    yields a relaxed plan for
s    
proof  by lemma    p    ss    is a relaxed plan for s    now  upon execution of o  in s    
its effects are true  i e   we have  x  c    and any side effects  if present   on the other hand 
obviously the only facts  z  e  that are true in s  but not in s   are in ctx c  c     x  c    since 
by prerequisite  the transition  c  c    has self irrelevant deletes  all facts in ctx c  c     x  c  
are either irrelevant or rop c  c    only relevant  meaning they are not in the goal and occur
in no operator precondition other than  possibly  that of o itself  the claim follows directly
from that 
we remark that a much more easily formulated  and more general  version of lemma  
could be proved simply by associating the notion of self irrelevant deletes with operators
rather than transitions  and postulating only that o be used in p    s   that argument
corresponds to part  a  in the proof to lemma   in the authors previous work  hoffmann 
       we state the argument in the particular form above since that will be the form we
need below 
we are now almost ready to prove the main lemma behind our exit path construction 
we need one last notation  capturing a simpler form of the cost function costd  odg   
   

fianalyzing search topology without running any search

that we considered in section    the simpler function does not make use of the shortcut construction pthat construction will be introduced separately further below  we define
costd  odg       xv costd  x   where costd  x    
 
 
x   x 
p
 
d
 
diam odt gx    x    x x   a cost  x   x    x 
lemma    let  x  si   sg   o  be a planning task  let s  s be a state with     h   s     
and let p    s  be an optimal relaxed plan for s  say that odg     v  a  is a successful

optimal rplan dependency graph for p    s   then there exists an operator sequence 
o so
that 

 i  
o constitutes a monotone path in s from s to a state s  with h   s    h   s    

 ii  the length of 
o is at most costd  odg    if we have definition   condition   a  or
  b   and is at most costd  odg        if we have definition   condition   c  
proof  let xk           x  be a topological ordering of v   x    according to the arcs a  consider
a state s  where for every x  v    x    we have that s   x  is a vertex in odt g 
x   and for
every variable x outside v    x    we have that s   x    s x  unless s x  is irrelevant  say
that preo   s    note first that such a state s  exists  by definition  we have that either
preo   x    is undefined or that preo   x      s x      s   x      note that for every variable
x outside v    x    we have that s   x    s x  unless s x  is irrelevant covers also the
case where a transition on v    x    has a side effect on x    whose delete must then by
prerequisite be irrelevant and thus either the side effect is x     s x    or o  is not actually
preconditioned on x     by definition   and because p    s  is a relaxed plan for s  each
variable x  xpreo is contained in v unless preo   x    s x   for the same reasons  by
 
 
construction of odt g 
x   we have that preo   x  is a vertex in odt gx  
now  consider the state s  that results from applying o  to s    we first consider the
situation where s  is in the invertible surroundings of s according to odg    the opposite
case will be discussed further below  we can apply lemma   to s    and hence have a relaxed
 
 s  x   for x 
plan p    ss    for s  that results from replacing  in p    s   some moves of p  
 
 
 
 
v    x     with their inverses  in particular  h  s   h  s     and p  ss    x     p    s  x   
for all x    v   what is a relaxed plan for s    we distinguish definition   condition    
cases  a    b   and  c  

 
in case  a   by definition we have that p  
 s  contains a sub sequence 
o  so that pre 



o 
 
 
 
s  and eff 
 r   c   f    this implies that we can remove o  from p  s  s    and

o 
obtain a relaxed plan p   for s    thus getting h   s    h   s     more precisely  we construct

p   by  removing o  from p    ss     if xeff o    v    x         then moving 
o  to occur at


 
 
the start of p    if xeff o    v    x        then moving o  to occur at the start of p  
 s 
 
 which is unchanged in p  ss     

observe first that o   p    s  s    and 
o  is a sub sequence of p    s  s    since the
adaptation pertains exclusively to operators that precede o  in p    s   second  of course
the values established by o  are true in s   

third  
o  is applicable  in the relaxation  at its assigned point in p     to see this 
consider first the case where xeff o    v    x          then  by definition of s    pre 
is


o
 

   

fihoffmann

contained in  prevo   eff o    and the set of facts  x  c   s where there exists no o such that
 
x  xeff o and o is either o  or in p  
 s  or is the responsible operator for the inverse of
 
 
a transition taken by an operator o  p  
 s   all these facts will be true in s    this is
obvious for prevo   eff o  and follows for the other facts because they were true in s and
cannot have been affected by any operator on the path to s    consider now the case where
xeff o    v    x         by definition of s    pre 
is contained in the previous sets of facts 


o 
plus   x  c     x  c   f    x  v    x      the latter facts  as far as relevant  will all be true

at the start of 
o  in p     this is because execution of o  does not affect the execution of
 
p  ss     and thus of p     up to this point  but then  with what was argued in lemma   
we have that the outcome of such execution in s  contains  on the variables v    x     the
 
relevant part of the outcome of p  
 s  in s  that is  the relevant part of f    since o  does
not affect these variables  the same is true of s    which concludes this point 
finally  consider any facts  z  e  that are true in s  but not in s    and that may be

needed by p   behind 
o    i e   that either are in the goal or in the precondition of any of
these operators  observe that  since inverse operators are performed only for transitions
on variables v    x     and since they do not include any new outside preconditions  any
such  z  e  is contained in r       now  say first that  z  e   f    then  with the above 
 z  e    ctx s x     c   x    s x      f  r   and thus  z  e   eff  
by prerequisite and we


o 
 
 s   else  this
are done  what if  z  e    f    note that  then   z  e    preo for any o  p  
 
precondition would not be true in the relaxed execution of p  s  and thus p    s  would not
 
 s   and thus  z  e  is not needed
be a relaxed plan  neither is  z  e  added by any o  p  
 
as the precondition of any inverse operator used in p  s  s     these operators do not
introduce new outside preconditions  and of course use only own preconditions previously
added by other operators affecting the respective variable  thus the only reason why  z  e 
 
could be needed in p   is if either  z  e   sg or  z  e   preo for some o  p  
 s   if
 
 z  e   sg then certainly  since p  s  is a relaxed plan  it is achieved by some operator o
in p    s   we cannot have o   o  since the effect of o  is true in s    and we cannot have
 
 
 s   and thus o is contained in p   and we are
 s  since  z  e    f    thus o  p  
o  p  
 
 s   the same arguments apply  i e   there must be
done  if  z  e   preo  for some o   p  
 
 
o  p    s   ordered before o   that adds  z  e   this concludes the proof for case  a  
consider now case  b   where s x      r     and the transition  s x     c  has replaceable
side effect deletes  i e   ctx s x     c   sg    and  for every o     o  o where preo 
ctx s x     c      there exists o   o so that eff o    eff o and preo   prevo   eff o    we
obtain a relaxed plan for p   by removing o  from p    s  s     and replacing any other
operators o with the respective o  if needed  precisely  say that  z  e  is true in s  but not
in s    if z   x  then e   s x    is not needed in p   by construction  for every other z  we
must have  z  e   ctx s x     c   then  z  e  is not a goal by prerequisite  for any operator
o  p   that has  z  e  as a precondition  we can replace o with the postulated operator o 
that is obviously applicable in s  and has the same effect  this concludes this case 
consider last case  c   where by definition s x      r     and the transition  s x     c  has
recoverable side effect deletes  here  the guarantee to decrease h  is obtained not for s 
    note in particular the special case of inverse transitions on non leaf variables x  which may have a
precondition in x that is added by  but not needed as a prerequisite of  the operators in p    s  x   such
preconditions  and only such preconditions  may be needed in p    ss    and thus in p     but not in
p    s   it is for this reason that we include these facts in the definition of r    

   

fianalyzing search topology without running any search

itself  but for a successor state s  of s    namely  let o  be the operator recovering the relevant
side effect deletes of  s x     c   precisely  let   ctx s x     c  so that   s   such a  exists
by definition of ctx s x     c    then 
s let o  be an operator so that preo    prevo   eff o   
and eff o     eff o      sg  o    o  o preo     such an operator exists by case  b    say
that we obtain p   by replacing  in p    ss     o  with o    then p   is a relaxed plan for
s    to see this  note first that o  is applicable in s  by virtue of preo    prevo   eff o    
further  note that the only values deleted by o  are those in  plus  x    s   x      since
s   x      s x     by s x      r   we know that s   x     sr   and thus this delete is of no
consequence  as for   by virtue of eff o      sg  o    o  o preo    all facts that could
possibly be relevant are re achieved by o    finally  the values established by o  are true in
s   
now  say we obtain s  by applying o  in s    then removing o  from p   yields a relaxed
plan for s    this is simply because its established effects are true in s    and by virtue of
eff o    the only facts it deletes are side effects of the transition  s x     c   by case  c  
these are not relevant for anything except possibly the recovering operators  the recovering
operator o  we have just removed from p     as for any other recovering
s operators o that
could still be contained in p     since eff o   and eff o      sg  o    o  o preo     all
relevant facts that o could possibly achieve are already true in s  and thus we can remove
o as well  hence  overall  h   s    h   s    
in cases  a  and  b  we can prove  i  by constructing a monotone path to s    in case  c 
the same is true of s     of course  we will also show  ii   by constructing a path that has at
most the specified length  we will ignore this issue for the moment   the only difficulty in
constructing such a path is achieving the preconditions of o    these preconditions may not
be satisfied in s  so we need to reach the state s  where they are satisfied  we need to do so
without ever increasing the value of h    note that  if we decrease the value of h  somewhere
along the way  then we have already reached an exit on a monotone path  and are done  thus
in what follows we will only show the upper bound h   s   with lemma    this bounding can
be accomplished by starting at s  and always taking only odt g 
x transitions of variables
x  v pertaining to the second case in definition   condition      i e   transitions that are
invertible induced and have irrelevant side effect deletes and no side effects on v    x     in
what follows we will  for brevity  refer to such transitions as case   note here that  this
way  we will reach only states in the invertible surroundings of s according to odg    for

any such operator sequence 
o   by lemma   we know that h   s   h   s    for all states
 
s along the way  now  what if we cannot reach s  by using such a sequence  i e   what if
 
we would have to take a non case  odt g 
x transition  c  c   of variable x  at some state
s    by prerequisite we know that transition  c  c    has self irrelevant deletes  we can apply
lemma   because  s  is in the invertible surroundings of s according to odg    since were
following a transition path  clearly s   x    c  i e   the value of the relevant variable in s  is
the start value of the last transition we are taking  and by construction  p    ss    changes
p    s  only in the case  transitions  and thus the responsible operator rop c  c     which is
not case   is guaranteed to be contained in p    ss     note here that rop c  c    cannot be
used in any of the case  transitions for any other v    x    variable we might have taken on
the path to s    because by prerequisite all these transitions have no side effects on v    x    
in contradiction to o constituting a transition for the variable x at hand  thus we know
that h   s    h   s    so we have already constructed our desired monotone path to an exit
   

fihoffmann



and can stop  else  if we can reach s  by such a sequence 
o   then with the above  
o  ho  i


 respectively o  ho    o  i  in case  c   constitutes the desired path 

it remains to show how exactly to construct the operator sequence 
o   consider a
topological ordering of v   xk           x    in what follows  we consider depth indices k  d 
   and we say that a variable x  v has depth d  written depth x    d  iff x   xd   each
d characterizes the d abstracted planning task which is identical to the original planning
task except that all  and only  those outside preconditions  of all odt g 
x transitions for
variables x where depth x   d  are removed that pertain to values of variables x  where
depth x      d  we prove by induction over d that 

    for the d abstracted task  there exists an operator sequence 
o d so that 


 a  either     
o d ho  i is an execution path applicable in s  or     
o d is an execution path

 
applicable in s  and the last transition  c  c   for variable x taken in 
o d is relevant 
has self irrelevant deletes  its responsible operator is contained in the adapted relaxed
plan for the state s  it is applied to  and s   x    c 

 b  
o d   except in the last step in case     of  a   uses only case  odt g 
x transitions for
variables x with    depth x   d 

 c  the number of operators in 
o d  ho  i pertaining to any x  v is at most costd  x  

our desired path 
o then results from setting d    k  to see this  note that the kabstracted planning task is identical to the original planning task  the claim then follows
with our discussion above   a  and  b  together mean that h  decreases monotonically




 
on
p o d and is less dthan h  s  at its end  given  c   the length of o d is bounded by
xv depth x d cost  x   this proves the claim when adding the trivial observation that 
if we have definition   condition     case  c  as discussed above  then we need to add one
additional operator at the end of the path 

we now give the proof of      the base case  d      is trivial  just set 
o   to be empty 
by the construction of  v  a  as per definition    and by construction of the   abstracted
task  all outside preconditions of o  are either true in s or have been removed  all of  a 
 case        b    c  are obvious 

inductive case  d  d      exploiting the induction hypothesis  let 
o d be the operator




sequence as per      we now turn o d into the requested sequence o d   for the d    abstracted planning task 
for the remainder of this proof  we will consider odt g 
x   for any x  v    x     to
contain also any irrelevant transitions  i e   we omit this restriction from definition    this
is just to simplify our argumentation  as we will show  the odt g 
x paths we consider do
not contain any irrelevant transitions  and hence are contained in the actual odt g 
x as per
definition   

let o be the first operator in 
o d  ho  i  o may not be applicable in s  in the d  
  abstracted planning task  the only reason for that  however  may be a precondition
that was removed in the d abstracted planning task but that is not removed in the d    abstracted planning task  by construction  that precondition must pertain to xd     say
the precondition is  xd     c   by induction hypothesis  we know that o is contained in
 
p  
 s   or is responsible for an inverse transition of such an operator  in both cases  since
inverse transitions introduce no new outside preconditions   xd     c  is a precondition of an
   

fianalyzing search topology without running any search

 
operator in p  
 s   thus c is a vertex in odt g 
xd    this is trivial if  xd     c  is true in
s  which actually cannot be the case here because else o would be applicable in s in the
d     abstracted planning task   and if  xd     c  is not true in s it follows because p    s 
is a relaxed plan and must thus achieve  xd     c  before it is needed as a precondition 

 
hence  p  
 s  xd     must contain a shortest path 
q in odt g 
xd   from s xd     to c  all
the transitions on the path are not irrelevant  to see this  note first that the endpoint is an
operator precondition by construction  and thus the last transition  c    c  is not irrelevant 
but then  neither is the previous transition   c    c     if it was  then  xd     c    would be in no
 
operator precondition  but then  rop c    c   which is contained in p  
 s  by construction

 
 would also constitute the transition  c    c  in odt gxd   and thus 
q would not be a


shortest path in contradiction  iterating the argument  q does not contain any irrelevant
transitions  thus  since depth xd       d      by definition    which includes all nonsatisfied preconditions of relevant transitions  and by construction of the d     abstracted

planning task  all the outside preconditions used in rop 
q   are either true in s or have been


removed  hence we can execute rop  q    we do so until either we have reached the end of
the sequence  or until the last transition taken in odt g 
xd   was not case   and hence has
self irrelevant deletes by prerequisite  in the latter case  since we are following a path and
since as discussed above the adapted relaxed plan exchanges only operators pertaining to
case  transitions and thus not the last one we just executed  we clearly have attained  a 

case     and can stop  the part of rop 
q   that we executed is  on its own  an operator

sequence 
o d   as desired  in the former case  we reach a state s  where s   xd       c  and
nothing else of relevance has been deleted  due to the non existence of relevant side effect
deletes   in s    o can be applied  leading to the state s    

let now o  be the second operator in 
o  ho i  like above  if o  is not applicable in s    
d

 

then the only reason may be an unsatisfied precondition of the form  xd     c     like above 
 
 s   and hence c  is a vertex in odt g 
o  or its inverse is contained in p  
xd     likewise 
  
 
s  xd       c is a vertex in odt gxd     now  we have not as yet used any non case 
transition in odt g 
xd     or else we wouldnt get here  this means that we are still in
the invertible surroundings around s xd     of odt g 
xd     clearly  this implies that there
 
 
exists a path in odt gxd   from c to c  we could simply go back to s xd     and move

to c  from there   taking the shortest such path 
q   clearly the path length is bounded
 
by the diameter of odt gxd     the path does not contain any irrelevant transitions  the
endpoint c  has been selected for being an operator precondition  the values in between are
part of a shortest path in odt g 
xd     and thus the same argument as given above applies 

thus the outside preconditions used by the operators constituting 
q are either true in s or
have been removed  this follows from the construction of  v  a  as per definition   and by
 
construction of the d     abstracted planning task for operators in p  
 s   and follows for
inverses thereof because inverse operators introduce no new outside preconditions  hence

we can execute 
q in s     we do so until either we have reached the end of the path  or until
the last transition taken was not case   and hence has self irrelevant deletes by prerequisite 
consider the latter case  the state s  just before the last transition is reached only by
case  transitions  and since the transition is in odt g 
xd   but not case   the responsible
 
operator must be contained in p  s  and with that in the adapted relaxed plan p    ss   
for s   recall here that  as pointed out above  since case  transitions are postulated to have
   

fihoffmann

no side effects on v   x     the responsible operator cannot be used by any of them  further 
clearly since we are following a path of transitions  we have that the value of xd   in s  is
the start value of the transition  hence we have attained  a  case     and can stop  in the
former case  we have reached a state where o  can be applied  and nothing of relevance has
been deleted  due to the postulated non existence of relevant side effect deletes  for case 

transitions   iterating the argument  we get to a state where the last operator of 
o d  ho  i
can be applied  by induction hypothesis reaching a state s  as desired by  a  case     
properties  a  and  b  are clear from construction  as for property  c   to support any

operator of 
o d  ho  i  clearly in the above we apply at most diam odt g 
xd     operators
pertaining to xd    or we stop the sequence earlier than that   note further that  for all

operators o in 
o d  ho  i with unsatisfied preconditions on xd   in the above  if o pertains to
variable x then we have  xd     x   a  this is a consequence of the construction of  v  a 
as per definition    and the fact that inverse transitions do not introduce new outside

preconditions  thus  in comparison to 
o d  ho  i  overall we execute at most
x
diam odt g 
k x 
xd     
x  xd    x a



additional operators in 
o d    ho  i  where k x  is the number of operators in 
o d  ho  i
pertaining to variable x  by induction hypothesis  property  c  of      we have that k x  
costd  x   for all x with depth x    d      and thus for all x with  xd     x   a  hence we
get  for the newly inserted steps affecting xd     the upper bound
x
diam odt g 
 

costd  x 
xd  
x  xd    x a

which is identical to costd  xd      this concludes the argument 
we next note that we can improve the exit distance bound in case we do not insist on
monotone exit paths 
lemma    let  x  si   sg   o  be a planning task  let s  s be a state with     h   s     
and let p    s  be an optimal relaxed plan for s  say that odg     v  a  is a successful
optimal rplan dependency graph for p    s   let v   v    x    so that  for every x  v   
all odt g 
x transitions are invertible induced and have irrelevant side effect deletes and no
side effects on v   x     and all other dt gx transitions either are irrelevant  or have empty

conditions and irrelevant side effect deletes  then there exists an operator sequence 
o so
that 

 i  
o constitutes a path in s from s to a state s  with h   s    h   s    

 ii  the length of 
o is at most costd  odg    if we have definition   condition   a  or
  b   and is at most costd  odg        if we have definition   condition   c  
proof  this is a simple adaptation of lemma    and we adopt in what follows the terminology of the proof of that lemma  the only thing that changes is that the bound imposed on
exit path length is sharper  and that we do not insist on that path being monotone  at the
level of the proof mechanics  what happens is that  whenever xd    v    when we choose a
   

fianalyzing search topology without running any search


path 
q to achieve the next open precondition of an operator o already chosen to participate


in o d  ho  i  then we do not restrict ourselves to paths within odt g 
xd     but allow also any
shortest path through dt gxd     being a shortest path in dt gxd   to a value that occurs

as an operator precondition  
q contains no irrelevant transitions  same argument as in the

proof of lemma     further  
q will be executable because by prerequisite the alternative
 non odt g 
 
transitions
in
it
have no outside conditions  for original induced transitions 
x
precondition achievement works exactly as before  note here the important property that
open preconditions to be achieved for xd   will only ever pertain to values contained in
odt g 
xd     this is trivial to see by induction because alternative transitions do not have
any outside preconditions  since by prerequisite any deletes of the alternative transitions
are irrelevant  executing them does no harm  all we need is a minor extension to lemma   
allowing s  to be identical with a state s   in the invertible surroundings of s  modulo a
set of irrelevant values that hold in s   but not in s  it is obvious that this extension is
valid  with this extension  it is also obvious that the arguments pertaining to s  and s 

remain valid  finally  consider the case where 
q involves a non case  odt g 
xd   transition 
then the state where this transition is applied is in the invertible surroundings of s  this
holds for any x   v  because for these our construction remains the same  it holds for
any x  v  because  first  alternative transitions have no outside conditions  hence cause
no higher depth transitions to be inserted in between  hence the value of all lower depth
 
variables x is in odt g 
x   second  by prerequisite  odt gx does not contain any non case 
transitions  and thus the value of x were at clearly can be reached by case  transitions 
theorem    let  x  si   sg   o   s  p    s   and odg  be as in definition    if odg  is successful  then s is not a local minimum  and ed s   costd  odg     if we have definition  
condition   a  or   b   then ed s   costd  odg       
proof  this is a direct consequence of lemmas   and   
we note that the prerequisites of lemma   could be weakened by allowing  for x  v   
outside conditions that are already true in s  this extension obviously does not break the
proof arguments  we have omitted it here to not make the lemma prerequisite even more
awkward than it already is 
as indicated  the exit path constructed in lemma   is not necessarily monotone  example   in appendix a   contains a construction showing this 
a   conservative approximations
for the sake of self containedness of this section  we re state the definitions given in section   
definition    let  x  si   sg   o  be a planning task  let s  s with     h   s      let
x   xsg   and let t     s x     c  be a relevant transition in dt gx  with o     rop t    
a local dependency graph for s  x    and o    or local dependency graph in brief  is a
graph ldg    v  a  with unique leaf vertex x    and where x  v and  x  x     a if either 
x    x    x  xpreo   and preo   x     s x   or x   v    x    and  x  x    is an arc in sg 
 

   

fihoffmann

a global dependency graph for x  and o    or global dependency graph in brief  is a
graph gdg    v  a  with unique leaf vertex x    and where x  v and  x  x     a if either 
x    x  and x     x  xpreo   or x   v    x    and  x  x    is an arc in sg 
 

definition    let  x  si   sg   o   s  t    o    and g   ldg or g   gdg be as in definition   
we say that g    v  a  is successful if all of the following holds 
    g is acyclic 
    if g   ldg then sg  x       s x     and there exists no transitive successor x  of x  in
sg so that x   xsg and sg  x       s x    
    we have that t  either 
 a  has self irrelevant side effect deletes  or
 b  has replaceable side effect deletes  or
 c  has recoverable side effect deletes 
    for x  v    x     all dt gx transitions either are irrelevant  or have self irrelevant
deletes  or are invertible and have irrelevant side effect deletes and no side effects on
v    x    
lemma    let  x  si   sg   o  be a planning task  and let s  s be a state with     h   s   
  say that x   x and  for every o    rop s x     c  in dt gx  where t     s x     c  is
relevant  ldgo  is a successful local dependency graph for s  x    and o    then  for at least
one of the o    there exist an optimal relaxed plan p    s  for s  and a successful optimal rplan
dependency graph odg  for p    s   x    and o    where odg  is a sub graph of ldgo   
proof  observe first that definition   property     forces any relaxed plan p    s  to move
x    i e   we have that p    s  x    is non empty  in particular  p    s  x    takes a path in

dt gx  from s x    to sg  x     let 
q be a shortest such path taken by p    s  x     and let

o  be the responsible operator of the first transition in 
q   clearly  this transition has the
form  s x     c   i e   o  is one of the operators o  in the claim  lying on a shortest path from
s x    to sg  x    in the sub graph of dt gx  taken by p    s  x     the transition  s x     c  is
not irrelevant  this can be seen with exactly the same argument as given in the proof to

lemma   for the transitions on the paths 
q constructed there  except that the endpoint is
now a goal instead of an operator precondition 
next  observe that any optimal p    s  contains at most one operator o with x   xpreo
and preo  x      s x     this also follows from definition   property      x  cannot become important for any non achieved goal  i e   no p    s  operator outside p    s  x    relies on a precondition on x    to see this  assume that such an operator o does exist 
then  since p    s  is optimal  there exists a reason for the inclusion of o  precisely 
o must achieve at least one fact that is needed in the terms of hoffmann and nebel
     b   a fact that is either in the goal or in the precondition of another operator o 
behind o in p    s   iterating this argument for o   if necessary   we obtain a sequence
o   o     x    c     o     x    c             on    xn   cn   where  xn   cn   is a goal fact not satisfied in s and
where oi achieves  xi   ci   in p    s   obviously  sg then contains a path from x  to xn   and
xn  xsg and sg  xn      s xn    in contradiction to definition   property      thus such o
does not exist  with the same argument  it follows also that every operator in p    s  x   
   

fianalyzing search topology without running any search

either has no side effect used elsewhere in the relaxed plan  or has no precondition on x   
thus those operators in p    s  x    that are preconditioned on x  serve only to transform
s x    into sg  x     of course  then  at most a single one of these operators relies on s x   
or else p    s  is not optimal 
say in what follows that ldgo     v  a   denote by  v     a    the result of backchaining
 
by definition   from o  with p  
 s   definition   will include all variables and arcs included
by definition    to see this  just note that all arcs  x  x    included by definition   are due
to relevant transitions  hence  v     a    is a sub graph of  v  a   in particular  since  v  a 
is acyclic   v     a    is acyclic as well 
our next observation is that  assuming that definition   condition     holds true  definition   condition   a  implies definition   condition   a   definition   condition   b  implies
definition   condition   b   and definition   condition   c  implies definition   condition
  c  
consider first case  a  where t  has self irrelevant side effect deletes  we show that
 
r   c      recall here the notations of appendix a    c      x    s x       ctx t     and
r   is a super set of the set of facts that we will need for the relaxed plan after removing o   
for all variables except x    it is clear that there is no fact in this intersection  all facts in
ctx t    are irrelevant or o   only relevant by prerequisite  and are thus not contained in r    
hence   x    s x     remains as the only possible content of r    c    we show in what follows
that  x    s x       r     and thus  x    s x       r   c  and the latter intersection is empty  as
desired  recall that r   denotes the union of sg   the precondition of any o     o  p    s  
and the precondition of any operator which is the responsible operator for an induced
transition in odt g 
x   with x  v    x     by definition   condition       x    s x       sg  
as argued above  o  is the only operator in p    s  that may be preconditioned on s x    and
thus it is not in the precondition of any o     o  p    s   lastly  say that p is a precondition
of a responsible operator for an induced transition in odt g 
x   the corresponding original
transition being t  then  since inverse transitions do not introduce any new conditions 
 
 s   but then  since
p  cond t  and thus p  prerop t  where  by definition  rop t   p  
 
o     rop t   p  s   we have  x    s x       prerop t    which implies that p     x    s x     
thus  x    s x       r   like we needed to show 
consider now case  b  where t  has recoverable side effect deletes  to show definition  
condition   b  for o    rop t     all we need to prove is that s x    is not odg   relevant 
i e   that s x      r     this was already shown above 
for case  c   t  has replaceable side effect deletes  again  to show definition   condition
  c  for t     all we need to prove is that s x    is not odg   relevant 
consider finally the conditions imposed on non leaf variables x  v    x     i e   definition   condition     and definition   condition      by definition   condition      the
dt gx transitions of every x  v    x    either are irrelevant  or have self irrelevant deletes 
or are invertible and have irrelevant side effect deletes and no side effects on v    x     if
a dt gx transitions is irrelevant then it cannot be in odt g 
x   thus the  nd or  rd case is
 
 
true of the odt gx transitions of every x  v    x     this concludes the argument 
theorem    let  x  si   sg   o  be a planning task  and let s  s be a state with    
h   s      say that x   x so that  for every o    rop s x     c  in dt gx  where
 s x     c  is relevant  ldgo  is a successful local dependency graph  then s is not a local
   

fihoffmann

minimum  and ed s   maxo  costd  ldgo     if  for every ldgo    we have definition  
condition   a  or   b   then ed s   maxo  costd  ldgo       
proof  by lemma    for some choice of o    rop s x     c  there exists an optimal relaxed
plan p    s  and a successful optimal rplan dependency graph odg     v     a    for p    s  
so that odg  is a sub graph of ldgo  with the same unique leaf vertex x    we can apply
lemma   and obtain that s is not a local minimum 
to see the other part of the claim  let v  be defined as in section    i e   v  is the subset
of v    x    for which all dt gx transitions either are irrelevant  or are invertible and have
empty conditions  irrelevant side effect deletes  and no side effects on v    x     then  for
each dt gx transition t where x  v    t satisfies both the restriction required by lemma  
 
on odt g 
x transitions  if t is irrelevant  then it cannot be in odt gx   else it is invertible
and has irrelevant side effect deletes and no side effects on v    x     and the restriction
required by lemma   on the other transitions  either irrelevant  or empty conditions and
irrelevant side effect deletes  we can hence apply lemma   to odg    and obtain a  not
necessarily monotone  path to an exit  with length bound costd  odg    if  s x     c  has
irrelevant side effect deletes or replaceable side effect deletes  and costd  odg        if
 s x     c  has recoverable side effect deletes  it thus suffices to show that costd  ldgo    
costd  odg     that  however  is obvious because v  v     costd  x     for all x  and
 
maxpath dt gx    diam odt g 
x   for all x  v  
theorem    let  x  si   sg   o  be a planning task  say that all global dependency graphs
gdg are successful  then s does not contain any local minima and  for any state s  s with
    h   s      ed s   maxgdg costd  gdg   if  for every gdg  we have definition  
condition   a  or   b   then ed s   maxgdg costd  gdg     
proof  let s  s be a state  we need to prove that s is no local minimum  if h   s      or
h   s      there is nothing to show  else  assume that the variables x are topologically
ordered according to the strongly connected components of sg  and let x   x be the
uppermost variable so that x   xsg and sg  x       s x     obviously  such x  exists  clearly 
the only chance for x  to not satisfy definition   condition      there exists no transitive
successor x  of x  in sg so that x   xsg and sg  x       s x     is if there exists x  in
the same strongly connected sg component  with x   xsg  and sg  x       s x      but
then  there exists a transition t  in dt gx  with an outside condition eventually leading  by
backwards chaining in sg  to x    let gdg  be the global dependency graph for x  and
rop t     such a gdg  exists because x   xsg    since definition   includes all transitive
sg predecessors of x  pertaining to the conditions of t    gdg  includes x    but then  since
x  and x  lie in the same strongly connected component  definition   eventually reaches
x    thus gdg  contains a cycle  in contradiction to the prerequisite  it follows that the
strongly connected sg component of x  contains only x    and thus definition   condition
    holds true 
now  say that o  is responsible for a relevant transition of the form  s x     c  in dt gx   
then there exists a local dependency graph ldg for s  x    and o  so that ldg is a sub graph
of gdg  this follows from the simple observation that definition   will include  for gdg 
all variables and arcs that it will include for ldg   note here that any precondition of o 
   

fianalyzing search topology without running any search

on x    if present  is satisfied in s because o    rop s x     c   and thus definition   will not
include x  as a predecessor for achieving o  preconditions in ldg  
obviously  given the above  ldg is successful  since this works for any choice of notirrelevant  s x     c   we can apply theorem    the claim follows directly from this and
the fact that costd  gdg   costd  ldg   the latter is obvious because costd increases
monotonically when adding additional variables 
a   example constructions
our first example shows that  even within the scope of our basic result  operators are not
necessarily respected by the relaxation  i e   an operator may start an optimal real plan yet
not occur in any optimal relaxed plan 
example    consider the planning task in figure    variables are shown  in dark green 
on the left hand side of their respective dtg  circles represent variable values  and lines
represent dtg transitions  transitions with a condition are longer lines  with the condition
inscribed below the line  in blue   for each variable  a dashed arrow indicates the value in
the initial state si   where a goal value is defined  this is indicated by a circled value  where
needed  we will refer to the operators responsible for a transition in terms of the respective
variable followed by the indices of the start and end value  for example  the operator moving
x from c  to c  will be referred to as x    we abbreviate states   x  c    y  d   as  c  d  
we stick to these conventions throughout this section 

x

d 

c 

c 

d 

c 

d 

y
d 

d 

d 

d 

figure    planning task underlying example   
as shown in figure    the dtg of x consists of three vertices whose connection requires
the conditions d  and d    or alternatively d  as a shortcut  the domain of y is a line of
length   requiring no conditions 
clearly  the support graph of this planning task is acyclic  and all transitions in all dtgs
have no side effects and are invertible  however  operator y    for example  is not respected
by the relaxation  to see this  note first that h   si        the only optimal relaxed plan is
hy    y    x    x  i because the relaxed plan ignores the need to move back to d  for operator x    on the other hand  the only optimal  real  plan for si is hy    y    y    y    x  i 
if we choose to use y   instead  like the optimal relaxed plan does  then we end up with the
sequence hy    y    x    y    y    x  i which is   step longer  hence  in si   y   starts an
optimal plan  but does not start an optimal relaxed plan 
   

fihoffmann

we next give three examples showing how local minima can arise in very simple situations generalizing our basic result only minimally  we consider  in this order  cyclic support
graphs  non invertible transitions  transitions with side effects 
example    consider the planning task in figure   

x
c 

d 

c 

y
d 

d 

dn 

dn

c 

figure    planning task underlying example   
the dtg of x is just two vertices whose connection requires the condition d    the
domain of y is a line of length n requiring no conditions  with a shortcut between d  and
dn that requires c  as condition  clearly  all transitions in all dtgs have no side effects
and are invertible  however  sg contains a cycle between x and y because they mutually
depend on each other  we will show now that this mutual dependence causes the initial state
si     x  c      y  d     to be a local minimum  for n     we abbreviate  as before  states
  x  c    y  d   as  c  d   we have h   si        the only optimal relaxed plan is hx    y ni 
now consider the operators applicable to si    c    d    
 execute x    leading to s     c    d    with h   s        due to hx    y ni  from here 
the only new state to be reached is via y    giving s     c    d    with h   s        due to
hy    x    y ni   note here that n       by prerequisite  so a relaxed plan composed
of yi i      operators also has    steps   we have h   s      h   si   so this way we
cannot reach an exit on a monotone path 
 execute y    leading to s     c    d    with h   s        due to hy    x    y ni   note
here that n       by prerequisite  so a relaxed plan moving y by ypp operators has
   steps   again  the path is not monotone 
 execute y n  leading to s     c    dn   with h   s        due to hyn   x  i  from here 
the only new state to be reached is via yn n    giving s     c    dn    with h   s       
due to hy n  n  yn   x  i   note here that n     by prerequisite  so a relaxed plan
moving y to d  via dn            d  has        steps   again  the path is not monotone 
no other operators are applicable to si   thus we have explored all states reachable from si on
monotone paths  none of those states is an exit  proving that si is a local minimum  as are
s  and s     there is  in fact  only a single state s with h   s       namely s    c    dn    
clearly  reaching s from si takes n    steps  first apply x    then traverse d            dn    so
the exit distance of si is n     thus this distance is unbounded 
   

fianalyzing search topology without running any search

in section    the following modification of example   is considered  we set n       i e  
the domain of y is reduced to the two values d    d    and we remove the line d            dn   
i e   y can move only via what was previously the short cut  this modified example falls
into the sas   pubs tractable class identified by backstrom and klein         and it still
contains a local minimum  the example is unsolvable  though  
example    consider the planning task in figure   

x
c 

d 

c 

d 

c 

y
d 

d 

dn

figure    planning task underlying example    the arrow between d  and d  indicates that
the respective dtg transition is directed  i e   there exists no transition from d 
to d   
the dtg of x is three vertices whose connection requires  starting from the initial value
c    first condition d    then condition d    the domain of y is a circle of length n requiring
no conditions  and being invertible except for the arc from d  to d   
clearly  the support graph is acyclic and all transitions in all dtgs have no side effects 
however  the non invertible arc from d  to d  causes the initial state si    c    d    to be a
local minimum for all n     this is very easy to see  we have h   si       due to the
only optimal relaxed plan hy    x    x  i  note here that the relaxed plan does not have to
move y back because  y  d    is still true after executing y    now  the operators applicable
to si are y   and y n  the latter  reaching the state sn    c    dn    immediately increases
the value of h    this is because  with n     y n does not get y closer to d    while moving
it farther away from d   both of which need to be achieved   the shortest relaxed for sn is
hyn   y    x    x  i  alternatively  say we apply y   in si   reaching the state s     c    d    
we have h   s      n      we need to apply  in the relaxation  x    n    steps to complete
the circle from d  back to d    and x    thus  for n     s  has a larger h  value than si  
it follows that si is a local minimum  the nearest exit to si is sn     c    dn     sn  has
the relaxed plan hy n    n  yn   x  i of length    and after applying y n    n we get h 
value    reaching sn  from si takes   step moving x and n    steps moving y  so the
exit distance of si is n     thus this distance is unbounded 
example    consider the planning task in figure   
the dtg of x consists of two kinds of transitions  first  there is a line c            cn of
transitions requiring no conditions  second  there are direct links  called short cuts in what
follows  between cn and every other ci   conditioned on value d  of y  the dtg of y contains
just two vertices that are connected unconditionally  moving from d  to d  has the side effect
cn    that side effect is responsible for the towards cn direction of the short cuts in the
dtg of x  
   

fihoffmann

d 
d 

x
c 

c 

cn

cn

y
d 

d 

figure    planning task underlying example    the  red  inscription cn above the line
between d  and d  indicates that the transition from d  to d  has the side effect
cn  
the support graph is acyclic  its only arc goes from y to x  due to the short cuts in the
dtg of x  and due to the operator y   which has an effect on x and a precondition on y 
the transitions are all invertible  in particular each short cut has both  a direction towards
cn and vice versa  however  the side effect of y   causes the initial state si    c    d    to be
a local minimum for all n    
we have h   si       due to the only optimal relaxed plan hy  i  note here that the
relaxed plan does not care about the side effect of y    because c  is still true afterward 
now  if we apply any operator in si that leaves c    then clearly we increase h  by    no
matter what move we make  the relaxed plan must include both y   and a move back to c   
the only other available option in si is to apply y    we get the state s     cn   d     there 
h   s        as well  because the relaxed plan needs to re achieve c    since n     doing so
via the unconditional sequence cn           c  takes    steps  the only alternative is to use the
short cut xn  from cn to c    doing so involves applying y   in the first place  giving us a
relaxed plan of length    hence all direct successors of si have a heuristic value      and
so si is a local minimum  note also that the exit distance of si grows with n  the nearest
exit is a state from which the goal can be reached in a single step  clearly  the only such
state is  c    d     the shortest path to that state  from si   applies y   and then moves along
the unconditional line cn           c    taking      n       n    steps 
we next show that the exit path constructed using short cuts  leading to the improved
bound costd instead of costd   may be non monotone  and that the improved bound may
indeed under estimate the length of a shortest monotone exit path 
example    consider the planning task in figure   
in this example  the only optimal relaxed plan for the initial state moves z along the
path e            e n  note here that all these values are needed for moving y  then moves y to
d k  n   then moves x to c    this gives a total of h   si      n     k    n         n    k    
steps 
the only operators applicable to si move z  if we move along the line e            e n   then
h  remains constant  we always need to include the moves back in order to achieve the
own goal of z  once we reach e n   we can move y one step  then need to move z back 
etc  during all these moves  up to the state where y   d k  n   as long as z stays within
   

fianalyzing search topology without running any search

x
c 

y
d 

e  n

d 

e 

e 

e  n

d 

d k  n

c 

d k

e 

d k   e 

e  n

d k  n

z
e 

e 

e  n 

e  n

e

figure    planning task underlying example   
e            e n   h  remains constant  to see this  observe first that of course it suffices for a
relaxed plan to reach once  with z  all the values on this line  taking  n moves wherever we
are on the line  the moves for y are as before  second  observe that indeed all these moves
are needed  wherever y is on the line d            d k  n   it needs to move to d k  n in order to
suit x  and it needs to move to d  to suit its own goal  every value in e            e n appears
as a condition of at least one of these y moves  thus  from si   the nearest exit reached
this way is the state s where y   d k  n and z   e n   there  we can move x to c  which

decreases h  to  n    k  the length of the exit path 
o we just described  from si to s 
obviously is  k    n         n       kn    k    n 
what happens if we move z to e    consider first that we do this in si   then h  increases
to  n    k      we need to reach all values on the line e            e n   which from e  takes one

step more  the same argument applies for any state traversed by 
o   because  as argued 

in any such state we still need to reach all values on the line e            e n   thus 
o is the
shortest monotone path to an exit 
the only optimal rplan dependency graph odg  for si is the entire sg  and odt g 
z
contains all of dt gz except e    the only global dependency graph gdg is the entire sg 
clearly  in si   the next required value to reach for any variable is e n   so the construction
in the proof to theorem   will first try to reach that value  when using short cuts as
accounted for by costd      the exit path constructed will move to e n via e  rather than via
the line e            e n   and thus as claimed this exit path is not monotone 
finally  consider the bound returned by costd  odg     obviously  costd  odg     
costd  gdg   we obtain the bound       costd  odg              costd  x          k  
d
 n  costd  x   diam odt g 
y        k    n    n      cost  y   diam dt gz     note here
that diam dt gz     n     because dt gz is a circle with  n     nodes  overall  we have
    costd  odg        k  n  n       kn  k  n    n  for sufficiently large k  this
is less than  kn  k   n  as claimed  in detail  we have  kn  k   n    kn  k   n    n
n 
iff  kn   k    n  iff kn  k   n  iff k   n 
  this holds  for example  if we set n     
and k      
the reader will have noticed that example   is very contrived  the reason why we need
such a complicated unrealistic example is that costd   and with that costd   contains two
sources of over estimation  cf  the discussion in section    in particular  every move of non   

fihoffmann

leaf variables is supposed to take a whole odt g   dt g diameter  to show that costd is not
in general an upper bound on the length of a monotone exit path  we thus need the presented
construction around k so that its under estimation  considering diam dt gz   instead of
diam odt g 
z    outweighs this over estimation  importantly  constructing examples where
the short cuts temporarily increase h   but costd nevertheless delivers an upper bound
on monotone exit path length  is much easier  all that needs to happen is that  for whatever
reason  we have a variable z like here  where the currently required value  e n in example   
is reached in odt g 
z values along an unnecessarily long path all of whose values are needed
in the relaxed plan  this happens quite naturally  e g   in transportation domains if the
same vehicle needs to load unload objects along such a longer path 
we now demonstrate that  in a case where our analyses apply  exit distance may be
exponential 
example    consider the planning task in figure   

x 
c   

x 
c   

c   

c   

c   

c   

c   

c   

c   

c   

c   

c   

xn
c  n

c  n

c  n

c  n

c  n

figure    planning task underlying example   
the dtg of x  is two vertices whose connection is conditioned on c     for all other
variables xi   we have five vertices on a line  alternatingly requiring the last vertex ci  
of
 
i  
xi   and the first vertex c  of xi     clearly  the only optimal rplan dependency graph
odg  for si   and the only global dependency graph gdg for the task is the full support
graph sg  this is acyclic  and all transitions are invertible and have no side effects  thus
our analyses apply 
what are h   si   and ed si    for a relaxed plan  we need to move x  to c     due to
the conditioning  for each variable both extreme values  left and right hand side  are
required so we need   moves for each xi with    i  n  thus h   si          n 
now  consider any state s where s x      c     to construct a relaxed plan  obviously we
still need   move for x    we also still need   moves for each other variable  consider x   
if s x      c   then we need to move it to c   in order to be able to move x    if s x      c  
then we need to move it to c   in order to be able to move x    and to c   for its own goal 
and so forth  in all cases  all four transitions must be taken in the relaxed plan  due to the
conditioning  recursively the same is true for all other variables  thus  h   s         n 
   

fianalyzing search topology without running any search

this means that the nearest exit is a state s  where x  has value c   and x  has value c    
in s    we can move x  and afterward  definitely   n steps suffice for a relaxed plan  what is
the distance to a state s    we need to move x  four times  lets denote this as d x        
each move requires   moves of x    so d x          the sequence of moves for x  inverses
direction three times  at these points  x  does not need to move so d x       d x           
generalizing this  we get d xi        d xi      d x  i              d xi        so the growth over
n is exponential 
obviously  example   also shows that plan length can be exponential in cases where
theorem   applies  we remark that example   is very similar to an example given by
domshlak and dinitz         the only difference is that domshlak and dinitzs example
uses different conditions for transitions to the left to the right  which enables them to
use smaller dtgs with only   nodes  in our setting  we cannot use different conditions
because we need the transitions to be invertible  this causes the loss of exit path steps
in those situations where the next lower variable inverses direction and thus relies on
the same outside condition as in the previous step  indeed  for dtgs of size    this loss
of steps results in a polynomially bounded exit distance  the recursive formula for d xi  
becomes d xi        d xi      d x  i             d xi        resulting in ed si     n    n 
on the other hand  costd and costd still remain exponential in this case  because they
do not consider the loss incurred by inversing
directions  precisely  it is easy to see that
p
costd  odg      costd  gdg        ni    i    n       this proves that these bounds
can over estimate by an exponential amount 
the next example shows that the exit path constructed  implicitly  by our analyses may
be exponentially longer than an optimal plan for the task 
example    consider the planning task in figure    

x 
c   

c   

c   

c  

x 
c   

c   

c   

 
c n  

c   

c   

c   

c   

c   

xn
c  n

c  n

c  n

c  n

c  n

figure     planning task underlying example   
   

c   

fihoffmann

in this example  the only optimal relaxed plan for the initial state is the same as in
example    because the alternative route via c              c    n    takes      n        n      
 n     steps  thus the exit path constructed remains the same  too  with length exponential
in n  however  the length of the shortest plan is  n     
note in example   that the observed weakness  being guided into the wrong direction
 is caused by a weakness of optimal relaxed planning  rather than by a weakness of our
analysis  the relaxation overlooks the fact that moving via x            xn will incur high costs
due to the need to repeatedly undo and re do conditions achieved beforehand  note also
that  in this example too  we get an exponential over estimation of exit distance 
we finally show that feeding theorem   with non optimal relaxed plans does not give
any guarantees 
example    consider the planning task in figure    

x
c 
g  

d 

c 

g n  

c

v 

y
d 

en

d 

g  

g  

g n  

g n  

v n  

z
e 

e n 

en

figure     planning task underlying example    the arrow between en  and en indicates
that the respective dtg transition is directed  i e   there exists no transition
from en to en   
there are two ways to achieve the goal c    either via moving y and z  or by moving
v            vn     the only optimal relaxed plan chooses the former option  giving h   si     n   
as soon as n     however  the only parallel optimal relaxed plan p    si   chooses the latter
option because moving y and z results in n     sequential moves  whereas v            vn   can
be moved in parallel  giving parallel length   
consider what happens to h  in either of the options  if we move z  then h  remains
constant because we need to move z back into its own goal  as soon as we reach z   en  
h     because the last transition is uni directional and we can no longer achieve the own
goal of z  thus there is no exit path  and in particular no monotone exit path  via this
option 
say we move v            vn   instead  in the first move  whichever vi we choose   h 
increases because the shortest option is to undo this move and go via y and z  this takes
n     steps whereas completing the vi moves and going via c  takes  n            n     steps 
   

fianalyzing search topology without running any search

thus there is no monotone exit path via this option either  and si is a local minimum  after
completing the n     moves of vi and moving to x   c    we have h     n          due to the
shortest relaxed plan that moves back all vi and moves to x   c    to reduce this heuristic
value to the initial value h   si     n      we need to execute a further   of these steps  the
state we have then reached has a better evaluated neighbor  so the exit distance is n     
consider now the effect of feeding theorem   with the parallel optimal plan p    si   
clearly  the optimal rplan dependency graph odg  constructed for p    si   consists of x
and all the vi variables  but does not include y nor z  thus the theorem applies  and
it wrongly concludes that si is not a local minimum 
the exit distance bound computed is
p
  

   costd  x   diam dt gvi      n     
      costd  odg              costd  x     n  
i  
this is less than the actual distance ed si     n      and thus this result is also wrong 
say we modify example   by making the last transition of z undirected  but making
one of the vi transitions unidirectional to the right  then the v            vn   option leads into
a dead end  whereas the y  z option succeeds  in particular  theorem   does not apply to
odg  constructed for the parallel optimal relaxed plan p    si    and thus this is an example
where using non optimal relaxed plans results in a loss of information 
a   benchmark performance guarantees
we give definitions of the   domains mentioned in propositions   and    for each domain 
we explain why the respective property claimed holds true  in most of the domains  we
assume some static properties as are used in pddl to capture unchanging things like the
shape of the road network in a transportation domain  we assume in what follows that
such static predicates have been removed prior to the analysis  i e   prior to testing the
prerequisites of theorem   
definition    the logistics domain is the set of all planning tasks     v  o  si   sg   whose
components are defined as follows  v   p v where p is a set of package location variables
p  with dp   l  v where l is some set representing all possible locations  and v is a set
of vehicle location variables v  with dv   lv for a subset lv  l of locations  o contains
three types of operators  move  load  and unload  where move v  l   l       v  
l     v   l    for l     l   load v  l  p      v   l  p   l    p   v    and unload v  l  p   
  v   l  p   v    p   l    si assigns an arbitrary value to each of the variables  and sg
assigns an arbitrary value to some subset of the variables 
every global dependency graph gdg in logistics either has a package p as the leaf
variable x    or has a vehicle variable v as the leaf variable x    in the latter case gdg
consists of only x    with no arcs  in the former case  o  is preconditioned on a single vehicle
v only  leading to a single non leaf variable v  in both cases  gdg is acyclic  all involved
transitions have no side effects  and all involved transitions are invertible  thus we can
apply theorem    we have costd  gdg             for packages and costd  gdg      for
vehicles  thus overall we obtain the correct bound   
definition    the miconic strips domain is the set of all planning tasks   
 v  o  si   sg   whose components are defined as follows  v   o  d  b  s   e  where
 o     d     b     s  and  o is a set of passenger origin variables o  with do   l where l
   

fihoffmann

is some set representing all possible locations  floors   d is a set of passenger destination
variables d with dd   l  b is a set of passenger boarded variables b with db           s is
a set of passenger served variables s with ds           e is the elevator location variable
with de   l  o contains three types of operators  move  board  and depart  where
move l   l       e   l     e   l    for l     l   board l  i      e   l  oi   l    bi        and
depart l  i      e   l  di   l  bi        bi      si        si assigns arbitrary locations to the
variables o  d  and e  and assigns   to the variables b and s  sg assigns   to the variables
s 
passenger origin and passenger destination variables are static  i e   not affected by any
operator  thus the common pre processes will remove these variables  using them only to
statically prune the set of operators that are reachable  we assume in what follows that
such removal has taken place 
every global dependency graph gdg in miconic strips has a passenger served variable
si as the leaf variable x    this leads to non leaf variables bi and e  with arcs from e to
both other variables and from bi to si   clearly  gdg is acyclic  the transitions of e are
all invertible and have no side effects  the transition        of bi  is not invertible since
departing has a different condition on e but  has an irrelevant own delete  bi     does not
occur anywhere in the goal or preconditions  and has no side effects and thus irrelevant
side effect deletes  the transition        of bi  is not invertible but  is irrelevant  bi    
doesnt occur anywhere  the transition        of the leaf variable si has self irrelevant side
effect deletes  bi     occurs only in the precondition of the transitions own responsible
operator rop         depart ld   i   hence we can apply theorem    this delivers the bound
costd  gdg             si            costd  si    maxpath dt gbi              costd  si    
costd  bi     diam dt ge        
definition    the simple tsp domain is the set of all planning tasks     v  o  si   sg  
whose components are defined as follows  v    p   v where  p is the position variable 
with dp   l where l is some set representing all possible locations  and v   with  v      l  
is a set of location visited variables v  with dv           o contains a single type of
operators  move l   l       p   l     p   l   vl        for l     l   si assigns an arbitrary
value to p and assigns   to the variables v   sg assigns   to the variables v  
every global dependency graph gdg in simple tsp has a location visited variable vi
as the leaf variable x    this leads to the single non leaf variable p  clearly  gdg is acyclic 
every transition        of vi considered  induced by o    move l   li   has replaceable side
effect deletes  any operator o   move l   x  can be replaced by the equivalent operator
move li  x  unless x   li  in the latter case  we have o    o which is excluded in the
definition of replaceable side effect deletes  every transition  l   l   of p clearly is invertible 
it has the irrelevant side effect delete vl       its side effect is only on vl  which is not
a non leaf variable of gdg  hence we can apply theorem    this delivers the bound
costd  gdg             vi            costd  vi    diam dt gp        
we consider an extended version of the movie domain  in the sense that  whereas the
original domain version considers only a fixed range of snacks  and thus the state space is
constant across all domain instances   we allow to scale the number of different snacks   
    the original domain version allows to scale the number of operators adding the same snack  all these
operators are identical  and can be removed by trivial pre processes 

   

fianalyzing search topology without running any search

definition    the movie domain is the set of all planning tasks     v  o  si   sg  
whose components are defined as follows  v    c   c   re   h  here  c  is the counterat zero variable  with dc            c  is the counter at two hours variable  with
dc            re is the movie rewound variable  with dre           h are have snack
variables h with dh           o contains four types of operators  rewindtwo  rewindother  resetcounter  and getsnack  where rewindt wo     c         re       
rewindother     c         re      c         resetcounter       c         and
getsnack i        hi        si assigns an arbitrary value to all variables  sg assigns
the re  c   and h variables to   
note that  depending on the value of the static variable c   the operator set will be
different  if si  c       then rewindother is removed  if si  c       then rewindt wo is
removed  we refer to the former as case  a  and to the latter as case  b  
every global dependency graph gdg consists of a single  leaf  variable  the transitions
of each h variable have no side effects and thus have irrelevant side effect deletes  the
transition        of c  has no side effects and thus has irrelevant side effect deletes  the
transition        of c  is irrelevant  for case  a   the transition        of re has no side
effects and thus has irrelevant side effect deletes so we can apply theorem    for case  b  
the transition        of re has the side effect c       observe that     this fact itself is
irrelevant  and     that the only   ctx       is  c        and o    resetcounter satisfies
   preo   prevrop       eff rop           re      c         c 
s        eff o      c       
and  c         eff o    y  d     y  d      y  d   sg  rop c c     o  o preo       c       
thus the transition has recoverable side effect deletes  and again we can apply theorem   
in case  a   for all gdgs the bound costd  gdg     applies  obviously  costd  gdg     
and thus we obtain the correct bound    in case  b   the bound costd  gdg  applies  and
again costd  gdg      so we obtain the correct bound   
definition    the ferry domain is the set of all planning tasks     v  o  si   sg   whose
components are defined as follows  v   c   f  e  where  c is a set of car location
variables c  with dc   l   f   where l is some set representing all possible locations  f is
the ferry location variable with df   l  e is the ferry empty variable with de          
o contains three types of operators  sail  board  and debark  where sail l   l    
  f   l     f   l    for l     l   board l  c      f   l  c   l  e        c   f  e       
and debark l  c      f   l  c   f     c   l  e        si assigns   to variable e  assigns an
arbitrary value to variable f   and assigns an arbitrary value other than f to the variables
c  sg assigns an arbitrary value    f to  some subset of   the variables c and f  
let s be an arbitrary reachable state where     h   s      and let p    s  be an
arbitrary optimal relaxed plan for s  then we can always apply theorem    to show this 
we distinguish three cases   a  s e       o    board l  c  is the first board operator in p    s  
and we set x    c   b  s e       o    debark l  c  is the first debark operator in p    s  
and we set x    c   c  p    s  contains no board or debark operator and we set o  to be the
first operator  sail l   l    in p    s   with x    f   obviously  exactly one of these cases will
hold in s  let odg     v  a  be the sub graph of sg including x  and the variables arcs
included as per definition    let t  be the transition taken by o   
in case  a   obviously we can reorder p    s  so that either board l  c  is the first operator
in p    s   or all its predecessors are sail operators  odg  then either     includes no new
   

fihoffmann

 non leaf  variables at all  or     includes only f   as for f   clearly all its transitions are
invertible and have no side effects  the transition t  has the own effect  c  f   deleting  c  l 
which clearly is not needed in the rest of p    s   it has the side effect e     deleting e     
that latter fact may be needed by other board operators in p    s   however  necessarily
p    s  contains an operator of the form debark l    c   which is applicable after board l  c 
and a sequence of moves that p    s  must contain from l to l    debark l    c  recovers e     
 
thus the odg   relevant deletes of t  are p  
 s  recoverable  in case  b   similarly we can
 
reorder p  s  so that either     debark l  c  is the first operator in p    s   or     all its
predecessors are sail operators  the transition t  has the own effect  c  l  deleting  c  f  
which clearly is not needed in the rest of p    s   it has the side effect e     deleting e    
which clearly is not needed in the rest of p    s   thus  again  the odg   relevant deletes
 
 
of t  are p  
 s  recoverable  the recovering sub sequence of p  
 s  being empty because
 
no recovery is required   in case  c   finally  odg contains only f   t  has no side effects 
and its own delete  f  l   is not needed anymore  in fact  in this case l  must be the goal
for f   and p    s  contains only the single operator o     hence  in all cases  we can apply
theorem    costd  odg        in cases  a     b    and  c  so there we get the bound   
costd  odg          diam dt gf       in cases  a   and  b   so there we get the bound   
definition     the gripper domain is the set of all planning tasks     v  o  si   sg  
whose components are defined as follows  v    ro  f    f     b  here  ro is the robotlocation variable  with dro    l  r   f    f  are gripper free variables  with df    df   
        and b are ball location variables  with db    l  r         o contains three types of
operators  move  pickup  and drop  where move l   l       ro   l     ro   l    for
l     l   pickup g  b  l      ro   l  b   l  fg        b   g  fg        and drop g  b  l      ro  
l  b   g    b   l  fg        si assigns l to ro  assigns   to f  and f    and assigns l to the
variables b  sg assigns r to the variables b 
let s be an arbitrary reachable state where     h   s      and let p    s  be an
arbitrary optimal relaxed plan for s  then we can always apply theorem    we distinguish
two cases   a  there exists b  b so that s b    g for g          o    drop g  b  r   and we
set x    b   b  there exists no b  b so that s b    g for g          o    pickup g  b  l 
for some b  b is in p    s   and we set x    b  obviously  exactly one of these cases will
hold in s  let odg     v  a  be the sub graph of sg including x  and the variables arcs
included as per definition    let t  be the transition taken by o   
in case  a   obviously we can reorder p    s  so that either drop g  b  r  is the first
operator in p    s   or its only predecessor is move l  r   odg  then either     includes no
new  non leaf  variables at all  or     includes only ro  as for ro  clearly all its transitions
are invertible and have no side effects  the transition t  has the own effect  b  r  deleting
 b  g  which clearly is not needed in the rest of p    s   it has the side effect fg     deleting
fg     which clearly is not needed in the rest of p    s   thus the odg   relevant deletes
 
of t  are p  
 s  recoverable  in case  b   similarly we can reorder p    s  so that either    
pickup g  b  l  is the first operator in p    s   or     its only predecessor is move r  l   the
transition t  has the own effect  b  g  deleting  b  l  which clearly is not needed in the rest of
p    s   it has the side effect fg     deleting fg      that latter fact may be needed by other
pickup operators in p    s   however  necessarily p    s  contains the operators move l  r 
and drop g  b  r   which are applicable after board l  c   drop g  b  r  recovers fg      thus 
   

fianalyzing search topology without running any search

 
again  the odg   relevant deletes of t  are p  
 s  recoverable  hence  in both cases  we can
d
 
apply theorem    cost  odg       in cases  a   and  b    so there we get the bound   
costd  odg          diam ro      in cases  a   and  b   so there we get the bound   

definition     the transport domain is the set of all planning tasks     v  o  si   sg  
whose components are defined as follows  v   p  v e  c where  p is a set of packagelocation variables p  with dp   l  v e where l is some set representing all possible
locations  v e is a set of vehicle location variables v  with dv   l  and c is a set of
vehicle capacity variables cv   with dcv               k  where k is the maximum capacity 
o contains three types of operators  drive  pickup  and drop  where  drive v  l   l    
  v   l     v   l    for  l   l    r where gr    l  r  is an undirected graph of roads
over l  pickup v  l  p  c      v   l  p   l  cv   c    p   v  cv   c       and drop v  l  p  c   
  v   l  p   v  cv   c    p   l  cv   c        si assigns an arbitrary value in l to each of
the variables p  v e  and assigns k to the variables c  sg assigns an arbitrary value in
l to some subset of the variables p  v e 
note here the use of numbers and addition subtraction  these are  of course  not part
of the planning language we consider here  however  they can be easily encoded  on the
finite set of number             k   via static predicates  after pre processing  in effect the
resulting task will be isomorphic to the one obtained by the simple arithmetic above  which
we thus choose to reduce notational clutter 
let s be an arbitrary reachable state where     h   s      then there exists an
optimal relaxed plan p    s  for s so that we can apply theorem    we distinguish three
cases   a  there exists p  p so that s p    v for v  v e  o    drop v  l  p  c  where
s cv     c is in p    s   and we set x    p   b  there exists no p  p so that s p    v for
v  v e  o    pickup v  l  p  k  for some p  p is in p    s   and we set x    p   c  p    s 
contains no drop or pickup operator and we set o  to be the first operator  drive v  l   l    in
p    s   with x    v  obviously  we can choose p    s  so that exactly one of these cases will
hold in s  the choice of p    s  is arbitrary for  b  and  c   but in  a  there may exist optimal
relaxed plans where s cv      c   let odg     v  a  be the sub graph of sg including x 
and the variables arcs included as per definition    let t  be the transition taken by o   
in case  a   obviously we can reorder p    s  so that either o    drop v  l  p  c  is the first
operator in p    s   or all its predecessors are drive operators  odg  then either     includes
no new  non leaf  variables at all  or     includes only v  as for v  clearly all its transitions
are invertible and have no side effects  the transition t  has the own effect  p  v  deleting
 p  l  which clearly is not needed in the rest of p    s   it has the side effect cv   c   deleting
cv   c  that latter fact may be needed by other operators in p    s   either taking the form
drop v  l    p    c  or the form pickup v  l    p    c   clearly  if p    s  contains these operators
then we can replace them with drop v  l    p    c      and pickup v  l    p    c      respectively
 the value  cv   c      will be true at their point of  relaxed  execution  thus we can
choose p    s  so that the p    s  relevant deletes of t  are p    s  recoverable on v    x    
in case  b   similarly we can reorder p    s  so that either     o    pickup v  l  p  k  is the
first operator in p    s   or     all its predecessors are drive operators  the transition t 
has the own effect  p  v  deleting  p  l  which clearly is not needed in the rest of p    s  
it has the side effect cv   k    deleting cv   k  that latter fact may be needed by
other operators in p    s   taking the form pickup v  l    p    k   however  necessarily p    s 
   

fihoffmann

contains an operator of the form drop v  l    p  c     if c     k    then we can replace this
operator with drop v  l    p  k     since  clearly  the value  cv   k     will be true at the
point of  relaxed  execution  now  drop v  l    p  k     is applicable after pickup v  l  p  k 
and a sequence of drive operators that p    s  must contain from l to l    drop v  l    p  k    
recovers cv   k  thus  again  we can choose p    s  so that the p    s  relevant deletes of
t  are p    s  recoverable on v    x     in case  c   finally  odg  contains only v  t  has no
side effects  and its own delete  v  l   is not needed anymore  hence  in all cases  we can
apply theorem    costd  odg        in cases  a     b    and  c  so there we get the bound
   costd  odg          min diam odt g 
v    diam dt gv    in cases  a   and  b   so there
the bound is at most the diameter of the road map gr  
when ignoring action costs  the elevators domain of ipc      is essentially a variant
of transport  the variant is more general in that  a  each vehicle  each elevator  may have
its own maximal capacity  and  b  each vehicle can reach only a subset of the locations  i e  
each vehicle has an individual road map  on the other hand  elevators is more restricted
than transport in that  c  each vehicle road map is fully connected  every reachable floor
can be navigated to directly from every other reachable floor   and  d  goals exist only for
packages  passengers  that is   not for vehicles  even when ignoring restrictions  c  and  d  
it is trivial to see that the arguments given above for transport still hold true  therefore 
whenever s is a reachable state with     h   s      there exists an optimal relaxed plan
p    s  for s so that we can apply theorem    as before  the bound is at most the diameter
of the road map  due to  c   this diameter is   

references
backstrom  c     klein  i          planning in polynomial time  the sas pubs class 
computational intelligence        
backstrom  c     nebel  b          complexity results for sas  planning  computational
intelligence                 
blum  a  l     furst  m  l          fast planning through planning graph analysis  artificial
intelligence                   
bonet  b     geffner  h          planning as heuristic search  artificial intelligence        
        
botea  a   muller  m     schaeffer  j          using component abstraction for automatic
generation of macro actions  in koenig et al   koenig  zilberstein    koehler        
pp         
brafman  r     domshlak  c          structure and complexity in planning with unary
operators  journal of artificial intelligence research             
bylander  t          the computational complexity of propositional strips planning 
artificial intelligence                  
cesta  a     borrajo  d   eds    ecp           recent advances in ai planning   th
european conference on planning  ecp     lecture notes in artificial intelligence 
toledo  spain  springer verlag 
   

fianalyzing search topology without running any search

chen  h     gimenez  o          causal graphs and structurally restricted planning  journal of computer and system sciences                 
domshlak  c     dinitz  y          multi agent offline coordination  structure and complexity  in cesta   borrajo  cesta   borrajo         pp       
edelkamp  s     helmert  m          exhibiting knowledge in planning problems to minimize state encoding length  in biundo  s     fox  m   eds    recent advances in ai
planning   th european conference on planning  ecp     lecture notes in artificial
intelligence  pp          durham  uk  springer verlag 
fox  m     long  d          the automatic inference of state invariants in tim  journal
of artificial intelligence research            
fox  m     long  d          the detection and exploitation of symmetry in planning
problems  in pollack  m   ed    proceedings of the   th international joint conference on artificial intelligence  ijcai     pp          stockholm  sweden  morgan
kaufmann 
garey  m  r     johnson  d  s          computers and intractabilitya guide to the
theory of np completeness  freeman  san francisco  ca 
gerevini  a   howe  a   cesta  a     refanidis  i   eds    icaps           proceedings of
the   th international conference on automated planning and scheduling  icaps   
thessaloniki  greece  aaai 
gerevini  a   saetti  a     serina  i          planning through stochastic local search and
temporal action graphs  journal of artificial intelligence research             
gerevini  a     schubert  l          inferring state constraints for domain independent
planning  in mostow  j     rich  c   eds    proceedings of the   th national conference of the american association for artificial intelligence  aaai     pp         
madison  wi  usa  mit press 
gimenez  o     jonsson  a          the complexity of planning problems with simple
causal graphs  journal of artificial intelligence research             
gimenez  o     jonsson  a       a   the influence of k dependence on the complexity of
planning  in gerevini et al   gerevini  howe  cesta    refanidis         pp         
gimenez  o     jonsson  a       b   planning over chain causal graphs for variables with
domains of size   is np hard  journal of artificial intelligence research             
haslum  p          reducing accidental complexity in planning problems  in veloso  m 
 ed    proceedings of the   th international joint conference on artificial intelligence
 ijcai     pp            hyderabad  india  morgan kaufmann 
helmert  m          complexity results for standard benchmark domains in planning 
artificial intelligence              
helmert  m          a planning heuristic based on causal graph analysis   in koenig et al 
 koenig et al          pp         
helmert  m          the fast downward planning system  journal of artificial intelligence
research             
   

fihoffmann

helmert  m          concise finite domain representations for pddl planning tasks  artificial intelligence                    
helmert  m     domshlak  c          landmarks  critical paths and abstractions  whats
the difference anyway  in gerevini et al   gerevini et al          pp         
hoffmann  j          utilizing problem structure in planning  a local search approach 
vol       of lecture notes in artificial intelligence  springer verlag 
hoffmann  j          where ignoring delete lists works  local search topology in planning
benchmarks  journal of artificial intelligence research             
hoffmann  j     nebel  b       a   the ff planning system  fast plan generation through
heuristic search  journal of artificial intelligence research             
hoffmann  j     nebel  b       b   rifo revisited  detecting relaxed irrelevance  in cesta
  borrajo  cesta   borrajo         pp         
hoffmann  j   porteous  j     sebastia  l          ordered landmarks in planning  journal
of artificial intelligence research             
jonsson  a          the role of macros in tractable planning  journal of artificial intelligence research             
jonsson  p     backstrom  c          incremental planning  in european workshop on
planning 
jonsson  p     backstrom  c          state variable planning under structural restrictions 
algorithms and complexity  artificial intelligence                    
karpas  e     domshlak  c          cost optimal planning with landmarks  in boutilier  c 
 ed    proceedings of the   st international joint conference on artificial intelligence
 ijcai     pp            pasadena  ca  usa  morgan kaufmann 
katz  m     domshlak  c       a   new islands of tractability of cost optimal planning 
journal of artificial intelligence research             
katz  m     domshlak  c       b   structural patterns heuristics via fork decomposition 
in rintanen  j   nebel  b   beck  j  c     hansen  e  a   eds    proceedings of the
  th international conference on automated planning and scheduling  icaps    
pp          sydney  australia  aaai 
knoblock  c          automatically generating abstractions for planning  artificial intelligence                 
koenig  s   zilberstein  s     koehler  j   eds    icaps           proceedings of the
  th international conference on automated planning and scheduling  icaps    
whistler  canada  aaai 
long  d     fox  m          automatic synthesis and use of generic types in planning  in
chien  s   kambhampati  r     knoblock  c   eds    proceedings of the  th international conference on artificial intelligence planning systems  aips     pp         
breckenridge  co  aaai press  menlo park 
mcdermott  d  v          using regression match graphs to control search in planning 
artificial intelligence                    
   

fianalyzing search topology without running any search

nebel  b   dimopoulos  y     koehler  j          ignoring irrelevant facts and operators in
plan generation  in steel  s     alami  r   eds    recent advances in ai planning   th
european conference on planning  ecp     vol       of lecture notes in artificial
intelligence  pp          toulouse  france  springer verlag 
richter  s   helmert  m     westphal  m          landmarks revisited  in fox  d     gomes 
c   eds    proceedings of the   rd national conference of the american association
for artificial intelligence  aaai     pp          chicago  illinois  usa  mit press 
richter  s     westphal  m          the lama planner  guiding cost based anytime
planning with landmarks  journal of artificial intelligence research             
rintanen  j          an iterative algorithm for synthesizing invariants  in kautz  h  a  
  porter  b   eds    proceedings of the   th national conference of the american
association for artificial intelligence  aaai     pp          austin  tx  usa 
mit press 
roberts  m     howe  a          learning from planner performance  artificial intelligence 
            
vidal  v          a lookahead strategy for heuristic search planning  in koenig et al 
 koenig et al          pp         
williams  b  c     nayak  p  p          a reactive planner for a model based executive  in
pollack  m   ed    proceedings of the   th international joint conference on artificial
intelligence  ijcai     pp            nagoya  japan  morgan kaufmann 

   

fi