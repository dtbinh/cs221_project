journal of artificial intelligence research                  

submitted        published      

sequential diagnosis by abstraction
sajjad siddiqi
national university of sciences and technology
 nust  islamabad  pakistan

sajjad ahmed seecs edu pk

jinbo huang
nicta and australian national university
canberra  australia

jinbo huang nicta com au

abstract
when a system behaves abnormally  sequential diagnosis takes a sequence of measurements of the system until the faults causing the abnormality are identified  and the goal
is to reduce the diagnostic cost  defined here as the number of measurements  to propose
measurement points  previous work employs a heuristic based on reducing the entropy over
a computed set of diagnoses  this approach generally has good performance in terms of
diagnostic cost  but can fail to diagnose large systems when the set of diagnoses is too
large  focusing on a smaller set of probable diagnoses scales the approach but generally
leads to increased average diagnostic costs  in this paper  we propose a new diagnostic
framework employing four new techniques  which scales to much larger systems with good
performance in terms of diagnostic cost  first  we propose a new heuristic for measurement
point selection that can be computed efficiently  without requiring the set of diagnoses  once
the system is modeled as a bayesian network and compiled into a logical form known as
d dnnf  second  we extend hierarchical diagnosis  a technique based on system abstraction from our previous work  to handle probabilities so that it can be applied to sequential
diagnosis to allow larger systems to be diagnosed  third  for the largest systems where
even hierarchical diagnosis fails  we propose a novel method that converts the system into
one that has a smaller abstraction and whose diagnoses form a superset of those of the
original system  the new system can then be diagnosed and the result mapped back to
the original system  finally  we propose a novel cost estimation function which can be
used to choose an abstraction of the system that is more likely to provide optimal average
cost  experiments with iscas    benchmark circuits indicate that our approach scales
to all circuits in the suite except one that has a flat structure not susceptible to useful
abstraction 

   introduction
when a system behaves abnormally  the task of diagnosis is to identify the reasons for
the abnormality  for example  in the combinational circuit in figure    given the inputs
p  q  r  the output v should be    but is actually   due to the faults at gates j and
b  given a system comprising a set of components  and a knowledge base modeling the
behavior of the system  along with the  abnormal  observed values of some system variables 
a  consistency based  diagnosis is a set of components whose failure  assuming the other
components to be healthy  together with the observation is logically consistent with the
system model  in our example   v     k    a   and  j  b  are some of the diagnoses given
c
    
ai access foundation  all rights reserved 

fisiddiqi   huang

and

buffer

 
p

 
q

not

 

 
a

j

 
b

or

 

 
d

v

 
k

 
r

figure    a faulty circuit 

the observation  in general  the number of diagnoses can be exponential in the number of
system components  and only one of them will correspond to the set of actual faults 
in this paper  therefore  we consider the problem of sequential diagnosis  de kleer  
williams         where a sequence of measurements of system variables is taken until the
actual faults are identified  the goal is to reduce the diagnostic cost  defined here as the
number of measurements  to propose measurement points  the state of the art gde  general
diagnosis engine  framework  de kleer   williams        de kleer  raiman    shirley       
de kleer        considers a heuristic based on reducing the entropy over a set of computed
diagnoses  this approach generally has good performance in terms of diagnostic cost  but
can fail to diagnose large systems when the set of diagnoses is too large  de kleer   williams 
      de kleer et al         de kleer         focusing on a smaller set of probable diagnoses
scales the approach but generally leads to increased average diagnostic costs  de kleer 
      
we propose a new diagnostic framework employing four new techniques  which scales to
much larger systems with good performance in terms of diagnostic cost  first  we propose a
new heuristic that does not require computing the entropy of diagnoses  instead we consider
the entropies of the system variables to be measured as well as the posterior probabilities
of component failures  the idea is to select a component that has the highest posterior
probability of failure  heckerman  breese    rommelse        and from the variables of
that component  measure the one that has the highest entropy  to compute probabilities 
we exploit system structure so that a joint probability distribution over the faults and
system variables is represented compactly as a bayesian network  pearl         which is then
compiled into deterministic decomposable negation normal form  d dnnf   darwiche       
darwiche   marquis         d dnnf is a logical form that can exploit the structure present
in many systems to achieve compactness and be used to compute probabilistic queries
efficiently  specifically  all the required posterior probabilities can be exactly computed by
evaluating and differentiating the d dnnf in time linear in the d dnnf size  darwiche 
      
   

fisequential diagnosis by abstraction

second  we extend hierarchical diagnosis  a technique from our previous work  siddiqi
  huang         to handle probabilities so that it can be applied to sequential diagnosis to
allow larger systems to be diagnosed  specifically  self contained subsystems  called cones 
are treated as single components and diagnosed only if they are found to be faulty in the
top level diagnosis  this significantly reduces the number of system components  allowing
larger systems to be compiled and diagnosed  for example  the subcircuit in the dotted box
in figure   is a cone  with a as output and  p  d  as inputs  which contains a fault  first 
cone a  as a whole  is determined as faulty  it is only then that a is compiled separately
and diagnosed  in previous work  siddiqi   huang        we only dealt with the task of
computing diagnoses  which did not involve measurements or probabilities  in the present
paper  we present several extensions that allow the technique to carry over to sequential
diagnosis 
third  when the abstraction of a system is still too large to be compiled and diagnosed 
we use a novel structure based technique called cloning  which systematically modifies the
structure of a given system c to obtain a new system c  that has a smaller abstraction
and whose diagnoses form a super set of those of the original system  the new system can
then be diagnosed and the result mapped back to the original system  the idea is to select
a system component g that is not part of a cone and hence cannot be abstracted away in
hierarchical diagnosis  create one or more clones of g  and distribute gs parents  from a
graph point of view  among the clones  in such a way that g and its clones now become parts
of cones and disappear from the abstraction  repeated applications of this operation can
allow an otherwise unmanageable system to have a small enough abstraction for diagnosis
to succeed 
finally  we propose a novel cost estimation function that can predict the expected
diagnostic cost when a given abstraction of the system is used for diagnosis  our aim is
to find an abstraction of the system that is more likely to give optimal average cost  for
this purpose  we use this function on various abstractions of the system where different
abstractions are obtained by destroying different cones in the system  by destroying a
cone we mean to overlook the fact that it is a cone and include all its components in the
abstraction   the abstraction with the lowest predicted cost can then be used for the actual
diagnosis 
experiments on iscas    benchmark circuits  brglez   fujiwara        indicate that
we can solve for the first time nontrivial multiple fault diagnostic cases on all the benchmarks  with good diagnostic costs  except one circuit that has a flat structure not susceptible
to useful abstraction  and the new cost estimation function can often accurately predict the
abstraction which is more likely to give optimal average cost 

   background and previous work
suppose that the system to be diagnosed is formally modeled by a joint probability distribution p r x  h  over a set of variables partitioned into x and h  variables x are
those whose values can be either observed or measured  and variables h are the health variables  one for each component describing its health mode  the joint probability distribution
p r x  h  defines a set of system states 
   

fisiddiqi   huang

diagnosis starts in the initial  belief  state
i    p r x  h   xo   xo  

   

where values xo of some variables xo  x  we are using boldface uppercase letters to mean
both sets and vectors  are given by the observation  and we wish to reach a goal state
in   p r x  h   xo   xo   xm   xm  

   

after measuring the values xm of some variables xm  x xo    xm     n  one at a time 
such that  the boldface   and   denote vectors of  s and  s  
hf  h  p r hf       xo   xo   xm   xm       and
p r hf      h hf       xo   xo   xm   xm       
that is  in a goal state a set of components hf are known to be faulty with certainty
and no logical inconsistency arises if all other components are assumed to be healthy  other
types of goal conditions are possible  for example  if the health states of all components are
to be determined with certainty  the condition will be that p r h       xo   xo   xm   xm  
is   or   for all h  h  such goals are only possible to reach if strong fault models are given 
where strong fault models are explicit descriptions of abnormal behavior  as opposed to
weak fault models where only the normal behavior is known  
two special cases are worth mentioning      if the initial state i  satisfies the goal
condition with hf    then the observation is normal and no diagnosis is required     
if the initial state i  satisfies the goal condition with some hf      then the observation
is abnormal but the diagnosis is already completed  assuming that we are able to check
probabilities as necessary   in other words  a sequence of length   solves the problem 
following de kleer and williams        we assume that all measurements have unit
cost  hence the objective is to reach a goal state in the fewest measurements possible 
the classical gde framework  on receiving an abnormal observation xo   xo   considers
the shannons entropy of the probability distribution over a set of computed diagnoses 
which is either the set of minimum cardinality diagnoses or a set of probable leading diagnoses  it proposes to measure a variable x whose value will reduce that entropy the most 
on average  the idea is that the probability distribution over the diagnoses reflects the
uncertainty over the actual faults  and the entropy captures the amount of this uncertainty 
after a measurement is taken the entropy is updated by updating the posterior probabilities
of the diagnoses  potentially reducing some of them to   
the results reported by de kleer et al         involving single fault cases for iscas   
circuits indicate that this method leads to measurement costs close to those of optimal
policies  however  a major drawback is that it can be impractical when the number of
diagnoses is large  e g   the set of minimum cardinality diagnoses can be exponentially
large   focusing on a smaller set of probable diagnoses scales the approach but can increase
the likelihood of irrelevant measurements and generally leads to increased average diagnostic
costs  de kleer        
from here on  we shall use combinational circuits as an example of the type of systems
we wish to diagnose  our approach  however  applies as well to other types of systems as
   

fisequential diagnosis by abstraction

p
 
 

p
   
   

p
 
 
 
 
 
 
 
 

okj
 
 
 
 
 
 
 
 

okj
 
 
j
 
 
 
 
 
 
 
 

okj
   
   

j p okj
 
 
   
   
 
 
   
   

figure    bayesian network for the circuit in figure    left   cpts for nodes p   j  and
okj  right  

long as a probabilistic model is given that defines the behavior of the system  in sections  
and   we will present the new techniques we have introduced to significantly enhance the
scalability of sequential diagnosis  we start  however  by presenting in the following section
the system modeling and compilation method that underlies our new diagnostic system 

   system modeling and compilation
in order to define a joint probability distribution p r x  h  over the system behavior  we
first assume that the prior probability of failure p r h      is given for each component
h  h as part of the input to the diagnosis task  de kleer   williams         for example 
the small table with two entries on the top right of figure   gives the prior probability of
failure for gate j as     
    conditional probability tables
prior fault probabilities alone do not define the joint probability distribution p r x  h  
in addition  we need to specify for each component how its output is related to its inputs
and health mode  a conditional probability table  cpt  for each component does this job 
the cpt shown on the bottom  right  of figure    for example  defines the behavior
of gate j  each entry gives the probability of its output  j  being a particular value given
the value of its input  p   and the value of its health variable  okj   in case okj     
the probabilities are always   or   as the behavior of a healthy gate is deterministic  the
case of okj     defines the fault model of the gate  which is also part of the input to the
diagnosis task  in our example  we assume that both output values have probability    
when the gate is broken  for simplicity we assume that all gates have two health modes
   

fisiddiqi   huang

 i e   each health variable is binary   the encoding and compilation to be described later 
however  allows an arbitrary number of health modes 
given these tables  the joint probability distribution over the circuit behavior can be
obtained by realizing that the gates of a circuit satisfy an independence property  known as
the markov property  given its inputs and health mode  the output of a gate is independent
of any wire which is not a descendant of the gate  a wire x is a descendant of a gate y if x
can be reached following a path from y to an output of the circuit in the direction towards
the circuit outputs   this means that the circuit can be effectively treated as a bayesian
network in the straightforward way  by having a node for each wire and each health variable 
and having an edge going from each input of a gate to its output  and also from the health
variable of a gate to its output  figure   shows the result of this translation for the circuit
in figure   
the joint probability distribution encoded in the bayesian network provides the basis
for computing any posterior probabilities that we may need when proposing measurement
points  by the chain rule   however  it does not provide an efficient way of doing so 
specifically  computing a posterior p r x   x   y   y  given the values y of all the variables
y with known values involves summing out all variables other than x and y  which has a
complexity exponential in the number of such variables if done naively 
    propositional modeling
it is known that a bayesian network can be encoded into a logical formula and compiled
into d dnnf  which  if successful  allows posterior probabilities of all variables to be computed efficiently  darwiche         for the purposes of sequential diagnosis  we encode the
bayesian network as follows 
consider the subcircuit in the dotted box in figure   as an example  which can be
modeled as the following formula 
okj   j  p    oka   a   j  d   
specifically  each signal of the circuit translates into a propositional variable  a  d 
p   j   and for each gate  an extra variable is introduced to model its health  oka  okj  
the formula is such that when all health variables are true the remaining variables are
constrained to model the functionality of the gates  in general  for each component x  we
have okx  normalbehavior x  
note that the above formula fails to encode half of the cpt entries  where okj      in
order to complete the encoding of the cpt of node j  we introduce an extra boolean variable
j   and write okj   j  j    finally  the health variables  oka  okj  are associated
with the probabilities of the respective gates being healthy      in our experiments   and
each  variable  j   is associated with the probability of the corresponding gate giving an
output of   when broken      in our experiments  thus assuming that the output of a faulty
gate is probabilistically independent of its inputs  
the above encoding of the circuit is similar to the encoding of bayesian networks described by darwiche        in the following way  according to the encoding by darwiche 
for every node in a bayesian network and for every value of it there is an indicator variable 
similarly for every conditional probability there is a network parameter variable  in our
   

fisequential diagnosis by abstraction

encoding  the variables for the wires are analogous to the network indicators  where the
encoding is optimized such that there is a single indicator for both values of the wire  also 
our encoding exploits the logical constraints and does not generate network parameters for
zeros and ones in the cpt  finally  the encoding for a node that represents a health variable has been optimized such that we only need a single ok variable which serves both as
an indicator and as a network parameter 
once all components are encoded as described above  the union  conjunction  of the
formulas is compiled into d dnnf  the required probabilities can be exactly computed
by evaluating and differentiating the d dnnf in time linear in its size  darwiche        
details of the compilation process are discussed by darwiche         and the computation
of probabilities is described in appendix a 
we now present our hierarchical diagnosis approach and propose a new measurement
selection heuristic 

   hierarchical sequential diagnosis
an optimal solution to sequential diagnosis would be a policy  that is  a plan of measurements conditioned on previous measurement outcomes  where each path in the plan leads
to a diagnosis of the system  heckerman et al          as computing optimal policies is
intractable in general  we follow the approach of heuristic measurement point selection as
in previous work 
we start with a definition of shannons entropy   which is defined with respect to a
probability distribution of a discrete random variable x ranging over values x    x            xk  
formally 
k
x
 x    
p r x   xi   log p r x   xi   
   
i  

entropy measures the amount of uncertainty over the value of the random variable  it
is maximal when all probabilities p r x   xi   are equal  and minimal when one of the
probabilities is    corresponding nicely to our intuitive notion of the degree of uncertainty 
in gde the entropy is computed for the probability distribution over the set of computed
diagnoses  i e   the value of the random variable x here ranges over the set of diagnoses  
as mentioned earlier  this entropy can be difficult to compute when the number of diagnoses
is large  de kleer   williams        de kleer        
    baseline approach
able to compute probabilities efficiently and exactly following successful d dnnf compilation  we now propose a new two part heuristic that circumvents this limitation in scalability 
first  we consider the entropy of a candidate variable to be measured 
      heuristic based on entropy of variable
since a wire x only has two values  its entropy can be written as 
 x     px log px   px log px  
   

   

fisiddiqi   huang

where px   p r x       y   y  and px   p r x       y   y  are the posterior probabilities
of x having values   and    respectively  given the values y of wires y whose values are
known 
while  x  captures the uncertainty over the value of the variable  we can also interpret
it as the expected amount of information gain provided by measuring the variable  hence
as a first idea we consider selecting a variable with maximal entropy for measurement at
each step 
      improving heuristic accuracy
this idea alone  however  did not work very well in our initial experiments  as would be
confirmed by subsequent experiments  this is largely due to the fact that the  implicit  space
of all diagnoses is generally very large and can include a large number of unlikely diagnoses 
which tends to compromise the accuracy of the information gain provided by the entropy 
the experiments to confirm this explanation are as follows 
when the d dnnf compilation is produced  and before it is used to compute probabilities  we prune the d dnnf graph so that models  satisfying variable assignments 
corresponding to diagnoses with more than k broken components are removed   we set the
initial k to the number of actual faults in the experiments  and observed that a significant
reduction of diagnostic cost resulted in almost all cases  this improved performance is apparently due to the fact that the pruning updates the posterior probabilities of all variables 
making them more accurate since many unlikely diagnoses have been eliminated 
in practice  however  the number of faults is not known beforehand and choosing an
appropriate k for the pruning can be nontrivial  note that k need not be exactly the same
as the number of actual faults for the pruning to help   interestingly  the following heuristic 
which is the one we will actually use  appears to achieve a similar performance gain in an
automatic way  we select a component that has the highest posterior probability of failure
 an idea from heckerman et al         see section     and then from the variables of that
component  measure the one that has the highest entropy  this heuristic does not require
the above pruning of the d dnnf  and appears to improve the diagnostic cost to a similar
extent by focusing the measurement selection on the component most likely to be broken
 empirical results to this effect are given and discussed in section      
      the algorithm
we start by encoding the system as a logical formula as discussed in section    where a
subset of the variables are associated with numbers representing the prior fault probabilities
and probabilities involved in the fault models of the components  which is then compiled
into d dnnf  
the overall sequential diagnosis process we propose is summarized in algorithm    the
inputs are a system c  its d dnnf compilation   the set of faults d  which is empty
but will be used in the hierarchical approach   a set of known values y of variables  and
an integer k specifying the fault cardinality bound  this is for running the model pruning
experiments described in section        and is not required for diagnosis using our final
   a complete pruning is not easy  however  an approximation can be achieved in time linear in the d dnnf
size  by a variant of the minimization procedure described by darwiche         see appendix b 

   

fisequential diagnosis by abstraction

algorithm   probabilistic sequential diagnosis
function psd c    d  y  k 
inputs   c  system      d dnnf    y  measurements    k  fault cardinality    d  ordered set
of known faults 
output   pair  d   y   
     reduce     d  k   d    if d has changed
   given y on variables y  evaluate    y  to obtain p r y 
   differentiate    to obtain p r x      y   variables x
   deduce fault as d   d   x   p r okx      y      
   if d has changed    meetscriteria  d y  then
  
return   d   y  
   measure variable x which is the best under a given heuristic
   add the measured value x of x to y  and go back to line  

heuristic   we reduce  by pruning some models  line    when the fault cardinality bound
k is given  using the function reduce   d  k   d    reduce accepts as arguments the
current dnnf   the set of known faults d  and the upper bound given by k  d on the
cardinality of remaining faults  whereas it returns the pruned dnnf  reduce excludes the
known faults in d when computing the minimum cardinality of   and then uses k   d 
as the bound on the remaining faults  explained further in appendix b    is reduced first
time when psd is called and later each time d is changed  i e   when a component is found
faulty   we then evaluate  line    and differentiate  line      see appendix a   select a
measurement point and take the measurement  line     and repeat the process  line    until
the stopping criteria are met  line    
the stopping criteria on line   are given earlier in section   as the goal condition  i e  
we stop when the abnormal observation is explained by all the faulty components d already
identified assuming that other components are healthy  a faulty component x is identified
when p r okx      y      where y are the values of variables that are already known 
and as mentioned earlier these probabilities are obtained for all variables simultaneously in
the d dnnf differentiation process  finally  the condition that the current set of faulty
components  with health modes hf   explains the observation is satisfied when p r hf  
   h hf      y       which is checked by a single evaluation of the original d dnnf  the
algorithm returns the actual faults together with the new set of known values of variables
 line    
    hierarchical approach
we now scale our approach to handle larger systems using the idea of abstraction based
hierarchical diagnosis  siddiqi   huang         the basic idea is that the compilation of
the system model into d dnnf will be more efficient and scalable when the number of
system components is reduced  this can be achieved by abstraction  where subsystems 
known as cones  are treated as single components  an example of a cone is depicted in
figure    the objective here is to use a single health variable and failure probability for
the entire cone  hence significantly reducing the size of the encoding and the difficulty of
compilation  once a cone is identified as faulty in the top level diagnosis  it can then be
compiled and diagnosed  in a recursive fashion 
   

fisiddiqi   huang

we now give formal definition of abstraction from our previous work 
      abstraction of system
abstraction is based upon the structural dominators  kirkland   mercer        of a system 
a component x dominates a component y   or x is called a dominator of y   if any path
from y to any output of the system contains x  a cone corresponds precisely to the set
of components dominated by a component  a cone may contain further cones leading to a
hierarchy of cones 
a system can be abstracted by treating all maximal cones in it as black boxes  a maximal
cone is one that is either contained in no other cone or contained in exactly one other cone
which is the whole system   in our example  cone a can be treated as a virtual gate with
two inputs  p  d  and the output a  the abstraction of a system can be formally defined
as 
definition    abstraction of system   given a system c  let c    c if c has a single
output  otherwise let c  be c augmented with a dummy component collecting all outputs
of c  let o be the only output of c    the abstraction ac of system c is then the set of
components x  c such that x is not dominated in c  by any component other than x
and o 
for example  ac    a  b  d  k  v    j   ac as j cannot reach any output without
passing through a  which is a dominator of j 
in our previous work  siddiqi   huang         we only dealt with the task of computing minimum cardinality diagnoses  which does not involve probabilities or measurement
selection  in the context of sequential diagnosis  several additional techniques have been
introduced  particularly in the computation of prior failure probabilities for the cones and
the way measurement points are selected  outlined below 
      propositional encoding
we start with a discussion of the hierarchical encoding for probabilistic reasoning  which is
similar to the hierarchical encoding presented in our previous work  siddiqi   huang        
specifically  for the diagnosis of the abstraction ac of the given system c  health variables
are only associated with the components ac  ic   which are the gates  a  b  d  k  v   in
our example  ic stands for the set of inputs of the system c   thus the gate j in figure  
will not be associated with a health variable  as j is a wire internal to the cone rooted
at a  consequently  only the nodes representing the components ac  ic will have health
nodes associated with them in the corresponding bayesian network  hence the node okj is
removed from the bayesian network in figure   
in addition  we define the failure of a cone to be when it outputs the wrong value  and
introduce extra clauses to model the abnormal behavior of the cone  for example  the
encoding given in section     for cone a in figure    in the dotted box  is as follows 
j  p  oka   a   j  d    oka   a    j  d  
the first part of the formula encodes the normal behavior of gate j  without a health
variable   the next encodes the normal behavior of the cone  the last encodes that the
   

fisequential diagnosis by abstraction

cone outputs a wrong value when it fails  other gates  that are not roots of cones  in the
abstraction ac are encoded normally as described in section     
note that the formulas for all the components in a cone together encode a single cpt
for the whole cone  which provides the conditional probability of the cones output given
the health and inputs of the cone  instead of the health and inputs of the component at
the root of the cone  for example  the above encoding is meant to provide the conditional
probability of a given p   d  and oka  instead of j  d  and oka   where oka represents
the health mode of the whole cone and is associated with its prior failure probability  which
is initially unknown to us and has to be computed for all cones  explained below   such
an encoding of the whole system provides a joint probability distribution over the variables
ac  ic  h  where h    okx   x  ac  ic   
      prior failure probabilities for cones
when a cone is treated as a single component  its prior probability of failure as a whole can
be computed given the prior probabilities of components and cones inside it  we do this by
creating two copies h and f of the cone  where h models only the healthy behavior of
the cone  without health variables   and f includes the faulty behavior as well  i e   the
full encoding described in section       the outputs of both h and f are collected into
an xor gate x when the output of xor gate x equals    both of its inputs are forced to
be different in value   we then compute the probability p r x      giving the probability
of the outputs of h and f being different  the probability is computed by compiling this
encoding into d dnnf and evaluating it under x     
note that this procedure itself is also abstraction based and hierarchical  performed
bottom up with the probabilities for the inner cones computed before those for the outer
ones  also note that it is performed only once per system as a pre processing step 
      measurement point selection and stopping criteria
in principle  the heuristic to select variables for measurement and the stopping criteria are
the same as in the baseline approach  however  a couple of details are worth mentioning 
first  when diagnosing the abstraction of a given system  or cone  c  the measurement
candidates are restricted to variables ac ic   ignoring the internal variables of the maximal
conesthose are only measured if a cone as a whole has been found faulty 
second  it is generally important to have full knowledge of the values of cones inputs
before a final diagnosis of the cone is concluded  a diagnosis of a cone concluded with only
partial knowledge of its inputs may not include some faults that are vital to the validity of
global diagnosis  the reason is that the diagnosis of the cone assumes that the unknown
inputs can take either value  while in reality their values may become fixed when variables
in other parts of the system are measured  causing the diagnosis of certain cones to become
invalid  and possibly requiring the affected cones to be diagnosed once again to meet the
global stopping criteria  see line    in algorithm    
to avoid this situation while retaining the effectiveness of the heuristic  we modify the
measurement point selection as follows when diagnosing a cone  after selecting a component
with the highest probability of failure  we consider the variables of that component plus the
inputs of the cone  and measure the one with the highest entropy  we do not conclude a
   

fisiddiqi   huang

algorithm   hierarchical probabilistic sequential diagnosis
function hpsd c  uc   k 
inputs   c   system   uc   obs  across system   k  fault cardinality 
local variables   b  d  t   set of components   y  z  ug   set of measurements   i  k     integer 
output   pair  d   uc   
     compile ddnnf  ac   uc  
   i      d     y  uc
     b  y   psd  c    b  y  k 
   for    i    b   i      do
  
g element  b  i 
  
if g is a cone then
  
z  y  implications    y 
  
ug   x   x  z  x  ig  og  
  
k    k   d    b    i    
   
  t  ug   hpsd dg  ig   ug   k    
   
y  y  ug   d  d  t
   
evaluate    y   differentiate     
   
else
   
d  d   g 
    z  y  implications    y 
    uc  uc   x   x  z  x  ic  oc  
    if meetscriteria  c  d  y  then
   
return   d   uc  
    else
   
goto line  

diagnosis for the cone until values of all its inputs become known  through measurement or
deduction   except when the health of all the components in the cone has been determined
without knowing all the inputs to the cone  it is possible to identify a faulty component 
and with strong fault models also a healthy component  without knowing all its inputs  
note that the restriction of having to measure all the inputs of a cone can lead to significant
increase in the cost compared with the cost of baseline approach  especially when the number
of inputs of a cone is large  this is discussed in detail in section   
      the algorithm
pseudocode for the hierarchical approach is given in algorithm   as a recursive function 
the inputs are a system c  a set of known values uc of variables at the inputs ic and
outputs oc of the system  and again the optional integer k specifying the fault cardinality
bound for the purpose of experimenting with the effect of model pruning  we start with
the d dnnf compilation of the abstraction of the given system  line    and then use the
function psd from algorithm   to get a diagnosis b of the abstraction  line     assuming that
the measurement point selection and stopping criteria in algorithm   have been modified
according to what is described in section        the abstract diagnosis b is then used to
get a concrete diagnosis d in a loop  lines       specifically  if a component g  b is
not the root of a cone  then it is added to d  line      otherwise cone g is recursively
diagnosed  line     and the result of it added to d  line      when recursively diagnosing
   

fisequential diagnosis by abstraction

a cone g  the subsystem contained in g is represented by dg  ig   where dg is the set of
components dominated by g and ig is the set of inputs of cone g 
before recursively diagnosing a cone g  we compute an abnormal observation ug at the
inputs and the output  ig  g   of the cone g  the values of some of gs inputs and output
will have been either measured or deduced from the current set of measurements  the value
of a variable x is implied to be x under the measurements y if p r x   x  y       which
is easy to check once  has been differentiated under y  the function implications   y 
 lines   and     implements this operation  which is used to compute the partial abnormal
observation ug  line     a fault cardinality bound k   for the cone g is then inferred  line    
and the algorithm called recursively to diagnose g  given ug and k    
the recursive call returns the faults t inside the cone g together with the updated
observation ug   the observation ug may contain some new measurement results regarding
the variables ig   g   which are added to the set of measurements y of the abstraction
 line      other measurement results obtained inside the cone are ignored due to reasons
explained in section        the concrete diagnosis d is augmented with the faults t found
inside the cone  line      and  is again evaluated and differentiated in light of the new
measurements  line     
after the loop ends  the variable uc is updated with the known values of the inputs
ic and outputs oc of the system c  line      the stopping criteria are checked for the
diagnosis d  line     and if met the function returns the pair   d  uc    line      otherwise
more measurements are taken until the stopping criteria  line     have been met 
since d can contain faults from inside the cones  the compilation  cannot be used
to check the stopping criteria for d  note the change in the parameters to the function
meetscriteria at line     as the probabilistic information regarding variables inside cones
is not available in   the criteria are checked as follows instead  we maintain the depth
level of every component in the system  the outputs of the system are at depth level   and
the rest of the components are assigned depth levels based upon the length of their shortest
route to an output of the system  for example  in figure   gates b and j are at depth
level    while a is at depth level    hence  b and j are deeper than a  we first propagate
the values of inputs in the system  and then propagate the fault effects of components in
d  one by one  by flipping their values to the abnormal ones and propagating them towards
the system outputs in such a way that deeper faults are propagated first  siddiqi   huang 
       and then check the values of system outputs obtained for equality with those in the
observation  y  
      example
suppose that we diagnose the abstraction of the circuit in figure    with the observation
uc    p      q      r      v       and take the sequence of measurements y    d  
   k      a       it is concluded  from the abstract system model  that given the values
of p and d  the value   at a is abnormal  so the algorithm concludes a fault at a  note
that q     and d     suggests the presence of another fault besides a  triggering the
measurement of gate b  which is also found faulty  the abstract diagnosis  a  b  meets
the stopping criteria with respect to the abstract circuit 
   

fisiddiqi   huang

 
p

 
q

 

 
e

j

 
b

 
a

 

 
d

v

 
k

 
r

figure    a faulty circuit with faults at b and j 
 
p

 
j

 
e

 
a

 
b
 
q

 
b 

 

 
d

v

 
k

 
r

figure    creating a clone b   of b according to d 
we then enter the diagnosis of cone a by a recursive call with observation ua    p  
   b      a       the diagnosis of the cone a immediately reveals that the cone e is
faulty  hence we make a further recursive call in order to diagnose e with the observation
ue    p      b      e       the only unknown wire j is measured and the gate j is found
faulty  which explains the observation at the outputs of the cones e as well as a  given the
inputs p and b  the recursion terminates and the abstract diagnosis b    a  b  generates
the concrete diagnosis d    j  b   which meets the stopping criteria and the algorithm
terminates 

   component cloning
in the preceding section  we have proposed an abstraction based approach to sequential diagnosis  which reduces the complexity of compilation and diagnosis by reducing the number
of system components to be diagnosed  we now take one step further  aiming to handle
systems that are so large that they remain intractable even after abstraction  as is the case
for the largest circuits in the iscas    benchmark suite 
our solution is a novel method that systematically modifies the structure of a system to
reduce the size of its abstraction  specifically  we select a component g with parents p  a
component x is a parent of a component y   and y is a child of x  if the output of y is an
input of x  that is not part of a cone and hence cannot be abstracted away in hierarchical
   

fisequential diagnosis by abstraction

diagnosis  and create a clone g  of it according to some of its parents p   p in the sense
that g  inherits all the children of g and feeds into p  while g no longer feeds into p   see
figures   and   for an example   the idea is to create a sufficient number of clones of g
so that g and its clones become part of some cones and hence can be abstracted away 
repeated applications of this operation can allow an otherwise unmanageable system to
have a small enough abstraction for compilation and diagnosis to succeed  the hierarchical
algorithm is then extended to diagnose the new system and the result mapped to the
original system  we show that we can now solve almost all the benchmark circuits  using
this approach 
before we go into the details of the new method  we differentiate it from a technique
known as node splitting  choi  chavira    darwiche         which is used to solve mpe
queries on a bayesian network  node splitting breaks enough number of edges between
nodes from the network such that the mpe query on the resulting network becomes easy
to solve  a broken edge is replaced with a root variable with a uniform prior  the resulting
network is a relaxation or approximation of the original in that its mpe solution  which
may be computed from its compilation  gives an upper bound on the mpe solution of the
original network  a depth first branch and bound search algorithm then searches for an
optimal solution using these bounds to prune its search space  a similar approach is also
used to solve weighted max sat problems  pipatsrisawat   darwiche        
this version of node splitting is not directly applicable in the present setting for the
following reasons  if edges in a system are broken and redirected into new root variables
 primary inputs   the resulting system represents a different input output function from
that of the original system  the abnormal observation on the original system may hence
become a normal one on the new system  if the edges through which the fault propagates
are broken   eliminating the basis for diagnosis  our technique of component cloning  which
can also be viewed as a version of node splitting  introduces clones of a component instead
of primary inputs and preserves the input output function of the system  also  the new
system is a relaxation of the original in that its diagnoses are a superset of those of the
original 
we now formally define component cloning 
definition    component cloning   let g be a component in a system c with parents
p  we say that g is cloned according to parents p   p when system c results in a
system c  as follows 
 the edges going from g to its parents p  are removed 
 a new component g  functionally equivalent to g is added to the system such that
g  shares the inputs of g and feeds into each of p   
figures   and   show an example where creating a clone b   of b according to  d 
results in a new circuit whose abstraction contains only the gates  a  d  k  v    whereas
the abstraction of the original circuit contains also gate b 
    choices in component cloning
there are two choices to be made in component cloning  which components do we clone 
and for each of them how many clones do we create and how do they split the parents 
   

fisiddiqi   huang

since the goal of cloning is to reduce the abstraction size  it is clear that we only wish
to clone those components that lie in the abstraction  i e   not within cones   among these 
cloning of the root of a cone cannot reduce the abstraction size as it will destroy the existing
cone by reintroducing some of the components inside the cone into the abstraction  for
example  cloning d according to k in figure   will produce a circuit where d and its clone
can be abstracted away but b   is no longer dominated by d and hence is reintroduced into
the abstraction  therefore  the final candidates for cloning are precisely those components
in the abstract system that are not roots of cones  note that the order in which these
candidates are processed is unimportant in that each when cloned will produce an equal
reduction  namely a reduction of precisely   in the abstraction size  if any 
it then remains to determine for each candidate how many clones to create and how
to connect them to the parents  to understand our final method  it helps to consider a
naive method that simply creates  p     clones  where p is the set of parents  and has
each clone  as well as the original  feed into exactly one parent  this way every parent of
the component becomes the root of a cone and the component itself and all its clones are
abstracted away  in figure    for example  b has three parents  e  a  d   and this naive
method would create two clones of b for a total of three instances of the gate to split the
three parents  which would result in the same abstraction as in figure   
the trick now is that the number of clones can be reduced by knowing that some parents
of the component may lie in the same cone and a single clone of the component according
to those parents will be sufficient for that clone to be abstracted away  in the example of
figure    again  the parents e  a of b lie in the same cone a and it would suffice to create
a single clone of b according to  e  a   resulting in the same  more efficient cloning as in
figure   
more formally  we partition the parents of a component g into subsets p    p            pq
such that those parents of g that lie in the same cone are placed in the same subset and
the rest in separate ones  we then create q    clones of g according to any q    of these
subsets  resulting in g and all its clones being abstracted away  this process is repeated for
each candidate component until the abstraction size is small enough or no further reduction
is possible 
    diagnosis with component cloning
the new system is functionally equivalent to the original and has a smaller abstraction 
but is not equivalent to the original for diagnostic purposes  as the new model allows
a component and its clones to fail independently of each other  it is a relaxation of the
original model in that the diagnoses of the new system form a superset of those of the
original  specifically  each diagnosis of the new system that assigns the same health state
to a component and its clones for all components corresponds to a diagnosis of the original
system  other diagnoses are spurious and are to be ignored 
the core diagnosis process given in algorithm   continues to be applicable on the new
system  with only two minor modifications necessary  first  the spurious diagnoses are
 implicitly  filtered out by assuming the same health state for all clones  including the
original  of a component as soon as the health state of any one of them is known  second 
whenever measurement of a clone of a component is proposed  the actual measurement is
   

fisequential diagnosis by abstraction

c    
number of cone inputs

  
  
  
  
  
  
 
 

   

    

    

    

    

cones

figure    cones in iscas    circuits 

taken on the original component in the original system  for obvious reasons  in other words 
the new system is used for reasoning and the original for measurements  
in principle  the presence of spurious diagnoses in the model can potentially skew the
measurement point selection heuristic  at least in the early stages of diagnosis  before the
spurious diagnoses are gradually filtered out   however  by using smaller benchmarks that
could be diagnosed both with and without cloning  we conducted an empirical analysis
which indicates  interestingly  that the overall diagnostic cost is only slightly affected  we
discuss this in more detail in section     

   diagnostic cost estimation
we now address an interesting issue stemming from an observation we made conducting experiments  to be detailed in the next section   while system abstraction is always beneficial
to compilation  the diagnostic cost does not always improve with the associated hierarchical
diagnosis  on the one hand  the hierarchical diagnosis approach can help in cases which
otherwise result in high costs using baseline approach by quickly finding faulty portions of
the system  represented by a set of faulty cones  and then directing the sequential diagnosis
to take measurements inside those cones  resulting in more useful measurements  on the
other hand  it can introduce overhead for cases where it has to needlessly go through hier   

fisiddiqi   huang

archies to locate the actual faults  and measure inputs of cones involved  while the baseline
version can find them more directly and efficiently 
the overhead of hierarchical approach can be quite high for faults that lie in cones with
a large number of inputs  for example  the graphs in figure   show the number of inputs 
represented as dots  of various cones in iscas    circuits  note that most of the cones have
a small number of inputs  however  some cones can have more than    inputs  especially
in c    and the circuits beyond c      which contribute to increased diagnostic cost in
several cases  such increase in the cost due to cones was also confirmed by a separate set of
experiments using a large set of systematically generated combinational circuits  detailed
in appendix c   to avoid the potential high cost of diagnosis for faults that lie in a cone
with a large number of inputs it is tempting to destroy that cone before compilation so
that any fault in it can now be directly found  however  due to the associated increase in
the abstraction size  destroying cones may cause increased costs for those cases that could
previously be solved more efficiently  and thus may show a negative impact  overall  this
calls for an automatic mechanism to predict the effect of destroying certain cones on the
overall diagnostic cost  which is the subject of this section 
we propose a novel cost estimation function to predict the average diagnostic cost when
a given abstraction of the system is considered for diagnosis  where different abstractions
can be obtained by destroying different cones in the system  since cones can be destroyed
automatically  the function can be used to automatically propose an abstraction of the system  to be used for diagnosis  that is more likely to give optimal average cost  the function
uses only the hierarchical structure of the given abstraction to predict its cost and does not
take into account other parameters that may also contribute to the cost  such as the probabilities  in addition the function is limited to single fault cases only  therefore  the expected
cost computed by this function is only indicative and cannot be always correct  however 
experiments show that the function is often quite useful in proposing an abstraction of the
system that is more likely to give optimal cost  to be discussed in the next section  
to estimate the expected diagnostic cost we assume that it is composed of two quantities
namely the isolation cost and the abstraction cost  which are inversely proportional to each
other  the isolation cost captures how well the given system abstraction can isolate the
faulty portions of the system  therefore the isolation cost is minimum when a complete
abstraction of the system is used  i e   all cones are considered  and generally increases as
cones are destroyed  the abstraction cost captures the overhead cost due to introduction
of cones  hence  the abstraction cost is minimum  zero  when no abstraction is considered
and generally increases as cones are introduced 
we define the isolation cost of diagnosis considering an abstraction of the system to
be the average cost required to isolate a single fault in the system using that abstraction 
similarly  we define the abstraction cost of diagnosis to be the average overhead cost required
to diagnose a single fault in the system using that abstraction  then the expected average
cost of diagnosis when an abstraction of the system is considered for diagnosis is the sum of
the isolation and the abstraction costs for that abstraction  as different cones are destroyed
in a given abstraction of the system we expect changes in the values of the abstraction and
isolation costs  which determine whether the overall cost can go up or down  if the changes
are uneven  or stay constant  if the changes are even   the idea is to obtain an abstraction
   

fisequential diagnosis by abstraction

of the system to strike a balance between the two quantities to get an overall optimal cost 
below we discuss how the isolation and abstraction costs can be estimated 
we noted in our experiments when using the baseline approach that our heuristic can
isolate a single fault in the system with a cost that is on average comparable to the log 
of the number of measurement points in the system  which provided us with the basis for
computing the isolation cost  in the hierarchical approach  when a fault lies inside a cone
one can first estimate the isolation cost of diagnosing the cone  separately  and then add
it to the isolation cost of diagnosing the abstract system to get the average isolation cost
for all  single  faults that lie in that cone  for example  when no cones are considered the
cost of isolating a fault in the circuit in figure   is log              values of p   q  r and
v are already known   however  when cones are considered the cost of isolating a fault
that lies inside the cone a is the sum of the isolation cost of the abstract circuit and the
isolation cost of the subcircuit inside cone a  which is log        log           similarly  to
get an average isolation cost for all single faults in the system  when using the hierarchical
approach  one can add the isolation cost of diagnosing the abstract system and the average
of the isolation costs of diagnosing all the abstract components  where the isolation cost
for an abstract component which is not a cone is zero   note that the isolation cost of
diagnosing a cone can be computed by again taking the abstraction of the cone 
to estimate the abstraction cost of diagnosis under a given abstraction we first need
to estimate the overhead cost involved for each individual component in the system under
that abstraction  to estimate the overhead cost of a  possibly faulty  component one can
take the union of all the inputs and outputs of cones in which that component lies  and
the number of such measurement points  approximately  constitutes the required overhead
cost for that component  if a component does not lie in any cone then the overhead cost
for that component is zero  for example  when the circuit in figure   is diagnosed using
the hierarchical approach  to find the gate j as faulty one must first find the cone a to be
faulty and then the cone e to be faulty and then the gate j to be faulty  so the overhead
cost for the gate j in this case will be                i e   we have to measure wires a  b  e 
j  assuming that q is known   the abstraction cost of diagnosis under a given abstraction
of the system is then the average of the overhead costs of all the system components under
that abstraction 
we now give formal definitions related to the cost estimation function  let m pu  c 
be the set of those measurement points in the system c whose values are unknown  and
m pu  g  the set of those inputs and output of an abstract or concrete component g whose
values are unknown  let p be the number of abstract components in an abstraction ac of
system c  let gi  ac be an abstract component  either a concrete component or a cone
in the abstraction  a concrete component in the abstraction can be regarded as a trivial
cone containing only the component itself   let dgi be the subsystem dominated by gi
and agi be the abstraction of the subsystem 
the isolation cost ic c  ac   when an abstraction ac of the system c is considered for
diagnosis is the sum of log    m pu  ac     and the average of the isolation costs computed 
in a similar manner  for the subsystems contained in the abstract components in ac  
   

fisiddiqi   huang

 
pp
log    m pu  ac       p 
i   ic dgi   agi    if  m pu  ac       
ic c  ac       pp
otherwise
i   ic dgi   agi  
p

   

where ic dgi   agi   recursively computes the isolation cost of the subsystem contained in
the abstract component gi   using equation    by taking its abstraction agi   note that
when computing ic dgi   agi   we assume that the inputs and output of gi have already
been measured  thus m pu  dgi   excludes the inputs and output of cone gi   if gi is a
concrete
component then ic dgi   agi        if no cones are considered  ac   c  then
pp
ic d
gi   agi       and the isolation cost is simply equal to log    m pu  c    
i  
to compute the abstraction cost of diagnosing the system under a given abstraction we
first compute the overhead costs of diagnosing individual cones in the abstraction  then
we multiply the abstraction cost for a cone with the number of components contained in
that cone to get the total overhead cost for all the components in that cone  adding up
the overhead costs computed this way from all the cones in the abstraction and dividing
this number by the total number of concrete components in the whole system gives us the
average overhead cost per component  which we call the abstraction cost  formally  let
there be q cones in ac   then the abstraction cost ac c  ac   when the abstraction ac
of the system c is considered for diagnosis is given as 

ac c  ac    

q
  x
 dgi     m pu  gi     ac dgi   agi      gi  ac is a cone
n

   

i  

where  dgi   is the number of  concrete  components contained in the cone gi   and m pu  gi   
ac dgi   agi   recursively computes the abstraction cost of diagnosing the cone gi   using
equation    by taking its abstraction agi   when the abstraction cost of gi is multiplied by
 dgi   we effectively add the cost of measuring cone inputs and output in the overhead cost
of every component inside the cone  again note that when computing ac dgi   agi   we
assume that all the variables in m pu  gi   have already been measured  thus m pu  dgi  
excludes the inputs and output of cone gi  
finally the total expected cost edc c  ac   of diagnosing a system c when an abstraction ac of the system is considered for diagnosis is given as 
edc c  ac     ic c  ac     ac c  ac   

   

   experimental results
this section provides an empirical evaluation of our new diagnostic system  referred to as
sda  sequential diagnosis by abstraction   that implements the baseline  hierarchical  and
cloning based approaches described in sections   and    and the cost estimation function
described in section    all experiments were conducted on a cluster of    computers consisting of two types of  comparable  cpus  intel core duo     ghz and amd athlon   
x  dual core processor        both with   gb of ram running linux  a time limit of  
   

fisequential diagnosis by abstraction

hours and a memory limit of     gb were imposed on each test case  the d dnnf compilation was done using the publicly available d dnnf compiler c d  darwiche              
the cnf was simplified before compilation using the given observation  which allowed us
to compile more circuits  at the expense of requiring a fresh compilation per observation
 see algorithm    line    
we generated single  and multiple fault scenarios using iscas    benchmark circuits 
where in each scenario a set of gates is assumed to be faulty  for single fault cases of circuits
up to c     we simulated the equal prior probability of faults by generating n fault scenarios
for each circuit  where n equals the number of gates in the circuit  each scenario contains a
different faulty gate  we then randomly generated   test cases  abnormal observations  for
each of these n scenarios  doing the same for multiple fault scenarios would not be practical
due to the large number of combinations  so for each circuit up to c      respectively  larger
than c      we simply generated      respectively       random scenarios with the given
fault cardinality and a random test case for each scenario 
thus in each test case we have a faulty circuit where some gate or gates give incorrect
outputs  the inputs and outputs of the circuit are observed  the values of internal wires are
then computed by propagating the inputs in the normal circuit towards the outputs followed
by propagating the outputs of the assumed faulty gates one by one such that deeper faults
are propagated first  the obtained values of internal wires are then used to simulate the
results of taking measurements  we use p r okx            for all gates x of the circuit 
note that such cases  where all gates fail with equal probability  are conceivably harder to
solve as the diagnoses will tend to be less differentiable  then  for each gate  the two output
values are given equal probability when the gate is faulty  again  this will tend to make
the cases harder to solve due to the high degree of uncertainty  for each circuit and fault
cardinality  we report the cost  number of measurements taken  and time  including the
compilation time  in cpu seconds  to locate the faults  averaged over all test cases solved 
we present the experiments in four subsections demonstrating the effectiveness of the
four techniques proposed in this paper  namely the new heuristic  hierarchical sequential
diagnosis  component cloning  and the cost estimation function 
    effectiveness of heuristic
we start with a comparison of the baseline algorithm of sda with gde and show that sda
achieves similar diagnostic costs and scales to much larger circuits  hence illustrating the
effectiveness of our new heuristic  along with the new way to compute probabilities  
      comparison with gde
we could obtain only the tutorial version of gde  forbus   de kleer        for the comparison  downloadable from http   www qrg northwestern edu bps readme html  gde uses
atcon  a constraint language developed using the lisp programming language  to represent diagnostic problem cases  a detailed account of this language is given by forbus and
de kleer         further  it employs an interactive user interface that proposes measurement points with their respective costs and lets the user enter outcomes of measurements 
for the purpose of comparison we translated our problem descriptions to the language accepted by gde  and also modified gde to automatically read in the measurement outcomes
   

fisiddiqi   huang

size system
  
  
  
  
  

gde
sda
gde
sda
gde
sda
gde
sda
gde
sda

single fault
cost time
   
   
        
        
        
   
   
        
   
   
        
        
        

double fault
cost time
   
    
   
    
   
    
   
    
   
  
   
    
   
   
   
    
   
    
   
    

triple fault
cost time
   
   
        
   
  
        
   
   
        
   
   
        
        
        

table    comparison with gde 
from the input problem description  we also compiled the lisp code to machine dependent
binary code using the native c compiler to improve run time performance 
this version of gde  developed for tutorial purposes  computes the set of minimal diagnoses instead of probable diagnoses  this makes our comparison less informative  nevertheless  we are able to make a reasonable comparison in terms of diagnostic cost as the set
of minimal diagnoses can also serve as a large set of probable diagnoses when components
have equal prior probabilities  according to de kleer        availability of more diagnoses
aids in heuristic accuracy  whereas focusing on a smaller set of probable diagnoses can be
computationally more efficient but increase the average diagnostic cost 
this version of gde was in fact unable to solve any circuit in iscas     to enable
a useful comparison  we extracted a set of small subcircuits from the iscas    circuits 
   circuits of size            and     and    circuits of size     for each circuit we randomly generated   single fault    double fault  and   triple fault scenarios  and one test
case  input output vector  for each fault scenario  the comparison between gde and sda
 baseline  on these benchmarks given in table   shows that sda performs as well as gde in
terms of diagnostic cost 
      larger benchmarks
to evaluate the performance of sda on the larger iscas    circuits  we have again conducted three sets of experiments  this time involving single  double  and five faults  respectively  as the version of gde available to us is unable to handle these circuits  in order to
provide a systematic reference point for comparison we have implemented a random strategy where a random order of measurement points is generated for each circuit and used
for all the test cases  this strategy also uses the d dnnf to check whether the stopping
criteria have been met 
table   shows the comparison between the random strategy and sda using the baseline
approach with two different heuristics  one based on entropies of wires alone  ew  and the
other based also on failure probabilities  fp   for each of the three systems we ran the same
set of experiments with and without pruning the d dnnf  using the known fault cardinality
as described in section         indicated in the third column of the table  only the test
cases for the first four circuits could be solved  for other circuits the failure occurred during
the compilation phase  and hence affected both the random strategy and sda 
   

fisequential diagnosis by abstraction

circuit system pruning
c   

rand

     gates 

sda ew 
sda fp 

c   

rand

     gates 

sda ew 
sda fp 

c   

rand

     gates 

sda ew 
sda fp 

c    

rand

     gates 

sda ew 
sda fp 

no
yes
no
yes
no
yes
no
yes
no
yes
no
yes
no
yes
no
yes
no
yes
no
yes
no
yes
no
yes

single fault
cost time
         
        
         
        
        
        
         
   
   
        
   
   
   
   
   
   
         
   
   
        
   
   
        
   
   
         
   
   
        
   
   
        
   
   

double fault
cost time
         
         
         
   
    
   
    
   
    
         
    
   
    
   
   
   
   
   
   
   
         
    
   
    
   
   
   
   
   
   
   
         
    
   
    
   
   
   
    
   
   
   

five fault
cost time
          
         
         
         
        
        
         
         
        
        
       
       
         
         
        
        
        
        
         
         
         
        
        
        

table    effectiveness of heuristic 
it is clear that the diagnostic cost is significantly lower with both heuristics of sda than
with the random strategy whether or not pruning has been used  it is also interesting
to note that pruning significantly reduces the diagnostic cost for the random and sda ew
strategies  but has much less effect on sda fp except in a few cases  c     single fault  
moreover  sda fp generally dominates sda ew  both with and without pruning 
we may also observe that  i  on the five fault cases  sda fp without pruning results in
much lower diagnostic cost than sda ew with pruning   ii  on the double fault cases  the two
are largely comparable  and  iii  on the single faults cases  the comparison is reversed  this
indicates that as the fault cardinality rises  the combination of failure probabilities and wire
entropies appears to achieve an effect similar to that of pruning  that sda ew with pruning
performs better than sda fp without pruning on single fault cases can be attributed to the
fact that on these cases pruning is always exact and hence likely to result in maximum
benefit 
    effectiveness of abstraction
we now report  in table    the results of repeating the same experiments with sda fp using
the hierarchical approach 
most notably  the running time generally reduces for all cases and we are now able to
handle two more circuits  namely c     and c      solving     of     cases for c        
of single      of double   and    of five fault cases  and     of     cases for c          of
   

fisiddiqi   huang

circuit

pruning

c   

no
yes
no
yes
no
yes
no
yes
no
yes
no
yes

    cones 

c   
    cones 

c   
     cones 

c    
     cones 

c    
     cones 

c    
     cones 

single fault
cost time
    
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
    
   
   
   
    
   
   
   

double fault
cost
time
    
   
    
   
   
   
   
   
    
   
   
   
   
   
   
   
    
   
   
   
    
   
    
  

five fault
cost time
        
        
        
       
        
        
        
        
        
        
       
       

table    effectiveness of abstraction 

circuit
c   
c   
c   
c    
c    
c    
c    
c    
c    
c    

total
gates
   
   
   
  
   
    
    
    
    
    

abstraction
size
  
  
  
  
   
   
   
   
    
   

cloning
time
    
    
   
    
    
    
    
   
    
    

total
clones
  
 
  
 
   
   
   
   
 
   

abstraction size
after cloning
  
  
  
  
  
   
   
   
    
   

table    results of preprocessing step of cloning 

single      of double   and    of five fault cases   again all failures occurred during the
compilation phase  note that some observations do not cause sufficient simplification of
the theory for it to be successfully compiled even after abstraction  in terms of diagnostic
cost  in most cases the hierarchical approach is comparable to the baseline approach  on
c     the baseline approach consistently performs better than the hierarchical in each fault
cardinality  while the reverse is true on c      note also that pruning helps further reduce
the diagnostic cost to various degrees as with the baseline approach 
as discussed earlier  the results confirm that the main advantage of hierarchical approach
is that larger circuits can be solved  for circuits that can also be solved by the baseline
approach  hierarchical approach may help reduce the diagnostic cost by quickly finding
faulty portions of the circuit  represented by a set of faulty cones  and then directing the
measurements inside them  which can result in more useful measurements  e g  in the case
of c       on the other hand  it may suffer in cases where it has to needlessly go through
hierarchies to locate the actual faults  while the baseline version can find them more directly
and efficiently  e g  in the case of c      this is further discussed in section     
   

fisequential diagnosis by abstraction

circuit
c   
c   

single fault
cost
time
   
    
    
   

double fault
cost
time
   
   
   
   

five fault
cost time
   
   
    
   

table    effect of component cloning on diagnostic performance 
circuit
c   
c   
c    
c    
c    
c    
c    

single fault
cost
time
    
   
   
   
    
   
    
   
    
   
   
   
    
    

double fault
cost
time
    
   
   
   
    
   
    
   
    
    
    
   
    
     

five fault
cost
time
    
   
    
   
    
   
    
   
    
     
    
   
          

table    hierarchical sequential diagnosis with component cloning  c    and c     omitted as they are already easy to diagnose and cloning does not lead to reduced
abstraction  

    effectiveness of component cloning
in this subsection we discuss the experiments with component cloning  we show that cloning
does not significantly affect diagnostic cost and allows us to solve much larger circuits  in
particular  nearly all the circuits in the iscas    suite 
table   shows the result of the pre processing step of cloning on each circuit  the
columns give the name of the circuit  the total number of gates in that circuit  the size of
the abstraction of the circuit before cloning  the time spent on cloning  the total number of
clones created in the circuit  and the abstraction size of the circuit obtained after cloning 
on all circuits except c     c      and c      a significant reduction in the abstraction size
has been achieved  c     appears to be an extreme case with a very large abstraction that
lacks hierarchy  while gates in the abstractions of c    and c     are all roots of cones 
affording no opportunities for further reduction  note that these two circuits are already
very simple and easy to diagnose  
we start by investigating the effect of component cloning on diagnostic performance 
to isolate the effect of component cloning we use the baseline version of sda  i e   without
abstraction   and without pruning  table   summarizes the performance of baseline sda
with cloning on the circuits c    and c     comparing these results with the corresponding entries in table   shows that the overall diagnostic cost is only slightly affected by
cloning  we further observed that in a significant number of cases the proposed measurement sequence did not change after cloning  while in most of the other cases it changed
only insubstantially  moreover  in a number of cases  although a substantially different
sequence of measurements was proposed  the actual diagnostic cost did not change much 
finally  note that the diagnosis time in the case of c    has reduced after cloning  which
can be ascribed to the general reduction in the complexity of compilation due to a smaller
abstraction 
   

fisiddiqi   huang

circuit
c   

c   

c   

c    

c    

c    

total max  cone abstraction measurement
ac ic edc
cases inputs
size
points
  
  
  
               
   
  
  
  
              
  
  
  
              
 
  
  
              
 
   
  
             
 
   
   
             
 
  
  
             
    
 
  
  
             
 
   
   
             
 
   
   
            
  
  
  
              
    
  
  
  
              
  
   
  
              
 
   
   
              
 
   
   
            
 
  
  
             
    
 
  
  
             
 
   
  
             
 
   
   
             
 
   
   
             
 
   
   
            
  
  
  
               
   
  
  
  
               
  
  
  
               
  
  
  
               
  
   
   
              
  
   
   
              
  
  
  
               
   
  
  
  
               
  
   
  
               
  
   
   
               

cases
solved
   
   
   
   
   
   
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
   
   
   
   
   
   
   
   
   
   

single fault
cost time
         
        
        
        
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
        
        
         
         
        
        
        
        
        
        
        
         
         
        
        
        
         

table    effectiveness of diagnostic cost estimation 
our final set of experimental results with iscas    circuits  summarized in table   
illustrates the performance of hierarchical sequential diagnosis with component cloning
the most scalable version of sda  all the test cases for circuits c     and      were now
solved  and the largest circuits in the benchmark suite could now be handled  all the cases
for c          of the     cases for c         of single      of double   and    of five fault
cases   and     of the     cases for c         of single      of double   and    of fivefault cases  were solved  in terms of diagnostic cost cloning generally resulted in a slight
improvement  in terms of time the difference is insignificant for c    and c     and for the
larger circuits  c     and c      diagnosis with cloning was clearly more than an order of
magnitude faster 
    effectiveness of diagnostic cost estimation
finally  we demonstrate the effectiveness of our cost estimation function  we show that it
is often possible to destroy different cones to obtain different abstractions of a system that
   

fisequential diagnosis by abstraction

can all be successfully compiled  and then  using the cost estimation function  select an
abstraction to be used for diagnosis that is more likely to give optimal average cost  these
results also help explain why in some cases the hierarchical approach causes diagnostic cost
to increase compared with the baseline approach 
in these experiments  we use sda with cloning and include circuits up to c      considering only single fault test cases  we did not include the largest circuits in our analysis as
these circuits often could not be compiled after some cones in them were destroyed  therefore it was not possible to obtain an overall picture of the actual cost for these circuits  test
cases for circuits up to c     are the same as used before  whereas for circuits c     and
c      this time  we use a more complete set of cases as done for smaller circuits  specifically  we generate n fault scenarios for each circuit  where n equals the number of gates
in the circuit  each scenario contains a different faulty gate  we then randomly generate
  test case for each of these n scenarios  in some cases  we could not obtain a test case in
reasonable time and the corresponding scenarios were not used  
the results of experiments are summarized in table    for each circuit the first row
shows results when all cones have been considered and the subsequent rows show results
when all cones having more than a specified number of inputs  in column    have been
destroyed  when the value in column   is   we get the trivial abstraction  where all cones
have been destroyed  which is equivalent to using the baseline approach  the last two
columns show the  actual  average cost and time for diagnosing a circuit using the given
abstraction  the columns labeled with ac  ic  and edc show values obtained using the
equations       and    respectively  for a given abstraction 
the results show that we are often able to destroy several cones while still being able to
compile the circuit successfully  however  quite naturally  the compilation time increases as
more cones are destroyed such that at some point the circuits start to fail to compile  where
we stop destroying cones  the actual diagnostic cost on different circuits show different
trends each time some cones have been destroyed  for example  on c    it shows significant
improvement while the reverse is true for c      on remaining circuits the actual cost shows
somewhat mixed trends  however  the relative increase or decrease in the costs is generally
less significant 
comparison of the isolation and abstraction costs  i e   ic and ac  respectively  for
various abstractions confirms that each time some cones are destroyed the isolation cost
increases while the abstraction cost decreases  it is the potentially imbalanced change in
the two costs that determines whether the cost might go up or down after the cones are
destroyed  for example  in the case of c    the abstraction cost drops more rapidly than
the isolation cost increases when cones are destroyed  while in the case of c     the two
costs change almost at the same pace 
comparison of the predicted costs edc with the actual costs shows that for c    
c     c      and c     the predicted costs are often quite close to the actual costs  which
demonstrates the relative accuracy of our approach  as a result  for these circuits the
cost estimation function can accurately predict the abstraction that is more likely to give
optimal cost  for example  it correctly suggests that one should use the baseline approach
with c     for the other two circuits  c    and c      the predicted and actual costs are
significantly different  and the cost estimation function fails to give good predictions  c    
   

fisiddiqi   huang

seems to be a special case in which the actual diagnostic cost increases quite rapidly as
cones are destroyed  the reason for which will be an interesting topic for future work 

   related work
out et al         considered two kinds of hierarchical models and discussed automatic
methods for constructing their abstractions  in the first kind  components of the given
detailed model are aggregated into single components of the abstract model  such that every
diagnosis of the detailed model  refined from a diagnosis of the abstract model  is guaranteed
to be valid  thus there is no need to check the validity of detailed diagnoses afterwards 
in the second kind  the abstract model is constructed such that it is always possible to
determine a unique diagnosis at every level of the hierarchy with a reasonable cost  where the
measurements that are less costly to make appear in the most abstract model and the more
costly measurements appear in the most detailed model  more techniques for automatic
abstraction based on system observability were discussed by torta and torasso              
these papers provide alternative techniques to automatic abstraction  however  they do not
address sequential diagnosis 
the idea of testing the most likely failing component comes from heckerman et al         
where the testing of a component was considered a unit operation and components were
tested in decreasing order of their likelihood of failure  which was computed assuming a
single fault  this assumption could compromise the quality of the measurement sequence
in multiple fault cases as the authors pointed out   in our case  by contrast  the testing of
each variable of a component is a unit operation  calling for a more complex heuristic in
order to minimize the number of tests  also  we do not need to assume a single fault  our
work also goes further in scalability using several structure based techniques  compilation 
abstraction  and component cloning 
chittaro   ranon        considered the computation of diagnoses using a hierarchical
algorithm  their method takes a hierarchical decomposition of the system as input  where
sets of components are aggregated into units  and computes a set of diagnoses at the most
abstract level  which are then refined hierarchically to the most detailed level  feldman  
van gemund        developed a hierarchical diagnosis algorithm and tested it on reverse
engineered iscas    circuits  hansen  yalcin    hayes        that are available in highlevel form  the idea is to decompose the system into hierarchies in such a way as to minimize
the sharing of variables between them  this can be done for well engineered problems and
they have formed hierarchies by hand for iscas    circuits  the system is represented
by a hierarchical logical formula where each hierarchy is represented by a traditional cnf
formula  this representation can be translated to a fully hierarchical dnf  a fully flattened
dnf  or a partially flattened dnf dictated by a depth parameter  after which a hierarchical
search algorithm is employed to find the diagnoses  the hierarchical aspect of these two
approaches is similar to that of ours  however  they require a hierarchical decomposition of
the system to be either given as part of the input  or obtained by hand  while our approach
searches for hierarchies automatically  another major difference is that they consider only
the computation of diagnoses and do not address the problem of sequential diagnosis 
based on the gde framework  de kleer        studied the sensitivity of diagnostic
cost to what is called the  policy  which is the policy that quantifies how the posterior
   

fisequential diagnosis by abstraction

probabilities of diagnoses are to be estimated when gde computes its heuristic  in our
case  probabilities of diagnoses are not required at all  and the other probabilities that
are required can all be computed exactly by evaluating and differentiating the d dnnf 
nevertheless  our algorithm can be sensitive to the initial probabilistic model given and
sensitivity analysis in this regard may lead to interesting findings 
recently  flesch  lucas    van der weide        proposed a new framework to integrate
probabilistic reasoning into model based diagnosis  the framework is based upon the notion
of conflict measure  which originated as a tool for the detection of conflicts between an
observation and a given bayesian network  jensen         when a system is modeled as
a bayesian network for diagnostic reasoning  it is possible to use this conflict measure to
differentiate between diagnoses according to their degree of consistency with a given set of
observations  this work  however  does not address the problem of sequential diagnosis 
i e   locating actual faults by taking measurements 
most recently  feldman  provan  and van gemund        proposed a related method
for reducing diagnostic uncertainty  while our work attempts to identify the actual faults
with the fewest individual measurements  their heuristic was aimed at reducing the number
of diagnoses with the fewest test vectors 

   conclusion
we have presented a new system for sequential diagnosis  called sda  that employs four
new structure based techniques to scale diagnosis to larger systems  specifically  it uses
a heuristic for measurement selection that can be computed efficiently from the d dnnf
compilation of the system  to diagnose larger systems  it automatically computes a structural abstraction of the system and performs diagnosis in a hierarchical fashion  it then
employs a structure based technique for further reducing the abstraction size of the system 
which scales the diagnosis to the largest benchmark systems  finally  it can automatically
select an abstraction of the system that is more likely to give optimal average cost 

acknowledgments
we thank the anonymous reviewers for their comments  nicta is funded by the australian
government as represented by the department of broadband  communications and the
digital economy and the australian research council through the ict centre of excellence
program  part of this work has appeared in kr       siddiqi   huang         another
part of this work was carried out during julyseptember      while the first author was
visiting nicta 

appendix a  computing probabilities on d dnnf
here we briefly describe the computation of probabilities based on d dnnf compilations of
bayesian networks  d dnnf is a graph representation of a nested and or expression where
negation only appears next to variables  children of every and node have disjoint sets of
variables  decomposability   and children of every or node are pairwise logically inconsistent
   

fisiddiqi   huang

and

      

      

or

and
 

and

and

      

    

oka
   

or

 

   

and

 

d
 

a
 

or

    

and j and

and

 

    

    

oka

p

 

a okj

   

   

    

j j

   

 

j
   

okj
   

figure    d dnnf compilation of subcircuit  dotted  in figure   given the observation
a  p  d and computation of the posterior probability of j     

 determinism   for example  figure   shows a d dnnf compilation of the subcircuit in
the dotted box of figure   under the observation a  p  d 
given a d dnnf compilation  the probability p r e   e  for an instantiation e of any set
of variables e can be obtained by the following linear time procedure   i  set all variables e
to boolean constants according to the instantiation e   ii  set all other literals  not in e  to
true except those that have numbers associated with them  negative literals are associated
with   minus the corresponding numbers for the positive literals   and  iii  evaluate the ddnnf bottom up by treating true as    false as    the remaining leaves as their associated
numbers  or nodes as additions  and and nodes as multiplications  the number at the root
will be p r e   e   for example  figure   shows the computation of the probability of j    
given the observation a  p  d  thus e    a      p      d      j       in the d dnnf 
we set a      p      d      j      j      the rest of the literals are given values that
are associated with them  discussed in section      
furthermore  a second traversal of the d dnnf  from the top down  can effectively
differentiate the d dnnf so that updated probabilities are computed at once for every
possible change in the value of a variable  e g   from unknown to known   darwiche        
this is useful for our measurement point selection where we need to update the entropies
for all candidate measurement points 

appendix b  cardinality based model pruning
here we present the technique referred to in section   that can be used to remove a significantly large number  if not all  of diagnoses of cardinality   k from the d dnnf 
the value of k must be greater or equal to the minimum cardinality of the d dnnf
for pruning to occur  if k is equal to the minimum cardinality of the d dnnf then all
diagnoses with cardinality   k can be removed using the minimization procedure described
   

fisequential diagnosis by abstraction

figure    pruning d dnnf to improve heuristic accuracy 
by darwiche         if  however  k is greater than the minimum cardinality of the d dnnf
then we need a similar but modified minimization algorithm to make sure we do not remove
diagnoses of cardinality  k 
while a complete pruning is difficult to achieve in general  an approximation is possible 
in a naive approach  one may remove every child l of every or node n for which minimumcardinality  mc  of l is greater than k  which will be sound in that it will never remove
diagnoses of cardinality  k but may result in too little pruning in many cases  we can
increase the amount of pruning performed by computing local value k n  for every node n
given the global k for the whole d dnnf using a top down traversal through the d dnnf 
every node n suggests a value k l  for its child l and the largest of these values is accepted to
be the final value of k l   this is essential to avoid possibly removing diagnoses of cardinality
 k   more pruning can occur in this way because k n  can often be less than the global
k  once k n  has been computed for every node  every child l of every or node n for which
mc l    k l  can then be pruned 
we now give the pruning algorithm which performs a two pass traversal through the
d dnnf  the mc n  is updated during upward traversal and represents the minimumcardinality of diagnoses under a node n  whereas the k n  is updated during downward
traversal and represents the upper bound on the fault cardinality for a node which is used
to prune branches emanating from the node whose mc n  exceeds the k n  
the two passes of the procedure are as follows  initialize mc n  to   and k n  to  
 least possible value  for all n  traverse the d dnnf so that children are visited before
parents and for every leaf node  set mc n  to   if n is a negated health variable and  
otherwise  for every or node  set mc n  to the minimum of the values of mc of its children 
for every and node set mc n  to the sum of the values of mc of its children  now traverse
the d dnnf so that parents are visited before children and set k n  for the root node to
the value k  for every or node  remove every child p of n for which mc p    k n  and for
every remaining child v set k v  to k n  if k n    k v   for every child p of every and node 
let tp be the sum of the values of mc of all the other children and set k p  to the value tp if
tp   k p  
in the above procedure the conditions k n    k v  and tp   k p  while updating k for
a node ensure that only a safe value for k is set  an example is shown in figure    the
mc  left  and k  right  values are shown for each node  the branches labeled       and
   

fisiddiqi   huang

i 

g 

i 
g 

c 

g 

i 
g 
g 
g 
c 

figure    a combinational circuit generated randomly from a set of components consisting
of gates g    g            g  and cones c    c    when they are processed in the order 
g    c    g    g    g    c    g    g   

n
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   

total
gates
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

average
depth
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

approx 
treewidth
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

abstraction
size
  
  
  
  
  
  
  
  
  
  
  
  
   
   
   
   

total
clones
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   

abstraction size
after cloning
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

table    randomly generated combinational circuits  n         

 are subgraphs associated with hypothetical values for mc  the figure shows that the
minimum cardinality for every node  mc  is less than or equal to the bound  k  except for
the branch labeled   which gets pruned accordingly 

appendix c  randomly generated combinational circuits
in this section we use a novel method to systematically generate series of combinational
circuits such that their structure and size can be controlled  this enables the evaluation of
our techniques on circuits other than iscas    benchmarks  which has helped us identify
factors that affect the diagnostic cost  leading us to the cost estimation function given in
section    specifically  we observe that for circuits of a similar structure  diagnostic cost
generally increases with circuit size  which helped us devise the notion of isolation cost  and
   

fisequential diagnosis by abstraction

that when circuit size is held constant  diagnostic cost generally increases with the number
of cones in the circuit  which helped us devise the notion of abstraction cost 
the circuits are generated by composing a set of pre formed building blocks  the latter
consist of both gates and cones  the gates are taken from a pool of six gates of types or 
nor  and  nand  not  and buffer  and the cones from a pool of eight cones  each
of which has    gates and is extracted from iscas    benchmark circuits 
our composition method is inspired from the method of generating random bayesian
networks described by marinescu  kask  and dechter         the circuits are generated
according to a formula  n  p  i   where n is the number of components  building blocks 
to use  p the percentage of cones in the components  and i the maximum number of inputs
a gate can have  to generate the n components we randomly pick  p       n cones  with
repetition  from the pool of cones and n   p       n gates  with repetition  from the
pool of gates and place them in a random order  the number of inputs of each gate is set
randomly between   and i  except for a not or buffer gate which can have only one
input 
we then process each component as follows  suppose that the components are placed
in the order c    c            cn   let pi be the set of components that precede ci in the
order  when we process a component ci we connect every input of ci to the output of a
randomly chosen component from pi such that no two inputs of ci are connected to the
same component  if an input of ci cannot be connected  either because pi is empty or all
the components in pi have been used  then it is treated as a primary input of the circuit 
for example  the circuit in figure   has been randomly generated according to the formula
            where the components shown in the boxes represent cones 
by varying the parameters  n  p  i  we can obtain circuits of varying size and structure 
first we fix p       i     and vary n to generate a range of circuits of increasing size  for
each n we generate    circuits  these circuits are summarized in table    the numbers in
the columns are averaged over all circuits of a given size  and rounded off  generally  when
n is increased we see an increase in the abstraction size as well as the estimated treewidth 
corresponding to an increase in the perceived difficulty of the circuit  e g   note that the
largest circuit in this set is smaller than c      but the estimated treewidth of c     is much
lower  at     the actual compilation was indeed harder for the former circuit   for each
circuit we randomly generate    single fault     double fault  and    five fault scenarios and
a single test case for each scenario 
the results of experiments with these circuits are given in tables        and     using
the baseline  hierarchical  and cloning techniques  respectively  these results are generally
consistent with those obtained using the iscas    circuits  the baseline sda could not
solve any circuit beyond              the hierarchical sda solved more circuits but could
not solve any circuit beyond              the most scalable version of sda  with component
cloning  solved much larger circuits  up to              
note that there is a general trend of increase in diagnostic cost with increase in n   this
is consistent with ones intuitive expectation that diagnostic uncertainty would increase with
system size  also note that diagnostic cost is often significantly higher for the hierarchical
approach than the baseline approach  as discussed earlier  this can be attributed to the
fact that the hierarchical approach often has to go through hierarchies of cones to reach a
faulty gate  which the baseline approach may be able to reach more directly 
   

fisiddiqi   huang

total
single fault
double fault
five fault
pruning
gates
solved cost time solved cost time solved cost
time
      
no
             
             
   
    
    
yes
             
             
   
    
    
      
no
             
             
              
yes
   
   
    
             
              
      
no
              
              
               
yes
              
   
         
   
          
      
no
  
           
  
          
  
           
yes
  
           
  
           
  
            
      
no
  
           
  
          
  
            
yes
  
           
  
           
  
           
      
no
  
          
  
          
  
           
yes
  
          
  
          
  
           
n

table    baseline heuristic on randomly generated circuits  n         
total
single fault
double fault
five fault
pruning
gates
solved cost time solved cost time solved cost
time
      
no
             
             
              
yes
             
             
              
      
no
   
   
    
             
              
yes
             
             
              
      
no
             
             
              
yes
             
             
              
      
no
              
   
         
               
yes
              
              
   
          
      
no
  
           
  
           
  
            
yes
  
           
  
           
  
            
      
no
  
           
  
           
  
            
yes
  
          
  
           
  
           
      
no
  
          
  
          
  
           
yes
  
          
  
          
  
           
n

table     hierarchical heuristic on randomly generated circuits  n         
we also observe that  again  pruning leads to a general improvement in diagnostic cost 
the improvement is more significant for the hierarchical approach  which can be explained
by the fact that the effect of pruning is much greater on the abstract model  as each branch
pruned can correspond to a large part of the original system 
we now perform another set of experiments to study the impact of hierarchy in a
controlled manner  this time we hold the size of the circuits more or less constant and
vary the percentage of cones in them  specifically  we generate a large number of random
circuits with p ranging from   to     such that for each value of p the generated circuits
contain     gates on average 
the experiments on these circuits are summarized in table     note that as p increases
the estimated treewidth of the circuits decreases  as would be expected  and the actual
compilation time indeed also decreases  the diagnostic cost  on the other hand  increases
steadily up to p      and remains more or less flat afterwards  this confirms the potential
   

fisequential diagnosis by abstraction

n
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   

total
single fault
double fault
five fault
gates solved cost
time solved cost
time solved cost
time
   
   
    
    
   
    
    
              
   
   
    
    
   
   
    
              
   
   
    
    
   
    
    
   
    
    
   
   
    
    
   
    
    
              
   
              
              
              
   
   
    
    
              
              
   
   
    
    
              
   
    
    
   
   
    
    
              
   
    
    
   
   
    
    
              
              
   
              
              
              
   
               
               
               
   
               
   
          
               
   
  
           
  
           
  
            
   
  
            
  
            
  
            
   
  
            
  
            
  
            
   
  
           
  
           
  
            
   
  
           
  
            
  
           
   
  
   
     
  
          
  
          

table     component cloning on randomly generated circuits  n         
p
 
 
  
  
  
  
  

total
single fault
treewidth
circuits
cost time
    
  
   
   
   
  
   
   
   
  
   
   
    
  
   
   
    
  
   
   
    
  
   
   
   
  
   
    

double fault
cost
time
   
   
   
   
   
   
   
   
   
   
    
   
    
    

five fault
cost time
        
        
        
        
        
        
        

table     component cloning on randomly generated circuits  n  p     
negative impact of hierarchy on the diagnostic cost we hypothesized  as p increases the
likelihood of a fault occurring inside a cone also increases and thus on average one has to
take more measurements  many on inputs to cones  to locate a fault  that diagnostic cost
does not further increase after p      is consistent with the observation that since the
circuit size is fixed at roughly     and each cone contributes    gates to the circuit  when
p increases to some point  there will be very few gates lying outside cones and hence the
likelihood of a fault occurring in a cone will have more or less plateaued 

references
brglez  f     fujiwara  h          a neutral netlist of    combinational benchmark circuits and a target translator in fortran  in proceedings of the ieee international
symposium on circuits and systems  iscas   pp         
chittaro  l     ranon  r          hierarchical model based diagnosis based on structural
abstraction  artificial intelligence                    
   

fisiddiqi   huang

choi  a   chavira  m     darwiche  a          node splitting  a scheme for generating upper bounds in bayesian networks  in proceedings of the   rd conference on
uncertainty in artificial intelligence  uai   pp       
darwiche  a     marquis  p          a knowledge compilation map  journal of artificial
intelligence research             
darwiche  a          decomposable negation normal form  journal of the acm         
       
darwiche  a          a differential approach to inference in bayesian networks  journal of
the acm                 
darwiche  a          new advances in compiling cnf into decomposable negation normal form  in proceedings of the   th european conference on artificial intelligence
 ecai   pp         
darwiche  a          the c d compiler user manual  tech  rep  d      computer science
department  ucla  http   reasoning cs ucla edu c d  
de kleer  j     williams  b  c          diagnosing multiple faults  artificial intelligence 
              
de kleer  j          focusing on probable diagnosis  in readings in model based diagnosis 
pp          morgan kaufmann publishers inc   san francisco  ca  usa 
de kleer  j          improving probability estimates to lower diagnostic costs  in   th
international workshop on principles of diagnosis  dx  
de kleer  j   raiman  o     shirley  m          one step lookahead is pretty good  in
readings in model based diagnosis  pp          morgan kaufmann publishers inc  
san francisco  ca  usa 
feldman  a     van gemund  a          a two step hierarchical algorithm for modelbased diagnosis  in proceedings of the   st aaai conference on artificial intelligence
 aaai   pp         
feldman  a   provan  g  m     van gemund  a  j  c          fractal  efficient fault
isolation using active testing  in proceedings of the   st international joint conference
on artificial intelligence  ijcai   pp         
flesch  i   lucas  p     van der weide  t          conflict based diagnosis  adding uncertainty to model based diagnosis  in proceedings of the   th international joint
conference on artificial intelligence  ijcai   pp         
forbus  k  d     de kleer  j          building problem solvers  mit press  cambridge 
ma  usa 
hansen  m  c   yalcin  h     hayes  j  p          unveiling the iscas    benchmarks  a
case study in reverse engineering  ieee design and test of computers               
   

fisequential diagnosis by abstraction

heckerman  d   breese  j  s     rommelse  k          decision theoretic troubleshooting 
communications of the acm               
jensen  f  v          bayesian networks and decision graphs  springer verlag new york 
inc   secaucus  nj  usa 
kirkland  t     mercer  m  r          a topological search algorithm for atpg  in
proceedings of the   th conference on design automation  dac   pp         
marinescu  r   kask  k     dechter  r          systematic vs  non systematic algorithms
for solving the mpe task  in proceedings of the   th conference on uncertainty in
artificial intelligence  uai   pp         
out  d  j   van rikxoort  r     bakker  r          on the construction of hierarchic models 
annals of mathematics and artificial intelligence                   
pearl  j          probabilistic reasoning in intelligent systems  networks of plausible inference  morgan kaufmann publishers inc   san francisco  ca  usa 
pipatsrisawat  k     darwiche  a          clone  solving weighted max sat in a reduced
search space  in proceedings of the   th australian joint conference on artificial
intelligence  ai   pp         
siddiqi  s     huang  j          hierarchical diagnosis of multiple faults  in proceedings of
the   th international joint conference on artificial intelligence  ijcai   pp     
    
siddiqi  s     huang  j          new advances in sequential diagnosis  in proceedings of
the twelfth international conference on principles of knowledge representation and
reasoning  kr   pp       
torta  g     torasso  p          automatic abstraction in component based diagnosis driven
by system observability  in proceedings of the   th international joint conference on
artificial intelligence  ijcai   pp         
torta  g     torasso  p          a symbolic approach for component abstraction in modelbased diagnosis  in   th international workshop on principles of diagnosis  dx  

   

fi