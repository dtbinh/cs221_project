journal of artificial intelligence research                  

submitted        published      

efficient multi start strategies for local search algorithms
andras gyorgy

gya szit bme hu

machine learning research group
computer and automation research institute
of the hungarian academy of sciences
     budapest  hungary

levente kocsis

kocsis sztaki hu

data mining and web search research group  informatics laboratory
computer and automation research institute
of the hungarian academy of sciences
     budapest  hungary

abstract
local search algorithms applied to optimization problems often suffer from getting
trapped in a local optimum  the common solution for this deficiency is to restart the
algorithm when no progress is observed  alternatively  one can start multiple instances of
a local search algorithm  and allocate computational resources  in particular  processing
time  to the instances depending on their behavior  hence  a multi start strategy has to
decide  dynamically  when to allocate additional resources to a particular instance and
when to start new instances  in this paper we propose multi start strategies motivated
by works on multi armed bandit problems and lipschitz optimization with an unknown
constant  the strategies continuously estimate the potential performance of each algorithm
instance by supposing a convergence rate of the local search algorithm up to an unknown
constant  and in every phase allocate resources to those instances that could converge to
the optimum for a particular range of the constant  asymptotic bounds are given on the
performance of the strategies  in particular  we prove that at most a quadratic increase in
the number of times the target function is evaluated is needed to achieve the performance
of a local search algorithm started from the attraction region of the optimum  experiments
are provided using spsa  simultaneous perturbation stochastic approximation  and kmeans as local search algorithms  and the results indicate that the proposed strategies work
well in practice  and  in all cases studied  need only logarithmically more evaluations of the
target function as opposed to the theoretically suggested quadratic increase 

   introduction
local search algorithms applied to optimization problems often suffer from getting trapped
in a local optimum  moreover  local search algorithms that are guaranteed to converge
to a global optimum under some conditions  such as simulated annealing or simultaneous
perturbation stochastic approximation  spsa  see  e g   spall  hill    stark         usually
converge at a very slow pace when the conditions are satisfied  on the other hand  if the
algorithms are employed with more aggressive settings  much faster convergence to local
optima is achievable  but with no guarantee to find the global optimum  the common soluc
    
ai access foundation  all rights reserved 

figyorgy   kocsis

tion to escape from a local optimum is to restart the algorithm when no progress is observed
 see e g   mart  moreno vega    duarte        zabinsky  bulger    khompatraporn       
and the references therein  
alternatively  one can start multiple instances of the local search algorithm  and allocate
computational resources  in particular  processing time  to the instances depending on their
behavior  instances can be started at any time  and so the number of instances may grow
over time depending on the allocation strategy   see  e g   chapter    of battiti  brunato   
mascia       and the references therein   in this type of problems the computational cost
is usually measured as the total number of steps made by all search algorithm instances 
this often reflects the situation that the evaluation of the target function to be optimized
is expensive  and the costs related to determine which algorithms to use next are negligible
compared to the former  e g   this is clearly the case if the task is to tune the parameters of
a system whose performance can only be tested via lengthy experiments  see  e g   bartzbeielstein        hutter  hoos  leyton brown    stutzle         in this paper we address
the above problem of dynamically starting several instances of local search algorithms and
allocating resources to the instances based on their  potential  performance 
to our knowledge  solutions to the above problem have either been based on heuristics
or on the assumption that the local optima the search algorithms converge to have an
extreme value distribution  see section   below   in this paper  we propose new multi start
strategies under very mild conditions on the target function  with attractive theoretical
and practical properties  supposing a convergence rate of the local search algorithms up
to an unknown constant  our strategies continuously estimate the potential performance of
each algorithm instance and in every phase allocate resources to those instances that could
converge to the optimum for a particular range of the constant  the selection mechanism
is analogous to the direct algorithm  jones  perttunen    stuckman        finkel  
kelley        horn        for optimizing lipschitz functions with an unknown constant 
where preference is given to rectangles that may contain the global optimum  the optimum
within each rectangle is estimated in an optimistic way  and the estimate depends on the
size of the rectangle  in our strategies we use the function describing the convergence rate
of the local search algorithms in a similar way as the size of the rectangles are used in the
direct algorithm 
since in the proposed multi start strategies the potential performance of each local search
algorithm is continuously estimated from the currently best value of the target function
returned by that algorithm  our method is restricted to work with local search algorithms
that return the best known value of the target function after each step  this is the case 
for example  in certain meta learning problems  where the goal is to find a good parameter
setting of a learning algorithm  here the search space is the parameter space of the learning
algorithm  and one step of the local search methods means running the learning algorithm
completely on a possibly very large data set  on the other hand  if the local search algorithm
is some sort of a gradient search optimizing an error function over some training data  then
the value of the target function is usually available only in the case of batch learning
 potentially after some very cheap computations   but not when the gradient is estimated
only from a few samples 
the rest of the paper is organized as follows  section   summarizes related research 
the problem is defined formally in section    the new multi start local search strategies of
   

fiefficient multi start strategies for local search algorithms

this paper are described and analyzed in section    in section     we deal with a selection
mechanism among a fixed number of instances of the local search algorithm  while  in
addition  simple schedules for starting new instances are also considered in section     
which are natural extensions of the case of finitely many local search algorithm instances 
this section concludes with a discussion of the results in section      simulation results
on real and synthetic data are provided in section    conclusions and future work are
described in section   

   related work
the problem of allocating resources among several instances of search algorithms can be
comfortably handled in a generalized version of the maximum k armed bandit problem 
the original version of this problem consists of several rounds  where in each round one
chooses one of k arms  receives some reward depending on the choice  with the goal of
maximizing the highest reward received over several rounds  this model can easily be used
for our problem by considering each local search algorithm instance as an arm  pulling an
arm means taking one additional step of the corresponding algorithm  that is  evaluating
the target function at a point suggested by that algorithm  and the reward received is the
value of the target function at the sampled point  a generic algorithm for the standard
maximum k armed bandit problem  where each reward is assumed to have independent and
identical distribution  is provided by adam         where the so called reservation price of
an instance is introduced  which gives the maximum amount of resources worth to spend
on an instance  if an instance achieves its reservation price  it is useless to select it again 
the computation of the reservation price depends on a model of the algorithm that can be
learnt under some specific constraints 
now consider a scenario where several instances of some  possibly randomized local
search algorithms are run after each other with the goal of maximizing the expected performance  each instance is run until it terminates  in this scenario it is natural to assume
that the values returned by the instances  usually some local optima of the target function  are independent  furthermore  since good search algorithms follow  usually heuristic 
procedures that yield substantially better results than pure random guessing  cicirello and
smith              suggested that the rewards  evaluated target function values  of the
search instances may be viewed as the maximum of many random variables  if the instances are run for sufficiently long time   and hence may be modeled by extreme value
distributions  several algorithms are based on this assumption  and are hence developed
for the maximum k armed bandit problem with returns following generalized extreme value
distributions  cicirello and smith apply  somewhat heuristic  methods that use the above
extreme value distribution assumption at each decision point of a meta learning algorithm 
while streeter and smith      a  use this model to obtain upper confidence bounds on the
performance estimate of each type of algorithms used and then try only the algorithms
with the best expected result  the latter is a theoretically justified example of the natural
strategy to probe the algorithm instances for a while  estimate their future performance
based on the results of this trial phase  and then use the most promising algorithm for the
time remaining  streeter and smith      b  proposed a distribution free approach that
   

figyorgy   kocsis

combines a multi armed bandit exploration strategy with a heuristic selection among the
available arms 
while in the standard maximum k armed bandit problem the rewards in each round
are assumed to be independent  this is clearly not the case in our situation where the
algorithm instances are run parallel and the reward for evaluating the target function at a
point is the improvement upon the current maximum  since the samples chosen by a local
search algorithm usually depend on previous samples  nevertheless  the ideas and lessons
learnt from the maximum k armed bandit problems can be used in our case  as well  for
example  the algorithm threshold ascent of streeter and smith      b  gives reasonably
good solutions in our case  or the principle of probing instances for a while and then using
the most promising in the time remaining also carries over to this situation easily  such
algorithms  having first an exploration then an exploitation phase  will be referred to in
the sequel as explore and exploit algorithms  in this class of algorithms  simple rules were
suggested by beck and freuder        to predict the future performance of each algorithm 
while carchrae and beck        employ bayesian prediction 
another related problem is to find fast algorithms among several ones that solve the
same problem  more precisely  several algorithm instances are available that all produce
the correct answer to a certain question if run for a sufficiently long time  the time needed
for an algorithm instance to find the answer is assumed to be a random quantity with
independent and identical distributions for all the instances  and the goal is to combine the
given algorithms to minimize the expected running time until the answer is found  when the
distribution of the running time is known  an optimal non adaptive time allocation strategy 
is to perform a sequence of runs with a certain cut off time that depends on the distribution
 luby  sinclair    zuckerman         if the distribution is unknown  a particular running
time sequence can be chosen that results in an expected total running time that is only a
logarithmic factor larger than the optimum achievable if the distribution is known  we note
that this strategy is among the few that provide a schedule that increases the number of
algorithm instances  the above set up can be specialized to our problem  the goal is to find
an  optimal approximation of the optimum and the running time is the number of steps
needed by the given search algorithm to achieve such an approximation  note that in this
case the running time of any algorithm instance providing an  suboptimal solution has to
be defined to be infinity  but the results of luby et al  remain valid if an  optimal solution
can be found with positive probability  for the same problem  kautz  horvitz  ruan 
gomes  and selman        proposed an allocation strategy based on updating dynamically
the belief over the run time distribution  concerning the latter  hoos and stutzle       
found empirically that run time distributions are approximately exponential in certain  nphard  problems  while ribeiro  rosseti  and vallejos        dealt with the comparison of
different run time distributions 
finally  when a set of time allocation strategies are available and the optimization problem is to be solved several times  one can use the standard multi armed bandit framework
as done by gagliolo and schmidhuber                    
running several instances of an algorithm or several algorithms in parallel and selecting
among the algorithms have been intensively studied  for example  in the area of meta   in a non adaptive time allocation strategy the running time of an algorithm instance is fixed in advance 
that is  the measured performance of the algorithm instances has no effect on the schedule 

   

fiefficient multi start strategies for local search algorithms

learning  vilalta   drissi        or automatic algorithm configuration  hutter et al         
the underlying problem is very similar in both cases  automatic algorithm configuration
usually refers to tuning search algorithms  while meta learning is used for a subset of these
problems  tuning machine learning algorithms  the latter often allows more specific use of
the data   the main problem here is to allocate time slices to particular algorithms with the
aim of maximizing the best result returned  this allocation may depend on the intermediate
performance of the algorithms  most of the automatic algorithm configuration and metalearning systems use various heuristics to explore the space of algorithms and parameters
 see  e g   hutter et al         
finally  it is important to note that  although multi start local search strategies solve
global optimization problems  we concentrate on maximizing the performance given the
underlying family of local optimization methods  since the choice of the latter has a major
effect on the achievable performance  we do not compare our results to the vast literature
on global optimization 

   preliminaries
assume we wish to maximize a real valued function f on the d dimensional unit hypercube
      d   that is  the goal is to find a maximizer x        d such that f  x     f  where
f    max f  x 
x     d

denotes the maximum of f in       d   for simplicity  we assume that f is continuous on
      d    the continuity of f implies the existence of x   and  in particular  that f is bounded 
therefore  without loss of generality  we assume that f is non negative 
if the form of f is not known explicitly  search algorithms usually evaluate f at several
locations and return an estimate of x and f  based on these observations  there is an
obvious trade off between the number of samples used  i e   the number of points where
the target function f is evaluated  and the quality of the estimate  and the performance of
any search strategy may be measured by the accuracy it achieves in estimating f  under a
constraint on the number of samples used 
given a local search algorithm a  a general strategy for finding a good approximation
of the optimum x is to run several instances of a initialized at different starting points
and approximate f  with the maximum f value observed  we concentrate on local search
algorithms a defined formally by a sequence of possibly randomized sampling functions
sn         dn        d   n                a evaluates f at locations x    x          where xi    
si  x            xi   for i     and the starting point x    s  is chosen uniformly at random from
      d   after n observations a returns the estimate of x and the maximum f    respectively 
by
bn   argmax f  xk  
bn   
x
and
f  x
 kn 

where ties in the argmax function may be broken arbitrarily  that is  if more samples xk
bn can be chosen to be any of them  to avoid ambiguity and
achieve the maximum  x
   the results can easily be extended to  arbitrary valued  bounded piecewise continuous functions with
finitely many continuous components 

   

figyorgy   kocsis

simplify notation  here and in the following  unless stated explicitly otherwise  we adopt the
convention to use argmax to denote the maximizing sample with the smallest index  but
the results remain valid under any other choice to break ties 
for simplicity  we consider only starting a single local search algorithm a at different
random points  although the results of this work can be extended to allow varying the
parameters of a  including the situation of running different local search algorithms  where
a parameter would choose the actually employed search algorithm   as well as to allow
dependence among the initializations of a  that is  the starting point and parameters of
a local search instance may depend on information previously obtained about the target
function  
it is clear that if the starting points are sampled uniformly from       d and each algorithm
bn   converges
is evaluated at its starting point then this strategy is consistent  that is  f  x
to the maximum of f with probability   as the number of instances tends to infinity  in the
worst case we perform a random search that is known to converge to the maximum almost
surely   on the other hand  if algorithm a has some favorable properties then it is possible
to design multi start strategies that still keep the random search based consistency  but
provide much faster convergence to the optimum in terms of the number of evaluations of
f 
bn   is bounded and non decreasing  it converges  no matter what
since the sequence f  x
random effects occur during the search   the next lemma  proved in appendix a  shows
that  with high probability  the convergence cannot be arbitrarily slow 
bn     f    if p  e      
lemma   for any f        d   let e denote the event limn f  x
bn    f
then  for any          there is an event e  e with    p  e      such that f  x
uniformly almost everywhere on e   in other words  there exists a non negative  nonincreasing function g  n  with limn g  n      such that


fi
bt     f       
b t    f  x
bn    g  n  for all nfi lim f  x
p lim f  x
   
t

t

in certain cases  g  n    o en    as shown by nesterov        for  gradient based 
optimization for convex functions  by gerencser and vago        for noise free spsa for
convex functions  or by kieffer        for k means clustering  or lloyds algorithm  in one
dimension for log concave densities  while these results pertain to the simple situation
where there is only one local optimum which is the global one  many of these results can
be extended to more general situations  and we observed exponential rate of convergence in
our own experiments with functions with many local maxima 
the convergence property of local search algorithms guaranteed by lemma   will be
exploited in the next section to derive efficient multi start search strategies 

   multi start search strategies
standard multi start search strategies run an instance of a until it seems to converge to
a location where there is no hope to beat the currently best approximation of f    an
   in practice we can usually assume that local search algorithms converge to local optima  and so f may
be assumed to be a local optimum 

   

fiefficient multi start strategies for local search algorithms

alternative way of using multiple instances of local search algorithms is to run all algorithms
in parallel  and in each round decide which algorithms can take an extra step  this approach
may be based on estimating the potential performance of a local search algorithm a based
on lemma    note that if g were known  an obvious way would be to run each instance
until their possible performances become separated with high probability in the sense that
the margin between the performance of the actually best and the second best algorithm
is so large that the actually best algorithm is guaranteed to be the best  in the long run 
with high probability  then we could just pick the best instance and run it until the given
computational budget is exhausted  this would be a simple adaptation of the explore andexploit idea of choosing the best algorithm based on a trial phase as in beck   freuder 
      carchrae   beck        
in practice  however  g is usually not known  but for certain problem classes and local
search algorithms it may be known to belong to some function class  for example  g may
be known up to a  multiplicative  constant factor  here  for example  the constant may
depend on certain characteristics of f   such as its maximum local steepness   even in the
latter case  the best instance still cannot be selected with high probability no matter how
large the margin is  as g may be arbitrarily large   however  using ideas from the general
methodology for lipschitz optimization with an unknown constant  jones et al         
we can get around this problem and estimate  in a certain optimistic way  the potential
performance of each algorithm instance  and in each round we can step the most promising
ones 
the main idea of the resulting strategy can be summarized as follows  assume we have
k instances of an algorithm a  denoted by a            ak   let xi n   i              k denote the
location at which f is evaluated by ai at the nth time it can take a step  where xi   is the
starting point of ai   the estimate of the location of the maximum by algorithm ai after n
samples  steps  is
bi n   argmax f  xi t  
x
 tn

bi n   
and the maximum value of the function is estimated by fi n   f  x
for any i  let fi   limn fi n denote the limiting estimate of the maximum of f
provided by ai   let g be defined as in lemma   for the largest of these values 
f   max fi  
i       k

since f is the best achievable estimate of the maximum of f given the actual algorithms
a            ak   g gives a high probability convergence rate for those algorithms that provide
the best estimate of the maximum in the long run  note that the assumption deals with
each limiting estimate  usually a local maximum  separately  that is  here no assumption
is made on algorithms whose limiting estimates are less than f    then  if ai evaluates f
at ni r points by the end of the rth round and ai converges to the best achievable estimate
f   by lemma   we have  with probability at least     
fi  fi ni r  g  ni r   
and so

fi ni r   g  ni r  
   

   

figyorgy   kocsis

is an optimistic estimate of f   if ai is suboptimal in the sense that limn fi n   f then
the above estimate is still optimistic if the rate of convergence is not slower than g   and
pessimistic if the rate of convergence is slower than g   the latter is desirable in the sense
that we have a negatively biased estimate on the expected performance of an algorithm
that we do not want to use  we should not waste samples on suboptimal choices  
as in practice g is usually not known exactly  the estimate     often cannot be constructed  on the other hand  if g is known up to a constant factor then we can construct
a family of estimates for all scales  let g denote a normalized version of g such that
g         and g  n  g  n  is a constant for all n  and construct the family of estimates
fi ni r   cg  ni r  

   

where c ranges over all positive reals  then it is reasonable to choose  in each round 
those algorithms to take another step that provide the largest estimate for some values of c
 typically  if an algorithm gives the largest estimate for some c   c then there is an interval
i containing c such that the algorithm provides the largest estimate for any c  i   in
this way we can get around the fact that we do not know the real scaling factor of g   as
we certainly use the algorithms that provide the largest value of     for c   g     g     
and  as it will be discussed later  we do not waste too many samples for algorithms that
maximize     for other values of c  using the optimistic estimate     is very similar  in spirit 
to the optimistic estimates in the standard upper confidence bound type solution to the
multi armed bandit problem  auer  cesa bianchi    fischer        or in the well known
a search algorithm  hart  nilsson    raphael        
however  the exact  local  convergence rate is not known  even up to a constant factor 
for many local search algorithms  and even if it is  the corresponding bounds are usually
meaningful only in the asymptotic regime  which is often not of practical interest  therefore 
to give more freedom in the design of the algorithm  we are going to use an estimate of the
form
fi ni r   ch ni r  
   
where  similarly to the requirements on g   h is a positive  monotone decreasing function
with limn h n       we will also assume  without loss of generality  that h        
the actual form of h will be based on the theoretical analysis of the resulting algorithms
and some heuristic considerations  essentially we will use h functions that converge to zero
exponentially fast  which is in agreement with the exponentially fast local convergence rates
in the examples given after lemma    the optimal choice of h  given  for example  g   is
not known  and is left for future work 
    constant number of instances
the above idea can be translated to the algorithm metamax k  shown in figure    here
we consider the case when we have a fixed number of instances  and our goal is to perform
 almost  as well as the best of them  in hindsight   while using the minimum number of
br
evaluations of f   note the slight abuse of notation that in the metamax k  algorithm x
and fr denote the estimates of the algorithm after r rounds  and not r steps samples  
in the first part of step  a  of metamax we sweep over all positive c and select local
search algorithms that maximize the estimate      it is easy to see  that if ai maximizes
   

fiefficient multi start strategies for local search algorithms

metamax k   a multi start strategy with k algorithm
instances 
parameters  k     and a positive  monotone decreasing function h with
limn h n      
initialization  for each i              k  take a step with each algorithm ai
once  and let ni       and fi     f  xi     
for each round r              
 a  for i              k select algorithm ai if there exists a c     such that
fi ni r    ch ni r      fj nj r    ch nj r   

   

for all j              k such that  ni r    fi ni r        nj r    fj nj r     if
there are several values of i selected that have the same step number
ni r  then keep only one of these selected uniformly at random 
 b  step each selected ai   and update variables  that is  set ni r  
ni r      if ai is selected  and ni r   ni r  otherwise  for each
bi n
selected ai evaluate f  xi ni r   and compute the new estimates x
i r
and fi ni r  
 c  let ir   argmaxi       k fi ni r denote the index of the algorithm with
the currently largest estimate of f    and estimate the location of the
br   x
bir  n
maximum with x
and its value with fr   fir  nir  r  
ir  r
figure    the metamax k  algorithm 
    for a particular c   u then there is a closed interval i containing u such that ai also
maximizes     for any c  i  therefore  in each round  the strategy metamax k  selects
the local search algorithms ai for which the corresponding point  h ni r     fi ni r    is a
corner of the upper convex hull of the set
pr     h nj r     fj nj r      j              k        max fj nj r     
 jk

   

the selection mechanism is illustrated in figure   
to avoid confusion  note that the random selection in step  a  of metamax k  implies
that if all algorithms are in exactly the same state  that is   ni r    fi ni r       nj r    fj nj r   
for all i  j  then one algorithm is selected uniformly at random  this pathological situation
may arise  e g   at the beginning of the algorithm or if all the local search algorithms give
the same estimate of f  for some range of step numbers   apart from the case when one of
the least used algorithms provides the currently best estimate  which happens surely in the
first round but usually does not happen later  and includes the previous pathological case  
it is guaranteed that in each round we use at least two algorithms  one with the largest
   

figyorgy   kocsis

   

   

f x 

   

   

   

   

   

 
   

   

   

   

h n 

   

   

   

   

figure    selecting algorithm instances in metamax  the points represent the algorithm
instances  and the algorithms that lie on the corners of the upper convex hull
 drawn with blue lines  are selected 

estimate fi ni r    fr   for very small values of c   and one with the smallest step number
nj r   for very large values of c   thus  usually at most half of the total number of function
calls to f can be used by any optimal local search algorithm  this observation gives a practical lower bound  which is valid apart from the pathological situation mentioned above  on
the proportion of function calls to f made by optimal local search algorithms  surprisingly 
theorem   below shows that this lower bound is achieved by the algorithm asymptotically 
the randomization in step  a  that precludes using multiple instances with the same
step number is introduced to speed up the algorithm in certain pathological cases  for
example  if a  converges to the correct estimate  while all the other algorithms a            ak
produce the same estimate in each round  independently of their samples  that is inferior
to the estimates of a    then if we use the randomization  half of the calls to compute f will
be made by a    but without the randomization this would drop down to   k as in each
round we would use each algorithm  furthermore  we could take a step with all algorithms
that lie on the convex hull  but similar pathological examples can be constructed when it is
more beneficial to use only algorithms on the corners  on the other hand  it almost never
happens in practice that three algorithms lie on the same line  and so algorithms typically
never fall at non corner points of the convex hull 
in the remainder of this section we analyze the performance of the metamax k 
algorithm  proposition   shows that the algorithm is consistent in the sense that its performance asymptotically achieves that of the best algorithm instance as the number of rounds
increases  to understand the algorithm better  lemma   provides a general sufficient condition that an algorithm instance is not advanced in a given round  while  based on this
result  lemma   provides conditions that ensure that suboptimal algorithm instances are
not used in a round if they have been stepped too many times  i e   they have evaluated f
at too many points  before  lemma   gives an upper bound on the number of algorithm
   

fiefficient multi start strategies for local search algorithms

instances used in a round  the results of the lemmas are then used to show in theorems  
and   and remark   that optimal algorithm instances are used  asymptotically  at least
at a minimum frequency that  in turn  yields the asymptotic rate of convergence of the
metamax k  algorithm 
the following proposition shows that the metamax k  algorithm is consistent in a
sense 
proposition   the metamax k  algorithm is consistent in the sense that fr  f  for
all r  and
o
n
f   lim fi n  
f   lim fr   min
r

i       k

n

proof the proof follows trivially from the fact that each algorithm is selected infinitely
often  that is  limr ni r     to see the latter  we show that in every k rounds the
number of steps taken by the least used algorithm  that is  mini       k ni r   is guaranteed
to increase by one  that is  for all k    
min ni kk  k 

i       k

   

as described above  in each round we select exactly one of the algorithms that have made
the least number of steps  thus  if there are k such algorithms  the minimum step number
per algorithm will increase in k rounds  which completes the proof 
 
the metamax k  algorithm is more efficient if suboptimal algorithms do not step too
often  the next lemma provides sufficient conditions that an algorithm is not used in a
given round 
lemma   an algorithm instance aj is not used in any round r     of the metamax k 
algorithm  if there are algorithms ai and ak such that fi ni r   fj nj r   fk nk r and either
ni r  nj r or


h nj r  
h nj r  


fj nj r  fi ni r   
   
  fk nk r
h nk r  
h nk r  
proof as in each round the algorithms at the corners of the convex hull pr   are used  it
is easy to see that an algorithm aj is not used in a round r if there are algorithms ai and
ak such that fi ni r   fj nj r   fk nk r and either ni r  nj r or
fi ni r  fk nk r
fi ni r  fj nj r

 
h nj r    h ni r  
h nk r    h ni r  

   

to finish the proof we show that     implies the latter  indeed      is equivalent to
h nk r   fi ni r  fj nj r    h nj r   fi ni r  fk nk r     h ni r   fk nk r  fj nj r   
as the last term in the right hand side of the above inequality is negative by our assumptions 
the inequality is satisfied if
h nk r   fi ni r  fj nj r    h nj r   fi ni r  fk nk r  
   

figyorgy   kocsis

which is equivalent to     

 

the above lemma provides conditions on not using some algorithm instances in a certain
round that depend on the actual performance of the instances  the next result gives similar
conditions  however  based on the best estimates  usually local optima  achievable with the
algorithms  let fi   limr fi ni r be the asymptotic estimate of algorithm ai for f    and
let f   max ik fi denote the best estimate achievable using algorithms a            ak  
let o              k  be the set of optimal algorithms that converge to the best estimate
f  for these algorithms   and let  o  denote the cardinality of o  i e   the number of
optimal algorithm instances   note that o is a random variable that depends on the actual
realizations of the possibly randomized search sequences of the algorithms  the next lemma
shows that if j   o  then aj is not used at a round r if it has been used too often so far 
lemma   let

   f  max fj
j o

denote the margin between the estimates of the best and the second best algorithms  then
for any     u    there is a random index r u      such that for any j   o  aj is not
used by metamax k  at a round r       r u  if
  



f
j
min ni r
 
nj r  h  h
 
    
i       k
f  u
furthermore  let           for any i  o  let g i denote the convergence rate of algorithm
ai guaranteed by lemma    and let g  n    maxio g i  n  for all n  then p  r u  
         where g   is the generalized inverse of g    and no suboptimal
kg   u  f            fk


algorithm aj   j   o  is used for any r   kg   u  with probability at least      o  given the
 
limiting estimates f            fk
proof let i  o  since limn fi n   fi   f by assumption and     implies that
 u 
limr ni r     there is an almost surely finite random index ri     such that for all
 u 

r   ri we have f  fi n
 u and so
i r
f  fr  u 

    

using lemma   we can easily derive a high probability upper bound on r u    since for any
r   kg   u    r       implies ni r  g   u   lemma   yields


fi
p fi  fi ni r  u for all r   r fi fi   f      

it follows that with probability at least      o  there is an i  o such that fi  fi ni r  u 
      o    thus  to
which implies that r u  can be chosen such that p  r u    r  f            fk
prove the lemma  it is enough to show      
clearly  by       the algorithm will pick the estimate of one of the best algorithms after
r u  rounds  let ak be an algorithm with the least number of steps taken up to the end
   

fiefficient multi start strategies for local search algorithms

of round r  that is  nk r   mini ni r   if fk nk r  fj nj r then aj is not used in round r     
moreover  since aj   o  fj nj r  fj   fr and in this case aj is not used in round r    
if nj r  nir  r  recall that nir  r is the number of evaluations of f initiated by the actually
best algorithm ir    therefore  lemma   implies that aj is not used for r   r   if
 
fj nj r  fk nk r
h nj r    h nk r     
 
fr  fk n
k r

this is clearly satisfied if
h nj r    h min ni r     
i

fj
f  u

 

    

for any     u     since by      we have
 

fj
fj nj r  fk nk r
fj nj r
 
 
 
fr  fk nk r
fr
f  u

applying the inverse of h to both sides of      proves       and  hence  the lemma 

 

the above result provides an individual condition for each suboptimal algorithm for
not being used in a round  on the other hand  if one of the optimal algorithms has been
stepped sufficiently many times  we can give a cumulative upper bound on the number of
suboptimal algorithms used in each round 
lemma   assume that h decreases asymptotically at least exponentially fast  that is  there
exist          and n     such that h n   
h n     for all n   n   assume that r is large
enough so that ni r   n for all i  and let r      maxi fi n

  fr
i r

fi ni r
fr

     then at most

r
 ln
ln       algorithms are stepped in round r      where x denotes the smallest integer at
least as large as x 

proof let i    i            im denote the indices of the algorithms chosen in round r     with
fi   r   fi   r        fim  r   fr   then lemma   implies that ni   r   ni   r        nim  r and
fr  fik  r    fr  fik   r  
for all k              m     repeated application of the above inequality implies
fr r  fr  fim   r    fr  fim   r          m   fr  fi   r    fr m 
which yields

ln r
ln 
as we assumed that m     algorithms were chosen in round r      this fact finishes the
proof 
 
m  

   

figyorgy   kocsis

based on lemmas   and    the next theorem shows that if the local search algorithm
converges fast enough  exponentially with a problem dependent rate  or faster than exponential  then half of the function calls to evaluate f correspond to optimal algorithm
instances 
theorem   assume that the performance of the algorithms ai   i              k are not all
the same  that is   o    k  and suppose that
 
 
fj
h n     
lim sup
 
    
  min   
j o
h n 
n
f
then asymptotically at least half of the function
respond to an optimal algorithm  that is 
p
ni r
 
p lim inf pio

k
r
 
i   ni r

calls to evaluate f in metamax k  cor 
fi
fi 

fi f            fk
    
fi

furthermore  for any          and      there is a constant r        such that
 p
  
k
n
i   i r
f  fr  g
       o 

    

    

 simultaneously for all r   r      where
with probability at least     o  given f            fk
   
g is defined in lemma    and the threshold r
    depends on     h  g  and   where
 
g and  are also defined in lemma   

proof we show that a suboptimal aj is not chosen for large enough r if nj r   mink nk r  
by lemma    it is sufficient to prove that  for large enough r 
  
fj
 
    
min nk r      h
h min nk r     
k
k
f  u
for some     u     recall that here r should be larger than r u    the almost surely finite
random index of lemma    
as the minimum in      is taken over a finite set  it follows that there exists a small
enough positive u    such that
 
 
fj
h n     
lim sup
 
    
 min   
j o
h n 
n
f  u
which clearly implies      as limr mink nk r    by      this fact finishes the proof of
      the first part of the theorem 
next we prove       let nu     be a threshold such that      holds for all n  nu  
furthermore  by lemma   and the union bound      holds for each local search algorithm
ai with g i in place of g simultaneously for all i  o with probability at least     o  
   

fiefficient multi start strategies for local search algorithms

then     and a slight modification of lemma   imply that      holds simultaneously for
 
all r   k max g   u   nu     r with probability at least     o  given f            fk
since
in each such round at most two algorithms are used  for any r   r   c we have
p
n
i r
c r
pio
   c kr
 with high probability  since the latter is bounded from below by       
k
n
i r
i  
pk
p
ni r
for c  r  k     we have io ni r  i  
for any r   r      r  r  k   
  
with
l p highmprobability  then there is an algorithm ai   i  o such that it is used in at least
k
i  

ni r
 o     

rounds  implying the statement of the theorem via lemma   

 

remark   the above proof of theorem   is based on lemma    a proof based on lemma  
is also possible  since setting    minj o     fj  f   in the lemma       implies that  for
large enough r  r    and so each round is approximately of length   by the lemma 
it may happen that although the decay rate of h is exponential  it is not quite fast
enough to satisfy       so the optimal scenarios in the above theorem do not hold  in this
case it turns out that the number of algorithms converging to the same local maximum
plays the key role in determining the usage frequency of the optimal algorithms 
theorem   assume that the estimates provided by the algorithms a            ak converge to
n     distinct limit points  such that k     o  algorithms converge to f   and k    k            kn  
algorithms converge to each suboptimal limit points  respectively  suppose furthermore
that h decreases asymptotically at least exponentially fast  that is  for some          
lim supn h n   
h n      then
p lim inf
r

p

io ni r
pk
i   ni r

 
fi
fi 
kmax

fi f           fk     

k  k    kmax fi  

where kmax   max in   ki  
furthermore  using the definitions of lemma   for any          and      there is a
constant threshold r   
  
 
pk
k
n
max
i   i r
f  fr  cg
 k  k    kmax     o 
 simultaneously for all r   r      where
with probability at least     o  given f            fk
r    depends on     f            sfk and the convergence rate of all the algorithms   
 are given  and fix the random trajectories of all the algorithms  if
proof suppose f            fk
there is a single suboptimal algorithm then the statement is trivial as kmax   k k   kmax    
    and in each round at least two algorithms are used  and at most one of them can be
the suboptimal one  from now on assume there are at least two suboptimal algorithms 
assume that aj and ak converge to suboptimal local maxima  strictly less than f    for
any r large enough  an optimal algorithm ai is better than any of the suboptimal ones  that

   instead of the convergence rate of all algorithms  r    may be defined to be dependent on g and  

   

figyorgy   kocsis

is  if ai converges to f then fi ni r   fj nj r   fk nk r   assume  without loss of generality  that
fj nj r  fk nk r   if nj r  nk r then clearly only aj can be chosen in round r      assume
nj r   nk r   since fj nj r and fk nk r are convergent sequences  as r     for large enough
r we have  for some j k     
 

fj nj r  fk nk r
  j k  tj k


fi n  fk n
i r

    

k r

where tj k   ln j k   ln  is a positive integer  note that if aj and ak converge to the
same point  that is  limr  fj nj r  fk nk r        the second term on the left hand side of
     converges to    and so j k can be chosen to be   implying tj k      rearranging the
above inequality one obtains
    tj k  fi ni r   tj k fk nk r   fj nj r  

    

if nj  nk  tj k   then the conditions on h and the fact that both nj r and nk r tend to
infinity as r    recall      imply that  for large enough r  h nj r   h nk r     tj k   since
fi ni r  fk nk r for large enough r  from      we obtain


h nj r   
h nj r   
tj k 
tj k 

fk nk r  
fi ni r  
fj nj r         fi ni r    fk nk r    
h nk r  
h nk r  
thus  by lemma    if r is large enough  aj cannot be used in round r     if nj r  nk r  tj k  
since both nj r and nk r tend to infinity  it follows that  for large enough r 
 nj r  nk r    tj k

    

for any two suboptimal algorithms aj and ak   note that this fact also implies that from
any set of suboptimal algorithms converging to the same point  eventually at most one can
be used in any round  since the corresponding thresholds are tj k      
clearly      implies that both nj r and nk r grow linearly with r  and since their differences is bounded by       limr nj r  nk r      therefore  for any suboptimal algorithm
aj   we have limn nj r  r    kmax  this is the maximal rate of using elements from the
largest group of suboptimal algorithms converging to the same local optimum   finally  as
an optimal algorithm is used in each round r  for large enough r  we have
p
p
io ni r
io ni r
p
lim inf pk
  lim inf p
r
r
n
 
i r
n
i o ni r
io
i r
i  
kmax
r
 lim
 
 
r
r r    k  k   
k  k    kmax
kmax
where we used the fact that a  a   b  is an increasing function of a for a  b      since the
 
above inequality holds for all realizations of the trajectories of a            ak   given f            fk
the first statement of the theorem follows 
the second statement follows similarly to      in theorem    since the exact value of
r    is not of particular interest  the derivation is omitted 
 

   

fiefficient multi start strategies for local search algorithms

remark   the main message of the above theorem is the somewhat surprising observation
that suboptimal algorithms are slowed down if there is a large group of suboptimal algorithms
converging to the same local optimum  the rate suboptimal algorithms are used at is bounded
by the the size of the largest such group 
    unbounded number of instances
it is clear that if the local search algorithms are not consistent  i e   they do not achieve
the global optimum f     then  despite its favorable properties  the metamax k  strategy
is inconsistent  too  however  if we increase the number of algorithms to infinity then we
get the consistency from random search  while still keeping the reasonably fast convergence
rate from metamax k  
clearly  one needs to balance between exploration and exploitation  that is  we have
to control how often we introduce a new algorithm  one solution is to let the metamax
algorithm solve this problem  the metamax   algorithm  given in figure    is the extension of metamax k  that is able to run with infinitely many local search algorithm
instances  here a major issue is that new local search algorithms have to be started from
time to time  this ensures that the algorithm will converge to the global maximum of f
since it also performs a random search   this is implemented by modifying step  a  of the
metamax k  algorithm so that a new  randomly initialized local search algorithm is introduced in each round  randomly selecting one algorithm uniformly from the infinitely
many possible algorithms not used so far   obviously  we have to skip the initialization
step of metamax k  and start each algorithm with   samples  to better control the
length of each round  i e   the exploration   in each round r we allow the use of a different
function h  denoted by hr  that may depend on any value measured before round r  this
is suppressed in the notation   as before  we assume that hr          hr  n  is monotone decreasing in n  and limn hr  n      for all r  typically we will make hr  be dependent on
pkr 
the total number of steps  i e   the function calls to evaluate f   tr    i  
ni r  made
by all the algorithms before round r  where kr  is the number of algorithm instances used
before round r  note that kr    r    for all r  as we start exactly one new algorithm in
each round 
it is desired that  although the number of local search algorithms grows to infinity 
the number of times the best local search algorithm is advanced by the metamax  
algorithm approaches infinity reasonably fast  somewhat relaxing the random initialization
condition  we may imagine a situation where the local search algorithms are initialized in
some clever  deterministic way  and so in the first few steps they do not find any better
value than their initial guesses  if all algorithms are optimal  this may be viewed as a result
of the clever initialization   then they may provide  for example  the identical estimates
            for the first three steps  then it is easy to see that each algorithm is stepped
exactly twice  thus no convergence to the optimum  which would be found after the third
step  is achieved  although the random initialization of the search algorithms guarantees
the consistency of metamax    see proposition    below   robust behavior in even such
pathological cases is preferred 
this can be achieved by a slight modification of the algorithm  if in a round a local search
algorithm overtakes the currently best algorithm  that is  ir    ir    then algorithm air
   

figyorgy   kocsis

metamax    a multi start strategy with infinitely many
algorithm instances 
parameters   hr    a set of positive  monotone decreasing functions with
limn hr  n      
for each round r              
 a  initialize algorithm ar by setting nr r       fr       
 b  for i              r select algorithm ai if there exists a c     such that
fi ni r    chr   ni r      fj nj r    chr   nj r   
for all j              r such that  ni r    fi ni r        nj r    fj nj r     if
there are several values of i selected that have the same step number
ni r  then keep only one of these selected uniformly at random 
 c  step each selected ai   and update variables  that is  set ni r  
ni r      if ai is selected  and ni r   ni r  otherwise  for each
bi n
selected ai evaluate f  xi ni r   and compute the new estimates x
i r
and fi ni r  

 d  let ir   argmaxi       r fi ni r denote the index of the algorithm with
the currently largest estimate of f    and estimate the location of the
br   x
bir  n
maximum with x
and its value with fr   fir  nir  r  
ir  r
figure    the metamax   algorithm 

is stepped several times until it is used more times than air     the resulting algorithm 
called metamax  is given in figure    note that the algorithms metamax   and
metamax conceptually differ only at one place  step  c  is extended with step  c  in
the new algorithm  as a result  a technical modification also appears in step  d   and  to
simplify the presentation of the metamax algorithm  a slight  insignificant modification is
also introduced in step  b   see the discussion below 
the modification in metamax is not really significant in the practical examples we
studied  see section     as the number of steps taken by an algorithm that overtakes the
currently best algorithm grows very quickly also in the metamax   algorithm  since in
metamax an overtake usually introduces very short rounds  close to the minimum length
two in many cases  until the leading algorithm becomes also the most used one  the goal
of the modification in step  b  is only to synchronize the choice of the optimal algorithms
in steps  b  and  c   an equally good solution would be to choose  in case of a tie in step
   in this way we achieve that the actually best algorithm dominates all others in terms of both accuracy
and the number of calls made by the algorithms to compute the target function  this is the same type
of dominance as used by hutter et al         in a slightly different context 

   

fiefficient multi start strategies for local search algorithms

metamax  a multi start strategy with infinitely many
algorithm instances 
parameters   hr    a set of positive  monotone decreasing functions with
limn hr  n      
for each round r              
 a  initialize algorithm ar by setting nr r       fr       
 b  for i              r select algorithm ai if there exists a c     such that
fi ni r    chr   ni r      fj nj r    chr   nj r   
for all j              r such that  ni r    fi ni r        nj r    fj nj r     if
there are several values of i selected that have the same step number
ni r  then keep only one of these that has the smallest index 
 c  step each selected ai   and update variables  that is  set ni r  
ni r      if ai is selected  and ni r   ni r  otherwise  for each
bi n
selected ai evaluate f  xi ni r   and compute the new estimates x
i r

and fi ni r  

 c  let ir   argmaxi       r fi ni r denote the index of the algorithm with
the currently largest estimate of f   in case ir is not unique  choose
the one with the smallest number of steps ni r    if ir    ir    step
algorithm air  nir   r  nir  r      times and set nir  r   nir   r     
br   x
bir  n
 d  estimate the location of the maximum with x
and its
ir  r
value with fr   fir  nir  r  
figure    the metamax algorithm 

 c   an algorithm that was used in the current round  also note that  as a result of the
modifications  the currently best algorithm  with index ir   has taken the most steps  and so
the extra number of steps taken in step  c  is indeed positive  an important consequence
of the modifications is that  in any round r  the number of steps taken by the local search
algorithm air   which is the best at the end of the round  is between r and  r  see theorem   
below  
the rest of the section is devoted to the theoretical analysis of metamax   and
metamax  following the lines of the analysis provided for metamax k   first  in proposition     it is shown that the algorithm is consistent  that is  the solution found by the
algorithm actually converges to f    lemma     a counterpart of lemma    shows that
suboptimal algorithms can make only finitely many steps  while lemma    gives an upper
bound on the length of each round  the main theoretical results of this section apply only
   

figyorgy   kocsis

to the metamax algorithm  theorem    gives a lower bound on the number of steps taken
by the actually best algorithm by the end of a given round  while  as a consequence  theorem    shows the rate of convergence of the algorithm as a function of the total number of
steps  i e   function calls to evaluate f   used by all algorithm instances  it turns out that at
most quadratically more steps are needed than for a generic local search algorithm instance
that converges to the optimum 
since the metamax   and the metamax strategies perform a random search  the
number of algorithms tends to infinity as the length of each round is finite   the algorithms
are consistent 
proposition    the strategies metamax   and the metamax are consistent  that
is 
lim fr   f 
r

almost surely 
proof clearly  the event that fr does not converge to f  can be written as
n

  
 n
  
o
o
 
lim fr    f   
fr   f     n

r

    

n   r   r r

now the continuity of f implies that  for any n  if x is chosen uniformly from       d then
qn p
  p f  x    f     n       thus  for any round r  p fr   f     n       qn  r   and


so 
r   p fr   f    n  is finite  therefore  the borel cantelli lemma  see  e g   ash  
doleans dade        implies that
 
 n
  
o
 

  
p
fr   f    n
r   r r

for all n  this  together with      finishes the proof  as
p



lim fr    f

r








x

n  

p

 n
  
 

r   r r

fr   f    n


o

 

    
 

in the reminder of this section we will assume that local search algorithms that achieve
an almost optimal value eventually converge to the optimum 
assumption    let f   r denote the set of local maxima of f   and let    f  
supff   f f  f  we assume that      and if an algorithm ai is such that fi n   f   
for some n  then limn fi n   f   
if the local search algorithms converge to local optima  which is a reasonable assumption
in practice   the above assumption is usually satisfied  the only situation when it does not
hold is the pathological case when f has infinitely many local maxima and the set of these
maxima is dense at the global maximum 
   

fiefficient multi start strategies for local search algorithms

under assumption    we can prove  similarly to lemma    that any suboptimal algorithm is selected only a limited number of times that increases with h 
r   in particular  if
hr   h for all r large enough  then any suboptimal algorithm is chosen only finitely many
times 
lemma    suppose assumption     and let q   p f  x    f       for an x uniformly
distributed in       d   then  for both the metamax   and the metamax algorithms  a
suboptimal algorithm aj started before round r    is not used at round r     with probability
at least        q r   if



 
nj r  hr
 
 f   
in addition  if hr  n  is a non decreasing function of r for all n  then
lim sup
r

h 
r 

n
 j r



 f  

  

almost surely 

    

in particular  if hr is a constant function  that is  hr   h  for all r  then limr nj r   
almost surely 
remark    note that in the second
 part of the lemma we coulddrop the
 monotonicity
 
 


assumption on hr and replace hr   f   with max r r  hr  f   in      
proof consider if algorithm aj is used at a round r      first note that with probability
at least        q r   fr   f       furthermore  the newly introduced algorithm  ar   is
not used yet  and we have nr   r     and fr          thus  by lemma    aj is not used if


h nj r  


  fr     hr  nj r     
fj nj r  fr   
hr    
since this is equivalent to
nj r 
and
h 
r

fj nj r
 
fr

h 
r

fj nj r
 
fr

 



by

h 
r



 

 


 f   



fr  fj nj r

fr   f    
 f         f    
  
 
    

 

f    
 f  
fr
fr
the first statement of the proof follows 
b denote the first round in which there is an optimal
to prove the second part  let r


algorithm ai with fi ni rb   f      then for any suboptimal algorithm aj   the first part
b
of the lemma implies that  for any r   r 










 
 
b
b
      max r  hr 
  
nj r  max r  max
h
 r  r  r
 f   
 f   
   

figyorgy   kocsis

where the equality holds since h 
r  n  is non decreasing in r  thus




b
nj r
r
 
  lim sup max
     




lim sup



 h 

r h 
r
h 
r   f  
r   f  
r   f  




b
 
r
     



 max



 h 
h 
 

 

 f  

    

 f  

b is finite       is also finite with
where we used that h 
is non decreasing in r  since r
r
probability   
 
a simple modification of lemma   implies that once a    optimal sample point is
found then only a limited number of suboptimal algorithms is chosen in each round 
lemma    consider algorithms metamax   and metamax  suppose assumption   
holds  and assume that f   fr      for some r      in anyround r   r  if hr  n    rn


for some     r     and for all n     then at most

ln  f 
ln   r  

algorithms are chosen that

have estimates fj  f    

proof the proof follows from lemma   taking into account that any suboptimal algorithm
aj satisfies fj  f    and that at least one optimal algorithm is chosen in each round
r   r  similarly to       r defined in lemma   can be bounded as r      f    
and so
l
m   f   
ln
ln   r  

the number of suboptimal algorithms used in round r is bounded by ln   
 
 ln   
r 
r 
 
finally we can derive the convergence rate of the algorithm metamax  first we bound
the number of steps taken by the currently best algorithm  both in terms of the number of
rounds and the total number of steps taken by all the local search algorithms 
theorem    consider the metamax algorithm  at the end of any round r the number
of steps taken by the currently best algorithm is between r and  r  that is 
r  nir  r    r 

    

furthermore  the number of calls nir  r to evaluate f by the currently
best algorithm air can
pr
be bounded by a function of the total number of times tr   i   ni r the target function f
is evaluated by all local search instances as

 tr       
nir  r 
 
    
 
proof the first statement of the lemma is very simple  since in any round the actually
best algorithm takes one step if there is no overtaking  and one or two steps if there is
   

fiefficient multi start strategies for local search algorithms

overtaking  indeed  in any round r     if there is no overtaking  that is  ir   ir   
then nir  r   nir  r       otherwise  if ir    ir    then nir  r   nir   r      and since
   nir   r  nir   r      we have
   nir  r  nir   r    
in all situations  since in the first round clearly the only algorithm used takes   step  that
is  ni               follows 
to prove the second part  notice that in any round r  at most nir   r      algorithms
can be stepped in step  c  as no algorithm can be used that has taken more steps than the
currently best one  also  in step  c  no extra samples are used if there is no overtaking 
in case of overtaking  air has to be advanced in step  c   as well as air    and so at most
nir   r      extra steps has to be taken by air   therefore 
tr  tr     nir   r      
thus  since no overtaking happens in round    we obtain
tr     

r
x

  nis   s       

s  

then  by      we have
tr       

r
x
s  

s         r      r            nir  r      nir  r    

which yields      

 

note that in the proof we used a crude estimate on the length of a usual round  without
overtaking  relative to  for example  lemma     this  however  affects the result only by a
constant factor as long as we are not able to bound the number of rounds or the number
of extra steps taken when overtaking happens  since the effect of the overtakings itself
introduces the quadratic dependence in the proof of       experimental results in section  
show  see figure     that the number of algorithm instances  which is in turn the number r
of rounds  has a usual growth rate of  tr   ln tr    which  if taken into account  may sharpen
the bound on how often the best algorithm is chosen 
under assumption     the random search component of metamax implies that eventually we will have an optimal algorithm that is the best  from that point the convergence
rate of the optimal local search algorithms determine the performance of the search  and
the number of steps taken by the best local search algorithm is bounded by theorem    
theorem    suppose assumption    holds  then there is an almost surely finite random
index r such that for all rounds r   r  the estimate fr of the metamax algorithm and
the total number of steps tr taken by all local search algorithms up to the end of round r
satisfies


 t
 
 

 
r

f  fr  g
 
with probability at least      where g is defined by lemma   for the global maximum f   
   

figyorgy   kocsis

remark     i  the value of r can be bounded with high probability using the properties
of uniform random search for the actual problem  this would yield similar bounds as in
theorems   and   for the metamax k  algorithm   ii  note the exploration exploitation
trade off in the metamax algorithm  the value of r is potentially decreased if we introduce
new algorithms more often  while nir  r is reduced at the same time   iii  theorems    and   
imply that  asymptotically  the metamax algorithm needs only quadratically more function
evaluations than a local search algorithm
psthat is ensured to converge to the optimum  in
particular  if f is of the form f  x   
i   fi  x isi  x  where the si form a partition of
      d   isi denotes the indicator function of si   and the fi belong to some nicely behaving
function class such that a local search algorithm started in si converges to the maximum
of fi on si  e g   f is a piecewise concave function with exponential convergence rate for
the spsa algorithm  which is used with a sufficiently small step size   then we can preserve
the performance of a local search algorithm for the original function class at the price of
an asymptotically quadratic increase in the number of function calls to evaluate f  i e   the
total number of steps taken by all local search algorithm instances  
    discussion on the results
in some sense the theoretical results presented in the previous sections are weak  the
consistency result for the metamax k  algorithm follows easily from the fact that each
local search algorithm is used infinitely many times  and the consistency of metamax  
and metamax follows from the consistency of a random search  the performance bounds
provided have a disadvantage that they are asymptotic in the sense that they hold only after
a possibly large number of rounds  a weakness of the bounds is that the minimum number
of rounds is obtained from properties of uniform random search sampling for the particular
problem  neglecting more attractive properties of the algorithms   in fact  it is quite easy
to construct scheduling strategies that are consistent and asymptotically an arbitrarily
large fraction of the function evaluations  even almost all  is used by optimal local search
algorithms  the explore and exploit algorithms achieve both of these goals if the number of
function evaluations to be used is known ahead and they use an arbitrarily small fraction
of the evaluations of the target function f for exploration  we compare the performance of
our algorithms to such explore and exploit algorithms in section    in particular  to match
the performance guarantees for the metamax family  we use algorithms that spend half
of their time with exploration and half with exploitation  where in the exploration part a
uniform allocation strategy is used when there is a finite number of local search algorithms 
and the schedule of luby et al         is used for infinitely many local search algorithms 
although the theoretical guarantees proved in this paper for the metamax family also hold
for these explore and exploit algorithms  in all experiments the metamax family seems to
behave superior compared to these algorithms  as expected 
the theoretical results also do not give sufficient guidance on how to chose the parameter
h or hr  the time varying version of h is not considered for the metamax k  algorithm
for simplicity and ease of presentation   most of our results require a sufficiently fast
exponential decay in h  which is problem dependent and cannot be determined in advance  a
sufficiently fast decay rate would ensure  for example  that for the metamax k  algorithm
we could always use the stronger results of theorem   and would never have to deal with
   

fiefficient multi start strategies for local search algorithms

the case when only the bound of theorem   holds  one may easily choose h to be any
function that decreases super exponentially  this would make the asymptotic bounds work 
however  would slow down exploration  in the extreme case of hr  n      which is excluded
by our conditions  no exploration would be performed  and the algorithms would use only
the actually best local search algorithm   in practice we have always found that it is
appropriate to chose hr decay exponentially  furthermore  we have found it even more
effective to gradually decrease the decay rate to enhance exploration as time elapses  the
rationale behind this approach is the assumption that good algorithms should have more
or less converged after a while  and so there may be a greater potential in exploration
to improve our estimates   finally  the connection between g and h should be further
investigated 
keeping the above limitations of the theoretical results in mind  we still believe that
the theoretical analyses given provide important insight to the algorithms and may guide
a potential user in practical applications  especially since the properties of the metamax
family that can be proved in the asymptotic regime  e g   that the rounds are quite short 
can usually be observed in practice  as well  furthermore  we think that it is possible to
improve the analysis to bound the thresholds from which the results become valid with
reasonable values  but this would require a different approach and  therefore  is left for
future work 

   experiments
the variants of the metamax algorithm are tested in synthetic and real examples  since
there was only negligible difference in the performance of metamax   and metamax  
in the following we present results only for metamax k  and metamax  first we demonstrate the performance of our algorithm in optimizing a synthetic function  using spsa as
the local search algorithm   next the behavior of our algorithm is tested on standard data
sets  we show how metamax can be applied for tuning the parameters of machine learning
algorithms  a classification task is solved by a neural network  and the parameters of the
training algorithm  back propagation  are fine tuned by metamax combined with spsa 
metamax is also applied to boost the performance of k means clustering  at the end of
the section  we compare the results of the experiments to the theoretical bounds obtained
in section     
in all the experiments  in accordance with our simplifying assumptions introduced in
section    the main difference between the individual runs of the particular local search
algorithm is their starting point  obviously  more general diversification techniques exist 
for example  the parameters of the local search algorithm could also vary from instance to
instance  including running instances of different local search algorithms  where a parameter would select the actually employed search algorithm   and the initialization  starting
point and parametrization  of a new instance could also depend on the results delivered by
   for example  the relative difference between the average error emetamax   of metamax   and
emetamax of metamax in optimizing the parameters of a multi layer perceptron for learning the letter
data set  see section     and especially figure    right for more details  was       with a standard
deviation of       averaged
over      experiments   where the relative difference is defined as
fi
fi
fiemetamax    emetamax fi   max emetamax     emetamax   

   

figyorgy   kocsis

existing instances  although the metamax strategies could also be applied to these more
general scenarios  their behavior can be better studied in the simpler scenario  hence  our
experiments correspond only to this setup 
    optimizing parameters with spsa
in this section we compare the two versions of the metamax algorithm with six multi start
strategies  including three with a constant and three with a variable number of algorithm
instances  the strategies are run for a fixed t time steps  that is  the target function can
be evaluated t times  together by all local search instances  note that several reference
strategies use t as a parameter  
we used spsa  simultaneous perturbation stochastic approximation  spall        as
the base local search algorithm in all cases  spsa is a local search algorithm with a sampling
function that uses gradient descent with a stochastic approximation of the derivative  at
the actual location xt    xt             xt d    spsa estimates the lth partial derivative of f by
f  xt   t bt    f  xt  t bt  
 
ft l  xt l    
 t bt l
where the bt l are i i d  bernoulli random variables that are the components of the vector
bt   and then uses the sampling function st  xt     xt   at ft  xt   to choose the next point
to be sampled  that is 
xt   l   xt l   at ft l  xt l  
for l              d  t and at are scalar parameters  
in the implementation of the algorithm we have followed the guidelines provided in
 spall         with the gain sequence at   a  a   t        and perturbation size t  
  t        where a                and           the values of a and  vary in the
different experiments  they are chosen heuristically based on our experience with similar
problems  this should not cause any problem here  as the goal of the experiments is not to
provide fast solutions of the global optimization problems at hand but to demonstrate the
behavior of the multi start algorithms to be compared   in addition to the two evaluations
required at the perturbed points  we also evaluate the function at the current point xt  
the starting point is chosen randomly  and the function is evaluated first at this point 
the six reference algorithms the metamax k  and metamax algorithms are compared to the following 
unif  this algorithm selects from a constant number of instances of spsa uniformly 
in our implementation the instance it   t mod k is selected at time t  where k denotes
the number of instances 
thrasc  the threshold ascent algorithm of streeter and smith      b   the algorithm begins with selecting each of a fixed number of instances once  after this phase at
each time step t thrasc selects the best s estimates produced so far by all algorithm
instances ai   i              k in all the previous time steps  and for each ai it counts how
many of these estimates were produced by ai   denoting the latter value by si t   at time
t the algorithm selects the instance with index it   argmaxi u  si t  ni t   ni t    where ni t is
   

fiefficient multi start strategies for local search algorithms

the number of times the ith instance has been selected up to time t 
u    n      

 

p
 n    
n

and    ln  t k    s and  are the parameters of the algorithm  and in the experiments
the best value for s appeared to be      while  was set to       we note that threshold
ascent has been developed for the maximum k armed bandit problem  nevertheless  it
provides sufficiently good performance in our setup to test it in our experiments 
rand  the random search algorithm  it can be seen as running a sequence of spsa
algorithms such that each instance is used for exactly one step  which is the evaluation of
the random starting point of the spsa algorithm 
luby  the algorithm based on the work of luby et al          this method runs several
instances of spsa sequentially after each other  where the ith instance is run for ti steps 
with ti defined by

 k   
if i    k   
ti  
ti k      
if  k   i    k   
the above definition produces a schedule such that from the first  k    algorithm instances
one is run for  k  steps  two for  k  steps  four for  k  steps  and so on 
ee unif  this algorithm is an instance of explore and exploit algorithms  for the first
t    steps the unif algorithm is used for exploration  and  subsequently  in the exploration
phase  the spsa instance that has achieved the highest value in the exploration phase is
selected 
ee luby  this algorithm is similar to ee unif  except that luby is used for exploration 
both versions of the metamax algorithm were tested  motivated by the fact that spsa
is known to converge to a global optimum exponentially fast if f satisfies some restrictive
conditions  gerencser   vago         we chose a hr  n  that decays exponentially fast  to
control the exploration of the so far suboptimal algorithm instances  we allowed hr  n  to
be a time varying function  that is  it changes with tr   the total number of function calls to
evaluate f  or equally  the total number of steps taken  by all algorithms so far  thus  at
round r     we used


hr  n    en 

tr

    

 note that we used the time varying version of hr also in the case of metamax k   the
latter can easily be extended to this situation  but this has been omitted to simplify the
presentation  
for the algorithms with a fixed number of local search instances  metamax k   unif 
ee unif  and thrasc   the number of instances k was set to     in the simulations  as
this choice provided reasonably good performance in all problems analyzed 
the multi start algorithms were tested using two versions of a synthetic function  and
by tuning the parameters of a learning algorithm on two standard data sets 
   

figyorgy   kocsis

the synthetic function was a slightly modified  version of the griewank function  griewank 
      
d
d
y
 xl x     x l
cos  
f  x   
   
l
l  
l  
where x    x            xd   and the xl were constrained to the interval         we show the
results for the   dimensional and the    dimensional cases 
the parameters of spsa were a        and        for the   dimensional case  and
a       and        for the    dimensional case  the performance of the search algorithms
were measured by the error defined as the difference between the maximum value of the
function  in this case    and the best result obtained by the search algorithm in a given
number of steps  the results for the above multi start strategies for the two  and the   dimensional test functions are shown in figure    each error curve is averaged over       
runs  and each strategy was run for         steps  or iterations   one may observe that in
both cases the two versions of the metamax algorithm converge the fastest  thrasc is
better than unif  while luby seems fairly competitive with these two  the two exploreand exploit type algorithms  ee unif and ee luby  have similar performance on the  dimensional function  and clearly better than their non exploiting base algorithms  but on
the    dimensional function their behavior is somewhat pathological in the sense that for low
values of t their performances are the best among all algorithms  but with increasing t   the
error actually increases such that their respective base algorithms achieve smaller errors for
some values of t   the random search seems an option only for the   dimensional function 
similar results were obtained for dimensions between   and     the pathological behavior of
the explore and exploit algorithms start to appear gradually starting from the   dimensional
function  and it is pronounced from   dimensions onwards  limited experimental data
obtained for higher dimensions up to      averaged over only a few hundred runs  shows
that the superiority of metamax is preserved for high dimensional problems as well 
the reason for the pathological behavior of the explore and exploit strategies  i e   why
the error curves are not monotone decreasing in the number of iterations  can be illustrated
as follows  assume we have two spsa instances  one converging to the global optimum
and another one converging to a suboptimal local optimum  assume that in the first few
steps the optimal algorithm gives better result  then the suboptimal algorithm takes over
and reaches its local maximum  while if the algorithms are run even further  the optimal
algorithm beats the suboptimal one  if the exploration is stopped in the first or the last
regime  an explore and exploit algorithm will choose the first  optimal local search instance 
whose performance may get to quite close to the global optimum in the exploitation phase
 even if it is stopped in the first regime   if the exploration is stopped in the middle regime 
the suboptimal search instance will be selected for exploitation  whose performance may
not even get close to the global optimum  in this scenario  the error after the exploitation
phase  i e  at the end  is lower if t is small  and increases with higher values of t   decrease
in the error with increasing t is only assured when the optimal instance converges in the
exploration phase past all suboptimal local optima  which results in selecting the optimal
local search instance for exploitation  in the above scenario the error will decrease fast
   the modification was made in order to have more significant differences between the values of the function
at the global maximum and at other local maxima 

   

fi  

  

 

 

   

   

average error

average error

efficient multi start strategies for local search algorithms

    

     

      

     

      
rand
luby
unif
thrasc
ee luby
ee unif
metamax   
metamax

 e   

 e   

    

 

rand
luby
unif
thrasc
ee luby
ee unif
metamax   
metamax

 e   

  

   

    

     

 e   

      

 

  

iteration

   

    

     

      

iteration

figure    the average error for the multi start strategies on the   dimensional  left  and
   dimensional  right  modified griewank function      confidence intervals are
shown with the same color as the corresponding curves  note that most of the
intervals are very small 
 

   

    

    

average error

average error

   

     

      
rand
luby
unif
thrasc
ee luby
ee unif
metamax   
metamax

 e   

 e   

 

     

      

rand
luby
unif
thrasc
ee luby
ee unif
metamax   
metamax

 e   

  

   

    

     

      

iteration

 e   

 

  

   

    

     

      

iteration

figure    the average error for the multi start strategies on tuning the parameters of multilayer perceptron for the vehicle data set  left  and the letter data set  right  
    confidence intervals are also shown with the same color as the corresponding
curves 

initially  then increase for a while and then it may decrease again till it converges to   
which is quite similar to what we observe in figure    right  this pathological behavior
becomes more transparent if there are many local search algorithms  as the length of the
exploitation phase scales with the number of local search instances if the length of the
exploration for each instance is kept fixed  analyzing the experimental data shows that
more complex versions of the scenario outlined above have occurred in the simulations and
are the main cause of the observed pathological behavior  the non monotonicity of the error
curves  
for tuning the parameters of a learning algorithm  we have used two standard data
sets from the uci machine learning repository  asuncion   newman         vehicle and
   

figyorgy   kocsis

letter  and the multilayer perceptron learning algorithm of weka  witten   frank       
 here the back propagation algorithm is used in the training phase   two parameters were
tuned  the learning rate and the momentum  both in the range of         the size of the
hidden layer for the multilayer perceptron was set to    while the number of epochs to
     the parameters of the spsa algorithm were a       and         the same as for
the    dimensional griewank function  as in the previous experiment  the parameters were
chosen based on our experience   the rate of correctly classified items on the test set for
vehicle using multilayer perceptron with varying values of the two parameters is shown in
figure    with the highest rate being           similarly  the classification rate for letter
is shown in figure    with the highest rate being        
the error rates of the optimized multilayer perceptron on the data sets vehicle and
letter are shown in figure    when the parameters of the learning algorithm were tuned
by the multi start strategies above  the error in these cases is the difference between the
best classification rate that can be obtained           and         respectively  and the
best classification rate obtained by the multi start strategies in a given number of steps 
the results shown are averaged over       runs  we observe that the metamax algorithm
 with an increasing number of algorithm instances  converged fastest in average  the three
strategies with a fixed number of algorithm instances had nearly identical results  luby
 and its explore and exploit variant  was slightly worse than these  and the random search
was the slowest  although it performed not nearly as badly as for the synthetic functions 
the reason why the random search had relatively better performance  relative to those that
used spsa  could be twofold   i  large parts of the error surface offer fairly small error 
and  ii  the error surface is less smooth  and therefore spsa is less successful in using
gradient information  the explore and exploit variants performed well on the vehicle data
set initially  but their performance worsened for larger values of t  compared to metamax 
and to other algorithms to some extent   this  coupled with the observation for figure   
right would suggest that explore and exploit variants are more competitive for small values
of t   despite their asymptotic guarantees 
in summary  the metamax algorithm  with an increasing number of algorithm instances  provided by far the best performance in all tests  usually requiring significantly
fewer steps to find the optimum than the other algorithms  e g   for the letter data set
only the metamax algorithm found the global optimum in all runs in         time steps 
we can conclude that metamax converged faster than the other multi start strategies investigated in all four test cases  with a notable advantage on the difficult surfaces  at least
from a gradient based optimization viewpoint  induced by the classification tasks 
    k means clustering
in this section we consider the problem of partitioning a set of m d dimensional real vectors
xj  rd   j              m into n clusters  where each cluster si is represented by a center  or
reconstruction  point ci  rd   i              n   the cost function to be minimized is the sum
of distances
pn x pci   from the data points to the corresponding centers  that is  we want to
minimize i   xsi  x  ci    there are two necessary conditions for optimality  see  e g  
linde  buzo    gray        gersho   gray         for all i              n  
si    x    x  ci     x  cj   for all j              n  
   

    

fiefficient multi start strategies for local search algorithms

figure    classification rate on the vehicle data set  the rates are plotted by subtracting
them from          and thus global optima are at the scattered black spots
corresponding to a value equal to       

figure    classification rate on the letter data set  the rates are plotted by subtracting them from        and thus global optima are at the scattered black spots
corresponding to a value equal to       

 with ties broken arbitrarily  and
ci   argmin
crd

x

xsi

   

 x  c  

    

figyorgy   kocsis

p

x

 
i
a usual choice for  is the squared euclidean distance  in which case ci   xs
 si     according to the above necessary conditions  the k means algorithm  or generalized lloyd
algorithm  see  e g   linde et al         gersho   gray        alternates between partitioning the data set according to      with the centers being fixed  and recomputing the
centers by      while the partitioning is kept fixed  it can easily be seen that the cost
 or error  cannot increase in any of the above steps  hence the algorithm converges to a
local minimum of the cost function  in practice  the algorithm stops when there is no  or
insufficient  decrease in the cost function  however  the k means algorithm is often trapped
in a local optimum  whose value is influenced by the initial set of centers  as with spsa 
restarting k means with a different initialization may result in finding the global optimum 
we consider two initialization techniques  the first  termed k means  chooses the centers
uniformly at random from the data points  the second  k means    arthur   vassilvitskii 
      chooses an initial center uniformly at random from the data set  and then chooses the
further centers from the data points with a probability that is proportional to the distance
between the data point and the closest center already selected 

the k means algorithm usually terminates after a relatively small number of steps  and
thus multi start strategies with bounded number of instances would run out of active local
search algorithms  and therefore do not appear particularly attractive  however  this is a
natural domain to consider the strategy that starts a new instance  when the previous has
finished  this strategy will be referred subsequently as serial  for the above mentioned
considerations  we test only metamax  the variant of our algorithms applicable for an
unbounded number of instances   as in the experiments with spsa  we used hr as in      
note that some theoretical results indicate that k means may converge at an exponential
rate  in particular  kieffer       showed that the rate of convergence is exponential for
random variables with log concave densities in   dimension provided that the logarithm of
the density is not piecewise affine  
two multi start strategies  serial and metamax were tested for the data set cloud
from the uci machine learning repository  asuncion   newman         the data set
was employed by arthur and vassilvitskii        as well  the number of clusters was set to
ten  the performance of the multi start strategies is defined as the difference between the
smallest cost function obtained by the strategy in a given number of steps and the smallest
cost seen in any of the experiments              the results averaged over       runs are
plotted in figure    with both initialization methods the metamax strategy converges
faster then the serial strategy  we note that for this data set  k means   with its
more clever initialization procedure yields faster convergence than the standard k means
with its uniform initialization  which is consistent with the results presented by arthur and
vassilvitskii        

   an extension to clustering random variables is well known and straightforward  but is omitted here
because in this paper we only consider clustering finite data sets 
   note that in the metamax algorithm we have to do the practical modification that if a local search
algorithm has terminated then it will not be chosen anymore  this clearly improves the performance as
an algorithm is not chosen anymore when no improvement can be observed 

   

fiefficient multi start strategies for local search algorithms

      

     
    
   

average error

average error

     

    

   

  
 
   
    
     

  

      
 

serial kmeans
metamax kmeans

 

  

   

    

     

      

iteration

 e   

serial kmeans  
metamax kmeans  

 

  

   

    

     

      

iteration

figure    the average error for the multi start strategies with k means  left  and kmeans    right       confidence intervals are shown with the same color as
the corresponding curves 

    practical considerations
in all experiments with the metamax algorithm presented above  we observed that the
number of algorithm instances r  shown in figure     grows at a rate of  tr   ln tr    recall
that tr is the total number of function calls to evaluate f   or the total number of steps 
by all algorithm instances by the end of round r   on the other hand  in the derivation of

the theoretical bounds  see theorem    and theorem     we used a bound r    tr   
in contrast to the quadratic penalty suggested by theorem     plugging the  tr   ln tr  
estimate of r into the theorem we would find that only a logarithmic factor more calls
to evaluate f  total number of steps  are needed to achieve the performance of a search
algorithm started from the attraction region of the optimum 
finally  perhaps the main practical question concerning the metamax family of multistart algorithms is to decide when to use them  as a rule of thumb  we have to say that
there should be a sufficiently large performance difference between an average run of
the local search algorithm and the best one  clearly  if a single local search produces an
acceptable result then it is not worth the effort to run several instances of the local search 
especially not with a complicated schedule  in many real problems it is often the case
that it is relatively easy to get close to the optimum  which may be acceptable for some
applications  but approaching the optimum with greater precision is hard  if the latter is of
importance  the metamax algorithm and its variants may be very useful  last  one may
wonder about the computational costs of our algorithms  as it was discussed before  we
consider the case when the evaluation of the target function is very expensive  this is clearly
not the case for the griewank function  which is only used to demonstrate basic properties
of the algorithm  but holds for many of the optimization problems in practice  including
all other experiments considered in this paper  in these problems the function evaluation
is indeed expensive  and depends on the available data   while the overhead introduced
by the metamax algorithms depends on the number of rounds  for the metamax k 
algorithm we have to find the upper convex hull of a set of k points in each round  in
the worst case this can take as long as o k     calculations  but in practice this is usually
   

figyorgy   kocsis

number of algorithm instances   ln t  t

   

griewank  d
griewank   d
vehicle
letter
k means
k means  
min
max

   
   
   
 
   
   
   
   

 

  

   

    

     

      

iteration

figure     number of algorithm instances  r  for metamax  the average number of
instances are shown on the six benchmarks  griewank function     and   dimensional   parameter tuning of multilayer perceptron  on the vehicle and
on the letter data set   and clustering with k means and k means    the
maximum and minimum number of instances over all runs of all benchmarks
are also shown  one can notice that for larger values of tr       tr   ln tr  r 
    tr   ln tr  

much cheaper  as the upper convex hull is determined by the point that corresponds to
the actually best estimate and by the point that corresponds to the least used algorithm 
which requires only o k  computations  or even less  if some special ordering tricks are
introduced  since the target function f is evaluated at least twice in each round  on average
at most o k     computational overhead is needed for each evaluation of f in the worst
case  which is practically reduced to o k   or even less  similar considerations hold for the
metamax   and the metamax algorithms  resulting in an average o r    worst case
overhead for each call to f  in r rounds   which is closer to o r  or even less in practice 
in all examples we considered  apart of the case for the griewank function   this amount
of overhead has been negligible relative to the computational resources needed to evaluate
f at a single point 

   conclusions
in this paper we provided multi start strategies for local search algorithms  the strategies
continuously estimate the potential performance of each algorithm instance in an optimistic
way  by supposing a convergence rate of the local search algorithms up to an unknown
constant  and in every phase resources are allocated to those instances that could converge
to the optimum for a particular range of the constant  three versions of the algorithm
were presented  one that is able to follow the performance of the best of a fixed number of
local search algorithm instances  and two that  with gradually increasing the number of the
local search algorithms  achieve global consistency  a theoretical analysis of the asymptotic
   

fiefficient multi start strategies for local search algorithms

behavior of the algorithms was also given  specifically  under some mild conditions on the
function to be maximized  e g   the set of the values of the local maxima is not dense at
the global maximum   our best algorithm  metamax  preserves the performance of a local
search algorithm for the original function class with at most a quadratic increase in the
number of times the target function needs to be evaluated  asymptotically   simulations
demonstrate that the algorithms work quite well in practice 
while the theoretical bound suggests that the target function has to be evaluated a
quadratic factor more times to achieve the performance of a search algorithm that is started
from the attraction region of the optimum  in the experiments we found only a logarithmic
penalty  it is not clear whether this difference is the result of our slightly conservative
 asymptotic  analysis or the choice of the experimental settings  also  a finite sample
analysis of the algorithm is of interest  as the experiments indicate that the metamax
algorithm provides good performance even for a relatively small number of steps taken by
the local search algorithms  in the sense that it provides a speed up compared to other
approaches even if the number of times the target function can be evaluated  i e   the total
number of steps that can be taken by all algorithms together  is relatively small  finally 
future work is needed to clarify the connection between the convergence rate of the optimal
algorithms  g   and the function hr used in the exploration 

acknowledgments
the authors would like to thank the anonymous referees for their numerous insightful
and constructive comments  this research was supported in part by the mobile innovation
center of hungary  by the national development agency of hungary from the research and
technological innovation fund  ktia otka cnk         and by the pascal  network
of excellence  ec grant no           parts of this paper were presented at ecml     
 kocsis   gyorgy        

appendix a  proof of lemma  
bn    since un    almost everywhere on e  egoroffs
fix          and let un   f  f  x
theorem  see  e g  ash   doleans dade        implies that there is an event e  e with
   p  e      such that un    uniformly almost everywhere on e   the second part of
the lemma follows from the definition of uniform convergence 
 

references
adam  k          learning while searching for the best alternative  journal of economic
theory              
arthur  d     vassilvitskii  s          k means    the advantages of careful seeding  in
proceedings of the   th annual acm siam symposium on discrete algorithms  pp 
         
ash  r  b     doleans dade  c  a          probability   measure theory  academic press 
   

figyorgy   kocsis

asuncion  a     newman  d  j          uci machine learning repository 
auer  p   cesa bianchi  n     fischer  p          finite time analysis of the multiarmed
bandit problem  machine learning                   
bartz beielstein  t          experimental research in evolutionary computation  the
new experimentalism  natural computing series  springer  new york 
battiti  r   brunato  m     mascia  f          reactive search and intelligent optimization 
vol     of operations research computer science interfaces  springer verlag 
beck  c  j     freuder  e  c          simple rules for low knowledge algorithm selection 
in regin  j  c     rueher  m   eds    cpaior  lecture notes in computer science
      pp        springer 
carchrae  t     beck  j  c          low knowledge algorithm control  in proceedings of
the nineteenth national conference on artificial intelligence  aaai   pp       
cicirello  v  a     smith  s  f          heuristic selection for stochastic search optimization 
modeling solution quality by extreme value theory  in in proceedings of the   th
international conference on principles and practice of constraint programming  pp 
        springer 
cicirello  v  a     smith  s  f          the max k armed bandit  a new model of exploration
applied to search heuristic selection  in in proceedings of the twentieth national
conference on artificial intelligence  pp           
finkel  d  e     kelley  c  t          convergence analysis of the direct algorithm  tech 
rep  crsc tr       ncsu mathematics department 
gagliolo  m     schmidhuber  j          learning dynamic algorithm portfolios  annals of
mathematics and artificial intelligence                   ai math      special
issue 
gagliolo  m     schmidhuber  j          learning restart strategies  in veloso  m  m   ed   
ijcai       twentieth international joint conference on artificial intelligence 
vol     pp          aaai press 
gagliolo  m     schmidhuber  j          algorithm selection as a bandit problem with
unbounded losses  in blum  c     battiti  r   eds    learning and intelligent optimization  vol       of lecture notes in computer science  pp        springer
berlin heidelberg 
gerencser  l     vago  z          the mathematics of noise free spsa  in proceedings of
the ieee conference on decision and control  pp           
gersho  a     gray  r  m          vector quantization and signal compression  kluwer 
boston 
griewank  a  o          generalized descent for global optimization  journal of optimization theory and applications           
hart  p   nilsson  n     raphael  b          a formal basis for the heuristic determination
of minimum cost paths  systems science and cybernetics  ieee transactions on 
               
   

fiefficient multi start strategies for local search algorithms

hoos  h  h     stutzle  t          towards a characterisation of the behaviour of stochastic
local search algorithms for sat  artificial intelligence              
horn  m          optimal algorithms for global optimization in case of unknown lipschitz
constant  journal of complexity               
hutter  f   hoos  h  h   leyton brown  k     stutzle  t          paramils  an automatic
algorithm configuration framework  journal of artificial intelligence research         
       
jones  d  r   perttunen  c  d     stuckman  b  e          lipschitzian optimization without
the lipschitz constant  journal of optimization theory and applications             
    
kautz  h   horvitz  e   ruan  y   gomes  c     selman  b          dynamic restart policies  in proceedings of the eighteenth national conference on artificial intelligence
 aaai   pp         
kieffer  j  c          exponential rate of convergence for lloyds method i  ieee trans 
inform  theory  it            
kocsis  l     gyorgy  a          efficient multi start strategies for local search algorithms 
in buntine  w   grobelnik  m   mladenic  d     shawe taylor  j   eds    machine
learning and knowledge discovery in databases  vol       of lecture notes in computer science  pp          springer berlin heidelberg 
linde  y   buzo  a     gray  r  m          an algorithm for vector quantizer design  ieee
transactions on communications  com          
luby  m   sinclair  a     zuckerman  d          optimal speedup of las vegas algorithms 
information processing letters             
mart  r   moreno vega  j     duarte  a          advanced multi start methods  in gendreau  m     potvin  j  y   eds    handbook of metaheuristics   nd edition    edition  
springer 
nesterov  y          introductory lectures on convex optimization  a basic course 
kluwer academic publishers 
ribeiro  c   rosseti  i     vallejos  r          on the use of run time distributions to evaluate
and compare stochastic local search algorithms  in stutzle  t   birattari  m     hoos 
h   eds    engineering stochastic local search algorithms  designing  implementing
and analyzing effective heuristic s  vol       of lecture notes in computer science 
pp        springer berlin heidelberg 
spall  j   hill  s     stark  d          theoretical framework for comparing several stochastic
optimization approaches  in calafiore  g     dabbene  f   eds    probabilistic and
randomized methods for design under uncertainty  chap     pp         springerverlag  london 
spall  j  c          multivariate stochastic approximation using a simultaneous perturbation
gradient approximation  ieee transactions on automatic control             
spall  j  c          implementation of the simultaneous perturbation algorithm for stochastic optimization  ieee transactions on aerospace electronic systems             
   

figyorgy   kocsis

streeter  m  j     smith  s  f       a   an asymptotically optimal algorithm for the max
k armed bandit problem  in proceedings  the twenty first national conference on
artificial intelligence and the eighteenth innovative applications of artificial intelligence conference  pp         
streeter  m  j     smith  s  f       b   a simple distribution free approach to the max
k armed bandit problem  in principles and practice of constraint programming cp         th international conference  cp       nantes  france  september       
      proceedings  pp         
vilalta  r     drissi  y          a perspective view and survey of meta learning  artificial
intelligence review               
witten  i  h     frank  e          data mining  practical machine learning tools and
techniques   nd edition   morgan kaufmann  san francisco 
zabinsky  z  b   bulger  d     khompatraporn  c          stopping and restarting strategy
for stochastic sequential search in global optimization  j  of global optimization 
               

   

fi