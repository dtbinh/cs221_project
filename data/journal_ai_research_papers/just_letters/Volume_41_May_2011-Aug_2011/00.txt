journal of artificial intelligence research               

submitted          published        

properties of bethe free energies and message passing
in gaussian models
botond cseke
tom heskes

b cseke science ru nl
t heskes science ru nl

institute for computing and information sciences
faculty of science  radboud university nijmegen
heyendaalseweg           aj  the netherlands

abstract
we address the problem of computing approximate marginals in gaussian probabilistic
models by using mean field and fractional bethe approximations  we define the gaussian fractional bethe free energy in terms of the moment parameters of the approximate
marginals  derive a lower and an upper bound on the fractional bethe free energy and
establish a necessary condition for the lower bound to be bounded from below  it turns out
that the condition is identical to the pairwise normalizability condition  which is known to
be a sufficient condition for the convergence of the message passing algorithm  we show
that stable fixed points of the gaussian message passing algorithm are local minima of
the gaussian bethe free energy  by a counterexample  we disprove the conjecture stating
that the unboundedness of the free energy implies the divergence of the message passing
algorithm 

   introduction
one of the major tasks of probabilistic inference is calculating marginal posterior probabilities of a set of variables given some observations  in case of gaussian models  the
computational complexity of computing marginals might scale cubically with the number of
variables  while for models with discrete variables it often leads to intractable computations 
computations can be made faster or tractable by using approximate inference methods like
the mean field approximation  e g   jaakkola        and the bethe type approximation  e g  
yedidia  freeman    weiss         these methods were developed for discrete probabilistic
graphical models  but they are applicable to gaussian models as well  however  there are
important differences in their behavior for the discrete and gaussian cases  for example 
while in discrete models the error function of the bethe approximationcalled bethe free
energyis bounded from below  heskes        watanabe   fukumizu         in gaussian
models this might not always the case  welling   teh        
an understanding of properties of the bethe free energy of gaussian models might
also be help to understand the properties of the energy function in conditional gaussian
models  conditional gaussian or hybrid graphical models  such as switching kalman filters
 zoeter   heskes         combine both discrete and gaussian variables  approximate
inference in these models can be carried out by expectation propagation  e g   minka       
      which can be viewed as a generalization of the bethe approximation  where the
marginal consistency constraints on the approximate marginals are replaced by expectation
constraints  heskes  opper  wiegerinck  winther    zoeter         in order to understand
c
    
ai access foundation  all rights reserved 

ficseke   heskes

the properties of the bethe free energy of hybrid models  a good understanding of the two
special cases of discrete and gaussian models is needed  while the properties of the bethe
free energy of discrete models have been studied extensively in the last decade and are well
understood  yedidia et al         heskes        wainwright  jaakkola    willsky       
watanabe   fukumizu         the properties of the gaussian bethe free energy have been
studied much less 
the message passing algorithm is a well established method for finding the stationary
points of the bethe free energy  yedidia et al         heskes         it works by locally
updating the approximate marginals and has been successfully applied in both discrete  e g  
murphy  weiss    jordan        wainwright et al         and gaussian models  e g   weiss
  freeman        rusmevichientong   roy        malioutov  johnson    willsky       
johnson  bickson    dolev        nishiyama   watanabe        bickson         gaussian
message passing is the simplest case of a free energy based message passing algorithm on
models with continuous variables  therefore  it is important to understand its behavior 
gaussian message passing has many practical applications like in distributed averaging
 moallemi   roy         peer to peer rating  linear detection  svm regression  bickson 
      and more generally in problems that involve solving large sparse linear systems or
approximating the marginal variances of large sparse gaussian systems typically encountered in distributed computing settings  for further applications the reader is referred to
the work of bickson        and references therein 
finding sufficient conditions for the convergence of message passing in gaussian models
has been successfully addressed by many authors  using the computation tree approach 
weiss and freeman        proved that message passing converges whenever the precision
matrixinverse covarianceof the probability distribution is diagonally dominant    with
the help of an analogy between message passing and walksum analysis   malioutov et al  
      derived the stronger condition of pairwise normalizability    a different approach was
taken by welling and teh         who directly minimized the bethe free energy with regard
to the parameters of approximate marginals  conjecturing that gaussian message passing
converges if and only if the free energy is bounded from below  their experiments showed
that message passing and direct minimization either converge to the same solution or both
fail to converge  we adopt a similar approach  that is  instead of analyzing the properties
of the gaussian message passing algorithm using approaches like in weiss and freeman or
malioutov et al   we choose to study the properties of the gaussian bethe free energy and
its stationary points  this will help us to draw conclusions about the existence of local
minima  the possible stable fixed points to which message passing can converge 
this paper is structured as follows  in section   we introduce gaussian markov random
fields and the message passing algorithm  in section   we define the gaussian fractional
bethe free energies parameterized by the moment parameters of the approximate marginals
and derive boundedness conditions for them  these two sections are based on the authors
earlier work  cseke   heskes         in section   we analyze the stability properties of the
gaussian message passing algorithm and  using a similar line of argument as watanabe and
p
   the matrix a is diagonally dominant if  aii     j  i  aij   for all i 
   following the work of malioutov et al          we call a gaussian distribution pairwise normalizable
if it
q
can be factorized into a product of normalizable pair factors  that is  p x            xn     ij ij  xi   xj  
such that all ij s are normalizable 

 

fibethe free energies and message passing in gaussian models

fukumizu         we show that its stable fixed points are indeed local minima of the bethe
free energy  we conclude the paper with a few experiments in sections   and   supporting
our results and their implications 

   approximating marginals in gaussian models
the probability density of a gaussian random vector x  rn is defined in terms of canonical
parameters h and q as


  t
t
p x   exp h x  x qx  
   
 
where q is s positive definite matrix  the expectation m and the covariance v of x is
then given by m   q  h and v   q  respectively  in many real world applications the
matrix q is sparse with and it typically has low density  that is  the number of non zero
elements in q scales with the number of variables n 
this probability density can also be defined in terms of an undirected probabilistic
graphical model commonly known as gaussian markov random field  gmrf   since the
interactions between the variables in p are pairwise  we can associate the variables xi to the
nodes v  v               n  of an undirected graph g    v  e   where the edges e  e  v v
of the graph stand for the non zero off diagonal elements of q  we use i  j as a proxy for
 i  j   e  by using the notation introduced above  the density p in     can be written as
the product
y
p x  
ij  xi   xj  
   
ij

of gaussian functions ij  xi   xj    also called potentials  associated with the edges e    i  j 
of the graph  if h and q are given then we can define the potentials as
j
j
i
i
ij  xi   xj     exp  ij
hi xi   ij
hj xj  ij
qii x i     ij
qjj x j     qij xi xj    

p
p
j
i
where
ij ij     and
ji ij     are partitioning h and q into the corresponding
factors  in practice  however  the factors ij might be given by the problem at hand and
i and  j computed by summing their parameters and computing the
h and q as well as ij
ij
partitioning respectively  without loss of generality  we can and we will use qii      since
the results in the paper can be easily re formulated for general qs by a rescaling of the
variables  e g   malioutov et al         
the numerical calculation of all marginals  can be done by solving the linear system
m   q  h and performing a sparse cholesky factorization llt   q followed by solving the takahashi equations  takahashi  fagan    chin         an alternative option to
calculate the marginal means and to approximate marginal variances is to run the gaussian message passing algorithm in the probabilistic graphical model associated with the
representation in      the gaussian message passing algorithm is the gaussian variant
of message passing algorithm  pearl         which is a dynamical programming algorithm
introduced to compute marginal densities in discrete probabilistic models with pairwise interactions and tree structured graphs g  however  it turned out that by running it in loops
on graphs with cycles  it yields good approximations of the marginal distributions  murphy
et al          weiss and freeman        showed that when the gaussian message passing
 

ficseke   heskes

figure    an illustration of the incoming and outgoing messages at adjacent nodes i and j 

algorithm is converging  it computes the exact mean parameters m  thus it can also be
used for solving linear systems  e g   bickson         message passing works by updating
and passing directed messages along the edges of the graph g  which  in case the algorithm
converges  are then used to compute  approximate  marginal probability distributions  the
gaussian and the discrete algorithms have the same functional form with the exception of
the summation  discrete case  and integration operators  gaussian case   each message
ij  xi   is updated according to
z
y
new
ij  xi     dxj ij  xi   xj  
jk  xj    
   
kj i

where i    j   j  i  denotes the index set of variables connected to xi in g  at each step
the current approximations qij  xi  j   of p xi   xj   can be computed according to
qij  xi   xj    ij  xi   xj  

y
li j

il  xi  

y

jk  xj    

   

kj i

the update steps in     have to be iterated until convergence  the corresponding qij  xi   xj  s
yield the final approximation of the p xi   xj  s  it is common to use damping  that is 
  new  x   with           in practice  this helps to
to replace new
ij  xi   by ij  xi  
ij i
dampen the possible periodic paths of      but it keeps the properties of the fixed points
unchanged  figure   illustrates the incoming and outgoing messages at the nodes associated
with variables xi and xj   a quite significant difference between the discrete and gaussian
the message passing is the replacement of the sum operator with the integral operator 
while finite sums always exist  the integral in     can become infinite  this problem can
be remedied technically by a canonical parameterization  see section    which keeps the
algorithm running  but it can lead to non normalizable approximate marginals qij   and thus
a  possible  break down of the algorithm 
message passing was introduced by pearl        as a heuristic algorithm  in discrete
models   however  yedidia et al         showed that it can also be viewed as an algorithm for
 

fibethe free energies and message passing in gaussian models

finding the stationary points of the so called bethe free energy  an error function measuring
the difference between p and a specific family of distributions to be detailed in the next
section  it has been shown by heskes        and later in a different way by watanabe and
fukumizu        that stable fixed points of the  loopy  message passing algorithm are local
minima of the corresponding bethe free energy  in this paper we show that this holds for
gaussian models as well 
our interest in the properties of the gaussian bethe free energy and the corresponding gaussian message passing algorithm is motivated mainly by their implications in more
general models and inference algorithms like non gaussian models and expectation propagation  respectively  for this reason  we will not compare the speed of the method and the
accuracy of the approximation with the above mentioned exact linear algebraic methods 
as mentioned in the introduction  the approach we take is similar to that of welling and
teh         that is  we study the properties of the gaussian bethe free energy  parameterized
in terms of the moment parameters of the approximate marginals  in the following we
introduce the mean field and the bethe approximation in gaussian models  readers familiar
with this subject can continue with section   
    the gaussian bethe free energy
a popular method to approximate marginals is approximating p with a distribution q having
a form that makes marginals easy to identify  for example  it factorizes or it has a treelike form  the most common quantity to measure the difference between two probability
distributions is the kullback leibler divergence d  q    p   it is often used to characterize the
quality of the approximation and formulate the computation of approximate marginals as
the optimization problem


z
q x 

q  x    argmin dx q x  log
 
   
p x 
qf
here  f is the set of distributions with the above mentioned form  since it is not symmetric 
the kullback leibler divergence is not a distance  but d  q    p     for any proper q and p 
d  q    p      if and only if p   q  and it is convex both in q and p 
a family f of densities possessing a form that
q makes marginals easy to identify is the
family of distributions that factorize as q x    k qk  xk    in other words  in problem     we
approximate p with a distribution that has independent variables  an approximation q of
thisqtype is called mean field approximation  e g   jaakkola         defining fmf   qk     
d   qk    p  and writing out the right hand side of     in detail  one gets
z
fmf   qk      

dx

y

qk  xk   log p x   

k

xz

dxk qk  xk   log qk  xk   

k

using the parameterization qk  xk     n  xk  mk   vk    m    m            mn  t and v    v            vn  t  
this reduces to
 
 x
 x
fmf  m  v    ht m   mt qm  
qkk vk 
log vk     cmf  
 
 
 
k

 

k

ficseke   heskes

q
where cmf is an irrelevant constant  although d   k qk    p  might not be convex in
 q            qn    one can easily check that fmf is convex in its variables m and v and its
minimum is obtained for m   q  h and vk     qkk   since

 
   

 
q kk   qkk  qtk  k q k  k
q k k
 
one can easily see that the mean field approximation underestimates variances  the mean
field approximation computes a solution in which the means are exact  but the variances are
computed as if there were no interactions between the variables  namely  as if the matrix
q were diagonal  thus giving poor estimates of the variances 
in order to improve the estimates for variances  one has to choose approximating distributions q that are able to capture dependencies between the variables in p  it can be
verified that any distribution in which the dependencies form a tree graph can be written
in the form
y p xi   xj   y
p x   
p xk   
p xi  p xj  
ij

k

where i and j run through the edges  i  j  of the tree and k through the nodes            n 
although in most cases the undirected graph generated by the non zero elements in q is
not a tree  based on the tree intuition one can construct q from one and two variable
marginals as
y qij  xi   xj   y
q x  
qk  xk  
   
qi  xi  qj  xj  
ij

k

andr constrain the functions qij and qk to be marginally
consistent and normalize to    that
r
is  dxj qij  xi   xj     qi  xi   for any i  j and dxk qk  xk       for any k  an approximation
of the form     together with the constraints on qij s and qk s is called a bethe approximation 
let us denote the family of such functions by fb   by choosing qij  xi   xj     qi  xi  qj  xj   one
can easily check that fmf  fb   thus fb is non empty  assuming that the approximate
marginals are correct and q normalizes to   and then substituting     into      we get an
approximation of the kullbackleibler divergence in     called the bethe free energy 
due to the factorization of p  we can write the bethe free energy as
xz
fb   qij   qk      
dxi j qij  xi j   log ij  xi j  
   
ij

 

xz
ij



 xz
qij  xi j  
dxi j qij  xi j   log
 
dxk qk  xk   log qk  xk   
qi  xi  qj  xj  
k

one can also define the free energy through the bethe approximation
z
xz
dx q  x  log q  x  
dxi j q  xi j   log q  xi j  
ij

 

x
k

 

z
    nk  

dxk q  xk   log q  xk  

fibethe free energies and message passing in gaussian models

of the entropy  e g   yedidia et al         and substitute the marginals with functions qij and
qrk that normalize to one and are connected through the marginal consistency constraints
dxj qij  xi   xj     qi  xi   
from the stationary conditions of the lagrangian corresponding to the fractional bethe
free energy     and the marginal consistency and normalization constraints  one can derive
the same iterative algorithm as in     for the corresponding lagrange multipliers of the
consistency constraints  yedidia et al          similarly  approximate marginals can then
be computed according to      it can be shown that there is a one to one correspondence
between the stationary points of the bethe free energy     and the fixed points of the
message passing algorithm      later  in section   we will link the stable fixed points of    
to the local minima of     
    fractional free energies and the message passing algorithm
as mentioned in the introduction  in case of gaussian models the message passing algorithm
does not always converge  the reason for this appears to be that the approximate marginals
may get indefinite or negative definite covariance matrices  welling and teh        pointed
out that this can be due to the unboundedness of the bethe free energy 
since fmf is convex and bounded and the bethe free energy might be unbounded  it
seems plausible to analyze the fractional bethe free energy
xz
f   qij   qk      
dxi j qij  xi j   log ij  xi j  
   
ij


 xz
x   z
qij  xi j  
 
dxi j qij  xi j   log
 
dxk qk  xk   log qk  xk   
ij
qi  xi  qj  xj  
ij

k

introduced by wiegerinck and heskes         here   denotes the set of positive reals  ij   
they showed that the fractional bethe free energy interpolates between the mean field
and the bethe approximation  that is  for ij     we get the bethe free energy  while in the
case when all ij s tend to    the mutual information between variables xi and xj is highly
penalized  therefore      enforces solutions close to the mean field solution  they also showed
that the fractional message passing algorithm derived from     can be interpreted as pearls
message passing algorithm with the difference that instead of computing local marginals
like in pearls algorithmone computes local ij marginals   the local ij marginals
correspond to true local marginals when ij     and to local mean field approximations
when ij      the resulting algorithm is called the fractional message passing algorithm
and the message updates are defined as
z
y

new
 x
 
 
dxj ij  xi   xj  
jk  xj   ji  xj     
   
ij i
kj i

while the approximate marginals are computed according to
y
y
qij  xi   xj    ij  xi   xj  
il  xi   ij  xi   
jk  xj   ji  xj     
li j

    

kj i



q
   we define the marginals of a distribution p as argmin qk   d p k qk   where d is the divergence
k
r

r
r
d  p    q    dxp x  q x      dxp x          dxq x          e g   minka        

 

ficseke   heskes

power expectation propagation by minka        is an approximate inference method
that uses local approximations with divergences  in case of gaussian models power
expectation propagationwith a fully factorized approximating distributionleads to the
same message passing algorithm as the one derived from     and the appropriate constraints 
starting from the idea of creating an upper bound on the log partition function when p and
q are exponential distributions  wainwright et al         derived a form of     where the
ij s are chosen such that this bound is convex in  qij   qk   
message passing works well in practice  however  there are other ways to find the local
minima of the fractional free energies like the direct minimization w r t  some parameterization of the approximate marginals qij and qk  welling   teh         the latter method is
slower but more likely to converge  in the following we analyze the bethe free energy when
expressed in terms of the moment parameters of the approximate marginals qij   later in
section   we analyze the stability conditions of the fractional message passing algorithm
and by expressing these conditions in term of the moment parameters of the approximate
marginals  we show that stable fixed points of the fractional gaussian message passing are
local minima of the fractional bethe free energy 

   bounds on the gaussian bethe free energy
in this section we analyze the parametric form of      we show that the fractional gaussian bethe free energy is a non increasing function of   by letting all ij tend to infinity  we obtain a lower bound for the free energies  it turns out that the condition for
the lower bound to be bounded from below is the same as the pairwise normalizability
condition in the work of malioutov et al         
as mentioned in section    without loss of generality  we can work with a unit diagonal q  we define r to be a matrix with zeros on its diagonal and q   i   r 
where i is the identity matrix   r  will be the matrix formed by the absolute values
of rs elements  we use the moment parameterization qij  xi j     n  xi j  mij   vij   and
i   v   v   v j    with v   v  
qk  xk     n  xk  mk   vk    where mij    miij   mjij  t and vij    vij
ij
ji ij
ij
ji
i   mi and v  v i   v k for all i  j and i  k  we embed the
by using mi  m
i
ij
ik
ik
r ij
r
marginalization   dxj qij  xi   xj     qi  xi   for all i  j  and normalization   dxj qj  xj       
constraints into the parameterization  with a slight abuse of notation the matrix formed
by diagonal elements vk and off diagonal elements vij is denoted by v  we can take vij    
for all i  j   the vector of means by m    m            mn  t and the vector of variances by
v    v            vn  t   substituting qij and qk into     one gets
 
 
f  m  v      ht m   mt qm   tr qt v  
 
   
 
x
v
 
 
 x
ij

log   

log  vk     c 
 
ij
vi vj
 
ij

    

k

where c is an irrelevant constant  note that the variables m and v are independent  hence
the minimizations of f  m  v   with regard to m and v can be carried out independently 
 

fibethe free energies and message passing in gaussian models

property    f  m  v   is convex and bounded in  m   vij  i  j   and at any stationary point
we have
m   q  h
vij



p
      ij rij    vi vj   
  sign rij  
 
 ij  rij  

    

proof  q is positive definite by definition  therefore  the quadratic term in m is convex
and bounded  the variables m and v are independent and the minimum with regard
to m is achieved at m   q  h  one can check that the second order derivative of
f  m  v   with regard to vij is non negative and the first order derivative has only one
   v v   since the variables v are independent  one can conclude
solution when vi vj  vij
i j
ij
that f  m  v   is convex in vij   from the independence of m and v   it follows that f is
convex in  m   vij  i  j   

    thus the
since the vij s are constrained to be covariance matrices  we have vi vj   vij
first logarithmic term in      is negative  as a consequence 

f   m  v    f   m  v  

for any

          

where      is taken element by element  this observation leads to the following
property 
property    with ij     f is a non increasing function of  
 into f we define the constrained function
using property   and substituting vij

 
 x
fc  m  v    ht m   mt qm  
vk
 
 
k
q

 x  
      ij rij    vi vj   

 

ij ij
 
p
      ij rij    vi vj   
  x  

log  
 
ij
  ij rij    vi vj
n i j 

 x

log vk     c c  
 

    

k

where c c is an irrelevant constant  from property    it follows that when choosing ij    
the function in      is a non increasing function of   it then makes sense to take   
and verify whether we can get a lower bound for      
lemma    for any v              and      the following inequalities hold 


fmf  m  v   fc   m  v   fb m   vij
   v


fb m   vij
   v  fc   m  v       

  t
       fmf  m  v  
v  r  v
 
moreover  they are tight  that is 


lim f m   vij
     v   fmf  m  v 
 

 

ficseke   heskes

and



  t

v  r  v 
lim f m   vij
     v   fmf  m  v  
 
proof  since the bethe free energy is the specific case of the fractional bethe free energy for
      v  follow from property    now  we show that
      the inequalities on fb  m   vij
the upper and lower bounds are tight  the function      x          behaves as    x  in the
neighborhood of    therefore 


v      
log    ijvi vj
     
vij
 

lim
lim vij
      
and
lim
 
    
 
 

vi vj   


showing that fmf  m  v  is a tight upper bound 
as  tends to infinity  we have
p
      rij    vi vj   
 
   rij   vi vj
lim

 
and
 
log
lim
 

 
p
      rij    vi vj   
    
  rij    vi vj

yielding a tight lower bound


  t

v  r  v 
lim f m   vij
     v   fmf  m  v  

 



let max   r   be the largest eigenvalue of  r   analyzing the boundedness of the lower
bound  we arrive at the following theorem 
theorem    for the fractional bethe free energy in      corresponding to a connected
gaussian model  the following statements hold
    if max   r        then f is bounded from below for all      
    if max   r        then f is unbounded from below for all      
p p  
    if max   r        then f is bounded from below if and only if
ij   n 
i ij

proof  since in f there is no interaction between the parameters m and v and the term
depending on m is bounded from below due to the positive definiteness of q  we can simply
neglect this term when analyzing the boundedness of f   let us write out in detail the
lower bound of the fractional bethe free energies in the form

  t
v  r  v  
 

  t
 
  t  
m q m  ht m  
v  i   r   v   t log v    const 
 
 
 

fmf  m  v  

    

statement      the condition max   r       implies that i   r  is positive definite  now 
  

fibethe free energies and message passing in gaussian models

 t
 t




log x   x     thus    v  i   r   v   t log  v      v  i   r   v   t v   n 
the latter is bounded from below and so it follows that      is bounded from below as
well  according to lemma    the boundedness of      implies that all fractional bethe free
energies are bounded from below 
statement      we assumed that the gaussian network is connected and undirected  according to the perron frobenius theory of non negative matrices  e g   horn   johnson 
        r  has a simple maximal eigenvalue max   r   and all elements of the eigenvector umax corresponding to it are positive  let us take the fractional bethe free energy

and analyze its behavior when v   tumax and t    for large values of t we have
       ij rij     uimax ujmax    t          ij  rij  uimax ujmax t    therefore  the sum of the second
and third term in      simplifies to     max   r   t  and this term dominates over the
logarithmic ones as t    as a result  the limit is independent of the choice of ij and it
tends to  whenever max   r       
statement      if max   r        then the only direction in which the quadratic term will

not dominate is v   tumax   therefore  we have to analyze the p
behavior of the loga 
rithmic terms in      when t    for large ts these behave as   ij ij
  n  log t  
c
for this reason  the boundedness of f and thus of f depends on the condition in
statement     

it was shown by malioutov et al         that the condition max   r       is an equivalent
condition to pairwise normalizability  therefore  pairwise normalizability is not only a
sufficient condition for the message passing algorithm to converge  but it is also a necessary
condition for the fractional gaussian bethe free energies to be bounded  using lemma    we
can show that for a suitably chosen      there always exists an  such that the constrained
fractional free energy fc possesses a local minimum for any          property a  in
section a of the appendix  
example in the case of models with an adjacency matrix  non zero entries of r  corresponding to a kregular graph  and equal interaction weights rij   r  the maximal eigenvalue of  r  is max   r     kr and the eigenvector corresponding to this eigenvalue is   
 we define   as the vector that has all its elements equal to     the model is symmetric
and by verifying the stationary point conditions  it turns out that for some choice of r and
 there exists a local minimum  which also lies in the direction    one can show that when
the model is not pairwise normalizable  kr       the critical r below
p which the fractional
bethe free energy possesses this local minimum is rc  k           k    and for any
valid r the critical  below which
p the fractional bethe free energies possesses this local
minimum is c  k  r       k          kr      these results are illustrated in figure   
 note that for  regular graphs  all valid models are pairwise normalizable and possess a
unique global minimum  

for kregular graphs  the convexity of the fractional bethe free energy in terms of
 qij   qk   requires   k  a much stronger condition than   c  k  r   thus  if we choose
 sufficiently large such that the bethe free energy is guaranteed to have a unique global
minimum  this minimum is unbounded 

   a kregular graph is a graph in which all nodes are connected to k other nodes 

  

ficseke   heskes

 

  

 

 

  

                
  d           
     
   vtuwff fi
   

 

                   

                   

 

  

     



  

 

  



  

 

                
  d           
           
    

  

                   


  

 

  

 





  



  

 

  
m

 

  

  



 



  

  



  

 

  
m

 

  



  

figure    visualizing critical parameters for a symmetric k regular gaussian model with rij   r 
plots
in the left panel correspond to the constrained fractional bethe free energies fc for

v     for an   node  regular gaussian model with r       kr      and varying
 

plots in the right panel correspond to the constrained bethe free energies f c for v    
in an   node  regular gaussian model with varying r  here  rvalid is the supremum of
rs for which the model is valid  that is  q is positive definite 

this example disproves the conjecture by welling and teh         that is  even when
the bethe free energy is not bounded from below  it can possess a finite local minimum to
which the message passing and the minimization algorithms can converge 

   the message passing algorithm in gaussian models
in this section  we turn our attention towards the properties of the message passing algorithm in gaussian models  following a similar line of argument as watanabe and fukumizu
       we show that stable fixed points of the message passing algorithm correspond to local
minima of the bethe free energy  we use the moment parameterization introduced in the
previous sections  the way we proceed is the following      we make a linear expansion of
message passing iteration at a fixed point      we express the linear expansion in terms of
moment parameters corresponding to the fixed point and finally     we connect the properties of the latter with the properties of the hessian of the bethe free energy by using the
matrix determinant lemma 
the form of the equation     implies that the messages ij  xi   are univariate gaussian
functions  thus we can express them in terms of two scalar  canonical  parameters ij and
ij such that log ij  xi     ij x i      ij xi   ijj   where the ij s are irrelevant constants 
when expressed in terms of ij and ij   the damped message passing algorithm     translates
  

fibethe free energies and message passing in gaussian models

to
j
hj  
ij


new
ij

 

     ij  

p

jk        ji



  i
kj i

p
ij hi  rij

j

ij
 
jk        ji

    

kj i



new
ij

 

  
x
  i

j
  
   rij
ij
 
jk        ji  
     ij   ij



kj i

    
i    j   h and r are parameters of  as in section      with r   q and the
where ij
i
ij
ij
ij
ij
ij
assumption that qii      the approximate marginals qij in      might not be normalizable 
but the message passing iteration in      and      stays well defined unless there is a zero
in the denominator on the rhs  this rarely happens in practice  however  it is more
common that message passing converges while there are some intermediate steps at which
the approximate marginals qij are not normalizable  this can often be remedied by choosing
an appropriate damping parameter  
the iteration      for the ij s is independent of ij s and the iteration      for the ij s
is linear in ij   it is interesting to see that when h     neither the constrained bethe
free energy      nor the message passing algorithm      depend on the sign of rij   these
are only relevant to compute the meanswhen h     and the signs of the correlations
in       as a result  the marginal variances computed by either minimizing the bethe free
energy or by running the message passing algorithm can only depend on  r   similarly to
the constrained fractional free energy fc  

    stability of the gaussian message passing algorithm
in the following we analyze the stability of the message passing iteration at its fixed points 
that is  at the stationary points of the lagrangian corresponding to the constrained minimization of the gaussian bethe free energy  we reiterate that we use g    v  e  to denote
the graph corresponding to q  namely  v               n  and e     i  j    qij        the vector   r e    corresponding to a set of messages  ij  ij   is composed by the concatenation
of ij s such that ij is followed by ji and the  ij  ji  blocks follow a lexicographic order w r t 
ij and i   j  the vector  consists of the variables ij and follows a similar structure as  
j
we define r  h    r e  as rij   rji   rij   hij   hj and ij   ij
  we also define the
 e    e  matrix

  if j   k

    if kl   ji
mij kl    

  otherwise
which encodes the weighted edge adjacency corresponding to g and   the number of nonzero elements in m    scales roughly with nnzeros  q    n  where nnzeros  q  denotes
the number of non zeros in q  since the parallel message update given equations      and
     can be rewritten in terms of two matrix vector multiplications and element by element
operations on vectors  the computational complexity of an update also scales as roughly
with nnzeros  q    n 
  

ficseke   heskes

with this notation  the local linearization of the update equations      and      can be
written as
   new   new  
            i      
     






 h m  
 
diag r  m   m   diag r   m     m  

 


  
 

 
diag   r     m   
m  
 

    

where all operations on vectors are element by element  the stability of a fixed point
        depends on the union of the spectra of

j            diag r    m      m  
and

j            diag   r       m      m   
it is important to point out that the stability properties depend only on  and r and are
independent of   and h 
our goal is to connect the stability properties of the message passing algorithm to the
properties of the bethe free energy  therefore  we express the stability properties in terms
of the moment parameters of approximate marginals  for any  that leads to normalizable approximate marginals qij  xi   xj    we can use      to identify the local covariance
parameters vij defined in section    but now without enforcing the marginal matching
i   v i   the correspondence is given by
constraints vij
ik
 

i
vij
vij

vij
j
vij


 

  

 

 

 

j
vij
vij

i vj  v 
vij
ij
ij
p
i  
il        ij
ij

vij
i
vij

 
    
rij

li j
j
ij

rij

 

p

jk        ji



 

kj i
i   v j and r
the approximate local covariances vij are fully determined by vij
ij and have
ij
the form as in       this leaves us with  e  moment parameters to be computed by the
i   v   v j and y  v   
message passing algorithm  let v  r e  be defined as vij   vij
ji
ij
ij
i v j  v      where v
vij   vij
ij
ij is computed according to       it can be checked that the
ij
mapping between y and v is continuous and bijective  this implies that the canonical to
moment parameter transformation in      can be written as y v       m    since
m   is singular only when    k and the graph g is k regularsee property a  in
section a of the appendix for detailsfor the rest of the cases  there is a continuous 
bijective mapping between the moment parameters v and the canonical parameters  that
lead to normalizable approximate marginals 
i   v i  v  for any
at any fixed point         we have moment matching  that is  vij
i
ik
k  j  i  therefore we can express the stability properties in terms of moment parameters

  

fibethe free energies and message passing in gaussian models

v     vi           vn    using p
     and defining the diagonal matrix d  r e  e  with the
diagonal elements dij ij   vi   we get

  v 
v
  
v
ij
i
j 
    diag  q
m  


vi vj


dj    v    d  

    

and
 





d j    v   d

 

 

 

diag

vij    vi   vj   
vi vj

 
m   

    


let  a  denote
the spectrum of the matrix a  since we have  dj d       j   and

 d   j d       j    it is sufficient to analyze the spectral properties of the right hand
sides in equations      and      
the message passing algorithm is asymptotically stable at   v    if and only if
max    j    v          j    v           

    

where    denotes the spectral radius  it is interesting to see that although the functional
forms of the free energies and the message passing algorithms are different in the gaussian
and discrete case  the stability conditions have similar forms  this will allow us to use
some of the results of watanabe and fukumizu         in the next section  we show the
implications of this condition for the properties of the hessian of the free energy 
    stable fixed points and local minima
the hessian h f   of the bethe free energy      depends only on the moment parameters
vi   vj and vij   note that now  the vij s are unconstrained parameters  it is an   e       n 
  e       n  matrix and it has the form


q


  
h f   v     

 

diag
h  

   

 f
   vij
it

 h

 f
vij vi ij i

  i

   f
vij vi ij i

h

i

   f
vi vj i j




 


where we use v to denote the collection of parameters vi   i              n and vij   i  j 
since the block corresponding to the partial differentials w r t  vij is diagonal with positive
elements  the hessian is positive definite at v if the schur complement corresponding to
  

ficseke   heskes

the partial differentials w r t  vi s is positive definite at v   the latter is given by
x     f    f  
   f
v

hii  f   v    
vi vi
vij vi
vij
ij


    
  x c ij 
 
 
 
 
 
  vi 

 

c
ij
ij

 
 
 
 f
 f    f    f
v
hij  f   v    

vi vj
vij vi vij vj    vij
      c ij
  
 
  vi vj     c ij

where we use the notation cij   vij   vi vj  
now  we would like to connect the condition in      to the positive definiteness of the
matrix h v  f   v    in the following we show that stable fixed points   v    of the gaussian
message passing algorithm  satisfying       correspond to local minima of the gaussian free
energy f at v  and vij    vi   vj   
according to watanabe and fukumizu         for any arbitrary vector w  r e  one
has

y
det i e     diag  w  m     det in     a w 
    wij wji   
    
ij

where
aii  w   

x
ij

wij wji
   wij wji

and

aij  w    

wij
 
   wij wji

    

the proof is an application of the matrix determinant lemma and a reproduction of it can
be found in section a of the appendix  equation      expresses the determinant of an
 e  e  matrix as the determinant of an nn matrix 

let c  r e  with cij  v     vij   vi vj   by substituting w   c v    in       we find that


det i    diag c v    m     f  v   det  h f   v     
    
where f  v   is a positive function defined as
f  v      n  e   q  

y
k

vk 


 
 
y vi vj  vij
ij

 
vi vj   vij

 
vij
 
vi vj

 
 

for all v corresponding to normalizable approximate marginals  now  adapting the theorem
of watanabe and fukumizu       
 we have
 the following theorem 
theorem if    diag c v    m    c   r  then the hessian of the  gaussian 
bethe free energy h f   is positive definite at
 v  
 
 
proof  the assumption
   diag c v   m    c   r  implies that we have
det i    diag c v    m         by choosing vij  t    tvij with t          we find
 
that c v t      t  c v      therefore  det i    diag c v  t   m        for any t         
  

fibethe free energies and message passing in gaussian models

this implies that det  h f   v  t        for any t          since h f   v        i    
and the eigenvalues of h f   v  t   change continuously w r t  t          it results that
h f   v          for any v   thus satisfying the condition of the theorem 

 
 
the fixed point         is stable if and
 only if max  j    v       j    v          
 

 
this implies   diag c v    m    c   r  and leads to the following property 

property    stable fixed points         of the damped gaussian message passing algorithm      are local minima of the gaussian bethe free energy fc in      at v      
the above shows that the boundedness of f or the existence of local minima in case
of an unbounded f plays a significant role in the convergence of gaussian message passing  we illustrate this in section    if the fractional message passing algorithm converges
then it converges to a set of messages that corresponds to a local minimum of the fractional free energy  this also implies that the mean parameters of the local approximate
marginals are exact  see property    in section     note that the observations in section  
and property a  in the appendix together with property   imply that there is always a
range of  values for which the fractional free energy possesses a local minimum to which
the fractional message passing can converge 
    the damping and the fractional parameters
the local stability condition in      is independent of the damping parameter   therefore 
it does not alter the local stability properties  it only makes the iteration slower and numerically more stable  that is  it can dampen the possible periodic trajectories of the message
passing algorithm 
the fractional parameter  characterizes the inference process and as we have seen in the
example in the previous sections  by choosing smaller s we can create local minima  in the
particular case when h      there is a somewhat similar property for the message passing
updates as well  let   r e  be the set of messages  that lead to normalizable approximate
marginals  the set  is characterized by the model parameters  r    and   we reiterate
i and v j and there is a continuous bijective
that the elements of v are the local variances vij
ij
 e 

mapping between    and v  r  given by y v       m    unless    k and g is
k regular  this allows us to study q
the stability properties in terms of moment parameters
i   v j   
v    let c v       vij    vij
ij

i v j   be the vector of local correlations  by using
vij
ij ij

gershgorins theorem  horn   johnson        and c v      c v     we find that for any
eigenvalue  of   diag c v    m   or   diag c v      m   we have


    max   c v      nj               
i j

when h      there are no updates in   the rhs of the above equation depends on
  c v      see equations      and       and we have lim   c v          thus  small
 

 values can help to achieve convergence  however  when h      the term   c v    is
dominating and the effects of decreasing  towards zero can be ambiguous 
  

ficseke   heskes

   experiments
we implemented both direct minimization and fractional message passing and analyzed
their behavior for different values of max   r    for reasons of simplicity  we set all ij s
equal  the results on an small scale model are summarized in figure    note that there
is a good correspondence between the behavior of the fractional bethe free energies in the
direction of the eigenvalue corresponding to max   r   and the convergence of the newton
method  the newton method was started from different initial points  we experienced
that when max   r       and setting the initial value to v    t  u max   the algorithm
did not converge for high values of t  this can be explained by the top plots in figure   
for high values of t  the initial point might not be in the convergence region of the local
minimum  for the fractional message passing algorithm we used two types of initialization 
i  
    when max   r       we set ij such that they are all normalizable by setting ij
i     n  
 rij  ujmax  max uimax  malioutov et al              when max   r       we used ij
i
that is  a symmetric partitioning of the diagonal elements  we set the initial messages such
that all approximate marginals are normalizable in the first step of the iteration 
we experienced a behavior similar to that described by welling and teh        for
standard message passing  namely  fractional message passing and direct minimization either
both converge or both fail to converge  our experiments in combination with theorem  
show that when max   r        standard message passing at best converges to a local
minimum of the bethe free energy  if standard message passing fails to converge  one
can decrease  and search for a stationary pointpreferably a local minimumof the
corresponding fractional free energy 
it can be seen from the results in the right panels of figure    that when the model is no
longer pairwise normalizable  the local minimum and not the unbounded global minimum
can be viewed the natural continuation of the  bounded  global minimum for pairwise
normalizable models  this explains why the quality of the approximation at the local
minimum for models that are not pairwise normalizable is still comparable to that at the
global minimum for models that are pairwise normalizable 

   conclusions
 t

as we have seen  fmf and fmf     v  r  v provide tight upper and lower bounds for
the gaussian fractional bethe free energies  it turns out that pairwise normalizability is
not only a sufficient condition for the message passing algorithm to converge  but it is also
a necessary condition for the gaussian fractional bethe free energies to be bounded from
below 
if the model is pairwise normalizable  then the lower bound is bounded  and both direct
minimization and message passing are converging  in our experiments both converged to
the same minimum  this suggests that in the pairwise normalizable case  fractional bethe
free energies possess a unique global minimum 
if the model is not pairwise normalizable  then none of the fractional bethe free energies
are bounded from below  however  there is always a range of  values for which the
fractional free energy possesses a local minimum to which both direct minimization and
fractional message passing can converge  thus  by decreasing  towards zero  one gets
  

fibethe free energies and message passing in gaussian models

 

  

 

 

  

          
  d           
           
           

 

  

 

  

 

 

  

  

 

 

  

  



  

 





 

  

  

 

 

  
 

  

 

  

  

function value after convergence

function value after convergence

 
 
 
 
 
 
 

 

  

 

  
 

 

 

  

  

 

 

  

  


 
 
 
 
 
 
 
 
 

 

  

error in variances after convergence

newton method
message passing
 

  

 

  

 

  



 

 

 

 

  

 

error in variances after convergence

 

          
  d           
           
           

 

  

 

  

 

  

  


 

newton method
message passing
 

  

 

  

 

 

  

 

  


  

 

  

 

  

  


 

figure    the top panels show the constrained
 fractional bethe free energies of an gaussian model

with   variables in the direction v   tumax   where umax is the eigenvector corresponding to max   r   for max   r          top left  and max   r          top right   the
thick lines are the functions fmf  dashed   fb  dashed dotted  and the lower bound
 t

fmf     v  r  v  continuous   the thin lines are the constrained  fractional free
energies fc for                 center panels show the final function values after the
convergence of the newton method  the bottom panels 
show the         error in approximation for the single node standard deviations    v  missing values indicate
non convergence 
  

ficseke   heskes

closer to the mean field energy and a finite local minimum will appear  property a  in
the appendix   we experienced that for a suitable range of s s and initial values the
fractional gaussian message passing can be made to converge 
as mentioned in section      ij s correspond to using local ij divergences when applying power expectation propagation with a fully factorized approximating distribution 
seeger        reports that when expectation propagation does not converge  applying power
expectation propagation with      helps to achieve convergence  in the case of the problem
addressed in this paper this behavior can be explained by the observation that small s
make a finite local minima more likely to occur and thus prevents the covariance matrices
from becoming indefinite or even non positive definite  although the most common reason
for using      in ep is numerical robustness  it also implies finding the saddle point of the
 fractional ep free energy  it might be interesting to investigate whether it is the same
reason why convergence is more likely as in the case of gaussian fractional message passing 
wainwright et al         propose to convexify the bethe free energy for discrete models
by choosing ij s sufficiently large such that the fractional bethe free energy has a unique
global minimum  this strategy appears to fail for gaussian models  convexification makes
the possibly useful finite local minima disappear  leaving just the unbounded global minimum  in the case of the more general hybrid models  the use of the convexification is still
unclear 
the example in section   disproves the conjecture in the work of welling and teh        
even when the bethe free energy is not bounded from below  it can possess a finite local
minimum to which the message passing and the minimization algorithms can converge 
we have shown that stable fixed points of the gaussian fractional message passing
algorithms are local minima of the fractional bethe free energy  although the existence
of a local minimum does not guarantee the convergence of the message passing algorithm 
in practice we experienced that the existence of a local minimum implies convergence 
based on these results  we hypothesize that when pairwise normalizability does not hold 
the gaussian bethe free energy and the gaussian message passing algorithm        can
have two types of behavior 
    the gaussian bethe free energy possesses a unique finite local minimum to which
optimization methods can converge by starting from  say  the mean field solution
vi     qii   the gaussian message passing has a corresponding unique stable fixed
point  to which it can converge with suitable starting point and sufficient damping 
    no finite local minimum exists  and thus  both the optimization and the message
passing algorithm diverge 
by using the fractional free energy and the fractional message passing and by varying  
one can switch between these behaviors  computing the critical c   r   for a general  r 
remains an open question  we believe that the properties of the free energies in k regular
symmetric models  section     where the critical values can be easily computed  give a good
insight into the properties of the free energies for general gaussian models 
  

fibethe free energies and message passing in gaussian models

acknowledgments
we would like to thank jason k  johnson for sharing his ideas about the properties of the
message passing algorithm in k regular models  we would also like to thank the anonymous
reviewers for their valuable comments on earlier versions of the manuscript  the research
reported in this paper was supported by vici grant             from the netherlands
organization for scientific research  nwo  

appendix a  properties and proofs
lemma a    watanabe   fukumizu        for any graph g    v  e   edge adjacency
matrix m    defined in section       and arbitrary vector w  r e    one has

y
det i e     diag  w  m     det i v       a w 
    wij wji   
ij

where
aii  w   

x
ij

wij wji
   wij wji

aij  w    

and

wij
 
   wij wji

proof  we reproduce the proof in a somewhat simplified form  let us define uij    etj  
vij    eti where ek is the k th unit vector of rn and s with


 
sij ij sij ji
   
 
 
sji ij sji ji
   
then we have m     u v t  s  let us define w  r e  e  a diagonal matrix with
wij ij   wij   using the matrix determinant lemma this reads as

det i    w u v t  s

  det i   w s    w u v t



  det i    w u v t  i   w s   det  i   w s 


  det i    v t  i   w s   w u det  i   w s  
the  ij  ji  block of  i   w s   w is


 
 
wij
wij
 
 
   wji wji wji

 
wji


 

 
   wji wji



wij
wji wij

wij wji
wji



and thus  we can define a  v t  i   w s   w u such that
x wij wji
wij
ai i  
and ai j   
 
   wij wji
   wij wji
ij

this completes the proof of the matrix determinant lemma      in section     

  



ficseke   heskes

property a   the matrix m     u v t  s is singular only for k regular graphs
with    k 
p
proof  let x  r e  and y  pm  x  then yij   kj xjk  xji   let us fix j  then
yij     for any i means that kj xjk   xji for any i  this can only hold if the graph is
k regular     k and all xij s are equal or xij     for all pair indices ij 

property a   for a suitably chosen       there exists an  such that the constrained
fractional free energy fc possesses a local minimum for all          

proof  let us define vm
f   argminv fm f  v  and


um
f    v   fm f  v   fm f  vm f         

the form of fm f implies that we can always choose  such that um
f is a proper subset of the
n

n
positive quadrant in r   in other words  um f  r    then due to the properties of fm f
 continuous and convex  with a unique finite global minimum attained at a finite value   the





domain um
f is closed  bounded  convex and vm f  um f   um f   that is  vm f is in the

n
c

interior of um f   since fm f and f  v  are continuous on r    the set um f is closed and
bounded and lim fc  v    fm f  v   pointwise convergence  for all v  rn    it follows that fc
 


c
converges uniformly on um
f as      this  together with the monotonicity of f w r t   
implies that there exists  such that fm f  vm f       fc  vm f     fm f  vm f   for all    
   let us fix   it is known that  since u 
    and all v  um
f
m f is closed and bounded and
       for all

c
c
f is continuous  f attains its extrema on um f   since fm f  v    fm f  vm
f
   
c

c

v  um f and f  v    fm f  v    for all v  um f it follows that f  v    fm f  vm
f


c

   
for all v  um f   we have chosen  such that fm f  vm f       f  vm f     fm f  vm
f
the latter two conditions imply that one of the extrema has to be a local minimum in the
  
interior of um

f

references
bickson  d          gaussian belief propagation  theory and application  ph d  thesis 
the hebrew university of jerusalem 
cseke  b     heskes  t          bounds on the bethe free energy for gaussian networks 
in mcallester  d  a     myllymaki  p   eds    uai       proceedings of the   th
conference in uncertainty in artificial intelligence  pp         auai press 
heskes  t          stable fixed points of loopy belief propagation are minima of the bethe
free energy  in becker  s   thrun  s     obermayer  k   eds    advances in neural
information processing systems     pp          cambridge  ma  the mit press 
heskes  t   opper  m   wiegerinck  w   winther  o     zoeter  o          approximate
inference techniques with expectation constraints  journal of statistical mechanics 
theory and experiment        p      
heskes  t          on the uniqueness of loopy belief propagation fixed points  neural
computation               
horn  r  a     johnson  c          matrix analysis  cambridge university press  cambridge  uk 
  

fibethe free energies and message passing in gaussian models

jaakkola  t          tutorial on variational approximation methods  in opper  m     saad 
d   eds    advanced mean field methods  theory and practice  pp          cambridge 
ma  the mit press 
johnson  j  k   bickson  d     dolev  d          fixing convergence of gaussian belief
propagation  corr  abs           
malioutov  d   johnson  j     willsky  a          walk sums and belief propagation in
gaussian graphical models  journal of machine learning research              
minka  t  p          power ep  tech  rep   microsoft research ltd   cambridge  uk 
msr tr          
minka  t  p          divergence measures and message passing  tech  rep  msr tr          microsoft research ltd   cambridge  uk 
moallemi  c     roy  b  v          consensus propagation  in weiss  y   scholkopf  b    
platt  j   eds    advances in neural information processing systems     pp         
mit press  cambridge  ma 
murphy  k   weiss  y     jordan  m  i          loopy belief propagation for approximate
inference  an empirical study  in proceedings of the fifteenth conference on uncertainty in artificial intelligence  vol     pp          san francisco  usa  morgan
kaufman 
nishiyama  y     watanabe  s          accuracy of loopy belief propagation in gaussian
models  neural networks                   
pearl  j          probabilistic reasoning in intelligent systems  networks of plausible inference  morgan kaufman publishers  san mateo  ca 
rusmevichientong  p     roy  b  v          an analysis of belief propagation on the turbo
decoding graph with gaussian densities  ieee transactions on information theory 
           
seeger  m  w          bayesian inference and optimal design for the sparse linear model 
journal of machine learning research            
takahashi  k   fagan  j     chin  m  s          formation of a sparse impedance matrix
and its application to short circuit study  in proceedings of the  th pica conference 
wainwright  m   jaakkola  t     willsky  a          tree reweighted belief propagation
algorithms and approximate ml estimation via pseudo moment matching  in bishop 
c     frey  b   eds    proceedings of the ninth international workshop on artificial
intelligence and statistics  society for artificial intelligence and statistics 
watanabe  y     fukumizu  k          graph zeta function in the bethe free energy and
loopy belief propagation  in bengio  y   schuurmans  d   lafferty  j   williams  c 
k  i     culotta  a   eds    advances in neural information processing systems    
pp            the mit press 
weiss  y     freeman  w  t          correctness of belief propagation in gaussian graphical
models of arbitrary topology  neural computation                    
  

ficseke   heskes

welling  m     teh  y  w          belief optimization for binary networks  a stable alternative to loopy belief propagation  in breese  j  s     koller  d   eds    proceedings
of the   th conference in uncertainty in artificial intelligence  pp          morgan
kaufmann publishers 
wiegerinck  w     heskes  t          fractional belief propagation  in becker  s   thrun 
s     obermayer  k   eds    advances in neural information processing systems    
pp          cambridge  ma  the mit press 
yedidia  j  s   freeman  w  t     weiss  y          generalized belief propagation  in
advances in neural information processing systems     pp          cambridge  ma 
the mit press 
zoeter  o     heskes  t          change point problems in linear dynamical systems 
journal of machine learning research              

  

fi