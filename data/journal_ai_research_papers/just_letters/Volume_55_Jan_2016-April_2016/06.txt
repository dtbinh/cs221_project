journal of artificial intelligence research                  

submitted       published     

searching for the m best solutions in graphical models
natalia flerova

nflerova   uci   edu

university of california  irvine
irvine  ca        usa

radu marinescu

radu   marinescu   ie   ibm   com

ibm research  ireland

rina dechter

dechter   uci   edu

university of california  irvine
irvine  ca        usa

abstract
the paper focuses on finding the m best solutions to combinatorial optimization problems
using best first or depth first branch and bound search  specifically  we present a new algorithm ma   extending the well known a  to the m best task  and for the first time prove that all its desirable
properties  including soundness  completeness and optimal efficiency  are maintained  since bestfirst algorithms require extensive memory  we also extend the memory efficient depth first branch
and bound to the m best task 
we adapt both algorithms to optimization tasks over graphical models  e g   weighted csp and
mpe in bayesian networks   provide complexity analysis and an empirical evaluation  our experiments confirm theory that the best first approach is largely superior when memory is available  but
depth first branch and bound is more robust  we also show that our algorithms are competitive with
related schemes recently developed for the m best task 

   introduction
the usual aim of combinatorial optimization is to find an optimal solution  minimum or maximum 
of an objective function  however  in many applications it is desirable to obtain not just a single
optimal solution  but a set of the first m best solutions for some integer m  we are motivated by
many real life domains  in which such task arises  for instance  a problem of finding the most likely
haplotype in a pedigree can be presented as finding the most probable assignment in a bayesian
network that encodes the genetic information  fishelson  dovgolevsky    geiger         in practice the data is often corrupted or missing  which makes the single optimal solution unreliable  it
is possible to increase the confidence in the answer by finding a set of the m best solutions and
then choosing the final solution with an expert help or by obtaining additional genetic data  more
examples of the m best tasks arise in procurement auction problems and in probabilistic expert systems  where certain constraints often cannot be directly incorporated into the model  either because
they make the problem infeasibly complex or they are too vague to formalize  e g  idiosyncratic
preferences of a human user   thus in such domains it may be more practical to first find several
good solutions to a relaxed problem and then pick the one that satisfies all additional constraints in a
post processing manner  additionally  sometimes a set of diverse assignments with approximately
the same cost is required  as in reliable communication network design  finally  in the context of
summation problem over graphical models  such as probability of evidence or the partition function 
an approximation can be derived by summing over the m most likely tuples 
c
    
ai access foundation  all rights reserved 

fif lerova   m arinescu     d echter

the problem of finding the m best solutions has been well studied  one of the earliest and
most influential works belongs to lawler         he provided a general scheme that extends any
optimization algorithm to the m best task  the idea is to compute the next best solution successively
by finding a single optimal solution for a slightly different reformulation of the original problem that
excludes the solutions generated so far  this approach has been extended and improved over the
years and is still one of the primary strategies for finding the m best solutions  other approaches
are more direct  trying to avoid the repeated computation inherent to lawlers scheme  two earlier
works that are most relevant and provide the highest challenge to our work are by nilsson       
and aljazzar and leue        
 nilsson proposed a junction tree based message passing scheme that iteratively finds the m
best solutions  he claimed that it has the best runtime complexity among m best schemes for
graphical models  our analysis  section    shows that indeed nilssons scheme has the second
best worst case time complexity after our algorithm be m bf  section       however  in
practice this scheme is not feasible for problems having a large induced width 
 in their recent work aljazzar and leue proposed an algorithm called k   an a  search style
scheme for finding the k shortest paths that is interleaved with breadth first search  they used
a specialized data structure and it is unclear if this approach can be straightforwardly extended
to graphical models  a point that we will leave to future work 
one of the popular approximate approaches to solving optimization problems is based on the
lp relaxation of the problem  wainwright   jordan         the m best extension of this approach
 fromer   globerson        does not guarantee exact solutions  but is quite efficient in practice 
we will discuss these and other previous works further in section   
our main focus lies in optimization in the context of graphical models  such as bayesian networks  markov networks and constraint networks  however  some of the algorithms developed
can be used for more general purpose tasks  such as finding m shortest paths in a graph  various
graph exploiting algorithms for solving optimization tasks over graphical models were developed
in the past few decades  such algorithms are often characterized as being either of inference type
 e g   message passing schemes  variable elimination  or of search type  e g   and or search or
recursive conditioning   in our earlier works   e g   flerova  dechter    rollon         we extended
inference schemes as represented by the bucket elimination algorithm  be   dechter              to
the task of finding the m best solutions  however  due to their large memory requirements  variable
elimination algorithms  including bucket elimination  cannot be used in practice for finding exact
solutions to combinatorial optimization tasks when the problems graph is dense  depth first branch
and bound  dfbnb  and best first search  bfs  are more flexible and can trade space for time  our
work explores the question of solving the m best solutions task using the heuristic search schemes 
our contribution lies in extending the heuristic algorithms to the m best solutions task  we describe general purpose m best variants of both depth first branch and bound and best first search 
more specifically a   yielding algorithms m bb and m a  respectively  and analyze their properties  we show that m a  inherits all a s desirable properties  dechter   pearl         most
significantly it is optimally efficient compared to any alternative exact search based scheme  we
also discuss the size of the search space explored by m bb  we then extend our new m best algorithms to graphical models by exploring the and or search space 
we evaluate the resulting algorithms on   benchmarks having more than     instances in total 
and examine the impact of the number of solutions m on the algorithms behaviour  in particular 
   

fis earching for m b est s olutions in g raphical m odels

we observe that the runtime of the most of the schemes  except for the depth first branch and bound
exploring an and or tree  scales much better with m than what worst case theoretical analysis
suggests 
we also show that a m a  search using the exact bucket elimination heuristic  a scheme we
call be m bf  is highly efficient on easier problems but suffers severely from memory issues
over denser graphs  far more than the a  based schemes using approximate mini bucket heuristics  finally  we compare our schemes with some of the most efficient algorithms based on the
lp relaxation  fromer   globerson        batra         showing competitiveness and even superiority for large values of m  m       while providing optimality guarantees 
the paper is organized as follows  in section   we provide relevant background  section  
presents the extension of best first search to the m best task  in particular  we define m a   the
extension of a  algorithm to finding the m best solutions        and prove its main properties       
section   describes algorithm m bb  an extension of depth first branch and bound algorithm to
solving the m best task  in section   we discuss the adaptation of the two newly proposed m best
search algorithms for and or search spaces over graphical models  including a hybrid method
be m bf that incorporates both variable elimination and heuristic search  section   elaborates on
the related work and contrasts it with our methods  section   presents the empirical evaluation of
our m best schemes and section   concludes 

   background
we begin by formally defining the graphical models framework and providing background on
heuristic search 
    graphical models
we denote variables by upper case letters  e g   x  y  z  and their values of variables by lower case
letters  e g   x  y  z   sets of variables are denoted by upper case letters in bold  e g  x  y  z   the
assignment  x    x            xn   xn   can be abbreviated as x    x            xn   
we denote functions by letters f  g  h etc   and a set of functions bypf  a function f over a
scope s     x            xr   is denoted by fs    p
the summation
p operator xx defines a sum over
all possible values of variables in x  namely x  x            xn xn   minimization minxx and
maximization maxxx operators are defined in a similar manner  note that we use terms elimination
p
and marginalization interchangeably 
for convenience we sometimes use minx  maxx   x   to
p
denote minxx  maxxx   xx   
a graphical model is a collection of local functions over subsets of variables that conveys probabilistic  deterministic  or preferential information  and whose structure is described by a graph  the
graph captures independencies or irrelevance information inherent in the model  that can be useful
for interpreting the modeled data and  most significantly  can be exploited by reasoning algorithms 
the set of local functions can be combined in a variety of ways to generate a global function  whose
scope is the set of all variables 
n
d efinition    graphical model   a graphical model m is a   tuple m   hx  d  f  i 
   x    x            xn   is a finite set of variables 

   d    d            dn   is the set of their respective finite domains of values 
   

fif lerova   m arinescu     d echter

   f    f            fr   is a set of non negative real valued discrete functions  defined over scopes
of variables si  x  they are called local functions 
n
n
q p
  
is a combination operator  e g  
        product  sum 
the graphical model represents
a global function  whose scope is x and which is the combination
n
of all the local functions  rj   fj  
n
p
when n
  qand fi   dsi  n we have weighted constraint satisfaction problems  wcsps   when
 
and fi   pi  xi   pai   we have a bayesian network  the probabilities p are
defined relative to a directed acyclic graph g over x  where the set xi            xik are the parents
pai of xi   i e  for each xij there is an edge pointing from xij to xi   for illustration  consider the
bayesian network with   variables whose directed acyclic graph  dag  is given in figure   a  
the most common optimization task for bayesian network is the most probable explanation
 mpe  also known as maximum a posteriori hypothesis  map    where the goal is to compute the
optimal value
r
y

c   max
fj  xsj  
x

j  

and its optimizing configuration


x   argmax
x

r
y

fj  xsj  

j  

the related task  typical for wcsp 
is the min sum  namely computing a minimal cost
p
p assignment  min sum   c    minx j fj  x  and the optimizing configuration x   argminx j fj  x  
historically this task is also sometimes referred to as energy q
minimization  it is equivalent to

an mpe map task in the following sense  if cmax
  maxx j fj  x  is a solution to an mpe




problem 
p then cmax   exp  cmin    where cmin is a solution to a min sum problem cmin  
minx j gj  x  and j  gj  x     log  fj  x   
a graphical model defines the primal graph that captures dependencies between the problems
variables  it has variables as its vertices  an edge connects any two vertices whose variables appear
in the scope of the same function  an important property of a graphical model  characterizing the
complexity of its reasoning tasks is the induced width  an ordered graph is a pair  g  o  where
g is an undirected graph  and o    x            xn   is an ordering of nodes  the width of a node
is the number of the nodes neighbors that precede it in the ordering  the width of a graph along
an ordering o is the maximum width over all nodes  an induced ordered graph is obtained from
an ordered graph as follows  nodes are processed from last to first based on o  when node xj is
processed  all its preceding neighbors are connected  the width of an ordered induced graph along
the ordering o is called induced width along o and is denoted by w  o   the induced width of a
graph  denoted by w   is the minimal induced width over all its orderings  abusing notation we
sometimes use w to denote the induced width along a particular ordering  when the meaning is
clear from the context 
figure   b  depicts the primal graph of the bayesian network from figure   a   figures   c  and
  d  show the induced graphs of the primal graph from figure   a  respectively along the orderings
   in some communities map also refers to the task of optimizing a partial assignment to the variables  however  in
this paper we use map and mpe as interchangeable  both referring to an optimal full variable assignment 

   

fis earching for m b est s olutions in g raphical m odels

p  a 

a

a

b

e

c

d

d

c

e

b

a

a

 c 

 d 

p  b a 

b

c

b

c

p  c a 

e

e

p  e b  c 

d

d

p  d a  b 

 a 

 b 

figure     a  a dag of a bayesian network   b  its primal graph  also called moral graph  
 c  its induced graph along o    a  e  d  c  b   and  d  its induced graph along
o    a  b  c  d  e   example by gogate        

o    a  e  d  c  b  and o     a  b  c  d  e   the dashed lines in figure   c  represent the
induced edges  namely edges that are absent from the moral graph  but were introduced in the
induced graph  we can see that the induced width along ordering o is w  o      and the induced
width along ordering o  is w  o         respectively 
    heuristic search
our analysis focuses on best first search  bfs   whose behaviour for the task of finding a single
optimal solution is well understood  assuming a minimization task  best first search always expands
the node with the best  i e   smallest  value of the heuristic evaluation function  it maintains a graph
of explored paths  a list closed of expanded nodes and a frontier of open nodes  bfs chooses
from open a node n with the smallest value of a heuristic evaluation function f  n   expands it by
generating its successors succ n   places it on closed  and places succ n  in open  the most
popular variant of best first search  a   uses the heuristic evaluation function f  n    g n    h n  
where g n  is the cost of the path from the root to n  and h n  is a heuristic function that estimates
the optimal cost to go h  n  from n to a goal node  a heuristic function is called admissible if
it never overestimates  for minimization  the true minimal cost to reach the goal h  n   namely 
n h n   h  n   a heuristic is called consistent or monotonic  if for every node n and for every
successor n  of n the following inequality holds  h n   c n  n      h n     if h n  is consistent 
then the values of evaluation function f  n  along any path are non decreasing  it is known that
regardless of the tie breaking rule a  expands any node n reachable by a strictly c   bounded path
from the root  and such a node is referred to as surely expanded by a   dechter   pearl        
a path  is c   bounded relative to f   if n     f  n    c    where c  is the cost of optimal
solution 
a  search has a number of attractive properties  nillson        pearl        dechter   pearl 
      
   

fif lerova   m arinescu     d echter

 soundness and completeness  a  terminates with the optimal solution 
 when h is consistent  a  explores only the set of nodes s    n f  n   c    and it surely
expands all the nodes having s    n f  n    c    
 optimal efficiency under consistent heuristic  when h is consistent  any node surely expanded by a  must be expanded by any other sound and complete search algorithm using the
same heuristic information 
 optimal efficiency for node expansions  when the heuristic function is consistent  a  
when searching a graph  expands each node at most once  and at the time of nodes expansion
a  has found the shortest path to it 
 dominance  given two heuristic functions h  and h    s t  n h   n    h   n   a  will expand
every node surely expanded by a    where ai uses heuristic hi  
although best first search is known to be the best algorithm in terms of number of nodes expanded  dechter   pearl         it requires exponential memory in the worst case 
a popular alternative is the depth first branch and bound  dfbnb   whose most attractive feature  compared to best first search  is that it can be executed with linear memory  yet  when the
search space is a graph  it can exploit memory to improve its performance by flexibly trading space
and time  depth first branch and bound expands nodes in a depth first manner  maintaining the cost
of the best solution found so far which is an upper bound u b on the cost of the optimal solution 
if the heuristic evaluation function of the current node n is greater or equal to the upper bound  the
node is pruned and the subtree below it is never explored  in the worst case depth first branch and
bound explores the entire search space  in the best case the first solution found is optimal  in which
case its performance can be as good as bfs  however  if the solution depth is unbound  depth first
search might follow an infinite branch and never terminate  also  if the search space is a graph 
dfbnb may expand nodes numerous time  unless it uses caching and checks for duplicates 
    search in graphical models
search algorithms provide a way to systematically enumerate all possible assignments of a given
graphical model  optimization problems over graphical models can be naturally presented as the
task of finding an optimal cost path in an appropriate search space 
the simplest variant of a search space is the so called or search tree  each level corresponds to
a variable from the original problem  the nodes correspond to partial variable assignments and the
arc weights are derived from problems input functions  the size of such a search tree is bounded
by o k n    where n is the number of variables and k is the maximum domain size 
throughout this section we are going to illustrate the concepts using an example problem with
six variables  a  b  c  d  e  f   and six pairwise functions  its primal graph is shown in figure
  a   figure   b  displays the or search tree corresponding to the lexicographical ordering 
      and or s earch s paces
or search trees are blind to the problem decomposition encoded in graphical models and can therefore be inefficient  they do not exploit the independencies in the model  and or search spaces
   

fis earching for m b est s olutions in g raphical m odels

 a  primal
graph

 b  or search tree along ordering a  b  c  d  e  f

figure    an example problem with   variables  a  b  c  d  e  f   and   pairwise functions 
for graphical models have been introduced to better capture the problem structure  dechter   mateescu         the and or search space is defined relative to a pseudo tree of the primal graph
that captures problem decomposition  figure   a  shows the pseudo tree of the example problem 
d efinition    a pseudo tree of an undirected graph g    v  e  is a directed rooted tree t  
 v  e      such that every arc of g not included in e   is a back arc in t   namely it connects a node
in t to an ancestor in t   the arcs in e   may not all be included in e 
given a graphical model m   hx  d  fi with primal graph g and a pseudo tree t of g  the
and or search tree st contains alternating levels of or and and nodes  its structure is based
on the underlying pseudo tree t   the root node of st is an or node labelled by the variable at the
root of t   the children of an or node xi are and nodes labelled with value assignments hxi   xi i
 or simply hxi i   the children of an and node hxi   xi i are or nodes labelled with the children
of xi in t   representing conditionally independent subproblems  an and or tree corresponding
to the pseudo tree in figure   a  is shown in figure   b   the arcs from nodes xi to hxi   xi i in an
and or search tree are annotated by the weights derived from the cost functions in f 
d efinition    arc weight   the weight w xi   xi   of the arc  xi   hxi   xi i  is the combination  i e 
sum for wcsp and product for mpe  of all the functions  whose scope includes xi and is fully
assigned along the path from root to the node corresponding to hxi   xi i  evaluated at all values
along the path 
some identical subproblems can be identified by their context  namely  a partial instantiation of
their ancestors that separates the subproblem from the rest of the problem graph   can be merged 
yielding an and or search graph  dechter   mateescu         merging all context mergeable
nodes yields the context minimal and or search graph  denoted by ct   an example can be seen in
figure   c   the size of the context minimal and or search graph can be shown to be exponential
in the induced width of g along the pseudo tree t  dechter   mateescu        
a solution tree t of ct is a subtree such that      it contains the root node of ct       if an
internal and node n is in t   then all its children are in t       if an internal or node n is in t  
then exactly one of its children is in t       every tip node in t  i e   nodes with no children  is a
terminal node  the cost of a solution tree is the product  for mpe or sum for wcsp  of the weights
associated with its arcs 
each node n in ct is associated with a value v n  capturing the optimal solution cost of the
conditioned subproblem rooted at n  assuming an mpe map problem  it was shown that v n  can
   

fif lerova   m arinescu     d echter

a

or
and

 

 

or

b

b

and

 

 

 

 

a

c

or

b
c

e

d

f

and

 

or

c

e
 

 

 

d d

f

f

 

and                

e

c

 

 

 

d d

f

f

 

               

 a  pseudo tree

 

 

 

d d

f

f

 

e
 

 

 

d d

f

f

               

               

 b  and or search tree

a

or
and

 

 

or

b

b

and

 

 

c

c

or
and

c

e

 

 

 

 

c

c
 

 

 

 

 

e
 

 

e
 

 

e

e
 

 

 

 

 

or

d

d

d

d

f

f

f

f

and

   

   

   

   

   

   

   

   

 c  context minimal and or search graph

figure    and or search spaces for graphical models 

be computed recursively based on the values of ns successors  or nodes by maximization  and
nodes by multiplication  for wcsps  v n  for or and and nodes is updated by minimization and
by summation  respectively  dechter   mateescu        
we next provide an overview of a depth first branch and bound and best first search algorithms 
that explore and or search spaces  marinescu   dechter      b      a  otten   dechter        
these schemes use heuristics generated either by the mini bucket elimination scheme         or
through soft arc consistency schemes  marinescu   dechter      a      b  schiex        darwiche  dechter  choi  gogate    otten        or their composite  ihler  flerova  dechter    otten 
       as it is customary in the heuristic search literature  when defining search algorithms we
assume without loss of generality a minimization task  i e   min sum optimization problem  
   

fis earching for m b est s olutions in g raphical m odels

algorithm    aobf exploring the and or search tree  marinescu   dechter      b 

 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  
  
  
  
  
  
  
  

input  a graphical model m   hx  d  fi  pseudo tree t rooted at x    heuristic function h  
output  optimal solution to m
create root or node s labelled by x  and let g  explored search space     s  
initialize v s    h s  and best partial solution tree t  to g 
while s is not solved do
select non terminal tip node n in t    if there is no such node then break 
if n is an or node labeled xi then
forall the xi  d xi   do
create and child n    hxi   xi i 
if n is terminal then
mark n  solved 
succ n   succ n   n   
else if n is an and node labeled hxi   xi i then
forall the successor xj of xi in t do
create or child n    xj  
succ n   succ n   n   
initialize v n      h n    for all new nodes 
add new nodes to the explores search space g  g   succ n   
let s   n  
while s     do
let p be a node in s that has no descendants in g still in s 
s  s   p  
if p is or node then
v p    minksucc p   w p  k    v k   
mark best successor k of or ancestors p  such that k   arg minksucc p   w p  k    v k  
 maintaining previously marked successor if still best  
mark p as solved if its best marked successor is solved 
else if p is and
p node then
v p    ksucc p  v k  
mark all arcs to the successors 
mark p as solved if all its children are solved 
if p changes its value or p is marked solved then
add to s all those parents of p such that p is one of their successors through a marked arc 
recompute t  by following marked arcs from the root s 
return hv s   t  i 

      b est f irst and or s earch
the state of the art version of best first search for and or search spaces for graphical models
is the best first and or search algorithm  aobf   marinescu   dechter      b   aobf is a
variant of ao   nillson        that explores the context minimal and or search graph 
aobf is described by algorithm    for simplicity  we present the algorithm for traversing
an and or search tree  aobf maintains the explicated part of the search space g and also keeps
track of the current best partial solution tree t    it interleaves iteratively a top down node expansion
step  lines        which selects a non terminal tip node of t  and generates its children in g  with
a bottom up cost revision step  lines         which updates the values of the internal nodes based
on their childrens values  if a newly generated child node is terminal it is marked solved  line    
   

fif lerova   m arinescu     d echter

during the bottom up phase  or nodes that have at least one solved child and and nodes who have
all children solved are also marked as solved  the algorithm also marks the arc to the best and
child of an or node through which the minimum is achieved  line      following the backward
step  a new best partial solution tree t  is recomputed  line      aobf terminates when the root
node is marked solved  if the heuristic used is admissible  at the point of termination t  is the
optimal solution with cost v s   where s is the root node of the search space 
extending the algorithm to explore the context minimal and or search graph is straightforward and can be done as follows  when expanding a non terminal and node in lines        aobf
does not generate the corresponding or children that are already present in the explicated search
space g but rather links to them  all these identical or nodes in g are easily recognized based on
their contexts  marinescu   dechter      b  
t heorem    complexity  marinescu   dechter      b   algorithm aobf traversing the context
minimal and or graph has time and space complexity of o n  k w    where n is the number of
variable in the problem  w is the induced width of the pseudo tree and k bounds the domain size 
      d epth  f irst and or b ranch and b ound
the depth first and or branch and bound  aobb   marinescu   dechter      a  algorithm
traverses the and or search space in a depth first rather than a best first manner  while keeping
track of the current upper bound on the minimal solution cost 
as before and for simplicity  we present the variant of the algorithm that explores an and or
search tree  aobb described by algorithm   interleaves forward node expansion  lines       with
a backward cost revision  or propagation  step  lines        that updates node values  capturing
the current best solution to the subproblem rooted at each node   until search terminates and the
optimal solution has been found  a node n will be pruned  lines        if the current upper bound
is higher than the nodes heuristic lower bound  computed recursively using the procedure described
in algorithm   

in the worst case  aobb explores the entire search space  namely o n  k w   nodes  assuming
a context minimal and or search graph   in practice  however  aobb is likely to expand more
nodes than aobf using the same heuristic  but the empirical performance of aobb depends heavily
on the order in which the solutions are encountered  namely on how quickly the algorithm finds a
close to optimal solution that it will use as an upper bound for pruning 
      m ini  b ucket h euristics
the and or search algorithms presented  aobf and aobb  most often use the mini bucket
 also known as mbe  heuristic h n   mini bucket elimination or mbe  dechter   rish       
is an approximate version of an exact variable elimination algorithm called bucket elimination  be 
 dechter         mbe  algorithm    bounds the space and time complexity of full bucket elimination  which is exponential in the induced width w    given a variable ordering  the algorithm
associates each variable xi with a bucket which contains all functions defined on this variable 
but not on higher index variables  large buckets are partitioned into smaller subsets  called minibuckets  each containing at most i distinct variables  the parameter i is called the i bound  the
algorithm processes buckets them from last to first  lines      in algorithm     the mini buckets of
the same variable are processed separately  assuming a min sum problem  mbe calculates the sum
   

fis earching for m b est s olutions in g raphical m odels

algorithm    aobb exploring the and or search tree  marinescu   dechter      b 

 
 
 
 
 
 
 
 
 
  
  

  
  

input  a graphical model m   hx  d  fi  pseudo tree t rooted at x    heuristic function h   
output  optimal solution to m
create root or node s labelled by x  and let the stack of created but not expanded nodes op en   s  
initialize v s    and best partial solution tree rooted in s t   s     u b   
while op en     do
select top node n in open 
if n is or node labeled xi then
foreach xi  d xi   do
add and child n  labeled hxi   xi i to list of successors of n 
initialize v n         best partial solution tree rooted in n t   n       
if n is and node labelled hxi   xi i then
foreach or ancestor k of n do
recursively evaluate the cost of the partial solution tree rooted in k  based on heuristic function
h    assign its cost to f  k      see algorithm  
if evaluated partial solution is not better than current upper bound at k  e g  f  k   v k  then
prune the subtree below the current tip node n 
else

  

foreach successor xj of xi  t do
add or child n  labeled xj to list of successors of n 
initialize v n       best partial solution tree rooted in n  t   n      

  
  
  

  
  
  
  
  
  
  
  
  
  

  
  

add successors of n on top of open 
while list of successors of node n is empty do
if node n is the root node then
return solution  v n   t   n   
else
if p is and node then
v p   v p    v n   t   p   t   p   t   n  
else if p is or node then
if the new value of better than the old one  e g  v p     c p  n    v n   for minimization then
v p   w p  n    v n   t   p   t   p   hxi   xi i 
remove n from the list of successors of p 
move one level up  n  p 

of the functions in each mini bucket and eliminates its variable using the min operator  line     the
new function is placed in the appropriate lower bucket  line      mbe generates a bound  lower for
minimization and upper for maximization  on the optimal value  higher i values take more computational resources  but yield more accurate bounds  when i is large enough  i e   i  w    mbe
coincides with full bucket elimination 
t heorem    complexity  dechter   rish         given a graphical model with variable ordering
o having induced width w  o  and an i bound parameter i  the time of the mini bucket algorithm


mbe i  is o nk min i w  o       and space complexity is o nk min i w  o      where n is the number
of problem variables and k is the maximum domains size 
mini bucket elimination can be viewed as message passing from leaves to root along a minibucket tree  a mini bucket tree of a graphical model m has the mini buckets as its nodes  bucketx
   

fif lerova   m arinescu     d echter

algorithm    recursive computation of the heuristic evaluation function
 

 
 
 

function evalpartialsolutiontree t  n   h n  
input  partial solution subtree t  n  rooted at node n  heuristic function h n  
output  heuristic evaluation function f  t  n   
if succ n      then
if n is an and node then
return   
else

 

return h n  

 
 
 
 
  
  
  
  

else
if n is an and node then
let k            kl be the or children of n 
p
return li   evalpartialsolutiontree t  ki    h ki    
else if n is an or node then
let k be the and child of n 
return w n  k    evalpartialsolutiontree t  k   h k   

algorithm    mini bucket elimination

 

 
 
 
 
 
 
 
 
  

  

  

input  a model m   hx  d  fi  ordering o  parameter i
output  approximate solution to m  and the ordered augmented buckets
initialize  partition the functions in f into bucket            bucketn   where bucketi contains all functions
whose highest variable is xi  
   backward pass
for p  n downto   do
let h            hj be the functions  original and intermediate  in bucketp   let s            sj be their scopes 
if xp is instantiated  xp   xp   then
assign xp   xp to each hi and put each resulting function into its appropriate bucket 
else
generate an i partitioning 
foreach qk  q  do
p
generate the message function hkb   hkb   minxp xp ji   hi  
add hkb to the bucket of xb   the largest index variable in scope hkb   
   forward pass
assign a value to each variable in the ordering o so that the combination of the functions in each bucket is
minimal 
return the function computed in the bucket of the first variable and the corresponding assignment 

is a child of buckety is the function hxy generated in bucketx when variable x is eliminated 
is placed in buckety   therefore  every vertex other than the root has one parent and possibly
several child vertices  note that a mini bucket tree corresponds to a pseudo tree  where the minibuckets of the same variables are combined to form what we call augmented buckets  corresponding
to variable nodes  dechter   mateescu        
mini bucket elimination is often used to generate heuristics for search algorithms over graphical
models  formulated for or search spaces by kask and dechter      a      b  and extended to
and or search by marinescu and dechter        
   

fis earching for m b est s olutions in g raphical m odels

d efinition    mbe heuristic for the and or search space  marinescu   dechter         given
an ordered set of augmented buckets  b x             b xn    generated by the mini bucket algorithm
m be i  along the bucket tree t   and given a node n in the and or search tree  the static minibucket heuristic function h n  is computed as follows 
   if n is an and node  labeled by hxp   xp i  then 
x
h n   
hkj
hkj  b xp  b xp     xpq   

namely  it is the sum of the intermediate functions hkj that satisfy the following two properties 
 they are generated in buckets b xk    where xk is any descendant of xp in the bucket tree t
 they reside in bucket b xp   or the bucket b xp        xpq      b xp             b xpq    that correspond to the ancestors  xp             xpq   of xp in t
   if n is an or node  labeled by xp   then 
h n   

min

msucc p 

 w n  m    h m  

where m are the and children of n labeled with values xp of xp  
having established the necessary background  we will now turn to the main part of the paper 
presenting our contributions  beginning with the extension of best first search to the m best task 
as it is customary in the heuristic search literature and without loss of generality  we will assume in
the remaining of the paper a min sum optimization problem 

   best first search for finding the m best solutions
extending best first search  section      and in particular its most popular version  a   to the mbest task is fairly straightforward and was suggested  for example  by charniak and shimony        
instead of stopping after finding the optimal solution  the algorithm continues exploring the search
space  reporting the next discovered solutions up until m of them are obtained  we will show that
these solutions are indeed the m best and that they are found in a decreasing order of their optimality 
in particular  the second solution reported is the second best solution and  in general  the ith solution
discovered is the ith best 
    m a   definition
the m best tree search variant of a  denoted m a   algorithm    assumes a consistent heuristic 
solves an m best optimization problem over any general search graph  we will show later how it
can be extended to general admissible heuristics 
the scheme expands the nodes in the order of increasing value of f in the usual a  manner 
it keeps the lists of created nodes open and expanded nodes closed  as usual  maintaining a
search tree  denoted by t r  beginning with the start node s  m a  picks the node with the smallest
evaluation function f  n  in open and puts it in closed  line     if the node is a goal  a new
solution is reported  lines        otherwise  the node is expanded and its children are created  lines
        the algorithm may encounter each node multiple times and will maintain up to m of its
   

fif lerova   m arinescu     d echter

algorithm    m a  exploring a graph  assuming consistent heuristic

 
 
 
 
 
 
 

 
 

  
  

input  an implicit directed search graph g    n  e   with a start node s and a set of goal nodes goals  a
consistent heuristic evaluation function h n   parameter m
output  the m best solutions
initialize  open   closed   a tree t r     i      i counts the current solution being searched for 
open   s   f  s    h s  
make s the root of t r 
while i  m do
if open is empty then
return the solutions found so far 
remove a node  denoted n  in open having a minimum f  break ties arbitrarily  but in favour of goal nodes
and deeper nodes  and put it in closed 
if n is a goal node then
output the current solution obtained by tracing back pointers from n to s  pointers are assigned in step
     denote this solution as soli  
if i   m then
return 
else

  

i  i     

  
  
  
  
  
  
  
  
  
  
  

  

else
expand node n  generating all its children ch  
foreach n   ch do
if n  already appears in open or closed m times then
discard node n   
else
compute current path cost g n      g n    c n  n    
compute evaluation function f  n      g n      h n     
attach a pointer from n  back to n in t r 
insert n  into the right place in open based on f  n    
return the set of the m best solutions found

copies in the open and closed lists combined  line      with separate paths to each copy in the
explored search tree  lines         nodes encountered beyond m times are discarded  line      we
denote by ci the ith best solution cost  by fi  n  the cost of the ith best solution going through node
n  by fi  n  the heuristic evaluation function estimating fi  n  and by gi  n  and hi  n  the estimates
of the ith best costs from s to n and from n to a goal  respectively 
if the heuristic is not consistent  whenever the algorithm reaches a node it has seen before  if
the search space is a graph and not a tree   there exists a possibility of the new path improving on
the previously discovered ones  therefore  lines       should be revised in the following way to
account for the possibility that a better path to n  is discovered 
  
if n  appears already more than m times in the union of open or closed then
  
if g n    is strictly smaller than gm  n     the current m best path to n  then
  
keep n  with a pointer to n and put n back in open
  
discard the earlier subtree rooted at n
figure   shows an example of m a  for finding the m     shortest paths on a toy problem  the
left hand side of figure   shows the problem graph with   variables and   edges  together with the
   

fis earching for m b est s olutions in g raphical m odels

a
 

h a     

 

h b     

a

order in which
nodes are expanded

  

h c     

b

  

c

b f   

h d     

c 
c 

 

 

  

d

d 

 

  

m  
c     

c f   

    
    

  
d  f    

f   

 
h f      

h e     

e

f
 

    f       
e 
f  f    

 
g

h g     

g 
f     

   
g 

   f       
f 

f     e 

   
g 

f     

f     

  
g 
f   

nodes on closed

 a  problem graph

 b  trace of m a 

figure    example problem  on the left  problem graph and heuristic values h n  for each node 
on the right  trace of m a  for finding m     best solutions and evaluation function f  n 
for each node  white nodes are in closed  the grey one was created  but discarded 

admissible heuristic functions for each node  note that the heuristic is not consistent  for example 
h a    h c    c a  c   a is the start node  g is the goal node  on the right side of the figure
we present the trace of m a   with the evaluation function for each copy of the nodes created by
the time the  rd solution is found  the white nodes are in closed  the grey one  node g    was
created  but never put in open  the algorithm expands the nodes in open in increasing order of
the evaluation functions  we assume that the ties are broken in favour of deeper nodes  first  m a 
discovers the solution a  c  d  f  g with cost c       next the solution a  c  d  e  g
with cost c       is found  the third solutions is a  b  d  f  g with cost c        note
that two copies of each node d  e and f and four copies of g were created  the goal node g  was
discarded  because we bound the total number of copies of a particular node by m     
n
t heorem    given a graphical model m   hx  d  f  i with n variables whose domain size is
bounded by k  the worst case time and space complexity of m a  exploring an or search tree of m
is o k n   
proof  in worst case m a  would explore the entire or search tree  whose size is o k n    section       since the underlying search space is a tree  the algorithm will never encounter any of the
nodes more than once  thus no nodes will be duplicated 
   

fif lerova   m arinescu     d echter

    properties of m a 
in this section we extend the desirable properties of a   listed in section      to the m best case  for
simplicity and without loss of generality  we assume throughout that the search graph accommodates
at least m distinct solutions 
t heorem    given an optimization task  its implicit directed search graph g and some integer
parameter m     m a  guided by an admissible heuristic has the following properties 
   soundness and completeness  m a  terminates with the m best solutions generated in order
of their costs 
   optimal efficiency under consistent heuristic  any node that is surely expanded  by m a 
must be expanded by any other search algorithm traversing g that is guaranteed to find the
m best solutions having the same heuristic information 
   optimal efficiency for node expansions  m a  expands each node at most m times when the
heuristic is consistent  the ith path found to a node is the ith best path 
   dominance  given two heuristic functions h  and h    such that for every n h   n    h   n  
m a   will expand every node surely expanded by m a     when m a i is using heuristic hi  
we prove the properties of m a  in sections             
      s oundness and c ompleteness
algorithm m a  maintains up to m copies of each node and discards the rest  we will next show
that this restriction does not compromise completeness 
p roposition    any node discarded by m a  does not lead to any of the m best solutions 
proof  consider a consistent heuristic first  as described in algorithm     at the moment when
m a  discovered a node n for the  m     th time  m copies of n reside on open or closed
and the algorithm maintains m distinct paths to each  let m be the  m     th path  as we will
prove in theorem     when node n is discovered for the  m     th time  the cost cnew of the newly
discovered path new is the  m     th best  namely it is no better than the costs already discovered 
cnew  cm   therefore  the eliminated  m     th path to node n is guaranteed to be worse than
the remaining m ones and thus can not be a part of any of the potential m best optimal solutions
that might be passing through node n 
if the heuristic is not consistent  m a  can be modified to replace the worst of the previously
discovered paths m with the newly found new   if the cost of the latter is better and place the new
copy in open  thus  again  it is safe to bound the number of copies by m 
it is clear that along any particular solution path  the evaluation function over all the nodes on
 is bounded by the paths cost c    when the heuristic is admissible 
p roposition    the following is true regarding m a  
   for any solution path   forall n    f  n   c   
   to be precisely defined in section      

   

fis earching for m b est s olutions in g raphical m odels

   unless  was already discovered by m a   there is always a node n on  which resides in
open 
   therefore  as long as m a  did not discover  there must be a node in open having f  n  
c   
proof     f  n    g  n    h n  and since h n   c  n  t  due to admissibility  where c  n  t  is
the actual cost from n to the goal node t along   we conclude that f  n   g  n    h n    c   
   any reachable path from the root always has a leaf in open unless all the nodes along the path
are expanded and are in closed 
   follows easily from   and   
it follows immediately from proposition    stated similarly by nilsson        that 
p roposition     necessary condition for node expansion  any node n expanded during m a 
when searching for the ith best solution     i  m  satisfies f  n   ci  
and it is also clear that
p roposition     sufficient condition for node expansion  every node n in open  such that
f  n    ci   must be expanded by m a  before the ith best solution is found 
soundness and completeness of m a  follows quite immediately 
t heorem    soundness and completeness   algorithm m a  generates the m best solutions in
order  namely  the ith solution generated is the ith best solution 
proof  let us assume by contradiction that this is not the case  let the ith generated solution path
i be the first one that is not generated according to the best first order  namely the ith solution
generated has a cost c such that c   ci   however  when the algorithm selected the goal ti along
i   its evaluation function was f  ti     gi  ti     c  while  based on proposition    there was a
node n  in open whose evaluation function was at most ci   thus n  should have been selected for
expansion instead of ti   we have a contradiction and therefore the result follows 
      t he i mpact of the h euristic s trength
like for a   the performance of m a  improves with more accurate heuristic 
p roposition    consider two heuristic functions h  and h    let us denote by m a   the algorithm that uses heuristic h  and by m a   the one using heuristic h    if the heuristic h  is
more informed than h    namely for every node n  h   n    h   n   algorithm m a   will expand
every node that will be expanded by the algorithm m a   before finding the j th solution for any
j                 m   assuming the same tie breaking rule 
proof  since h  is more informed than h    h   n    h   n  for every non goal node n  let us
assume that m a   expands some non terminal node n before finding the j th best solution with
cost cj   if node n is expanded  it means that  a  at some point it is on open and  b  its evaluation
function satisfies f   n    g n    h   n   cj  proposition     consider the current path  from
start node to n  each node n    on the path was selected at some point for expansion and thus
   

fif lerova   m arinescu     d echter

m a search space

search space of
c  cm
any other algorithm
ci


 cm
 c   

search space
explored by m a
compared to a

figure    the schematic representation of the search spaces explored by the m a  algorithm  de
pending on m and cost cm

the evaluation functions of all these nodes are also bounded by the cost of the j th best solution 
f   n     cj   since h   n      h   n    for every node n  along the path   their evaluation functions
according to heuristic h   n  obey 
f   n      g n      h   n      g n      h   n      cj

   

and thus each node n  must also be expanded by m a    
consider the case of the exact heuristic  it is easy to show that 
t heorem    if h   h is the exact heuristic  then m a  generates solutions only on j optimal
paths    j  m 
proof  since h is exact  the f values on open are expanded in sequence of values c   c  
   all the generated nodes having evaluation function f   c  are by definition
       ci        cm
 
on optimal paths  since h   h    all those who have f   c  must be on paths that can be second
best and so on  notice that some solutions can have the same costs 
when h   h   m a s complexity is clearly linear in the number of nodes having evaluation
   however  when the cost function has only a small range of values  there may be
function f   cm
   to avoid this exponential frontier we
an exponential number of solution paths having the cost cm
chose the tie breaking rule of expanding deeper nodes first  yielding a number of node expansions
bounded by m  n  when n bounds the solution length  clearly 

t heorem    when m a  has access
favour of deeper
p to h   h   then  using a tie breaking rule in
th
nodes  it expands at most  n   i  ni nodes  where  ni is the length of the i optimal solution
path  clearly   n  m  n 

   

fis earching for m b est s olutions in g raphical m odels

figure    the graph g  represents a new problem instance constructed by appending a branch leading to a new goal node t to node n 

      m  a  with c onsistent h euristic
when m a  uses a consistent heuristic  it has several useful properties 
optimal efficiency under consistent heuristic  algorithm a  is known to be optimally efficient
for consistent heuristic  dechter   pearl         namely  any other algorithm that extends search
paths from the root and uses the same heuristic information as a  will expand every node that is
surely expanded by a   i e   it will expand every n  such that f  n    c    we extend the notion of
nodes surely expanded by a  to the m best case 
  bounded
p roposition    algorithm m a  will expand any node n reachable by a strictly cm
path from the root  regardless of the tie breaking rule  the set of such nodes is referred to as surely
expanded by m a  
  bounded path     s  n   n         n   the start node s is
proof  let us consider the strictly cm
   
clearly expanded at the beginning of the search and its children  including node n    are placed
   node n must be expanded by m a  before finding the mth best
on open  since f  n      cm
 
solution  proposition     its children  including n    in turn are placed in open  the same is true for
all nodes of   including n 

t heorem    m optimal efficiency   any search algorithm  that is guaranteed to find the m best
solutions and that explores the same search space as m a  and has the same consistent heuristic 
will have to expand any node that is surely expanded by m a   namely it will expand every node
   i e  f  n      c    n    
that lies on any path  that is dominated by cm
m
the proof idea is similar to the work by dechter and pearl         namely we can show that
any algorithm that does not expand a node n  surely expanded by m a   can miss one of the m best
solutions  when applied to a slightly modified problem 
proof  let us consider a problem having the search graph g and a consistent heuristic h  assume
that node n is surely expanded by m a  before finding the j th best solution  let b be an algorithm
that uses the same heuristic h and is guaranteed to find the m best solutions  let also assume that
node n is not expanded by b  a consistency of the heuristic also allows us to better characterize the
nodes expanded by m a  
we can create a new problem graph g   see figure    by adding a new goal node t with
h t       connecting it to n by an edge having cost c   h n      where        cj  d 
   

fif lerova   m arinescu     d echter

and d   maxn  sj f  n     where sj is the set of nodes surely expanded by m a  before finding the
j th solution  it is possible to show that the heuristic h is admissible for the graph g   dechter  
pearl         since        cj  d   c    d     by construction  the evaluation function of
the new goal node is 

f  t    g t    h t    g n    c   g n    h n       f  n      d      cj     cj

   

which means that t is reachable from s by a path whose cost is strictly bounded by cj   that
guarantees that m a  will expand t  proposition     discovering a solution with cost cj    on the
other hand  algorithm b  that does not expand node n in the original problem  will still not expand it
and thus will not reach node t and will only discover the solution with cost cj   not returning the true
set of m best solutions to the modified problem  from the contradiction the theorem follows 
p roposition    if the heuristic function employed by m a  is consistent  the values of the evaluation function f of the sequence of expanded nodes are non decreasing 
the proof is a straightforward extension of a result by nilsson        
proof  let node n  be expanded immediately after n    if n  was already in open at the time when
n  was expanded  then from the node selection rule it follows that f  n     f  n     if n  was not
in open  then it must have been added to it as a result of expansion of n    i e   be a child of n   
in this case the cost of getting to n  from the start node is g n      g n      c n    n    and the
evaluation function of node n  is f  n      g n      h n      g n      c n    n      h n     since h n 
is consistent  h n     c n    n    h n    and f  n     g n    h n     namely  f  n     f  n    
if the heuristic function is consistent  we have a stronger condition of proposition   
t heorem    algorithm m a  using a consistent heuristic function 
 
   expands all nodes n such that f  n    cm
 
   never expands any nodes with evaluation function f  n    cm

   expands some nodes such that f  n    cm   subject to a tie breaking rule 
 and node n is never expanded by
proof     assume that there exists a node n such that f  n    cm
m a   such a situation can only arise if node n has never been in the open list  otherwise it would
have been expanded  according to proposition    that implies that the parent of node n in the search
space  let us denote it by node p  has never been expanded  however  similarly how it is done in the
   thus
proof of proposition    it is easy to show that f  p   f  n  and  consequently f  p    cm
node p must also have never been in open  otherwise it would be expanded  clearly  this is true
for all the ancestors of n  up to the start node s  since node s is clearly in open at the beginning of
the search  the initial assumption is incorrect and the property follows 
   and    follow directly from proposition   

figure   provides a schematic summary of the search space explored by m a  having a consistent heuristic 
   

fis earching for m b est s olutions in g raphical m odels


 n f n    cm
 

search space
explored by m a

 

 

 n f  n    cm
 


 n f  n    cm
 

figure    the nodes explored by the m a  algorithm with a consistent heuristic 
optimal efficiency for node expansions  whenever a node n is selected for expansion for the
first time by m a   the algorithm has already found the shortest path to that node  we can extend
this property as follows 
t heorem     given a consistent heuristic h  when m a  selects a node n for expansion for the
ith time  then g n    gi  n   namely it has found the ith best path from start node s to n 
proof  by induction  for i      basic step  the theorem holds  nillson         assume that it also
holds for  i    th expansion of node n  let us consider the ith case  i      inductive step   we
have already expanded the node n  i     times and due to the inductive hypothesis we have already
found the  i     distinct best paths to the node n  let us assume that the cost of the newly found
solution path is greater than the ith optimal one  i e  gi  n    gi  n   then  there exists a different 
undiscovered path  from s to n with cost g  n    gi  n    gi  n   from proposition   there exists
in open a node n     obviously  node n  must be located between the start node s and node
n  denoting by c  n    n    c n    n           c nk   n   from the heuristic consistency it easily
follows that h n      c  n    n    h n  and that the evaluation function of node n  along path 
is f  n      g  n      h n      g  n      c  n    n    h n   seeing that the cost of path  from
s to n is g  n    g  n      c   we conclude that f  n      f  n   however  that contradicts our
assumption that node n was expanded for the ith time before node n    the theorem follows 
      t he i mpact of the r equired b est s olutions m
the sequence of the sizes of search spaces explored by m a  as a function of m is obviously monotonically increasing with m  denoting by j a  and i a  the versions of the m a  algorithm that
search respectively for j and i best solutions  we can make the following straightforward characterization 
p roposition    given a search graph and consistent heuristic 
   any node expanded by i a  is expanded by j a  if i   j and if both use the same tie breaking
rule 
   

fif lerova   m arinescu     d echter

   the set s i  j  of nodes defined by s i  j     n ci   f  n    cj   will surely be expanded
by j a  and surely not expanded by i a  
   if cj   ci   the difference in the number of nodes expanded by i a  and j a  is determined
by the tie breaking rule 
the proof follows trivially from theorem    as a result  larger discrepancy between the respective costs cj  ci yields larger difference in the search spaces explored by j a  and i a  
this difference  however  also depends on the granularity with which the values of a sequence of
observed evaluation functions increase  which is related to the arc costs  or weights  of the search
graph  if ci   cj   c  then the search space explored by i a  and j a  will differ only in the
frontier of nodes satisfying f  n    c  figure   represents schematically the search spaces explored
by the i a  algorithm 

   depth first branch and bound for finding the m best solutions
along with its valuable properties  m a  inherits also the disadvantages of a   its exponential space
complexity  which makes the algorithm infeasible for many applications  an alternative approach
is searching using depth first branch and bound  dfbnb   which can be implemented in linear
space if necessary and is therefore often more practical  dfbnb finds the optimal solution by
exploring the search space in a depth first manner  the algorithm maintains a cost u of the best
solution encountered so far and prunes search nodes whose lower bounding evaluation function
f  n    g n    h n  is larger than u   extending dfbnb to the m best task is straightforward  as
we describe next 
    the m bb algorithm
algorithm m bb  the depth first branch and bound extension to the m best task  that explores a
search tree is presented in algorithm    as usual  the algorithm maintains lists of open and
closed nodes  it also maintains a sorted list of candidate nodes that contains the best m
solutions found so far  nodes on open are organized in a last in   first out manner in order to
facilitate a depth first exploration of the search space  i e   open is a stack   at each step  m bb
expands the next node n in open  line     if it is a goal node  a new complete solution is found
 line    and it is stored in the candidate list  line       which is then re sorted  line      only
up to m best solutions are maintained  lines        
the main modification to the depth first branch and bound  when extended to the m best task 
is in its pruning condition  let u   u          um denote the costs of the m best solutions
encountered thus far  then um is the upper bound used for pruning  before m solutions are discovered  no pruning takes place  algorithm m bb expands the current node n  generates its children
 lines        and computes their evaluation function  line         it prunes a subproblem below n
iff f  n   um  lines         it is easy to see that when the algorithm terminates  it outputs the
m best solutions to the problem 
t heorem     algorithm m bb is sound and complete for the m best solutions task 
proof  algorithm m bb explores the search space systematically  the only solutions that are
   where c  is the m
skipped are the ones satisfying f  n   um  see step      since um  cm
m
   

fis earching for m b est s olutions in g raphical m odels

algorithm    m bb exploring a graph  assuming a consistent heuristic

 

 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  

input  an implicit directed search graph g    n  e  with a start node n  and a set of goal nodes goals  a
heuristic function h n   parameter m  the number of desired solutions  
output  the m best solutions
initialize  open   closed   a tree t r     sorted list candidate     upperbound     i      i
counts the current solution being searched for  
put the start node n  in open  g n         f  n      h n    
assign n  to be the root of t r 
while open is not empty do
remove the top node from open  denoted n  and put it on closed 
if n is a goal node then
soli  solution obtained by tracing back pointers from n to n   pointers assigned at step     
ci  cost of soli  
place solution soli on candidate 
sort candidate in increasing order of solution costs 
if size of candidate list  m then
um  cost of the mth element in candidate 
keep first m elements of candidate  discard the rest 
else
expand node n  generating its children succ n  
forall the n   succ n  do
attach a pointer from n  back to n in t r 
g n      g n    c n  n    
f  n      g n      h n    
if f  n      um then
place n  in open 
else
discard n   
return the solutions on candidate list

 and therefore that path cannot lead to a newly discovered
best solution cost  it implies f  n   cm
m best cost 

n
t heorem     given a graphical model m   hx  d  f  i  the worst case time complexity of
m bb that explores an or search tree of m is o k n   log m   where n is the number of variables 
k is the domain size and m is the number of required solutions  space complexity is o n  
proof  in worst case m bb would explore the entire or search tree of size o k n    the maintaining
of candidate list introduces additional time overhead of o log m   since the or search tree
yields no caching  m bb uses space linear in the number of variables 
    characterization of the search space explored by m bb
we have already shown that m a  is superior to any exact search algorithm for finding the mbest solutions when the heuristic is consistent  theorem     in particular  m bb must expand all
    from
the nodes that are surely expanded by m a   namely the set of nodes  n f  n    cm
theorem   and the pruning condition it is clear that 
   

fif lerova   m arinescu     d echter

p roposition    given a consistent heuristic m bb must expand any node in the set  n f  n   
    also  there are instances for which m bb will expands nodes satisfying f  n    c   
cm
m
several sources of overhead of m bb are discussed next 
      m  bb vs   bb
pruning in m bb does not occur until the upper bound on the current mth best solution is assigned
a valid value  i e   until m solutions are found  in the absence of determinism  when all solutions are
consistent  the time it takes to find m arbitrary solutions in depth first manner is o m  n   where
n is the length of solution  for graphical models n coincides with the number of variables   if the
problem contains determinism it may be difficult to find even a single solution  this means that for
m bb the search may be exhaustive for quite some time 
      t he i mpact of s olution o rder
the difference in the number of nodes expanded by bb and m bb depends greatly on the variance
between the solution costs  if all the solutions have the same cost  then u    um   however  such
a situation is unlikely and therefore the conditions for m bbs node expansions are impacted by
            u j   be the non increasing sequence of
the order in which solutions are discovered  let  um
m
th
the upper bounds on the m best solution  up to a point when m bb uncovered the j th solution 
j
initially um
    for j              m     
p roposition     between the discovery of the  j    th and the j th solutions the set of nodes
j 
  u j  u j    
expanded by m bb are included in sj    n   f  n   um
   where cm
m
m
proof  between discovering the  j    th and j th solutions m bb expands only nodes satisfying
j 
j 
 n   f  n   um
   hence j   cj  um
  once the j th solution is found  it either replaces the
j
th
previous bound on m solution um   cj or some k th upper bound  k              m      yielding
j 
j
  u j  u j   
  either way  cm
  um 
um
m
m
      o rdering overhead
the need to keep a list of m sorted solutions  the candidate list  implies o log m  overhead
for each new solution discovered  the total number of solutions encountered before termination is
hard to characterize 
      c aching overhead
the overhead related to caching arises only when m bb explores a search graph and uses caching 
this version of the algorithm  not explicitly presented  stores the m best partial solutions to any
fully explored subproblems  and a subset of m when only a partial set is discovered  and re uses
these results whenever the subproblem is encountered again  in order to implement caching  mbb requires to store a list of length m for each node that is cached  moreover  the cached partial
solutions need to be sorted  which yields an o m log m  time overhead per cached node 
   

fis earching for m b est s olutions in g raphical m odels

   adapting m a  and m bb for graphical models
our main task is to find the m best solutions to optimization tasks over graphical models  therefore 
we adapt the m best search algorithms m a  and m bb to explore the and or search space over
graphical models  yielding algorithms m aobf and m aobb  respectively  we will also describe
a hybrid algorithm be m bf  combining bucket elimination and m a  
    m aobf  best first and or search for m best solutions in graphical models
the extension of algorithm aobf  section        to the m best task seems fairly straightforward 
in principle  m aobf is aobf that continues searching after discovering the first solution  until
the required number of m best solutions is obtained  the actual implementation requires several
modifications as we discuss next 
it is not easy to extend aobfs bottom up node values updates and corresponding arc marking
mechanism to the m best task  therefore  in order to keep track of the current best partial solution
tree while searching for the ith best solution we adopt a naive approach that maintains explicitly a
list open containing entire partial solution trees  not just nodes   sorted in ascending order of their
heuristic evaluation costs  algorithm   presents the pseudo code of our simple scheme that explores
the and or search tree and generates solutions one by one in order of their costs  at each step 
the algorithm removes the next partial solution tree t   from open  line     if t   is a complete
solution  it is added to the list of solutions along with its cost  lines       otherwise the algorithm
expands a tip node n of t     generating its successors  line         each such newly generated node
n  is added to t   separately  yielding a new partial solution tree t     lines         whose cost is
recursively evaluated using algorithm    as in aobb  line      these new partial trees are then
placed in open  line      search stops when all m solutions have been found 
we note that the maintenance of the open list containing explicit partial solution subtrees is a
source of significant additional overhead which will become apparent in the empirical evaluation in
section    thus  the question whether the performance of m aobf can be improved further is open
and is therefore a rich topic of future work 
all m a  properties  section      can be extended to m aobf  in particular  algorithm maobf with an admissible heuristic is sound and complete  terminating with the m best solutions
generated in order of their costs  m aobf is also optimal in terms of the number of nodes expanded
compared with any other algorithm that explores the same and or search space with the same
consistent heuristic function 
t heorem     m aobf complexity   the complexity of algorithm m aobf traversing either the
h 
and or search tree or the context minimal and or search graph is time and space o k deg   
where h is the depth of the underlying pseudo tree  k is the maximum domain size  and deg bounds
the degree of the nodes in the pseudo tree  if the pseudo tree is balanced  each internal node has
exactly deg child nodes   then the time and space complexity is o k n    where n is the number of
variables 
the real complexity bound of m aobf comes from the cost function  it appears however that
maintaining an open list in a brute force manner does not lend itself easily to an effective way
of enumerating all partial solution subtrees and therefore the search space of all partial solution
subtrees is actually exponential in n  the detailed proof of theorem    is given in the appendix 
   

fif lerova   m arinescu     d echter

algorithm    m aobf exploring an and or search tree

 
 
 
 
 
 
 
 
 

  
  
  
  
  
  
  
  
  

  
  
  
  
  
  
  
  
  
  

  
  

input  a graphical model m   hx  d  fi  pseudo tree t rooted at x    heuristic function h    parameter m 
output  the m best solutions to m
create root or node s labelled by x    let g    s   explored search space  and t    s   partial solution tree  
initialize s    op en   t    i       i counts the current solution being searched for  
while i  m and op en     do
select the top partial solution tree t   and remove it from open 
if t   is a complete solution then
s  s   hf  t      t   i  
i  i     
continue 
select a non terminal tip node n in t    
   expand node n
if n is or node labeled xi then
forall the xi  d xi   do
create and child n  labeled hxi   xi i 
succ n   succ n    n    
else if n is and node labeled hxi   xi i then
forall the successor xj of xi in t do
create an or child n  labeled xj  
succ n   succ n    n    
g  g   succ n   
   generate new partial solution trees
l   
forall the n   succ n  do initialize v n      h n    
if n is or node then
forall the n   succ n  do
create a new partial solution tree t     t     n    
l  l   t      
else if n is and node then
create a new partial solution tree t     t     succ n   
forall the t     l do
recursively evaluate and assign to f  t      the cost of the partial solution tree t      based on heuristic
function h       see algorithm  
place t    in open  keeping it sorted in the ascending order of costs f  t      
return the m best solutions found s 

    m aobb  and or branch and bound for m best solutions in graphical models
algorithm m aobb extends the and or branch and bound search  aobb  section        to the
m best task  the main difference between aobb and m aobb is in the value function computed
for each node  m aobb tracks the costs of the m best partial solutions of each solved subproblem  thus it extends the node value v n  and solution tree t   n  rooted by n in aobb to ordered
sets of length m  denoted by v n  and t   n   respectively  where v n     v   n           vm  n   is
an ordered set of the costs of the m best solutions to the subproblem rooted by n  and t   n   
  n   is a set of corresponding solution trees  this extension arises due to the
 t   n           tm
depth first manner of search space exploration of m aobb in conjunction with the and or decomposition  therefore  due to the and or decomposition m aobb needs to completely solve
   

fis earching for m b est s olutions in g raphical m odels

algorithm    m aobb exploring an and or search tree

 
 

 
 
 
 
 
 
 
  
  
  
  
  

input  a graphical model m   hx  d  fi  pseudo tree t rooted at x    heuristic function h    parameter m 
output  the m best solutions to m
   initialize
create root or node s labeled by x  and let the stack of created but not expanded nodes op en    s  
initialize v s      a set of bounds on m best solutions under s  and a set of best partial solution trees rooted in s
t   s      u b     sorted list can didat e    
while op en     do
select top node n in open 
   expand
if n is or node labeled xi then
foreach xi  d xi   do
add and child n  labeled hxi   xi i to list succ n  containing the successors of n 
initialize v n         a set of best partial solution trees rooted in n t   n       
if n is and node labeled hxi   xi i then
let p be ancestor of n 
recursively evaluate and assign to f  p  the cost of the partial solution tree rooted in p  based on the heuristic h      
see algorithm  
if vm  p     and f  p   vm  p  then
prune the subtree below the current tip node n 
else
foreach successor xj of xi  t do
add or child n  labeled xj to list succ n  containing the successors of n 
initialize v n        a set of best partial solution trees rooted in n t   n       

  
  
  

  
  
  
  
  
  
  
  

  

  
  
  

  

  
  
  
  

remove n from open and add succ n  on top of open 
   propagate
while list of successors of node n is empty do
if n is the root node then
return a set of solutions rooted at n and their costs  t   n   v n   
else
update ancestors of n  and and or nodes p  bottom up 
if p is and node then
combine the set of the partial solution trees to the subproblem rooted in p t   p  and the set of partial
solution trees rooted in n t   n  and their costs v p  and v n      see algorithm  
assign the resulting set of the costs and the set of the best partial solution trees respectively to v p  and
t   p  
else if p is or node then
foreach solution cost vi  n  in the set v n  do
update the cost with the weight of the arc  creating a new set of costs v    n  
vi   n    c p  n    vi  n  
merge the sets of partial solutions v n  and v p  and the sets of partial solution trees rooted in p and n 
t   p  and t   n   keeping m best elements    algorithm   
assign results of merging respectively to v p  and t   p  
remove n from the list of successors of p 
move one level up  n  p 
return v s  and t   s 

the subproblems rooted in all the children n  of an and node n  before even a single solution to a
subproblem above n is acquired  unlike the m bb case   consequently  during the bottom up phase
sets of m costs have to be propagated and updated  m aobf on the other hand  only maintains a
set of partial solution trees 
   

fif lerova   m arinescu     d echter

algorithm    combining the sets of costs and partial solution trees
 

 
 
 

 
 
 
 
 
  
  

function combine v n   v p   t   n  t   n  
input  input sorted sets of costs v n   v p   corresponding partial solution trees t   n   t   p   number of
required solutions m
output  a set of costs m best combined solutions v    p   corresponding partial solution trees t    p 
   initialize
sorted list open  initially empty    contains potential cost combinations
v    p     t    p    
k        number of partial solutions already assembled  up to m in total
   search over possible combinations
open v   n    v   p  
while k   m and op en is not empty do
remove the top node v on open  where v   svi  n    vj  p  
vk   p   v  
 
t   p   ti  n   tj  p  
if vi    n    vj  p  not in op en then
put vi    n    vj  p  in op en  

  

if vi  n    vj    p  not on op en then
put vi  n    vj    p  in op en  

  

k  k     

  

return v    p   t   p  

  

unlike m aobf that discovers solutions one by one in order of their costs  m aobb  pseudocode in algorithm    reports the entire set of m solutions at once  at termination  m aobb interleaves forward node expansion  lines       with a backward propagation  or cost revision  step
 lines        that updates node values until search terminates  a node n will be pruned  lines       
if the current upper bound on the mth solution under n  vm  n   is lower than the nodes evaluation
functions f  n   which is computed recursively as in aobb  algorithm     during the bottom up
propagation phase at each and node the partial solutions to the subproblems rooted in the nodes
children are combined  line        algorithm     at each parent or node p v p  and t   p  are
updated to incorporate the new and possibly better partial solutions rooted in a child node n  lines
       algorithm     
      c haracterizing n ode p rocessing overhead
in addition to the increase in the explored search space that m bb experiences compared with bb
due to the reduced pruning  section       and or search introduces additional overhead for maobb  the propagation of a set of m costs and of m partial solution trees leads to an increase in
memory by a factor of m per node  processing the partial solutions at both or and and nodes
introduces an additional overhead 
t heorem     algorithm m aobb exploring the and or search tree has a time overhead of
o m  deg  log m  per and node and o m  k  per or node  where deg bounds the degree of the
pseudo tree and k is the largest domain size  assuming k   deg  log m   the total worst case time
complexity is o n  k h deg  m log m   and the space complexity is o mn   the time complexity

of m aobb exploring the and or search graph is o n  k w deg  m log m    space complexity

o mn  k w   
   

fis earching for m b est s olutions in g raphical m odels

algorithm     merging the sets of costs and partial solution trees
 

 
 
 
 

 
 
 
 
  
  
  
  
  
  
  

  

function merge v n  v p  t   n  t   p  
input  input sorted cost sets v n  and v p   sets of corresponding partial solution trees t   n  and t   p  
number of required solutions m
output  v    p   a merged set of m best solution costs  t    p  a set of corresponding partial solution trees
   initialize
v    p    
t    p    
i  j       indices in the cost sets
k       index in the resulting array
   merge two sorted sets
while k  m do
if vi  p   vj  n  then
vk   p   vi  p  
 
tk  p   ti  p  
i  i     
k  k     
else
vk   p   vj  n  
 
tk  p   tj  n  
j  j     
k  k     
return v    p  and t    p  

proof  combining the sets of current m best partial solutions  algorithm    introduces an overheard
of o m log m    the resulting time overhead per and node is o deg  m log m    merging two
sorted sets of costs  algorithm     can be done in o m  steps  if an or node has o k  children 
the resulting overhead is o m  k   assuming k   deg  log m   the complexity is dominated by
processing of the and nodes  in the worst case  the tree version of m aobb  called m aobb tree 
would explore the complete search space of size o n  k h    where h bounds the depth of the pseudo

tree  while the graph version  called m aobb graph  would visit a space of of size o n  k w   
where w is the induced width of the pseudo tree  the space complexity of m aobb tree follows
from the need to propagate the sets of o m  partial solutions of length o n   the time overhead for
m aobb is the same for and or trees and and or graphs  the space complexity of m aobbgraph is explained by the need to store m partial solutions for each cached node 

    algorithm be m bf
it is known that exact heuristics for graphical models can be generated by the bucket elimination
 be  algorithm described in section        we can therefore first compile the exact heuristics along
an ordering using be and then apply m a   or m aobf  both will work the same at this point  
using these exact heuristics  the resulting algorithm is called be m bf  worst case analysis of
this algorithm will show that it yields the best worst case complexity compared with any known
m best algorithm for graphical models 
   

fif lerova   m arinescu     d echter

t heorem     the time complexity of be m bf is o nk w     nm  when n is the number of
variables  k is the largest domain size  w is the induced width of the problem and m is the desired
number of solutions  the space complexity is o nk w   nm  
proof  bes time complexity is o nk w     and space complexity of o nk w    dechter        
since be compiles an exact heuristic function  m a  with this exact heuristic expands nodes for
which f  n    cj only while searching for ith solution  if the algorithm breaks ties in favour of
deeper nodes  it will only expand nodes on solution paths  each path has length n  yielding the total
time and space complexity of this step of the algorithm equal to o n  m  

   related work
we can distinguish several primary approaches employed by earlier m best exact algorithms  some
mentioned already in the introduction  note that some of the original works do not include space
complexity analysis and the bounds provided are often our own 
the first and most influential approach was introduced by lawler         it aimed to use of theshelf optimization schemes for best solutions  lawler showed how to extend any given optimization
algorithm to the m best task  at each step  the algorithm seeks the best solution to a re formulation
of the original problem that excludes the solutions already discovered  the scheme has been improved over the years and is still one of the primary strategies for finding the m best solutions  the
time and space complexity of lawlers scheme are o nmt  n   and o s n   respectively  where
t  n  and s n  are the time and space complexity of finding a single best solution  for example 
if we use aobf as the underlying optimization algorithm  the use of lawlers method yields time


complexity of o n  mk w log n   and space complexity of o nk w log n   
hamacher and queyranne        built upon lawlers work but used as building blocks algorithms that find both the first and second best solutions  once two best solutions are generated  a
new problem is formulated so that the second best solution is the best solution to the new problem 
then  the second best solution for the new problem becomes the overall third best solution and the
procedure is repeated  the algorithm has time complexity of o m  t   n   and space complexity of
o s   n    where t   n  and s   n  are respectively the time and space for finding the second best
solution  the complexity of this method is always bounded from above by that of lawler  seeing
that lawlers scheme can be used as an algorithm for finding the second best task  using m aobf

to find the two best solutions  we obtain time complexity of o  mnk w log n   and space complexity

o  nk w log n   
nilsson        applied lawlers method using a join tree algorithm  on top of that his algorithm reuses computations from previous iterations  his scheme  called max flow algorithm  uses
message passing on a junction tree to calculate the initial max marginal functions for each cluster
 e g  probability values of the most probable assignments task  yielding the best solution  note that
this step is equivalent to running the bucket elimination algorithm  subsequent solutions are recovered by conditioning search which consult the generated function  the time complexity analysis by
nilsson        is o  p c     mp r    pm log  pm    where p is the number of cliques in the joint
tree   c  is the size of the largest clique and  r  is the size of the largest residual  i e  the number
of variables in a cluster but not in neighbouring clusters   the space complexity can be bounded by
o p c    p  s     where  s  is the size of a separator between the clusters  if applied to a buckettree  nilssons scheme has time and space complexity of o  nk w     mn  k   log mn   and


o nk w      nk w   respectively  since the the bucket tree has p   n cliques  whose size is bounded
   

fis earching for m b est s olutions in g raphical m odels



by  c    k w    and the residual in each cluster is  r    k  the domain of a single variable  
thus the algorithm has better time complexity than all other schemes mentioned so far  except for
be m bf 
two works by de campos et al  build upon nilssons approach  extending it to solving the mbest map task using genetic algorithms  de campos  gamez    moral        and probability trees
 de campos  gamez    moral         respectively  these schemes are approximate and the authors
provide no theoretical analysis of their complexity 
fairly recently  yanover and weiss        developed an iterative scheme based on belief propagation  called bmmf  at each iteration bmmf uses loopy belief propagation to solve two new
problems obtained by restricting the values of certain variables  when applied to a junction tree

having induced width w  whose largest cluster size is bounded by k w      it is an exact algorithm
having time complexity o  mnk w     and space complexity o nk w   mnk   when applied on
a loopy graph  bmmf is not guaranteed to find exact solutions 
another approach based on lawlers idea uses optimization via the lp relaxation  wainwright
  jordan         formulated by fromer and globerson         their method  called spanning tree
inequalities and partitioning for enumerating solutions  or stripes  also partitions the search
space  while systematically excluding all previously determined assignments  at each step new
constraints are added to an lp optimization problem  which is solved via an off the shelf lp solver 
in general  the algorithm is approximate  however  on trees or junction trees it is exact if the
underlying lp solver reports solutions within the time limit  pesteelars is an extension of the
above scheme by batra        that solves the lp relaxation using message passing approach that 
unlike conventional lp solvers  exploits the structure of the problems graph  the complexity of
these lp based algorithm is hard to characterize using the usual graph parameters 
another approach extends variable elimination  or dynamic programming  schemes to directly
obtain the m best solutions  in our recent paper  flerova et al         we extended bucket elimination and mini bucket elimination to the m best solutions task  yielding an exact scheme called
elim m opt and its approximate version called mbe m opt  respectively  this work also embeds
the m best optimization task within the semi ring framework  the time and space complexities of


algorithm elim m opt are bounded by o m log mnk w      and o mnk w    respectively 
two related dynamic programming based ideas are by seroussi and golmard        and elliot
        seroussi and golmard extract the m solutions directly  by propagating the m best partial
solutions along a junction tree  given a junction tree with p cliques  largest cluster size  c   separator
size bounded by  s  and branching degree deg  the time complexity of the algorithm is o m   p 
 c   deg  and the space complexity is o m  p   s    adapted to a bucket tree  this algorithm has


time complexity o m  nk w    deg  and space complexity of o mnk w    elliot propagates the m
best partial solutions along a representation called valued and or acyclic graph  also known as
a smooth deterministic decomposable negation normal form  sd dnnf   darwiche         the

time complexity of elliots algorithm is o nk w    m log  m  deg   and the space complexity is

o mnk w      
several methods focus on search schemes obtaining multiple optimal solution for the k shortest
paths task  ksp   for a survey see the paper by eppstein         the majority of these algorithms
assume that the entire search graph is available in memory and thus are not directly applicable  a
recent exception is by aljazzar and leue         whose k  algorithm finds the k shortest paths
during search on the fly and thus can be potentially useful for graphical models  the algorithm
interleaves a  search on the problems implicit graph g and dijkstras algorithm        on a spe   

fif lerova   m arinescu     d echter

be m bf


o nk w

m aobf


o nk w

log n

  

  mn 

o  nk w

 



nilsson     

  

  mn   log mn     k  

elim m opt


gosh et al      

elliot
    


yanover and weiss     

m aobb


hamacher and queyranne

o mnk w

o mnk w

  

  



o mnk w  

log m 

log  m  deg  

o mnk w

o mnk w deg log m 



o  mnk w

  

log n

aljazzar and leue     


o nk w w log  nk    m 

 

 

seroussi and golmard     
o m  nk w   deg 

lawler     

o n  mk w  

m a  tree
o k n  

m bb tree

o k n   log m 

figure    time complexity comparison of the exact m best algorithms specified for a bucket tree 
a parent node in the graph has a better complexity than its children  problem parameters 
n   number of variables  k   largest domain size  w   induced width  deg   the degree of
the join  bucket  tree  our algorithms are highlighted 

cific path graph structure denoted p  g   p  g  is a directed graph  the vertices of which correspond
to edges in the problem graph g  given a consistent heuristic  k    when applied to an and or

search graph is time and space o nk w w log n  k    m  
more recently  gosh  et al          introduced a best first search algorithm for generating ordered solutions for explicit and or trees or graphs  the time complexity of their algorithm can
be bounded by o mnk w    when applied to a context minimal and or search graph  the space
complexity is bounded by o s  nk w      where s is the number of candidate solutions generated
and stored by the algorithm  hard to quantify using usual graph parameters  however  this approach 
which explores the space of complete solutions  does not seem to be practical for graphical models
because it requires the entire and or search space to be fully explicated in memory before attempting to generate even the second best solution  in contrast  our algorithms generate the m best
solutions while traversing the space of partial solutions 
   

fis earching for m b est s olutions in g raphical m odels

figure   provides a visual comparison between the worst case time complexity bounds of the
discussed schemes in a form of a directed graph  where each node corresponds to an algorithm
and a parent in the graph has a better complexity than its child  we assume in our analysis that
n    m   k     
we see that the best emerging scheme  as far as worst case performance goes is be m bf 
however  since it requires compiling of the exact heuristics  it is often infeasible  we see also that
algorithm elim m opt appears to have relatively good time complexity superior  for example  to maobb search  however  as we showed in our previous work  flerova et al          it is quite limited
empirically  note that the worst case analysis often fails to capture the practical performance  either because the algorithms that have good worst case performance require too much memory  or
because it ignores the power of the cost function in bounding the performance 

   experimental evaluation
our experiments consist of two parts  evaluation of the m best search algorithms on the benchmarks
from recent uai and pascal  competitions and comparison of our schemes with some of the previously developed algorithms on randomly generated networks  whose parameters and structure had
to be restricted due to the limitations of the available implementations of the competing schemes 
we defer the discussion of the second part of experiments until section      concentrating now on
the evaluation our m best search schemes only 
    overview and methodology
we used   benchmarks  all  except for binary grids  came from real world domains 
   pedigrees
   binary grids
   wcsp
   promedas
   proteins
   segmentation
the pedigrees benchmark  pedigree   was used in the uai      competition   they arise
from the domain of genetic linkage analysis and are associated with the task of haplotyping  a
haplotype is a sequence of alleles at different loci inherited by an individual from one parent  and
the two haplotypes  maternal and paternal  of an individual constitute this individuals genotype 
when genotypes are measured by standard procedures  the result is a list of unordered pairs of
alleles  one pair for each locus  the maximum likelihood haplotype problem consists of finding
a joint haplotype configuration for all members of the pedigree which maximizes the probability
of data  it can be shown that  given the pedigree data  the haplotyping problem is equivalent to
computing the most probable explanation of a bayesian network that represents the pedigree  see
the paper by fishelson and geiger        for more details  
   http   graphmod ics uci edu group repository

   

fif lerova   m arinescu     d echter

benchmark
pedigrees
grids
wcsp
promedas
proteins
segmentation

  inst
  
  
  
  
  
  

n
        
        
       
        
      
       

k
   
 
     
 
     
    

w
     
     
     
     
    
     

ht
      
      
      
      
    
     

table    benchmark parameters    inst   number of instances  n   number of variables  k   domain
size  w   induced width  ht   pseudo tree height 

in each of the binary grid networks             and        the nodes corresponding
to binary variables are arranged in an n by n square and the functions are defined over pairs of
variables and are generated uniformly randomly 
the wcsp    wcsp  benchmark includes random binary wcsps  scheduling problems from
the spot  benchmark  and radio link frequency assignment problems  providing a large variety of
problem parameters 
protein side chain prediction  pdb   networks correspond to side chain conformation prediction tasks in the protein folding problem  yanover  schueler furman    weiss         the
resulting instances have relatively few nodes  but very large variable domains  generally rendering
most instances very complex 
promedas  or chain    and segmentation    s binary  are probabilistic networks that
come from the set of problems used in the      probabilistic inference challenge   promedas instances are based on a bayesian network model developed for expert systems for medical diagnosis
 wemmenhove  mooij  wiegerinck  leisink  kappen    neijt         segmentation is a common
benchmark used in computer vision  modeling the task of image segmentation as an mpe problem 
namely assigning a label to every pixel in an image  such that pixels with the same label share
certain characteristics 
table   describes the benchmark parameters    inst   number of instances  n   number of variables  k   maximum domain size  w   induced width of the ordering used  ht   pseudo tree height 
the induced width is not only one of the crucial parameters indicating the difficulty of the problem 
but the difference between the induced width and the mini bucket i bound signifies the strength of
the heuristic  when the i bound is considerably smaller than the induced width  the heuristic is
weak  while the i bound equal or greater than the induced width yields an exact heuristic  which in
turn yields much faster search  clearly  a large number of variables  a high domain size or a large
pseudo tree height suggest harder problems 
      a lgorithms
we can distinguish   algorithms  be m bf  m a  tree and m bb tree exploring a regular or
search tree and their modifications that explore an and or search tree  denoted m aobf tree and
m aobb tree  we also consider a variant of m aobf that explores the and or search graph
m aobf graph  we did not implement the m aobb over and or search graph  because the
   http   graphmod ics uci edu repos mpe grids 
   http   www cs huji ac il project pascal archive mpe tgz

   

fis earching for m b est s olutions in g raphical m odels

overhead due to book keeping looked prohibitive  we used m aobf as representative for and or
graph search  and as we will see it proved indeed to be not cost effective  all algorithms were
guided by pre compiled mini bucket heuristics  described in section        we used    i bounds 
ranging from   to     however  for some hard problems computing the mini bucket heuristic with
the larger i bounds proved infeasible  so the actual range of i bounds varies among the benchmarks
and among instances within a benchmark  all algorithms were restricted to a static variable ordering
computed using a min fill heuristic  kjrulff         both and or schemes used the same pseudo
tree  in our implementation algorithms m bb  m bf and m aobf break ties lexicographically 
while algorithm m aobb solves the independent subproblems rooted at an and node in increasing
order of their lower bound heuristic estimates 
the algorithms were implemented in c       bit  and the experiments were run on a    ghz
quad core processor  the memory limit was set for   gb per problem  the time limit to   hours  we
report the cpu time  in seconds  and the number of nodes expanded during search  for uniformity
we consider the task throughout to be the maximization product problem  also known as most
probable explanation task  mpe or map   we focus on complete and exact solutions only and thus
do not report the results if the algorithm found less than m solutions  for best first schemes  or if
the optimality of the solutions was not proved  for branch and bound schemes  
      g oals of the e mpirical e valuation
we will address the following aspects 
   comparing best first and depth first branch and bound approaches
   the impact of and or decomposition on the search performance
   scalability of the algorithms with the number of required solutions m
   comparison with earlier proposed algorithms
    the main trends in the behavior of the algorithms
tables                 and    present for each of our algorithms the raw results in the form of runtime
in seconds and number of expanded nodes for select instances from each benchmark  selected to
best illustrate the prevailing trends  for each benchmark we show the results for two values of the
i bound  corresponding  in most cases  to relatively weak and strong heuristics  note that the ibound has no impact on the be m bf  since it always calculates the exact heuristic  we show three
values of number of solutions m  equal to    ordinary optimization problem      and     
in order to see the bigger picture  in figures      we show bar charts representing for each
benchmark a median runtime and a number of instances solved by each algorithm for a particular
strength of the heuristic  i bound  for m                      the y axis is on logarithmic scale 
the numbers above the bars indicate the actual values of median time in seconds and number of
solved instances  respectively  it is important to note that in these figures we only account for harder
instances  for which the i bound did not yield exact heuristic  we acknowledge that the median
times are not strictly comparable since they are calculated over a varied number of instances solved
by each algorithm  however  this metric is robust to outliers and gives us an intuition about the
algorithms relative success  in addition  tables                and    show for each benchmark the
number of instances  for which a given algorithm is the best in terms of runtime and in terms of
number of expanded nodes  if several algorithms show the same best result  it counts towards the
score of all of them 
   

fif lerova   m arinescu     d echter

instance
 n k w  h 

i bound

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
timeout
    
    
oom
oom
oom
      
         
     
       
    
    

number of solutions
m   
nodes
oom
oom
oom
timeout
timeout
    
    
oom
oom
oom
       
         
      
        
    
    

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
oot
       
        
oom
oom
oom
oom
      
        
      
       
oom

oom
oom
oom
oot
       
        
oom
oom
oom
oom
      
        
      
       
oom

oom
oom
oom
oot
       
        
oom
oom
oom
oom
      
        
      
       
oom

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
       
        
oom
oom
oom
      
       
timeout
      
       
oom

oom
oom
oom
timeout
oot
oom
oom
oom
oom
timeout
      
       
oom

oom
oom
oom
timeout
oot
oom
oom
oom
oom
timeout
      
       
oom

     

     

algorithm

m  
time

    wcsp

 

               

 

myciel g   wcsp

 

              

 

satellite  ac wcsp

 

               

 

   wcsp

 

               

 

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

     
     
     
    
   
    
    
    
    
    
   

nodes

      
oom
      
       
     
   
    
    
    
     
    
   

time

     
     
    
   
    
    
    
    
    
   

      
oom
      
       
      
   
    
    
    
     
     
   

m    
time

nodes
oom
oom
oom
timeout
timeout
    
    
oom
oom
oom
       
         
       
         
    
    

     
     
     
    
    
    
    
    
     
    

      
oom
      
       
       
   
    
    
    
     
       
   

table    wcsp  cpu time  in seconds  and number of nodes expanded  a timeout stands for
exceeding the time limit of   hours  oom indicates out of  gb memory  in bold we
highlight the best time and number of nodes for each m  parameters  n   number of
variables  k   domain size  w   induced width  h   pseudo tree height 

we next provide some elaboration and interpretation of the results 
      wcsp
table   shows the results for two values of the i bound for select instances chosen to best illustrate
the common trends seen across the wcsp benchmark  figure   presents the median time and
number of solved instances for each algorithm for i     table   shows for the same i bound  i    
the number of instances for which each of the schemes had the best runtime and best number of
expanded nodes  for many problem instances of this benchmark the mini bucket elimination with
the large i bounds is infeasible  thus we present the results for a small and a medium i bounds 
   

fis earching for m b est s olutions in g raphical m odels

be m bf
m aobf tree

m aobf graph
m a  tree

    
    
    
    
    

    

  

   

 
 
 
 

 
 
 

 
 
 

 
 
 

 

solved instances

wcsps  i   

 
 

 

 

 

 

m bb tree
m aobb tree

 
 

 
 

 

 

m aobf graph
m a  tree

 

be m bf
m aobf tree
 

   
    
    
    

   
   
    
    
    

 
m

 

 
 

 

    

   

    

    
    
   
    
    
    

    
   

   
    
    
    

median time
wcsps  i   

   

m bb tree
m aobb tree
    

   

   

 

 

 

m

  

   

figure    median time and number of solved instances  out of     for select values of m for wcsps 
i bound     numbers above bars   actual values of time  sec  and   instances  total
instances in benchmark      discarded instances due to exact heuristic     

be m bf  as suggested by theory  whenever be m bf does not run out of memory  it is the
most efficient scheme  see for example table        wcsp and    wcsp  however  calculation of
the exact heuristic is only feasible for easier instances and  as figure   shows  it can only solve
   

fif lerova   m arinescu     d echter

algorithm

not solved
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

wcsps    inst     n        
k        w         ht         i bound   
m  
m  
m  
m   
m    
 bt    bn  bt    bn  bt    bn  bt    bn  bt    bn
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

table    number of instances  for which each algorithm has the best runtime   bt  and best number
of expanded nodes   bn   wcsps  out of    instances    have exact heuristics  the table
accounts for remaining     i bound      

  wcsp instances  as seen in table    on these two instances be m bf demonstrated the best
runtime among all the schemes 
m aobb tree  for a number of problems for small values of m  m aobb tree is superior to mbb tree both in terms of the runtime and in number of expanded nodes  for example  for    wcsp 
i    m    m aobb tree requires      seconds to solve the problem and expands        nodes
while the runtime of m bb tree is       seconds and it expands         nodes  however  on the
majority of instances m aobb tree is slower than all other schemes  as seen in figure    moreover 
m aobb tree scales poorly with the number of solutions  for m       it very often has both the
worst runtime and the largest explored search space among all the schemes  e g  i        wcsp 
such striking decrease in performance as m grows is consistent across various benchmarks and
can be explained by the need to combine sets of partial solutions at and nodes as we described
earlier  the overhead connected to and or decomposition also accounts for the larger time per
node ratio of m aobb tree  compared to other schemes  for example  in table   for instance
myciel g   wcsp  i    for m    and m     m aobb tree expands less nodes than m bb tree  but
its runtime is larger  nevertheless  m aobb tree has its benefits  since it is more space efficient
than the other algorithms  it is often the only scheme able for find solutions for the harder instances 
especially when the heuristic is weak  as we see for myciel g   wcsp for i   and satellite  ac wcsp
for both i   and i    respectively 
m bb tree  in figure   we see that m bb tree solves almost the same number of problems as
m aobb tree while having considerably better median time 
m aobf tree and m aobf graph  unsurprisingly  best first search algorithms often run out of
space on problems feasible for branch and bound  such as     wcsp and myciel g   wcsp for i   
m aobf based schemes are overall inferior to other algorithms  solving  as figure   shows  the
least number of problems  both schemes run out of memory much more often than m a  tree  we
believe this is due to overhead of maintaining an open list of partial solution trees  as opposed of
an open list of individual nodes as m a  tree does  whenever the m aobf schemes do manage
to find solutions  as for example for instance    wcsp  i    m aobf graph explores the smallest
   

fis earching for m b est s olutions in g raphical m odels

search space among the schemes  except for be m bf  at the same time m aobf tree sometimes
expands more nodes compared not only to m aobf graph  but also to m a  tree  which is not what
we would normally expect  since m a  tree traverses an or search space  which is inherently larger
than the and or one  however  it is important to remember that though better space efficiency
of and or schemes is often observed  it is not guaranteed  many factors  such as tie breaking
between the nodes with the same value of evaluation function  can impact the performance of maobf tree  m aobf tree and m aobf graph have almost the same median time and number of
solved problems  as seen in figure   
m a  tree  out of the three best first algorithms m a  tree is overall the best  in figure   we see
that it solves more instances than all other schemes for all values of m and its median runtime is
close to that of be m bf  table   proves that for i bound    this scheme is the fastest among all
the schemes on largest number of instances  showing best runtime on     instances  depending on
m  this is explained in part by the relatively reduced overhead for maintaining the search space and
open list in memory  compared for example with the m aobf schemes 
      p edigrees
table   displays the results for select instances from the pedigree benchmark for two i bounds each 
overall  the difference between the results for the algorithms greatly diminishes as the heuristic
strength increases  figure    shows the median time and number of solved instances for select
values of m for i     the number of instances for which each of the schemes had the best runtime
and best number of expanded nodes for the same i bound is presented in table   
be m bf  here too be m bf is often superior to other algorithms  especially when the other
schemes use lower values of the i bound  e g  pedigree    i     all ms  for large i bounds and thus
more accurate heuristics the difference is much smaller  moreover  sometimes be m bf can be
slower than other schemes  due to the time required to calculate the exact heuristic  e g  pedigree   
i     table   shows that be m bf is overall the fastest  we see that on the pedigree benchmark
this algorithm is quite successful  as is evident from the many instances it solved  see figure     
m aobb tree  for low values of m m aobb tree is slightly superior to all other algorithms 
solving the most number of instances   see figure      on the other hand  its median time is the
largest  it fails to solve any instances for m      from table   we see that m aobb tree is the
slowest   e g   pedigree    i     all ms   yet  for instance pedigree    i     m    this scheme is
the only one to find any solution 
m bb tree  as expected  m bb tree is inferior to the best first search schemes unless the latter
run out of memory  as was the case for wcsp  this scheme is often faster than m aobb tree  for
example  on pedigree    i     all values of m  the bar charts show that m bb tree has the second
worst median time for all values of m  but solves the most number of problems for m     
m aobf schemes  both m aobf algorithms are unsuccessful on the pedigree benchmark  they
often run out of memory even for m      e g  pedigree    i      for most instances where they
do report solution m aobf tree is faster than m aobf graph  though the difference is usually not
very large 
m a  tree  as we saw for wcsps  on some pedigree instances m a  tree is faster than the two
m aobf schemes  as seen in figure     all values of m  moreover  it is superior on harder instances
   

fif lerova   m arinescu     d echter

instance
 n k w  h 

i bound

pedigree  

  

algorithm

m  
time

                 
  

pedigree  

  

                  

  

pedigree  

  

                

  

pedigree  

  

                
  

nodes

number of solutions
m   
time
nodes
oom
oom
oom
timeout
timeout
oom
oom
oom
    
     
    
      
timeout
oom

m    
nodes
oom
oom
oom
timeout
timeout
oom
oom
oom
    
      
     
      
timeout
oom
time

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
       
         
oom
oom
oom
    
     
    
      
    
     
oom

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
       
        
    
    
oom
oom
     
       
     
        
      
       
    
    

oom
oom
oom
timeout
oot
    
    
oom
oom
     
       
     
        
timeout
    
    

oom
oom
oom
timeout
oot
    
     
oom
oom
     
       
      
        
timeout
    
     

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
    
      
    
       
     
      
    
   
oom
oom
    
     
   
      
     
      
    
   

oom
oom
      
       
        
    
oom
oom
     
      
        
    

oom
oom
     
      
     
       
timeout
    
     
oom
oom
    
     
     
       
oom
    
     

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

    
     
     
     

     
     
     
     

oom
oom
       
       
       
   
oom
oom
       
       
       
   

    
     
      
    

    
    
      
    

     
     
       
     

     
     
      
     

oom
oom
       
       
        
    
oom
oom
       
       
        
    

oom
oom
       
       
timeout
     
     
oom
oom
     
       
    
       
timeout
     
     
     
     

table    pedigrees  cpu time  in seconds  and number of nodes expanded  a timeout stands
for exceeding the time limit of   hours  oom indicates out of  gb memory  in bold
we highlight the best time and number of nodes for each m parameters  n   number of
variables  k   domain size  w   induced width  h   pseudo tree height 

infeasible for both m aobf schemes and be m bf  e g  pedigree    i     as shown in figure    
it solves   instances for i     for all ms  which is the best or second best results  depending on the
number of solutions  however  the median time of m a  tree is considerably larger than that of
be m bf  while for this i bound the latter solves only a single instance less 
      b inary g rids
table   shows the results for select instances from the grid networks domain  figure    shows the
median runtime and number of solved instances for i     while table   presents the number of
instances  for which an algorithm is the best  for the same i bound  most trends in the algorithms
   

fis earching for m b est s olutions in g raphical m odels

m aobf graph
m a  tree

m bb tree
m aobb tree

      

be m bf
m aobf tree

    

    

    

     

     

    

     

m bb tree
m aobb tree
 
 
 

 
 
 

 

 
 
 

 
 

 
 

 

   

   
   

   

m aobf graph
m a  tree

 
 
 

  

m

be m bf
m aobf tree

  

   

   

 

m

   
   

 

   
   

 

   
   

    

   
   

   

   
   

solved instances
pedigrees  i   

    
   
   

 

 

 

 

    
   
   

    
   
   

   

    
   
   

    

   

   

    

     

   

     

     

median time
pedigrees  i   

      

   

figure     median time and number of solved instances  out of     for select values of m for pedigrees  i bound     numbers above bars   actual values of time  sec  and   instances 
total instances in benchmark       discarded instances due to exact heuristic    

behavior observed on wcsp and pedigree benchmarks can be also noticed on the grid benchmark
as well  in particular  m aobb tree is very successful when m is small  even solving the most
instances  as seen in figure     but it shows worse results for m     and for any number of
solutions has the largest median time  m bb tree has smaller median time for all ms  but is still
   

fif lerova   m arinescu     d echter

algorithm

not solved
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

pedigrees    inst     n         
k      w         ht          i bound   
m  
m  
m  
m   
m    
 bt    bn  bt    bn  bt    bn  bt    bn  bt    bn
 
 
 
 
 
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

table    number of instances  for which each algorithm has the best runtime   bt  and best number
of expanded nodes   bn   pedigrees  out of    instances   have exact heuristics  the table
accounts for remaining     i bound      

considerably slower than any of the best first schemes  m a  tree presents the best compromise
between a small medium running time and a relatively large number of solved instances  table  
shows that for majority of grid instances it is the fastest algorithm  the two m aobf schemes have
results quite similar to each other  solving almost the same number of instances for all ms with little
difference in median runtimes  as is shown in figure     they both are consistently inferior to all
other schemes except for be m bf  which often runs out of memory  the main difference of the
grid benchmark compared with the previously discussed domains lies in the behaviour of be mbf when the i bound is high  even though it expands less nodes  for many problems be m bf is
slower than the other schemes due to the large time required to compute the exact heuristic  for
example  on grid          i     for m    the runtime of be m bf is        seconds  while even
m aobb tree  known to be slow  terminates in just      seconds  at the same time  for this instance
be m bf explores the smallest search space for all values of m 
      p romedas
table   shows the results for the promedas benchmark  figure    presents the median time and number of solved instances for the benchmark for i     table   shows for the same i bound the number
of instances for which each of the schemes had the best runtime and best number of expanded nodes 
a significant fraction of the instances is not solved by any of the algorithms  especially for low and
medium i bounds  unlike the other benchmarks  m aobb tree not only solves the most instances
for small ms  but also is quite successful for m      solving only one instance less than the best
scheme for this value of m  m bb tree  moreover  sometimes m aobb tree is the only scheme to
report any solutions  especially for weak heuristic  e g  or chain    fg and or chain     fg  i    
be m bf runs out of memory on most instances  as seen in table    overall  the variance of the
algorithms performance is more significant for promedas than for the previously discussed benchmarks  for example  as we see in figure     for i    m a  tree  m bb tree and m aobb tree solve
between    and    instances for m           while be m bf and both m aobf based schemes
solve only between   and   instances  table   demonstrates that m a  tree most often is the fastest
of the algorithms 
   

fis earching for m b est s olutions in g raphical m odels

instance
 n k w  h 

       

i bound

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
    
      
    
       
    
      
oom
oom
oom
oom
oom
timeout
      
        
oom
oom

number of solutions
m   
time
nodes
oom
oom
     
       
     
       
     
       
oom
oom
oom
oom
oom
timeout
      
        
oom
oom

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
       
   
oom
oom
     
      
     
   

oom
oom
oom
timeout
      
        
     
    
oom
oom
    
     
    
      
      
       
     
    

oom
oom
oom
timeout
timeout
     
    
oom
oom
    
      
    
      
timeout
     
    

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
      
        
oom
oom
oom
oom
   
      
     
        
     
       
oom
oom

oom
oom
oom
timeout
      
        
oom
oom
oom
oom
    
      
     
        
      
       
oom
oom

oom
oom
oom
timeout
       
        
oom
oom
oom
oom
    
      
     
        
      
        
oom
oom

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
      
         
      
   
oom
oom
    
       
     
       
     
       
      
   

oom
oom
oom
timeout
timeout
      
    
oom
oom
     
       
     
       
    
       
      
    

oom
oom
oom
timeout
timeout
      
     
oom
oom
     
       
     
       
timeout
      
     

algorithm

m  
time

  

                
  

       
  

                
  

       

  

                

  

       

  

                
  

     
     

    
    
    
     

nodes

m    
time

nodes
oom
oom
     
       
     
       
timeout
oom
oom
oom
oom
oom
timeout
       
        
oom
oom

table    grids  cpu time  in seconds  and number of nodes expanded  a timeout stands for
exceeding the time limit of   hours  oom indicates out of  gb memory  in bold we
highlight the best time and number of nodes for each m  parameters  n   number of
variables  k   domain size  w   induced width  h   pseudo tree height 

      p rotein
table    shows select protein instances for i   and i    respectively  figure    and table    show
the summary of the results for i    this benchmark is fairly difficult due to very large domain size
 up to      the heuristic calculation is not feasible for higher i bounds  in particular  be m bf has
considerable problems in calculating the exact heuristic  even for low i bounds only relatively easy
instances are solved  note that for instances pdb ctk and pdb dlw i bound   yields exact heuristic 
both m aobf tree and m aobf graph fail to find any solutions within the memory limit on the
majority of instances  e g   pdb b v and pdb cxy  i    there is not much difference between the
runtimes of all algorithms  with an exception of m aobb tree  for example  for pdb b v  i   
   

fif lerova   m arinescu     d echter

m aobf graph
m a  tree

m bb tree
m aobb tree
      

be m bf
m aobf tree

     
    

  

m

   

m bb tree
m aobb tree
  
  

  
  
  

  
  

  
  

  

m aobf graph
m a  tree

  

be m bf
m aobf tree

    

    
    
    

    

   
   
    

 

 

    
    
   

     

     
     

     
     
    

 

  
  
  

    

   

    

    

   

    
    

   

    
    

     
     

median time
grids  i   

   

     

   

 
 
 
 

 

 
 

 
 
 

 

 
 

 

 

solved instances

grids  i   

 

   

   

 

 

 

m

  

   

figure     median time and number of solved instances  out of     for select values of m for
grids  i bound     numbers above bars   actual values of time  sec  and   instances 
total instances in benchmark      discarded instances due to exact heuristic    

m aobb tree requires      seconds to find m    solutions  while the runtimes of other algorithms
range from      to      seconds  except for be m bf which runs our of memory   however 
the slow performance of m aobb tree on easier problems that are feasible for all algorithms is
compensated by the fact that for many instances it is the only scheme to report any solution  solving
   

fis earching for m b est s olutions in g raphical m odels

algorithm

not solved
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

grids    inst     n         
k      w         ht          i bound   
m  
m  
m  
m   
m    
 bt    bn  bt    bn  bt    bn  bt    bn  bt    bn
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
      
      
   
   
   
   
   
   
   
   

table    number of instances  for which each algorithm has the best runtime   bt  and best number
of expanded nodes   bn   grids  out of    instances   have exact heuristics  the table
accounts for remaining     i bound      

most instances by considerable amount for m           figure      table    shows that m aobbtree is the best both in terms of time and space for the overwhelming majority of problems for all
values of m except for m       
      s egmentation
table    shows the results for select instances from the segmentation benchmark for two i bounds 
namely i   and i     while figure    and table    present the summary of the results for i    
unlike wcsp  for this benchmark we chose to display relatively low i bounds not because calculating heuristic with larger is is infeasible  but because the problems have low induced width and
we wished to avoid displaying results obtained with exact heuristics  the main peculiarity of this
benchmark is the striking success of be m bf  overall it solves as many instances as the usually
superior m a  tree and m bb tree  as is seen in figure     moreover  its runtime is superior to
the other schemes  as is true for all instances in table    and is also illustrated by the results in the
table     when the heuristic is very weak  m aobb tree is fairly successful  for example  finding
solutions for all values of m for      s binary  i    which is infeasible for any other scheme except
for be m bf  however  as usual  m aobb tree is the overall slowest of the schemes 
    best first vs depth first branch and bound for the m best solutions
let us again consider the data presented in tables      and figures      in order to summarize our
observations and contrast the performance of best first and depth first branch and bound schemes 
among the best first search schemes m a  tree is the most successful  it is often very effective 
when armed with a good heuristic  and requires less space than the other best first schemes  as we
already noted  be m bf shows good results on the segmentation benchmark  where it is the best
algorithm in terms of the median runtime  while solving at least the same number of problems as
the other schemes  however  on the other benchmarks the calculation of the exact heuristic is often
infeasible 
   

fif lerova   m arinescu     d echter

instance
 n k w  h 

i bound

  

                

  

                

or chain     fg

  

  

  

                
  

or chain    fg

m  
time

or chain     fg

or chain     fg

algorithm

  

               
  

nodes

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
    
      
     
       
     
       
oom
oom
oom
   
       
    
       
      
       
oom

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
       
          
     
       
oom
oom
oom
     
       
      
        
     
       
oom

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

number of solutions
m   
time
nodes
oom
oom
     
       
     
       
      
       
oom
oom
oom
     
       
     
       
      
        
oom

m    
time

     
     
      

     
      
      

nodes
oom
oom
       
        
        
oom
oom
oom
       
        
        
oom

oom
oom
oom
oot
        
oom
oom
oom
       
        
        
oom

oom
oom
oom
oot
       
        
oom
oom
oom
oom
      
         
      
        
oom

oom
oom
oom
timeout
        
oom
oom
oom
       
        
        
oom

oom
oom
oom
timeout
       
         
oom
oom
oom
     
       
      
        
       
        
oom

oom
oom
oom
timeout
timeout
oom
oom
oom
     
       
      
        
       
        
oom

oom
oom
oom
timeout
       
        
oom
oom
oom
     
       
     
        
timeout
oom

oom
oom
oom
timeout
       
        
oom
oom
oom
oom
      
        
timeout
oom

oom
oom
oom
timeout
       
         
oom
oom
oom
oom
      
        
timeout
oom

      

    
     
      

      

     
      
     

table    promedas  cpu time  in seconds  and number of nodes expanded  an timeout stands
for exceeding the time limit of   hours  oom indicates out of  gb memory  in bold
we highlight the best time and number of nodes for each m  parameters  n   number of
variables  k   domain size  w   induced width  h   pseudo tree height 

the two m aobf based schemes are overall inferior due to prohibitively large memory  solving
fewer instances than the other algorithms  we believe that a non trivial extension of aobf from
a single solution to the m best task is not straightforward  because it is hard to represent multiple
partial solution trees in an efficient manner  in order to have an efficient m aobf implementation 
one needs to quickly identify which partial solution subtree to select and extend next  when searching for the  k     th solution after finding the k th best solution  while aobf  for   solution  uses
an arc marking mechanism to efficiently represent the current best partial solution subtree during
search  this is not easy to extend for the case when searching for the m best solutions  therefore 
as was shown in section      our m aobf implements a naive mechanism where each of the par   

fis earching for m b est s olutions in g raphical m odels

be m bf
m aobf tree

   

m aobf graph
m a  tree

m bb tree
m aobb tree

  

m

   

m aobf graph
m a  tree

m bb tree
m aobb tree
  
  
 

 

 

 

 

 

 
 

 

 

 

 

 
 

solved instances

promedas  i   

   

 

  

  
  
  

  
  
  

  
  
  

be m bf
m aobf tree

    
    
    
    

    
    
    
    
   

    
    
    
    

 

 

      

      

      
     

      
    

 

  
  
  

    

    
    

    
    
    
    

   

   

    

     

   

     

      

median time
promedas  i   

   

       

   

   

 

 

 

m

  

   

figure     median time and number of solved instances  out of     summary for select values of
m for promedas  i bound     numbers above bars   actual values of time  sec  and  
instances  total instances in benchmark      discarded instances due to exact heuristic 
   

tial solution trees is represented explicitly in memory  this simple representation  however  incurs
a considerable computational overhead when searching for the m best solutions  which is indeed
revealed by our experiments  a more efficient implementation of m aobf is left for future work 
   

fif lerova   m arinescu     d echter

algorithm

not solved
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

promedas    inst     n         
k      w         ht          i bound   
m  
m  
m  
m   
m    
 bt    bn  bt    bn  bt    bn  bt    bn  bt    bn
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
       
       
       
       
   
   
   
   
   
      
   
   
   
   
   
   
   
   
   
   

table    number of instances  for which each algorithm has the best runtime   bt  and best number
of expanded nodes   bn   promedas  out of    instances    have exact heuristics  the
table accounts for remaining     i bound      

unsurprisingly  the branch and bound algorithms are more robust in terms of memory and also
dominate m a  tree and other best first schemes on many benchmarks in terms of the number of
instances solved  however  they tend to have considerably larger median time and expand more
nodes  in particular  m aobb tree does not scale well with the number of solutions and for large
values of m the runtime increases drastically  unlike m aobf  whose inferior performance can be
attributed to specifics of implementation  the depth first m aobb suffers from issues inherent to
solving the m best problem in a depth first manner  as algorithm    describes  m aobb needs to
merge the m best partial solution at each internal node  which hurts the performance significantly 
but cannot be avoided  unless the algorithmic approach itself is fundamentally changed  we did not
see a way to overcome this limitation 
overall  whenever the calculation of the exact heuristic is feasible  be m bf should be the
algorithm of choice  otherwise  m a  tree is superior for the relatively easy problems  while maobb tree is the best scheme for hard memory intensive instances  this superiority of a best first
approach  whenever memory is available  is expected  based  on the one hand  on intuition derived
from our knowledge of the task of finding a single solution  and on the other hand  on the theoretical
results in section     
    scalability of the algorithms with the number of required solutions
figures       present the plots showing the runtime in seconds and the number of expanded nodes
as a function of number of solutions m  on a log scale  for two instances from each benchmark 
figure    displays results for wcsp and pedigree benchmarks  figure      for grids and promedas 
figure      for proteins and segmentation  lower values  on the y axis  are preferable  each row
contains two instances from each benchmarks for a specific value of the i bound  the runtime plots
being shown above the ones containing the expanded nodes  the examples are chosen to best
illustrate the prevailing tendencies 
note that the theoretical analysis suggests that the runtime of be m bf  the best among the

algorithms  should scale with m since its worst case complexity is o nk w   mn   the theoretical
complexity of the best first search schemes m aobf tree and m a  tree is linear in the number of
   

fis earching for m b est s olutions in g raphical m odels

instance
 n k w  h 

pdb b v

                 

pdb cxy

               

i bound

m  
time

 

 

 

 

pdb ctj

 

               

 

pdb dlw

 

               

algorithm

 

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

nodes
oom
oom

    
     
    
    
    
   
    
    

    
      
      
oom
  
  
   
    
    
oom

number of solutions
m   
nodes
oom
oom
    
    
     
       
     
      
oom
    
   
    
   
    
   
    
    
    
      
oom
time

oom
oom
    
   

    
     
oom
oom
oom
    
   
    
    
    
    
oom

     
      
    
    
   
    
    
    
    
    

     
     
      
    

    
    
     
    

oom
oom
     
        
     
  
  
  
  
    
    
  
oom
oom
      
       
       
   
oom
oom
    
      
      
   

m    
time

nodes
oom
oom

    
    
      
    
    
    
   

    
       
         
oom
    
   
    
     
timeout
oom

oom
oom
    
   

oom
oom
    
     

oom

     
      
oom
oom
oom
   
    
    
     
     
       
oom

oom
oom

oom
oom

oom
oom
oom
    
    
    

     
       
     
    
    
    
    
    
    
    

     
     
      
    

    
    
      
    

   
     
     

     
        
      
   
   
  
   
    
     
   
oom
oom
      
       
        
   
oom
oom
    
      
       
   

    
    

     
       
      
    
    
    
    
    
     
    

     
     
    

    
    
    

     
         
       
    
    
  
    
     
       
    
oom
oom
      
       
oot
    
oom
oom
     
      
oot
    

table     protein  cpu time  in seconds  and number of nodes expanded  an timeout stands
for exceeding the time limit of   hours  oom indicates out of  gb memory  in bold
we highlight the best time and number of nodes for each m  parameters  n   number of
variables  k   domain size  w   induced width  h   pseudo tree height 

solutions  while for m bb tree the overhead due to the m best task is a factor of  m  log m  and
for m aobb tree it is  m log m  deg   where deg is the degree of the pseudo tree  we observed
that compared to other schemes the runtime of be m bf indeed rises quite slowly as the number
of solutions increases  even as m reaches      the runtime m a  tree also scales well with m  the
behaviour of m bb tree depends a lot on the benchmarks  on pedigrees and protein its runtime
changes very little on most instances as the number of solutions grows  but on the other benchmarks 
the runtime for m     tends to be significantly larger then for m    m aobf tree and m aobfgraph often do not provide any solutions even for m   or  alternatively  run out of memory as
m slightly increases  m            these algorithms are clearly not successful in practice  as
   

fif lerova   m arinescu     d echter

be m bf
m aobf tree

   

m aobf graph
m a  tree

m bb tree
m aobb tree

       

     

     

      
     

     
     

   

      

   

     

      

median time
protein  i  

   

 

 

  

m

   

  
  

  
  

  
  

  
  

  
  

solved instances
protein  i  

  

  

  

  
  
  

  

  

m bb tree
m aobb tree

  

  
  

  

  

  

m aobf graph
m a  tree

  

be m bf
m aobf tree

    
    
    

    

    

    
    
    

 

    
    
    

    
    
    
    

    
    
    
    

   

    

   

   

 

 

 

m

 

 

 

 

 

   

  

   

figure     median time and number of solved instances  out of     for select values of m for
protein  i bound    numbers above bars   actual values of time  sec  and   instances 
total instances in benchmark      discarded instances due to exact heuristic    

we discussed before  both the runtime and number of expanded nodes of m aobb tree increase
drastically as m gets larger 
   

fis earching for m b est s olutions in g raphical m odels

algorithm

not solved
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

m  
 bt    bn
  
   
      
      
   
       
   

protein    inst     n       
k        w        ht        i bound  
m  
m  
m   
 bt    bn  bt    bn  bt    bn
  
  
  
   
   
   
      
      
      
   
      
       
   
   
   
       
       
       
   
   
   

m    
 bt    bn
  
   
      
       
       
   
   

table     number of instances  for which each algorithm has the best runtime   bt  and best
number of expanded nodes   bn   protein  out of    instances   have exact heuristics 
the table accounts for remaining     i bound     

    comparison with competing algorithms
we compare our methods with a number of previously developed schemes described in more details
in section    stripes  pesteelars and nilssons algorithm  the implementations of these
schemes were provided by dhruv batra  the first two approaches are based on ideas of lp relaxations and are approximate  but are known to often find exact solutions  though they provide
no guarantees of optimality  nilssons algorithm is an exact message passing scheme operating on
a junction tree  for the first set of experiments  on a tree benchmark  we also show results for
stilars algorithm  an older version of the pesteelars algorithm  however  this scheme is
consistently inferior to the other two lp based schemes and is not considered for the other two
benchmarks  in the following  we collectively refer to these   algorithms as competing schemes 
      r andomly g enerated b enchmarks
the available to us code of the lp based and nilssons approaches was developed to run on restricted inputs only  and so it could not be applied to the benchmarks used in the bulk of our evaluation described above  we concluded that re implementing the competing codes to work on general
input would be too time consuming and would not provide any additional insights  thus we chose
to compare our algorithms with the competitors using benchmarks that can be acceptable to the
competing schemes 
specifically  the comparison was performed on the following three benchmarks  random trees 
random binary grids and random graphs with submodular potentials  that we call submodular
graphs in the remainder of the section  table    shows the parameters of the benchmarks  the
instances were generated in the following manner  first  a vector of    logarithmically spaced integers between    and       was generated  serving as the number of variables for the instances 
for binary grids benchmarks each value was used to generate two problems with the same number
of variables  the edges between the variables were generated uniformly randomly  while making
sure that the end graph is a tree  grid or a loopy graph  depending on the benchmark  for each edge
we define a binary potential and for each vertex a unary potential in an exponential form  f   e  
   

fif lerova   m arinescu     d echter

instance
 n k w  h 

i bound

 

                

  

                

    s binary

                

oom
oom
oom
timeout
      
       
   
   
    
      
     
    
    
    
    
    
    
    
   
   

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
     
       
    
   
    
    
    
   
    
   
    
     
    
     
    
   

oom
oom
oom
timeout
      
        
    
    
    
     
    
    
    
    
    
     
     
       
    
    

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
      
       
    
   
    
      
oom
    
    
    
    
    
    
    
   

oom
oom
oom
timeout
      
        
    
    
oom
oom
    
    
    
     
     
      
    
    

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

oom
oom
oom
timeout
      
       
    
   
oom
oom
    
      
    
      
    
     
    
   

oom
oom
oom
timeout
     
        
    
    
oom
oom
    
      
   
      
     
      
    
    

m  
time

     s binary

      s binary

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

number of solutions
m   
nodes
oom
oom
oom
timeout
      
        
    
    
     
      
oom
    
    
    
     
    
      
    
    

algorithm

 

  

 

  

     s binary

 

                

  

nodes

time

m    
time

nodes
oom
oom
oom
timeout
       
         
    
     
oom
oom
   
     
    
      
      
        
    
     

    

    
   
    

    

    
    
    

oom
oom
oom
timeout
oot
     
oom
oom
     
      
oot
     
oom
oom
oom
timeout
oot
     
oom
oom
     
     
oot
     

oom
oom
oom
timeout
oot
    
     
oom
oom
    
      
   
       
       
         
    
     

table     segmentation  cpu time  in seconds  and number of nodes expanded  an timeout
stands for exceeding the time limit of   hours  oom indicates out of  gb memory  in
bold we highlight the best time and number of nodes for each m  parameters  n   number
of variables  k   domain size  w   induced width  h pseudo tree height 

where  is a real number sampled from a uniform distribution  for the third benchmark the potentials are further modified to be submodular  on the random trees the m best optimization lp
problem is guaranteed to be tight  on the graphs with submodular potentials the lp optimization
problem is tight  but its m best extension is not  and on the arbitrary loopy graphs  including grids 
the algorithms provide no guarantees 
      c ompeting a lgorithms  p erformance
table    shows the runtimes for select instances from the random tree benchmark for our   mbest search schemes and the competing lp schemes stilars  pesteelars and stripes  we
   

fis earching for m b est s olutions in g raphical m odels

be m bf
m aobf tree

m aobf graph
m a  tree

m bb tree
m aobb tree

   

      

   

 

   

  

  
  

  

  

  

  

  
  
  

m bb tree
m aobb tree

  

  
  
  

  
  

  

  
  
  

m aobf graph
m a  tree

  
  

  
  

solved instances
segmentation  i   

  

  
  
  

be m bf
m aobf tree

   

  

m

  
  

 

    
    
   
    
    

 

    

    
    
    
    
    
   

    
    
   
    
    
    

   

    

   

    
   
    
    
    

   

   
    
   
    
    
    

median time
segmentation  i   

   

 

 

 

m

  

   

figure     median time and number of solved instances  out of     for select values of m for
segmentation  i bound     numbers above bars   actual values of time  sec  and  
instances  total instances in benchmark      discarded due to exact heuristic    

observed on this benchmarks that stilars was always inferior to the other two schemes and
therefore it was excluded from the remainder of evaluation  instead  in tables    and     where
we show results for the random binary grids and submodular graphs benchmarks  we added for
comparison nilssons max flow algorithm  in the table       the time limit was set to   hour 
memory limit to   gb  the schemes behavior is quite consistent across the instances 
   

fif lerova   m arinescu     d echter

time vs m  wcsps  bwt ac wcsp

time vs m  wcsps  queen      wcsp

                  i  

                 i   

 

  

 

time  sec

time  sec

 
  

 

 
 
 
 

 

 

   

    

number of solutions m

m aobf tree
m aobf graph

   

 e 

m a  tree
m bb tree

     

   

m aobb tree
be m bf

    

m aobf tree
m aobf graph

nodes vs m  wcsps  bwt ac wcsp
                  i  
   

 e 

     

number of solutions m
m a  tree
m bb tree

m aobb tree
be m bf

nodes vs m  wcsps  queen      wcsp
                 i   

   
   

   

nodes

nodes

   

   

   

   

   

   

   

   

   

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

   

m aobb tree
be m bf

m aobf tree
m aobf graph

m a  tree
m bb tree

     

m aobb tree
be m bf

time vs m  pedigrees  pedigree 

time vs m  pedigrees  pedigree  

                    i   

                    i   

    

    

    

    

time  sec

    

time  sec

    

number of solutions m

   

    

   
   
   
 

   
 

   

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

   

m aobb tree
be m bf

m aobf tree
m aobf graph

nodes vs m  pedigrees  pedigree  
 e 

    

number of solutions m
m a  tree
m bb tree

     

m aobb tree
be m bf

nodes vs m  pedigrees  pedigree 

                    i   

 

 

                    i   

nodes

 

   

nodes

   

 e 

   

 

   

 

   

 
   

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

   

m aobb tree
be m bf

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

m aobb tree
be m bf

figure     cpu time in seconds and number of expanded nodes as a function of number of solutions  wcsp and pedigrees    gb    hours 

   

fis earching for m b est s olutions in g raphical m odels

time vs m  grids         

time vs m  grids         

                  i   

                  i   

  

    
    
    
    
    
    
   
 

time  sec

time  sec

  
  
  
 
   

    

     

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

   

m aobb tree
be m bf

m aobf tree
m aobf graph

nodes vs m  grids         
 

 
 
 
 
 
 
 
 

m a  tree
m bb tree

m aobb tree
be m bf

                  i   

 e 

 

nodes

nodes

 
 
 
 
 

   

    

     

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

   

m aobb tree
be m bf

    

     

number of solutions m

m aobf tree
m aobf graph

time vs m  promedas  or chain    fg

m a  tree
m bb tree

m aobb tree
be m bf

time vs m  promedas  or chain     fg
                  i   

                  i   

    

  

    

 

time  sec

time  sec

     

nodes vs m  grids         

                  i   

   e 

    

number of solutions m

    

 

    

 

    

 
 

 
   

    

m aobf tree
m aobf graph

 e 

     

number of solutions m
m a  tree
m bb tree

   

m aobb tree
be m bf

    

m aobf tree
m aobf graph

nodes vs m  promedas  or chain    fg
                  i   

 e 

   

m a  tree
m bb tree

m aobb tree
be m bf

nodes vs m  promedas  or chain     fg
                  i   

nodes

   

 

nodes

 

     

number of solutions m

   

 
 

   

 

   
   

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

   

m aobb tree
be m bf

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

m aobb tree
be m bf

figure     cpu time in seconds and a number of expanded nodes as a function of number of solutions  grids and promedas    gb    hours 

   

fif lerova   m arinescu     d echter

time vs m  protein  pdb at 

time vs m  protein  pdb b v

                  i  

                   i  

   
   
   
   
   
   
   
   
 

 
 

time  sec

time  sec

 
 
 
 
 
 
   

    

     

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

   

m aobb tree
be m bf

m aobf tree
m aobf graph

nodes vs m  protein  pdb at 

m aobb tree
be m bf

   
   

   

nodes

nodes

   

   

   

   

   

   

   
   

    

     

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

   

m aobb tree
be m bf

    

     

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

m aobb tree
be m bf

time vs m  segmentation        s binary

time vs m  segmentation       s binary

                  i  

                  i   

     

 

    

 

time  sec

time  sec

m a  tree
m bb tree

                   i  

 e 

   

    

 

    

 

    

 

 

   

    

     

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

   

m aobb tree
be m bf

    

     

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

m aobb tree
be m bf

time vs m  segmentation        s binary

time vs m  segmentation       s binary

                  i  

                  i   

     

 

    

 

time  sec

time  sec

     

nodes vs m  protein  pdb b v

                  i  

 e 

    

number of solutions m

    

 

    
    

 

 

 
   

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

   

m aobb tree
be m bf

    

number of solutions m

m aobf tree
m aobf graph

m a  tree
m bb tree

     

m aobb tree
be m bf

figure     cpu time in seconds and number of expanded nodes as a function of number of solutions  protein and segmentation    gb    hours 

   

fis earching for m b est s olutions in g raphical m odels

algorithm

not solved
m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
be m bf

segmentation    inst     n        
k       w         ht         i bound   
m  
m  
m  
m   
m    
 bt    bn  bt    bn  bt    bn  bt    bn  bt    bn
  
  
  
  
  
   
   
   
   
   
   
   
      
      
      
      
      
      
      
   
   
   
   
   
   
   
   
   
   
   
       
       
       
      
       

table     number of instances  for which each algorithm has the best runtime   bt  and best number of expanded nodes   bn   segmentation  out of    instances   have exact heuristics 
the table accounts for remaining     i bound      

benchmark
random trees
random binary grids
random submodular graphs

  inst
  
  
  

n
       
       
       

k
   
 
 

w
 
    
    

ht
     
     
     

table     benchmark parameters    inst   number of instances  n   number of variables  k   domain
size  w   induced width  ht   pseudo tree height 

stilars and nilssons schemes are always dominated by the other two competing schemes
in terms of runtime  stripes and pesteelars are sometimes faster than all our schemes for
m    e g  tree nnodes    ps  k   however  on all three benchmark they scale rather poorly with
m  for m    they are almost always inferior to our algorithms  provided that the latter report
any results  with occasional exception of m aobb tree  which also tends to be slow for large m 
the only problems on which pesteelars and stripes are superior to our search schemes
are the largest networks having over a      variables  such as grid nnodes     ps  k   which
are infeasible for our algorithms  overall  our five m best algorithms proved superiority over the
considered competing schemes on the majority of instances  often having better runtime  especially
when m      while guaranteeing solution optimality 

   conclusion
most of the work on finding m best solutions over graphical models was focused on either iterative
schemes based on lawlers idea or on dynamic programming  e g   variable elimination or treeclustering   we showed for the first time that for combinatorial optimization defined over graphical
models the traditional heuristic search paradigms are not only directly applicable  but often superior 
specifically  we extended best first and depth first branch and bound search algorithms to solve
the m best optimization task  presenting m a  and m bb  respectively  we showed that the properties of a  extend to the m a  algorithm and  in particular  proved that m a  is superior to any
   

fif lerova   m arinescu     d echter

instance

tree nnodes    ps  k 

               

tree nnodes    ps  k 

               

tree nnodes     ps  k 

                 

algorithm

i bound    k  
m  
m   
time
time
    
    
    
    
    
    
    
    
    
     
    
    
   
    
    
    

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
stilars
stripes
pesteelars

m  
time
    
    
   
   
    
   
    
   

m  
time
    
    
   
   
    
    
    
    

m    
time
    
    
    
    
       
       
     
     

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
stilars
stripes
pesteelars

   
    
    
   
    
   
    
   

    
    
    
   
    
    
     
    

    
   
    
    
     
     
     
    

   
    
    
    
      
     
     
    

oom
oom
    
     
timeout
       
      
    

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
stilars
stripes
pesteelars

oom
oom
    
    
      
    
      
    

oom
oom
     
     
      
    
      
     

oom
oom
     
     
timeout
     
       
     

oom
oom
     
     
timeout
      
       
      

oom
oom
      
      
timeout
      
timeout
timeout

table     random trees  i bound    timeout   out of time  oom   out of memory    gb    hour 
other search scheme for the m best task  we also analyzed the overhead of both algorithms caused
by the need to find multiple solutions  we introduced be m bf  a hybrid of variable elimination
and best first search scheme and showed that it has the best worst case time complexity among all
m best algorithms over graphical models known to us 
we evaluated our schemes empirically  we observed that the and or decomposition of the
search space  which significantly boosts the performance of traditional heuristic search schemes 
was not cost effective for m best search algorithms  at least with our current implementation  as
expected  the best first schemes dominate the branch and bound algorithms whenever sufficient
space is available  but fail on the memory intensive problems  we compared our schemes with  
previously developed algorithms  three approximate schemes based on an lp relaxation of the problem and an algorithm performing message passing on a junction tree  we showed that our schemes
often dominate the competing schemes  known to be efficient  in terms of runtime  especially when
the required number of solutions is large  moreover  our scheme guarantee solution optimality 

acknowledgement
this work was sponsored in part by nsf grants iis         and iis          and by the united
states air force under contract no  fa        c      under the darpa ppaml program 

   

fis earching for m b est s olutions in g raphical m odels

instance

grid nnodes    ps  k 

                 

grid nnodes    ps  k 

                

grid nnodes     ps  k 

                  

algorithm

m  
time
random binary grid

i bound   
m  
m   
time
time

m   
time

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
nilsson
stripes
pesteelars

oom
oom
    
    
     
     
    
    

oom
oom
    
    
      
      
     
    

oom
oom
    
    
      
       
      
     

oom
oom
    
    
       
       
      
     

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
nilsson
stripes
pesteelars

oom
oom
   
    
    
     
    
    

oom
oom
    
    
     
      
     
    

oom
oom
    
    
     
       
     
     

oom
oom
    
    
       
      
timeout
timeout

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
nilsson
stripes
pesteelars

oom
oom
oom
timeout
timeout
oom
      
     

oom
oom
oom
timeout
timeout
oom
      
     

oom
oom
oom
timeout
timeout
oom
       
      

oom
oom
oom
timeout
timeout
oom
timeout
timeout

table     random binary grids  i bound     timeout   out of time  oom   out of memory    gb 
  hour 

   

fif lerova   m arinescu     d echter

instance

gen nnodes    ps  k 

                

gen nnodes    ps  k 

                

gen nnodes     ps  k 

                  

algorithm

i bound   
m  
m   
time
time
    
    
    
    
    
    
   
    
    
    
     
      
    
    
    
     

m   
time
    
    
    
    
      
      
     
     

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
nilsson
stripes
pesteelars

m  
time
    
    
   
   
    
    
   
   

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
nilsson
stripes
pesteelars

oom
oom
    
    
     
      
    
    

oom
oom
    
    
      
     
   
     

oom
oom
    
    
      
       
     
     

oom
oom
    
    
       
       
    
     

m aobf tree
m aobf graph
m a  tree
m bb tree
m aobb tree
nilsson
stripes
pesteelars

oom
oom
oom
timeout
timeout
oom
     
    

oom
oom
oom
timeout
timeout
oom
     
     

oom
oom
oom
timeout
timeout
oom
      
     

oom
oom
oom
timeout
timeout
oom
     
     

table     random loopy graphs with submodular potentials  i bound     timeout   out of time 
oom   out of memory    gb    hour 

   

fis earching for m b est s olutions in g raphical m odels

figure     example and or search tree with   layers of or and and nodes 

appendix a  proof of theorem   
let st be the and or search tree relative to pseudo tree t with depth h  n be the number of
variables  k be the maximum domain size  and deg be the maximum degree of the nodes in t  
define a partial solution subtree t   to be a subtree of st such that      t   contains the root s
of st       if a non terminal or node n is in t     then t   contains exactly one and child node n  of
n      if a non terminal and node n is in t   then t   contains all or child nodes n             n j of n 
    a leaf or tip node of t   doesnt have any successors in t    
the nodes in st are grouped into layers  there are h layers such that the ith layer  denoted by
li   where    i  h  contains all the or nodes whose variables have depth i in t   together with
their and children  we assume that the root of t has depth    for illustration  figure    depicts
an and or search tree with   layers  where for example l     a  ha   i  ha   i  
we denote by tior the set of partial solution subtrees whose leaf nodes are or nodes in li  
similarly  tian d is the set of partial solution subtrees whose leaf nodes are and nodes in li   a
partial solution subtree t    t or whose leaf nodes are or nodes belonging to the  nd layer is
highlighted in figure     namely t      a  ha   i  b  c  
l emma    given t    tior and t     tian d such that t    is an extension of t     then t   and t   
have the same number of leaf nodes 
proof  let m be the number of or leaf nodes in t     by definition  each of the m nodes can be
extended by exactly one and child node in t      it follows that t    has also m and leaf nodes 
l emma    given t    tior   the number of leaf nodes t     denoted by mi   is at most deg i   
proof  we show by induction that mi   deg i    if i     then m       assume that for i   p    
or   we first extend t   to t     t an d   by lemma    t    and t  
mp    deg p    and let t    tp 
p 
have the same number of leaf nodes  namely mp    next  we extend t    to t      tpor   since each
of the mp  and leaf nodes in t    can have at most deg or child nodes in t       it follows that mp  
the number of leaf nodes in t     is mp   mp   deg   deg p   deg   deg p   
proof of theorem    consider the number of partial solution subtrees n that are contained by st  
   

fif lerova   m arinescu     d echter

n 

h
x

 nior   nian d  

   

i  

nior

where
   tior   and nian d    tian d    respectively 
 
an d   it is easy to see that t   can be extended to a single partial solution subtree
given t  ti 
  
or
t  ti such that each of the leaf nodes in t   has at most deg or child nodes in t      therefore 
an d
nior   ni 

   

given t    tior   t   can be extended to at most k m partial solution subtrees t     tian d
because each of the m or leaf nodes in t   can have exactly one and child node in t    and k
bounds the domain size  by lemmas   and    we then have that 
nian d   nior  k deg

i 

   

using equations   and    as well as n or      we rewrite equation   as follows 
n        k 
   k   k deg    
   k deg     k deg

   deg  

 
   

     
   k deg
 o k

h   deg h        

deg h  
deg 

  k deg

h   deg h        

 

 

thus  the worst case number of partial solution subtrees that need to be stored in open is
h 
h 
n  o k deg    therefore  the time and space complexity of m aobf follows as o k deg   
when the pseudo tree t is balanced  namely each internal node has exactly deg child nodes  the
time and space complexity bound is to o k n    since n  o deg h    

references
aljazzar  h     leue  s          k   a heuristic search algorithm for finding the k shortest paths 
artificial intelligence                    
batra  d          an efficient message passing algorithm for the m best map problem  uncertainty
in artificial intelligence 
charniak  e     shimony  s          cost based abduction and map explanation  artificial intelligence                
darwiche  a          decomposable negation normal form  journal of the acm  jacm         
       
darwiche  a   dechter  r   choi  a   gogate  v     otten  l         
results from the probablistic inference evaluation of uai    a web report in
http   graphmod ics uci edu uai   evaluation report 
in  uncertainty in artificial intelligence applications workshop 
   

fis earching for m b est s olutions in g raphical m odels

de campos  l  m   gamez  j  a     moral  s          partial abductive inference in bayesian belief
networks using a genetic algorithm  pattern recognition letters                   
de campos  l  m   gamez  j  a     moral  s          partial abductive inference in bayesian networks by using probability trees  in enterprise information systems v  pp          springer 
dechter  r          bucket elimination  a unifying framework for reasoning  artificial intelligence 
             
dechter  r     mateescu  r          and or search spaces for graphical models  artificial intelligence                  
dechter  r     rish  i          mini buckets  a general scheme for bounded inference  journal of
the acm                
dechter  r          reasoning with probabilistic and deterministic graphical models  exact algorithms  synthesis lectures on artificial intelligence and machine learning             
dechter  r     pearl  j          generalized best first search strategies and the optimality of a  
journal of the acm  jacm                 
dijkstra  e  w          a note on two problems in connexion with graphs  numerische mathematik 
             
elliott  p          extracting the k best solutions from a valued and or acyclic graph  masters
thesis  massachusetts institute of technology 
eppstein  d          finding the k shortest paths  in proceedings   th symposium on the foundations of computer science  pp          ieee comput  soc  press 
fishelson  m     geiger  d          exact genetic linkage computations for general pedigrees  in
international conference on intelligent systems for molecular biology  ismb   pp         
fishelson  m  a   dovgolevsky  n     geiger  d          maximum likelihood haplotyping for
general pedigrees  human heredity              
flerova  n   dechter  r     rollon  e          bucket and mini bucket schemes for m best solutions
over graphical models  in graph structures for knowledge representation and reasoning
workshop 
fromer  m     globerson  a          an lp view of the m best map problem  advances in neural
information processing systems             
ghosh  p   sharma  a   chakrabarti  p     dasgupta  p          algorithms for generating ordered
solutions for explicit and or structures  journal of artificial intelligence  jair         
       
gogate  v  g          sampling algorithms for probabilistic graphical models with determinism
dissertation  ph d  thesis  university of california  irvine 
hamacher  h     queyranne  m          k best solutions to combinatorial optimization problems 
annals of operations research               
ihler  a  t   flerova  n   dechter  r     otten  l          join graph based cost shifting schemes 
arxiv preprint arxiv           
kask  k     dechter  r       a   branch and bound with mini bucket heuristics  in ijcai  vol     
pp         
   

fif lerova   m arinescu     d echter

kask  k     dechter  r       b   mini bucket heuristics for improved search  in proceedings
of the fifteenth conference on uncertainty in artificial intelligence  pp          morgan
kaufmann publishers inc 
kjrulff  u          triangulation of graphsalgorithms giving small total state space  tech  report
r       
lawler  e          a procedure for computing the k best solutions to discrete optimization problems
and its application to the shortest path problem  management science                
marinescu  r     dechter  r       a   and or branch and bound search for combinatorial optimization in graphical models  artificial intelligence                       
marinescu  r     dechter  r       b   memory intensive and or search for combinatorial optimization in graphical models  artificial intelligence                       
marinescu  r     dechter  r          and or branch and bound for graphical models  in international joint conference on artificial intelligence  vol      p       lawrence erlbaum
associates ltd 
nillson  n  j          principles of artificial intelligence  tioga  palo alto  ca 
nilsson  d          an efficient algorithm for finding the m most probable configurations in probabilistic expert systems  statistics and computing               
nilsson  n          principles of artificial intelligence  springer verlag 
otten  l     dechter  r          anytime and or depth first search for combinatorial optimization  in socs 
pearl  j          heuristics  intelligent search strategies  addison wesley 
schiex  t          arc consistency for soft constraints  international conference on principles and
practice of constraint programming  cp          
seroussi  b     golmard  j          an algorithm directly finding the k most probable configurations in bayesian networks  international journal of approximate reasoning            
    
wainwright  m  j     jordan  m  i          variational inference in graphical models  the view from
the marginal polytope  in proceedings of the annual allerton congerence on communication
control and computing  vol      pp          citeseer 
wemmenhove  b   mooij  j  m   wiegerinck  w   leisink  m   kappen  h  j     neijt  j  p         
inference in the promedas medical expert system  in artificial intelligence in medicine  pp 
        springer 
yanover  c     weiss  y          finding the m most probable configurations using loopy belief
propagation  in advances in neural information processing systems     the mit press 
yanover  c   schueler furman  o     weiss  y          minimizing and learning energy functions
for side chain prediction  journal of computational biology                

   

fi