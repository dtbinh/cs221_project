journal of artificial intelligence research                  

submitted        published      

adaptive contract design for crowdsourcing markets 
bandit algorithms for repeated principal agent problems
chien ju ho

ch    cornell edu

cornell university  ithaca  ny  usa

aleksandrs slivkins

slivkins microsoft com

microsoft research  new york  ny  usa

jennifer wortman vaughan

jenn microsoft com

microsoft research  new york  ny  usa

abstract
crowdsourcing markets have emerged as a popular platform for matching available
workers with tasks to complete  the payment for a particular task is typically set by the
tasks requester  and may be adjusted based on the quality of the completed work  for
example  through the use of bonus payments  in this paper  we study the requesters
problem of dynamically adjusting quality contingent payments for tasks  we consider a
multi round version of the well known principal agent model  whereby in each round a
worker makes a strategic choice of the effort level which is not directly observable by the
requester  in particular  our formulation significantly generalizes the budget free online task
pricing problems studied in prior work  we treat this problem as a multi armed bandit
problem  with each arm representing a potential contract  to cope with the large  and
in fact  infinite  number of arms  we propose a new algorithm  agnosticzooming  which
discretizes the contract space into a finite number of regions  effectively treating each region
as a single arm  this discretization is adaptively refined  so that more promising regions
of the contract space are eventually discretized more finely  we analyze this algorithm 
showing that it achieves regret sublinear in the time horizon and substantially improves
over non adaptive discretization  which is the only competing approach in the literature  
our results advance the state of art on several different topics  the theory of crowdsourcing
markets  principal agent problems  multi armed bandits  and dynamic pricing 

   introduction
crowdsourcing harnesses human intelligence and common sense to complete tasks that are
difficult to accomplish using computers alone  crowdsourcing markets  such as amazon mechanical turk and crowdflower  are platforms designed to match available human workers
with tasks to complete  using these platforms  requesters may post tasks that they would
like completed  along with the amount of money they are willing to pay  workers then
choose whether or not to accept the available tasks and complete the work 
of course not all human workers are equal  nor is all human produced work  some tasks 
such as proofreading english text  are easier for some workers than others  requiring less
effort to produce high quality results  additionally  some workers are more dedicated than
others  willing to spend extra time to make sure a task is completed properly  to encourage
high quality results  requesters may set quality contingent bonus payments on top of the
base payment for each task  rewarding workers for producing valuable output  this can be
c
    
ai access foundation  all rights reserved 

fiho  slivkins    vaughan

viewed as offering workers a contract that specifies how much they will be paid based on
the quality of their output  
we examine the requesters problem of dynamically setting quality contingent payments
for tasks  we consider a setting in which time evolves in rounds  in each round  the requester
posts a new contract  a performance contingent payment rule which specifies different levels
of payment for different levels of output quality  a random  unidentifiable worker then
arrives in the market and strategically decides whether to accept the requesters task and
how much effort to exert  the choice of effort level is not directly observable by the requester 
after the worker completes the task  or chooses not to complete it   the requester observes
the workers output  pays the worker according to the offered contract  and adjusts the
contract for the next round  the properties of a random worker  formally  the distribution
over the workers types  are not known to the requester  but may be learned over time  the
goal of the requester is to maximize his expected utility  the value he receives from completed
work minus the payments made  we call it the dynamic contract design problem 
for concreteness  consider a special case in which a worker can strategically choose to
perform a task with low effort or with high effort  and the task may be completed either at
low quality or at high quality  the low effort incurs no cost and results in low quality  which
in turn brings no value to the requester  the high effort leads to high quality with some
positive probability  which may vary from one worker to another  and is unknown to the
requester   the requester only observes the quality of completed tasks  and therefore cannot
always infer the effort level  this example captures the two main tenets of our model  that
the properties of a random worker are unknown to the requester and that workers strategic
decisions are unobservable 
we treat the dynamic contract design problem as a multi armed bandit  mab  problem 
with each arm representing a potential contract  since the action space is large  potentially
infinite  and has a well defined real valued structure  it is natural to consider an algorithm
that uses discretization  our algorithm  agnosticzooming  divides the action space into
regions  and chooses among these regions  effectively treating each region as a single metaarm  the discretization is defined adaptively  so that the more promising areas of the
action space are eventually discretized more finely than the less promising areas  while
the general idea of adaptive discretization has appeared in prior work on mab  kleinberg 
slivkins    upfal        bubeck  munos  stoltz    szepesvari      a  slivkins              
our approach to adaptive discretization is new and problem specific  the main difficulty 
compared to this prior work  is that an algorithm is not given any information that links
the observable numerical structure of contracts and the expected utilities thereof 
to analyze performance  we propose a concept called width dimension which measures
how nice a particular problem instance is  we show that agnosticzooming achieves
regret sublinear in the time horizon for problem instances with small width dimension 
in particular  if the width dimension is d  it achieves regret o log t  t  d     d      after
t rounds  for problem instances with large width dimension  agnosticzooming matches
the performance of the naive algorithm which uniformly discretizes the space and runs a
   for some tasks  such as labeling websites as relevant to a particular search query or not  verifying the
quality of work may be as difficult as completing the task  these tasks can be assigned in batches  with
each batch containing one or more instances in which the correct answer is already known  often called
gold data   quality contingent payments can then be based on the known instances 

   

fiadaptive contract design for crowdsourcing markets

standard bandit algorithm  we illustrate our general results via some corollaries and special
cases  including the high low example described above  we support the theoretical results
with simulations 
further  we consider a special case of our setting where each worker only chooses whether
to accept or reject a given task  this special case corresponds to a dynamic task pricing
problem previously studied in the literature  our results significantly improve over the prior
work on this problem 
our contributions can be summarized as follows  we define a broad  practically important setting in crowdsourcing markets  identify novel problem specific structure  for both
the algorithm and the regret bounds  distill ideas from prior work to work with these
structures  argue that our approach is productive by deriving corollaries and comparing
to prior work  and identify and analyze specific examples where our theory applies  the
main conceptual contributions are the model itself and the adaptive discretization approach
mentioned above  finally  this paper prompts further research on dynamic contract design
along several directions that we outline in the conclusion 
    related work
our work builds on three areas of research  first  our model can be viewed as a multi round
version of the classical principal agent model from contract theory  laffont   martimort 
       a single round of our model corresponds to the basic principal agent setting  with
adverse selection  unknown workers type  and moral hazard  unobservable workers decisions   unlike much of the existing work in contract theory  the prior over worker types is
not known to the principal  but may be learned over time  accordingly  our techniques are
very different from those employed in contract theory 
second  our methods build on those developed in the rich literature on mab with
continuous outcome spaces  the closest line of work is that on lipschitz mab  kleinberg
et al          in which the algorithm is given a distance function on the arms  and the
expected rewards of the arms are assumed to satisfy lipschitz continuity  or a relaxation
thereof  with respect to this distance function  agrawal        kleinberg        auer 
ortner    szepesvari        kleinberg et al         bubeck et al       a  slivkins        
most related to our techniques is the idea of adaptive discretization  kleinberg et al        
bubeck et al       a  slivkins         and in particular  the zooming algorithm  kleinberg
et al         slivkins         however  the zooming algorithm cannot be applied directly
in our setting because the required numerical similarity information is not immediately
available  this problem also arises in web search and advertising  where it is natural to
assume that an algorithm can only observe a tree shaped taxonomy on arms  kocsis  
szepesvari        munos   coquelin        pandey  agarwal  chakrabarti    josifovski 
      which can be used to explicitly reconstruct relevant parts of the underlying metric
space  slivkins        bull         we take a different approach  using a notion of virtual
width to estimate similarity information  explicit comparisons between our results and
prior mab work are made throughout the paper 
finally  our work follows several other theoretical papers on pricing in crowdsourcing
markets  kleinberg   leighton        badanidiyuru  kleinberg    singer        singer
  mittal        singla   krause        badanidiyuru  kleinberg    slivkins         in
   

fiho  slivkins    vaughan

particular  badanidiyuru et al         and singla and krause        study a version of our
setting with simple  single price contracts  independent of the output   where the focus is
on dealing with a global budget constraint 
a more thorough literature review  including a discussion of some related empirical
work  can be found in section   

   our setting  the dynamic contract design problem
in this section  we formally define the problem that we set out to solve and discuss the
implications of several aspects of our model 
    our model
we start by describing a static model  which captures what happens in a single round of
interaction between a requester and a worker  as described above  this is a version of the
standard principal agent model  laffont   martimort         we then define our dynamic
model  an extension of the static model to multiple rounds  with a new worker arriving
each round  we then detail the objective of our pricing algorithm and the simplifying
assumptions that we make throughout the paper  finally  we compare our setting to the
classic multi armed bandit problem 
      static model
we begin with a description of what occurs during each interaction between the requester
and a single worker  the requester first posts a task which may be completed by the worker 
and a contract specifying how the worker will be paid if she completes the task  if the task
is completed  the requester pays the worker as specified in the contract  and the requester
derives value from the completed task  for normalization  we assume that the value derived
is in         the requesters utility from a given task is this value minus the payment to the
worker 
when the worker observes the contract and decides whether or not to complete the task 
she also chooses a level of effort to exert  which in turn determines her cost  in terms of time 
energy  or missed opportunities  and a distribution over the quality of her work  to model
quality  we assume that there is a  small  finite set of possible outcomes that result from the
worker completing the task  or choosing not to complete it   and that the realized outcome
determines the value that the requester derives from the task  the realized outcome is
observed by the requester  and the contract that the requester offers is a mapping from
outcomes to payments for the worker 
we emphasize two crucial  and related  features of the principal agent model  that
the mapping from effort level to outcomes can be randomized  and that the effort level
is not directly observed by the requester  this is in line with a standard observation in
crowdsourcing that even honest  high effort workers occasionally make errors 
the workers utility from a given task is the payment from the requester minus the
cost corresponding to her chosen effort level  given the contract she is offered  the worker
chooses her effort level strategically so as to maximize her expected utility  crucially  the
chosen effort level is not directly observable by the requester 
   

fiadaptive contract design for crowdsourcing markets

the workers choice not to perform a task is modeled as a separate effort level of zero
cost  called the null effort level  and a separate outcome of zero value and zero payment
 called the null outcome  such that the null effort level deterministically leads to the null
outcome  and it is the only effort level that can lead to this outcome 
the mapping from outcomes to the requesters value is called the requesters value
function  the mapping from effort levels to costs is called the cost function  and the
mapping from effort levels to distributions over outcomes is called the production function 
for the purposes of this paper  a worker is completely specified by these two functions  we
say that the cost function and the production function comprise the workers type  unlike
some traditional versions of the principal agent problem  in our setting a workers type is
not observable by the requester  nor is any prior given 
      dynamic model
the dynamic model we consider in this paper is a natural extension of the static model to
multiple rounds and multiple workers  we are still concerned with just a single requester 
in each round  a new worker arrives  we assume a stochastic environment in which the
workers type in each round is an i i d  sample from some fixed and unknown distribution
over types  called the supply distribution  the requester posts a new task and a contract
for this task  all tasks are of the same type  in the sense that the set of possible effort
levels and the set of possible outcomes are the same for all tasks  the worker strategically
chooses her effort level so as to maximize her expected utility from this task  based on
the chosen effort level and the workers production function  an outcome is realized  the
requester observes this outcome  but not the workers effort level  and pays the worker the
amount specified by the contract  the type of the arriving worker is never revealed to the
requester  the requester can adjust the contract from one round to another  and his total
utility is the sum of his utility over all rounds  for simplicity  we assume that the number
of rounds is known in advance  though this assumption can be relaxed using the standard
doubling trick  cesa bianchi   lugosi        in which full executions of the algorithm
are repeated in phases with exponentially increasing time horizons 
      the dynamic contract design problem
throughout this paper  we take the point of view of the requester interacting with workers
in the dynamic model  the algorithms we examine dynamically choose contracts to offer
on each round with the goal of maximizing the requesters expected utility  a problem
instance consists of several quantities  some of which are known to the algorithm  and some
of which are not  the known quantities are the number of outcomes  the requesters value
function  and the time horizon t  i e   the number of rounds   the latent quantities are the
number of effort levels  the set of worker types  and the supply distribution  the algorithm
adjusts the contract from round to round and observes the realized outcomes but receives
no other feedback 
we focus on contracts that are bounded  offer payments in          and monotone  assign
equal or higher payments for outcomes with higher value for the requester   let x be the
set of all bounded  monotone contracts  we compare a given algorithm against a given
subset of candidate contracts xcand  x  letting opt xcand   be the optimal utility over
   

fiho  slivkins    vaughan

all contracts in xcand   the goal is to minimize the algorithms regret r t  xcand    defined as
t  opt xcand   minus the algorithms expected utility 
the subset xcand may be finite or infinite  possibly xcand   x  the most natural
example of a finite xcand is the set of all bounded  monotone contracts with payments that
are integer multiples of some       we call it the uniform mesh with granularity   and
denote it xcand    
      notation
let v   be the value function of the requester  with v   denoting the value of outcome  
let o be the set of all outcomes and let m be the number of non null outcomes  we will
index the outcomes as o                      m  in the order of increasing value  ties broken
arbitrarily   with a convention that   is the null outcome 
let ci    and fi    be the cost function and production function for type i  then the
cost of choosing effort level e is ci  e   and
pthe probability of obtaining outcome  having
chosen effort e is fi   e   let fi   e       fi      e  be the probability of obtaining an
outcome at least as good as  having chosen effort e 
recall that a contract x is a function from outcomes to  non negative  payments  if
contract x is offered to a worker sampled i i d  from the supply distribution  v  x  is the
expected value to the requester  p  x     is the expected payment  and u  x    v  x p  x 
is the expected utility of the requester  let opt xcand     supxxcand u  x  
      assumption  first order stochastic dominance  fosd 
given two effort levels e and e    we say that e has fosd over e  for type i if fi   e   fi   e   
for all outcomes   with a strict inequality for at least one outcome   we say that type i
satisfies the fosd assumption if for any two distinct effort levels  one effort level has fosd
over the other for type i  we assume that all types satisfy this assumption 
      assumption  consistent tie breaking
if multiple effort levels maximize the expected utility of a given worker for a contract x  we
assume the tie is broken consistently in the sense that this worker chooses the same effort
level for any contract that leads to this particular tie  this assumption is minor  it can
be avoided  with minor technical complications  by adding random perturbations to the
contracts  this assumption is implicit throughout the paper 
    discussion
before jumping into our results  we discuss the implications of several aspects of our model
in more detail 
      number of outcomes
our results assume a small number of outcomes  this regime is important in practice
for several reasons  first  some tasks naturally have only a small number of outcomes 
   this mimics the standard notion of fosd between two distributions over a linearly ordered set 

   

fiadaptive contract design for crowdsourcing markets

for example  a binary labeling task can only have four possible outcomes if completed 
 yes no    correct incorrect   second  it often makes sense to group together multiple
outcomes with similar value to the requester  such as false positives and false negatives  if
the value is not known very precisely  this has the added benefit that contracts become
simpler from the workers perspective  third  even if a task can be completed in many
different ways  the quality may be difficult to evaluate in fine granularity  a good example
is a translation of a sentence  fourth  even if a fine grained quality evaluation exists  such
as the error count in speech transcription tasks  it may be difficult to make it consistent
across different tasks 
even with m     non null outcomes  our setting has not been studied before  the special
case m     is equivalent to the dynamic pricing problem from kleinberg and leighton
        we obtain improved results for it  too 
      the benchmark
our benchmark opt   only considers contracts that are bounded and monotone  in practice 
restricting to such contracts may be appealing to all human parties involved  however  this
restriction is not without loss of generality  there are problem instances in which monotone
contracts are not optimal  see appendix a for an example  further  it is not clear whether
bounded monotone contracts are optimal among monotone contracts 
our benchmark opt xcand   is relative to a given set xcand   which is typically a finite
discretization of the contract space  there are two reasons for this  first  crowdsourcing platforms may require the payments to be multiples of some minimum unit  e g   one
cent   in which case it is natural to restrict our attention to contracts satisfying the same
constraint  second  achieving guarantees relative to opt x  for the full generality of our
problem appears beyond the reach of our techniques  as in many other machine learning
scenarios  it is useful to consider a restricted benchmark set  set of alternatives to compare to   in such settings  it is considered important to handle arbitrary benchmark sets 
which is what we do 
one known approach to obtain guarantees relative to opt x  is to start with some
finite xcand  x  design an algorithm with guarantees relative to opt xcand    and then 
as a separate result  bound the discretization error opt x   opt xcand    then the choice
of xcand drives the tradeoff between the discretization error and regret r t  xcand    and
one can choose xcand to optimize this tradeoff  however  while one can upper bound the
discretization error in some  very  simple special cases  see section     it is unclear whether
this can be extended to the full generality of dynamic contract design 
      alternative worker models
one of the crucial tenets in our model is that the workers maximize their expected utility 
this rationality assumption is very standard in economics  and is often used to make
the problem amenable to rigorous analysis  however  there is a considerable literature
suggesting that in practice workers may deviate from this rational behavior  thus  it is
worth pointing out that our results do not rely heavily on the rationality assumption  the
   a particularly relevant analogy is contextual bandits with policy sets  dudik  hsu  kale  karampatziakis 
langford  reyzin    zhang        

   

fiho  slivkins    vaughan

fosd assumption  which is also fairly standard  can be circumvented  too  in fact  all
our assumptions regarding worker behavior serve only to enable us to prove lemma     
and more specifically to guarantee that the collective worker behavior satisfies a natural
increment payment property used in the proof of lemma      if the requester increases
the increment payment for a particular outcome  as described in the next section   the
probability of obtaining an outcome at least that good also increases  in particular  this
property is consistent with worker behavior that takes into account long term effects such
as changes in reputation scores  it is also consistent with workers acting upon subjective
 and possibly incorrect  beliefs about the offered contract  such as beliefs about how the
guaranteed base payment may actually depend on the quality of submitted work  
      minimum wage
for ethical or legal reasons one may want to enforce some form of minimum wage  this
can be expressed within our model as a minimal payment  for a completed task  i e  
for any non null outcome  our algorithm can be easily modified to accommodate this
constraint  essentially  it suffices to restrict the action space to contracts that pay at least
 for a completed task  formally  the increment space defined in section   should be
             m  rather than       m   and the quadrants of each cell are defined by
splitting the cell in half in each dimension  all our results easily carry over to this version
 restricting xcand to contracts that pay at least  for a completed task   we omit further
discussion of this issue for the sake of simplicity 
      comparison to multi armed bandits  mab 
dynamic contract design can be modeled as special case of the mab problem with some
additional  problem specific structure  the basic mab problem is defined as follows  an
algorithm repeatedly chooses actions from a fixed action space and collects rewards for the
chosen actions  the available actions are traditionally called arms  more specifically  time
is partitioned into rounds  so that in each round the algorithm selects an arm and receives
a reward for the chosen arm  no other information  such as the reward the algorithm
would have received for choosing an alternative arm  is revealed  in an mab problem
with stochastic rewards  the reward of each arm in a given round is an i i d  sample from
some distribution which depends on the arm but not on the round  a standard measure
of an algorithms performance is regret with respect to the best fixed arm  defined as the
difference in expected total reward between a benchmark  usually the best fixed arm  and
the algorithm 
thus  dynamic contract design can be naturally modeled as an mab problem with
stochastic rewards  in which arms correspond to monotone contracts  the prior work on
mab with large or infinite action spaces often assumes known upper bounds on the similarity between arms  more precisely  this prior work would assume that an algorithm is given a
metric d on contracts such that expected rewards are lipschitz continuous with respect to
   a worker model that incorporates such subjective beliefs has been suggested by ho  slivkins  suri  and
vaughan        based on experimental evidence  and this model satisfies the increment payment property
mentioned above 

   

fiadaptive contract design for crowdsourcing markets

d  i e   we have upper bounds  u  x u  y    d x  y  for any two contracts x  y   however 
in our setting such upper bounds are absent  on the other hand  our problem has some
auxiliary structure compared to the standard mab setting  in particular  the algorithms
reward decomposes into value and payment  both of which are determined by the outcome 
which in turn is probabilistically determined by the workers strategic choice of the effort
level  effectively  this auxiliary structure provides some soft information on similarity
between contracts  in the sense that numerically similar contracts usually  but not always 
induce similar response from the workers 
      applicability of the model
despite a considerable generality  our model is somewhat idealized  let us discuss several
potential concerns regarding how applicable and realistic the model is 
an implicit intuition behind using performance based payments is that they can incentivize better quality  a growing empirical literature on incentives in crowdsourcing markets
finds that it happens for some types of tasks but not for others  in particular  the experiments in the work of ho et al         suggest that it happens if and only if the task is
effort responsive  in the sense that one can obtain higher quality work by increasing effort 
at effort levels that are not too costly for the worker  this observation is consistent with our
worker model  indeed  effort responsiveness of a task is a joint property of the production
function and the cost function which implies a significant response to sufficiently increased
quality based payments  ho et al  propose pilot experiments to determine whether a given
type of tasks is effort responsive  which in turn would shed light on whether to use qualitybased payments for these tasks in practice  a more comprehensive discussion of related
empirical work can be found in section    we also observe that our model and results for
a single non null outcome are applicable and novel even if the task is not effort responsive 
following the bulk of prior work on dynamic pricing and mab  we assume that the
collective worker response to a given contract  as given by a distribution over the outcomes 
does not depend on the contracts that have been offered in the past  or on the algorithm used
to choose future contracts  thus  we do not model the possibility that price experimentation
may alter future worker responses  or that the workers may try to game the system  both
effects are not easy to model and extremely difficult to analyze  even in the relatively
simple scenario of a single non null outcome with no emphasis on adaptive discretization 
additionally  the available empirical work does not provide sufficient guidance on how to
choose a realistic model for these effects among theoretically plausible alternatives  we
leave this to future work 
from the mab point of view  our model does not incorporate the possibility that the
worker response may intrinsically change over time  or the fact that requesters may have
hard budget constraints on the total amount of money that they can spend  this reflects
the limitations of state of the art work on mab  adaptive discretization  budgets  and adversarial change over time are fairly well understood separately  but any two of them  let
alone all three  have not been studied jointly  that said  we conjecture that our techniques
would be useful in generalizing dynamic pricing and dynamic contract design to these richer
settings 
   such upper bound is informative if and only if d x  y      

   

fiho  slivkins    vaughan

likewise  we do not model a scenario when the requesters stream of tasks overwhelms
the crowdsourcing market and causes a drastic change in the available worker population
 and therefore in the worker response   in particular  we assume that the worker pool is
sufficiently large to accommodate the requester  this is a relatively benign assumption for
a large crowdsourcing system 
to deploy dynamic selection of prices or contracts in practice  regardless of the particular
algorithm used  the crowdsourcing platform needs to enable requesters to change their
prices contracts relatively fast in response to observed worker responses  while this feature
is not currently instrumented on commercial platforms such as amazon mechanical turk 
it appears easily implementable from an engineering point of view  we believe the main
hurdle would be to incorporate dynamic price contract selection into the overall economic
design of the market  given the multitude of existing crowdsourcing markets and a relative
ease of deploying new market designs  we believe this direction is well worth studying 

   our algorithm  agnosticzooming
in this section  we specify our algorithm  we call it agnosticzooming because it zooms
in on more promising areas of the action space  and does so without knowing a precise
measure of the similarity between contracts  this zooming can be viewed as a dynamic
form of discretization  before stating the algorithm itself  we discuss the discretization of
the action space in more detail  laying the groundwork for our approach 
    discretization of the action space
in each round  the agnosticzooming algorithm partitions the action space into several regions and chooses among these regions  effectively treating each region as a meta arm  in
this section  we discuss which subsets of the action space are used as regions  and introduce
some useful notions and properties of such subsets 
      increment space and cells
to describe our approach to discretization  it is useful to think of contracts in terms of
increment payments  specifically  we represent each monotone contract x   o        as a
vector x       m   where m is the number of non null outcomes and x   x  x     
  for each non null outcome    recall that by convention   is the null outcome and
x          we call this vector the increment representation of contract x  and denote it
incr x   note that if x is bounded  then incr x         m   conversely  call a contract
weakly bounded if it is monotone and its increment representation lies in       m   such a
contract is not necessarily bounded 
we discretize the space of all weakly bounded contracts  viewed as a multi dimensional
unit cube  more precisely  we define the increment space as       m with a convention that
every vector represents the corresponding weakly bounded contract  each region in the discretization is a closed  axis aligned m dimensional cube in the increment space  henceforth 
such cubes are called cells  the size of a cell is the length of any one side  a cell is called
relevant if it contains at least one candidate contract  a relevant cell is called atomic if it
contains exactly one candidate contract  and composite otherwise 
   

fiadaptive contract design for crowdsourcing markets

in each composite cell c  the algorithm will only use two contracts  the maximal corner 
denoted x   c   in which all increment payments are maximal  and the minimal corner 
denoted x  c   in which all increment payments are minimal  these two contracts are
called the anchors of c  in each atomic cell c  the algorithm will only use one contract 
the unique candidate contract  also called the anchor of c  note that anchors are not
necessarily candidate contracts 
      virtual width
to take advantage of the problem structure  it is essential to estimate how similar the
contracts within a given composite cell c are  ideally  we would like to know the maximal
difference in expected utility 
width c    supx yc  u  x   u  y    
we estimate the width using a proxy  called virtual width  which is expressed in terms of
the anchors 


virtwidth c    v  x   c    p  x  c    v  x  c    p  x   c    
   
this definition is one crucial place where the problem structure is used   note that it is
not the difference in utility at the anchors   it is useful due to the following lemma  proved
in section      
lemma      if all types satisfy the fosd assumption and consistent tie breaking holds 
then width c   virtwidth c  for each composite cell c 
recall that the proof of this lemma is the only place in the paper where we use our
assumptions on worker behavior  all further developments hold for any model of worker
behavior which satisfies lemma     
    description of the algorithm
with these ideas in place  we are now ready to describe our algorithm  the high level
outline of agnosticzooming is very simple  the algorithm maintains a set of active cells
which cover the increment space at all times  initially  there is only a single active cell
comprising the entire increment space  in each round t  the algorithm chooses one active
cell ct using an upper confidence index and posts contract xt sampled uniformly at random
among the anchors of this cell  after observing the feedback  the algorithm may choose to
zoom in on ct   removing ct from the set of active cells and activating all relevant quadrants
thereof  where the quadrants of cell c are defined as the  m sub cells of half the size for
which one of the corners is the center of c  in the remainder of this section  we specify how
the cell ct is chosen  the selection rule   and how the algorithm decides whether to zoom
in on ct  the zooming rule  
let us first introduce some notation  consider cell c that is active in some round t  let
u  c  be the expected utility from a single round in which c is chosen by the algorithm 
i e   the average expected utility of the anchor s  of c  let nt  c  be the number of times
this cell has been chosen before round t  consider all rounds in which c is chosen by
   

fiho  slivkins    vaughan

the algorithm before round t  let ut  c  be the average utility over these rounds  for a
composite cell c  let vt   c  and pt   c  be the average value and average payment over
all rounds when anchor x   c  is chosen  similarly  let vt  c  and pt  c  be the average
value and average payment over all rounds when anchor x  c  is chosen  accordingly  we
can estimate the virtual width of composite cell c at time t as


wt  c    vt   c   pt  c   vt  c   pt   c   
   
to bound the deviations  we define the confidence radius as
p
radt  c    crad log t   nt  c  

   

for some absolute constant crad   in our analysis  crad     suffices  we will show that with
high probability all sample averages defined above will stay within radt  c  of the respective
expectations  if this high probability event holds  the width estimate wt  c  will always be
within   radt  c  of virtwidth c  
the algorithm pseudocode is summarized in algorithm    the selection rule and the
zooming rule are explained in more detail below 
algorithm    agnosticzooming
inputs  subset xcand  x of candidate contracts 
data structure  collection a of cells  initially  a           m   
for each round t     to t
let ct   argmaxca it  c   where it    is defined as in equation     
sample contract xt u a r  among the anchors of ct      anchors are defined in section     
post contract xt and observe feedback 
if  ct  xcand       and   radt    ct     wt    ct   then
a  a   all relevant quadrants of ct      ct       c is relevant if  c  xcand      

      selection rule
the selection rule is as follows  in each round t  the algorithm chooses an active cell c
with maximal index it     it  c  is an upper confidence bound on the expected utility of
any candidate contract in c  defined as
 
ut  c    radt  c 
if c is an atomic cell 
it  c   
   
ut  c    wt  c      radt  c  otherwise 
if nt  c       ut  c  and wt  c  can be initialized to any finite values  since radt  c  is
infinite when nt  c       agnosticzooming will first select the cell that is never selected
before time t 
      zooming rule
we zoom in on a composite cell ct if
wt    ct       radt    ct   
   

fiadaptive contract design for crowdsourcing markets

i e   the uncertainty due to random sampling  expressed by the confidence radius  becomes
sufficiently small compared to the uncertainty due to discretization  expressed by the virtual
width  we never zoom in on atomic cells 
      notes on integer payments
in practice it may be necessary to only allow contracts in which all payments are integer
multiples of some amount   e g   whole cents   in this case we can assume that candidate
contracts have this property  too   then we can redefine the two anchors of each composite
cell  the maximal  resp   minimal  anchor is the nearest allowed contract to the maximal
 resp   minimal  corner  width can be redefined as a supremum over all allowed contracts
in a given cell  with these modifications  the analysis goes through without significant
changes  we omit further discussion of this issue 
    proof of lemma      virtual width 
for two vectors x  x    m   write x   x if x  pointwise dominates x  i e   if x j  xj for all
j  for two monotone contracts x  x    write x   x if incr x     incr x  
claim      consider a worker whose type satisfies the fosd assumption and two weakly
bounded contracts x  x  such that x   x  let e  resp   e    be the effort levels exerted by this
worker when he is offered contract x  resp   x     then e does not have fosd over e   
proof  for the sake of contradiction  assume that e has fosd over e    note that e    e   
let i be the workers type  recall that fi   e  denotes the probability of generating an
outcome      given the effort level e  define f     fi    e            fi  m e     and define f 
similarly for e   
let x and x  be the increment representations for x and x    given contract x  the
workers expected utility for effort level e is ui  x e    x  f  ci  e   since e is the optimal
effort level given this contract  we have ui  x e   ui  x e     and therefore
x  f  x  f   ci  e   ci  e    
similarly  since e  is the optimal effort level given contract x    we have
x   f   x   f  ci  e     ci  e  
combining the above two inequalities  we obtain
 x  x      f  f       

   

note that if equation     holds with equality then ui  x e    ui  x e    and ui  x   e   
ui  x   e     so the worker breaks the tie between e and e  in a different way for two different
contracts  this contradicts the consistent tie breaking assumption  however  equation    
cannot hold with a strict equality  either  because x   x and  since e has fosd over e   
we have f  f  and fi   e    fi   e    for some outcome       therefore we obtain a
contradiction  completing the proof 
the proof of claim     is the only place in the paper where we directly use the consistent
tie breaking assumption   but the rest of the paper relies on this claim  
   

fiho  slivkins    vaughan

claim      assume all types satisfy the fosd assumption  consider weakly bounded
contracts x  x  such that x   x  then v  x     v  x  and p  x     p  x  
proof  consider some worker  let i be his type  let e and e  be the chosen effort levels for
contracts x and x    respectively  by the fosd assumption  either e   e    or e  has fosd
over e  or e has fosd over e    claim     rules out the latter possibility 
define vectors f and f  as in the proof of claim      note that f   f 
then p   x  f and p     x   f  is the expected payment for contracts x and x   
respectively  further  letting v denote the increment representation of the requesters value
for each outcome  v   v  f and v     v  f  is the expected requesters value for contracts
x and x    respectively  since x   x and f   f  it follows that p    p and v    v   since
this holds for each worker  this also holds in expectation over workers 
to finish the proof of lemma      consider a composite cell c with anchors x   
and x   x  c   and fix a contract x  c  since x   x  x   by claim    
it follows that v  x     v  x   v  x   and p  x     p  x   p  x    therefore  u  x  
u  y    virtwidth c   taking the supremum over all x  c over  we obtain width c  
virtwidth c   as claimed 
x   c 

   regret bounds and discussion
we present the main regret bound for agnosticzooming  formulating this result requires
some new  problem specific structure  stated in terms of this structure  the result is somewhat difficult to access  to explain its significance  we state several corollaries  and compare
our results to prior work 
    the main result
we start with the main regret bound  like the algorithm itself  this regret bound is parameterized by the set xcand of candidate contracts  our goal is to bound the algorithms
regret with respect to candidate contracts 
recall that opt xcand     supxxcand u  x  is the optimal expected utility over candidate
contracts  the algorithms regret with respect to candidate contracts is r t  xcand    
t opt xcand    u   where t is the time horizon and u is the expected cumulative utility of
the algorithm 
define the badness  x  of a contract x  x as the difference in expected utility between
an optimal candidate contract and x   x    opt xcand    u  x   let x    x  xcand  
 x     
we will only be interested in cells that can potentially be used by agnosticzooming 
formally  we recursively define a collection of feasible cells as follows   i  the cell       m is
feasible   ii  for each feasible cell c  all relevant quadrants of c are feasible  note that the
definition of a feasible cell implicitly depends on the set xcand of candidate contracts  by
definition  a feasible cell is one that contains a candidate contract 
let f denote the collection of all feasible  composite cells c such that virtwidth c  
  for y  xcand   let f  y   be the collection of all cells c  f that overlap with y   and
let n  y      f  y     sometimes we will write n  y  xcand   in place of n  y   to emphasize
the dependence on xcand  
   

fiadaptive contract design for crowdsourcing markets

using the structure defined above  the main theorem is stated as follows  we prove this
theorem in section   
theorem      consider the dynamic contract design problem with all types satisfying the
fosd assumption and a constant number of outcomes  consider agnosticzooming  parameterized by some set xcand of candidate contracts  assume t  max  m           there
is an absolute constant       such that for any      
x

r t  xcand    t   o log t  

  j   jn

n    x  xcand  
 


   

remark    as discussed in section      we target the practically important case of a small
number of outcomes  the impact of larger m is an exponential dependence on m in the
o   notation  and  more importantly  increased number of candidate policies  typically
exponential in m for a given granularity  
remark    our regret bounds do not depend on the number of worker types  in line with
prior work on dynamic pricing  essentially  this is because bandit approaches tend to
depend only on expected reward of a given arm  and perhaps also on the variance   not
the finer properties of the distribution 
equation     has a shape similar to several other regret bounds in the literature  as
discussed below  to make this more apparent  we observe that regret bounds in bandits
in metric spaces are often stated in terms of covering numbers   for a fixed collection
f of subsets of a given ground set x  the covering number of a subset y  x relative
to f is the smallest number of subsets in f that is sufficient to cover y    the numbers
n  y  xcand   are  essentially  about covering y with feasible cells with virtual width close to
  we make this point more precise as follows  let an  minimal cell be a cell in f which
does not contain any other cell in f   let nmin  y   be the covering number of y relative
to the collection of  minimal cells  i e   the smallest number of  minimal cells sufficient to
cover y   then
n  y    dlog   e nmin  y   for any y  xcand and     

   

where  is the smallest size of a feasible cell   thus  equation     can be easily restated
using the covering numbers nmin    instead of n    
    corollary  polynomial regret
literature on regret minimization often states polynomial regret bounds of the form
r t     o t           while covering number regret bounds are more precise and versatile  the exponent  in a polynomial regret bound expresses algorithms performance in a
particularly succinct and lucid way 
for bandits in metric spaces the exponent  is typically determined by an appropriately defined notion of dimension  such as the covering dimension   which succinctly
   to prove equation      observe that for each cell c  f  y   there exists an  minimal cell c    c  and
for each  minimal cell c   there exist at most dlog   e cells c  f  y   such that c    c 
   given covering numbers n     the covering dimension of y is the smallest d    such that n  y    
o d   for all      

   

fiho  slivkins    vaughan

captures the difficulty of the problem instance  interestingly  the dependence of  on the
dimension d is typically of the same shape      d       d       for several different notions
of dimension  in line with this tradition  we define the width dimension 
n
o
widthdim   inf d      n    x  xcand     d for all             
   
note that the width dimension depends on xcand and the problem instance  and is parameterized by a constant       by optimizing the choice of  in equation      we obtain the
following corollary 
corollary      consider the the setting of theorem      for any       let d   widthdim  
then
r t  xcand    o  log t   t    d     d   

   

the width dimension is similar to the zooming dimension in the work of kleinberg
et al         and near optimality dimension in the work on bandits in metric spaces
 bubeck et al       a  
    comparison to prior work
below we compare our results with previous work in non adaptive discretization and bandits
in metric spaces 
      non adaptive discretization
one approach from prior work that is directly applicable to the dynamic contract design
problem is non adaptive discretization  this is an algorithm  call it nonadaptive  which
runs an off the shelf mab algorithm  treating a set of candidate contracts xcand as arms  
for concreteness  and following the prior work  kleinberg   leighton        kleinberg 
      kleinberg et al          we use a well known algorithm ucb   auer  cesa bianchi   
fischer        as an off the shelf mab algorithm 
to compare agnosticzooming with nonadaptive  it is useful to derive several worstcase corollaries of theorem      replacing n  x   with various  loose  upper bounds  
corollary      in the setting of theorem      the regret of agnosticzooming can be upperbounded as follows 
p
 a  r t  xcand    t     j   jn o  x       for each          
p
 b  r t  xcand    o  t  xcand    
here the o   notation hides the logarithmic dependence on t and  
the best known regret bounds for nonadaptive coincide with those in corollary     up
to poly logarithmic factors  however  the regret bounds in theorem     may be significantly
better than the ones in corollary      we further discuss this in the next section  in the
context of a specific example 
   to simplify the proofs of the lower bounds  we assume that the candidate contracts are randomly
permuted when given to the mab algorithm 
   we use the facts that x  xcand   n  y    n   y    and n min  y     y   for all subsets y  x 

   

fiadaptive contract design for crowdsourcing markets

      bandits in metric spaces
consider a variant of dynamic contract design in which an algorithm is given a priori
information on similarity between contracts  a function d   xcand  xcand         such that
 u  x   u  y    d x  y  for any two candidate contracts x  y  if an algorithm is given this
function d  call such algorithm d aware   the machinery from bandits in metric spaces
 kleinberg et al         bubeck et al       a  can be used to perform adaptive discretization
and obtain a significant advantage over nonadaptive  we argue that we obtain similar
results with agnosticzooming without knowing the d 
in practice  the similarity information d would be coarse  probably aggregated according
to some predefined hierarchy  to formalize this idea  the hierarchy can be represented as
a collection f of subsets of xcand   so that d x  y  is a function of the smallest subset in
f containing both x and y  the hierarchy f should be natural given the structure of
the contract space  one such natural hierarchy is the collection of all feasible cells  which
corresponds to splitting the cells in half in each dimension  formally  d x  y    f  cx y   for
some f with f  cx y    width cx y    where cx y is the smallest feasible cell containing both
x and y 
given this shape of d  let us state the regret bounds for d aware algorithms in the work
of kleinberg et al         and bubeck et al       a   to simplify the notation  we assume
that the action space is restricted to xcand   the regret bounds have a similar shape as
that in theorem     
r t  xcand    t   o log t  

  x  
n  


x
  j  

jn



 

    

where the numbers n    have a similar high level meaning as n     and nearly coincide
with nmin    when d x  y    virtwidth cx y    one can use equation      to derive a
polynomial regret bound like equation     
for a more precise comparison  we focus on the results in the work of kleinberg et al 
         the regret bounds in bubeck et al       a are very similar in spirit  but are stated
in terms of a slightly different structure   the covering type regret bound in the work of
kleinberg et al         focuses on balls of radius at most  according to distance d  so that
n  y   is the smallest number of such balls that is sufficient to cover y   in the special case
d x  y    virtwidth cx y   balls of radius   are precisely feasible cells of virtual width
   this is very similar  albeit not technically the same  as the  minimal cells in the
definition of nmin    
further  the covering numbers n  y   determine the zooming dimension 
n
o

zoomdim   inf d      n  
 x     d for all             
    
this definition coincides with the covering dimension in the worst case  and can be much
smaller for nice problem instances in which x is a significantly small subset of xcand  
with this definition  one obtains a polynomial regret bound which is a version of equation     with d   zoomdim  
we conclude that agnosticzooming essentially matches the regret bounds for d aware
algorithms  despite the fact that d aware algorithms have access to much more information 
   

fiho  slivkins    vaughan

   a special case  the high low example
we apply the machinery in section   on a special case  and we show that agnosticzooming
significantly outperforms nonadaptive 
the most basic special case is when there is just one non null outcome  essentially  each
worker makes a strategic choice whether to accept or reject a given task  where reject
corresponds to the null effort level   and this choice is fully observable  this setting has been
studied before  kleinberg   leighton        badanidiyuru et al         singla   krause 
      badanidiyuru et al          we will call it dynamic task pricing  here the contract
is completely specified by the price p for the non null outcome  the supply distribution is
summarized by the function s p    pr accept p   so that the corresponding expected utility
is u  p    s p  v  p   where v is the value for the non null outcome  this special case
is already quite rich  because s   can be an arbitrary non decreasing function  by using
adaptive discretization  we achieve significant improvement over prior work  see section  
for further discussion 
we consider a somewhat richer setting in which workers strategic decisions are not
observable  this is a salient feature of our setting  called moral hazard in the contract
theory literature  there are two non null outcomes  low and high   and two non null effort
levels  low and high   low outcome brings zero value to the requester  while high outcome
brings value v      low effort level inflicts zero cost on a worker and leads to low outcome
with probability    we assume that workers break ties between effort levels in a consistent
way  high better than low better than null   hence  as low effort incurs zero cost  the
only possible outcomes are low and high   we will call this the high low example  it is
perhaps the simplest example that features moral hazard 
in this example  the workers type consists of a pair  ch   h    where ch    is the cost for
high effort and h         is the probability of high outcome given high effort  note that
dynamic task pricing is equivalent to the special case h     
the following claim states a crucial property of the high low example 
claim      consider the high low example with a fixed supply distribution  then the probability of obtaining high outcome given contract x pr high outcome   contract x  depends only
on p   x high   x low   denote this probability by s p   moreover  s p  is non decreasing
in p  therefore 
 expected utility is u  x    s p  v  p   x low  
 discretization error opt x   opt xcand     is at most    for any      
to bound the discretization error  it is essential that s p  is non decreasing in p 
recall that xcand     the uniform mesh with granularity       consists of all bounded 
monotone contracts with payments in n 
for our purposes  the supply distribution is summarized via the function s    denote
u  p    s p  v  p   note that u  x  is maximized by setting x low       in which case
u  x    u  p   thus  if an algorithm knows that it is given a high low example  it can set
x low       thereby reducing the dimensionality of the search space  then the problem
essentially reduces to dynamic task pricing with the same s   
however  in general an algorithm does not know whether it is presented with the highlow example  because the effort levels are not observable   so in what follows we will
consider algorithms that do not restrict themselves to x low      
   

fiadaptive contract design for crowdsourcing markets

    nice supply distribution
we focus on a supply distribution d that is nice  in the sense that s   satisfies the
following two properties 
 s p  is lipschitz continuous   s p   s p      l p  p    for some constant l 
 u  p  is strongly concave  in the sense that u       exists and satisfies u        c     
here l and c are absolute constants  we call such d strongly lipschitz concave 
the above properties are fairly natural  for example  they are satisfied if h is the same
for all worker types and the marginal distribution of ch is piecewise uniform such that the
density is between   and   for some absolute constant     
we show that for any choice xcand  x  agnosticzooming has a small width dimension
in this setting  and therefore small regret 
lemma      consider the high low example with a strongly lipschitz concave supply distribution  then the width dimension is at most      for any given xcand  x  therefore 
agnosticzooming with this xcand has regret r t  xcand     o log t   t      
we contrast this with the performance of nonadaptive  parameterized with the natural
choice xcand   xcand     we focus on r t  x   regret w r t  the best contract in x  we
show that agnosticzooming achieves r t  x    o t       for a wide range of xcand   whereas
nonadaptive cannot do better than r t  x    o t       for any xcand   xcand          
lemma      consider the setting of lemma      then 
 a  agnosticzooming with xcand  xcand  t       has regret r t  x    o t     log t   
 b  nonadaptive with xcand   xcand    cannot achieve regret r t  x    o t       over
all problem instances  for any         

    proofs
proof of claim      consider a contract x with x low    b and x high    b   p  and a
worker of type  ch   h    if the worker exerts high effort  she pays cost ch and receives
expected payment h  p   b        h  b  for a total expected payoff ph   b  ch   her
expected payoff for exerting low effort is b  therefore she will choose to exert high effort
if and only if ph   b  ch  b  i e   if ch  h  p  and choose to exert low effort otherwise 
therefore


pr high outcome   contract x    e h   ch  h p   
 ch  h  

this is a function of p  call it s p   moreover  this is a non decreasing function simply
because the expression inside the expectation is non decreasing in p 
it trivially follows that u  x    s p  v  p   x low  
we can upper bound the discretization error using a standard approach from the work
on dynamic pricing  kleinberg   leighton         fix discretization granularity       for
any       there exists a contract x  x such that opt x   u  x       round x  high 
    this lower bound holds even if ucb  in nonadaptive is replaced with any other mab algorithm 

   

fiho  slivkins    vaughan

and x  low  up and down  respectively  to the nearest integer multiple of   let x  xcand   
be the resulting contract  denoting p   x high   x low  and p   x  high   x  low   we
see that p  p  p      it follows that
u  x   u  x       opt x       
since this holds for any       we conclude that opt x   opt xcand        
proof of lemma      to calculate the width dimension  we need to count the number of
feasible cells in the increment space which  i  have virtual width larger than or equal to
o   and  ii  overlap with x   the set of contracts with badness smaller than  
we first characterize x   we use xp b to denote the contract with x high    p   b and
x low    b  the benefit of this representation is that  p and b would then be the two axes
in the increment space  let xp    be an optimal contract  since u  xp b   is strongly concave
in p  we know that for any b  there exist constants c  and c  such that for any p         
c   p  p    u  xp  b    u  xp b    c   p  p     also we know that u  xp  b     u  xp       b 
therefore 
x    xp b    p  p      b  o   
we can also write it as


x    xp b   p  h      p  p   h     and b  o   

intuitively  x contains contracts  xp b   with p not o    away from p and b not o  
away from b     
next we characterize the virtual width of a cell  we use cp b d to denote the cell with
size d and with anchors  xp b   x p d   b d     we can derive the expected payment and value
on the two anchors as 
 p    cp b d      p   d s p   d    b   d
 v    cp b d     vs p   d 
 p   cp b d     ps p    b
 v   cp b d     vs p 
by definition  we can get that  we use df to represent s p   d   s p  for simplification 
virtwidth cp b d      v   p df   ds p    d df   d 
now we can count the number of feasible cells with virtual width larger than h    which
overlaps with x   note that since the total number of feasible cells cp b d with large d is
small  we can treat the number of cells with large d as a constant  also  for any relevant
cell cp b d   we have p  p   therefore  we only care about feasible cells cp b d with small d
and when p is close to p  
since s p  is lipschitz  we have df   o d   therefore  for any relevant cell cp d  
virtwidth cp b d     o d 
given the above two arguments  we know that the number of cells with virtual width

larger than  which also overlaps with x is o     o       o        therefore the
width dimension is     
   

fiadaptive contract design for crowdsourcing markets

proof sketch of lemma     b   consider a version of nonadaptive that runs an off theshelf mab algorithm alg on candidate contracts xcand   xcand     for alg  the arms
are the candidate contracts  recall that the arms are randomly permuted before they are
given to alg 
fix       it is easy to construct a problem instance with discretization error error  
opt x   opt xcand          note that xcand contains n         suboptimal contracts that are suboptimal w r t  opt xcand     for example  all contracts x with x low     
are suboptimal  
fix any problem instance i of mab with n suboptimal arms  using standard lowerbound arguments for mab  one can show that if one runs alg on a problem instance
obtainedby randomly permuting the arms in i  then the expected regret in t rounds is at
least   n t   

therefore  r t  xcand      n t    it follows that


r t  x     n t     error  t    t     t     t       

   proof of the main regret bound  theorem     
we now prove the main result from section    our high level approach is to define a
clean execution of an algorithm as an execution in which some high probability events are
satisfied  and derive bounds on regret conditional on the clean execution  the analysis of
a clean execution does not involve any probabilistic arguments  this approach tends to
simplify regret analysis 
we start by listing some simple invariants enforced by agnosticzooming 
invariant      in each round t of each execution of agnosticzooming 
 a  all active cells are relevant 
 b  each candidate contract is contained in some active cell 
 c  wt  c     radt  c  for each active composite cell c 
note that the zooming rule is essential to ensure invariant     c  
throughout  we say that the algorithm activates a cell if this cell is added to the
collection of active cells  a cell stays active once it is activated 
    analysis of the randomness
definition      clean execution   an execution of agnosticzooming is called clean if for
each round t and each active cell c it holds that
 u  c   ut  c    radt  c  
 virtwidth c   wt  c      radt  c 

    
 if c is composite  

    

lemma      assume crad     and t  max      m        then 
 a  pr   equation      holds  rounds t  active cells c         t    
 b  pr   equation      holds  rounds t  active composite cells c          t    
consequently  an execution of agnosticzooming is clean with probability at least      t  
   

fiho  slivkins    vaughan

lemma     follows from the standard concentration inequality known as chernoff
bounds  however  one needs to be careful about conditioning and other details 
proof of lemma     a   consider an execution of agnosticzooming  let n be the total
number of activated cells  since at most  m cells can be activated in any one round 
n       m t  t     let cj be the min j  n   th cell activated by the algorithm   if multiple
quadrants are activated in the same round  order them according to some fixed ordering
on the quadrants  
fix some feasible cell c and j  t     we claim that
pr    u  c   ut  c    radt  c  for all rounds t   cj   c         t    

    

let n c    n  t  c  be the total number of times cell c is chosen by the algorithm 
for each s  n     s  n c  let us be the requesters utility in the round when c is
chosen for the s th time  further  let dc be the distribution of u    conditional on the
event n s       that is  the per round reward from choosing cell c   let u             ut  be
a family of mutually independent random variables  each with distribution dc   then for
each n  t   conditional on the event  cj   c    n c    n   the tuple  u            un   has
the same joint distribution as the tuple  u             un     consequently  applying chernoff
bounds to the latter tuple  it follows that
fi
hfi
i
fi q
p
fi
pr fiu  c   n  ns   us fi  n  crad log t   fi  cj   c    n c    n 
      t  crad       t    
taking the union bound over all n  t   and plugging in radt  cj    nt  cj    and ut  cj    we
obtain equation      
now  let us keep j fixed in equation       and integrate over c  more precisely  let us
multiply both sides of equation      by pr cj   c  and sum over all feasible cells c  we
obtain  for all j  t    
pr    u  cj    ut  cj     radt  cj   for all rounds t         t    

    

 note that to obtain equation       we do not need to take the union bound over all
feasible cells c   to conclude  we take the union bound over all j      t    
proof sketch of lemma     b   we show that
fi
fi

pr fiv    c   vt   c fi  radt  c   rounds t  active composite cells c    

 
 
t 

    

and similarly for v      p      and p      each of these four statements is proved similarly 
using the technique from lemma     a   in what follows  we sketch the proof for one of the
four cases  namely for equation      
for a given composite cell c  we are only interested in rounds in which anchor x   c 
is selected by the algorithm  letting n 
t  c  be the number of times this anchor is chosen
up to time t  let us define the corresponding notion of confidence radius 
s
  crad log t
 
radt  c   
 
 
n 
t  c 
   

fiadaptive contract design for crowdsourcing markets

with the technique from the proof of lemma     a   we can establish the following
high probability event 
fi
fi  
fiv  c   v    c fi  rad   c  
    
t
t
more precisely  we can prove that
pr   equation      holds  rounds t  active composite cells c         t    
further  we need to prove that w h p  the anchor x   c  is played sufficiently often 
 
  
noting that e n 
t  c       nt  c   we establish an auxiliary high probability event 
n 
t  c  

 
 

nt  c      radt  c  

    

more precisely  we can use chernoff bounds to show that  if crad     
pr   equation      holds  rounds t  active composite cells c         t    

    

now  letting n     crad log t        observe that
nt  c   n 
nt  c    n 




 
n 
t  c     nt  c 
radt  c    




 
t  c  
fi
firad t  c   rad
fiv  c   v    c fi  radt  c  
t

fi
fi
therefore  once equations      and      hold  we have fiv    c   vt   c fi  radt  c   this
completes the proof of equation      
    analysis of a clean execution
the rest of the analysis focuses on a clean execution  recall that ct is the cell chosen by
the algorithm in round t 
claim      in any clean execution  i ct    opt xcand   for each round t 
proof  fix round t  and let x be any candidate contract  by invariant     b   there exists
an active cell  call it ct   which contains x  
we claim that it  ct    u  x    we consider two cases  depending on whether ct is
atomic  if ct is atomic then the anchor is unique  so u  ct     u  x    and it  ct    u  x  
by the clean execution  if ct is composite then
it  ct    u  ct     virtwidth ct  


u  ct  


 u  x  

 

by clean execution

width ct  

by lemma    
by definition of width  since x  ct  

we have proved that it  ct    u  x    now  by the selection rule we have it  ct    it  ct   
u  x    since this holds for any candidate contract x   the claim follows 
    the constant
proof 

 
 

in equation      is there to enable a consistent choice of n  in the remainder of the

   

fiho  slivkins    vaughan

claim      in any clean execution  for each round t  the index it  ct   is upper bounded as
follows 
 a  if ct is atomic then i ct    u  ct       radt  ct   
 b  if ct is composite then i ct    u  x    o radt  ct    for each contract x  ct  
proof  fix round t  part  a  follows because it  ct     ut  ct     radt  ct   by definition of the
index  and ut  ct    u  ct     radt  ct   by clean execution 
for part  b   fix a contract x  ct   then 
ut  ct    u  ct     radt  ct  

by clean execution

 u  x    width ct     radt  ct  

by definition of width

 u  x    virtwidth ct     radt  ct  

by lemma    

 u  x    wt  ct       radt  ct  

by clean execution 

it  ct     ut  ct     wt  ct       radt  ct  

    

by definition of index

 u  x      wt  ct        radt  ct  

by equation     

 u  x       radt  ct  

by invariant     c  

for each relevant cell c  define badness  c  as follows  if c is composite   c   
supxc  x  is the maximal badness among all contracts in c  if c is atomic and x  c
is the unique candidate contract in c  then  c     x  
claim      in any clean execution   c   o radt  c   for each round t and each active
cell c 
proof  by claims     and       ct    o radt  ct    for each round t  fix round t and
let c be an active cell in this round  if c has never be selected before round t  the claim
is trivially true  else  let s be the most recent round before t when c is selected by the
algorithm  then  c   o rads  c    the claim follows since rads  c    radt  c  
claim      in a clean execution  each cell c is selected  o log t    c      times 
proof  by claim       c   o radt  c    the claim follows from the definition of radt
in equation     
let n x  and n c  be the number of times contract x and cell c  respectively  are chosen
by the algorithm  then regret of the algorithm is
r t  xcand    

p

xx

n x   x  

p

cells c

n c   c  

    

the next result  lemma      upper bounds the right hand side of equation      for a clean
execution  by lemma      this suffices to complete the proof of theorem    
lemma      consider a clean execution of agnosticzooming  for any          
p

cells c

n c   c   t   o log t  
   

p

  j   jn

 f  x    
 


fiadaptive contract design for crowdsourcing markets

the proof of lemma     relies on some simple properties of     stated below 
claim      consider two relevant cells c  cp   then 
 a   c    cp   
 b  if  c    for some       then c overlaps with x  
proof  to prove part  a   one needs to consider two cases  depending on whether cell cp is
composite  if it is  the claim follows trivially  if cp is atomic  then c is atomic  too  and so
 c     cp      x   where x is the unique candidate contract in cp  
for part  b   there exists a candidate contract x  c  it is easy to see that  x    c 
 again  consider two cases  depending on whether c is composite   so  x  x  
proof of lemma      let  denote the sum in question  let a be the collection of all
cells ever activated by the algorithm  among such cells  consider those with badness on the
order of  
g      c  a    c            
by claim      the algorithm chooses each cell c  g at most o log t      times  so
n c   c   o log t    
fix some          and observe that all cells c with  c    contribute at most t
to   therefore it suffices to focus on g         it follows that
p
  t   o log t     i     g    
    
we bound  g   as follows  consider a cell c  g   the cell is called a leaf if it is never
zoomed in on  i e   removed from the active set  by the algorithm  if c is activated in the
round when cell cp is zoomed in on  cp is called the parent of c  we consider two cases 
depending on whether or not c is a leaf 
 i  assume cell c is not a leaf  since  c       c overlaps with x  by claim     b  
note that c is zoomed in on in some round  say in round t     then
  radt  c   wt  c 

by the zooming rule

 virtwidth c      radt  c 

by clean execution 

so radt  c   virtwidth c   therefore  using claim      we have
   c   o radt  c    o virtwidth c   
it follows that c  f    x    
 ii  assume cell c is a leaf  let cp be the parent of c  since c  cp   we have  c  
 cp   by claim     a   therefore  invoking case  i   we have
   c    cp    o virtwidth cp    
since  c       c overlaps with x  by claim     b   and therefore so does cp   it
follows that cp  f    x    
fi
fi
combing these two cases  it follows that  g      m      fif    x   fi  plugging this into
     and making an appropriate substitution      to simplify the resulting expression 
we obtain the regret bound in theorem    
   

fiho  slivkins    vaughan

   simulations
we evaluate the performance of agnosticzooming through simulations  agnosticzooming
is compared with two versions of nonadaptive that use  respectively  two standard bandit
algorithms  ucb   auer et al         and thompson sampling  thompson        with
gaussian priors  in both algorithms  in each round a numerical score  called index   is
computed for each arm  and an arm with a maximal index is chosen  in ucb   the index of
an arm is a high confidence upper bound on the expected reward of this arm  in thompson
sampling  the index is sampled independently from the bayesian posterior distribution of
the arms expected reward 
    setup
we consider a generalized version of the high low example from section   in which the
requesters value of the low outcome could be nonzero  in the results reported below  we
set the requesters values to v  high      and v  low        and the probability of obtaining
high outcome given high effort to h       while we do not explicitly report the results  we
additionally tried a wide range of alternative values of v  high   v  low   and h and found
that they were similar qualitatively  intuitively  varying the requesters values and h only
changes which contracts the algorithms converge to  that is  the optimal arms   but does
not impact the problem structure  the width dimension is the same for all settings 
in this generalized high low example  the workers type is characterized by the cost ch
for high effort  we consider three supply distributions 
 uniform  ch is uniformly distributed on        
 homogeneous  ch is the same for every worker 
 two type  ch is uniformly distributed over two values  c h and c  h  
these first two distributions represent the extreme cases in which workers are either
extremely homogeneous or extremely diverse  the third distribution is one way to get
at the middle ground  for each distribution  we run each algorithm     times    for the
homogeneous supply distribution  ch is drawn uniformly at random from        for each run 
for the two type supply distribution  c h and c  h are drawn independently and uniformly
from        on each run 
for both ucb  and agnosticzooming  we replace the logarithmic confidence terms with
small constants  we find this beneficial in practice for both algorithms  which is consistent
with prior work  radlinski  kleinberg    joachims        slivkins  radlinski    gollapudi 
       for both algorithms  we tried several different constants and found that performance
is not very sensitive to the particular constant used as long as it is on the order of    in the
results reported below  we set these confidence terms equal to    for ucb   this means that

if a given arm a has been played na times  its
p index is the average reward plus    na   for
agnosticzooming  it means that radt        nt    
all three algorithms are run with xcand   xcand     where      is a parameter
specifying the granularity of discretization 
    the standard errors in all plots are in the order of       or less   note that each point is not only the
average of     runs but also the average of all previous rounds  

   

fiadaptive contract design for crowdsourcing markets

    overview of the results 
across all simulations  agnosticzooming either outperforms or nearly matches nonadaptive 
its performance does not appear to suffer from the large hidden constants that appear in
the analysis  we find that agnosticzooming converges faster than nonadaptive when 
is near optimal or smaller  this is consistent with the intuition that agnosticzooming
focuses on exploring the more promising regions of contract space  when  is large 
agnosticzooming converges more slowly than nonadaptive  but eventually achieves similar
performance  further  we find that agnosticzooming with small  performs well compared
to nonadaptive with larger   in particular  it is not much worse initially  and much better
eventually 
our simulations suggest that if time horizon t is known in advance and one can tune
 to t   then nonadaptive can achieve near optimal performance  however  in real applications approximately optimal  may be difficult to compute  and the t may not be known in
advance  agnosticzooming performs consistently well with a wide range of  and therefore
does not require prior knowledge of t or careful tuning of  
    detailed results
for each algorithm  we compute the time averaged cumulative utility after t rounds given
b  t     for various values of t and  
granularity   denoted u
b  t    changes with
first  we fix the time horizon t to       rounds  and study how u
  the results are shown in figure    we observe that agnosticzooming either closely
matches or outperforms both versions of nonadaptive across all supply distributions and
all values of   agnosticzooming performs consistently well with different  while the
performance of both versions of nonadaptive decreases rapidly when  is small 
second  we study how the three algorithms perform over time  specifically  we plot
b  t     for three values of   namely             and      since setting   
t vs  u
     is close to optimal in our examples  these values of  represent  respectively  values that are too small  adequate  and too large  the results are shown in figure    for
small values of   agnosticzooming quickly zooms in on promising regions of the contract space  leading to faster converge than the alternatives  however  when  is large 
agnosticzooming converges more slowly  but eventually achieves similar performance  in
this regime  agnosticzooming does not reap the benefits of adaptive discretization because
the mesh of candidate contracts is too sparse  but still suffers the overhead  this suggests
that if the time horizon t is known in advance and one can optimize  given this t   then
nonadaptive can achieve near optimal performance  agnosticzooming performs consistently with different choices of  and therefore does not require either the prior knowledge
of t or the careful tuning of  
to further demonstrate the benefit of not having to know t or tune   we compare the
performance of agnosticzooming with small  against that of nonadaptive with different
b  t     see figure   
values of   for each algorithm and each choice of   we plot t vs  u
we only show the results for the uniform supply distribution since the results for other distributions are very similar  additionally  we omit the results for thompson sampling since
ucb  performed better in these experiments    we find that for small t   agnosticzooming
    we conjecture that this is because we replaced the logarithmic confidence term in ucb  with   

   

fi   

   

   

   

   

   

   
   

agnosticzooming
ucb 
thompsonsampling

   
   
    

    

    


    

average utility

average utility

ho  slivkins    vaughan

   
   

agnosticzooming
ucb 
thompsonsampling

   
   

    

    

 a  uniform supply distribution

    

    


    

    

 b  homogeneous supply distribution

   

average utility

   
   
   
   

agnosticzooming
ucb 
thompsonsampling

   
   
    

    

    


    

    

 c  two type supply distribution

figure    the requesters average per round utility after       rounds vs  the choice of
initial discretization  

with small  converges nearly as fast as nonadaptive with larger   when t is large 
agnosticzooming with small  matches nonadaptive with the optimal  
finally  in figure    we confirm the intuition that opt xcand     decreases with the
granularity   to this end  we run agnosticzooming for        rounds  so the algorithm
has time to nearly converge to the optimal contract   and examine the average utility over
the last       rounds  as expected  we see that the average requester utility achievable
when  is small is significantly higher than the utility achievable when  is larger 
our simulation results suggest that agnosticzooming performs well across different
supply distributions and different settings of   not requiring careful tuning of the algorithm
parameters  given that the smaller the value of   the better the payoff of the optimal
contract opt xcand      agnosticzooming with small  is a good algorithm for a variety
of settings 
   

fiadaptive contract design for crowdsourcing markets

agnosticzooming
   
   
   
   
   
   
   

thompsonsampling

uniform        

uniform        

uniform        

two type        

two type        

two type        

homogeneous        

homogeneous        

homogeneous        

average utility

   
   
   
   
   
   
   

ucb 

   
   
   
   
   
   
   
 

                        

 

                        

 

                        

time

figure    the requesters average per round utility over time under different supply distributions and discretization sizes 

   application to dynamic task pricing
we discuss dynamic task pricing  which can be seen as the special case of dynamic contract
design in which there is exactly one non null outcome  we identify an important family of
problem instances for which agnosticzooming out performs nonadaptive 
    background
the dynamic task pricing problem  in its most basic version  is defined as follows  there
is one principal  buyer  who sequentially interacts with multiple agents  sellers   in each
round t  an agent arrives  with one item for sale  the principal offers price pt for this item 
and the agent agrees to sell if and only if pt  ct   where ct         is the agents private
cost for this item  the principal derives value v for each item bought  his utility is the
value from bought items minus the payment  the time horizon t  the number of rounds 
is known  each private cost ct is an independent sample from some fixed distribution 
called the supply distribution  we are interested in the prior independent version  where
the supply distribution is not known to the principal  the algorithms goal is to choose the
offered prices pt so as to maximize the expected utility of the principal 
   

fiho  slivkins    vaughan

uniform

   

agnosticzooming        
ucb         
ucb         
ucb         

   

average utility

   
   
   
   
   
   
 

    

    

time

    

    

    

figure    the requesters average per round utility over time using agnosticzooming with
small  compared with nonadaptive with three different values of  

uniform

average utility of last  k rounds

   
   
   
   
   
   

agnosticzooming

   
    

    

    

    


    

    

    

figure    average requester utility over the last       rounds in a        round run of
agnosticzooming for different values of  

dynamic task pricing can be seen as the special case of dynamic contract design in
which there is exactly one non null outcome  which corresponds to a sale   indeed  in this
special case there is exactly one non null effort level e without loss of generality  because
any non null effort levels deterministically lead to the non null outcome  
   

fiadaptive contract design for crowdsourcing markets

one crucial simplification compared to the full generality of dynamic contract design is
that the discretization error can now be easily bounded from above    
opt x   opt xcand      

for each      

worst case regret bounds are implicit in prior work on dynamic inventory pricing  kleinberg   leighton           let nonadaptive   denote algorithm nonadaptive with xcand  
xcand     then  by the analysis in the work of kleinberg and leighton         nonadaptive  
achieves regret r t     o t         this is optimized to r t     o t       if and only
if    o t        moreover  there is a matching lower bound  r t      t       for any
algorithm 
further  it is a folklore result that nonadaptive   achieves regret r t     o t       if
and only if     t         we sketch a lower bounding example in the proof of lemma     
to make the paper more self contained  
    preliminaries
each contract is summarized by a single number  the offered price p for the non null
outcome  let f  p  be the probability of a worker accepting a task at price p  and let
u  p    f  p   v  p  be the corresponding expected utility of the algorithm 
note that all contracts are trivially monotone and any optimal contract is bounded
without loss of generality  it follows that opt x    supp  u  p   the optimal expected
utility over all possible prices 
a cell c is just a price interval c    p  p             and its virtual width is


virtwidth c    v f  p     p f  p   v f  p   p  f  p     
    our results  the general case
we will be using agnosticzooming with xcand   x 
first  let us prove that this is a reasonable choice in the worst case  namely  that we
achieve the optimal o t       regret 
lemma      consider the dynamic task pricing problem  agnosticzooming with xcand  
x achieves regret o t     log t   
proof sketch  fix       the key observation is that if virtwidth c    then either
p   p      or f  p     f  p       call c a red cell if the former happens  and blue cell
otherwise  therefore in any collection of mutually disjoint cells of virtual width   there
can be at most o      red cells and at most o      blue cells  hence at most o      cells total 
it follows that there can be at most o      active cells of virtual width   
so  in the notation of theorem     we have n     o       it follows that the width
dimension is at most    which in turn implies the desired regret bound 
    recall that xcand    denotes the set of all prices in        that are integer multiples of a given       call
this set the additive  mesh 
    the algorithmic result for dynamic task pricing is an easy modification of the analysis in the work of
kleinberg and leighton        for dynamic inventory pricing  the lower bound in the work of kleinberg
and leighton can also be translated from dynamic inventory pricing to dynamic task pricing without
introducing any new ideas  we omit the details from this version 

   

fiho  slivkins    vaughan

    our results  nice problem instances
we focus on problem instances with piecewise uniform costs and bounded density  formally 
we say that an instance of dynamic task pricing has k piecewise uniform costs if the interval
      is partitioned into k  n sub intervals such that the supply distribution is uniform
on each sub interval  a problem instance has  bounded density      if the supply
distribution has a probability density function almost everywhere  and the density is between
 
 and   using the full power of theorem      we obtain the following regret bound 
theorem      consider the dynamic task pricing problem with k piecewise uniform costs
and  bounded density  for some absolute constants k  n and       agnosticzooming
with xcand   x achieves regret r t     o t       
proof sketch  since the supply distribution has density at most   it follows that f    is a
lipschitz continuous function with lipschitz constant   it follows that each cell of virtual
width at least  has diameter at least      for any        note that each cell is now
simply a sub interval  p  q           so its diameter is simply q  p  

second  we claim that x is contained in a union of k intervals of diameter o     to
see this  consider the partition of        into k subintervals such that the supply distribution
has a uniform density on each subinterval  let  pj   qj   be the j th subinterval  let pj be the
local optimum of u    on this subinterval  and let xj     x   pj   qj     u  pj    u  x     

then x  j xj    we can show that xj    pj    pj     for some    o    
recall that n   x   is the number of feasible cells of virtual width at least   which
overlap with x   it follows that n   x   is at most k times the maximal number
 of
feasible cells of diameter at least     that overlap with an interval of diameter o    
therefore  n   x     o k        log      moreover  we have a less sophisticated upper
bound on n   x    it is at most the number of feasible cell of diameter at least     
so n   x     o    log      the theorem follows by plugging both upper bounds on
n   x   into equation     
    comparison with nonadaptive
consider nonadaptive      where      t       is the granularity required for the optimal
worst case performance  call a problem instance nice if it has   piecewise uniform costs
and  bounded density  for some sufficiently large absolute constant   say      for
concreteness  we claim that agnosticzooming outperforms nonadaptive     on the nice
problem instances 
lemma      nonadaptive     achieves regret r t      t       in the worst case over all
nice problem instances 
proof sketch  recall that for k     the supply distribution has density   on interval
    p     and density   on interval  p        for some numbers         p    we pick p  so that
it is sufficiently far from any point in xcand       note that the function u    is a parabola
on each of the two intervals  we adjust the densities so that u    achieves its maximum at
p    and the maximum of either of the two parabolas is sufficiently far from p    then the
discretization error of xcand      is at least       which implies regret    t   
   

fiadaptive contract design for crowdsourcing markets

    lower bound for nonadaptive
we provide a specific lower bounding example for the worst case performance of nonadaptive   
for an arbitrary       let f be the family of all problem instances with k piecewiseuniform costs and  bounded density  for all k  n and      
lemma      let r  t   be the maximal
over all problem inp regret of nonadaptive  
   
stances in f  then r  t      t   t      t   
proof sketch  for piecewise uniform costs  we have f         and f  p       assume that
the principal derives value v     from each item  then the expected utility from price p is
u  p    f  p     p  
fix       use the following problem instance  let p                  j      j  n  
set u  p       for each p  p    further  pick some p  p   and set u  p             
this defines f  p  for p  p         p    for the rest of the prices  define f    via linear
interpolation  this completes the description of the problem instance 
we show that x consists of n         candidate contracts  therefore  using stanp

dard lower bounding arguments for mab  we obtain r t  xcand      t n       t    
further  we show that the discretization error is at least     implying that r t   
r t  xcand      t   

   related work
this paper is related to three different areas  contract theory  market design for crowdsourcing  and online decision problems  below we outline connections to each of these
areas 
    contract theory
our model can be viewed as an extension of the classic principal agent model from contract
theory  laffont   martimort         in the most basic version of the classic model  a
single principal interacts with a single agent whose type  specified by a cost function and
production function  as described in section    is generally assumed to be known  the
principal specifies a contract mapping outcomes to payments that the principal commits to
make to the agent  the agent then chooses an action  i e   effort level  that stochastically
results in an outcome in order to maximize his expected utility given the contract  the
principal observes the outcome  but cannot directly observe the agents effort level  creating
a moral hazard problem  the goal of the principal is to design a contract to maximize
her own expected utility  which is the difference between the utility she receives from the
outcome and the payment she makes  this maximization can be written as a constrained
optimization problem  and it can be shown that linear contracts are optimal 
the adverse selection variation of the principal agent problem relaxes the assumption
that the agents type is known  most existing literature on the principal agent problem with
adverse selection focuses on applying the revelation principle  laffont   martimort        
in this setting  the principal offers a menu of contracts  and the contract chosen by the agent
reveals the agents type  the problem of selecting a menu of contracts that maximizes the
principals expected utility can again be formulated as a constrained optimization 
   

fiho  slivkins    vaughan

our work differs from the classic setting in that we consider a principal interacting with
multiple agents  and the principal may adjust her contract over time in an online manner 
several other authors have considered extensions of the classic model to multiple agents 
levy and vukina        show that with multiple agents it is optimal to set individual
linear contracts for each agent rather than a single uniform contract for all agents  but offer
a variety of descriptive explanations for why it is more common to see uniform contracts
in practice  babaioff  feldman  and nisan        consider a setting in which one principal
interacts with multiple agents  but observes only a single outcome which is a function of
all agents effort levels  misra  nair  and daljord        consider a variant in which the
algorithm must decide both how to set a uniform contract for many agents and how to
select a subset of agents to hire 
alternative online versions of the problem have been considered in the literature as well 
in dynamic principal agent problem  sannikov        williams        sannikov         a
single principal interacts with a single agent repeatedly over a period of time  the agent
can choose to exert different effort at different time  and the outcome at time t is a function
of all the efforts exerted by the agent before t  the principal cannot observe the agents
efforts but can observe the outcome  the goal of the principal is to design an optimal
contract over time to maximize his payoff  our work is different from this line of work since
we consider the setting with multiple agents with different  unknown types  our algorithm
needs to learn the distribution of agent types and design an optimal contract accordingly 
conitzer and garera        study the online principal agent problem with a similar
setting to ours  however  they focus on empirically comparing different online algorithms 
including bandit approaches with uniform discretization  gradient ascent  and bayesian
update approaches to the problem  our goal is to provide an algorithm with nice theoretical
guarantees 
bohren and kravitz        study the setting when the outcome is unverifiable  to
address this issue  they propose to assign a bundle of tasks to each worker  to verify
the outcome  each task in the bundle is chosen as a verifiable task with some non trivial
probability  a verifiable task can either be a gold standard task with known answer or a
task which is assigned to multiple workers for verification  the payment for a task bundle
is then conditional only on the outcome of verified tasks  in our setting  we assume the task
outcome is verifiable  we can relax this assumption by adopting similar approaches 
    incentives in crowdsourcing systems
researchers have recently begun to examine the design of incentive mechanisms to encourage
high quality work in crowdsourcing systems  jain  chen  and parkes        explore ways in
which to award virtual points to users in online question and answer forums to improve the
quality of answers  ghosh and hummel              and ghosh and mcafee        study
how to distribute user generated content  e g   youtube videos  to users to encourage the
production of high quality internet content by people who are motivated by attention  ho 
zhang  vaughan  and van der schaar        and zhang and van der schaar        consider
the design of two sided reputation systems to encourage good behavior from both workers
and requesters in crowdsourcing markets  while we also consider crowdsourcing markets 
   

fiadaptive contract design for crowdsourcing markets

our work differs in that it focuses on how to design monetary contracts  perhaps the most
natural incentive scheme  to incentivize workers to exert effort 
the problem closest to ours which has been studied in the context of crowdsourcing
systems is the online task pricing problem in which a requester has an unlimited supply of
tasks to be completed and a budget b to spend on them  badanidiyuru et al         singer
  mittal         workers with private costs arrive online  and the requester sets a single
price for each arriving worker  the goal is to learn the optimal single fixed price over time 
our work can be viewed as a generalization of the task pricing problem  which is a special
case of our setting with the number of non null outcomes m fixed at   
there has also been empirical work examining how workers behavior varies based on the
financial incentives offered in crowdsourcing markets  mason and watts        study how
workers react to changes of performance independent financial incentives  in their study 
increasing financial incentives increases the number of tasks workers complete  but not the
quality of their output  yin  chen  and sun        provide a potential explanation for this
phenomenon using the concept of anchoring effect  a workers cost for completing a task
is influenced by the first price the worker sees for this task  horton and chilton        run
experiments to estimate workers reservation wage for completing tasks  they show that
many workers respond rationally to offered contracts  whereas some of the workers appeared
to have some target payment in mind 
some recent research studies the effects of performance based payments  pbps   harris
       runs mturk experiments on resume screening  where workers can get a bonus if
they perform well  he concludes that the quality of work is better with pbps than with
uniform payments  yin et al         show that varying the magnitude of the bonus does
not have much effect in certain settings  ho et al         perform a more comprehensive set
of experiments aimed at determining whether  when  and why pbps increase the quality
of submitted work  their results suggest that pbps can increase quality on tasks for
which increased time or effort leads to higher quality work  their results also suggest that
workers may interpret a contract as performance based even if it is not stated as such  since
requesters always have the option to reject work   based on this evidence  they propose a
new model of worker behavior that extends the principal agent model to explicitly reflect
workers subjective beliefs about their likelihood of being paid 
overall  previous empirical work demonstrates that workers in crowdsourcing markets
do respond to the change of financial incentives  but that their behavior does not always
follow the traditional rational worker model  similar to people in any real world market 
in our work  we start our analysis with the rational worker assumption ubiquitous in economic theory  but demonstrate that our results can still hold without these assumptions as
long as the collective worker behavior satisfies some natural properties  namely  as long as
lemma     holds   we note that our results hold under the generalized worker model proposed by ho et al          which is consistent with their experimental evidence as discussed
above 
   

fiho  slivkins    vaughan

    sequential decision problems
in sequential decision problems  an algorithm makes sequential decisions over time  two
directions that are relevant to this paper are multi armed bandits  mab  and dynamic
pricing 
mab have been studied since       thompson        in operations research  economics 
and several branches of computer science including machine learning  theoretical computer
science  ai  and algorithmic economics  a survey of prior work on mab is beyond the scope
of this paper  the reader is encouraged to refer to the work of cesa bianchi and lugosi       
or bubeck and cesa bianchi        for background on prior independent mab  and to the
work of gittins  glazebrook  and weber        for background on bayesian mab  below
we briefly discuss the lines of work on mab that are directly relevant to our paper 
our setting can be modeled as prior independent mab with stochastic rewards  the reward of a given arm i is an i i d  sample of some time invariant distribution  and neither this
distribution nor a bayesian prior on it are known to the algorithm  the basic formulation
 with a small number of arms  is well understood  lai   robbins        auer et al        
bubeck   cesa bianchi         to handle problems with a large or infinite number of arms 
one typically needs side information on similarity between arms  a typical way to model
this side information  called lipschitz mab  kleinberg et al          is that an algorithm
is given a distance function on the arms  and the expected rewards are assumed to satisfy
lipschitz continuity  or a relaxation thereof  with respect this distance function  agrawal 
      kleinberg        auer et al         kleinberg et al         bubeck et al       a 
slivkins         most related to this paper is the idea of adaptive discretization which is
often used in this setting  kleinberg et al         bubeck et al       a  slivkins         and
particularly the zooming algorithm  kleinberg et al         slivkins         in particular 
the general template of our algorithm is similar to the one in the zooming algorithm  but
our selection rule and zooming rule are very different  reflecting the lack of a priori
known similarity information  
in some settings  including ours   the numerical similarity information required for lipschitz mab is not immediately available  for example  in applications to web search and
advertising it is natural to assume that an algorithm can only observe a tree shaped taxonomy on arms  kocsis   szepesvari        munos   coquelin        pandey et al        
slivkins        bull         in particular  slivkins        and bull        explicitly reconstruct  the relevant parts of  the metric space defined by the taxonomy  in a different
direction  bubeck  stoltz  and yu      b  study a version of lipschitz mab where the
lipschitz constant is not known  and essentially recover the performance of nonadaptive
for this setting 
in mab with partial monitoring  audibert   bubeck        bartok  foster  pal 
rakhlin    szepesvari        antos  bartok  pal    szepesvari         in each round the
algorithm receives auxiliary feedback about rewards in this round  along with the reward
of the chosen arm   and the goal is to take advantage of this auxiliary feedback  dynamic
task pricing can be cast in this framework  if a given price p is accepted  then any higher
price would be too  and if it is rejected  then any lower price would be  however  we are
not aware of any way to link dynamic task pricing to existing results on partial monitoring
   

fiadaptive contract design for crowdsourcing markets

via this connection  the general version of dynamic contract design does not appear to fit
the partial monitoring framework  essentially due to moral hazard 
dynamic pricing  a k a  online posted price auctions  refers to settings in which a
principal interacts with agents that arrive over time and offers each agent a price for a
transaction  such as selling or buying an item  the version in which the principal sells items
has been extensively studied in operations research  typically in a bayesian setting  see the
work of den boer        for a through literature review  the study of prior independent 
non parameterized formulations has been initiated in the work of blum  kumar  rudra 
and wu        and kleinberg and leighton        and continued by several others  besbes
  zeevi        babaioff  dughmi  kleinberg    slivkins        besbes   zeevi        wang 
deng    ye        badanidiyuru et al         badanidiyuru  langford    slivkins        
further  badanidiyuru et al         and singla and krause        studied the version in
which the principal buys items  or equivalently commissions tasks  we call this version
dynamic task pricing  modulo budget constraints  this is essentially the special case of our
setting where in each round a worker is offered the chance to perform a task at a specified
price  and can either accept or reject this offer  in particular  the workers strategic choice
is directly observable  more general settings have been studied  badanidiyuru et al        
      agrawal   devanur        agrawal  devanur    li           however  all this work
 after the initial papers  see blum et al        and kleinberg   leighton        has focused
on models with constraints on the principals supply or budgets  and does not imply any
improved results when specialized to unconstrained settings 

    conclusions
motivated by applications to crowdsourcing markets  we define the dynamic contract design
problem  a multi round version of the principal agent model with unobservable strategic
decisions  we treat this problem as a multi armed bandit problem  design an algorithm for
this problem  and derive regret bounds which compare favorably to prior work  our main
conceptual contribution  aside from identifying the model  is the adaptive discretization
approach that does not rely on lipschitz continuity assumptions  we provably improve
on the uniform discretization approach from prior work  both in the general case and in
some illustrative special cases  these theoretical results are supported by simulations  the
generality and the shortcomings of our model are discussed in section     
we believe that the dynamic contract design problem deserves further study  in several
directions that we outline below 
   it is not clear whether our provable results can be improved  perhaps using substantially
different algorithms and relative to different problem specific structures  in particular  one
needs to establish lower bounds in order to argue about optimality  no lower bounds for
dynamic contract design are currently known 
   our adaptive discretization approach may be fine tuned to improve its performance
in practice  in particular  the definition of the index it  c  of a given feasible cell c
    the papers by badanidiyuru et al         and agrawal and devanur        are concurrent and independent work with respect to the conference publication of this paper  and the work of agrawal et al 
       is subsequent work 

   

fiho  slivkins    vaughan

may be re defined in several different ways  first  it can use the information from c in
a more sophisticated way  similar to the more sophisticated indices for the basic k armed
bandit problem  for example  see the work of garivier and cappe         second  the index
can incorporate information from other cells  third  it can be defined in a smoother 
probabilistic way  e g   as in thompson sampling  thompson        
   deeper insights into the structure of the  static  principal agent problem are needed 
primarily in order to optimize the choice of xcand   the set of candidate contracts  the
most natural target here is the uniform mesh xcand     to optimize the granularity   one
needs to upper bound the discretization error opt xcand    opt xcand     in terms of some
function f    such that f       as      the first order open question is to resolve
whether this can be done in the general case  or provide a specific example when it cannot 
a related open question concerns the effect of increasing the granularity  upper bound the
difference opt xcand      opt xcand                  in terms of some function of  and    
further  it is not known whether the optimal mesh of contracts is in fact a uniform mesh 
also of interest is the effect of restricting our attention to monotone contracts  while
we prove that monotone contracts may not be optimal  appendix a   the significance of
this phenomenon is unclear  one would like to characterize the scenarios when restricting
to monotone contracts is alright  in the sense that the best monotone contract is as good 
or not much worse  than the best contract   and the scenarios when this restriction results
in a significant loss  for the latter scenarios  different algorithms may be needed 
   a much more extensive analysis of special cases is in order  our general results are
difficult to access  which appears to be an inherent property of the general problem   so the
most immediate direction for special cases is deriving lucid corollaries from the current regret
bounds  in particular  it is desirable to optimize the choice of candidate contracts  apart
from massaging the current results  one can also design improved algorithms and derive
specialized lower bounds  particularly appealing special cases concern supply distributions
that are mixtures of a small number of types  and supply distributions that belong to a
 simple  parameterized family with unknown parameter 
going beyond our current model  a natural direction is to incorporate a budget constraint  extending the corresponding results on dynamic task pricing  the main difficulty
for such settings is that a distribution over two contracts may perform much better than
any fixed contract  see the work of badanidiyuru et al         for discussion  effectively 
an algorithm needs to optimize over the distributions  as a first step  one can use nonadaptive discretization in conjunction with the general algorithms for bandits with budget
constraints  sometimes called bandits with knapsacks  badanidiyuru et al         agrawal
  devanur         however  it is not clear how to choose an optimal mesh of contracts
 as we discussed throughout the paper   and this mesh is not likely to be uniform  because
it is not uniform for the special case of dynamic task pricing with a budget  see badanidiyuru et al        for discussion   the eventual target in this research direction is to marry
adaptive discretization and the techniques from prior work on bandits with knapsacks 

   

fiadaptive contract design for crowdsourcing markets

acknowledgments
we thank the anonymous reviewers for their useful comments  much of this research was
completed while ho was an intern at microsoft research  this research was partially supported by the nsf under grant iis          any opinions  findings  conclusions  or recommendations are those of the authors alone 

appendix a  monotone contracts may not be optimal
in this section we provide an example of a problem instance for which all monotone contracts
are suboptimal  at least when restricting attention to only those contracts with non negative
payoffs   in this example  there are three non null outcomes  i e   m       and two non null
effort levels  low effort and high effort  which we denote e  and eh respectively  there
is only a single worker type  since there is only one type  we drop the subscript when
describing the cost function c  we let c e         and let c eh   be any positive value less
than     v     v      if a worker chooses low effort  the outcome is equally likely to be   or
   if the worker chooses high effort  it is equally likely to be   or    it is easy to verify that
this type satisfies the fosd assumption  finally  for simplicity  we assume that all workers
break ties between high effort and any other effort level in favor of high effort  and that all
workers break ties between low effort and the null effort level in favor of low effort 
lets consider the optimal contract  since there is just a single worker type and all
workers of this type break ties in the same way  we can consider separately the best contract
that would make all workers choose the null effort level  the best contract that would make
all workers choose low effort  and the best contract that would make all workers choose high
effort  and compare the requesters expected value for each 
since c e        and workers break ties between low effort and null effort in favor of low
effort  there is no contract that would cause workers to choose null effort  workers always
prefer low effort to null effort 
it is easy to see that the best contract  in terms of requester expected value  that would
make workers choose low effort would set x      x        and x    sufficiently low that
workers would not be enticed to choose high effort  setting x        is sufficient  in this
case  the expected value of the requester would be     v      v     
now lets consider contracts that cause workers to choose high effort  if a worker chooses
high effort  the expected value to the requester is
    v     x      v     x     

    

workers will choose high effort if and only if
    x      x          x      x      c eh  
or
   x        x     c eh   

    

so to find the contract that maximizes the requesters expected value when workers choose
high effort  we want to maximize equation    subject to the constraint in equation    
since x    doesnt appear in equation     we can set it to   to maximize equation    
   

fiho  slivkins    vaughan

since x    does not appear in equation     we can set x        to make equation    as
easy as possible to satisfy  we can then see that the optimal occurs when x       c eh   
plugging this contact x into equation     the expected utility in this case is     v     
v      c eh    since we assumed that c eh         v     v       this is strictly preferable to
the constant   contract  and is in fact the unique optimal contract  since x      x     the
unique optimal contract is not monotonic 

references
agrawal  r          the continuum armed bandit problem  siam j  control and optimization                   
agrawal  s     devanur  n  r          bandits with concave rewards and convex knapsacks 
in   th acm conf  on economics and computation  ec  
agrawal  s   devanur  n  r     li  l          contextual bandits with global constraints
and objective   technical report  arxiv            
antos  a   bartok  g   pal  d     szepesvari  c          toward a classification of finite
partial monitoring games  theor  comput  sci             
audibert  j     bubeck  s          regret bounds and minimax policies under partial
monitoring  j  of machine learning research  jmlr                
auer  p   cesa bianchi  n     fischer  p          finite time analysis of the multiarmed
bandit problem   machine learning                   
auer  p   ortner  r     szepesvari  c          improved rates for the stochastic continuumarmed bandit problem  in   th conf  on learning theory  colt   pp         
babaioff  m   dughmi  s   kleinberg  r  d     slivkins  a          dynamic pricing with
limited supply  acm trans  on economics and computation           
babaioff  m   feldman  m     nisan  n          combinatorial agency  in  th acm conf 
on electronic commerce  ec  
badanidiyuru  a   kleinberg  r     singer  y          learning on a budget  posted price
mechanisms for online procurement  in   th acm conf  on electronic commerce
 ec   pp         
badanidiyuru  a   kleinberg  r     slivkins  a          bandits with knapsacks  in   th
ieee symp  on foundations of computer science  focs  
badanidiyuru  a   langford  j     slivkins  a          resourceful contextual bandits  in
  th conf  on learning theory  colt  
bartok  g   foster  d  p   pal  d   rakhlin  a     szepesvari  c          partial monitoring
  classification  regret bounds  and algorithms  math  oper  res                  
besbes  o     zeevi  a          dynamic pricing without knowing the demand function 
risk bounds and near optimal algorithms  operations research               
besbes  o     zeevi  a  j          blind network revenue management  operations research 
                 
   

fiadaptive contract design for crowdsourcing markets

blum  a   kumar  v   rudra  a     wu  f          online learning in online auctions  in
  th acm siam symp  on discrete algorithms  soda   pp         
bohren  j  a     kravitz  t          incentives for spot market labor when output is
unverifiable  working paper 
bubeck  s     cesa bianchi  n          regret analysis of stochastic and nonstochastic
multi armed bandit problems  foundations and trends in machine learning        
     
bubeck  s   munos  r   stoltz  g     szepesvari  c       a   online optimization in xarmed bandits  j  of machine learning research  jmlr                
bubeck  s   stoltz  g     yu  j  y       b   lipschitz bandits without the lipschitz constant 
in   nd intl  conf  on algorithmic learning theory  alt   pp         
bull  a  d          adaptive treed bandits  tech  rep             arxiv org 
cesa bianchi  n     lugosi  g          prediction  learning  and games  cambridge univ 
press 
conitzer  v     garera  n          online learning algorithms for online principal agent
problems  and selling goods online   in international conference on machine learning
 icml  
den boer  a  v          dynamic pricing and learning  historical origins  current research 
and new directions  surveys in operations research and management science  forthcoming 
dudik  m   hsu  d   kale  s   karampatziakis  n   langford  j   reyzin  l     zhang  t 
        efficient optimal leanring for contextual bandits  in   th conf  on uncertainty
in artificial intelligence  uai  
garivier  a     cappe  o          the kl ucb algorithm for bounded stochastic bandits
and beyond  in   th conf  on learning theory  colt  
ghosh  a     hummel  p          a game theoretic analysis of rank order mechanisms for
user generated content  in   th acm conf  on electronic commerce  ec  
ghosh  a     hummel  p          learning and incentives in user generated content  multiarmed bandits with endogenous arms  in proc   th conference on innovations in
theoretical computer science  itcs  
ghosh  a     mcafee  p          incentivizing high quality user generated content  in   th
intl  world wide web conf   www  
gittins  j   glazebrook  k     weber  r          multi armed bandit allocation indices 
john wiley   sons 
harris  c  g          youre hired  an examination of crowdsourcing incentive models in
human resource tasks  in csdm 
ho  c   slivkins  a   suri  s     vaughan  j  w          incentivizing high quality crowdwork  in   th intl  world wide web conf   www  
ho  c  j   zhang  y   vaughan  j  w     van der schaar  m          towards social norm
design for crowdsourcing markets  in hcomp 
   

fiho  slivkins    vaughan

horton  j  j     chilton  l  b          the labor economics of paid crowdsourcing  in   th
acm conf  on electronic commerce  ec  
jain  s   chen  y     parkes  d          designing incentives for online question and answer
forums  games and economic behavior 
kleinberg  r          nearly tight bounds for the continuum armed bandit problem  in
  th advances in neural information processing systems  nips  
kleinberg  r     leighton  t          the value of knowing a demand curve  bounds
on regret for online posted price auctions   in   th ieee symp  on foundations of
computer science  focs   pp         
kleinberg  r   slivkins  a     upfal  e          multi armed bandits in metric spaces  in
  th acm symp  on theory of computing  stoc   pp         
kleinberg  r  d     leighton  f  t          the value of knowing a demand curve  bounds
on regret for online posted price auctions  in ieee symp  on foundations of computer
science  focs  
kocsis  l     szepesvari  c          bandit based monte carlo planning  in   th european
conf  on machine learning  ecml   pp         
laffont  j  j     martimort  d          the theory of incentives  the principal agent
model  princeton university press 
lai  t  l     robbins  h          asymptotically efficient adaptive allocation rules 
advances in applied mathematics         
levy  a     vukina  t          optimal linear contracts with heterogeneous agents  in
european review of agricultural economics 
mason  w     watts  d          financial incentives and the performance of crowds  in
hcomp 
misra  s   nair  h  s     daljord  o          homogenous contracts for heterogeneous
agents  aligning salesforce composition and compensation  working paper 
munos  r     coquelin  p  a          bandit algorithms for tree search  in   rd conf  on
uncertainty in artificial intelligence  uai  
pandey  s   agarwal  d   chakrabarti  d     josifovski  v          bandits for taxonomies 
a model based approach  in siam intl  conf  on data mining  sdm  
radlinski  f   kleinberg  r     joachims  t          learning diverse rankings with multiarmed bandits  in   th intl  conf  on machine learning  icml   pp         
sannikov  y          a continuous time version of the principal agent problem  in the
review of economics studies 
sannikov  y          contracts  the theory of dynamic principal agent relationships and
the continuous time approach  in   th world congress of the econometric society 
singer  y     mittal  m          pricing mechanisms in crowdsourcing markets  in   nd
intl  world wide web conf   www  
singla  a     krause  a          truthful incentives in crowdsourcing tasks using regret
minimization mechanisms  in   nd intl  world wide web conf   www  
   

fiadaptive contract design for crowdsourcing markets

slivkins  a          multi armed bandits on implicit metric spaces  in   th advances in
neural information processing systems  nips  
slivkins  a          contextual bandits with similarity information  j  of machine learning
research  jmlr                     preliminary version in colt      
slivkins  a   radlinski  f     gollapudi  s          ranked bandits in metric spaces  learning optimally diverse rankings over large document collections  j  of machine learning
research  jmlr       feb           preliminary version in   th icml       
thompson  w  r          on the likelihood that one unknown probability exceeds another
in view of the evidence of two samples   biometrika                   
wang  z   deng  s     ye  y          close the gaps  a learning while doing algorithm for
single product revenue management problems  operations research                 
williams  n          on dynamic principal agent problems in continuous time  working
paper 
yin  m   chen  y     sun  y  a          the effects of performance contingent financial
incentives in online labor markets  in aaai 
zhang  y     van der schaar  m          reputation based incentive protocols in crowdsourcing applications  in infocom 

   

fi