journal of artificial intelligence research                 

submitted        published      

goal probability analysis in mdp probabilistic planning 
exploring and enhancing the state of the art
marcel steinmetz
jorg hoffmann

steinmetz   cs   uni   saarland   de
hoffmann   cs   uni   saarland   de

saarland university 
saarland informatics campus 
saarbrucken  germany

olivier buffet

olivier   buffet   loria   fr

inria   universite de lorraine   cnrs 
nancy  france

abstract
unavoidable dead ends are common in many probabilistic planning problems  e g  when actions may fail or when operating under resource constraints  an important objective in such settings
is maxprob  determining the maximal probability with which the goal can be reached  and a policy
achieving that probability  yet algorithms for maxprob probabilistic planning are severely underexplored  to the extent that there is scant evidence of what the empirical state of the art actually is 
we close this gap with a comprehensive empirical analysis  we design and explore a large space
of heuristic search algorithms  systematizing known algorithms and contributing several new algorithm variants  we consider maxprob  as well as weaker objectives that we baptize atleastprob
 requiring to achieve a given goal probabilty threshold  and approxprob  requiring to compute
the maximum goal probability up to a given accuracy   we explore both the general case where
there may be   reward cycles  and the practically relevant special case of acyclic planning  such
as planning with a limited action cost budget  we design suitable termination criteria  search algorithm variants  dead end pruning methods using classical planning heuristics  and node selection
strategies  we design a benchmark suite comprising more than      instances adapted from the
ippc  resource constrained planning  and simulated penetration testing  our evaluation clarifies
the state of the art  characterizes the behavior of a wide range of heuristic search algorithms  and
demonstrates significant benefits of our new algorithm variants 

   introduction
many probabilistic planning problems contain unavoidable dead ends  e g  kolobov  mausam 
weld    geffner        teichteil konigsbuch  vidal    infantes        kolobov  mausam    weld 
      teichteil konigsbuch         i e   no policy guarantees to eventually  under all circumstances 
attain the goal  examples are planning under resource constraints or a limited budget  or situations
where actions may fail and we will eventually run out of options  one important objective then is
maxprob  determining the maximal probability with which the goal can be reached  and identifying
a policy achieving that probability   maxprob also partly underlies the international probabilistic planning competition  ippc   younes  littman  weissman    asmuth        bryce   buffet 
      coles  coles  garca olaya  jimenez  linares lopez  sanner    yoon         when planners are evaluated by how often they reach the goal in online policy execution   the time limit
in the ippc setting mixes maxprob with a bias towards policies reaching the goal quickly  this
c
    
ai access foundation  all rights reserved 

fis teinmetz   h offmann   b uffet

also relates to the proposals by kolobov et al        and teichteil konigsbuch        asking for
the cheapest policy among those maximizing goal probability  and to the proposal by chatterjee 
chmelik  gupta    kanodia              asking for the cheapest policy ensuring that a target state
is reached almost surely in a partially observable setting  
we consider mdp based probabilistic planning  with factored models  probabilistic extensions
of strips  whose state spaces may be too large to build explicitly  we focus on the optimal offline
setting  i e   solving maxprob exactly  while this setup and objective certainly is relevant  there has
been little work towards developing solvers  the main effort was made by kolobov et al         
which we discuss in detail below  hou  yeoh  and varakantham        consider several variants
of topological vi  dai  mausam  weld    goldsmith         solving maxprob but necessitating to
build the entire reachable state space  other works addressing goal probability maximization do
not aim at guaranteeing optimality  e g  teichteil konigsbuch  kuter    infantes        camacho 
muise    mcilraith        
mdp heuristic search  barto  bradtke    singh        hansen   zilberstein        bonet
  geffner      b  mcmahan  likhachev    gordon        smith   simmons        bonet  
geffner        has the potential to find optimal policies without building the entire state space  but
kolobov et al         are the only authors addressing optimal maxprob through heuristic search 
part of the reason for this lack of research on heuristic search for maxprob are the following two major obstacles  first  while mdp heuristic search has been successful in expected cost minimization 
it suffers from a lack of admissible  upper bounding  heuristic estimators of goal probability  the
best known possibility is to detect dead ends and set their initial heuristic estimate to    using the
trivial upper bound   elsewhere  second  maxprob does not fit the stochastic shortest path  ssp 
framework  bertsekas         due to   reward cycles  as pointed out by kolobov et al         
maxprob is equivalent to a non discounted reward maximization problem  where non goal cycles
receive   reward and thus improper policies do not accumulate reward  
to address the second problem  kolobov et al         devised the fret  find  revise  eliminate traps  framework  which admits heuristic search  yet requires several iterations of complete
searches  in between heuristic search iterations  fret eliminates   reward cycles  traps   fret iterates until no more such cycles persist  kolobov et al s contribution is mainly theoretical  considering not only maxprob but a much larger class of generalized ssps  and their empirical evaluation
serves merely as a proof of concept  they experiment with a single domain  explodingblocks   and
run only one configuration of search  lrtdp  bonet   geffner      b   with one possibility for
dead end detection and thus non trivial initial heuristic estimates  sixthsense  kolobov  mausam 
  weld         this does outperform value iteration  vi   but the dead end detection is not used
in vi  and it remains unclear to what extent the improvement is due to the actual heuristic search 
rather than the state pruning itself 
in summary  heuristic search for maxprob is challenging  and has only been addressed by
kolobov et al          with very limited experiments  given this 
 i  what is actually the empirical state of the art in heuristic search for maxprob  are there other
known algorithms  or variants thereof  that work better 
we explore a large design space of such algorithms  and show that  indeed  some variants work
much better 
 ii  what about simpler yet still relevant special cases  and weaker objectives  that may be easier
to solve 
   

fig oal p robability a nalysis in p robabilistic p lanning

there are indeed practically relevant cases that do not necessitate fret  and weaker objectives
that enable what we will refer to as early termination 
to elaborate first on  ii   if the state space of the planning task at hand is acyclic  then clearly fret
is not needed  there are no cycles  so in particular no   reward cycles  and the state space is
finite  so that any execution will end in a  goal or non goal  absorbing state  this implies that we are
within the realm of ssps  this special case is  however  still practically relevant  as an illustration 
acyclic state spaces occur even in a standard ippc benchmarks  namely in the triangletireworld
domain where moves can only be made in one direction  more importantly  planning with a limited
action cost budget  limited budget planning  has acyclic state spaces when action costs are non   
strictly decreasing the remaining budget  a similar class of scenarios is where every action consumes a non   amount of some non replenishable resource  another example are recently proposed
models of simulated penetration testing  as per hoffmann         the mdp there models a network
intrusion from the point of view of an attacker  the state space is acyclic because each exploit can
be attempted at most once  trying the same exploit again on the same network configuration would
yield the same outcome   states thus need to remember the remaining action set  and every action
application strictly reduces that set 
regarding weaker objectives  as alternatives to maxprob  it is reasonable to ask whether the
maximum goal probability exceeds a given threshold   or to require computing the maximum goal
probability up to a given accuracy   we refer to these objectives as atleastprob and approxprob
respectively   for example  in penetration testing  atleastprob naturally assesses the level of network security  can an attacker reach a target host with probability greater than a given security
margin  e g   can a customer data server be compromised with probability greater than      
atleastprob and approxprob allow early termination based on maintaining both  a lower  pessimistic  bound v l and an upper  admissible optimistic  bound v u   this is especially promising
in atleastprob  where we can terminate if the lower bound already is good enough  v l     or if
the upper bound already proves infeasibility  v u      good anytime behavior  on either or both
bounds  translates into early termination 
let us now elaborate on  i   exploring the state of the art and beyond  we design an algorithm
space characterized by 
 a  search algorithm  we design variants of ao  nilsson         lrtdp  bonet   geffner 
    b   and depth first oriented heuristic searches  bonet   geffner      a         maintaining
upper and lower bounds for early termination 
 b  fret  we design a new variant of fret better suited to problems with uninformative initial
upper bounds 
 c  bisimulation reduction  we design a new probabilistic state space reduction method  via bisimulation relative to the all outcomes determinization  e g  bonet   geffner      b  yoon  fern 
  givan        little   thiebaux        
   atleastprob relates to mdp model checking  where one typically wants to validate that a given pctl  probabilistic
computation tree logic  formula is valid with some probability  baier  groer  leucker  bollig    ciesinski       
kwiatkowska  parker    qu      a  kwiatkowska  norman    parker      b   it also relates to constrained mdps
 altman         as enforcing a minimum success probability could be expressed through a constraint on a particular
quantity  chance constrained pomdps  santana  thibaux    williams        are different from atleastprob as
their constraint is on the probability to remain in safe states  not to reach goal states 

   

fis teinmetz   h offmann   b uffet

 d  dead end pruning method  we employ classical planning heuristic functions for dead end detection in probabilistic planning  via the all outcomes determinization  as previously done by
teichteil konigsbuch et al          this is especially promising in limited budget planning 
where we can prune a state s if an admissible classical planning estimate exceeds the remaining
budget in s 
 e  node selection strategy  we design a comprehensive arsenal of simple strategies  biasing tie
breaking in action and state selection in manners targeted at fostering early termination 
we implemented all these techniques within fast downward  fd   helmert         thus contributing  as a side effect of our work  an ideal implementation basis for exploiting classical planning
heuristic search techniques in mdp heuristic search  
the algorithm dimensions  a    e  are orthogonal  excepting some dependencies  in particular
that bisimulation reduction subsumes dead end pruning   we explore the behavior of the resulting
design space on a large benchmark suite we design for that purpose  the suite includes domains
from the ippc  resource constrained planning  and penetration testing  each with with a limitedbudget version and an unlimited budget version  the suite comprises      benchmark instances in
total   amongst other things  we observe 
 heuristic search yields substantial benefits  even with the trivial admissible heuristic setting
the initial estimate to   everywhere      total coverage across all benchmarks   more so
with admissible heuristics based on dead end detection        
 early termination yields substantial benefits  e g  for atleastprob     with        and
    with         
 our fret variant yields dramatic benefits       total coverage on the cyclic benchmarks  
 bisimulation reduction yields an optimal maxprob solver that excells in triangletireworld 
even surpassing prob prp  muise  mcilraith    beck        camacho et al          and
this not only in the standard version where the goal can be achieved with certainty and hence
prob prp is optimal  but also in the limited budget version where that is not so 
on the side  we discover that landmarks compilation as per domshlak and mirkis         employed
for dead end pruning in their oversubscription planning setting  is actually  on its own  equivalent
to pruning against the remaining budget with a standard admissible landmark heuristic  this is
relevant to our work because  otherwise  that compilation would be a canonical candidate also for
dead end pruning in our setting  indeed this is what we started out with in our investigation  
the paper is organized as follows  section   describes our model syntax and semantics  for goal
probability analysis with and without an action cost budget limit  section   specifies our search
algorithm  a  and fret variants  b   section   describes our bisimulation reduction method  c  
section   describes the dead end pruning methods  d   and section   describes the node selection
strategies  e   we present our experiments in section    and we conclude in section    there are
two appendices giving additional technical details that we only sketch in the main text  appendix b
   the source code is available at http   fai cs uni saarland de downloads fd prob tar bz 
   the
benchmark
suite
is
available
at
http   fai cs uni saarland de downloads 
ppddl benchmarks acyclic tar bz   acyclic cases  and http   fai cs uni saarland 
de downloads ppddl benchmarks cyclic tar bz   cyclic cases  

   

fig oal p robability a nalysis in p robabilistic p lanning

regarding domshlak and mirkis        landmarks compilation  and appendix a regarding depthfirst oriented heuristic searches   

   mdp models
we consider ppddl style models  younes et al          more precisely probabilistic extensions of
strips  we employ two formalism variants  with and without a limited action cost budget  we
specify first the unlimited budget version  planning tasks are tuples     f  a  i  g  consisting of
a finite set f of facts  a finite set a of actions  an initial state i  f   and a goal g  f   each
a  a is a pair  pre a   o a   where pre a   f is the precondition  and o a  is the finite set of
outcomes o  each o  o a  is a tuple  p o   add  o   del  o  
p of outcome probability p o   add list
add  o   f   and delete list del  o   f   we require that oo a  p o      
given a task   its state space is a probabilistic transition system  s  p  i  s     here  s is the
set of states  each s  s associated with its set f  s  of true facts  the initial state i is that of  
the set of goal states s   s contains those s where g  f  s   transitions  and the transition
probability function p   s  a  s           are defined as follows  action a is applicable to state
s if pre a   f  s  and s   s   goal states are absorbing  see also below   by a s  we denote the
set of actions applicable in s  given s  a  a s   and an outcome o  o a   by sjok we denote the
result of outcome o in s  i e   f  sjok      f  s   add  o     del  o   we define p  s  a  t     p o 
if a is applicable to s and t   sjok   otherwise  we define p  s  a  t        there is no transition  
absorbing states are those with no outgoing transitions  no applicable actions   the set of non goal
absorbing states  lost states  is denoted s  
for limited budget planning  we extend the above as follows  a limited budget task is a tuple
    f  a  i  g  b   as above but now including also a budget b  r 
    and associating each
 
in
addition
to
their
true
facts
f
 s  
states s are now also
action outcome o with a cost c o   r 
 
associated with their remaining budget b s   r  states with negative remaining budget b s     
are legal and may occur  but they are lost  s  s   due to the following definitions of goal states 
action applicability  and transitions  the goal states s  s  are those where g  f  s  and
b s      i e   we must reach the goal with    remaining budget  the actions a applicable to s are
those where pre a   f  s  and at least one outcome fits within the remaining budget  i e   there
exists o  o a  so that c o   b s   in the outcome states sjok  the outcomes cost is deduced from
the remaining budget  i e   b sjok     b s   c o  
a few notes are in order regarding limited budget planning  if c o      for all o  then the state
space  viewed as a directed graph with an arc  s  t  whenever there is an action mapping s into t
with non   probability  is acyclic because every transition strictly reduces the remaining budget 
the state space is infinite due to the continuous state variable b s   but its reachable part  which our
algorithms consider  is finite  note further that the remaining budget is local to each state  if some
states in a policy violate the budget  other parts of the policy  even other outcomes of the same
action  can still continue trying to reach the goal  this differs from constrained mdps  altman 
       where the budget bound is applied globally to the expected cost of the policy  also note
   this paper is an extension of a previous conference paper  steinmetz  hoffmann    buffet         we cover a larger
space of algorithms  now including depth first oriented heuristic searches   provide comprehensive explanations and
discussions  and present our experiments in detail 
   we assume here that each o  o a  leads to a different outcome state  this is just to simplify notation  our
implementation does not make this assumption  

   

fis teinmetz   h offmann   b uffet

that  while a single budget is considered here for the sake of simplicity  our framework and results
straightforwardly extend to models with multiple budget variables 
limited budget planning has been explored in a deterministic oversubscription setting  the objective being to maximize the reward from achieved  soft  goals subject to the budget  domshlak
  mirkis         a classical planning variant would relate to resource constrained planning  e g 
haslum   geffner        nakhost  hoffmann    muller        coles  coles  fox    long       
with a single consumed resource  our probabilistic variant here has been previously considered
only by hou et al          prior work on probabilistic planning with resources  e g  marecki  
tambe        meuleau  benazera  brafman  hansen    mausam        coles        has often
assumed limited budgets and non   consumption  but has dealt with uncertain continuous resource
consumption  in contrast to the discrete and fixed budget consumed by action costs 
though relatively restricted  limited budget probabilistic planning is quite natural  decision
making is often constrained by a finite budget  furthermore  non   costs are often reasonable to
assume  this applies to  for example  penetration testing  problems asking to achieve a goal within
a given number of steps  e g  finite horizon goal probability maximization  are a special case 
let us now define solutions to our planning tasks  as well as the objectives we wish these to
achieve  a policy is a partial function    s    s   s     a      mapping each non absorbing
state s within its domain either to an action applicable in s  or to the dont care symbol   that
symbol will be used  only  by policies that already achieve sufficient goal probability elsewhere 
so do not need to elaborate on how to act on s and its descendants  that is  we still require closed
policies  see below   and we use  to explicitly indicate special cases where actions may be chosen
arbitrarily  formally   s     extends the domain of  by picking  for every t   s  s reachable
from s and where  t  is undefined  an arbitrary action a applicable in t and setting  t     a 
a policy  is closed for state s if  for every state t   s   s reachable from s under    t  is
defined   is closed if it is closed for the initial state i   is proper if  from every state s on which
 is defined   eventually reaches an absorbing state with probability    
following kolobov et al          we formulate goal probability as maximal non discounted
expected reward where reaching the goal gives reward   and all other rewards are    the value
v   s  of a policy  closed for state s then is 

s  s 
 
s  s
v   s     p
   


t p  s   s   t v  t  otherwise
the optimal value of state s is
v   s   

max

  closed for s

v   s 

   

observe here that  in difference to kolobov et al  who consider problems more general than maxprob  we dont need to exclude improper  from this maximization  this is because there are no
negative rewards  i e   policies cannot gain anything from infinite cycles 
given a value function v  any function mapping states to r   the bellman update operator is
defined  as usual  through maximization over actions relative to the current values given by v  
   keep in mind here that the absorbing states in our setting are s   s   i e   goal states and lost states  while an ssp
policy can only be considered as valid when all executions end up in a goal state  because finding a shortest path
implies that a path exists  a maxprob policy is valid when all executions end up in an absorbing  goal or non goal 
state  executions may fail  but need to always terminate 

   

fig oal p robability a nalysis in p robabilistic p lanning


s  s 
 
s  s
v  s      
p

maxaa s  t p  s  a  t v  t  otherwise

   

the difference between v  s  prior to the update  and its updated value according to the right hand
side  is called the bellman residual 
the greedy policy  on a value function v selects in each non absorbing state an action obtaining the maximum in the right hand side of this equation  note that the greedy policy is unique only
up to tie breaking   we will refer to the state space subgraph induced by those states reachable from
i using such a greedy policy  as the  greedy graph  by the v  greedy graph  we will refer to
the state space subgraph induced by those states reachable from i by any greedy policy on v   i e  
allowing in each state to choose any action greedy on v  
for acyclic state spaces  every run ends in an absorbing state in a finite number of steps  so
we are facing an ssp problem  subject to our definition of absorbing states  cf  above  and the
bellman update operator has the unique fixed point v    which it converges to from any initial v  
for cyclic state spaces  as pointed out by kolobov et al          the bellman update operator may
have multiple sub optimal fixed points  and updates from an optimistic  upper bound  initialization
v are not guaranteed to converge to the optimum v    one can either use a pessimistic  lowerbound  initialization v   from which the updates are guaranteed to converge to v    or one can use
kolobov et al s fret method described earlier 
we consider three different objectives  algorithmic problems  for goal probability analysis 
maxprob  find an optimal policy  i e   a closed  s t  v   i    v   i  
atleastprob  find a policy guaranteeing a user defined goal probability threshold           i e  
a closed  s t  v   i      or prove that such  does not exist  
approxprob  find a policy optimal up to a user defined goal probability accuracy           i e  
a closed  s t  v   i   v   i    
we now define our algorithm family addressing these problems  we cover search algorithms  bisimulation reduction  dead end pruning  and node selection strategies  in this order 

   search algorithms
we use value iteration  vi  as a baseline  we design variants of ao and lrtdp  as well as a family
of depth first oriented heuristic searches  systematizing algorithm parameters underlying improved
lao  here  ilao    hansen   zilberstein         heuristic dynamic programming  bonet  
geffner      a   and learning depth first search  bonet   geffner         we furthermore design a
variant of fret better suited to problems with uninformative initial upper bounds 
    vi
as a pre process to vi  we make one forward pass building the reachable state space  actually
its pruned subgraph  see section     we initialize the value function pessimistically  simply as  
everywhere  for acyclic cases  we then perform a single backward pass of bellman updates  starting
at absorbing states and updating children before parents  thus computing the optimal value function
while updating every state exactly once 
   

fis teinmetz   h offmann   b uffet

procedure goalprob ao
initialize  to consist only of i  initialize i 
loop do
if  maxprob  v l  i      
 atleastprob v l  i    
 approxprob  v l  i       or v u  i   v l  i     then
return  l endif    early termination  positive    
if  atleastprob  v u  i      then
return impossible endif    early termination  negative    
if ex  leaf state s   s   s in  reachable using  u then
select such a state s
else return  u endif    regular termination   
for all a and t where p  s  a  t      do
if t not already contained in  then
insert t as child of s into   initialize t 
else insert s as a new parent of t into 
endif
endfor
backwardsupdate s 
endloop
procedure 
initialize s  
  s  s
u
v  s    
   otherwise
  s  s 
l
v  s    
  otherwise
if s   s   s then  l  s      endif

figure    ao  search for maxprob  atleastprob  and approxprob  as indicated   on acyclic state
spaces   u is the current greedy policy on v u    l is the current greedy policy on v l  
the backwardsupdate s  procedure updates all of v u    u   v l    l   as states may have
several parents in   we first make a backwards sweep to collect the sub graph  s ending
in s  to update v u and  u   the greedy sub graph on v u suffices   then we update  s
in reverse topological order 
for the general cyclic case  we assume a convergence parameter   likewise in all other algorithms addressing this case   and compute an  consistent value function  where the bellman
residual on every state is at most   for efficient value iteration  we employ topological vi as per
dai et al          we find the strongly connected components  scc  of the state space  and handle
each scc individually  children sccs before parent sccs  vi on an scc stops when every state is
 consistent 
dai et al         also introduce focused topological vi  which eliminates sub optimal actions
in a pre process to obtain smaller sccs  while this can be much more runtime effective  it still
requires building the entire state space  in our experiments  runtime memory exhaustion during this
process  i e   during building the state space  was the only reason for vi failures  so we do not
consider focused topological vi here 
    ao
for ao   we restrict ourselves to the acyclic case  where the overhead for repeated value iteration
fixed points  inherent in lao  hansen   zilberstein         disappears   the ilao variant 
   

fig oal p robability a nalysis in p robabilistic p lanning

where that issue has been addressed through a depth first orientation  is covered as part of our
depth first oriented heuristic search family introduced in section     below  
figure   shows pseudo code for our goalprob ao variant  the algorithm incrementally constructs a subgraph  of the state space  the handling of duplicates is simple  identifying search
nodes with states  as the state space is acyclic  for the same reason  simple backward updating
suffices to maintain the value function  adopting ideas from prior work  e g  mcmahan et al        
little  aberdeen    thiebaux        smith   simmons        kuter   hu         we maintain
two value functions  namely both an upper bound v u and a lower bound v l on goal probability 
for lack of heuristic estimators of goal probability  both value functions are initialized trivially 
by   for v u and by   for v l   except for absorbing states where the exact value is known   dead end
detection  as a simple but non trivial v u initialization  will be discussed in section     nevertheless 
both bounds can be useful for search  through early termination  v l and v u    and through detecting
sub optimal parts of the state space  v u    to observe the latter  note that  to refute an action a  it
may suffice to reduce v u for just one of as outcomes  hence  even for trivial initialization  v u
may allow to disregard parts of the search space  in the usual way of admissible heuristic functions 
as we shall see  this kind of behavior occurs frequently in practice  as reflected by our benchmarks  
regarding early termination  the lower bound enables positive early termination when we can
already guarantee sufficient goal probability  namely    maxprob     atleastprob   or      approxprob   the upper bound enables negative early termination in atleastprob  when v u  i     
in approxprob  clearly we can terminate when v u  i   v l  i     a relevant observation
here is that the v l  i       maxprob  and v l  i        approxprob  criteria are redundant
when maintaining an upper bound  i e   for heuristic search  if v l  i        then trivially also
v u  i   v l  i     if v l  i       then there is a search branch achieving the goal with certainty 
so v u  i      there as well and search terminates regularly  in configurations not maintaining v u  
however  these criteria can be very useful to reduce search 
the correctness of goalprob ao is easy to establish  by the standard properties of bellman
updates  at any point in time during the execution of the algorithm  and for any state s in   we
have that v l  s   v   s   v u  s   i e   v l and v u are lower respectively upper bounds on goal
probability  indeed  these bounds are monotone  bertsekas   tsitsiklis 
       precisely  v l and
p
u
l
v are exact on absorbing states  and satisfy v  s   maxaa s  t p  s  a  t v l  t  respectively
p
v u  s   maxaa s  t p  s  a  t v u  t  on non absorbing ones  this is because v l and v u are
initialized with functions trivially satisfying these properties  and these properties are invariant over
bellman updates on non absorbing states  given monotonicity  v l can only grow  while v u can
only decrease   thanks to monotonicity  with the same arguments as given for lao  hansen  
zilberstein         we get that v u converges to v  in finite time on the  u  greedy graph 
finally  we need to prove that  in case of early termination returning  l   the greedy policy  l
on v l actually achieves what we want  i e        l is closed and      l provides sufficient goal
l
probability  i e   v   i   v l  i   for       l is always a closed policy  because it applies the
dont care symbol  at the non absorbing leaf states in    note also that  is applied only by  l
l
and only on those states   for      we show that  for all states s  we have v   s   v l  s   this
claim is trivial for states s where  l  s      as these have never been updated so v l  s       for
other states s  the claim follows by a simple inductive reasoning over the maximal distance to an
l
absorbing state in the  l  greedy graph  for absorbing states s  we have v   s    v l  s    v   s  
p
l
l
so the claim is trivially satisfied  in the induction step  we have v   s    t p  s   l  s   t v   t 
l
l
by definition of v    while  by the induction hypothesis  v   t   v l  t  for all those states t
   

fis teinmetz   h offmann   b uffet

procedure goalprob lrtdp
     i   initialize i 
loop do
 early termination criteria exactly as in goalprob ao  
if i is not labeled as solved then
lrtdp trial i 
else return  u endif    regular termination   
endloop
procedure lrtdp trial s  
p    empty stack
while s is not labeled as solved do
push s onto p
if s  s   s then break endif
 cyclic  if s is  consistent then break endif 
for all a and t where p  s  a  t      do
if t    then initialize t  endif
endfor
update v u  s    u  s   v l  s    l  s 
s    sample t according to p  s   u  s   t 
endwhile
while p not empty do
pop s from p
 acyclic  if  checksolved s     then break endif 
 cyclic  if  checksolved s    then break endif 
endwhile

figure    lrtdp for maxprob  atleastprob  and approxprob  on acyclic or general  cyclic  state
spaces   u is the current greedy policy on v u    l is the current greedy policy on v l  
the checksolved s    procedure is exactly as specified by bonet and geffner      b   it
visits states t reachable from s using  u   initializing t if not previously visited  stopping
at t if not  consistent  it then performs updates bottom up  labeling t as solved iff all its
descendants are  consistent  our only change is to update v l and  l along with v u
and  u  
p
l
where p  s   l  s   t       so in other words v   s   t p  s   l  s   t v l  t   by plugging in
the definition of  l  s   and by using the monotonicity property  it is now easy to conclude that
l
v   s   v l  s   as desired 
    lrtdp
figure   shows pseudo code for our goalprob lrtdp variant  applicable to the general case  cyclic
as well as acyclic problems   we assume that  in cyclic cases  the algorithm is run within the fret
framework  the main change to the original version of lrtdp consists in maintaining a lower
bound in addition to the upper  optimistic  bound  and adding the same early termination criteria as
in goalprob ao   correctness of early termination follows with the same arguments as before  i e  
v l  s  and v u  s  are monotone lower respectively upper bounds  and  l is always a closed policy 
note that this is true even in the general cyclic case  i e   if early termination applies  then we can
terminate the overall fret process 
the only other change we make is an additional stopping criterion for trials in the cyclic case 
namely if the current state s is  consistent  kolobov et al         use this criterion to keep trials
   

fig oal p robability a nalysis in p robabilistic p lanning

procedure goalprob dfhs
     i 
loop do
 early termination criteria exactly as in goalprob ao  
if  label and i is not labeled as solved 
or  vi and  u changed after running vi on the  u  greedy graph  then
dfhs exploration i 
clean visited markers
else return  u endif    regular termination   
endloop
procedure dfhs exploration s  
if s    then initialize s  endif
if s  s   s or s is labeled solved then
label s solved
return 
endif
f lag    
if fw then
if v u  s  is not  consistent then f lag      endif
update v u  s    u  s   v l  s   and  l  s 
if consist and f lag then return   endif
endif
mark s as visited
foreach t with p  s   u  s   t      do
if t has not been visited then f lag    dfhs exploration t   f lag endif
done
if f lag or fw then
if v u  s  is not  consistent then f lag      endif
update v u  s    u  s   v l  s   and  l  s 
endif
if label and f lag then label s solved endif
return f lag

figure    depth first heuristic search  dfhs  for acyclic maxprob  atleastprob  and approxprob  the cyclic version is shown in appendix a and uses tarjans scc procedure
instead of depth first search  vi  label  fw  and consist are boolean algorithm parameters  see text   recall that the  u  greedy graph is the set of states reachable from i using
the current greedy policy  u   the f lag returned by dfhs exploration is used inside the
recursion only  it is ignored in the top level calls   to decide whether to backward update
a state if forward updates are in use 

from getting trapped in   reward  non goal  cycles  the criterion preserves the property that  upon
regular termination  all states reachable using  u are  consistent  

in the cyclic case  the v u fixed point found by lrtdp may be sub optimal  so we have to use
fret  in the acyclic case  we use       and a single call to lrtdp suffices 
   

fis teinmetz   h offmann   b uffet

    depth first heuristic search
we finally consider systematic heuristic searches  not based on trials like lrtdp  with a strong
depth first orientation  intuitively  such an orientation is especially beneficial in our context as it is
likely to lead to absorbing states  and thus to states with a non trivial heuristic function initialization 
quickly  we refer to such algorithms as depth first heuristic search  dfhs   known instances are
ilao  hansen   zilberstein          heuristic dynamic programming  hdp   bonet   geffner 
    a   and learning depth first search  ldfs   bonet   geffner         their commonality lies in
conducting depth first searches  dfs  on the state space subgraph defined by actions greedy on a
current upper bound v u   which is being updated backwards in dfs  until a termination criterion applies  the algorithms differ in how depth first branches are terminated  how the overall algorithm is
terminated  and in whether or not updates are also performed in the forward direction  here  we systematize these parameters  obtaining a dfhs algorithm family containing the previous algorithms
as family members 
figure   gives a pseudo code description of our dfhs algorithm family  for simplicity  the
figure considers acyclic problems only  for cyclic problems  instead of dfs the algorithms use
tarjans depth first scc algorithm  tarjan         in order to detect the sccs at the same time
as doing the exploration and updates  as suggested by bonet and geffner      a    knowing the
sccs is required for correct solved labeling in the general case   the pseudo code description of
the dfhs algorithm family for the general  cyclic  case is given in appendix a 
the algorithms search in the  u  greedy graph  a variant would be to instead search the v u greedy graph  that variant  employed by ldfs  is not effective for goal probability analysis because
v u is   everywhere initially  and the v u  greedy graph is the entire  dead end pruned  reachable
state space  we hence omit this option  and therewith ldfs  from our dfhs family  matters may
change if better admissible heuristic functions are identified in future work  cf  section    
all algorithms update values in the backward direction  when leaving a state  if the fw algorithm
parameter is true  then value updates are done also in the forward direction  when entering a state 
as that consistently yields  small  advantages empirically  we switch fw to true in all our algorithm
configurations  except in the one corresponding to the known algorithm ilao which does not use
this technique  detecting whether the optimal solution has been found can be done in two ways     
label  maintaining solved labels while doing the dfs  or     vi  running value iteration on the  u greedy graph after dfs has terminated  in       u is optimal if the initial state is labeled solved  in
     one can terminate if the greedy policy did not change during vi  if we do use forward updates 
then  as we already check the bellman residual anyway  we have the additional option consist to
stop the search at  inconsistent states  as opposed to stopping only at absorbing states  overall  we
run   different parameter settings for dfhs  overviewed in table   
correctness of early termination follows again with the same arguments as before  for the
correctness of regular termination  we need to show that a fixed point policy is obtained  i e   upon
regular termination      the  u  greedy graph contains no  inconsistent states  this holds because
all our algorithm variants fit bonet and geffners      a  find and revise schema on a finite state
space with a monotone optimistic bound  where     in each search iteration we find and update at
   the updates during trials are  in difference to the original lrtdp formulation  not related to a trial stopping guarantee
in goal probability maximization  they just turn out to consistently yield  small  advantages empirically  so we keep
them in here 
   the brief description of ilao by hansen and zilberstein         and thus its depth first orientation  can be subject
to interpretation  our design here follows that of bonet and geffner        in their mgpt tool 

   

fig oal p robability a nalysis in p robabilistic p lanning

acronym
dfhsvi
dfhsfwd
vi
dfhsfwdcons
vi
dfhsfwd
lab
dfhsfwdcons
lab

termination
vi
vi
vi
label
label

fw 
no
yes
yes
yes
yes

cons 
no
no
yes
no
yes

known 
yes  ilao  hansen   zilberstein       
no  new variant
no  new variant
no  new variant
yes  hdp  bonet   geffner      a 


table    depth first heuristic search  dfhs  family overview  we do not include ldfs  bonet
  geffner        as  due to considering the v u  greedy graph rather than the  u  greedy
graph  ldfs does not work well on maxprob  see text  
least one  inconsistent state  until     condition     is met  given the depth first search  respectively
tarjans algorithm  in the general case  it is clear that     holds true  regarding      this is obvious
when the vi termination option is used   it holds for the label termination option because a state
is labeled solved only when all its descendant states in the  u  greedy graph are  consistent 
as done in table    we will usually omit the goalprob  in algorithm names  keep in mind
though that our algorithms differ from the original ones  in particular in terms of early termination
which depends on the objective maxprob  atleastprob  or approxprob  to study the termination
benefits of the lower vs  upper bound  we will switch each bound on and off individually  where
x denotes one of our search algorithms  we denote by x u and x l the variants of x maintaining
only v u respectively only v l   we will sometimes write x lu to make explicit that both bounds
are used  early termination criteria involving the non maintained bound are disabled  for x u   this
leaves just the negative criterion v u  i     in atleastprob  x l still has positive criteria 
we test a version x l only for x ao   as a canonical representative of  non vi  blind search 
in ao  l   all non absorbing leaf states in  are open  rather than only those reachable using  u   
and in case of regular termination we return  l  
    fret
as previously hinted  kolobov et al s        fret performs an iteration of complete searches  it
starts with some upper bound approximation v u of v    which is continuously updated throughout
the fret process  within each fret iteration  a heuristic search algorithm runs until termination 
i e   until finding a fixed point policy  in between these iterations  fret runs a trap elimination
step  which finds all traps in the v u  greedy graph  fret forces the next search iteration to not
include these traps  fret terminates if the v u  greedy graph does not contain a trap 
the trap elimination step works as follows  a trap is a subset t of non absorbing states in
which any greedy policy will remain indefinitely  i e   all outgoing transitions in the v u  greedy
graph of any s  t lead to another trap state t  t   a trap t is removed by collapsing t s states
into a single state st   the incoming transitions of st are those incoming to any state of t   and its
outgoing transitions are those transitions of t  states exiting t  note that these transitions are  by
construction  not contained in the v u  greedy graph  
this transformation obviously prevents t from occuring again in later iterations  it preserves

v as the trap states have identical v  values  as all trap states are non absorbing and can reach each
other  these states can reach each other with   reward transitions  note that this holds regardless of
   note that  in the acyclic case  full vi is not actually needed so the algorithm could be simplified  we leave it this way
here  as used by ilao in the general case  for simplicity of presentation 

   

fis teinmetz   h offmann   b uffet

v u   i e   it holds also on parts of the state space where v u has not yet converged   because there
is only a finite number of possible traps in the state space  fret eventually finds a v u whose v u greedy graph does not contain a trap  from that graph  a v u  greedy policy  is extracted  which
does not contain traps  hence is proper on the trap collapsed state space  hence is optimal for that
state space  an optimal policy for the original task can be constructed from  by acting  within
collapsed traps  in a way so that the exit taken by  is eventually reached with certainty   this is the
correctness argument given by kolobov        
our new variant of fret differs from the original version only in terms of the state space
subgraph considered  instead of the v u  greedy graph  we use the  u  greedy graph  i e   we consider
only the actions selected into the current greedy policy  cf  our discussion of dfhs above   we will
refer to this design as fret  u   and we will refer to kolobov et al s        design as fret v u  
it is easy to see that fret  u is still correct  the arguments above remain intact as stated 
fret v u potentially eliminates more traps in each iteration  and may hence require fewer iterations  yet not all these traps may actually need to be eliminated  we might eventually find an optimal
policy not entering them   and each trap elimination step may be much more costly  in particular 
in goal probability analysis  fret v u is typically ineffective because  similarly as discussed above
for dfhs  in the first fret step v u often is   almost everywhere  and the v u  greedy graph is
almost the entire reachable state space  as we shall see  fret  u clearly outperforms fret v u  

   state space reduction via determinized bisimulation
bisimulation is a known method to reduce state space size in mdps probabilistic planning  e g 
dean   givan         the idea essentially is to group equivalent sets of states together as block
states  and then solve the smaller mdp over these block states  here  we observe that this approach can be fruitfully combined with state of the art classical planning techniques  namely mergeand shrink heuristics  drager  finkbeiner    podelski        helmert  haslum  hoffmann    nissim         which allow to effectively compute a bisimulation over the determinized state space 
determinized bisimilar states are bisimilar in the probabilistic state space as well  so this identifies a practical special case of probabilistic bisimulation given a factored  strips like  problem
specification 
let us spell this out in a little more detail  given a task   with or without budget limit   a
probabilistic bisimulation for  is a partitioning p    b            bn   of s state set s so that  for
every bi and bj   every action a  and every s  t  bi   the following two properties are satisfied
 dean   givan        
 i  a is applicable in s iff a is applicable in t  and
p
p
 ii  if a is applicable in s and t  then oo a  sjokbj p o    oo a  tjokbj p o  
dean and givan show that an optimal solution to the bisimulation of an mdp induces an optimal
solution to the mdp itself  in other words  it suffices to work on the block states bi  
now  denote by det the all outcomes determinization of   e g  yoon et al         little
  thiebaux         with a separate action adet
for every a and o  o a   inheriting as preo
condition and os adds  deletes  and cost  a determinized bisimulation for  is a partitioning
p    b            bn   of s states so that  for every bi and bj   every determinized action adet
o  
and every s  t  bi   the following two properties are satisfied  milner        helmert et al         
det
 a  adet
o is applicable in s iff ao is applicable in t  and

   

fig oal p robability a nalysis in p robabilistic p lanning

det
det
 b  if adet
o is applicable in s and t  then sjao k  bj iff tjao k  bj  

it is easy to see that such  b            bn   also is a probabilistic bisimulation for   since an action
adet
o is applicable in a state s iff the corresponding action a of the original mdp is applicable in s 
 a  directly implies  i   from  b   we know that for every action a applicable to s  t  and for each
det
outcome o  o a   we have sjadet
o k  bj iff tjao k  bj   this obviously implies  ii   it is more
restrictive than needed as it insists on the subset of outcomes being the same on both sides  rather
than only their summed up probability being the same 
but how to compute a determinized bisimulation for   the nave solution is to build the state
space up front and then computing a determinized bisimulation on it  one can potentially do much
better though  by using merge and shrink with the widely employed shrinking strategies based on
bisimulation  nissim  hoffmann    helmert        katz  hoffmann    helmert        helmert
et al          in a nutshell  this algorithm framework constructs an abstraction by starting with a
collection of abstractions each considering a single state variable only  then iteratively merging
two abstractions  replacing them with their synchronized product  until only a single abstraction is
left  and shrinking abstractions to a bisimulation thereof in between every merging step  as we
shall see in the experiments  this often still incurs a prohibitive overhead  but it can be feasible  and
lead to substantial state space size reductions  in some cases  it results in tremendous performance
improvements 

   dead end pruning
we refer to states s where v   s       i e   the goal cannot be reached at all from s  as dead ends 
if one detects such s via some dead end detection technique  then one can treat s exactly like a lost
state s  except for setting  l  s      as we need to act on non absorbing states   this constitutes
a pruning method in itself  useful for any search algorithm  as the state space below s needs no
longer be explored  apart from this pruning itself  for the heuristic search algorithms  dead end
detection provides a non trivial initialization of v u   as we will initialize v u  s      instead of
v u  s      if we detected s to be a dead end  this more informed initial upper bound typically
leads to additional search reductions 
but how to detect dead ends  kolobov et al         employ sixthsense  kolobov et al         
which learns dead end detection rules by generalizing from information obtained using a classical planner  here we instead exploit the power of classical planning heuristic functions  readily
available in our fd implementation framework  run on the all outcomes determinization  this is
especially promising in limited budget planning  where we can use lower bounds on determinized
remaining cost to detect states with insufficient remaining budget  observe that this is natural and
effective using admissible remaining cost estimators  yet would be impractical using an actual classical planner  which would need to be optimal and thus prohibitively slow   in the unlimited budget
case  we can use any heuristic function able to detect dead ends  returning    which applies to
most known heuristics  indeed  merge and shrink heuristics have recently been shown to be extremely competitive dead end detectors  hoffmann  kissmann    torralba        
to make this concrete  consider a state s in a task   and denote as before by det the alloutcomes determinization of   let h be a classical planning heuristic function  if h guarantees
to return  only on dead ends  and h s     on det   then there exists no sequence of action
outcomes achieving the goal from s  so v   s       if  is a limited budget task  h is admissible 
and h s    b s   then we cannot achieve the goal from s within the budget  and thus also v   s      
   

fis teinmetz   h offmann   b uffet

we experiment with state of the art heuristic functions  namely  a  an admissible landmark
heuristic as per karpas and domshlak          b  lm cut  helmert   domshlak          c  several
variants of merge and shrink heuristics  and  d  hmax  bonet   geffner        as a simple and
canonical option   a  turned out to perform consistently worse than  b   so we will report only on
 b    d  
for limited budget planning  we also considered adopting the problem reformulation by domshlak and mirkis        for oversubscription planning  which reduces the budget b using landmarks
and in exchange allows traversing yet unused landmarks at a reduced cost during search  it turns
out  however  that pruning states whose reformulated budget is     is equivalent to the much simpler method pruning states whose heuristic  a  exceeds the  original not reformulated  remaining
budget  the added value of domshlak and mirkis reformulation thus lies  not in its pruning per se 
but in its compilation into a planning language and the resulting combinability with other heuristics 
we give full details in appendix b  to get an intuition why domshlak and mirkis reformulation
is  per se  equivalent to  a   assume for simplicity that l is a set of disjoint disjunctive action landmarks for the initial state  and assume that actions have unit costs  say we prune s if its reduced budget  b   s   is      the reduced initial budget is b     b l   the reduced costs allow applying member actions of yet non used landmarks at   cost  where the non used landmarks for a given search
path are those l  l not touched by the path  consider now some state s reached on path  a  denote
the non used landmarks by l    the cost saved on  a thanks to the reformulation is exactly that of the
used landmarks   l l     hence b   s    b     a  l l        b l    a   l l      b  a  l    
so s is pruned in the reformulation  b   s       iff b    a    l        iff b    a     l     the latter
condition  however  is exactly the pruning condition using the simple method  a  instead 

   node selection strategies
in all our algorithms  good anytime behavior on v l and or v u may translate into early termination 
we explore the potential of fostering this via     biasing the tie breaking in the selection of best
actions  u greedy with respect to v u   and     biasing  respectively  the outcome state sampling
during trials  lrtdp  and the choice of expanded leaf states  ao    to be precise regarding the
latter  as usual  we maintain state open flags in ao   true if a state has open descendants within
the  u  greedy graph  we select the leaf state to expand by going forward from i using  u   and if
an action has more than one open outcome state t  we select a t best according to the bias      note
that     is not as relevant in dfhs  which in every iteration of dfs explores all outcomes anyhow 
hence  in dfhs  we use only the  u tie breaking criteria     explained in what follows 
we experimented with a variety of strategies  in what follows  where a strategy specifies one
of     or     only  the other setting is as in the default strategy  that strategy corresponds to the
commonly used settings  it uses arbitrary tie breaking for      but in a fixed manner  changing
 u  s  only if some other action becomes strictly better in s  as suggested by bonet and geffner
     b  for lrtdp  there is no bias     on outcome states in ao  an open outcome state is selected
arbitrarily   bias     in lrtdp is by outcome probability  we also tried this most prob outcome
bias strategy in ao   where the most likely open outcome state is selected 
the h bias strategy prefers states with smaller h value  where the heuristic h is the same one
used for dead end pruning    specifically  for action selection tie breaking      from those actions
    we also experimented with a strategy using merge and shrink with determinized action costs set to the negated
logarithm of outcome probability  compare e g  jimenez  coles    smith         this is compelling in theory

   

fig oal p robability a nalysis in p robabilistic p lanning

p
u
a maximizing the optimistic expected
pgoal probability t p  s  a  t v  t   we select an a minimizing the expected heuristic value t p  s  a  t h t   the outcome state bias     is obtained by
 
renormalizing the weighed probabilities h t 
 p  s  a  t   so we prefer high probability outcomes
with small h value 
inspired by brtdp  mcmahan et al          we experiment with a gap bias strategy  biasing
u
l
search towards states with large
precisely  for     we break ties in favor of actions a
pv  v gaps 
maximizing the expected gap t p  s  a  t  v u  t v l  t    and for     we renormalize the weighed
probabilities  v u  t   v l  t    p  s  a  t  
inspired by common methods in classical planning  e g  hoffmann   nebel        helmert 
      richter   helmert         we experiment with a preferred actions strategy  which in    
u  s  to an action a participating in a delete relaxed determinized plan for s  if such
prefers to set p
a maximizing t p  s  a  t v u  t  exists 
ao  l is a special case  as we do not maintain an upper bound and thus there is no selection
    of actions  u greedy with respect to v u   we apply node selection strategies for     directly
to the set of  all  leaf states in the current search graph   the default strategy is depth first  the
rationale being to try to reach absorbing states quickly  the h bias strategy selects a deepest leaf
with minimal h value  the preferred actions strategy selects a deepest open leaf reachable using only
preferred actions  we furthermore experiment with a breadth first strategy  just for comparison 

   experiments
we implemented all the algorithms in fast downward  fd   helmert         and ran experiments
on an extensive suite of benchmarks    in our evaluation we first summarize the results for acyclic
benchmarks  where fret is not needed   and then the ones for cyclic benchmarks  where fret is
needed  
    experiments setup
we start with giving details of our implementation and describing the benchmark suite used for the
experiments 
      i mplementation
as our model pertains to goal directed mdps with a limited number of  explicitly listed  outcomes
per action  naturally we use ppddl  younes et al          rather than rddl  sanner        coles
et al          as the surface level language  fds pre processes were extended to handle ppddl 
and we added support for specifying a  numeric  budget limit 
given the fd implementation framework in contrast to previous works on optimal probabilistic
planning  we implemented all algorithms from scratch  for fret  we closely followed the original
implementation  up to details not specified by kolobov et al          based on personal communication with andrey kolobov   kolobovs original source code is not available anymore  which also
plays a role in our state of the art comparison  see next  
because  then  a bisimulation based heuristic corresponds to the exact goal probability of the best outcome sequence
from a state  yet  as already pointed out  computing such a heuristic is often infeasible 
    the source code is available in an online appendix  and can be downloaded at http   fai cs unisaarland de downloads fd prob tar bz 

   

fis teinmetz   h offmann   b uffet

given the scant prior work on optimal goal probability analysis  cf  section     the state of the art
is represented by topological vi  by lrtdp u with dead end pruning on acyclic problems  and by
fret v u using lrtdp u with dead end pruning on cyclic problems  all these configurations are
particular points in the space of configurations we explore  so the comparison to the state of the art
is part of our comparison across configurations  the only thing missing here is the particular form
of dead end detection  which was sixthsense in the only prior work  by kolobov et al          as
sixthsense is a complex method and advanced dead end pruning via heuristic functions is readily
available in our framework  we did not re implement sixthsense  our discussion of cyclic problems
in section     below includes a detailed comparison of our results with those by kolobov et al   on
ippc explodingblocks which is the only domain kolobov et al  considered 
note that providing quality guarantees is an important property in this study  for this reason 
and for the sake of clarity  we do not compare against unbounded suboptimal approaches  such
as using an algorithm with a discounted criterion or assigning large finite penalties to dead ends
 teichteil konigsbuch et al         kolobov et al         
furthermore  as atleastprob is a special case of mdp model checking  one may wonder how
probabilistic model checking tools  e g  prism  kwiatkowska et al       b   would fare on that
problem in planning benchmarks  we do not investigate that question here  which would entail a
translation from ppddl into a model checking language  which is non trivial and makes a direct
comparison  of algorithms taking different inputs  problematic  one may speculate that  given
their focus on blind searches  model checking tools are inferior to our heuristic search approaches
where those fare well  but that remains a question for future work 
      b enchmark s uite
our aim being to comprehensively explore the relevant problem space  we designed a broad suite
of benchmarks       instances in total  based on domains from the ippc  resource constrained
planning  and penetration testing  pentesting  
from the ippc  we selected those pddl domains in strips format  or with moderate nonstrips constructs easily compilable into strips  this resulted in    domains from ippc   
ippc    we selected the most recent benchmark suite for each of these 
for resource constrained planning  we adopted the nomystery  rovers  and tpp benchmarks
by nakhost et al          more precisely those suites with a single consumed resource  fuel  energy  money   which correspond to limited budget planning    we created probabilistic versions
by adding uncertainty about the underlying road map  akin to the canadian traveler scenario  each
road segment being present with a given probability  this is encoded through a separate  probabilistic  action attempting a segment for the first time   for simplicity  we set that probability to    
throughout 
for pentesting  the general objective is  using exploits  to compromise computers in a network  one after another  until specific targets are reached  or no action is available   we modified
the pomdp generator by sarraute  buffet  and hoffmann         which itself is based on a test scenario used at core security  http   www coresecurity com   to output ppddl encodings of
hoffmanns        attack asset mdp pentesting models  in these models  the network configura    to make the benchmarks feasible for optimal probabilistic planning  we had to reduce their size parameters  number
of locations etc   we scaled all parameters with the same number      chosen to get instances at the borderline of
feasibility for vi 

   

fig oal p robability a nalysis in p robabilistic p lanning

tion is known and fixed  and each exploit is callable once and succeeds  or fails  with some probability  the generator uses a network consisting of an exposed part  a sensitive part  and a user part 
it allows to scale the numbers h of hosts and e of exploits  sarraute et al s pomdp model and
solver  sarsop  see kurniawati  hsu    lee        which does not guarantee optimality  scale to
h      e         for our benchmarks  we fixed h   e for simplicity  and to obtain a number of
instances similar to the other benchmark domains   we scaled the instances from            without
budget limit  and from             with budget limit 
from each of the above benchmark tasks   except the pentesting ones for which we already
generated a separate limited budget version anyway   we obtained several limited budget benchmarks  as follows  we set outcome costs to   where not otherwise specified  we determined the
minimum budget  bmin   required to achieve non   goal probability  for the resource constrained
benchmarks  bmin is determined by the generator itself  as the minimum amount of resource required
to reach the goal in the deterministic domain version  for all other benchmarks  we ran fd with a
and lm cut on the all outcomes determinization of   if this failed  we skipped   otherwise we
read bmin off the cost of the optimal plan and created several limited budget tasks  c   differing in
their constrainedness level c  namely  following nakhost et al          we set the global budget b
in  c  to b    c  bmin   so that c is the factor by which the available budget exceeds the minimum
needed  to be able to reach the goal at all   we let c range in                         
for atleastprob  we let  range in                               is pointless   for approxprob 
we let  range in                               is pointless   on cyclic problems  the convergence
parameter  was set to          the same value as used by kolobov et al          all experiments
were run on a cluster of intel e       machines running at      ghz  with time memory cut offs
of    minutes   gb 
    acyclic planning
we consider first acyclic planning  this pertains to all budget limited benchmarks  to pentesting
with and without budget limit  as well as to ippc triangletireworld  moves can be made in only
one direction so the state space is acyclic   we consider the   objectives maxprob  atleastprob 
and approxprob  we run all    search algorithm variants  vi  ao   lrtdp    dfhs variants  with
subsets of bounds as applicable   each with up to   node selection strategies as explained  for deadend pruning  we run lm cut  as well as merge and shrink  m s  with the state of the art shrinking
strategies based on bisimulation and an abstraction size bound n   we show data for n    and
n      k  we also tried n     k    k     k  which resulted in similar behavior   we also run
variants without dead end pruning  we use the deterministic bisimulation  db  reduced state space
only for vi  once  and if  a bisimulation is successfully computed  the block state mdp is easily
solved by that simplest algorithm  given db  we do not require any dead end pruning because all
dead ends are already removed from the reduced state space 
overall  this yields     different possible algorithm configurations  we do not actually test all
these configurations  of course  as not all of them are interesting  or needed to make the essential
observations  we instead organize our experiment in terms of three parts         each focusing
on a particular issue of interest  consider table    which gives an overview of the configurations
considered in each experiment  the design of the experiments is as follows 
    for modeling solving the entire network  that is  with their domain dependent decomposition algorithm  al 
trading accuracy for performance  sarraute et al  scale up much further 

   

fis teinmetz   h offmann   b uffet

experiment

search algorithm


pruning

node selection

  configs



ao  u  
maxprob search   prun  vi  ao  l  
default
lrtdp 
 
dfhs 
u
u      all    
ing
vi on db
vi  ao  l  
ao  u  

atleastprob   approx  ao  lu  
lrtdp u  
   
lm cut
default
prob parameters
lrtdp lu  
hdp u  
hdp lu   vi on db
vi  ao  l  
ao  u  
all                

lrtdp u  
atleastprob   approx  ao  lu  
   
lm cut          and   respeclrtdp lu  
hdp u  
prob node selection
tively 
hdp lu   vi on db
   

  

  

  

table    overview of algorithms tested on acyclic problems  section      numbers in brackets give
the number of options where that number is not obvious  in     and      note that the total
number of configurations gets multiplied by   because atleastprob vs  approxprob result
in different algorithm configurations  using different termination criteria   hdp is the
member of our dfhs family  corresponding to bonet and geffners      a 
dfhsfwdcons
lab
hdp algorithm 
    we first evaluate different search algorithms and dead end pruning methods on maxprob  fixing
the node selection strategy to default 
we omit here all x lu variants  because  as explained earlier  for maxprob heuristic search 
maintaining v l is redundant  early termination is dominated by regular termination  
using the default node selection strategy makes sense here because node selection strategies
are relevant only for anytime performance  i e   early termination  this plays a minor role in
maxprob  whose only early termination possibility is the exceptional case where the initial state
lower bound becomes v l  i      
    we next fix the best performing dead end pruning method  and analyze search algorithm performance in atleastprob and approxprob as a function of the parameter  respectively  
we again fix the node selection strategy to default here  leaving their examination to experiment
    
    we finally let the node selection strategies range  keeping otherwise the setting of experiment
    
we will conclude our discussion with     additional data illustrating typical anytime behavior  each
part of the experiment is described in a separate sub section in what follows 
          s earch a lgorithms   p runing m ethods in m ax p rob
table   shows coverage data  i e   the number of benchmark tasks for which maxprob was solved
within the given time memory limits 
of the pruning methods  lm cut clearly stands out  for every search algorithm  it yields the
by far best overall coverage  m s has substantial advantages only in rectangletireworld and
nomystery b  note that  for n     overall coverage is worse than for using no pruning at
all  this is due to the prohibitive overhead  in some domains  of computing a bisimulation on the
determinized state space  and  having invested this effort  it pays off more to use the bisimulation
   

fig oal p robability a nalysis in p robabilistic p lanning

domain

 

triatire

  

blocksw b
boxworl b
drive b
elevator b
expbloc b
random b
rectire b
tirewor b
triatire b
zenotra b

  
  
  
  
  
  
  
  
  
  

nomystery b   
rovers b
  
tpp b
  
pentest b
pentest
p

  
  
   

domain

 

triatire

  

blocksw b
boxworl b
drive b
elevator b
expbloc b
random b
rectire b
tirewor b
triatire b
zenotra b

  
  
  
  
  
  
  
  
  
  

nomystery b   
rovers b
  
tpp b
  
pentest b
pentest
p

  
  
   

dfhsfwd
dfhsfwdcons
 u
dfhsfwd
vi  u
vi
lab  u
 lm m s
 lm m s
 lm m s

n 
n 
n 
ippc benchmarks
          
                   
          
ippc benchmarks with budget limit
                                                  
       
       
       
       
 
                                                  
                                                  
                                                  
                                                  
                                                  
                                                  
                                                  
                                                  
probabilistic resource constrained benchmarks with budget limit
                                                  
                                                  
                                                  
pentesting benchmarks
                                                  
       
       
       
       
 
                                                                   
dfhsvi  u
 lm m s
n 

hdp u
lm m s
n 
        
  
 
  
  
  
  
  
  
  
  

  
 
  
  
  
  
  
  
  
  

        
        
        
        
     
           

ao  l
ao  u
lrtdp u
hdp u
 lm m s
 lm m s
 lm m s
 lm m s
n 
n 
n 
n 
ippc benchmarks
       
                                           
ippc benchmarks with budget limit
                                                           
       
       
       
       
       
                                                           
                                                           
                                                           
                                                           
                                                           
                                                           
                                                           
                                                           
probabilistic resource constrained benchmarks with budget limit
                                                           
                                                           
                                                           
pentesting benchmarks
                                                           
       
       
       
       
       
                                                                               
vi
 lm m s
n 

  
 
  
  
  
  
  
  
  
  

vi
on
db
  
  
 
  
  
  
  
  
  
  
  
  
  
  
  
 
   

table    acyclic planning  maxprob coverage  number of tasks solved within time   memory
limits   best values  within each table  in boldface  top  dfhs variants  recall that hdp
is the dfhsfwdcons
member of our dfhs family  dfhsvi is ilao    bottom  remaining
lab
search algorithms  including also the overall best dfhs variant  domains  b modified
with budget limit     number of instances    no pruning  else pruning  against
remaining budget on  b domains  based on h    on other domains  lm  lm cut 
m s  merge and shrink  n  size bound n      k   no size bound  vi on db 
vi run on reduced  deterministic bisimulated  state space  default node selection 

   

fis teinmetz   h offmann   b uffet

   

   

   

   

lrtdp u  lm cut 

lrtdp u

as a reduced mdp state space  vi on db   rather than only for dead end pruning  an extreme
example of the latter is triangletireworld  far beyond the standard benchmarks in table    triangleside length      vi on db scales to side length    in both the original domain and the limited budget
version  for comparison  the hitherto best solver by far was prob prp  camacho et al          which
scales to side length    on the original domain  and is optimal only for goal probability    i e   in the
presence of strong cyclic plans  which holds for the original domain but not for the limited budget
version   we could not actually run prob prp on the limited budget domain version  as prob prp
does not natively support a budget  and hard coding the budget into ppddl resulted in encodings
too large to pre process  
comparing the different dfhs u variants  there is no configuration that clearly stands out 
overall  they all perform equally well  though the fwdcons variants  cutting off the exploration at
 inconsistent states rather than absorbing states  have a slight edge  this difference mainly comes
from triangletireworld  explodingblocks  and tpp b  where the fwdcons configurations solve more
instances  while in zenotravel b the fwdcons configurations perform slightly worse than their counterparts  the termination parameter  vi vs  label  has almost no effect on coverage  due to the
gives the best coverage results 
similarity of the dfhs configurations  and because dfhsfwdcons
lab
as
the
representative
of
the
dfhs
family
in
the remaining discussion  as
we will use dfhsfwdcons
lab
fwdcons
corresponds to hdp  for simplicity we will from now on refer to it by that name 
dfhslab
ao  l is better than vi only in case of early termination on v l      when a full certainty
policy is found before visiting the entire state space  this happens very rarely here  and ao  l is
dominated by vi  this changes for atleastprob  see figures  a and   below   all failures of vi are
due to memory or runtime exhaustion while building the reachable state space  lrtdp u clearly
outperforms ao  u   presumably because it tends to find absorbing states more quickly  lrtdp u
and hdp u are about on par  with lm cut they solve the exact same number of instances  though
not exactly the same instances   and otherwise hdp u solves slightly fewer tasks than lrtdp u  
to gauge the efficiency of heuristic search vs  blind search on maxprob  compare lrtdp u vs 
vi in table    contrary to the intuition that a good initial goal probability estimator is required for
heuristic search to be useful  lrtdp u is clearly superior  its advantage does grow with the quality
of the initialization  lm cut yields the largest coverage increase by far  however  even without
dead end pruning  i e   with the trivial initialization of v u   lrtdp u dominates vi throughout  and
improves coverage in   of the    domains 

   
   
   

   
   
   

   
     
  

   

   

   

   
vi

   

   

     
  

   

   

   

   
   
vi  lm cut 

   

   

figure    acyclic planning  number of states visited  for vi  x  vs  lrtdp u  y   with no pruning
 left  respectively lm cut pruning  right   default node selection 
we next shed additional light on this by comparing search space sizes and runtime values 
tables   and   provide aggregate data  figure   gives a scatter plot for the canonical comparison
   

fig oal p robability a nalysis in p robabilistic p lanning

ao  u
lrtdp u
lm
m s

lm
m s
n

n

ippc benchmarks
                       
               
               
               
               
ippc benchmarks with budget limit
                
                               
               
           
 
         
 
            
 
               
               
   k                                                     
   k                                        
           
   k                 k             
               
               
             
   k                                                  
   k                 k             
                                                  
                                          
 
 
   k                  
 
 
                   
   k                      k                   k               
   k                      k                  
                                                              
                 
                                               
probabilistic resource constrained benchmarks with budget limit
   k                k                k            
    k                     k                
   k                                                         
   k                      k                   k               
   k                      k          k      
   k                      
                                 
   k                     k                     k                 
pentesting benchmarks
                                                  
                                                                     
                                                           
                                                                       


domain

 

triatire
only h

 
 

blocksw b
  
drive b
  
elevator b
  
expbloc b
  
non trivial  
only h
 
random b
  
non trivial  
only h
 
rectire b
  
non trivial   
triatire b
  
non trivial  
only h
 
zenotra b
  
non trivial   
nomystery b   
only h
 
rovers b
  
non trivial   
only h
 
tpp b
 
non trivial  
pentest b
  
non trivial  
pentest
 
non trivial  

vi
lm
m s
n






hdp u
lm
m s
n


               
                       
                
             
               
                  
                   
   k             
               
                
   k             
    
         
                
               
   k               
   k                  
                    
                     
   k            
    k                
                    
   k                 
   k                
                    
   k           
  
                
                       
                   
                       

table    acyclic planning  maxprob geometric mean search space size  number of states visited  in
multiples of         gives the size of the instance basis  namely those instances solved
by all shown configurations  skipping instances solved in under   second by all configurations  non trivial uses only those instances not solved by vi in     second 
only h uses those instances commonly solved by ao  u   lrtdp u   and hdp u   but
not solved by vi  rows with empty instance basis are skipped  default node selection 
between vi and lrtdp u   data for ao  l is not shown as its coverage is dominated by vi  cf 
table     and the same goes for its runtime and search space  we include the non trivial rows
in the tables to show behavior on the more interesting instances  where the averages are not skewed
by the many very small instances in most domains  we include the only h rows to elucidate the
behavior on the most challenging instances beyond reach of vi 
a clear message from table   and figure   is that the heuristic search algorithms  apart from
a few exceptions  visit much fewer states than vi does  even with trivial upper bound initialization where search spaces are reduced in all domains except rectangletireworld and pentest  for
instance  using lrtdp u instead of vi results in a gain of around   order of magnitude in many
instances  and larger gains  up to   orders of magnitude  also occur in rare cases  by giving the
heuristic search algorithms additional information through earlier dead end detection  the differences become even larger 
   

fis teinmetz   h offmann   b uffet

domain

 

triatire
only h

 
 

blocksw b
  
drive b
  
elevator b
  
expbloc b
  
non trivial  
only h
 
random b
  
non trivial  
only h
 
rectire b
  
non trivial   
triatire b
  
non trivial  
only h
 
zenotra b
  
non trivial   
nomystery b   
only h
 
rovers b
  
non trivial   
only h
 
tpp b
 
non trivial  
pentest b
  
non trivial  
pentest
 
non trivial  

ao  u
lrtdp u
hdp u
lm m s
 lm m s
 lm m s
n

n

n

ippc benchmarks
           
 
 
         
     
 
           
                               
                  
ippc benchmarks with budget limit
               
       
                     
       
     
            
       
      
              
              
               
 
         
           
           
            
   
    
                  
   
          
                  
                
               
               
                                                        
               
                               
               
                   
                                 
                 
                                                           
              
                                                      
                                                                          
                
                                
               
                
            
      
                          
                                      
               
          
 
                
                    
          
                                                                              
probabilistic resource constrained benchmarks with budget limit
                                                                    
                                                      
               
                       
                             
                                                                            
                                                                
                 
                                   
                 
                                                                            
pentesting benchmarks
            
   
          
            
   
          
                 
               
                  
                
               
                   
         
               
   
          
                
                 
                  
vi
 lm m s
n 



table    acyclic planning  maxprob geometric mean runtime  in cpu seconds   same setup and
presentation as in table   
as previously hinted  these observations have not been made in this clarity before  while
kolobov et al         also report lrtdp to beat vi on maxprob  they consider only a single domain  they do not experiment with trivially initialized v u   and they do not use dead end pruning in
vi  so that lrtdp already benefits from a smaller state space  and the impact of heuristic search
remains unclear 
even though the search space of the heuristic search algorithms is in many cases only a small
fraction of the whole  dead end pruned  state space  this is not necessarily reflected in runtime 
on those instances solved by vi  it is typically fast  often faster than heuristic search and rarely
outperformed significantly  this is despite having larger search spaces  i e   heuristic search does
visit less states but suffers from having to do more updates on these  recall that vi here updates each
visited state exactly once   significant runtime advantages over vi  in the non trvial rows 
are obtained by heuristic search only in explodingblocksb  randomb  and triangletireworldb 
comparing the heuristic search algorithms  the conclusions are more fine grained but overall
similar to what we concluded from coverage above  lrtdp u dominates ao  u almost throughout 
note that  even though the search space size of ao  u and lrtdp u almost always is similar  ao  u
requires a lot more time than lrtdp u   this is because it performs more updates  across the nontrivial commonly solved instances in the tables  the geometric mean of the number of updates done
   

fig oal p robability a nalysis in p robabilistic p lanning

in ao  u is about   times higher than that in lrtdp u   lrtdp u and hdp u with non trivial
value initialization give very similar results  not only in terms of coverage  but also in terms of
runtime and search space size  lrtdp u is  however  more effective in some of the domains  e g  
rectangletireworld and zenotravel  if no additional dead end detection method is used  on the
other hand  hdp u has a slight edge in the probabilistic resource constrained domains  one notable
case where lrtdp u consistently outperforms hdp u is triangletireworld 
the impact of dead end pruning on vi is typically moderate  the gains for heuristic search are
much more pronounced  thanks to the stronger heuristic function initialization  especially ao  u
benefits a lot  lrtdp u and hdp u benefit as well  but to a smaller extent  partly because they
are already more effective in the first place  comparing across different dead end pruning methods 
although m s with n    clearly yields the largest search space reductions  and necessarily so as
it recognizes all dead ends  the overhead of bisimulation computation outweighs the search space
reduction in all but a few cases  in terms of pruning power  m s with n      k and the lm cut
heuristic are overall roughly similar  yet lm cut has the edge in runtime 
          at l east p rob and a pprox p rob parameter a nalysis
we now turn to the weaker objectives  atleastprob and approxprob  we fix lm cut for the  almost
always most effective  dead end pruning  we examine the power of early termination for different
search algorithms and node selection strategies  this is best viewed as a function of the goal probability threshold  in atleastprob  and of the desired goal probability accuracy  in approxprob  vi
forms a baseline independent of      consider figure   
vi
lrtdp u

   

vi

lrtdp lu

ao  lu

hdp u

hdp lu

   

   
   
  solved instances

  solved instances

   

ao  l

ao  u

   
   
   
   
   

ao  l

ao  u

lrtdp lu

ao  lu

hdp u

hdp lu

   
   
   
   
   
   

   

   

   

   
                                     


lrtdp u

                                     


 a 
 b 
figure    acyclic planning  total coverage for atleastprob as a function of  in  a   for approxprob as a function of  in  b   all configurations use default node selection and lm cut
dead end pruning 
for atleastprob  figure  a   in the interesting region of benchmark instances not feasible for
vi yet sometimes feasible for the other search algorithms  one clear feature is the superiority of
lrtdp over both ao and hdp  as one can see for the smaller values of   lrtdp is able to
update v l much more effectively than hdp  resulting in a larger coverage of lrtdp in the region
   

fis teinmetz   h offmann   b uffet

of smaller  values  ao  l exhibits strikingly strong behavior for small values of   approaching
 and in one case  surpassing  the performance of lrtdp u   evidently  the depth first expansion
strategy is quite effective for anytime behavior on v l and thus for termination via v l  i     it
is way more effective than the heuristic search in ao  lu   as we shall see below  figure     it is
often also more effective than lrtdp  in general  for all algorithms  using v l is a clear advantage
for small   for larger   maintaining v l can become a burden  yet v u is of advantage due to early
termination on v u  i      algorithms using both bounds exhibit an easy hard easy pattern 
the spike at the left hand side in figure    a   i e   significantly worse performance for       
than for         is an outlier due to the pentest domains  without these domains  ao  lu  
lrtdp lu and hdp lu exhibit a strict easy hard easy pattern  this is because  in contrast to typical probabilistic planning scenarios  in penetration testing the goal probability  the chance of a
successful attack  are typically small  and indeed this is so in our benchmarks  searches using an
upper bound quickly obtain v u  i         terminating early based on v u  i     for         but
it takes a long time to obtain v u  i        
for approxprob  figure  b   smaller values of  consistently result in worse performance  we
see again the superiority of lrtdp over ao and hdp  and the  relatively  compared to ao  lu  
strong behavior of ao  l in  regions allowing aggressive early termination  again  the key to
lrtdp beating hdp so clearly is due to lrtdp updating v l much more effectively  hdp lu can
only improve on hdp u by a small margin  nonetheless  we see again the superiority of algorithms
using both bounds over those that dont 
          n ode s election s trategies
figure   shows different node selection strategies in atleastprob  the relative performance of node
selection strategies is the same in approxprob  so we do not include a separate figure for that  
lrtdp lu  def 
ao  l  bfs 

   

  solved instances

   

ao  lu  def 
ao  lu  h 

ao  l  dfs 
ao  l  h 

ao  lu  o prob 
hdp lu  def 

vi

   
   
   
   
   
   
   
   
                                     


figure    acyclic planning  total coverage for atleastprob as a function of   varying the node
selection strategy  all configurations use lm cut dead end pruning 
for readability  we show only the most competitive base algorithms  ao  l   ao  lu   lrtdp lu  
and hdp lu  as well as the vi baseline   for lrtdp and hdp  we show only default node selection  which consistently works basically as well as the alternatives  for ao  l   we see that the
   

fig oal p robability a nalysis in p robabilistic p lanning

depth first strategy is important  and way beyond breadth first  which does worse than vi   the
h bias strategy is marginally  but consistently  better than depth first  for ao  lu   both the h bias
and the most prob outcome bias are helpful  substantially improving over the default strategy  the
h bias consistently improves a bit on default ao   the gap bias and preferred actions strategies
are not shown as they were consistently slightly worse  apparently  the gap bias leads to a more
breadth first style behavior  while preferred actions mainly cause runtime overhead  
          a n i llustration of t ypical a nytime b ehavior
to conclude our discussion of acyclic planning  figure   exemplifies typical anytime behavior  i e  
the development of the v l  i  and v u  i  bounds on the initial state value  as a function of runtime 
for lrtdp lu and ao  l  
 

lrtdp v u lm cut

lrtdp v l

lrtdp v l lm cut

ao  

ao  

l

 

l lm cut

   
probability

probability

   

lrtdp v u

   
   
   

   
   
   

 

 
 

   

   
   
time  s 

   

   

 

   

 a 

lrtdp v u

lrtdp v u lm cut

lrtdp v l

lrtdp v l lm cut

ao  l

ao  l lm cut

   
   
time  s 

   

   

 b 

figure    acyclic planning  anytime behavior in lrtdp lu  v and v l   and ao  l  v l only  
as a function of runtime  elevators instance     without pruning and with lm cut pruning 
for constrainedness level c        a  respectively c        b   default node selection 
u

the benefit of lm cut pruning is evident  observe that ao  l is way more effective than
lrtdp in quickly improving the lower bound  indeed  the runs shown here find an optimal policy
very quickly  across the benchmarks solved by both ao  l and lrtdp  omitting those where both
took     second  in     of cases ao  l finds an optimal policy faster than lrtdp  on  geometric  average  ao  l takes     of the time taken by lrtdp for this purpose  on the downside 
unless v   i     ao  l must explore the entire state space  its runs in figure   exhaust memory
for maxprob  in summary  heuristic search is much stronger in proving that the maximum goal
probability is found  but is often distracting for improving v l quickly 
as both parts of figure   use the same base instance but with different constrainedness levels c 
we can also draw conclusions on the effect of surplus budget  with more budget  more actions can
be applied before reaching absorbing states  this adversely affects the upper bound  consistently
across our experiments   which takes a much longer time to decrease  the lower bound  on the other
hand  often increases more quickly with higher c as it is easier to find goal states 
   

fis teinmetz   h offmann   b uffet

    cyclic planning with fret
we now consider cyclic planning  pertaining to the standard ippc benchmarks  and to probabilistic
nomystery  rovers  tpp without budget  nor resource   limit  we run only lrtdp and dfhs  as
ao is restricted to acyclic state spaces  we use the two different variants of fret described earlier 
fret v u as per kolobov et al          and our new variant fret  u   we consider all   objectives 
and the same   dead end pruning methods  as lm cut returns  iff the cheaper heuristic hmax does 
we use hmax here   we do not vary node selection strategies because  like we have seen before  in
lrtdp and dfhs these do not bring a notable advantage over the default strategy  we use the
deterministic bisimulation  db  reduced state space with each base algorithm  as some differences
do emerge  in difference to the acyclic case  between vi and the other algorithms  which now need
to run fret  again  given db we do not require any dead end pruning 
overall  this yields     different possible algorithm configurations  as before  not all of these
are interesting  and we instead organize our experiment in terms of parts focusing on issues of
interest  specifically  we have parts     on maxprob and     on atleastprob approxprob as before 
as node selection strategies are not relevant here  we do not have the previous part     considering
these  we integrate data illustrating anytime behavior with our discussion of      table   gives an
overview of tested configurations 
experiment
fret variant
search algorithm
pruning
  configs
maxprob search   prun   
  
  fret v u   fret  u vi  lrtdp u   dfhs     all      db
ing
   

vi 
atleastprob   approxu
u lrtdp   
 
fret v
 
fret 
lu
prob parameters
hdp lu

lrtdp u  
hdp u  

hmax

  

table    overview of algorithms tested on cyclic problems  section      note that vi does not require  and is hence not combined with  fret  we denote this  not using fret at all  by 
  in      note that the number of configurations gets multiplied by   because atleastprob
vs  approxprob result in different algorithm configurations  using different termination
criteria   all configurations tested use default node selection 
          s earch a lgorithms   p runing m ethods in m ax p rob
table   shows coverage data  as before  the dfhs family is shown at the top  and the remaining
search algorithms  including the most competitive dfhs algorithm which as before is hdp  are
shown at the bottom  we do not vary the fret variant at the top for space reasons  and as  for
fret v u   there were no coverage differences at all across dfhs family members 
similarly as in the acyclic case  the dfhs configurations stopping exploration at  inconsistent
states give slightly better results than those stopping only at absorbing states  the termination
parameter has almost no effect on coverage  hdp  i e   dfhsfwdcons
  solves one more task in
lab
explodingblocks than dfhsfwdcons
 
but
otherwise
the
coverage
is
the
same  also akin to the
vi
acyclic case  both lrtdp and hdp perform equally well  though now hdp has a slight edge in
combination with fret  u  
running the search on a deterministic bismulation state space is less effective on the cyclic
benchmarks than on the acyclic ones  it gives a clear advantage only in rovers 
   

fig oal p robability a nalysis in p robabilistic p lanning


domain

 

blocksworld
boxworld
drive
elevators
explodingblocks
random
rectangletireworld
tireworld
zenotravel
nomystery
rovers
tpp
p

domain
blocksworld
boxworld
drive
elevators
explodingblocks
random
rectangletireworld
tireworld
zenotravel
nomystery
rovers
tpp
p

    
    
    
     
    
    
     
     
    
    
    
    
      

 

fret  u
dfhsvi  u
dfhsfwdcons
 u
dfhsfwd
hdp u
vi
lab  u
hmax m s on 
on  hmax m s on  hmax m s on  hmax m s
n  bs
n  bs
n  bs
n  bs
n 
ippc benchmarks
         
         
         
         
     
         
         
         
         
     
                                                           
                                                           
                                                  
         
         
         
         
     
                                                                    
                                                                    
         
         
         
         
     
probabilistic resource constrained benchmarks
         
         
         
         
     
         
         
         
         
     
         
         
         
         
     
                                                                         
dfhsfwd
vi  u
hmax m s

 
 
  
  
 
 
  
  
 

 
 
  
  
 
 
  
  
 

 
 
  
  
 
 
  
  
 

    
    
    
      

 
 
 
  

 
 
 
  

  
  
  
  
  
  
  
  
  

fret v u
fret  u
lrtdp u
hdp u
lrtdp u
hdp u
 hmax m s on  hmax m s on  hmax m s on  hmax m s
n  db
n  db
n  db
n 
ippc benchmarks
     
         
         
         
     
     
         
         
         
     
                                                     
                                                     
     
         
                           
     
         
         
         
     
                                                              
                                                              
     
         
         
         
     
probabilistic resource constrained benchmarks
     
         
         
         
     
     
         
         
         
     
     
         
         
         
     
                                                                

vi
 hmax m s on
n  db

on
bs
 
 
 
 
 
 
  
  
 
 
 
 
  

on
db
 
 
 
 
 
 
  
  
 
 
 
 
  

table    cyclic planning  maxprob coverage  best values  within each table  in boldface  fretv u is as per kolobov et al          fret  u is our modified version  top  dfhs variants
member of our dfhs family  dfhsvi is ilao   
 recall that hdp is the dfhsfwdcons
lab
showing only the dominating fret version  fret  u   bottom  remaining search algorithms  varying the fret version  and including also the overall best dfhs variant 
dead end pruning variants   none  else based on heuristic value   for hmax respectively merge and shrink  n  size bound n      k   no size bound   on db  run
on reduced  deterministic bisimulated  state space  default node selection 
the most striking result here by far is that fret  u outperforms both vi and fret v u substantially  note that  in all domains except explodingblocks and rovers  the advantage over vi is
obtained even without dead end pruning  i e   for trivial initialization of v u   this strongly confirms
the power of heuristic search even in the absence of good admissible goal probability estimators 
as before  we shed additional light on the coverage results through search space size and runtime
data  figure   compares the search space sizes for vi vs  fret  u   the non trivial initialization
using hmax is useful  but gains of up to   orders of magnitude are possible even without it 
table   provides aggregate search space size and runtime data  no data is shown for the configuration using fret v u with hdp  as that data is almost identical to that of fret v u with lrtdp 
   

fi   

   

   

   
fret  u  hmax  

fret  u

s teinmetz   h offmann   b uffet

   
   
   

   
   
   
   

   
     
  

   

   

   
vi

   

   

     
  

   

   

   

   
   
vi  hmax  

   

   

figure    cyclic planning  number of states visited  for vi  x  vs  fret  u using lrtdp u  y  
with no pruning  left  respectively hmax pruning  right  
fret v u
fret  u
lrtdp u
lrtdp u
m s
 hmax
m s
 hmax
m s

n

n

n

ippc benchmarks
   
   
     
   
   
   
   
     
   
      
 
          
 
          
 
   
   
 
     
   
 
     
   
 
                                 
           
   
                                    
                  
   
   
   
     
        
   
   
        
   
 
       
   
 
      
   
        
  
  
                 
 
          
 
                            
 
          
 
          
                 
   
              
   
probabilistic resource constrained benchmarks
                                                             
                                 
   
   
   
   
   
                                                          
                                                          
ippc benchmarks
   
   
       
   
   
   
   
   
   
   
   
   
       
   
   
   
   
   
   
   
   
   
       
   
   
   
   
   
   
   
                                     
   
           
   k          k         k           
         
         
 
 
       
 
 
   
   
 
 
   
 
 
     
 
 
     
 
 
 
   k    k    k                  
   
   
   
   
   
   k    k    k    k    k    k
   
   
   
   
   
                                   
   
   
   
   
   
probabilistic resource constrained benchmarks
   k    k    k    k    k    k                          
   k    k    k    k    k    k                         
   k    k    k    k    k    k                           
   k    k    k    k    k    k                              

vi
 hmax
domain

 

blocksworld
drive
elevators
explodingblocks
non trivial
rectangletireworld
non trivial
tireworld
non trivial
zenotravel

 
 
 
 
 
 
 
 
 
 

 
 
 
   
    
   
   
   
  
    

 
 
 
   
   
 
   
    
    
    

nomystery
rovers
tpp
non trivial

 
 
 
 

    
    
    
    

    
    
    
    

blocksworld
drive
elevators
explodingblocks
non trivial
rectangletireworld
non trivial
tireworld
non trivial
zenotravel

 
   
   
 
   
   
 
   
   
            
     k      
 
   
   
 
 
   
     k    k
     k    k
             

nomystery
rovers
tpp
non trivial

 
 
 
 

   k
   k
   k
   k

   k
   k
   k
   k

hdp u
hmax
m s
n

   
   
   
          
     
   
           
            
   
   
   
   
   
   
          
          
   
        
                 
   
   
   
              
                
   
   
   
   
   
   
   
  
         
   
 
   
 
   
   
   
   
   
   

   
   
   
   
   
 
 
   
   
   

                 
              
              
                 

table    cyclic planning  top  maxprob geometric mean runtime  in cpu seconds   bottom 
maxprob geometric mean search space size  number of states visited  in multiples of      
similar setup and presentation as in table      gives the size of the instance basis  the
default are commonly solved instances  skipping trivial ones  non trivial uses only
those instances not solved by vi in     second   only h not shown  see text  

   

fig oal p robability a nalysis in p robabilistic p lanning

the search space sizes are exactly the same  and runtimes differ only by a few seconds  in difference
to tables   and    we do not include only h rows  because this would not be interesting here 
fret v u hardly solves more instances than vi  so would have to be excluded from these rows  but
then  the data would compare only lrtdp vs  hdp  which perform very similarly anyway 
most striking in table   is the consistency with which  and the extent by which  fret  u visits
less states than its competitors  for both lrtdp and hdp   this advantage typically yields better
runtimes as well  with the notable exception of nomystery  where the larger number of fret iterations results in a substantial slow down  despite the much smaller search space  while fret v u
with lrtdp only requires    fret iterations on average  in the nomystery instances commonly
solved with fret  u and lrtdp  the latter configuration requires over       iterations on average  similarly when using hdp 
the impact of dead end pruning is notably smaller than in the acyclic case  search spaces are
reduced substantially in only a single domain  explodingblocks  in the other domains  there either
is no reduction  or a minor moderate one only 
vi  kolobov 
vi
vi  hmax  
fret v u  kolobov 
fret v u  hmax  
fret  u  hmax  

   
   

   

time  s 

states visited

   

   

   

   
   
   

   
 

 

 
 
problem  

 

   

 

 

 

 
 
problem  

 

 

 a 
 b 
figure    cyclic planning  results on explodingblocks  as shown by kolobov et al          fret
vs vi   a  number of states visited   b  runtime in cpu seconds  as a function of the
ippc instance index  different variants included for comparison  the data for kolobov
et al  is taken from their paper  as this code is not available anymore   hence the runtime
comparison is modulo the different computational platforms  and should be treated with
care  all shown fret configurations use lrtdp u   with default node selection 
explodingblocks also happens to be the single domain kolobov et al         experimented with 
figure   provides a detailed comparison to kolobov et al s data  which is the only state of the art
measure provided by previous work  we use here the exact runtime search space size data reported
by kolobov et al   recall that their source code is not available anymore 
kolobov et al         ran vi with no pruning vs  fret v u using lrtdp with pruning based
on sixthsense  kolobov et al          they observed a coverage of   for the former and of   for
the latter  identical with our results for vi  vs  fret v u using lrtdp with hmax   to give more
   

fis teinmetz   h offmann   b uffet

detail  figure   shows the number of states visited  and the total runtime  in terms of plots over ippc
instance index as done by kolobov et al        
consider first figure    a   the search space size  the only difference between vi  kolobov  and
our vi here is the different task state representation resulting from the respective implementation
framework  the fd framework being somewhat more effective  the substantially better performance
of vi with hmax dead end pruning shows that the omission of kolobov et al s        study  using
dead end pruning in fret but not in vi  indeed obfuscates the possible conclusions regarding the
effect of heuristic search vs  the effect of the state pruning itself  with hmax pruning  vi is almost
as effective as fret v u using the same pruning  kolobov et al s fret v u also is very close to
this  except for exploring significantly less states in the large instances  the latter shows  especially
given the more effective representation in fd  that sixthsense is a stronger dead end detector here
than hmax   that is hardly surprising  considering the information sources in sixthsense  outcomes
of  determinized  classical planning for guidance  and h   graphplan  based validity tests 
on the other hand  sixthsenses information sources are much more time intensive than hmax  
which presumably is the reason for the runtime picture in figure    b   the latter is qualitatively
very similar to  a   except that fret v u  kolobov  is significantly worse  rather than better  on the
largest instance  this last conclusion should be taken with a grain of salt though  given the different
computational environments 
certainly  given the clarity of fret  u s advantage in both search space size and runtime  one
can conclude that this variant of fret substantially improves over the previous state of the art 
          at l east p rob and a pprox p rob parameter a nalysis
for the weaker objectives atleastprob and approxprob  as before we examine coverage as a function of  respectively   figure    shows the data 
for fret v u   the behavior in figure    is similar to that for the acyclic case in figure    in
particular  when maintaining both an upper and a lower bound  fret v u exhibits an easy hardeasy pattern due to the advantages of early termination 
for fret  u   though  the curves are flat over   and the only observation is a small advantage
of using v l in addition to v u   this is due to the scaling of benchmarks  combined with an extreme
performance loss at some point in the scaling  in each domain  there is an instance number x so
that  below x  fret  u can solve all instances completely  i e   solving maxprob   while above x
neither v l  i  nor v u  i  can be improved at all  remaining   respectively   up to the time memory
limit  on smaller instances  we do get the expected anytime behavior  figure    exemplifies this 
the easy hard easy pattern would thus emerge for smaller runtime memory limits   

   conclusion
optimal goal probability analysis in probabilistic planning is a notoriously hard problem  to the
extent that the amount of work addressing it is limited  our investigation contributes a comprehensive design space of known and adapted algorithms addressing this problem  designing several new
algorithm variants along the way  and establishing an fd implementation basis supporting the tight
integration of mdp heuristic search with classical planning techniques  our experiments clarify the
    figure     b  considers the largest instance feasible when using hmax pruning  figure     a  considers the secondlargest instance feasible without pruning  on the largest one feasible without pruning  namely instance     the maximum goal probability is   so the anytime curve for v u is not interesting 

   

fig oal p robability a nalysis in p robabilistic p lanning

fret v u lrtdp u

fret  u lrtdp u

fret v u lrtdp u

fret  u lrtdp u

fret v u lrtdp lu
fret v u hdp u
fret v u hdp lu
vi

fret  u lrtdp lu
fret  u hdp u
fret  u hdp lu

fret v u lrtdp lu
fret v u hdp u
fret v u hdp lu
vi

fret  u lrtdp lu
fret  u hdp u
fret  u hdp lu

   
  solved instances

  solved instances

   

   

  

   

  

                                     


                                     


 a 

 b 

 

 

   

   
probability

probability

figure     cyclic planning  total coverage for atleastprob as a function of  in  a   for approxprob as a function of  in  b   all configurations use default node selection and hmax
dead end pruning 

   
   

   
   

   

   

 

 
 

  

  
time  s 

 

  

 a 

   

   
   
time  s 

   

 b 
fret  u

figure     cyclic planning  anytime behavior of
with lrtdp lu and hdp lu   with
default node selection   a  without pruning for explodingblocks instance     and  b 
with hmax pruning for instance    
empirical state of the art  and exhibit substantial improvements thanks to new techniques and technique combinations  they furthermore showcase the opportunities arising from naturally acyclic
problems  and from early termination on criteria weaker than maximum goal probability 
we hope that these encouraging results and new implementation basis will inspire renewed
interest and research in this important problem  there are many promising future directions  of
which we would like to emphasize 
 advanced admissible goal probability estimators  these could be obtained  e g  from abstractions interpreted as bounded parameter mdps  givan  leach    dean         a promis   

fis teinmetz   h offmann   b uffet

ing approach is to extend state of the art classical planning abstraction techniques  pattern
databases  edelkamp        haslum  botea  helmert  bonet    koenig         merge andshrink  helmert et al          cartesian abstractions  seipp   helmert               to the
probabilistic setting 
 hybrids of heuristic search with monte carlo tree search  this appears a promising option
to improve anytime behavior  with respect to the upper and or lower bound  and thus foster
early termination  inspiration could be taken here from existing such hybrids  geared toward
other purposes  keller   eyerich        bonet   geffner        keller   helmert        
 exploiting dominance relations  goal probability can only be higher in dominating states 
raising the opportunity to prune dominated regions and or transfer upper lower bounds across
states  state domination is ubiquitous in limited budget planning  and resource constrained
planning   more general domination relations have been shown to exist also in many other
classical planning problems  torralba   hoffmann         and the transfer of these techniques to the probabilistic case  via all outcomes determinization  should be straightforward 
last but not least  simulated penetration testing is an application worth algorithms research in its
own right  the basic idea is to exploit the particular structure of such models  specifically their
partially delete relaxed behavior  a characterizing property of simulated penetration testing is that
any action  once applicable  remains applicable until it is first executed  once the attacker gets into a
position enabling an exploit  that exploit remains enabled   hence  like in delete relaxed planning 
to find an optimal solution  navely we will branch over that same action at every state ever after  to
combat this  there are at least three interesting directions  following pommerening and helmerts
       methods for computing h    different branching schemes might apply  the challenge being
to maintain value function correctness  following gefen and brafmans        methods for computing h    partial order reduction could be adapted  the challenge being to deal with the action
interference entailed by a shared budget  finally  methods specific to the probabilistic setting may
apply  intuitively  to preserve optimality  certain actions need to be attempted only if an alternate
goal path failed  this suggests to identify  and branch at  only particular critical points along any
search path 

acknowledgments
this work was partially supported by the german research foundation  dfg   under grant ho
          critically constrained planning via partial delete relaxation  as well as by the federal ministry of education and research  bmbf  through funding for the center for it security 
privacy and accountability  cispa  under grant   kis      we thank christian muise for his
probabilistic pddl extension of the fd parser  we thank andrey kolobov for discussions  we
thank the anonymous reviewers  whose comments helped to improve the paper 

appendix a  depth first heuristic search for cyclic problems
the pseudo code of the family of depth first heuristic search algorithms  dfhs  for general  cyclic 
probabilistic planning problems is shown in figure    
   

fig oal p robability a nalysis in p robabilistic p lanning

procedure goalprob dfhs
     i  
loop do
 early termination criteria exactly as in goalprob ao  
if  label and i is not labeled as solved 
or  vi and  u changed after running vi on the  u  greedy graph  then
index     
dfhs exploration i 
set idx of visited states to 
clean stack and visited
else return  u endif    regular termination   
endloop
procedure dfhs exploration s  
if s    then initialize s  endif
if s  s   s or s is labeled solved then
label s solved
return 
endif
f lag    
if fw then
if v u  s  is not  consistent then f lag      endif
update v u  s    u  s   v l  s    l  s 
if consist and f lag then return   endif
endif
s idx    index  s lowlink    index
push s onto stack  mark s as visited
index    index    
foreach t with p  s   u  s   t      do
if t idx    then
f lag    dfhs exploration s   f lag
if t idx    and t lowlink   s lowlink then s lowlink    t lowlink endif
else if t is on stack and t idx   s lowlink then s lowlink    t idx endif
done
if f lag or fw then
if v u  s  is not  consistent then f lag      endif
update v u  s    u  s   v l  s   and  l  s 
endif
if label and f lag and s idx   s lowlink then
while forever
t    stack pop  
label t solved
if t   s then break endif
done
endif
return f lag

figure     depth first heuristic search  dfhs  for general  cyclic  maxprob  atleastprob  and
approxprob 

appendix b  landmarks pruning  admissible heuristic vs  budget reduction
as stated  domshlak and mirkis        problem reformulation  pruning states based on a global
budget reduced using disjunctive action landmarks  is equivalent  regarding the states pruned by
the method on its own  to the much simpler method using the same landmarks for pruning against
   

fis teinmetz   h offmann   b uffet

the remaining original budget  we now give this argument  previously made only for unit costs
and pairwise disjoint landmarks  for the general setting  we assume a classical planning setup for
simplicity  the arguments in probabilistic and oversubscription setups are essentially the same 
assume a strips planning task     f  a  i  g   with action costs c a  and with a global
budget b  we use a notation following admissible landmark heuristics as per karpas and domshlak
        let l be a set of disjunctive action landmarks for i  i e   for every l  l and every
action sequence  a leading from i to the goal   a touches l  there exists a  l used on  a   let
furthermore
cp   a  l   r 
  be a cost partitioning  i e   a function satisfying  for each a  a 
p
that ll c a  l p
 c a   denote h l     minal cp a  l   and for a subset l   l of landmarks
denote h l       ll  h l   intuitively  each landmark l  l is assigned a weight h l  via cp  and
the admissible heuristic value h l  for i is obtained by summing up these weights 
we now describe domshlak and mirkis        pruning technique in these terms  domshlak
and mirkis formulation is in terms of a compilation into a planning language  which is more complicated  but is equivalent to our formulation here as far as the pruning is concerned 
domshlak and mirkis technique maintains the non used landmarks as part of states  namely 
for a state s reached on path  a  l  l is non used in s iff  a does not touch l  we denote the set of nonused landmarks in s by l s   obviously  the l  l s  are landmarks for s  note also that  as l s 
is part of the state  even if two search paths lead to the same end state but use different landmarks 
their end states are considered to be different  this restriction arises from the compilation approach 
where the book keeping of landmarks must happen inside the language  i e   inside states  one
could formulate the pruning technique without this restriction  we get back to this below 
the pruning technique now arises from the interplay of a reduced global budget and reduced
action costs depending on non used landmarks  define the reduced global budget as b     b  h l  
for any action a  denote by l a  the set of landmarks a participates in  i e   l a      l   l  l  a 
l   for any state t during search  and an applicable action a  the transition from t to t  a   has a
reduced cost  namely the cost c a   h l a   l t    in words  we reduce the cost of a by the
 summed up  weight of the non used landmarks a participates in 
consider now some state s during search  denote the remaining reduced budget in s by b   s  
say that we prune s iff b   s         consider any path  a ending in s  as non used landmarks
are part of the state  all these paths must touch the
p same subset of landmarks from l  namely
l   l s   denote the actual cost of  a by c  a     a a c a   relative to this cost  the cost saved
thanks to the cost reduction is exactly h l   l s    the weight of the touched landmarks  therefore 
b   s    b    c  
a   h l   l s     p b  h l    c  a    h l   l s    by p
definition of h 
p
this equals  b  ll h l    c  a    ll l s  h l   which equals b  c  a   ll s  h l   
b  c  a   h l s    thus  s is pruned  b   s       iff b  c  a    h l s    the latter condition is the
same as b s    h l s    which is exactly the pruning condition resulting from using h l s   as an
admissible heuristic function pruning against the remaining budget 
in a non compilation setting  one could  as is indeed customary in admissible landmark heuristics  handle landmarks in a path dependent manner  that is  non used landmarks are maintained as
    domshlak and mirkis        do not maintain the remaining budget as part of the state  but instead prune if g s   
b    this is  obviously  equivalent  except that duplicate detection is more powerful as it compares states based on
their facts f  s  only  for the purpose of our discussion here  this does not make a difference  note that  in the
probabilistic setting  we do have to distinguish states based on both f  s  and b s   as goal probability depends on
both so maintaining only the best way of reaching f  s  does not suffice to compute the exact goal probability of the
initial state 

   

fig oal p robability a nalysis in p robabilistic p lanning

annotations to states rather than as part of them  and multiple search paths may end in the same state
s but use different landmarks  the set of remaining landmarks l s  for s then is the union over
those for each individual path  that is  l  l is non used in s iff there exists at least one path that
does not touch l  this still suffices to show that l is a landmark for s  the landmark heuristic approach as per karpas and domshlak        does this kind of book keeping  and uses the admissible
heuristic value h l s   
if one were to apply domshlak and mirkis        reformulation technique without maintaining
landmarks as part of state  then the notion of transition cost reduction would have to become more
complicated  lest one loses information   this is because  if s is reached on a   with a reduced
cost due to touching landmark l    but later on we find another path a   to s that does not touch l   
then l  actually still is a valid landmark for s  and therefore there was no need to reduce the cost
on a     to account for this  we would have to revise path costs posthoc  every time a new path
to s becomes available  after these revisions  the cost reduction on each path  a to s is exactly
h l   l s    the weight of the non used landmarks l s  is no longer subtracted  and the weight of
the other landmarks l   l s  is subtracted on every  a because  by definition  every  a touches every
l  l   l s   so the cost saved on every path  a to s  relative to  a  is exactly h l   l s    from
which point the same arguments as above apply to show that the pruning is equivalent to pruning
via b s    h l s     this is a stronger pruning method than what we would get without posthoc
path cost revision  
in summary  s based on reduced remaining budget b   s      is equivalent to pruning s based on
original remaining budget vs  the landmark heuristic b s    h l s    it should be noted  though 
that such pruning is not the only benefit of domshlak and mirkis        reformulation technique 
the technique allows to compute another  complementary  admissible heuristic h on the reformulated task    and this is what domshlak and mirkis point out as part of the motivation  and what
they do in practice   from our perspective here  the landmark heuristic and h are used additively
for admissible pruning against the remaining budget  where additivity is achieved with a method
generalizing cost partitionings  in     the cost reduced variant of each action can be applied only
once  so if h does not abstract away this constraint  and if h uses an action twice  then it employs
the reduced cost only once  yet pays the full cost the second time  exploring this kind of generalized
cost partitioning in more detail is an interesting research line for future work 

references
altman  e          constrained markov decision processes  crc press 
baier  c   groer  m   leucker  m   bollig  b     ciesinski  f          controller synthesis for
probabilistic systems  extended abstract   pp          springer us  boston  ma 
barto  a  g   bradtke  s  j     singh  s  p          learning to act using real time dynamic programming  artificial intelligence                 
bertsekas  d          dynamic programming and optimal control     volumes   athena scientific 
bertsekas  d     tsitsiklis  j          neurodynamic programming  athena scientific 
bonet  b     geffner  h          planning as heuristic search  artificial intelligence          
    
   

fis teinmetz   h offmann   b uffet

bonet  b     geffner  h       a   faster heuristic search algorithms for planning with uncertainty
and full feedback  in gottlob  g   ed    proceedings of the   th international joint conference on artificial intelligence  ijcai     pp            acapulco  mexico  morgan kaufmann 
bonet  b     geffner  h       b   labeled rtdp  improving the convergence of real time dynamic
programming  in giunchiglia  e   muscettola  n     nau  d   eds    proceedings of the   th
international conference on automated planning and scheduling  icaps     pp       
trento  italy  morgan kaufmann 
bonet  b     geffner  h          mgpt  a probabilistic planner based on heuristic search  journal
of artificial intelligence research             
bonet  b     geffner  h          learning depth first search  a unified approach to heuristic search
in deterministic and non deterministic settings  and its application to mdps  in long  d    
smith  s   eds    proceedings of the   th international conference on automated planning
and scheduling  icaps     pp          ambleside  uk  morgan kaufmann 
bonet  b     geffner  h          action selection for mdps  anytime ao  versus uct  in hoffmann  j     selman  b   eds    proceedings of the   th aaai conference on artificial intelligence  aaai     toronto  on  canada  aaai press 
bryce  d     buffet  o           th international planning competition  uncertainty part  in proceedings of the  th international planning competition  ipc    
camacho  a   muise  c     mcilraith  s  a          from fond to robust probabilistic planning  computing compact policies that bypass avoidable deadends  in coles  a   coles  a  
edelkamp  s   magazzeni  d     sanner  s   eds    proceedings of the   th international
conference on automated planning and scheduling  icaps     aaai press 
chatterjee  k   chmelik  m   gupta  r     kanodia  a          optimal cost almost sure reachability in pomdps  in bonet  b     koenig  s   eds    proceedings of the   th aaai conference
on artificial intelligence  aaai     pp            aaai press 
chatterjee  k   chmelik  m   gupta  r     kanodia  a          optimal cost almost sure reachability in pomdps  artificial intelligence            
coles  a  j          opportunistic branched plans to maximise utility in the presence of resource
uncertainty  in raedt  l  d   ed    proceedings of the   th european conference on artificial
intelligence  ecai     pp          montpellier  france  ios press 
coles  a  j   coles  a   fox  m     long  d          a hybrid lp rpg heuristic for modelling
numeric resource flows in planning  journal of artificial intelligence research             
coles  a  j   coles  a   garca olaya  a   jimenez  s   linares lopez  c   sanner  s     yoon  s 
        a survey of the seventh international planning competition  the ai magazine        
dai  p   mausam  weld  d  s     goldsmith  j          topological value iteration algorithms 
journal of artificial intelligence research             
dean  t  l     givan  r          model minimization in markov decision processes  in kuipers 
b  j     webber  b   eds    proceedings of the   th national conference of the american
association for artificial intelligence  aaai     pp          portland  or  mit press 
   

fig oal p robability a nalysis in p robabilistic p lanning

domshlak  c     mirkis  v          deterministic oversubscription planning as heuristic search 
abstractions and reformulations  journal of artificial intelligence research            
drager  k   finkbeiner  b     podelski  a          directed model checking with distancepreserving abstractions  international journal on software tools for technology transfer 
            
edelkamp  s          planning with pattern databases  in cesta  a     borrajo  d   eds    proceedings of the  th european conference on planning  ecp     pp        springer verlag 
gefen  a     brafman  r  i          pruning methods for optimal delete free planning  in bonet 
b   mccluskey  l   silva  j  r     williams  b   eds    proceedings of the   nd international
conference on automated planning and scheduling  icaps     aaai press 
givan  r   leach  s  m     dean  t          bounded parameter markov decision processes  artificial intelligence                  
hansen  e  a     zilberstein  s          lao    a heuristic search algorithm that finds solutions
with loops  artificial intelligence                 
haslum  p   botea  a   helmert  m   bonet  b     koenig  s          domain independent construction of pattern database heuristics for cost optimal planning  in howe  a     holte 
r  c   eds    proceedings of the   nd national conference of the american association for
artificial intelligence  aaai     pp            vancouver  bc  canada  aaai press 
haslum  p     geffner  h          heuristic planning with time and resources  in cesta  a    
borrajo  d   eds    proceedings of the  th european conference on planning  ecp     pp 
        springer verlag 
helmert  m          the fast downward planning system  journal of artificial intelligence research             
helmert  m     domshlak  c          landmarks  critical paths and abstractions  whats the difference anyway   in gerevini  a   howe  a   cesta  a     refanidis  i   eds    proceedings of
the   th international conference on automated planning and scheduling  icaps     pp 
        aaai press 
helmert  m   haslum  p   hoffmann  j     nissim  r          merge   shrink abstraction  a method
for generating lower bounds in factored state spaces  journal of the association for computing machinery        
hoffmann  j          simulated penetration testing  from dijkstra to turing test    in brafman  r   domshlak  c   haslum  p     zilberstein  s   eds    proceedings of the   th international conference on automated planning and scheduling  icaps     aaai press 
hoffmann  j   kissmann  p     torralba  a          distance  who cares  tailoring merge andshrink heuristics to detect unsolvability  in schaub  t   ed    proceedings of the   st european
conference on artificial intelligence  ecai     prague  czech republic  ios press 
hoffmann  j     nebel  b          the ff planning system  fast plan generation through heuristic
search  journal of artificial intelligence research             
hou  p   yeoh  w     varakantham  p          revisiting risk sensitive mdps  new algorithms
and results  in chien  s   do  m   fern  a     ruml  w   eds    proceedings of the   th
international conference on automated planning and scheduling  icaps     aaai press 
   

fis teinmetz   h offmann   b uffet

jimenez  s   coles  a     smith  a          planning in probabilistic domains using a deterministic
numeric planner  in proceedings of the   th workshop of the uk planning and scheduling
special interest group  plansig    
karpas  e     domshlak  c          cost optimal planning with landmarks  in boutilier  c   ed   
proceedings of the   st international joint conference on artificial intelligence  ijcai    
pp            pasadena  california  usa  morgan kaufmann 
katz  m   hoffmann  j     helmert  m          how to relax a bisimulation   in bonet  b   mccluskey  l   silva  j  r     williams  b   eds    proceedings of the   nd international conference on automated planning and scheduling  icaps     pp          aaai press 
keller  t     eyerich  p          prost  probabilistic planning based on uct  in bonet  b  
mccluskey  l   silva  j  r     williams  b   eds    proceedings of the   nd international
conference on automated planning and scheduling  icaps     aaai press 
keller  t     helmert  m          trial based heuristic tree search for finite horizon mdps  in
borrajo  d   fratini  s   kambhampati  s     oddi  a   eds    proceedings of the   rd international conference on automated planning and scheduling  icaps     rome  italy  aaai
press 
kolobov  a          scalable methods and expressive models for planning under uncertainty 
ph d  thesis  university of washington 
kolobov  a   mausam    weld  d  s          sixthsense  fast and reliable recognition of dead ends
in mdps  in fox  m     poole  d   eds    proceedings of the   th national conference of the
american association for artificial intelligence  aaai     atlanta  ga  usa  aaai press 
kolobov  a   mausam    weld  d  s          a theory of goal oriented mdps with dead ends  in
de freitas  n     murphy  k  p   eds    proceedings of the   th conference on uncertainty in
artificial intelligence  uai     pp          catalina island  ca  usa  auai press 
kolobov  a   mausam  weld  d  s     geffner  h          heuristic search for generalized stochastic
shortest path mdps  in bacchus  f   domshlak  c   edelkamp  s     helmert  m   eds   
proceedings of the   st international conference on automated planning and scheduling
 icaps     aaai press 
kurniawati  h   hsu  d     lee  w  s          sarsop  efficient point based pomdp planning
by approximating optimally reachable belief spaces  in robotics  science and systems iv 
kuter  u     hu  j          computing and using lower and upper bounds for action elimination in
mdp planning  in miguel  i     ruml  w   eds    proceedings of the  th international symposium on abstraction  reformulation  and approximation  sara      vol       of lecture
notes in computer science  whistler  canada  springer verlag 
kwiatkowska  m   parker  d     qu  h       a   incremental quantitative verification for markov
decision processes  in      ieee ifip   st international conference on dependable systems
networks  dsn   pp         
kwiatkowska  m  z   norman  g     parker  d       b   prism      verification of probabilistic
real time systems  in gopalakrishnan  g     qadeer  s   eds    proceedings of the   rd international on conference computer aided verification  cav     vol       of lecture notes in
computer science  pp          springer 
   

fig oal p robability a nalysis in p robabilistic p lanning

little  i   aberdeen  d     thiebaux  s          prottle  a probabilistic temporal planner  in veloso 
m  m     kambhampati  s   eds    proceedings of the   th national conference of the american association for artificial intelligence  aaai     pp            pittsburgh  pennsylvania  usa  aaai press 
little  i     thiebaux  s          probabilistic planning vs replanning  in icaps workshop on the
international planning competition  past  present and future 
marecki  j     tambe  m          towards faster planning with continuous resources in stochastic
domains  in fox  d     gomes  c   eds    proceedings of the   rd national conference of the
american association for artificial intelligence  aaai     pp            chicago  illinois 
usa  aaai press 
mcmahan  h  b   likhachev  m     gordon  g  j          bounded real time dynamic programming  rtdp with monotone upper bounds and performance guarantees  in proceedings of
the   nd international conference on machine learning  icml     
meuleau  n   benazera  e   brafman  r  i   hansen  e  a     mausam  m          a heuristic search
approach to planning with continuous resources in stochastic domains  journal of artificial
intelligence research              
milner  r          operational and algebraic semantics of concurrent processes  in van leeuwen  j 
 ed    handbook of theoretical computer science  volume b  formal models and sematics 
pp            elsevier and mit press 
muise  c  j   mcilraith  s  a     beck  j  c          improved non deterministic planning by
exploiting state relevance  in bonet  b   mccluskey  l   silva  j  r     williams  b   eds   
proceedings of the   nd international conference on automated planning and scheduling
 icaps     aaai press 
nakhost  h   hoffmann  j     muller  m          resource constrained planning  a monte carlo
random walk approach  in bonet  b   mccluskey  l   silva  j  r     williams  b   eds   
proceedings of the   nd international conference on automated planning and scheduling
 icaps     pp          aaai press 
nilsson  n  j          problem solving methods in artificial intelligence  mcgraw hill 
nissim  r   hoffmann  j     helmert  m          computing perfect heuristics in polynomial time 
on bisimulation and merge and shrink abstraction in optimal planning  in walsh  t   ed   
proceedings of the   nd international joint conference on artificial intelligence  ijcai    
pp            aaai press ijcai 
pommerening  f     helmert  m          optimal planning for delete free tasks with incremental
lm cut  in bonet  b   mccluskey  l   silva  j  r     williams  b   eds    proceedings of the
  nd international conference on automated planning and scheduling  icaps     aaai
press 
richter  s     helmert  m          preferred operators and deferred evaluation in satisficing planning  in gerevini  a   howe  a   cesta  a     refanidis  i   eds    proceedings of the   th
international conference on automated planning and scheduling  icaps     pp         
aaai press 
   

fis teinmetz   h offmann   b uffet

sanner  s          relational dynamic influence diagram language  rddl   language description 
available at http   users cecs anu edu au ssanner ippc      rddl 
pdf 
santana  p   thibaux  s     williams  b          rao   an algorithm for chance constrained
pomdps  in schuurmans  d     wellman  m   eds    proceedings of the   th aaai conference on artificial intelligence  aaai     pp            aaai press 
sarraute  c   buffet  o     hoffmann  j          pomdps make better hackers  accounting for
uncertainty in penetration testing  in hoffmann  j     selman  b   eds    proceedings of the
  th aaai conference on artificial intelligence  aaai     pp            toronto  on 
canada  aaai press 
seipp  j     helmert  m          counterexample guided cartesian abstraction refinement  in
borrajo  d   fratini  s   kambhampati  s     oddi  a   eds    proceedings of the   rd international conference on automated planning and scheduling  icaps     pp         
rome  italy  aaai press 
seipp  j     helmert  m          diverse and additive cartesian abstraction heuristics  in chien  s  
do  m   fern  a     ruml  w   eds    proceedings of the   th international conference on
automated planning and scheduling  icaps     aaai press 
smith  t     simmons  r  g          focused real time dynamic programming for mdps  squeezing more out of a heuristic  in gil  y     mooney  r  j   eds    proceedings of the   st
national conference of the american association for artificial intelligence  aaai     pp 
          boston  massachusetts  usa  aaai press 
steinmetz  m   hoffmann  j     buffet  o          revisiting goal probability analysis in probabilistic planning  in coles  a   coles  a   edelkamp  s   magazzeni  d     sanner  s   eds   
proceedings of the   th international conference on automated planning and scheduling
 icaps     aaai press 
tarjan  r  e          depth first search and linear graph algorithms  siam journal on computing 
             
teichteil konigsbuch  f          stochastic safest and shortest path problems  in hoffmann  j  
  selman  b   eds    proceedings of the   th aaai conference on artificial intelligence
 aaai     toronto  on  canada  aaai press 
teichteil konigsbuch  f   kuter  u     infantes  g          incremental plan aggregation for generating policies in mdps  in van der hoek  w   kaminka  g  a   lesperance  y   luck  m    
sen  s   eds    proceedings of the  th international conference on autonomous agents and
multiagent systems  aamas     pp            ifaamas 
teichteil konigsbuch  f   vidal  v     infantes  g          extending classical planning heuristics to
probabilistic planning with dead ends  in burgard  w     roth  d   eds    proceedings of the
  th national conference of the american association for artificial intelligence  aaai    
san francisco  ca  usa  aaai press 
torralba  a     hoffmann  j          simulation based admissible dominance pruning  in yang 
q   ed    proceedings of the   th international joint conference on artificial intelligence
 ijcai     pp            aaai press ijcai 
   

fig oal p robability a nalysis in p robabilistic p lanning

yoon  s  w   fern  a     givan  r          ff replan  a baseline for probabilistic planning  in
boddy  m   fox  m     thiebaux  s   eds    proceedings of the   th international conference
on automated planning and scheduling  icaps     pp          providence  rhode island 
usa  morgan kaufmann 
younes  h  l  s   littman  m  l   weissman  d     asmuth  j          the first probabilistic track
of the international planning competition  journal of artificial intelligence research     
       

   

fi