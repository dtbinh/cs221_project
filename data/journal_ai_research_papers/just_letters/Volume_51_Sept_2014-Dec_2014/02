journal artificial intelligence research                 

submitted        published      

text rewriting improves semantic role labeling
kristian woodsend
mirella lapata

k woodsend ed ac uk
mlap inf ed ac uk

institute language  cognition computation
school informatics  university edinburgh
   crichton street  edinburgh eh   ab

abstract
large scale annotated corpora prerequisite developing high performance nlp
systems  corpora expensive produce  limited size  often demanding linguistic
expertise  paper use text rewriting means increasing amount labeled
data available model training  method uses automatically extracted rewrite rules
comparable corpora bitexts generate multiple versions sentences annotated
gold standard labels  apply idea semantic role labeling show
model trained rewritten data outperforms state art conll     
benchmark dataset 

   introduction
recent years witnessed increased interest automatic identification labeling
semantic roles conveyed sentential constituents  gildea   jurafsky        
goal semantic role labeling task discover relations hold
predicate arguments given input sentence  e g   whom 
when  where  how  
   

 mrs  yeargin a   gave v  the questions answers a   two days
examination tmp  two low ability geography classes arg   

sentence      a  represents agent giver  a  represents theme thing given 
a  represents recipient  tmp temporal modifier indicating action took
place  v determines boundaries predicate  semantic roles example
labeled style propbank  palmer  gildea    kingsbury         broad coverage
human annotated corpus semantic roles syntactic realizations  propbank annotation framework predicate associated set core roles  named a  
a   a   on  whose interpretations specific predicate  set adjunct
roles location time whose interpretation common across predicates  e g   two
days examination sentence     above  
type semantic information shallow relatively straightforward infer automatically useful development broad coverage  domain independent language
understanding systems  indeed  analysis produced existing semantic role labelers
shown benefit wide spectrum applications ranging information extraction
 surdeanu  harabagiu  williams    aarseth        question answering  shen   lapata 
   precisely  a  a  common interpretation across predicates proto agent protopatient sense described dowty        
c
    
ai access foundation  rights reserved 

fiwoodsend   lapata

source
   retreating guerrillas soon pursued government forces 
   survey conducted gallup poll
last summer indicated one four
americans takes cues stars believes ghosts 
   examiner kind let student finish lunch 
   didnt know rules 
died 
   mexico city  biggest city world 
many interesting archaeological sites 
   arrival train unexpected 

target
government forces soon pursued retreating guerrillas 
survey conducted gallup
poll last summer  indicated one
four americans takes cues stars
believes ghosts 
kind examiner let student finish
lunch 
died  didnt know
rules 
mexico city many interesting archaeological sites 
trains arrival unexpected 

table    examples syntactic rewriting 

       machine translation  wu   fung        summarization  melli  wang  liu 
kashani  shi  gu  sarkar    popowich        
srl systems date conceptualize semantic role labeling task supervised
learning problem rely role annotated data model training  supervised methods
deliver reasonably good performance  f  scores low eighties standard test
collections english  rely primarily syntactic features  such path features 
order identify classify roles  mixed blessing path
argument predicate informative quite complicated  many paths
parse tree likely occur relatively small number times  or all 
resulting sparse information classifier learn from  even training
data includes examples specific predicate set arguments  unless test sentence
contains syntactic structure  far classifier concerned 
labeling items within two sentences unrelated 
idea use use rewrite rules order create several syntactic variants
sentence  thus alleviating training requirements semantic role labeling  rewrite
rules typically synchronous grammar rules defining sequence source terminals
nonterminals rewrites sequence target terminals nonterminals  rules
often extracted monolingual corpora containing parallel translations
source text  barzilay   mckeown        pang  knight    marcu         bilingual
corpora consisting documents translations  bannard   callison burch      a 
callison burch         comparable corpora wikipedia revision histories  coster
  kauchak        woodsend   lapata         examples rewrites given table   
include transforming passive active sentences  see sentence pair     table    
splitting long complicated sentence several shorter ones  see     table    
removing redundant parts sentence  see     table     reordering parts sentence
 see     table     deleting appositives  see     table     transforming prepositional
phrase genitive  see     table     on 
   

fitext rewriting improves semantic role labeling

automatically extract syntactic rewrite rules corpora use generate
multiple versions role annotated sentences whilst preserving original semantic roles 
therefore expand training data wide range syntactic variations
predicate argument combination learn semantic role labeler expanded
dataset  approach describe essentially increases size training data
creating many different syntactic variations different predicates roles 
rewrite rules previously deployed variety text to text generation applications ranging summarisation  galley   mckeown        yamangil   nelken       
cohn   lapata        ganitkevitch  callison burch  napoles    van durme        
question answering  wang  smith    mitamura         information retrieval  park  croft 
  smith         simplification  zhu  bernhard    gurevych        woodsend   lapata 
      feblowitz   kauchak         machine translation  callison burch        marton  callison burch    resnik        ganitkevitch  cao  weese  post    callison burch 
       however  application text rewriting means increasing amount
labeled data available model training novel knowledge  show experimentally  syntactic transformations improve srl performance beyond state art
using conll      benchmark dataset best scoring system  bjorkelund 
hafdell    nugues         importantly  approach used combination
srl learner role annotated data  moreover  specifically tied srl task
employed learning model dataset  rewrite rules could used expand
training data tasks make use syntactic features semantic parsing
 kwiatkowski        textual entailment  mehdad  negri    federico        wang  
manning        
following  present overview related work  section    describe
rewrite rules automatically extracted filtered correctness  section     section   details experiments section   reports results 

   related work
idea transforming sentences make amenable nlp technology dates
back chandrasekar  doran  srinivas        argue simpler sentences would
decrease likelihood incorrect parse  end  employ mostly hand crafted
syntactic rules aimed splitting long complicated sentences simpler ones  klebanov  knight  marcu        preprocess texts easy access sentences  i e   sentences
consisting one finite verb dependents order facilitate information seeking applications summarization information retrieval accessing factual information 
similar vein  vickrey koller        devise large number hand written rules
order simplify sentences semantic role labeling  present log linear model
jointly learns select best simplification  out possibly exponential space
candidates  role labeling  kundu roth        use textual transformations
domain adaptation  rather training new model out of domain data  propose
rewrite out of domain text similar training domain 
pilot idea semantic role labeling using hand written rewrite rules show
compares favorably approaches retrain model target domain 
   

fiwoodsend   lapata

work focused idea automatically expanding data available
given task without  however  applying transformations  furstenau lapata       
combine labeled unlabeled data projecting semantic role annotations labeled
source sentence onto unlabeled target sentence  find novel instances classifier
training based lexical structural similarity manually labeled seed instances 
zanzotto pennacchiotti        increase datasets textual entailment mining
wikipedia revision histories 
contrary previous work  automatically extract general rewrite rules various data sources including wikipedia revision histories  comparable articles  bilingual
corpora  given sentence  semantic role  annotated data  create several syntactic transformations  many may erroneous  maintain model
training transformations whose role labels preserved syntactic rewrite 
identify transformations label preserving automatically  without requiring
srl specific knowledge  approach differs vickrey koller       
three important aspects   a  employ automatic rules simplification specific   b  attempt select best rewrite  transformations preserve
gold standard role labels used training  c  model jointly
rewrites sentences labels semantic roles  rewrite training data
available model srl task  work shares kundu
roth        idea transforming sentences preserving gold standard
role labels  however  transform test data make look training
data  unavoidably requires specialized knowledge differences two
domains  general model have 
mentioned earlier  use synchronous grammars extract set possible syntactic rewrites  synchronous context free grammars  scfgs  aho   ullman       
generalization context free grammar  cfg  formalism simultaneously produce
strings two languages  used extensively syntax based statistical mt
 wu        yamada   knight        chiang        graehl   knight        related
generation tasks sentence compression  galley   mckeown        cohn   lapata 
            ganitkevitch et al          sentence simplification  zhu et al         feblowitz
  kauchak        woodsend   lapata         summarization  woodsend   lapata 
       rather focusing one type transformation  e g   simplification compression   learn full spectrum rewrite operations select rules appropriate
task hand  furthermore  results show rewrite rules improve semantic role
labeling performance across board  irrespectively specific variant synchronous
grammar corpus used  experiment conventional  weighted  scfgs  aho  
ullman        tree substitution grammars  eisner        employ transformation
rules extracted wikipedia revision histories  zhu et al         woodsend   lapata 
      bitexts  ganitkevitch  van durme    callison burch        

   method
section describe general idea behind algorithm move
present specific implementation  define transformation g function
maps example sentence modified sentence s    let g set known
   

fitext rewriting improves semantic role labeling

transformation functions  g    g    g            gn    suppose labels associated
example s  context paper  semantic role labels  labels could
defined spans tokens  use conll       formalism
head word span labelled  transformation function therefore mapping
tokens sentence tokens t  s    require mapping
involves tokens s    require mappings one to one 
label preserving transformation transformation gi mapping  some the 
tokens example tokens t  s     correct  labels t  identical
labels source tokens token mappings defined gi   words 
labels could preserved  preserved  others introduced 
let g set label preserving transformation functions  g g  problem
address paper therefore two fold  firstly  find automatically set
possible transformation functions g due automated nature unavoidably
error prone process  secondly  identify  again automatically  transformations g
actually label preserving specifically  transformations rewrite
training instance s  varying syntactic structure  yet preserve
semantic roles arguments appear new version s   
algorithm   describes approach boils three steps   a  extracting
transformations   b  refining transformations   c  generating labeling extended
corpus  standard gold annotated corpus used train initial semantic role labeling
model  see lines    algorithm     meanwhile  set candidate transformation functions g extracted suitable comparable parallel corpus  line     full
set transformation functions used rewrite gold corpus  creating much extended
corpus inevitably contain grammatically semantically incorrect sentences 
extended corpus next automatically labeled using original srl model preprocessing normal srl pipeline  whose details discuss section       without
knowledge transformation functions involved 
could theory use extended corpus basis training srl
model  however  contain many errors  unlikely yield useful information
guide model  one approach could manually correct rewrites
generated automatically  would time resource intensive  instead 
corrections automatically  create extended corpus rewrites
impair quality training data  therefore learn rules yield accurate
rewrites  i e   rewrites preserve labels gold standard  intuition
that  given large number possible rewrites  srl model general label
accurate rewrites correctly mis label erroneous sentences  due finding
confusing  thus compare semantic role labels produced model
labels corresponding predicate argument pairs gold corpus  provide
samples train binary classifier  here svm  learns predict rewrites
likely successful problematic  lines      algorithm    
rewritten sentence classed positive sample srl model able label
transformation standard better able label original
sentence  i e  labels srl model predicts transformed sentence match
predicted original  corrected respect mapped
gold labels  if  however  semantic role longer predicted correctly  missed 
   

fiwoodsend   lapata

algorithm   learn srl model mextended extending gold training corpus cgold
transformation functions g 
   mgold srl model trained cgold
   cmodel label cgold using mgold
extract transformations 
   g transformation functions extracted pairs aligned sentences
comparable corpora
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   

refine transformations 
initialize svm training data dsvm
sentences cgold
g applicable transformations g
s  rewrite using g
label s  using mgold
srl labels s  match labels cgold equivalent cmodel
true
else
false
end
add  s    y  dsvm
end
end
train svm using dsvm
g  g g   g positive svm weight 
generate extended corpus 
initialize refined rewrite corpus crefined
sentences cgold
g applicable transformations g
s  rewrite using g
project labels s  using g
add s  crefined
end
end
cextended cgold crefined

retrain srl model 
mextended srl model trained cextended
    return mextended

   

   

fitext rewriting improves semantic role labeling

erroneous role introduced  classified negative sample  sample likely
harm training new srl model 
svm identified refined set transformation functions g  line     
transformations used create extended training corpus  time  knowledge
transformation function involved project labels correspond original
gold corpus  lines        case srl  labels describe predicate
arguments  extended corpus supplements original gold standard corpus  line     
combination used create srl model  line     
worth noting method impinge actual process learning
srl model  concerned preparation training data  therefore believe
applied range srl modeling approaches  gains performance
achieve largely orthogonal could made improving aspects
learning process  see section     empirical evidence  
    learning transformations
conceptually wide range text rewriting transformation functions could included
set g  paraphrasing  simplification translation another language  here 
focus transformation functions expressed synchronous context free
grammars  aho   ullman         synchronous rules operate parse tree constituents
context free manner  typically modify syntax  transformations consider
sub categorized into 
   statement extraction  constituents sub tree parse tree identified  extracted context rewritten complete sentence  typically shorter
simpler  although necessarily so 
   compression  original sentence rewritten compressing constituents
parse tree  typically deleting nodes 
   insertion  new elements added parse tree  significant chunks new
text would semantic role information own  practice insertions
often additional punctuation clarify scope phrases  simple structure
        aid statement extraction 
   substitution  using lexicalized synchronous grammar  text replaced
new text  paraphrases represented 
obtain set possible transformations g monolingual comparable corpora
drawn wikipedia bitexts  see section   details   following describe
grammar formalisms resources consider 
      transformations monolingual corpora
extract transformation rules corpora broadly comparable  using
unsupervised process  corpora constructed wikipedia revision histories 
comparable wikipedia articles  result  cannot guaranteed aligned source
target sentences truly related  expected source sentence
   

fiwoodsend   lapata

fully generate target sentence  practice means addition requiring
strictly synchronous structure source target sentences  cannot assume
alignment source target root nodes  require surjective alignment
target nodes nodes source parse tree  able describe structural mismatches
non isomorphic tree pairs  the grammar rules comprise trees arbitrary depth 
fragments mapped  represent transformation functions using synchronous
tree substitution grammar formalism  eisner        
synchronous tree substitution grammar  stsg  defines space valid pairs
source target parse trees  rules specify map tree fragments source parse
tree fragments target tree  recursively free context  following cohn
lapata         stsg   tuple  g    ns   nt       p  rs   rt   n
non terminals terminals  subscripts indicating source
target respectively  p productions rs ns rt nt distinguished
root symbols 
typically  production rewrite rule two aligned non terminals x ns
nt source target 
hx  h    i 
elementary trees rooted symbols x respectively 
synchronous context free grammar would limited one level elementary
trees  stsg imposes limits elementary trees arbitrarily deep 
one to one alignment frontier nodes  non terminal leaves elementary
trees  specified  
experiments  investigate two stsg variants  strictly synchronous tree
substitution grammar t   cohn   lapata         originally developed
task text compression  support full range transformation operations
quasi synchronous tree substitution grammar  qtsg  woodsend lapata        
used text simplification summarization  woodsend   lapata        
t  tokens first aligned using probabilistic aligner initially provided
identity mappings entire vocabulary  experiments used berkeley
aligner  liang  taskar    klein         however aligner broadly similar output
could used instead  synchronous rules comprising trees arbitrary depth
extracted pair input cfg parse trees  consistent alignment  across
complete corpus aligned trees  t  filters extracted rules provide maximally
general rule set  consisting rules smallest depth  still capable
synchronously deriving original aligned tree pairs  removing identity rules 
resulting grammar forms transformation functions g 
unlike t   qtsg works partial alignment tokens  based identity 
non terminal nodes parse trees aligned consistent token
alignment  result sections source target parse trees
remain unaligned  then  t   synchronous rules comprising trees minimum necessary
depth extracted pair input trees  consistent alignment 
before  identity rules removed form g 
example  figure   shows two comparable parse trees aligned token level 
synchronous rules extracted alignment t  qtsg shown table   
   

fitext rewriting improves semantic role labeling

root


nnp

 

vp

np
nns

vp

vbp



vbn

vp
vp



np

vb

pp

np

np



nn

dt

advp

modern

scholars

come





scholars



question

question





existence

existence

nns
np



least

jj

cd

nns



first

nine

emperors



first

nine

emperors

dt

jj

cd

nns

 

 

np
pp

np
nnp

jjs



nn

dt







dt

np

vbp
vp

 

root

figure    example sentence alignment showing source  above  target  below  trees 

possible extract rules nodes child level  rules t 
qtsg extract parent level identical  cases sub tree
compressed   in example  come question compressed question   qtsg
extracts full sub tree frontier nodes align  t  extract several rules
smallest depth 
      transformations bitexts
obtain transformation rules paraphrase database  ppdb  ganitkevitch
et al          collection english  and spanish  paraphrases derived large bilingual
parallel corpora  variety paraphrases  lexical  phrasal  syntactic  obtained
following bannard callison burchs      b  bilingual pivoting method 
   

fiwoodsend   lapata

rules extracted t 
    s np
vp
   i

hs  si



h s np

hnp  npi



h np  nnp modern  nns

hvp  vpi



h vp vbp

hvp  vpi



h vp vbn

hvp  vpi



h vp

hvp  vpi



h vp  vb question  np

hnp  npi



h np np

hnp  npi



h np dt

hpp  ppi



h pp

hnp  npi



h np advp

hs  si



h s np

hnp  npi



h np nnp

hvp  vpi



h vp vbp

hnp  npi



h np np

hnp  npi



h np dt

hpp  ppi



h pp

hnp  npi



h np advp

vp

 

 

vp



vp

pp

 

np



 

 

jj

np


 

 

 

 i

 

 i

pp

 

np
cd

 

 

nn

 

 

 i

 i

 

 i

 

nns

 

 

 i

 

    np dt

 

 

 

jj

 

cd

 

nns

 

 i

 

 s  vp



    pp
 

 

    np  dt some  nns

jj

 

 

pp

 

    np dt

dt

 i

 

 

 i

 

    vp  vbp question  np

    np np

 

 

rules extracted qtsg
    s np
vp
   i

 vp vbn

nn

 

 

    np dt

 

 

     vp vp

    pp

 

pp

 

 

 

 

    np np

 

nns



 

    vp vp

dt



vp

 

 

    np  dt some  nns

    vp vp

 

 

nn

 

 

 s vp





 

 

 

nn

 

np
cd

 

 



 

 i

 vp vb

 

np

 

        vp vbp

 

np

 

 i

 i

 

 i

 i
nns

 

    np dt

 

jj

 

cd

 

nns

 

 i

table    synchronous tree grammar rules extracted t  qtsg aligned
sentences figure    boxed indices short hand notation alignment   

intuition two english strings e  e  translate foreign
string f assumed meaning  method pivots f
extract he    e  pair paraphrases  example shown figure    taken
ganitkevitch et al          method extracts wide range possible paraphrases
unavoidably noisy due inaccurate word alignments  paraphrases ranked
computing p e   e    shown below 
x
p e   e   
p e   f  p f  e   
   
f

p ei  f   p f  ei   translation probabilities estimated bitext  koehn 
och    marcu        
rewrite rules ppdb obtained using generalization method sketched
extract syntactic paraphrases  ganitkevitch et al          using techniques
syntactic machine translation  koehn         scfg rules first extracted englishforeign sentence pairs  foreign phrase corresponding english phrase found via
   

fitext rewriting improves semantic role labeling

      farmers thrown jail

ireland    

    fnf landwirte

festgenommen

  weil    

    oder wurden

festgenommen

  gefoltert    

   

imprisoned

  tortured    

figure    paraphrases extracted via bilingual pivoting 
word alignments  phrase pair turned scfg rule assigning left hand side
nonterminal symbol  corresponding syntactic constituent dominates english
phrase  introduce nonterminals right hand sides rule  corresponding subphrases english foreign phrases replaced nonterminal symbols 
sentence pairs bilingual parallel corpus results translation grammar
serves basis syntactic machine translation  translation grammar
converted paraphrase grammar follows  let r  r  denote translation rules
left hand side nonterminals hx  foreign language strings match 
r    hx  h     

   

r    hx  h     
paraphrase rule rp created pivoting f  
rp   hx  h       

   

although shown equations          rules scfg associated
set features combined log linear model estimate derivation
probabilities 
      manual transformations
experiments primarily make use automatically learned transformations since
adapted different tasks  domains languages  however  proposed approach necessary transformation functions acquired automatically
functions could crafted hand  thus investigated effectiveness
rewrites generated system heilman smith         henceforth h s  
uses sophisticated hand crafted rule based algorithm extract simplified declarative sentences english syntactically complex ones  rules similar engineered vickrey koller        deterministic generate
unique rewrite given sentence  algorithm operates standard phrase
   

fiwoodsend   lapata

structure tree input sentence  extracts new sentence trees input tree
following  non restrictive appositives relative clauses  subordinate clauses
subject finite verb  participial phrases modify noun phrases  verb phrases 
clauses  addition  algorithm splits conjoined s  sbar  vp nodes  extracts new
sentence trees conjunct  output tree processed move leading
prepositional phrases quotations last children main verb phrase 
following removed  noun modifiers offset commas  non restrictive appositives 
non restrictive relative clauses  parenthetical phrases  participial phrases   verb modifiers
offset commas  subordinate clauses  participial phrases  prepositional phrases   leading
modifiers main clause  nodes precede subject  
table   shows examples rules extracted using t   qtsg ppdb grammar
formalisms applied sentence conll dataset  final column table   indicates whether transformation could classed statement extraction  compression 
insertion  substitution  reflected table  t  captures compression transformations deleting nodes parse tree  qtsg rules range mainly syntactic
transformations  ppdb transformations substitutions words short phrases 
    refining transformations
mentioned earlier  transformation rules obtained synchronous grammars
could used rewrite gold standard sentences  unfortunately  due nature
corpora rules obtained automatic extraction process  many
rules contain errors impair rather improve quality
training data  idea extrapolate rules trust observing srl
labeler handles rewritten sentences  mis labeled them  possible
rewrite correct original labels preserved 
rewritten sentence classed positive sample srl model predicts
labels transformed sentence predicted original  labels
corrected respect gold labels  if  however  semantic role
longer predicted correctly  missed  erroneous role introduced  classified
negative sample  sample likely harm training new srl model 
capture full impact candidate transformation function  sentence provided
positive sample classifier labels  i e   predicates arguments 
source sentence successfully projected onto rewrite  table   shows
examples positive negative samples t   qtsg  ppdb rewrites  note
refining used h s outputs 
decide transformation function include refined set  used linear
kernel svm  vapnik        binary classifier  classifiers indeed suitable
statistical tests contingency could used  input svm learner set
l training samples  x    y              xl   yl    xi rn            xi n dimensional
feature vector representing ith sample  yi label sample  learning
process involves solving convex optimization problem find large margin separation
hyperplane positive negative samples  order cope inseparable data 
misclassification allowed  amount determined parameter c 
thought penalty misclassified training sample  one
   

fitext rewriting improves semantic role labeling

grammar
original

t 

examples
bell  based los angeles  makes distributes electronic  computer
building products 
bell  based  makes distributes electronic  computer building products 
hpp  ppi h pp np     pp  i

comp

bell  based los angeles  makes distributes 
hnp  npi h np adjp nns     np  i

comp

based los angeles  makes distributes electronic  computer building
products 
hnp  npi h np nnp      np  i

comp

bell  based angeless  makes distributes electronic  computer building products 
hnp  npi h np nnp nnp     np nnp
 pos s  i

comp

bell makes distributes electronic  computer building products 
hnp  npi h np np
  vp      np np  i

comp

makes distributes electronic  computer building products 
hs  si
h s np vp
      s  np it  vp
   i

ins

 

qtsg

 

 

 

 

bell based los angeles 
hnp  si
h np np
  vp
 

 

 

     s np

 

 

 

 vp  vbd was  vp

 

    i

ext

bell  based los  makes distributes electronic  computer building
products 
hnp  npi h np nnp
nnp     np nnp  i

comp

los angeles makes distributes electronic  computer building products 
hnp  npi h np np    vp vbn  pp np         np np  i

comp

bell  founded los angeles  makes distributes electronic  computer
building products 
hvp  vpi h vp  x based  pp     vp  x founded  pp  i

sub

bell  building los angeles  makes distributes electronic  computer
building products 
hvp  vpi h vp  x based 
np     vp  x building 
np  i

sub

bell  based los angeles  makes distributes electronic  computer
building products 
hvp  vpi h vp vbn
np     vp vbn
 x during  np
 i

sub

 

 

 

ppdb

type

 

 

 

 

 

 

 

 

 

 

 

table    examples transformation rules extracted using t   qtsg ppdb grammar
formalisms  applied sentence marked original  final column indicates
whether rule statement extraction  ext   compression  comp   insertion
 ins  substitution  sub   before  boxed indices short hand notation
alignment   

view  the dual problem   result set support vectors  associated weights  
constant b  another view  the primal problem   result vector w
defines separation hyperplane  dimension depends particular kernel
   

fiwoodsend   lapata

original bell  based los angeles  makes distributes electronic  computer building products 
t 

qtsg

bell  based  makes distributes electronic  computer building products 
bell  based los angeles  makes distributes 
based los angeles  makes distributes electronic  computer building products 
bell  based angeless  makes distributes electronic  computer building products 

 
 
 


bell makes distributes electronic  computer building products 
makes distributes electronic  computer building products 
bell based los angeles 
bell  based los  makes distributes electronic  computer building products 
bell  based angeles  makes distributes electronic  computer building products 
los angeles makes distributes electronic  computer building products 

 
 
 

 


ppdb

bell  founded los angeles  makes distributes electronic  computer building products 
bell  building los angeles  makes distributes electronic  computer building products 
bell  based los angeles  makes distributes electronic  computer building products 

h s

bell makes  bell distributes  bell based los angeles 

original employees sign options  college must approve plan 
t 

it  college must approve plan 
college must approve plan 
employees sign options  must approve the 
employees sign for  college must approve plan 


 

 

qtsg

employees sign options  college must approve 
employees sign options  college must approve plan 
employees sign options  college must approve plan 


 


ppdb






 

 


h s

college must approve plan employees sign options 






employees
employees
employees
employees






sign
sign
sign
sign
















options 
options 
options 
options 






college
college
college
college






must adopt plan 
must agree plan 
must endorse plan 
needs approve plan 

original went permissible line warm fuzzy feelings 
t 






went permissible line feelings 
went warm fuzzy feelings 
went it 
went 

 


 

qtsg

went line warm fuzzy feelings 
went permissible line feelings 
went permissible warm fuzzy feelings 

 



ppdb

went permissible line hot fuzzy feelings 
went permissible line warm fuzzy feelings 


 

h s

went permissible line warm fuzzy feelings 

table    examples rewrites generated t   qtsg  ppdb source sentence
 original  conll      training set  symbols    indicate whether
sample classified positive  i e   argument label preserving  forms part
extended training corpus  not 

   

fitext rewriting improves semantic role labeling

function used svm  case linear kernel function  wpis ndimensional 
feature vectors  straight forward relationship w   lj   yj j xj
primal dual variables  effectively assigning weights explicitly specified features 
kernel functions allow interaction variables  instance using
binary valued features  degree  polynomial kernel function implies classifier
considers available pairs features well 
used identity transformation functions involved features
sample  size feature space n   kgk  features binary valued 
features could easily incorporated setting  perhaps capturing information
structure source sentence transformation function  might achieve good
results conjunction polynomial kernel  pursue avenue further 
instead used linear kernel  due simple structure features  svm
assigned weight transformation function independent source sentence 
chose transformation functions form refined set based whether
corresponding weight global threshold value  set threshold value
maximizing performance resulting srl model development set 
    labeling extended corpus
svm identified refined set transformation functions g  transformations used create extended training corpus  using alignment information
transformation functions trace position tokens original sentence
rewrite  semantic role labels gold corpus projected onto corresponding predicate argument pairs rewritten corpus  assuming svm correctly
identified transformation function involved indeed label preserving 
transformation functions applied current context  semantic role labeling
rewrite quality standard source  conditions
however unlikely true  resulting degradation quality rewrite corpus 
corpus rewrites appended original gold standard corpus create new
larger training corpus  used create srl model 

   experimental setup
section present experimental setup assessing performance approach  give details corpora grammars used create transformations 
model parameters used identify preserve labels  explain existing srl system modified approach  evaluated effects
increasing training data transformations 
    grammar extraction
extracted synchronous grammars two monolingual comparable corpora drawn
wikipedia  corpus         aligned sentences created pairing simple english
wikipedia english wikipedia  kauchak         corpus        paired sentences comparing consecutive revisions articles simple english wikipedia  woodsend   lapata         corpora provide large repository monolingual  comparable
   

fiwoodsend   lapata

grammar
t 
qtsg

aligned
      
     

revisions
     
   

table    non identical rules extracted wikipedia corpus  rules appearing
one two times removed 

sentences  taken real world writing  advantageously  simple english wikipedia encourages contributors employ simpler grammar ordinary english wikipedia 
corpora therefore naturally contain many examples syntactic variation reordering sentence splitting  well paraphrasing changes content  table   lists
number non identical rules grammar formalism extracted wikipedia
corpora  rules instance count one two removed 
addition grammars extracted simple english wikipedia  worked
monolingual synchronous grammar included paraphrase database  ganitkevitch et al          paraphrases extracted bilingual parallel corpora 
english portion ppdb contains     million paraphrase pairs  including    
million paraphrase patterns capturing syntactic transformations varying confidence 
form synchronous grammar  used highest scoring         paraphrases
subset constituent syntactic paraphrases  where nonterminals labeled penn
treebank constituents  
    semantic role labeler
method presented paper crucially relies semantic role labeler refining
transformations performing semantic analysis general  used publicly available system bjorkelund et al          competed
conll      srl only challenge  ranked first english language  second overall  best knowledge  system represents state of the art english
srl parsing  system architecture consists four stage pipeline classifiers 
predicate identification  although module required evaluation   predicate
sense disambiguation  binary classifier argument identification  finally argument
classification using multiclass classifier  beam search used identify arguments
predicate label them  according local classifiers using features relate
mainly dependency parse information linking predicates potential arguments
siblings  addition  global reranker used select best combination candidates  see section   details   srl system requires tokenized input lemma 
pos tag dependency parse information  information already provided
gold standard training corpus  see immediately below   create equivalent information
transformed text evaluation files  used mate tools pipeline  bjorkelund
et al          retrained  like srl model itself  training partition data 
used english language benchmark datasets conll      shared task
train evaluate srl models  identified labeled semantic arguments nouns
   

fitext rewriting improves semantic role labeling

corpus
training
  h s
  ppdb
  t 
  qtsg
  t    qtsg
  ppdb   t 
  ppdb   qtsg
  ppdb   t    qtsg
development
test in domain
test out of domain

sentences
      
      
       
       
       
       
       
       
       
     
     
   

tokens
       
       
         
         
         
          
          
          
          
      
      
     

table    statistics corpora used train evaluate srl models 
verbs  hajic  ciaramita  johansson  kawahara  mart  marquez  meyers  nivre  pado 
stepanek  stranak  surdeanu  xue    zhang         used training  development 
test out of domain test partitions provided  statistics
data sets shown table    specifically  show increase training data
effected method using transformations obtained t   qtsg  ppdb 
combinations  comparison use manual transformations available
heilman smith         train srl model  and previous stages nlp
pipeline   used data training partition only  development partition
used identify best subset g transformations   
used liblinear  fan  chang  hsieh  wang    lin        train svm 
hyper parameters svm tuned cross validation training set
maximise area roc curve  using automatic grid search utility python
package scikit learn  pedregosa  varoquaux  gramfort  michel  thirion  grisel  blondel 
prettenhofer  weiss  dubourg  vanderplas  passos  cournapeau  brucher  perrot    duchesnay         assessment cross validation accuracy  in terms f  score area
roc curve  svm grammar shown table    results show
ppdb rewrites accurate employ  perhaps rules
heavily lexicalized grammars  t  grammar unpredictable use 
although svm scores considerably higher chance 
test sets used solely evaluation  making use indicators data
files words argument bearing predicates  results generated using
conll      evaluation script unmodified  report results semantic roles
 i e   combination syntactic dependencies tends yield higher scores 
using in domain out of domain evaluation data  evaluation script 
semantic propositions evaluated converting semantic dependencies
   result re training performance reported worse models
available mate website  trained partitions conll      data
 training  development test  

   

fiwoodsend   lapata

grammar
ppdb
t 
qtsg

f 
    
    
    

area roc
    
    
    

table    statistics svms performance grammar  obtained crossvalidation training set 

predicate arguments  labeling dependency labels
corresponding argument  additionally  dependency created virtual root node
predicate labeled predicate sense  comparable published
results  general report scores combine predicate sense argument role label
predictions  tables            however  focus arguments only  remove
predicate sense scores 

   results
section provide empirical evidence performance approach 
experiments primarily designed answer following questions  text rewriting
generally improve srl performance  matter transformation rules use 
i e   rules better others  transformation rules useful out ofdomain data  srl labels mostly affected rewriting  performance vary
depending size original training data  results sensitive learner
employed  first examine effect different  transformation  grammars
srl task in domain out of domain test data  move assess
labels mostly affected method  finally  present results effect
combining approach global reranker training different sized datasets 
    transformation rules improve f  across board
table    left half  shows srl performance  measured terms precision  recall  f  
in domain conll      test set  training corpora rewritten h s
system  t   qtsg  ppdb grammars  resulting srl models significantly
 p         improve model trained original corpus  used stratified shuffling  noreen        examine whether differences f  significant  pado        
recall shows largest increase  particularly acquired synchronous grammars 
indicating increased training data resulting better coverage  generally
expense precision cases apart ppdb increased well 
significant gains seen acquired grammars compared h s system 
exception t  greater variation performance 
combined rewrites produced different grammars  see t  qtsg 
ppdb t   ppdb qtsg ppdb t  qtsg table    significantly
improve performance individual grammars  although still significantly better
original model h s system   suggesting grammars capturing
   

fitext rewriting improves semantic role labeling

original
h s
ppdb
t 
qtsg
ppdb t 
ppdb qtsg
t  qtsg
ppdb qtsg t 
label projection

p
     
     
     
     
     
     
     
     
     
     

in domain
r
f 
           
           
           
           
           
           
           
           
           
           

out of domain
p
r
f 
                 
                 
                 
                 
                 
                 
                 
                 
                 
                 

table    semantic evaluation results conll      in domain out of domain test
sets  combining predicate word sense argument role labels   results
models trained original training set  baseline extension training set 
extensions due grammar combinations  label projection  results
training ppdb qtsg t  training corpus  without rewriting
labels using gold corpus information  difference original significant
p         difference h s significant p        

proportion sentences
produced grammar

h s
qtsg

produced
ppdb
   
   

grammar
t 
qtsg
   
    
   

table    sentence rewrite overlap     refined rewrite corpora produced h s 
ppdb  t  qtsg 

similar information  instance  t  qtsg extracted corpora
aligned sentence pairs  degree overlap rewrite corpora produced
grammars shown table    although degree overlap exact sentences low 
relative performance resulting models closer  discussed below   overall 
best performing system uses transformations obtained qtsg ppdb 
surprising rules extracted grammars present minimal overlap 
benefits transfer out of domain text acquired grammars  improving
overall performance even in domain data  see right half table    
f  score qtsg model    higher original model  recall
model combining acquired grammars increased       meanwhile 
rewrites h s system seem improve coverage  resulting drop recall
f  score 
   

fiwoodsend   lapata

original
ppdb
t 
qtsg

p
     
     
     
     

in domain
r
f 
           
           
           
           

out of domain
p
r
f 
                 
                 
                 
                 

table     results conll      in domain out of domain test sets  training srl
model rewrites labeled positive 

svm
thresholds count
none

      
  
      
  
    
  

  
      
 
      
 

p
     
     
     
     
     
     
     

quality
r
     
     
     
     
     
     
     

f 
     
     
     
     
     
     
     

table     effect selecting transforms svm quality resulting model
 precision  recall f  measures labeling development set  

addition  examined whether filtering set acquired transformation functions
indeed beneficial  approach proposed  transformations applied
training corpus twice  first time input svm identify reliable rewrite
rules  second pass reduced set rules applied whole training corpus 
alternative approach would apply transforms once  train srl
model  thus took rewrites labeled positive steps     algorithm  
corrected labels gold standard  step      srl models subsequently trained using
extended training corpus  created concatenating original training dataset
rewrites  table    shows srl performance different grammars  ppdb  t  
qtsg  test set  although precision f  increased original model 
gains much reduced compared results obtained using svm  table    
appears extra rewrites obtained applying generally reliable transforms
whole training set increases coverage  improves performance models 
table    shows altering quality threshold  and removing indicator features
number times transformation function extracted  affects performance 
results shown qtsg grammar  in domain  development set  we observed
similar patterns grammars grammar combinations   svm quality
threshold varied positive  no transformations accepted  negative  all
   

fitext rewriting improves semantic role labeling

original
h s
ppdb
t 
qtsg
ppdb t 
ppdb qtsg
t  qtsg
ppdb qtsg t 

p
     
     
     
     
     
     
     
     
     

in domain
r
f 
           
           
           
           
           
           
           
           
           

out of domain
p
r
f 
                 
                 
                 
                 
                 
                 
                 
                 
                 

table     performance labeling semantic arguments  predicate word sense information removed   difference original significant p         difference
h s significant p        

original
h s
ppdb
t 
qtsg
ppdb t 
ppdb qtsg
t  qtsg
ppdb qtsg t 

in domain
p
r
f 
                 
                 
                 
                 
                 
                 
                 
                 
                 

out of domain
p
r
f 
                 
                 
                 
                 
                 
                 
                 
                 
                 

table     accuracy identification classification  labeling  semantic arguments 

transformations   findings indicate constructing g transformations
positive svm weight  threshold         gives better results transformations 
permissive threshold 
    transformation rules improve semantic role assignment verbal
nominal predicates
results table   combine accuracy predicting sense predicates accuracy
labeling arguments  generally  models better assigning correct predicate
sense  interesting result much gain performance seen rewriting
training corpus comes improving semantic role assignment  appears
   

fiwoodsend   lapata



rammnr



ramloc





ramcau





ra 

















ra 
ra 
ca 





















































































































ca 
amtmp









amprd
ampnc

argument



ramtmp







amneg





ammod





ammnr







amloc



















































amdir















amcau



















































amdis

amadv







a 



a 

























a 





















a 



























a 







jj

nn

vbp

vbz

a 

nnp nns

vb

    

   






amext

change f 



vbd vbg vbn

  
  

   
occurrences




  
   

    



     

predicate

figure    changes f  score ppdb t  qtsg model original  measured
pairs predicate pos tag argument 

introducing syntactic variation training data provides model wider coverage
syntactic dependency paths predicate arguments 
table    shows results models data sets above  focusing
argument labels only  acquired grammars show biggest improvements 
   improvement recall case  gains f  score           
models data sets used table     results argument
identification only  classification  unlabelled arguments   improvements
   

fitext rewriting improves semantic role labeling



rammnr



ramloc





ramcau





ra 

















ra 
ra 
ca 











































































   







  







































ca 
amtmp









amprd
ampnc

argument



ramtmp







amneg





ammod





ammnr







amloc






















































amdir















amcau



















































amext
amdis

amadv







a 



a 

























a 





















a 



























a 







jj

nn

vbp

vbz

a 

nnp nns

vb



vbd vbg vbn

change f 
    

  

   
occurrences




  
   

    



     

predicate

figure    relative performance terms f  score qtsg  red  ppdb  blue 
models  pairs predicate pos tag argument 

original recall f   large before  showing overall
gains result improvements argument identification classification 
breakdown gains f  score predicate pos tag argument shown
figure    illustrating relative improvements model trained acquired grammars  ppdb t  qtsg  model trained original conll training data 
analysis reveals gain came increased precision recall
predicting core arguments  additional gains modifiers nominal pred   

fiwoodsend   lapata

dependency path distance
proportion test set
srl model 
original
ppdb
t 
qtsg
ppdb qtsg t 

  
     

 
     

 
    

 
    

 
    

 
    

  
    

     
     
     
     
     

     
     
     
     
     

     
     
     
     
     

     
     
     
     
     

     
     
     
     
     

     
     
     
    
     

     
    
     
     
     

table     f  scores labeled arguments distance predicate argument
measured number arcs dependency graph  results
conll in domain test set  lower rows show change f  score
original srl model 

icates  improvement losses common core arguments
 a  a   verbal predicates  striking gains seen
core argument labels  seems consistent models learning wider syntactic
coverage  figure   shows similar breakdown gains f  score predicate postag argument  time comparing improvements seen qtsg corpus
resulting ppdb  differences less pronounced  ppdb improving
core arguments more  qtsg improving performance labeling modifiers 
investigated effect label projection mechanism itself  used
rewrites produced grammars  ppdb t  qtsg  extend training set  however  instead using projected labels  used original model mgold  trained
training partition conll       label refined corpus  retrained
extended corpus used retrained model label test corpus  words 
removed step    algorithm    considered form self training  results
test out of domain sets show using automatically generated labels
instead projected ones seriously impairs resulting model  f  scores decreasing
almost    test set    out of domain set  see last row table    
    transformation rules improve performance relations involving long
dependency paths
dependency path  the sequence arcs syntactic dependency tree 
predicate argument typically short  table    shows gold labeled
test set  three quarters arguments direct dependency heads children
predicate  case nominal predicates  argument predicate itself  existing
srl models highly accurate shorter pathsthe original srl model
f  score almost    but prediction accuracy drops considerably dependency path
grows  seen table     adding rewrites training set improves prediction
accuracy almost combinations transformation grammar dependency path
distance  largest gains seen number arcs dependency path
   

fitext rewriting improves semantic role labeling

original
h s
ppdb
t 
qtsg
t  qtsg
ppdb t 
ppdb qtsg
ppdb qtsg t 

p
     
     
     
     
     
     
     
     
     

in domain
r
f 
           
           
           
           
           
           
           
           
           

out of domain
p
r
f 
                 
                 
                 
                 
                 
                 
                 
                 
                 

table     results conll test sets models combining extended training data
global reranker  difference original significant p         difference
h s significant p        

three six  improvements f  score observed individual grammars
combination  ppdb qtsg t   
    transformation rules improve performance even global
reranker used
srl system used  bjorkelund et al         optionally incorporate global
reranker  toutanova  haghighi    manning         reranker re scores complete
predicate argument structure  using features stages local pipeline additional features representing sequence core argument labels current predicate 
table    presents evaluation results global reranker trained extended corpora
produced method  compared model trained original corpus  adding
reranker provide significant improvement   training extended data gives
increases performance  smaller  though still significant 
case table    indicates global reranker compensating some 
all  new information contained extended training data 
    transformation rules improve performance across  small large 
datasets
investigated accuracy labeler function size original
training data  size  subsets original training data created  with replacement  used train srl model  performance resulting model
measured using development set  training subset  applied algorithm   
original srl model trained subset  created extended corpus
   scores reported higher official conll      ones  in domain p        r       
f         domain p        r        f         using mate tools nlp pipeline
dependency parse  rather dependency information provided test set 

   

fiwoodsend   lapata




  

  











  




  












  

  

recall

precision











rewrites



source


  



  



  

  






  

  
   

   

    

     

     



   

source sentences

   

    

     

     

source sentences

figure    srl model performance function size training data 
without additional rewrites  error bars show standard error    experiments 

subset using grammar  svm trained time refine transformations
preserved labels  srl model retrained original plus refined
rewritten version corpus subset 
particular  wanted investigate rewritten text provided performance
benefit small amount training data  benefit would
subsumed labeled training data provided  learning curves figure   show
contrary  increasing quantity source training data undoubtedly improves
quality srl model  found including rewritten training data addition
consistently improves precision recall measures  learning curves figure  
use qtsg grammar set transformation functions  obtained similar results
ppdb t   and grammar combinations   however omit sake
brevity 

   conclusions
paper investigated potential text rewriting means increasing
amount training data available supervised nlp tasks  method automatically
extracts rewrite rules comparable corpora uses generate multiple syntactic variants sentences annotated gold standard labels  application method
semantic role labeling reveals syntactic transformations improve srl performance
   

fitext rewriting improves semantic role labeling

qtsg

ppdb

hnp  npi



h np dt

hnp  npi



h np np

hnp  si



h np np

hs  si



h s even vbz

hadjp  adjpi



h adjp jj

hpp  ppi



h pp past month    pp last month i

 
 
 

jj



  np
pp

nns

    np dt

cc np



 

 



 

np

 

nns

    np np

    s np
 

 

 

pp

 

 

 

 i

 i

  i

    s even though vbz

    adjp equally jj

 

 

np

 

 i

 i

table     examples qtsg ppdb synchronous grammar rules given high importance
refinement  boxed indices indicate alignment   

beyond sate art conll      benchmark dataset  specifically  experimentally show  a  rewrite rules  whether automatic hand written  consistently
improve srl performance  although automatic variants tend perform best   b  syntactic transformations improve srl performance within  out of domain   c 
improvements observed across learners  even using global reranker 
future would explore better ways identifying best  i e   performance enhancing  rewrite rules may task grammar specific  table   
illustrates rules deemed important  i e   given high weight  svm classifier
srl task  instance  could undertake detailed feature engineering  including tree based ngram features capture grammaticality rewritten sentences 
throughout paper argued transformation rules used enhance
performance srl task  conversely  work described might
relevance nlp tasks employing rewriting  example  idea identifying
label preserving transformations  could used learn rules meaning preserving
consequently safe use tasks simplification sentence compression  machine
translation  textual entailment  semantic parsing additional application areas
stand benefit accurate rewrite rules  much methodology reported
could adapted machine translation either training larger datasets  callisonburch  koehn    osborne         domain adaptation  irvine  quirk    daume iii 
       evaluation  kauchak   barzilay       
finally  beyond supervised srl  would adapt method unsupervised
semantic role induction  lang   lapata        titov   klementiev         investigate alternative synchronous grammar extraction methods  e g   based dependency information  
obtain rewrite rules larger comparable corpora 

acknowledgments
grateful anonymous referees whose feedback helped substantially improve
present paper  acknowledge financial support epsrc  ep k         
framework chist era readers project 
   

fiwoodsend   lapata

references
aho  a  v     ullman  j  d          syntax directed translations pushdown assembler  journal computer system sciences              
bannard  c     callison burch  c       a   paraphrasing bilingual parallel corpora 
proceedings   rd annual meeting association computational linguistics  pp          ann arbor 
bannard  c     callison burch  c       b   paraphrasing bilingual parallel corpora 
proceedings   rd acl  pp          ann arbor  mi 
barzilay  r     mckeown  k          extracting paraphrases parallel corpus 
proceedings acl eacl  pp        toulouse  france 
bjorkelund  a   hafdell  l     nugues  p          multilingual semantic role labeling 
proceedings thirteenth conference computational natural language learning  conll        shared task  pp        boulder  colorado  software retrieved
https   code google com p mate tools  
callison burch  c          paraphrasing translation  ph d  thesis  university edinburgh 
callison burch  c          syntactic constraints paraphrases extracted parallel
corpora  proceedings      conference empirical methods natural
language processing  pp          honolulu  hawaii 
callison burch  c   koehn  p     osborne  m          improved statistical machine translation using paraphrases  proceedings human language technology conference
naacl  main conference  pp        new york city  usa 
chandrasekar  r   doran  c     srinivas  b          motivations methods text
simplification  proceedings   th international conference computational
linguistics  pp            copenhagen  denmark 
chiang  d          hierarchical phrase based translation  computational linguistics 
               
cohn  t     lapata  m          sentence compression tree transduction  journal
artificial intelligence research             
cohn  t     lapata  m          abstractive approach sentence compression  acm
trans  intell  syst  technol                    
coster  w     kauchak  d          simple english wikipedia  new text simplification
task  proceedings   th annual meeting association computational
linguistics  human language technologies  pp          portland  oregon  usa 
dowty  d          thematic proto roles argument selection  language             
    
eisner  j          learning non isomorphic tree mappings machine translation 
proceedings acl interactive poster demonstration sessions  pp          sapporo  japan 
   

fitext rewriting improves semantic role labeling

fan  r  e   chang  k  w   hsieh  c  j   wang  x  r     lin  c  j          liblinear 
library large linear classification  journal machine learning research    
         
feblowitz  d     kauchak  d          sentence simplification tree transduction 
proceedings second workshop predicting improving text readability
target reader populations  pp       sofia  bulgaria 
furstenau  h     lapata  m          semi supervised semantic role labeling via structural
alignment  computational linguistics                 
galley  m     mckeown  k          lexicalized markov grammars sentence compression  proceedings naacl hlt  pp          rochester  ny 
ganitkevitch  j   callison burch  c   napoles  c     van durme  b          learning
sentential paraphrases bilingual parallel corpora text to text generation 
proceedings      conference empirical methods natural language
processing  pp            edinburgh  scotland  uk 
ganitkevitch  j   cao  y   weese  j   post  m     callison burch  c          joshua     
packing  pro  paraphrases  proceedings seventh workshop statistical
machine translation  pp          montreal  canada 
ganitkevitch  j   van durme  b     callison burch  c          ppdb  paraphrase
database  proceedings      conference north american chapter
association computational linguistics  human language technologies  pp 
        atlanta  georgia  used prepackaged small constituent syntactic
subset ppdb  retrieved http   paraphrase org 
gildea  d     jurafsky  d          automatic labeling semantic roles  computational
linguistics                 
graehl  j     knight  k          training tree transducers  hlt naacl       main
proceedings  pp          boston  ma 
hajic  j   ciaramita  m   johansson  r   kawahara  d   mart  m  a   marquez  l   meyers 
a   nivre  j   pado  s   stepanek  j   stranak  p   surdeanu  m   xue  n     zhang  y 
        conll      shared task  syntactic semantic dependencies multiple
languages  proceedings thirteenth conference computational natural
language learning  conll        shared task  pp       boulder  colorado 
heilman  m     smith  n          extracting simplified statements factual question
generation  proceedings  rd workshop question generation  pp       
carnegie mellon university  pa  software available http   www ark cs cmu edu 
mheilman questions  
irvine  a   quirk  c     daume iii  h          monolingual marginal matching translation model adaptation  proceedings      conference empirical methods
natural language processing  pp            seattle  washington  usa 
kauchak  d          improving text simplification language modeling using unsimplified
text data  proceedings   st annual meeting association computational linguistics  volume    long papers   pp            sofia  bulgaria  used
   

fiwoodsend   lapata

version     sentence aligned corpus  retrieved http   www cs middlebury 
edu  dkauchak simplification  
kauchak  d     barzilay  r          paraphrasing automatic evaluation  proceedings
human language technology conference naacl  main conference  pp 
        new york city  usa 
klebanov  b  b   knight  k     marcu  d          text simplification informationseeking applications  meersman  r     tari  z   eds    move meaningful
internet systems       coopis  doa  odbase  pp          springer berlin
heidelberg 
koehn  p          statistical machine translation  cambridge university press 
koehn  p   och  f  j     marcu  d          statistical phrase based translation  proceedings hlt naacl  pp        edmonton  canada 
kundu  g     roth  d          adapting text instead model  open domain
approach  proceedings fifteenth conference computational natural language learning  pp          portland  oregon  usa 
kwiatkowski  t          probabilistic grammar induction sentences structured
meanings  ph d  thesis  university edinburgh 
lang  j     lapata  m          unsupervised semantic role induction via split merge clustering  proceedings   th annual meeting association computational
linguistics  human language technologies  pp            portland  oregon  usa 
liang  p   taskar  b     klein  d          alignment agreement  proceedings
hlt naacl  pp          new york  ny 
marton  y   callison burch  c     resnik  p          improved statistical machine translation using monolingually derived paraphrases  proceedings      conference
empirical methods natural language processing  pp          singapore 
mehdad  y   negri  m     federico  m          towards cross lingual textual entailment 
human language technologies       annual conference north american
chapter association computational linguistics  pp          los angeles 
california 
melli  g   wang  y   liu  y   kashani  m  m   shi  z   gu  b   sarkar  a     popowich  f 
        description squash  sfu question answering summary handler
duc      summarization task  proceedings human language technology conference conference empirical methods natural language
processing document understanding workshop  vancouver  canada 
noreen  e          computer intensive methods testing hypotheses  introduction 
wiley 
pado  s          users guide sigf  significance testing approximate randomisation 
retrieved http   www nlpado de  sebastian software sigf shtml 
palmer  m   gildea  d     kingsbury  p          proposition bank  annotated
corpus semantic roles  computational linguistics                
   

fitext rewriting improves semantic role labeling

pang  b   knight  k     marcu  d          syntax based alignment multiple translations 
extracting paraphrases generating new sentences  proceedings naacl 
pp          edmonton  canada 
park  j  h   croft  b     smith  d  a          quasi synchronous dependence model
information retrieval  proceedings   th acm international conference
information knowledge management  pp        glasgow  united kingdom 
pedregosa  f   varoquaux  g   gramfort  a   michel  v   thirion  b   grisel  o   blondel 
m   prettenhofer  p   weiss  r   dubourg  v   vanderplas  j   passos  a   cournapeau 
d   brucher  m   perrot  m     duchesnay  e          scikit learn  machine learning
python  journal machine learning research               
shen  d     lapata  m          using semantic roles improve question answering 
proceedings      joint conference empirical methods natural language
processing computational natural language learning  emnlp conll   pp    
    prague  czech republic 
surdeanu  m   harabagiu  s   williams  j     aarseth  p          using predicate argument
structures information extraction  proceedings annual meeting
association computational linguistics  pp       sapporo  japan 
titov  i     klementiev  a          bayesian approach unsupervised semantic role
induction  proceedings   th conference european chapter
association computational linguistics  pp        avignon  france 
toutanova  k   haghighi  a     manning  c          joint learning improves semantic role
labeling  proceedings   rd annual meeting association computational linguistics  acl     pp          ann arbor  michigan 
vapnik  v          nature statistical learning theory  springer verlag new york 
inc 
vickrey  d     koller  d          sentence simplification semantic role labeling 
proceedings acl     hlt  pp          columbus  ohio 
wang  m     manning  c          probabilistic tree edit models structured latent
variables textual entailment question answering  proceedings   rd
international conference computational linguistics  coling        pp           
beijing  china 
wang  m   smith  n  a     mitamura  t          jeopardy model  quasisynchronous grammar qa  proceedings      joint conference empirical methods natural language processing computational natural language
learning  emnlp conll   pp        prague  czech republic 
woodsend  k     lapata  m          learning simplify sentences quasi synchronous
grammar integer programming  proceedings      conference empirical methods natural language processing  pp          edinburgh  scotland  uk 
used wikipedia revisions corpus  retrieved http   homepages inf ed 
ac uk kwoodsen wiki html 
woodsend  k     lapata  m          multiple aspect summarization using integer linear
programming  proceedings      joint conference empirical methods
   

fiwoodsend   lapata

natural language processing computational natural language learning  pp 
        jeju island  korea 
wu  d          stochastic inversion transduction grammars bilingual parsing
parallel corpora  computational linguistics                 
wu  d     fung  p          semantic roles smt  hybrid two pass model  proceedings human language technologies  annual conference north american
chapter association computational linguistics  companion volume  short
papers  pp        boulder  colorado 
yamada  k     knight  k          syntax based statistical translation model  proceedings   th annual meeting association computational linguistics 
pp          toulouse  france 
yamangil  e     nelken  r          mining wikipedia revision histories improving
sentence compression  proceedings acl     hlt  short papers  pp         
columbus  ohio 
zanzotto  f  m     pennacchiotti  m          expanding textual entailment corpora
fromwikipedia using co training  proceedings  nd workshop peoples web meets nlp  collaboratively constructed semantic resources  pp       
beijing  china  coling      organizing committee 
zhu  z   bernhard  d     gurevych  i          monolingual tree based translation model
sentence simplification  proceedings   rd international conference
computational linguistics  pp            beijing  china 

   


