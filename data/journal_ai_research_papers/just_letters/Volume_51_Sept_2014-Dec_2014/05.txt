journal of artificial intelligence research          

submitted        published      

using meta mining to support data mining workflow
planning and optimization
phong nguyen
melanie hilario

phong nguyen unige ch
melanie hilario unige ch

department of computer science
university of geneva
switzerland

alexandros kalousis

alexandros kalousis hesge ch

department of business informatics
university of applied sciences
western switzerland  and
department of computer science
university of geneva
switzerland

abstract
knowledge discovery in databases is a complex process that involves many different
data processing and learning operators  todays knowledge discovery support systems
can contain several hundred operators  a major challenge is to assist the user in designing
workflows which are not only valid but also  ideally  optimize some performance measure
associated with the user goal  in this paper we present such a system  the system relies
on a meta mining module which analyses past data mining experiments and extracts metamining models which associate dataset characteristics with workflow descriptors in view of
workflow performance optimization  the meta mining model is used within a data mining
workflow planner  to guide the planner during the workflow planning  we learn the metamining models using a similarity learning approach  and extract the workflow descriptors
by mining the workflows for generalized relational patterns accounting also for domain
knowledge provided by a data mining ontology  we evaluate the quality of the data mining
workflows that the system produces on a collection of real world datasets coming from
biology and show that it produces workflows that are significantly better than alternative
methods that can only do workflow selection and not planning 

   introduction
learning models and extracting knowledge from data using data mining can be an extremely
complex process which requires combining a number of data mining  dm  operators  selected from large pools of available operators  combined into a data mining workflow  a dm
workflow is an assembly of individual data transformations and analysis steps  implemented
by dm operators  composing a dm process with which a data analyst chooses to address
his her dm task  workflows have recently emerged as a new paradigm for representing and
managing complex computations accelerating the pace of scientific progress  their  meta  
analysis is becoming increasingly challenging with the growing number and complexity of
available operators  gil et al         
c
    
ai access foundation  all rights reserved 

finguyen  hilario   kalousis

todays second generation knowledge discovery support systems  kdss  allow complex
modeling of workflows and contain several hundreds of operators  the rapidminer platform  klinkenberg  mierswa    fischer         in its extended version with weka  hall
et al         and r  r core team         proposes actually more than     operators  some
of which can have very complex data and control flows  e g  bagging or boosting operators 
in which several sub workflows are interleaved  as a consequence  the possible number of
workflows that can be modeled within these systems is on the order of several millions 
ranging from simple to very elaborated workflows with several hundred operators  therefore the data analyst has to carefully select among those operators the ones that can be
meaningfully combined to address his her knowledge discovery problem  however  even the
most sophisticated data miner can be overwhelmed by the complexity of such modeling 
having to rely on his her experience and biases as well as on thorough experimentation in
the hope of finding the best operator combination  with the advance of new generation
kdss that provide even more advanced functionalities  it becomes important to provide
automated support to the user in the workflow modeling process  an issue that has been
identified as one of the top ten challenges in data mining  yang   wu        

   state of the art in dm workflow design support
during the last decade  a rather limited number of systems have been proposed to provide
automated user support in the design of dm workflows  bernstein  provost  and hill       
propose an ontology based intelligent discovery assistant  ida  that plans valid dm workflows  valid in the sense that they can be executed without any failure  according to basic
descriptions of the input dataset such as attribute types  presence of missing values  number
of classes  etc  by describing into a dm ontology the input conditions and output effects of
dm operators  according to the three main steps of the kd process  pre processing  modeling and post processing  fayyad  piatetsky shapiro    smyth         ida systematically
enumerates with a workflow planner all possible valid operator combinations  workflows 
that fulfill the data input request  a ranking of the workflows is then computed according
to user defined criteria such as speed or memory consumption which are measured from
past experiments 
zakova  kremen  zelezny  and lavrac        propose the kd ontology to support automatic design of dm workflows for relational dm  in this ontology  dm relational algorithms
and datasets are modeled with the semantic web language owl dl  providing semantic
reasoning and inference in querying over a dm workflow repository  similar to ida  the
kd ontology describes dm algorithms with their data input output specifications  the
authors have developed a translator from their ontology representation to the planning domain definition language  pddl   mcdermott et al          with which they can produce
abstract directed acyclic graph workflows using a ff style planning algorithm  hoffmann 
       they demonstrate their approach on genomic and product engineering  cad  usecases where complex workflows are produced that make use of relational data structure and
background knowledge 
more recently  the e lico project  featured another ida built upon a planner which
constructs dm plans following a hierarchical task networks  htn  planning approach  the
   http   www e lico eu

   

fiusing meta mining to support dm workflow planning and optimization

specification of the htn is given in the data mining workflow  dmwf  ontology  kietz 
serban  bernstein    fischer         as its predecessors  the e lico ida has been designed
to identify operators whose preconditions are met at a given planning step in order to plan
valid dm workflows and does an exhaustive search in the space of possible dm plans 
none of the three dm support systems that we have just discussed consider the eventual
performance of the workflows they plan with respect to the dm task that they are supposed
to address  for example  if our goal is to plan design workflows that solve a classification
problem  we would like to consider a measure of classification performance  such as accuracy 
and deliver workflows that optimize it  all the discussed dm support systems deliver an
extremely large number of plans  dm workflows  which are typically ranked with simple
heuristics  such as workflow complexity or expected execution time  leaving the user at a
loss as to which is the best workflow in terms of the expected performance in the dm task
that he she needs to address  even worse  the planning search space can be so large that
the systems can even fail to complete the planning process  see for example the discussion
by kietz  serban  bernstein  and fischer        
there has been considerable work that tries to support the user  in view of performance
maximization  for a very specific part of the dm process  that of modeling or learning  a
number of approaches have been proposed  collectively identified as meta learning  brazdil 
giraud carrier  soares    vilalta        kalousis        kalousis   theoharis        hilario        soares   brazdil         the main idea in meta learning is that given a new
dataset the system should be able to rank a pool of learning algorithms with respect to their
expected performance on the dataset  to do so  one builds a meta learning model from the
analysis of past learning experiments  searching for associations between algorithms performances and dataset characteristics  however  as already mentioned  all meta learning
approaches address only the learning modeling part and are not applicable on the complete
process level 
in the work of hilario  nguyen  do  woznica  and kalousis         we did a first effort to
lift meta learning ideas to the level of complete dm workflows  we proposed a novel metalearning framework that we called meta mining or process oriented meta learning applied
on the complete dm process  we associate workflow descriptors and dataset descriptors 
applying decision tree algorithms on past experiments  in order to learn which couplings of
workflows and datasets will lead to high predictive performance  the workflow descriptors
were extracted using frequent pattern mining accommodating also background knowledge 
given by the data mining optimization  dmop  ontology  on dm tasks  operators  workflows  performance measures and their relationships  however the predictive performance
of the system was rather low  due to the limited capacity of decision trees in capturing
the relations between the dataset and the workflow characteristics that were essential for
performance prediction 
to address the above limitation  we presented in the work of nguyen  wang  hilario  and
kalousis      b  an approach that learns what we called heterogeneous similarity measures 
associating dataset and workflow characteristics  there we learn similarity measures in
the dataset space  the workflow space  and the dataset workflow space  these similarity
measures reflect respectively  the similarity of the datasets as it is given by the similarity of
the relative workflow performance vectors of the workflows that were applied on them  the
similarity of the workflows given by their performance based similarity on different datasets 
   

finguyen  hilario   kalousis

the dataset workflow similarity based on the expected performance of the latter applied on
the former  however the two meta mining methods described here were limited to select
from  or rank  a set of given workflows according to their expected performance  i e  they
cannot plan new workflows given an input dataset 
retrospectively  we presented in the work of nguyen  kalousis  and hilario        an
initial blueprint of an approach that does dm workflow planning in view of workflow performance optimization  there we suggested that the planner should be guided by a metamining model that ranks partial candidate workflows at each planning step  we also gave a
preliminary evaluation of the proposed approach with interesting results  nguyen  kalousis 
  hilario      a   however  the meta mining module was rather trivial  it uses dataset and
pattern based workflow descriptors and does a nearest neighbor search over the dataset descriptors to identify the most similar datasets to the dataset for which we want to plan
the workflows  within that neighborhood  it ranks the partial workflows using the support
of the workflow patterns on the workflows that perform best on the datasets of the neighborhood  the pattern based ranking of the workflows was cumbersome and heuristic  the
system was not learning associations of dataset and workflow characteristics which explicitly optimize the expected workflow performance  which is what must guide the workflow
planning  this approach was then deployed by kietz et al         
in this paper  we follow the line of work we first sketched in the work of nguyen et al 
        we couple tightly together a workflow planning and a meta mining module to
develop a dm workflow planning system that given an input dataset designs workflows
that are expected to optimize the performance on the given dataset  the meta mining
module applies the heterogeneous similarity learning method presented by nguyen et al 
     b  to learn associations between dataset and workflow descriptors that lead to optimal
performance  it exploits then the learned associations to guide the planner in the workflow
construction during the planning  to the best of our knowledge  it is the first system
of its kind  i e  being able to design dm workflows that are specifically tailored to the
characteristics of the input dataset in view of optimizing a dm task performance measure 
we evaluate the system on a number of real world datasets and show that the workflows it
plans are significantly better than the workflows delivered by a number of baseline methods 
the rest of this paper is structured as follows  in section    we present the global architecture of the system  together with a brief description of the planner  in section   we
describe in detail the meta mining module  including the dataset and workflow characteristics it uses  the learning model  and how the learned model is used for workflow planning 
in section    we provide detailed experimental results and evaluate our approach in different
settings  finally  we conclude in section   

   system description
in this section  we will provide a general description of the system  we will start by defining
the notations that we will use throughout the paper and then give a brief overview of the
different components of the system  its two most important components  the planner and
the meta miner will be described in subsequent sections      and   respectively   we will
close the section by providing the formal representation of the dm workflows which we will
use in the planner and the meta miner 
   

fiusing meta mining to support dm workflow planning and optimization

symbol
o
e
wl    o            ol  
wcl    i p  t wl            i p p   t wl   t
xu    x            xd  t
r x  w 
g
t
m
o    o            on  
cl
sl

meaning
a workflow operator 
a workflow data type 
a ground dm workflow as a sequence of l operators 
the fixed length  p   dimensional vector description
of a workflow wl
the d dimensional vector description of a dataset 
the relative performance rank of w workflow on x
dataset
a dm goal 
a htn task 
a htn method 
a htn abstract operator with n possible operators 
a set of candidate workflows at some abstract operator o 
a set of candidate workflows selected from cl  

table    summary of notations used 
    notations
we will provide the most basic notations here and subsequently introduce additional notations as they are needed  we will use the term dm experiment to designate the execution of
a dm workflow w  w on a dataset x  x   we will describe a dataset x by a d dimensional
column vector xu    x          xd  t   we describe in detail in section       the dataset descriptions that we use  each experiment will be characterized by some performance measure 
for example if the mining problem we are addressing is a classification problem one such
performance measure can be the accuracy  from the performance measures of the workflows
applied on a given dataset x we will extract the relative performance rank r x  w   r  of
each workflow w for the x dataset  we will do so by statistically comparing the performance
differences of the different workflows for the given dataset  more on that in section        
the matrix x   n  d contains the descriptions of n datasets that will be used for the training of the system  for a given workflow w we will have two representations  wl will denote
the l length operator sequence that constitutes the workflow  note that different workflows
can have different lengths  so this is not a fixed length representation  wcl will denote the
fixed length  p   dimensional binary vector representation of the w workflow  each feature
of wcl indicates the presence or absence of some relational feature pattern in the workflow 
essentially wcl is the propositional representation of the workflow  we will describe in more
detail in section       how we extract this propositional representation  finally w denotes
a collection of m workflows  which will be used in the training of the system  and w is the
corresponding m   p   matrix that contains their propositional representations  depending on the context the different workflow notations can be used interchangeably  table  
summarizes the most important notations 
    system architecture and operational pipeline
we provide in figure   a high level architectural description of our system  the three blue
shaded boxes are   i  the data mining experiment repository  dmer  which stores all the
   

finguyen  hilario   kalousis

input data

   user interface
goal
input md

  

input md

dmer

optimal plans   

training md

metaminer

intelligent discovery assistant  ida 

 partial  candidate workflows
ai
planner

dm workflow
ontology  dmwf 

workflow ranking
  

online
mode

metamined
model

offline
mode

  

dm optimization
ontology  dmop 

software
data flow

figure    the meta mining systems components and its pipeline 
base level resources  i e  training datasets  workflows  as well as the performance results
of the application of the latter on the former  essentially dmer contains the training data
that will be used to derive the models that will be necessary for the workflow planning and
design   ii  the user interface through which the user interacts with the system  specifying
data mining tasks and input datasets and  iii  the intelligent discovery assistant  ida 
which is the component that actually plans data mining workflows that will optimize some
performance measure for a given dataset and data mining task that the user has provided
as input  ida constitutes the core of the system and contains a planning component and a
meta mining component which interact closely in order to deliver optimal workflows for the
given input problem  we will describe these two components in detail in sections     and  
respectively  the system operates in two modes  an offline and an online mode  in the offline
mode the meta mining component analyses past base level data mining experiments  which
are stored in the dmer  to learn a meta mining model that associates dataset and workflow
characteristics in view of performance optimization  in the online mode the meta miner
interacts with the planner to guide the planning of the workflows using the meta mining
model 
we will now go briefly through the different steps of the systems life cycle  we first
need to collect in the dmer a sufficient number of base level data mining experiments 
i e  applications of different data mining workflows on different datasets  step     these
experiments will be used in step   by the meta miner to generate a meta mining model 
more precisely we extract from the base level experiments a number of characteristics that
describe the datasets and the workflows and the performance that the latter achieved when
applied on the former  from these meta data the meta miner learns associations of dataset
and workflow characteristics that lead to high performance  it does so by learning a heterogeneous similarity measure which outputs a high similarity of a workflow to a dataset if
the former is expected to achieve a high performance when it will be applied to the latter
 more details in section      
once the model is learned  the offline phase is completed and the online phase can
start  in the online phase the system directly interacts with its user  a given user can
select a data mining task g  g  such as classification  regression  clustering  etc  as well
   

fiusing meta mining to support dm workflow planning and optimization

as an input dataset on which the task should be applied  he or she might also specify the
number of top k optimal workflows that should be planned  step     given a new task
and an input dataset the action is transfered in the ida where the ai planner starts the
planning process  at each step of the planning process the ai planner generates a list of
valid actions  partial candidate workflows  which it passes for ranking to the meta miner
according to their expected performance on the given dataset  step    the meta miner
ranks them using the learned meta mining model and the planning continues with the topranked partial candidate workflows until the data mining task is resolved  at the end of
this planning process  the top k workflows are presented to the user in the order given
by their expected performance on the input dataset  this is a greedy planning approach
where at each step we select the top k current solutions  in principle we can let the aiplanner first generate all possible workflows and then have the meta miner rank them 
then the resulting plans would not be ranked according to a local greedy approach  but
they would be ranked globally and thus optimally with respect to the meta mining model 
however in general this is not feasible due to the complexity of the planning process and
the combinatorial explosion in the number of plans 
    dm workflow representation
we will now give a formal definition of a dm workflow and how we represent it  dm
workflows are directed acyclic typed graphs  dags   in which nodes correspond to operators
and edges between nodes to data input output objects  in fact they are hierarchical dags
since they can have dominating nodes operators that contain sub workflows  a typical
example is the cross validation operator whose control flow is given by the parallel execution
of training sub workflows  or a complex operator such as boosting  more formally  let 
 o be the set of all available operators that can appear in a dm workflow  e g  classification operators  such as j    svms  etc  o also includes dominating operators
which are defined by one or more sub workflows they dominate  an operator o  o
is defined by its name through a labelling function  o   the data types e  e of its
inputs and outputs  and its direct sub workflows if o is a dominating operator 
 e be the set of all available data types that can appear in a dm workflow  namely
the data types of the various i o objects that can appear in a dm workflow such as
models  datasets  attributes  etc 
the graph structure of a dm workflow is a pair  o   e     which also contains all subworkflows if any  o  o is the set of vertices which correspond to all the operators used in
this dm workflow and its sub workflow s   and e   e is the set of pairs of nodes   oi   oj   
directed edges  that correspond to the data types of the output input objects  that are
passed from operator oi to operator oj   following this graph structure  the topological sort
of a dm workflow is a permutation of the vertices of the graph such that an edge  oi   oj  
implies that oi appears before oj   i e  this is a complete ordering of the nodes of a directed
acyclic graph which is given by the node sequence 
wl    o        ol  
   

   

finguyen  hilario   kalousis

legend
input   output edges
sub input   output edges
x
x

end

retrieve

basic nodes
output

composite nodes

result
x validation
split

training set

join

test set

weight by information gain

weights
example set
apply model
performance
select by weights
labelled data
training set
performance
naive bayes
model

figure    example of a dm workflow that does performance estimation of a combination
of feature selection and classification algorithms 

where the subscript in wl denotes the length l  i e  number of operators  of the topological
sort  the topological sort of a dm workflow can be structurally represented with a rooted 
labelled and ordered tree  bringmann        zaki         by doing a depth first search over
its graph structure where the maximum depth is given by expanding recursively the subworkflows of the dominating operators  thus the topological sort of a workflow or its tree
representation is a reduction of the original directed acyclic graph where the nodes and
edges have been fully ordered 
an example of the hierarchical dag representing a rapidminer dm workflow is given in
figure    the graph corresponds to a dm workflow that cross validates a feature selection
method followed by a classification model building step with the naivebayes classifier  xvalidation is a typical example of a dominating operator which itself is a workflow  it has
two basic blocks  a training block which can be any arbitrary workflow that receives as
input a dataset and outputs a model  and a testing block which receives as input a model
and a dataset and outputs a performance measure  in particular  we have a training subworkflow  in which feature weights are computed by the informationgain operator  after
which a number of features is selected by the selectbyweights operator  followed by the
final model building by the naivebayes operator  in the testing block  we have a typical
sub workflow which consists of the application of the learned model on the testing set with
the applymodel operator  followed by a performance estimation given by the performance
operator  the topological sort of this graph is given by the ordered tree given in figure   
   

fiusing meta mining to support dm workflow planning and optimization

retrieve
 

weight by
information gain
 

select by
weights
 

x validation
   

naive
bayes
 

end
 

apply
model
 

performance
 

figure    the topological order of the dm workflow given in figure   

    workflow planning
the workflow planner we use is based on the work of kietz et al                and designs
dm workflows using a hierarchical task network  htn  decomposition of the crisp dm process model  chapman et al          however this planner only does workflow enumeration
generating all possible plans  i e  it does not consider the expected workflow performance
during the planning process and does not scale to large set of operators which explode the
search space  in order to address these limitations  we presented some preliminary results
in which the planner was coupled with a frequent pattern meta mining algorithm and a
nearest neighbor algorithm to rank the partial workflows at each step of the workflow planning  nguyen et al             a   this system was also deployed by kietz et al         
the approach we followed was to prioritize the partial workflows according to the support
that the frequent patterns they contained achieved on a set of workflows that performed
well on a set of datasets that were similar to the input dataset for which we want to plan
the workflow  however we were not learning associations between dataset and workflow
characteristics  which is the approach we follow here 
in section       we briefly describe the htn planner of kietz et al                and
in section       we describe how we use the prediction of the expected performance of a
partial workflow applied on a given dataset to guide the htn planner  we will give the
complete description of our meta mining module that learns associations of dataset and
workflow characteristics that are expected to achieve high performance in section   
      htn planning
given some goal g  g  the ai planner will decompose in a top down manner this goal into
elements of two sets  tasks t and methods m   for each task t  t that can achieve g 
there is a subset m   m of associated methods that share the same data input output
 i o  object specification with t and that can address it  in turn  each method m  m 
defines a sequence of operators  and or abstract operators  see below   and or sub tasks 
which executed in that order can achieve m  by recursively expanding tasks  methods and
operators for the given goal g  the ai planner will sequentially construct an htn plan
in which terminal nodes will correspond to operators  and non terminal nodes to htn
task or method decompositions  or to dominating operators  x validation for instance will
dominate a training and a testing sub workflows   an example of an htn plan is given
   

finguyen  hilario   kalousis

evaluateattributeselectionclassification
x validation
in  dataset
out  performance

attributeselection
classificationtraining

classification
training

attributeselection
training

attribute
weighting
operator
in  dataset
out  attributeweights

select by
weights
in  dataset
in  attributeweights
out  dataset

predictive
supervised
learner
in  dataset
out  predictive
model

attributeselection
classificationtesting

model
application
apply
model
in  dataset
in  predictive
model
out  labelled
dataset

model
evaluation
in  labelled
dataset
out  performance

figure    the htn plan of the dm workflow given in figure    non terminal nodes are
htn tasks methods  except for the dominating operator x validation  abstract
operators are in bold and simple operators in italic  each of which is annotated
with its i o specification 

in figure    this plan corresponds to the feature selection and classification workflow of
figure   with exactly the same topological sort  of operators  given in figure   
the sets of goals g  tasks t   methods m   and operators o  and their relations  are
described in the dmwf ontology  kietz et al          there  methods and operators are
annotated with their pre  and post conditions so that they can be used by the ai planner 
additionally  the set of operators o has been enriched with a shallow taxonomic view in
which operators that share the same i o object specification are grouped under a common
ancestor 
o    o            on  

   

where o defines an abstract operator  i e  an operator choice point or alternative among a set
of n syntactically similar operators  for example  the abstract attributeweighting operator
given in figure   will include any feature weighting algorithms such as informationgain or
relieff  and similarly the abstract predictive supervised learner operator will contain any
classification algorithms such as naivebayes or a linear svm 
the htn planner can also plan operators that can be applied on each attribute  e g 
a continuous attribute normalization operator  or a discretization operator  it uses cyclic
planning structures to apply them on subsets of attributes  in our case we use its attributegrouping functionality which does not require the use of cyclic planning structures  more
precisely if such an operator is selected for application it is applied on all appropriate
attributes  overall the htn grammar contains descriptions of    different tasks and more
   

fiusing meta mining to support dm workflow planning and optimization

than     operators  over which the planner can plan  these numbers are only limited by the
modeling effort required to describe the tasks and the operators  they are not an inherent
limitation of the htn grammar planner  kietz et al         have developed a module for
the open source ontology editor protege called e proplan  to facilitate the modelling of
new operators and describe task method decomposition grammars for dm problems in the
dmwf ontology 
      the workflow selection task
the ai planner designs during the construction of an htn plan several partial workflows 
each of which will be derived by substituting an abstract operator o with one of its n
operators  the number of planned workflows can be in the order of several thousands
which will leave the user at a loss as to which workflow to choose for her his problem 
even worse  it is possible that the planning process never succeeds to find a valid plan and
terminate due to the complexity of the search space 
to support the user in the selection of dm workflows  we can use a post planning approach in which the designed workflows will be evaluated according to some evaluation
measure in order to find the k ones that will be globally the best for the given mining problem  however  this global approach will be very computational expensive in the planning
phase as we mentioned above  instead  we will follow here a planning approach in which we
will locally guide the ai planner towards the design of dm workflows that will be optimized
for the given problem  avoiding thus the need to explore the whole planning search space 
clearly  by following a local approach the cost that one has to pay is a potential reduction
in performance since not all workflows are explored and evaluated  potentially missing good
ones due to the greedy nature of the plan construction 
we adopt a heuristic hill climbing approach to guide the planner  at each abstract
operator o we need to determine which of the n candidate operators o  o are expected to
achieve the best performance on the given dataset  more formally  we will define by 
cl     wlo    wl   sl   o  o  kn

   

the set of k  n partial candidate workflows of length l which are generated from the
expansion of an abstract operator o by adding one of the n candidate operators o  o to
one of the k candidate workflows of length l    that constitute the set sl  of workflows
selected in the previous planning step  s  is the empty set see below   now let xu be a vector
description of the input dataset for which we want to plan workflows which address some
data mining goal g and optimize some performance measure  moreover let wclo be a binary
vector that provides a propositional representation of the wlo workflow with respect to the
set of generalized relational frequent workflow patterns that it contains    we construct the
set sl of selected workflows at the current planning step according to 
sl     arg max r xu   wclo  g  k

   

 wlo cl  

   available at http   www e lico eu eproplan html
   we will provide a detailed description of how we extract the wclo descriptors in section        for the
moment we note that these propositional representations are fixed length representations  that do not
depend on l 

   

finguyen  hilario   kalousis

where r xu   wclo  g  is the estimated performance of a workflow with the propositional description wclo when applied to a dataset with description xu   i e  at each planning step
we select the best current partial workflows according to their estimated expected performance  it is the meta mining model  that we learn over past experiments  that delivers
the estimations of the expected performance  in section     we describe how we derive the
meta mining models and how we use them to get the estimates of the expected performance 
we should stress here that in producing the performance estimate r xu   wclo  g  the
meta mining model uses the workflow description wclo   and not just the candidate operator descriptions  these pattern based descriptions capture dependencies and interactions
between the different operators of the workflows  again more on the wclo representation in
section         this is a rather crucial point since it is a well known fact that when we construct data mining workflows we need to consider the relations of the biases of the different
algorithms that we use within them  some bias combinations are better than others  the
pattern based descriptions that we will use provide precisely that type of information  i e 
information on the operator combinations appearing within the workflows 
in the next section we will provide the complete description of the meta miner module 
including how we characterize datasets  workflows and the performance of the latter applied
to the former  and of course how we learn the meta mining models and use them in planning 

   the meta miner
the meta miner component operates in two modes  in the offline mode it learns from
past experimental data a meta mining model which provides the expected performance
estimates r xu   wclo  g   in the on line mode it interacts with the ai planner at each step
of the planning process  delivering the r xu   wclo  g  estimates which are used by the planner
to select workflows at each planning step according to eq     
the rest of the section is organised as follows  in subsection       we explain how we
describe the datasets  i e  how we derive the xu dataset descriptors  in subsection       how
we derive the propositional representation wclo of the data mining workflows and in subsection       how we rank the workflows according to their performance on a given dataset  i e 
r xu   wclo  g   finally in subsection     we explain how we build models from past mining
experiments which will provide the expected performance estimations r xu   wclo  g  and how
we use these models within the planner 
    meta data and performance measures
in this section we will describe the meta data  namely dataset and workflow descriptions 
and the performance measures that are used by the meta miner to learn meta mining models
that associate dataset and workflow characteristics in view of planning dm workflows that
optimize a performance measure 
      dataset characteristics
the idea to characterize datasets has been a full fledged research problem from the early
inception of meta learning until now  michie  spiegelhalter  taylor    campbell       
kopf  taylor    keller        pfahringer  bensusan    giraud carrier         soares  
   

fiusing meta mining to support dm workflow planning and optimization

brazdil        hilario   kalousis        peng  flach  soares    brazdil        kalousis 
gama    hilario         following state of art dataset characteristics  we will characterize
a dataset x  x by the three following groups of characteristics 
 statistical and information theoretic measures  this group refers to data characteristics
defined in the statlog  michie et al         king  feng    sutherland        and
metal projects   soares   brazdil         and it includes number of instances 
number of classes  proportion of missing values  proportion of continuous   categorical
features  noise signal ratio  class entropy  mutual information  they mainly describe
attribute statistics and class distributions of a given dataset sample 
 geometrical and topological measures  this group concerns new measures which try
to capture geometrical and topological complexity of class boundaries  ho   basu 
             and it includes non linearity  volume of overlap region  maximum fishers
discriminant ratio  fraction of instance on class boundary  ratio of average intra inter
class nearest neighbour distance 
 landmarking and model based measures  this group is related to measures asserted
with fast machine learning algorithms  so called landmarkers  pfahringer et al         
and its derivative based on the learned models  peng et al          and it includes error
rates and pairwise  p values obtained by landmarkers such as  nn or decisionstump 
and histogram weights learned by relief or svm  we have extended this last group
with new landmarking methods based on the weight distribution of feature weighting
algorithms such as relief or svm where we have build twenty different histogram
representations of the discretized feature weights 
overall  our system makes use of a total of d       numeric characteristics to describe
a dataset  we will denote this vectorial representation of a dataset x  x by xu   we
have been far from exhaustive in the dataset characteristics that we used  not including
characteristics such as subsampling landmarks  leite   brazdil         our main goal in
this work is not to produce a comprehensive set of dataset descriptors but to design a dm
workflow planning system that given a set of dataset characteristics  coupled with workflow
descriptors  can plan dm workflows that optimize some performance measure 
      workflow characteristics
as we have seen in section     workflows are graph structures that can be quite complex
containing several nested sub structures  these are very often difficult to analyze not only
because of their spaghetti like structure but also because we do not have any information
on which subtask is addressed by which workflow component  van der aalst   giinther 
       process mining addresses this problem by mining for generalized patterns over
workflow structures  bose   der aalst        
to characterize dm workflows we will follow a process mining like approach  we will
extract generalized  relational  frequent patterns over their tree representations  that we
will use to derive propositional representations of them  the possible generalizations will
   http   www metal kdd org 

   

finguyen  hilario   kalousis

dm algorithm
dataprocessing
algorithm

predictivemodelling
algorithm

featureweighting
algorithm

classificationmodelling
algorithm

learnerfreefw
algorithm

univariatefw
algorithm

multivariatefw
algorithm

missingvalues
tolerant
algorithm

irrelevant
tolerant
algorithm

exactcos
based
algorithm

c   

naive
bayes

svm

entropybasedfw
algorithm

ig

relieff
is followed by

is implemented by

figure    a part of the dmops algorithm taxonomies  short dashed arrows represent the
is followed by relation between dm algorithms  and long dashed arrows represent the is implemented by relation between dm operators and dm algorithms 

 a 

 b 

x validation

 c 

x validation

feature
weighting
algorithm

classification
modeling
algorithm

feature
weighting
algorithm

classification
modeling
algorithm

univariatefw
algorithm

irrelevant
tolerant
algorithm

learnerfreefw
algorithm

missingvalues
tolerant
algorithm

entropybasedfw
algorithm

x validation
feature
weighting
algorithm

classification
w
algorithm
exactcos
based
algorithm

figure    three workflow patterns with cross level concepts  thin edges depict workflow
decomposition  double lines depict dmops concept subsumption 

be described by domain knowledge which  among other knowledge  will be given by a data
mining ontology  we will use the data mining optimization  dmop  ontology  hilario
et al                briefly  this ontology provides a formal conceptualization of the dm
domain by describing dm algorithms and defining their relations in terms of dm tasks 
models and workflows  it describes learning algorithms such as c     naivebayes or svm 
according to their learning behavior such as their bias variance profile  their sensitivity to
the type of attributes  etc  for instance  the algorithms cited above are all tolerant to irrelevant attributes  but only c    and naivebayes algorithms are tolerant to missing values 
whereas only the svm and naivebayes algorithms have an exact cost function  algorithm characteristics and families are classified as taxonomies in dmop under the primitive
   

fiusing meta mining to support dm workflow planning and optimization

concept of dm algorithm  moreover  dmop specifies workflow relations  algorithm order 
with the is followed by relation and relates workflow operators with dm algorithms with
the is implemented by relation  figure   shows a snapshot of the dmops algorithm taxonomies with ground operators at the bottom related to the dm algorithms they implement 
to mine generalized relational patterns from dm workflows  we will follow the method
presented by hilario et al          first  we use the dmop ontology to annotate a set w
of workflows  then  we extract from this set generalized patterns using a frequent pattern
mining algorithm  concretely  for each operator contained in the parse tree of a training dm
workflow wl  w   we insert into the tree branch above the operator the taxonomic concepts 
ordered from top to bottom  that are implemented by this operator  as these are given in
the dmop  the result is a new parse tree that has additional nodes which are dmops
concepts  we will call this parse tree an augmented parse tree  we then reorder the nodes
of each augmented parse tree to to satisfy dmops algorithm taxonomies and relations  for
example a feature selection algorithm is typically composed of a feature weighting algorithm
followed by a decision rule that selects features according to some heuristics  the result
is a set of augmented and reordered workflow parse trees  over this representation  we
apply a tree mining algorithm  zaki        to extracts a set p of frequent patterns  each
pattern corresponds to a tree that appears frequently within the augmented parse trees 
we mine patterns that have a support higher or equal to five  in principle we can go as
low as a support of one  exploding the dimensionality of the description of workflows  with
what probably will be features of poor discriminatory power  nevertheless since our metamining models rely on metric learning  which is able to learn the importance of the different
meta features  they would be able to cope also with such a scenario  note that to extract
the workflow characteristics we could have used other different techniques such as graph
mining directly over the graph structures defined by the workflows and the ontology  the
main reason for not doing that was the computational cost of the latter approaches  as well
as the fact that frequent pattern mining propositionalization is known to work very well 
in figure   we give examples of the mined patterns  note that the extracted patterns are
generalized  in the sense that they contain entities defined at different abstraction levels 
as these are provided by the dmop ontology  they are relational because they describe
relations  such as order relations  between the structures that appear within a workflow 
and they also contain properties of entities as these are described in the dmop ontology  for
example pattern  c  of figure   states that we have a feature weighting algorithm  abstract
concept  followed by  relation  a classification algorithm that has an exact cost function
 property   within a cross validation 
we use the set p of frequent workflow patterns to describe any dm workflow wl  w
through the patterns p  p that this wl workflow contains  the propositional description
of a workflow wl is given by the  p   length binary vector 
wcl    i p  t wl            i p p   t wl   t         p  

   

where t denotes the induced tree relation  zaki        and i pi t wl   returns one if the
frequent pattern  pi   appears within the workflow and zero otherwise 
we will use this propositional workflow representation together with a tabular representation of the datasets characteristics to learn the meta mining models which we will describe
in the next section  although we could have used tree or even graph properties to represent
   

finguyen  hilario   kalousis

workflows  propositionalization is a standard approach used extensively and successfully in
learning problems in which the learning instances are complex structures  kramer  lavrac 
  flach        
also  the propositional workflow representation can easily deal with the parameter values
of the different operators that appear within the workflows  to do so  we can discretize the
range of values of a continuous parameter to ranges such as low  medium  high  or other
ranges depending on the nature of the parameter  and treat these discretized values as
simply a property of the operators  the resulting patterns will now be parameter aware 
they will include information on the parameter range of the mined operators and they can
be used to support also the parameter setting during the planning of the dm workflows 
however within this paper we will not explore this possibility 
      performance based ranking of dm workflow
to characterize the performance of a number of workflows applied on a given dataset we
will use a relative performance rank schema that we will derive using statistical significance
tests  given the estimations of some performance measure of the different workflows on a
given dataset we use a statistical significance test to compare the estimated performances
of every pair of workflows  if within a given pair one of the workflows was significantly
better than the other then it gets one point and the other gets zero points  if there was
no significance difference then both workflows get half a point  the final performance rank
of a workflow for the given dataset is simply the sum of its points over all the pairwise
performance comparisons  the higher the better  we will denote this relative performance
rank of a workflow wc applied on dataset xu by r xu   wc    note that if a workflow was not
applicable  or not executed  on the dataset x  we set its rank score to the default value of zero
which means that the workflow is not appropriate  if not yet executed  for the given dataset 
when the planning goal g is the classification task  we will use as evaluation measure in our
experiments the classification accuracy  estimated by ten fold cross validation  and do the
significance testing using mcnemars test  with a significance level of      
in the next section we will describe how we build the meta mining models from the
past data mining experiments using the meta data and the performance measures we have
described so far and how we use these models to support the dm workflow planning 
    learning meta mining models for workflow planning
before starting to describe in detail how we build the meta mining models let us take a
step back and give a more abstract picture of the type of meta mining setting that we will
address  in the previous sections  we described two types of learning instances  datasets
x  x and workflows w  w  given the set of datasets and the set of workflows stored in
the dmer  the meta miner will build from these  two training matrices x and w  the
x   n  d dataset matrix  has as its ith row the description xui of the ith dataset  the
w   m   p   workflow matrix  has as its j th row the description wcj of the jth workflow 
we also have a preference matrix r   n  m  where rij   r xui   wcj    i e  it gives the
relative performance rank of the workflow wj when applied to the dataset xi with respect
to the other workflows  we can see rij as a measure of the appropriateness or match of
the wj workflow for the xi dataset  the ith line of the r matrix contains the vector
   

fiusing meta mining to support dm workflow planning and optimization

of the relative performance ranks of the workflows that were applied on the xui dataset 
the meta miner will take as input the x  w and r matrices and will output a model that
predicts the expected performance  r xu   wc    of a workflow w applied to a dataset x 
we construct the meta mining model using similarity learning  exploiting two basic
strategies initially presented in the context of dm workflow selection  nguyen et al       b  
here we will give only a high level presentation of them  for more details the interested user
should refer to the original paper  in the first strategy we learn homogeneous similarity
measures  measuring similarity of datasets and similarity of workflows  which we then use to
derive the r xu   wc  g  estimates  in the second we learn heterogeneous similarity measures
which directly estimate the appropriateness of a workflow for a dataset  i e  they produce
direct estimates of r xu   wc  g  
      learning homogeneous similarity measures
our goal is to provide meta mining models that are good predictors of the performance
of a workflow applied to a dataset  in the simplest approach we want to learn a good
similarity measure on the dataset space that will deem two datasets to be similar if a set
of workflows applied to both of them will result in a similar relative performance  i e  if
we order the workflows according to the performance they achieve on each dataset then
two datasets will be similar if the workflow orders are similar  thus the learned similarity
measure on the dataset space should be a good predictor of the similarity of the datasets
as this is determined by the relative performance order of the workflows  in a completely
symmetrical manner we will consider two workflows to be similar if they achieve similar
relative performance scores on a set of datasets  thus in the case of workflows we will learn
a similarity measure on the workflow space that is a good predictor of the similarity of their
relative performance scores over a set of datasets 
briefly  we learn two mahalanobis metric matrices  mx   mw   over the datasets and the
workflows respectively  by optimizing the two following convex metric learning optimization
problems 
min f      rrt  xmx xt    f    tr mx  
mx

s t 

   

mx   

and
min f      rt r  wmw wt    f    tr mw  
mw

s t 

   

mw   

where      f is the frobenius matrix norm  tr   the matrix trace  and     is a parameter
controlling the trade off between empirical error and the metric complexity to control overfitting  the rrt   n  n matrix reflects the similarity of the relative workflow performance
vectors over the different dataset pairs which the learned dataset similarity metric should
reflect  the rt r   m  m matrix gives the respective similarities for the workflows  for
more details on the learning problem and how we solve it  see the work of nguyen et al 
     b  
   

finguyen  hilario   kalousis

note that so far we do not have a model that computes the expected relative performance
r xu   wclo    in the case of the homogeneous metric learning we will compute it in the on line
mode during the planning phase  we will describe right away how we do so in the following
paragraph 
planning with the homogeneous similarity metrics  p   we will use the two
learned mahalanobis matrices  mx   mw   to compute the dataset similarity and the workflow similarity out of which we will finally compute the estimates r xu   wclo   at each planning
step 
concretely  prior to planning we determine the similarity of the input dataset xu  for
which we want to plan optimal dm workflows  to each of the training datasets xui  x using
the mx dataset metric to measure the dataset similarities  the mahalanobis similarity of
two datasets  xu   xui   is given by
sx  xu   xui     xtu mx xui

   

then  during planning at each planning step we determine the similarity of each candidate
workflow wlo  cl to each of the training workflows wcj of w  by
sw  wclo   wcj     wctlo mw wcj  

   

finally we derive the r xu   wclo   estimate through a weighted average of the elements
of the r matrix  the weights are given by the similarity of the input dataset xu to the
training datasets  and the similarities of the candidate workflow wclo to each of the training
workflows  more formally the expected rank is given by 
p
p
wcj w  xui  wcj r xui   wcj  g 
xui x
p
p
    
r xu   wclo  g   
wc w  xui  wcj
xu x
j

i

 xui and  wcj are the gaussian weights given by  xui   exp sx  xu   xui   x   and  wcj  
exp sw  wclo   wcj   w    x and w are the kernel widths that control the size of the neighbors
in the data and workflow spaces respectively  smart   kaelbling        forbes   andre 
      
using the rank performance estimates delivered by eq       we can select at each planning step the best candidate workflows set  sl   according to eq      we will call the resulting
planning strategy p   under p  the expected performance of the set of selected candidate
workflows sl greedily increases until we deliver the k dm complete workflows which are
expected to achieve the best performance on the given dataset 
      learning a heterogeneous similarity measure
the p  planning strategy makes use of two similarity measures that are learned independently of each other  each one defined in its own feature space  this is a simplistic
assumption because it does not model for the interactions of workflows and datasets  we
know that certain types of dm workflows are more appropriate for datasets with certain
types of characteristics  in order to address this limitation  we will define a heterogeneous
metric learning problem in which we will directly estimate the similarity appropriateness
   

fiusing meta mining to support dm workflow planning and optimization

of a workflow for a given dataset as this is given by the r xu   wc   relative performance
measure 
since learning a mahalanobis metric is equivalent to learning a linear transformation we
can rewrite the two mahalanobis metric matrices described previously as mx   uut and
mw   vvt   u   d  t and v    p    t are the respective linear transformation matrices
with dimensionality t   min rank x   rank w   
to learn a heterogeneous similarity
measure between datasets and workflows using these two linear transformations we solve
the following optimization problem 
min f      r  xuvt wt    f     rrt  xuut xt    f
u v

    rt r  wvvt wt    f  

    


   u   f     v   f  
 

using an alternating gradient descent algorithm  where we first optimize for u keeping
v fixed and vice versa  the optimization problem is non convex and the algorithm will
converge to a local minimum  the first term is similar to the low rank matrix factorization
of srebro  rennie  and jaakkola         however the factorization that we learn here
is a function of the dataset and workflow feature spaces and as a result it can address
samples that are out of the training instances  also known as the cold start problem in
recommendation systems  in the case of the dm workflow planning problem this is a strong
requirement because we need to be able to plan workflows for datasets that have never been
seen during training  and also be able to qualify workflows that have also not been seen
during training  the second and third terms define metrics that reflect the performancebased similarities of datasets and workflows respectively  along the lines of the homogeneous
metrics given previously   while together they give directly the similarity appropriateness
of a dm workflow for a dataset by estimating the expected relative predictive performance
as 
r xu   wclo  g    xu uvt wctlo

    

we can see the heterogeneous similarity metric as performing a projection of the dataset and
workflow spaces on a common latent space on which we can compute a standard similarity
between the projections  again for more details  see the work of nguyen et al       b  
planning with the heterogeneous similarity measure  p   planning with the heterogeneous similarity measure  a strategy we will denote by p   is much simpler than planning with the homogeneous similarity measures  given an input dataset described by xu
at each step of the planning we make use of the relative performance estimate r xu   wclo  g 
delivered by eq      to select the set of best workflows sl from the set of partial workflows cl using the selection process described by eq      unlike the planning strategy p 
which computes r xu   wclo  g  through a weighted average with the help of the two independently learned similarity metrics  p  relies on a heterogeneous metric that directly computes
r xu   wclo  g   modeling thus explicitly the interactions between dataset and workflow characteristics 
we should note here that both p  and p  planning strategies are able to construct
workflows even over pools of ground operators that include operators with which we have
never experimented with in the baseline experiments  provided that these operators are well
   

finguyen  hilario   kalousis

described within the dmop  this is because the meta mining models that the planner uses
to prioritize the workflows rely on the wclo descriptions of a workflow which are generalized
descriptions over workflows and operators 
in the next section we evaluate the ability of the two planning strategies that we have
introduced to plan dm workflows that optimize the predictive performance and compare
them to a number of baseline strategies under different scenarios 

   experimental evaluation
we will evaluate our approach on the data mining task of classification  the reasons for
that are rather practical  classification is a supervised task which means that there is a
ground truth against which we can compare the results produced by some classification
algorithm  using different evaluation measures such as accuracy  error  precision etc  for
other mining tasks such as clustering  performance evaluation and comparison is a bit more
problematic due to the lack of ground truth  it has been extensively studied  and it is
extensively used in many application fields  resulting in a plethora of benchmark datasets 
which we can easily reuse to construct our base level experiments as well as to evaluate
our system  moreover  it has been extensively addressed in the context of meta learning 
providing baseline approaches against which to compare our approach  finally our approach
requires that the different algorithms and operators that we use are well described in the
dmop ontology  due to the historical predominance of the classification task and algorithms
as well as their extensive use in real world problems  we started developing dmop from them 
as a result the task of classification and the corresponding algorithms are well described 
having said all this  we should emphasize that our approach is not limited to the task
of classification  it can be applied to any mining task for which we can define an evaluation
measure  collect a set of benchmark datasets on which we will perform the base level experiments  and provide descriptions of the task and the respective algorithms in the dmop 
to train and evaluate our approach  we have collected a set of benchmark classification
datasets  we have applied on them a set of classification data mining workflows  from
these base level experiments we learn our meta mining models which are then used by the
planner to plan data mining workflows  then we challenge the system with new datasets
which were not used in the training of the meta mining models  datasets for which it has to
plan new classification workflows that will achieve a high level of predictive performance 
we will explore two distinct evaluation scenarios  in the first one  we will constrain the
system so that it plans dm workflows by selecting operators from a restricted operator
pool  namely operators with which we have experimented in the base level experiments 
thus these are operators that are characterized in the dmop ontology and are tested in
the base level experiments  we will call them tested operators  in the second scenario we
will allow the system to also choose from operators with which we have never experimented
but which are characterized in the dmop ontology  we will call these operators untested
operators  the goal of the second scenario is to evaluate the extend to which the system
can effectively use untested operators in the workflows it designs 
   

fiusing meta mining to support dm workflow planning and optimization

type
fs tested
fs tested
fs tested

abbr 
ig
chi
rf

parameters
  features selected k     
  features selected k     
  features selected k     

svmrfe

  features selected k     

fs untested
cl tested

operator
information gain
chi square
relieff
recursive feature
elimination with svm
information gain ratio
one nearest neighbor

igr
 nn

  features selected k     

cl tested

c   

c   

cl tested

cart

cart

fs tested

cl tested
cl tested

naivebayes with normal
density estimation
logistic regression
linear kernel svm

cl tested

gaussian kernel svm

svmr

cl untested
cl untested
cl untested
cl untested

linear discriminant analysis
rule induction
random decision tree
perceptron neural network

lda
ripper
rdt
nnet

cl tested

 pruning confidence c
 min  inst  per leaf m
 pruning confidence c
 min  inst  per leaf m

      
  
      
  

nb
lr
svml

 complexity c    
 complexity c    
 gamma       

table    table of operators we used to design dm workflows for the    datasets  the type
corresponds to feature selection  fs  or classification  cl  operators  the operators that have been experimented are marked as tested  otherwise untested 

    base level datasets and dm workflows
to construct the base level experiments  we have collected    real world datasets on genomic
microarray or proteomic data related to cancer diagnosis or prognosis  mostly from the
national center for biotechnology information    as is typical with such datasets  the
datasets we use are characterized by high dimensionality and small sample size  and a
relatively low number of classes  most often two  they have an average of       instances 
         attributes  and      classes 
to build the base level experiments  we applied on these datasets workflows that consisted either of a single classification algorithm  or of a combination of feature selection and
a classification algorithm  although the htn planner we use  kietz et al               is
able to generate much more complex workflows  over    different tasks  with more than    
operators  we had to limit ourselves to the planning of classification  or feature selection
and classification  workflows simply because the respective tasks  algorithms and operators
are well annotated in the dmop  this annotation is important for the characterization of
the workflows and the construction of good meta mining models which are used to guide
the planning  nevertheless  the system is directly usable on planning scenarios of any com   http   www ncbi nlm nih gov 

   

finguyen  hilario   kalousis

plexity  as these are describe in the htn grammar  provided that the appropriate tasks 
algorithms and operators are annotated in the dmop ontology 
we used four feature selection algorithms together with seven classification algorithms
to build our set of base level training experiments  these are given in table    noted as
tested  as we have mentioned previously  we can also plan over the operators parameters
by discretizing the range of values of the parameters and treating them as properties of
the operators  another alternative is to use inner cross validation to automatically select
over a set of parameter values  strictly speaking  in that case  we would not be selecting a
standard operator but its cross validated variant  nevertheless  this would incur a significant
computational cost 
overall  we have seven workflows that only contained a classification algorithm  and
   workflows that had a combination of a feature selection with a classification algorithm 
resulting to a total of    workflows applied on    datasets which corresponds to      baselevel dm experiments  the performance measure we use is accuracy which we estimate
using ten fold cross validation  for all algorithms  we used the implementations provided
in the rapidminer dm suite  klinkenberg et al         
as already said  we have two evaluation settings  in the first  scenario    we constrain
the system to plan workflows using only the tested operators  in the second  scenario   
we allow the system to select also from untested operators  these additional operators are
also given in table    denoted as untested  the total number of possible workflows in this
setting is    
    meta learning   default methods
we will compare the performance of our system against two baseline methods and a default
strategy  the two baseline methods are simple approaches that fall in the more classic metalearning stream but instead of selecting between individual algorithms they select between
workflows  thus they cannot plan dm workflows and they can only be used in a setting in
which all workflows to choose from have been seen in the model construction phase 
the first meta learning method that we will use  which we will call eucl  is the standard
approach in meta learning  kalousis   theoharis        soares   brazdil         which
makes use of the euclidean based similarity over the dataset characteristics to select the n
most similar datasets to the input dataset xu for which we want to select workflows and
then averages their workflow rank vectors to produce the average rank vector 
n
  x
rxui   xui   arg max xtu xui  n
n
xui x

    

i

which it uses to order the different workflows  thus this method simply ranks the workflows
according to the average performance they achieve over the neighborhood of the input
dataset  the second meta learning method that we call metric makes use of the learned
dataset similarity measure given by eq     to select the n most similar datasets to the
input dataset and then averages as well their respective workflow rank vectors 
n
  x
rxui   xui   arg max xtu mx xui  n
n
xui x
i

   

    

fiusing meta mining to support dm workflow planning and optimization

   

   

   

   

chi c  
rf nbn
svmrfe c  
chi cart
rf c  
svmr
 nn
ig c  
rf  nn
svmrfe cart
c  
chi svmr
rf cart
chi svml
ig cart
rf svmr
rf svml
svmrfe  nn
chi  nn
ig  nn
svmrfe svmr
cart
chi nbn
ig svmr
svmrfe lr
chi lr
rf lr
svmrfe nbn
ig svml
svml
ig lr
svmrfe svml
nbn
ig nbn
lr

   

figure    percentage of times that a workflow is among the top   workflows over the different datasets 

for the default recommendation strategy  we will simply use the average of the rxui workflow
rank vectors over the collection of training datasets 
 x
rxui   xui  x
n
n

    

i

to rank and select the workflows  we should note that this is a rather difficult baseline to
beat  to see why this is the case we plot in figure   the percentage of times that each of
the    dm workflows appears among the top   worfklows over the    datasets  the top
workflow  consisting of just the lr algorithm  is among the top   for more than     of
the datasets  the next two workflows  nbn and ig with nbn  are among the top   for
almost     of the datasets  in other words if we select the top   workflows using the default
strategy then in roughly     of the datasets lr will be correctly between them  while for
nbn and ig with nbn this percentage is around      thus the set of dataset we have
here is quite similar with respect to the workflows that perform better on them  making the
default strategy a rather difficult one to beat 
    evaluation methodology
to estimate the performance of the planned workflows in both evaluation scenarios we will
use leave one dataset out  using each time    datasets on which we build the meta mining
models and one dataset for which we plan 
we will evaluate each method by measuring how well the list  l  of top k ranked workflows  that it delivers for a given dataset  correlates with the true list  t   of top k ranked
   

finguyen  hilario   kalousis

workflows for that dataset using a rank correlation measure  we place true between quotes
because in the general case  i e  when we do not restrict the choice of operators to a specific
set  we cannot know which are the true best workflows unless we exhaustively examine an
exponential number of them  however since here we select from a restricted list of operators
we can have the set of the best  more precisely  to measure the rank correlation between
two lists l and t   we will use the kendall distance with p penalty  which we will denote
k  p   l  t    fagin  kumar    sivakumar         the kendall distance gives the number of
exchanges needed in a bubble sort to convert one list to the other  it assigns a penalty of
p to each pair of workflows such that one workflow is in one list and not in the other  we
set p        because k        l  t   is not normalized  we propose to define the normalized
kendall similarity ks l t  as 
 

k        l  t  
ks l  t       
u

    

 

   
and
pktakes values in         u is the upper bound of k  l  t   given by u      k  k      
  i   i  derived from a direct application of lemma     of the work of fagin et al         
where we assume that the two lists do not share any element  we will qualify each method 
m  including the two baselines  by its kendall similarity gain  kg m   i e  the gain  or loss 
it achieves with respect to the default strategy for a given datasets  which we compute as 

kg m  l  t    

ks m  l  t  
 
ks def   l  t  

    

for each method  we will report its average kendall similarity gain overall the datasets 
kg m   note that  in scenario    the default strategy is based on the average ranks of the
   workflows  in scenario    the default strategy is based on the average ranks of the   
workflows  which we also had to experiment with in order to set the baseline 
in addition to see how well the top k ranked list of workflows  that a given method
suggests for a given dataset  correlates to the true list  we also compute the average accuracy
that the top k workflows it suggests achieve for the given dataset  and we report the average
overall datasets 
    meta mining model selection
at each iteration of the leave one dataset out evaluation of the planning performance  we
rebuild the meta mining model and we tune its  parameter of the mahalanobis metric
learning using inner ten fold cross validation  we select the  value that maximizes the
spearman rank correlation coefficient between the predicted workflow rank vectors and the
real rank vectors  for the heterogenous metric  we used the same parameter setting defined
by nguyen et al       b   for the two meta learning methods  we fixed the number n
of nearest neighbors to five  reflecting our prior belief on appropriate neighborhood size 
for planning  we set manually the dataset kernel width parameter to kx        and the
workflow kernel width parameter to kw        which result on small dataset and workflow
neighborhoods respectively  again  these two parameters were not tuned but simply set on
our prior belief of their respective neighborhood size 
   

fiusing meta mining to support dm workflow planning and optimization

 b  scenario    tested and untested operators 

    

  

  

  

  

  

kg

    

    

 

    
    

    

 

p 
p 
def  

    

    
    

p 
p 
metric
eucl
def  

    

kg

    

    

 a  scenario    only tested operators 

  

 

k

 

  

  

  

  

  

  

k

figure    average correlation gain kg of the different methods against the baseline on the
   bio datasets  in the x axis  k               we have the number of top k workflows
suggested to the user  p  and p  are the two planning strategies  metric and
eucl are baseline methods and defx is the default strategy computed over the set
of x workflows 

    experimental results
in the following sections we give the results of the experimental evaluation of the different
methods we presented so far under the two evaluation scenarios described above 
      scenario    building dm workflows from a pool of tested only
operators
in this scenario  we will evaluate the quality of the dm workflows constructed by the two
planning strategies p  and p  and compare it to that of the two baseline methods as well
as to that of the default strategy  we do leave one dataset out to evaluate the workflow
recommendations given by each method  in figure   a  we give the average kendall gain
kg for each method against the default strategy which we compute over their top k lists for
k                  clearly the p  strategy is the one that gives the largest improvements with
respect to the default strategy  between    to     of gain  compared to any other method 
we establish the statistical significance of these results for each k  counting the number
of datasets for which each method was better worse than the default  using a mcnemars
test  we summarize in figure   the statistical significance results given the p values for
the different ks and give the detailed results in table   in the appendix for all methods for
k               we can see that the p   is by far the best method being significantly better
than the default for    out of the    values of k  close to significant         p value      
ten out of the    times and never significantly worse  from the other methods  only p 
managed to beat the default and this only for   out of the    cases of k 
   

finguyen  hilario   kalousis

   
 

  

  

  

  

  

  

 

  

  

  

  

  

metric    wins   losses 

eucl    wins   losses 

  

   
   
   

   

   

   

pvalue

   

   

k

   

k

   

pvalue

   

pvalue

   

   

   
   

   

pvalue

   

   

p     wins   losses 

   

p      wins   losses 

 

  

  

  

  

  

  

 

k

  

  

  

  

  

  

k

figure    p values of the mcnemars test on the number of times that the kendal similarity
of a method is better than the default for a given k  scenario    a positive pvalue means more wins than losses  a negative the opposite  the solid lines are
at p             the dash dotted at p            the x wins  y losses in
the header indicates the number of times over k         that the method was
significantly better worse then the default 

when we examine the average accuracy that the top k workflows suggested by each
method achieve  the advantage of p  is even more striking  its average accuracy is      
and       higher than that of the default strategy  for k     and k     respectively  see
table   a   for k      p  achieves a higher average accuracy than the default in    out of
the    datasets  while it under performs compared to the default only in     using again
a mcnemars test the statistical significance is       i e  p  is significantly better than
the default strategy when it comes to the average accuracy of the top k     workflows it
plans  the results are similar for k      in fact for the eight top k lists  k               p  is
significantly better than the default for five values of k  close to significantly better once 
and never significantly worse  for the higher values of k  k                it is significantly
better    times  close to significantly better three times  and never significantly worse  it
stops being significantly better when k       for such large k values  the average is taken
over almost all workflows  thus we do not expect important differences between the lists
produced by the different methods  in figure     we visualize the statistical significance
results for the different values of k              and give the detailed results in table   of the
appendix 
   

fiusing meta mining to support dm workflow planning and optimization

   
 

  

  

  

  

  

  

 

  

  

  

  

  

metric    wins   losses 

eucl    wins   losses 

  

   
   
   

   

   

   

pvalue

   

   

k

   

k

   

pvalue

   

pvalue

   

   

   
   

   

pvalue

   

   

p     wins   losses 

   

p      wins   losses 

 

  

  

  

  

  

  

 

k

  

  

  

  

  

  

k

figure     p values of the mcnemars test on the number of times that the average accuracy of a method is better than the default for a given k  scenario    same
figure interpretation as in figure  

p  is never significantly better than the default for all k               while for k               
it is significantly better for nine values of k  close to significantly better three times  and
close to significantly worse once  the metric baseline is never significantly better than the
default for all k               while for k                it is significantly better for four values of
k and close to significantly better four times  the results of ec are quite poor  in terms of
the average accuracy  it is very similar to the default  while in terms of the number of times
that it performs better than the default  for most of the cases  it is less than the number of
times that it performs worse than the default  as before in figure    we give the results
of the statistical significance results for the different values of k and the detailed results in
table   of the appendix  p  is the only method that directly learns and exploits in the
workflow planning the associations between the dataset and the workflow characteristics
which as the experimental results clearly demonstrate is the strategy that best pays off 
      scenario    building dm workflows from a pool of tested and
non tested operators
in the second scenario  we evaluate the performance of the two planning strategies  p  and
p   where the pool of available operators during the planning is not any more limited to
operators with which we have already experimented in the base level experimented with 
but it is extended to include additional operators which are described in the dmop ontology 
   

finguyen  hilario   kalousis

 a  scenario    only tested operators

p 
p 
metric
eucl
def  

avg  acc
      
      
      
      
      

k  
w l
     
     
     
     

p  value
     
    
    
    

avg  acc
      
      
      
      
      

k  
w l
     
     
     
     

p  value
     
    
    
    

 b  scenario    tested and untested operators

p 
p 
def  

avg  acc
      
      
      

k  
w l
     
     

p  value
    
    

avg  acc
      
      
      

k  
w l
     
     

p  value
    
    

table    average accuracy of the top k workflows suggested by each method  w indicates
the number of datasets that a method achieved a top k average accuracy larger
than the respective of the default  and l the number of datasets that it was smaller
than the default  p  value is the result of the mcnemars statistical significance
test    indicates that the method is statistically better than the default 

we have already described the exact setting in section      as a reminder the number of
possible workflows is now     as before  we will estimate performances using leave onedataset out  note that the two baseline methods  metric and eucl  are not applicable in
this setting  since they can be only deployed over workflows with which we have already
experimented in the baseline experiments  here  as we already explained in section      the
default strategy will correspond to the average rank of the    possible workflows and we
will denote it with def    note that this is a highly optimistically biased default method
since it relies on the execution of all    possible workflows on the base level datasets  unlike
p  and p  which only get to see    workflows for the model building  and the operators
therein  but will plan over the larger pool 
in figure   b   we give the average kendall gain kg for p  and p  over the def  
baseline  similarly to the first evaluation scenario  p  has an advantage over p  since it
demonstrates higher gains over the default  note though that these performance gains are
now smaller than they were previously  in terms of the number of k values for which p 
is  close to be  significantly better than the default  these are now six and eight  for the
different k               def   is now once significantly better than p  and once close to
being significantly better  in what concerns p   there is no significant difference between
its performance and def    for any value of k  for values of k       p  systematically
under performs compared to def    due to the advantage of the latter that comes from
seeing the performance of all    workflows over the base level dataset  we visualize the
statistical significance results in the top row of figure     and give the detailed results in
table   of the appendix for all values of k              
   

fiusing meta mining to support dm workflow planning and optimization

   
  

  

  

  

  

  

 

  

  

  

  

  

k

p     wins    losses 

p     wins   losses 

  

   
   
   
   

   

   

   

pvalue

   

   

k

   

 

pvalue

   

pvalue

   

   

   
   

   

pvalue

   

   

p     wins   losses 

   

p     wins   loss 

 

  

  

  

  

  

  

 

k

  

  

  

  

  

  

k

figure     top row p values of the mcnemars test on the number of times that the kendall
similarity of a method is better than the default for a given k  scenario    bottom
row same for average accuracy  same figure interpretation as in figure   

in what concerns the performance of p  with respect to the average accuracy of the
top k workflows it suggests  it has a slight advantage over def   but only for very small
values of k  up to four  it is significantly better compared to def   only once  k      for
k     to     the two methods have no significant difference  while for k               p  is
worse     times in a significant manner  for p  the picture is slightly different  its average
accuracy is not significantly different than def    with the exception of three k values for
which it is significantly worse  we visualize the statistical significance results in the bottom
row of figure     and give the detailed results in table    it seems that the fact that p 
learns directly the associations between datasets and workflow characteristics puts it at a
disadvantage when we want to plan over operators that have not been tested in the training
phase  in such a scenario  the p  strategy which weights preferences by dataset similarity
and by workflow similarity seems to cope better with untested operators  nevertheless
it is still not possible to outperform the default strategy in a significant manner  keeping
however in mind that def   is an optimistic default strategy because it is based on the
experimentation of all possible workflows on the training dataset 
    discussion
in the previous sections  we evaluated the two workflow planning strategies in two settings 
planning only over tested operators  and planning with both tested and untested operators 
   

finguyen  hilario   kalousis

in the first scenario  the p  planning strategy that makes use of the heterogeneous metric
learning model  which directly connects dataset to workflow characteristics  clearly stands
out  it outperforms the default strategy in terms of the kendall similarity gain  in a
statistically significant  or close to statistically significant  manner for    values of k 
                 in terms of the average accuracy of its top k workflows  it outperforms it for   
values of k in a statistically significant  or close to statistically significant  manner  all the
other methods  including p   follow with a large performance difference from p  
when we allow the planners to include in the workflows operators which have not
been used in the baseline experiments  but which are annotated in the dmop ontology  p s
performance advantage is smaller  in terms of the kendall similarity gain  this is statistically
significant  or close to  for k                    with respect to the average accuracy of its top k
lists  this is better than the default only for very small lists  k         for k       it is in
fact significantly worse  p  fairs better in the second scenario  however its performance is
not different from the default method  keep in mind though that the baseline used in the
second scenario is a quite optimistic one 
in fact  what we see is that we are able to generalize and plan well over datasets  as
evidenced by the good performance of p  in the first setting  however  when it comes
to generalizing both over datasets and operators as it is the case for the second scenario
the performance of the planned workflows is not good  with the exception of the few top
workflows  if we take a look at the new operators we added in the second scenario  these were
a feature selection algorithm  information gain ratio  and four classification algorithms 
namely a linear discriminant algorithm  the ripper rule induction algorithm  a neural net
algorithm  and a random tree  out of them  only for information gain ratio we have seen
during the base level set of experiments an algorithm  information gain  that has a rather
similar learning bias to it  the ripper rule induction is a sequential covering algorithm 
the closest operators to which in our set of training operators are the two decision tree
algorithms which are recursive partitioning algorithms  with respect to the dmop ontology 
ripper shares a certain number of common characteristics with decision trees  however the
meta mining model contains no information on how the set covering learning bias performs
over different datasets  this might lead to it being selected for a given dataset based on its
common features with the decision trees  while its learning bias is not in fact appropriate
for that dataset  similar observations hold for the other algorithms  for example lda
shares a number of properties with svml and lr  however its learning bias  maximizing
the between to within class distances ratio  is different from the learning biases of these
two  as before the meta mining model contains no information on how its bias associates
with dataset characteristics 
overall  the extent to which the system will be able to plan  over tested and untested
operators  workflows that achieve a good performance  depends on the extend to which
the properties of the latter have been seen during the training of the meta mining models
within the operators with which we have experimented with  as well as on whether the
unseen properties affect critically the final performance  in the case that all operators are
well characterized experimentally  as we did in scenario    then the performance of the
workflows designed by the p  strategy is very good  note that it is not necessary that all
operators or workflows are applied to all datasets  it is enough to have a sufficient set of
experiments for each operator  the heterogeneous metric learning algorithm can handle
   

fiusing meta mining to support dm workflow planning and optimization

 b 

 a 

x validation

x validation

dataprocessing
algorithm
fwalgorithm

classificationmodeling dataprocessing
algorithm
algorithm
fwalgorithm

highbiascma

multivariatefw
algorithm

classificationmodeling
algorithm
highvariancecma

univariatefw
algorithm

figure     top ranked workflow patterns according to their average absolute weights given
in matrix v 

incomplete preference matrices  using only the available information  of course it is clear
that the more the available information  whether in the form of complete preference matrices
or in the form of extensive base level experiments over large number of datasets  the better
the quality of the learned meta mining model will be  it will be interesting to explore the
sensitivity of the heterogeneous metric learning method over different levels of completeness
of the preference matrix  however this is outside the scope of the present paper 
we can quantify the importance of the different workflow patterns and that of the
operators properties by analyzing the linear transformation over the workflow patterns
contained in the heterogeneous metric  more precisely  we establish the learned importance
of each workflow pattern by averaging the absolute values of the weights it is assigned over
the different factors  rows  of the v linear transformation matrix of eq       note that
under this approach  we only establish the importance of the patterns  and not whether
they are associated with good or bad predictive performance  in figure     we give the two
most important patterns as these are determined on the basis of their averaged absolute
weights  both of them describe relations between the workflow operators  the first one
indicates that we have a multivariate feature weighting algorithm followed by a high bias
classification algorithm  while the second describes a univariate feature weighting algorithm
followed by a high bias classification algorithm  a systematic analysis of the learned model
could provide hints on where one should focus the ontology building effort  looking at what
are the important patterns as well as what are the patterns that are not used  in addition 
it can reveal which parts of the ontology might need refinement in order to distinguish
between different workflows with respect to their expected performance 

   conclusions and future work
in this paper  we have presented what is  to the best of our knowledge  the first system
that is able to plan data mining workflows  for a given task and a given input dataset 
that are expected to optimize a given performance measure  the system relies on the tight
interaction of a hierarchical task network planner with a learned meta mining model to
plan the workflows  the meta mining model  a heterogeneous learned metric  associates
datasets characteristics with workflow characteristics which are expected to lead to good
   

finguyen  hilario   kalousis

performance  the workflow characteristics describe relations between the different components of the workflows  capturing global interactions of the various operators that appear
within them  and incorporate domain knowledge as the latter is given in a data mining ontology  dmop   we learn the meta mining model on a collection of past base level mining
experiments  data mining workflows applied on different datasets  we carefully evaluated
the system on the task of classification and we showed that it outperforms in a significant
manner a number of baselines and the default strategy when it has to plan over operators
with which we have experimented with in the base level experiments  the performance
advantage is less pronounced when it has to consider also during planning operators with
which we have not experimented with in the base level experiments  especially when the
properties of these operators were not present within other operators with which we have
experimented with in the base level experiments 
the system is directly applicable to other mining tasks e g  regression  clustering  the
reasons for which we focused on classification were mainly practical  there is extensive
annotation of the classification task and the related concepts in the data mining ontology 
large availability of classification datasets  and extensive relevant work on meta learning
and dataset characterization for classification  the main hurdle in experimenting with a
different mining task is the annotation of the necessary operators in the dmop ontology and
the set up of a base level collection of mining experiments for the specific task  although
the annotation of new algorithms and operators is a quite labor intensive task  many of the
concepts currently available in the dmop are directly usable in other mining tasks  e g  cost
functions  optimization problems  feature properties etc  in addition  there is a small active
community  the dmo foundry    maintaining and augmenting collaboratively the ontology
with new tasks and operators  significantly reducing the deployment barrier for a new task 
in the dmo foundry web site  one can find a number of tools and templates to facilitate
the addition of new concepts and operators in the ontology as well as to annotate the
existing ones  having said that we should note that the use of dmop is not sine qua non
for the system to function  we can very well perform the workflow characterization task
by mining just over ground operators  without using the ontology  the downside of that
would be that the extracted patterns will not be generalized nor will they contain operator
properties  instead they will be defined over ground operators  everything else remains as
it is 
there are a number of issues that we still need to explore in a finer detail  we would
like to gain a deeper understanding and a better characterization of the reduced performance in planning over untested operators  for example  under what conditions we can be
relatively confident on the suitability of an untested operator within a workflow  we want
to experiment with the strategy we suggested for parameter tuning  in which we treat the
parameters as yet another property of the operators  in order to see whether it gives better
results  we expect it will  we want to study in detail how the level of missing information
in the preference matrix affects the performance of the system  as well as whether using
ranking based loss functions in the metric learning problem instead of sum of squares would
lead to even better performance 

   http   www dmo foundry org 

   

fiusing meta mining to support dm workflow planning and optimization

on a more ambitious level we want to bring in ideas from reinforcement learning  sutton
  barto         let the system design its own workflows in a systematic way and have them
applied on the collection of available datasets in order to derive even better characterizations
of the workflow space and how they relate to the dataset space  exploring for example areas
in which the meta mining model is less confident 

acknowledgments
this work has been partially supported by the european community  th framework program ict          under grant number        e  lico  an e laboratory for interdisciplinary collaborative research in data mining and data intensive science  alexandros
kalousis was partially supported by the rsco isnet nft project  the basic htn planner has been the result of collaborative work within the e lico project of jorg uwe kietz 
floarea serban  simon fischer  we would like to thank jun wang for his important contribution in developing the metric learning part of the paper  in addition we would like to
thank all the members of the ai lab  adam woznica  huyen do  and jun wang  for the
significant effort they placed in providing content in the dmop  finally  we would like to
thank the reviewers for the suggestions that helped improve the paper 

   

finguyen  hilario   kalousis

appendix a  detailed results
k
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
total

p 
w l p value
 
 
 
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
wins    losses  

p 
w l p value
       
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
wins   losses  

metric
w l p value
 
        
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
wins   losses  

eucl
w l p value
 
        
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
wins   losses  

table    wins losses and respective p values of the mcnemars test on the number of
times that the kendal similarity of a method is better than the kendal similarity
of the default  scenario    in bold  the winning p value that are lower than      

   

fiusing meta mining to support dm workflow planning and optimization

k
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
total

p 
avg acc w l p value
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
 
 
     
     
           
     
 
 
 
wins    losses  

p 
avg acc w l p value
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
 
 
 
wins     losses

metric
avg acc w l p value
     
           
     
           
     
       
     
       
     
       
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
       
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
 
 
     
wins   losses  

ec
avg acc w l p value
     
           
     
       
     
       
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
       
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
 
 
 
wins    losses  

def
avg acc
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     

table    average accuracy  wins losses  and respective p values of the mcnemars test on
the number of times the average accuracy of a method is better than the average
accuracy of the default  scenario    in bold  the winning p value that are lower
than      

   

finguyen  hilario   kalousis

k
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
total

p 
w l p value
 
        
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
wins   losses  

p 
w l p value
 
        
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
wins   losses  

table    wins losses and p values of the mcnemars test on the number of times kendal
similarity of a method is better than the kendal similarity of the default  scenario
   in bold  the winning p value that are lower than      

   

fiusing meta mining to support dm workflow planning and optimization

k
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
total

p 
avg acc w l
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
wins   losses

p value
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
  

p 
avg acc w l p value
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
     
           
wins   losses  

def
avg acc
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     

table    avg acc   wins losses  and respective p values of the mcnemars test on the
number of times the average accuracy of a method is better than the average
accuracy of the default  scenario    in bold  the winning p value that are lower
than      

   

finguyen  hilario   kalousis

references
bernstein  a   provost  f     hill  s          toward intelligent assistance for a data mining
process  an ontology based approach for cost sensitive classification  knowledge and
data engineering  ieee transactions on                 
bose  r  j  c     der aalst  w  m  v          abstractions in process mining  a taxonomy
of patterns  in proceedings of the  th international conference on bussiness process
management 
brazdil  p   giraud carrier  c   soares  c     vilalta  r          metalearning  applications
to data mining    edition   springer publishing company  incorporated 
bringmann  b          matching in frequent tree discovery  in proceedings of the fourth
ieee international conference on data mining  icdm    pp         
chapman  p   clinton  j   kerber  r   khabaza  t   reinartz  t   shearer  c     wirth  r 
        crisp dm     step by step data mining guide  tech  rep   the crisp dm
consortium 
fagin  r   kumar  r     sivakumar  d          comparing top k lists  in proceedings of
the fourteenth annual acm siam symposium on discrete algorithms  soda     pp 
      philadelphia  pa  usa  society for industrial and applied mathematics 
fayyad  u   piatetsky shapiro  g     smyth  p          from data mining to knowledge
discovery in databases  ai magazine             
forbes  j     andre  d          practical reinforcement learning in continuous domains 
tech  rep   berkeley  ca  usa 
gil  y   deelman  e   ellisman  m   fahringer  t   fox  g   gannon  d   goble  c   livny 
m   moreau  l     myers  j          examining the challenges of scientific workflows 
computer                
hall  m   frank  e   holmes  g   pfahringer  b   reutemann  p     witten  i  h         
the weka data mining software  an update  sigkdd explor  newsl                
hilario  m          model complexity and algorithm selection in classification  in proceedings of the  th international conference on discovery science  ds     pp         
london  uk  uk  springer verlag 
hilario  m     kalousis  a          fusion of meta knowledge and meta data for casebased model selection  in proceedings of the  th european conference on principles
of data mining and knowledge discovery  pkdd     pp          london  uk  uk 
springer verlag 
hilario  m   kalousis  a   nguyen  p     woznica  a          a data mining ontology for
algorithm selection and meta learning  in proc of the ecml pkdd   workshop on
third generation data mining  towards service oriented knowledge discovery 
hilario  m   nguyen  p   do  h   woznica  a     kalousis  a          ontology based metamining of knowledge discovery workflows  in jankowski  n   duch  w     grabczewski 
k   eds    meta learning in computational intelligence  springer 
   

fiusing meta mining to support dm workflow planning and optimization

ho  t  k     basu  m          complexity measures of supervised classification problems 
ieee trans  pattern anal  mach  intell                  
ho  t  k     basu  m          data complexity in pattern recognition  springer 
hoffmann  j          ff  the fast forward planning system  ai magazine             
kalousis  a          algorithm selection via metalearning  ph d  thesis  university of
geneva 
kalousis  a   gama  j     hilario  m          on data and algorithms  understanding
inductive performance  machine learning                 
kalousis  a     theoharis  t          noemon  design  implementation and performance
results of an intelligent assistant for classifier selection  intell  data anal             
    
kietz  j  u   serban  f   bernstein  a     fischer  s          towards cooperative planning of data mining workflows  in proc of the ecml pkdd   workshop on third
generation data mining  towards service oriented knowledge discovery  sokd     
kietz  j  u   serban  f   bernstein  a     fischer  s          designing kdd workflows via
htn planning for intelligent discovery assistance  in  th planning to learn
workshop ws   at ecai       p     
king  r  d   feng  c     sutherland  a          statlog  comparison of classification
algorithms on large real world problems  applied artificial intelligence            
    
klinkenberg  r   mierswa  i     fischer  s          free data mining software  rapidminer
     formerly yale   http   www rapid i com  
kopf  c   taylor  c     keller  j          meta analysis  from data characterisation for
meta learning to meta regression  in proceedings of the pkdd    workshop on data
mining  decision support meta learning and ilp 
kramer  s   lavrac  n     flach  p          relational data mining   chap  propositionalization approaches to relational data mining  pp          springer verlag new
york  inc   new york  ny  usa 
leite  r     brazdil  p          active testing strategy to predict the best classification algorithm via sampling and metalearning  in proceedings of the      conference on ecai
        th european conference on artificial intelligence  pp          amsterdam 
the netherlands  the netherlands  ios press 
mcdermott  d   ghallab  m   howe  a   knoblock  c   ram  a   veloso  m   weld  d    
wilkins  d          pddl the planning domain definition language  
michie  d   spiegelhalter  d  j   taylor  c  c     campbell  j          machine learning 
neural and statistical classification  
nguyen  p   kalousis  a     hilario  m          a meta mining infrastructure to support kd
workflow optimization  proc of the ecml pkdd   workshop on planning to learn
and service oriented knowledge discovery    
   

finguyen  hilario   kalousis

nguyen  p   kalousis  a     hilario  m       a   experimental evaluation of the e lico
meta miner  in  th planning to learn workshop ws   at ecai      
p     
nguyen  p   wang  j   hilario  m     kalousis  a       b   learning heterogeneous similarity
measures for hybrid recommendations in meta mining  in ieee   th international
conference on data mining  icdm   pp            
peng  y   flach  p  a   soares  c     brazdil  p          improved dataset characterisation
for meta learning  in discovery science  pp          springer 
pfahringer  b   bensusan  h     giraud carrier   c          meta learning by landmarking various learning algorithms   proc    th international conference on machine
learning         
r core team         r  a language and environment for statistical computing  http 
  www r project org  
smart  w  d     kaelbling  l  p          practical reinforcement learning in continuous
spaces  in proceedings of the seventeenth international conference on machine learning  icml     pp          san francisco  ca  usa  morgan kaufmann publishers
inc 
soares  c     brazdil  p          zoomed ranking  selection of classification algorithms based
on relevant performance information  in proceedings of the  th european conference
on principles of data mining and knowledge discovery  pkdd     pp         
london  uk  springer verlag 
srebro  n   rennie  j  d  m     jaakkola  t  s          maximum margin matrix factorization  in saul  l  k   weiss  y     bottou  l   eds    advances in neural information
processing systems     pp            mit press  cambridge  ma 
sutton  r     barto  a          reinforcement learning  an introduction  neural networks 
ieee transactions on              
van der aalst  w  m     giinther  c          finding structure in unstructured processes 
the case for process mining  in application of concurrency to system design       
acsd       seventh international conference on  pp       ieee 
yang  q     wu  x             challenging problems in data mining research  international
journal of information technology   decision making                 
zaki  m  j          efficiently mining frequent trees in a forest  algorithms and applications 
ieee transactions on knowledge and data engineering                    special
issue on mining biological data 
zakova  m   kremen  p   zelezny  f     lavrac  n          automating knowledge discovery workflow composition through ontology based planning  automation science and
engineering  ieee transactions on                

   

fi