journal of artificial intelligence research                  

submitted        published      

distributed evaluation of nonmonotonic multi context systems
minh dao tran
thomas eiter
michael fink
thomas krennwallner

dao   kr   tuwien   ac   at
eiter   kr   tuwien   ac   at
fink   kr   tuwien   ac   at
tkren   kr   tuwien   ac   at

institute fur informationssysteme  tu wien
favoritenstrasse       a      vienna  austria

abstract
multi context systems  mcss  are a formalism for systems consisting of knowledge bases
 possibly heterogeneous and non monotonic  that are interlinked via bridge rules  where the global
system semantics emerges from the local semantics of the knowledge bases  also called contexts 
in an equilibrium  while mcss and related formalisms are inherently targeted for distributed settings  no truly distributed algorithms for their evaluation were available  we address this shortcoming and present a suite of such algorithms which includes a basic algorithm dmcs  an advanced version dmcsopt that exploits topology based optimizations  and a streaming algorithm
dmcs streaming that computes equilibria in packages of bounded size  the algorithms behave quite differently in several respects  as experienced in thorough experimental evaluation of a
system prototype  from the experimental results  we derive a guideline for choosing the appropriate
algorithm and running mode in particular situations  determined by the parameter settings 

   introduction
in the last decade  there has been an increasing interest in systems that comprise information from
multiple knowledge bases  this includes a wide range of application fields such as data integration  multi agent systems  argumentation and many others  to picture a more concrete real world
application  we may consider metis  velikova et al          an industrial prototype system for facilitating timely human decision making in maritime control  in this application  human operators
need support to determine whether a ship entering a port might hide its identity for illegal activities or might be a high risk for environmental hazard  to access such risks  metis relies on a
number of heterogeneous external information sources such as the commercial ship database ihs
fairplay   ship tracking websites   and news items for history of pollution events the ship may have
been involved in 
the rise of the word wide web and distributed systems has propelled this development  and
to date several ai based formalisms are available to host multiple  possibly distributed knowledge
bases in a compound system  well known such formalisms are distributed sat solving  hirayama
  yokoo         distributed constraint satisfaction  faltings   yokoo        yokoo   hirayama 
       distributed ontologies in different flavors  homola         mweb  analyti  antoniou   
damasio         and different approaches to multi context systems  giunchiglia   serafini       
ghidini   giunchiglia        brewka  roelofsen    serafini        brewka   eiter        bikakis
   www ihs com products maritime information 
   marinetraffic com  myship com
c
    
ai access foundation  all rights reserved 

fidao  t ran   e iter   f ink     k rennwallner

figure    pinpointing joker
  antoniou        rooted in mccarthys        work  among them  we focus here on heterogeneous nonmonotonic multi context systems  mcss   brewka   eiter        
as a generalization of previous proposals  mcss are a powerful formalism to specify systems
of knowledge bases that may have different formats and reasoning powers  ranging from simple
query answering over a relational database to reasoning over description logic knowledge bases  see
baader et al          as well as to nonmonotonic formalisms such as default logic  reiter        or
answer set programs  gelfond   lifschitz         to allow for heterogeneous knowledge bases and
to deal with the impedance mismatch between them  mcss abstract knowledge bases to plain mathematical structures  on top  special bridge rules interlink the knowledge bases  where a bridge rule
adds a formula to a knowledge base  depending on certain beliefs at other knowledge bases  hence
the semantics of a knowledge base with associated bridge rules  which forms a context  depends on
the other contexts  possibly in a cyclic manner  based on this  mcss have an equilibrium semantics
in terms of global states in which every context adopts an abstract local model  called belief set 
that is conformant with the local models adopted by the other contexts and in addition obeys the
bridge rules  the following simple example  which is a paraphrase of ghidini and giunchiglias
       magic box  illustrates the power of this idea 
example   suppose that in a computer game  players batman and robin chased player joker to
a partially occluded area  as shown in figure    robin is wounded and cannot read his distance to
objects  neither batman nor robin can tell jokers exact position on the    box  batman can only
assure that he is not in columns   and    while robin can only tell that he is on row    however  if
they exchange their partial knowledge  they can pinpoint joker to row   and column   
we can model batman and robin as contexts whose local knowledge bases include their information about jokers position  which is exchanged using bridge rules  such as at row  x       
at row  x    for batman  which informally imports robins knowledge  context    about row
positions  a full encoding is given in example    the equilibrium of the emerging mcs discloses
then jokers position to both batman and robin 
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

although mcss and related formalisms inherently target distributed systems  no truly distributed algorithms for computing equilibria of mcss were available  brewka and eiter       
encoded equilibria into hex programs  eiter  ianni  schindlauer    tompits         which can be
evaluated using the dlvhex solver  however  while this approach elegantly offers full heterogeneity  it is fully centralized and needs technical assumptions  roelofsen  serafini  and cimatti       
had proposed earlier an algorithm to check satisfiability of homogeneous  monotonic mcs with a
centralized control that accesses contexts in parallel  hence is not truly distributed   bikakis and
antoniou        instead gave a distributed algorithm for their defeasible multi context systems 
however  the latter have homogeneous  possibly nonmonotonic  contexts with a particular type of
semantics  and the algorithm serves query answering but not model building 
the lack of distributed algorithms for evaluating mcss based on local context handlers is due
to several obstacles 
 the abstract view of local semantics as belief sets limits for an algorithm at the global level
interference with the knowledge bases and the evaluation process at each context 
 towards real life applications  certain levels of information hiding and security are required
 e g  for information exchange between knowledge bases of companies  such that only selected
information is transferred between contexts via well defined interfaces  this prevents a context
from getting more insight about its neighbors for optimization  for instance to learn conflicts  i e  
joint beliefs leading to contradiction  across contexts 
 the mcs system topology  i e   the structure of context linkage  might be unknown at a context 
this disables decomposing the system for more efficient  modular evaluation 
 the bridge rules might fuel a cyclic information flow through a group of contexts  even if each
context is easy to evaluate  e g   all knowledge bases are acyclic logic programs   such global cycles
require nontrivial care 
in this article  we address these obstacles and present results towards efficient distributed evaluation of mcss  our main contributions are a suite of generic algorithms dmcs  dmcsopt  and
dmcs streaming which work truly distributed  and their implementation in a system prototype 
in more detail  the contributions are as follows 
    algorithms and optimization techniques
    our first  basic algorithm dmcs aims at a fully distributed setting and we deal with the obstacles
above in a generic way  contexts just exchange belief sets and the call history  i e   the access path
traversing bridge rules   but no further information  at the global level  belief states are formed
as tuples of belief sets  each context with bridge rules must respect the belief sets of its neighbors
when computing its own belief sets using a local solver for its knowledge base  cycles are detected
from the call history  if a context gets a request and finds itself in the call history  to break a cycle 
a guessing technique is used with checks on the return path 
    by localizing a contexts knowledge about the system and information exchange  dmcs
can fairly easily adapt to context changes  additions or deletions   but at the same time faces some
scalability issues  to enhance the performance in an optimized version dmcsopt  we disclose
meta level information to contexts  viz   i  the topology of context dependencies  which is exploited
for decomposing the mcs into sub mcss  blocks  that are linked in a block tree  and  ii  the interface between contexts  for optimizing the data transfer between blocks  here  i  breaks cycles in
   

fidao  t ran   e iter   f ink     k rennwallner

advance and  ii  significantly reduces duplicate local evaluation  each yields a remarkable performance gain 
    still as dmcs and dmcsopt compute all equilibria of an mcs  they can not escape from
scalability and memory issues  as multiple local belief sets can lead to combinatorial explosion at the
global level  we thus consider computing equilibria in a streaming mode  to this end  contexts pass
their belief sets not in one shot to their parents but gradually in small packages  memory blowup
can be thus avoided and moreover contexts can continue earlier than when they wait for all answers
from all neighbors  this approach seems more user friendly as equilibria gradually appear rather
than all at once  possibly after long time  and one may quit the computation after seeing sufficiently
many results  i e   equilibria  
    implementation and experiments
we have implemented the algorithms in a system prototype  to assess the effects of the optimization techniques  we have set up a benchmarking system and conducted comprehensive experiments
with mcss of various topologies and interlinking  the results confirm our expectation of the optimization techniques in general  in a nutshell   i  the decomposition technique clearly improves the
performance in the non streaming mode   ii  streaming is worthwhile as it may still find answers
while non streaming times out   iii  for streaming  choosing the package size is very important 
 iv  the system topology is important as some optimization techniques show drastic improvements
for specific topologies   v  sometimes  the techniques yield no gain but incur overhead 
the results of this work provide not only truly distributed algorithms for evaluating mcss  but
through this also for distributed versions of non monotonic knowledge base formalisms as such
 e g   for distributed answer set programs   and the underlying principles and techniques might be
exploited in related contexts  furthermore  they may provide a basis for the evaluation of extensions and generalizations of mcss  such as non ground mcss  fink  ghionna    weinzierl        
managed mcss  brewka  eiter  fink    weinzierl         supported mcs  tasharrofi   ternovska 
       or reactive mcss  goncalves  knorr    leite        brewka  ellmauthaler    puhrer        
    organization
the remainder of this article is organized as follows  the next section provides preliminaries on
multi context systems  section   introduces the basic distributed algorithm dmcs  while section   develops the optimized algorithm dmcsopt  section   presents then the streaming algorithm dmcs streaming  experimental results of the prototype implementation are reported in
section    in section    we consider related works  and in section   we summarize and address
further and open issues  to increase readability  proofs have been moved to the appendix 

   preliminaries
this sections briefly introduces the preliminaries needed for the rest of the article 
    multi context systems
first  we present the formalization of heterogeneous nonmonotonic multi context systems  mcss 
proposed by brewka and eiter        and further described by brewka  eiter  and fink        
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

which serves as the base of this work  the idea behind mcss is to allow different logics to be used
in different contexts  and to model information flow among contexts via bridge rules  the notion of
logic is defined as follows 
definition    cf  brewka   eiter        a logic l    kbl   bsl   accl   is composed of the
following components 
   kbl is the set of well formed knowledge bases of l  each of which consists of a set of
elements called formulas 
   bsl is the set of possible belief sets  where each s  bsl is a set of elements called beliefs 
and
   accl   kbl   bsl is a function describing the semantics of the logic  by assigning
to each element of kbl a set of acceptable sets of beliefs 
this notion of logic is very generic  and it abstracts the formation of an agents beliefs to a bare
minimum  structure of formulas  both in the knowledge base and the belief sets  is dismissed  and
they are viewed as naked elements  likewise no particular inference mechanism is associated
with a knowledge base  nor are any logical properties imposed on belief sets  the term belief
reflects that statements held by the agent might be on an epistemic basis  without going into further
detail  the assignment of acceptable beliefs sets to a knowledge base  each of which is intuitively a
set of beliefs that an agent is willing to adopt given the knowledge base  captures that in some logics
 e g   in nonmonotonic logics  multiple or even no acceptable belief sets are possible 
this abstract model allows us to capture a range of different logics for knowledge representation
and reasoning  including classical logic  modal logics  epistemic logics  spatial logics  description
logics etc  but also nonmonotonic logics such as default logic  reiter        or answer set programs
 gelfond   lifschitz         in different varieties and settings  a comparison to other formalisms
is given by brewka et al          for example  classical  propositional or predicate logic  may be
modeled as follows 
 kb  the set of  well formed  sentences over a signature  
 bs  the set of deductively closed sets s of  sentences   i e   cn s    s  where cn  
denotes deductive closure  
 acc kb   the singleton containing the deductive closure of kb  i e   acc kb     cn kb   
for an example of nonmonotonic logics   disjunctive  logic programs under answer set semantics  gelfond   lifschitz        can be modeled by
 kb  the set of logic programs over a signature  
 bs  the set of consistent sets of literals over  
 acc kb   the set as  kb  of answer sets of kb according to gelfond and lifschitz         
we refer to this setting  which will be used repeatedly in the sequel  as answer set programming
 asp   note that the answer sets of a knowledge base kb amount to particular   valued models of kb 
intuitively  if a positive literal p is in an answer set s  then p is known to be true  and if a negative
   as common  we exclude inconsistent answer sets admitted by gelfond and lifschitz        

   

fidao  t ran   e iter   f ink     k rennwallner

literal p is in s  then p is known to be false  where known means that the literal is present as a
fact or derivable from rules  if neither p nor p is in s  then the truth value of p is unknown  the
above mcs modeling is a possible worlds  scenarios  view via answer sets  which can be generated
by an answer set solver  however  asp and its implementations also capture inference  truth of a
query in some respectively all answer sets  and further forms of belief set formation 
bridge rules  based on logics  bridge rules are introduced to provide a uniform way of interlinking
heterogeneous information sources as follows 
definition    cf  brewka   eiter        let l    l            ln   be a  multi  set of logics  an lk bridge rule over l     k  n  is of the form
s   c    p              cj   pj    not  cj     pj              not  cm   pm  

   

where  i  for each    i  m  ci              n  and pi is an element of some belief set of lci   and
 ii  for each kb  kbk   it holds that kb   s   kbk  
informally  bridge rules refer in their bodies to other contexts  identified by ci   and can thus add
information to a contexts knowledge base depending on what is believed or disbelieved in other
contexts  in contrast to giunchiglias        multi context systems  there is no single  global set of
bridge rules  each context knows only its own bridge rules 
now that the means for connecting contexts is available  mcss can be formally defined 
definition    brewka   eiter        a multi context system  mcs  m    c            cn   consists
of a collection of contexts ci    li   kb i   br i   where li    kbi   bsi   acci   is a logic  kb i 
kbi is a knowledge base  and br i is a set of li  bridge rules over  l            ln   
example    contd  the scenario from example   can be formalized by an mcs m    c    c    
where in both contexts l    l  are instances of answer set programming  and 


at col  x   see col  x  
 kb     f  f  
 r 
at col  x   see col  x  


at row  x        at row  x   
 br    
at row  x   covered row  x   not      see row  x         row  x   


at row  x   see row  x  
 kb     f  f  
 r 
at row  x   see row  x  


at col  x        at col  x   
 br    
 
at col  x   covered col  x   not      see col  x         col  x   
where
 f    row      row      row      col      col      col       
 f     see col      see col       
 f     see row        and
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems


 r 





joker in  at row  x  
joker in  at col  x  

at row  x   joker
at row  x   joker
at col  x   joker



at col  x   joker




in  row  x   not at row  x  
in  row  x   at row  y    x    y 
in  col  x   not at col  x  
in  col  x   at col  y    x    y 





 




here  x and y are variables used in schematic rules  and they range over rows resp  columns  i e  
        intuitively  c  formalizes batmans knowledge about the scene and c  that of robin  in the
knowledge bases kb   and kb     the facts f represent the box of size       while f  and f  state
what batman and robin see  viz  that joker is not in columns   and   respectively that he is on
row    the next two rules simply map sensed locations to respective facts  informally  the rules in
r make a guess on the row and the column where joker is  if he is concluded to be in the box  first
two rules   this may lead to multiple belief sets  importantly  batman adjusts his knowledge base
depending on beliefs communicated by robin  bridge rules br     and vice versa  bridge rules br     
for convenience  we introduce the following notation and conventions  for an mcs m  
 c        s
    cn    we denote by bi the set s
of all beliefs that can occur in belief sets of context ci   i e  
bi   sbsi s  and we let bm   ni   bi  simply b  if m is understood   without loss of
generality  we assume that for distinct contexts ci and cj   bi  bj     and that for any bridge
atom of the form  i   bi   appearing in any bridge rule in m   it holds that bi  bi  
    semantics of multi context systems
the semantics of an mcs is defined in terms of special belief states  which are sequences s  
 s            sn   such that each si is an element of bsi   intuitively  si should be a belief set of the
knowledge base kb i   however  also the bridge rules must be respected  to this end  kb i is augmented
with the conclusions of its bridge rules that are applicable  more precisely  a bridge rule r of form    
is applicable in s  if pi  sci   for    i  j  and pk 
  sck   for j      k  m  we denote by
head  r  the head of r  and by app r  s  the set of bridge rules r  r that are applicable in s 
then 
definition    brewka   eiter        a belief state s    s            sn   of an mcs m    c           
cn   is an equilibrium  if si  acci  kb i   head  r    r  app br i   s     for all    i  n 
an equilibrium thus is a belief state which contains for each context an acceptable belief set 
given the belief sets of the other contexts 
example    contd  the mcs m in example   has the single equilibrium s    s    s    where
s    f  f   f  and s    f  f   f  where f     joker in  at row      at row     
at row      at col      at col      at col       this equilibrium indeed reflects the intuition in
the scenario in example    where batman and robin together can infer the location of joker  while
any single one of them cannot accomplish this task without communication 
example   let m    c    c    c    c    be an mcs such that all li are asp logics  with signatures
     a        b        c  d  e   and      f  g   suppose
 kb       br      a       b        c   
   

fidao  t ran   e iter   f ink     k rennwallner

 kb       br      b       g   
 kb      c  d  d  c   br      c  e  not      f    
 kb      f  g    br      
one can check that s     a    b    c  d    g   is an equilibrium of m  
the computation of equilibria for a given mcs has been realized by a declarative implementation using hex programs  eiter et al         which can be evaluated using the dlvhex system  
the idea is to translate an mcs into a hex program with  i  disjunctive facts for guessing the
truth values of beliefs   ii  hex rules for capturing bridge rules  and  iii  constraints with external
atoms for capturing the acceptability functions  for further details on a concrete implementation
of this approach  we refer the reader to the mcs ie system  bogl  eiter  fink    schuller        
in this article  we pursue a more sophisticated approach  i e   we design and implement distributed
algorithms  to compute equilibria of mcss  during evaluation  there is no centralized component
that controls the communication between contexts  each context independently runs an instance of
the algorithm and communicates with each other to exchange beliefs as well as to detect and break
cycles  these novel contributions are described in the next sections 

   basic algorithm  dmcs 
this section introduces a very first  basic  truly distributed algorithm for evaluating equilibria of
an mcs  the algorithm takes a general setting as input  that is  each context has only minimal
knowledge about the whole system  or in other words  it just knows the interface with direct neighbors  parents and child contexts  but not the topological information or any further metadata of the
system  under this setting  we concentrate on distributeness  section   shifts the focus towards
optimization techniques when more metadata is provided 
taking a local stance  we consider a context ck and compute those parts of  potential  equilibria
of the system which contain coherent information from all contexts that are reachable from ck  
    basic notions
we start with some basic concepts  the import closure formally captures reachability 
definition    import closure  let m    c            cn   be an mcs  the import neighborhood of
context ck   k              n   is the set
in k     ci    ci   pi    b r   r  br k   
furthermore  the import closure ic  k  of ck is the smallest set s such that  i  k  s and  ii  for
all i  s  in i   s 
equivalently  we can define the import closure constructively by ic  k     k  
s
where ic    k    in k   and ic j    k    iic j  k  in i  

s

j  ic

j

 k  

example   consider m in example    then in              in      in           and in     
  the import closure of c  is ic                     see figure    
   www kr tuwien ac at research systems dlvhex 

   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

c 

c 

ic    

in   
c 

c 

c 

c 

c 

c 
 a  import neighborhood of c 

 b  import closure of c 

figure    import neighborhood and import closure
s 

s 

   



   



   

sj

   

sn

t  



   



   

ti

   

tj

   

tn

s    t  

s 

   



   

ti

   

sj    tj  

   

figure    joining partial belief states
based on the import closure we define partial equilibria 
definition
   partial belief states and equilibria  let m    c            cn   be an mcs  and let
sn

  i   bsi   then a sequence s    s            sn   such that si  bsi      for all    i  n  is
a partial belief state  pbs  of m   and s is a partial equilibrium  pe  of m w r t  ck   k              n  
if i  ic  k  implies si  acci  kb i   head  r    r  app br i   s     and i   ic  k  implies
si     for all    i  n 
note that ic  k  essentially defines a subsystem m   of m that is connected by bridge rules  we use
pes of m instead of equilibria of m   to keep the original mcs m intact 
for combining partial belief states s    s            sn   and t    t            tn    we define their
join s    t as the partial belief state  u            un   such that

si   if ti    or si   ti  
ui  
  for all    i  n
ti   if ti     and si    
 see figure     note that s    t is void  if some couples si   ti are from bsi but different  naturally 
the join of two sets s and t of partial belief states is then s    t    s    t   s  s  t  t   
example   consider two sets of partial belief states 
s         b      f  g         b      f  g     and
t          c  d  e    f  g          c  d  e    f  g          c  d  e    f  g     
   

fidao  t ran   e iter   f ink     k rennwallner

their join is given by

s    t  

    b    c  d  e    f  g        b    c  d  e    f  g   
    b    c  d  e    f  g  


 

    the basic algorithm
given an mcs m and a starting context ck   we aim at finding all pes of m w r t  ck in a distributed
way  to this end  we design an algorithm dmcs whose instances run independently at a node for
each context and communicate with each other for exchanging sets of partial belief states  this
provides a method for distributed model building  and the dmcs algorithm can be applied to any
mcs provided that appropriate solvers for the respective context logics are available  as a main
feature of dmcs  it can also compute projected partial equilibria  i e   pes projected to a relevant
part of the beliefs showing up in ck s import closure  this can be exploited for specific tasks
like  e g   local query answering or consistency checking  when computing projected pes  the
information communicated between contexts is minimized  keeping communication cost low 
in the sequel  we present a basic version of the algorithm  abstracting from low level implementation issues  the overall mcs structure is assumed to be unknown at context nodes  the idea is as
follows  starting from context ck   we visit its import closure by expanding the import neighborhood
at each context ci like in a depth first search  dfs   until a leaf context is reached or a cycle is detected  by finding the current context in the set hist of already visited contexts  a leaf context simply
computes its local belief sets  transforms them into partial belief states  and returns this result to its
parent  invoking context  figure  a   in case of a cycle  figure  c   the context ci which detects the
cycle must also break it  by  i  guessing belief sets for its export interface   ii  transforming the
guesses into partial belief states  and  iii  returning them to the invoking context 
an intermediate context ci produces partial belief states that will be joined  i e   consistently
combined  with partial belief states of its neighbors  to enable this  ci returns its local belief sets 
joined with the results of its own neighbors  figure  b  
for computing projected pes  the algorithm offers a parameter v called the relevant interface
which must fulfill some conditions w r t  import closure that we next discuss 
notation  given a  partial  belief state s and set v  b of beliefs  we denote by s v the restriction
of s to v  i e   the  partial  belief state s      s   v           sn  v    where si  v   si  v if si      and
 v     for a set s of  partial  belief states  we let s v    s v   s  s   next 
definition    recursive import interface  for an mcs m    c            cn   and k              n  
we call v k     pi    ci   pi    b r   r  brk   the import interface of context ck and v  k   
s
iic  k  v i  the recursive import interface of context ck  
for a correct relevant interface v  we have two extremal cases      v   v  k  and     v   vb   b 
in      dmcs basically checks for consistency on the import closure of ck by computing pes
projected to interface beliefs  in      it computes pes w r t  ck   in between  by providing a fixed
interface v  problem specific knowledge  such as query variables  and or infrastructure information
can be exploited to keep computations focused on relevant projections of partial belief states 
the projections of partial belief states are cached in every context such that recomputation and
recombination of belief states with local belief sets are kept at a minimum 
we assume that each context ck has a background process  or daemon in unix terminology 
that waits for incoming requests of the form  v  hist   upon which it starts the computation outlined
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

si  

s

ss    sj

lsolve s 

 v  hist 

  
 i


 v  hist 

sj

s

 

ci

c 

 v

 h

is
t

s

cj

c 
lsolve                 s
 a  leaf context

 b  intermediate context

v
ci

hi

st

 

  
 

  

i 

cj

  

  

c 
ct
 c  cycle breaking

figure    basic distributed algorithm   casewise
in algorithm    this process also serves the purpose of keeping the cache c k  persistent  we
write ci  dmcs v  hist  to specify that we send  v  hist  to the process at context ci and wait for
its return message 
algorithm   uses the following primitives 
 function lsolve s   algorithm     augments the knowledge base kb of the current context
with the heads of bridge rules in br that are applicable w r t  partial belief state s  computes
local belief sets using function acc  combines each local belief set with s  and returns the
resulting set of partial belief states  and
 function guess v  ck    guesses all possible truth assignments for the relevant interface w r t 
ck   i e   for bk  v  
dmcs proceeds in the following way 

 a  check the cache for an appropriate partial belief state 
   in order to relate beliefs in bk   v can either be a vector of sets  or variables in v are prefixed with context ids  for
simplicity  we kept v as a set without further assumptions 

   

fidao  t ran   e iter   f ink     k rennwallner

algorithm    dmcs v  hist  at ck    lk   kb k   br k  
input  v  relevant interface  hist  visited contexts
data  c k   static cache
output  set of accumulated partial belief states
 a 

if c k  is not empty then return c k 
s    

 b 
 c 

 d 

if k  hist then
s    guess v  ck  
else
t                   and hist    hist   k 
foreach i  in k  do
if for some t  t   ti    then
t    t    ci  dmcs v  hist 

 e 

foreach t  t do s    s  lsolve t  

 f 

c k     s v

   cyclic  guess local beliefs w r t  v
   acyclic  collect neighbor beliefs and add local ones

return s v
algorithm    lsolve s  at ck    lk   kb k   br k  
input  s  partial belief state s    s            sn  
output  set of locally acceptable partial belief states
t    acck  kb k   head  r    r  app brk   s   
return   s              sk    tk   sk             sn     tk  t 

 b  check for a cycle 
 c  if a cycle is detected  then guess partial belief states of the relevant interface of the context
running dmcs 
 d  if no cycle is detected  but import from neighbor contexts is needed  then request partial belief
states from all neighbors and join them 
 e  compute local belief states given the partial belief states collected from neighbors 
 f  cache the current  projected  partial belief state 
the next examples illustrate evaluation runs of dmcs for finding all partial equilibria with
different mcs  we start with an acyclic run 
example   reconsider m from example    suppose the user invokes c   dmcs v     where
v    a  b  c  f  g   to trigger the evaluation process  next  c  forwards in  d  requests to c 
and c    which both call c    when called for the first time  c  calculates in  e  its own belief sets
and assembles the set of partial belief states
s             f  g            f  g     
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

v

c      s 
c 
s    v

s    v

c      s 

c      s 
c 

c 
s    v

figure    a cyclic topology
after caching s   v in  f   c  returns s   v   s  to one of the contexts c    c  whose request arrived
first  on second call  c  simply returns s   v to the other context from the cache 
c  and c  next call lsolve  in  e   two times each  which results in s    s resp  s    t with
s  t from example   
s         b      f  g         b      f  g     and
t          c  d  e    f  g          c  d  e    f  g          c  d  e    f  g     
thus 
s   v

        b      f  g         b      f  g     and

s   v

         c    f  g          c    f  g          c    f  g     

c    after computing in  d 
s   v    s   v        b    c    f  g        b    c    f  g        b    c    f  g   
calls lsolve in  e  thrice to compute the final result 
s   v      a    b    c    f  g      a    b    c    f  g      a    b    c    f  g     
the next example illustrates the run of dmcs on a cyclic topology 
example   let m    c    c    c    be an mcs such that each li is an asp logic  and
 kb       br      a  not      b   
 kb       br      b       c    and
 kb       br      c  d  not      a   
figure   shows the cyclic topology of m   suppose that the user sends a request to c  by calling c   dmcs v    with v    a  b  c   in step  d  of algorithm    c  calls c   dmcs v       
then context c  issues a call c   dmcs v           thus c  invokes c   dmcs v              at
this point  the instance of dmcs at c  detects a cycle in  b  and guesses the partial belief states
s        a          a       
   

fidao  t ran   e iter   f ink     k rennwallner

for    v  then  following the dotted lines in figure    the set s    v   s   is the return value for
the request from c    which joins it with an initial empty belief state         gives us t and then
calls lsolve t   for each t  t in  e   resulting in
s       a      c  d      a      c  d      a      c  d     
the next step of c  is to return s   v back to c    which will proceed as c  before  the result is
the set of belief states
s       a    b    c      a    b    c      a    b    c     
which will be sent back to c  as s   v   notice that belief state   a    b    c   is inconsistent in
c    but will be eventually eliminated once c  evaluates s   v with lsolve 
next  c  will join s   v with         which yields s   v   and then use this result to call lsolve 
the union gives us
s       a    b    c      a    b    c     
which is also sent back to the user as final result 
given an mcs m    c            cn   and a context ck   using the recursive import interface of ck  
i e   v  k   as the relevant interface is a safe  lower  bound for the correctness of algorithm    in
what follows  let m   ck   and v  k  as above 
theorem    correctness of dmcs with partial equilibrium  for every v  v  k   it holds that
s    ck  dmcs v    iff m has some partial equilibrium s w r t  ck such that s     s v  
we can compute partial equilibria at ck if we use vb   this holds because using vb preserves
all belief sets returned from step  e   as the projection at step  f  takes no effect 
corollary   s is a partial equilibrium of m w r t  ck iff s  ck  dmcs vb     
under the assumption that m has a single root context c    i e   such that i  ic     for all
   i  n  dmcs computes equilibria 
corollary   if an mcs m has a single root context c    then s is an equilibrium of m iff s 
c   dmcs vb     
an analysis of the algorithm yields the following upper bound on the computational complexity
and communication activity 
proposition   let m    c            cn   be an mcs  in each run of dmcs at a context ck with an
interface v  it holds that
    the total number of calls to lsolve is exponentially bound by n   v   i e   o  n v    
    the number of messages exchanged between contexts ci   where i  ic  k   is bounded by
    e k    where e k      i  cj     i  ic  k   r  bri    cj   pj    b r   
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

    discussion
algorithm dmcs naturally proceeds forward in the import direction of context ck   thus  starting
from there  it computes partial equilibria which cover ck and contexts in its import closure  all
other contexts will be ignored  in fact  they are unknown to all contexts in the closure  while partial
equilibria may exist for ck and its import closure  the whole mcs could have no equilibrium 
because  e g    p   contexts that access beliefs from ck or its closure get inconsistent  or  p   an
isolated context or subsystem is inconsistent 
enhancements of dmcs may deal with such situations  as for  p    the context neighborhood
may include both importing and supporting contexts  intuitively  if ci imports from cj   then ci
must register to cj   by carefully adapting dmcs  we can then solve  p    however   p   remains 
this needs knowledge about the global system topology 
a suitable assumption is that a manager m exists which every context ci in the system can
reach and ask whether some isolated inconsistent context or subsystem exists  if m confirms this 
ci s dmcs instance simply returns   eliminating all partial equilibria 
to improve decentralization and information hiding  we can weaken the manager assumption by
introducing routers  instead of asking m  a context ci queries an assigned router r  which collects
topology information needed by ci or looks up a cache  the information exchange between ci and
r is flexible  depending on the system setting  and could contain contexts that import information
from ci   or isolated and inconsistent contexts 
a further advantage of topological information is that ci can recognize cyclic and acyclic
branches upfront  the invocation order of the neighborhood can then be optimized  by starting with
all acyclic branches before entering cyclic subsystems  the caching mechanism can be adapted
for acyclic branches  as intermediate results are complete and the cache is meaningful even across
different evaluation sessions 
in our setting  we are safe assuming that v  k   v  but this is not needed if m resp  ck s
import closure has no join contexts  i e   contexts having at least two parents  if we have access
to path information in m at each context  we could calculate v on the fly and adjust it during
mcs traversal  in particular  for a tree  or ring shaped m   we can restrict v to the locally shared
interface between ck and its import neighbors  i e   restricting v to the bridge atoms of br k   in
presence of join contexts  v must be made big enough  e g  using path information  furthermore 
join contexts may be eliminated by virtually splitting them  if orthogonal parts of the contexts are
accessed  this way  scalability to many contexts can be achieved 
next  we present optimization techniques using topological information of the system 

   topology based optimization algorithm  dmcsopt 
as a basic version  algorithm dmcs uses no further metadata apart from the minimal information
that each context must know  its interface with every neighboring context  there are scalability
issues which can be tracked down to the following problems 
    contexts are unaware of context dependencies in the system beyond their neighbors  and thus
treat all neighbors equally  specifically  cyclic dependencies remain undetected until a context 
seeing the invocation chain  requests models from a context in the chain  furthermore  a context
ci does not know whether a neighbor cj already requested models from another neighbor cj  
which then would be passed to ci   hence  ci makes possibly a superfluous request to cj    
   

fidao  t ran   e iter   f ink     k rennwallner

    a context ci returns its local models combined with the results from all its neighbors  in case of
multiple models  the result size can become huge as the system size and number of neighbors
increases  in fact  this is one of the main performance obstacles 
in this section we address optimizations to increase the scalability of distributed mcs evaluation  resorting to methods from graph theory  we aim at decomposing  pruning  and improved
cycle breaking for dependencies in mcss  focusing on      we describe a decomposition method
using biconnected components of inter context dependencies  based on it we can break cycles and
prune acyclic parts ahead and create an acyclic query plan  to address      we foster a partial view
of the system  which is often sufficient for a satisfactory answer  as a compromise between partial
information and performance  we thus define a set of variables for each import dependency in the
system to project the models in each context to a bare minimum such that they remain meaningful 
in this manner  we can omit needless information and circumvent excessive model combinations 
we proceed as follows  after introducing a running example and a superficial explanation of
optimization on it  we present the details of the techniques in section      section     introduces
the notion of query plans  which is used in section     to describe the algorithm dmcsopt that
intertwines decomposition and pruning with variable projection for performance gains in mcs evaluation 
    running scenario
we first present a scenario in example   as a running example for this section 
example    scientists group  a group of four scientists  alice  bob  charlie  and demi meets
after a conference closing to arrange travel back home  the options are going by train or by car
 which is slower   if they use the train  they should bring along some food  alice as the group
leader finally decides  based on the information she gets from bob and charlie  
alice prefers to go by car  but she would not object if bob and charlie want to go by train 
charlie has a daughter  fiona  he does not mind either option  but if fiona is sick he wants the
fastest transport to get home  demi just got married  and her husband  eddie  wants her to be back
soon  and even sooner if she would come soon  demi tries to yield to her husbands plea 
charlie is in charge of buying provisions if they go by train  he might choose either salad or
peanuts  notably  alice is allergic to nuts  the options for beverages are coke and juice  bob is
modest  he agrees to any choice of charlie and demi for transport but he dislikes coke  charlie
and demi do not want to bother the others with their personal matters and just communicate their
preferences  which is sufficient for reaching an agreement 

example    the scenario in example   can be encoded as an mcs m    c            c     where
alice      bob      etc in lexicographical order and all li are asp logics  the knowledge bases kbi
and bridge rules bri are as follows 




car    not train    
train         train           train     
c    kb    
and br    
 
  nuts    
nuts         peanuts     
   similar scenarios have already been investigated in the realm of multi agent systems  on social answer set programming see  e g   buccafurri   caminiti         we do not aim at introducing a new semantics for such scenarios  our
example serves as a plain mcs showcase for the algorithms 

   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

b 

 
 

 
 

 
 

 
 
 

 

b 

 

 

 

b 
 
 

 
 b  diamond ring block tree

 a  diamond ring

figure    topologies and decomposition of the scientist group example

c    kb  

c    kb  

c    kb  
c    kb  
c    kb  



 car         car           car      
     not car     not train      and br     train         train           train       


not      coke     


car    train     








train    urgent    
urgent         sick     
 
 
and br    
salad    peanuts    train     
train         train    





coke    juice    train  

 

 
  car    train    and br     train         sooner      

 

 
  sooner    soon   and br     soon         train      

 
  sick    fit    and br      

the context dependencies of m are shown in fig   a  m has three equilibria  namely 
   train       train       train     urgent     juice     salad       train     
 soon     sooner       sick      
   train       train       train     juice     salad       train       soon     sooner       fit       and
   car       car       car       car         fit      
example    consider an mcs m    c            c    with context dependencies as drawn in figure  a  when the user queries c  and just cares about the local belief sets in c    then in the
evaluation process  c  can discard all local belief sets of c  and c  when answering to a call from
c  or c    however  when c  calls c   or c     the invoked context must carry local belief sets of
c  in its answers to c    the reason is that belief sets of c  can cause inconsistent joins at c  for
partial belief states returned from c  and c    while those of c  to c  contribute only directly to
computing local belief sets at c    note that belief sets of c  to c  play no role in determining the
applicability of bridge rules in c   
   

fidao  t ran   e iter   f ink     k rennwallner

query

query
c 
c 

c 
c 

c 

c 

c 

 s

c 
 a  original topology

c 

c 

     s   
 b  triangle

c 

 

c 

c 

 

 

 s

  

 

c 

s 

 

c 

 

c 

c 

 c  transitive reduction

figure    topology of example     two stacked zig zag diamonds 
now  take a sub system including c    c    and c    assuming that c  has bridge rules with atoms
     p    and      p    in the body  and c  with atoms      p     that is  c  depends on both c  and
c    while c  depends on c   see fig   b   a straightforward approach to evaluate this mcs asks
at c  for the belief sets of c  and c    but as c  also depends on c    we would need another query
from c  to c  to evaluate c  w r t  the belief sets of c    this shows evident redundancy  as c  will
need to compute its belief sets twice  simple caching strategies could mellow out the second belief
state building at c    nonetheless  when c  asks c    the context will transmit its belief states back 
thus consuming network resources 
moreover  when c  asks for the pes of c    it will receive a set of pes that covers the belief sets
of c  and in addition of all contexts in c  s import closure  this is excessive from c  s view  as it
only needs to know about      p    and      p     however  c  needs the belief states of both c  and
c  in reply of c    if c  only reports its own belief sets  which are consistent w r t  c     c  cant
align the belief sets received from c  with those received from c    realizing that c  also reports
the belief sets of c    no call to c  must be made 
    decomposition of nonmonotonic mcs
based on the observations above  we present an optimization strategy that pursues two orthogonal
goals   i  to prune dependencies in an mcs and cut superfluous transmissions  belief state building 
and joining of belief states  and  ii  to minimize content in transmissions  we start with defining the
topology of an mcs 
definition    topology  the topology of an mcs m    c            cn   is the directed graph gm  
 v  e   where v    c            cn   resp  v               n  and  i  j   e iff some rule in br i has an
atom  j p  in the body 
the first optimization technique is made up of three graph operations  we get a coarse view of the
topology by splitting it into biconnected components  which form a tree representation of the mcs 
then  edge removal techniques yield acyclic structures 
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

in the sequel  we will use standard terminology from graph theory  see bondy   murty        
graphs are directed by default  we may view undirected graphs as directed graphs that have both
edges  u  v    v  u  for an undirected edge  u  v  
for any graph g and edges s  e g   we denote by g s the maximal subgraph of g having
no edges from s  suppose that v    v  g  is nonempty  then the subgraph g     v     e     of g
with vertex set v   and edge set e     u  v   e g    u  v  v  g   is the subgraph induced by
v     denoted by g v      the induced subgraph g v   v     is denoted by g v     it results from g by
deleting the vertices in v   together with their incident edges  if v      v   we write g v for g  v  
two vertices u and v of g are said to be connected  if there is a  directed  path from u to v
in g  i e   a sequence of vertices u   v    v            vn   v  such that  vi   vi      e g   for each i  
           n   the path is trivial if n      for an undirected graph g  connectedness is an equivalence
relation on v  g   thus there is a partition of v  g  into nonempty subsets v    v            vw such
that two vertices u and v of g are connected iff both of them belong to the same set vi   the
subgraphs g v     g v             g vw   are called the components of g  if w      i e   g has exactly
one component   then g is connected  otherwise  g is disconnected 
a directed graph g is strongly connected  if for each vertices u  v  v  g  a path from u to v
and vice versa exists  the strongly connected components of g are the subgraphs g v             g vm  
in the unique partition of the graph g into pairwise disjoint induced subgraphs  i e   vi  vj    
that are strongly connected 
furthermore  a directed graph g is weakly connected  if turning all edges into undirected edges
yields a connected graph  a vertex c of a weakly connected graph g is a cut vertex  if g c is
disconnected  a biconnected graph is a weakly connected graph without cut vertices 
a block in a graph g is a maximal
biconnected
subgraph of g  given a set of blocks b  the
s
s
union of blocks in b is defined as b   bb b  where the union of two graphs g     v    e   
and g     v    e    is defined as g   g     v   v    e   e    
let t  g     b  c  e  denote the undirected bipartite graph  called block tree of graph g 
where
 i  b is the set of blocks of g 
 ii  c is the set of cut vertices of g 
 iii  and  b  c   e with b  b and c  c iff c  v  b  
note that t  g  is a forest for any graph g and a rooted tree if g is weakly connected 
example    consider the graph in figure  a  one can check that   is the only cut vertex and there
are two blocks  viz  the subgraphs induced by              and              
the next example shows the block tree of our scenario in example   
example    the topology gm of m in example    is shown in figure  a  it has two cut vertices 
namely   and    thus the block tree t  gm    figure  b  contains the blocks b    b    and b    which
are subgraphs of gm induced by                       and         respectively 
a topological sort of a directed graph is a linear ordering of its vertices such that for every
directed edge  u  v  from vertex u to vertex v  u comes before v in the ordering 
   

fidao  t ran   e iter   f ink     k rennwallner

pruning  in acyclic topologies  like the triangle presented in figure  b  we can exploit a minimal
graph representation to avoid unnecessary calls between contexts  namely  the transitive reduction
of the graph gm   recall from aho  garey  and ullman        that a graph g is a transitive
reduction of the directed graph g whenever the following two conditions are satisfied 
 i  there is a directed path from vertex u to vertex v in g iff there is a directed path from u to v
in g  and
 ii  there is no graph with fewer edges than g satisfying condition  i  
note that g is unique if g is acyclic  for instance  the graph in figure  c is the unique transitive
reduction of the one in figure  a 
ear decomposition another essential part of our optimization strategy is to break cycles by removing edges  to this end  we use ear decompositions of cyclic graphs  a block may have multiple
cycles that are not necessarily strongly connected  thus we first decompose blocks into their strongly
connected components  using tarjans algorithm  tarjan        for this task  one gets as a byproduct a topological sort on the directed acyclic graph formed by the strongly connected components 
this yield a sequence of nodes r            rs that are used as entry points to each component  the next
step is to break cycles 
an ear decomposition of a strongly connected graph g rooted at a node r is a sequence p  
hp            pm i of subgraphs of g such that
 i  g   p       pm  
 ii  p  is a simple cycle  i e   has no repeated edges or vertices  with r  v  p     and
 iii  each pi  i      is a non trivial path  without cycles  whose endpoint ti is in p       pi   
but the other nodes are not 
let cb g  p   be the set of edges containing       r  of p  and the last edge   i   ti   of each pi   i     
here     is the vertex belonging to the edge to the root node r in the simple cycle p   
example    take  as an example  a strongly connected graph g in figure  a  an ear decomposition of g rooted at node   is p   hp    p    p    p  i where
vp               ep                             

vp               ep                     

vp               ep                     

vp            ep             

the last edges of pi are dashed  they form the set cb g  p                                      
removing these edges results in an acyclic topology as in figure  b 
intuitively  ear decomposition is used to remove cycles from the original system m   on the
resulting acyclic topology  algorithms for evaluating mcss can be designed more conveniently 
the trade off is that for any edge     t  removed from m   context c    despite being now a leaf
context  has to guess values for variables from ct   the following example shows the application of
the optimization techniques above to our running scenario 
example     contd  block b  of t  gm   is acyclic  and the transitive reduction gives b  with
edges                           b  is cyclic  and hb  i is the only ear decomposition rooted at   
removing cb b    hb  i              we obtain b   with edges           b  is acyclic and already
reduced  fig   b shows the final result  dotted edges are removed  
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

 

 

 

 

 

 

 

 

 

 

 a  a strongly connected component

 b  acyclic topology

figure    ear decomposition example
the graph theoretic concepts introduced here  in particular the transitive reduction of acyclic blocks
and the ear decomposition of cyclic blocks  are used to implement the first optimization of mcs
evaluation outlined above  intuitively  in each block  we apply ear decomposition to get rid of cycles  with the trade off of guessing   and then use transitive reduction to minimize communication 
given the transitive reduction b  of an acyclic block b  b  and a total order on v  b      one
can evaluate the respective contexts in the reverse order of this total order for computing pes at
some context ck   the first context simply computes its local belief sets whichrepresented as a
set of partial belief states s  constitutes an initial set of partial belief states t    in each iteration
step i     ti is computed by joining ti  with the local belief sets si of the considered context ci  
given the final tk   we have that tk  v  k  is the set of pes at ck  restricted to contexts in v  b     
refined recursive import  next  we define the second part of our optimization strategy which
handles minimization of information needed for transmission between two neighboring contexts
ci and cj   for this purpose  we refine the notion of recursive import interface  definition    in a
context w r t  a particular neighbor and a given  sub  graph 
definition   given an mcs m    c            cn   and a subgraph g of gm   for s
an edge  i  j  


e g   the recursive import interface of ci to cj w r t  g is v  i  j g   v  i    g j b  where
g j contains all nodes in g reachable from j  
example     contd  for the mcs in example     we have v         train     train     peanuts    
car     coke     car     train     sooner     sick      when we focus on block b    the refined recursive
import interface v        b  can be obtained by removing bridge atoms from contexts in the other
 
blocks b  and b    yielding  train     train     peanuts     car     coke     car     train     
algorithms  algorithms   and   combine the optimization techniques outlined above  intuitively 
optimizetree takes as input a block tree t with parent cut vertex cp and root cut vertex cr   it traverses t in dfs manner and calls optimizeblock on every block  the call results are collected in a
   note that v   k  is defined in definition   

   

fidao  t ran   e iter   f ink     k rennwallner

algorithm    optimizetree t    b  c  e   cp   cr  
input  t   block tree  cp   identifiesslevel in t   cr   identifies
level above cp
s
output  f   removed edges from b  v  labels for   b  f
b        f      v    
if cp   cr then
b       b  b   cr  v  b  
else
b       b  b    b  cp    e 

 a 

 b 

   initialize siblings b  and return values

foreach sibling block b  b   do
   sibling blocks b of parent cp
e    optimizeblock b  cp  
   prune block
 
c     c  c    b  c   e  c    cp  
   children cut vertices of b
b      b e  f    f  e
foreach edge  i  j  of b   dos
   setup interface of pruned b
s
v i  j     v  i  j b    cc   v  cp   bc     t e v  cp   bt
foreach child cut vertex c  c   do
   accumulate children
 f     v        optimizetree t  b  c  cp  
f    f  f     v    v  v  
return  f  v 

set f of removed edges  after all blocks have been processed  the final result of optimizetree is the
pair  f  v  where v is a labeling for the remaining edges  optimizeblock takes a graph g and calls
cyclebreaker for cyclic g  which decomposes g into its strongly connected components  creates
an ear decomposition p for each component gc   and breaks cycles by removing edges cb gc   p   
for the resulting acyclic subgraph of g  optimizeblock computes the transitive reduction g and
returns all edges that have been removed from g  optimizetree continues by computing the labeling v for the remaining edges  building on the recursive import interface  but keeping relevant
interface beliefs of child cut vertices and removed edges  example     appendix b  illustrates
algorithms   and   with a detailed run on the mcs in example    
formally  the following property holds 
proposition   given an mcs m and a context ck such that k is a cut vertex in the topology gm  
optimizetree t  gm    k  k  returns a pair  f  v  such that
 i  the subgraph g of gm  f induced by ic  k  is acyclic  and
 ii  in any block b of g and for all  i  j   e b   it holds that v i  j   v  i  j b  
regarding the computational cost of computation  we obtain 
proposition   given an mcs m and a context ck such that k is a cut vertex in the topology gm  
optimizetree t  gm    k  k  runs in polynomial  quadratic  time in the size of t  gm   resp  gm  

   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

algorithm    optimizeblock g   graph  r   context id 

 c 
 d 

f    
if g is cyclic then
f    cyclebreaker g  r 

   ear decomposition of strongly connected components

let g be the transitive reduction of g f
return e g    e g  

   removed edges from g

    query plan
given the topology of an mcs  we need to represent a stripped version of it that contains both
the minimal dependencies between contexts and interface beliefs that need to be transferred between contexts  this representation will be a query plan that can be used for execution processing 
syntactically  query plans have the following form 
definition     query plan  a query plan of an mcs m w r t  context ck is any labeled subgraph
 of gm induced by ic  k  with e    e gm    and edge labels v   e g      
for any mcs m and context ck of m   not every query plan is suitable for evaluating m  however 
the following query plan is in fact effective 
definition     effective query plan  given an mcs m and a context ck   the effective query plan
of m with respect to ck is k    v  g   e g  f  v  where g is the subgraph of gm induced by
ic  k  and  f  v    optimizetree t  gm    k  k  
we next use k for mcs evaluation  and tacitly assume that query plans are effective 
    evaluation with query plans
we now present the algorithm dmcsopt  which is based on dmcs but exploits the optimization
techniques from above  the idea of dmcsopt is as follows  we start with context ck and traverse
a given query plan k by expanding the outgoing edges of k at each context  like in a dfs  until
a leaf context ci is reached  the context simply computes its local belief sets  transforms all belief
sets into partial belief states  and returns the result to its parent  if ci has  j   p  in bridge rules
bodies but context cj is not in the query plan  this means we broke a cycle by removing the last
edge to cj    all possible truth assignments to the import interface to cj are considered 
the result of any context ci is a set of partial belief states  which amounts to the join  i e   the
consistent combination  of its local belief sets with the results of its neighbors  the final result is
obtained from ck   to keep recomputation and recombination of belief states with local belief sets
at a minimum  partial belief states are cached in every context 
algorithm   shows our distributed algorithm  dmcsopt  with its instance at context ck   on
input of the id c of a predecessor context  which the process awaits   it proceeds based on an
 acyclic  query plan r w r t  context cr   i e   the starting context of the system  the algorithm
maintains in cache k  a cache at ck  which is kept persistent  
 ci  dmcsopt c   send id c to dmcsopt at context ci and wait for its result 
 guess v   guess all possible truth assignments for the interface beliefs v 
   

fidao  t ran   e iter   f ink     k rennwallner

algorithm    dmcsopt c   context id of predecessor  at ck    lk   kb k   br k  
data  r   query plan w r t  starting context cr and label v  cache k   cache
output  set of accumulated partial belief states
 a 

 b 
 c 

 d 

 e 

if cache k  is not empty then
s    cache k 
else
t                  
foreach  k  i   e r   do t    t    ci  dmcsopt k 

   neighbor belief sets

if there is i  in k  s t   k  i  
  e r   and ti    for t  t then
t    guess v c  k      t
   guess for removed dependencies in r
s    
foreach t  t do s    s  lsolve t  
   get local beliefs w r t  t
cache k     s
if  c  k   e r    i e   ck is non root  then
return s v c k 
else
return s

 lsolve s   algorithm     given a partial belief state s  augment kbk with all heads from
bridge rules brk applicable w r t  s     kb k    compute local belief sets by acc kb k    and
merge them with s  return the resulting set of partial belief states 
the steps of algorithm   are explained as follows 
 a   b  check the cache  and if it is empty get neighbor contexts from the query plan  request
partial belief states from all neighbors and join them 
 c  if there are  i   p  in the bridge rules brk such that  k  i  
  e r    and no neighbor delivered
the belief sets for ci in step  b   i e   ti      we have to call guess on the interface v c  k 
and join the result with t  intuitively  this happens when edges have been removed from
cycles  
 d  compute local belief states given the partial belief states collected from neighbors  and
 e  return the locally computed belief states and project them to the variables in v c  k  for nonroot contexts  this is the point where we mask out parts of the belief states that are not needed
in contexts lying in a different block of t  gm   
theorem   shows that dmcsopt is sound and complete 
theorem   let ck be a context of an mcs m   let k be the query plan as in definition    and let
b    p  v k  j     k  j   e k     then 
v
 i  for each s    ck  dmcsopt k   there exists a partial equilibrium s of m w r t  ck such
that s     s vb   and
 ii  for each partial equilibrium s of m w r t  ck   there exists an s    ck  dmcsopt k  such
that s     s vb  
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

   streaming equilibria  dmcs streaming 
algorithm dmcsopt shows substantial improvements over dmcs  however  when the sizes of
the local knowledge bases and the context interfaces increase  it also suffers from bottlenecks 
this stems from the way in which models are exchanged between contexts  suppose context c 
accesses several neighbors c            cm under an acyclic information flow  and that each ci   i  n 
has ni pes  before ci computes in dmcs resp  dmcsopt any local models  it must join all pes
from its neighbors  this may lead to n   n       nm many pes  and each of them is an input
to the local solver  this may not only take considerable time but also exhaust memory  even before
local model computation starts 
note however that if instead each neighbor would transfer just a portion of its pes  then the
computation at c  can avoid such a memory blowup  moreover  this strategy also helps to reduce
inactive running time at c  while waiting for all neighbors to return all pes  as c  can already start
local computing while the neighbors are producing more models 
in general  it is indispensable to trade more computation time  due to recomputations  for less
memory if eventually all partial equilibria at c  shall be computed  this is the idea underlying a
streaming evaluation method for distributed mcs  it is particularly useful when a user is interested
in obtaining just some instead of all answers from the system  but also for other realistic scenarios
where the current evaluation algorithm does not manage to output under resource constraints in
practice any equilibrium at all 
in this section  we turn this idea into a concrete streaming algorithm dmcs streaming for
computing partial equilibria  its main features are briefly summarized as follows 
 the algorithm is fully distributed  i e   instances of its components run at every context and
communicate  thus cooperating at the level of peers 
 when invoked at a context ci   the algorithm streams  i e  computes  k    partial equilibria
at ci at a time  in particular  setting k     allows for consistency checking of the mcs
 sub  system 
 issuing follow up invocations one may compute the next k partial equilibria at context c 
until no further equilibria exist  i e   this evaluation scheme is complete 
 local buffers can be used for storing and exchanging local models  partial belief states  at
contexts  avoiding the space explosion problem 
as this section mainly studies the streaming aspect of the algorithm  we simplify the presentation and omit the interface between contexts  the principles presented here can be applied for
both dmcs and dmcsopt by adapting the interface and pruning the topology at preprocessing
time  furthermore  we assume to work with acyclic mcss  treatment of cyclic cases can be easily
achieved by adding guessing code to the solving component as in dmcs and dmcsopt 
to the best of our knowledge  a similar streaming algorithm has neither been developed for
the particular case of computing equilibria of a mcs  nor more generally for computing models of
distributed knowledge bases  thus  the results obtained here are not only of interest in the setting
of heterogeneous mcs  but they are also relevant in general for model computation and reasoning
over distributed  potentially homogeneous  knowledge bases like e g  distributed sat instances 
   

fidao  t ran   e iter   f ink     k rennwallner

request  k    k   

 k belief states

handler

ci

cj 

solver

joiner

  
 

output

cjm

figure    dmcs streaming architecture
algorithm    handler k    k    package range  at ci
output k     k    output k     k   
solver k     k    joiner k    k   k     
call solver

    basic streaming procedure
the basic idea is as follows  each pair of neighboring contexts can communicate in multiple rounds 
and each request has the effect to receive at most k pes  each communication window of k pes
ranges from the k   th pe to the k   th    k    k     pe  a parent context ci requests from a child
context cj a pair  k    k    and will receive some time later a package of at most k pes  receiving 
indicates that cj has fewer than k  models  a parallelized version is discussed in section     
important subroutines of the new algorithm dmcs streaming take care of receiving the
requests from parents  receiving and joining answers from neighbors  local solving and returning
results to parents  they are reflected in four components  handler  solver  output  and joiner
 only active in non leaf contexts   see figure   for an architectural overview 
all components except handler  shown in algorithm    communicate using message queues 
joiner has j queues to store partial equilibria from j neighbors  solver has one queue to hold joined
pes from joiner  and output has a queue to carry results from solver  to bound space usage  each
queue has a limit on the number of entries  when a queue is full  resp   empty   the enqueuing writer
 resp   dequeuing reader  is automatically blocked  furthermore  getting an element also removes
it from the queue  which makes room for other pes in the queue later  this property frees us from
synchronization technicalities 
algorithms   and   show how solver and joiner work  they use the following primitives 
 lsolve s   works as lsolve in dmcs and dmcsopt  but in addition may return only one
answer at a time and may be able to tell whether there are models left  moreover  we require that
the results from lsolve are returned in a fixed order  regardless of when it is called  this property is
the key to guarantee the correctness of our algorithm 
 get first           k   send to each neighbor from c   to c   a request for the first k partial equilibria  i e   k      and k    k  if they all return some models  store them in the respective queues
and return true  otherwise  return false  some neighbor is inconsistent  
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

algorithm    solver   at ci
data  input queue  q  maximal number of models  k 

 a 
 b 

count     
while count   k  do
if ci is a leaf then s    
else call joiner and pop s from q
if s    then count    k 

 c 

while count   k  do
pick the next model s   from lsolve s 
if s       then
push s   to output q
count    count    
else break
refresh   and push  to output q

 get next    k   request the next k equilibria from neighbor cc    if cc  sends back some models  store them in the queue q  and return true  otherwise  return false as the neighbor already
exhaustively returned its pes from the previous request  note that this subroutine needs to keep
track of which range has been already asked for to what neighbor  by maintaining a set of counters 
a counter w r t  a neighbor cc  is initialized to   and increased each time get next    k  is called 
when its value is t  the request to cc  asks for the tth package of k models  i e   models in the range
given by k     t      k     and k    t  k  when get first           k  is called  all counters in
range            are reset to   
 refresh    reset all counters and flags of joiner to their starting states  e g   first join to true 
all counters to   
the process at each context ci is triggered when a message from a parent  which contains the
range  k    k    arrives at handler  the latter notifies solver to compute up to k  models and output
to collect those in the range  k    k    and return them to the parent  furthermore  it sets the package
size at joiner to k   k   k      in case ci needs to query further neighbors  cf  algorithm    
when solver receives a notification from handler  it first prepares the input for the local solver 
if ci is a leaf context  the input s gets the empty set assigned in step  a   otherwise  solver triggers
joiner  step  b   for input from neighbors  fed with input from them  lsolve is used in step  c  to
compute at most k  results and send them to the output queue 
the joiner  which is only activated for intermediate contexts as discussed  gathers partial equilibria from the neighbors in a fixed ordering and stores the joined  consistent input to a local buffer 
it communicates just one input at a time to solver upon request  the fixed joining order is guaranteed by always asking the first package of k models from all neighbors at the beginning in step  d  
in subsequent rounds  we begin with finding the first neighbor cc  that can return further models
 step  e    and reset the query to ask for first packs of k models from neighbors from cc  to cc    
when all neighbors run out of models in step  f   the joining process ends and sends  to solver 
note that while the above procedure guarantees that no models are missed  it can lead to consider the same combinations  inputs to solver  multiple times  using a cache helps to mitigate
   

fidao  t ran   e iter   f ink     k rennwallner

algorithm    joiner   at ci
data  queue q            queue qj for in i     c            cj    buffer for partial equilibria  buf  
flag first join
while true do
if buf is not empty then
pop s from buf   push s to solver q
return

 d 

 e 

 f 

if first join then
if get first    j  k    false then
push  to solver q
return
else first join    false
else
      
while get next    k    false and    j do           
if        j then
get first          k 
else if     j then
push  to solver q
return
for s   q            sj  qj do add s           sj to buf
c 

c 

c 

c 

c 

c 

c 

figure     binary tree mcs

recomputation  but as unlimited buffering again quickly exceeds memory limits  recomputation is
an inevitable part of trading computation time for less memory 
the output component simply reads from its queue until it receives  or reaches k  models
 cf  algorithm     upon reading  it throws away the first k     models and only keeps the ones
from k  onwards  eventually  if fewer than k  models have been returned by solver  then output
will return  to the parent 
example    let m    c            cn   be an mcs such that for a given integer m      we have n  
 m      contexts  and let       be an integer  let all contexts in m have asp logics  for i    m  
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

algorithm    output   at ci
data  input queue  q  starting model  k    end model  k 
buf     and count     
while count   k  do
pick an s from output q
if s    then count    k     
else count    count    
while count   k      do
wait for an s from output q
if s    then count    k     
else
count    count    
add s to buf
if buf is empty then
send  to parent
else
send content of buf to parent

the context ci    li   kbi   bri   has
 
kbi  

 aji



aji

 ti      j     and bri  

 
fi
fi
ti    i   aj i   
fi j   
ti    i       aj i     fi

   

and for i   m   we let ci have
kbi    aji  aji      j     and bri     

   

intuitively  m is a binary tree shaped mcs with depth m and     is the size of the alphabet in each
context  figure    shows such an mcs with n     contexts and depth m      the internal contexts
have knowledge bases and bridge rules as in      while the leaf contexts are as in      the directed
edges show the dependencies of the bridge rules  such a system m has equilibria s    s            sn  
with si    aki   ti    for    k    
to compute one pe of m using dmcs or dmcsopt  one needs to transfer packages of   
pes from each context to its parent  as each context ci computes all subsets of  a i           a i     each
intermediate context receives    results from each of its children  whose join leads to     inputs for
lsolve  it invokes lsolve that often and only then returns its    models to the parent  which has to
wait for this 
on the other hand  dmcs streaming only needs to transfer a single pe between each pair
of connected contexts  which is a significant saving  indeed  consider e g  m             i e  
m    c    c    c     querying c  with package size k     first causes the query to be forwarded to
c  as a pair k    k       as c  is a leaf context  it invokes the local solver and eventually gets five
different models  however  it just returns one pe to c    say     a         note that t  is projected
off as it is not among the atoms of c  accessed by c    the same happens at c    which we assume
   

fidao  t ran   e iter   f ink     k rennwallner

to return       a      to c    at the root context c    the two pes from its neighbors are consistently
combined into     a       a       feeding this to the local solver  c  obtains five models  and returns
one of them  say s     a     t      a       a      
the following proposition shows the correctness of our algorithm 
proposition   let m    c            cn   be an mcs  i              n  and let k    be an integer  on
input     k  to ci  handler  ci  output returns up to k different partial equilibria with respect to ci  
and in fact k if at least k such partial equilibria exist 
    parallelized streaming
as one might expect  the strategy of ignoring up to k  models and then collecting the next k is
not likely to be the most effective  the reason is that each context uses only one solver  which in
general has to serve more than one parent  i e   requests for different ranges of models of size k 
when a new parent context requests models  we have to refresh the state of solver and joiner and
redo from scratch  this is unavoidable  unless a context satisfies the specific property that only one
parent can call it 
a way to address this problem is parallelization  the idea is to serve each parent with a suite
of handler  joiner  solver and output  the basic interaction between units is still as shown in
figure    with the notable difference that each component now runs in an individual thread  the
significant change is that solver does not control joiner but waits at its queue to get new input
for the local solving process  the joiner independently queries the neighbors  combines pes from
neighbors  and puts the results into the solver queue 
the effect is that we do not waste recomputation time for unused models  however  parallelization has its limits in practice  while dmcsopt may run out of memory  unlimited parallel
instances of the streaming algorithm can exceed the number of threads processes that the operating
system can support  this happens if contexts can reach others on many alternative paths  like in the
stacked diamond topology  the number of threads is exponential in the number of connected contexts  which prohibits scaling to large system sizes  however  in real world applications the number
of paths might still be ok 
a compromise between the two extremes is a bounded parallel algorithm  the idea is to create
a fixed size pool of multiple threads and components to share among the contexts  when incoming requests cannot be served with the resources available  the algorithm continues with the basic
streaming procedure  a realization remains for future work 

   experimental evaluation
we have implemented the algorithms above using c    in a system prototype called dmcs  which
is available online   for space reasons  we omit a detailed presentation and refer for it to the work
of bairakdar  dao tran  eiter  fink  and krennwallner      b   dao tran        ch      briefly 
the main components of the global architecture are  i  a command line frontend dmcs for the user
to access the system   ii  demons daemon which represent nodes that contain  a set of  contexts 
and  iii  a manager dmcsm containing meta information about the mcs  topology  interfaces  with
   http   www kr tuwien ac at research systems dmcs 
https   github com distributedmcs dmcs 

   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

c 

c 

c 

c 

c 

c 
c 

c 

c 

c 

c 

c 

c 

c 

c 

c 
c 

c 
c 

c 

c 

c 

c 

 a  binary tree  t 

c 

c 

 b  diamond  d 

 c  zig zag  z 

c 

 d  ring  r 

figure     topologies for testing dmcs algorithms
a helper dmcsgen for generating configurations with optimized components  contexts are implemented as groups of threads that communicate with each other through concurrent message queues 
the system has two main command line tools  viz  for running the algorihms and for test case generation  respectively  it allows to switch between different algorithms and modes by simply changing
the command line arguments 
we now turn to an experimental evaluation of dmcs under various aspects  next we describe
how the benchmarks were set up  and then we go into runs and results interpretation 
    benchmark setup
the idea is to analyze strong and weak points of each algorithm with respect to different parameters 
namely system topology  system size  local theory  i e   knowledge base  size  and interface size 
specifically  we considered mcss with topologies as in figure     including 
binary tree  t   binary trees grow balanced  i e   every level except the last one is complete 
with this topology  no edge needs to be removed to form the optimal topology  as every
intermediate node is a cut vertex  the import interface in the query plan is drastically reduced 
leading to an extreme performance improvement 
 stack of  diamond s   d   a diamond consists of four nodes connecting as c  to c  in figure   b  a stack of diamonds combines multiple diamonds in a row  i e   stacking m diamonds
in a tower of  m     contexts  similar to binary tree  no edge is removed in constructing
the query plan  w r t  this topology  every context connecting two diamonds is a cut vertex 
as such  the import interface in the query plan is refined after every diamond  this avoids
significantly repetition of partial pes in evaluation 
 stack of  zig zag diamond s   z   a zig zag diamond is a diamond with a connection between
the two middle contexts  as depicted by contexts c  to c  in figure   c  a stack of zigzag diamonds is built as above  this topology is interesting as after removing two edges per
block  the query plan turns into a linear topology 
ring  r   ring  figure   d   the query plan removes the connection from context cn to c  and
then carries the interface between them all the way back to c    this topology requires guess   

fidao  t ran   e iter   f ink     k rennwallner

a 

a 

a 

a 

a 

a 

a 

a 

figure     local theory structure
ing and checking in any dmcs algorithm  thus it is quite unpredictable which algorithm
performs better in general 
the other quantitative parameters are represented as tuple p    n  s  b  r   where
 n is the system size  number of contexts  
 s is the local theory size  number of ground atoms in a local theory  
 b is the number of local atoms that can be used as bridge atoms in other contexts  in other
words  the number of interface atoms  and
 r is the maximal number of bridge rules  the generator generates a bridge rule while iterating
from   to r with     chance  hence on average r   bridge rules are generated  we allow
bridge bodies of size   or   
a test configuration is formulated as x  n  s  b  r  where x   t  d  z  r  represents the topology and n  s  b  r are integers representing the quantitative  i e   size related  parameters  as we
would like to run several instances over one configuration  the final formulation of a test instance is
xi   n  s  b  r   where i is the index of the test instance 
inside each context  the local theories are structured as follows  context ci has s ground atoms
indicated by ai             ai s   rules are of the form ai j  not ai k where k   j      if j is odd 
otherwise  we randomly choose k to be j    or j     with a probability of     for each possibility 
in case if k   s then the rule does not exist  an example of a context with local theory size is   can
be illustrated with the dependency graph as in figure     here  the bold arrows stand for the fixed
rules while dashed arrows stands for the rules decided by randomization  the corresponding local
theory of this figure is 


a   not a 
a   not a 

a   not a 
a   not a 

a   not a 
a   not a 

a   not a 
a   not a 


 

with this setting  a local context has  m answer sets  where m      s    
furthermore  one can obtain deterministic contexts  having just one answer set  by disallowing
cycles in the structure of local theories 
    experiments
we conducted the experiments on a host system using   core intel r  xeon r  cpu    ghz processor with   gb ram  running ubuntu linux          furthermore  we used dlv  build ben sep
        gcc        as a back end asp solver 
we ran a comprehensive set of benchmarks under the setup described in section      as the
parameter space p    n  s  b  r  is huge  we singled out in an initial probing phase the following
values for the experiments 
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

    

dmcs
dmcsopt

   

  

 

   

    
  

t        
 

 

d        
  

z        
  

r        
  

t         
  

d         
  

  

z         
  

r         
  

  

figure     dmcs vs  dmcsopt in non streaming mode
 for the system size n  depending on the topology 
t 
d 

n                          
n                        

z 
r 

n                            
n                    

 s  b  r are fixed to either          or             respectively 
a combination of topology x and parameters p    n  s  b  r  is denoted by x n  s  b  r  or x n s b r
 used in figures   each parameter setting has been tested on five instances  for each instance 
we measured the total running time and the total number of returned partial equilibria on dmcs 
dmcsopt in non streaming and streaming mode  for the latter mode  dmcs streaming  we
asked for k answers  where k                this parameter also influences the size of packages
transferred between contexts  at most k partial equilibria are transferred in one message   as in
streaming mode  asking for more than one pe may require multiple rounds to get all answers  it is
of interest to see how fast the first answers arrive compared to having all answers  we thus compared
the running time of these tasks for k      and k       
    observations and interpretations
figures       summarize the results of our experiments  run times are in seconds and timeout
is     seconds  from these data  several interesting properties can be observed  we organize
our analysis along the following aspects      comparing dmcs and dmcsopt      comparing
streaming and non streaming mode      effect of the package size      role of the topologies  and
    the behavior of the algorithms on deterministic contexts 
      dmcs vs   dmcsopt
figure    shows the running time of dmcs and dmcsopt for computing all partial equilibria  i e  
in non streaming mode  of five instances of the respective parameter settings  clearly dmcsopt
outperforms dmcs  this can be explained by the fact that when computing all answers  dmcs
always produces more partial equilibria than dmcsopt  as one pe returned by dmcsopt can
   

fidao  t ran   e iter   f ink     k rennwallner

   

   
dmcs  st
dmcsopt  st
dmcs   
dmcsopt   

dmcs  st
dmcsopt  st
dmcs    
dmcsopt    

  

  

 

 

   

t 

t 

t 

t 

t 

d 

 a  t               

d 

d 

d 

d 

 b  d              

    

   
dmcs  st
dmcsopt  st
dmcs   
dmcsopt   

dmcs  st
dmcsopt  st
dmcs   
dmcsopt   

   

  

  

 

 

   

   

z 

z 

z 

z 

z 

r 

 c  z              

r 

r 

r 

r 

 d  r             

figure     dmcs vs  dmcsopt in streaming mode
be obtained from projecting many partial equilibria returned by dmcs on the imported interface 
furthermore  all intermediate results are transferred in one message  which makes no difference
in terms of the number of communications between the algorithms  as such  dmcs must spend
more time on processing possibly exponentially more input  hence  unsurprisingly  it is consistently
slower than dmcsopt 
however  the observation in streaming mode is different  figure    shows the running time of
dmcs and dmcsopt in streaming mode to compute the first     respectively    unique partial
equilibria for t                respectively d                z               and r               on a
first view  as dmcsopt is consistently slower than dmcs  one might question the correctness of
the results  however  they are not a surprise  again a pe returned by dmcsopt should correspond to several pes returned by dmcs  hence  the batch of the first k unique answers in dmcs
corresponds to only a smaller number of  few  unique answers in dmcsopt 
therefore  comparing dmcs and dmcsopt in streaming mode by measuring the runtime to
compute the first k answers is not fair  we thus took the time when both algorithms finished the first
round of answers  denoted by dmcs  st and dmcsopt  st in figure      with this setting  we
observed the following 
 on the majority of cases dmcsopt finishes the first round faster than dmcs  however in
about     of the instances  it is the other way around  this shows the effect of using the query plan 
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

 however  in some cases dmcs wins  this can be explained as follows  first of all  in streaming
mode  we transfer only packages of k partial equilibria at a time  therefore  the effect of reducing the
amount of total work to be done does not always apply as in the non streaming mode  furthermore 
at every context  we compute k pes and project them to the output interface before returning the
results  according to this strategy  when a context ci returns k  partial equilibria in non streaming
mode and k  partial equilibria in streaming to another context cj   it might happen that k  is much
smaller than k  and hence does not provide enough input for cj to compute k pes  therefore  cj
will issue more requests to ci asking for further packages of k pes  e g    k       k     k       k  
etc  and this costs dmcsopt more time to even compute the first batch of pes at the root context 
another approach is to compute always k unique partial equilibria before returning to a parent
context  however  this strategy risks to compute even all local models before k unique partial
equilibria can be found 
overall  there is not much difference in running time when dmcsopt is slower than dmcs  except
for instance r   figure   d   this however comes from a different reason  the cyclic topology with
guess and check effects  which play a much more important role than choosing between dmcs and
dmcsopt  see section        
      s treaming vs   n on   streaming dmcs
we now compare streaming and non streaming for the same algorithm  dmcs resp  dmcsopt  
figure    shows the results for dmcs in    a   and the results for dmcsopt to compute
the first    resp      pes with small systems local knowledge bases in    b  and with large systems local theories in    c   excluding ring  which behaves abnormally due to guess and check 
one can see that 
 for dmcs  the streaming mode is definitely worth pursuing since dmcs in non streaming
mode times out in many cases  see also figure      while in streaming mode we still could find
some answers after a reasonable time 
 for dmcsopt  the situation is a bit different  as streaming loses against non streaming on
small instances  this is due to the recomputation that the streaming mode pays for transferring just
chunks of partial equilibria between contexts  furthermore  there are duplications between answers 
when one moves to larger systems and local knowledge bases  the streaming mode starts gaining
back  however  it does not always win  as recomputation still significantly takes time in some cases 
summing up  when the system is small enough  one should try the non streaming mode as it
avoids recomputation and duplication of pes between different rounds of computation  but for large
systems  streaming can rescue us from timing out  even if we have to pay for recomputation  it still
helps in cases when some but not all results are needed  e g  in brave query answering  membership
of the query in some pe  
      e ffects of the package s ize in s treaming m ode
the considerations above raise the question of the optimal number of pes that should be transferred
in return messages between contexts  we will analyze the experimental results on the streaming
mode with package sizes        and     to give some hints on this 
figure    shows the average time to compute   pe of dmcsopt in streaming mode with
respect to three package sizes  one can see that transferring just a single pe to get the first answer
   

fidao  t ran   e iter   f ink     k rennwallner

    

non streaming
streaming   
streaming    

   

  

 

   

    
  

t         

 

 

d         
  

  

z         

  

r        
  

  

 a  dmcs
    

non streaming
streaming   
streaming    

   

  

 

   

    
  

t         

 

 

d         
  

  

z         

  

r        
  

  

 b  dmcsopt with small systems and local theories
    

non streaming
streaming   
streaming    

   

  

 

   

    
  

 

t           

 

d           
  

  

z           

  

r          
  

  

 c  dmcsopt with large systems and local theories

figure     non streaming vs  streaming under dmcs and dmcsopt
is acceptable in most cases  in particular if no guessing is needed  moving from size   to a small
package size like    here is sometimes better  as one can save communication time  sending once
a package of    partial equilibria vs  sending ten times a package with a single pe   this setting
 small package sizes like     will be more effective when communication is a big factor  which
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

    

streaming  
streaming   
streaming    

   
  
 
   
    
     
  

 

t            

 

d           

  

z           
  

r          
  

  

figure     average time of dmcsopt to find one partial equilibrium in streaming mode  varying
package size
happens in real applications where contexts are located at physically distributed nodes  in such
cases  computing    partial equilibria should be faster than computing   pe in    consecutive times 
furthermore  having package of size   is not safe in cases where guessing is applied  e g   in
r                   for these cases  a large enough package size might help to cover the correct
guess  but in general  there is no guarantee for such a coverage  to thoroughly solve this problem 
one needs to apply conflict learning on the whole mcs evaluation 
also  it is interesting to see that with package size      dmcsopt usually times out  the
reason is that there are many duplications and once dmcsopt is stuck with a local search branch
that promises fewer than     partial equilibria  the algorithm will lose time here without finding
new unique answers and will eventually time out 
to find a good package size p with a specific setting  topology  system size  local theory size  
one may run the system on a training set and apply binary search on p 
      e ffect of t opology
a quick glance over all plots in figures      reveals the pattern that the algorithms  especially
the optimizations  perform better on tree than on zigzag and diamond  depending on dmcs or
dmcsopt  and worst on ring 
the system topology plays an important role here  the aspects that affect the performance of
the algorithms are  i  number of connections   ii  the structure of block trees and cut vertices  and
 iii  acyclicity vs  cyclicity 
regarding  i   the topology introduces the number of connections based on the system size  tree
has fewer connections than diamond and zigzag  which reduces not only communication but also
local solving time as fewer requests are made  and the performance of dmcs on these topologies
proves this observation  if one follows this argument  then ring must offer the best performance 
however  this is actually not the case due to aspect  iii  that we will shortly analyze below 
concerning  ii   tree can be ultimately optimized as every intermediate node is a cut vertex 
hence  when applying the query plan for dmcsopt  we can strip off all beliefs in pes sent from
child contexts to a parent context  in other words  only local beliefs at a context ci are needed
to be transferred back to its parents  this drastically decreases the amount of information to be
   

fidao  t ran   e iter   f ink     k rennwallner

    
dmcs    
dmcsopt    

   

  

 
  

 

r        
 

 

 

r        
 

  

  

r          
  

  

  

figure     dmcs vs  dmcsopt in streaming mode with package size     on ring
communicated  and more importantly  the number of calls to lsolve  due to this special property 
dmcsopt performs extremely well on the tree topology  and scales to hundreds of contexts 
comparing diamond and zigzag  they have the same number of cut vertices  however  zigzag
is converted to a linear topology with an optimal query plan  cf  figure   c   and therefore can be
processed much faster than diamond  in figure     dmcsopt scales on zigzag to    contexts with
an average time to compute one answer that still better than the one on diamond with    contexts 
regarding  iii   ring is a cyclic topology while the other topologies are acyclic  hence each
of the algorithms must do some guess and check at some context in the topology  making the
right guess is most important  even more important than reducing communication and calls to local
solvers  the result of running dmcs and dmcsopt on this topology  figure     does not follow
any pattern  it absolutely depends on a specific instance whether the above sequential guessing
luckily arrives at the result  therefore  we frequently see that dmcs outperforms dmcsopt in
streaming mode  as in such cases  guessing at the root context  after detecting the cycle  is more
effective than guessing at the parent of the root context according to the optimal query plan 
based on these observations  one can come up with a best strategy to evaluate different types of
topologies  when dealing with mcss of arbitrary topologies  it looks natural to decompose them
into parts of familiar topologies for which efficient strategies are known  and to combine then these
strategies to an overall evaluation method  studying this is beyond the scope of this work and an
interesting issue for future research 
      b ehavior on d eterministic c ontexts
above we considered our algorithms on mcss consisting of possibly non deterministic contexts 
i e   they can have more than one acceptable belief set per knowledge base  it is intriguing to see how
the algorithms behave if all contexts always have exactly one accepted belief set per knowledge base 
this might be because the underlying logic is genuinely deterministic and the accepted belief set
clear  e g   closure in classical logic  or among multiple candidates a particular belief set is chosen
 in implementations typically the first or a best solution computed  e g  in sat solving or in asp  
we observed that 
 for non cyclic topologies  there is no performance difference between dmcs and dmcsopt 
because the smaller interface used in dmcsopt does not reduce the number of intermediate pes
transferred between contexts  as there is only one partial equilibrium computed at every context 
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

    

dmcs
dmcsopt
mcs ie

   

  

 

   

    
  

t        
 

 

d        
  

z        
  

r        
  

t         
  

d         
  

  

z         
  

r         
  

  

figure     dmcs vs  dmcsopt in streaming mode with package size     on ring
 for cyclic topology  ring   guessing plays the main role  hence it depends on the individual
instance whether dmcs or dmcsopt wins  like in the case of non deterministic contexts  cf 
section        
 non streaming mode is much faster than streaming  on both dmcs and dmcsopt   this is
reasonable as any request for further partial equilibria is redundant 
      c omparison with mcs ie and p p dr
systems close to dmcs are mcs ie  bogl et al          and p p dr  bikakis  antoniou    hassapis         the former is a plugin of the dlvhex system and was originally developed to compute
explanations for inconsistency in multi context systems  but also includes a mode for computing
equilibria of an mcs  however  mcs ie was implemented with a centralized approach  figure   
presents the run time of dmcs  dmcsopt in comparison with mcs ie in computing all partial equilibria of the respective configurations  it shows that mcs ie outperforms dmcs since it
inherits a powerful decomposition technique from dlvhex  however  the decomposition based on
topological information of dmcsopt turns out to be more efficient  as it also localizes the interface beliefs to communicate between blocks of contexts  which is specific for mcs and is not
exploited by the general decomposition technique in dlvhex 
p p dr supports distributed query answering for multi context systems based on defeasible
logic  for more details  see section    we present here a comparison between dmcs and p p dr 
we converted our benchmark to p p drs style by converting the local knowledge bases and
bridge rules to defeasible local and meta rules  and added a fixed trust order between contexts  we
then queried the root context with an atom appearing in one of the answers of dmcs streaming
with package size     it turned out that p p dr always found the answers in around      seconds 
regardless of the tested instance  this behavior can be explained as follows  to find answers for a
query atom  the algorithm of p p dr first evaluates the local theory  if it can determine the truth
value of the query  it terminates  otherwise the algorithm consults neighbors to get further evidence
for the reasoning  as our local knowledge base structure  when converted to p p drs defeasible
theories  allows for a local decision  the system works only on the local theory of the root context
   http   www kr tuwien ac at research systems mcsie tut 

   

fidao  t ran   e iter   f ink     k rennwallner

for every test case  thus results in almost constant execution time  even when asking neighbours is
necessary  p p dr in general may be much faster than dmcs  as the query answering process is
inherently deterministic and in a low complexity logic  in turn  the formalism is less expressive  a
detailed study of this issue remains for future work 
      s ummary
summing up  the analysis of the experimental results shows that there is no clear winner among the
algorithms  dmcs vs  dmcsopt  under different running modes  streaming vs  non streaming 
with different package size  on different topologies  we can distill from it a guideline to choose the
setup that fits specific instances in practice  including some issues open for further investigation 
which can be briefly stated as follows 
 choose dmcsopt over dmcs in non streaming mode  except for cyclic topologies 
 in streaming mode  choose an appropriate package size carefully  e g   doing a binary search
on some training instances 
 decompose random topologies into parts whose topologies have effective strategies to evaluate 
and study how to combine the strategies for the over all systems 

   related work
in this section  we resume the discussion of related work  starting with multi context systems  we
provide more details on the work by roelofsen et al          bikakis et al         and consider other
work  we then move to related formalisms in sat  csp and asp 
roelofsen et al         described evaluation of monotone mcs with classical theories using
sat solvers for the contexts in parallel  they used a  co inductive  fixpoint strategy to check mcs
satisfiability  where a centralized process iteratively combines results of the sat solvers  apart
from being not truly distributed  an extension to nonmonotonic mcs is non obvious  furthermore 
no caching technique was used 
serafini  borgida  and tamilin        and serafini and tamilin        developed distributed
tableaux algorithms for reasoning in distributed ontologies  which can be regarded as multi context
systems with special bridge rules  the algorithms serve to decide whether such a system is consistent  provided no cyclic context dependencies exist  in technical terms  the distributed tbox is
acyclic   the drago system  serafini   tamilin        implements this approach for owl ontologies  compared to ours  this work is tailored for a specific class of multi context systems resp 
knowledge bases  without nonmonotonic negation and cyclic dependencies  which are challenging   furthermore  it targets query answering rather than model building  which in a sense is a dual
problem 
more related to our work as regards distributed evaluation is the the system p p dr of bikakis
et al          they developed a distributed algorithm for query evaluation in a multi context system
framework that is specifically based on  propositional  defeasible logic  in this framework  contexts are built using defeasible rules and can exchange literals via bridge rules  and a trust order
between contexts is be supplied  each knowledge base at a context has  in our terminology  a single
accepted belief set which contains the literals concluded  the global system semantics is given in
terms of a  unique  three valued assignment to all literals  which can be determined using the algorithm  whether literal l is provably  not  a logical conclusion of the system  or whether this remains
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

open  apart from being tailored to a particular logic and preference mechanisms for evaluating interlinked contexts  applying this algorithm to model building is not straightforward  in particular  as
it produces unique belief sets  dealing with nondeterminism and multiple equilibria is not possible 
our work on computing equilibria for distributed multi context systems is clearly related to
work on solving constraint satisfaction problems  csp  and sat solving in a distributed setting 
yokoo and hirayama        survey some algorithms for distributed csp solving  which are usually developed for a setting where each node  agent  holds exactly one variable  the constraints
are binary  communication is done via messages  and every node holds constraints in which it is
involved  this is also adopted by later works  gao  sun    zhang        but can be generalized
 yokoo   hirayama         in relation to the topology based optimization techniques in section   
biconnected components are used by baget and tognetti        to decompose csp problems  the
decomposition is used to localize the computation of a single solution in the components of undirected constraint graphs  along the same lines  our approach is based on directed dependencies 
which allows us to use a query plan for mcs evaluation 
the predominant solution methods in csp are backtracking algorithms  bessiere  bouyakhf 
mechqrane  and wahbi        took them a step further with backtracking on a dynamic total ordering between agents guided by nogoods  our approach  however  allows for cyclic dependency
between contexts  hirayama and yokoo        presented a suite of algorithms for solving distributed sat  dissat   based on a random assignment and improvement flips to reduce conflicts 
however  these algorithms are geared towards finding a single model  and an extension to streaming
multiple  or all  models is not straightforward  for other works on distributed csp and sat  this is
similar 
finally   distributed  sat and csp solving concerns monotonic systems  removal of clauses
resp  constraints preserves satisfiability   while mcss evaluation concerns nonmonotonic systems 
even if all contexts were monotonic  e g   clause sets   this makes efficient evaluation more difficult 
as important structural properties of the search space cannot be exploited 
adjiman  chatalic  goasdoue  rousset  and simon        present a framework of peer to peer
inference systems  where local theories of propositional clause sets share atoms and a special algorithm for consequence finding is available  as we pursue the dual problem of model building 
applying it for our needs is not straightforward  furthermore  we are dealing with non monotonic
systems  while the peer to peer systems by adjiman et al  are monotonic 
moving to asp  pontelli  son  and nguyens        asp prolog shares with mcs the idea
of integrating several knowledge bases  called modules  possibly under different semantics  however  they restricted module semantics to asp and prolog  that is  the least herbrand model   and
asp prolog pursues query answering instead of model building 
as for streaming  an answer set streaming algorithm for hex programs  which generalize asp
with external information access  was given by eiter  fink  ianni  krennwallner  and schuller
        despite some similarities to algorithm dmcs streaming  it is rather different  monolithic programs are syntactically decomposed into modules and answer sets computed in a modular
fashion  it is not fully distributed and combines partial models from lower components to input for
upper components straightforwardly  moreover  it may use exponential space in components 
   

fidao  t ran   e iter   f ink     k rennwallner

   conclusion
we have considered distributed evaluation of multi context systems  mcss  that were introduced
by brewka and eiter        as a general formalism to interlink possibly nonmonotonic and heterogeneous knowledge bases  we have presented a suite of generic algorithms to compute the equilibria  i e   the semantics of an mcs in a fully distributed manner  using local solvers for the knowledge
bases at the contexts  it contains a basic algorithm dmcs  an advanced version dmcsopt that
uses topology based optimizations  and a streaming variant dmcs streaming for computing
partial equilibria gradually  we believe that the underlying principles and techniques might be
exploited in related contexts  and in particular for distributed evaluation of other non monotonic
knowledge base formalisms 
the algorithms have been implemented in a prototype system that is available as open source  
on top of this implementation  we have conducted comprehensive experiments to compare the performance of the algorithms and we gave an insight analysis on the results  it points out advantages 
disadvantages as well as the time memory trade off between the algorithms in different situations
depending on parameters such as system topology  local interface and theory size  and number of
equilibria desired by the user  based on this  the user can choose the setting  algorithm and mode 
that fits her need best for finding  partial  equilibria of an mcs  a more extensive treatment is given
by dao tran        
further work and open issues  several issues remain for further investigation  one is further improvement of the algorithms  here  the experimental results on the ring topology strongly suggest
to incorporate conflict learning  which proved to be valuable in asp and sat solving  to dmcs
and dmcsopt  we expect that cyclic topologies will benefit from a better guided guessing process  another issue concerns further semantics and variants of mcss  as for the former  grounded
equilibria are considered by dao tran         which are akin to answer sets of logic programs and
applicable to mcss that satisfy certain algebraic conditions  they can be characterized like answer
sets using an  adapted  loop formula approach  lee   lifschitz         dealing with supported
equilibria  tasharrofi   ternovska         however  is open 
regarding mcs variants  managed mcss  brewka et al         generalize bridge rules to derive
operations  commands  for a management function that is applied on the knowledge bases  it seems
possible to generalize our algorithms to this setting  but an efficient realization is not straightforward  another generalization of mcs concerns dynamic data  in areas like sensor networks  social
networks  or smart city applications  data may change or even continuously arrive at nodes  which
motivates reactive and stream processing for mcss  goncalves et al         brewka et al         
last but not least  allowing contexts to evolve via interation with users or with changes in the environment is a valuable extention  extending our algorithms to these settings is interesting but
challenging 
finally  extending this work to query answering over mcss  where the user poses a query at a
context and receives results derived from  partial  equilibria is another natural issue  as there is no
need for building whole equilibria  better performance may be achieved 

acknowledgments
this research has been supported by the austrian science fund  fwf  projects p      and
p      
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

c    

c 

c 

c    

c 

c 

c    

figure     introducing guess context s 
we thank to the reviewers for pointing out corrections and their constructive suggestions which
helped to improve the presentation of this work  and we thank antonis bikakis for providing us with
the p p dr system for the experimental comparison 

appendix a  proofs
proof of theorem  
to prove this theorem  we first prove the following lemmas   and     the latter aims at simplifying
the proof for the cyclic case  based on the notion of converting cyclic mcss to acyclic ones 
lemma   for any context ck and partial belief state s of an mcs m    c            cn   
app brk   s    app brk   s v   for all vb  v  v  k  
proof for any r  app brk   s   we have that for all  ci   pi    b    r    pi  sci and for all
 cj   pj    b   r    pj 
  scj   we need to show that pi  sci  vci  pj 
  scj  vcj   indeed 
we have v  vb  vcj  vbj  scj  vcj  scj   therefore  pj 
  scj  pj 
  scj  vcj  
now  assume that pi 
  sci  vci   from the fact that pi  sci   it follows that pi 
  vci   hence

pi 
  v  k   but this is in contradiction with the fact that pi occurs in some bridge rule body 
therefore  r  app brk   s v   

the next lemma    is based on the following notions that convert cyclic mcss to acyclic
ones and show that they have corresponding equilibria  the intuition  illustrated in figure    and
examples         is to introduce an additional context ck to take care of guessing for every cycle
breaker ck   then  the bridge rules of ck and its parents are modified to point to ck   we now
formally realize this idea starting with a function ren that renames part of the bridge rules 
definition    let ck be a context in an mcs m   and let v be an interface for running dmcs  the
renaming function ren is defined as follows 

 for an atom a  ren a  k  v   

ag
a

if a  bk  v
otherwise


 for a context index c  ren c  k  v   

c
c

if c              n 
otherwise

 for a bridge atom  ci   pi    ren  ci   pi    k  v     ren ci   k  v    ren pi   k  v  

   

fidao  t ran   e iter   f ink     k rennwallner

 for a bridge body b     c    p           cj   pj    
ren b  k  v     ren  ci   pi    k  v     ci   pi    b 
 for a bridge rule r   head  r   b r  
ren r  k  v    head  r   ren b r   k  v 
 for a set of bridge rules br   ren br   k  v     ren r  k  v    r  br  
 for a context ci    li   kb i   br i   in m   ren ci   k  v     li   kb i   ren bri   k  v   
example    let us slightly modify the mcs m    c    c    c    from example   as follows 
 kb      e  e   br      a       e   not      b   
 kb       br      b       c    and
 kb       br      c  d  not      a   
applying function ren to contexts c  and c  results in the following bridge rules wrt  an interface v    a  b  c  e  
 ren br        v     a       eg    not      b   
 ren br        v     c  d  not      ag    
for two contexts ci and cj   the former is called a parent of the latter with respect to an interface
v  denoted by parent ci   cj   v  iff there exists a bridge rule r  br i such that there exists  c   p  
b r  and p  bj  v 
a set of contexts  cc    cc            cc    of an mcs m is called a cycle w r t  an interface v iff
 
parent cc    c    v  
parent cci   cci     v 
 i  

holds  one can pick an arbitrary context in this set to be its cycle breaker  given an mcs m   there
are several ways to choose a  finite  set of its contexts to be cycle breakers  in algorithm dmcs 
step  d  practically establishes the cycle breakers based on the order that elements in in k  are
iterated  for the next definition  we are interested in this particular set of cycle breakers 
definition    given an mcs m    c            cn    let cb rm    cc            ccj   be the set of cyclebreakers for m based on the application of dmcs on m starting from context cr   the conversion
of m to an equal acyclic m   based on cb rm and an interface v is done as follows 

ren ci   i  v  if ci  cb rm
 
 
let ci    li   kb i   br i    
ci
otherwise
let ci      li   kb i   br   i     ck cbm ren ci    k  v   
   
br i   a   i   ag     a  bi  v 
   
let ci       li   kb i   br    
 
where
br
 
i
i
br   i

if ci  cb rm
otherwise

for each cj  cb rm   introduce cj    lj   kb j   br j   where br j    and kb j    ag  ag   a 
bj  v   then m      c               cn      cc            ccj   
    the order of composing function ren with different parameters k does not matter here 

   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

example     contd  let m be the mcs from example    and cb rm    c     then  the conversion in definition    gives m      c       c       c       c     where 
g
 kb      e  e   br    
     a       e    not      b  

a       ag   

e       eg     

 kb       br    
     b       c   
g
 kb       br    
     c  d  not      a     and

 kb      eg  eg  

ag  ag     br      

lemma    let m be an mcs and m   be its conversion to an acyclic mcs as in definition    
then the equilibria of m and m   are in     correspondence 
proof  sketch  let  r    and  r    be the runs of dmcs on m and m     respectively  due to the
selection of cb rm to construct m     both  r    and  r    have the same order visiting the contexts 
except that when  r    revisits a cycle breaker ck  cb rm   its counterpart  r    visits ck   at these
corresponding locations 
  r    calls guess v  ck   at step  c   and
  r    calls lsolve               at step  e  since ck is a leaf context 
the construction of the local knowledge base of ck gives us exactly the guess on ck   furthermore 
these guesses are passed on to the parent contexts of ck and then later on unified by the additional
bridge rules a   k   ag   introduced in br    
k   therefore  the belief combinations  step  d   done at
ck are executed on the same input on both runs  r    and  r     the correspondence of equilibria
hence follows 

proof  theorem    thanks to lemma     we now need to prove theorem   only for the acyclic
case and automatically get the result for the cyclic case 
   we start by showing soundness of dmcs  let s    ck  dmcs v    such that v  v  k   we
show now that there is a partial equilibrium s of an acyclic m w r t  ck such that s     s v   we
proceed by structural induction on the topology of m  
base case  ck is a leaf with in k     and brk    and k 
  hist  this means that  d  is not
executed  hence  in  e   lsolve runs exactly once on               and we get as result the set of all belief
states s   lsolve                               tk                 tk  acck  kbk     we now show that
s    s v   towards a contradiction  assume that there is no partial equilibrium s    s            sn   of
m w r t  ck such that s     s v   from in k      we get that ic  k     k   thus the partial belief
state              tk                s  where tk  acck  kbk    is a partial equilibrium of m w r t  ck  
contradiction 
induction step  assume context ck has import neighborhood in k     i            im   and
s i    ci   dmcs v  hist   k   
  
 
s im   cim  dmcs v  hist   k   
   

fidao  t ran   e iter   f ink     k rennwallner

then by the induction hypothesis  for every s  ij  s ij   there exists a partial equilibrium s ij of m
w r t  cij such that s ij  v   s  ij  
let s   ck  dmcs v  hist   we need to show that for every s    s  there is a partial equilibrium of m w r t  ck such that s     s v   indeed  since in k       step  d  is executed  let
t   s i           s im
be the result of combining partial belief states from
scalling dmcs at ci            cim   furthermore 
 
 
by step  e   we have that s   s  v where s    lsolve s    s  t    eventually  s    s v  
since every dmcs at ci            cim returns its partial equilibria w r t  cij projected to v  we have
that every t  t is a partial equilibrium w r t  cij projected to v  m is acyclic and we have visited
all contexts from in k   thus by lemma   we get that for every t  t   app brk   t   gives us all
applicable bridge rules r regardless of tj    in t   for j 
  in k   hence  for all t  t   lsolve t  
returns only partial belief states  where each component is projected to v except the kth component 
as every t  t preserves applicability of the rules by lemma    we get that for every s    s v  
there exists a partial equilibrium s of m w r t  ck such that s     s v  
   we give now a proof for completeness of dmcs by structural induction on the topology of an
acyclic m   let s    s            sn   be a partial equilibrium of m w r t  ck and let s     s v   we
show now that s    ck  dmcs v    
base case  ck is a leaf context  then  when executing ck  dmcs v     step  d  is ignored and
step  e  is called with input               and lsolve               gives us all belief sets s of ck   as s
is an equilibrium of m w r t  ck   s  s  hence  s     s v will be returned from ck  dmcs v    
induction case  suppose that the import neighborhood of context ck is in k     i            im    let
the restriction of s to every context cij  in k  be denoted by s ij   where 

s  if    ic  ij  
 
 
 
ij
s    s            sn   where s   

otherwise
informally speaking  this restriction keeps only belief sets of the contexts reachable from cij and
sets those of non reachable contexts to   by the induction hypothesis  s ij  v is computed by
cij  dmcs v    for all ij  in k   we will show that s v is computed by ck  dmcs v    
indeed  because we are considering an acyclic m   it holds that s ij  v is also returned from a call
cij  dmcs v   k    as k plays no role in further calls from cij to its neighbors  this means that
after step  d   t contains a t   si              sim where sij appears at position ij in s 
since s is a partial equilibrium of m w r t  ck   we have that sk  acck  kbk   head  r   
r  app brk   s     furthermore  by choosing v  v  k   lemma   tells us that the applicability of
bridge rules is preserved under the projection of belief sets to v  this gives us that sk  lsolve t  
in step  e   and hence s     s v is returned from ck  dmcs v    

proof of proposition  
    for a context ck   let the number of calls to its local solver be denoted by c k   this number is
calculated during the computation of t in step  d   and it is bounded by the maximal number of
combined partial belief sets from its neighbors  formally speaking 
c k   iin k    vbi      in k   v    n v   
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

hence for the whole mcs  the upper bound of calls to lsolve in a run of dmcs is
c    kn c k   n   n v 
    for a context ck of an mcs m    c            cn    the set e k  contains all dependencies from
contexts ci for i  ic  k   we visit all  i  j   e k  exactly twice during dfs traversal of m   once
when calling cj  dmcs v  hist  at ci   and once when retrieving s v from cj in ci   furthermore 
the caching technique in step  a  prevents recomputation on already visited nodes  thus prevents
recommunication in the subtree of any visited node  the claim hence follows 

proof of proposition  
item  i  is trivial to see since cyclebreaker is applied in algorithm    to prove item  ii   let us look
at two cases in which an edge     t  is removed from the original topology at step  a  of algorithm   
     t  is removed by cyclebreaker  this causes that certain nodes in the graph cannot reach t
via    however  the interface that ct provides is already attached to v i  j  via v   cp   bt  
     t  is removed by transitive reduction  this does not change the reachability of t from other
nodes  therefore  the interface that ct provides is already included in v   i  j b    


this argument gives us property  ii  
proof of proposition  
first  we estimate the complexity to compute v i  j  in loop  a  
 
 
v i  j     v  i  j b   
v  cp   bc 
v  cp   bt
cc  

   t e

on the one hand  the refined recursive import v  i  j  b is defined as  definition    
v  i  j  b    v   i  

 

b   

 b    j

where b    j contains all nodes reachable from j 
on the other hand  since all sets of possible beliefs in different contexts are disjoint  we have
that
 
cc  

v  cp   bc 

 

v  cp   bt   v  cp   scc  bc s   t e bt

   t e

s
since the recursive import interface for a node k is defined as v  k    iic  k  v i   the
expression to compute v i  j  is in the end a combination of set intersection  union  and projection 
with an implementation of sets using hash set  that is  look up takes o     these operators can be
implemented in linear time  therefore  v i  j  can be computed in linear time in the total number of
beliefs of contexts in the system 
given gm   the block tree graph t  gm   can be constructed in linear time  vats   moura 
       ear decomposition  step  c   can also be done in linear time  valdes  tarjan    lawler 
   

fidao  t ran   e iter   f ink     k rennwallner

       transitive reduction  step  d   can be computed in quadratic time with respect to the number
of edges in the block 
optimizetree t  gm    k  k  iterates through all blocks  assume that we have m blocks b         
bm   and each bi contains ni edges  where n   m
i   ni is the total number of edges in the original
graph  let ti be the time to process block bi   then the bound of the total processing time can be
assessed as follows 
m
m
m
x
x
x
 
t 
ti 
ni   
ni      n   
i  

i  

i  

therefore  if we ignore loop  a   optimizetree can be done in quadratic time in the size of the
original input  i e   the size of gm  

proof of theorem  
to prove this  we need proposition    to claim that partial equilibria returned from dmcs and
dmcsopt are in correspondence  but first  we need the following supportive notion 

definition    let ck be a context of an mcs m   and let k be the query plan as in definition    
for each block b of k   the block interface of b  whose root vertex is cb   is
vb    p  v i  j     i  j   e b    bcb  
let ci be a context in b  the self recursive import interface of ci in b is
 
v   i b   bi 
v   i    b  
 i   e k  

proposition    let ck be a context of an mcs m
s   let k be the query plan as in definition    in
which ck belongs to block b of k and let v   bk vb   then 
 i  for each s    dmcsopt k  called from cc where  c  k   e k   or c   k  there exists
a partial equilibrium s  ck  dmcs v    such that s     s v   c k b if  c  k   e k   or
s     s v   k b if c   k 
 ii  for each s  ck  dmcs v     there exists some s  dmcsopt k  called from cc such that
s     s v   c k b if  c  k   e k   or s     s v   k b if c   k 
a detailed proof for proposition    is given in the next section  we now give a proof for theorem   
proof  theorem     i  let s    ck  dmcsopt k  be a result from dmcsopt  by proposi  
 
  
tion     i  for
sc   k  there exists an s  ck  dmcs v    such that s   s  v   k b   where we
choose v   bk vb   note that v  k   v as v collects all bridge atoms from all blocks  which
might contain blocks not reachable from k  by theorem    there exists a partial equilibrium s of
m such that s      s v   thus  we have that
s      s v   v   k b
  s v   k b
because v   k b  v
b  v   k b
  s vb
because v
 ii  let s be a partial equilibrium of ms  by theorem    there exists s     ck  dmcs v    such
that s      s v where we choose v   bk vb   as above  v   k   v  by proposition     ii 
for c   k  there exists s    ck  dmcsopt k  such that s     s     v   k b   as above  we have that
s     s vb  

   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

proof of proposition   
to support the proof of proposition     we need the following lemmas 
lemma    assume context ck has import neighborhood in k     i            im    no  k  ij   is removed from the original topology by optimizeblock b  cb    and
s  i 

  dmcsopt k  at ci 
  
 

s i 

  ci   dmcs vb    
  
 

s  im

  dmcsopt k  at cim

s im

  cim  dmcs vb    

such that for every partial equilibrium s    s  ij   there exists s  s ij such that s     s v   k ij  b  
let t     s  i              s  im and t   s i              ssim   then  for each t    t     there exists
 
v   k  ij  b  
t  t such that t     t  vinput    m  with vinput               j  
 
proof we prove by induction on the number of neighbors in in k  
base case  in k     i   the claim trivially holds 
induction case  in k     i            i     u     s  i              s  i     u   s i              s i     and
for each u    u     there exists u  u such that u     u  vinput         we need to show that for each
t    u      s  i    there exists a t  u    s i  such that t     t  vinput        
assume that the opposite holds  i e   there exists t   u      s   where u    u   and s    s  i   
and for all u  u  s  s i  such that u     u  vinput        and s     s v   k i   b   we have that
u    s is void 
this means there exists a context ct reachable from ck by two different ways  one via i  and
the other via one of i            i   such that ut      st      ut    st   and either
 i  ut     or st      or
 ii  ut    st     
case  i  cannot happen because ct is reachable from ck   hence vinput            bt     and
v   k  i     bt     
concerning case  ii   we have that ut  vinput          st  v   k i         hence there exists a 
ut   ut  vinput        and a 
  st  v   k i      this means that vinput            bt    v   k  i     bt  


s however  from definition   of recursive import interface  we have that v  k  ix  b   v  k  
 b k b    where b ix contains all nodes in b reachable from ix   it follows that v  k  i    and

v  k  ij   for any    j       that reaches t  share the same projection to bt   hence vinput       
    bt   v   k  i     bt  
we reach a contradiction  and therefore lemma    is proved 


lemma    the join operator    has the following properties  given arbitrary belief states s  t   u
with the same size   i  s    s   s  ii  s    t   t    s  iii  s     t    u      s    t      u  
these properties also hold for sets of belief states 
proof the first two properties are trivial to prove  we will prove associativity 
let r   s     t    u   and w    s    t      u   consider doing the joins from left to right 
at each position i     i  n   ri and wi are determined by locally comparing si   ti and ui   if we
   

fidao  t ran   e iter   f ink     k rennwallner

si   
y
y
y

ti   
y
y
n

ui   
y
n
y

y

n

n

n

y

y

n

y

n

n

n

y

n

n

n

si   ti
y
y
n
n
n
n
n
n
y
n
y
y
n
n

ti   ui
y
n
n
y
n
y
n
n
n
n
y
n
y
n

ui   si
y
n
y
n
n
n
y
n
n
n
y
n
n
n

ri

ui
ti
ti
void
si
si
void
si
void
si
void
void
void

wi

ui
ti
ti
void
si
si
void
si
void
si
void
void
void

table    possible cases when joining at position i

reach inconsistency  the process terminates and void is returned  otherwise  we conclude the value
for ri   wi and continue to the next position  the final join is returned if position n is processed
without any inconsistency 
all possible combination of si   ti   and wi are shown in table    one can see that we always
have the same outcome for ri and wi   therefore  we have in the end either r   w or both are
void   this concludes that the join operator    is commutative 

lemma    let ci and cj be two contexts in m such that they are in the same block after executing
optimizetree and there is a directed path from ci to cj   suppose that s i   dmcsopt k  at ci
and s j   dmcsopt k  at cj   then s i   s i    s j  

proof the use of cache in dmcsopt does not change the result and can be disregarded  i e   we
can assume without loss of generality that cache k     in dmcsopt  indeed  cache k  is filled
with the result of the computation when it is empty  i e   when ck is accessed the first time   and
is after that never changed and dmcsopt just returns cache k   i e   the value of the computation
with empty cache k  
under the above assumption  lemma    can be proven by taking any path ci   cp            cph  
cj that connects ci to cj   and arguing that for each index                h   it holds that s p    s p    
s j      indeed  we can show this by an induction on the path 
base case      h  statement     holds as we have s ph    s j   s j    s j   s j by identity
 lemma        i   
induction case  consider     h  and suppose we already established by the induction hypothesis
that s p      s p       s j  
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

now by definition of s p  and dmcsopt  it holds that s p    lsolve t     and t is  by the
statements  b  and  c   of the form t   s p       t     this holds because there is an edge  p    p     
in e  and because    is commutative and associative  lemma        ii  and  iii    by the induction
hypothesis  we get
t   s p       t      s p       s j      t     s j     s p       t     
that is  t is of the form s j    t     
next  lsolve t   does not change the value of any component of any interpretation i in t that is
defined in s j   that is  lsolve t      s j   lsolve t    this means s p    lsolve t     lsolve t     
s j   s p     s j   which proves statement     holds for   
eventually  we get for       that s i   s p    s p     s j   s i    s j  

based on lemma     we have the following result 
lemma    assume the import neighborhood of context ck is in k     i            im    and that
s ij   dmcsopt k  at cij      j  m  furthermore  suppose that edge  k  ij   was removed by
the optimization process     j  m   and that ci  is a neighbor of ck such that there exists a path
from k to ij through i  in the optimized topology  then s i    s i     s ij   in other words  the input
to dmcsopt at ck is not affected by the removal of  k  ij   
proof since cij and ci  are direct children of ck   it follows that they belong to the same block 
therefore  by lemma    we have that s i    s i     s ij  

proof  proposition     we proceed by structural induction on the block tree of an mcs m   first 
we consider the case where the topology of m is a single block b  in this case  the interface passed
to dmcs is v   vb  
base case  ck is a leaf  then we now compare a call dmcsopt k  at ck and ck  dmcs v    
where v   v   k b   bk   algorithm   returns local belief sets of ck projected to v and algorithm   returns plain local belief sets  the claim follows as v   v   k b   bk  
induction case  assume the import neighborhood of context ck is in k     i            im    and
s  i 

  dmcsopt k  at ci 
  
 

s i 

  ci   dmcs vb    
  
 

s  im

  dmcsopt k  at cim

s im

  cim  dmcs vb    

such that for every partial equilibrium s    s  ij   there exists s  s ij such that s     s v   k ij  b  
there are two cases  first  no edge  k  ij   is removed by the optimization procedure  then  by
lemma     we have the correspondence between the input to dmcsopt and dmcs at ck  
on the other hand  assume that an edge  k  ij   was removed by the optimization process  the
removal can be from either transitive reduction or ear decomposition  in the former case  lemma   
shows that the input to ck is not affected by the removal of this edge  for the latter case  the removal
can be one of three possibilities as illustrated in figure     assuming that context c  gets called 
 i          the last edge of the simple cycle p                      
    with abuse of notation  we write lsolve t   for

s

t t

lsolve t  

   

fidao  t ran   e iter   f ink     k rennwallner

 

  
  

  

 

 

 

 

 
 

 

 

figure     possible cycle breakings
 ii          the last edge of path p                   
 iii           the last edge of path p                   
cases  i  and  iii  differ from case  ii  in the sense that a cycle will be recognized by dmcs
while for case  ii   no cycle is detected along the corresponding path 
now  consider when  k  ij   is removed in situations similar to cases  i  and  iii   dmcsopt
will issue a guess at step  c  of algorithm   on v k  ij    which includes v   cb   bij   vb  bij  
on the other hand  dmcs will recognize the cycle at cij and issue a guess on vb  bij at step  c 
of algorithm    therefore  the guess is fed equally to ck  
when  k  ij   is removed in situations similar to case  ii   all guesses of ck on the interface from
cij will be eventually filtered when being combined with the local belief states computed by cij  
at the starting node of the path containing  k  ij   as the last edge  in the ear decomposition   in
figure     this is node   
in all cases  we have that whenever there is an input t   into lsolve in dmcsopt k  called by
cc   there is an input t to lsolve in ck  dmcs vb      therefore  the claim on the output holds 
now that proposition    holds for a single leaf block  one can see that the upper blocks only
need to import the interface
s beliefs from the cut vertices  also the root contexts of the lower blocks  
under the setting of v   bk vb   results from dmcsopt and dmcs projected to the interface
of the cut vertices are identical  therefore  the upper blocks receive the same input regarding the
interfaces of the cut vertices in running both algorithms  and therefore the final results projected to
v   k b are in the end the same 


proof of proposition  
note that the components handler and output simply take care of the communication part of
dmcs streaming  output makes sure that the models sent back to the invokers are in correspondence with the request that handler got  the other routines joiner and solver are the main
components that play the role of step  b  and  d  in algorithm    respectively 
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

t   

t   
t   

t   

  

t   

  



  

  

t   

  



  

  

t   

  



  

  

t   

  



  


t   

t   

t   

  

t   

  



  

  

t   

  



  

  

t  p 

  



  

tm  



  

tm pm



  

tm  



  

tm pm



tm  pm 

tm  pm 


  

tm  



  

tm pm



tm   

  

tm  



  

tm pm



  

tm  




  

t  p 

  



  


t  p 

tm   

tm   

  




t   

tm   

tm   

tm  pm 


  

t   

  



  



tm  p 


t  p 

  

t  p 

  



  

tm  pm 

  

tm pm

t   

t   

t   

t   

t  p 

  

t   

  



  

tm   


  

f  m  m 



  

t   

  



  

  

f  m  m 



  

t  p 

  



  

  

f  m  m 



  

t  p 

  



  

  

f  m  m 



  

t  p 

  



  

tm  pm 

tm   

tm  pm 

tm  pm 

  

f  m  m 

t   

t   

t  p 

  

t   

  



  



  

t  p 

  



  

  

t  p 

  



  

f  m     m 

f  m     m 

f  m     m 

 

 t       f     m  







 t  p     f     m  

 

f     m  

 

 



table    accumulation of joiner

to prove the correctness of dmcs streaming  we just need to show that the input to lsolve
is complete in the sense that if step  e  of algorithm   is exhaustively executed  the full join of
partial equilibria from the neighboring contexts is delivered 
   

fidao  t ran   e iter   f ink     k rennwallner

formally  assume that the current contexts import neighborhood is                m   assume that
for neighbor ci where    i  m  the full partial equilibria are ti and the returned packages of size
k are denoted by ti             ti pi   that is  ti   ti           ti pi   for the correctness of the algorithm 
we assume that ti             ti pi is a fixed partition of ti   this is possible when  for example  lsolve
always returns answers in a fixed order  we need to show that the accumulation of the join by
algorithm   is actually t              tm  
indeed  each possible join t  i     t  i              tm im is considered by joiner  which performs
a lexicographical traversal of all suitable combinations  formally speaking  let f  p  q   where q  
q  denote the join result of neighbors from p to q  that is  f  p  q    tp    tp     
s           tq  
according to the lexicographical order  we have that the accumulation of joiner is pj  
 t  j   
f     m     f     m  as demonstrated in table   
this shows that the input to lsolve is complete  hence  dmcs streaming is correct 


appendix b  detailed run of optimizetree
example    we illustrate now the call optimizetree t    b  c  e   cp   cr   for the block set b  
 b    b    b     b                  b            b            c              e     b         b       
 b         and cp   cr     
from the local knowledge bases presented in example     we have 
b     car     train     nuts    
b     car     train    
b     car     train     salad     peanuts     coke     juice     urgent    

b     car     train    
b     soon    sooner    
b     fit     sick    

since cp   cr   we start with b      b     we have f   v    
now we call optimizeblock b        since b  is acyclic  only the transitive reduction is applied 
we get b                                              the subroutine returns e                    
the child cut vertices of b  are c             we update f to                  
next  we update the label of all edges  i  j  in b    but before this  let us enumerate the recursive
import interfaces  starting from the import interface  for every node from   to   
v       train     train     peanuts    
v       car     coke     train     car     train    
v     
v     
v     
v     
v     
v     

v       train     sick    
v       train    

v       sooner    
v      

 train     train     peanuts     car     coke     car     train     sooner     sick    
 train     car     coke     train     car     sooner     sick    
 train     sooner     sick    
 train     sooner    
 train     sooner    

s
now  let us compute v        b    v        b     b    we have that b               thus
 
 
 
 
 
 

v        b    v        b   b       train     train     peanuts     car     coke     car     train    
similarly  with b       b            we have 
v           v       b     car     train    
v           v       b     train    
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

the removed edges and updated labels to be stored respectively in f and v for block b  can be
summarized as 
f                   
v        

v        



v      b 



v      b 

v         v          v      b   v      b 
v         v          v      b   v      b 




train     train     peanuts    
 
car     coke     car     train  
   train     peanuts     car     coke     car     train    
   train     peanuts     car     coke     car     train    

next  we call optimizetree t   b          and optimizetree t   b           which eventually process
blocks b  and b  in the same manner as above  the two calls respectively return 
f             
v             sooner    

f      
v              train     sick    

combining all results together  optimizetree t        returns as the set of removed edges
f                           
and as updated labels v for the remaining edges in the blocks
v      
v      
v      
v      
v      

 
 
 
 
 

 train     train     peanuts     car     coke     car     train    
 train     peanuts     car     coke     car     train    
 train     peanuts     car     coke     car     train    
 sooner    
 train     sick    

references
adjiman  p   chatalic  p   goasdoue  f   rousset  m  c     simon  l          distributed reasoning
in a peer to peer setting  application to the semantic web  j  artif  intell  res              
aho  a  v   garey  m  r     ullman  j  d          the transitive reduction of a directed graph 
siam j  comput                
analyti  a   antoniou  g     damasio  c  v          mweb  a principled framework for modular
web rule bases and its semantics  acm trans  comput  log             
baader  f   calvanese  d   mcguinness  d   nardi  d     patel schneider  p  f   eds            the
description logic handbook  cambridge university press 
baget  j  f     tognetti  y  s          backtracking through biconnected components of a constraint
graph  in nebel  b   ed    proceedings of the seventeenth international joint conference on
artificial intelligence  ijcai       seattle  washington  usa  august             pp     
     morgan kaufmann 
bairakdar  s  e  d   dao tran  m   eiter  t   fink  m     krennwallner  t       a   decomposition
of distributed nonmonotonic multi context systems  in janhunen  t     niemela  i   eds   
logics in artificial intelligence     th european conference  jelia       helsinki  finland 
september              proceedings  vol       of lecture notes in computer science  pp 
      springer 
   

fidao  t ran   e iter   f ink     k rennwallner

bairakdar  s  e  d   dao tran  m   eiter  t   fink  m     krennwallner  t       b   the dmcs
solver for distributed nonmonotonic multi context systems  in janhunen  t     niemela  i 
 eds    logics in artificial intelligence     th european conference  jelia       helsinki 
finland  september              proceedings  vol       of lecture notes in computer science  pp          springer 
bessiere  c   bouyakhf  e   mechqrane  y     wahbi  m          agile asynchronous backtracking
for distributed constraint satisfaction problems  in ieee   rd international conference on
tools with artificial intelligence  ictai       boca raton  fl  usa  november           
pp         
bikakis  a     antoniou  g          defeasible contextual reasoning with arguments in ambient
intelligence  ieee transactions on knowledge and data engineering                   
bikakis  a   antoniou  g     hassapis  p          strategies for contextual reasoning with conflicts
in ambient intelligence  knowl  inf  syst               
bogl  m   eiter  t   fink  m     schuller  p          the mcs ie system for explaining inconsistency
in multi context systems  in logics in artificial intelligence     th european conference 
jelia       helsinki  finland  september              proceedings  vol       of lecture
notes in computer science  pp          springer 
bondy  a     murty  u  s  r          graph theory  vol      of graduate texts in mathematics 
springer 
brewka  g   eiter  t   fink  m     weinzierl  a          managed multi context systems  in walsh 
t   ed    proceedings of the   nd international joint conference on artificial intelligence
 ijcai      pp          aaai press ijcai 
brewka  g   ellmauthaler  s     puhrer  j          multi context systems for reactive reasoning in
dynamic environments  in ellmauthaler  s     puhrer  j   eds    proceedings of the international workshop on reactive concepts in knowledge representation  reactknow        pp 
      tech rep     computer science institute  univ  leipzig  issn           
brewka  g     eiter  t          equilibria in heterogeneous nonmonotonic multi context systems 
in proceedings of the twenty second aaai conference on artificial intelligence  july       
      vancouver  british columbia  canada  pp          aaai press 
brewka  g   eiter  t     fink  m          nonmonotonic multi context systems  a flexible approach for integrating heterogeneous knowledge sources  in balduccini  m     son  t  c 
 eds    logic programming  knowledge representation  and nonmonotonic reasoning   essays dedicated to michael gelfond on the occasion of his   th birthday  vol       of lecture notes in computer science  pp          springer 
brewka  g   roelofsen  f     serafini  l          contextual default reasoning  in veloso  m  m 
 ed    ijcai       proceedings of the   th international joint conference on artificial intelligence  hyderabad  india  january             pp         
buccafurri  f     caminiti  g          logic programming with social features  theory and practice
of logic programming                 
dao tran  m          distributed nonmonotonic multi context systems  algorithms and efficient
evaluation  ph d  thesis  faculty of informatics  vienna university of technology  austria 
   

fid istributed e valuation of n onmonotonic m ulti   context s ystems

dao tran  m   eiter  t   fink  m     krennwallner  t          distributed nonmonotonic multicontext systems  in lin  f   sattler  u     truszczynski  m   eds    principles of knowledge representation and reasoning  proceedings of the twelfth international conference 
kr       toronto  ontario  canada  may             aaai press 
dao tran  m   eiter  t   fink  m     krennwallner  t          model streaming for distributed multicontext systems  in mileo  a     fink  m   eds     nd international workshop on logicbased interpretation of context  modeling and applications  vol      of ceur workshop
proceedings  pp       
eiter  t   fink  m   ianni  g   krennwallner  t     schuller  p          pushing efficient evaluation of
hex programs by modular decomposition  in delgrande  j  p     faber  w   eds      th international conference on logic programming and nonmonotonic reasoning  lpnmr       
vancouver  bc  canada  may              vol       of lecture notes in computer science 
pp         springer 
eiter  t   ianni  g   schindlauer  r     tompits  h          a uniform integration of higher order
reasoning and external evaluations in answer set programming  in ijcai  pp       
faltings  b     yokoo  m          introduction  special issue on distributed constraint satisfaction 
artif  intell                
fink  m   ghionna  l     weinzierl  a          relational information exchange and aggregation
in multi context systems  in delgrande  j  p     faber  w   eds      th international conference on logic programming and nonmonotonic reasoning  lpnmr        vancouver  bc 
canada        may        vol       of lecture notes in computer science  pp         
springer 
gao  j   sun  j     zhang  y          an improved concurrent search algorithm for distributed csps 
in australian conference on artificial intelligence  pp         
gelfond  m     lifschitz  v          classical negation in logic programs and disjunctive databases 
new generation comput                  
ghidini  c     giunchiglia  f         
local models semantics  or contextual reasoning locality compatibility  artif  intell                  
giunchiglia  f          contextual reasoning  epistemologia  special issue on i linguaggi e le
macchine              
giunchiglia  f     serafini  l          multilanguage hierarchical logics or  how we can do without
modal logics  artif  intell               
goncalves  r   knorr  m     leite  j          evolving multi context systems  in schaub  t  
friedrich  g     osullivan  b   eds    proceedings of the   st eureopean conference on
artificial intelligence  ecai      prague  czech republic  august              ios press 
hirayama  k     yokoo  m          the distributed breakout algorithms  artif  intell           
      
homola  m          semantic investigations in distributed ontologies  ph d  thesis  comenius
university  bratislava  slovakia 
   

fidao  t ran   e iter   f ink     k rennwallner

lee  j     lifschitz  v          loop formulas for disjunctive logic programs  in palamidessi  c 
 ed    logic programming    th international conference  iclp       mumbai  india  december             proceedings  lecture notes in computer science  pp          springer 
mccarthy  j          notes on formalizing context  in bajcsy  r   ed    proceedings of the   th
international joint conference on artificial intelligence  chambery  france  august    september          pp          morgan kaufmann 
pontelli  e   son  t     nguyen  n  h          combining answer set programming and prolog  the
asp prolog system  in balduccini  m     son  t   eds    logic programming  knowledge
representation  and nonmonotonic reasoning  vol        pp          springer berlin heidelberg 
reiter  r          a logic for default reasoning  artificial intelligence            
roelofsen  f   serafini  l     cimatti  a          many hands make light work  localized satisfiability for multi context systems  in de mantaras  r  l     saitta  l   eds    proceedings of
the   th eureopean conference on artificial intelligence  ecai      including prestigious
applicants of intelligent systems  pais       valencia  spain  august              pp       
ios press 
serafini  l   borgida  a     tamilin  a          aspects of distributed and modular ontology reasoning  in nineteenth international joint conference on artificial intelligence  ijcai       
pp          aaai press 
serafini  l     tamilin  a          drago  distributed reasoning architecture for the semantic web 
in gomez perez  a     euzenat  j   eds    the semantic web  research and applications 
second european semantic web conference  eswc       heraklion  crete  greece  may   
  june          proceedings  lecture notes in computer science  pp          springer 
tarjan  r  e          depth first search and linear graph algorithms  siam j  comput        
       
tasharrofi  s     ternovska  e          generalized multi context systems   in baral  c   giacomo 
g  d     eiter  t   eds    principles of knowledge representation and reasoning  proceedings of the fourteenth international conference  kr       vienna  austria  july             
aaai press 
valdes  j   tarjan  r  e     lawler  e  l          the recognition of series parallel digraphs  siam
j  comput                 
vats  d     moura  j  m  f          graphical models as block tree graphs  corr  abs           
velikova  m   novak  p   huijbrechts  b   laarhuis  j   hoeksma  j     michels  s          an
integrated reconfigurable system for maritime situational awareness  in ecai          st
european conference on artificial intelligence        august       prague  czech republic
  including prestigious applications of intelligent systems  pais        pp           
yokoo  m     hirayama  k          algorithms for distributed constraint satisfaction  a review 
autonomous agents and multi agent systems               

   

fi