journal artificial intelligence research               

submitted        published      

coherent predictive inference exchangeability
imprecise probabilities
gert de cooman
jasper de bock

gert decooman ugent be
jasper debock ugent be

ghent university  systems research group
technologieparkzwijnaarde    
     zwijnaarde  belgium

mrcio alves diniz

marcio alves diniz gmail com

federal university carlos  department statistics
rod  washington luis  km    
carlos  brazil

abstract
coherent reasoning uncertainty represented general manner
coherent sets desirable gambles  context allow indecision  leads
approach mathematically equivalent working coherent conditional
probabilities  allow indecision  leads general foundation coherent
 imprecise  probabilistic inference  framework  given finite category set 
coherent predictive inference exchangeability represented using bernstein
coherent cones multivariate polynomials simplex generated category set 
powerful generalisation de finettis representation theorem allowing
imprecision indecision 
define inference system map associates bernstein coherent cone
polynomials every finite category set  many inference principles encountered
literature interpreted  represented mathematically  restrictions
maps  discuss  particular examples  two important inference principles  representation
insensitivitya strengthened version walleys representation invarianceand specificity 
show infinity inference systems satisfy two principles 
amongst discuss particular skeptically cautious inference system  inference
systems corresponding  a modified version of  walley bernards imprecise dirichlet
multinomial models  idmm   skeptical idmm inference systems  haldane
inference system  prove latter produces posterior inferences
would obtained using haldanes improper prior  implying infinity
proper priors produce coherent posterior inferences haldanes improper one 
finally  impose additional inference principle allows us characterise uniquely
immediate predictions idmm inference systems 

   introduction
paper deals predictive inference categorical variables  therefore concerned
 possibly infinite  sequence variables xn assume values finite set
categories a  observed number n them  found that  say x    x   
x    x            xn   xn   consider subjects belief model next n variables
xn           xn n   probabilistic traditionand want build tradition
     ai access foundation  rights reserved 

fide cooman  de bock    diniz

context paperthis belief modelled conditional predictive probability
mass function pn   x            xn   set possible values  probability mass
functions used prediction estimation  statistical inferences  decision
making involving uncertain values variables  sense  predictive inference lies
heart statistics  generally  learning uncertainty  reason 
crucial importance dealing uncertainty artificial intelligence 
instance  intelligent systems learn multinomial probabilities  markov
transition probabilities  rates occurrence phenomena  local probabilities bayesian
credal networks on  refer synthesis geisser        collection
essays zabell        good introductions predictive inference underlying
issues present paper concerned with 
connects predictive probability mass functions various values n  n
 x            xn   requirements time consistency coherence  former requires
n  n    pn    x            xn   obtained pn    x            xn  
usual marginalisation procedure  latter essentially demands conditional
probability mass functions connected time consistent unconditional probability
mass functions bayess rule 
common assumption variables xn exchangeable  meaning
roughly subject believes order observed  present
themselves  influence decisions inferences make regarding
variables  assumption  analysis consequences  goes back de finetti
        see cifarelli   regazzini         famous representation theorem states 
essence  time consistent coherent conditional unconditional predictive
probability mass functions associated countably infinite exchangeable sequence
variables completely characterised by  completely characterisea unique
probability measure borel sets simplex probability mass functions a 
called representation  
leads us central problem predictive inference  since infinity
probability measures simplex  one subject choose particular
context  given choice motivated justified  subjectivists de
finettis persuasion might answer question needs answer  subjects personal
predictive probabilities entirely his  time consistency coherence
requirements heed  earlier scholars  laplace bayes  would
call subjectivists  invoked principle indifference justify using specific class
predictive mass functions  proponents logicist approach predictive inference would
try enunciating general inference principles order narrow down  hopefully eliminate
entirely  possible choices representing probability measures simplex 
logicians w  e  johnson        and  much systematic fashion  rudolf carnap       
         unless observed sequence probability zero 
   actually  order clarify connection shall later on  essence de finettis
argument representation coherent prevision set multinomial polynomialsor
equivalently  continuous real functionson simplex  de cooman  quaeghebeur    miranda 
    b    finitely additive  coherent prevision  extended uniquely far set
lower semicontinuous functions  determine unique  countably additive  probability
measure borel sets simplex  f  riesz representation theorem  de cooman  
miranda      a  troffaes   de cooman        

 

ficoherent predictive inference exchangeability

tried develop axiom system predictive inference based reasonable inference
principles  carnaps first group axioms related called coherence 
suggested  weak single particular predictive
model  second group consisted invariance axioms  including exchangeability 
included axiom instantial relevance  translating intuitive principle predictive
inferences actually learn experience  last axiom  predictive irrelevance 
proposed earlier johnson called sufficientness postulate good        
armed axioms  carnap able derive continuum probabilistic inference
rules  closely related dirichlet multinomial model imprecise dirichlet
multinomial model  idmm  proposed walley        walley bernard        
discuss appendices c d  respectively 
point view holds middle ground subjectivist logicist positions 
possible subject make assessments certain predictive probabilities 
combine certain inference principles finds reasonable  suit
purpose problem hand  indeed  inference systems introduce discuss
section    notion conservative coherent inferenceor natural extensionwe
associate them  provide elegant framework tools making conservative coherent
predictive inferences combine  local  subjective probability assessments  general 
inference principles  work section    characterising immediate predictions
idmm constitutes exercise inor example forprecisely that 
idea conservative probabilistic inference brings us believe
main contribution paper  central idea de finettis        approach
probabilitybut course implicit markov chebyshev inequalitiesthat
subject makes probability assessments  consider bounds so called
precise probability models  calculating conservative tightest bounds indeed
de finettis        fundamental theorem prevision  see lad        about 
theory imprecise probabilities  brought synthesis williams        walley
              going back boole        keynes         crucial contributions
quite number statisticians philosophers  smith        levi        seidenfeld 
schervish    kadane         looks conservative probabilistic inference precisely
way  calculate efficiently possible consequencesin sense
conservative tightest boundsof making certain probability assessments  may local
assessments  inequalities imposed probabilities previsions certain events
variables  structural assessments  independence  exchangeability 
one advantage imprecise probability models allow imprecision 
words  use partial probability assessments using bounding inequalities rather
equalities  another  related  advantage allow indecision modelled
explicitly  loosely stated  imposed bounds probabilities allow one
probability model solution  may well two actions  first
higher expected utility one compatible probability model  smaller another
compatible probability model  meaning neither action robustly preferred other 
current stated model beliefs  subject undecided
actions  section    give concise overview relevant ideas  models techniques
field imprecise probabilities  much extensive detailed recent overview
area research published augustin  coolen  de cooman  troffaes        
 

fide cooman  de bock    diniz

present paper  then  described application ideas imprecise probabilities predictive inference  aim studyand develop general framework
dealing withconservative coherent predictive inference using imprecise probability models 
using models allow us represent subjects indecision  believe
natural state knowing  learned little  problem hand 
seems important theories learning uncertainty general  predictive
inference particular  least allow us  i  start conservative  imprecise
indecisive models little learned   ii  become precise decisive
observations come in  shall see abstract notion inference system
introduce on  allows forbut necessarily forcesuch behaviour 
shall give number examples concrete inference systems display it 
work builds on  manages reach much than  earlier paper
one authors  de cooman  miranda    quaeghebeur      a   one reason
so  earlier work deals immediate prediction models  shall
see on  predictive inference using imprecise probabilities completely determined
immediate prediction  contrary expect using precise probabilities 
main reason position use powerful mathematical
language represent imprecise probabilistic inferences  walleys        coherent sets
desirable gambles  earlier imprecise probability models  boole              koopman       
centred lower upper probability bounds eventsor propositions  later  walley 
      section       became apparent language events lower upper
probabilities lacking power expression  much expressive theory uses random
variables lower previsions expectations  successful theory coherent lower
previsions quite well developed  walley        augustin et al         troffaes  
de cooman         faces number problems  mathematical well
conceptual complexity  especially dealing conditioning independence 
fact that  case many approaches probability  shall see
section      issues conditioning sets  lower  probability zero 
attractive solution problems offered walley         form
coherent sets desirable gambles  inspired earlier ideas  smith        williams      b 
seidenfeld  schervish    kadane         here  primitive notions probabilities
events  expectations random variables  focus rather whether gamble 
risky transaction  desirable subjectstrictly preferred zero transaction 
status quo  basic belief model probability measure lower prevision 
set desirable gambles  course  stating gamble desirable leads
particular lower prevision assessment  provides lower bound zero prevision
gamble  explain prefer use sets desirable gambles basic uncertainty
models section   
summary  then  aim paper use sets desirable gambles extend
existing probabilistic theory predictive inference  let us explain detail
intend go this  basic building blocks introduced sections    
already indicated above  give overview relevant notions results concerning
imprecise probability model choicecoherent sets desirable gamblesin section   
particular  explain use conservative inference well conditioning 
 

ficoherent predictive inference exchangeability

derive commonly used models  lower previsions lower probabilities 
them  relate precise probability models 
section    explain describe subjects beliefs sequence
variables terms predictive sets desirable gambles  derived notion predictive
lower previsions  imprecise probability models generalise above mentioned predictive
probability mass functions pn   x            xn    constitute basic tools shall
working with  explain proper formulations above mentioned
time consistency coherence requirements general context 
section    discuss number inference principles believe could reasonably
imposed predictive inferences  show represent mathematically
terms predictive sets desirable gambles lower previsions  pooling invarianceor
walley        called representation invariance principle  rip and renaming
invariance seem reasonable requirements type predictive inference  category
permutation invariance seems natural thing require starting state
complete ignorance  taken together  constitute call representation insensitivity 
means predictive inferences remain essentially unchanged transform
set categories  words essentially insensitive choice
representationthe category set  another inference principle look imposes so called
specificity property  predictive inference specific  certain type question
involving restricted number categories  general model replaced
specific model deals categories interest  produce
relevant inferences  bernard        
next important step taken section    recall literature  de
cooman et al       b  de cooman   quaeghebeur        deal exchangeability
predictive inference models imprecise  recall de finettis representation
theorem significantly generalised  case  time consistent coherent
predictive sets desirable gambles completely characterised set  multivariate 
polynomials simplex probability mass functions category set  
set polynomials must satisfy number properties  taken together define
notion bernstein coherence  without becoming technical point  conclusion
section that  general context  precise probabilistic notion
representing probability measure simplex probability mass functions replaced
bernstein coherent set polynomials simplex  set polynomials serves
completely purpose representing probability measure  completely determines 
conveniently densely summarises  predictive inferences  reason
rest developments paper expressed terms bernstein coherent
sets polynomials 
introduce coherent inference systems section   maps associate
finite set categories bernstein coherent set polynomials simplex probability
mass functions set  coherent inference system way fixing completely
coherent predictive inferences possible category sets  reasons introducing
coherent inference systems twofold  first all  inference principles section   impose
connections predictive inferences different category sets  represent
   contradistinction de finettis version  version problems conditioning observed
sequences  lower  probability zero 

 

fide cooman  de bock    diniz

inference principles mathematically restrictions coherent inference systems 
main topic section    secondly  allows us extend method natural extensionor
conservative inferenceintroduced section      take account principles
predictive inference  generally  predictive inference multiple category sets once 
leads method combining  local  predictive probability assessments  global 
inference principles produce conservative predictive inferences compatible
them 
first illustration power methodology  look immediate prediction
section    implications representation insensitivity specificity
predictive inference single next observation  show approach allows us
streamline  simplify significantly extend previous attempts direction de
cooman et al       a  
material sections     shows  producing explicit examples 
quite different typeseven uncountable infinitiesof coherent inference systems
representation insensitive and or specific  discuss vacuous nearly vacuous
inference systems sections       skeptically cautious inference system section    
family idmm inference systems section     family skeptical idmm inference
systems section     haldane inference system section     inference
systems  apart idmm  appear first time  also  believe
first publish detailed explicitas well still elegantproof idmm
inference systems indeed representation insensitive specific  already
mentioned here  however  idmm inference systems based modified 
arguably better behaved  version models originally introduced walley bernard
 see walley        walley   bernard        bernard         refer appendix
explanation  proof original idmm specific that  contrary
often claimed  satisfy so called nestedness property 
results disprove conjecture  bernard        de cooman et al       a 
idmm inference systemsour version original oneare ones  even
conservative ones  satisfy representation insensitivity specificity 
show section    idmm family immediate predictionswhich
version original oneare definite sense conservative ones
representation insensitive specific  satisfy another requirement 
called concave surprise 
conclusion  section     point number surprising consequences
results  discuss avenues research 
order make paper self contained possible  included number
appendices additional discussion  help reader find way many
notions notations need paper  appendix provides list common
ones  short hint meaning  introduced  appendix b provides
useful necessary background theory multivariate polynomials simplices 
important part bernstein basis polynomials there  discussion idmm
inference systems relies quite heavily dirichlet densities simplices  expectation
operators associated them  discuss important relevant properties
appendix c  appendix contains discussion original idm idmm models 
proposed walley bernard  see walley              walley   bernard        bernard 
 

ficoherent predictive inference exchangeability

       show claims make model need
carefully formulated  stated above  main reason introducing 
section     modified version idmm models  suffer
shortcomings  produces immediate prediction models original version 
finally  effort make lengthy paper readable possible  moved
proofs  additional technical discussion  appendix e 

   imprecise probability models
section  give concise overview imprecise probability models representing 
making inferences decisions under  uncertainty  suggested introduction 
shall focus sets desirable gambles uncertainty models choice 
let us briefly summarise next section why  present paper  work
sets basic uncertainty models conservative probabilistic inference  reader
wants dispense motivation proceed section      introduce
mathematics behind models  later sections  shall course briefly mention
derived results terms familiar language  lower  previsions probabilities 
    sets desirable gambles 
first all  number examples literature  moral        couso   moral        de
cooman   quaeghebeur        de cooman   miranda        shown working
making inferences using models general expressive 
simpler elegant mathematical point view  intuitive
geometrical interpretation  quaeghebeur         shall see sections      
marginalisation conditioning especially straightforward  issues
conditioning sets  lower  probability zero 
also  become apparent discussion section      explained
detail moral wilson        de cooman miranda        
similarity accepting gamble one hand accepting proposition true
other  gives logical flavour conservative probabilistic inference  indeed 
strong analogy two  connects conservative probabilistic inferencealso
called natural extension fieldwith logical deduction  classical propositional
logic looking smallest deductively closed set contains number given
propositions  imprecise probabilities context looking smallest coherent set
desirable gambles contains number given gambles  context analogy 
precise probability models closely related complete  maximal  deductively closed
setsperfect information states  clear indication precise probability models
well suited dealing conservative inference  need
broader context imprecise probability models natural language setting
this  summary  working sets desirable gambles encompasses subsumes
special cases classical  or precise  probabilistic inference inference classical
propositional logic  see detailed discussion de cooman miranda        
finally  briefly explain section    de cooman quaeghebeur       
shown working sets coherent desirable gambles especially illuminating
context modelling exchangeability assessments  exposes simple geometrical meaning
 

fide cooman  de bock    diniz

notion exchangeability  leads simple particularly elegant proof
significant generalisation de finettis        representation theorem exchangeable
random variables 
summary  work sets desirable gambles powerful 
expressive general models hand  intuitive work withthough
unfortunately less familiar people closely involved field  and 
importantly  avoid problems conditioning sets  lower  probability
zero  details  refer work walley         moral         couso moral
        de cooman quaeghebeur         quaeghebeur        
    coherent sets desirable gambles natural extension
consider variable x assumes values finite  possibility space a  model
subjects beliefs value x looking gambles variable
subject finds desirable  meaning strictly prefers  zero gamblethe status
quo  general approach  extends usual rationalist subjectivist
approach probabilistic modelling allow indecision imprecision 
gamble real valued function f a  interpreted uncertain reward f  x 
depends value x  expressed units predetermined linear utility 
represents reward subject gets transaction first actual value x
x determined  subject receives amount utility f  x which may
negative  meaning pay it  throughout paper  use device writing f  x 
want make clear variable x gamble f depends on 
events subsets possibility space a  event b associate
special gamble ib   called indicator  assumes value   b   elsewhere 
denote set gambles l a   linear space point wise
addition gambles  point wise multiplication gambles real numbers 
subset l a   posi a  set positive linear combinations gambles a 
posi a    

 
n

 
k fk   fk a  k r     n n  

   

k  

here  n set natural numbers  without zero   r   set positive real
numbers  convex cone gambles subset l a  closed positive linear
combinations  meaning posi a    a 
two gambles f g a  write f g  x a f  x  g x   f   g
f g f    g  gamble f     called positive  gamble g   called non positive 
   sake simplicity  restrict discussion finite possibility spaces 
really need purposes paper  limited number remarks on  shall
occasion mention related notions infinite possibility spaces  give ample references
guide interested reader relevant literature 
   want point notion strict preferenceor preference without indifferencecommonly
used preference modelling  confused walleys        section        notion strict
desirability  one many ways construct lower prevision set gambles
strictly preferred zero gamble  see discussion near end section     
details  refer recent paper quaeghebeur  de cooman  hermans        

 

ficoherent predictive inference exchangeability

l    a  denotes convex cone positive gambles  l   a  convex cone
non positive gambles 
collect gambles subject finds desirablestrictly prefers  zero gamble
set desirable gambles  shall take sets basic uncertainty models 
course  satisfy certain rationality criteria 
definition    coherence   set desirable gambles l a  called coherent
satisfies following requirements 
d    
  d 
d   l    a  d 
d     posi d  
d a  denotes set coherent sets desirable gambles a 
requirement d  turns convex cone  due d   includes l    a   d d  
avoids non positivity 
d   f   f
  posi d   equivalently l   a  posi d     
l    a  smallest coherent subset l a   so called vacuous model therefore
reflects minimal commitments part subject  knows absolutely nothing
likelihood different outcomes  strictly prefer zero
gambles never decrease wealth possibility increasing it 
d  d    subject set desirable gambles d  conservative  less
committal  subject set desirable gambles d    simply latter strictly
prefers zero gambles former does  possibly more  inclusion relation
imposes natural partial ordering sets desirable gambles  simple interpretation
least conservative as 
non empty family coherent sets desirable gambles di   i  intersection
ii di still coherent  simple result underlies notion  conservative  coherent
inference  subject gives us assessmenta set l a  gambles
finds desirablethen tells us exactly assessment extended coherent
set desirable gambles  construct smallestand therefore least committal
conservativesuch set 
theorem    natural extension  de cooman   quaeghebeur         let l a  
define natural extension by  

ea   
 d d a    d   
following statements equivalent 
 i  avoids non positivity  l   a  posi a     
 ii  included coherent set desirable gambles 
   see footnote   

   usual  expression  let   l a  

 

fide cooman  de bock    diniz

 iii  ea    l a  
 iv  set desirable gambles ea coherent 
 v  ea smallest coherent set desirable gambles includes a 
 and hence all  equivalent statements holds  ea   posi l    a  a  
moreover  coherent    l a  ea   a 
    maximal coherent sets desirable gambles
element d a  called maximal strictly included element
d a   words  adding gamble f makes sure longer extend
set  f   set still coherent 
 d  d a   d d    d    
m a  denotes set maximal elements d a   coherent set desirable gambles
maximal non zero gambles f a  f
  f  see couso  
moral       case finite a  de cooman   quaeghebeur       infinite
case   coherence natural extension described completely terms maximal
elements 
theorem    couso   moral        de cooman   quaeghebeur         set avoids
non positivity
maximal m a  d  moreover 

ea    d m a    d  
    conditioning sets desirable gambles
let us suppose subject coherent set desirable gambles a  expressing
beliefs value variable x assumes a  ask so called
updated set dcb desirable gambles b would be  receive additional
informationand nothing morethat x actually belongs subset b a 
updating  conditioning  rule sets desirable gambles states that 
g dcb gib gambles g b 

   

states gamble g desirable subject observe x b
called off gamble gib desirable him  called off gamble gib
gamble variable x gives zero rewardis called offunless x b 
case reduces gamble g new possibility space b  updated set dcb
set desirable gambles b still coherent  provided  de cooman
  quaeghebeur         see discussions moral         couso moral         de
cooman quaeghebeur         de cooman miranda        quaeghebeur       
detailed information updating sets desirable gambles 
    coherent lower previsions
use coherent sets desirable gambles introduce derived concepts  coherent
lower previsions  probabilities 
  

ficoherent predictive inference exchangeability

given coherent set desirable gambles d  functional p defined l a 
p  f      sup   r   f d  f l a  

   

coherent lower prevision  walley        thm          means lower
envelope expectations associated set probability mass functions   or 
equivalently  satisfies following coherence properties  walley              de
cooman   quaeghebeur        miranda   de cooman        troffaes   de cooman        
p   p  f   min f gambles f a 
p   p  f   g  p  f     p  g  gambles f  g a 
p   p  f     p  f   gambles f real   
used notation min f    min  f  x    x a   max f defined similarly 
conjugate upper prevision p defined p  f      inf   r   f d    p  f   
following properties implied p p  
p   max f p  f   p  f   min f gambles f a 
p   p  f       p  f     p  f       p  f     gambles f r 
gamble f   p  f   called lower prevision f   follows equation    
interpreted subjects supremum desirable price buying gamble f  
event b  p  ib   denoted p  b   called lower probability b 
interpreted subjects supremum desirable rate betting b  similarly
upper previsions upper probabilities 
lower prevision associated vacuous set desirable gambles l    a  given
p  f     min f   called vacuous lower prevision  point wise smallest 
conservative  coherent lower previsions 
coherent conditional model dcb  b non empty subset a  induces conditional lower prevision p   b  l b   invoking equation     
p  g b     sup   r   g dcb    sup   r    g  ib d 
gambles g b     
difficult show  walley        p p   b  related following
coherence condition 
p   g p  g b  ib       g l b  
 gbr 
called generalised bayes rule  rule allows us infer p   b  uniquely p  
provided p  b       otherwise  usually infinity coherent lower previsions
p   b  coherent p sense satisfy  gbr   equivalently 
coherent set desirable gambles leads p p   b   two
   statement valid working finite a  infinite a  similar results shown
hold  walley        de cooman   quaeghebeur        miranda   de cooman        troffaes  
de cooman         expectations involved coherent previsionsexpectation operators
associated finitely additive probability measures  see discussion section     

  

fide cooman  de bock    diniz

particular conditioning rules  namely natural regular extension  walley        miranda
  de cooman         always produce conditional lower previsions satisfy gbr 
therefore coherent p   p  b     but necessarily p  b      they
always produce point wise smallest largest coherent conditional lower previsions 
respectively  miranda        miranda   de cooman         
many different coherent sets desirable gambles lead coherent lower prevision
p   typically differ boundaries  sense  coherent sets desirable
gambles informative coherent lower previsions  gamble positive lower
prevision always desirable one negative lower prevision never  gamble
zero lower prevision lies border set desirable gambles  lower
prevision generally provide information desirability gambles 
border behaviour importantand dealing conditioning events
zero  lower  probability  walley        moral        couso   moral        quaeghebeur 
     it useful work sets desirable gambles rather lower previsions 
equations         tell us  allow us derive unique conditional models
unconditional ones  coherent set desirable gambles corresponds unique
conditional set desirable gambles dcb unique conditional lower prevision p   b  
non empty event b  smallest set desirable gambles induces given coherent
lower prevision  called associated set strictly desirable gambles  walley       
given  f l a    f     p  f         see papers walley        quaeghebeur
       additional discussion sets desirable gambles informative
coherent lower previsions 
    linear previsions credal sets
coherent lower upper prevision coincide gambles  real
functional p defined l a  p  f      p  f     p  f   f l a  coherent prevision 
since assumed finite    means corresponds
expectation

operator associated probability mass function p  p  f     xa f  x p x     ep  f  
f l a   p x     p  i x    x a  happens particular lower
upper previsions induced maximal coherent set desirable gambles  indeed 
boundary behaviour  so called precise probability models p correspond maximal
coherent sets desirable gambles  see discussions williams      a   miranda
zaffalon        proposition    couso moral        section    information 
coherent previsions p   generalised bayes rule  gbr  reduces bayess rule 
p  gib     p  b p  g b  g l b  

 br 

indicating central probabilistic updating rule special case equation     
   conditional lower previsions section    idmm produced regular extension 
models sections           lower previsions amongst them  nearly cases
different conditional lower previsions  even though cases natural regular extensions
coincidethey vacuous there 
    already hinted footnote    similar things still said infinite a  would unduly
complicate discussion  details  see work walley         troffaes de cooman
       miranda de cooman        

  

ficoherent predictive inference exchangeability

assumed finite  define so called credal set m p   associated
coherent lower prevision p as 
m p       p    f l a  ep  f   p  f     
closed convex subset so called simplex probability mass
functions a    p lower envelope m p    p  f     min  ep  f     p m p   
f l a   walley        miranda   de cooman        troffaes   de cooman 
       sense  convex closed sets precise probability models seen
imprecise probability models  mathematically equivalent coherent lower
previsions  therefore less general powerful coherent sets desirable
gambles  suffer problems conditioning events  lower  probability
zero   

   predictive inference
predictive inference  specific sense focussing here  considers number
variables x            xn assuming values category set awe define category set
non empty finite set    follows  shall occasion use many different
category sets  shall use italic capitals a  b  c  d        refer them 
start discussion predictive inference models general representationally powerful language  coherent sets desirable gambles  introduced previous
section  on  shall pay attention specific derived models 
predictive lower previsions  predictive lower probabilities 
predictive inference assumes generally number n observations made 
   x            xn   first n variables x            xn   based
know values
n c
values
subject posterior predictive model da
observation sample  
n
n
coherent set
next n variables xn             xn n assume   da c
desirable gambles f  xn             xn n     assume n n 
hand  want allow n n     n      set natural numbers
zero  want able deal case previous observations
n prior predictive model    course 
made  case  call corresponding model da
technically speaking  n   n n 
said  subject may prior  unconditional model  obn
servations yet made  general form  coherent set da
    see section     explicit definition  
    using sets full conditional measures  dubins        cozman         rather sets probability
mass functions  leads imprecise probability model related sets desirable gambles  couso
  moral         problems conditioning sets lower probability zero either 
feel less elegant mathematically complicated 
    formal reasons  include trivial case category sets single element  case
certain value variables assume 
    terms posterior prior association predictive models indicate whether previous
observations made  but  order avoid well known issues temporal coherence
 zaffalon   miranda         assuming prior posterior models based
subjects beliefs observations made  posterior models refer hypothetical
future situations 

  

fide cooman  de bock    diniz

n
desirable gambles f  x            xn     n n  may coherent sets da
n
desirable gambles f  x            xn     n natural number
n n must related following
n n  sets da

marginalisation  time consistency  requirement   
n
n
f  x            xn   da
f  x            xn   da
gambles f  

   

expression  throughout paper  identify gamble f cylindrical
extension f     defined f    x            xn           xn      f  x            xn    x            xn    
introduce marginalisation operator margn       l an    time consistency
n   marg  d n     n l an   
condition rewritten simply da
n


n posterior  conditional  ones n c
prior  unconditional  predictive models da
must
related following updating requirement 
n
n
f  xn             xn n  i  
f  xn             xn n   da
c
 x            xn   da

gambles f      
special case equation      gamble f  xn             xn n   desirable observ gamble f  xn             xn n  i  
ing sample
 x            xn   desirable
observations made  called off gamble f  xn             xn n  i  
 x            xn  

gamble gives zero rewardis called offunless first n observations  
case reduces gamble f  xn             xn n   remaining variables
xn             xn n   updating requirement generalisation bayess rule updating 
fact reduces sets desirable gambles lead  precise  probability
mass functions  described section     proved detail walley       
de cooman miranda         contrary bayess rule probability mass
functions  updating rule     coherent sets desirable gambles clearly suffer
problems conditioning event  lower  probability zero  allows us infer
unique conditional model unconditional one  regardless  lower upper 
probability conditioning event  refer work de cooman miranda
       detailed discussions marginalisation updating sets desirable gambles
many variable context 
explained section      use relationship     derive prior  unconditional 
n through 
predictive lower previsions p na    l an   prior set da
n
p na  f      sup   r   f da
  gambles f   n n 

l an   posterior
posterior  conditional  predictive lower previsions p na    
n
through 
sets da c
 
 
n
   sup r   f da
gambles f  
p na  f   
c
    see related discussion notion de cooman miranda      b  de cooman
quaeghebeur         confused temporal consistency discussed goldstein
             zaffalon miranda        

  

ficoherent predictive inference exchangeability

on  shall want condition predictive lower previsions additional
information  xn             xn n   b n   proper subset b a  using ideas
sections          leads instance following lower prevision 
 
 
n
b n      sup r    g  ib n da
gambles g b n  
p na  g  
c
   
conditioned event b n  
lower prevision p na    

   principles predictive inference
far  introduced coherence  marginalisation updating basic rationality
requirements prior posterior predictive inference models must satisfy  could
envisaged requirementsother inference principlescan imposed
inference models  want show deal additional
requirements theory conservative predictive inference  discuss  way
examples  number additional conditions  suggested number
authors reasonable properties ofor requirements forpredictive inference models 
want stress considering requirements examples  want
defend using circumstances  mean suggest always reasonable
useful  are  inference principles might want impose  whose
implications conservative predictive inference might therefore want investigate 
    pooling invariance
first consider walleys        notion representation invariance  prefer call
pooling invariance  consider set categories a  partition b non empty
partition classes  course consider partition b set categories well 
therefore  order streamline discussion notation  shall henceforth denote
bas stated before  want use italic capitals category sets  elements
subset c acorresponds single new category  consists original
categories x c pooledconsidered one  denote  x  unique element
partition b original category x belongs to  leads us consider surjective
 onto  map b 
say gamble g differentiate pooled categories when 
g     g      k             n   xk      yk   
means gamble f b n that 
   g     f   x              xn    
idea underlying formulaor requirementis sample    x            xn  
  corresponds sample      x              xn    b n pooled categories  pooling
invariance requires gambles g   f differentiate pooled
categories  make difference whether make predictive inferences using set
original categories a  using set pooled categories b  formally  terms
predictive lower previsions 

  

fide cooman  de bock    diniz

  p nb  f   

p na  f     p nb  f   p na  f   
 
n  n n considered  gambles f b n
alternatively  generally  terms predictive sets desirable gambles 
n
n
n
n
f db

f da
f db
f da
c
c

 
n  n n considered  gambles f b n
pooling invariance seems reasonable principle uphold cases category
set known full detail  case useful start limited set broadly
defined categories  allow creation new ones  pooling splitting old categories
observations proceed  context  recall walleys        example 
closed bag containing coloured marbles  probability drawing red marble
it  information  subject idea colours
marbles bag  making difficult construct suitable detailed category set
experiment  draws bag  predictive inference model used
respects pooling invariance  inferences made red marbles uses
category set  red  yellow  blue  other  using category
set  red  non red   colours different red pooled together single
category  appears pooling invariance typically useful principle  instance 
sampling species problems  one wants assess prevalence given species
certain area 
special case pooling invariance  called embedding invariance    concentrates case without prior observations  terms lower previsions 
p na  f     p nb  f   n n considered  gambles f b n  
alternatively  generally  terms sets desirable gambles 
n
n
f da
f db
n n considered  gambles f b n  

    renaming invariance
besides pooling invariance  may require renaming invariance  long confusion
arise  matter subjects predictive inferences names  labels 
gives different categories 
may seem trivial even mention  far know  always implicitly
taken granted predictive inference  well devote attention
here  order distinguish category permutation invariance discussed
shortly  easily confused pay proper attention 
renaming bijection  a one to one onto map  set original categories
set renamed categories c  clearly distinguish elements
c  sample    x            xn   original categories 
corresponds sample renamed categories      x              xn     gamble
    walley calls underlying requirement  lower  probability event depend
possibility space embedded  embedding principle  walley        section        

  

ficoherent predictive inference exchangeability

f set c n renamed samples  corresponds gamble f set
original samples  clearly  require make difference whether
make predictive inferences using set original categories a  using set renamed
categories c  formally  terms predictive lower previsions 
  p nc  f   

p na  f     p nc  f   p na  f   
 
n  n n considered  gambles f c n
alternatively  generally  terms predictive sets desirable gambles 
n
n
n
n
f dc

f da
f dc
f da
c
c

 
n  n n considered  gambles f c n
    category permutation invariance
shall especially interested predictive inference subject starts state
prior ignorance  state  reason distinguish different elements
set categories chosen  formalise idea  consider permutation
  elements a    sample   corresponds permuted sample
        x               xn     gamble f   corresponds permuted
gamble f     subject reason distinguish categories z
images   z   make sense require following category permutation invariance   
  p na  f    

p na  f      p na  f   p na  f    
 
n  n n considered  gambles f
alternatively  generally  terms predictive sets desirable gambles 
n
n
n
n
f da

f   da
f da
f   da
c
c 

 
n  n n considered  gambles f
formally  requirement closely resembles renaming invariance  whereas latter
trivial requirement  category permutation invariance symmetry requirement
categories justified subject reason distinguish
them  may instance justified starts state prior ignorance 
draw attention difference two somewhat loose manner  category
permutation invariance allows confusion new old categories  something
renaming invariance carefully avoids 
see principle could reasonable  recall walleys        bag marbles
example  introduced discussing pooling invariance  since  drawn
    permutation   elements a  words categories  contrasted
permutations order observations  i e  time set             n   considered discussion
exchangeability  section   
    requirement related notion  weak  permutation invariance de cooman miranda
       studied much detail paper dealing symmetry uncertainty modelling  goes
back walleys        section        symmetry principle 

  

fide cooman  de bock    diniz

marbles bag  subject idea marbles coloured  state
complete prior ignorance  therefore  starts sample space  red  non red  
observes outcomes draws  say twice non red  consider probability
obtaining red marble next draw  due symmetry originating complete
ignorance  permute categories  calling red marbles non red
non red ones red  situation looking completely before 
therefore probability obtaining non red marble next draw observing
twice red  must observing red one  observing non red twice 
principle reminiscent axiom a  proposed carnap        system
inductive logic  course  reasonable principle subject prior
knowledge problem would  instance  allow impose ordering
categories 
    representation insensitivity
shall call representation insensitivity combination pooling  renaming category
permutation invariance  means predictive inferences remain essentially unchanged
transform set categories  words insensitive
choice representationthe category set  difficult see representation
insensitivity formally characterised follows  consider two category sets
so called relabelling map   onto  i e 
   a       x    x a   sample   corresponds transformed
sample      x              xn    dn   gamble f dn corresponds
gamble f  
      representation insensitivity
category sets onto map   d  n  n n
gambles f dn  
considered 
  p nd  f    

p na  f     p nd  f   p na  f   

 ri  

alternatively  generally  terms predictive sets desirable gambles 
n
n
n
n
f dd

f da
f dd
f da
c
c 

 ri  

weaker combination pooling  renaming category permutation
invariance models prior observations 
      prior representation insensitivity
category sets onto map   d  n n considered
gambles f dn  
p na  f     p nd  f   
 ei  
alternatively  generally  terms sets desirable gambles 
n
n
f da
f dd
 

  

 ei  

ficoherent predictive inference exchangeability

    specificity
turn another  rather peculiar view intuitively appealing  potential property predictive inferences  assume addition observing sample observations
n observations category set a  subject comes know determine

way n following observations belong proper subset b a  nothing
elsewe might suppose instance observation  xn             xn n   made 
imperfect  allows conclude  xn             xn n   b n  
impose following requirement  uses models conditioned
event b n   conditional models introduced equations          see
discussion leading equation      near end section   
      specificity

category sets b b a  n  n n considered 
gambles f b n  
b n     p nb  f  
b   
p na  f  b n     p nb  f   p na  f   

 sp  

alternatively  generally  terms predictive sets desirable gambles 
n
n
n
n
f db
b 
f ib n da
f db
f ib n da
c
c

 sp  

b tuple observations obtained eliminating tuple
observawhere
b empty tuple  observations
tions b  expressions 
b  posterior predictive model simply taken reduce prior predictive

model 
specificity means predictive inferences subject makes
ones would get focussing category set b  time discarding
previous observations producing values outside b  effect retaining observations
inside b  knowing future observations belong b allows
subject ignore previous observations happened lie outside b  term
specificity context seems proposed bernard               based
work rouanet lecoutre         so called specific inference approach  questions 
inferences decisions involving restricted number categories  general
model replaced specific model deals categories interest 
specificity respected  general specific models produce
inferences  specificity seems relevant principle analysing categorical data
described tree structures  case of  instance  patients classified
according symptoms  bernard        
give simple example involving  again  walleys bag marbles  subject
may observed  drawings  green  red  blue white marbles  asked
probability drawing red marble next  observer already seen
is  informs us either green redperhaps due bad lighting conditions
shes colour blind  subject uses specific inference model  disregard
previous observations involving colours green red 
  

fide cooman  de bock    diniz

    prior near ignorance
use notion near ignorance defined walley        p       give following
definition prior near ignorance context predictive inference  see related
discussions walley        section         walley        section    walley bernard
       section       refer paper piatti  zaffalon  trojani  hutter       
interesting discussion prior near ignorance may produce undesirable results
certain contexts 
      prior near ignorance
prior model single variable xk assuming values arbitrary category set
vacuous  category set a  n n considered    k n gambles
f a 
p na  extnk  f      min f 
alternatively  generally  terms sets desirable gambles 
n
extnk  f   da
f     

extnk  f   denotes cylindrical extension f gamble   defined
extnk  f   x            xn      f  xk    x            xn     perhaps intuitive  less
formally correct  notation gamble f  xk   
theorem    prior representation insensitivity implies prior near ignorance 
simple result implies model whose predictive previsions precise
prior representation insensitive  let alone representation insensitive  prior model
immediate predictions vacuous  shall see section   
nevertheless possible representation insensitive coherent inferences deploy precise
posterior predictive previsions 

   adding exchangeability picture
now  remainder paper  going add two additional assumptions 
first assumption is  principle  upper bound number
variables take account  words  considering n variables
x            xn   always envisage looking one variable xn     effectively
means dealing countably infinite sequence variables x            xn        
assume values category set a 
n coherent
predictive inference models  means sequence da
sets desirable gambles   n n  sequence course time consistent
sense requirement      meaning
n 
n 
n 
 n    n  n  n  n  da
  margn   da
    da
l an     

second assumption sequence variables exchangeable  means 
roughly speaking  subject believes order variables observed 
  

ficoherent predictive inference exchangeability

present themselves  influence decisions inferences make regarding
them   
section  explain succinctly deal assumptions technically 
consequences predictive models interested in  detailed
discussion derivation results presented here  refer papers de cooman
et al       b  de cooman quaeghebeur        
begin useful notation  employed numerous times
follows  consider element ra   consider a tuple  many  real 
components
x r categories x a  subset b a  denote
b    xb x sum components b 
    permutations  count vectors hypergeometric distribution
consider arbitrary n n  denote    x            xn   generic  arbitrary element  
p n set permutations index set             n   permutation  
associate permutation   denoted   defined   k    x k   
words   x            xn       x              x n     similarly  lift permutation
l an   letting f    f     f        f    
permutation invariant atoms           p n    smallest permutation invariant subsets   introduce counting map   nan        
count vector    a tuple components
tz         k             n    xk   z   z a 
set possible count vectors n observations given
 
 
nan    na
      n  

   

   

tz    number times category z appears sample        
                 atom    completely determined single count
vector elements  therefore denoted    
consider linear expectation operator hyna     associated uniform
distribution invariant atom    
hyna  f      


 
f    gambles f  
    

    

  

number elements            invariant atom    given
multinomial coefficient 
 
     

n
n 
  
    
 
 
    


za mz  
expectation operator equation      characterisesor one associated
 multivariate  hyper geometric distribution  johnson  kotz    balakrishnan        section        associated random sampling without replacement urn n balls
    exchangeability assumed carnaphis axiom a and johnson         named
permutation postulate 

  

fide cooman  de bock    diniz

types z a  whose composition characterised count vector   borne
 
fact that      n  n        
 
          
hyna  i       
 
otherwise
probability randomly selecting  without replacement  sequence n  balls types
urn n balls whose composition determined count vector   see
running example concrete illustration 
hyper geometric expectation operator seen linear transformation
hyna linear space l an   generally much lower dimensional linear space
l nan    turning gamble f so called count gamble hyna  f      hyna  f   
count vectors 
running example  order make argumentation  notions introduce
discuss  tangible concrete  shall use simple running example 
shall come back repeatedly number sections  notations assumptions made
maintained throughout series 
consider  potentially infinite  sequence coin flips  whose successive outcomes
denote variables x    x          xn         assuming values category set  h     
make somewhat interesting usual run of the mill example  assume
stepfor coin flipnathalie selects coin bag three coins  hands
arthur  proceeds flip it  coin put back bag next
step  subject whose beliefs modelling  may may know something
nature coins  nathalie choosing coins subsequent flips 
might choose completely random  might specific deterministic
mechanism selecting them       
   h     h   h   first n     observed coin flips  count
consider sequence
corresponds sequence given components
vector   
th   h     h   h        tt   h     h   h        
          letting first component always refer h  
denote
on  corresponding permutation invariant atom
  h     h   h                   t   h   h   h     h     h   h     h   h     h     h   h   h     
  
    

 
    elements  set possible count vectors given n h
 t    
     h       t   h     h     
                                          consider event ht
two different outcomes first two observations 

          

 
 
hy  h  t    iht
                            
 
 
probability observing two different outcomes two random draws without replacement urn containing three balls marked h one ball marked   whose
composition therefore determined count vector        

  

ficoherent predictive inference exchangeability

    multinomial distribution
next  consider simplex probability mass functions a 

 
 
   ra           where  before    
x  

    

xa

probability mass function a  corresponds following multinomial
expectation operator mnna       
mnna  f      




f   



ztz    gambles f  

    

za

characterises multinomial distribution  associated n independent trials
experiment possible outcomes probability mass function   observe
 


   
f       
zmz
mnna  f     
  
n
za
na
  


n
mz
 
hya  f     
z   comnna  hyna  f     
n
na

za

used so called count multinomial expectation operator   


comnna  g     
g    
zmz gambles g nan  
n
na

    

za

running example  consider n     independent trials experiment possible outcomes
category set  h     probability mass function    h     
 
   
 
 
mn  h  t    iht
  h         h    h    h    h  h        h  

  observe  way  mnn
gives probability event ht
  h       
 h  t    iht
 h n   
gamble fht
   iht
observation sequences  x            x     corresponds
 
count gamble ght
   hy h  t    fht
   given by 
ght
           ght
        

 
 
 
ght
ght
ght
        
        
           
 
 
 



 
     
   
 
comn  h  t    g  h         h
   h
   h
   h
 
 
 
leads polynomial before  should 



    avoid confusion  make  perhaps non standard  distinction multinomial expectation 
associated sequences observations  count multinomial expectation  associated
count vectors 
    see footnote    

  

fide cooman  de bock    diniz

    multivariate polynomials

let us introduce notation na    mn nam set possible count vectors
corresponding samples least one observation  equation      let n     
turns na  singleton
containing null count vector    whose

components zero  mn  nam   na     set possible count vectors 
count vector na      consider  multivariate  bernstein basis
polynomial ba  degree   defined by 
 
 

mz
mz
ba          
z  
z  
    

za

za

particular  course  ba       
linear combination p bernstein basis polynomials degree n    multivariate 
polynomial   whose degree deg p  n    denote linear space
polynomials degree n v n  a   course  polynomials degree zero simply real
constants  gathered relevant useful information multivariate polynomials
appendix b  follows discussion that  n    introduce
linear isomorphism comnna linear spaces l nan   v n  a  
gamble g
nan   corresponds polynomial comnna  g     comnna  g     n n g  ba 

v n  a   conversely  polynomial p v n  a  unique gamble bnp nan
p   comnna  bnp      observe particular  n   nan  
comnna         ba      
    

denote v  a     nn  v n  a  linear space  multivariate  polynomials  
arbitrary degree 
set ha v  a  polynomials called bernstein coherent satisfies
following properties 
b    
  ha  
b   v    a  ha  
b   posi ha     ha  
here  v    a  set bernstein positive polynomials   polynomials p
n deg p  bnp      follows proposition    appendix b
v    a  subset set v     a  polynomials p p      
interior int a           x a x        consequence b b  
find set v   a     v    a  bernstein negative polynomials that 
b   v   a  ha    
    degree may smaller n sum bernstein basis polynomials fixed degree
one  strictly speaking  polynomials p restrictions multivariate polynomials q ra  
called representations p  p  multiple representations  possibly different degrees 
smallest degree called degree deg p  p 
    strictly speaking  equation      defines count multinomial expectation operator comnn

n      clear definition extends trivially case n     

  

ficoherent predictive inference exchangeability

finally  every bernstein coherent set ha polynomials induces lower prevision
h v  a  defined by 
h  p     sup   r   p ha   p v  a  

    

lower prevision coherent  mathematical sense satisfies coherence
requirements p p    
    exchangeability representation theorem
ready deal exchangeability  shall give definition coherent sets
desirable gambles generalises de finettis              definition  allows
significant generalisation representation theorem 
first all  fix n n  subject considers variables x            xn
exchangeable distinguish gamble f permuted
version f   words  gamble f f equivalent zero gamble foror
indifferent tohim  means so called set indifferent gambles 
 
 
n
   f f   f l an   p n  
ia
n   set must compatible
subject coherent set desirable gambles da
n   sense must satisfy rationality
set indifferent gambles ia
n
n
n
requirement da   ia   da   see detailed explanations justifications de cooman
quaeghebeur        quaeghebeur et al         so called desiring sweetened
n  
deals requirement  say sequence x            xn   model da
exchangeable 
next  countably infinite sequence variables x            xn       called exchangeable
n  n n
finite subsequences x            xn are  n n  means models da
exchangeable  course time consistent 
formulate powerful generalisation de finettis              representation
theorem  straightforward compilation various results proved de cooman
quaeghebeur        

theorem    representation theorem  de cooman   quaeghebeur         sequence
n desirable gambles   n n coherent  time consistent exchangeable
sets da
bernstein coherent set ha polynomials
na
   

n n  gambles f  
n
n
mnna  f  ba 
f da
mnna  f   ha f da
c
ha  

case representation ha unique given ha   



    

n
n
nn mna  da   

follows condition      ha completely determines predictive inferences
n
sequence variables x            xn           fixes prior predictive models da
    actually  suitably adapted version  underlying possibility space need longer finite
 walley        troffaes   de cooman         domain restricted polynomials
 de cooman   quaeghebeur        

  

fide cooman  de bock    diniz

n c 
   tells us representation ha set
posterior predictive models da
polynomials plays role probability measure  density  distribution
function  precise probabilistic case 
indeed  corresponding coherent lower prevision h v  a  given equation      
shown determine convex closed  compact  set

m h       ha    p v  a  ha  p  h  p  
coherent previsions ha v  a   walley        de cooman et al       b  de cooman  
quaeghebeur        troffaes   de cooman         pointed footnote  and
come back footnote   each coherent prevision ha uniquely
determines  additive probability measure borel sets   therefore set
polynomials ha   via m h    uniquely determines set probability measures  but 
argued before  ha informative h m h    problems
conditioning sets lower probability zero  bernstein coherent set polynomials
ha determines unique lower prevision h   therefore m h   unique set
probability measuresand densities absolutely continuouson simplex  
converse necessarilyand usually notthe case  set probability densities
used define coherent set polynomialswe provide example
section   but generally one coherent set polynomials
leads set densities  updating behaviour different sets
polynomials different conditioning events lower probability zero 
n c
depend
condition      tells us posterior predictive models da
count vector
     
count vectors sufficient
observed sequence
statistics exchangeability  reason  shall denote posterior
n c
n c 
well da
also  every then  shall use
predictive models da
n
n
da c  alternative notation da  
immediate interesting consequence theorem   updating observations
preserves exchangeability  observing values first n variables  count
remaining sequence variables xn     xn           still exchangeable 
vector  
condition      tells us representation given bernstein coherent set
defined by 
polynomials ha c
    p v  a    ba 
ha c
p ha    

    

compare expressions          tells us that  essentially  bernstein
basis polynomials serve likelihood functions updating sets polynomials  use
refer coherent lower prevision v  a  derived ha c
means
h    
     find ha c    ha h        h  
equation       special case
related following version generalised
observe h h    
bayes rule 

h   p h  p   b
    
      p v  a  
a 
completely determined ha   one consider ha prior model
clearly  ha c
plays role posterior derived it 
parameter space   ha c
    contrasted usual precise probabilistic version  posterior predictive
models uniquely determined observed sequences non zero probability  see footnote   

  

ficoherent predictive inference exchangeability

see condition      equation      thatsimilarly happens preciseprobabilistic settingthe multinomial distribution serves direct link one
n and  hand 
hand  prior ha prior predictive inference models da
n c 
posterior predictive inference models da
recalling
posterior ha c

na     
convention      summarise follows  n n
 
 
n
  f l an     mnna  f   ha c

da
c
    
and  immediate consequence 
 
 
  sup r   mnna  f   ha c
f l an  
p na  f   

    

or  equivalently 
  h  mnna  f    
f l an   
p na  f   

    

practical point view  equation      often easier work equa often admit simpler expression
tion       shall see on  h    
compare equations                       equations                 
ha c 
always uniquely determined h   relaand       respectively  but  h    
uniquely h prior lower probability
tion      allows us determine h    

h  ba 
 

observing

non zero 
therefore 
sets polynomials ha


uniquely  quite dramatic
fundamental models  allow us determine ha c
illustration this  shall sections           come across number
quite different inference systemswith different ha give rise prior h

different posterior h     
running example  assume subject assesses sequence coin flips
exchangeable  finds desirable gamble type i h    xn    fixed
        upper probability observing heads coin flip   since
infer equation      n n  mnn
 h  t    i h    xn       h   infer
theorem   assessment corresponds following coherent set polynomials 
 
 
h      p        h     p  v     h             r  max              
smallest bernstein coherent set polynomials contains polynomial
h   explanation  see discussions de cooman et al       b 
de cooman quaeghebeur         followsafter manipulationsfrom
equation      proposition    corresponding lower prevision v   h     
completely determined following optimisation 
h  p    sup

min  p      h   

   h  t  

given
hence  lower probability event ht
h   h     sup min   x   x     x        
  x     

upper probability
h   h     h   h     inf max   x   x   x   
  x     

  

fide cooman  de bock    diniz

 

 
     
 
 

  
otherwise 


tells us exchangeability alone already guarantees upper probability ht
 
    three coins bag assumed biased towards heads        
upper probability drops     

finish section representation  want stress polynomials
given behavioural interpretation gambles may may desirable 
merely mathematical representational tools help us characterise
gambles observation sequences desirable    similarly  set polynomials ha
lower prevision h merely mathematical tools allow convenient
representation predictive models observation sequences 
running example  illustrate polynomial representation much convenient
efficient  recall want make inferences sequence coin flips
length n  need work sets desirable gambles  h    n   words 
cones  n  dimensional space  work polynomial representations 
led consider cones polynomials degree n  constitute linear
space spanned n     bernstein basis polynomials degree n  therefore
n     dimensional  working polynomial representations therefore leads
dramaticexponentialreduction complexity 


   reasoning inference systems
seen previous section that  fix category set a  predictive inferences
exchangeable sequences assuming values completely determined bernstein
coherent set ha polynomials   way associating bernstein
coherent set ha every possible set categories a  would completely fix predictive
inferences  leads us following definition 
definition    inference systems   denote f collection category sets  i e  finite
non empty sets  inference system map maps category set f
set polynomials  a    ha   inference system called coherent
category sets f   a  bernstein coherent set polynomials  
so  coherent inference system way systematically associate coherent predictive
inferences category set  since inference principles section   impose connections
predictive inferences different category sets  see interpret
inference principlesor rather  represent mathematicallyas properties of 
restrictions on  coherent inference systems  shall section   
provides one important motivation introducing systems  another  equally
    makes operational  behavioural sense consider notion accepting polynomial  finding
desirable  much classical case  de finetti        probability distributions
simplex used mathematical representations  direct behavioural
meaningalthough bayesians less careful foundations de finetti might care make
distinction 

  

ficoherent predictive inference exchangeability

important reason so  allows us extend method natural extension
conservative inferenceintroduced section      take account inference
principles predictive inference  generally  predictive inference multiple category
sets once 
see comes about  let us show conservative reasoning
inference systems  two inference systems       say   less committal
conservativethan     write   v  
 a f    a     a  
simply means predictive inferences category set less committal
first second inference system  denote set inference
systems  clearly set partially ordered v  actually  complete lattice 
infimum supremum non empty family   given by 
 

 
 
 


inf  a   
 a  sup  a   
 a  category sets a 
ii

ii

ii

ii

denote c set coherent inference systems 
c         a f  a  bernstein coherent   

    

clear c complete meet semilattice  meaning closed arbitrary
non empty infima   
 i i i c inf c 
    
ii

bottom structurethe conservative coherent inference systemis called
vacuous inference system v   coherent inference system given by 
v  a    v    a  category sets a 
shall come back detail vacuous inference system section   
property      allows us conservative reasoning coherent inference systems 
suppose  instance  collection category sets f f  assessments
form set polynomials aa v  a   f  then  exists 
conservative coherent inference system compatible assessments given
by 
  inf   c    a f aa  a    
and  course  exist set polynomials aa included
bernstein coherent set polynomials ha a  f  case  difficult
see  given discussion section       a    posi v    a  aa   f
 a    v    a  f   f 
    necessarily closed suprema  however  union bernstein coherent sets polynomials
need bernstein coherent 

  

fide cooman  de bock    diniz

   representation insensitivity specificity exchangeability
let us investigate form inference principles representation insensitivity  ri  
specificity  sp   take predictive inference exchangeability  inference
completely characterised bernstein coherent sets polynomials  allow us
reformulate principles constraints onor properties ofinference systems 
    representation insensitivity
recall notations assumptions section      surjective  onto  map
  associate surjective map r   ra rd letting 
r   z   



x

ra z d 

    

xa    x  z

map allows us give following elegant characterisation representation insensitivity 
theorem    coherent inference system representation insensitive
category sets onto map   d  p v  d 
na     
 p r  ba   a  pbd r     d  
 ri  
running example  assume coins bag actually rather thick  implying
non negligible chance fall one flat sides 
remain upright  denote new state u   new category set
    h     u    consider new flat state f   meaning either heads tails 
consider  instead a  category set     f   u   distinguish
heads tails  relabelling map  h       t      f  u      u
identifies proper relations categories d 
suppose want say something lower probability event
observing u one flip h other  immediately observing
uf
sequence  h   u   h     count vector            the last count three
refers number u observation sequence  a domain  gamble iuf

n
  
expressed polynomial q   mn h  t  u    iuf
   n   given by 
q       h    u  h  t  u    
  belong
want find whether polynomials type    h    u    h
u
  h     u     see equation      
hand  seen previously  d domain  gamble iuf

expressed polynomial p given p      f u  f  u     observe
q   p r   count vector             a domain corresponds count vector
r             d domain  first component refers number f
second number u s  here  need check whether polynomials type
  f u    f u belong   f   u    

    similar contexts  easy check polynomial remains n   

  

ficoherent predictive inference exchangeability

nice thing representation insensitivity makes checking whether
 
polynomials type    h    u    h
u belong   h     u    adomain equivalent checking whether polynomials type   f u    f u belong
  f   u    d domain 

interestingly  representation insensitivity preserved taking arbitrary nonempty infima coherent inference systems  allows us look conservative
representation insensitive coherent inference system compatible assessment
f  way straightforward extension discussion near end section   
theorem    consider non empty family   representation insensitive coherent
inference systems  infimum inf ii representation insensitive coherent
inference system well 
    specificity
next  turn specificity  recall notations assumptions section      let us
define surjective restriction map rb   ra rb by 
rb   z    z ra z b 

    

particular  rb    count vector b obtained restricting b  indices
the  components count vector a  define one to one injection map
ia   rb ra by 
 
x x b
ia   x   
rb x a 
    
 
otherwise
map used define following one to one maps irb a   v  b  v  a  
r n    follows 

irb a  p    
bdeg p  r
  ba ia    polynomials p v  b  
    
p
deg p  r

nb

derive meaning following observation  polynomial p b
equivalently represented bernstein basis b degree deg p    r 
interpret different representations polynomials   longer equivalent 
lead different polynomials irb a  p   r n    following propositions clarify
exactly effect operator irb a is 
proposition    polynomial p b r n    irb a  p  ia   p 
introduce following notation  b        
b    rb    b  
observe   


whenever

 
  
b
b
b
proposition     consider polynomial p b   r n   
deg p    r     p   c r  irb a  p     c  otherwise  deg p    r     
 
deg p  r
b
p   
b    
b 
irb a  p    
 
otherwise 
  

fide cooman  de bock    diniz

maps irb a allow us give following elegant characterisation specificity 
theorem     coherent inference system specific category sets
b b a  p v  b   na     r n   
irb a  p ba   a  pbb rb     b  

 sp  

running example  suppose  before  made observation  h   u   h     
count vector              interested posterior lower probability
  somebody told us neither two subsequent coin flipsafter
event ht
first fourresulted u   specific inference system  allowed consider
predictive inference problem reduced category space b    h      rather
category space    h     u    then  b space  use reduced count
vector rb              obtained leaving number observed u s  polynomials
lead consider here  therefore type   h    h   want
know whether belong   f   u    
a space  polynomial p      h   whose degree deg p      
transformed polynomials
 
 

h
r
ib a  p      
 h      r     h  h        h    r
h   h  
r n    follows argumentation proof theorem    original
problem requires us check whether polynomials type
 
  h  h        h    r   h
u

  h     u     specificity allows us look problem b space 
easier 

observe close formal similarity conditions  ri    sp   
therefore surprise us specificity  too  preserved taking arbitrary non empty
infima inference systems 
theorem     consider non empty family   specific coherent inference systems 
infimum inf ii specific coherent inference system well 
let us denote crs set coherent inference systems representation
insensitive specific  follows theorems      crs   c  closed
arbitrary non empty infima  perform conservative reasoning  much
way discussed near end section   

   immediate prediction
inference system   look special case immediate prediction 
given category set a  observing sample n   variables count vector
nan   want express beliefs value next observation xn  

assume a  specific case predictive inference n      condition     
nan  
simplified somewhat  gambles f
 
 
ba 
f da
sa  f    a  f da
c
sa  f    a  

  

ficoherent predictive inference exchangeability

let
so called sampling expectation sa  f   linear polynomial given
sa  f       xa f  x x  
reason na     x   x a  x count vector corresponding
single observation category x  words  exz   xz z  kronecker
delta   hence  x  
   
   
 
 
x
x
f
 z 
 
f
 x 

b
  
 
zez   x  
hy a  f  x    
a 
x
x

x
za

z   

leading to 
mn a  f     



hy a  f  x  ba x     

 
x na



f  x x   sa  f    

    

xa

matter straightforward verification that  due bernstein coherence ha  
  c
coherent set desirable gambles a 
so called immediate prediction model da
na      induces following predictive lower previsions 
every count vector
 
 
 
  sup r   f da

p  a  f   
c
  sup   r    sa  f    ba 
 a    

    

immediate prediction context exchangeable imprecise probability models
studied detail de cooman et al       a   lower previsions  rather
sets desirable gambles  model choice paper  that 
authors encountered problems conditioning sets  lower  probability zero  fact 
problems provided motivation dealing much general
problem  not necessarily immediate  predictive inference using sets desirable gambles
present paper  section  want illustrate many results proved
made stronger  and easier proofs  borne appendix e   
present context 
requirement  ri   representation insensitivity reduces following simpler
requirement immediate prediction models  category sets
onto map   d  gambles f na     
 
 
f da
c f dd
cr    

 ri  

similarly  requirement  sp   specificity reduces following simpler requirement
immediate prediction models  category sets b b a 
gambles f b na     
 
 
f ib da
c f db
crb    

 sp  

let us show simple characterisation immediate prediction
models satisfy representation insensitivity  get there  observe consider
gamble g category set  surjective  pooling map finite subset
g a  ralso category set  corresponding rg   ra rg a  given by 

rg   r  
x r g a  
xa   g x  r

  

fide cooman  de bock    diniz

simple idea allows intriguing reformulation representation insensitivity
requirement immediate prediction models 
proposition     immediate prediction models associated coherent inference
system representation insensitive category sets a  gambles g
count vectors na     
 
 
g da
c idg a  dg a 
crg    

 ri  

here  non empty set b  denote idb identity map b  defined idb  z     z
z b 
proposition    tells us whether gamble desirable depends values
assumesand assumedand number times
values observed pastor rather would observing
g xk   rather xk  
let us focus happens events  consider event b nontrivial meaning b neither empty equal a  real gamble
ib assumes two values      see applying proposition   
na     
 
 
ib da
c id     d    
c mb   ma b   

therefore
 
 
 
p  a  b     sup r   ib da
c
 
 
 
  sup r   id     d    
c mb   ma b       ma   mb   

    
    

meaning that  representation insensitivity  predictive lower probability non trivial
event b depends number times mb observed past
experiments  total number observations   thing holds predictive
upper probability    ma   mb    precise predictive probabilities  similar property
known johnsons sufficientness postulate  johnson        zabell        
representation insensitive coherent inference system 
see define
 
 
so called lower probability function    n  k  n    k n        equation      
completely characterises one step ahead predictive lower upper probabilities  
non trivial events count vectors  shall use representation insensitivity
specificity requirements try say lower probability function 
following theorem strengthens  simplifies  extends similar results de cooman et al 
     a  
theorem     consider representation insensitive coherent inference system  
associated lower probability function following properties 
l   bounded     n  k    n  k n  k n 
l   super additive second argument   n  k       n  k     n    
n  k    n  k     n 
          necessarily predictive lower upper previsions      

  

ficoherent predictive inference exchangeability

l    n         n n   
l    n  k  k n     n n       n  k n    k n 
l   non decreasing second argument   n  k   n     n  k    n 
k   n 
l    n  k   n      k     n  k   n      k       n      k   n  k n 
k n 
l   non increasing first argument   n      k   n  k  n  k n 
k n 
l   suppose  n         n n  let sn   
 
  sn   sn   sn  
 n       n s
n

 
 n   

n  equivalently 

moreover specific  following properties 
n
l   consider real        suppose           n  n    n

 
n n    consequence  consider     suppose          s  
n
 n  n  n s
n n   

know theorem   representation insensitive coherent inference systems
near ignorant  meaning vacuous therefore completely indecisive
single observation prior observations made  borne
theorem    l   let us define imprecision function
 n  k        n  n k   n  k  n  k n  k n 

    

 

clear p  b   p  a  b      ma   mb   width probability interval
event b observed mb times  representation
insensitive coherent inference system whose imprecision function  n  k  satisfies following
property 
 
 n      k   n  k 
  k n 
    
 n      k       n  k 
imprecision increase total number observations increases  suggests
representation insensitive coherent inference systems display
desirable behaviour mentioned introduction  conservative little
learned  never become less precise observations come in  following
sections  intendamongst thingsto take closer look whether behaviour
present number systems 
immediate prediction important predictive inference precise probabilities 
law total probability guarantees completely determined immediate
predictions  perhaps surprisingly  case predictive inference imprecise
probabilities  appendix provides counterexample  points
limitations scope earlier work de cooman et al       a   reason 
leave immediate prediction models are  rest paper concentrate
general notion inference system 
  

fide cooman  de bock    diniz

   vacuous inference system
following sections  provide explicit interesting examples representation insensitive  specific coherent inference systems  begin simplest
one  vacuous inference system v   introduced section   smallest 
conservative  coherent inference system  associates category set
smallest bernstein coherent set v  a    hv a    v    a  containing bernstein positive
polynomialsthe ones guaranteed anyway  bernstein coherence alone 
deduce proposition    appendix b that 
  hv a   v    a 
na     
hv a c
proposition    appendix b that 
 
 
  h v a  p    sup r   p v    a 
h v a  p  
  min p   min p   p v  a  


predictive models inference system straightforward find 
na     
follow directly equations            n n
deduce that 
 
 
n
n
  f l an     mnna  f   v    a   
dv a
  dv a
c
    

  min mnna  f    f l an   
p nv a  f     p nv a  f   


    

particular 
 
 
  l    a  
dv a
  dv a
c

p  v a  f  

 


p  v a  f   

    

  min f f l a  

    


v  n  k      n  k n  k n 

    

conservative exchangeable predictive models are  arise
making assessments exchangeability alone  gather equations     
      interesting  involve non trivial commitments 
allow learning observations  borne corresponding
imprecision function  given by 
v  n  k      n  k n  k n 
running example  seen mnn h  t    iht
      h n   
therefore
n
p nv  h  t    iht
    p v  h  t    iht
          

min

mnn h  t    iht
    

max

mnn h  t    iht
    

 h  t  

min

 h  t  

 h    


n

n

p v  h  t    iht
    p v  h  t    iht
          

 h  t  

  

 
 h    
 h  t  
 
max

ficoherent predictive inference exchangeability

shows vacuous inference model produce completely vacuous inferences 
allows us find consequences making assessments exchangeability 
allow us change lower upper probabilities previsions
new observations come in 

even though makes non trivial inferences  vacuous inference system satisfies
representation insensitivity  specific 
theorem     vacuous inference system v coherent representation insensitive 
let us show means counterexample v specific 
running example  let us go back inferences category space    h     u  
reduced category space b    h      consider polynomial p      h h    t
 h  t     polynomial bernstein positiveso p v     h     because
p       h h    t   h        h    t
expansion bernstein basis degree   positive  let us consider
corresponding polynomial  h  t  u    
 
 
q      i b a  p     h
h  
 

    

polynomial bernstein positive  easy see every n n   
 
 
q      h
h  
  h     u  n
n   q   i   p 
always term h u
  v     h     u     infer
b a
theorem    v cannot specific 


following sections  shall prove infinity committal 
specific representation insensitive coherent inference systems  begin introducing
slightly modified version vacuous inference system coherent  representation
insensitive specific 

    nearly vacuous inference system
let us introduce nearly vacuous inference system nv reason name
become clear presentlyby 
nv  a     hnv a    v     a      p v  a      int a   p       
category sets a 
since v     a  consists polynomials positive int a    deduce
na      hnv a c
  hnv a   v     a 
proposition    appendix b that 
that 
  h nv a  p   
h nv a  p  

p     min p   p v  a  

inf
int a  

  



fide cooman  de bock    diniz

since know proposition    appendix b  counterexample following it 
generally speaking v    a  v     a   see inference system less conservative
vacuous one  case vacuous inference system  predictive models
nearly vacuous inference system straightforward find  follow directly
na      deduce that 
equations            n n
 
 
n
n
  f l an     mnna  f   v     a   
dnv a
  dnv a
c

  min mnna  f    f l an   
p nnv a  f     p nnv a  f   


particular 
 
 
  l    a  
dnv a
  dnv a
c

  min f f l a  
p  nv a  f     p  nv a  f   
see immediate prediction models  predictive lower previsions 
inference system exactly ones vacuous inference systems   
allow learning observations 
interestingly  contrast vacuous inference system  nearly vacuous
inference system specific  already tells us crs     
theorem     nearly vacuous inference system nv coherent  representation insensitive specific  nv crs  

    skeptically cautious inference system
construct rather simple inference system quite intuitive slightly
informative vacuous nearly vacuous ones  suppose subject uses
following system making inferences based sequence n     observations count
category set a  skeptical believes future 
vector  
observe categories seen previously  categories set 
    x   mx       
a  

    

cautious  beliefs already observed categories
observed future  nearly vacuous  explain this  assume first
particular  n future observations  vacuous beliefs count vector
observe set
 
 
n
n


na    y   a   my       na 

 
holds possible observing count vector  

future count vectors
   lemma    appendix b 
namely count vectors observation outside a   
    first example shows immediate prediction models completely determine
inference system  shall come across another example appendix d 
    last equality equation actually device allows us identify count vectors
zero  count vectors a   
shall using repeatedly 
whose components outside a  
without explicit mention  rest paper 

  

ficoherent predictive inference exchangeability

would lead us associate following set polynomials count vector na  
 
 
 
n
v  
 a     p v  a     n deg p   bnp  na  
  
 
 
 
  p v  a    p a   v  a     
but  already know vacuous models v    a  lead specific systems 
whereas nearly vacuous models v     a  do  modify slightly  rather
associate following set polynomials count vector na  
 
 
  
v  
 a     p v  a    p a   v     a     
  
polynomials v  
 a  desirable representation   observing sample
count vector   infer equation      subject considers desirable
representation polynomials in 
 
 
  
  
v  
 a ba    pba    p v  
 a   

thus led consider following assessment 

  
asc a   
v  
 a ba   
na

set positive linear combinations 
hsc a

   posi  asc a    

 
 

pk ba k     n  nk n  k

nank   pk

 



  
v 
 a 
k 

      

k  

following proposition guarantees sets hsc a appropriate conservative
models summarise exchangeable inferences skeptically cautious subject 
proposition     hsc a smallest bernstein coherent set polynomials
includes asc a  
shows inference system sc   defined sc  a     hsc a category
sets a  coherent  shall call skeptically cautious inference system 
want find updating works system  end  introduce
slight generalisation set defined equation       consider na      let
hsc a    

 
 

pk ba k     n  nk n      nk      k

nank   pk

 



  
v  
 a 
k 

 

k  

    
see that  particular  hsc a   hsc a      
sets hsc a  following interesting characterisation 
    stated before  polynomials direct behavioural indirect representational meaning 
conveniently condensed representations desirable gambles observation sequences  hence
caution using term desirable representation 

  

fide cooman  de bock    diniz

proposition     na     
 
 
hsc a    p v  a           k min sa   p  p k v     k   

    


 
 
sa   p      
  k   a   k p k       

    

min sa   p  mean set minimal  non dominating  elements sa   p  
min sa   p      c sa   p     k sa   p   k c k    c    formally extend
 
equation      include case      a      sa    p     
  k   p k       
proposition     na      hsc a c   hsc a   
combining result equation       deriveadmittedly rather involved
expressions predictive sets desirable gambles skeptically cautious inference
na     
system  n n
 
 
n
  f l an     mnna  f   hsc a 
c
    
dsc a
 
na  
immediate prediction  expressions simplify significantly 
 
 
 
 
  f l a    f  a  
dsc a
  l    a  dsc a
c
    l    a  

    

na  
lower previsions derived hsc a 
tractable 
 
h sc a  p    min p x   h sc a  p  
xa

min p   p v  a  

a  


    

where  x a  x degenerate probability mass function assigns
probability mass x 
predictive lower previsions skeptically cautious inference system
na  
easily obtained combining equations            n n
 
p nsc a  f   

min mnna  f    f l an  

a  


    


p nsc a  f     min f  x  x          x  f l an   

    

  min f  x  f l a  
p  sc a  f     min f p  sc a  f   

    

xa

particular 

xa  

lower probability function given by 
 
  k   n    
sc  n  k   
  otherwise

n  k n  k n 

corresponding imprecision function by 
 
  n         k   n
sc  n  k   
  otherwise
  

n  k n  k n 

ficoherent predictive inference exchangeability

running example  before  mnn h  t    iht
      h n    take
account  h                h      get 
n
p nsc  h  t    iht
    p sc  h  t    iht
          

min

mnn h  t    iht
    

 h  t  

max

mnn h  t    iht
    

 h  t  

 h  t  

min

 h    

max

 
 h    
 


n

n

p sc  h  t    iht
    p sc  h  t    iht
          

 h  t  

categories observed count vector       meaning  h              
 h    we find inferences vacuous inference system 

interestingly  coherent inference system sc satisfies representation insensitivity specificity 
theorem     skeptically cautious inference system sc coherent  representation
insensitive specific  sc crs  

    idmm inference systems
imprecise dirichlet modelsor idms  shortare family parametric inference models
introduced walley        conveniently chosen sets dirichlet densities dia    
constant prior weight s 
 
 
 dia       ksa     ksa    ra
    
          s   int a     
value  so called  hyperparameter r   category set a  dirichlet
densities dia     defined int a    see appendix c explicit definition
extensive discussion 
idms generalise imprecise beta models introduced earlier walley        
later paper  walley bernard        focussed closely related family predictive
inference models  called imprecise dirichlet multinomial modelsor idmms 
short    refer papers  recent overview paper bernard
       extensive motivating discussion idm m s  inferences properties 
precise dirichlet models expectations  related dirichlet multinomial
models  gathered appendix c important facts  properties results 
necessary proper understanding present discussion idm m s context
inference systems 
one reasons walley        suggesting idm reasonable model
precisely satisfies pooling   invariance properties discussed section     
discussed emphasis walley bernard        bernard        
know detailed explicit formulations properties literature 
proofs seen fairly sketchy  bernard              suggests idm
    later paper  walley bernard        clearly distinguish name parametric idms
predictive idmms  earlier paper walley         types models referred
idms 
    walley uses term representation invariance rather pooling invariance 

  

fide cooman  de bock    diniz

underlying precise dirichlet models satisfy so called specificity property 
tried translate present context predictive inference section     
present section  use ideas behind walley bernards idm m s construct
interesting family coherent inference systems  give detailed formal proof
appendix e fact inference systems indeed representation insensitive
specific  interestingly  shall need slightly modified version walleys idm m 
make things work  reason walleys original version  described
expression       number less desirable properties  seem either
unknown to  ignored by  walley bernard  describe shortcomings
detail appendix d  present purposes  suffices mention that  contrary
often claimed  contradistinction new version  inferences using original
version idm m  necessarily become conservative  or less committal 
hyperparameter increases 
version  rather using hyperparameter sets ksa   consider sets
 
 
sa    ra
       r    
observe
 
 
sa   s    s  r     s    int a    



 

ksa  

  s   s

r     category set a  consider following set polynomials
p  positive dirichlet expectation dia  p   hyperparameters sa  

    p v  a      sa   dia  p         
hidm a

shall see theorem    set bernstein coherent  call inference
system sidm   defined by 

sidm  a     hidm a
category sets a 

idmm inference system hyperparameter      corresponding updated models
na      given by 
are 

   p v  a      sa   dia  p 
        
hidm a
c

    

  inf dia  p 
    p v  a  
h sidm a  p  

    




using expressions  predictive models idmm inference system straightforward find  suffices apply equations            n n
na     

 
 
s n
  f l an       sa   dia  mnna  f   
         
didm a
c
    

  inf dia  mnna  f   
    f l an   
p s n
idm a  f   


  

    

ficoherent predictive inference exchangeability

where  using notations introduced appendix c 
      dimnna  hyna  f   
   
dia  mnna  f   
   

n
 
n

 
hya  f   
 mx   x   mx    
 n 

 ma    
n
xa

n

    



general  expressions seem forbidding  immediate prediction models
na     
manageable enough 
 
 
 
s  
  f l a    f  
    
didm a c
f  x mx  

xa

 


p s  
 f
 
 
 
f  x mx  
min f f l a  
    
idm a
 
 
xa



k
n  k n  k n 
n s
corresponding imprecision function given by 
sidm  n  k   

sidm  n  k   


n  k n  k n 
n s

decreasing first constant second argument  implies
satisfies condition       suggests idmm inference systems conservative
little learned  become precise observations come in 
running example  before  mnn h  t    iht
      h n    find that 
using results appendix c 
 
 

di h  t   mnn h  t    iht
    

 h
 
 h     h       

difficult verify using equation          s 
s n

p s n
      p idm  h  t    iht
   
idm  h  t    iht

 
 
   s

observing count vector         find manipulations that 
       
      s 
 
 
   s             
     s      s 

p s n
           inf
idm  h  t    iht
similarly 




 

  s
     s      s 
s n
p idm  h  t    iht
          

 
  s


   s

 
  

observe infinitely large s  recover inferences vacuous system 
  



fide cooman  de bock    diniz

interestingly  immediate prediction models version idmm inference
system coincide walleys original version  hence  many practical applications concerned immediate prediction only  approaches yield identical
results 
idmm inference systems constitute uncountably infinite family coherent
inference systems  satisfies representation insensitivity specificity
requirements 
theorem     r     idmm inference system sidm coherent  representation
insensitive specific  sidm crs  

since crs closed non empty infima  infimum
idm idm      
still coherent  representation insensitive specific  conservative
idmm inference systems  given by 
 
 
   

 a     p v  a      ra
idm  a    v
     dia  p        

although set generally strictly includes sets v    a  v     a   associated
immediate prediction models predictive lower previsions shown coincide
ones vacuous nearly vacuous inference systems 

    skeptical idmm inference systems
combine ideas previous two sections  suppose subject uses
following system making inferences based sequence n     observations
category set a  section     skeptical
count vector  
believes future  observe categories seen previously 
rather cautious completely vacuous
categories set a   
beliefs already observed categories observed future 
uses idmm like inference them  described section    
turns done quite simply replacing  characterisation     
sets hsc a  skeptically cautious inference system  nearly vacuous models

v     k  appropriate idmm models hidm k
crk     define  category
set a  na     r     following set polynomials 
 
 


   p v  a           k min sa   p  p k hidm k
hsi a 
crk     
    
recall k min sa   p   a   k therefore k rk      
a   k   a    rk    essentially count vectors  let


   hsi a 
hsi a
     words 
 
 


   p v  a           k min sa    p  p k hidm k
hsi a
 
 
 
where  again  sa    p     
  k   p k        remainder section  show

sets polynomials hsi a
indeed lead definition reasonable potentially
useful type inference system  begin coherence 

proposition     hsi a
bernstein coherent set polynomials  

  

ficoherent predictive inference exchangeability


shows inference system ssi   given ssi  a     hsi a
category sets a 

coherent  call si skeptical idmm inference system hyperparameter s 
want find updating works inference system  following
proposition really come surprise 


proposition     na      hsi a
c   hsi a 
 

combining equation       obtain followingagain  rather involved
predictive sets desirable gambles skeptical idmm inference systems  n n
na     

 
 
s n

  f l an     mnna  f   hsi a 
dsi a
c
    
 


rather abstract  case
although expressions hsi a
c
na  
corresponding lower previsions 

h ssi a  p    min p x   p v  a 
xa

    


 
h ssi a  p  

inf

sa  


   
dia  
 ra  
 p a  
  


p v  a  
  h sidm a  
 ra  
   
 p a  


    
    

combining equation       immediately obtain following predictive lower
na  
previsions skeptical idmm inference systems  n n
n
p s n
si a  f     min f  x  x          x  f l a  
xa


 
p s n
si a  f   

inf

sa  


n
   
dia  
 mna  
  
 f  a  
n   ra  

f l an   
  p s n
   
n  ra  
 f  a  
idm a  

    

immediate prediction models skeptical idmm inference systems surprisingly
manageable 
s  
dsi a
  l    a  p s  
si a  f     min f f l a 

na  
and 
 
 
 
s  
  f l a    f  a  
dsi a c
f  x mx l    a 
 


    


xa  


 

s  
 
 f   
f  x mx  
min f  x  f l a  
p si a
 
  xa  


xa  

  

    

fide cooman  de bock    diniz

lower probability function given by 
 
k
k   n n    

si  n  k    n s
 
k   n    
corresponding imprecision function by 
 

n         k   n

si  n  k    n s
 
otherwise

n  k n  k n 

n  k n  k n 

consider case n      see ssi  n  n      ssi  n      n   
imprecision function satisfy condition      


n   s

    

running example   h                h      infer equation     
idmm inference systems 
inferences event ht

coherent inference systems ssi satisfy representation insensitivity
specificity 
theorem     r     corresponding skeptical idmm inference system
coherent  representation insensitive  specific  ssi crs  

since crs closed non empty infima  infimum
si si       still
coherent  representation insensitive specific  conservative
skeptical idmm inference systems  shown associated immediate prediction
models predictive lower previsions coincide ones skeptically cautious
inference system 

    haldane inference system
already know discussion near ignorance following theorem   representation insensitive coherent inference system fully precise  immediate prediction
models observations made  must completely vacuous  ask
whether representation insensitive  and specific  inference systems whose
posterior predictive lower previsions become precise  linear  previsions  problem
address section  shall first construct inference system  show
system is  definite sense  unique linear posterior predictive previsions 
use family idmm inference systems sidm   r     define inference
system h committal them 



hidm a
 
sidm  a  category sets a 
h  a    hh a   
sr  

sr  

call h haldane inference system  reasons become clear
section 
theorem     haldane inference system h coherent  representation insensitive
specific  h crs  
  

ficoherent predictive inference exchangeability

due representation insensitivity  haldane system satisfies prior near ignorance 
implies making observation  immediate prediction model vacuous 
far away precise probability model possible  show
that  making even single observation  inferences become precise probabilistic 
coincide inferences generated haldane  improper  prior 
get there  first take look models involving sets desirable gambles 
na     



   p v  a     s r      sa   dia  p 
          

hh a c
hidm a
c 
sr  
    
corresponding predictive models easily derived applying equation      
na     
n n
 
 
n
  f l an      s r      sa   dia  mnna  f   
       
dh a
c

s n

 
didm a
c 
    
sr  

immediate prediction models obtained combining equations           
na  

 
 

 
 
  f l a   
dh a   l    a  dh a c
f  x mx     l    a  
xa

turns expressions corresponding lower previsions much
na     
manageable  first all  find
      lim h sidm a  p  
p v  a  
inf dia  p 

  lim
h h a  p  

s   sa

s  

    

     simplifies to 
particular 
h h a  p    min p x   p v  a  
xa

    

na   find linear previsions   
whereas
  h h a  p  
  hh a  p  
  dia  p  
p v  a  
h h a  p  

    

corresponding predictive models easily derived applying equation      
na     
n n
  lim
p nh a  f   

      lim p s n
f l an   
inf dia  mnna  f   
idm a  f   

s   sa

s  

    
    
particular 
p nh a  f     min f  x  x          x  f l an   
xa

    dirichlet expectations dia     strictly speaking defined ra
     argue
appendix c  continuously extended components zero  others strictly
positive 

  

fide cooman  de bock    diniz

na  


p nh a  f   

 

n

p h a  f   

 

n

ph a
 f   

 


n
na

   
 nx  
n
xa mx
 
 n 



hyna  f   

    



na  
immediate prediction models  find

mx
 
 
p  h a  f     min f ph a
 f   
f  x 
f l a  

xa

lower probability function given by 
 
k
n    
h  n  k    n
n  k n  k n 
 
n    
corresponding imprecision function given by 
 
  n    
h  n  k   
n  k n  k n 
  n    
satisfies condition       suggests haldane inference system displays
albeit extreme interesting mannerthe desirable behaviour mentioned
introduction  conservative little learned  never become less
precise observations come in 
running example  use equation      results previously obtained
idmm inference systems find
n

n
p nh  h  t    iht
      ph  h  t    iht
          
    p h  h  t    iht

 
 
  

want point first equalities contradict prior near ignorance
haldane inference system  pertains immediate predictions  predictions
single future observations 

precise posterior predictive previsions equation      exactly ones
would found formally apply bayess rule multinomial likelihood
haldanes improper prior  haldane 
      jeffreys        jaynes         whose density
function int a   proportional xa x    this  course  use haldanes name
inference system produces them  argumentation shows nothing
wrong posterior predictive previsions  based coherent inferences 
fact  analysis shows infinity precise proper priors simplex
that  together multinomial likelihood  coherent posterior predictive
previsions  every coherent prevision v  a  dominates coherent lower prevision
h h a v  a     binomial parametric inferences haldane prior  walley       
section        comes related conclusion completely different manner 
    immediate consequence f  riesz representation theorem coherent prevision
restriction polynomials expectation operator unique  additive probability measure
borel sets   see instance discussion de cooman miranda      a 
footnote   

  

ficoherent predictive inference exchangeability

simple argument show haldane posterior predictive previsions
precise ones compatible representation insensitivity  indeed 
shown representation insensitive coherent inference system precise
posterior predictive previsions  lower probability function must satisfy  n  k    k n
n       k n    straightforward prove  using bayess theorem go
immediate prediction general predictive inference  posterior predictive
previsions must haldanes 

    characterisation idmm immediate predictions
lower probability function  n  k  representation insensitive coherent inference
system gives lower probability observing non trivial event observed k
times n trials 
suppose subject specifies single lower probability  namely value
               probability observing something  again  observed  once 
single trial  ask conservative consequences
assessment are  take representation insensitivity specificity granted 
words  conservative representation insensitive specific coherent inference
system  at least  given value        lower probability function 
question makes sense representation insensitive specific coherent inference
systems constitute complete meet semilattice statement      theorems        
clearly              smallest representation insensitive specific coherent
inference system  know discussion sections       must
immediate prediction models predictive lower previsions  nearly  vacuous
inference system  consider case                   words  use
parametrisation turn convenient purposes  that 
        

 
 
positive real number   
  
  s
      

    

let us denote conservative inference system   lower probability
 
function   assumption          s
  follows theorem    l 
n

 n  n  n s n n    since idmm inference system sidm   equation     
n
tells us sidm  n  n    n s
  since assumption sidm  n  n   n  n   conclude
that 
n
 n  n    sidm  n  n   
n n   
    
n s
surmised  bernard        de cooman et al       a  idmm inference
system hyperparameter could smallest  conservative  representation
 
insensitive specific coherent inference system given value            s
 
fact  trying prove made us start research present paper 
conjecture turns false  apart lower bound       n  n  
    suffices exploit additivity precise probabilities symmetry implied representation
insensitivity  explicit proof  see paper de cooman et al       a  thm     
    see discussion near end section   
    surmise  prove here  conservative representation insensitive specific
coherent inference system corresponding            might skeptically cautious one 

  

fide cooman  de bock    diniz

representation insensitivity specificity impose lower bounds  n  k  k   n 
see this  consider inference system smc    inf sc   sidm    statement     
theorems              coherent  representation insensitive specific  smc crs  
lower probability function smc satisfies 
 
n
n
min    n s
    n s
k   n    
smc  n  k    min sc  n  k   sidm  n  k    
k
min    n s      
otherwise 
substantiating claim made above  see figure    depicted lower  and
upper  probability functions haldane system h   idmm system sidm   smc
n

inference system inf  s
si   idm    latter three share value n s  n  n  
n    conjecture smc could smallest  conservative  representation
 
insensitive specific coherent inference system given value            s
  offer
proof this 
 n  k 
 
n
n s


n s

 
 

 

 

   

n 

n

k

figure    lower upper probability functions  h haldane system  dark grey 

    sidm idmm system hyperparameter  blue      min  s
si   idm  
 orange    smc   min sc   sidm    red     specific plot made
n          
means want characterise idmm inference systems way
conservative ones  need add  besides coherence  representation insensitivity
specificity  another requirement preserved taking infima  one possible
candidate this  shall prove job inspired figure   
following requirement 
let us define subjects surprise event supremum rate betting
opposite event  words  lower probability opposite event  surprise
highclose onewhen subject believes strongly event occur 
lowclose zerowhen subject strong beliefs occur 
  

ficoherent predictive inference exchangeability

allows us associate so called surprise function  n  k      n  n k 
lower probability function   n  k  subjects surprise observing non trivial
event observed k n times before 
follows theorem    l  representation insensitive system  surprise
function non increasing second argument 
 n  k      n  k       n  k     n  n k     n  n k      k n   
fairly intuitive property  often event observed before 
smaller surprise seeing again 
shall say representation insensitive system concave surprise
   n  k      n  k       n  k      k n   
where  course     n  k     n  n k      n  n k       n  n k  
difficult see concave surprise preserved taking non empty infima
inference systems  makes sense go looking smallest  most conservative 
coherent representation insensitive specific coherent inference system concave
surprise  satisfies additional local assessments       
looking figure   makes us suspect idmm inference system sidm might
system  again  offer proof conjecture  however provide proof
following  related  probably  weaker  statement  focusses immediate
prediction only 
theorem     immediate prediction models p  a      na     smallest
 most conservative  coherent representation insensitive specific coherent inference system
concave surprise satisfies       coincide ones idmm inference
system sidm hyperparameter s 

    conclusion
believe first paper tries deal systematic fashion principles
predictive inference exchangeability using imprecise probability models  two salient
features approach  i  consistently use coherent sets desirable gambles
uncertainty models choice   ii  notion inference system allows us
derive conservative predictive inference method combining local predictive probability
assessments general inference principles 
first feature allows us  contradistinction approaches
probability theory  avoid problems determining unique conditional models
unconditional ones conditioning events  lower  probability zero  set
n c

polynomials ha completely determines prior posterior predictive models da
n
n
even  lower  prior probability p     
  h  ba 
p     
  observing
zero  approach using lower previsions probabilities would make
count vector
much complicated involved  impossible  interestingly  provide
perfect illustration fact using results sections              three
    something similarly dramatic happens sections       inference systems
immediate prediction models  predictive  lower previsions  one specific
not 

  

fide cooman  de bock    diniz

inference systems described therethe skeptically cautious  skeptical idmm
haldane systemshave  given category set a  three different sets polynomials
ha   nevertheless  gather equations                 
lower prevision h therefore prior predictive models p na   count vector
na prior lower probability 


  h  ba 
p na     
    min ba 
 x       
xa


zero lower probability makes sure posterior lower previsions h    
uniquely determined prior lower prevision
posterior predictive models p na    
h   infer equations                 indeed different
three types inference systems  fail see could come withlet alone
proved necessary results forthese three systems relying lower prevision credal
set theory 
canand musttake line argumentation even further  theorem   
inference system satisfies  prior  representation insensitivity near vacuous prior
predictive models  therefore  time consistency coherence  monotonicity   see
n
   
prior predictive lower previsions must satisfy h  ba 
    p     
na well  simply means impossible  prior  representation insensitive

coherent inference system lower prevision h uniquely determine conditional
therefore systematic way dealing inference
lower previsions h     
systems must able resolveor deal withthis non unicity way  believe
approach involving coherent sets desirable gambles one mathematically
elegant ways this 
second feature allowed us  example  characterise idmm immediate
predictions conservative ones satisfying number inference principles 
approach follow canat least principlealso used types inference
systems inference principles  key requirement inference principle
make amenable approach that  formulated property inference
system  preserved taking arbitrary non empty infima  three inference
principles considering aboverepresentation insensitivity  specificity
concave surprisehave property  nothing prevents analysis
approach extended inference principle too 
complications see  point  technical mathematical nature  reader
doubt noticed proofs results later sections quite involved
technical  rely quite heavily properties polynomials simplex  feel
present paper made headway mathematical territory  instance
new discussion bernstein positivity polynomials near proposition   
appendix b  conclusions paper de cooman quaeghebeur        
characterisation bernstein positivity mentioned open problem interesting
practical applications inferencenatural extensionunder exchangeability 
much remains open exploration  determined study mathematical
structure properties polynomials would certainly help alleviating technical
difficulties working inference principles inference systems 
paper opened feel interesting line
research foundations predictive inference  nevertheless provided answers
  

ficoherent predictive inference exchangeability

number ofif allopen problems formulated conclusions earlier paper
de cooman et al       a   tried deal representation insensitivity immediate
prediction  first example  asked whether representation insensitive
coherent inference systems whose lower probability functions additive second
argument  suffices look figure   see answer is  clearly  yes  another
question was  representation insensitive coherent inference systems
mixing predictive systems    follows equation      answer yes 
skeptical idmm inference systems provides example  finally  use infimum
smc skeptically cautious inference system sc idmm inference system sidm  
mentioned briefly section     answer two questions  representation
insensitive coherent inference systems inequality theorem    l  strict 
representation insensitive coherent inference systems whose behaviour
gambles completely determined lower probability function  inference
system smc provides positive answer questions 
inference systems mentioned above  apart idmm haldane
systems  appear first time  may appear contrived perhaps
even artificial  found useful constructing  counter examples 
shaping intuition  building new models  figure   argumentation clearly
indicate  might wonder whether representation insensitive and or
specific coherent inference systems  cannot produced appropriately chosen infima
examples introduced here  suggest  candidates consideration 
inference systems derived using walleys        bounded derivative model 
inference systems constructed using sets infinitely divisible distributions 
recently proposed mangili benavoli         framework provided here  well
simple characterisation results theorems       quite useful addressing
similar problems 
end  want draw attention simple direct  quite appealing 
consequence argumentation section     infinity precise proper
priors that  together multinomial likelihood  coherent haldane posterior
predictive previsions  so  need improper priors justify posteriors 
proper priors job perfectly well   precise  probabilistic conclusion
follows easily looking problem using general powerful language
imprecise probabilities  moreover  seen properties representation
insensitivity cannot satisfied precise probabilistic models  finally  entire framework
conservative predictive inference using inference principles would impossible develop
within limitative context precise probabilities  shows distinct
advantages using imprecise probability models dealing predictive inference 

acknowledgements
gert de coomans research partially funded project number  g      
research foundation flanders  fwo   jasper de bock phd fellow research
    loosely speaking  cannot written  specific kind of  convex mixture haldane inference
system idmm inference system  see paper de cooman et al       a  section   
information 

  

fide cooman  de bock    diniz

foundation flanders wishes acknowledge financial support  marcio diniz
supported fapesp  so paulo research foundation   project             
wishes thank systems research group ghent university hospitality
support sabbatical visit there  authors would thank three anonymous
reviewers many insightful comments suggestions aimed making paper
easier read cleaning misunderstandings  special thank great
arthur van camp enthusiasm everything and  particular  helping us check
little examples 

appendix a  notation
appendix  provide list commonly used important notation 
defined first introduced 
notation

meaning

introduced

a  b  c 
ib
x  xn
n
n
posi a 
l a 
l    a 
l   a 




n
da

category sets  events
indicator event b
variable  variable time n
number already observed variables
number observed variables
cone generated
set gambles
set positive gambles
set non positive gambles
observed sample
observed count vector
prior predictive set desirable gambles
category set n future observations
posterior predictive set desirable gambles
prior predictive lower prevision
posterior predictive lower prevision
pooling map relabelling map
renaming bijection
category permutation
sample observations outside b eliminated
counting map
set count vectors n observations
set count vectors  zero
hypergeometric expectation operator
multinomial coefficient count vector
multinomial expectation operator
simplex probability mass functions
sum components x x b
bernstein basis polynomial
set polynomials degree n

section  
section    
section  
section  
section  
equation    
section    
section    
section    
section  
section    
section  

n c 
n c
da

da
n
p   
p na    

p na     


 
b


nan
na   na    
hyna    
  
mnna    

b
ba 
v n  a 

  

section  
section  
section  
sections        
section    
sections    
section    
equation    
equation    
section    
equation     
equation     
equation     
equation     
equation     
equation     
section    

ficoherent predictive inference exchangeability

v  a 
v    a 
v     a 
ha

ha c
ha

h    
f

c
crs
r
rb
ia
irb a
sa



subscript
subscript
subscript
subscript
subscript
subscript
subscript

a  
  
v  
 a 

v
nv
sc
idm
si
h
oi

dia    
dia    
dimnna    
bnp

set polynomials
set bernstein positive polynomials
set polynomials
positive int a  
representing set polynomials
updated representing set polynomials
lower prevision induced ha

lower prevision induced ha c
set category sets
inference system
set coherent inference systems
set coherent inference systems
representation insensitive specific
extended relabelling map
restriction map
injection map
extended injection map
sampling expectation
lower probability function
imprecision function
surprise function
related vacuous inference system
related nearly vacuous inference system
related skeptically cautious inference system
related idmm inference systems
related skeptical idmm inference systems
related haldane inference system
related original idmm inference systems
categories already observed
set polynomials
positive int a    
dirichlet density
dirichlet expectation operator
dirichlet multinomial expectation operator
expansion polynomial p
bernstein basis degree n

section    
section    
section   
theorem  
equation     
equation     
equation     
definition  
definition  
equation     
theorem   
equation     
equation     
equation     
equation     
section  
equation     
equation     
section   
section  
section   
section   
section   
section   
section   
appendix
equation     
section   
appendix
appendix
appendix
appendix

c
c
c
b

appendix b  multivariate bernstein basis polynomials
n   nan corresponds
bernstein basis polynomial
 multivariate 

x
  
degree n   given ba    
   xa x     polynomials
number interesting properties  see instance prautzsch  boehm    paluszny       
chapters         list here 
bb   set  ba   
nan   bernstein basis polynomials fixed degree n linearly
independent  n n ba           nan  


  

fide cooman  de bock    diniz

nan   bernstein basis polynomials fixed degree n forms
bb   set  ba   
partition unity  n n ba      


bb   bernstein basis polynomials non negative  strictly positive interior
int a    
bb   set  ba    nan   bernstein basis polynomials fixed degree n forms
basis linear space polynomials whose degree n 
property bb  follows bb  bb     follows bb  that 
bb   polynomial p unique expansion terms bernstein basis polynomials
called bernstein expansionof fixed degree n deg p  
words  unique count gamble bnp nan that 

p    
bnp   ba      

    

n
na

tells us  also use bb  bb   p   convex combination bernstein
coefficients bnp     nan whence 
min bnp min p p   max p max bnp  

    

following proposition adds detail picture 
proposition     polynomial p  
lim  min bnp   max bnp      min p  max p    p a   

n 
ndeg p 

proof proposition     since bnp converges uniformly polynomial p n  
 trump   prautzsch         sense
   



lim maxn p
bnp        
n  na
n
ndeg p 

find
lim

n 
ndeg p 

min bnp min p  

lim

 
 
minn bnp    min p

n  na
ndeg p 

 
    
minn bnp    p
n  na
n
ndeg p 
   



lim maxn p
bnp        
n  na
n



lim

ndeg p 

therefore limn  ndeg p  min bnp min p  furthermore  statement       see
limn  ndeg p  min bnp min p  hence indeed limn  ndeg p  min bnp   min p  proof
equality completely analogous 
    see how  clearly polynomials definition linear combinations bernstein basis polynomials 
possibly different degrees  terms  use bb  raise degree common higher
degree nmultiply appropriate version    shows bernstein basis polynomials
fixed degree n generating polynomials lower degrees  independent bb  

  

ficoherent predictive inference exchangeability

using results  prove number useful relations bernstein
positivity polynomial positivity  the interior of  simplex  related
property first proved hausdorff univariate case  hausdorff        p       
proposition     let p polynomial   consider following statements 
 i     p       
 ii  p v    a   meaning n deg p  bnp     
 iii  p v     a   meaning   int a   p       
 iv     p     
 i  ii  iii  iv  
proof proposition     first implication direct consequence proposition    
infer  i  continuity p min p     therefore  proposition    
limn  ndeg p  min bnp   min p      implies  ii  
prove  ii  iii   assume n deg p  bnp     
consider int a    since ba         nan  bb    since
assumption bnp   bnp        nan   see
p    



bnp   ba     bnp   ba         

n
na

third implication immediate consequence continuity p 
following counterexample shows necessarily v    a    v     a  
running example  go back polynomial q  h  t  u   defined equation      
 
 
q     h
h  
   h      h  h  t  u    

already argued polynomial bernstein positive  nevertheless 
obviously positive interior  h  t  u    

quite easy trace effect bernstein expansion multiplying
bernstein basis polynomial 
proposition     polynomials p   natural n deg p   na    
nan ma  

  
bn    

p
n ma
 

   
bpba      

 
otherwise 
proof proposition     observe that 
 
 

n
pba   
bp   ba  ba   
bnp   ba  ba 
n
na

n
na

  

fide cooman  de bock    diniz

 



bnp   

n
na

     
ba    
    

use uniqueness  bernstein  basis expansion 
allows us prove following simple interesting result bernstein positivity 
proposition     consider na     polynomial p   then 
pba  v    a  p v    a  
proof proposition     first  assume pba  v    a   natural n
n

deg p  bn m
pba       follows proposition    bp     
therefore p v    a  
assume  conversely  p v    a   n deg p  bnp     
 

follows proposition    bn m
pba       therefore pba  v  a  

appendix c  dirichlet distribution
density dia     dirichlet distribution hyperparameter ra
   given by 
dia       


 a  
xx   int a   
 
 
x
xa
xa

polynomial p define corresponding expectation as   


 a  
p  
dia  p     
xx   d 
 
 
x

xa
xa

particular 


 

 


 a  
xx  
 x  

xa
xa
xa
   
   

n
 a  
 mx   x  
 
n
 
x  mx    
 
 n    
 x  
 n 

dia  ba      

n


xmx

    

xa

xa

using ascending factorial  r       r 
                      r     r
r n   
dirichlet distribution used prior combination multinomial
likelihood  leading so called dirichlet multinomial distribution  described
follows  probability observing  a sample n   observations with  count vector
na     multinomial process dirichlet prior density dia     given by 

n
dimna         
comnna       dia    


    integrals section interpreted multiple riemann integrals 

  

ficoherent predictive inference exchangeability


ba     dia       dia  ba     

 


second equality follows equation       therefore  generally  take
expansion polynomial p bernstein basis polynomials degree n deg p  
dia  p    



bnp    dia  ba      

n
na

  dimnna



bnp    dimnna  i     

n
na

 
n
na

 

n
bp   i     dimnna  bnp    

dirichlet multinomial expectation count gamble bnp   general
useful relationship dirichlet expectation polynomial p  dirichlet
multinomial expectation bernstein expansion bnp   although expectations
strictly speaking defined ra
     extend definition continuously
elements ra
 
   

taking
appropriate
limits  equation      indicates 

c   special properties dirichlet distribution
recall interesting properties dirichlet distribution  begin
updating property 
proposition     updating   category set a  polynomial p v  a   count
vector na     ra
    
dia  pba       dia  ba     dia  p      
proof proposition    

dia  pba      
p  ba     dia    

 
 


mx  a  
xx  
 
p  
x
 
 

x

xa
xa
xa
 
 


 mx   x  

 a  
 
p   dia       
 ma    
 x  

xa

  dia  ba     dia  p      
last equality follows equation      
next  turn so called renaming property 
proposition     renaming   category sets c bijective
 one to one onto  map   c  polynomial p v  c  ra
    
dia  p r      dic  p r     
  

fide cooman  de bock    diniz

proof proposition     due linear nature dirichlet expectation  clearly
suffices prove property bernstein basis polynomials p   bc   
nc      observe r bijection too  then  using equation       let    r   
   r      z      z  mz   n   z  z c    c
na   mc   get 
 
 
 mz   z  
mc
 c  
dic  bc   r       dic  bc      
 mc   c  
 z  
zc
   
 n   z       z   
 a  
na
 
 na    
    z   
zc
   
 nx   x  
 a  
na
 
  dia  ba     
 na    
 x  
xa

take account int a   
 bc  r       bc   r    
 
 
 
 
 
 
mc mz
mc
mc n   z 
mz
 
   z 
   z   
r   z  



zc
zc
zc
   
na
xnx   ba     
 

xa

see indeed dic  bc   r       dia  bc  r    
so called pooling property generalises renaming property 
proposition     pooling   category sets onto
map   d  polynomial p v  d  ra
    
dia  p r       p r     
proof proposition     due linear nature dirichlet expectation  suffices
prove property bernstein basis polynomials p   bd    nd     
also  take account renaming property proposition     enough consider
following special case  non empty set different categories b 
c belonging it  let     b  c      d   define letting
 x     x x  b     c     d 
one hand  taking account equation       letting    r     
 
 
 mz   z  
md
 d  
 bd   r        bd      
 md    
 z  
zd
 
 
md
 d  
 md      mz   z  
 
 
    
 md      d  
 z  
zdo

hand 

  

ficoherent predictive inference exchangeability

dia  bd  r   
 
 
 
 
md
md
mz
 b   c  
z
dia    
 


zdo
 
 


 a  
md

 
 b   c  md bb   cc  
zmz  z  

xa  x  
zdo
 
 
 
 



md

 a  
md

bk b   cmd k c  
zmz  z  
 
k
 
 

x

xa
zdo
k  

 
 
 
 



 a  
md  k   b   md k   c   zdo  mz   z  
md

 
 

k
 md    
xa  x  
k  

so  compare results recall     z   z z   b   c  
see must prove that 
 
md  

 
md
 md   b   c  
 
 k   b   md k   c  
 b   c  
 b   c  
k
k  

equivalently  using ascending factorials 
 b   c   md    

 
md  

md
b  k  c  md k   
k

    

k  

see proving pooling property essentially equivalent proving equation      
binomial theorem ascending factorials  well known result 
follows fact ascending factorials sheffer sequences binomial type  sheffer 
       completeness  give proof here  easy 
shown hold prove pooling property particular case
   a   category different b  c d     a  b  c     a  d  
case rewrite equation      as 
 bd   r    
 
 
  md
 a   b   c  
 md   b   c    ma    
 

 ma   md     b   c    b   c  
 a  
whereas
dia  bd  r     
let
   
  
 
 

  

 

  

 

 a

 md bb     

 md ama  a  

 

 
 
  md  a   b   c  


 a   b   c  



 a

b  c   ama  a   db

bb     

b  

c  

 
da

 

db da
   
 
 
md  b  c    a  
b  
c  
 
    


   t 
dt da
 

 

 

 

  

fide cooman  de bock    diniz

  b ma     md   b   c  b b   c    

 ma     md   b   c    b   c  
 
 ma   md     b   c    b   c  

using well known evaluation beta function terms gamma functions 
finally  look properties related restriction 
proposition     restriction   category sets b b a 
polynomial p v  b   ra
   r n   
dia  irb a  p     

 deg p    r   b  
 a  
dib  p rb     
 deg p    r    
 b  

proof proposition     let n    deg p    r  due linearity dirichlet
expectation operator  equations           

dia  irb a  p     
bnp    dia  ba ia      
n
nb



   
n
 a  
xb  nx   x  
xa b  x  


 
 n    
n
xa b  x  
xb  x  
nb
   

n
 a    nx   x  
 
bnp   
 n    
 x  
n


bnp   

nb

 


n
nb

 

xb

bnp   

 a    n   b  
dib  bb   rb    
 n      b  

 a    n   b  
dib  p rb     
 n      b  

concluding proof 

appendix d  original idmm inference system walley
bernard
idmm inference system sidm   introduced section     differs one
originally proposed walley bernard           appendix  discuss original
idmm inference system  denote soi   explain related ours 
illustrate advantages version one walley bernard 
d   defining original idmm inference system
r     category set a  consider following set polynomials 

    p v  a      ksa   dia  p       
hoi a

   p v  a      int a    dia  p s        
    strictly speaking  walley bernard propose inference system sense  rather
collection prior posterior predictive lower previsions category set a  inference system
call original idmm inference system one produces predictive lower previsions 

  

ficoherent predictive inference exchangeability

reasons become clear shortly  call inference system soi defined

soi  a     hoi a
category sets a 

original idmm inference system hyperparameter      updating done much
na     
way inference system sidm section    

   p v  a      int a    dia  p 
  s        
hoi a
c

compared equation       leave exercise reader
check soi coherent representation insensitive    however  illustrated
counterexample section d    soi specific 
predictive models soi easily derived mimicking approach used
section    derive predictive models sidm   see equations           
nan  
n n    n n
 
 
s n
  f l an       int a    dia  mnna  f   
  s       
doi a
c

    

 
p s n
oi a  f   

    


inf
int a  

  s  gambles f  
dia  mnna  f   

latter expression motivates refer soi original idmm inference system 
predictive lower previsions coincide proposed walley bernard        
using equation      n      mimicking argument proof equation     
appendix e    see
s  
 
doi a
c

 
f l a    f  

 
 
s  

na     
f  x mx   didm a
c

xa

tells us idmm original idmm immediate prediction
models  corresponding immediate predictive lower previsions original idmm
well known course identical ones produced version idmm
inference system  given equation       however  examples next section
illustrate  equality extend beyond immediate prediction  idmm
original idmm different coherent inference systems  leads us general
important conclusion coherent inference systems completely determined
immediate prediction models 
nevertheless  approaches closely related  comparing equations           
nan
see n n    n n
 

 n
  inf  p soi a
gambles f  
p s n
 f   
idm a  f   
  s  s

    proof similar one sidm  see theorem     

  

    

fide cooman  de bock    diniz

d   original idmm inference system monotone
hyperparameter original idmm inference system usually interpreted
degree caution  higher values often claimed produce inferences
cautious less informative  following quote walley bernard       
section      makes explicit 
b event concerning future observations  idmm s  produces intervals
posterior probabilities  p  b    p  b    nested become wider
increases  means inferences produced two idmms different
values always consistent other  effect increasing
simply make inferences cautious less informative 
similar statements found related papers walley        section      bernard
       section       although indeed true many inferences  including many important
onesfor example  immediate predictions  hold event concerning
future observations  illustrated following example  lower probability
event concerning two future observations shown initially increase s 
example    consider situation possibility space consists two elements
only  say heads  h  tails  t    observed once  n    
   mh   mt             interested predictive lower probability

next two trials  heads tails observed once  n     looking
    h      t  h   
   mh   mt            
predictive lower probability event   
original idmm inference system  following formula provides closed form
expression 
 
p s n
  
oi a  i  

  s    inf dia  ba 
  s 
dia  mnna  i  
 
  
int a  
   
 
n
 mx   stx   mx  
  inf
 n 


int a    n   s 
xa
inf

int a  

  inf

  t  

      st      s   t  
      s 
 
 
     s      s 
     s      s 

initially increases s  see figure   
conclude p s n
  
oi a  i  

    


version idmm inference system  statement made aforementioned
quote hold event concerning future observations  follows trivially
equation       illustrate next example 
example    consider problem example    time  solve using version
idmm  result depicted figure    function hyperparameter s 
s n
p idm a
non increasing function s  indeed 
contrast p s n
 i  
   
  
oi a  i  

   n
 

 
 i  
       
p soi a

  
slim
   
 
s n
 
p idm a  i  
  

      s 

p s n
 
 
  
oi a  i  
     s      s 
closed form expression find combining equations           
  



ficoherent predictive inference exchangeability

    


p s n
  
oi a  i  

    
    


p s n
  
idm a  i  

   
    

 

   

 

   

 

figure    lower probability observing two different outcomes next two experiments  given possibility space consists two categories 
already observed once  solutions according soi  solid line  sidm
 dashed solid line   see examples     information 

clearly  inferences soi sidm differ  suffices compare results
examples      see figure   well  therefore  seems clear walleys        p     
statement          allowed vary   s  produces exactly
inferences idm   s  equivalently  soi sidm produce
inferences  taken apply immediate prediction only 
d   original idmm inference system specific
announced theorem     version idmm inference system specific 
show that  least values hyperparameter s  true original
version 
nbn   b f l b n   
consider n n    n n
s n
  int a    dia  mnna  f ib n   ia   
  s     
f ib n doi a
cia   

  srb         
  int a    dib  mnnb  f   
last equivalence consequence propositions       fact
   
particular b a  hard see sb    srb      int a    
rb  ia    
implies that 
s n
s n
  sb   dib  mnnb  f   
        f didm b

f ib n doi a
cia   
c 

therefore also 

b n     inf dib  mnnb  f   
      p s n
p s n
oi a  f  ia    
idm b  f    
b

  

fide cooman  de bock    diniz

hand  due equation  sp    soi specific  would that 
b n     p s n


  p s n
p s n
oi a  f  ia    
oi b  f  rb  ia     
oi b  f    
p s n

hence  order soi specific  necessary p s n
oi b    
idm b    
coincide  illustrated examples previous section  necessarily
case  therefore  soi always specific  counterexample provided 
difference occurs     only  whereas practice  usually chosen either  
   walley   bernard        section       would interesting see whether similar
counterexamples constructed   
original idmm inference systems specific  apparently contradicts theorem    de cooman et al       a   seems state are  fact 
theorem states original idmm immediate prediction models satisfy weaker
specificity condition  tailored immediate prediction only  since immediate prediction
models original idmm idmm coincide  contradiction 

appendix e  proofs additional results technical
e   proofs results section  
proof theorem    sake notational simplicity  use intuitive notation f  xk  
extnk  f    give proof general definition  terms sets desirable
gambles  proof lower previsions follows immediately 
consider category set a  n n    k n gamble f
n may assume without loss generality singleton 
f  xk   da
already implies f      coherence  d    hence particular f      max f     
assume ex absurdo f       must f  a       define
gamble g letting g a     f  a  g x     max f     x    a  
g f therefore g xk   f  xk    implies  coherence  use d  d   
n   let    max f f  a         f  a        define
g xk   da
n       
gamble h    g      ia  a    also  coherence  d    h xk   da
consider natural number n    follows repeatedly applying pooling
n
renaming invariance appropriate manner   i a     zk   d a
 
       an  
zk variable assumes value a  xk    assumes value
 a              xk   a  repeatedly applying category permutation invariance  find
n
  i a     zk   d a
              n    coherence  d   tells us
       an  
n
n
n               i a     zk    d a
  leads contradiction coherence
       an  
 d   choose n large enough 
e   proofs results section  
proposition     n n        r       
proof proposition     consider z d 
tz        k             n     xk     z    


ya    y  z

  

  k             n    xk   y  

ficoherent predictive inference exchangeability



 

ty      r      z  

ya    y  z

concluding proof 
lemma     n n  nan dn  

 
 
i       

   
  
 r      r    
  


proof lemma     consider map   dn r defined       i    
permutation index set             n  dn   see


    
i       
i         
  

  



 



i       

  

i           

  

tells us permutation invariant thereforeconstant atoms
    ndn   means that  obvious notations    n n   i    

       implies        therefore 
proposition               r         r    therefore  r      tells
us        unless   r    therefore    r    i r      
plug f      equation       see


    
    
 r    i r           r     r     
dn

dn

lemma     n n ndn  


bd  r  

ba 

n   r    
na


proof lemma      
     
 nz
n
 bd  r      
x

zd x    z  
   
   

n
nz
 
z


nz
z
zd n

   
n
 

 

    z  

 


n   r    
na



n 
na

r    

 

n


  

xa

z

xmx

x    z  

xmx

   

xa

 

concluding proof 



xmx  

zd

 

nz

     z  


n 
na

r    

ba     

fide cooman  de bock    diniz

lemma allows us prove two related propositions 
proposition     n n gambles f dn   mnna  f     mnnd  f   r  
proof proposition     first all  count vector nan
hyna  f     



 
 
f     
i     f   
  
  
n
  

  



 

f   

dn

i     

    

  

 

  
f   
 r      r    
n



 



 

 
  



 
 r    



f      hynd  f  r     

 r    

fourth equality follows lemma     therefore indeed 


mnna  f    
hyna  f   ba   
hynd  f  r    ba 
n
na

 



n
na

hynd  f   

n
nd

 





ba 

n   r    
na


hynd  f    bd  r     mnnd  f   r  

n
nd

fourth equality follows lemma    
proposition     polynomials p n n  n deg p  
bnpr   bnp r  
proof proposition     find expanding p appropriate bernstein basis 
 
 

n
p r  
bp   bd  r  
bnp    bd  r  
n
nd

 



bnp   

n
nd

 



n
nd



ba   





bnp  r    ba 

n
n   r    
nd
na


n   r    
na


 bnp r    ba   

n
na

third equality follows lemma     desired result follows
uniqueness expansion  bernstein  basis 
proof theorem    fix category sets onto map   d 
gamble f dn   use notation ha     a 
n  n n 
  

ficoherent predictive inference exchangeability

hd     d   transform condition  ri   using equivalence condition      
      

one hand  letting
n
f da
mnna  f   ha mnnd  f   r ha
n
n
n
ba 
f da
c
mna  f   ha ba 
 mnd  f   r   ha  

second equivalences follow proposition     hand  recalling
  r      
  r   
proposition    
  
n
f dd
mnnd  f   hd
n
n
bd r   
f dd
c
mnd  f   hd  

tells us equivalences condition  ri   rewritten as 
mnnd  f   r ha mnnd  f   hd
n
n
ba 
 mnd  f   r   ha bd r   
mnd  f   hd  

proof complete observe  and recall discussion section    
appendix b  varying n n f l dn    let p    mnnd  f   range
  let
     
range
polynomials   varying n n
count vectors na  
proof theorem    let  ease notation    inf ii   coherent using equation       consider category sets onto map   d 
p v  d  na      then  using representation insensitivity
coherent theorem   
 p r  ba   a   i i  p r  ba   a 
 i i pbd r     d  pbd r     d  
concludes proof 
proposition        b     rb       
proof proposition     immediate  since b sample whose components belong
b  category b  number times occurs b exactly
number times occurs  
proof proposition    consider b   let  simplicity notation   ia    
since nbn   n    deg p    r
 
 
   
n
n
ia   x
ba ia        
x
 
nx x   bb     
ia   

xa

xb

see indeed 
irb a  p    



bnp   ba ia        

n
nb


n
nb

  

bnp   bb       p   

fide cooman  de bock    diniz

proof proposition     deg p    r      r     p   c r  trivially
irb a  p     i b a  c      c  let us assume deg p    r      first all  observe
deg p  r

nb

 
 
 
 
 
deg p    r ia   x
deg p    r nx
ba ia        
x
 
x
ia   

xa
xb
 
deg p  r
b
bb     
b    
b 
 
 
otherwise 

    

therefore already follows condition      irb a  p       b      let us therefore
assume b      condition      equation      tell us that 

irb a  p    
bdeg p  r
  ba ia      
p
deg p  r

nb

deg p  r



 

bdeg p  r
  b
p

bb     
b 

deg p  r

nb

deg p  r

deg p  r



  b

bdeg p  r
  bb     
p
b     b

p   
b   

deg p  r

nb

concludes proof 
proposition     n n gambles f b n  
mnna  f ib n     irb a  mnnb  f     r    n deg mnnb  f    
proof proposition     first all  count vector nan thatwith
slight abuse notation 
hyna  f ib n     


 
 
 f ib n      
  
  
  



f   

  b n

zero unless   ia    nbn   case  since obviously         
 ia     b n   again slight abuse notation 
hyna  f ib n  ia      

 
f      hynb  f    
  
  

therefore  recall condition      


hynb  f   ba ia   
mnna  f ib n    
hyna  f ib n  ia    ba ia     
n
nb

n
nb

  irb a  mnnb  f    
r    n deg mnnb  f    
  

ficoherent predictive inference exchangeability

proof theorem     fix category sets b b a  n  n n 
gamble f b n   use notation ha     a  hb     b  

transform condition  sp   using equivalence condition       one hand 
     
r    n deg mnnb  f    
letting
n
f ib n da
mnna  f ib n   ha irb a  mnnb  f    ha
n
n
r
n
ba 
f ib n da
c
mna  f ib n   ha ba 
ib a  mnb  f    ha  

second equivalences follow proposition     hand  recalling
b     rb      
  rb   
proposition    
 
n
f db
mnnb  f   hb
n
n
b bb rb   
f db
c
mnb  f   hb  

tells us equivalences condition  sp   rewritten as 
irb a  mnnb  f    ha mnnb  f   hb
r
n
n
ba 
ib a  mnb  f    ha bb rb   
mnb  f   hb  

proof complete recall discussion section     appendix b
varying n n f l b n    let p    mnnb  f     comnnb  hynb  f    range
polynomials b r   n deg mnnb  f    range elements n   
  let
     
range count vectors na  
varying n n
proof theorem     let  ease notation    inf ii   coherent using
equation       consider category sets b b a  p v  b  
na     r n    then  using specificity  
irb a  p ba   a   i i irb a  p ba   a 
 i i pbb rb     b  pbb rb     b  
concludes proof 
e   proofs results section  
proof proposition     sufficiency  fix category set a  gamble g a  count
vector na      condition  ri      g a      g  f    idd yields condition  ri   
necessity  fix category sets onto map   d 
gamble f d  count vector na      observe  f   a    f  d 
r f  d 



rf   r  
mx  
mx
xa    f   x  r

zd   f  z  r xa    x  z



 

zd   f  z  r

  

r   z   rf  r    r  

fide cooman  de bock    diniz

rf   rf r   infer invoking condition  ri   twice that 
 
 
f da
c id f   a  d f
  a  crf   
 
idf  d  df   d  crf  r     f dd
cr    

concluding proof 
proof theorem     arguments proof rely heavily following expression
lower probability function 
 
 
 
 n  k    sup r   i a  d a b 
c k  n k 
 
 
  sup r   ak bnk  a     a  b  
    
related expressions equivalent representation insensitivity
bernstein coherence  b    expressions follow equations            bernstein
coherence  b   representation insensitivity form  ri   
l   immediate bernstein coherence fact  n  k  lower probability 
use equation       b  b  
l   fix non negative integers n  k   k     n  consider real
   n  k     n      follows applying equation      condition  ri  
xk y  znk   x     x  y  z   xk y  znk   y     x  y  z    whence 
bernstein coherence  b    xk y  znk    x              x  y  z    applying
equation      condition  ri   tells us uk   znk   u          u  z   
whence    n  k      
l   l  l  immediate consequences l  l  
l   consider category set     a  b  count vector    k
mb    n k  define gamble g g a      n      k      g b      n      k  
g a  g b  l   therefore coherence  p  p   predictive lower
prevision p  a     tells us p  a  g     g b     g a  g b  p  a   a       n      k   
 n  k   n      k       n      k    see equation        clearly suffices prove
p  a  g    n  k    p  a   a     consider   p  a  g    follows using
equation      that 
ak bnk  g a a   g b b    a  
    
also       ak   bnk  a g a       a  ak bn  k  a g b       a  
therefore  coherence  b    recalling   b     
 a    ak   bnk  a g a        ak bn  k  a g b     
  ak bnk  a g a a g b b          
combining statements           using coherence  b    leads ak bnk  a    
 a   whence  n  k    completes proof 
l   use l  l  find  n  k   n      k       n      k      use l  
l   sn   follows l   need prove sn   sn   equivalently 
 n      n              n       indeed 
 n      n            n      n          n         
  

ficoherent predictive inference exchangeability

 n            n       n          n         
   n            n     n         
first inequality follows l  k      second l  l  
l   inequalities hold trivially n      due l   consider n n 
category sets     x  y  b     x    x            xn   y   let              
since            see x  x    a   equivalently  x  x         a  
since x        representation insensitivity  use equation      condition  ri   
tells us xk  xk   
      xk   y    specificity  use theorem     allows us
infer   nk   xk
  xk     
n    b   k             n  
n
infer coherence  b     k   xk    k   xk      ny    b   apply
representation insensitivity get xn  x      ny    a   since     x  
n
equivalent xn  x      n  n   a   shows  n  n    n
  using
equation       rest proof immediate 
e   proofs results section  
proof theorem     v coherent obvious  category set f 
v  a    v    a  bernstein coherent set polynomials  
prove representation insensitivity  use theorem    consider category sets
onto map   d  p v  d  na     
indeed
 p r  ba  v    a  p r v    a  p v    d  pbd r    v    d  
first last equivalences follow proposition     second one
lemma    k   a 
e   proofs results section   
proof theorem     v coherent obvious  category set f 
v  a    v     a  obviously convex cone includes v    a   proposition    
contain zero polynomial  v     a  therefore bernstein coherent set polynomials
 
prove representation insensitivity  use theorem    consider category sets
onto map   d  p v  d  na     
indeed
 p r  ba  v     a    int a   p r    ba        
  int a   p r        
  int d   p      
  int d   p  bd r           pbd r    v     d  
second fourth equivalences follow bernstein positivity bernstein
basis polynomials proposition     third one lemma    k   a 
  

fide cooman  de bock    diniz

prove specificity  use theorem     consider category sets b
b a  p v  b   na     r n    indeed 
irb a  p ba  v     a    int a   irb a  p  ba        
  int a   irb a  p      
  int b   p      
  int b   p  bb rb           pbb rb    v     b  
second fourth equivalences follow bernstein positivity bernstein
basis polynomials proposition     third one lemma    k   a 
e   proofs results section   
below  use convenient device identifying  proper subset b a  element
b unique corresponding element   ia    whose components outside
b zero 
 x b x   x  x   b x     
observe that  using convention  identify int a     subset  
characterise follows 
  int a      x a  x     mx      
proof proposition     clearly suffices prove v    a  hsc a  
  hsc a  
first statement easy prove asc a trivially includes non constant
bernstein basis polynomials  proposition     since v    a  consists finite  strictly positive
linear combinations non constant bernstein basis polynomials  immediately
v    a  hsc a  
prove second statement  suppose ex absurdo   hsc a   implies
  
finitely many nk      count vectors k nank pk v 
 a 
k 

    k pk ba k   always possible find  at least  one count vector    say 
a k     a     k  words  either a k     a    
a k     a          consider int a        a k     a         
  
ba k         a k     a      ba k         moreover  since pk v 
 a  
k 

pk         hence     k pk   ba k         contradiction 
lemma     consider na     p hsc a      n  nk n 

  
  nk      k nank pk v  
 a  p    k   pk ba k  
k 

sa   p     k   a    k   k k                
therefore
min sa   p    min  a    k     k                  
proof lemma     second statement trivial  given first  restrict
attention proving first statement 
assume first a    r   k r                 clearly k     
since   nr      may assume without loss generality a    r   minimal
  

ficoherent predictive inference exchangeability

element set  a    k     k                  consider int a  r      whence
k   k                a    k     a    r  and
  
clearly least one kwe see pk        since pk v  
 a  
k 
ba k         whence  pk ba k          k must a    k    
a    r        therefore  pk ba k         since ba k         guarantees

p      k    pk ba k          whence indeed k sa   p   since already know
k   a   a    r   k k     
assume  conversely  k sa   p   implies    k a   k 
k p         observe a    k     a  a k   
assume ex absurdo a    k     k therefore a k     k k                
fix k                 x a 
  k  therefore x     
k   x
whence ba k         shows p      k    pk ba k          contradiction 
lemma     consider na      p v  a  n n n deg p  
nan  
bnp          k min sa   p  k   a   a   
proof lemma     fix nan   prove contraposition  suppose
k min sa   p   k   a     a   therefore k   a       since
a        a   a    hence  a     
  sa   p   since moreover    a     
a   a       infer equation      p b      let  ease
notation  b    a       rewrite  see lemma     
    p b  


n
na

bnp   ba   b  


n
nb

bnp   ba   b  



bnp   bb   

n
nb

due uniqueness bernstein expansion  possible bnp       
n
n
na   
  concludes proof since  clearly  na   
 

proof proposition     first  assume p hsc a    implying p    k   pk ba k
  
  n  nk n    nk      k nank pk v  
 a   already
k 
follows lemma    p  
    min sa   p    min  a    k     k                 
consider k min  a    k     k                 int k   
k  either a    k     k a    k     k      a    k     kwhich
happens least one k  due choice kthen pk        ba k        
a    k     k      since a   k  a k     k  
    implying ba k        
hence  p        since holds int k    find p k v     k  
assume  conversely  p v  a     
p k v     k 
k n min sa   p  
n
fix n n n deg p   p   n n bp   ba    bp   ba   

 
 
   nan   bnp           since p       infer equation      min sa   p    
 observe sa   p    know lemma      least
one k min sa   p  k   a   a    let us pick k  call
k   let  k min sa   p   mk        k   k   found
way divide disjoint subsets mk   one every k min sa   p 
  

fide cooman  de bock    diniz


may empty  k   a   a   mk     kmin sa   p  mk


therefore p   kmin sa   p  mk bnp   ba   
fix k min sa   p   construct count vector k letting  mk  x     
x k   a    mk  x      otherwise  notice k nank   nk number
elements  k   a    set k   a    therefore nk n  consider mk  
since  mk  x     implies x a   therefore x    see  
ba         



xx     

xa  



xx  mk  x

xa  



x mk  x

xa  

   k   ba k   ba k    

n
         hence  rewrite
 k          

 
k
k
mk bp   ba 

   mk  k   bnp   ba k   way  find p  

pk ba k   pk
kmin sa   p  ba k pk  
hence  fix k min sa   p       left prove   nk    
  
pk v  
 a   assume first  ex absurdo    nk      particular
k 
  
k     contradicts k sa   p   remains prove pk v  
 a  
k 
consider int a  k      derive k min sa   p  sa   p 
a   k  since a k     k  a    implies a    k     a  a k    
a    k   a      k  therefore int k    k   min sa   p     k  
k    k  
  therefore ba k           hence  p     ba k   pk     know
p       p k v     k  ba k        a k     k   a   k 
conclude indeed pk        
lemma     na     p v  a  
sa   p    sa    pba    therefore min sa   p    min sa    pba    
proof lemma     first  assume k sa   p      k a  a   k
p k       last inequality continuity polynomials  infer
int k   p         since a   k  find p  ba         
therefore  pba    k      
assume  conversely  k sa    pba      
  k  pba    k      
last inequality implies k  pba           therefore
ba          p         ba           derive a   k
p         derive p k      
proof proposition     way hsc a hsc a  constructed  see defining
expressions             clearly suffices prove hsc a c hsc a    consider
therefore p v  a  pba  hsc a   proposition     implies
pba        pba    k v     k  k min sa    pba     set
prove p hsc a    applying proposition    again  since  clearly  p      
see suffices show p k v     k  k min sa   p   consider
k min sa   p   then  lemma     k min sa    pba     already argued
 pba    k v     k   hence indeed p k v     k  
  

ficoherent predictive inference exchangeability


proof equation       combining equations            see that 
na     
 
   f l a    sa  f   hsc a 
dsc a
c
    
  
also  f l a   
  k a 
sa  f       f      sa  f   k v     k  f  k     sa  f   k     f  k          
     f l a  
start case
min sa    sa  f        x    x f  x         
 
statement       hence  proposition    equations            dsc a
 
l    a  
na   f l a  
next  consider

 

 a   
f  a  
   
 
min sa 
 sa  f     
 x    x   a  
f  x        f  a  
 a  
  

    

equation       recall proposition    equations          
 

consider two cases  f  a  
     f  a  
     f  a  
      f dsc a c
 if f       which redundant 
f  a  
    or  equivalently  since f  a  
      
 
 

f h l a    h a  
    l    a   f  a  
     f dsc a c
or  equivalently  since f  a  
f      f  x     
x   a  
     
f h l a    h a  
    l    a  
proof equation       start first part equation       due equation     
proposition     suffices prove that  p v  a   minxa p x       p
hsc a   minxa p x       p
  hsc a    

first  assume minxa p x        p y       
hence  since p  y    p y        find  y  min sa    p  therefore
p
  hsc a     proposition    
next  assume minxa p x        p  x    p x       x a  implying
min sa    p      x    x a  therefore also  since p       p hsc a    
proposition    
turn second part equation       due equation      proposition    
na p v  a   mina  
suffices prove that 
p       p

hsc a 
p       p
  hsc a 
mina  
 

first  assume mina  
p  
 
  

int a  
 

  


p        implying p a  
     p a  

  v  a    
hence  find a  


min sa 
  hsc a 
 p  therefore p
  proposition    

next  assume mina  
p  
 
  

p a  
 
    p a  
v     a    



therefore also  since p       p hsc a 
hence  find min sa 
 p     a   
 
proposition    
  

fide cooman  de bock    diniz

proof equation       first part equation      trivial consequence equa na f l a   then  combining
tion       second part  consider
equations           


  min
f  x x   min f  x  
p  sc a  f   
f  x x   min
a  


xa

a  



xa  


xa  

lemma     consider category sets onto map   d 
p v  d   
  k a   p r   k      p  k       
proof lemma     first  assume p  k         k 
p         choose k r        then  clearly   p r      
p r       p        therefore  p r   k      
assume  conversely   pr   k       k  pr          
let    r      k  p     p r        p r           hence 
p  k       
lemma     consider category sets onto map   d 
p v  d   na     
 
 
sa   p r     k   a   k  k  sd r     p   
therefore
 sa   p r      sd r     p   min sa   p r      min sd r     p  
proof lemma     start proving first statement  first  assume k sa   p
r    implying  
  k a  a   k  p r   k           k  d 
d r        a     k  and  lemma     p  k        hence   k  sd r     p  
conversely  assume k a  a   k  k  sd r     p    
   k  
implies  
  k  p  k        which  lemma     implies  p r   k      
hence  k sa   p r   
first statement implies  sa   p r    sd r     p  therefore  order
prove second statement  suffices show sd r     p   sa   p r    or 
equivalently  every l sd r     p   k sa   p r  
 k    l  choose l sd r     p  let k     x    x  l       l  
 k    l onto  since  a      d r     l  follows a   k 
hence  first statement  k sa   p r   
prove third statement  first assume k min sa   p r    implying
k sa   p r   that  k   sa   p r    k     k  second statement 
 k  sd r     p   prove  k  min sd r     p   assume ex absurdo
l sd r     p  l  k   let k       x k    x  l    k    l  
k   k  k       l  therefore  lemma      p r   k        
k      p l  
     since l sd r     p   see  a      d r     l
therefore a      l   since k sa   p r    know a   k 
therefore a   k    l    k     tells us k   sa   p r    contradiction 
assume  conversely  l min sd r     p   implying l sd r     p   then 
  

ficoherent predictive inference exchangeability

second statement  k   sa   p r    k       l  hence 
k min sa   p r   k k   therefore  k   k       l  since
l min sd r     p  since  due second statement   k  sd r     p  
 k    l therefore  k    l 
lemma     let  
  k let p polynomial   n deg p  
bnp    bnp  nkn  
k

proof lemma     follows

p    
bnp   ba    
n
na

k  
p k     


n
na

 





bnp   ba   ia      

bnp   ba   ia    

n   a  k
na

bnp  nkn   bk     

n
nk

completes proof 
lemma     consider category sets onto map   d 
p v  d   
  k a  then 
 i   p r   k v    k  p  k  v     k   
 ii   p r   k v     k  p  k  v      k   
proof lemma     first statement follows fact that  n deg p  
bn pr   

k

n
    bn pr    nkn      bnp r   nkn     bnp  n k 
    bnp 

    
 k 

first last equivalence due lemma     second equivalence follows
n    nn
proposition     third equivalence holds r  nk
 k   
turn second statement  prove following statements
equivalent 
 a    int k   p r         
 b    int  k    p       
first assume  a  holds  consider int  k     prove p       
 
construct k follows 
consider z  k   x   z   k  choose
x     way xk    x  z x   z   way  found k
satisfying r        moreover x     x k  whence int k   
infer  a  indeed p     p r         
assume  conversely   b  holds  consider int k    then  z d 
r   z     z  k  r   z     otherwise  means r    int  k   
infer  b  indeed p r         
  

fide cooman  de bock    diniz

proposition     sc representation insensitive 
proof proposition     use characterisation representation insensitivity theorem    consider category sets onto map   d 
p v  d  na      then  proposition     need prove
p r hsc a  p hsc d r     
first  assume p hsc d r      which  proposition     implies p     
p l v     l  l min sd r     p   applying lemma    k   a  infer
p  
    p r       consider k min sa   p r    then  lemma    
 k  min sd r     p   implying that  due assumption  p  k  v      k    since
k      apply lemma    find  p r   k v     k   hence  proposition    
p r hsc a   
assume  conversely  pr hsc a    which  proposition     implies pr     
 p r   k v     k  k min sa   p r    applying lemma    
k   a  infer p r      p       now  consider l min sd r     p  
lemma     k min sa   p r    k    l  since k  
  and 
assumption   p r   k v     k   infer lemma    p l v     l   hence 
proposition     p hsc d r     
lemma     consider category sets b b a  p v  b  
k k b    r n    irb a  p  k      p kb      
proof lemma     may assume without loss generality r   deg p      
proof trivial otherwise 
first  assume p kb  
     means kb
p            ia    k   infer proposition   irb a  p     p       
therefore irb a  p  k      
assume  conversely  irb a  p  k       means  due continuity polynomials  int k   irb a  p         infer k b   
 
b      proposition    guarantees p   
b         since  b kb   find
p kb      
lemma     consider category sets b b a  p v  b 
r n  r   deg p       na     
 
 
sa   irb a  p     k   a   k k b sb rb     p   
therefore
 
 
sb rb     p    k b   k sa   irb a  p  

 
 
min sb rb     p    k b   k min sa   irb a  p    
proof lemma     begin first statement  first  assume k sa   irb a  p  
therefore    k a  a   k irb a  p  k  
     k implies
kb b  a   k implies b rb       a  b kb  moreover  irb a  p  k  
   
together proposition    r   deg p      implies k b      turn 
lemma     implies p kb       hence  k b sb rb     p   conversely  assume
  

ficoherent predictive inference exchangeability

k a  a   k k b sb rb     p   k b      implying k     
p kb       which  lemma     implies irb a  p  k       hence  k sa   irb a  p   
order prove second statement  clearly suffices show sb rb     p 
 k b   k sa   irb a  p     since converse inclusion follows directly first
statement  consider l sb rb     p  let k    l a    k a  a   k
k b   l  a   b    l b rb       l  hence  first statement  indeed
k sa   irb a  p   
prove third statement  first assume k min sa   irb a  p    implying
particular k sa   irb a  p    then  second statement  k b sb rb     p  
prove k b min sb rb     p   consider l sb rb     p  l k b 
let k      l a    then  argument identical one used proof second
statement  k   b   l k   sa   irb a  p    however  since k   b   l k b
k     b   a     b k   b  find k      k   b   k     b   k b   k   b    k 
therefore k     k  assumption  hence indeed l   k   b   k b  assume 
conversely  l min sb rb     p   implying l sb rb     p   then  second
statement  k   sa   irb a  p   k   b   l 
k min sa   irb a  p   k k   therefore k b k   b   l  since
l min sb rb     p  and  second statement  k b sb rb     p  
k b   l 
lemma     consider category sets b b a  p v  b   k
k b    r n    irb a  p  k v     k  p kb v     k b  
proof lemma     may assume without loss generality r   deg p      
proof trivial otherwise  using proposition     considering that  since k b  
    b    
int k    suffices prove following statements equivalent 
 a    int k   p   
b       
 b    int kb   p       
first assume  a  holds  consider int kb    prove p       
construct
k follows  x k   b  choose x     way

   xk b x      always possible  x k b  let x       x     
follows construction b            
b   int k   
infer  a  indeed p     p   
 
 
  
b
assume  conversely   b  holds  consider int k    b    
 
k b  
    therefore  z b     
b  z     z k b  hence  b int kb   
 
infer  b  p  b       
proposition     sc specific 
proof proposition     use characterisation specificity theorem     consider
category sets b b a  p v  b   na      r n   
then  proposition     need prove irb a  p  hsc a  p hsc b rb     
first  assume p hsc b rb      which  proposition     implies p     
p l v     l  l min sb rb     p   applying lemma    k   a  infer
p      irb a  p        consider k min sa   irb a  p    lemma    
  

fide cooman  de bock    diniz

k b min sb rb     p   implying that  due assumption  p kb v     k b  
since k b       apply lemma    find irb a  p  k v     k   hence 
proposition     irb a  p  hsc a   
assume  conversely  irb a  p  hsc a    which  proposition     implies
r
ib a  p       irb a  p  k v     k  k min sa   irb a  p    lemma   
k   a  irb a  p        infer p       consider l min sb rb     p  
then  lemma     k min sa   irb a  p   kb   l  since therefore
k b      since  assumption  irb a  p  k v     k   infer lemma   
p l v     l   hence  proposition     p hsc b rb     
proof theorem     immediate consequence propositions     coherence     
 representation insensitivity      specificity  
e   proofs results section   
na     p v  a  
proof equation       consider


ba  p hidm a
p hidm a
c
  sa   dia  ba  p      

       
  sa   dia  ba     dia  p 
        
  sa   dia  p 
third equivalence follows updating property dirichlet expectation
 proposition     
na      then  combining equations     
proof equation       consider
     n     
 
 

mx   x
s  
  f l a      sa  
didm a
c
f  x 
    
 
xa

consider f l a   sa  

xa

f  x 



mx   x
x
 
  
f  x  mx   x      
 
f  x 
f  x mx  
 


xa

xa

combining equations above  letting c     s
find that 

xa



xa f  x mx

s  
 s      s    int a   
f didm a
c

ease notation 

s 
f  x tx   c 


    

xa

f c  f  y    c therefore  statement      
s  
 choose s  ty close enough    respectively   f   c  due
f
  didm a
c
s  
finally  let us
definition c  f   c      hence  statement       f
  didm a
c 
see happens
f   c  clearly c    consider s     
s  int a   
 
 
since f   c  xa f  x tx   c therefore also  since c    ss xa f  x tx   ss c c 
s  
statement      
hence f didm a
c
  

ficoherent predictive inference exchangeability

na     f l a   combining
proof equation       consider
equations           

mx   x
mx   s  tx
  inf
inf
f  x 

  s     s  int a  
  s 
xa
xa
 
 


 
s 
  inf
f  x mx  
inf
f  x tx
  s  int a  
s     s    s 
xa
xa
 
 

 
s 
  inf
f  x mx  
min f
  s 
s     s    s 
xa


 
f  x mx  
min f 
 
 
 

  inf
p s  
idm a  f   



f  x 

xa

last equality follows min f

mx
xa f  x   



property convex combinations 

proof theorem     coherence  fix category set a  must prove

hidm a
satisfies requirements b b  bernstein coherence  trivial

definition hidm a
  linearity dirichlet expectation operator  fact
dirichlet expectation bernstein basis polynomial positive 
next  turn representation insensitivity  use characterisation theorem   
consider category sets onto map   d  p v  d 
na      then  using pooling property  proposition     dirichlet
expectation equation       find indeed 

 p r  ba  hidm a
  sa   dia  p r          

  sa    p r           

  sd    p r            pbd r    hidm d
 

third equivalence follows equality sd   r  sa   
finally  turn specificity  use characterisation theorem     consider
category sets b b a  p v  b   na    
r n    then  using restriction property  proposition     dirichlet expectation
equation       find indeed 

irb a  p ba  hidm a
  sa   dia  irb a  p          

  sa   dib  p rb           

  sb   dib  p rb            pbb rb    hidm b
 

third equivalence follows sb   rb  sa   
e   proofs results section   

lemma     p    p  hsi a
  sa    p    p      sa    p    sa    p    

  

fide cooman  de bock    diniz

proof lemma     first  consider k sa    p    p     meaning    k
 p    p    k       assume  ex absurdo  k
  sa    p    k
  sa    p     p   k    
p   k     therefore  p    p    k      contradiction  hence indeed
k sa    p    sa    p    
next  consider k sa    p    sa    p     implying  
  k a 
least one k   min sa    p    sa    p     k   k  assume without
loss generality k   sa    p     since k   min sa    p    sa    p     
l   k   l sa    p    sa    p     therefore k   min sa    p     already tells us

 
p   k   hidm k
    two possibilities  first one k sa    p    

then  much way above  find p   k   hidm k     hence 


due bernstein coherence  b   hidm k
     p    p         p        p      hidm k    
k
k
k
 
 
second possibility k
  sa    p     p   k       since k      find 

too   p    p    k     p   k     p   k     p   k   hidm k
    cases  therefore 


 p    p    k   hidm k     bernstein coherence  b   hidm k
  allows us conclude
     since k   k  find  p    p    k      therefore
 p    p    k    
k sa    p    p    


proof proposition     since  
  hsi a
  left prove v    a  hsi a
that 



    p  p    p  hsi a   p hsi a p    p  hsi a  

first  consider     p hsi a
  then  clearly  sa    p    sa    p  therefore
min sa    p    min sa    p   k min sa    p   k min sa    p  


which  since p hsi a
  implies p k hidm k
therefore  due bernstein


coherence hidm k    p  k    p k   hidm k
  furthermore  since p     

p       therefore p hsi a  

next  consider p    p  hsi a
  p       p        implying sa    p      
sa    p         therefore sa    p    sa    p         applying lemma     find
sa    p    p         k    k a   p    p    k  
   
therefore p    p        k   min sa    p    p     equivalently  due lemma    
k   min sa    p    sa    p      then  applying reasoning second part


proof lemma     find  p    p    k   hidm k
    hence  p    p  hsi a  

since already shown hsi a closed taking positive linear combinations 
since v    a  consists positive linear combinations bernstein basis polynomials 

need show hsi a
contains bernstein basis polynomials order prove
 

v  a  hsi a   consider na      then  k    k a 
ba   k   bk rk    a   k  ba   k     otherwise  implies

sa    ba         
  k   a   k  that  due bernstein coherence hidm k
 


ba   k   bk rk    hidm k k sa    ba     hence  ba   k hidm k

k min sa    ba     since ba        find indeed ba  hsi a
 


proof proposition     first prove hsi a
c hsi a 
  consider p v  a 


pba  hsi a   meaning pba        pba    k hidm k


k min sa    pba     set prove p hsi a    since  clearly  p       suffices

show p k hidm k
crk    k min sa   p   consider k min sa   p  
implying a   k therefore k rk       a    infer

lemma    k min sa    pba     tells us  pba    k hidm k
  since

 pba    k   p k ba   k   p k bk rk      find p k hidm k crk    

  

ficoherent predictive inference exchangeability




next  prove hsi a 
hsi a
c  consider p hsi a 
  meaning

p      p k hidm k crk    k min sa   p   set prove


pba  hsi a
or  equivalently  pba   

     pba    k hidm k
k min sa    pba     since p       continuity polynomials guarantees
int a   p        therefore  pba            know already
pba        consider k min sa    pba     then  lemma     k min sa   p  


implying a   k p k hidm k
crk    therefore p k bk rk    hidm k
 

since moreover p k bk rk       pba    k   find indeed  pba    k hidm k  

proof equation       due equation       suffices prove that  p v  a  


minxa p x       p hsi a
minxa p x       p
  hsi a
 

first  assume minxa p x        p y       
hence  since p  y    p y        find  y  min sa    p  therefore also  due


bernstein coherence hidm  y 
 see theorem      p  y 
  hidm  y 
 

infer p
  hsi a  
next  assume minxa p x        p  x    p x       x a  implying

min sa    p      x    x a  that  x a  p  x  hidm  x 
 


bernstein coherence hidm  x    hence  since p       find p hsi a
 
proof equations            equation      follows directly equation      
prove equation       due equation      proposition     suffices prove that 
na p v  a  



    p hsi a 
  p
c p   
  hsi a 
c p   
 



where  ease notation  let
  
c p   

inf

sa  


    
dia  
 ra  
 p a  
  


     implying dia  
       
first  assume c p   
 ra  
 p a  
  


a  
     and  equation       p a  

 
therefore p a  





hidm a  
 p  therefore
    hence  find a   min sa 
cra  

p
  hsi a 
 


     implying p a  
next  assume c p   
     and  equation      



therefore
p a  

h
cr
 
  
hence 

find

min

 p     a   
a 

a  

idm a  


p hsi a 
 
na  
proof equation       combining equations            see that 
 
 
s  

  f l a    sa  f   hsi a 
dsi a
c
    
 

consider f l a  distinguish two cases  f  a  
     f  a  
    
f  a  
      and therefore f       
s  

sa  f   a  
f dsi a
c
hidm a 
  
cra  
 


sa  
 f  a  
  hidm a  
  
cra  

  

fide cooman  de bock    diniz

s  
f  a  
didm a  
  
cra  

 
 
f  a  
 

f
 x 


f
 

f  x mx f     
x


 a  



xa  


xa  

first equivalence due statement      equations                 
second equivalence follows definition sa sa  
third one due
equations            fourth equivalence consequence equation     
final equivalence holds f     redundant  given f  a  
     
f  a  
      again  using statement      equations                 
s  
f      x   a   

f dsi a
c

f  x      sa  f   a   x 
hidm a 
cra   x 
   


  x 


since f  a  
cra   x 
   bernstein coherent  theorem     
    hidm a   x 


latter statement equivalent f  x       hence  find that 
s  
f       x   a   f

f dsi a
c
 x   

f   
f  a  
 

 
f  x mx f     


xa  

second third equivalences consequences f  a  
    
lemma     consider category sets onto map   d 
p v  d   na         k a   k 


 p r   k hidm k
crk    p  k  hidm  k 
cr k   r     
proof lemma     let    k      k       k p    p  k   
onto map   p v  d   p r   p  k  r k    p r   k  

since a   k  identify element    rk    nk
therefore
result follows representation insensitivity idmm inference system
hyperparameter s  r       r k  rk       r k   r     





p r hidm a
c p hidm d cr     

proposition     ssi representation insensitive 
proof proposition     use characterisation representation insensitivity theorem    consider category sets onto map   d 
p v  d  na      then  proposition     need prove


p r hsi a 
p hsi d r
 
  


first  assume p hsi d r      meaning p      p l hidm l
crl  r    
l min sd r     p   applying lemma    k   a  infer p     
p r       consider k min sa   p r       k a   k  then 
lemma      k  min sd r     p   implying that  due assumption  p  k 
  

ficoherent predictive inference exchangeability



hidm  k 
cr k   r      applying lemma     find  p r   k hidm k
crk    

hence  p r hsi a   

assume  conversely  p r hsi a 
  meaning p r       p r   k

hidm k crk    k min sa   p r    applying lemma    k   a  infer
p r      p       consider l min sd r     p   lemma    
k min sa   p r    k    l  since    k a  a   k

and  assumption   p r   k hidm k
crk     infer lemma   


p l hidm l crl  r      hence  p hsi d r     

lemma     consider category sets b b a  p v  b  
na      r n  k k b    a   k 


irb a  p  k hidm k
crk    p kb hidm kb
crkb    
proof lemma     let    k  b    k b  p    p kb r   deg p  deg p     r 
b   p v  b    r r    r   deg p     r   deg p  


bdeg p  r
  ba ia    k  
bdeg p  r
  ba ia    k
irb a  p  k  
p
p
deg p  r

deg p  r

nb

 



nb
b  k


bdeg p  r
  bk ik      irb  a  p   
p 
kb

deg p  r

nkb

third equality follows unicity bernstein expansion polynomial 
since a   k  identify element    rk    nk     therefore
result follows specificity idmm inference system hyperparameter s 
rb       rkb    







irb  a  p   hidm a
c p hidm b crb     

proposition     ssi specific 
proof proposition     use characterisation specificity theorem     consider
category sets b b a  p v  b   na    


r n    then  proposition     need prove irb a  p  hsi a 
p hsi b r
 
b   
clear propositions       assume without loss generality
r   deg p      


first  assume p hsi b r
  implying p  
    p l hidm l
crbl   
b   
l min sb rb     p   applying lemma    k   a  infer p     
irb a  p        consider k min sa   irb a  p    infer lemma    k

crkb    
b min sb rb     p   implying that  due assumption  p kb hidm kb
r

since k b      a   k  ib a  p  k hidm k crk    lemma     hence 

irb a  p  hsi a 
 

assume  conversely  irb a  p  hsi a 
  implies irb a  p      
r

ib a  p  k hidm k crk    k min sa   irb a  p    applying lemma   
k   a  infer irb a  p       p       consider l min sb rb     p  
lemma     k min sa   irb a  p   k b   l  since k b      
  

fide cooman  de bock    diniz


a   k and  assumption  irb a  p  k hidm k
crk     infer lemma   


p kb hidm kb crkb     words  p l hidm l
crbl     hence 

p hsi b rb     

proof theorem     immediate consequence propositions     coherence     
 representation insensitivity      specificity  
e   proofs results section   
proof theorem     begin coherence  consider category set a 

prove hh a bernstein coherent  b   recall  
  hidm a
    
 

therefore  
  hh a   similarly  b   recall v  a  hidm a     
 
therefore v  a  hh a   b   consider n n k r   pk hh a

k            
n       pk hidm a
k             n  
n


n therefore k   k pk hidm a   bernstein coherence  theorem      hence indeed
k   k pk hh a  
next  turn representation insensitivity  use characterisation theorem   
consider category sets onto map   d  p v  d 
na      find indeed 

 p r  ba  hh a  s r     p r  ba  hidm a

 s r    pbd r    hidm d
pbd r    hh d  

second equivalence follows representation insensitivity idmm
inference systems  theorem     
finally  turn specificity  use characterisation theorem     consider
category sets b b a  p v  b   na     r n   
find indeed 

irb a  p ba  hh a  s r    irb a  p ba  hidm a

 s r    pbb rb    hidm b
pbb rb    hh b  

second equivalence follows specificity idmm inference systems  theorem     
na     p v  a  
proof equation      

pba 
p hh a c
hh a  s r    pba 
hidm a


 s r    p hidm a
c 

combined equation       yields desired result 
na     p v  a  
proof equation      
  sup   r   p hh a c 

h h a  p  
 
 


  sup sup r   p hidm a
c
sr  

  

ficoherent predictive inference exchangeability

      lim
inf dia  p 

  sup

    
inf dia  p 

s   sa

sr  

second equality due equation       third one due equation      
proof equation       consider p v  a  apply equation      
h h a  p    lim

inf dia  p     lim

s   sa

inf dia  p s   

inf

s   int a   s     s 

    

fix n max deg p      int a    using equation       find
nan  
 

 

 

dia  ba   s    

s   n 

 
   
n    mx  
n
 
 m  
 s tx  
   n 
 s  tx   x  
 



xa
xa  

x a   
 mx  

 s  tx  

   s  tx   s  tx             s  tx   mx      s  tx  mx         o s    

similarly 
 
s   n 

 

s   n

 
     o s     
   

hence  find
 
 

dia  ba   s    

xa   tx  mx

   

 

 n    

s  a          o s     

consider two cases   a         a         since n    cases
exhaustive    a         dia  ba   s      o s      a        or  equivalently 
x   nx   dia  ba nx  s      tx      o s      combine
equation       find
dia  p s     



bnp    dia  ba   s     

n
na



bnp  nx  tx   o s    

xa

furthermore  due equation      
bnp  nx    



bnp   ba   x     p x   x a 

n
na

hence  conclude
dia  p s     



p x  tx   o s    

xa

which  combined equation       leads desired result 
  

fide cooman  de bock    diniz

na p v  a  use equation      
proof equation       consider
  lim
h h a  p  

  lim sup dia  p 
         
    h h a  p  
inf dia  p 

s   sa

s  



bernstein coherent  theorem      follows h h a    
coherent
since hh a c
super additive  conjugate upper
lower prevision  implies h h a    
sub additive  hence  suffices prove equalities equation     
prevision h h a    
bernstein basis polynomial p   ba    na      sa
gather equation      appendix b that 
   
n
     
 mx   x   nx    
dia  ba   
 n 
 ma    
xa
 

observe that 
x 
 mx   x   nx      mx   x   mx   x             mx   x   nx      m n
     o x    
x

similarly  since     
 
 ma    

 n 

 

 

 n 



     o a   

therefore 
   
 nx  

n
xa mx
     
dia  ba   
  
 
o 
  
     o x    

 n 


xa



which  using equation       leads to   
   
 nx  
n
xa mx
  h h a  ba    
 

h h a  ba    
  dia  ba     
 n 




e    proofs results section   
proof theorem     already argued smallest inference
system   shall denote lower probability function   first  assume n   
denote  n  k      n  k       n  k   follows assumptions
 n  k       n  k    k n   

    

first going prove induction implies
 n  k 

k
 n  n    k n 
n

    see footnote    

  

     

ficoherent predictive inference exchangeability

observe inequality holds trivially k      theorem    l    assume
inequality holds k                    n     must show holds
k          assume  ex absurdo  not  therefore
 n          

   
 
 n  n   n        n  n  
n
n

     

second inequality follows induction hypothesis 
 n  n     n          

n 


 n  m   n            n      n    

m    

 

   
n  
 n  n   
 n  n     n  n  
n
n

first inequality follows equation       second first
second inequalities equation        contradiction  completes proof
induction       
infer        theorem    l  assumption     
 n  k 

k n
k
 
  k n 
nn s
n s

     

observe inequality holds trivially n         get predictive
lower prevision p  a  h   gamble h a 

 h x  min h p  a  i x    
p  a  h     min h   p  a  h min h   min h  
xa

  min h  



 h x  min h  n  mx  

xa

min h  


xa

 h x  min h 

mx
  p s  
idm a  h   
n s

first equality first inequality follow coherence  p   p  p  
p  a      second equality representation insensitivity  equation       
second inequality equation        converse inequality  observe idmm
inference system sidm coherent  representation insensitive  specific theorem    
clearly concave surprise  satisfies assumption       therefore dominates smallest
inference system 

references
augustin  t   coolen  f  p  a   de cooman  g     troffaes  m  c  m   eds           
introduction imprecise probabilities  john wiley   sons 
bernard  j  m          bayesian analysis tree structured categorized data  revue internationale de systmique           
bernard  j  m          introduction imprecise dirichlet model multinomial
data  international journal approximate reasoning             
  

fide cooman  de bock    diniz

bernard  j  m          personal conversation  
boole  g         reprinted        laws thought  dover publications  new york 
boole  g         reprint work originally published watts   co   london        
studies logic probability  dover publications  mineola  ny 
carnap  r          continuum inductive methods  university chicago press 
cifarelli  d  m     regazzini  e          de finettis contributions probability statistics 
statistical science             
couso  i     moral  s          sets desirable gambles  conditioning  representation 
precise probabilities  international journal approximate reasoning              
     
cozman  f  g          independence full conditional probabilities  structure  factorization  non uniqueness  bayesian networks  international journal approximate
reasoning                   
de cooman  g     miranda  e          symmetry models versus models symmetry 
harper  w  l     wheeler  g  r   eds    probability inference  essays honor
henry e  kyburg  jr   pp         kings college publications 
de cooman  g     miranda  e       a   f  riesz representation theorem finite
additivity  dubois  d   lubiano  m  a   prade  h   gil  m  a   grzegorzewski 
p     hryniewicz  o   eds    soft methods handling variability imprecision
 proceedings smps        pp          springer 
de cooman  g     miranda  e       b   weak strong laws large numbers coherent
lower previsions  journal statistical planning inference                    
de cooman  g     miranda  e          irrelevant independent natural extension
sets desirable gambles   journal artificial intelligence research             
de cooman  g   miranda  e     quaeghebeur  e       a   representation insensitivity
immediate prediction exchangeability  international journal approximate
reasoning                 
de cooman  g     quaeghebeur  e          exchangeability sets desirable gambles 
international journal approximate reasoning                  special issue
honour henry e  kyburg  jr 
de cooman  g   quaeghebeur  e     miranda  e       b   exchangeable lower previsions 
bernoulli                 
de finetti  b          la prvision  ses lois logiques  ses sources subjectives  annales de
linstitut henri poincar          english translation kyburg jr  smokler
       
de finetti  b          teoria delle probabilit  einaudi  turin 
de finetti  b              theory probability  critical introductory treatment  john
wiley   sons  chichester  english translation de finettis        book  two volumes 
dubins  l  e          finitely additive conditional probabilities  conglomerability
disintegrations  annals probability          
  

ficoherent predictive inference exchangeability

geisser  s          predictive inference  introduction  chapman   hall 
goldstein  m          prevision prevision  journal american statistical
society             
goldstein  m          temporal coherence  bernardo  j  m   degroot  m  h   lindley 
d  v     smith  a  f  m   eds    bayesian statistics  vol     pp          north holland 
amsterdam  discussion 
good  i  j          estimation probabilities  essay modern bayesian methods 
mit press 
haldane  j  b  s          method estimating frequencies  biometrika             
hausdorff  f          momentprobleme fr ein endliches intervall  mathematische zeitschrift 
           
jaynes  e  t          probability theory  logic science  cambridge university press 
jeffreys  h          theory probability  oxford classics series  oxford university press 
reprint third edition         corrections 
johnson  n  l   kotz  s     balakrishnan  n          discrete multivariate distributions 
wiley series probability statistics  john wiley sons  new york 
johnson  w  e          logic  part iii  logical foundations science  cambridge
university press  reprinted dover publications      
keynes  j  m          treatise probability  macmillan  london 
koopman  b  o          axioms algebra intuitive probability  annals
mathematics  second series                 
kyburg jr   h  e     smokler  h  e   eds            studies subjective probability  wiley 
new york  second edition  with new material       
lad  f          operational subjective statistical methods  mathematical  philosophical
historical introduction  john wiley   sons 
levi  i          enterprise knowledge  mit press  london 
mangili  f     benavoli  a          new prior near ignorance models simplex 
cozman  f   denux  t   destercke  s     seidenfeld  t   eds    isipta   
proceedings eighth international symposium imprecise probability  theories
applications  pp          sipta 
miranda  e          updating coherent lower previsions finite spaces  fuzzy sets
systems                    
miranda  e     de cooman  g          introduction imprecise probabilities  chap  lower
previsions  john wiley   sons 
miranda  e     zaffalon  m          notes desirability conditional lower previsions 
annals mathematics artificial intelligence                   
moral  s          epistemic irrelevance sets desirable gambles  annals mathematics
artificial intelligence             
  

fide cooman  de bock    diniz

moral  s     wilson  n          revision rules convex sets probabilities  coletti 
g   dubois  d     scozzafava  r   eds    mathematical models handling partial
knowledge artificial intelligence  pp          plenum press  new york 
piatti  a   zaffalon  m   trojani  f     hutter  m          limits learning categorical
latent variable prior near ignorance  international journal approximate
reasoning                 
prautzsch  h   boehm  w     paluszny  m          bzier b spline techniques  springer 
berlin 
quaeghebeur  e          introduction imprecise probabilities  chap  desirability  john
wiley   sons 
quaeghebeur  e   de cooman  g     hermans  f          accept   reject statement based
uncertainty models  international journal approximate reasoning  accepted
publication 
rouanet  h     lecoutre  b          specific inference anova  significance tests
bayesian procedures  british journal mathematical statistical psychology 
               
seidenfeld  t   schervish  m  j     kadane  j  b          representation partially ordered
preferences  annals statistics                reprinted collection
seidenfeld et al         pp         
seidenfeld  t   schervish  m  j     kadane  j  b          rethinking foundations
statistics  cambridge university press  cambridge 
sheffer  i  m          properties polynomial sets type zero  duke mathematical
journal            
smith  c  a  b          consistency statistical inference decision  journal
royal statistical society  series a          
troffaes  m  c  m     de cooman  g          lower previsions  wiley 
trump  w     prautzsch  h          arbitrary degree elevation bzier representations 
computer aided geometric design             
walley  p          statistical reasoning imprecise probabilities  chapman hall 
london 
walley  p          inferences multinomial data  learning bag marbles  journal
royal statistical society  series b           discussion 
walley  p          bounded derivative model prior ignorance real valued
parameter  scandinavian journal statistics                 
walley  p          towards unified theory imprecise probability  international journal
approximate reasoning             
walley  p     bernard  j  m          imprecise probabilistic prediction categorical data 
tech  rep  caf       laboratoire cognition et activites finalises  universit de
paris   
  

ficoherent predictive inference exchangeability

williams  p  m       a   coherence  strict coherence zero probabilities  proceedings
fifth international congress logic  methodology philosophy science 
vol  vi  pp        dordrecht  proceedings      conference held warsaw 
williams  p  m       b   notes conditional previsions  tech  rep   school mathematical
physical science  university sussex  uk  see revised journal version
williams        
williams  p  m          indeterminate probabilities  przelecki  m   szaniawski  k    
wojcicki  r   eds    formal methods methodology empirical sciences  pp 
        reidel  dordrecht  proceedings      conference held warsaw 
williams  p  m          notes conditional previsions  international journal approximate
reasoning             
zabell  s  l          w  e  johnsons sufficientness postulate  annals statistics     
          reprinted collection zabell        
zabell  s  l          symmetry discontents  essays history inductive probability  cambridge studies probability  induction  decision theory  cambridge
university press  cambridge  uk 
zaffalon  m     miranda  e          probability time  artificial intelligence           

  


