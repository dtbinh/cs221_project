journal of articial intelligence research                  

submitted        published      

lazy model expansion 
interleaving grounding with search

broes decat gmail com

broes de cat

om partners  belgium

marc denecker cs kuleuven be

marc denecker

dept  computer science  kuleuven  belgium

pstuckey unimelb edu au

peter stuckey

national ict australia and
dept  of computing and information systems
the university of melbourne  australia

maurice bruynooghe

dept  computer science  kuleuven  belgium

maurice bruynooghe cs kuleuven be

abstract

finding satisfying assignments for the variables involved in a set of constraints can be
cast as a  bounded  model generation problem  search for  bounded  models of a theory
in some logic  the state of the art approach for bounded model generation for rich knowledge representation languages like answer set programming  asp  and fo   and a csp
modeling language such as zinc  is ground and solve   reduce the theory to a ground or
propositional one and apply a search algorithm to the resulting theory 
an important bottleneck is the blow up of the size of the theory caused by the grounding
phase  lazily grounding the theory during search is a way to overcome this bottleneck 
we present a theoretical framework and an implementation in the context of the fo  
knowledge representation language  instead of grounding all parts of a theory  justications
are derived for some parts of it  given a partial assignment for the grounded part of the
theory and valid justications for the formulas of the non grounded part  the justications
provide a recipe to construct a complete assignment that satises the non grounded part 
when a justication for a particular formula becomes invalid during search  a new one is
derived  if that fails  the formula is split in a part to be grounded and a part that can be
justied  experimental results illustrate the power and generality of this approach 

   introduction
the world is lled with combinatorial problems 

these include important combinatorial

optimization tasks such as planning  scheduling and rostering  combinatorics problems such
as extremal graph theory  and countless puzzles and games  solving combinatorial problems
is hard  and all the methods we know to tackle them involve some kind of search 
various

declarative paradigms

have been developed to solve such problems 

in such

approaches  objects and attributes that are searched for are represented by symbols  and
constraints to be satised by those objects are represented as expressions over these symbols

c      ai access foundation  all rights reserved 


fide cat  denecker  stuckey   bruynooghe
in a declarative language  solvers then search for values for these symbols that satisfy the
constraints  this idea is found in the elds of constraint programming  cp   apt        
asp  marek   truszczyski         sat  mixed integer programming  mip   etc  in the
terminology of logic  the declarative method amounts to expressing the desired properties of

logical theory  the data of a particular problem instance
partial interpretation  or structure   the solving process is to
apply model generation  or more specically model expansion  mitchell   ternovska        
a problem class by sentences in a

corresponds naturally to a

the task of nding a structure that expands the input partial structure and satises the
theory  the resulting structure is a solution to the problem  model generation expansion 
studied for example in the eld of knowledge representation  kr   baral         is thus
analogous to the task of solving constraint satisfaction problems  studied in cp  and that
of generating answer sets of logic programs  studied in asp 
the similarities between these areas go deeper and extend to the level of the used techniques 

state of the art approaches often follow a two phase solving methodology 

in a

rst phase  the input theory  in the rich language at hand  is reduced into a fragment of
the language that is supported by some search algorithm  in the second phase  the search
algorithm is applied to the reduced theory to eectively search for models  for example 
model generation for the language minizinc  nethercote et al         is performed by reducing to the ground language flatzinc  for which search algorithms are available  similarly 
the language

pc  

fo  

 denecker   ternovska        is reduced to its propositional fragment

 see  e g   wittocx  marin    denecker         and asp is reduced to propositional

asp  see  e g   gebser  schaub    thiele         as the reduced theory is often in a ground
fragment of the language  we refer to the resulting reduced theory as the
the rst phase as the

grounding

grounding

and to

phase  where quantiers are instantiated with elements in

the domain   in other elds  grounding is also referred to as attening  unrolling  splitting
or propositionalization  the solving methodology itself is generally referred to as

and solve 

ground 

grounding becomes a bottleneck as users turn to applications with large domains and
complex constraints  indeed  it is easy to see that the grounding size of an fo formula is
exponential in the nesting depth of quantiers and in the arity of predicates and polynomial
in the size of the universe of discourse 

there is an increasing number of applications

where the size of the grounded theory is so large that it does not t in memory 

for

example  son  pontelli  and le        discuss several asp applications where the groundand solve approach turns out to be inadequate 
in this paper  we present a novel approach to remedy this bottleneck  called

lazy model

expansion  where the grounding is generated lazily  on the y  during search  instead of upfront  the approach works by associating justications to the non ground parts of the theory 
a valid justication for a non ground formula is a recipe to expand a partial structure into
a more precise  partial  structure that satises the formula  of course  it is crucial that the
recipe is a lot more compact than the grounding of the formula  given a partial structure
and a valid justication for each of the non ground formulas  a  total  structure is obtained
by extending the partial structure with the literals in the justications of the non ground
formulas  justications are selected in such a way that this total structure is a model for
the whole initial theory 

consequently  model generation can be limited to the grounded

part of the theory  if a model is found for that part  it can be extended to a model of the

   

filazy model expansion  interleaving grounding with search
whole theory  however  a new assignment during model generation can conict with one of
the justications  in that case  an alternative justication needs to be sought  if none is
found  the associated formula can be split in two parts  one part that is grounded and one
part for which a valid justication is still available 

example     

consider the

sokoban

problem  a planning problem where a robot has to

push blocks around on a   d grid to arrange them in a given goal conguration  a constraint
on the move action is that the target position
 at time

t  t 

pp

of the moved block

bb

is currently

empty  which can be expressed as

 t  b  p   t  b  p   move b  p  t   empty p  t  

   

as it is not known in advance how many time steps are needed  one ideally wants to assume
a very large or even innite number of steps  using ground and solve  this blows up the size
of the grounding  incremental grounding  iteratively extending the time domain until it is
large enough to allow for a plan  has been developed to avoid the blow up in the context of
planning  gebser et al          our approach is more general and does not depend on the
presence of one domain that can be incrementally increased 
returning to the example  instead of grounding sentence      we associate with it a
justication  a recipe to satisfy it 

make

move b  p  t 

false for all

b  p

and

t

is such a

recipe  when the search nds a model for the grounded part of the problem that is not in
conict with the recipe  the model can be extended with the literals in the recipe to obtain a
model of the whole theory  however  if the search would decide to move block

p 

b 

to position

at time t    a conict is created with the recipe  to resolve it  the instance of sentence    

that is in conict with the partial model of the search is split o and sentence     is replaced
by the equivalent sentences 

move b    p    t     empty p    t   

   

 t  b  p   t  b  p   t    b    p      move b  p  t   empty p  t 

   

sentence     is grounded and passed to the search component which will use it to check
that

empty p    t   

holds 

sentence     is non ground and can be satised by the recipe

 move b  p  t  is false except for

move b    p    t    

when the search makes more moves  more

instances will be grounded  until the search nds a partial plan for the problem at hand 
then the literals in the recipe of the remaining non ground formula making

move b  p  t 

false for all instances of sentence     that have not been grounded will complete the plan 
the main contributions of this paper are 



a theoretical framework for

lazy model expansion 

by aiming at minimally instantiat 

ing quantied variables  it paves the way for a solution to the long standing problem of
handling quantiers in search problems  encountered  e g   in the elds of asp  lefvre
  nicolas        and sat modulo theories  ge   de moura         the framework
also generalizes existing approaches that are related to the grounding bottleneck such
as incremental domain extension  claessen   srensson        and lazy clause generation  ohrimenko  stuckey    codish        

   

fide cat  denecker  stuckey   bruynooghe


a complete algorithm for lazy model expansion for the logic

fo id   

the extension of

rst order logic  fo  with inductive denitions  a language closely related to asp as
shown in denecker et al          this includes ecient algorithms to derive consistent
sets of justications and to maintain them throughout changes in a partial structure
 e g   during search  



idp

an implementation extending the

knowledge base system  de cat et al        

and experiments that illustrate the power and generality of lazy grounding 
lazy grounding is a new step in our ability to solve complex combinatorial problems  by
avoiding the up front grounding step of previous approaches  lazy grounding can ground
enough of the problem to solve it  while our method is developed for the logic

fo id   

as

will become clear  justications are associated with rules  and these rules are very similar
to the rules used by asp systems  hence  as discussed towards the end of the paper  our
framework and algorithms can be applied also in the context of asp 
the paper is organized as follows 

in section    the necessary background and nota 

tions are introduced  formal denitions of lazy grounding with

fo id  

are presented in

section    followed by a presentation of the relevant algorithms and heuristics in sections  
and    experimental evaluation is provided in section    followed by a discussion on related
and future work and a conclusion  a preliminary version of the paper appeared as the work
of de cat  denecker  and stuckey        and of de cat        ch     

   preliminaries
in this section  we provide the necessary background on the logic
tasks model generation and model expansion for

fo id  

fo id   

on the inference

and on the ground and solve

approach to model expansion 

   

fo id  

first  we dene syntax and semantics of the logic

fo id  

 denecker   ternovska        

the extension of rst order logic  fo  with inductive denitions  we assume familiarity with
fo  without loss of generality  we limit

fo id  

to the function free fragment  function

symbols can always be eliminated using graph predicates  enderton        
a  function free  vocabulary



consists of a set of predicate symbols 

propositional

  and   denoting true and
false respectively  predicate symbols are usually denoted by p   q  r  atoms by a  literals
 atoms or their negation  by l  variables by x  y   and domain elements by d  with e we
denote an ordered set of objects e            en   with p n a predicate p of arity n 

symbols are   ary predicate symbols  these include the symbols

the methods for model generating developed below require that a  possibly innite 
domain

d

  a domain atom is an

p d with p n   and d  dn   an n tuple of domain elements  likewise 

is given and xed  given a  function free  vocabulary

atom of the form
we consider

domain literals 

 consists of the domain d and an n ary relation p i  dn
for all predicate symbols p n    alternatively  an n ary relation can be viewed as a
n
function d   t  f    the propositional symbols   and  are respectively interpreted as t
and f  
a structure

i

interpreting

   

filazy model expansion  interleaving grounding with search
model generation algorithms maintain
themselves in an

inconsistent

partial

structures and may  temporarily  nd

state  for example when a conict arises  to represent such

i are introduced  they consist of the domain
n ary predicate p in   of a three  or four valued relation p i   this is a
n
function d   t  f   u  i   a structure is two valued if the range of its relations is  t  f   
partial or three valued if the range is  t  f   u   and four valued in general  thus  two valued
states  three valued and four valued structures

d

and  for each

structures are also three valued and four valued 

when unqualied  the term

structure

stands for the most general  four valued case 
given a xed

d

and

  an alternative way to represent i

domain

ai

 t

d

if only

a

 f

if only

s

and

a  ai   i  inconsistent  if
a is in s and ai   u  unknown 

such that for a domain atom

i
is in s   a

s of domain literals 
 structures i with
both a and a are in s  

is as a set

indeed  there is a one to one correspondence between such sets

otherwise  hence 

we may treat four valued structures as sets of domain literals and vice versa  a structure is

inconsistent if at least one domain atom is inconsistent 

i of a vocabulary  can be naturally viewed as a structure of a larger
   namely by setting ai   u for any domain atom of a predicate in      
for a set  of predicate symbols  we use i  to denote the restriction of i to the symbols
i 
i
of    for a set s of domain atoms  we use i s to denote the restriction of i to s   a s   a
i 
if a  s and a s   u otherwise  we call i a two valued structure of s if i is two valued
on domain atoms of s and unknown otherwise 
  of a truth value v is dened as follows  t    f   f     t  u    u and
the inverse v
 
i   i  the truth order  t on truth values is dened by t  t u  t f and t  t i  t f   the
precision order  p is dened by i  p t  p u and i  p f  p u  both orders are pointwise
 
extended to arbitrary  structures  we say that i   is an expansion of i if i p i   that
 
i
i
is if for each domain atom a  a
p a   viewing structures as sets of domain literals  this
 
corresponds to i  i  
a structure

 
vocabulary 

we assume familiarity with the syntax of  function free  fo  to facilitate the reasoning
with partially grounded formulas  we deviate from standard fo and quantify over explicitly

x  d     and x  d      with
 d  we sometimes abbreviate x   d          xn  dn    as x  d     and similarly
for   given a formula    x  indicates that x are the free variables of   substitution of a
variable x in formula  by a term t is denoted by  x t   a ground formula  in domain d  
specied subsets of the domain

d 

this is denoted as

d 

is a formula without variables  hence without quantiers   similar properties and notations
are used for

rules

 introduced below  

voc t   the set of all predicate symbols that occur in theory t   for
a structure i   voc i  is the set of symbols interpreted by i   unless specied otherwise 
theories and structures range over the vocabulary  
the language fo id   extends fo with  inductive  denitions  a theory in fo id  
is a  nite  set of sentences and denitions  a denition  is a  nite  set of rules of the
form x  d   p  x            xn      with p a predicate symbol and  an fo formula  the
atom p  x  is referred to as the head of the rule and  as the body  given a rule r   we let
head  r  and body r  denote respectively the head and the body of r  given a denition  
a domain atom p d is dened by  if there exists a rule x  d   p  x    in  such



that d  d   otherwise p d is open in   a domain literal p d is dened by  if p d
we denote by

   

fide cat  denecker  stuckey   bruynooghe
  the sets of dened and open domain atoms of  are denoted as defined   
open    respectively 

is dened by
and

without loss of generality  we assume that in any denition a domain atom is dened
by at most one rule  technically  this means that rules

p  x    

x  d    p  x       x  d   

d   d      rules can always be made disjunct
x  d   d    p  x          x  d    d    p  x      

are pairwise disjunct  that is

by transforming them in

x  d    d    p  x      
      model semantics
the semantics of

fo id  

is a two valued model semantics 

nevertheless  we introduce

concepts of three  and four valued semantics which are useful in dening the semantics
of denitions and in formalizing lazy grounding 

we use the standard four valued truth

assignment function  dened by structural induction for pairs of fo domain formulas

 and

i that interpret  
i
i
 p d   p i  d   

structures

     i   min t   i   i   
     i   max t   i   i   
   i     i     
  x  d    i   max t    x d i   d  d   
  x  d    i   min t    x d i   d  d   
the assignment function is monotonic in the precision order  if

i p i    

then

i p i

 

 

hence  if a formula is true in a partial structure  it is true in all two valued expansions of
it 

also  if

i

is two valued  respectively three valued  four valued  then

i

is two valued

i

is two valued

 respectively three valued  four valued  
a structure
and

i   t 

i

is a

model

of  

satises

a sentence



 notation

i     

if

the satisfaction relation can be dened for denitions as well  the semantics

of denitions is based on the parametrized well founded semantics  an extension of the wellfounded semantics of logic programs informally described rst in the work of van gelder
        and formally dened for

fo id   s

denitions by denecker         this semantics

formalizes the informal semantics of rule sets as  inductive  denitions  denecker       
a structure i is
  notation i      if i is two valued and is the wellfounded model denoted as wf   i open     of  in the structure i open    denecker
  ternovska         in case wf   i open     is not two valued   has no model expanding
i open     a structure i satises a theory t if i is two valued and i is a model of all
sentences and denitions in t   in the next subsection  we present a formalization of the
denecker  bruynooghe    marek        denecker   vennekens        
a

model

of  

satises

a denition

well founded semantics using the notion of
according to

fo id   s

justication 

methodology   formal  denitions are used to express informal

denitions  in the work of denecker and vennekens         it was shown that

fo id  

de 

nitions oer a uniform representation of the most important types of informal denitions and

   

filazy model expansion  interleaving grounding with search
that expressing informal denitions leads to rule sets that are



is called

total

if the well founded model of



is two valued  denecker   ternovska        

total 

formally  a denition

in each two valued structure

i

open  

of

in general  totality is undecidable  however

broad  syntactically dened classes of denitions have been proven to be total  e g   nonrecursive  positive  stratied and locally stratied denitions  see denecker   ternovska 
       inspection of current

fo id  

applications shows that in practice  non total deni 

tions occur rarely and almost always contain a modeling error  also  in most cases totality
can be established through a simple syntactic check 

totality can be usefully exploited

during computation  the lazy grounding techniques introduced below exploit totality and
should be applied only to total denitions  this restriction matches with

fo id   s

and methodology and  in practice  this does not impose a strong limitation 

design

in case the

input theory does contain denitions that are not known to be total  all is not lost  those
denitions can be grounded completely up front  in which case lazy grounding can be applied
safely to the remaining sentences and total denitions in the input 

equivalence 
equivalent

two theories

t

and

t   

which can be over dierent vocabularies  are

 

 
can be expanded to a model of t and vice

t restricted to 
t   are strongly  equivalent if the above expansions are also
unique  by extension   strong   equivalence in a structure i is dened similarly  if each
 
model of t expanding i can be expanded to a model of t expanding i and vice versa  to
obtain strong equivalence  these expansions have to be unique  from a theory t   we often
 
derive a strongly voc t   equivalent theory t in a given structure i   such transformations
 
preserve satisability and number of models and each model of t can be directly mapped
to a model of t by projection on voc t   
versa 

if each model of

two theories

t

canonical theories 

and

to simplify the presentation  the lazy grounding techniques are

presented here for theories of the form

 pt     

a single denition with function free rules 

with

pt

a propositional symbol  and

this is without loss of generality 



first  as

mentioned above  standard techniques  enderton        allow one to make a theory functionfree  second  multiple denitions can always be combined into one as described by denecker
and ternovska        and marin  gilis  and denecker         this is achieved by renaming
dened predicates in some of the denitions  merging all rules into one set and adding
equivalence constraints between predicates and their renamings 

             n    

equivalent theory

 pt      pt         n   

with

pt

t  
voc t   

third  the theory

resulting from the previous step can be translated to the strongly

a new propositional symbol 

this transformation results in a ground set of sentences and a denition consisting of a
set of  ground and non ground  rules  so lazy grounding has only to cope with non ground
rules  furthermore  we assume that rule bodies are in negation normal form  negation only
occurs in front of atoms  and that  for each dened domain atom
rule

x  d   p  x     

such that

dd


p d  

there is a unique

 

the methods proposed below can be extended to full

fo id  

with functions  and such

extended methods have been implemented in our system  however  this introduces a number
of rather irrelevant technicalities which we want to avoid here 

   

fide cat  denecker  stuckey   bruynooghe
      justifications

d and a canonical theory t        as explained
d correspond one to one to sets of domain literals 

denition      direct
justication   a direct justication for a dened domain literal p d

 respectively p d   is a consistent non empty set s of domain literals such that  for the
s
rule x  d   p  x    of  such that d  d   it holds that  x d    t  respectively
s
 x d    f   

 
any consistent superset s of a direct justication s of p d is a direct justication
 
as well  indeed  a body  x d  true in s is true in the more precise s   also  a direct
justication s is not empty by denition  if  is true in every structure  then a minimal
direct justication is     

we assume the presence of a domain

above  recall  structures with domain

example     

consider a domain



a direct justication for

d    d            dn  

and the denition

x  d   p  x   q x   r x 
x  d   q x   p  x 

q di  

is

 p  di   

and for

q di  

is





 p  di    

both domain literals

have many other direct justications  but those are the unique minimal ones under the

p  di   are both  q di    and  r di    while
p  di   is  q di    r di     atoms r di   are open

subset relation  minimal direct justications for
the only minimal direct justication for
and have no direct justication 

g is a pair hv  ei of a set v of nodes and a set e of directed
 vi   vj   of nodes  for any node v  v   we denote by g v  the
g v     w    v  w   e  

a  directed  graph
i e   ordered pairs
children of

v 

i e  

denition      justication  
of domain literals of



a

justication

over a denition

such that for each domain literal

l  j l 



is a graph

j

edges 
set of

over the set

is either empty or a direct

justication of l 
thus  a justication is a graph that encodes for every dened domain literal none or one
direct justication  in the sequel we say that
denoted as a set of pairs

l  s 

with

s

j

is

dened in l

if

j l      

a justication is

a direct justication of l 

denition      justication subgraph  

let

j

be a justication over

 

the justication

for a literal l is the subgraph jl of nodes and edges of j reachable from l  the justication
for a set of literals l is the subgraph jl of nodes and edges of j reachable from any l  l 
a justication j over  is total for l if j is dened in each literal that is reachable from
l and dened in   it is total for a set of literals l if it is total for each literal in l  a
justication j is consistent with a structure i if i is consistent and none of the literals for
which
if

j
j

is dened is false in

i 

is total for l  then the leaves of

jl

are open domain literals 

   

filazy model expansion  interleaving grounding with search
denition     
li  li    

positive literals  it is

cycle

j

a path in a justication

is a sequence

then there is an edge from li to li   in

negative

in a justication

j

j 

l   l        

a path is

positive

if it consists of only negative literals  it is

is a set of domain literals on a path in

j

such that  if

if it consists of only

mixed

otherwise  a

that starts and ends in

the same domain literal  a cycle is positive  respectively  negative  if all domain literals are
positive literals  respectively  negative literals   otherwise the cycle is mixed 
an innite path may be cyclic or not  if
intuitively  a justication
truth of

l 

j

d

is nite  every innite path is cyclic 

containing a domain literal

l

provides an argument for the

the strength of this argument depends on the truth of the leaves and on the

innite paths and cycles in
provides the argument that

jl  
l is

if all leaves are true and every innite path is negative 
true  if a leaf is false or unknown  or

or mixed loop  the argument for

l

jl

jl

contains a positive

is weak  notice that other justications for

l

may still

argue l s truth 

denition      justies  

l is well founded in the justication
j if every innite path in jl is negative  otherwise l is unfounded in j  
a justication j over  justies a set of literals l dened in   the set l of literals has
a justication j   if  i  jl is total for l   ii  each literal of l is well founded in j    iii  the
set of literals in jl is consistent 

p  d 

q d 

we say that a dened literal

p  d 

r d 

p  d 

q d 

p  d 

q d 

r d 

q d 
 i 

 ii 

 iii 

figure    justications for denition

example     



p  d 

d  d 

in example     that contain the dened domain atoms

justication  ii  justies

 iii   however  is not total for
for both

in example      with

in figure    we show a few possible justications  ordered  i   iv  from left

to right  over denition

q d   d  d  



 iv 

and

p  d 

nor

p  d 
q d 

and

q d 

and  iv  justies

p  d 

p  d  and
q d  

and

and  i  has a positive cycle and is unfounded

q d  

the relationship between justications and the well founded semantics has been investigated in dierent publications  denecker   de schreye              marin         below
we recall the results on which this paper relies  the rst result states that if
literals in
in

l

l  then
jl  

any model

i

of



in which the leaves of

jl

j

justies all

are true  satises all literals

and in

proposition      if j is a justication over  that justies a set of domain literals l then
all literals in jl are true in every model of  in which the  open  leaves of jl are true 
   

fide cat  denecker  stuckey   bruynooghe
for an interpretation iopen that is two valued for open    the well founded model
wf  iopen   can be computed in time polynomial in the size of the domain  as shown by chen
and warren         in general  wf  iopen   is a three valued structure  if wf  iopen   is twovalued  then it is the unique model of  that expands iopen   otherwise   has no model that
expands iopen   the above proposition follows from the fact that if a justication j justies
l and all leaves of j are true in iopen   then all literals of l are true in wf  iopen   

example    

 

if

r d 

is true in

in which

r d 

justication  ii  justies l    q d   and
iopen interpreting the open predicates of  
wf  iopen    in particular  in any model of 

 continued from example     

has a unique open leaf
is

r d  

for any structure

iopen   then q d  is
true  q d  is true 

true in

proposition       if i is a model of   then a justication j over  exists that consists
of literals true in i   is dened for all dened domain literals true in i and justies each of
them 

corollary       in case

 is total  if a justication j over  justies a set of domain
literals l  then every two valued open   structure consistent with jl can be extended in a
unique way to a model of  that satises all literals of l 
 pt    
justies pt  

hence  for a canonical theory
justication

j

exists that

 recall 



is total   the theory is satisable i a

    generating models
model generation
a model of

t 

is the inference task that takes as input a theory

t

and returns as output

model expansion  mx  was dened by mitchell et al         as the inference

task that takes as input a theory
subvocabulary of

 

t

over vocabulary

and returns an expansion

m

of


i

i

and a two valued structure
that satises

t 

over a

here  it will be the

more general inference problem as dened by wittocx  marin  and denecker        that
takes as input a  potentially partial  structure
that satises

i

over

 

and returns an expansion

m

of

i

t 

as already mentioned  the state of the art approach to model expansion in
is  similar to asp  grounding

t

in the context of

i

fo id  

and afterwards applying search to

the resulting ground theory  the latter can  e g   be accomplished by the sat id  search
algorithm  marin et al         
below  we present the grounding algorithm that is the basis of the lazy mx algorithm 
we assume familiarity with the basic conict driven clause learning  cdcl  algorithm of
sat solvers  marques silva  lynce    malik        

      grounding
for an overview of intelligent grounding techniques in

fo id   

we refer the reader to the

work of wittocx  denecker  and bruynooghe        and of wittocx et al          below we
present the basic principle 

t over vocabulary   a partial structure i with
  and returns a ground theory t   that is strongly

a grounder takes as input a theory
domain

d 

interpreting at least

 

and

   

filazy model expansion  interleaving grounding with search
 equivalent

with

we assume that

t

t

in

i 

theory

t 

is then called a

is a canonical theory of the form

grounding

of

t

given

i 

recall that

 pt     

one way to compute the grounding is using a top down process on the theory  iteratively
applying grounding steps to direct subformulas of the rule or formula at hand  the grounding
let  x  be a
t and let d be the domains of x  a tseitin transformation replaces  by the
 
atom t  x   with t a new  x  ary predicate symbol called a tseitin symbol  and extends
 with the rule x  d   t  x     the new theory is strongly  equivalent to the

algorithm may replace subformulas by new predicate symbols as follows 
formula in

original one  vennekens et al         
the procedure one step ground  outlined in figure    performs one step in the grounding process  called with a formula or rule



in canonical form  the algorithm replaces all

g
 rules or formulas  and a possibly non ground part r  rules   if  is a formula  then g
consists of ground formulas  replacing  by the returned ground formulas and extending 
with the returned rules produces a theory that is strongly voc t   equivalent to the original 
if  is a rule from   g consists of ground rules  and replacing  by both sets of returned
rules results again in a theory that is strongly voc t   equivalent to the original 
direct subformulas with tseitin symbols and returns a pair consisting of a ground part

algorithm    the one step ground algorithm 
  function one step ground  formula or rule  
 
switch  do 
 
case   p d return h    i 
 
case p d  
 
 
 
 
 
  
  
  
  
  
  
  

hg  i

   one step ground    

return h p d  gg g   i 
case          w
 n
return h  i   n  ti     ti  i   i      n  i 
case           n
return h ti   i      n     ti  i   i      n  i 
case x  d   p  x   
return h   p  x  x d    x d    d  d i 
case x  d  w x 
return h  dd t x d      t x d    x d    d  d i 
case x  d    x 
return h t x d    d  d    t x d    x d    d  d i 


v

grounding a theory then boils down to applying one step ground on the sentence
 which copies

pt

pt

to the ground part  and on each rule of the theory and repeatedly applying

one step ground on the returned rules

r  all returned sentences and rules in g are ground  

we use ground to refer to the algorithm for this overall process 
   tseitin        introduced such symbols as part of his normal form transformation 

   

fide cat  denecker  stuckey   bruynooghe
various improvements exist  such as returning



returning

  

for atoms interpreted in

i

and

from conjunctions whenever a false conjunct is encountered  analogously for

disjunctions and quantications  
also  algorithm one step ground introduces a large number of tseitin symbols  stateof the art grounding algorithms use a number of optimizations to reduce the number of such
symbols  as these optimizations are not directly applicable to the techniques presented in
this paper  we start from the naive one step ground algorithm  in section    we present
an optimized version of one step ground that introduces fewer tseitin symbols and hence
results in smaller groundings 

   lazy grounding and lazy model expansion
lazy grounding to refer to the process of partially grounding a theory and
lazy model expansion  lazy mx  for the process that interleaves lazy grounding

we use the term
the term

with model expansion over the grounded part  in section      we formalize a framework for
lazy model expansion of

fo id  

theories  in section      we formalize the instance of this

framework that is the basis of our current implementation  in section      we illustrate its
operation 

    lazy model expansion for fo id  theories
given a canonical theory

t    pt    

and an input structure

iin  

models expanding

iin

are searched for by interleaving lazy grounding with search on the already grounded part 
we rst focus on the lazy grounding 
apart from the initial step that moves

pt

to the grounded part  the input of each step

consists of a set of rules still to be grounded  an already grounded theory and a three valued
structure that is an expansion of the initial input structure 
each subsequent grounding step can replace non ground rules by ground rules and might
introduce new rules  hence  the state of the grounding includes a set
and a set

d

 the

delayed denition  

g

of ground rules

of  possibly  non ground rules  the denitions have

g  d  in what follows abbreviated as gd   is voc   equivalent with
the original denition  and hence  gd is total  the grounding procedure will guarantee
that  at all times  g and d are total 
given a partial structure iin and the rule sets g and d   the key idea behind lazy
model expansion is  i  to use a search algorithm to search for a model i of g that is an
expansion of iin in which pt is true   ii  to maintain a justication j such that the literals
true in i and dened in d are justied over gd and that j is consistent with i    iii  to
interleave steps  i  and  ii  and to move parts of d to g when some literal dened in d
the property that

that needs to be justied cannot be justied 

hg   d   j  ii
d yet to be grounded  a justication j   and
d is   g     and j is the empty graph 

thus  to control lazy model expansion  it suces to maintain a state
consisting of the grounded rules
a three valued structure

i 

g  

initially 

the rules

i

is

iin  

lazy model expansion searches over the space of

denition      acceptable state  
tence

acceptable

states 

a tuple hg   d   j  ii of a theory with an atomic senpt   a total denition   and an input structure iin is an acceptable state if  i  gd   g

   

filazy model expansion  interleaving grounding with search
and

d

gd is strongly voc   equivalent with    ii  no domain
d    iii  j is a justication over gd    iv  i is an expansion
l of literals true in i and dened in d is justied by j   and  vi  jl  
the literals in l  is consistent with i  

are total denitions and

atom is dened in both
of

v

iin  

    the set

the justication of

example     

g

and

consider the theory

 pt     

with



the denition



pt  t   t   t   



 t  x  d   q x  
 

t   x  d   r x  




t   x  d   q x  
let

i

be the structure

 pt   t   

 hence 

t 

and

t 













are unknown   and

g

and

d

the

denitions consisting of the rst rule and the remaining rules  respectively  furthermore  let

j be  t    q d    d  d    the tuple hg   d   j  ii is then an acceptable
t  is the only literal in i that is dened in d and it is justied by j  

state  indeed 

as already said  the lazy model expansion algorithm starts from the initial state

  d     j     i   iin  

which is acceptable if dened literals are unknown in

each state  it either renes

i

by propagation or choice  or it backjumps 

g  

iin  

in

if the resulting

state is unacceptable  a repair operation restores acceptability  these steps are described in
section     
in

gd  

the algorithm tries to compute an acceptable state in which

t

by corollary       this would entail that a model of

pt

is justied

exists  it can be computed

eciently through well founded model computation  in intermediate states  the justication
may be non total for

pt  

iii  

note that  in  
is justied over

d  

contain unfounded literals  or be inconsistent 

the justication must be over

gd  

indeed  assume some literal

its justication graph can have a leaf that is dened in

g

l

and that

depends positively or negatively on l  then every attempt to extend this justication graph

l over gd might fail  e g   because of a forbidden
cycle  consider  e g   the denitions g    p  q  and d    q  p    in that case  it
would not be correct to take p as justication for q being true  even though it is a valid
justication within d   indeed  no model exists that justies q in the full denition gd  
to a total justication graph that justies

proposition      let hg   d   j  ii be an acceptable state 

gd has a well founded model
that expands the literals that are true in i and dened in the  delayed  denition d  

proof 

l

let

be the set of literals true in

justies the literals of
expands

l 

i

and dened in

to the open literals of

because

as the state is acceptable 

j

hence  by corollary       there exists a well founded model that

l 

example      continued from example      
 

d  

i

is a model of

j

 i e   to

g   pt

be interpreted randomly  as no

the well founded evaluation  after assigning

 q d    d  d   

derives that

t 

is true 

moreover 

is also true in such a well founded model  note that

r atoms

occur in

i

or

j 

the following theorem states when the obtained expansion is also a model of

   

t 

r

can

fide cat  denecker  stuckey   bruynooghe
theorem      let hg   d   j  ii be an acceptable state of a theory t    pt     with input
structure iin such that pt is true in i and i voc g   is a model of g   then there exists a
model m of t that expands i voc g    
proof  i voc g  
justication

jg

is a model of
over

g

only domain literals true in
combine them in one

it follows from proposition      that there exists a

i voc g    

g

and that consists of

we now have two justications 

as follows  for each dened literal

l

of

gd  

if

j

j

and

jg  

we

l  we
jg for

is dened in

jc  l    jg  l   as jc takes edges from either j or
each dened literal  it is a justication for gd  
we verify that jc justies pt   first  it is total in pt   indeed  any path from pt either
consists of literals dened in g   and then it is a branch of the total jg over g   or it passes
 
to a literal l dened in d   which is justied by j according to condition  v  and hence
 jc  l    jl  is total  as such  from pt we cannot reach a dened literal of gd in which
jc is undened  second  jc does not contain unfounded literals starting from pt   this is
because any path from pt is either a path in jg  so well founded as it justies g   or it has
a tail in j  well founded by property  v    finally  the set of literals reachable from pt in
jc is consistent  also this we can see if we look at paths in jc from pt   at rst we follow
jg which consists of true literals in i   then we may get into a path of j which contains
literals that are consistent with i   in any case  it is impossible to reach both a literal and
set

jc  l    j l  

jc

g  

that justies every true dened literal of

otherwise  we set

its negation 
it follows from proposition     that there exists a model of
and in which

pt

is true  since

gd

that expands

i voc g  

gd is strongly equivalent with   the proposition follows 

m can be achieved by well founded evalstarting from any two valued open gd   

recall that eectively computing such a model
uation of

gd  

with polynomial data complexity 

structure expanding

i voc g  

 chen   warren        

in the above theorem  it is required that
to compute a two valued model of
justication that justies

pt  

g  

i

is a model of

g  

actually  we do not need

it suces to search for a partial structure and a

so  we can relax this requirement at the expense of also

maintaining justications for literals true in

i

and dened in

g  

corollary      let hg   d   j  ii be an acceptable state of a theory t

   pt     with input

structure iin such that pt is true in i and j justies pt over gd   then there exists a
model m of t that expands i s with s the set of dened literals in jpt  
g expanding iin in which pt is true implies the lack of models
g has no model expanding iin   then it has an unsatisable
core  i e   a set of rules from g such that no model exists that expands iin   hence  it is also
an unsatisable core for t    pt      to nd an unsatisable core  one can  for example 
failure to nd a model of

of

t

expanding

iin  

indeed  if

use techniques described by torlak  chang  and jackson        

    practical justication management for fo id  theories
roughly speaking  our lazy model expansion framework consists of two components 
the one hand  a standard model expansion algorithm that operates on

 pt   g   and  on
gd and lazily

the other hand  a justication manager that maintains a justication over

   

on

filazy model expansion  interleaving grounding with search
grounds

d  

lazy model expansion performs search over the space of acceptable states and

aims at reaching a state where theorem      or corollary      is applicable  to avoid slowing
down the search during model expansion  the work done by the justication manager and
the lazy grounding must be limited  to achieve this  we have designed a system in which the
justication manager has no access to the grounded denition

g

and need not restore its

state when the search algorithm backtracks over the current structure
manager only has access to

i

g

particular  a literal dened in

i 

the justication

and maintains justications that are restricted to

d  

in

is not allowed in a direct justication  our justication

manager maintains the following properties 



literals in direct justications are either open in



all direct justications in
structure



j

gd

or dened in

d  

are kept consistent with each other and with the current

i 

the justication graph dened by

j

has no unfounded literals and is total 

to distinguish acceptable states that meet these additional requirements from acceptable
states as dened in denition      we call them

denition    

 default acceptable state 

 

default acceptable states   we dene them as 

a state

i

hg   d   j  ii

is a default acceptable

state if it is an acceptable state and  in addition      literals in direct justications are either
open in

gd

or dened in

d  

ii

and    

j

justies the set of all literals for which

j

is dened 

it follows that default acceptable states satisfy two extra conditions  they do not justify
literals dened in
consistent 

d

in terms of literals dened in

g  

and dened in

d  

are consistent 

j

is

that are true in

i

and the set of all literals in

for an acceptable state  it suces that the literals in

j

since default acceptable states are acceptable states 

theorem     and corollary     also hold for default acceptable states 
during standard model expansion  the main state changing operations are to make

i

more precise  by making literals true  either through choice or propagation  and to make

i

less precise  by backjumping  

and model expansion modies

i

when
into

i   

s   hg   d   j  ii is a default acceptable state
 
the new state hg   d   j  i i is not necessarily a

default acceptable state  the following propositions identify situations where acceptability
is preserved 

proposition      let hg   d   j  ii be a default acceptable state  l a set of literals unknown
in i and i   the consistent structure i  l  if  i  literals of l either are not dened in d
or have a direct justication in j and  ii  no direct justication in j contains the negation
of a literal in l  then hg   d   j  i   i is a default acceptable state 
proof 

i

as the literals true in

    that all literals true in
in

j

are consistent with

all literals true in

i 

i 

i 

i

d have a direct justication  it follows from
d have a direct justication  as justications
they are also consistent with i    hence  j justies

and dened in

and dened in

ii

then  by     

and dened in

d  

proposition      let hg   d   j  ii be a default acceptable state  then hg   d   j  i   i with
i    p i is a default acceptable state 

   

fide cat  denecker  stuckey   bruynooghe
proof 
of

i  j

j

the justication

justies all literals dened in

justies all literals dened in



and true in

in a default acceptable state  literals dened in
of literals dened in
hidden loops over
both

g

and

d  

d  

gd  



and true in

i 

as

i 

is a subset

i   

g

are not allowed in direct justications

this restriction is quite limiting  see next section  but is to avoid

such loops can only be detected by maintaining a justication over

which our current implementation does not do  several methods exist to

l dened in g can be allowed in direct
d   provided it can be established that l s justication cannot loop over gd  
one case is when the body of the rule of l has no dened literals  a step further is to analyze
the dependency graph  a literal dened in g can be allowed in the direct justication of
a literal dened in d provided both literals do not belong to the same strongly connected

extend the class of default acceptable states  literals
justications of

component of the dependency graph  in that case  they cannot be part of the same cycle 

    an example
in the rest of the section  we illustrate the behavior of lazy model expansion on an articial
example  constructed in such a way that all main features are illustrated  in the next section 
the processes involved are described in more detail 
we focus on the operation of the justication manager and its interaction with the
solving process  the manager is activated in an unacceptable state  either when the solver
falsies a literal that occurs in a direct justication of

j

l dened in
for l to extend

or when a true literal

d is not justied by j   one option for repair is to search for a justication
j   in general this problem is as hard as the model expansion problem itself 
corollary       our manager only searches
extend

j 

and if it does not nd one  it grounds l s denition and moves it to

our example uses a theory

t

as shown by

locally for a direct justication that justies l to
g  

which states that a symmetric graph  edge    exists where

r   
d    d            dn   and
the equality predicate as the identity relation on d  below omitted in i    predicates edge  r
and root are not interpreted  r and root are dened  in particular  root is dened as the
singleton  d     specifying the root as d   

at least one node other than the root node  predicate
from the root node  the input structure

p
t











pt
c 
c 
x  d   root x 
x  d   r x 

i

root   

is reachable  predicate

interprets the domain as

 c   c 
 x  d   root x   r x 
  x y   d    edge x  y   edge y  x 
 x   d 
 root x   y  d   edge x  y   r y 

   
   
   
   
   













the lazy mx algorithm proceeds as follows 
   the initial default acceptable state is
and

hg   d   j  ii

in which

g   i

and

j

are empty 

d    

   propagation over

 pt   g  

sets

i

to

 pt   

this expands the structure

the conditions of proposition     are no longer satised 

   

i 

but now

the resulting state is not

filazy model expansion  interleaving grounding with search
acceptable since

j 

pt

is true and dened in

d

while it has no direct justication in

j with a direct justication for pt  
the atom pt has a unique direct justication  c    c    but extending j with it does
not restore  default  acceptability since c    c  have no direct justication in j and
pt remains unjustied  therefore  the alternative is taken and rule     is moved to
g   now  a default acceptable state is obtained 
one option to repair acceptability is to extend

i to  pt   c    c     now c  and c  have to be justied  consider
c  and rule      as edge is open  our manager can build the direct justication
 edge d  d       d  d     d     that sets all negative edge literals true  and extends j
with it  setting all positive edge literals true would be equally good   this justies c 
and avoids the grounding of the rule dening c   

   unit propagation sets
rst

   literal

c 

cannot be justied  with the local approach  since each of its direct jus 

tications contains unjustied dened literals 

however  as rule     is existentially

quantied  one can avoid grounding the whole rule by performing a tseitin transformation to isolate one instance and then only ground that instance  for the purpose

d   

  root d     r d      t
  a 
 x  d    d      root x   r x    b 

of illustration  we make the  bad  choice of instantiating



c 
t

rule   a  is moved to

g

x

with

and a default acceptable state is reached 

   we are in an acceptable state in which no further propagation is possible  so a choice
has to be made  as

c 

is true  the body of rule   a  has to become true  preferably

not selecting a tseitin  this would trigger more grounding   the rst disjunct is selected
by model expansion and propagation extends the structure with
the literal

root d   

denition of
dening

root

root

d by
  d    d     is

is dened in

unique direct justication

root d    and r d    

rule     but cannot be justied since its
false  the manager partially grounds the

and splits it up in a ground rule   a  and a non ground rule   b 

for the other domain elements 



root d     d    d    a 
x  d    d      root x   x   d    b 



g   note that root d    is justied by  d    d    in gd   hence
root d    in direct justications in d   whenever grounding has been

rule   a  is moved to
it is safe to use

done  the justication manager is interrupted by propagation  which can infer the truth
of additional literals  or detect an inconsistency  which will result in backjumping  
in both cases  the manager has to resume the revision of the justication afterwards 
until an acceptable state is reached 
unacceptable  due to the unjustied

here  even though the resulting state is still

r d     

g
root d    and a conict 

the creation of the new rule   a  in

interrupts the manager  propagation using the new rule derives

i    pt   c    c     the subsequent propagation sets the structure
 pt   c    c    root d     t    still not in a default acceptable state  t is not justied  

after backtracking to

i

to

rule   b  is further transformed to split o another instance 



t   root d     r d      t 
  ba 
t   x  d    d    d      root x   r x    bb 

   



fide cat  denecker  stuckey   bruynooghe
g  

rule   ba  is moved to

while rule   bb  remains in

d  

this state is default

acceptable 

t    choosing the rst disjunct in rule   ba 
r d     the literal root d    is dened in d   but is
justied by the direct justication   d    d      the literal r d    cannot be justied
by a direct justication  as all edge literals are false in the current justication graph 
and rule     is transformed to split o the instance for d    actually  this instance in

   again  the search avoids the new tseitin
which propagates

root d   

and

turn has a disjunctive body with a complex subformula  so to avoid grounding the
subformula  we break it up in two parts and introduce another tseitin 







r d     root d     t 
  aa  


t   y  d   edge d    y   r y 
  ab 
 x  d    d      r x   root x 





 y  d   edge x  y   r y 
  b 
rule   aa  is moved to

g  

the others remain in

d  

i is  pt   c    c    root d     t  root d     r d      hence propagation on rule   aa  in g extends it with t    there is no direct justication justifying
t  and  hence  rule   ab  is partially grounded by splitting o the d  case 


t    edge d    d     r d      t 
  aba 
t   y  d    d      edge d    y   r y    abb 

   the current structure

rule   aba  is moved to

g

while rule   abb  remains in

   the search selects the rst disjunct of

r d    
it 

the literal

extending

j

r d   

is dened in

d  

t   s rule body and propagates edge d    d    and
d   but  root d     is a direct justication for

with this direct justication yields an acceptable but not default

root d    is dened in g   however  root d    is justied in gd  
j with this direct justication as discussed earlier  now the
justication manager faces a new problem  the true literal edge d    d    is in conict
 
 
 
with the direct justication  edge d  d      d  d    d   of c   rule       to handle
this conict  it splits o the aected instance  x   d    y   d    from this rule 


c    edge d    d     edge d    d      t 
  a 
t    x y   d      d    d       edge x  y   edge y  x    b 

acceptable state  since

making it safe to extend

g while rule   b  remains in d   the direct justication of
 edge d  d       d  d     d      d    d       the unaected part of the direct
justication of c    this restores acceptability 

rule   a  is moved to

t 

is set to

   propagation on rule   a  extends

i

with

edge d    d   

and

t    the literal edge d    d    
t   rule   b    to resolve

which is true  is in conict with the direct justication for

it  the justication manager partially grounds rule   b  and splits o the instance

 x   d    y   d    as follows 


  ba  
 t    edge d    d     edge d    d      t 
t    x y   d      d    d      d    d      


edge x  y   edge y  x    bb 

   

filazy model expansion  interleaving grounding with search
g while rule   bb  remains in d   t  inherits the direct
edge d    d    removed  propagation on rule   ba  extends i
state is acceptable  with t  dened in d but justied 

rule   ba  is moved to
justication of
with

t   

by now 

t 

with

the resulting

g

consists of the rules        a     a     ba     aa     aba     a   and   ba   and

d consists of the rules   b     bb     b     abb   and   bb   the cur pt   c    c    root d     root d     edge d    d     edge d    d     r d     r d    
t  t    t    t     a model of pt  g  
of these literals  root d     r d    and t  are dened in d   literal root d     dened
by rule   b  has   d    d     as direct justication  literal r d     dened by rule   b   has
 root d    as direct justication  literal t    dened by rule   bb  has as direct justication
the set of all negative edge literals over d except edge d    d    and edge d    d     to obtain
a full model of the theory  i is extended with the literals of the above direct justications 

the residual denition
rent structure

i

is

in this case  this assigns all open literals and the model can be completed by the wellfounded model computation over

gd  

actually  this can be done without grounding the

denition  jansen  jorissen    janssens        

   justication management
in section      we have instantiated our general framework  developed in section      for a
justication manager that only has access to

d  

in the example of section      the justi 

cation was constructed on demand  i e   each time some literal needed a  dierent  direct
justication  the body of its dening rule was analyzed and a justication was extracted  if
that failed  part of the rule was grounded  this was called the
imagine a

global approach 

where more rules of

d

local approach 

one can also

are considered at once in an attempt to

select direct justications that minimize the grounding of the rules as a whole  obviously 
a global approach will be more time consuming  so should not be applied every time an
adjustment of the justication is required  in this section  we describe both approaches 
before describing the algorithms  we introduce some notations and assume some normalizations have been done  the function nnf reduces a formula to its negation normal form 

s a set and s a single element  s   s and s  s are used as shorthands for s   s  and
s  s   with j a justication  we denote by j l  d  the graph identical to j except that l
is now justied by d  we assume quantiers range over a single variable and variable names
with

are not reused in a formula  furthermore  we assume basic reductions have been applied to
formulas  e g  

 

reduces to

  x     

reduces to

t 

   

    the local approach
algorithm   shows the top level of the lazy mx model expansion algorithm  taking as input
theory

 pt    

and

iin   denitions d and g are initialized with  and
i is initialized as iin   the set of ground sentences tg
the initial justication j is empty  an auxiliary  fifo 

is initialized as empty 

the latter keeps track of literals for which the direct

and input structure

the empty denition  respectively  and
is initialized with the fact
queue

qch

pt

justication needs to be checked 
the main loop performs model expansion over

tg  g  

interleaved with work by the

justication manager towards establishing a default acceptable state  the model expansion

   

fide cat  denecker  stuckey   bruynooghe
part consists of propagation  the call to propagate   the test on whether the current state
is inconsistent  with learning and backjumping   the test on whether a model of

tg  g

has been found  returning the model and the justication  and of the choice step that

tg  g

selects a literal unknown in

and assigns it a value 

propagation returns literals

that are entailed by a ground theory over a  partial  structure  for example by applying
unit propagation and unfounded wellfoundedness propagation  marin et al          the
test for a model is only performed in a default acceptable state  i e   when the queue

qch

is empty   if the test succeeds  this ensures that the well founded model computation can
expand the current structure

i

extended with the direct justications of all literals into

a model of the whole theory  also the choice step only takes place in a default acceptable
state  this ensures that the search space is limited to the state space of default acceptable
states 

the justication manager is activated when a propagation or choice step assigns

a literal
valid 

if

l 
l

by calling check literal  it is checked whether the current justication remains
is dened in

to the queue

qch

d

and has no justication  it needs a justication and is added

for further processing by the justication manager 

if

l

 
justication of another literal l   the justication becomes inconsistent with
another justication so it is also added to

qch  

occurs in the

i

and

l 

needs

the further processing is done by selecting

elements from the queue and calling the lazy ground function 

the latter function rst

attempts to nd a  dierent  consistent direct justication for l  if that fails  it splits o the
rule instance dening

l

from

d

and partially grounds it  hence

g

is extended  the new

clauses may trigger propagation  therefore the processing of queued literals is interleaved
with propagation and  possibly  with backtracking   note that backtracking might restore
the consistency with

i

of the direct justication

j l 

of a literal

l

on

qch  

      lazy grounding of one rule
the function lazy ground  algorithm    checks whether the literal
tion  if not  it simply returns  otherwise  it checks whether

l

l

needs a direct justica 

has a valid justication  i e  

one that satises the invariants detailed below  if so  it also returns  otherwise  it passes the
rule body that has to be used to construct a justication  the negation of the dening rule
when the literal is negative  to build djust  a function that attempts to nd a valid direct
justication  besides the literal and the rule body  also an initial justication  derived from
the rule body  is passed to build djust  if the latter function is successful  the justication
is updated and lazy ground is done  if not  the direct justication of the literal

false

l

is set to

and split and ground is called to ground part of the rule dening l 

before going into more details  we rst analyze which properties we want to maintain
in the current justication
considered part of

j

j 

the direct justications of literals in the

qch queue
j are 

are not

since they might be invalid  the global invariants of



no literals are unfounded in



the set of literals in

j

 recall  negative cycles are allowed  

j

is consistent 

for each direct justication

s   j l  of j

for some

l

not on the queue  invariants of the lazy

grounding process are 

 s

contains no literals dened in

g

 unless such a literal is safely justied in

discussed before  

   

gd  

as

filazy model expansion  interleaving grounding with search

algorithm    the lazy mx lazy model expansion algorithm 
  function lazy mx  atomic sentence pt   denition   structure iin  
output  either a model of g and j or false

 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  

  
  
  

tg

    pt   

g

while true do

  

  d

  

  j

  

  i

  

iin   qch

  

l    propagate tg  g   i   
i    i  l 
foreach l  l do qch   check literal l qch   
if i is inconsistent then
tg    learn nogood i   tg   
if conict at root level then return false  
i    i at state of backjump point 
else if qch is not empty then
 l  qch      dequeue qch   
lazy ground l  
else if i is a model of tg  g then
return i   j  

else

select choice literal l 

i

  

i   l 

qch   check literal l qch   

function check literal  literal l  literal queue qch  
data  global d and j output  updated queue
if l dened in d and j l    undef then qch    enqueue l qch    
foreach l  such that l  j l    do qch    enqueue l   qch    
return qch  

algorithm    the lazy grounding of a literal 
  function lazy ground  literal l 
data  global d   j and i
 
if l  i and l dened in d then
 
if j l  exists and obeys the invariants then return 
 
else

 
 
 
 
 
  
  

 



   body of the rule dening l 

if l is a negative literal then

    nnf   
dj    build djust l    init just l   
if dj    false then j    j l  dj   return 

else

j

 

j l  false  

split and ground l  

   

 

fide cat  denecker  stuckey   bruynooghe


literals in
the queue

s that
qch  

are dened in

d

either have a direct justication in

j

or belong to

qch

these invariants imply that a default acceptable state is reached when the

queue is

empty  indeed  it follows from the invariants that the current justication is total in that
situation and hence all literals that have a direct justication are justied  denition      
due to the policy followed to queue literals  the current justication is also consistent with

i

while all literals true in

i

and dened in

d

have a justication  hence

hg   d   j  ii

is a

default acceptable state 

      building a direct justification
the purpose of build djust  algorithm    is to extend
for literal

l

d  

dened in

i 
formula 

here

l

j

with a suitable direct justication

is a literal for which

j l 

is currently undened or is

i

inconsistent with

it is a recursive function which takes three parameters      the literal

l 

to be made true by the direct justication  initially the whole body of

ii

    the

the rule dening the literal  note that the initialization takes the negation of the rule when

iii  a description of the direct justication derived so far  initialized

the literal is negative    

through init just l   for this algorithm  we assume

 is such that dierent quantiers range

over dierent variables 
before going into details  we discuss how to represent direct justications 

basically 

we could represent a direct justication as a set of ground literals  however  this set can
be quite large and using a ground representation might hence defy the purpose of lazy

hl  bi with l a set of
b a set of bindings xi  di with xi a variable and di
a domain  a set of bindings b    x   d            xn  dn   represents the set of variable
substitutions sb     x   d            xn  dn     di  di for each i      n    the set of ground
literals represented by hl  bi is then  l   l  l and   sb    the direct justication of a
literal p  d            dn    dened by a rule x  d   p  x     is initialized by init just l  as
h   x    d             xn   dn   i  in eect  b allows to identify the relevant rule instantiation

grounding 

instead  we represent a direct justication as a pair

possibly non ground literals and

by providing the appropriate variable instantiation from the domains  while the set of literals
is empty 
the build djust algorithm searches for a set of literals making
recursively calling itself on subformulas of
larger justication for

 





true 

it works by

and composing the results afterwards into a

when no such set of literals is found  for example because none

exists that is consistent with all other direct justications 

false

is returned 

the base case is when the formula is a literal  to make that literal true  all instances of
the literal under the set of bindings

b

must be true  hence  the set of literals

l

is extended

with the literal itself  the resulting direct justication has to satisfy all invariants  which is
checked by the call to valid  it returns

true for a call valid l  dj  if dj
l and j l  dj  satises

to be  part of   a direct justication for

satises the invariants
the invariants on the

justication 
a universally quantied formula
quantied variable 

x  d 

x  d   

has to be true for each instance of the

hence  in the recursive call  the set of bindings

b

is extended with

for an existentially quantied formula  it suces that one instance is true  hence 

a minimal approach is to try each instance separately until one succeeds  if all fail 

   

false

is

filazy model expansion  interleaving grounding with search

algorithm    the build djust algorithm 
  function build djust  literal l  formula  and justication hl  bi 
input  b binds all free variables of 
output  either a direct justication or false
 
switch  do
 
case  is a literal
 
if valid l  hl      bi  then return hl      bi 
 
else return false  
 
case x  d    
 
return build djust l    hl  b   x  d   i  
 
case x  d    
 
if large d    then
  
return build djust l    hl  b   x  d   i  
  
foreach di  d  do

  
  

hl    b   i    build djust l    hl  b   x   di   i  
if hl    b   i  
  false then return hl    b   i 

  
  
  
  
  
  

return false  
case           n
foreach i      n  do

  
  
  
  
  

return hl  bi 
case           n
foreach i      n  do

  

hl    b   i    build djust l  i   hl  bi  
if hl    b   i   false then return false  
else hl  bi    hl    b   i 

hl    b   i    build djust l  i   hl  bi  
if hl    b   i  
  false then return hl    b   i 

return false  

   

fide cat  denecker  stuckey   bruynooghe
returned  note however that we do not want to iterate over each domain element if
large  which would be similar to constructing the grounding itself  instead  if
extend the binding with

x  d 

d

d

is

is large  we

conjunction is similar to universal quantication  except

that explicit iteration over each conjunct is needed  as soon as one conjunct fails  the whole
conjunction fails  disjunction is similar to existential quantication with a small domain 
note that build djust is non deterministic due to choices for a domain element to justify
an existentially quantied formula  or for a disjunct to justify a disjunction 

example     

consider the following rule over a large domain

d 

h  x  d   p  x    y  d   q x  y   r x  y  
assume that

j is empty and we
h p  x     x  d i

have no loops to keep track of 

applying build djust

p  x  in the body is chosen  this
corresponds to the direct justication  p  x    x  d   alternatively  if the second disjunct is chosen  it returns h q x  y   r x  y     x  d  y  d i  which represents the direct
justication  q x  y    x  d  y  d    r x  y    x  d  y  d  
to

h

returns

if the rst disjunct

      partially grounding a rule
the last bit of the lazy model expansion algorithm handles the case where no justication
can be found and the denition of a literal

l

is to be grounded 

a straightforward way

would be to call one step ground on the rule dening l  and store the result in

g

and

d  

however  in many cases such an operation results in too much grounding 

example     

of the form x  d   p  x    in a situation where no
p  d   applying one step ground to r  would instantiate
x with all elements in d  resulting in  d  rules  while in fact it suces to split r  in two rules 
one for the instance x   d and one for the remainder  another example applies to a rule r 
of the form h  x  d   q x   r x  and a direct justication j h     q x    x  d  
when q d  becomes false  the justication manager may need to ground this rule  applying
one step ground to it would instantiate the universally quantied x with all elements in d  
instead  it is better to split o the instance for x   d and to introduce a tseitin t for the
remainder  producing h   q d   r d    t for g and t  x  d  d   q x   r x 
for d   the direct justication for t can be obtained incrementally by removing q d  from
that of h   as discussed in section       
consider a rule

r 

justication can be found for atom

the split and ground algorithm  algorithm    has to ground part of the rule dening
a given literal
dening

d

l

l 

say


p d  

the rst step is to split o the rule instance for which the rule

has to be grounded  the call to split  

that denes


p d  

let

we then replace that rule by

additionally return the rule


p d   x d  

x  d   p  x    be the rule in
x  d  d   p  x    in d and

afterwards  we apply one step ground to the

latter rule and add the computed rules to either

g

or

d    

the result of split and ground is that denition
one  the limit is a ground denition
equivalent with

gd

in which

gd is more ground than the previous
d is empty and g is strongly voc   

 

   recall  the head of a new grounded rule is always dierent from the head of already grounded rules 

   

filazy model expansion  interleaving grounding with search
algorithm    the split and ground algorithm 
  function split and ground  literal l 
input  l is dened in d
result  update to g   d   j   and qch
 
 

r    split l      split updates d
  g    d      one step ground r  
g    g    d    d   

 

even if no justication was found  we can do better than just splitting o

l

and applying

one step ground  as shown in example      first  splitting can be made signicantly more
intelligent  which is discussed in section        second  we can improve one step ground to
only ground part of expressions if possible  which we describe below 

improving one step ground 
all subformulas instantiations of
result consists of

 d 

l   iterates over
x  d   p  x   the

applying one step ground to a rule

 

for example if



is the sentence

new rules and as many new tseitin symbols  instead  depending on

the value of l  it is sucient to introduce only one  or some  of these subformulas  as shown
in algorithm    which extends the switch statement of one step ground with two higherpriority cases 

if

l

is true  it is sucient to ground one disjunct existential instantiation

and to delay the rest by tseitin introduction  if

l

is false  we take a similar approach for

conjunction universal quantication 

algorithm    additional cases for the one step ground algorithm 
  switch r do
 
case l            n and i l    t

 
 

 
 
 
 

choose

i      n  

return h l  i  t     t 
case l  x  d    and i l    t

w

choose

j     n i j  i 

d  d 

return h l   x d   t     t
analogous cases for



and



in

 x  d  d    i 
combination with i l    f  

      algorithmic properties
correctness and termination of the presented algorithms is discussed in the following theorem 

theorem      correctness and termination   if lazy mx returns an interpretation i   then

expanding i with the literals in the direct justications of j   applying the well founded evaluation over gd and restricting it to voc t   results in a model of t   if the algorithm returns
false   no interpretation exists that is more precise than iin and satises t  

   

fide cat  denecker  stuckey   bruynooghe
algorithm lazy mx terminates if i is over a nite domain d  otherwise  termination is
possible but not guaranteed  
proof 

if lazy mx returns an interpretation

i  i

is a model of

g

and

qch

is empty  given

the properties of split and ground  after applying lazy ground for a literal l  either
valid justication or is dened in
state and  by theorem     
returns

false  

i

g  

gd

qch

has a

is empty  we are in a default acceptable

can be expanded into a model of the whole theory  if lazy mx

it has been proven that

be no models of

hence if

l

and hence

t

g

has no models in

iin  

in that case  there can also

iin  

also has no models expanding

without calls to lazy ground  the search algorithm terminates for any nite
tion lazy ground itself produces an ever increasing ground theory
as limit  hence  lazy mx always terminates if

d

d

is nite  if

g

g   the func 

with the full grounding

is innite  the limit of

g

is

an innite grounding  so termination cannot be guaranteed 

      symbolic justifications  incremental querying and splitting
the algorithms presented above are sound and complete 

however  they can be further

improved by taking the formulas from which justications are derived into account 

symbolic justications and incremental querying 
for  subformulas of   a formula

example     

 

when multiple justications exist

grounding can be further delayed 

consider the formula

x  d   p  x   q x  

where both

h p  x     x  d i

h q x     x  d i are justications  from that  we could derive the justication  for
d  d  make either p  d  or q d  true  hence  more grounding is necessary only when
both p  d  and q d  become false for the same d 

and

each

we can do this automatically by changing build djust as follows 



the algorithm is allowed to select multiple disjunctions   existential quantications
even if a valid justication was already found for one  lines    and     



build djust no longer returns a justication  but a symbolic

justication formula

that

entails the original formula  the formula is built during build djust and reects the
subformulas instantiations that have been selected 

from

 

the justication itself

   for
 p  x    x 
x  d   p  x   q x  

can be derived directly as the set of non false literals in the  full  grounding of
example  for a formula

d  


x  d   p  x   q x  

instead of the justication

build djust might now return the justication formula

the validity check  valid  is extended to return false if the justication formula is false 

by allowing more complex formulas  instead of a conjunction of universally quantied literals   the validity check whether a formula has become false after incremental changes
to

i

is now more expensive  this is in fact an

incremental query

problem  in the exper 

iments  we limit the depth of the allowed formulas and use a straightforward  expensive 
algorithm that evaluates the whole formula whenever an assignment can falsify it 
   it is possible to change the integration of

lazy ground in lazy mx to guarantee termination if a nite

model exists  see section     

   

filazy model expansion  interleaving grounding with search
body splitting 

as described in algorithm   of section        split simply splits o the

rule instance that denes l  then one step ground grounds this rule instance step by step 
in accordance with the structure of the formula  however  when the grounding is triggered
by a conict with the current justication  one step ground is blind for the origin of the
conict 

by using the conicting literals  one could focus on grounding the part of the

formula that contributes to the conict  one can do so by restructuring the rule in a part
to be grounded  that contains the conict  and a part not to be grounded  for which the
old justication can be adjusted to still apply 

the latter part can then be split o by

introducing new tseitins and the transformation is called body splitting  this approach can
be inserted in algorithm   after the call to split  for this  the original justication  call it

jold  

is passed as an extra argument to split and ground 

example     

h  x  d   p  x   let h p  x     x  d i be the justication for h true in i   when p  d  becomes false  it is easy to see that we can split o the
violating instantiation by rewriting the original rule into h  p  d   t and adding the
rule t  x  d  d   p  x   crucially  a justication for the second part can be derived
from the original justication  namely h p  x     x  d  d i  the second part can hence
be added to d and its justication to j while the rst part is added to g  
consider the rule

r and its direct justication jold can be done in an ecient way 
v is a true domain literal in the partial structure and that the direct justication
of rule r contains its negation v   the implementation is such that the binding s  for
which the justication instantiates to v can be extracted from the representation of the
direct justication of the rule  for simplicity  assume  x   d            dn   is the single such
instance  a recursive algorithm visits the formula  in the body of r depth rst  whenever
a quantication x  d    is encountered with x equal to xj  x  it is replaced by
 x  d  dj       x   dj    then a tseitin transformation is applied to the left hand
this revision of a rule

assume that

conjunct and the algorithm recurses on the right hand conjunct with what remains of the
binding  the new rule dening the new tseitin has jold v as a direct justication  similarly 
an existential quantication is replaced by a disjunction 

the result is a set of new rules

for which no new justication has to be sought and a smaller rule

r 

which is passed to

one step ground  correctness follows from the fact the jold  v is a valid justication  none
of the new rules contains

example     

v 

and from the correctness of the tseitin transformation 

in example      justications were sought for

h

in the rule

h  x  d   p  x    y  d   q x  y   r x  y   
j    q x  y    x  d  y  d    r x  y    x 
i   and l   q d    d    becomes false  j is no longer
consistent with i and cannot be repaired  j  l  however  is still consistent with i   but is
not a justication of the whole body  on the other hand  j  l is a justication for the
subformula p  x   y  d   q x  y   r x  y  for each instantiation of x dierent from
d    consequently  we can split the quantication x  d   into x  d  d  and x   d 

assume we selected the justication

d  y  d  

when

p  d   

is true in

and apply a tseitin transformation to the former  afterwards  we recursively visit the latter
formula and apply a similar reasoning to the existential quantication  the operations on

   

fide cat  denecker  stuckey   bruynooghe
  split   
x  d  d 

 





p  x 

y  d


q x  y 

  split   

p  d   

y    d  d 

 





r x  y 
q d    y    

r d    y     q d    d    r d    d   

x  d   p  x   y  d   q x  y   r x  y  is split for a violating
q d    d     the original justication without q d    d    is a justication of

figure    the rule body
literal

the left hand side of all splits  with the justication formula shown in blue  the
remaining non justied formula is shown in red 

the formula are illustrated in figure    the result consists of the following rules  where the
rule for

h

is now even ground 




 h  t    p  d      t    q d    d     r d    d       






t   x  d  d    p  x   y  d   q x  y   r x  y  




 t  y  d  d   q d   y   r d   y  

 
 
 
 
to further optimize the traversal of the formula
the path taken through the parse tree of

example     



 

build djust can be extended to store

and the direct justications of the subformulas 

c    x y   d    edge x  y   edge y  x  has to be
justied  j is empty and i does not interpret edge  the build djust algorithm recursively
visits the body of the rule until edge x  y  is returned as it is a valid literal to use  going
up one level  we store that for edge x  y   edge y  x   we selected  edge x  y    assuming
no more disjuncts are selected  edge x  y  is returned again  going back up through both
quantications  we store that  for both quantications  we selected d as the set of relevant
 
domain elements  and build djust returns the justication formula  x y   d   edge x  y  
assume the rule

if build djust is given access to
direct justication 

jold  

similar optimizations are possible for repairing a

consider again example      but assume

p  d   

is unknown in

i 

in

this case  the left branch of figure   can also be transformed in a rule with a still valid 

p  d    as direct
justication for the rule h  t    p  d      y   d  d      q d    y   r d    y     where
t  is as in example     

direct justication  for the right branch  a repair is to select the disjunct

    the global approach
finding justications using the greedy local approach can easily lead to more grounding than
necessary  consider for example the sentences

   

x  d   p  x 

and

x  d   p  x   q x  

filazy model expansion  interleaving grounding with search
applying the local approach to the second sentence rst  with an empty
the construction which makes atoms over

p

j   

might result in

false  then applying the local approach to the

rst sentence nds no valid justication for it  so it has to be fully grounded  the global
approach takes a set of rules as input and tries to select direct justications for them such
that the

expected

grounding size of the whole set is minimal 

we cast the task  called the

optimal justication problem  as a problem on a graph as
rule nodes r and justication nodes j  

follows  the graph consists of two types of nodes 

a justication node is a symbolic set of literals representing a possible justication  for the

i    a rule node is a pair
t  t  f   u   a pair hr  ti for a rule r with head l
expresses that there exists a direct justication for l  the pair hr  f i that there exists a direct
justication for l and the pair hr  ui that r has no justication 

literals dened by a rule in

hr  ti

r

of a rule

in

d

d  

given the current partial structure

and a truth value

there are three types of edges 

 valid edges

between a rule node

 the negation of   the head of

 conict edges

hr  ti  hr  f i  and a justication node j

where

j

justies

r 

i

ii

between     rule nodes of the same rule with dierent truth value     

iii  a rule node hr  ti  hr  f i  where
l  l   and  iv  a rule node hr  ui 

justication nodes that contain opposite literals   

r

denes

where
 or

r

l 

l 

and a justication node that contains

denes

l 

and a justication node that contains

or

l

 a conict because

l

hr  ti  hr  f i 

j

needs a justication  

 depends on edges

between a justication node

contains negative  positive  literals dened by
the aim is then to select subsets



l

rsel  r

and

j and
r 

jsel  j

a rule node

where

such that

each selected rule node is connected with a valid edge to at least one selected justication node 



no conict edges exist between pairs of selected nodes 



neither positive nor mixed cycles exist in the subgraph consisting of the valid and
depends on edges between the selected nodes 

from a selection

 rsel   jsel  

extracted as follows 
rule

r

such that

satisfying these constraints  an initial justication

a literal

hr  ti  hr  f i 

l  l 

can be

is a selected rule  its direct justication is the union of the

justications of the justication nodes in
edge 

j

is given a direct justication if it is dened by a

jsel

connected with

hr  ti  hr  f i 

through a valid

moreover  all literals dened by rules for which no rule node was selected can be

added to the initial

qch

queue  to be handled by the local approach  as a complete solution

must have a justication for them  when

hr  ui

is selected  it means that the grounding of

instances of the rule is delayed until the literals it denes become assigned 
this type of problem is somewhat related to the np hard

hitting set

 or

set cover  

problem  karp         given a set of top and bottom nodes and edges between them 
the task is to nd a minimal set of bottom nodes such that each top node has an edge to at
least one selected bottom node 

   

fide cat  denecker  stuckey   bruynooghe
hg   d   j  ii  the input for the optimal justication
d   a node is constructed for each of the
the truth value is known in i   and also their conict

given a default acceptable state

problem is generated as follows  for any rule in
three truth values  only one when
edges are added 

valid edges and justication nodes are obtained using a  straightforward 

adaptation of build djust that returns a set of possible justications that make the head of
a rule true  false   e g   for a rule

p  x 

x  d   p  x     build djust is called with the literal
 x  d   conict and depends on edges are derived

and the binding is initialized at

by checking dependencies between justications and between rules and justications 

to

keep this ecient  it is done on the symbolic level 

example     

pt   c 

and

c 

 x  d   root x   r x 
  x y   d    edge x  y   edge y  x 
 x   d 
 root x   y  d   edge x  y   r y 

   
   
   
   






consider the theory of our running example  after

propagated to be true  denition






c 
c 
x

d
 
root x 



x  d   r x 

d

have been

is then





the associated optimal construction set input is shown in figure    note that in rule

c  and c  are true in i  
root x  nor root x  can be

nodes  we use the dened head literals to identify the rule  literal
hence there is only one rule node for rules     and      neither
justied for all

x  d 

hence there is only a

hroot  ui

tuple 

there are four solutions that are subset maximal with respect to rule nodes  namely the
following rule node selections 

 hr  ui   hroot  ui   hc    ti 

 a 

 hr  f i   hc    ti 

 b 

 hr  ti   hc    ti 

 c 

 hc    ti   hc    ti 

 d 

for each of these  multiple justication selections are possible  also shown in figure    
for

c   

we have to select justication

 iv  

but for

c 

we can choose from

 v 

or

 vi 

 but

not both  
the objective is then not to maximize the number of selected rule nodes  but to minimize
the expected grounding size 

to obtain an estimate of the expected grounding size  the

following conditions were taken into account 



it should depend on the size of the grounding of the rule 



assigning multiple justications to a rule should result in a lower estimate as the rule
will only be grounded when all are false 



variables occurring in multiple justications result in less matching instantiations 



in most practical applications  the number of false atoms far exceeds the number of
true ones in any model  hence  positive literals in a justication should have a higher
cost than negative ones 

   

filazy model expansion  interleaving grounding with search
hr  f i

h root x   edge x  y     x  d  y  d i

hr  ui

h root x   r x     x  d i

hr  ti

h root x     x  d i

hc    ti

h root x   r x     x  d i

hc    ti

h edge x  y     x  d  y  d i

hroot  ui

h edge x  y     x  d  y  d i

 i 

 ii  

 iii 
 iv 
 v 
 vi 

figure    the graph that is part of the input to the optimal justication problem of example     

rule nodes are shown on the left  justication nodes on the right 

valid edges are shown in green  conict edges in red and depends on edges in blue 
for readability  conicts between justications and unknown rule nodes are not
shown 

we approximate the expected grounding size with the function
input a rule

r

 with head

h  

j 

which takes as

n

the selected type of justication  rule not selected      no

justication  u   a justication for
cations

expsize

h  t 

or a justication for

h  f   

and the set of justi 

the function returns the expected grounding size of the rule  size r   dened

below  weighted depending on the type of justication  the weights are derived from two
estimates 

pval

ptr

is the probability an atom will become assigned and

is the probability of

n

an assigned atom to be true  hence  as dened formally below  for non delayed rules     

u

the full size is used  a rule without justication     is weighted by

t

    is weighted by

ptr  

product over the justications
namely

pt

literals in

f

a false one     by

j

in

j 

   ptr  

a true justication

the latter two weights are multiplied by a

each factor of this product is a sum of two terms 

times the number of negative literals in

j 

pval  

j

and

   ptr

times the number of positive

the eect is that the expected size decreases as the number of justications

increases and that the expected size increases as a justication has more literals 

expsize  r  n      size r 
expsize  r  u      size r   pval
expsize  r  f   j    size r   pval      ptr   

y

     ptr     pos 

lits 

 j 

jj

  ptr   neg  lits   j  
y
expsize  r  t  j    size r   pval  ptr 
     ptr     pos  lits   j 
jj

  ptr   neg 
for the probabilities  we assumed

pval

lots of literals will not get a value  and

lits 

 j  

to be small  currently      to reect the hope that

ptr

is less than half  to reect that atoms are more

   

fide cat  denecker  stuckey   bruynooghe
often assigned false than true  the function

size

is dened below  the function returns the

number of atoms in the grounding of a rule or formula  except for existential quantication
and disjunction  for these  we take into account that they can be grounded only partially
using tseitin transformation  by taking the logarithm of the total grounding size 

size l     
size l      size      
size x  d       d  size  
x
size i  
size           n    
i   n 

size x  d       log d   size  
p

i   n  size i  

size           n     log n  

n

solutions to the optimal justication problem should minimize the term

x

expsize  r  t r   j r  

rd
with

t r 

the type  t 

f 

or

u 

and

j r 

the justication of the literal dened by

r 

example      continued from example       the size of rule c  is   log d    that of c 

  d  log     that of root is d       and that of r is d   log      log d      
consider assigning justication  iv  to c    this results in an expected cost for that rule of
     log d               as the construction relies on making r true   additionally  it
would force the grounding of the rule dening r  increasing the cost with the size of the
rule for r  the optimal solution for the problem in figure   is then rule node selection  a 
 
with justication  vi  for c    its cost is the sum of      d  log          for justication
 vi   and     log d      the expected size of the rule for c     now  only the rule for c 
is

has to be passed to the local approach 
to solve the optimal justication problem 

idp s

optimization inference itself is applied

to a  meta level  declarative specication of the task 

 

for larger theories

t 

the problem

turns out to be quite hard  so two approximations were considered to reduce the search
space 

first  the number of selected justications for any rule was limited to   

as the values of

size r 

can grow quite large  the approximation

standard approach   rounding to integer values was applied as

dlog size r  e

idp s

second 

is used  a

support for oating

point number is still preliminary  the resulting specication could be solved to optimality
within seconds for all tested theories  during lazy model expansion  the global approach is
applied in the initial phase when all tseitin literals representing sentences in the original
theory have been propagated true 

   heuristics and inference tasks
this section discusses how to tune the lazy grounding and the search heuristics of the
underlying sat solver to obtain an eective implementation of lazy model expansion  we
   the specication is part of

idp

 s public distribution 

   

filazy model expansion  interleaving grounding with search
also describe a few other inferences tasks beyond model expansion that are useful in the
context of lazy grounding  a few less important issues are discussed in appendix a 

    heuristics
heuristics play an important role in the lazy grounding algorithms  as they serve to nd
the right balance between how much to ground and how long to search  we rst discuss
how our heuristics were chosen  afterwards  we discuss an alternative approach to minimize
grounding 

      the balance between grounding and search
the algorithms leave room for a number of heuristic choices that can have an important
eect on the performance 

we now briey discuss these choices 

as a guideline for our

decisions  the following principles are used 



avoid leaving the search process without enough information to make an informed
decision  for example  avoid losing too much  unit  propagation or introducing too
many tseitin symbols 



prevent creating a grounding that is too large  this may for example happen as the
result of a very long propagate ground sequence 

recall  the goal is not to create a minimal grounding  but to solve model expansion problems
while avoiding a too large grounding 
below  we introduce a number of parameters that aect these heuristics 

the exact

values used in the experimental evaluation for the parameters introduced below are specied
in appendix a 
in split and ground  when handling a disjunction or existential quantication  there is
a choice on how many disjuncts to expand  if we expand one instantiation at a time for a
rule

h  x  d   p  x  

as done in algorithm    lines   and     iterative application results

in a ground theory

h  p  d     t 
t   p  d     t 
t   p  d     t 
 
 
 

tn  x  d    d    d            dn     p  x  
a sat solver such as minisat  which is used in the
the

p  di  

idp

system  initially assigns

atoms  such a choice triggers an iteration of propagation and grounding 

f

to

the

resulting thrashing behavior can be reduced somewhat  and the grounding is more compact
when the grounding introduces

n

disjuncts at a time 

h  p  d            p  dn    t
t  x  d    d    d            dn     p  x  

   

fide cat  denecker  stuckey   bruynooghe
to further remedy this  two search related heuristics are changed  first  the initial truth
value is randomized  but favoring false  as in most models  many more atoms are false than
true   second  search algorithms typically

restart

after an  ever increasing  threshold on the

number of conicts  sometimes caching the truth value assigned to atoms  

polarity caching   

this allows the solver to take learned information into account in the search heuristic while
staying approximately in the same part of the search space 

in case of lazy grounding 

we might want to jump to another part of the search space when we come across long
propagate ground sequences  to this end  we introduce the concept of

randomized restarts 

which take place after an  ever increasing  threshold on the number of times

g

is extended

and randomly ipping some of the cached truth values 
in addition  build djust always returns

false

if it is estimated that the formula has a

small grounding  indeed  grounding such formulas can help the search  whether a formula
is considered small is determined in terms of its  estimated  grounding size 
strategy is used in split and ground 

the same

whenever the formula to which one step ground

would be applied is small  ground is applied instead  to completely ground the formula 

      late grounding
grounding is applied during the search process as soon as unit propagation has taken place 
the result is a focus on the current location in the search space  but with the danger of
grounding too much if there is no solution in that part of the space  alternatively  we could
apply the opposite strategy  namely to ground as late as possible  only apply additional
grounding when the search algorithm terminates without ever having found a model in an
acceptable default state  such a strategy is well known from the elds of incremental proving
and planning  where the domain  number of time steps  is only increased after search over
the previous  smaller bound has nished  this guarantees a minimal grounding  a prototype
of this strategy has been implemented in

idp

with good results on planning problems 

    related inference tasks
the bulk of the paper focuses on model expansion  mx  for
solutions are structures that are two valued on

voc t   

fo id  

theories

t 

for which

often  one is only interested in a

small subset of the symbols in voc t    this is for example the case for model generation for
so id   the language which extends fo id  with existential quantication over relations 
an so id   problem p            pn   t with an initial structure i   relation symbols p           
pn   and t an fo id  theory  can be solved by model generation for the fo id  theory
t with initial structure i and by dropping the interpretation of the symbols p            pn in
the models  another example is query evaluation for fo id    given a theory t   an initial
structure i and a formula  with free variables x  all in fo id     the purpose of evaluating
the query ht   i  i is to nd assignments of domain elements d to x such that a model of
t exists that expands i and in which  x d  is true  to solve it by model expansion in
fo id    a new predicate symbol t is introduced and answers to the query are tuples of

domain elements d such that t d is true in a model of the theory t extended with the
sentence x  d   t  x  and the denition  x  d   t  x     
in both cases  approaches using  standard  model expansion compute a total interpretation and afterwards drop all unnecessary information  which is quite inecient  lazy model

   

filazy model expansion  interleaving grounding with search
expansion can save a lot of work by only partially grounding the theory  however  once a
model is found for the grounded part  the justications and the remaining denitions are
used to expand the structure to a model of the full theory 

although this expansion is

obtained in polynomial time  it is still inecient when afterwards a large part of the model
is dropped 
to remedy this  we dene a variant of the model expansion task  denoted

t 

restricted

mx 

i and an additional list of symbols o 
 
called output symbols  solutions are then structures m which are two valued on all symbols
in o and for which an expansion exists that extends i and is a model of t   adapting lazy
restricted mx takes as input a theory

a structure

grounding to solve restricted mx can be done through an analysis of which justications
need not be added  completely  to the structure  splitting

gd

into multiple denitions and

only evaluating those dening output symbols or symbols on which those depend  using a
stratication argument  
the above mentioned inference tasks can be cast trivially to restricted mx problems and
lazy restricted mx then greatly improves the eciency with respect to ground and solve  as
shown in the experimental section 
the extension of

fo id  

with

procedurally interpreted

symbols  de cat et al        

provides another class of interesting problems  such predicate symbols have a xed interpretation  but to know whether a tuple belongs to the predicate  a procedural function has
to be executed  such an approach provides a clean way to combine declarative and procedural specications  consider for example a symbol

isp rime n 

that is interpreted by a

procedure which executes an ecient prime verication algorithm and returns true i the
given argument is prime  we are generally not interested in the complete interpretation of

isp rime  so it can be cast as a restricted mx problem with isp rime not in o 

solving such

a problem using lazy grounding then has the benet of only executing the associated function

during

search for relevant atoms

isp rime d  

also for this task  we show an experimental

evaluation in the next section 

   experiments
the

idp

system has a state of the art model expansion engine  as can be observed from

previous answer set programming competitions  denecker et al         calimeri et al        
alviano et al          the lazy model expansion algorithms presented in this paper were
implemented in the

idp

system  by extending the existing algorithms  de cat  bogaerts 

devriendt    denecker        
the current implementation is incomplete in the sense that the cycle check for justications has not been implemented yet  this only aects inductive denitions as non inductive
ones can be replaced by the fo formulas of their completion 

as a workaround for the

lack of a cycle check  build djust  the function that constructs a direct justication  returns
false for rules dening inductive predicates  as a consequence  an instance of such a rule
is immediately grounded  although lazily  when a domain atom dened by the rule is assigned a value  another consequence is that inductively dened predicates cannot be used
in justications of other rules  this aects three benchmarks of the asp competition  de   within the asp community  they are sometimes referred to as show predicates 

   

fide cat  denecker  stuckey   bruynooghe
scribed below in section       namely

reachability  sokoban

and

labyrinth 

for these 

the grounding might be delayed even more in a complete implementation 
the section is organized as follows  in section      we evaluate the overhead of completely
grounding a theory using the presented approach  in section      we evaluate the eect of
lazy grounding on a number of benchmarks of the asp competition 

in section      a

number of additional properties of the presented algorithms are demonstrated 
we tested three dierent setups 
 referred to as

g s   idp

idp

with the standard ground and solve approach

with lazy model expansion  lazy  and the award winning asp

system gringo clasp  asp   we used

idp

version       lazy  gringo       and clasp       st 

the parameters of the lazy grounding algorithms are discussed in section      the values
used in the experiments are documented in appendix a  the experiments for sections    
and     were run on a    bit ubuntu       system with a quad core      ghz processor
and   gb of ram  experiments for section     were run on a    bit ubuntu       system
with a    core      ghz processor and     gb of ram  a timeout of      seconds and a
memory limit of   gb was used  out of time is indicated by

t 

out of memory by

m  

    eect on grounding time
lazy grounding may reduce grounding size and time but also causes overhead  for instance 
we expect the  naive  incremental querying of justications to be costly as discussed previously  the aim of this section is to quantify the overhead caused by lazy grounding  in the
experiments below we compare the grounding time of the standard idp system with that
of a

naive

instance of the lazy grounding algorithm that is forced to generate the complete

grounding before starting the search  this instance was obtained from the standard algorithm using some small changes  the shortcut to ground small formulas at once is turned
o  disjuncts and instances of existentially quantied formulas are grounded one by one  a
dened literal is enqueued for lazy grounding as soon as it appears in

g  

for comparison 

we also measure the cost of the standard lazy grounding algorithm that computes partial
groundings 
we devised six benchmarks to test various aspects of the novel algorithm  each benchmark is a simple theory with at most two sentences that is simple to solve  the benchmarks
are designed to measure the cost of dierent aspects of lazy grounding  delaying and resuming grounding  the querying needed to resume grounding  the splitting of formulas  etc 
specically  the tested aspects are the following 
   overhead of delaying and resuming grounding in case of an existential quantier with
a large domain 

the sentence is

n disjuncts  naive lazy
n    tseitin symbols 

clause with
introduces

x   p  x  

standard grounding creates a single

grounding grounds the formula piece by piece and

   overhead in case of an inductive denition  here

 x   p  x   p  x   q x   

standard grounding and naive lazy grounding construct a ground rule for each

both

p  d 

atom 
   benchmarks  experimental data and complete results are available at

krr experiments lazygrounding jair 

   

http   dtai cs kuleuven be 

filazy model expansion  interleaving grounding with search
   overhead in case of a universal quantication 
standard grounding creates

n

the sentence is

x   p  x  

while

atomic formulas  naive lazy grounding splits o one

instance at a time and introduces

n 

tseitin symbols 

   lifted unit propagation  lup   wittocx et al               is an important preprocessing step to reduce the grounding size  concretely  applying lup to the rules

x   r x 
x   r x   y   p  x  y 
derives that the second formula follows from the rst and hence does not need to be
grounded at all  this theory is used to check whether lup remains equally important
in a system with lazy grounding 

x  
r x   y   p  x  y   standard grounding creates a formula for each instance d of
x with a tseitin for the grounding of y   p  d  y   naive lazy grounding creates an
extra tseitin for each instance d of x and an extra set of tseitins for the piece by piece
grounding of the subformula y   p  d  y  

   overhead in case of nested universal quantication  the sentence is of the form

   overhead of the incremental querying in case a symbolic justication has to be validated  the sentence is

x   r x   s x  

with an identical justication formula  the

formula is validated by checking the falsity of the query
query is re evaluated each time an

r atom

or

s  atom

x   r x   s x  

this

is falsied 

      results
experiments were done for predicates

p

and

q

with arity   and

r

and

s

with arity    and

domains of size                and     none of the predicates symbols were interpreted in
the structure 
in all experiments  the overhead for the time required to solve the initial optimization
problem  for the global approach  was always around      seconds  so in itself negligible 
the results for the rst three experiments are not shown as the dierences between standard
grounding and naive lazy grounding are negligible 

while expected for experiment    for

experiments   and    it shows that our actual implementation eliminates the overhead for
tseitins when quantiers are not nested  in each of these three experiments  standard lazy
grounding is able to justify the formulas without grounding them and hence fast and almost
insensitive to the domain size  as shown in figure    there is no dierence between standard
grounding and naive lazy grounding for experiment    in both cases  the use of lup has a
big impact on the size of the grounding and hence on the time  while experiment   and  
showed that a top level quantier does not create overhead for lazy grounding  experiment  
shows that this does not hold anymore for nested quantiers and that naive lazy grounding
has substantial overhead when compared with standard grounding  note that this overhead
is worst case 

when tseitins can be justied  their denitions are not grounded  which

explains why normal lazy grounding is faster than standard grounding and insensitive to
the domain size 

experiment   shows that a more complex justication formula causes

signicant overhead for naive lazy grounding  also here  the overhead is worst case and not

   

fide cat  denecker  stuckey   bruynooghe

   grounding with bounds

   nested universal quantification

  

   complex justification  shared variables
   

  

ground without lup
ground with lup
naive lazy ground without lup
naive lazy ground with lup
lazy ground with lup

  
  

ground
naive lazy ground
lazy ground

  

ground
naive lazy ground
lazy ground

   
   

  
   

 

seconds

seconds

seconds

  
 

 

   
   

 
   
 

 

   

 

 

 

 
 

  

  

  

  

  

   
   
 

  

domain size

  

  

domain size

  

  

 

  

  

  

  

  

domain size

figure    time overhead of naive lazy grounding over ground and solve when completely
grounding the input theory  for benchmarks      and    the time includes grounding  solving and the time needed to nd justications  the time required by the
standard lazy grounding algorithm is also shown for comparison 

visible in normal lazy grounding  still  it is an important part of future research to reduce
the overhead of the incremental querying of complex justication formulas 

    asp competition benchmarks
second  we selected benchmarks from previous asp competitions to evaluate the lazy
grounding algorithm in a more realistic setting  many benchmarks solutions of that competition are carefully ne tuned for speed and minimal grounding  lazy grounding is usually
unable to substantially reduce the grounding of such theories and  due to its overhead  is
then slower than standard ground and solve  for this reason  we have sometimes selected
modelings of the benchmarks that are more natural but less optimized in time and grounding size  we justify this on the ground that the aim of our work is to improve inference for
declarative

modeling

 de cat et al          where the emphasis is not on developing intricate

encodings  but on modeling a problem close to its natural language specication 
we selected the following problems  see the competition websites for complete descriptions   they consist of problems that are known to be hard  in order to evaluate the eect
of lazy model expansion on search  and problems that typically result in a large grounding 

 reachability 

given a directed graph  determine whether a path exists between two

given nodes 

 labyrinth 

a planning problem where an agent traverses a graph by moving between

connected nodes to reach a given goal node  in addition  the graph can be manipulated
to change its connectedness 

 packing 

given a rectangle and a number of squares  t all squares into the grid

without overlaps 

 disjunctive scheduling 

schedule a number of actions with a given earliest start

and latest end time with additional constraints on precedence and disjointness 

   

filazy model expansion  interleaving grounding with search
  inst 

  solved

g s

benchmark

sokoban
disj  sched 
packing
labyrinth
reachability
stable marr 
graph col 

  

  

  

 

lazy
  

  

  

  
  

   

  

  

  

 

   

  

  

  
  

  

  

avg  time  sec  

asp

  

g s

lazy

asp

   

  

 

   

   

 

   

   

  
 

   

   

   
  

   
 

   

  

 

   

   

  

   

  

   
  
  

table    the number of solved instances for the asp benchmarks and the average time taken
on the solved instances  dierent solvers solve quite dierent sets of instances 

 sokoban 

a planning problem where a robot has to push a number of blocks to goal

positions  constrained by a   d maze 

 graph colouring 

given a graph  assign colour to nodes  from a given set of colours  

such that no connected nodes have the same colour 

 stable marriage 

given a set of men and women and a set of preferences  nd a

stable assignment  no swap results in a better match 
for each of these  we used all instances from the      and      competitions  except for
the     

reachability

instances  because of the huge data les which none of the systems

stable marriage  graph colouring and reachability  we
packing and disjunctive
idp
scheduling  we constructed a natural fo   encoding and made a faithful translation to
asp  for the more complex benchmarks of labyrinth and sokoban  we used the original
fo  idp and gringo clasp s asp specications submitted to the      competition  for the

is designed to handle 

for

based our encodings on the available asp core   encodings  for

lazy model expansion  we replaced cardinality expressions by their fo encoding as for the
former no justications are derived yet  this also increases the size of the full grounding 

      results
the number of solved instances and average time are shown in table    the average grounding
size for the

idp

 

setup is shown in table   

for time and grounding size  unsolved instances

reachability    times for g s 
asp   disjunctive scheduling    times for asp  labyrinth      times for g s 
once for asp   packing    times for g s    times for lazy     times for asp  and stable
marriage     times for asp   all other unsolved instances were caused by a time out  
were not taken into account  memory overows happened in
  times for

   grounding consists of variable instantiation interleaved with formula simplication  e g   dropping false
disjuncts  true conjuncts  replacing disjunctions with true disjuncts by true and conjunctions with false
conjunctions by false  etc   these simplication steps may seriously reduce the grounding size 
  

idp

has automatic symmetry breaking  the cause of the dierence between

colouring 

   

g s

and

asp

for

graph

fide cat  denecker  stuckey   bruynooghe
ground size    atoms 
benchmark

sokoban
disj  sched 
packing
labyrinth
reachability
stable marr 
graph col 

g s
         
         
         
         
         
         
         

lazy
         
         
         
         
         
         
         

ground time

asp
         
         
         
         
         
         
         

table    the average grounding size for the number of
marks  for all setups  for the
taken  for

g s

and

asp 

lazy

solved

g s sec  

asp

   
     
     
     
     
     

   

 sec  

   
   
   
   
    
   
   

instances of the asp bench 

setup  the size of the nal ground theory was

the average grounding time is also shown 

the results show that lazy model expansion solved more instances than the other setups
in four out of seven cases  in those cases  the problems also got solved signicantly below
the time threshold 

in ve out of seven cases  the  nal  grounding size was smaller for

lazy model expansion  orders of magnitude in one case  for

colouring 

sokoban  labyrinth and graph

lazy model expansion was outperformed by ground and solve  indicating that

sokoban 
lazy grounding size was even higher than for g s  possible due to the fo encoding
of cardinalities   indicating that a large part of the search space was explored  for stable
marriage  the relatively small dierence in grounding size between g s and lazy leads us
the loss of information outweighed the gain of grounding less up front  e g   for
the nal

to believe that the dierent search heuristic was the main factor  not lazy grounding itself 
we also experimented with the

airport pickup asp      benchmark  a fairly standard

scheduling problem  transporting passengers by taxis taking into account fuel consumption 
except that no upper bound on time is provided 

 

hence any ground and solve approach

would need to construct an innite grounding  applying straightforward lazy model expansion also resulted in a grounding that was too large  however  with the prototype that uses
the late grounding heuristic described in section     

idp

solved one out of ten instances 

for the others  grounding was not the problem  but the search took too long at each of the
time intervals

   n

considered to get up to a sucient

n

to solve the problem  even with the

standard search heuristic  
the presented results show that  although often benecial  lazy model expansion can be
a considerable overhead for some hard search problems  on the other hand  while inspecting
the outcome of the experiments  we observed that the class of specications and instances
solved by lazy grounding and traditional grounding only partially overlap  this suggests that
it might be a good idea to integrate both approaches into a

portfolio

system  such a system

can either select heuristically whether to use ground and solve or lazy model expansion
 based on the input  or running both in parallel  aborting either one if it uses too much
memory  however  on all the problems considered  lazy model expansion could start search
   it is possible to derive nite worst case thresholds for the airport pickup problem  this is  however  not
part of the original specication 

   

filazy model expansion  interleaving grounding with search
much earlier than ground and solve  even though it got lost more often during search  this
leads us to believe that to realize the full potential of lazy grounding  more work is necessary
on developing suitable heuristics  possibly user specied ones  

    specic experiments
in addition to the asp competition benchmarks  some experiments were conducted using
crafted benchmarks to illustrate specic properties of the lazy grounding algorithm 
the rst part of table   shows the results of scalability experiments  for each of the
benchmarks

packing  sokoban

and

disjunctive scheduling 

we selected a simple prob 

lem instance and gradually extended its domain size by orders of magnitude  the size of the
grid  packing  or the number of time points  sokoban 

disjunctive scheduling  

the

results show that for each of the instances  lazy model expansion scales much better than
the ground and solve strategies of
satisable instances  however  for
signicantly 

idp

and gringo clasp and for satisable as well as un 

disjunctive scheduling the solving time still increases

the reason is that the lazy heuristics are still naive and make uninformed

choices too often 
as we mentioned in the previous section  asp competition problems typically have small
groundings since running benchmarks which are too large for any system to handle does not
provide a useful comparison of the systems  hence  we also evaluated lazy model expansion
on a number of crafted benchmarks where grounding is non trivial 
work to look for more practical applications of this type 

it is part of future

we constructed the following

benchmarks 

 dynamic reachability 


lazy evaluation of

the example described in section     

procedurally interpreted

the prime numbers 

symbols  using a simple theory over

as described in section      a predicate symbol

isp rime  

is

interpreted by a procedure that returns true if the argument is prime 

function



a predicate encoding of a



an experiment that simulates model generation for a theory with an unknown domain 

with a huge domain 

used    quantied formulas
x    used x      model
 
domain of size     

the unknown domain is expressed by a new predicate

x   

are translated to

x    used x    

and

x   

generation is simulated by model expansion with a

to

for each one  a faithful asp encoding was constructed  the second part of table   shows
the results for these benchmarks  they show a signicant improvement of lazy model expansion over ground and solve on all examples  in each case  both
memory overow during grounding  while
for

disjunctive scheduling 

lazy

g s

and

asp

went into

found solutions within seconds  however 

it is also evident that the lazy approach would benet from

improved heuristics  increasing the domain size signicantly increases the solving time  while
the instances are not intrinsically harder 

      closer to inherent complexity 
during the modeling phase of an application  dierent encodings are typically tested out 
in an attempt to improve performance or to locate bugs  while modeling our experimental

   

fide cat  denecker  stuckey   bruynooghe
benchmark

packing   
packing   
packing   
sokoban    
sokoban    
sokoban    
disj sched sat    
disj sched sat    
disj sched sat    
disj sched unsat    
disj sched unsat    
disj sched unsat    
dynamic reachability
procedural
function
modelgeneration

lazy

g s

asp

   

   

   

   

   

   

   

     

   

    

   

   

   

    

   

   

t

    

    

    

    
     

     

     

      

m

m

    

    

    

    

     

     

m
m
m
m
m

m
m
m
m
m

     
    
    
    
    

table    the solving time for additional crafted benchmarks  one instance each 

benchmarks  we noticed that simplifying a theory by dropping constraints often resulted
in a dramatic reduction in the time lazy model expansion took to nd a model  standard
model expansion  on the other hand  was much less aected by such simplications 

in

our opinion  this observation  while hardly denitive evidence  is another indication that
the presented algorithms are able to derive justications for parts of a theory that can be
satised cheaply  in that way  the approach is able to distinguish better between problems
which are inherently dicult and problems which would just have a large grounding 

   related work
lazy model expansion oers a solution for the blow up of the grounding that often occurs
in the ground and solve model expansion methodology for

fo id  

theories 

answer set

programming  asp  and sat modulo theories  smt  techniques also process theories that
can have a large grounding  the constraint store of constraint programming  cp  and mixed
integer programming and the clauses of sat can be considered the equivalent of a grounded
theory  they are often derived from quantied descriptions such as  ci

j

  cj

for all i and

for which         and can also become very large  lefvre and nicolas        and ge and

de moura        have reported a blow up problem in these paradigms and a multitude of
techniques has been developed to address it  we distinguish four approaches 
first  concerning grounding up front  research has been done towards

of the grounding

i static analysis
ii

itself through    

reducing the size

of the input to derive bounds on variable

instantiations  wittocx et al                    techniques to

compile

specic types of sen 

tences into more compact ground sentences  tamura et al         metodi   codish        

iii  detect parts that can be evaluated polynomially  leone et al         gebser et al        
iv  detect parts that are not relevant to the task at hand  e g   in

 

jansen et al         and  

   

filazy model expansion  interleaving grounding with search
the context of query problems  as shown in the work of leone et al          naturally  each
of these approaches can be used in conjunction with lazy grounding to further reduce the
size of the grounding  in

idp 

i

e g   lazy grounding is already combined with     and  

second  the size of the grounding can be reduced by

enriching

the language 

iii  

for ex 

ample  asp solvers typically support ground aggregates  interpreted second order functions
such as cardinality or sum that take sets as arguments   and cp and smt solvers support
 uninterpreted  functions  more recently  the constraint asp paradigm was developed  ostrowski   schaub         that integrates asp and cp by extending the asp language with

constraint

atoms  these are interpreted as constraints in a csp problem and can thus be

handled using cp techniques  various casp solvers are already available  such as clingcon  ostrowski and schaub   ezcsp  balduccini         mingo  liu  janhunen    niemel 
      and inca  drescher   walsh         this technique is also integrated into
cat et al         

inca and

idp

idp

 de

in fact implement lazy clause generation  ohrimenko

et al          an optimized form of lazy grounding for specic types of constraints 
language hex asp  eiter et al         also extends asp  this time with

external

the

atoms

that represent  higher order  external function calls 
third 

incremental approaches

are well known from model generation  theorem proving

and planning  for these tasks  the domain is typically not xed in advance  but part of the
structure being sought  such as the number of time steps in a planning problem  recall the
sokoban example from the introduction   such an approach typically works by grounding
the problem for an initial guess of  the number of elements in  the domain 

afterwards 

search is applied  if no model was found  the domain is extended and more grounding is
done  this is iterated until a model is found or a bound on the maximum domain size is
hit  if one is known  

this technique is applied  e g   in the prover paradox  claessen  

srensson        and the asp solver iclingo  gebser et al         
fourth  and closest to lazy grounding itself  is a large body of research devoted to
delaying the grounding of specic types of expressions until necessary  for example until they
result in propagation   propagation techniques on the rst order level that delay grounding
until propagation ensues have been researched within asp  lefvre   nicolas        dal
pal et al         dao tran et al         and within cp  ohrimenko et al         

such

techniques can be used in conjunction with lazy grounding as they derive more intelligent
justications for specic types of constraints than presented here  for example  dao tran et
al  also presented an ecient algorithm for bottom up propagation in a denition  within
smt  various theory propagators work by lazily transforming their theory into sat  such
as for the theory of bit vectors by bruttomesso et al         

ge and de moura       

investigated quantier handling by combining heuristic instantiation methods with research
into decidable fragments of fo theories  as these can be eciently checked for models 
within asp  work has been done on goal directed reasoning  both bonatti  pontelli  and
son        and marple  bansal  min  and gupta        demonstrate approaches  in the
style of sld resolution  that apply top down instantiation to answer queries over innite
domains  saptawijaya and pereira        extend an abduction framework to lazily generate
part of the relevant sentences  in search algorithms  justications  or

watches  

are used to

derive when a constraint will not result in propagation or is already satised  and hence need
not be checked in the propagation phase  nightingale et al         show how maintaining
 short  justications can signicantly reduce the cost of the propagation phase 

   

fide cat  denecker  stuckey   bruynooghe
in fact  a well known technique already exists that combines search with lazy instantiation of quantiers  namely

skolemization 

where existentially quantied variables are re 

placed by newly introduced function symbols 

universal quantications are handled by

instantiating them for those introduced function symbols 

reasoning on consistency can 

e g   be achieved by congruence closure algorithms  capable of deriving consistency without eectively assigning an interpretation to the function symbols 

these techniques are

used in tableau theorem proving  hhnle        and smt solvers  detlefs  nelson    saxe 
      

formula  jackson  bjorner    schulte        interleaves creating a ground pro 

gram and giving it to an smt solver  iterating when symbolic guesses proved to be wrong 
skolemization based techniques typically work well in case only a small number of constants
needs to be introduced  but have diculty in case the relevant domain is large  one can also
see that lazy grounding  with support for function symbols  could incorporate skolemization by adapting the rules for grounding existential and universal quantication  we expect
skolemization to be complementary to lazy grounding  but an in depth investigation is part
of future work 
in the eld of probabilistic inference  several related techniques have been developed that
also rely on lazy instantiation  first  the problog system uses a form of static dependency
analysis to ground a  probabilistic  program in the context of a given query  by constructing
all possible ways to derive the query in a top down fashion  kimmig et al          second 
so called

lazy inference 

applied e g  in

lazysat

fact that  for the considered inference  a  xed 

 singla   domingos         exploits the

default

assumption exists under which

an expression certainly does not contribute to the probabilities 

hence  expressions for

which the assumption certainly holds do not have to be considered during search  third 

cutting plane inference

 riedel        applies lazy inference in an interleaved setting  only

constructing the part of the program for which the assumptions are not satised 

   future work
several aspects of the presented work need further investigation  one aspect is extending
support to lazily ground more complex expressions  including aggregate expressions and

p
  xd and p  x  f  x        which
atom p  d  is true  with d  d   p a

 nested  function terms  consider for example the sentence
expresses that the sum of terms
predicate and

f

f  d 

for which the

a function  should be larger than    one can observe that it is not necessary

to ground the whole sentence up front 
 hence positive   the set

for example  if

 p  d     f  d        

f

maps to the natural numbers

is a minimal justication 

even if no easy

justication can be found  we can suce by grounding only part of the sentence and delay

p

p  d    f  d          t  
p
p
with t a tseitin symbol dened as  
p  d    f  d         xd d  and p  x  f  x        indeed 
in any model of the sentence in which t is false  the original inequality is satised 

the remainder 

for example  we can create the ground sentence

 

a second aspect is whether there are advantages to grounding earlier  for example to
guarantee no propagation is lost  or grounding later  possibly reducing the size of the grounding even more  for example  consider the sentences

p 

and

p    

with



and



both large formulas for which no justication was found  instead of grounding at least one
of the sentences  we might add

p

to the list of atoms the search algorithm has to assign and

   

filazy model expansion  interleaving grounding with search
only ground either of the sentences when

p

has been assigned a value  it might even be that

unsatisability is detected before grounding either one  
given that lazy grounding is useful  what about lazy

forgetting

the grounded theory  as

the ground theory is extended when making the structure more precise  the ground theory
could be reduced again during backtracking 

by storing the justication violations that

caused grounding  we can derive which grounding can be forgotten again if the violation is
no longer problematic  e g   after backtracking   for this  an algorithm needs to be developed
which tracks grounding splitting dependencies between rules given their justications  this
closely resembles techniques used in tableau theorem proving and smt  where the theory
at hand can be compacted when moving to a dierent part of the search space 
the approach described for lazy grounding can also be applied to answer set generation
in the eld of asp  in asp  a logic program under stable semantics can be seen as one rule
set  a single denition  however  such asp programs do not satisfy a major condition to
apply lazy grounding  indeed such programs are typically non total  due to the presence of
constraints and rules of the form

p  not np  np  not p

or other

choice rules

which result

in multiple stable models  however  as described by denecker et al          most practical
asp programs can be partitioned in a set of choice rules  a set of

total

denitions and a set

of constraints  the so called generate dene test partition   any asp program that can
be gdt partitioned  can be translated straightforwardly into an equivalent

fo id  

theory

that only contains total denitions  this suggests a way to apply lazy grounding to such
asp programs 

   conclusion
solvers used in the domains of sat  smt and asp are often confronted with problems
that are too large to ground  lazy model expansion  the technique described in this paper 
interleaves grounding and search in order to avoid the grounding bottleneck  the technique
builds upon the concept of a justication  a deterministic recipe to extend an interpretation
such that it satises certain constraints  a theoretical framework has been developed for lazy
model expansion for the language

fo id   and algorithms have been presented to derive and

maintain such justications and to interleave grounding with state of the art cdcl search
algorithms 

the framework aims at bounded model expansion  in which all domains are

nite  but is also an initial step towards handling innite domains eciently  experimental
evaluation has been provided  using an implementation in the

idp

system  in which lazy

model expansion was compared with a state of the art ground and solve approach 

the

experiments showed considerable improvement over ground and solve in existing benchmarks
as well as in new applications  the main disadvantage is the less informed search algorithm 
caused by the delay in propagation and the introduction of additional symbols  a possible
solution is to develop new heuristics or portfolio approaches that combine the strengths of
both methods  finally  we have indicated a way how the proposed methods can be applied
beyond

fo id   

to asp solvers in general 

   

fide cat  denecker  stuckey   bruynooghe
acknowledgements
during this research  broes de cat was funded by the agency for innovation by science
and technology in flanders  iwt   this research was also supported by fwo vlaanderen
and by the project goa         research fund kuleuven 

nicta is funded by the

australian government through the department of communications and the australian
research council through the ict centre of excellence program 

appendix a  more details about the algorithms
in this appendix  we mention parameter values as well as some optimizations that further
reduce the grounding overhead and or improve the search  for each optimization  we indicate what is currently implemented  and part of the experimental results  and what is part
of future work 

a   parameter values
in      a number of parameters were introduced to control the behavior of lazy model
expansion 

here  we provide details on the values used in the experimental evaluation 

these values were set manually  based on experience and a limited number of observations
 e g   the extension threshold works similar to the conict threshold of the sat solver   it
is part of future work to study the impact of dierent values 



for an existential quantication     instantiations are grounded at a time  for a disjunction    disjuncts are grounded at a time  this turned out to give the best balance
between introducing too many tseitin atoms and grounding too much 



the initial truth value is



the initial threshold for randomized restarts is     extensions of the ground theory 

t

with probability

   

and

f

otherwise 

it is doubled after each restart 



a formula is considered small if its estimated grounding size is below

   

atoms 

a   extension to fo  idp
so far  we have described a lazy model expansion algorithm for function free
however 

fo  idp  

the knowledge base language of the

idp

fo id   

system  supports a much richer

input language  besides types which we use to initialize the domains it also supports
 partial  functions  aggregates and arithmetic 

our current implementation ignores the

latter extensions through a straightforward adaptation of build djust  algorithm     the
case for literals is extended to return

fo id  

false

when the literal is not part of the function free

language  for example  given a rule

a justication but

q f  x  

h  x   p  x   q f  x    p  x  can be used in

cannot  for functions  there is also the option to replace them

by graph predicates during the preprocessing step  as for the experiments of section     
functions  if any  are given in the input structure and hence play no role 
it is part of future work to extend lazy grounding for these extensions  especially for
functions  techniques developed in smt and in constraint programming to handle  ground 

   

filazy model expansion  interleaving grounding with search
atoms containing function symbols are useful to reduce the size of the grounding and improve
search  in previous work  these techniques have been integrated in the

idp

system  de cat

et al         and it is certainly worthwhile to fully integrate them with lazy grounding 

a   cheap propagation checks 
in lazy mx  it is checked for each assigned literal whether it is dened in

d

and whether

it violates any justications  to implement this cheaply  our implementation maintains a
mapping for literals in

g  

it states whether the literal is dened in

d

and also lists the

justications in which its negation occurs  this mapping is extended whenever a new literal
is added to

g

and maintained whenever justications change 

the performance of the

search loop is unaected as long as literals are assigned for which the mapping is empty 

a   stopping early
in algorithm    we took the standard stopping criterion used in most search algorithms
 line      to stop in a conict free state where

i

is two valued on all symbols of

principle  we may stop earlier  with a partial structure

pt  

indeed  corollary     tells us that such an

i

i

tg  g  

in

that admits a total justication for

can be expanded to a model  this has a

a dened
d that is irrelevant  in eect  does not appear in the justication  will trigger grounding
of a s denition  which in turn might introduce new literals dened in d   causing a cascade

considerable impact on grounding size  indeed  assigning a truth value to an atom
in

of unnecessary groundings and assignments 
justication of

g  

our solver algorithm does not maintain a

so it cannot know exactly when a justication exists 

instead  the

implemented algorithm only chooses literals that are watched by some formula rule 

it

stops with a partial structure in which unwatched literals may not be assigned  it can be
shown that this suces to guarantee that

i

admits a justication  hence it is safe to stop

search 

a   approximate justications
in some cases  build djust cannot nd a valid justication for a large formula because a few

i 
false if at least one atom of p
literals are already false in

for example for a formula

x  d   p  x  

build djust returns

is false  instead  we have adapted build djust with a heuristic

check on the number of expected violations  if it is small enough  the justication is still
returned  naturally  we are then required to check whether there are any real violations  by
querying the justication formula over

i 

and apply lazy ground to them 

references
alviano  m   calimeri  f   charwat  g   dao tran  m   dodaro  c   ianni  g   krennwallner 
t   kronegger  m   oetsch  j   pfandler  a   phrer  j   redl  c   ricca  f   schneider 
p   schwengerer  m   spendier  l  k   wallner  j  p     xiao  g          the fourth
answer set programming competition  preliminary report 
t  c   eds   
apt  k  r         

in cabalar  p     son 

lpnmr  vol       of lncs  pp        springer 
principles of constraint programming  cambridge university press 
   

fide cat  denecker  stuckey   bruynooghe
balduccini  m         

industrial size scheduling with asp cp 

in delgrande  j  p    

lpnmr  vol       of lncs  pp          springer 
knowledge representation  reasoning  and declarative problem solving 

faber  w   eds   
baral  c         

cambridge university press  new york  ny  usa 
bonatti  p  a   pontelli  e     son  t  c         

credulous resolution for answer set

programming  in fox  d     gomes  c  p   eds   

aaai  pp          aaai press 

bruttomesso  r   cimatti  a   franzn  a   griggio  a   hanna  z   nadel  a   palti  a  
  sebastiani  r         
verication problems 

a lazy and layered smt bv  solver for hard industrial

in damm  w     hermanns  h   eds   

lncs  pp          springer 

cav 

vol       of

calimeri  f   ianni  g     ricca  f          the third open answer set programming competition 

tplp                 

chen  w     warren  d  s          tabled evaluation with delaying for general logic programs 

j  acm               

claessen  k     srensson  n         

new techniques that improve mace style model

proceedings of the cade    workshop  model computation   principles 
algorithms  applications 
nding  in

dal pal  a   dovier  a   pontelli  e     rossi  g          answer set programming with
constraints using lazy grounding  in hill  p  m     warren  d  s   eds   
     of

lncs  pp          springer 

dao tran  m   eiter  t   fink  m   weidinger  g     weinzierl  a         

iclp 

vol 

omiga   an

open minded grounding on the y answer set solver  in del cerro  l  f   herzig  a  

jelia  vol       of lncs  pp          springer 
cat  b          separating knowledge from computation  an fo    knowledge base
system and its model expansion inference  ph d  thesis  ku leuven  leuven  belgium 
  mengin  j   eds   

de

de cat  b   bogaerts  b   bruynooghe  m     denecker  m         
modelling language  the idp system 

corr  abs           

predicate logic as a

de cat  b   bogaerts  b   devriendt  j     denecker  m          model expansion in the
presence of function symbols using constraint programming  in

ictai  pp           

ieee 
de cat  b   denecker  m     stuckey  p  j          lazy model expansion by incremental
grounding  in dovier  a     costa  v  s   eds   

iclp  technical communications  

lipics  pp          schloss dagstuhl   leibniz zentrum fuer informatik 
delgrande  j  p     faber  w   eds            logic programming and nonmonotonic reasoning     th international conference  lpnmr       vancouver  canada  may       
      proceedings  vol       of lncs  springer 
vol     of

denecker  m          the well founded semantics is the principle of inductive denition  in
dix  j   del cerro  l  f     furbach  u   eds   
springer 

   

jelia  vol       of lncs  pp      

filazy model expansion  interleaving grounding with search
denecker  m          extending classical logic with inductive denitions  in lloyd  j  w  
dahl  v   furbach  u   kerber  m   lau  k  k   palamidessi  c   pereira  l  m   sagiv 
y     stuckey  p  j   eds   

cl  vol       of lncs  pp          springer 

denecker  m   bruynooghe  m     marek  v  w          logic programming revisited  logic
programs as inductive denitions 

acm trans  comput  log                 

denecker  m     de schreye  d          justication semantics  a unifying framework for
the semantics of logic programs 

tech  rep       department of computer science 

k u leuven 
denecker  m     de schreye  d          justication semantics  a unifying framework for
the semantics of logic programs  in pereira  l  m     nerode  a   eds   

lpnmr  pp 

        mit press 
denecker  m   lierler  y   truszczynski  m     vennekens  j         
mal semantics for answer set programming 

iclp  technical communications  

vol     of

a tarskian infor 

in dovier  a     costa  v  s   eds   

lipics 

pp          schloss dagstuhl

  leibniz zentrum fuer informatik 
denecker  m     ternovska  e          a logic of nonmonotone inductive denitions 

trans  comput  log                    

acm

denecker  m     vennekens  j          the well founded semantics is the principle of inductive denition  revisited  in baral  c   de giacomo  g     eiter  t   eds   

kr 

pp 

      aaai press 
denecker  m   vennekens  j   bond  s   gebser  m     truszczyski  m          the second
answer set programming competition 

in erdem  e   lin  f     schaub  t   eds   

lpnmr  vol       of lncs  pp          springer 
detlefs  d   nelson  g     saxe  j  b         
checking 

j  acm                 

simplify  a theorem prover for program

technical communications of the   th international conference on logic programming  iclp       september            budapest 
hungary  proceedings  vol     of lipics  schloss dagstuhl   leibniz zentrum fuer in 

dovier  a     costa  v  s   eds           

formatik 
drescher  c     walsh  t          answer set solving with lazy nogood generation  in dovier 
a     costa  v  s   eds   

iclp  technical communications  

vol     of

lipics 

pp 

        schloss dagstuhl   leibniz zentrum fuer informatik 
eiter  t   ianni  g   schindlauer  r     tompits  h          a uniform integration of higherorder reasoning and external evaluations in answer set programming 

in kaelbling 

ijcai  pp        professional book center 
a mathematical introduction to logic  second edition  

l  p     saotti  a   eds   
enderton  h  b         

academic

press 

logic programming and nonmonotonic reasoning    th international conference  lpnmr       potsdam  germany  september
             proceedings  vol       of lncs  springer 

erdem  e   lin  f     schaub  t   eds           

   

fide cat  denecker  stuckey   bruynooghe
ge  y     de moura  l  m          complete instantiation for quantied formulas in satisabiliby modulo theories  in bouajjani  a     maler  o   eds   

lncs  pp          springer 

cav 

vol       of

gebser  m   kaminski  r   kaufmann  b   ostrowski  m   schaub  t     thiele  s         
engineering an incremental asp solver 
 eds   

in garca de la banda  m     pontelli  e 

iclp  vol       of lncs  pp          springer 

gebser  m   kaminski  r   knig  a     schaub  t          advances in gringo series   
in delgrande  j  p     faber  w   eds   

lpnmr 

vol       of

lncs 

pp         

springer 
gebser  m   schaub  t     thiele  s         

gringo   a new grounder for answer set

programming  in baral  c   brewka  g     schlipf  j  s   eds   

lncs  pp          springer 

hhnle  r         
 eds   

tableaux and related methods 

lpnmr  vol       of

in robinson  j  a     voronkov  a 

handbook of automated reasoning  pp          elsevier and mit press 

jackson  e  k   bjorner  n     schulte  w         

open world logic programs  a new

foundation for formal specications  tech  rep  msr tr          microsoft research 
jansen  j   jorissen  a     janssens  g          compiling input

 
into tabled prolog rules for idp  

fo   inductive denitions

tplp                   

karp  r          reducibility among combinatorial problems  in miller  r     thatcher  j 
 eds   

complexity of computer computations  pp         plenum press 

kimmig  a   demoen  b   de raedt  l   santos costa  v     rocha  r         
implementation of the probabilistic logic programming language problog 

                 

lefvre  c     nicolas  p         

on the

tplp 

the rst version of a new asp solver  asperix 

erdem  e   lin  f     schaub  t   eds   

lpnmr 

vol       of

lncs 

in

pp         

springer 
leone  n   pfeifer  g   faber  w   eiter  t   gottlob  g   perri  s     scarcello  f         
the dlv system for knowledge representation and reasoning 

log                 

acm trans  comput 

liu  g   janhunen  t     niemel  i          answer set programming via mixed integer
programming 

in brewka  g   eiter  t     mcilraith  s  a   eds   

kr 

pp       

aaai press 
marek  v  w     truszczyski  m         
gramming paradigm 
d  s   eds   

stable models and an alternative logic pro 

in apt  k  r   marek  v  w   truszczyski  m     warren 

the logic programming paradigm  a    year perspective 

pp         

springer verlag 
marin  m         

model generation for id logic 

ph d  thesis  department of computer

science  ku leuven  belgium 
marin  m   gilis  d     denecker  m          on the relation between id logic and answer
set programming  in alferes  j  j     leite  j  a   eds   
pp          springer 

   

jelia 

vol       of

lncs 

filazy model expansion  interleaving grounding with search
marin  m   wittocx  j   denecker  m     bruynooghe  m          sat id   satisability of
propositional logic extended with inductive denitions  in kleine bning  h     zhao 
x   eds   

sat  vol       of lncs  pp          springer 

marple  k   bansal  a   min  r     gupta  g          goal directed execution of answer
set programs  in schreye  d  d   janssens  g     king  a   eds   

ppdp 

pp       

acm 
marques silva  j  p   lynce  i     malik  s         

conict driven clause learning sat

handbook of
satisability  vol      of frontiers in articial intelligence and applications  pp     
solvers 

in biere  a   heule  m   van maaren  h     walsh  t   eds   

     ios press 
metodi  a     codish  m          compiling nite domain constraints to sat with bee 

tplp                   

mitchell  d  g     ternovska  e         

a framework for representing and solving np

search problems  in veloso  m  m     kambhampati  s   eds   

aaai 

pp         

aaai press   the mit press 
mitchell  d  g   ternovska  e   hach  f     mohebali  r         

model expansion as a

framework for modelling and solving search problems  tech  rep  tr          simon
fraser university  canada 
nethercote  n   stuckey  p   becket  r   brand  s   duck  g     tack  g          minizinc 
towards a standard cp modelling language  in bessiere  c   ed   
of

lncs  pp          springer 

cp    

vol      

nightingale  p   gent  i  p   jeerson  c     miguel  i          short and long supports for
constraint propagation 

j  artif  intell  res   jair           

ohrimenko  o   stuckey  p  j     codish  m          propagation via lazy clause generation 

constraints                 

ostrowski  m     schaub  t         

                 

asp modulo csp  the clingcon system 

riedel  s          cutting plane map inference for markov logic  in

on statistical relational learning  srl       

saptawijaya  a     pereira  l  m         

tplp 

international workshop

towards practical tabled abduction in logic

programs  in correia  l   reis  l  p     cascalho  j   eds   

epia  vol       of lncs 

pp          springer 
singla  p     domingos  p          memory ecient inference in relational domains  in gil 
y     mooney  r  j   eds   

aaai  pp          aaai press 

son  t  c   pontelli  e     le  t         

two applications of the asp prolog system 

decomposable programs and multi context systems  in flatt  m     guo  h  f   eds   

padl  vol       of lecture notes in computer science  pp         springer 

tamura  n   taga  a   kitagawa  s     banbara  m          compiling nite linear csp
into sat 

constraints                 

   

fide cat  denecker  stuckey   bruynooghe
torlak  e   chang  f  s  h     jackson  d          finding minimal unsatisable cores of
declarative specications  in cullar  j   maibaum  t  s  e     sere  k   eds   
vol       of

lncs  pp          springer 

fm 

tseitin  g  s          on the complexity of derivation in propositional calculus  in slisenko 
a  o   ed   

studies in constructive mathematics and mathematical logic ii  pp     

     consultants bureau  n y 
van gelder  a          the alternating xpoint of logic programs with negation 

syst  sci                  

j  comput 

vennekens  j   marin  m   wittocx  j     denecker  m          predicate introduction for
logics with a xpoint semantics  part i  logic programming 

                 

fundamenta informaticae 

wittocx  j   denecker  m     bruynooghe  m          constraint propagation for rst order
logic and inductive denitions 

acm trans  comput  logic                    

wittocx  j   marin  m     denecker  m          the

idp system  a model expansion system

for an extension of classical logic  in denecker  m   ed   

lash  pp          acco 

wittocx  j   marin  m     denecker  m          grounding fo and fo id  with bounds 

j  artif  intell  res   jair              

   

fi